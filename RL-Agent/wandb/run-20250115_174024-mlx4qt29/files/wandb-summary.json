{"PPO Batch Consumption Time":0.09413313865661621,"Cumulative Model Updates":3710,"Policy Entropy":3.7819341818491616,"_step":2475,"x_vel":34.2939005854639,"Overall Steps per Second":15805.906227308511,"Value Function Update Magnitude":0.053568676114082336,"y_vel":553.8795722095366,"z_vel":13.020349842975703,"Policy Reward":0.0035230770289478505,"Collected Steps per Second":22252.483060145132,"_runtime":3663.2907764,"SB3 Clip Fraction":0.00365333321193854,"Mean KL Divergence":0.0008678114778983096,"_wandb":{"runtime":3663},"Timestep Collection Time":2.247569399999975,"Cumulative Timesteps":61919042,"Total Iteration Time":3.164260199999717,"Policy Update Magnitude":0.08086339384317398,"_timestamp":1.736984487613062e+09,"Timesteps Collected":50014,"Timestep Consumption Time":0.916690799999742,"Value Function Loss":0.09101556489864986}