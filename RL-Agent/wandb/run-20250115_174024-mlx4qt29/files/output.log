Created new wandb run! mlx4qt29
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01873
Policy Entropy: 4.49884
Value Function Loss: nan

Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06621
Value Function Update Magnitude: 0.06878

Collected Steps per Second: 22,499.85640
Overall Steps per Second: 16,243.69887

Timestep Collection Time: 2.22313
Timestep Consumption Time: 0.85622
PPO Batch Consumption Time: 0.14591
Total Iteration Time: 3.07935

Cumulative Model Updates: 1
Cumulative Timesteps: 50,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00979
Policy Entropy: 4.49884
Value Function Loss: 0.55682

Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09225
Value Function Update Magnitude: 0.10829

Collected Steps per Second: 22,657.30141
Overall Steps per Second: 15,072.76474

Timestep Collection Time: 2.20724
Timestep Consumption Time: 1.11067
PPO Batch Consumption Time: 0.16845
Total Iteration Time: 3.31790

Cumulative Model Updates: 3
Cumulative Timesteps: 100,030

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 100030...
Checkpoint 100030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07854
Policy Entropy: 4.49878
Value Function Loss: 0.90179

Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08339
Value Function Update Magnitude: 0.11207

Collected Steps per Second: 23,845.47135
Overall Steps per Second: 17,248.88732

Timestep Collection Time: 2.09717
Timestep Consumption Time: 0.80203
PPO Batch Consumption Time: 0.05848
Total Iteration Time: 2.89920

Cumulative Model Updates: 5
Cumulative Timesteps: 150,038

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03514
Policy Entropy: 4.49869
Value Function Loss: 1.60375

Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11199
Value Function Update Magnitude: 0.16530

Collected Steps per Second: 23,709.10898
Overall Steps per Second: 15,295.96366

Timestep Collection Time: 2.10965
Timestep Consumption Time: 1.16036
PPO Batch Consumption Time: 0.13425
Total Iteration Time: 3.27001

Cumulative Model Updates: 8
Cumulative Timesteps: 200,056

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 200056...
Checkpoint 200056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00752
Policy Entropy: 4.49858
Value Function Loss: 1.88189

Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10605
Value Function Update Magnitude: 0.16870

Collected Steps per Second: 23,151.47926
Overall Steps per Second: 15,729.51301

Timestep Collection Time: 2.16047
Timestep Consumption Time: 1.01942
PPO Batch Consumption Time: 0.10131
Total Iteration Time: 3.17988

Cumulative Model Updates: 11
Cumulative Timesteps: 250,074

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02995
Policy Entropy: 4.49850
Value Function Loss: 2.13847

Mean KL Divergence: 0.00005
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10188
Value Function Update Magnitude: 0.17280

Collected Steps per Second: 24,524.03571
Overall Steps per Second: 17,434.58222

Timestep Collection Time: 2.03890
Timestep Consumption Time: 0.82908
PPO Batch Consumption Time: 0.06273
Total Iteration Time: 2.86798

Cumulative Model Updates: 14
Cumulative Timesteps: 300,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 300076...
Checkpoint 300076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01938
Policy Entropy: 4.49841
Value Function Loss: 1.87958

Mean KL Divergence: 0.00005
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09865
Value Function Update Magnitude: 0.17720

Collected Steps per Second: 19,553.22320
Overall Steps per Second: 14,046.57069

Timestep Collection Time: 2.55825
Timestep Consumption Time: 1.00291
PPO Batch Consumption Time: 0.07565
Total Iteration Time: 3.56115

Cumulative Model Updates: 17
Cumulative Timesteps: 350,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00577
Policy Entropy: 4.49829
Value Function Loss: 1.96267

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09566
Value Function Update Magnitude: 0.18315

Collected Steps per Second: 22,092.76895
Overall Steps per Second: 16,174.73161

Timestep Collection Time: 2.26337
Timestep Consumption Time: 0.82812
PPO Batch Consumption Time: 0.03056
Total Iteration Time: 3.09149

Cumulative Model Updates: 20
Cumulative Timesteps: 400,102

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 400102...
Checkpoint 400102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02636
Policy Entropy: 4.49813
Value Function Loss: 1.96102

Mean KL Divergence: 0.00007
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08979
Value Function Update Magnitude: 0.18990

Collected Steps per Second: 24,190.85184
Overall Steps per Second: 17,202.14835

Timestep Collection Time: 2.06805
Timestep Consumption Time: 0.84019
PPO Batch Consumption Time: 0.03091
Total Iteration Time: 2.90824

Cumulative Model Updates: 23
Cumulative Timesteps: 450,130

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06637
Policy Entropy: 4.49795
Value Function Loss: 2.20806

Mean KL Divergence: 0.00007
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08794
Value Function Update Magnitude: 0.19612

Collected Steps per Second: 21,242.85711
Overall Steps per Second: 14,200.52066

Timestep Collection Time: 2.35383
Timestep Consumption Time: 1.16731
PPO Batch Consumption Time: 0.11398
Total Iteration Time: 3.52114

Cumulative Model Updates: 26
Cumulative Timesteps: 500,132

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 500132...
Checkpoint 500132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01274
Policy Entropy: 4.49775
Value Function Loss: 2.30373

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08847
Value Function Update Magnitude: 0.20226

Collected Steps per Second: 19,531.97250
Overall Steps per Second: 13,946.12498

Timestep Collection Time: 2.56001
Timestep Consumption Time: 1.02536
PPO Batch Consumption Time: 0.10322
Total Iteration Time: 3.58537

Cumulative Model Updates: 29
Cumulative Timesteps: 550,134

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03549
Policy Entropy: 4.49753
Value Function Loss: 2.32693

Mean KL Divergence: 0.00007
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08918
Value Function Update Magnitude: 0.20865

Collected Steps per Second: 23,423.40992
Overall Steps per Second: 15,795.33402

Timestep Collection Time: 2.13470
Timestep Consumption Time: 1.03092
PPO Batch Consumption Time: 0.09929
Total Iteration Time: 3.16562

Cumulative Model Updates: 32
Cumulative Timesteps: 600,136

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 600136...
Checkpoint 600136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00702
Policy Entropy: 4.49729
Value Function Loss: 2.37516

Mean KL Divergence: 0.00007
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08923
Value Function Update Magnitude: 0.21273

Collected Steps per Second: 23,575.20184
Overall Steps per Second: 16,501.16188

Timestep Collection Time: 2.12181
Timestep Consumption Time: 0.90962
PPO Batch Consumption Time: 0.05829
Total Iteration Time: 3.03142

Cumulative Model Updates: 35
Cumulative Timesteps: 650,158

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01237
Policy Entropy: 4.49699
Value Function Loss: 2.32002

Mean KL Divergence: 0.00009
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09031
Value Function Update Magnitude: 0.21450

Collected Steps per Second: 21,555.53509
Overall Steps per Second: 14,858.52054

Timestep Collection Time: 2.32033
Timestep Consumption Time: 1.04582
PPO Batch Consumption Time: 0.10160
Total Iteration Time: 3.36615

Cumulative Model Updates: 38
Cumulative Timesteps: 700,174

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 700174...
Checkpoint 700174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00208
Policy Entropy: 4.49665
Value Function Loss: 2.30462

Mean KL Divergence: 0.00011
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09146
Value Function Update Magnitude: 0.21224

Collected Steps per Second: 23,401.24547
Overall Steps per Second: 15,702.66096

Timestep Collection Time: 2.13766
Timestep Consumption Time: 1.04804
PPO Batch Consumption Time: 0.09725
Total Iteration Time: 3.18570

Cumulative Model Updates: 41
Cumulative Timesteps: 750,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03203
Policy Entropy: 4.49616
Value Function Loss: 2.22859

Mean KL Divergence: 0.00014
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09322
Value Function Update Magnitude: 0.20814

Collected Steps per Second: 23,599.08105
Overall Steps per Second: 16,980.47930

Timestep Collection Time: 2.12034
Timestep Consumption Time: 0.82646
PPO Batch Consumption Time: 0.05774
Total Iteration Time: 2.94680

Cumulative Model Updates: 44
Cumulative Timesteps: 800,236

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 800236...
Checkpoint 800236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10295
Policy Entropy: 4.49537
Value Function Loss: 1.56059

Mean KL Divergence: 0.00020
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09477
Value Function Update Magnitude: 0.18982

Collected Steps per Second: 22,037.71179
Overall Steps per Second: 15,417.89498

Timestep Collection Time: 2.26902
Timestep Consumption Time: 0.97422
PPO Batch Consumption Time: 0.07486
Total Iteration Time: 3.24324

Cumulative Model Updates: 47
Cumulative Timesteps: 850,240

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02812
Policy Entropy: 4.49418
Value Function Loss: 0.86429

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08945
Value Function Update Magnitude: 0.15999

Collected Steps per Second: 23,423.05206
Overall Steps per Second: 16,710.18989

Timestep Collection Time: 2.13482
Timestep Consumption Time: 0.85761
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 2.99243

Cumulative Model Updates: 50
Cumulative Timesteps: 900,244

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 900244...
Checkpoint 900244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01342
Policy Entropy: 4.49262
Value Function Loss: 0.25050

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07694
Value Function Update Magnitude: 0.14508

Collected Steps per Second: 19,585.40556
Overall Steps per Second: 14,021.83066

Timestep Collection Time: 2.55323
Timestep Consumption Time: 1.01307
PPO Batch Consumption Time: 0.08878
Total Iteration Time: 3.56630

Cumulative Model Updates: 53
Cumulative Timesteps: 950,250

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01707
Policy Entropy: 4.49087
Value Function Loss: 0.14900

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06476
Value Function Update Magnitude: 0.14991

Collected Steps per Second: 22,522.39168
Overall Steps per Second: 15,656.98131

Timestep Collection Time: 2.22046
Timestep Consumption Time: 0.97365
PPO Batch Consumption Time: 0.05754
Total Iteration Time: 3.19410

Cumulative Model Updates: 56
Cumulative Timesteps: 1,000,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1000260...
Checkpoint 1000260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01374
Policy Entropy: 4.48917
Value Function Loss: 0.12896

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05360
Value Function Update Magnitude: 0.16118

Collected Steps per Second: 19,398.97606
Overall Steps per Second: 13,995.66188

Timestep Collection Time: 2.57900
Timestep Consumption Time: 0.99568
PPO Batch Consumption Time: 0.08744
Total Iteration Time: 3.57468

Cumulative Model Updates: 59
Cumulative Timesteps: 1,050,290

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02286
Policy Entropy: 4.48778
Value Function Loss: 0.10999

Mean KL Divergence: 0.00019
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04801
Value Function Update Magnitude: 0.16671

Collected Steps per Second: 23,529.56788
Overall Steps per Second: 15,696.96328

Timestep Collection Time: 2.12507
Timestep Consumption Time: 1.06039
PPO Batch Consumption Time: 0.10440
Total Iteration Time: 3.18546

Cumulative Model Updates: 62
Cumulative Timesteps: 1,100,292

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1100292...
Checkpoint 1100292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03096
Policy Entropy: 4.48671
Value Function Loss: 0.09423

Mean KL Divergence: 0.00013
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04567
Value Function Update Magnitude: 0.14881

Collected Steps per Second: 23,907.19266
Overall Steps per Second: 16,785.09615

Timestep Collection Time: 2.09142
Timestep Consumption Time: 0.88741
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 2.97883

Cumulative Model Updates: 65
Cumulative Timesteps: 1,150,292

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02122
Policy Entropy: 4.48593
Value Function Loss: 0.07184

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04282
Value Function Update Magnitude: 0.12378

Collected Steps per Second: 21,431.06907
Overall Steps per Second: 14,724.85576

Timestep Collection Time: 2.33306
Timestep Consumption Time: 1.06256
PPO Batch Consumption Time: 0.10560
Total Iteration Time: 3.39562

Cumulative Model Updates: 68
Cumulative Timesteps: 1,200,292

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1200292...
Checkpoint 1200292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05283
Policy Entropy: 4.48534
Value Function Loss: 0.05229

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03985
Value Function Update Magnitude: 0.10451

Collected Steps per Second: 23,466.72063
Overall Steps per Second: 16,527.25670

Timestep Collection Time: 2.13093
Timestep Consumption Time: 0.89474
PPO Batch Consumption Time: 0.02960
Total Iteration Time: 3.02567

Cumulative Model Updates: 71
Cumulative Timesteps: 1,250,298

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00198
Policy Entropy: 4.48488
Value Function Loss: 0.05474

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03735
Value Function Update Magnitude: 0.09022

Collected Steps per Second: 21,166.10489
Overall Steps per Second: 15,520.74077

Timestep Collection Time: 2.36350
Timestep Consumption Time: 0.85968
PPO Batch Consumption Time: 0.05328
Total Iteration Time: 3.22317

Cumulative Model Updates: 74
Cumulative Timesteps: 1,300,324

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1300324...
Checkpoint 1300324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03636
Policy Entropy: 4.48447
Value Function Loss: 0.04748

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03470
Value Function Update Magnitude: 0.07789

Collected Steps per Second: 22,441.30341
Overall Steps per Second: 16,426.28356

Timestep Collection Time: 2.22937
Timestep Consumption Time: 0.81636
PPO Batch Consumption Time: 0.02933
Total Iteration Time: 3.04573

Cumulative Model Updates: 77
Cumulative Timesteps: 1,350,354

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00658
Policy Entropy: 4.48408
Value Function Loss: 0.04646

Mean KL Divergence: 0.00005
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03393
Value Function Update Magnitude: 0.06786

Collected Steps per Second: 21,273.02373
Overall Steps per Second: 15,342.82767

Timestep Collection Time: 2.35162
Timestep Consumption Time: 0.90893
PPO Batch Consumption Time: 0.05095
Total Iteration Time: 3.26055

Cumulative Model Updates: 80
Cumulative Timesteps: 1,400,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1400380...
Checkpoint 1400380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03605
Policy Entropy: 4.48368
Value Function Loss: 0.03963

Mean KL Divergence: 0.00005
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03389
Value Function Update Magnitude: 0.06003

Collected Steps per Second: 19,815.76788
Overall Steps per Second: 15,278.43599

Timestep Collection Time: 2.52385
Timestep Consumption Time: 0.74952
PPO Batch Consumption Time: 0.03003
Total Iteration Time: 3.27337

Cumulative Model Updates: 83
Cumulative Timesteps: 1,450,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00107
Policy Entropy: 4.48327
Value Function Loss: 0.04005

Mean KL Divergence: 0.00005
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03159
Value Function Update Magnitude: 0.05480

Collected Steps per Second: 23,650.82493
Overall Steps per Second: 16,116.19902

Timestep Collection Time: 2.11494
Timestep Consumption Time: 0.98877
PPO Batch Consumption Time: 0.07967
Total Iteration Time: 3.10371

Cumulative Model Updates: 86
Cumulative Timesteps: 1,500,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1500412...
Checkpoint 1500412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04927
Policy Entropy: 4.48313
Value Function Loss: 0.06517

Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03009
Value Function Update Magnitude: 0.04974

Collected Steps per Second: 23,375.87935
Overall Steps per Second: 16,871.67989

Timestep Collection Time: 2.13930
Timestep Consumption Time: 0.82472
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 2.96402

Cumulative Model Updates: 89
Cumulative Timesteps: 1,550,420

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01868
Policy Entropy: 4.48318
Value Function Loss: 0.06548

Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03188
Value Function Update Magnitude: 0.04842

Collected Steps per Second: 19,461.91956
Overall Steps per Second: 13,857.82706

Timestep Collection Time: 2.57015
Timestep Consumption Time: 1.03937
PPO Batch Consumption Time: 0.09444
Total Iteration Time: 3.60951

Cumulative Model Updates: 92
Cumulative Timesteps: 1,600,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1600440...
Checkpoint 1600440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04390
Policy Entropy: 4.48322
Value Function Loss: 0.06586

Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03441
Value Function Update Magnitude: 0.04837

Collected Steps per Second: 23,647.11396
Overall Steps per Second: 16,490.13073

Timestep Collection Time: 2.11527
Timestep Consumption Time: 0.91806
PPO Batch Consumption Time: 0.05927
Total Iteration Time: 3.03333

Cumulative Model Updates: 95
Cumulative Timesteps: 1,650,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01509
Policy Entropy: 4.48310
Value Function Loss: 0.04115

Mean KL Divergence: 0.00005
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03229
Value Function Update Magnitude: 0.04558

Collected Steps per Second: 22,311.42869
Overall Steps per Second: 16,290.17771

Timestep Collection Time: 2.24244
Timestep Consumption Time: 0.82886
PPO Batch Consumption Time: 0.02957
Total Iteration Time: 3.07130

Cumulative Model Updates: 98
Cumulative Timesteps: 1,700,492

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1700492...
Checkpoint 1700492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01855
Policy Entropy: 4.48286
Value Function Loss: 0.04151

Mean KL Divergence: 0.00005
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03033
Value Function Update Magnitude: 0.04428

Collected Steps per Second: 23,727.13201
Overall Steps per Second: 16,642.09156

Timestep Collection Time: 2.10822
Timestep Consumption Time: 0.89753
PPO Batch Consumption Time: 0.05235
Total Iteration Time: 3.00575

Cumulative Model Updates: 101
Cumulative Timesteps: 1,750,514

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04685
Policy Entropy: 4.48274
Value Function Loss: 0.03485

Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.02762
Value Function Update Magnitude: 0.04306

Collected Steps per Second: 22,368.07713
Overall Steps per Second: 15,442.15578

Timestep Collection Time: 2.23542
Timestep Consumption Time: 1.00260
PPO Batch Consumption Time: 0.10979
Total Iteration Time: 3.23802

Cumulative Model Updates: 104
Cumulative Timesteps: 1,800,516

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1800516...
Checkpoint 1800516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02134
Policy Entropy: 4.48277
Value Function Loss: 0.05414

Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.02702
Value Function Update Magnitude: 0.04061

Collected Steps per Second: 23,950.66898
Overall Steps per Second: 16,368.11450

Timestep Collection Time: 2.08829
Timestep Consumption Time: 0.96740
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 3.05570

Cumulative Model Updates: 107
Cumulative Timesteps: 1,850,532

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00288
Policy Entropy: 4.48301
Value Function Loss: 0.04614

Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.02860
Value Function Update Magnitude: 0.03718

Collected Steps per Second: 21,377.58458
Overall Steps per Second: 15,041.71408

Timestep Collection Time: 2.33927
Timestep Consumption Time: 0.98535
PPO Batch Consumption Time: 0.08661
Total Iteration Time: 3.32462

Cumulative Model Updates: 110
Cumulative Timesteps: 1,900,540

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1900540...
Checkpoint 1900540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00191
Policy Entropy: 4.48336
Value Function Loss: 0.04677

Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03111
Value Function Update Magnitude: 0.03700

Collected Steps per Second: 24,572.78680
Overall Steps per Second: 17,082.84744

Timestep Collection Time: 2.03518
Timestep Consumption Time: 0.89232
PPO Batch Consumption Time: 0.07436
Total Iteration Time: 2.92750

Cumulative Model Updates: 113
Cumulative Timesteps: 1,950,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05902
Policy Entropy: 4.48371
Value Function Loss: 0.06717

Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03198
Value Function Update Magnitude: 0.03837

Collected Steps per Second: 24,773.79826
Overall Steps per Second: 17,512.71530

Timestep Collection Time: 2.01834
Timestep Consumption Time: 0.83684
PPO Batch Consumption Time: 0.02963
Total Iteration Time: 2.85518

Cumulative Model Updates: 116
Cumulative Timesteps: 2,000,552

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2000552...
Checkpoint 2000552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05004
Policy Entropy: 4.48425
Value Function Loss: 0.07833

Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03635
Value Function Update Magnitude: 0.04362

Collected Steps per Second: 23,347.63343
Overall Steps per Second: 15,821.21314

Timestep Collection Time: 2.14283
Timestep Consumption Time: 1.01938
PPO Batch Consumption Time: 0.11702
Total Iteration Time: 3.16221

Cumulative Model Updates: 119
Cumulative Timesteps: 2,050,582

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05171
Policy Entropy: 4.48482
Value Function Loss: 0.08130

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03971
Value Function Update Magnitude: 0.04853

Collected Steps per Second: 24,482.68517
Overall Steps per Second: 16,335.69704

Timestep Collection Time: 2.04267
Timestep Consumption Time: 1.01873
PPO Batch Consumption Time: 0.08232
Total Iteration Time: 3.06139

Cumulative Model Updates: 122
Cumulative Timesteps: 2,100,592

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2100592...
Checkpoint 2100592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01569
Policy Entropy: 4.48518
Value Function Loss: 0.05800

Mean KL Divergence: 0.00007
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03863
Value Function Update Magnitude: 0.04710

Collected Steps per Second: 22,596.61643
Overall Steps per Second: 15,116.83642

Timestep Collection Time: 2.21414
Timestep Consumption Time: 1.09555
PPO Batch Consumption Time: 0.12292
Total Iteration Time: 3.30969

Cumulative Model Updates: 125
Cumulative Timesteps: 2,150,624

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04620
Policy Entropy: 4.48510
Value Function Loss: 0.07127

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04024
Value Function Update Magnitude: 0.04757

Collected Steps per Second: 24,419.92308
Overall Steps per Second: 17,084.77245

Timestep Collection Time: 2.04825
Timestep Consumption Time: 0.87939
PPO Batch Consumption Time: 0.06174
Total Iteration Time: 2.92764

Cumulative Model Updates: 128
Cumulative Timesteps: 2,200,642

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2200642...
Checkpoint 2200642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01516
Policy Entropy: 4.48459
Value Function Loss: 0.06970

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04373
Value Function Update Magnitude: 0.05464

Collected Steps per Second: 24,601.58886
Overall Steps per Second: 17,551.22364

Timestep Collection Time: 2.03345
Timestep Consumption Time: 0.81684
PPO Batch Consumption Time: 0.02877
Total Iteration Time: 2.85029

Cumulative Model Updates: 131
Cumulative Timesteps: 2,250,668

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01177
Policy Entropy: 4.48395
Value Function Loss: 0.05692

Mean KL Divergence: 0.00007
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04336
Value Function Update Magnitude: 0.05468

Collected Steps per Second: 23,283.74097
Overall Steps per Second: 15,658.94132

Timestep Collection Time: 2.14862
Timestep Consumption Time: 1.04623
PPO Batch Consumption Time: 0.11635
Total Iteration Time: 3.19485

Cumulative Model Updates: 134
Cumulative Timesteps: 2,300,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2300696...
Checkpoint 2300696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02543
Policy Entropy: 4.48345
Value Function Loss: 0.03306

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03842
Value Function Update Magnitude: 0.04493

Collected Steps per Second: 23,561.52290
Overall Steps per Second: 15,807.05692

Timestep Collection Time: 2.12219
Timestep Consumption Time: 1.04108
PPO Batch Consumption Time: 0.08330
Total Iteration Time: 3.16327

Cumulative Model Updates: 137
Cumulative Timesteps: 2,350,698

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01375
Policy Entropy: 4.48327
Value Function Loss: 0.03680

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03400
Value Function Update Magnitude: 0.04101

Collected Steps per Second: 21,566.53338
Overall Steps per Second: 14,652.63233

Timestep Collection Time: 2.31915
Timestep Consumption Time: 1.09430
PPO Batch Consumption Time: 0.10720
Total Iteration Time: 3.41345

Cumulative Model Updates: 140
Cumulative Timesteps: 2,400,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2400714...
Checkpoint 2400714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02236
Policy Entropy: 4.48316
Value Function Loss: 0.04358

Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03287
Value Function Update Magnitude: 0.04275

Collected Steps per Second: 23,842.92715
Overall Steps per Second: 16,967.57194

Timestep Collection Time: 2.09731
Timestep Consumption Time: 0.84984
PPO Batch Consumption Time: 0.05925
Total Iteration Time: 2.94715

Cumulative Model Updates: 143
Cumulative Timesteps: 2,450,720

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01411
Policy Entropy: 4.48295
Value Function Loss: 0.05677

Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03433
Value Function Update Magnitude: 0.03998

Collected Steps per Second: 24,663.10993
Overall Steps per Second: 16,451.39410

Timestep Collection Time: 2.02789
Timestep Consumption Time: 1.01222
PPO Batch Consumption Time: 0.08651
Total Iteration Time: 3.04011

Cumulative Model Updates: 146
Cumulative Timesteps: 2,500,734

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2500734...
Checkpoint 2500734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04458
Policy Entropy: 4.48268
Value Function Loss: 0.06621

Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03813
Value Function Update Magnitude: 0.04841

Collected Steps per Second: 24,380.04316
Overall Steps per Second: 16,995.84128

Timestep Collection Time: 2.05102
Timestep Consumption Time: 0.89111
PPO Batch Consumption Time: 0.06113
Total Iteration Time: 2.94213

Cumulative Model Updates: 149
Cumulative Timesteps: 2,550,738

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04464
Policy Entropy: 4.48239
Value Function Loss: 0.04878

Mean KL Divergence: 0.00005
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04151
Value Function Update Magnitude: 0.04862

Collected Steps per Second: 25,178.47931
Overall Steps per Second: 17,776.84373

Timestep Collection Time: 1.98614
Timestep Consumption Time: 0.82696
PPO Batch Consumption Time: 0.02906
Total Iteration Time: 2.81310

Cumulative Model Updates: 152
Cumulative Timesteps: 2,600,746

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2600746...
Checkpoint 2600746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04577
Policy Entropy: 4.48208
Value Function Loss: 0.04054

Mean KL Divergence: 0.00007
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04389
Value Function Update Magnitude: 0.04122

Collected Steps per Second: 23,224.44848
Overall Steps per Second: 15,639.61093

Timestep Collection Time: 2.15368
Timestep Consumption Time: 1.04448
PPO Batch Consumption Time: 0.09731
Total Iteration Time: 3.19816

Cumulative Model Updates: 155
Cumulative Timesteps: 2,650,764

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00960
Policy Entropy: 4.48166
Value Function Loss: 0.03146

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03887
Value Function Update Magnitude: 0.03827

Collected Steps per Second: 23,958.08207
Overall Steps per Second: 16,957.85160

Timestep Collection Time: 2.08781
Timestep Consumption Time: 0.86185
PPO Batch Consumption Time: 0.06229
Total Iteration Time: 2.94967

Cumulative Model Updates: 158
Cumulative Timesteps: 2,700,784

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2700784...
Checkpoint 2700784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03218
Policy Entropy: 4.48108
Value Function Loss: 0.04785

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03714
Value Function Update Magnitude: 0.04062

Collected Steps per Second: 24,599.43317
Overall Steps per Second: 16,523.75638

Timestep Collection Time: 2.03379
Timestep Consumption Time: 0.99398
PPO Batch Consumption Time: 0.08923
Total Iteration Time: 3.02776

Cumulative Model Updates: 161
Cumulative Timesteps: 2,750,814

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01506
Policy Entropy: 4.48039
Value Function Loss: 0.05871

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04032
Value Function Update Magnitude: 0.04371

Collected Steps per Second: 24,711.26960
Overall Steps per Second: 17,631.61783

Timestep Collection Time: 2.02426
Timestep Consumption Time: 0.81280
PPO Batch Consumption Time: 0.02924
Total Iteration Time: 2.83706

Cumulative Model Updates: 164
Cumulative Timesteps: 2,800,836

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2800836...
Checkpoint 2800836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01290
Policy Entropy: 4.47950
Value Function Loss: 0.05848

Mean KL Divergence: 0.00009
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04197
Value Function Update Magnitude: 0.04591

Collected Steps per Second: 25,532.73663
Overall Steps per Second: 17,012.98651

Timestep Collection Time: 1.95952
Timestep Consumption Time: 0.98129
PPO Batch Consumption Time: 0.08046
Total Iteration Time: 2.94081

Cumulative Model Updates: 167
Cumulative Timesteps: 2,850,868

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06975
Policy Entropy: 4.47855
Value Function Loss: 0.04700

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04030
Value Function Update Magnitude: 0.04445

Collected Steps per Second: 24,413.56255
Overall Steps per Second: 16,868.55269

Timestep Collection Time: 2.04903
Timestep Consumption Time: 0.91649
PPO Batch Consumption Time: 0.05959
Total Iteration Time: 2.96552

Cumulative Model Updates: 170
Cumulative Timesteps: 2,900,892

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2900892...
Checkpoint 2900892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00076
Policy Entropy: 4.47760
Value Function Loss: 0.04236

Mean KL Divergence: 0.00009
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03794
Value Function Update Magnitude: 0.03915

Collected Steps per Second: 21,600.83263
Overall Steps per Second: 14,673.86172

Timestep Collection Time: 2.31547
Timestep Consumption Time: 1.09304
PPO Batch Consumption Time: 0.11645
Total Iteration Time: 3.40851

Cumulative Model Updates: 173
Cumulative Timesteps: 2,950,908

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04305
Policy Entropy: 4.47675
Value Function Loss: 0.03864

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03502
Value Function Update Magnitude: 0.03198

Collected Steps per Second: 20,680.02204
Overall Steps per Second: 14,746.07827

Timestep Collection Time: 2.41866
Timestep Consumption Time: 0.97329
PPO Batch Consumption Time: 0.07800
Total Iteration Time: 3.39195

Cumulative Model Updates: 176
Cumulative Timesteps: 3,000,926

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3000926...
Checkpoint 3000926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04405
Policy Entropy: 4.47602
Value Function Loss: 0.03234

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03564
Value Function Update Magnitude: 0.02965

Collected Steps per Second: 24,150.49458
Overall Steps per Second: 16,857.77446

Timestep Collection Time: 2.07168
Timestep Consumption Time: 0.89621
PPO Batch Consumption Time: 0.05861
Total Iteration Time: 2.96789

Cumulative Model Updates: 179
Cumulative Timesteps: 3,050,958

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01204
Policy Entropy: 4.47541
Value Function Loss: 0.02733

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03356
Value Function Update Magnitude: 0.03097

Collected Steps per Second: 21,505.16547
Overall Steps per Second: 14,725.40668

Timestep Collection Time: 2.32521
Timestep Consumption Time: 1.07055
PPO Batch Consumption Time: 0.10583
Total Iteration Time: 3.39576

Cumulative Model Updates: 182
Cumulative Timesteps: 3,100,962

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3100962...
Checkpoint 3100962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00923
Policy Entropy: 4.47511
Value Function Loss: 0.01767

Mean KL Divergence: 0.00005
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03068
Value Function Update Magnitude: 0.03805

Collected Steps per Second: 24,630.07867
Overall Steps per Second: 16,907.36941

Timestep Collection Time: 2.03126
Timestep Consumption Time: 0.92781
PPO Batch Consumption Time: 0.06193
Total Iteration Time: 2.95906

Cumulative Model Updates: 185
Cumulative Timesteps: 3,150,992

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00909
Policy Entropy: 4.47515
Value Function Loss: 0.04210

Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03265
Value Function Update Magnitude: 0.03591

Collected Steps per Second: 21,161.04169
Overall Steps per Second: 14,703.55253

Timestep Collection Time: 2.36397
Timestep Consumption Time: 1.03820
PPO Batch Consumption Time: 0.12644
Total Iteration Time: 3.40217

Cumulative Model Updates: 188
Cumulative Timesteps: 3,201,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3201016...
Checkpoint 3201016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03279
Policy Entropy: 4.47513
Value Function Loss: 0.04831

Mean KL Divergence: 0.00005
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03572
Value Function Update Magnitude: 0.02873

Collected Steps per Second: 24,706.73412
Overall Steps per Second: 16,593.68429

Timestep Collection Time: 2.02431
Timestep Consumption Time: 0.98973
PPO Batch Consumption Time: 0.07711
Total Iteration Time: 3.01404

Cumulative Model Updates: 191
Cumulative Timesteps: 3,251,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00723
Policy Entropy: 4.47501
Value Function Loss: 0.05964

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04294
Value Function Update Magnitude: 0.03080

Collected Steps per Second: 23,815.44946
Overall Steps per Second: 16,722.72727

Timestep Collection Time: 2.10023
Timestep Consumption Time: 0.89079
PPO Batch Consumption Time: 0.05919
Total Iteration Time: 2.99102

Cumulative Model Updates: 194
Cumulative Timesteps: 3,301,048

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3301048...
Checkpoint 3301048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02024
Policy Entropy: 4.47465
Value Function Loss: 0.04924

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04528
Value Function Update Magnitude: 0.03453

Collected Steps per Second: 22,135.31602
Overall Steps per Second: 14,835.17483

Timestep Collection Time: 2.25883
Timestep Consumption Time: 1.11153
PPO Batch Consumption Time: 0.12069
Total Iteration Time: 3.37037

Cumulative Model Updates: 197
Cumulative Timesteps: 3,351,048

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05414
Policy Entropy: 4.47423
Value Function Loss: 0.03758

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04567
Value Function Update Magnitude: 0.03046

Collected Steps per Second: 24,684.58395
Overall Steps per Second: 16,873.24196

Timestep Collection Time: 2.02588
Timestep Consumption Time: 0.93787
PPO Batch Consumption Time: 0.06317
Total Iteration Time: 2.96375

Cumulative Model Updates: 200
Cumulative Timesteps: 3,401,056

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3401056...
Checkpoint 3401056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00360
Policy Entropy: 4.47381
Value Function Loss: 0.04047

Mean KL Divergence: 0.00011
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04301
Value Function Update Magnitude: 0.02887

Collected Steps per Second: 22,281.67031
Overall Steps per Second: 15,458.02386

Timestep Collection Time: 2.24454
Timestep Consumption Time: 0.99081
PPO Batch Consumption Time: 0.10095
Total Iteration Time: 3.23534

Cumulative Model Updates: 203
Cumulative Timesteps: 3,451,068

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00832
Policy Entropy: 4.47340
Value Function Loss: 0.04666

Mean KL Divergence: 0.00009
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04087
Value Function Update Magnitude: 0.02970

Collected Steps per Second: 22,169.80898
Overall Steps per Second: 14,826.60358

Timestep Collection Time: 2.25541
Timestep Consumption Time: 1.11704
PPO Batch Consumption Time: 0.09838
Total Iteration Time: 3.37245

Cumulative Model Updates: 206
Cumulative Timesteps: 3,501,070

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3501070...
Checkpoint 3501070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03761
Policy Entropy: 4.47314
Value Function Loss: 0.04515

Mean KL Divergence: 0.00009
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04573
Value Function Update Magnitude: 0.03125

Collected Steps per Second: 20,642.77466
Overall Steps per Second: 15,538.91073

Timestep Collection Time: 2.42361
Timestep Consumption Time: 0.79605
PPO Batch Consumption Time: 0.02922
Total Iteration Time: 3.21966

Cumulative Model Updates: 209
Cumulative Timesteps: 3,551,100

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04671
Policy Entropy: 4.47289
Value Function Loss: 0.03755

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04672
Value Function Update Magnitude: 0.03245

Collected Steps per Second: 25,533.83627
Overall Steps per Second: 17,981.60656

Timestep Collection Time: 1.95826
Timestep Consumption Time: 0.82247
PPO Batch Consumption Time: 0.02938
Total Iteration Time: 2.78073

Cumulative Model Updates: 212
Cumulative Timesteps: 3,601,102

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3601102...
Checkpoint 3601102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00076
Policy Entropy: 4.47307
Value Function Loss: 0.02566

Mean KL Divergence: 0.00012
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04349
Value Function Update Magnitude: 0.03386

Collected Steps per Second: 23,767.32197
Overall Steps per Second: 15,876.89573

Timestep Collection Time: 2.10491
Timestep Consumption Time: 1.04609
PPO Batch Consumption Time: 0.09825
Total Iteration Time: 3.15099

Cumulative Model Updates: 215
Cumulative Timesteps: 3,651,130

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06735
Policy Entropy: 4.47372
Value Function Loss: 0.04325

Mean KL Divergence: 0.00011
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04021
Value Function Update Magnitude: 0.03910

Collected Steps per Second: 24,705.09174
Overall Steps per Second: 16,689.52726

Timestep Collection Time: 2.02404
Timestep Consumption Time: 0.97209
PPO Batch Consumption Time: 0.09528
Total Iteration Time: 2.99613

Cumulative Model Updates: 218
Cumulative Timesteps: 3,701,134

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3701134...
Checkpoint 3701134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00804
Policy Entropy: 4.47502
Value Function Loss: 0.04201

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04148
Value Function Update Magnitude: 0.03970

Collected Steps per Second: 24,740.80881
Overall Steps per Second: 17,559.72621

Timestep Collection Time: 2.02111
Timestep Consumption Time: 0.82654
PPO Batch Consumption Time: 0.02970
Total Iteration Time: 2.84765

Cumulative Model Updates: 221
Cumulative Timesteps: 3,751,138

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03717
Policy Entropy: 4.47640
Value Function Loss: 0.05017

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04220
Value Function Update Magnitude: 0.03574

Collected Steps per Second: 24,118.25088
Overall Steps per Second: 16,301.81596

Timestep Collection Time: 2.07403
Timestep Consumption Time: 0.99446
PPO Batch Consumption Time: 0.09288
Total Iteration Time: 3.06849

Cumulative Model Updates: 224
Cumulative Timesteps: 3,801,160

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3801160...
Checkpoint 3801160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00514
Policy Entropy: 4.47782
Value Function Loss: 0.03296

Mean KL Divergence: 0.00011
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04285
Value Function Update Magnitude: 0.03613

Collected Steps per Second: 25,973.49716
Overall Steps per Second: 18,228.32491

Timestep Collection Time: 1.92542
Timestep Consumption Time: 0.81811
PPO Batch Consumption Time: 0.02910
Total Iteration Time: 2.74353

Cumulative Model Updates: 227
Cumulative Timesteps: 3,851,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00439
Policy Entropy: 4.47897
Value Function Loss: 0.02438

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04034
Value Function Update Magnitude: 0.04438

Collected Steps per Second: 23,883.68731
Overall Steps per Second: 17,132.36193

Timestep Collection Time: 2.09457
Timestep Consumption Time: 0.82540
PPO Batch Consumption Time: 0.02896
Total Iteration Time: 2.91997

Cumulative Model Updates: 230
Cumulative Timesteps: 3,901,196

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3901196...
Checkpoint 3901196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01847
Policy Entropy: 4.47987
Value Function Loss: 0.02336

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03626
Value Function Update Magnitude: 0.04695

Collected Steps per Second: 24,498.18441
Overall Steps per Second: 16,915.59129

Timestep Collection Time: 2.04187
Timestep Consumption Time: 0.91529
PPO Batch Consumption Time: 0.08571
Total Iteration Time: 2.95715

Cumulative Model Updates: 233
Cumulative Timesteps: 3,951,218

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06294
Policy Entropy: 4.48067
Value Function Loss: 0.05526

Mean KL Divergence: 0.00007
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03547
Value Function Update Magnitude: 0.04484

Collected Steps per Second: 24,792.71286
Overall Steps per Second: 16,945.73965

Timestep Collection Time: 2.01729
Timestep Consumption Time: 0.93413
PPO Batch Consumption Time: 0.06161
Total Iteration Time: 2.95142

Cumulative Model Updates: 236
Cumulative Timesteps: 4,001,232

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 4001232...
Checkpoint 4001232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00500
Policy Entropy: 4.48141
Value Function Loss: 0.08314

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04241
Value Function Update Magnitude: 0.05097

Collected Steps per Second: 24,315.87657
Overall Steps per Second: 17,315.92861

Timestep Collection Time: 2.05726
Timestep Consumption Time: 0.83164
PPO Batch Consumption Time: 0.02971
Total Iteration Time: 2.88890

Cumulative Model Updates: 239
Cumulative Timesteps: 4,051,256

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13749
Policy Entropy: 4.48205
Value Function Loss: 0.07447

Mean KL Divergence: 0.00007
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04710
Value Function Update Magnitude: 0.05844

Collected Steps per Second: 25,210.54830
Overall Steps per Second: 17,814.42204

Timestep Collection Time: 1.98377
Timestep Consumption Time: 0.82362
PPO Batch Consumption Time: 0.02944
Total Iteration Time: 2.80739

Cumulative Model Updates: 242
Cumulative Timesteps: 4,101,268

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 4101268...
Checkpoint 4101268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00409
Policy Entropy: 4.48242
Value Function Loss: 0.05573

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04450
Value Function Update Magnitude: 0.05502

Collected Steps per Second: 24,036.49772
Overall Steps per Second: 16,130.81901

Timestep Collection Time: 2.08092
Timestep Consumption Time: 1.01985
PPO Batch Consumption Time: 0.08330
Total Iteration Time: 3.10077

Cumulative Model Updates: 245
Cumulative Timesteps: 4,151,286

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01489
Policy Entropy: 4.48241
Value Function Loss: 0.03093

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03939
Value Function Update Magnitude: 0.03979

Collected Steps per Second: 23,641.82111
Overall Steps per Second: 17,530.83701

Timestep Collection Time: 2.11490
Timestep Consumption Time: 0.73722
PPO Batch Consumption Time: 0.02900
Total Iteration Time: 2.85212

Cumulative Model Updates: 248
Cumulative Timesteps: 4,201,286

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 4201286...
Checkpoint 4201286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06294
Policy Entropy: 4.48212
Value Function Loss: 0.04406

Mean KL Divergence: 0.00005
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03693
Value Function Update Magnitude: 0.03533

Collected Steps per Second: 23,836.51887
Overall Steps per Second: 16,554.41445

Timestep Collection Time: 2.09880
Timestep Consumption Time: 0.92324
PPO Batch Consumption Time: 0.04936
Total Iteration Time: 3.02203

Cumulative Model Updates: 251
Cumulative Timesteps: 4,251,314

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01282
Policy Entropy: 4.48194
Value Function Loss: 0.03288

Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03552
Value Function Update Magnitude: 0.03102

Collected Steps per Second: 24,363.23388
Overall Steps per Second: 16,176.98444

Timestep Collection Time: 2.05326
Timestep Consumption Time: 1.03904
PPO Batch Consumption Time: 0.09496
Total Iteration Time: 3.09229

Cumulative Model Updates: 254
Cumulative Timesteps: 4,301,338

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 4301338...
Checkpoint 4301338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01358
Policy Entropy: 4.48207
Value Function Loss: 0.03907

Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03805
Value Function Update Magnitude: 0.03191

Collected Steps per Second: 23,714.13613
Overall Steps per Second: 16,760.56490

Timestep Collection Time: 2.10904
Timestep Consumption Time: 0.87499
PPO Batch Consumption Time: 0.07437
Total Iteration Time: 2.98403

Cumulative Model Updates: 257
Cumulative Timesteps: 4,351,352

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04677
Policy Entropy: 4.48246
Value Function Loss: 0.01735

Mean KL Divergence: 0.00005
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03562
Value Function Update Magnitude: 0.03382

Collected Steps per Second: 25,016.07394
Overall Steps per Second: 16,703.68020

Timestep Collection Time: 1.99935
Timestep Consumption Time: 0.99496
PPO Batch Consumption Time: 0.08180
Total Iteration Time: 2.99431

Cumulative Model Updates: 260
Cumulative Timesteps: 4,401,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 4401368...
Checkpoint 4401368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00130
Policy Entropy: 4.48289
Value Function Loss: 0.03099

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03332
Value Function Update Magnitude: 0.03496

Collected Steps per Second: 24,077.80560
Overall Steps per Second: 15,835.18587

Timestep Collection Time: 2.07660
Timestep Consumption Time: 1.08092
PPO Batch Consumption Time: 0.11005
Total Iteration Time: 3.15753

Cumulative Model Updates: 263
Cumulative Timesteps: 4,451,368

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04672
Policy Entropy: 4.48321
Value Function Loss: 0.03922

Mean KL Divergence: 0.00005
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03267
Value Function Update Magnitude: 0.03116

Collected Steps per Second: 25,873.24130
Overall Steps per Second: 16,872.68954

Timestep Collection Time: 1.93273
Timestep Consumption Time: 1.03099
PPO Batch Consumption Time: 0.08717
Total Iteration Time: 2.96372

Cumulative Model Updates: 266
Cumulative Timesteps: 4,501,374

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 4501374...
Checkpoint 4501374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08913
Policy Entropy: 4.48335
Value Function Loss: 0.06260

Mean KL Divergence: 0.00005
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03673
Value Function Update Magnitude: 0.02699

Collected Steps per Second: 23,448.12924
Overall Steps per Second: 16,349.88252

Timestep Collection Time: 2.13356
Timestep Consumption Time: 0.92628
PPO Batch Consumption Time: 0.06079
Total Iteration Time: 3.05984

Cumulative Model Updates: 269
Cumulative Timesteps: 4,551,402

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03045
Policy Entropy: 4.48349
Value Function Loss: 0.07752

Mean KL Divergence: 0.00005
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04121
Value Function Update Magnitude: 0.03865

Collected Steps per Second: 21,625.00547
Overall Steps per Second: 14,964.64727

Timestep Collection Time: 2.31242
Timestep Consumption Time: 1.02919
PPO Batch Consumption Time: 0.12413
Total Iteration Time: 3.34161

Cumulative Model Updates: 272
Cumulative Timesteps: 4,601,408

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 4601408...
Checkpoint 4601408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02560
Policy Entropy: 4.48340
Value Function Loss: 0.06841

Mean KL Divergence: 0.00007
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04634
Value Function Update Magnitude: 0.05107

Collected Steps per Second: 25,092.23322
Overall Steps per Second: 16,641.08270

Timestep Collection Time: 1.99313
Timestep Consumption Time: 1.01221
PPO Batch Consumption Time: 0.08623
Total Iteration Time: 3.00533

Cumulative Model Updates: 275
Cumulative Timesteps: 4,651,420

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11516
Policy Entropy: 4.48327
Value Function Loss: 0.06169

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04742
Value Function Update Magnitude: 0.05520

Collected Steps per Second: 25,130.79535
Overall Steps per Second: 16,727.46325

Timestep Collection Time: 1.99023
Timestep Consumption Time: 0.99983
PPO Batch Consumption Time: 0.09361
Total Iteration Time: 2.99005

Cumulative Model Updates: 278
Cumulative Timesteps: 4,701,436

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 4701436...
Checkpoint 4701436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01213
Policy Entropy: 4.48320
Value Function Loss: 0.06291

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04599
Value Function Update Magnitude: 0.05023

Collected Steps per Second: 26,116.73596
Overall Steps per Second: 16,787.08941

Timestep Collection Time: 1.91448
Timestep Consumption Time: 1.06400
PPO Batch Consumption Time: 0.11142
Total Iteration Time: 2.97848

Cumulative Model Updates: 281
Cumulative Timesteps: 4,751,436

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01000
Policy Entropy: 4.48321
Value Function Loss: 0.07278

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04821
Value Function Update Magnitude: 0.04763

Collected Steps per Second: 21,908.14637
Overall Steps per Second: 14,779.09531

Timestep Collection Time: 2.28290
Timestep Consumption Time: 1.10121
PPO Batch Consumption Time: 0.11050
Total Iteration Time: 3.38410

Cumulative Model Updates: 284
Cumulative Timesteps: 4,801,450

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 4801450...
Checkpoint 4801450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01242
Policy Entropy: 4.48298
Value Function Loss: 0.05705

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05188
Value Function Update Magnitude: 0.03964

Collected Steps per Second: 23,167.58728
Overall Steps per Second: 16,678.40686

Timestep Collection Time: 2.15845
Timestep Consumption Time: 0.83980
PPO Batch Consumption Time: 0.05895
Total Iteration Time: 2.99825

Cumulative Model Updates: 287
Cumulative Timesteps: 4,851,456

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04004
Policy Entropy: 4.48232
Value Function Loss: 0.03741

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.03359

Collected Steps per Second: 23,084.82918
Overall Steps per Second: 16,569.43890

Timestep Collection Time: 2.16610
Timestep Consumption Time: 0.85175
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 3.01785

Cumulative Model Updates: 290
Cumulative Timesteps: 4,901,460

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 4901460...
Checkpoint 4901460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03578
Policy Entropy: 4.48144
Value Function Loss: 0.02890

Mean KL Divergence: 0.00011
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04464
Value Function Update Magnitude: 0.04106

Collected Steps per Second: 22,384.89234
Overall Steps per Second: 15,324.37930

Timestep Collection Time: 2.23454
Timestep Consumption Time: 1.02954
PPO Batch Consumption Time: 0.08876
Total Iteration Time: 3.26408

Cumulative Model Updates: 293
Cumulative Timesteps: 4,951,480

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10509
Policy Entropy: 4.48083
Value Function Loss: 0.04467

Mean KL Divergence: 0.00009
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03959
Value Function Update Magnitude: 0.04669

Collected Steps per Second: 23,602.59293
Overall Steps per Second: 16,539.47542

Timestep Collection Time: 2.11883
Timestep Consumption Time: 0.90484
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 3.02368

Cumulative Model Updates: 296
Cumulative Timesteps: 5,001,490

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 5001490...
Checkpoint 5001490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01819
Policy Entropy: 4.48075
Value Function Loss: 0.04663

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04192
Value Function Update Magnitude: 0.04594

Collected Steps per Second: 21,814.74794
Overall Steps per Second: 15,173.53885

Timestep Collection Time: 2.29203
Timestep Consumption Time: 1.00318
PPO Batch Consumption Time: 0.08067
Total Iteration Time: 3.29521

Cumulative Model Updates: 299
Cumulative Timesteps: 5,051,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04246
Policy Entropy: 4.48094
Value Function Loss: 0.04514

Mean KL Divergence: 0.00005
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04381
Value Function Update Magnitude: 0.03962

Collected Steps per Second: 19,784.50865
Overall Steps per Second: 14,492.90479

Timestep Collection Time: 2.52824
Timestep Consumption Time: 0.92310
PPO Batch Consumption Time: 0.06688
Total Iteration Time: 3.45134

Cumulative Model Updates: 302
Cumulative Timesteps: 5,101,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 5101510...
Checkpoint 5101510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03216
Policy Entropy: 4.48126
Value Function Loss: 0.03576

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04362
Value Function Update Magnitude: 0.03546

Collected Steps per Second: 19,595.93884
Overall Steps per Second: 13,728.08959

Timestep Collection Time: 2.55288
Timestep Consumption Time: 1.09119
PPO Batch Consumption Time: 0.11895
Total Iteration Time: 3.64406

Cumulative Model Updates: 305
Cumulative Timesteps: 5,151,536

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05656
Policy Entropy: 4.48128
Value Function Loss: 0.03694

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04086
Value Function Update Magnitude: 0.03423

Collected Steps per Second: 24,390.75303
Overall Steps per Second: 16,856.21226

Timestep Collection Time: 2.05037
Timestep Consumption Time: 0.91649
PPO Batch Consumption Time: 0.06562
Total Iteration Time: 2.96686

Cumulative Model Updates: 308
Cumulative Timesteps: 5,201,546

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 5201546...
Checkpoint 5201546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03087
Policy Entropy: 4.48093
Value Function Loss: 0.07351

Mean KL Divergence: 0.00005
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04416
Value Function Update Magnitude: 0.02825

Collected Steps per Second: 25,431.51296
Overall Steps per Second: 16,542.82311

Timestep Collection Time: 1.96717
Timestep Consumption Time: 1.05699
PPO Batch Consumption Time: 0.10063
Total Iteration Time: 3.02415

Cumulative Model Updates: 311
Cumulative Timesteps: 5,251,574

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04016
Policy Entropy: 4.48048
Value Function Loss: 0.09310

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05293
Value Function Update Magnitude: 0.03616

Collected Steps per Second: 23,415.14281
Overall Steps per Second: 16,005.82058

Timestep Collection Time: 2.13665
Timestep Consumption Time: 0.98909
PPO Batch Consumption Time: 0.06641
Total Iteration Time: 3.12574

Cumulative Model Updates: 314
Cumulative Timesteps: 5,301,604

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 5301604...
Checkpoint 5301604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05571
Policy Entropy: 4.48054
Value Function Loss: 0.10278

Mean KL Divergence: 0.00009
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06149
Value Function Update Magnitude: 0.04682

Collected Steps per Second: 22,553.91316
Overall Steps per Second: 15,307.70014

Timestep Collection Time: 2.21726
Timestep Consumption Time: 1.04959
PPO Batch Consumption Time: 0.12151
Total Iteration Time: 3.26685

Cumulative Model Updates: 317
Cumulative Timesteps: 5,351,612

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01267
Policy Entropy: 4.48111
Value Function Loss: 0.06838

Mean KL Divergence: 0.00013
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06149
Value Function Update Magnitude: 0.04347

Collected Steps per Second: 22,854.36383
Overall Steps per Second: 16,069.94235

Timestep Collection Time: 2.18864
Timestep Consumption Time: 0.92400
PPO Batch Consumption Time: 0.05879
Total Iteration Time: 3.11264

Cumulative Model Updates: 320
Cumulative Timesteps: 5,401,632

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 5401632...
Checkpoint 5401632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00157
Policy Entropy: 4.48156
Value Function Loss: 0.05957

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05642
Value Function Update Magnitude: 0.03740

Collected Steps per Second: 24,119.03340
Overall Steps per Second: 16,384.76561

Timestep Collection Time: 2.07355
Timestep Consumption Time: 0.97880
PPO Batch Consumption Time: 0.09192
Total Iteration Time: 3.05235

Cumulative Model Updates: 323
Cumulative Timesteps: 5,451,644

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01093
Policy Entropy: 4.48198
Value Function Loss: 0.04922

Mean KL Divergence: 0.00013
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.03653

Collected Steps per Second: 24,967.62222
Overall Steps per Second: 16,819.63646

Timestep Collection Time: 2.00299
Timestep Consumption Time: 0.97032
PPO Batch Consumption Time: 0.07182
Total Iteration Time: 2.97331

Cumulative Model Updates: 326
Cumulative Timesteps: 5,501,654

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 5501654...
Checkpoint 5501654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00141
Policy Entropy: 4.48220
Value Function Loss: 0.05376

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.03502

Collected Steps per Second: 22,475.29706
Overall Steps per Second: 14,770.26202

Timestep Collection Time: 2.22466
Timestep Consumption Time: 1.16052
PPO Batch Consumption Time: 0.10514
Total Iteration Time: 3.38518

Cumulative Model Updates: 329
Cumulative Timesteps: 5,551,654

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03740
Policy Entropy: 4.48241
Value Function Loss: 0.05158

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.03607

Collected Steps per Second: 22,459.19573
Overall Steps per Second: 16,581.40291

Timestep Collection Time: 2.22733
Timestep Consumption Time: 0.78955
PPO Batch Consumption Time: 0.02980
Total Iteration Time: 3.01687

Cumulative Model Updates: 332
Cumulative Timesteps: 5,601,678

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 5601678...
Checkpoint 5601678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03682
Policy Entropy: 4.48260
Value Function Loss: 0.05202

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.03893

Collected Steps per Second: 22,235.71386
Overall Steps per Second: 15,659.80818

Timestep Collection Time: 2.24962
Timestep Consumption Time: 0.94467
PPO Batch Consumption Time: 0.07718
Total Iteration Time: 3.19429

Cumulative Model Updates: 335
Cumulative Timesteps: 5,651,700

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02635
Policy Entropy: 4.48263
Value Function Loss: 0.05953

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05100
Value Function Update Magnitude: 0.03478

Collected Steps per Second: 24,350.39915
Overall Steps per Second: 16,833.22370

Timestep Collection Time: 2.05352
Timestep Consumption Time: 0.91704
PPO Batch Consumption Time: 0.07247
Total Iteration Time: 2.97055

Cumulative Model Updates: 338
Cumulative Timesteps: 5,701,704

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 5701704...
Checkpoint 5701704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01041
Policy Entropy: 4.48256
Value Function Loss: 0.04830

Mean KL Divergence: 0.00009
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05082
Value Function Update Magnitude: 0.03138

Collected Steps per Second: 24,729.78130
Overall Steps per Second: 17,496.61916

Timestep Collection Time: 2.02250
Timestep Consumption Time: 0.83611
PPO Batch Consumption Time: 0.06028
Total Iteration Time: 2.85861

Cumulative Model Updates: 341
Cumulative Timesteps: 5,751,720

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01099
Policy Entropy: 4.48234
Value Function Loss: 0.04246

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.02786

Collected Steps per Second: 22,388.87528
Overall Steps per Second: 15,075.97390

Timestep Collection Time: 2.23540
Timestep Consumption Time: 1.08432
PPO Batch Consumption Time: 0.08411
Total Iteration Time: 3.31972

Cumulative Model Updates: 344
Cumulative Timesteps: 5,801,768

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 5801768...
Checkpoint 5801768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02440
Policy Entropy: 4.48202
Value Function Loss: 0.03792

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04682
Value Function Update Magnitude: 0.02519

Collected Steps per Second: 24,229.98050
Overall Steps per Second: 15,862.30522

Timestep Collection Time: 2.06447
Timestep Consumption Time: 1.08905
PPO Batch Consumption Time: 0.11741
Total Iteration Time: 3.15351

Cumulative Model Updates: 347
Cumulative Timesteps: 5,851,790

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03613
Policy Entropy: 4.48133
Value Function Loss: 0.04601

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.02606

Collected Steps per Second: 24,475.10660
Overall Steps per Second: 16,649.70845

Timestep Collection Time: 2.04330
Timestep Consumption Time: 0.96036
PPO Batch Consumption Time: 0.06305
Total Iteration Time: 3.00366

Cumulative Model Updates: 350
Cumulative Timesteps: 5,901,800

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 5901800...
Checkpoint 5901800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04022
Policy Entropy: 4.48027
Value Function Loss: 0.04758

Mean KL Divergence: 0.00009
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.03235

Collected Steps per Second: 20,892.73359
Overall Steps per Second: 14,662.33998

Timestep Collection Time: 2.39337
Timestep Consumption Time: 1.01700
PPO Batch Consumption Time: 0.07712
Total Iteration Time: 3.41037

Cumulative Model Updates: 353
Cumulative Timesteps: 5,951,804

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00762
Policy Entropy: 4.47910
Value Function Loss: 0.04890

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04805
Value Function Update Magnitude: 0.03779

Collected Steps per Second: 23,919.87573
Overall Steps per Second: 16,956.40614

Timestep Collection Time: 2.09056
Timestep Consumption Time: 0.85853
PPO Batch Consumption Time: 0.05960
Total Iteration Time: 2.94909

Cumulative Model Updates: 356
Cumulative Timesteps: 6,001,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 6001810...
Checkpoint 6001810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04962
Policy Entropy: 4.47826
Value Function Loss: 0.04833

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04535
Value Function Update Magnitude: 0.03614

Collected Steps per Second: 21,367.83639
Overall Steps per Second: 14,525.34256

Timestep Collection Time: 2.34006
Timestep Consumption Time: 1.10234
PPO Batch Consumption Time: 0.11035
Total Iteration Time: 3.44240

Cumulative Model Updates: 359
Cumulative Timesteps: 6,051,812

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02124
Policy Entropy: 4.47796
Value Function Loss: 0.06165

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04766
Value Function Update Magnitude: 0.03230

Collected Steps per Second: 23,075.20429
Overall Steps per Second: 16,382.04271

Timestep Collection Time: 2.16700
Timestep Consumption Time: 0.88537
PPO Batch Consumption Time: 0.05934
Total Iteration Time: 3.05237

Cumulative Model Updates: 362
Cumulative Timesteps: 6,101,816

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 6101816...
Checkpoint 6101816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07607
Policy Entropy: 4.47812
Value Function Loss: 0.05356

Mean KL Divergence: 0.00009
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04885
Value Function Update Magnitude: 0.03405

Collected Steps per Second: 22,117.69504
Overall Steps per Second: 15,214.36151

Timestep Collection Time: 2.26244
Timestep Consumption Time: 1.02656
PPO Batch Consumption Time: 0.09053
Total Iteration Time: 3.28900

Cumulative Model Updates: 365
Cumulative Timesteps: 6,151,856

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03246
Policy Entropy: 4.47836
Value Function Loss: 0.05023

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.03540

Collected Steps per Second: 24,617.35480
Overall Steps per Second: 16,973.02952

Timestep Collection Time: 2.03214
Timestep Consumption Time: 0.91524
PPO Batch Consumption Time: 0.06313
Total Iteration Time: 2.94738

Cumulative Model Updates: 368
Cumulative Timesteps: 6,201,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 6201882...
Checkpoint 6201882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02327
Policy Entropy: 4.47873
Value Function Loss: 0.03469

Mean KL Divergence: 0.00011
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05141
Value Function Update Magnitude: 0.03422

Collected Steps per Second: 24,103.90945
Overall Steps per Second: 17,819.10289

Timestep Collection Time: 2.07435
Timestep Consumption Time: 0.73163
PPO Batch Consumption Time: 0.02909
Total Iteration Time: 2.80598

Cumulative Model Updates: 371
Cumulative Timesteps: 6,251,882

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02468
Policy Entropy: 4.47887
Value Function Loss: 0.03703

Mean KL Divergence: 0.00012
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04862
Value Function Update Magnitude: 0.03732

Collected Steps per Second: 24,984.26120
Overall Steps per Second: 17,687.47384

Timestep Collection Time: 2.00190
Timestep Consumption Time: 0.82586
PPO Batch Consumption Time: 0.02957
Total Iteration Time: 2.82776

Cumulative Model Updates: 374
Cumulative Timesteps: 6,301,898

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 6301898...
Checkpoint 6301898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03164
Policy Entropy: 4.47875
Value Function Loss: 0.03263

Mean KL Divergence: 0.00011
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04732
Value Function Update Magnitude: 0.03925

Collected Steps per Second: 23,655.70128
Overall Steps per Second: 15,827.21124

Timestep Collection Time: 2.11518
Timestep Consumption Time: 1.04621
PPO Batch Consumption Time: 0.10558
Total Iteration Time: 3.16139

Cumulative Model Updates: 377
Cumulative Timesteps: 6,351,934

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02807
Policy Entropy: 4.47821
Value Function Loss: 0.03329

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04636
Value Function Update Magnitude: 0.03893

Collected Steps per Second: 25,422.97920
Overall Steps per Second: 16,674.86128

Timestep Collection Time: 1.96712
Timestep Consumption Time: 1.03201
PPO Batch Consumption Time: 0.09812
Total Iteration Time: 2.99913

Cumulative Model Updates: 380
Cumulative Timesteps: 6,401,944

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 6401944...
Checkpoint 6401944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01857
Policy Entropy: 4.47749
Value Function Loss: 0.03070

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04490
Value Function Update Magnitude: 0.03483

Collected Steps per Second: 24,701.28007
Overall Steps per Second: 16,596.88026

Timestep Collection Time: 2.02467
Timestep Consumption Time: 0.98867
PPO Batch Consumption Time: 0.07908
Total Iteration Time: 3.01334

Cumulative Model Updates: 383
Cumulative Timesteps: 6,451,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00029
Policy Entropy: 4.47661
Value Function Loss: 0.04621

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04521
Value Function Update Magnitude: 0.02756

Collected Steps per Second: 24,506.42282
Overall Steps per Second: 16,973.55258

Timestep Collection Time: 2.04061
Timestep Consumption Time: 0.90562
PPO Batch Consumption Time: 0.06666
Total Iteration Time: 2.94623

Cumulative Model Updates: 386
Cumulative Timesteps: 6,501,964

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 6501964...
Checkpoint 6501964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00427
Policy Entropy: 4.47540
Value Function Loss: 0.04059

Mean KL Divergence: 0.00011
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.03088

Collected Steps per Second: 21,421.00733
Overall Steps per Second: 15,838.33161

Timestep Collection Time: 2.33518
Timestep Consumption Time: 0.82310
PPO Batch Consumption Time: 0.02884
Total Iteration Time: 3.15829

Cumulative Model Updates: 389
Cumulative Timesteps: 6,551,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01147
Policy Entropy: 4.47400
Value Function Loss: 0.04718

Mean KL Divergence: 0.00014
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.03008

Collected Steps per Second: 23,594.06359
Overall Steps per Second: 15,535.47802

Timestep Collection Time: 2.11952
Timestep Consumption Time: 1.09944
PPO Batch Consumption Time: 0.11633
Total Iteration Time: 3.21895

Cumulative Model Updates: 392
Cumulative Timesteps: 6,601,994

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 6601994...
Checkpoint 6601994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04990
Policy Entropy: 4.47254
Value Function Loss: 0.03356

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.02581

Collected Steps per Second: 24,679.10793
Overall Steps per Second: 17,448.53386

Timestep Collection Time: 2.02609
Timestep Consumption Time: 0.83960
PPO Batch Consumption Time: 0.05770
Total Iteration Time: 2.86568

Cumulative Model Updates: 395
Cumulative Timesteps: 6,651,996

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07142
Policy Entropy: 4.47097
Value Function Loss: 0.06210

Mean KL Divergence: 0.00014
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.02715

Collected Steps per Second: 24,868.27329
Overall Steps per Second: 17,669.40817

Timestep Collection Time: 2.01108
Timestep Consumption Time: 0.81935
PPO Batch Consumption Time: 0.02931
Total Iteration Time: 2.83043

Cumulative Model Updates: 398
Cumulative Timesteps: 6,702,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 6702008...
Checkpoint 6702008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14473
Policy Entropy: 4.46921
Value Function Loss: 0.05116

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.02753

Collected Steps per Second: 23,629.54944
Overall Steps per Second: 16,201.13847

Timestep Collection Time: 2.11676
Timestep Consumption Time: 0.97056
PPO Batch Consumption Time: 0.07768
Total Iteration Time: 3.08731

Cumulative Model Updates: 401
Cumulative Timesteps: 6,752,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02683
Policy Entropy: 4.46702
Value Function Loss: 0.05579

Mean KL Divergence: 0.00020
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06090
Value Function Update Magnitude: 0.03199

Collected Steps per Second: 25,454.82311
Overall Steps per Second: 17,327.96453

Timestep Collection Time: 1.96450
Timestep Consumption Time: 0.92136
PPO Batch Consumption Time: 0.06145
Total Iteration Time: 2.88586

Cumulative Model Updates: 404
Cumulative Timesteps: 6,802,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 6802032...
Checkpoint 6802032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00319
Policy Entropy: 4.46450
Value Function Loss: 0.02965

Mean KL Divergence: 0.00026
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05623
Value Function Update Magnitude: 0.03765

Collected Steps per Second: 22,811.72109
Overall Steps per Second: 16,407.23150

Timestep Collection Time: 2.19308
Timestep Consumption Time: 0.85606
PPO Batch Consumption Time: 0.03853
Total Iteration Time: 3.04914

Cumulative Model Updates: 407
Cumulative Timesteps: 6,852,060

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00757
Policy Entropy: 4.46199
Value Function Loss: 0.03488

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05307
Value Function Update Magnitude: 0.04488

Collected Steps per Second: 24,415.40754
Overall Steps per Second: 17,568.98018

Timestep Collection Time: 2.04854
Timestep Consumption Time: 0.79829
PPO Batch Consumption Time: 0.02912
Total Iteration Time: 2.84684

Cumulative Model Updates: 410
Cumulative Timesteps: 6,902,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 6902076...
Checkpoint 6902076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04216
Policy Entropy: 4.45997
Value Function Loss: 0.02832

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05106
Value Function Update Magnitude: 0.04328

Collected Steps per Second: 23,556.04673
Overall Steps per Second: 15,888.27329

Timestep Collection Time: 2.12370
Timestep Consumption Time: 1.02491
PPO Batch Consumption Time: 0.09662
Total Iteration Time: 3.14861

Cumulative Model Updates: 413
Cumulative Timesteps: 6,952,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04058
Policy Entropy: 4.45875
Value Function Loss: 0.03226

Mean KL Divergence: 0.00017
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05142
Value Function Update Magnitude: 0.03780

Collected Steps per Second: 23,752.29454
Overall Steps per Second: 16,878.28701

Timestep Collection Time: 2.10565
Timestep Consumption Time: 0.85757
PPO Batch Consumption Time: 0.02962
Total Iteration Time: 2.96322

Cumulative Model Updates: 416
Cumulative Timesteps: 7,002,116

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 7002116...
Checkpoint 7002116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02575
Policy Entropy: 4.45835
Value Function Loss: 0.02135

Mean KL Divergence: 0.00014
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04854
Value Function Update Magnitude: 0.03795

Collected Steps per Second: 20,988.47879
Overall Steps per Second: 15,760.93400

Timestep Collection Time: 2.38283
Timestep Consumption Time: 0.79033
PPO Batch Consumption Time: 0.03254
Total Iteration Time: 3.17316

Cumulative Model Updates: 419
Cumulative Timesteps: 7,052,128

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01031
Policy Entropy: 4.45841
Value Function Loss: 0.02769

Mean KL Divergence: 0.00012
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04683
Value Function Update Magnitude: 0.03739

Collected Steps per Second: 18,193.14298
Overall Steps per Second: 13,455.75436

Timestep Collection Time: 2.74972
Timestep Consumption Time: 0.96810
PPO Batch Consumption Time: 0.04610
Total Iteration Time: 3.71781

Cumulative Model Updates: 422
Cumulative Timesteps: 7,102,154

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 7102154...
Checkpoint 7102154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01362
Policy Entropy: 4.45851
Value Function Loss: 0.03413

Mean KL Divergence: 0.00011
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04559
Value Function Update Magnitude: 0.02775

Collected Steps per Second: 22,832.63066
Overall Steps per Second: 15,317.46146

Timestep Collection Time: 2.19002
Timestep Consumption Time: 1.07449
PPO Batch Consumption Time: 0.09953
Total Iteration Time: 3.26451

Cumulative Model Updates: 425
Cumulative Timesteps: 7,152,158

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02944
Policy Entropy: 4.45757
Value Function Loss: 0.04551

Mean KL Divergence: 0.00012
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05011
Value Function Update Magnitude: 0.02680

Collected Steps per Second: 25,643.77938
Overall Steps per Second: 17,331.02733

Timestep Collection Time: 1.95073
Timestep Consumption Time: 0.93566
PPO Batch Consumption Time: 0.06308
Total Iteration Time: 2.88638

Cumulative Model Updates: 428
Cumulative Timesteps: 7,202,182

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 7202182...
Checkpoint 7202182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05147
Policy Entropy: 4.45504
Value Function Loss: 0.04598

Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.03227

Collected Steps per Second: 21,887.05261
Overall Steps per Second: 15,069.37052

Timestep Collection Time: 2.28573
Timestep Consumption Time: 1.03411
PPO Batch Consumption Time: 0.09405
Total Iteration Time: 3.31985

Cumulative Model Updates: 431
Cumulative Timesteps: 7,252,210

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06772
Policy Entropy: 4.45303
Value Function Loss: 0.04095

Mean KL Divergence: 0.00019
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.03243

Collected Steps per Second: 24,692.63792
Overall Steps per Second: 17,516.24003

Timestep Collection Time: 2.02562
Timestep Consumption Time: 0.82990
PPO Batch Consumption Time: 0.06182
Total Iteration Time: 2.85552

Cumulative Model Updates: 434
Cumulative Timesteps: 7,302,228

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 7302228...
Checkpoint 7302228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00759
Policy Entropy: 4.45238
Value Function Loss: 0.03605

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05131
Value Function Update Magnitude: 0.02692

Collected Steps per Second: 21,824.11489
Overall Steps per Second: 15,078.75141

Timestep Collection Time: 2.29224
Timestep Consumption Time: 1.02541
PPO Batch Consumption Time: 0.09125
Total Iteration Time: 3.31765

Cumulative Model Updates: 437
Cumulative Timesteps: 7,352,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00758
Policy Entropy: 4.45384
Value Function Loss: 0.02327

Mean KL Divergence: 0.00012
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05216
Value Function Update Magnitude: 0.02548

Collected Steps per Second: 24,951.07593
Overall Steps per Second: 16,702.28150

Timestep Collection Time: 2.00392
Timestep Consumption Time: 0.98968
PPO Batch Consumption Time: 0.09059
Total Iteration Time: 2.99360

Cumulative Model Updates: 440
Cumulative Timesteps: 7,402,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 7402254...
Checkpoint 7402254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01995
Policy Entropy: 4.45649
Value Function Loss: 0.04654

Mean KL Divergence: 0.00018
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05606
Value Function Update Magnitude: 0.02540

Collected Steps per Second: 25,622.79899
Overall Steps per Second: 16,776.53619

Timestep Collection Time: 1.95248
Timestep Consumption Time: 1.02954
PPO Batch Consumption Time: 0.09130
Total Iteration Time: 2.98202

Cumulative Model Updates: 443
Cumulative Timesteps: 7,452,282

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00750
Policy Entropy: 4.45958
Value Function Loss: 0.05337

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06418
Value Function Update Magnitude: 0.02726

Collected Steps per Second: 24,832.74649
Overall Steps per Second: 16,687.98668

Timestep Collection Time: 2.01347
Timestep Consumption Time: 0.98270
PPO Batch Consumption Time: 0.07909
Total Iteration Time: 2.99617

Cumulative Model Updates: 446
Cumulative Timesteps: 7,502,282

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 7502282...
Checkpoint 7502282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02979
Policy Entropy: 4.46212
Value Function Loss: 0.05955

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07185
Value Function Update Magnitude: 0.03597

Collected Steps per Second: 24,463.43864
Overall Steps per Second: 15,845.09524

Timestep Collection Time: 2.04493
Timestep Consumption Time: 1.11226
PPO Batch Consumption Time: 0.12571
Total Iteration Time: 3.15719

Cumulative Model Updates: 449
Cumulative Timesteps: 7,552,308

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03469
Policy Entropy: 4.46366
Value Function Loss: 0.04773

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06907
Value Function Update Magnitude: 0.03752

Collected Steps per Second: 26,176.86531
Overall Steps per Second: 17,723.27012

Timestep Collection Time: 1.91108
Timestep Consumption Time: 0.91154
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 2.82262

Cumulative Model Updates: 452
Cumulative Timesteps: 7,602,334

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 7602334...
Checkpoint 7602334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02546
Policy Entropy: 4.46434
Value Function Loss: 0.04091

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06499
Value Function Update Magnitude: 0.03435

Collected Steps per Second: 21,652.09353
Overall Steps per Second: 14,865.97686

Timestep Collection Time: 2.30962
Timestep Consumption Time: 1.05431
PPO Batch Consumption Time: 0.11342
Total Iteration Time: 3.36392

Cumulative Model Updates: 455
Cumulative Timesteps: 7,652,342

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02614
Policy Entropy: 4.46461
Value Function Loss: 0.04708

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06201
Value Function Update Magnitude: 0.03623

Collected Steps per Second: 24,546.75466
Overall Steps per Second: 17,399.75662

Timestep Collection Time: 2.03709
Timestep Consumption Time: 0.83674
PPO Batch Consumption Time: 0.06188
Total Iteration Time: 2.87383

Cumulative Model Updates: 458
Cumulative Timesteps: 7,702,346

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 7702346...
Checkpoint 7702346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11912
Policy Entropy: 4.46447
Value Function Loss: 0.04336

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05774
Value Function Update Magnitude: 0.03451

Collected Steps per Second: 22,289.37838
Overall Steps per Second: 15,139.72423

Timestep Collection Time: 2.24439
Timestep Consumption Time: 1.05990
PPO Batch Consumption Time: 0.10193
Total Iteration Time: 3.30429

Cumulative Model Updates: 461
Cumulative Timesteps: 7,752,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03419
Policy Entropy: 4.46392
Value Function Loss: 0.04897

Mean KL Divergence: 0.00019
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05752
Value Function Update Magnitude: 0.03320

Collected Steps per Second: 24,762.46615
Overall Steps per Second: 16,684.25233

Timestep Collection Time: 2.02015
Timestep Consumption Time: 0.97812
PPO Batch Consumption Time: 0.08631
Total Iteration Time: 2.99828

Cumulative Model Updates: 464
Cumulative Timesteps: 7,802,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 7802396...
Checkpoint 7802396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01517
Policy Entropy: 4.46322
Value Function Loss: 0.04920

Mean KL Divergence: 0.00018
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06129
Value Function Update Magnitude: 0.03434

Collected Steps per Second: 25,602.57369
Overall Steps per Second: 16,790.82531

Timestep Collection Time: 1.95355
Timestep Consumption Time: 1.02522
PPO Batch Consumption Time: 0.09179
Total Iteration Time: 2.97877

Cumulative Model Updates: 467
Cumulative Timesteps: 7,852,412

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02303
Policy Entropy: 4.46147
Value Function Loss: 0.05345

Mean KL Divergence: 0.00023
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06409
Value Function Update Magnitude: 0.03561

Collected Steps per Second: 25,034.77734
Overall Steps per Second: 16,677.55629

Timestep Collection Time: 1.99778
Timestep Consumption Time: 1.00110
PPO Batch Consumption Time: 0.07980
Total Iteration Time: 2.99888

Cumulative Model Updates: 470
Cumulative Timesteps: 7,902,426

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 7902426...
Checkpoint 7902426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00493
Policy Entropy: 4.45811
Value Function Loss: 0.05136

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06490
Value Function Update Magnitude: 0.03725

Collected Steps per Second: 24,217.59120
Overall Steps per Second: 15,847.17293

Timestep Collection Time: 2.06470
Timestep Consumption Time: 1.09057
PPO Batch Consumption Time: 0.12204
Total Iteration Time: 3.15526

Cumulative Model Updates: 473
Cumulative Timesteps: 7,952,428

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12645
Policy Entropy: 4.45315
Value Function Loss: 0.05616

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00088
Policy Update Magnitude: 0.06587
Value Function Update Magnitude: 0.04150

Collected Steps per Second: 25,367.52453
Overall Steps per Second: 16,456.59182

Timestep Collection Time: 1.97158
Timestep Consumption Time: 1.06757
PPO Batch Consumption Time: 0.05998
Total Iteration Time: 3.03915

Cumulative Model Updates: 476
Cumulative Timesteps: 8,002,442

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 8002442...
Checkpoint 8002442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03209
Policy Entropy: 4.44773
Value Function Loss: 0.04896

Mean KL Divergence: 0.00061
SB3 Clip Fraction: 0.00089
Policy Update Magnitude: 0.06768
Value Function Update Magnitude: 0.04613

Collected Steps per Second: 22,070.29324
Overall Steps per Second: 14,954.96823

Timestep Collection Time: 2.26594
Timestep Consumption Time: 1.07810
PPO Batch Consumption Time: 0.11490
Total Iteration Time: 3.34404

Cumulative Model Updates: 479
Cumulative Timesteps: 8,052,452

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01669
Policy Entropy: 4.44275
Value Function Loss: 0.05181

Mean KL Divergence: 0.00061
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.06773
Value Function Update Magnitude: 0.04686

Collected Steps per Second: 25,112.39348
Overall Steps per Second: 16,608.97007

Timestep Collection Time: 1.99169
Timestep Consumption Time: 1.01970
PPO Batch Consumption Time: 0.08925
Total Iteration Time: 3.01138

Cumulative Model Updates: 482
Cumulative Timesteps: 8,102,468

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 8102468...
Checkpoint 8102468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00155
Policy Entropy: 4.43896
Value Function Loss: 0.07019

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.06701
Value Function Update Magnitude: 0.04038

Collected Steps per Second: 24,013.62827
Overall Steps per Second: 15,831.46070

Timestep Collection Time: 2.08332
Timestep Consumption Time: 1.07672
PPO Batch Consumption Time: 0.10929
Total Iteration Time: 3.16004

Cumulative Model Updates: 485
Cumulative Timesteps: 8,152,496

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05415
Policy Entropy: 4.43710
Value Function Loss: 0.07949

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06657
Value Function Update Magnitude: 0.04050

Collected Steps per Second: 24,804.71852
Overall Steps per Second: 16,955.67596

Timestep Collection Time: 2.01599
Timestep Consumption Time: 0.93323
PPO Batch Consumption Time: 0.06599
Total Iteration Time: 2.94922

Cumulative Model Updates: 488
Cumulative Timesteps: 8,202,502

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 8202502...
Checkpoint 8202502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01633
Policy Entropy: 4.43663
Value Function Loss: 0.07502

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07199
Value Function Update Magnitude: 0.04122

Collected Steps per Second: 25,883.58422
Overall Steps per Second: 17,571.79333

Timestep Collection Time: 1.93219
Timestep Consumption Time: 0.91396
PPO Batch Consumption Time: 0.05990
Total Iteration Time: 2.84615

Cumulative Model Updates: 491
Cumulative Timesteps: 8,252,514

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03201
Policy Entropy: 4.43655
Value Function Loss: 0.04160

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07197
Value Function Update Magnitude: 0.03450

Collected Steps per Second: 21,681.01871
Overall Steps per Second: 14,611.47888

Timestep Collection Time: 2.30616
Timestep Consumption Time: 1.11580
PPO Batch Consumption Time: 0.12589
Total Iteration Time: 3.42197

Cumulative Model Updates: 494
Cumulative Timesteps: 8,302,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 8302514...
Checkpoint 8302514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02110
Policy Entropy: 4.43638
Value Function Loss: 0.03423

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06436
Value Function Update Magnitude: 0.03135

Collected Steps per Second: 24,613.82178
Overall Steps per Second: 17,474.00737

Timestep Collection Time: 2.03260
Timestep Consumption Time: 0.83051
PPO Batch Consumption Time: 0.06027
Total Iteration Time: 2.86311

Cumulative Model Updates: 497
Cumulative Timesteps: 8,352,544

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03010
Policy Entropy: 4.43835
Value Function Loss: 0.03279

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.03306

Collected Steps per Second: 25,296.76521
Overall Steps per Second: 16,315.64907

Timestep Collection Time: 1.97654
Timestep Consumption Time: 1.08801
PPO Batch Consumption Time: 0.11497
Total Iteration Time: 3.06454

Cumulative Model Updates: 500
Cumulative Timesteps: 8,402,544

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 8402544...
Checkpoint 8402544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01663
Policy Entropy: 4.44159
Value Function Loss: 0.07263

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05924
Value Function Update Magnitude: 0.03446

Collected Steps per Second: 24,598.70316
Overall Steps per Second: 16,921.57250

Timestep Collection Time: 2.03295
Timestep Consumption Time: 0.92233
PPO Batch Consumption Time: 0.06519
Total Iteration Time: 2.95528

Cumulative Model Updates: 503
Cumulative Timesteps: 8,452,552

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03397
Policy Entropy: 4.44462
Value Function Loss: 0.06868

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06497
Value Function Update Magnitude: 0.02463

Collected Steps per Second: 25,778.85012
Overall Steps per Second: 16,561.10132

Timestep Collection Time: 1.94043
Timestep Consumption Time: 1.08002
PPO Batch Consumption Time: 0.11720
Total Iteration Time: 3.02045

Cumulative Model Updates: 506
Cumulative Timesteps: 8,502,574

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 8502574...
Checkpoint 8502574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02636
Policy Entropy: 4.44552
Value Function Loss: 0.06862

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07158
Value Function Update Magnitude: 0.02970

Collected Steps per Second: 25,114.94446
Overall Steps per Second: 17,155.88458

Timestep Collection Time: 1.99148
Timestep Consumption Time: 0.92390
PPO Batch Consumption Time: 0.06290
Total Iteration Time: 2.91538

Cumulative Model Updates: 509
Cumulative Timesteps: 8,552,590

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01275
Policy Entropy: 4.44387
Value Function Loss: 0.04321

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06618
Value Function Update Magnitude: 0.02404

Collected Steps per Second: 24,269.83616
Overall Steps per Second: 16,327.70926

Timestep Collection Time: 2.06042
Timestep Consumption Time: 1.00223
PPO Batch Consumption Time: 0.11202
Total Iteration Time: 3.06265

Cumulative Model Updates: 512
Cumulative Timesteps: 8,602,596

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 8602596...
Checkpoint 8602596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00957
Policy Entropy: 4.44058
Value Function Loss: 0.03896

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06037
Value Function Update Magnitude: 0.02426

Collected Steps per Second: 25,003.51187
Overall Steps per Second: 17,091.84815

Timestep Collection Time: 2.00036
Timestep Consumption Time: 0.92595
PPO Batch Consumption Time: 0.06406
Total Iteration Time: 2.92631

Cumulative Model Updates: 515
Cumulative Timesteps: 8,652,612

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04681
Policy Entropy: 4.43518
Value Function Loss: 0.03928

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06187
Value Function Update Magnitude: 0.02360

Collected Steps per Second: 24,843.02746
Overall Steps per Second: 16,363.16611

Timestep Collection Time: 2.01336
Timestep Consumption Time: 1.04338
PPO Batch Consumption Time: 0.10630
Total Iteration Time: 3.05674

Cumulative Model Updates: 518
Cumulative Timesteps: 8,702,630

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 8702630...
Checkpoint 8702630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01649
Policy Entropy: 4.42789
Value Function Loss: 0.02615

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06064
Value Function Update Magnitude: 0.03459

Collected Steps per Second: 25,258.44521
Overall Steps per Second: 17,179.52553

Timestep Collection Time: 1.97969
Timestep Consumption Time: 0.93098
PPO Batch Consumption Time: 0.06364
Total Iteration Time: 2.91067

Cumulative Model Updates: 521
Cumulative Timesteps: 8,752,634

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00316
Policy Entropy: 4.41954
Value Function Loss: 0.02149

Mean KL Divergence: 0.00073
SB3 Clip Fraction: 0.00044
Policy Update Magnitude: 0.05677
Value Function Update Magnitude: 0.03890

Collected Steps per Second: 24,672.59533
Overall Steps per Second: 16,296.97097

Timestep Collection Time: 2.02727
Timestep Consumption Time: 1.04189
PPO Batch Consumption Time: 0.10370
Total Iteration Time: 3.06916

Cumulative Model Updates: 524
Cumulative Timesteps: 8,802,652

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 8802652...
Checkpoint 8802652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00241
Policy Entropy: 4.41124
Value Function Loss: 0.02460

Mean KL Divergence: 0.00073
SB3 Clip Fraction: 0.00168
Policy Update Magnitude: 0.05131
Value Function Update Magnitude: 0.04282

Collected Steps per Second: 24,487.74574
Overall Steps per Second: 17,033.42817

Timestep Collection Time: 2.04184
Timestep Consumption Time: 0.89357
PPO Batch Consumption Time: 0.06454
Total Iteration Time: 2.93540

Cumulative Model Updates: 527
Cumulative Timesteps: 8,852,652

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02022
Policy Entropy: 4.40461
Value Function Loss: 0.02456

Mean KL Divergence: 0.00060
SB3 Clip Fraction: 0.00099
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.04088

Collected Steps per Second: 25,752.87516
Overall Steps per Second: 16,531.53465

Timestep Collection Time: 1.94231
Timestep Consumption Time: 1.08343
PPO Batch Consumption Time: 0.11142
Total Iteration Time: 3.02573

Cumulative Model Updates: 530
Cumulative Timesteps: 8,902,672

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 8902672...
Checkpoint 8902672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00391
Policy Entropy: 4.39929
Value Function Loss: 0.04056

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.05531
Value Function Update Magnitude: 0.03618

Collected Steps per Second: 24,809.77954
Overall Steps per Second: 16,973.48350

Timestep Collection Time: 2.01646
Timestep Consumption Time: 0.93096
PPO Batch Consumption Time: 0.06429
Total Iteration Time: 2.94742

Cumulative Model Updates: 533
Cumulative Timesteps: 8,952,700

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01134
Policy Entropy: 4.39475
Value Function Loss: 0.04323

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06126
Value Function Update Magnitude: 0.03204

Collected Steps per Second: 24,970.22295
Overall Steps per Second: 16,503.47092

Timestep Collection Time: 2.00247
Timestep Consumption Time: 1.02732
PPO Batch Consumption Time: 0.11781
Total Iteration Time: 3.02979

Cumulative Model Updates: 536
Cumulative Timesteps: 9,002,702

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 9002702...
Checkpoint 9002702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01598
Policy Entropy: 4.39298
Value Function Loss: 0.05685

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06854
Value Function Update Magnitude: 0.02489

Collected Steps per Second: 24,601.18996
Overall Steps per Second: 16,839.97051

Timestep Collection Time: 2.03275
Timestep Consumption Time: 0.93685
PPO Batch Consumption Time: 0.06160
Total Iteration Time: 2.96960

Cumulative Model Updates: 539
Cumulative Timesteps: 9,052,710

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02458
Policy Entropy: 4.39670
Value Function Loss: 0.04654

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00009
Policy Update Magnitude: 0.07398
Value Function Update Magnitude: 0.02309

Collected Steps per Second: 24,350.44617
Overall Steps per Second: 16,509.91460

Timestep Collection Time: 2.05343
Timestep Consumption Time: 0.97517
PPO Batch Consumption Time: 0.08348
Total Iteration Time: 3.02860

Cumulative Model Updates: 542
Cumulative Timesteps: 9,102,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 9102712...
Checkpoint 9102712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02601
Policy Entropy: 4.40158
Value Function Loss: 0.05819

Mean KL Divergence: 0.00075
SB3 Clip Fraction: 0.00037
Policy Update Magnitude: 0.07646
Value Function Update Magnitude: 0.02335

Collected Steps per Second: 25,691.23353
Overall Steps per Second: 17,374.41528

Timestep Collection Time: 1.94627
Timestep Consumption Time: 0.93164
PPO Batch Consumption Time: 0.06134
Total Iteration Time: 2.87791

Cumulative Model Updates: 545
Cumulative Timesteps: 9,152,714

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01781
Policy Entropy: 4.40364
Value Function Loss: 0.05664

Mean KL Divergence: 0.00076
SB3 Clip Fraction: 0.00005
Policy Update Magnitude: 0.07324
Value Function Update Magnitude: 0.02690

Collected Steps per Second: 21,999.43756
Overall Steps per Second: 15,167.72356

Timestep Collection Time: 2.27297
Timestep Consumption Time: 1.02377
PPO Batch Consumption Time: 0.08960
Total Iteration Time: 3.29674

Cumulative Model Updates: 548
Cumulative Timesteps: 9,202,718

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 9202718...
Checkpoint 9202718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01892
Policy Entropy: 4.40152
Value Function Loss: 0.05872

Mean KL Divergence: 0.00069
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.07441
Value Function Update Magnitude: 0.03021

Collected Steps per Second: 24,476.58639
Overall Steps per Second: 16,769.73457

Timestep Collection Time: 2.04342
Timestep Consumption Time: 0.93909
PPO Batch Consumption Time: 0.08931
Total Iteration Time: 2.98252

Cumulative Model Updates: 551
Cumulative Timesteps: 9,252,734

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00924
Policy Entropy: 4.39508
Value Function Loss: 0.04560

Mean KL Divergence: 0.00077
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07392
Value Function Update Magnitude: 0.02729

Collected Steps per Second: 24,803.89544
Overall Steps per Second: 16,689.04166

Timestep Collection Time: 2.01581
Timestep Consumption Time: 0.98017
PPO Batch Consumption Time: 0.07814
Total Iteration Time: 2.99598

Cumulative Model Updates: 554
Cumulative Timesteps: 9,302,734

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 9302734...
Checkpoint 9302734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01321
Policy Entropy: 4.38332
Value Function Loss: 0.03819

Mean KL Divergence: 0.00107
SB3 Clip Fraction: 0.00007
Policy Update Magnitude: 0.07236
Value Function Update Magnitude: 0.02339

Collected Steps per Second: 22,078.74198
Overall Steps per Second: 14,902.48146

Timestep Collection Time: 2.26571
Timestep Consumption Time: 1.09105
PPO Batch Consumption Time: 0.11786
Total Iteration Time: 3.35676

Cumulative Model Updates: 557
Cumulative Timesteps: 9,352,758

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04375
Policy Entropy: 4.37244
Value Function Loss: 0.02859

Mean KL Divergence: 0.00117
SB3 Clip Fraction: 0.00180
Policy Update Magnitude: 0.06452
Value Function Update Magnitude: 0.02133

Collected Steps per Second: 25,590.68925
Overall Steps per Second: 17,152.14285

Timestep Collection Time: 1.95470
Timestep Consumption Time: 0.96168
PPO Batch Consumption Time: 0.06397
Total Iteration Time: 2.91637

Cumulative Model Updates: 560
Cumulative Timesteps: 9,402,780

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 9402780...
Checkpoint 9402780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01122
Policy Entropy: 4.36884
Value Function Loss: 0.03166

Mean KL Divergence: 0.00074
SB3 Clip Fraction: 0.00006
Policy Update Magnitude: 0.05987
Value Function Update Magnitude: 0.02565

Collected Steps per Second: 21,874.85121
Overall Steps per Second: 15,232.44921

Timestep Collection Time: 2.28719
Timestep Consumption Time: 0.99737
PPO Batch Consumption Time: 0.07475
Total Iteration Time: 3.28457

Cumulative Model Updates: 563
Cumulative Timesteps: 9,452,812

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02678
Policy Entropy: 4.37327
Value Function Loss: 0.02473

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.06049
Value Function Update Magnitude: 0.03673

Collected Steps per Second: 24,605.20580
Overall Steps per Second: 16,687.45369

Timestep Collection Time: 2.03258
Timestep Consumption Time: 0.96440
PPO Batch Consumption Time: 0.07214
Total Iteration Time: 2.99698

Cumulative Model Updates: 566
Cumulative Timesteps: 9,502,824

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 9502824...
Checkpoint 9502824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01650
Policy Entropy: 4.38112
Value Function Loss: 0.02316

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06179
Value Function Update Magnitude: 0.04154

Collected Steps per Second: 25,695.11641
Overall Steps per Second: 16,829.29466

Timestep Collection Time: 1.94621
Timestep Consumption Time: 1.02528
PPO Batch Consumption Time: 0.09511
Total Iteration Time: 2.97149

Cumulative Model Updates: 569
Cumulative Timesteps: 9,552,832

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00074
Policy Entropy: 4.38992
Value Function Loss: 0.01242

Mean KL Divergence: 0.00071
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05747
Value Function Update Magnitude: 0.04258

Collected Steps per Second: 24,674.75200
Overall Steps per Second: 16,670.23921

Timestep Collection Time: 2.02693
Timestep Consumption Time: 0.97327
PPO Batch Consumption Time: 0.08449
Total Iteration Time: 3.00020

Cumulative Model Updates: 572
Cumulative Timesteps: 9,602,846

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 9602846...
Checkpoint 9602846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05754
Policy Entropy: 4.39863
Value Function Loss: 0.03688

Mean KL Divergence: 0.00076
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.05959
Value Function Update Magnitude: 0.03474

Collected Steps per Second: 24,442.57685
Overall Steps per Second: 16,784.44575

Timestep Collection Time: 2.04684
Timestep Consumption Time: 0.93390
PPO Batch Consumption Time: 0.08432
Total Iteration Time: 2.98074

Cumulative Model Updates: 575
Cumulative Timesteps: 9,652,876

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07433
Policy Entropy: 4.40806
Value Function Loss: 0.05513

Mean KL Divergence: 0.00082
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.06326
Value Function Update Magnitude: 0.02648

Collected Steps per Second: 24,596.75633
Overall Steps per Second: 15,790.89402

Timestep Collection Time: 2.03376
Timestep Consumption Time: 1.13414
PPO Batch Consumption Time: 0.12694
Total Iteration Time: 3.16790

Cumulative Model Updates: 578
Cumulative Timesteps: 9,702,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 9702900...
Checkpoint 9702900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04475
Policy Entropy: 4.41384
Value Function Loss: 0.05844

Mean KL Divergence: 0.00073
SB3 Clip Fraction: 0.00006
Policy Update Magnitude: 0.07294
Value Function Update Magnitude: 0.02855

Collected Steps per Second: 25,039.19730
Overall Steps per Second: 17,315.92257

Timestep Collection Time: 1.99695
Timestep Consumption Time: 0.89068
PPO Batch Consumption Time: 0.06018
Total Iteration Time: 2.88763

Cumulative Model Updates: 581
Cumulative Timesteps: 9,752,902

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00918
Policy Entropy: 4.41652
Value Function Loss: 0.04591

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07536
Value Function Update Magnitude: 0.03473

Collected Steps per Second: 22,623.63006
Overall Steps per Second: 15,183.79071

Timestep Collection Time: 2.21087
Timestep Consumption Time: 1.08330
PPO Batch Consumption Time: 0.11085
Total Iteration Time: 3.29417

Cumulative Model Updates: 584
Cumulative Timesteps: 9,802,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 9802920...
Checkpoint 9802920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02898
Policy Entropy: 4.41650
Value Function Loss: 0.03962

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07283
Value Function Update Magnitude: 0.03354

Collected Steps per Second: 24,692.08073
Overall Steps per Second: 16,891.02725

Timestep Collection Time: 2.02599
Timestep Consumption Time: 0.93570
PPO Batch Consumption Time: 0.06238
Total Iteration Time: 2.96169

Cumulative Model Updates: 587
Cumulative Timesteps: 9,852,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00150
Policy Entropy: 4.41804
Value Function Loss: 0.03287

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06991
Value Function Update Magnitude: 0.03150

Collected Steps per Second: 24,841.52686
Overall Steps per Second: 16,595.49138

Timestep Collection Time: 2.01332
Timestep Consumption Time: 1.00039
PPO Batch Consumption Time: 0.11327
Total Iteration Time: 3.01371

Cumulative Model Updates: 590
Cumulative Timesteps: 9,902,960

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 9902960...
Checkpoint 9902960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01245
Policy Entropy: 4.42175
Value Function Loss: 0.03703

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06774
Value Function Update Magnitude: 0.03021

Collected Steps per Second: 24,899.14775
Overall Steps per Second: 17,064.83012

Timestep Collection Time: 2.00890
Timestep Consumption Time: 0.92227
PPO Batch Consumption Time: 0.06376
Total Iteration Time: 2.93117

Cumulative Model Updates: 593
Cumulative Timesteps: 9,952,980

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07543
Policy Entropy: 4.42647
Value Function Loss: 0.03013

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06507
Value Function Update Magnitude: 0.02705

Collected Steps per Second: 24,826.29413
Overall Steps per Second: 16,377.74782

Timestep Collection Time: 2.01440
Timestep Consumption Time: 1.03914
PPO Batch Consumption Time: 0.10609
Total Iteration Time: 3.05353

Cumulative Model Updates: 596
Cumulative Timesteps: 10,002,990

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 10002990...
Checkpoint 10002990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03216
Policy Entropy: 4.43137
Value Function Loss: 0.04630

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06529
Value Function Update Magnitude: 0.02905

Collected Steps per Second: 24,671.86435
Overall Steps per Second: 17,394.60494

Timestep Collection Time: 2.02725
Timestep Consumption Time: 0.84813
PPO Batch Consumption Time: 0.06204
Total Iteration Time: 2.87537

Cumulative Model Updates: 599
Cumulative Timesteps: 10,053,006

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02888
Policy Entropy: 4.43501
Value Function Loss: 0.03516

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06540
Value Function Update Magnitude: 0.03040

Collected Steps per Second: 22,259.73713
Overall Steps per Second: 15,135.01175

Timestep Collection Time: 2.24711
Timestep Consumption Time: 1.05781
PPO Batch Consumption Time: 0.10251
Total Iteration Time: 3.30492

Cumulative Model Updates: 602
Cumulative Timesteps: 10,103,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 10103026...
Checkpoint 10103026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01504
Policy Entropy: 4.43838
Value Function Loss: 0.04725

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.06787
Value Function Update Magnitude: 0.03060

Collected Steps per Second: 24,684.55079
Overall Steps per Second: 16,724.82330

Timestep Collection Time: 2.02653
Timestep Consumption Time: 0.96447
PPO Batch Consumption Time: 0.07903
Total Iteration Time: 2.99100

Cumulative Model Updates: 605
Cumulative Timesteps: 10,153,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01208
Policy Entropy: 4.44173
Value Function Loss: 0.04354

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06703
Value Function Update Magnitude: 0.02877

Collected Steps per Second: 25,766.11237
Overall Steps per Second: 16,744.60176

Timestep Collection Time: 1.94077
Timestep Consumption Time: 1.04563
PPO Batch Consumption Time: 0.09279
Total Iteration Time: 2.98640

Cumulative Model Updates: 608
Cumulative Timesteps: 10,203,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 10203056...
Checkpoint 10203056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05683
Policy Entropy: 4.44602
Value Function Loss: 0.05984

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07538
Value Function Update Magnitude: 0.03267

Collected Steps per Second: 24,829.91548
Overall Steps per Second: 16,716.49062

Timestep Collection Time: 2.01442
Timestep Consumption Time: 0.97771
PPO Batch Consumption Time: 0.07687
Total Iteration Time: 2.99214

Cumulative Model Updates: 611
Cumulative Timesteps: 10,253,074

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01780
Policy Entropy: 4.45285
Value Function Loss: 0.06620

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08663
Value Function Update Magnitude: 0.03980

Collected Steps per Second: 24,783.96299
Overall Steps per Second: 16,752.43033

Timestep Collection Time: 2.01784
Timestep Consumption Time: 0.96740
PPO Batch Consumption Time: 0.09883
Total Iteration Time: 2.98524

Cumulative Model Updates: 614
Cumulative Timesteps: 10,303,084

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 10303084...
Checkpoint 10303084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00608
Policy Entropy: 4.45997
Value Function Loss: 0.07808

Mean KL Divergence: 0.00090
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.09157
Value Function Update Magnitude: 0.04898

Collected Steps per Second: 24,573.71064
Overall Steps per Second: 15,818.68112

Timestep Collection Time: 2.03502
Timestep Consumption Time: 1.12631
PPO Batch Consumption Time: 0.12236
Total Iteration Time: 3.16133

Cumulative Model Updates: 617
Cumulative Timesteps: 10,353,092

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03346
Policy Entropy: 4.46575
Value Function Loss: 0.06151

Mean KL Divergence: 0.00090
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.08853
Value Function Update Magnitude: 0.04941

Collected Steps per Second: 25,250.09147
Overall Steps per Second: 17,404.08051

Timestep Collection Time: 1.98075
Timestep Consumption Time: 0.89295
PPO Batch Consumption Time: 0.05919
Total Iteration Time: 2.87369

Cumulative Model Updates: 620
Cumulative Timesteps: 10,403,106

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 10403106...
Checkpoint 10403106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10456
Policy Entropy: 4.46890
Value Function Loss: 0.03927

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08238
Value Function Update Magnitude: 0.04190

Collected Steps per Second: 22,671.97874
Overall Steps per Second: 15,135.72596

Timestep Collection Time: 2.20589
Timestep Consumption Time: 1.09834
PPO Batch Consumption Time: 0.11298
Total Iteration Time: 3.30424

Cumulative Model Updates: 623
Cumulative Timesteps: 10,453,118

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03685
Policy Entropy: 4.47082
Value Function Loss: 0.02048

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07347
Value Function Update Magnitude: 0.05157

Collected Steps per Second: 24,870.95452
Overall Steps per Second: 16,919.71207

Timestep Collection Time: 2.01142
Timestep Consumption Time: 0.94525
PPO Batch Consumption Time: 0.06582
Total Iteration Time: 2.95667

Cumulative Model Updates: 626
Cumulative Timesteps: 10,503,144

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 10503144...
Checkpoint 10503144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00625
Policy Entropy: 4.47237
Value Function Loss: 0.02122

Mean KL Divergence: 0.00023
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06720
Value Function Update Magnitude: 0.05576

Collected Steps per Second: 23,211.37791
Overall Steps per Second: 15,541.44115

Timestep Collection Time: 2.15455
Timestep Consumption Time: 1.06330
PPO Batch Consumption Time: 0.11153
Total Iteration Time: 3.21785

Cumulative Model Updates: 629
Cumulative Timesteps: 10,553,154

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00348
Policy Entropy: 4.47361
Value Function Loss: 0.03540

Mean KL Divergence: 0.00018
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06259
Value Function Update Magnitude: 0.05053

Collected Steps per Second: 25,552.75122
Overall Steps per Second: 16,612.12788

Timestep Collection Time: 1.95689
Timestep Consumption Time: 1.05320
PPO Batch Consumption Time: 0.10168
Total Iteration Time: 3.01009

Cumulative Model Updates: 632
Cumulative Timesteps: 10,603,158

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 10603158...
Checkpoint 10603158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06990
Policy Entropy: 4.47524
Value Function Loss: 0.05914

Mean KL Divergence: 0.00018
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06845
Value Function Update Magnitude: 0.03462

Collected Steps per Second: 24,652.81304
Overall Steps per Second: 16,738.92007

Timestep Collection Time: 2.02873
Timestep Consumption Time: 0.95915
PPO Batch Consumption Time: 0.08262
Total Iteration Time: 2.98789

Cumulative Model Updates: 635
Cumulative Timesteps: 10,653,172

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04553
Policy Entropy: 4.47666
Value Function Loss: 0.07256

Mean KL Divergence: 0.00020
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07479
Value Function Update Magnitude: 0.03348

Collected Steps per Second: 24,845.53514
Overall Steps per Second: 16,737.74659

Timestep Collection Time: 2.01284
Timestep Consumption Time: 0.97502
PPO Batch Consumption Time: 0.09858
Total Iteration Time: 2.98786

Cumulative Model Updates: 638
Cumulative Timesteps: 10,703,182

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 10703182...
Checkpoint 10703182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05340
Policy Entropy: 4.47741
Value Function Loss: 0.06838

Mean KL Divergence: 0.00020
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07924
Value Function Update Magnitude: 0.04192

Collected Steps per Second: 25,008.60852
Overall Steps per Second: 15,798.90887

Timestep Collection Time: 1.99947
Timestep Consumption Time: 1.16556
PPO Batch Consumption Time: 0.10850
Total Iteration Time: 3.16503

Cumulative Model Updates: 641
Cumulative Timesteps: 10,753,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02257
Policy Entropy: 4.47756
Value Function Loss: 0.03873

Mean KL Divergence: 0.00017
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07758
Value Function Update Magnitude: 0.03731

Collected Steps per Second: 24,869.58357
Overall Steps per Second: 16,990.08205

Timestep Collection Time: 2.01161
Timestep Consumption Time: 0.93293
PPO Batch Consumption Time: 0.06436
Total Iteration Time: 2.94454

Cumulative Model Updates: 644
Cumulative Timesteps: 10,803,214

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 10803214...
Checkpoint 10803214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03505
Policy Entropy: 4.47794
Value Function Loss: 0.03597

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07090
Value Function Update Magnitude: 0.02881

Collected Steps per Second: 25,855.79448
Overall Steps per Second: 17,531.08287

Timestep Collection Time: 1.93380
Timestep Consumption Time: 0.91827
PPO Batch Consumption Time: 0.05931
Total Iteration Time: 2.85208

Cumulative Model Updates: 647
Cumulative Timesteps: 10,853,214

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00035
Policy Entropy: 4.47895
Value Function Loss: 0.03668

Mean KL Divergence: 0.00014
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06832
Value Function Update Magnitude: 0.02617

Collected Steps per Second: 21,754.63014
Overall Steps per Second: 14,605.81320

Timestep Collection Time: 2.29836
Timestep Consumption Time: 1.12493
PPO Batch Consumption Time: 0.12309
Total Iteration Time: 3.42329

Cumulative Model Updates: 650
Cumulative Timesteps: 10,903,214

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 10903214...
Checkpoint 10903214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00203
Policy Entropy: 4.48009
Value Function Loss: 0.04796

Mean KL Divergence: 0.00014
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07138
Value Function Update Magnitude: 0.02948

Collected Steps per Second: 24,525.55260
Overall Steps per Second: 17,277.54743

Timestep Collection Time: 2.04032
Timestep Consumption Time: 0.85592
PPO Batch Consumption Time: 0.06084
Total Iteration Time: 2.89624

Cumulative Model Updates: 653
Cumulative Timesteps: 10,953,254

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00409
Policy Entropy: 4.48123
Value Function Loss: 0.04962

Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07178
Value Function Update Magnitude: 0.03167

Collected Steps per Second: 25,067.11021
Overall Steps per Second: 16,425.04096

Timestep Collection Time: 1.99496
Timestep Consumption Time: 1.04965
PPO Batch Consumption Time: 0.10092
Total Iteration Time: 3.04462

Cumulative Model Updates: 656
Cumulative Timesteps: 11,003,262

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 11003262...
Checkpoint 11003262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02277
Policy Entropy: 4.48183
Value Function Loss: 0.04848

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07232
Value Function Update Magnitude: 0.03925

Collected Steps per Second: 23,135.09967
Overall Steps per Second: 16,238.39599

Timestep Collection Time: 2.16234
Timestep Consumption Time: 0.91838
PPO Batch Consumption Time: 0.06481
Total Iteration Time: 3.08072

Cumulative Model Updates: 659
Cumulative Timesteps: 11,053,288

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04919
Policy Entropy: 4.48213
Value Function Loss: 0.03920

Mean KL Divergence: 0.00014
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07231
Value Function Update Magnitude: 0.04808

Collected Steps per Second: 22,094.99452
Overall Steps per Second: 15,013.02866

Timestep Collection Time: 2.26404
Timestep Consumption Time: 1.06800
PPO Batch Consumption Time: 0.10763
Total Iteration Time: 3.33204

Cumulative Model Updates: 662
Cumulative Timesteps: 11,103,312

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 11103312...
Checkpoint 11103312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07917
Policy Entropy: 4.48227
Value Function Loss: 0.02659

Mean KL Divergence: 0.00012
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06863
Value Function Update Magnitude: 0.05217

Collected Steps per Second: 24,480.83708
Overall Steps per Second: 16,158.68728

Timestep Collection Time: 2.04290
Timestep Consumption Time: 1.05215
PPO Batch Consumption Time: 0.08600
Total Iteration Time: 3.09505

Cumulative Model Updates: 665
Cumulative Timesteps: 11,153,324

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02923
Policy Entropy: 4.48230
Value Function Loss: 0.02064

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06321
Value Function Update Magnitude: 0.04562

Collected Steps per Second: 22,563.46691
Overall Steps per Second: 16,338.65155

Timestep Collection Time: 2.21730
Timestep Consumption Time: 0.84476
PPO Batch Consumption Time: 0.05809
Total Iteration Time: 3.06206

Cumulative Model Updates: 668
Cumulative Timesteps: 11,203,354

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 11203354...
Checkpoint 11203354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01254
Policy Entropy: 4.48248
Value Function Loss: 0.01740

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06053
Value Function Update Magnitude: 0.04169

Collected Steps per Second: 21,351.35152
Overall Steps per Second: 14,722.80903

Timestep Collection Time: 2.34252
Timestep Consumption Time: 1.05466
PPO Batch Consumption Time: 0.09822
Total Iteration Time: 3.39718

Cumulative Model Updates: 671
Cumulative Timesteps: 11,253,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01225
Policy Entropy: 4.48275
Value Function Loss: 0.01800

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05737
Value Function Update Magnitude: 0.04028

Collected Steps per Second: 25,092.84146
Overall Steps per Second: 17,319.62090

Timestep Collection Time: 1.99332
Timestep Consumption Time: 0.89462
PPO Batch Consumption Time: 0.06344
Total Iteration Time: 2.88794

Cumulative Model Updates: 674
Cumulative Timesteps: 11,303,388

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 11303388...
Checkpoint 11303388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01560
Policy Entropy: 4.48327
Value Function Loss: 0.02340

Mean KL Divergence: 0.00009
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.03738

Collected Steps per Second: 24,665.39551
Overall Steps per Second: 17,570.19508

Timestep Collection Time: 2.02819
Timestep Consumption Time: 0.81902
PPO Batch Consumption Time: 0.05756
Total Iteration Time: 2.84721

Cumulative Model Updates: 677
Cumulative Timesteps: 11,353,414

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07445
Policy Entropy: 4.48426
Value Function Loss: 0.03682

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06084
Value Function Update Magnitude: 0.02969

Collected Steps per Second: 19,219.16891
Overall Steps per Second: 13,619.04486

Timestep Collection Time: 2.60271
Timestep Consumption Time: 1.07023
PPO Batch Consumption Time: 0.08826
Total Iteration Time: 3.67294

Cumulative Model Updates: 680
Cumulative Timesteps: 11,403,436

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 11403436...
Checkpoint 11403436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01667
Policy Entropy: 4.48581
Value Function Loss: 0.03636

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06579
Value Function Update Magnitude: 0.02924

Collected Steps per Second: 24,338.73720
Overall Steps per Second: 17,246.67344

Timestep Collection Time: 2.05434
Timestep Consumption Time: 0.84477
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 2.89911

Cumulative Model Updates: 683
Cumulative Timesteps: 11,453,436

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05478
Policy Entropy: 4.48722
Value Function Loss: 0.04536

Mean KL Divergence: 0.00018
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06951
Value Function Update Magnitude: 0.03358

Collected Steps per Second: 21,869.95603
Overall Steps per Second: 14,730.36909

Timestep Collection Time: 2.28652
Timestep Consumption Time: 1.10824
PPO Batch Consumption Time: 0.12060
Total Iteration Time: 3.39476

Cumulative Model Updates: 686
Cumulative Timesteps: 11,503,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 11503442...
Checkpoint 11503442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03125
Policy Entropy: 4.48802
Value Function Loss: 0.05026

Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06903
Value Function Update Magnitude: 0.03697

Collected Steps per Second: 24,465.78559
Overall Steps per Second: 16,979.25029

Timestep Collection Time: 2.04432
Timestep Consumption Time: 0.90139
PPO Batch Consumption Time: 0.06402
Total Iteration Time: 2.94571

Cumulative Model Updates: 689
Cumulative Timesteps: 11,553,458

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04783
Policy Entropy: 4.48798
Value Function Loss: 0.04904

Mean KL Divergence: 0.00011
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07119
Value Function Update Magnitude: 0.04250

Collected Steps per Second: 24,837.10885
Overall Steps per Second: 16,585.03860

Timestep Collection Time: 2.01457
Timestep Consumption Time: 1.00237
PPO Batch Consumption Time: 0.11566
Total Iteration Time: 3.01694

Cumulative Model Updates: 692
Cumulative Timesteps: 11,603,494

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 11603494...
Checkpoint 11603494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04036
Policy Entropy: 4.48710
Value Function Loss: 0.04207

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07270
Value Function Update Magnitude: 0.04545

Collected Steps per Second: 24,777.47051
Overall Steps per Second: 17,017.66378

Timestep Collection Time: 2.01820
Timestep Consumption Time: 0.92027
PPO Batch Consumption Time: 0.06395
Total Iteration Time: 2.93848

Cumulative Model Updates: 695
Cumulative Timesteps: 11,653,500

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04137
Policy Entropy: 4.48612
Value Function Loss: 0.03740

Mean KL Divergence: 0.00012
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06883
Value Function Update Magnitude: 0.04441

Collected Steps per Second: 24,437.89352
Overall Steps per Second: 16,443.37076

Timestep Collection Time: 2.04690
Timestep Consumption Time: 0.99517
PPO Batch Consumption Time: 0.10902
Total Iteration Time: 3.04208

Cumulative Model Updates: 698
Cumulative Timesteps: 11,703,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 11703522...
Checkpoint 11703522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01954
Policy Entropy: 4.48561
Value Function Loss: 0.03883

Mean KL Divergence: 0.00011
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06897
Value Function Update Magnitude: 0.04236

Collected Steps per Second: 24,760.69301
Overall Steps per Second: 16,897.54642

Timestep Collection Time: 2.01989
Timestep Consumption Time: 0.93994
PPO Batch Consumption Time: 0.06362
Total Iteration Time: 2.95984

Cumulative Model Updates: 701
Cumulative Timesteps: 11,753,536

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10623
Policy Entropy: 4.48571
Value Function Loss: 0.04872

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06782
Value Function Update Magnitude: 0.04110

Collected Steps per Second: 24,628.98309
Overall Steps per Second: 16,510.65166

Timestep Collection Time: 2.03045
Timestep Consumption Time: 0.99838
PPO Batch Consumption Time: 0.09505
Total Iteration Time: 3.02883

Cumulative Model Updates: 704
Cumulative Timesteps: 11,803,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 11803544...
Checkpoint 11803544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00906
Policy Entropy: 4.48604
Value Function Loss: 0.06359

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06853
Value Function Update Magnitude: 0.03977

Collected Steps per Second: 24,691.24833
Overall Steps per Second: 16,799.83102

Timestep Collection Time: 2.02582
Timestep Consumption Time: 0.95159
PPO Batch Consumption Time: 0.06023
Total Iteration Time: 2.97741

Cumulative Model Updates: 707
Cumulative Timesteps: 11,853,564

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00691
Policy Entropy: 4.48607
Value Function Loss: 0.07289

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07523
Value Function Update Magnitude: 0.05031

Collected Steps per Second: 21,998.19746
Overall Steps per Second: 14,794.63802

Timestep Collection Time: 2.27346
Timestep Consumption Time: 1.10695
PPO Batch Consumption Time: 0.12055
Total Iteration Time: 3.38041

Cumulative Model Updates: 710
Cumulative Timesteps: 11,903,576

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 11903576...
Checkpoint 11903576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02098
Policy Entropy: 4.48530
Value Function Loss: 0.05815

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07809
Value Function Update Magnitude: 0.04819

Collected Steps per Second: 24,551.57423
Overall Steps per Second: 16,871.92830

Timestep Collection Time: 2.03734
Timestep Consumption Time: 0.92734
PPO Batch Consumption Time: 0.06399
Total Iteration Time: 2.96469

Cumulative Model Updates: 713
Cumulative Timesteps: 11,953,596

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03580
Policy Entropy: 4.48361
Value Function Loss: 0.04600

Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07598
Value Function Update Magnitude: 0.04362

Collected Steps per Second: 25,825.86912
Overall Steps per Second: 17,592.14606

Timestep Collection Time: 1.93666
Timestep Consumption Time: 0.90642
PPO Batch Consumption Time: 0.05960
Total Iteration Time: 2.84309

Cumulative Model Updates: 716
Cumulative Timesteps: 12,003,612

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 12003612...
Checkpoint 12003612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00653
Policy Entropy: 4.48093
Value Function Loss: 0.04506

Mean KL Divergence: 0.00026
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07439
Value Function Update Magnitude: 0.04860

Collected Steps per Second: 21,249.04952
Overall Steps per Second: 14,715.45342

Timestep Collection Time: 2.35380
Timestep Consumption Time: 1.04508
PPO Batch Consumption Time: 0.09807
Total Iteration Time: 3.39888

Cumulative Model Updates: 719
Cumulative Timesteps: 12,053,628

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00147
Policy Entropy: 4.47759
Value Function Loss: 0.05214

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07672
Value Function Update Magnitude: 0.05332

Collected Steps per Second: 24,576.56981
Overall Steps per Second: 17,326.12713

Timestep Collection Time: 2.03535
Timestep Consumption Time: 0.85173
PPO Batch Consumption Time: 0.06336
Total Iteration Time: 2.88708

Cumulative Model Updates: 722
Cumulative Timesteps: 12,103,650

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 12103650...
Checkpoint 12103650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00521
Policy Entropy: 4.47418
Value Function Loss: 0.05464

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07937
Value Function Update Magnitude: 0.05624

Collected Steps per Second: 24,724.82372
Overall Steps per Second: 16,374.99706

Timestep Collection Time: 2.02234
Timestep Consumption Time: 1.03122
PPO Batch Consumption Time: 0.09114
Total Iteration Time: 3.05356

Cumulative Model Updates: 725
Cumulative Timesteps: 12,153,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03722
Policy Entropy: 4.47132
Value Function Loss: 0.06015

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08155
Value Function Update Magnitude: 0.05475

Collected Steps per Second: 24,673.45194
Overall Steps per Second: 17,008.87329

Timestep Collection Time: 2.02704
Timestep Consumption Time: 0.91343
PPO Batch Consumption Time: 0.06353
Total Iteration Time: 2.94047

Cumulative Model Updates: 728
Cumulative Timesteps: 12,203,666

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 12203666...
Checkpoint 12203666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04378
Policy Entropy: 4.46929
Value Function Loss: 0.05504

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08292
Value Function Update Magnitude: 0.05438

Collected Steps per Second: 25,819.66409
Overall Steps per Second: 16,584.08565

Timestep Collection Time: 1.93659
Timestep Consumption Time: 1.07847
PPO Batch Consumption Time: 0.11193
Total Iteration Time: 3.01506

Cumulative Model Updates: 731
Cumulative Timesteps: 12,253,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01446
Policy Entropy: 4.46766
Value Function Loss: 0.05439

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08476
Value Function Update Magnitude: 0.06668

Collected Steps per Second: 24,863.60297
Overall Steps per Second: 16,991.97465

Timestep Collection Time: 2.01113
Timestep Consumption Time: 0.93167
PPO Batch Consumption Time: 0.06494
Total Iteration Time: 2.94280

Cumulative Model Updates: 734
Cumulative Timesteps: 12,303,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 12303672...
Checkpoint 12303672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00890
Policy Entropy: 4.46718
Value Function Loss: 0.03727

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08175
Value Function Update Magnitude: 0.07741

Collected Steps per Second: 24,705.61017
Overall Steps per Second: 16,510.56212

Timestep Collection Time: 2.02456
Timestep Consumption Time: 1.00489
PPO Batch Consumption Time: 0.11813
Total Iteration Time: 3.02945

Cumulative Model Updates: 737
Cumulative Timesteps: 12,353,690

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01649
Policy Entropy: 4.46693
Value Function Loss: 0.04835

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08016
Value Function Update Magnitude: 0.05867

Collected Steps per Second: 24,914.68141
Overall Steps per Second: 17,053.84963

Timestep Collection Time: 2.00765
Timestep Consumption Time: 0.92541
PPO Batch Consumption Time: 0.06322
Total Iteration Time: 2.93306

Cumulative Model Updates: 740
Cumulative Timesteps: 12,403,710

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 12403710...
Checkpoint 12403710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01515
Policy Entropy: 4.46748
Value Function Loss: 0.03526

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07844
Value Function Update Magnitude: 0.04642

Collected Steps per Second: 24,721.93385
Overall Steps per Second: 16,385.30308

Timestep Collection Time: 2.02314
Timestep Consumption Time: 1.02935
PPO Batch Consumption Time: 0.10738
Total Iteration Time: 3.05249

Cumulative Model Updates: 743
Cumulative Timesteps: 12,453,726

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03907
Policy Entropy: 4.46811
Value Function Loss: 0.03557

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07689
Value Function Update Magnitude: 0.04083

Collected Steps per Second: 25,425.66148
Overall Steps per Second: 17,337.39322

Timestep Collection Time: 1.96707
Timestep Consumption Time: 0.91768
PPO Batch Consumption Time: 0.06296
Total Iteration Time: 2.88475

Cumulative Model Updates: 746
Cumulative Timesteps: 12,503,740

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 12503740...
Checkpoint 12503740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00348
Policy Entropy: 4.46842
Value Function Loss: 0.02027

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07071
Value Function Update Magnitude: 0.03910

Collected Steps per Second: 22,213.62124
Overall Steps per Second: 15,187.63537

Timestep Collection Time: 2.25168
Timestep Consumption Time: 1.04166
PPO Batch Consumption Time: 0.09707
Total Iteration Time: 3.29334

Cumulative Model Updates: 749
Cumulative Timesteps: 12,553,758

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04611
Policy Entropy: 4.46820
Value Function Loss: 0.02406

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06691
Value Function Update Magnitude: 0.03795

Collected Steps per Second: 24,836.91494
Overall Steps per Second: 16,731.16971

Timestep Collection Time: 2.01354
Timestep Consumption Time: 0.97550
PPO Batch Consumption Time: 0.10442
Total Iteration Time: 2.98903

Cumulative Model Updates: 752
Cumulative Timesteps: 12,603,768

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 12603768...
Checkpoint 12603768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00070
Policy Entropy: 4.46782
Value Function Loss: 0.01759

Mean KL Divergence: 0.00017
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06305
Value Function Update Magnitude: 0.03378

Collected Steps per Second: 24,859.29179
Overall Steps per Second: 16,698.30565

Timestep Collection Time: 2.01212
Timestep Consumption Time: 0.98339
PPO Batch Consumption Time: 0.07926
Total Iteration Time: 2.99551

Cumulative Model Updates: 755
Cumulative Timesteps: 12,653,788

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00445
Policy Entropy: 4.46751
Value Function Loss: 0.01626

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.02849

Collected Steps per Second: 24,915.96466
Overall Steps per Second: 16,712.89666

Timestep Collection Time: 2.00755
Timestep Consumption Time: 0.98535
PPO Batch Consumption Time: 0.08732
Total Iteration Time: 2.99290

Cumulative Model Updates: 758
Cumulative Timesteps: 12,703,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 12703808...
Checkpoint 12703808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01002
Policy Entropy: 4.46742
Value Function Loss: 0.02689

Mean KL Divergence: 0.00012
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.02385

Collected Steps per Second: 25,819.07407
Overall Steps per Second: 16,817.61767

Timestep Collection Time: 1.93756
Timestep Consumption Time: 1.03706
PPO Batch Consumption Time: 0.09756
Total Iteration Time: 2.97462

Cumulative Model Updates: 761
Cumulative Timesteps: 12,753,834

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03208
Policy Entropy: 4.46656
Value Function Loss: 0.02833

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05682
Value Function Update Magnitude: 0.03053

Collected Steps per Second: 24,587.32044
Overall Steps per Second: 16,653.69825

Timestep Collection Time: 2.03398
Timestep Consumption Time: 0.96896
PPO Batch Consumption Time: 0.07786
Total Iteration Time: 3.00294

Cumulative Model Updates: 764
Cumulative Timesteps: 12,803,844

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 12803844...
Checkpoint 12803844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02169
Policy Entropy: 4.46438
Value Function Loss: 0.02801

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06265
Value Function Update Magnitude: 0.03175

Collected Steps per Second: 24,620.85662
Overall Steps per Second: 16,801.60883

Timestep Collection Time: 2.03194
Timestep Consumption Time: 0.94564
PPO Batch Consumption Time: 0.09425
Total Iteration Time: 2.97757

Cumulative Model Updates: 767
Cumulative Timesteps: 12,853,872

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03610
Policy Entropy: 4.46175
Value Function Loss: 0.01988

Mean KL Divergence: 0.00023
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06011
Value Function Update Magnitude: 0.02869

Collected Steps per Second: 24,716.69401
Overall Steps per Second: 16,669.69441

Timestep Collection Time: 2.02406
Timestep Consumption Time: 0.97708
PPO Batch Consumption Time: 0.07882
Total Iteration Time: 3.00113

Cumulative Model Updates: 770
Cumulative Timesteps: 12,903,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 12903900...
Checkpoint 12903900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04691
Policy Entropy: 4.45983
Value Function Loss: 0.03654

Mean KL Divergence: 0.00023
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05690
Value Function Update Magnitude: 0.02789

Collected Steps per Second: 23,690.65362
Overall Steps per Second: 15,786.43047

Timestep Collection Time: 2.11071
Timestep Consumption Time: 1.05682
PPO Batch Consumption Time: 0.11140
Total Iteration Time: 3.16753

Cumulative Model Updates: 773
Cumulative Timesteps: 12,953,904

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04711
Policy Entropy: 4.45852
Value Function Loss: 0.04889

Mean KL Divergence: 0.00018
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06150
Value Function Update Magnitude: 0.03297

Collected Steps per Second: 25,679.20053
Overall Steps per Second: 17,466.73027

Timestep Collection Time: 1.94718
Timestep Consumption Time: 0.91552
PPO Batch Consumption Time: 0.06139
Total Iteration Time: 2.86270

Cumulative Model Updates: 776
Cumulative Timesteps: 13,003,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 13003906...
Checkpoint 13003906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02067
Policy Entropy: 4.45816
Value Function Loss: 0.04099

Mean KL Divergence: 0.00014
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06803
Value Function Update Magnitude: 0.03538

Collected Steps per Second: 21,043.17145
Overall Steps per Second: 14,302.62138

Timestep Collection Time: 2.37673
Timestep Consumption Time: 1.12011
PPO Batch Consumption Time: 0.12097
Total Iteration Time: 3.49684

Cumulative Model Updates: 779
Cumulative Timesteps: 13,053,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02950
Policy Entropy: 4.45776
Value Function Loss: 0.02345

Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06518
Value Function Update Magnitude: 0.03239

Collected Steps per Second: 24,421.35189
Overall Steps per Second: 16,584.81228

Timestep Collection Time: 2.04747
Timestep Consumption Time: 0.96746
PPO Batch Consumption Time: 0.09214
Total Iteration Time: 3.01493

Cumulative Model Updates: 782
Cumulative Timesteps: 13,103,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 13103922...
Checkpoint 13103922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03921
Policy Entropy: 4.45709
Value Function Loss: 0.01781

Mean KL Divergence: 0.00018
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05755
Value Function Update Magnitude: 0.03032

Collected Steps per Second: 24,031.33358
Overall Steps per Second: 15,556.22221

Timestep Collection Time: 2.08078
Timestep Consumption Time: 1.13362
PPO Batch Consumption Time: 0.10365
Total Iteration Time: 3.21441

Cumulative Model Updates: 785
Cumulative Timesteps: 13,153,926

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03050
Policy Entropy: 4.45578
Value Function Loss: 0.03533

Mean KL Divergence: 0.00018
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05813
Value Function Update Magnitude: 0.02910

Collected Steps per Second: 20,256.10523
Overall Steps per Second: 14,914.33830

Timestep Collection Time: 2.46839
Timestep Consumption Time: 0.88409
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 3.35248

Cumulative Model Updates: 788
Cumulative Timesteps: 13,203,926

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 13203926...
Checkpoint 13203926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04708
Policy Entropy: 4.45449
Value Function Loss: 0.04188

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06838
Value Function Update Magnitude: 0.03203

Collected Steps per Second: 22,787.40709
Overall Steps per Second: 15,678.55643

Timestep Collection Time: 2.19516
Timestep Consumption Time: 0.99531
PPO Batch Consumption Time: 0.08466
Total Iteration Time: 3.19047

Cumulative Model Updates: 791
Cumulative Timesteps: 13,253,948

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01218
Policy Entropy: 4.45225
Value Function Loss: 0.04772

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07583
Value Function Update Magnitude: 0.03615

Collected Steps per Second: 24,835.25711
Overall Steps per Second: 16,933.40966

Timestep Collection Time: 2.01496
Timestep Consumption Time: 0.94026
PPO Batch Consumption Time: 0.06271
Total Iteration Time: 2.95522

Cumulative Model Updates: 794
Cumulative Timesteps: 13,303,990

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 13303990...
Checkpoint 13303990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01673
Policy Entropy: 4.44952
Value Function Loss: 0.04230

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07086
Value Function Update Magnitude: 0.03298

Collected Steps per Second: 21,906.83759
Overall Steps per Second: 15,555.88073

Timestep Collection Time: 2.28276
Timestep Consumption Time: 0.93198
PPO Batch Consumption Time: 0.08470
Total Iteration Time: 3.21473

Cumulative Model Updates: 797
Cumulative Timesteps: 13,353,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02254
Policy Entropy: 4.44774
Value Function Loss: 0.04786

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07357
Value Function Update Magnitude: 0.03795

Collected Steps per Second: 24,637.46991
Overall Steps per Second: 16,941.74140

Timestep Collection Time: 2.03073
Timestep Consumption Time: 0.92245
PPO Batch Consumption Time: 0.06187
Total Iteration Time: 2.95318

Cumulative Model Updates: 800
Cumulative Timesteps: 13,404,030

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 13404030...
Checkpoint 13404030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02737
Policy Entropy: 4.44671
Value Function Loss: 0.05486

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07664
Value Function Update Magnitude: 0.05208

Collected Steps per Second: 24,665.71984
Overall Steps per Second: 16,552.03098

Timestep Collection Time: 2.02832
Timestep Consumption Time: 0.99427
PPO Batch Consumption Time: 0.08987
Total Iteration Time: 3.02259

Cumulative Model Updates: 803
Cumulative Timesteps: 13,454,060

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05448
Policy Entropy: 4.44649
Value Function Loss: 0.04103

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07836
Value Function Update Magnitude: 0.04864

Collected Steps per Second: 25,660.92976
Overall Steps per Second: 17,485.84811

Timestep Collection Time: 1.94934
Timestep Consumption Time: 0.91137
PPO Batch Consumption Time: 0.06106
Total Iteration Time: 2.86071

Cumulative Model Updates: 806
Cumulative Timesteps: 13,504,082

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 13504082...
Checkpoint 13504082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02888
Policy Entropy: 4.44709
Value Function Loss: 0.03412

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07330
Value Function Update Magnitude: 0.04162

Collected Steps per Second: 21,643.54824
Overall Steps per Second: 15,076.31226

Timestep Collection Time: 2.31080
Timestep Consumption Time: 1.00659
PPO Batch Consumption Time: 0.08091
Total Iteration Time: 3.31739

Cumulative Model Updates: 809
Cumulative Timesteps: 13,554,096

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01548
Policy Entropy: 4.44857
Value Function Loss: 0.04060

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06820
Value Function Update Magnitude: 0.03773

Collected Steps per Second: 24,416.72380
Overall Steps per Second: 16,726.10125

Timestep Collection Time: 2.04868
Timestep Consumption Time: 0.94198
PPO Batch Consumption Time: 0.09125
Total Iteration Time: 2.99066

Cumulative Model Updates: 812
Cumulative Timesteps: 13,604,118

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 13604118...
Checkpoint 13604118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06888
Policy Entropy: 4.45156
Value Function Loss: 0.05580

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07471
Value Function Update Magnitude: 0.03766

Collected Steps per Second: 24,626.88254
Overall Steps per Second: 15,853.51039

Timestep Collection Time: 2.03071
Timestep Consumption Time: 1.12380
PPO Batch Consumption Time: 0.12626
Total Iteration Time: 3.15451

Cumulative Model Updates: 815
Cumulative Timesteps: 13,654,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01042
Policy Entropy: 4.45651
Value Function Loss: 0.06754

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00016
Policy Update Magnitude: 0.08811
Value Function Update Magnitude: 0.03984

Collected Steps per Second: 24,968.08735
Overall Steps per Second: 17,368.16202

Timestep Collection Time: 2.00344
Timestep Consumption Time: 0.87666
PPO Batch Consumption Time: 0.05812
Total Iteration Time: 2.88010

Cumulative Model Updates: 818
Cumulative Timesteps: 13,704,150

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 13704150...
Checkpoint 13704150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04816
Policy Entropy: 4.46198
Value Function Loss: 0.04756

Mean KL Divergence: 0.00076
SB3 Clip Fraction: 0.00075
Policy Update Magnitude: 0.08564
Value Function Update Magnitude: 0.03823

Collected Steps per Second: 21,421.10579
Overall Steps per Second: 15,092.44363

Timestep Collection Time: 2.33508
Timestep Consumption Time: 0.97916
PPO Batch Consumption Time: 0.10200
Total Iteration Time: 3.31424

Cumulative Model Updates: 821
Cumulative Timesteps: 13,754,170

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03227
Policy Entropy: 4.46753
Value Function Loss: 0.04109

Mean KL Divergence: 0.00085
SB3 Clip Fraction: 0.00104
Policy Update Magnitude: 0.07925
Value Function Update Magnitude: 0.04479

Collected Steps per Second: 24,797.45547
Overall Steps per Second: 16,888.97640

Timestep Collection Time: 2.01722
Timestep Consumption Time: 0.94459
PPO Batch Consumption Time: 0.06262
Total Iteration Time: 2.96181

Cumulative Model Updates: 824
Cumulative Timesteps: 13,804,192

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 13804192...
Checkpoint 13804192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02672
Policy Entropy: 4.47156
Value Function Loss: 0.03463

Mean KL Divergence: 0.00066
SB3 Clip Fraction: 0.00008
Policy Update Magnitude: 0.06737
Value Function Update Magnitude: 0.04575

Collected Steps per Second: 24,597.32212
Overall Steps per Second: 16,612.03548

Timestep Collection Time: 2.03355
Timestep Consumption Time: 0.97752
PPO Batch Consumption Time: 0.10542
Total Iteration Time: 3.01107

Cumulative Model Updates: 827
Cumulative Timesteps: 13,854,212

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00575
Policy Entropy: 4.47323
Value Function Loss: 0.03308

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05948
Value Function Update Magnitude: 0.03692

Collected Steps per Second: 25,030.03128
Overall Steps per Second: 17,088.58022

Timestep Collection Time: 1.99800
Timestep Consumption Time: 0.92852
PPO Batch Consumption Time: 0.06313
Total Iteration Time: 2.92652

Cumulative Model Updates: 830
Cumulative Timesteps: 13,904,222

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 13904222...
Checkpoint 13904222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03496
Policy Entropy: 4.47259
Value Function Loss: 0.03175

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05670
Value Function Update Magnitude: 0.03449

Collected Steps per Second: 24,715.59424
Overall Steps per Second: 16,413.28556

Timestep Collection Time: 2.02350
Timestep Consumption Time: 1.02354
PPO Batch Consumption Time: 0.10158
Total Iteration Time: 3.04704

Cumulative Model Updates: 833
Cumulative Timesteps: 13,954,234

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00081
Policy Entropy: 4.47062
Value Function Loss: 0.03762

Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05800
Value Function Update Magnitude: 0.03095

Collected Steps per Second: 24,577.19731
Overall Steps per Second: 17,494.88855

Timestep Collection Time: 2.03473
Timestep Consumption Time: 0.82370
PPO Batch Consumption Time: 0.06186
Total Iteration Time: 2.85843

Cumulative Model Updates: 836
Cumulative Timesteps: 14,004,242

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 14004242...
Checkpoint 14004242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03320
Policy Entropy: 4.46838
Value Function Loss: 0.05593

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06003
Value Function Update Magnitude: 0.03579

Collected Steps per Second: 21,572.32592
Overall Steps per Second: 15,038.49532

Timestep Collection Time: 2.31797
Timestep Consumption Time: 1.00710
PPO Batch Consumption Time: 0.08453
Total Iteration Time: 3.32507

Cumulative Model Updates: 839
Cumulative Timesteps: 14,054,246

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05100
Policy Entropy: 4.46698
Value Function Loss: 0.05496

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06620
Value Function Update Magnitude: 0.04768

Collected Steps per Second: 24,306.20296
Overall Steps per Second: 15,810.25969

Timestep Collection Time: 2.05791
Timestep Consumption Time: 1.10586
PPO Batch Consumption Time: 0.12570
Total Iteration Time: 3.16377

Cumulative Model Updates: 842
Cumulative Timesteps: 14,104,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 14104266...
Checkpoint 14104266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00431
Policy Entropy: 4.46590
Value Function Loss: 0.04379

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07236
Value Function Update Magnitude: 0.04400

Collected Steps per Second: 25,988.33055
Overall Steps per Second: 17,522.30416

Timestep Collection Time: 1.92509
Timestep Consumption Time: 0.93012
PPO Batch Consumption Time: 0.05851
Total Iteration Time: 2.85522

Cumulative Model Updates: 845
Cumulative Timesteps: 14,154,296

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10440
Policy Entropy: 4.46369
Value Function Loss: 0.03106

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07079
Value Function Update Magnitude: 0.03796

Collected Steps per Second: 22,014.21482
Overall Steps per Second: 14,951.21750

Timestep Collection Time: 2.27171
Timestep Consumption Time: 1.07316
PPO Batch Consumption Time: 0.10262
Total Iteration Time: 3.34488

Cumulative Model Updates: 848
Cumulative Timesteps: 14,204,306

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 14204306...
Checkpoint 14204306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01710
Policy Entropy: 4.46009
Value Function Loss: 0.03188

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06586
Value Function Update Magnitude: 0.04202

Collected Steps per Second: 24,534.22119
Overall Steps per Second: 17,206.92114

Timestep Collection Time: 2.03830
Timestep Consumption Time: 0.86798
PPO Batch Consumption Time: 0.06291
Total Iteration Time: 2.90627

Cumulative Model Updates: 851
Cumulative Timesteps: 14,254,314

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04699
Policy Entropy: 4.45597
Value Function Loss: 0.04062

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06367
Value Function Update Magnitude: 0.03846

Collected Steps per Second: 24,846.90288
Overall Steps per Second: 16,301.86371

Timestep Collection Time: 2.01273
Timestep Consumption Time: 1.05502
PPO Batch Consumption Time: 0.10397
Total Iteration Time: 3.06775

Cumulative Model Updates: 854
Cumulative Timesteps: 14,304,324

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 14304324...
Checkpoint 14304324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04999
Policy Entropy: 4.45296
Value Function Loss: 0.04256

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06289
Value Function Update Magnitude: 0.03761

Collected Steps per Second: 24,425.30525
Overall Steps per Second: 16,870.41264

Timestep Collection Time: 2.04763
Timestep Consumption Time: 0.91697
PPO Batch Consumption Time: 0.06019
Total Iteration Time: 2.96460

Cumulative Model Updates: 857
Cumulative Timesteps: 14,354,338

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03575
Policy Entropy: 4.45239
Value Function Loss: 0.05854

Mean KL Divergence: 0.00018
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06418
Value Function Update Magnitude: 0.04775

Collected Steps per Second: 22,556.88418
Overall Steps per Second: 15,523.67744

Timestep Collection Time: 2.21662
Timestep Consumption Time: 1.00427
PPO Batch Consumption Time: 0.08277
Total Iteration Time: 3.22089

Cumulative Model Updates: 860
Cumulative Timesteps: 14,404,338

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 14404338...
Checkpoint 14404338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02263
Policy Entropy: 4.45279
Value Function Loss: 0.05846

Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06586
Value Function Update Magnitude: 0.05477

Collected Steps per Second: 24,584.01576
Overall Steps per Second: 15,850.77335

Timestep Collection Time: 2.03392
Timestep Consumption Time: 1.12062
PPO Batch Consumption Time: 0.12657
Total Iteration Time: 3.15455

Cumulative Model Updates: 863
Cumulative Timesteps: 14,454,340

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02380
Policy Entropy: 4.45158
Value Function Loss: 0.05203

Mean KL Divergence: 0.00018
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06761
Value Function Update Magnitude: 0.04847

Collected Steps per Second: 25,017.40461
Overall Steps per Second: 17,544.57436

Timestep Collection Time: 1.99861
Timestep Consumption Time: 0.85128
PPO Batch Consumption Time: 0.05812
Total Iteration Time: 2.84988

Cumulative Model Updates: 866
Cumulative Timesteps: 14,504,340

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 14504340...
Checkpoint 14504340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00873
Policy Entropy: 4.44902
Value Function Loss: 0.03732

Mean KL Divergence: 0.00023
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06804
Value Function Update Magnitude: 0.05407

Collected Steps per Second: 21,969.26859
Overall Steps per Second: 14,953.86052

Timestep Collection Time: 2.27654
Timestep Consumption Time: 1.06801
PPO Batch Consumption Time: 0.10247
Total Iteration Time: 3.34455

Cumulative Model Updates: 869
Cumulative Timesteps: 14,554,354

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01709
Policy Entropy: 4.44578
Value Function Loss: 0.02787

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06628
Value Function Update Magnitude: 0.07280

Collected Steps per Second: 24,651.17547
Overall Steps per Second: 17,104.55656

Timestep Collection Time: 2.02895
Timestep Consumption Time: 0.89518
PPO Batch Consumption Time: 0.06347
Total Iteration Time: 2.92413

Cumulative Model Updates: 872
Cumulative Timesteps: 14,604,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 14604370...
Checkpoint 14604370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03559
Policy Entropy: 4.44423
Value Function Loss: 0.03649

Mean KL Divergence: 0.00026
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06278
Value Function Update Magnitude: 0.06719

Collected Steps per Second: 25,506.86920
Overall Steps per Second: 16,201.11411

Timestep Collection Time: 1.96057
Timestep Consumption Time: 1.12613
PPO Batch Consumption Time: 0.12794
Total Iteration Time: 3.08670

Cumulative Model Updates: 875
Cumulative Timesteps: 14,654,378

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01963
Policy Entropy: 4.44222
Value Function Loss: 0.02793

Mean KL Divergence: 0.00024
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06653
Value Function Update Magnitude: 0.05093

Collected Steps per Second: 23,965.77413
Overall Steps per Second: 16,512.94439

Timestep Collection Time: 2.08731
Timestep Consumption Time: 0.94207
PPO Batch Consumption Time: 0.06451
Total Iteration Time: 3.02938

Cumulative Model Updates: 878
Cumulative Timesteps: 14,704,402

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 14704402...
Checkpoint 14704402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03694
Policy Entropy: 4.43909
Value Function Loss: 0.02963

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07157
Value Function Update Magnitude: 0.04178

Collected Steps per Second: 21,490.79743
Overall Steps per Second: 14,989.21495

Timestep Collection Time: 2.32741
Timestep Consumption Time: 1.00952
PPO Batch Consumption Time: 0.11179
Total Iteration Time: 3.33693

Cumulative Model Updates: 881
Cumulative Timesteps: 14,754,420

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00418
Policy Entropy: 4.43499
Value Function Loss: 0.03109

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07079
Value Function Update Magnitude: 0.03353

Collected Steps per Second: 24,587.91014
Overall Steps per Second: 16,889.94952

Timestep Collection Time: 2.03409
Timestep Consumption Time: 0.92708
PPO Batch Consumption Time: 0.05800
Total Iteration Time: 2.96117

Cumulative Model Updates: 884
Cumulative Timesteps: 14,804,434

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 14804434...
Checkpoint 14804434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06332
Policy Entropy: 4.43219
Value Function Loss: 0.03741

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07008
Value Function Update Magnitude: 0.03202

Collected Steps per Second: 21,602.41136
Overall Steps per Second: 14,795.33777

Timestep Collection Time: 2.31520
Timestep Consumption Time: 1.06518
PPO Batch Consumption Time: 0.11055
Total Iteration Time: 3.38039

Cumulative Model Updates: 887
Cumulative Timesteps: 14,854,448

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00385
Policy Entropy: 4.43079
Value Function Loss: 0.03521

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07192
Value Function Update Magnitude: 0.03406

Collected Steps per Second: 25,688.63024
Overall Steps per Second: 16,684.82533

Timestep Collection Time: 1.94740
Timestep Consumption Time: 1.05089
PPO Batch Consumption Time: 0.09944
Total Iteration Time: 2.99829

Cumulative Model Updates: 890
Cumulative Timesteps: 14,904,474

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 14904474...
Checkpoint 14904474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02513
Policy Entropy: 4.43250
Value Function Loss: 0.02980

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07162
Value Function Update Magnitude: 0.04045

Collected Steps per Second: 24,690.56087
Overall Steps per Second: 15,811.42823

Timestep Collection Time: 2.02571
Timestep Consumption Time: 1.13757
PPO Batch Consumption Time: 0.12798
Total Iteration Time: 3.16328

Cumulative Model Updates: 893
Cumulative Timesteps: 14,954,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02528
Policy Entropy: 4.43584
Value Function Loss: 0.02940

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06537
Value Function Update Magnitude: 0.04394

Collected Steps per Second: 24,961.32850
Overall Steps per Second: 17,703.89249

Timestep Collection Time: 2.00406
Timestep Consumption Time: 0.82153
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 2.82559

Cumulative Model Updates: 896
Cumulative Timesteps: 15,004,514

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 15004514...
Checkpoint 15004514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00942
Policy Entropy: 4.43855
Value Function Loss: 0.06080

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06621
Value Function Update Magnitude: 0.04654

Collected Steps per Second: 21,558.56007
Overall Steps per Second: 14,843.21828

Timestep Collection Time: 2.31945
Timestep Consumption Time: 1.04936
PPO Batch Consumption Time: 0.10141
Total Iteration Time: 3.36881

Cumulative Model Updates: 899
Cumulative Timesteps: 15,054,518

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02558
Policy Entropy: 4.44155
Value Function Loss: 0.07065

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07407
Value Function Update Magnitude: 0.06040

Collected Steps per Second: 25,031.54723
Overall Steps per Second: 17,149.89383

Timestep Collection Time: 1.99772
Timestep Consumption Time: 0.91810
PPO Batch Consumption Time: 0.06461
Total Iteration Time: 2.91582

Cumulative Model Updates: 902
Cumulative Timesteps: 15,104,524

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 15104524...
Checkpoint 15104524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05436
Policy Entropy: 4.44526
Value Function Loss: 0.08434

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08186
Value Function Update Magnitude: 0.06450

Collected Steps per Second: 24,549.52283
Overall Steps per Second: 16,423.98772

Timestep Collection Time: 2.03686
Timestep Consumption Time: 1.00771
PPO Batch Consumption Time: 0.11078
Total Iteration Time: 3.04457

Cumulative Model Updates: 905
Cumulative Timesteps: 15,154,528

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02282
Policy Entropy: 4.44834
Value Function Loss: 0.06982

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08399
Value Function Update Magnitude: 0.06065

Collected Steps per Second: 25,233.05813
Overall Steps per Second: 17,133.94422

Timestep Collection Time: 1.98184
Timestep Consumption Time: 0.93681
PPO Batch Consumption Time: 0.06337
Total Iteration Time: 2.91865

Cumulative Model Updates: 908
Cumulative Timesteps: 15,204,536

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 15204536...
Checkpoint 15204536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00323
Policy Entropy: 4.45058
Value Function Loss: 0.04951

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08097
Value Function Update Magnitude: 0.05408

Collected Steps per Second: 24,434.09486
Overall Steps per Second: 16,292.13002

Timestep Collection Time: 2.04657
Timestep Consumption Time: 1.02277
PPO Batch Consumption Time: 0.10122
Total Iteration Time: 3.06933

Cumulative Model Updates: 911
Cumulative Timesteps: 15,254,542

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01277
Policy Entropy: 4.45367
Value Function Loss: 0.04773

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08106
Value Function Update Magnitude: 0.05746

Collected Steps per Second: 25,590.69440
Overall Steps per Second: 17,252.89831

Timestep Collection Time: 1.95454
Timestep Consumption Time: 0.94457
PPO Batch Consumption Time: 0.06296
Total Iteration Time: 2.89911

Cumulative Model Updates: 914
Cumulative Timesteps: 15,304,560

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 15304560...
Checkpoint 15304560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00523
Policy Entropy: 4.45739
Value Function Loss: 0.03293

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07554
Value Function Update Magnitude: 0.06427

Collected Steps per Second: 24,915.86376
Overall Steps per Second: 16,289.44476

Timestep Collection Time: 2.00764
Timestep Consumption Time: 1.06319
PPO Batch Consumption Time: 0.10530
Total Iteration Time: 3.07082

Cumulative Model Updates: 917
Cumulative Timesteps: 15,354,582

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04157
Policy Entropy: 4.46086
Value Function Loss: 0.03726

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07405
Value Function Update Magnitude: 0.06187

Collected Steps per Second: 24,495.91358
Overall Steps per Second: 17,325.67559

Timestep Collection Time: 2.04173
Timestep Consumption Time: 0.84497
PPO Batch Consumption Time: 0.06261
Total Iteration Time: 2.88670

Cumulative Model Updates: 920
Cumulative Timesteps: 15,404,596

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 15404596...
Checkpoint 15404596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01121
Policy Entropy: 4.46396
Value Function Loss: 0.04530

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06659
Value Function Update Magnitude: 0.04315

Collected Steps per Second: 21,981.84801
Overall Steps per Second: 15,174.33281

Timestep Collection Time: 2.27533
Timestep Consumption Time: 1.02076
PPO Batch Consumption Time: 0.09014
Total Iteration Time: 3.29609

Cumulative Model Updates: 923
Cumulative Timesteps: 15,454,612

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00446
Policy Entropy: 4.46611
Value Function Loss: 0.04321

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06530
Value Function Update Magnitude: 0.04281

Collected Steps per Second: 24,579.12511
Overall Steps per Second: 16,680.46090

Timestep Collection Time: 2.03514
Timestep Consumption Time: 0.96370
PPO Batch Consumption Time: 0.07757
Total Iteration Time: 2.99884

Cumulative Model Updates: 926
Cumulative Timesteps: 15,504,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 15504634...
Checkpoint 15504634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09717
Policy Entropy: 4.46742
Value Function Loss: 0.04892

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06836
Value Function Update Magnitude: 0.05026

Collected Steps per Second: 25,462.89143
Overall Steps per Second: 16,799.48033

Timestep Collection Time: 1.96419
Timestep Consumption Time: 1.01292
PPO Batch Consumption Time: 0.08415
Total Iteration Time: 2.97712

Cumulative Model Updates: 929
Cumulative Timesteps: 15,554,648

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01326
Policy Entropy: 4.46857
Value Function Loss: 0.03074

Mean KL Divergence: 0.00019
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06522
Value Function Update Magnitude: 0.04368

Collected Steps per Second: 24,711.95370
Overall Steps per Second: 16,521.19010

Timestep Collection Time: 2.02380
Timestep Consumption Time: 1.00334
PPO Batch Consumption Time: 0.08086
Total Iteration Time: 3.02714

Cumulative Model Updates: 932
Cumulative Timesteps: 15,604,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 15604660...
Checkpoint 15604660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03026
Policy Entropy: 4.46974
Value Function Loss: 0.02851

Mean KL Divergence: 0.00017
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.04551

Collected Steps per Second: 22,717.82730
Overall Steps per Second: 15,913.10988

Timestep Collection Time: 2.20188
Timestep Consumption Time: 0.94156
PPO Batch Consumption Time: 0.09347
Total Iteration Time: 3.14345

Cumulative Model Updates: 935
Cumulative Timesteps: 15,654,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03391
Policy Entropy: 4.47085
Value Function Loss: 0.02223

Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05857
Value Function Update Magnitude: 0.05362

Collected Steps per Second: 24,876.30099
Overall Steps per Second: 16,976.37021

Timestep Collection Time: 2.01099
Timestep Consumption Time: 0.93581
PPO Batch Consumption Time: 0.06514
Total Iteration Time: 2.94680

Cumulative Model Updates: 938
Cumulative Timesteps: 15,704,708

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 15704708...
Checkpoint 15704708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01998
Policy Entropy: 4.47122
Value Function Loss: 0.01524

Mean KL Divergence: 0.00013
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05310
Value Function Update Magnitude: 0.05383

Collected Steps per Second: 24,647.89895
Overall Steps per Second: 17,087.94323

Timestep Collection Time: 2.02938
Timestep Consumption Time: 0.89783
PPO Batch Consumption Time: 0.06303
Total Iteration Time: 2.92721

Cumulative Model Updates: 941
Cumulative Timesteps: 15,754,728

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00868
Policy Entropy: 4.47188
Value Function Loss: 0.02502

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.03877

Collected Steps per Second: 22,458.31695
Overall Steps per Second: 15,198.43002

Timestep Collection Time: 2.22733
Timestep Consumption Time: 1.06393
PPO Batch Consumption Time: 0.10120
Total Iteration Time: 3.29126

Cumulative Model Updates: 944
Cumulative Timesteps: 15,804,750

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 15804750...
Checkpoint 15804750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03073
Policy Entropy: 4.47338
Value Function Loss: 0.02790

Mean KL Divergence: 0.00009
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.02988

Collected Steps per Second: 24,952.40676
Overall Steps per Second: 17,069.92438

Timestep Collection Time: 2.00470
Timestep Consumption Time: 0.92572
PPO Batch Consumption Time: 0.06532
Total Iteration Time: 2.93042

Cumulative Model Updates: 947
Cumulative Timesteps: 15,854,772

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02987
Policy Entropy: 4.47579
Value Function Loss: 0.03480

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06437
Value Function Update Magnitude: 0.02919

Collected Steps per Second: 24,576.60772
Overall Steps per Second: 16,503.96726

Timestep Collection Time: 2.03445
Timestep Consumption Time: 0.99512
PPO Batch Consumption Time: 0.11175
Total Iteration Time: 3.02957

Cumulative Model Updates: 950
Cumulative Timesteps: 15,904,772

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 15904772...
Checkpoint 15904772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00515
Policy Entropy: 4.47819
Value Function Loss: 0.05016

Mean KL Divergence: 0.00024
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06636
Value Function Update Magnitude: 0.03264

Collected Steps per Second: 24,895.03257
Overall Steps per Second: 17,042.79440

Timestep Collection Time: 2.00908
Timestep Consumption Time: 0.92565
PPO Batch Consumption Time: 0.06484
Total Iteration Time: 2.93473

Cumulative Model Updates: 953
Cumulative Timesteps: 15,954,788

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01035
Policy Entropy: 4.47942
Value Function Loss: 0.06046

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06887
Value Function Update Magnitude: 0.04202

Collected Steps per Second: 24,759.38740
Overall Steps per Second: 16,428.53275

Timestep Collection Time: 2.02041
Timestep Consumption Time: 1.02454
PPO Batch Consumption Time: 0.10849
Total Iteration Time: 3.04495

Cumulative Model Updates: 956
Cumulative Timesteps: 16,004,812

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 16004812...
Checkpoint 16004812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00648
Policy Entropy: 4.48059
Value Function Loss: 0.07269

Mean KL Divergence: 0.00019
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07296
Value Function Update Magnitude: 0.05890

Collected Steps per Second: 25,374.85489
Overall Steps per Second: 17,245.59506

Timestep Collection Time: 1.97124
Timestep Consumption Time: 0.92921
PPO Batch Consumption Time: 0.06296
Total Iteration Time: 2.90045

Cumulative Model Updates: 959
Cumulative Timesteps: 16,054,832

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14475
Policy Entropy: 4.48218
Value Function Loss: 0.05634

Mean KL Divergence: 0.00019
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07589
Value Function Update Magnitude: 0.05467

Collected Steps per Second: 22,226.46001
Overall Steps per Second: 15,186.16439

Timestep Collection Time: 2.25065
Timestep Consumption Time: 1.04340
PPO Batch Consumption Time: 0.09549
Total Iteration Time: 3.29405

Cumulative Model Updates: 962
Cumulative Timesteps: 16,104,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 16104856...
Checkpoint 16104856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03888
Policy Entropy: 4.48416
Value Function Loss: 0.04761

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07486
Value Function Update Magnitude: 0.04890

Collected Steps per Second: 24,454.17427
Overall Steps per Second: 16,772.06456

Timestep Collection Time: 2.04464
Timestep Consumption Time: 0.93651
PPO Batch Consumption Time: 0.09089
Total Iteration Time: 2.98115

Cumulative Model Updates: 965
Cumulative Timesteps: 16,154,856

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00160
Policy Entropy: 4.48565
Value Function Loss: 0.03603

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06838
Value Function Update Magnitude: 0.04914

Collected Steps per Second: 24,730.53700
Overall Steps per Second: 16,680.43867

Timestep Collection Time: 2.02301
Timestep Consumption Time: 0.97632
PPO Batch Consumption Time: 0.07124
Total Iteration Time: 2.99932

Cumulative Model Updates: 968
Cumulative Timesteps: 16,204,886

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 16204886...
Checkpoint 16204886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01509
Policy Entropy: 4.48638
Value Function Loss: 0.04024

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06280
Value Function Update Magnitude: 0.04340

Collected Steps per Second: 21,571.14064
Overall Steps per Second: 14,865.16377

Timestep Collection Time: 2.31828
Timestep Consumption Time: 1.04582
PPO Batch Consumption Time: 0.10832
Total Iteration Time: 3.36411

Cumulative Model Updates: 971
Cumulative Timesteps: 16,254,894

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03769
Policy Entropy: 4.48658
Value Function Loss: 0.04421

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06064
Value Function Update Magnitude: 0.04174

Collected Steps per Second: 24,777.00841
Overall Steps per Second: 17,390.62461

Timestep Collection Time: 2.01848
Timestep Consumption Time: 0.85732
PPO Batch Consumption Time: 0.06387
Total Iteration Time: 2.87580

Cumulative Model Updates: 974
Cumulative Timesteps: 16,304,906

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 16304906...
Checkpoint 16304906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01278
Policy Entropy: 4.48600
Value Function Loss: 0.05114

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06451
Value Function Update Magnitude: 0.04388

Collected Steps per Second: 22,063.26794
Overall Steps per Second: 15,102.15677

Timestep Collection Time: 2.26739
Timestep Consumption Time: 1.04512
PPO Batch Consumption Time: 0.09588
Total Iteration Time: 3.31251

Cumulative Model Updates: 977
Cumulative Timesteps: 16,354,932

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04897
Policy Entropy: 4.48524
Value Function Loss: 0.06231

Mean KL Divergence: 0.00007
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06482
Value Function Update Magnitude: 0.04996

Collected Steps per Second: 24,556.83514
Overall Steps per Second: 16,740.18498

Timestep Collection Time: 2.03797
Timestep Consumption Time: 0.95161
PPO Batch Consumption Time: 0.09506
Total Iteration Time: 2.98957

Cumulative Model Updates: 980
Cumulative Timesteps: 16,404,978

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 16404978...
Checkpoint 16404978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00679
Policy Entropy: 4.48459
Value Function Loss: 0.04989

Mean KL Divergence: 0.00007
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06896
Value Function Update Magnitude: 0.04879

Collected Steps per Second: 24,844.39717
Overall Steps per Second: 16,726.94896

Timestep Collection Time: 2.01325
Timestep Consumption Time: 0.97701
PPO Batch Consumption Time: 0.07939
Total Iteration Time: 2.99026

Cumulative Model Updates: 983
Cumulative Timesteps: 16,454,996

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00034
Policy Entropy: 4.48415
Value Function Loss: 0.04526

Mean KL Divergence: 0.00007
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07078
Value Function Update Magnitude: 0.05237

Collected Steps per Second: 24,665.60900
Overall Steps per Second: 16,699.27309

Timestep Collection Time: 2.02736
Timestep Consumption Time: 0.96714
PPO Batch Consumption Time: 0.07651
Total Iteration Time: 2.99450

Cumulative Model Updates: 986
Cumulative Timesteps: 16,505,002

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 16505002...
Checkpoint 16505002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02547
Policy Entropy: 4.48435
Value Function Loss: 0.03714

Mean KL Divergence: 0.00007
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06542
Value Function Update Magnitude: 0.05362

Collected Steps per Second: 24,255.65089
Overall Steps per Second: 16,819.48440

Timestep Collection Time: 2.06195
Timestep Consumption Time: 0.91162
PPO Batch Consumption Time: 0.08418
Total Iteration Time: 2.97358

Cumulative Model Updates: 989
Cumulative Timesteps: 16,555,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00002
Policy Entropy: 4.48484
Value Function Loss: 0.05467

Mean KL Divergence: 0.00007
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06615
Value Function Update Magnitude: 0.04558

Collected Steps per Second: 24,489.17801
Overall Steps per Second: 15,804.73590

Timestep Collection Time: 2.04245
Timestep Consumption Time: 1.12229
PPO Batch Consumption Time: 0.12374
Total Iteration Time: 3.16475

Cumulative Model Updates: 992
Cumulative Timesteps: 16,605,034

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 16605034...
Checkpoint 16605034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01435
Policy Entropy: 4.48509
Value Function Loss: 0.05306

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07029
Value Function Update Magnitude: 0.05358

Collected Steps per Second: 24,898.44820
Overall Steps per Second: 17,517.95151

Timestep Collection Time: 2.00944
Timestep Consumption Time: 0.84660
PPO Batch Consumption Time: 0.05893
Total Iteration Time: 2.85604

Cumulative Model Updates: 995
Cumulative Timesteps: 16,655,066

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01333
Policy Entropy: 4.48449
Value Function Loss: 0.04821

Mean KL Divergence: 0.00005
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07666
Value Function Update Magnitude: 0.05853

Collected Steps per Second: 21,952.57864
Overall Steps per Second: 14,976.01341

Timestep Collection Time: 2.27837
Timestep Consumption Time: 1.06138
PPO Batch Consumption Time: 0.09964
Total Iteration Time: 3.33974

Cumulative Model Updates: 998
Cumulative Timesteps: 16,705,082

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 16705082...
Checkpoint 16705082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03653
Policy Entropy: 4.48285
Value Function Loss: 0.02876

Mean KL Divergence: 0.00011
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07933
Value Function Update Magnitude: 0.05658

Collected Steps per Second: 24,953.12244
Overall Steps per Second: 17,230.52511

Timestep Collection Time: 2.00384
Timestep Consumption Time: 0.89811
PPO Batch Consumption Time: 0.06178
Total Iteration Time: 2.90194

Cumulative Model Updates: 1,001
Cumulative Timesteps: 16,755,084

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03032
Policy Entropy: 4.48048
Value Function Loss: 0.02798

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07817
Value Function Update Magnitude: 0.05196

Collected Steps per Second: 24,726.30971
Overall Steps per Second: 16,367.22009

Timestep Collection Time: 2.02424
Timestep Consumption Time: 1.03382
PPO Batch Consumption Time: 0.12049
Total Iteration Time: 3.05806

Cumulative Model Updates: 1,004
Cumulative Timesteps: 16,805,136

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 16805136...
Checkpoint 16805136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04515
Policy Entropy: 4.47864
Value Function Loss: 0.02167

Mean KL Divergence: 0.00024
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06992
Value Function Update Magnitude: 0.04814

Collected Steps per Second: 24,703.62809
Overall Steps per Second: 16,851.29579

Timestep Collection Time: 2.02440
Timestep Consumption Time: 0.94333
PPO Batch Consumption Time: 0.06238
Total Iteration Time: 2.96772

Cumulative Model Updates: 1,007
Cumulative Timesteps: 16,855,146

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01975
Policy Entropy: 4.47729
Value Function Loss: 0.02328

Mean KL Divergence: 0.00020
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06986
Value Function Update Magnitude: 0.04770

Collected Steps per Second: 24,982.65690
Overall Steps per Second: 16,621.68559

Timestep Collection Time: 2.00267
Timestep Consumption Time: 1.00737
PPO Batch Consumption Time: 0.11039
Total Iteration Time: 3.01004

Cumulative Model Updates: 1,010
Cumulative Timesteps: 16,905,178

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 16905178...
Checkpoint 16905178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00817
Policy Entropy: 4.47592
Value Function Loss: 0.02905

Mean KL Divergence: 0.00018
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06685
Value Function Update Magnitude: 0.04362

Collected Steps per Second: 24,645.33580
Overall Steps per Second: 16,906.46397

Timestep Collection Time: 2.02902
Timestep Consumption Time: 0.92878
PPO Batch Consumption Time: 0.06360
Total Iteration Time: 2.95780

Cumulative Model Updates: 1,013
Cumulative Timesteps: 16,955,184

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02006
Policy Entropy: 4.47507
Value Function Loss: 0.03607

Mean KL Divergence: 0.00017
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06818
Value Function Update Magnitude: 0.03662

Collected Steps per Second: 24,635.24889
Overall Steps per Second: 16,482.17230

Timestep Collection Time: 2.02977
Timestep Consumption Time: 1.00405
PPO Batch Consumption Time: 0.09193
Total Iteration Time: 3.03382

Cumulative Model Updates: 1,016
Cumulative Timesteps: 17,005,188

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 17005188...
Checkpoint 17005188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00567
Policy Entropy: 4.47373
Value Function Loss: 0.06150

Mean KL Divergence: 0.00017
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07514
Value Function Update Magnitude: 0.04472

Collected Steps per Second: 24,687.55081
Overall Steps per Second: 17,338.63376

Timestep Collection Time: 2.02604
Timestep Consumption Time: 0.85873
PPO Batch Consumption Time: 0.06110
Total Iteration Time: 2.88477

Cumulative Model Updates: 1,019
Cumulative Timesteps: 17,055,206

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01102
Policy Entropy: 4.47177
Value Function Loss: 0.05594

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08131
Value Function Update Magnitude: 0.05554

Collected Steps per Second: 24,853.71096
Overall Steps per Second: 16,279.50718

Timestep Collection Time: 2.01290
Timestep Consumption Time: 1.06017
PPO Batch Consumption Time: 0.10964
Total Iteration Time: 3.07307

Cumulative Model Updates: 1,022
Cumulative Timesteps: 17,105,234

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 17105234...
Checkpoint 17105234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04420
Policy Entropy: 4.46936
Value Function Loss: 0.05020

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08374
Value Function Update Magnitude: 0.05091

Collected Steps per Second: 24,326.09674
Overall Steps per Second: 17,256.09762

Timestep Collection Time: 2.05598
Timestep Consumption Time: 0.84236
PPO Batch Consumption Time: 0.06203
Total Iteration Time: 2.89834

Cumulative Model Updates: 1,025
Cumulative Timesteps: 17,155,248

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00628
Policy Entropy: 4.46750
Value Function Loss: 0.04072

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08076
Value Function Update Magnitude: 0.04779

Collected Steps per Second: 21,658.51939
Overall Steps per Second: 15,143.07717

Timestep Collection Time: 2.30967
Timestep Consumption Time: 0.99376
PPO Batch Consumption Time: 0.07994
Total Iteration Time: 3.30342

Cumulative Model Updates: 1,028
Cumulative Timesteps: 17,205,272

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 17205272...
Checkpoint 17205272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04904
Policy Entropy: 4.46695
Value Function Loss: 0.06013

Mean KL Divergence: 0.00024
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07996
Value Function Update Magnitude: 0.04715

Collected Steps per Second: 24,744.01185
Overall Steps per Second: 16,777.18879

Timestep Collection Time: 2.02093
Timestep Consumption Time: 0.95966
PPO Batch Consumption Time: 0.08123
Total Iteration Time: 2.98059

Cumulative Model Updates: 1,031
Cumulative Timesteps: 17,255,278

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04697
Policy Entropy: 4.46538
Value Function Loss: 0.06481

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08789
Value Function Update Magnitude: 0.05389

Collected Steps per Second: 25,709.93306
Overall Steps per Second: 16,760.44423

Timestep Collection Time: 1.94508
Timestep Consumption Time: 1.03861
PPO Batch Consumption Time: 0.10580
Total Iteration Time: 2.98369

Cumulative Model Updates: 1,034
Cumulative Timesteps: 17,305,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 17305286...
Checkpoint 17305286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03331
Policy Entropy: 4.46312
Value Function Loss: 0.05913

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09740
Value Function Update Magnitude: 0.05575

Collected Steps per Second: 24,595.79004
Overall Steps per Second: 15,798.94085

Timestep Collection Time: 2.03384
Timestep Consumption Time: 1.13244
PPO Batch Consumption Time: 0.12614
Total Iteration Time: 3.16629

Cumulative Model Updates: 1,037
Cumulative Timesteps: 17,355,310

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00263
Policy Entropy: 4.45836
Value Function Loss: 0.03985

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09475
Value Function Update Magnitude: 0.06234

Collected Steps per Second: 25,049.89674
Overall Steps per Second: 17,759.18329

Timestep Collection Time: 1.99697
Timestep Consumption Time: 0.81982
PPO Batch Consumption Time: 0.05595
Total Iteration Time: 2.81680

Cumulative Model Updates: 1,040
Cumulative Timesteps: 17,405,334

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 17405334...
Checkpoint 17405334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04634
Policy Entropy: 4.45434
Value Function Loss: 0.05294

Mean KL Divergence: 0.00065
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08848
Value Function Update Magnitude: 0.07131

Collected Steps per Second: 21,930.18606
Overall Steps per Second: 14,836.04498

Timestep Collection Time: 2.28097
Timestep Consumption Time: 1.09069
PPO Batch Consumption Time: 0.10999
Total Iteration Time: 3.37165

Cumulative Model Updates: 1,043
Cumulative Timesteps: 17,455,356

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00296
Policy Entropy: 4.45308
Value Function Loss: 0.05372

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09114
Value Function Update Magnitude: 0.05957

Collected Steps per Second: 24,612.66957
Overall Steps per Second: 16,986.82670

Timestep Collection Time: 2.03221
Timestep Consumption Time: 0.91231
PPO Batch Consumption Time: 0.06489
Total Iteration Time: 2.94452

Cumulative Model Updates: 1,046
Cumulative Timesteps: 17,505,374

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 17505374...
Checkpoint 17505374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01976
Policy Entropy: 4.45778
Value Function Loss: 0.05901

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09971
Value Function Update Magnitude: 0.05311

Collected Steps per Second: 24,707.08681
Overall Steps per Second: 16,578.55793

Timestep Collection Time: 2.02444
Timestep Consumption Time: 0.99259
PPO Batch Consumption Time: 0.11132
Total Iteration Time: 3.01703

Cumulative Model Updates: 1,049
Cumulative Timesteps: 17,555,392

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03818
Policy Entropy: 4.46427
Value Function Loss: 0.04044

Mean KL Divergence: 0.00098
SB3 Clip Fraction: 0.00141
Policy Update Magnitude: 0.09655
Value Function Update Magnitude: 0.04902

Collected Steps per Second: 24,807.66744
Overall Steps per Second: 16,948.07483

Timestep Collection Time: 2.01672
Timestep Consumption Time: 0.93524
PPO Batch Consumption Time: 0.06448
Total Iteration Time: 2.95196

Cumulative Model Updates: 1,052
Cumulative Timesteps: 17,605,422

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 17605422...
Checkpoint 17605422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00023
Policy Entropy: 4.46945
Value Function Loss: 0.05490

Mean KL Divergence: 0.00102
SB3 Clip Fraction: 0.00193
Policy Update Magnitude: 0.08913
Value Function Update Magnitude: 0.04954

Collected Steps per Second: 24,503.66198
Overall Steps per Second: 16,551.98901

Timestep Collection Time: 2.04157
Timestep Consumption Time: 0.98078
PPO Batch Consumption Time: 0.10713
Total Iteration Time: 3.02236

Cumulative Model Updates: 1,055
Cumulative Timesteps: 17,655,448

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01150
Policy Entropy: 4.47220
Value Function Loss: 0.04611

Mean KL Divergence: 0.00065
SB3 Clip Fraction: 0.00034
Policy Update Magnitude: 0.08753
Value Function Update Magnitude: 0.05033

Collected Steps per Second: 24,752.14077
Overall Steps per Second: 16,976.33443

Timestep Collection Time: 2.02027
Timestep Consumption Time: 0.92536
PPO Batch Consumption Time: 0.06313
Total Iteration Time: 2.94563

Cumulative Model Updates: 1,058
Cumulative Timesteps: 17,705,454

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 17705454...
Checkpoint 17705454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01044
Policy Entropy: 4.47220
Value Function Loss: 0.05218

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08981
Value Function Update Magnitude: 0.04867

Collected Steps per Second: 22,481.26400
Overall Steps per Second: 15,416.15354

Timestep Collection Time: 2.22487
Timestep Consumption Time: 1.01964
PPO Batch Consumption Time: 0.09497
Total Iteration Time: 3.24452

Cumulative Model Updates: 1,061
Cumulative Timesteps: 17,755,472

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01804
Policy Entropy: 4.47018
Value Function Loss: 0.04373

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08736
Value Function Update Magnitude: 0.04877

Collected Steps per Second: 24,221.43837
Overall Steps per Second: 16,673.88059

Timestep Collection Time: 2.06453
Timestep Consumption Time: 0.93453
PPO Batch Consumption Time: 0.08503
Total Iteration Time: 2.99906

Cumulative Model Updates: 1,064
Cumulative Timesteps: 17,805,478

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 17805478...
Checkpoint 17805478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01152
Policy Entropy: 4.46716
Value Function Loss: 0.04361

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08694
Value Function Update Magnitude: 0.05241

Collected Steps per Second: 24,416.56496
Overall Steps per Second: 15,833.43279

Timestep Collection Time: 2.04779
Timestep Consumption Time: 1.11008
PPO Batch Consumption Time: 0.11914
Total Iteration Time: 3.15787

Cumulative Model Updates: 1,067
Cumulative Timesteps: 17,855,478

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03812
Policy Entropy: 4.46401
Value Function Loss: 0.05113

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08472
Value Function Update Magnitude: 0.05405

Collected Steps per Second: 24,481.77255
Overall Steps per Second: 16,841.77072

Timestep Collection Time: 2.04332
Timestep Consumption Time: 0.92692
PPO Batch Consumption Time: 0.06639
Total Iteration Time: 2.97023

Cumulative Model Updates: 1,070
Cumulative Timesteps: 17,905,502

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 17905502...
Checkpoint 17905502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00913
Policy Entropy: 4.46314
Value Function Loss: 0.04302

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08227
Value Function Update Magnitude: 0.05304

Collected Steps per Second: 24,809.87840
Overall Steps per Second: 16,533.85831

Timestep Collection Time: 2.01605
Timestep Consumption Time: 1.00913
PPO Batch Consumption Time: 0.08760
Total Iteration Time: 3.02519

Cumulative Model Updates: 1,073
Cumulative Timesteps: 17,955,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01923
Policy Entropy: 4.46487
Value Function Loss: 0.05683

Mean KL Divergence: 0.00026
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09048
Value Function Update Magnitude: 0.05609

Collected Steps per Second: 24,599.64479
Overall Steps per Second: 16,957.47232

Timestep Collection Time: 2.03361
Timestep Consumption Time: 0.91648
PPO Batch Consumption Time: 0.06232
Total Iteration Time: 2.95009

Cumulative Model Updates: 1,076
Cumulative Timesteps: 18,005,546

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 18005546...
Checkpoint 18005546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03852
Policy Entropy: 4.46641
Value Function Loss: 0.07181

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08778
Value Function Update Magnitude: 0.06286

Collected Steps per Second: 24,630.01917
Overall Steps per Second: 17,411.93159

Timestep Collection Time: 2.03094
Timestep Consumption Time: 0.84192
PPO Batch Consumption Time: 0.06160
Total Iteration Time: 2.87286

Cumulative Model Updates: 1,079
Cumulative Timesteps: 18,055,568

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01390
Policy Entropy: 4.46676
Value Function Loss: 0.08896

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09829
Value Function Update Magnitude: 0.07652

Collected Steps per Second: 21,153.57698
Overall Steps per Second: 14,757.05261

Timestep Collection Time: 2.36480
Timestep Consumption Time: 1.02504
PPO Batch Consumption Time: 0.08866
Total Iteration Time: 3.38984

Cumulative Model Updates: 1,082
Cumulative Timesteps: 18,105,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 18105592...
Checkpoint 18105592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01303
Policy Entropy: 4.46742
Value Function Loss: 0.08508

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10006
Value Function Update Magnitude: 0.07427

Collected Steps per Second: 24,735.30983
Overall Steps per Second: 16,955.49615

Timestep Collection Time: 2.02197
Timestep Consumption Time: 0.92775
PPO Batch Consumption Time: 0.07231
Total Iteration Time: 2.94972

Cumulative Model Updates: 1,085
Cumulative Timesteps: 18,155,606

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01242
Policy Entropy: 4.46939
Value Function Loss: 0.06580

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.09788
Value Function Update Magnitude: 0.07984

Collected Steps per Second: 25,751.54813
Overall Steps per Second: 16,787.71639

Timestep Collection Time: 1.94194
Timestep Consumption Time: 1.03690
PPO Batch Consumption Time: 0.10166
Total Iteration Time: 2.97884

Cumulative Model Updates: 1,088
Cumulative Timesteps: 18,205,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 18205614...
Checkpoint 18205614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03276
Policy Entropy: 4.47182
Value Function Loss: 0.06125

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.08931
Value Function Update Magnitude: 0.07403

Collected Steps per Second: 24,744.51082
Overall Steps per Second: 16,943.01293

Timestep Collection Time: 2.02105
Timestep Consumption Time: 0.93060
PPO Batch Consumption Time: 0.06247
Total Iteration Time: 2.95166

Cumulative Model Updates: 1,091
Cumulative Timesteps: 18,255,624

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02790
Policy Entropy: 4.47335
Value Function Loss: 0.07718

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08866
Value Function Update Magnitude: 0.07662

Collected Steps per Second: 24,714.84628
Overall Steps per Second: 16,520.92185

Timestep Collection Time: 2.02308
Timestep Consumption Time: 1.00339
PPO Batch Consumption Time: 0.09526
Total Iteration Time: 3.02647

Cumulative Model Updates: 1,094
Cumulative Timesteps: 18,305,624

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 18305624...
Checkpoint 18305624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03355
Policy Entropy: 4.47358
Value Function Loss: 0.08058

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09201
Value Function Update Magnitude: 0.07943

Collected Steps per Second: 25,726.00616
Overall Steps per Second: 17,415.13870

Timestep Collection Time: 1.94488
Timestep Consumption Time: 0.92814
PPO Batch Consumption Time: 0.06169
Total Iteration Time: 2.87302

Cumulative Model Updates: 1,097
Cumulative Timesteps: 18,355,658

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01227
Policy Entropy: 4.47282
Value Function Loss: 0.06286

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09322
Value Function Update Magnitude: 0.08526

Collected Steps per Second: 21,706.82231
Overall Steps per Second: 15,111.78551

Timestep Collection Time: 2.30545
Timestep Consumption Time: 1.00614
PPO Batch Consumption Time: 0.08898
Total Iteration Time: 3.31159

Cumulative Model Updates: 1,100
Cumulative Timesteps: 18,405,702

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 18405702...
Checkpoint 18405702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01154
Policy Entropy: 4.47106
Value Function Loss: 0.04027

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08659
Value Function Update Magnitude: 0.08859

Collected Steps per Second: 24,368.69559
Overall Steps per Second: 16,788.11559

Timestep Collection Time: 2.05222
Timestep Consumption Time: 0.92667
PPO Batch Consumption Time: 0.08516
Total Iteration Time: 2.97889

Cumulative Model Updates: 1,103
Cumulative Timesteps: 18,455,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01604
Policy Entropy: 4.46917
Value Function Loss: 0.02850

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07802
Value Function Update Magnitude: 0.08106

Collected Steps per Second: 24,709.07212
Overall Steps per Second: 16,660.01257

Timestep Collection Time: 2.02420
Timestep Consumption Time: 0.97796
PPO Batch Consumption Time: 0.07324
Total Iteration Time: 3.00216

Cumulative Model Updates: 1,106
Cumulative Timesteps: 18,505,728

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 18505728...
Checkpoint 18505728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00085
Policy Entropy: 4.46758
Value Function Loss: 0.03214

Mean KL Divergence: 0.00024
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07409
Value Function Update Magnitude: 0.06853

Collected Steps per Second: 24,514.53670
Overall Steps per Second: 15,877.07979

Timestep Collection Time: 2.04042
Timestep Consumption Time: 1.11003
PPO Batch Consumption Time: 0.12170
Total Iteration Time: 3.15045

Cumulative Model Updates: 1,109
Cumulative Timesteps: 18,555,748

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00797
Policy Entropy: 4.46598
Value Function Loss: 0.04746

Mean KL Divergence: 0.00020
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06990
Value Function Update Magnitude: 0.06130

Collected Steps per Second: 25,527.96153
Overall Steps per Second: 17,312.20444

Timestep Collection Time: 1.95879
Timestep Consumption Time: 0.92957
PPO Batch Consumption Time: 0.05996
Total Iteration Time: 2.88837

Cumulative Model Updates: 1,112
Cumulative Timesteps: 18,605,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 18605752...
Checkpoint 18605752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02143
Policy Entropy: 4.46518
Value Function Loss: 0.05062

Mean KL Divergence: 0.00014
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07223
Value Function Update Magnitude: 0.06562

Collected Steps per Second: 21,560.92364
Overall Steps per Second: 15,108.01387

Timestep Collection Time: 2.32022
Timestep Consumption Time: 0.99101
PPO Batch Consumption Time: 0.07857
Total Iteration Time: 3.31122

Cumulative Model Updates: 1,115
Cumulative Timesteps: 18,655,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02740
Policy Entropy: 4.46486
Value Function Loss: 0.05226

Mean KL Divergence: 0.00012
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07961
Value Function Update Magnitude: 0.07555

Collected Steps per Second: 24,125.89906
Overall Steps per Second: 16,989.60291

Timestep Collection Time: 2.07387
Timestep Consumption Time: 0.87111
PPO Batch Consumption Time: 0.06487
Total Iteration Time: 2.94498

Cumulative Model Updates: 1,118
Cumulative Timesteps: 18,705,812

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 18705812...
Checkpoint 18705812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05167
Policy Entropy: 4.46560
Value Function Loss: 0.04000

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08359
Value Function Update Magnitude: 0.06741

Collected Steps per Second: 24,567.38287
Overall Steps per Second: 16,493.43362

Timestep Collection Time: 2.03595
Timestep Consumption Time: 0.99665
PPO Batch Consumption Time: 0.07833
Total Iteration Time: 3.03260

Cumulative Model Updates: 1,121
Cumulative Timesteps: 18,755,830

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02950
Policy Entropy: 4.46777
Value Function Loss: 0.04045

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08016
Value Function Update Magnitude: 0.06252

Collected Steps per Second: 24,658.57079
Overall Steps per Second: 17,019.09016

Timestep Collection Time: 2.02834
Timestep Consumption Time: 0.91048
PPO Batch Consumption Time: 0.06307
Total Iteration Time: 2.93882

Cumulative Model Updates: 1,124
Cumulative Timesteps: 18,805,846

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 18805846...
Checkpoint 18805846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02669
Policy Entropy: 4.46972
Value Function Loss: 0.03936

Mean KL Divergence: 0.00024
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07581
Value Function Update Magnitude: 0.05925

Collected Steps per Second: 24,646.41513
Overall Steps per Second: 16,577.16819

Timestep Collection Time: 2.02869
Timestep Consumption Time: 0.98750
PPO Batch Consumption Time: 0.11059
Total Iteration Time: 3.01620

Cumulative Model Updates: 1,127
Cumulative Timesteps: 18,855,846

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00613
Policy Entropy: 4.47081
Value Function Loss: 0.03450

Mean KL Divergence: 0.00018
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07465
Value Function Update Magnitude: 0.06331

Collected Steps per Second: 24,708.39968
Overall Steps per Second: 16,889.64656

Timestep Collection Time: 2.02409
Timestep Consumption Time: 0.93701
PPO Batch Consumption Time: 0.06488
Total Iteration Time: 2.96110

Cumulative Model Updates: 1,130
Cumulative Timesteps: 18,905,858

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 18905858...
Checkpoint 18905858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02618
Policy Entropy: 4.47056
Value Function Loss: 0.03123

Mean KL Divergence: 0.00013
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07515
Value Function Update Magnitude: 0.06287

Collected Steps per Second: 24,519.62499
Overall Steps per Second: 16,493.86484

Timestep Collection Time: 2.03918
Timestep Consumption Time: 0.99225
PPO Batch Consumption Time: 0.09184
Total Iteration Time: 3.03143

Cumulative Model Updates: 1,133
Cumulative Timesteps: 18,955,858

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00113
Policy Entropy: 4.46949
Value Function Loss: 0.04096

Mean KL Divergence: 0.00014
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07813
Value Function Update Magnitude: 0.05437

Collected Steps per Second: 25,517.40986
Overall Steps per Second: 17,243.87065

Timestep Collection Time: 1.95952
Timestep Consumption Time: 0.94017
PPO Batch Consumption Time: 0.06227
Total Iteration Time: 2.89970

Cumulative Model Updates: 1,136
Cumulative Timesteps: 19,005,860

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 19005860...
Checkpoint 19005860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03406
Policy Entropy: 4.46869
Value Function Loss: 0.04737

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08043
Value Function Update Magnitude: 0.05556

Collected Steps per Second: 24,552.07679
Overall Steps per Second: 16,290.11984

Timestep Collection Time: 2.03689
Timestep Consumption Time: 1.03306
PPO Batch Consumption Time: 0.09645
Total Iteration Time: 3.06996

Cumulative Model Updates: 1,139
Cumulative Timesteps: 19,055,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02900
Policy Entropy: 4.46750
Value Function Loss: 0.05408

Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08179
Value Function Update Magnitude: 0.06151

Collected Steps per Second: 24,629.84081
Overall Steps per Second: 17,386.44133

Timestep Collection Time: 2.03071
Timestep Consumption Time: 0.84602
PPO Batch Consumption Time: 0.06294
Total Iteration Time: 2.87672

Cumulative Model Updates: 1,142
Cumulative Timesteps: 19,105,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 19105886...
Checkpoint 19105886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01919
Policy Entropy: 4.46693
Value Function Loss: 0.04654

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08306
Value Function Update Magnitude: 0.05193

Collected Steps per Second: 22,395.16726
Overall Steps per Second: 15,196.58409

Timestep Collection Time: 2.23370
Timestep Consumption Time: 1.05810
PPO Batch Consumption Time: 0.10524
Total Iteration Time: 3.29179

Cumulative Model Updates: 1,145
Cumulative Timesteps: 19,155,910

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04768
Policy Entropy: 4.46776
Value Function Loss: 0.05145

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08672
Value Function Update Magnitude: 0.05192

Collected Steps per Second: 24,660.00437
Overall Steps per Second: 16,671.93893

Timestep Collection Time: 2.02863
Timestep Consumption Time: 0.97198
PPO Batch Consumption Time: 0.08402
Total Iteration Time: 3.00061

Cumulative Model Updates: 1,148
Cumulative Timesteps: 19,205,936

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 19205936...
Checkpoint 19205936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02812
Policy Entropy: 4.46996
Value Function Loss: 0.03653

Mean KL Divergence: 0.00020
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08949
Value Function Update Magnitude: 0.05470

Collected Steps per Second: 24,803.86211
Overall Steps per Second: 16,799.66344

Timestep Collection Time: 2.01678
Timestep Consumption Time: 0.96090
PPO Batch Consumption Time: 0.09376
Total Iteration Time: 2.97768

Cumulative Model Updates: 1,151
Cumulative Timesteps: 19,255,960

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05656
Policy Entropy: 4.47226
Value Function Loss: 0.03598

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08402
Value Function Update Magnitude: 0.05545

Collected Steps per Second: 24,669.42414
Overall Steps per Second: 16,670.96623

Timestep Collection Time: 2.02753
Timestep Consumption Time: 0.97278
PPO Batch Consumption Time: 0.07366
Total Iteration Time: 3.00031

Cumulative Model Updates: 1,154
Cumulative Timesteps: 19,305,978

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 19305978...
Checkpoint 19305978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01996
Policy Entropy: 4.47282
Value Function Loss: 0.04666

Mean KL Divergence: 0.00019
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07388
Value Function Update Magnitude: 0.04893

Collected Steps per Second: 24,432.99569
Overall Steps per Second: 16,744.71322

Timestep Collection Time: 2.04641
Timestep Consumption Time: 0.93960
PPO Batch Consumption Time: 0.07262
Total Iteration Time: 2.98602

Cumulative Model Updates: 1,157
Cumulative Timesteps: 19,355,978

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07449
Policy Entropy: 4.47287
Value Function Loss: 0.05445

Mean KL Divergence: 0.00011
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07463
Value Function Update Magnitude: 0.05653

Collected Steps per Second: 24,158.60217
Overall Steps per Second: 16,528.92453

Timestep Collection Time: 2.07007
Timestep Consumption Time: 0.95554
PPO Batch Consumption Time: 0.06742
Total Iteration Time: 3.02561

Cumulative Model Updates: 1,160
Cumulative Timesteps: 19,405,988

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 19405988...
Checkpoint 19405988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01269
Policy Entropy: 4.47295
Value Function Loss: 0.05911

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07933
Value Function Update Magnitude: 0.06646

Collected Steps per Second: 21,790.13356
Overall Steps per Second: 15,156.66796

Timestep Collection Time: 2.29462
Timestep Consumption Time: 1.00426
PPO Batch Consumption Time: 0.07273
Total Iteration Time: 3.29888

Cumulative Model Updates: 1,163
Cumulative Timesteps: 19,455,988

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01169
Policy Entropy: 4.47312
Value Function Loss: 0.05984

Mean KL Divergence: 0.00009
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07717
Value Function Update Magnitude: 0.06730

Collected Steps per Second: 24,232.82664
Overall Steps per Second: 16,494.57442

Timestep Collection Time: 2.06365
Timestep Consumption Time: 0.96814
PPO Batch Consumption Time: 0.10662
Total Iteration Time: 3.03178

Cumulative Model Updates: 1,166
Cumulative Timesteps: 19,505,996

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 19505996...
Checkpoint 19505996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01226
Policy Entropy: 4.47126
Value Function Loss: 0.05827

Mean KL Divergence: 0.00011
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08219
Value Function Update Magnitude: 0.07384

Collected Steps per Second: 24,686.89298
Overall Steps per Second: 16,952.61218

Timestep Collection Time: 2.02561
Timestep Consumption Time: 0.92414
PPO Batch Consumption Time: 0.06417
Total Iteration Time: 2.94975

Cumulative Model Updates: 1,169
Cumulative Timesteps: 19,556,002

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00330
Policy Entropy: 4.46811
Value Function Loss: 0.05882

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08998
Value Function Update Magnitude: 0.08381

Collected Steps per Second: 24,596.01481
Overall Steps per Second: 16,512.16864

Timestep Collection Time: 2.03374
Timestep Consumption Time: 0.99566
PPO Batch Consumption Time: 0.09667
Total Iteration Time: 3.02940

Cumulative Model Updates: 1,172
Cumulative Timesteps: 19,606,024

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 19606024...
Checkpoint 19606024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00121
Policy Entropy: 4.46436
Value Function Loss: 0.06514

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08718
Value Function Update Magnitude: 0.08869

Collected Steps per Second: 25,211.60769
Overall Steps per Second: 17,164.49786

Timestep Collection Time: 1.98329
Timestep Consumption Time: 0.92981
PPO Batch Consumption Time: 0.06410
Total Iteration Time: 2.91311

Cumulative Model Updates: 1,175
Cumulative Timesteps: 19,656,026

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00282
Policy Entropy: 4.46238
Value Function Loss: 0.07293

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08754
Value Function Update Magnitude: 0.07466

Collected Steps per Second: 24,430.66542
Overall Steps per Second: 16,299.40490

Timestep Collection Time: 2.04751
Timestep Consumption Time: 1.02144
PPO Batch Consumption Time: 0.08925
Total Iteration Time: 3.06895

Cumulative Model Updates: 1,178
Cumulative Timesteps: 19,706,048

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 19706048...
Checkpoint 19706048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03365
Policy Entropy: 4.46192
Value Function Loss: 0.07916

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08959
Value Function Update Magnitude: 0.06294

Collected Steps per Second: 24,367.99975
Overall Steps per Second: 17,187.58969

Timestep Collection Time: 2.05327
Timestep Consumption Time: 0.85779
PPO Batch Consumption Time: 0.06243
Total Iteration Time: 2.91105

Cumulative Model Updates: 1,181
Cumulative Timesteps: 19,756,082

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01930
Policy Entropy: 4.46479
Value Function Loss: 0.06239

Mean KL Divergence: 0.00023
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09398
Value Function Update Magnitude: 0.05271

Collected Steps per Second: 25,109.68546
Overall Steps per Second: 16,429.36529

Timestep Collection Time: 1.99222
Timestep Consumption Time: 1.05257
PPO Batch Consumption Time: 0.10989
Total Iteration Time: 3.04479

Cumulative Model Updates: 1,184
Cumulative Timesteps: 19,806,106

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 19806106...
Checkpoint 19806106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01069
Policy Entropy: 4.46972
Value Function Loss: 0.06334

Mean KL Divergence: 0.00054
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.09844
Value Function Update Magnitude: 0.05161

Collected Steps per Second: 24,453.70272
Overall Steps per Second: 16,915.53847

Timestep Collection Time: 2.04550
Timestep Consumption Time: 0.91155
PPO Batch Consumption Time: 0.06474
Total Iteration Time: 2.95704

Cumulative Model Updates: 1,187
Cumulative Timesteps: 19,856,126

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03586
Policy Entropy: 4.47503
Value Function Loss: 0.09001

Mean KL Divergence: 0.00087
SB3 Clip Fraction: 0.00071
Policy Update Magnitude: 0.09782
Value Function Update Magnitude: 0.06513

Collected Steps per Second: 24,684.84976
Overall Steps per Second: 16,558.11114

Timestep Collection Time: 2.02553
Timestep Consumption Time: 0.99413
PPO Batch Consumption Time: 0.10986
Total Iteration Time: 3.01967

Cumulative Model Updates: 1,190
Cumulative Timesteps: 19,906,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 19906126...
Checkpoint 19906126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05702
Policy Entropy: 4.47851
Value Function Loss: 0.10345

Mean KL Divergence: 0.00072
SB3 Clip Fraction: 0.00059
Policy Update Magnitude: 0.09795
Value Function Update Magnitude: 0.08036

Collected Steps per Second: 24,550.86436
Overall Steps per Second: 16,814.90849

Timestep Collection Time: 2.03675
Timestep Consumption Time: 0.93704
PPO Batch Consumption Time: 0.06270
Total Iteration Time: 2.97379

Cumulative Model Updates: 1,193
Cumulative Timesteps: 19,956,130

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06380
Policy Entropy: 4.48065
Value Function Loss: 0.09533

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.10480
Value Function Update Magnitude: 0.07654

Collected Steps per Second: 20,947.08925
Overall Steps per Second: 14,503.50510

Timestep Collection Time: 2.38735
Timestep Consumption Time: 1.06065
PPO Batch Consumption Time: 0.10870
Total Iteration Time: 3.44799

Cumulative Model Updates: 1,196
Cumulative Timesteps: 20,006,138

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 20006138...
Checkpoint 20006138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01898
Policy Entropy: 4.48183
Value Function Loss: 0.05527

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10266
Value Function Update Magnitude: 0.08028

Collected Steps per Second: 25,559.81456
Overall Steps per Second: 17,242.70042

Timestep Collection Time: 1.95713
Timestep Consumption Time: 0.94403
PPO Batch Consumption Time: 0.06292
Total Iteration Time: 2.90117

Cumulative Model Updates: 1,199
Cumulative Timesteps: 20,056,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00704
Policy Entropy: 4.48232
Value Function Loss: 0.03475

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08942
Value Function Update Magnitude: 0.07935

Collected Steps per Second: 24,135.62554
Overall Steps per Second: 16,384.81753

Timestep Collection Time: 2.07196
Timestep Consumption Time: 0.98014
PPO Batch Consumption Time: 0.07992
Total Iteration Time: 3.05209

Cumulative Model Updates: 1,202
Cumulative Timesteps: 20,106,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 20106170...
Checkpoint 20106170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02047
Policy Entropy: 4.48244
Value Function Loss: 0.03187

Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08066
Value Function Update Magnitude: 0.06828

Collected Steps per Second: 22,515.68216
Overall Steps per Second: 15,895.32103

Timestep Collection Time: 2.22085
Timestep Consumption Time: 0.92498
PPO Batch Consumption Time: 0.06341
Total Iteration Time: 3.14583

Cumulative Model Updates: 1,205
Cumulative Timesteps: 20,156,174

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01554
Policy Entropy: 4.48238
Value Function Loss: 0.03121

Mean KL Divergence: 0.00012
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07859
Value Function Update Magnitude: 0.05565

Collected Steps per Second: 21,574.20917
Overall Steps per Second: 14,883.13269

Timestep Collection Time: 2.31888
Timestep Consumption Time: 1.04251
PPO Batch Consumption Time: 0.07172
Total Iteration Time: 3.36139

Cumulative Model Updates: 1,208
Cumulative Timesteps: 20,206,202

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 20206202...
Checkpoint 20206202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05399
Policy Entropy: 4.48241
Value Function Loss: 0.03804

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07736
Value Function Update Magnitude: 0.04963

Collected Steps per Second: 23,623.01302
Overall Steps per Second: 16,627.83138

Timestep Collection Time: 2.11734
Timestep Consumption Time: 0.89075
PPO Batch Consumption Time: 0.05958
Total Iteration Time: 3.00809

Cumulative Model Updates: 1,211
Cumulative Timesteps: 20,256,220

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00513
Policy Entropy: 4.48200
Value Function Loss: 0.04197

Mean KL Divergence: 0.00009
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07508
Value Function Update Magnitude: 0.05037

Collected Steps per Second: 22,630.23326
Overall Steps per Second: 15,493.48452

Timestep Collection Time: 2.20943
Timestep Consumption Time: 1.01773
PPO Batch Consumption Time: 0.09446
Total Iteration Time: 3.22716

Cumulative Model Updates: 1,214
Cumulative Timesteps: 20,306,220

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 20306220...
Checkpoint 20306220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04442
Policy Entropy: 4.48053
Value Function Loss: 0.06456

Mean KL Divergence: 0.00012
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08253
Value Function Update Magnitude: 0.06314

Collected Steps per Second: 24,443.20553
Overall Steps per Second: 16,895.31885

Timestep Collection Time: 2.04695
Timestep Consumption Time: 0.91446
PPO Batch Consumption Time: 0.05984
Total Iteration Time: 2.96141

Cumulative Model Updates: 1,217
Cumulative Timesteps: 20,356,254

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02806
Policy Entropy: 4.47813
Value Function Loss: 0.06153

Mean KL Divergence: 0.00024
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09089
Value Function Update Magnitude: 0.06573

Collected Steps per Second: 21,585.56950
Overall Steps per Second: 15,463.66745

Timestep Collection Time: 2.31683
Timestep Consumption Time: 0.91721
PPO Batch Consumption Time: 0.08130
Total Iteration Time: 3.23403

Cumulative Model Updates: 1,220
Cumulative Timesteps: 20,406,264

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 20406264...
Checkpoint 20406264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02110
Policy Entropy: 4.47599
Value Function Loss: 0.05312

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00007
Policy Update Magnitude: 0.09441
Value Function Update Magnitude: 0.06520

Collected Steps per Second: 19,619.04100
Overall Steps per Second: 14,356.45659

Timestep Collection Time: 2.54916
Timestep Consumption Time: 0.93443
PPO Batch Consumption Time: 0.05905
Total Iteration Time: 3.48359

Cumulative Model Updates: 1,223
Cumulative Timesteps: 20,456,276

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01012
Policy Entropy: 4.47382
Value Function Loss: 0.02875

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00006
Policy Update Magnitude: 0.08562
Value Function Update Magnitude: 0.08529

Collected Steps per Second: 21,644.68817
Overall Steps per Second: 15,102.78889

Timestep Collection Time: 2.31068
Timestep Consumption Time: 1.00089
PPO Batch Consumption Time: 0.07817
Total Iteration Time: 3.31157

Cumulative Model Updates: 1,226
Cumulative Timesteps: 20,506,290

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 20506290...
Checkpoint 20506290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00124
Policy Entropy: 4.47195
Value Function Loss: 0.02568

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.07210
Value Function Update Magnitude: 0.07793

Collected Steps per Second: 24,891.62111
Overall Steps per Second: 16,998.94782

Timestep Collection Time: 2.00927
Timestep Consumption Time: 0.93291
PPO Batch Consumption Time: 0.07575
Total Iteration Time: 2.94218

Cumulative Model Updates: 1,229
Cumulative Timesteps: 20,556,304

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03474
Policy Entropy: 4.47006
Value Function Loss: 0.05156

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07343
Value Function Update Magnitude: 0.05080

Collected Steps per Second: 25,075.89569
Overall Steps per Second: 17,181.09895

Timestep Collection Time: 1.99474
Timestep Consumption Time: 0.91659
PPO Batch Consumption Time: 0.06354
Total Iteration Time: 2.91134

Cumulative Model Updates: 1,232
Cumulative Timesteps: 20,606,324

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 20606324...
Checkpoint 20606324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00120
Policy Entropy: 4.46866
Value Function Loss: 0.06001

Mean KL Divergence: 0.00018
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08222
Value Function Update Magnitude: 0.07624

Collected Steps per Second: 25,396.38639
Overall Steps per Second: 17,873.17442

Timestep Collection Time: 1.96981
Timestep Consumption Time: 0.82914
PPO Batch Consumption Time: 0.06243
Total Iteration Time: 2.79894

Cumulative Model Updates: 1,235
Cumulative Timesteps: 20,656,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02910
Policy Entropy: 4.46678
Value Function Loss: 0.05302

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09203
Value Function Update Magnitude: 0.07330

Collected Steps per Second: 25,765.11931
Overall Steps per Second: 16,512.14088

Timestep Collection Time: 1.94115
Timestep Consumption Time: 1.08777
PPO Batch Consumption Time: 0.12195
Total Iteration Time: 3.02892

Cumulative Model Updates: 1,238
Cumulative Timesteps: 20,706,364

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 20706364...
Checkpoint 20706364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03583
Policy Entropy: 4.46318
Value Function Loss: 0.03259

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09404
Value Function Update Magnitude: 0.05918

Collected Steps per Second: 25,796.47905
Overall Steps per Second: 16,696.10774

Timestep Collection Time: 1.93926
Timestep Consumption Time: 1.05701
PPO Batch Consumption Time: 0.10351
Total Iteration Time: 2.99627

Cumulative Model Updates: 1,241
Cumulative Timesteps: 20,756,390

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01877
Policy Entropy: 4.45774
Value Function Loss: 0.02805

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.08651
Value Function Update Magnitude: 0.06515

Collected Steps per Second: 23,503.23779
Overall Steps per Second: 15,703.25820

Timestep Collection Time: 2.12847
Timestep Consumption Time: 1.05724
PPO Batch Consumption Time: 0.10671
Total Iteration Time: 3.18571

Cumulative Model Updates: 1,244
Cumulative Timesteps: 20,806,416

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 20806416...
Checkpoint 20806416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03674
Policy Entropy: 4.45326
Value Function Loss: 0.03337

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07475
Value Function Update Magnitude: 0.05594

Collected Steps per Second: 25,382.81792
Overall Steps per Second: 17,143.70857

Timestep Collection Time: 1.97047
Timestep Consumption Time: 0.94699
PPO Batch Consumption Time: 0.06234
Total Iteration Time: 2.91746

Cumulative Model Updates: 1,247
Cumulative Timesteps: 20,856,432

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09275
Policy Entropy: 4.45283
Value Function Loss: 0.05411

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07881
Value Function Update Magnitude: 0.05981

Collected Steps per Second: 21,491.13156
Overall Steps per Second: 15,705.45182

Timestep Collection Time: 2.32766
Timestep Consumption Time: 0.85748
PPO Batch Consumption Time: 0.05864
Total Iteration Time: 3.18514

Cumulative Model Updates: 1,250
Cumulative Timesteps: 20,906,456

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 20906456...
Checkpoint 20906456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01793
Policy Entropy: 4.45600
Value Function Loss: 0.05266

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08573
Value Function Update Magnitude: 0.06642

Collected Steps per Second: 22,455.11099
Overall Steps per Second: 15,272.46491

Timestep Collection Time: 2.22738
Timestep Consumption Time: 1.04754
PPO Batch Consumption Time: 0.08908
Total Iteration Time: 3.27491

Cumulative Model Updates: 1,253
Cumulative Timesteps: 20,956,472

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02225
Policy Entropy: 4.45905
Value Function Loss: 0.05416

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08532
Value Function Update Magnitude: 0.05730

Collected Steps per Second: 24,088.99864
Overall Steps per Second: 16,794.00553

Timestep Collection Time: 2.07564
Timestep Consumption Time: 0.90162
PPO Batch Consumption Time: 0.06205
Total Iteration Time: 2.97725

Cumulative Model Updates: 1,256
Cumulative Timesteps: 21,006,472

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 21006472...
Checkpoint 21006472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06532
Policy Entropy: 4.46113
Value Function Loss: 0.04564

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08360
Value Function Update Magnitude: 0.05624

Collected Steps per Second: 21,185.42148
Overall Steps per Second: 15,739.31160

Timestep Collection Time: 2.36144
Timestep Consumption Time: 0.81710
PPO Batch Consumption Time: 0.03000
Total Iteration Time: 3.17854

Cumulative Model Updates: 1,259
Cumulative Timesteps: 21,056,500

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02862
Policy Entropy: 4.46286
Value Function Loss: 0.04400

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08118
Value Function Update Magnitude: 0.05642

Collected Steps per Second: 23,398.79227
Overall Steps per Second: 16,452.26115

Timestep Collection Time: 2.13695
Timestep Consumption Time: 0.90227
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 3.03922

Cumulative Model Updates: 1,262
Cumulative Timesteps: 21,106,502

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 21106502...
Checkpoint 21106502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00845
Policy Entropy: 4.46445
Value Function Loss: 0.03711

Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07895
Value Function Update Magnitude: 0.04964

Collected Steps per Second: 21,922.20680
Overall Steps per Second: 15,036.37242

Timestep Collection Time: 2.28143
Timestep Consumption Time: 1.04477
PPO Batch Consumption Time: 0.12358
Total Iteration Time: 3.32620

Cumulative Model Updates: 1,265
Cumulative Timesteps: 21,156,516

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00412
Policy Entropy: 4.46458
Value Function Loss: 0.04905

Mean KL Divergence: 0.00012
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07599
Value Function Update Magnitude: 0.04659

Collected Steps per Second: 24,418.22376
Overall Steps per Second: 16,325.55835

Timestep Collection Time: 2.04781
Timestep Consumption Time: 1.01511
PPO Batch Consumption Time: 0.08357
Total Iteration Time: 3.06293

Cumulative Model Updates: 1,268
Cumulative Timesteps: 21,206,520

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 21206520...
Checkpoint 21206520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00675
Policy Entropy: 4.46348
Value Function Loss: 0.05276

Mean KL Divergence: 0.00011
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08369
Value Function Update Magnitude: 0.04733

Collected Steps per Second: 23,293.77065
Overall Steps per Second: 15,947.14079

Timestep Collection Time: 2.14718
Timestep Consumption Time: 0.98918
PPO Batch Consumption Time: 0.08899
Total Iteration Time: 3.13636

Cumulative Model Updates: 1,271
Cumulative Timesteps: 21,256,536

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00681
Policy Entropy: 4.46023
Value Function Loss: 0.06382

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09354
Value Function Update Magnitude: 0.04575

Collected Steps per Second: 25,399.80321
Overall Steps per Second: 17,406.08974

Timestep Collection Time: 1.96970
Timestep Consumption Time: 0.90458
PPO Batch Consumption Time: 0.06135
Total Iteration Time: 2.87428

Cumulative Model Updates: 1,274
Cumulative Timesteps: 21,306,566

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 21306566...
Checkpoint 21306566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06579
Policy Entropy: 4.45475
Value Function Loss: 0.05088

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00088
Policy Update Magnitude: 0.09853
Value Function Update Magnitude: 0.05008

Collected Steps per Second: 21,416.89371
Overall Steps per Second: 14,247.39652

Timestep Collection Time: 2.33461
Timestep Consumption Time: 1.17481
PPO Batch Consumption Time: 0.12882
Total Iteration Time: 3.50941

Cumulative Model Updates: 1,277
Cumulative Timesteps: 21,356,566

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05259
Policy Entropy: 4.44729
Value Function Loss: 0.05709

Mean KL Divergence: 0.00083
SB3 Clip Fraction: 0.00415
Policy Update Magnitude: 0.09581
Value Function Update Magnitude: 0.05735

Collected Steps per Second: 23,082.97716
Overall Steps per Second: 16,813.67455

Timestep Collection Time: 2.16688
Timestep Consumption Time: 0.80796
PPO Batch Consumption Time: 0.05228
Total Iteration Time: 2.97484

Cumulative Model Updates: 1,280
Cumulative Timesteps: 21,406,584

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 21406584...
Checkpoint 21406584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01535
Policy Entropy: 4.44121
Value Function Loss: 0.07773

Mean KL Divergence: 0.00081
SB3 Clip Fraction: 0.00366
Policy Update Magnitude: 0.08903
Value Function Update Magnitude: 0.07592

Collected Steps per Second: 20,779.12019
Overall Steps per Second: 14,685.66047

Timestep Collection Time: 2.40655
Timestep Consumption Time: 0.99854
PPO Batch Consumption Time: 0.07980
Total Iteration Time: 3.40509

Cumulative Model Updates: 1,283
Cumulative Timesteps: 21,456,590

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00632
Policy Entropy: 4.44063
Value Function Loss: 0.07594

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09634
Value Function Update Magnitude: 0.08479

Collected Steps per Second: 23,829.62069
Overall Steps per Second: 16,697.71564

Timestep Collection Time: 2.09924
Timestep Consumption Time: 0.89662
PPO Batch Consumption Time: 0.05974
Total Iteration Time: 2.99586

Cumulative Model Updates: 1,286
Cumulative Timesteps: 21,506,614

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 21506614...
Checkpoint 21506614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03145
Policy Entropy: 4.44314
Value Function Loss: 0.07478

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10369
Value Function Update Magnitude: 0.07319

Collected Steps per Second: 19,817.71411
Overall Steps per Second: 14,088.26035

Timestep Collection Time: 2.52441
Timestep Consumption Time: 1.02663
PPO Batch Consumption Time: 0.11277
Total Iteration Time: 3.55104

Cumulative Model Updates: 1,289
Cumulative Timesteps: 21,556,642

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02393
Policy Entropy: 4.44738
Value Function Loss: 0.04376

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10143
Value Function Update Magnitude: 0.07281

Collected Steps per Second: 24,632.55074
Overall Steps per Second: 16,940.31275

Timestep Collection Time: 2.03040
Timestep Consumption Time: 0.92196
PPO Batch Consumption Time: 0.06266
Total Iteration Time: 2.95237

Cumulative Model Updates: 1,292
Cumulative Timesteps: 21,606,656

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 21606656...
Checkpoint 21606656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01984
Policy Entropy: 4.45288
Value Function Loss: 0.05598

Mean KL Divergence: 0.00069
SB3 Clip Fraction: 0.00009
Policy Update Magnitude: 0.09584
Value Function Update Magnitude: 0.07678

Collected Steps per Second: 24,248.87561
Overall Steps per Second: 16,530.64043

Timestep Collection Time: 2.06261
Timestep Consumption Time: 0.96304
PPO Batch Consumption Time: 0.10048
Total Iteration Time: 3.02565

Cumulative Model Updates: 1,295
Cumulative Timesteps: 21,656,672

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01247
Policy Entropy: 4.45888
Value Function Loss: 0.04275

Mean KL Divergence: 0.00078
SB3 Clip Fraction: 0.00075
Policy Update Magnitude: 0.09392
Value Function Update Magnitude: 0.08190

Collected Steps per Second: 24,645.62430
Overall Steps per Second: 16,943.73056

Timestep Collection Time: 2.02941
Timestep Consumption Time: 0.92248
PPO Batch Consumption Time: 0.06325
Total Iteration Time: 2.95189

Cumulative Model Updates: 1,298
Cumulative Timesteps: 21,706,688

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 21706688...
Checkpoint 21706688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00437
Policy Entropy: 4.46384
Value Function Loss: 0.04113

Mean KL Divergence: 0.00073
SB3 Clip Fraction: 0.00102
Policy Update Magnitude: 0.09025
Value Function Update Magnitude: 0.07738

Collected Steps per Second: 24,586.33554
Overall Steps per Second: 16,541.04206

Timestep Collection Time: 2.03463
Timestep Consumption Time: 0.98961
PPO Batch Consumption Time: 0.08931
Total Iteration Time: 3.02424

Cumulative Model Updates: 1,301
Cumulative Timesteps: 21,756,712

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03988
Policy Entropy: 4.46690
Value Function Loss: 0.02916

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00019
Policy Update Magnitude: 0.07853
Value Function Update Magnitude: 0.06412

Collected Steps per Second: 23,808.53914
Overall Steps per Second: 16,980.47059

Timestep Collection Time: 2.10126
Timestep Consumption Time: 0.84495
PPO Batch Consumption Time: 0.06423
Total Iteration Time: 2.94621

Cumulative Model Updates: 1,304
Cumulative Timesteps: 21,806,740

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 21806740...
Checkpoint 21806740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02027
Policy Entropy: 4.46750
Value Function Loss: 0.04374

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07202
Value Function Update Magnitude: 0.05845

Collected Steps per Second: 20,152.41920
Overall Steps per Second: 14,828.11970

Timestep Collection Time: 2.48109
Timestep Consumption Time: 0.89088
PPO Batch Consumption Time: 0.03081
Total Iteration Time: 3.37197

Cumulative Model Updates: 1,307
Cumulative Timesteps: 21,856,740

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01031
Policy Entropy: 4.46618
Value Function Loss: 0.03644

Mean KL Divergence: 0.00009
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07651
Value Function Update Magnitude: 0.06495

Collected Steps per Second: 22,469.58853
Overall Steps per Second: 16,206.02200

Timestep Collection Time: 2.22630
Timestep Consumption Time: 0.86046
PPO Batch Consumption Time: 0.09315
Total Iteration Time: 3.08675

Cumulative Model Updates: 1,310
Cumulative Timesteps: 21,906,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 21906764...
Checkpoint 21906764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04168
Policy Entropy: 4.46297
Value Function Loss: 0.03556

Mean KL Divergence: 0.00018
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07973
Value Function Update Magnitude: 0.07148

Collected Steps per Second: 24,339.26646
Overall Steps per Second: 17,382.76869

Timestep Collection Time: 2.05438
Timestep Consumption Time: 0.82215
PPO Batch Consumption Time: 0.06493
Total Iteration Time: 2.87653

Cumulative Model Updates: 1,313
Cumulative Timesteps: 21,956,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01028
Policy Entropy: 4.45809
Value Function Loss: 0.03245

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07786
Value Function Update Magnitude: 0.06447

Collected Steps per Second: 24,296.74193
Overall Steps per Second: 17,674.55247

Timestep Collection Time: 2.05797
Timestep Consumption Time: 0.77107
PPO Batch Consumption Time: 0.06017
Total Iteration Time: 2.82904

Cumulative Model Updates: 1,316
Cumulative Timesteps: 22,006,768

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 22006768...
Checkpoint 22006768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03762
Policy Entropy: 4.45297
Value Function Loss: 0.06134

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07916
Value Function Update Magnitude: 0.06568

Collected Steps per Second: 19,754.71863
Overall Steps per Second: 14,583.31414

Timestep Collection Time: 2.53236
Timestep Consumption Time: 0.89800
PPO Batch Consumption Time: 0.07724
Total Iteration Time: 3.43036

Cumulative Model Updates: 1,319
Cumulative Timesteps: 22,056,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01192
Policy Entropy: 4.44838
Value Function Loss: 0.06606

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08512
Value Function Update Magnitude: 0.08957

Collected Steps per Second: 22,425.93485
Overall Steps per Second: 16,193.86011

Timestep Collection Time: 2.23036
Timestep Consumption Time: 0.85834
PPO Batch Consumption Time: 0.06469
Total Iteration Time: 3.08870

Cumulative Model Updates: 1,322
Cumulative Timesteps: 22,106,812

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 22106812...
Checkpoint 22106812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00532
Policy Entropy: 4.44495
Value Function Loss: 0.06827

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09485
Value Function Update Magnitude: 0.10043

Collected Steps per Second: 24,160.13687
Overall Steps per Second: 17,430.27420

Timestep Collection Time: 2.06952
Timestep Consumption Time: 0.79905
PPO Batch Consumption Time: 0.07992
Total Iteration Time: 2.86857

Cumulative Model Updates: 1,325
Cumulative Timesteps: 22,156,812

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01477
Policy Entropy: 4.44304
Value Function Loss: 0.04747

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09635
Value Function Update Magnitude: 0.09935

Collected Steps per Second: 24,557.92373
Overall Steps per Second: 17,565.27970

Timestep Collection Time: 2.03633
Timestep Consumption Time: 0.81065
PPO Batch Consumption Time: 0.06140
Total Iteration Time: 2.84698

Cumulative Model Updates: 1,328
Cumulative Timesteps: 22,206,820

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 22206820...
Checkpoint 22206820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00691
Policy Entropy: 4.44352
Value Function Loss: 0.03955

Mean KL Divergence: 0.00026
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09499
Value Function Update Magnitude: 0.08712

Collected Steps per Second: 21,506.43712
Overall Steps per Second: 15,091.84706

Timestep Collection Time: 2.32535
Timestep Consumption Time: 0.98836
PPO Batch Consumption Time: 0.11473
Total Iteration Time: 3.31371

Cumulative Model Updates: 1,331
Cumulative Timesteps: 22,256,830

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01928
Policy Entropy: 4.44580
Value Function Loss: 0.02754

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08959
Value Function Update Magnitude: 0.08083

Collected Steps per Second: 24,387.43115
Overall Steps per Second: 16,793.79039

Timestep Collection Time: 2.05163
Timestep Consumption Time: 0.92768
PPO Batch Consumption Time: 0.11851
Total Iteration Time: 2.97932

Cumulative Model Updates: 1,334
Cumulative Timesteps: 22,306,864

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 22306864...
Checkpoint 22306864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03659
Policy Entropy: 4.45079
Value Function Loss: 0.04929

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00015
Policy Update Magnitude: 0.08915
Value Function Update Magnitude: 0.07483

Collected Steps per Second: 24,577.23113
Overall Steps per Second: 16,657.67074

Timestep Collection Time: 2.03473
Timestep Consumption Time: 0.96737
PPO Batch Consumption Time: 0.10432
Total Iteration Time: 3.00210

Cumulative Model Updates: 1,337
Cumulative Timesteps: 22,356,872

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01269
Policy Entropy: 4.45734
Value Function Loss: 0.06301

Mean KL Divergence: 0.00076
SB3 Clip Fraction: 0.00054
Policy Update Magnitude: 0.09712
Value Function Update Magnitude: 0.07812

Collected Steps per Second: 21,358.05172
Overall Steps per Second: 15,546.00540

Timestep Collection Time: 2.34104
Timestep Consumption Time: 0.87522
PPO Batch Consumption Time: 0.09327
Total Iteration Time: 3.21626

Cumulative Model Updates: 1,340
Cumulative Timesteps: 22,406,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 22406872...
Checkpoint 22406872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04674
Policy Entropy: 4.46241
Value Function Loss: 0.07739

Mean KL Divergence: 0.00096
SB3 Clip Fraction: 0.00103
Policy Update Magnitude: 0.11052
Value Function Update Magnitude: 0.07810

Collected Steps per Second: 21,359.29804
Overall Steps per Second: 15,759.07575

Timestep Collection Time: 2.34090
Timestep Consumption Time: 0.83187
PPO Batch Consumption Time: 0.06225
Total Iteration Time: 3.17277

Cumulative Model Updates: 1,343
Cumulative Timesteps: 22,456,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01119
Policy Entropy: 4.46565
Value Function Loss: 0.07770

Mean KL Divergence: 0.00088
SB3 Clip Fraction: 0.00041
Policy Update Magnitude: 0.10816
Value Function Update Magnitude: 0.08245

Collected Steps per Second: 21,124.21659
Overall Steps per Second: 14,905.32687

Timestep Collection Time: 2.36903
Timestep Consumption Time: 0.98842
PPO Batch Consumption Time: 0.12219
Total Iteration Time: 3.35746

Cumulative Model Updates: 1,346
Cumulative Timesteps: 22,506,916

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 22506916...
Checkpoint 22506916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00066
Policy Entropy: 4.46761
Value Function Loss: 0.07636

Mean KL Divergence: 0.00067
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.10342
Value Function Update Magnitude: 0.08443

Collected Steps per Second: 25,407.41753
Overall Steps per Second: 18,076.85181

Timestep Collection Time: 1.96864
Timestep Consumption Time: 0.79833
PPO Batch Consumption Time: 0.06016
Total Iteration Time: 2.76696

Cumulative Model Updates: 1,349
Cumulative Timesteps: 22,556,934

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04679
Policy Entropy: 4.46840
Value Function Loss: 0.09349

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10148
Value Function Update Magnitude: 0.08565

Collected Steps per Second: 22,516.92383
Overall Steps per Second: 15,535.03084

Timestep Collection Time: 2.22100
Timestep Consumption Time: 0.99818
PPO Batch Consumption Time: 0.11329
Total Iteration Time: 3.21918

Cumulative Model Updates: 1,352
Cumulative Timesteps: 22,606,944

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 22606944...
Checkpoint 22606944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00403
Policy Entropy: 4.46769
Value Function Loss: 0.07687

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10342
Value Function Update Magnitude: 0.07278

Collected Steps per Second: 24,231.91963
Overall Steps per Second: 17,744.61097

Timestep Collection Time: 2.06339
Timestep Consumption Time: 0.75436
PPO Batch Consumption Time: 0.05872
Total Iteration Time: 2.81776

Cumulative Model Updates: 1,355
Cumulative Timesteps: 22,656,944

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09267
Policy Entropy: 4.46668
Value Function Loss: 0.06746

Mean KL Divergence: 0.00026
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10354
Value Function Update Magnitude: 0.07203

Collected Steps per Second: 21,643.08743
Overall Steps per Second: 14,942.99022

Timestep Collection Time: 2.31085
Timestep Consumption Time: 1.03613
PPO Batch Consumption Time: 0.12333
Total Iteration Time: 3.34699

Cumulative Model Updates: 1,358
Cumulative Timesteps: 22,706,958

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 22706958...
Checkpoint 22706958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00719
Policy Entropy: 4.46546
Value Function Loss: 0.05120

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09517
Value Function Update Magnitude: 0.06117

Collected Steps per Second: 21,769.39383
Overall Steps per Second: 15,777.92945

Timestep Collection Time: 2.29708
Timestep Consumption Time: 0.87229
PPO Batch Consumption Time: 0.07722
Total Iteration Time: 3.16936

Cumulative Model Updates: 1,361
Cumulative Timesteps: 22,756,964

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02387
Policy Entropy: 4.46465
Value Function Loss: 0.05595

Mean KL Divergence: 0.00026
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09191
Value Function Update Magnitude: 0.05634

Collected Steps per Second: 21,507.17533
Overall Steps per Second: 16,207.93189

Timestep Collection Time: 2.32508
Timestep Consumption Time: 0.76020
PPO Batch Consumption Time: 0.06607
Total Iteration Time: 3.08528

Cumulative Model Updates: 1,364
Cumulative Timesteps: 22,806,970

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 22806970...
Checkpoint 22806970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01529
Policy Entropy: 4.46568
Value Function Loss: 0.05471

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09324
Value Function Update Magnitude: 0.06804

Collected Steps per Second: 21,977.54576
Overall Steps per Second: 15,802.91124

Timestep Collection Time: 2.27523
Timestep Consumption Time: 0.88900
PPO Batch Consumption Time: 0.07220
Total Iteration Time: 3.16423

Cumulative Model Updates: 1,367
Cumulative Timesteps: 22,856,974

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04063
Policy Entropy: 4.46780
Value Function Loss: 0.04761

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09104
Value Function Update Magnitude: 0.05919

Collected Steps per Second: 21,403.19303
Overall Steps per Second: 16,341.09724

Timestep Collection Time: 2.33666
Timestep Consumption Time: 0.72384
PPO Batch Consumption Time: 0.05807
Total Iteration Time: 3.06050

Cumulative Model Updates: 1,370
Cumulative Timesteps: 22,906,986

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 22906986...
Checkpoint 22906986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02723
Policy Entropy: 4.47105
Value Function Loss: 0.04234

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08472
Value Function Update Magnitude: 0.05515

Collected Steps per Second: 23,995.22628
Overall Steps per Second: 16,285.33914

Timestep Collection Time: 2.08491
Timestep Consumption Time: 0.98705
PPO Batch Consumption Time: 0.10053
Total Iteration Time: 3.07197

Cumulative Model Updates: 1,373
Cumulative Timesteps: 22,957,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02544
Policy Entropy: 4.47338
Value Function Loss: 0.04001

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08075
Value Function Update Magnitude: 0.06503

Collected Steps per Second: 22,310.09579
Overall Steps per Second: 16,445.62664

Timestep Collection Time: 2.24203
Timestep Consumption Time: 0.79950
PPO Batch Consumption Time: 0.05924
Total Iteration Time: 3.04154

Cumulative Model Updates: 1,376
Cumulative Timesteps: 23,007,034

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 23007034...
Checkpoint 23007034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04716
Policy Entropy: 4.47525
Value Function Loss: 0.04561

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07456
Value Function Update Magnitude: 0.05630

Collected Steps per Second: 22,032.21269
Overall Steps per Second: 16,035.24266

Timestep Collection Time: 2.27086
Timestep Consumption Time: 0.84927
PPO Batch Consumption Time: 0.09831
Total Iteration Time: 3.12013

Cumulative Model Updates: 1,379
Cumulative Timesteps: 23,057,066

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04018
Policy Entropy: 4.47637
Value Function Loss: 0.04746

Mean KL Divergence: 0.00018
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07690
Value Function Update Magnitude: 0.04874

Collected Steps per Second: 24,878.72307
Overall Steps per Second: 16,791.04722

Timestep Collection Time: 2.01015
Timestep Consumption Time: 0.96822
PPO Batch Consumption Time: 0.11095
Total Iteration Time: 2.97837

Cumulative Model Updates: 1,382
Cumulative Timesteps: 23,107,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 23107076...
Checkpoint 23107076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01397
Policy Entropy: 4.47689
Value Function Loss: 0.05674

Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07655
Value Function Update Magnitude: 0.05941

Collected Steps per Second: 24,787.79109
Overall Steps per Second: 17,817.96981

Timestep Collection Time: 2.01793
Timestep Consumption Time: 0.78935
PPO Batch Consumption Time: 0.07678
Total Iteration Time: 2.80728

Cumulative Model Updates: 1,385
Cumulative Timesteps: 23,157,096

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01557
Policy Entropy: 4.47717
Value Function Loss: 0.05848

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07882
Value Function Update Magnitude: 0.05207

Collected Steps per Second: 25,085.16250
Overall Steps per Second: 17,863.55880

Timestep Collection Time: 1.99369
Timestep Consumption Time: 0.80598
PPO Batch Consumption Time: 0.05879
Total Iteration Time: 2.79967

Cumulative Model Updates: 1,388
Cumulative Timesteps: 23,207,108

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 23207108...
Checkpoint 23207108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01217
Policy Entropy: 4.47767
Value Function Loss: 0.07338

Mean KL Divergence: 0.00013
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08475
Value Function Update Magnitude: 0.05673

Collected Steps per Second: 19,749.20398
Overall Steps per Second: 14,791.38350

Timestep Collection Time: 2.53246
Timestep Consumption Time: 0.84884
PPO Batch Consumption Time: 0.07607
Total Iteration Time: 3.38129

Cumulative Model Updates: 1,391
Cumulative Timesteps: 23,257,122

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04629
Policy Entropy: 4.47811
Value Function Loss: 0.07533

Mean KL Divergence: 0.00014
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08527
Value Function Update Magnitude: 0.06212

Collected Steps per Second: 25,105.74321
Overall Steps per Second: 17,961.73465

Timestep Collection Time: 1.99174
Timestep Consumption Time: 0.79218
PPO Batch Consumption Time: 0.07553
Total Iteration Time: 2.78392

Cumulative Model Updates: 1,394
Cumulative Timesteps: 23,307,126

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 23307126...
Checkpoint 23307126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02526
Policy Entropy: 4.47860
Value Function Loss: 0.06773

Mean KL Divergence: 0.00013
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08493
Value Function Update Magnitude: 0.06098

Collected Steps per Second: 25,099.54509
Overall Steps per Second: 17,776.19363

Timestep Collection Time: 1.99334
Timestep Consumption Time: 0.82121
PPO Batch Consumption Time: 0.06496
Total Iteration Time: 2.81455

Cumulative Model Updates: 1,397
Cumulative Timesteps: 23,357,158

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01330
Policy Entropy: 4.47865
Value Function Loss: 0.05556

Mean KL Divergence: 0.00011
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07940
Value Function Update Magnitude: 0.05326

Collected Steps per Second: 19,394.74047
Overall Steps per Second: 14,699.29166

Timestep Collection Time: 2.57895
Timestep Consumption Time: 0.82380
PPO Batch Consumption Time: 0.07840
Total Iteration Time: 3.40275

Cumulative Model Updates: 1,400
Cumulative Timesteps: 23,407,176

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 23407176...
Checkpoint 23407176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03314
Policy Entropy: 4.47873
Value Function Loss: 0.05236

Mean KL Divergence: 0.00009
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07641
Value Function Update Magnitude: 0.06309

Collected Steps per Second: 21,984.44267
Overall Steps per Second: 16,383.77248

Timestep Collection Time: 2.27561
Timestep Consumption Time: 0.77790
PPO Batch Consumption Time: 0.03881
Total Iteration Time: 3.05351

Cumulative Model Updates: 1,403
Cumulative Timesteps: 23,457,204

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04188
Policy Entropy: 4.47808
Value Function Loss: 0.05785

Mean KL Divergence: 0.00009
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07909
Value Function Update Magnitude: 0.04501

Collected Steps per Second: 23,152.18156
Overall Steps per Second: 17,484.39308

Timestep Collection Time: 2.15962
Timestep Consumption Time: 0.70007
PPO Batch Consumption Time: 0.02858
Total Iteration Time: 2.85969

Cumulative Model Updates: 1,406
Cumulative Timesteps: 23,507,204

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 23507204...
Checkpoint 23507204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02522
Policy Entropy: 4.47678
Value Function Loss: 0.06595

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08018
Value Function Update Magnitude: 0.03792

Collected Steps per Second: 22,030.51430
Overall Steps per Second: 16,356.16768

Timestep Collection Time: 2.27085
Timestep Consumption Time: 0.78781
PPO Batch Consumption Time: 0.06992
Total Iteration Time: 3.05866

Cumulative Model Updates: 1,409
Cumulative Timesteps: 23,557,232

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01620
Policy Entropy: 4.47613
Value Function Loss: 0.07917

Mean KL Divergence: 0.00009
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08041
Value Function Update Magnitude: 0.04017

Collected Steps per Second: 22,152.46526
Overall Steps per Second: 16,756.06766

Timestep Collection Time: 2.25727
Timestep Consumption Time: 0.72697
PPO Batch Consumption Time: 0.02895
Total Iteration Time: 2.98423

Cumulative Model Updates: 1,412
Cumulative Timesteps: 23,607,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 23607236...
Checkpoint 23607236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00751
Policy Entropy: 4.47612
Value Function Loss: 0.07881

Mean KL Divergence: 0.00007
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08580
Value Function Update Magnitude: 0.04149

Collected Steps per Second: 21,121.50712
Overall Steps per Second: 15,773.07747

Timestep Collection Time: 2.36934
Timestep Consumption Time: 0.80341
PPO Batch Consumption Time: 0.08045
Total Iteration Time: 3.17275

Cumulative Model Updates: 1,415
Cumulative Timesteps: 23,657,280

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05132
Policy Entropy: 4.47699
Value Function Loss: 0.06195

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09099
Value Function Update Magnitude: 0.03895

Collected Steps per Second: 23,657.21599
Overall Steps per Second: 17,735.46536

Timestep Collection Time: 2.11386
Timestep Consumption Time: 0.70580
PPO Batch Consumption Time: 0.02911
Total Iteration Time: 2.81966

Cumulative Model Updates: 1,418
Cumulative Timesteps: 23,707,288

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 23707288...
Checkpoint 23707288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00270
Policy Entropy: 4.47804
Value Function Loss: 0.05850

Mean KL Divergence: 0.00010
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08838
Value Function Update Magnitude: 0.04247

Collected Steps per Second: 24,649.75921
Overall Steps per Second: 18,258.38810

Timestep Collection Time: 2.02890
Timestep Consumption Time: 0.71022
PPO Batch Consumption Time: 0.03021
Total Iteration Time: 2.73912

Cumulative Model Updates: 1,421
Cumulative Timesteps: 23,757,300

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03747
Policy Entropy: 4.47885
Value Function Loss: 0.07872

Mean KL Divergence: 0.00009
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09123
Value Function Update Magnitude: 0.03471

Collected Steps per Second: 23,852.29550
Overall Steps per Second: 16,838.47837

Timestep Collection Time: 2.09640
Timestep Consumption Time: 0.87323
PPO Batch Consumption Time: 0.09561
Total Iteration Time: 2.96963

Cumulative Model Updates: 1,424
Cumulative Timesteps: 23,807,304

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 23807304...
Checkpoint 23807304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01464
Policy Entropy: 4.47797
Value Function Loss: 0.08525

Mean KL Divergence: 0.00014
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10294
Value Function Update Magnitude: 0.04179

Collected Steps per Second: 24,683.48161
Overall Steps per Second: 17,593.59451

Timestep Collection Time: 2.02605
Timestep Consumption Time: 0.81646
PPO Batch Consumption Time: 0.05888
Total Iteration Time: 2.84251

Cumulative Model Updates: 1,427
Cumulative Timesteps: 23,857,314

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03272
Policy Entropy: 4.47437
Value Function Loss: 0.07024

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00013
Policy Update Magnitude: 0.11248
Value Function Update Magnitude: 0.04425

Collected Steps per Second: 21,203.91924
Overall Steps per Second: 15,052.13056

Timestep Collection Time: 2.35834
Timestep Consumption Time: 0.96385
PPO Batch Consumption Time: 0.12251
Total Iteration Time: 3.32219

Cumulative Model Updates: 1,430
Cumulative Timesteps: 23,907,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 23907320...
Checkpoint 23907320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01627
Policy Entropy: 4.46960
Value Function Loss: 0.05701

Mean KL Divergence: 0.00088
SB3 Clip Fraction: 0.00299
Policy Update Magnitude: 0.10169
Value Function Update Magnitude: 0.03484

Collected Steps per Second: 24,417.07541
Overall Steps per Second: 16,683.97616

Timestep Collection Time: 2.04783
Timestep Consumption Time: 0.94918
PPO Batch Consumption Time: 0.10338
Total Iteration Time: 2.99701

Cumulative Model Updates: 1,433
Cumulative Timesteps: 23,957,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00199
Policy Entropy: 4.46607
Value Function Loss: 0.05700

Mean KL Divergence: 0.00080
SB3 Clip Fraction: 0.00279
Policy Update Magnitude: 0.09849
Value Function Update Magnitude: 0.03780

Collected Steps per Second: 24,376.94536
Overall Steps per Second: 16,732.73342

Timestep Collection Time: 2.05194
Timestep Consumption Time: 0.93741
PPO Batch Consumption Time: 0.10340
Total Iteration Time: 2.98935

Cumulative Model Updates: 1,436
Cumulative Timesteps: 24,007,342

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 24007342...
Checkpoint 24007342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03747
Policy Entropy: 4.46473
Value Function Loss: 0.05777

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00002
Policy Update Magnitude: 0.09578
Value Function Update Magnitude: 0.04066

Collected Steps per Second: 25,146.85168
Overall Steps per Second: 16,807.28685

Timestep Collection Time: 1.98912
Timestep Consumption Time: 0.98697
PPO Batch Consumption Time: 0.11643
Total Iteration Time: 2.97609

Cumulative Model Updates: 1,439
Cumulative Timesteps: 24,057,362

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05738
Policy Entropy: 4.46385
Value Function Loss: 0.04568

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09012
Value Function Update Magnitude: 0.03697

Collected Steps per Second: 23,433.12846
Overall Steps per Second: 16,948.83680

Timestep Collection Time: 2.13544
Timestep Consumption Time: 0.81698
PPO Batch Consumption Time: 0.02915
Total Iteration Time: 2.95241

Cumulative Model Updates: 1,442
Cumulative Timesteps: 24,107,402

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 24107402...
Checkpoint 24107402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03782
Policy Entropy: 4.46262
Value Function Loss: 0.05879

Mean KL Divergence: 0.00017
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08527
Value Function Update Magnitude: 0.03812

Collected Steps per Second: 22,345.33350
Overall Steps per Second: 17,409.03994

Timestep Collection Time: 2.23850
Timestep Consumption Time: 0.63472
PPO Batch Consumption Time: 0.02958
Total Iteration Time: 2.87322

Cumulative Model Updates: 1,445
Cumulative Timesteps: 24,157,422

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00681
Policy Entropy: 4.45964
Value Function Loss: 0.05460

Mean KL Divergence: 0.00020
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08756
Value Function Update Magnitude: 0.04470

Collected Steps per Second: 24,108.39010
Overall Steps per Second: 16,883.81624

Timestep Collection Time: 2.07471
Timestep Consumption Time: 0.88777
PPO Batch Consumption Time: 0.07732
Total Iteration Time: 2.96248

Cumulative Model Updates: 1,448
Cumulative Timesteps: 24,207,440

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 24207440...
Checkpoint 24207440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00493
Policy Entropy: 4.45500
Value Function Loss: 0.07408

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.09646
Value Function Update Magnitude: 0.04078

Collected Steps per Second: 24,024.68454
Overall Steps per Second: 17,339.03699

Timestep Collection Time: 2.08227
Timestep Consumption Time: 0.80289
PPO Batch Consumption Time: 0.06139
Total Iteration Time: 2.88517

Cumulative Model Updates: 1,451
Cumulative Timesteps: 24,257,466

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00241
Policy Entropy: 4.44687
Value Function Loss: 0.06832

Mean KL Divergence: 0.00089
SB3 Clip Fraction: 0.00091
Policy Update Magnitude: 0.09934
Value Function Update Magnitude: 0.05665

Collected Steps per Second: 23,898.97147
Overall Steps per Second: 17,210.75937

Timestep Collection Time: 2.09298
Timestep Consumption Time: 0.81334
PPO Batch Consumption Time: 0.08482
Total Iteration Time: 2.90632

Cumulative Model Updates: 1,454
Cumulative Timesteps: 24,307,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 24307486...
Checkpoint 24307486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00062
Policy Entropy: 4.43651
Value Function Loss: 0.08313

Mean KL Divergence: 0.00151
SB3 Clip Fraction: 0.00743
Policy Update Magnitude: 0.10773
Value Function Update Magnitude: 0.05118

Collected Steps per Second: 23,956.46178
Overall Steps per Second: 17,325.14673

Timestep Collection Time: 2.08745
Timestep Consumption Time: 0.79899
PPO Batch Consumption Time: 0.05948
Total Iteration Time: 2.88644

Cumulative Model Updates: 1,457
Cumulative Timesteps: 24,357,494

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08196
Policy Entropy: 4.42983
Value Function Loss: 0.06877

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.00423
Policy Update Magnitude: 0.10262
Value Function Update Magnitude: 0.04429

Collected Steps per Second: 24,135.83763
Overall Steps per Second: 17,855.28088

Timestep Collection Time: 2.07169
Timestep Consumption Time: 0.72871
PPO Batch Consumption Time: 0.06403
Total Iteration Time: 2.80040

Cumulative Model Updates: 1,460
Cumulative Timesteps: 24,407,496

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 24407496...
Checkpoint 24407496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03154
Policy Entropy: 4.42742
Value Function Loss: 0.06608

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00025
Policy Update Magnitude: 0.10284
Value Function Update Magnitude: 0.04536

Collected Steps per Second: 24,232.34443
Overall Steps per Second: 17,972.47548

Timestep Collection Time: 2.06377
Timestep Consumption Time: 0.71882
PPO Batch Consumption Time: 0.02969
Total Iteration Time: 2.78259

Cumulative Model Updates: 1,463
Cumulative Timesteps: 24,457,506

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01335
Policy Entropy: 4.42342
Value Function Loss: 0.06111

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09679
Value Function Update Magnitude: 0.04495

Collected Steps per Second: 24,781.98113
Overall Steps per Second: 18,525.62523

Timestep Collection Time: 2.01864
Timestep Consumption Time: 0.68172
PPO Batch Consumption Time: 0.02945
Total Iteration Time: 2.70037

Cumulative Model Updates: 1,466
Cumulative Timesteps: 24,507,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 24507532...
Checkpoint 24507532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02032
Policy Entropy: 4.41874
Value Function Loss: 0.07799

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00002
Policy Update Magnitude: 0.09722
Value Function Update Magnitude: 0.04882

Collected Steps per Second: 23,733.36746
Overall Steps per Second: 17,007.95531

Timestep Collection Time: 2.10741
Timestep Consumption Time: 0.83333
PPO Batch Consumption Time: 0.09098
Total Iteration Time: 2.94074

Cumulative Model Updates: 1,469
Cumulative Timesteps: 24,557,548

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04249
Policy Entropy: 4.42054
Value Function Loss: 0.08029

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10262
Value Function Update Magnitude: 0.04657

Collected Steps per Second: 24,757.95610
Overall Steps per Second: 17,722.92492

Timestep Collection Time: 2.01963
Timestep Consumption Time: 0.80168
PPO Batch Consumption Time: 0.06086
Total Iteration Time: 2.82132

Cumulative Model Updates: 1,472
Cumulative Timesteps: 24,607,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 24607550...
Checkpoint 24607550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02700
Policy Entropy: 4.42707
Value Function Loss: 0.07712

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00009
Policy Update Magnitude: 0.11157
Value Function Update Magnitude: 0.04571

Collected Steps per Second: 21,018.56027
Overall Steps per Second: 14,955.07659

Timestep Collection Time: 2.37885
Timestep Consumption Time: 0.96450
PPO Batch Consumption Time: 0.11157
Total Iteration Time: 3.34335

Cumulative Model Updates: 1,475
Cumulative Timesteps: 24,657,550

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01002
Policy Entropy: 4.43525
Value Function Loss: 0.06424

Mean KL Divergence: 0.00101
SB3 Clip Fraction: 0.00243
Policy Update Magnitude: 0.10947
Value Function Update Magnitude: 0.04819

Collected Steps per Second: 25,448.67774
Overall Steps per Second: 18,142.32714

Timestep Collection Time: 1.96490
Timestep Consumption Time: 0.79131
PPO Batch Consumption Time: 0.06110
Total Iteration Time: 2.75621

Cumulative Model Updates: 1,478
Cumulative Timesteps: 24,707,554

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 24707554...
Checkpoint 24707554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01708
Policy Entropy: 4.44268
Value Function Loss: 0.05655

Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.00451
Policy Update Magnitude: 0.10539
Value Function Update Magnitude: 0.04369

Collected Steps per Second: 24,571.68885
Overall Steps per Second: 18,245.91484

Timestep Collection Time: 2.03584
Timestep Consumption Time: 0.70582
PPO Batch Consumption Time: 0.02947
Total Iteration Time: 2.74165

Cumulative Model Updates: 1,481
Cumulative Timesteps: 24,757,578

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00505
Policy Entropy: 4.44688
Value Function Loss: 0.05111

Mean KL Divergence: 0.00086
SB3 Clip Fraction: 0.00222
Policy Update Magnitude: 0.09897
Value Function Update Magnitude: 0.05689

Collected Steps per Second: 24,735.99585
Overall Steps per Second: 18,688.85511

Timestep Collection Time: 2.02248
Timestep Consumption Time: 0.65441
PPO Batch Consumption Time: 0.03753
Total Iteration Time: 2.67689

Cumulative Model Updates: 1,484
Cumulative Timesteps: 24,807,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 24807606...
Checkpoint 24807606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03379
Policy Entropy: 4.44797
Value Function Loss: 0.06625

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00007
Policy Update Magnitude: 0.09616
Value Function Update Magnitude: 0.05080

Collected Steps per Second: 21,983.07533
Overall Steps per Second: 15,612.65634

Timestep Collection Time: 2.27593
Timestep Consumption Time: 0.92865
PPO Batch Consumption Time: 0.08569
Total Iteration Time: 3.20458

Cumulative Model Updates: 1,487
Cumulative Timesteps: 24,857,638

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01425
Policy Entropy: 4.44886
Value Function Loss: 0.07351

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.10074
Value Function Update Magnitude: 0.04213

Collected Steps per Second: 22,260.63408
Overall Steps per Second: 16,754.15545

Timestep Collection Time: 2.24630
Timestep Consumption Time: 0.73828
PPO Batch Consumption Time: 0.05043
Total Iteration Time: 2.98457

Cumulative Model Updates: 1,490
Cumulative Timesteps: 24,907,642

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 24907642...
Checkpoint 24907642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03164
Policy Entropy: 4.44814
Value Function Loss: 0.07153

Mean KL Divergence: 0.00024
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10602
Value Function Update Magnitude: 0.05774

Collected Steps per Second: 23,362.64230
Overall Steps per Second: 15,905.55069

Timestep Collection Time: 2.14043
Timestep Consumption Time: 1.00351
PPO Batch Consumption Time: 0.11954
Total Iteration Time: 3.14393

Cumulative Model Updates: 1,493
Cumulative Timesteps: 24,957,648

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00271
Policy Entropy: 4.44628
Value Function Loss: 0.06094

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10233
Value Function Update Magnitude: 0.05072

Collected Steps per Second: 25,382.15471
Overall Steps per Second: 18,121.02409

Timestep Collection Time: 1.97028
Timestep Consumption Time: 0.78950
PPO Batch Consumption Time: 0.06308
Total Iteration Time: 2.75978

Cumulative Model Updates: 1,496
Cumulative Timesteps: 25,007,658

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 25007658...
Checkpoint 25007658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03781
Policy Entropy: 4.43915
Value Function Loss: 0.06061

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00014
Policy Update Magnitude: 0.10281
Value Function Update Magnitude: 0.05633

Collected Steps per Second: 25,002.41802
Overall Steps per Second: 18,405.94033

Timestep Collection Time: 2.00061
Timestep Consumption Time: 0.71699
PPO Batch Consumption Time: 0.05956
Total Iteration Time: 2.71760

Cumulative Model Updates: 1,499
Cumulative Timesteps: 25,057,678

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00125
Policy Entropy: 4.42944
Value Function Loss: 0.08342

Mean KL Divergence: 0.00106
SB3 Clip Fraction: 0.00316
Policy Update Magnitude: 0.10118
Value Function Update Magnitude: 0.06820

Collected Steps per Second: 22,721.92368
Overall Steps per Second: 16,066.73392

Timestep Collection Time: 2.20175
Timestep Consumption Time: 0.91201
PPO Batch Consumption Time: 0.09172
Total Iteration Time: 3.11376

Cumulative Model Updates: 1,502
Cumulative Timesteps: 25,107,706

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 25107706...
Checkpoint 25107706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07300
Policy Entropy: 4.42231
Value Function Loss: 0.08675

Mean KL Divergence: 0.00094
SB3 Clip Fraction: 0.00323
Policy Update Magnitude: 0.10160
Value Function Update Magnitude: 0.07560

Collected Steps per Second: 22,155.12540
Overall Steps per Second: 15,620.23895

Timestep Collection Time: 2.25690
Timestep Consumption Time: 0.94420
PPO Batch Consumption Time: 0.10104
Total Iteration Time: 3.20110

Cumulative Model Updates: 1,505
Cumulative Timesteps: 25,157,708

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00438
Policy Entropy: 4.42138
Value Function Loss: 0.10693

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00011
Policy Update Magnitude: 0.11211
Value Function Update Magnitude: 0.07920

Collected Steps per Second: 23,378.17587
Overall Steps per Second: 17,072.69484

Timestep Collection Time: 2.13900
Timestep Consumption Time: 0.79000
PPO Batch Consumption Time: 0.06206
Total Iteration Time: 2.92900

Cumulative Model Updates: 1,508
Cumulative Timesteps: 25,207,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 25207714...
Checkpoint 25207714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00204
Policy Entropy: 4.42607
Value Function Loss: 0.07843

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00008
Policy Update Magnitude: 0.11643
Value Function Update Magnitude: 0.08734

Collected Steps per Second: 25,527.06141
Overall Steps per Second: 17,982.65173

Timestep Collection Time: 1.95972
Timestep Consumption Time: 0.82218
PPO Batch Consumption Time: 0.06263
Total Iteration Time: 2.78190

Cumulative Model Updates: 1,511
Cumulative Timesteps: 25,257,740

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01220
Policy Entropy: 4.42763
Value Function Loss: 0.06814

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00009
Policy Update Magnitude: 0.11333
Value Function Update Magnitude: 0.08605

Collected Steps per Second: 24,536.33960
Overall Steps per Second: 17,619.61601

Timestep Collection Time: 2.03869
Timestep Consumption Time: 0.80030
PPO Batch Consumption Time: 0.07915
Total Iteration Time: 2.83899

Cumulative Model Updates: 1,514
Cumulative Timesteps: 25,307,762

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 25307762...
Checkpoint 25307762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03621
Policy Entropy: 4.42522
Value Function Loss: 0.06515

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00020
Policy Update Magnitude: 0.10337
Value Function Update Magnitude: 0.07682

Collected Steps per Second: 22,681.62810
Overall Steps per Second: 16,570.83738

Timestep Collection Time: 2.20478
Timestep Consumption Time: 0.81305
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 3.01783

Cumulative Model Updates: 1,517
Cumulative Timesteps: 25,357,770

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15539
Policy Entropy: 4.41829
Value Function Loss: 0.07882

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00118
Policy Update Magnitude: 0.09949
Value Function Update Magnitude: 0.07564

Collected Steps per Second: 21,527.91106
Overall Steps per Second: 16,452.38595

Timestep Collection Time: 2.32377
Timestep Consumption Time: 0.71688
PPO Batch Consumption Time: 0.02991
Total Iteration Time: 3.04065

Cumulative Model Updates: 1,520
Cumulative Timesteps: 25,407,796

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 25407796...
Checkpoint 25407796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02407
Policy Entropy: 4.41431
Value Function Loss: 0.09211

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00065
Policy Update Magnitude: 0.10546
Value Function Update Magnitude: 0.07282

Collected Steps per Second: 25,551.36154
Overall Steps per Second: 17,269.66088

Timestep Collection Time: 1.95739
Timestep Consumption Time: 0.93867
PPO Batch Consumption Time: 0.10466
Total Iteration Time: 2.89606

Cumulative Model Updates: 1,523
Cumulative Timesteps: 25,457,810

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05283
Policy Entropy: 4.41648
Value Function Loss: 0.07405

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.11124
Value Function Update Magnitude: 0.07533

Collected Steps per Second: 23,306.68416
Overall Steps per Second: 16,800.47748

Timestep Collection Time: 2.14591
Timestep Consumption Time: 0.83103
PPO Batch Consumption Time: 0.06545
Total Iteration Time: 2.97694

Cumulative Model Updates: 1,526
Cumulative Timesteps: 25,507,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 25507824...
Checkpoint 25507824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02615
Policy Entropy: 4.41756
Value Function Loss: 0.07478

Mean KL Divergence: 0.00068
SB3 Clip Fraction: 0.00073
Policy Update Magnitude: 0.11097
Value Function Update Magnitude: 0.07497

Collected Steps per Second: 24,058.45240
Overall Steps per Second: 18,461.45194

Timestep Collection Time: 2.07944
Timestep Consumption Time: 0.63043
PPO Batch Consumption Time: 0.02951
Total Iteration Time: 2.70986

Cumulative Model Updates: 1,529
Cumulative Timesteps: 25,557,852

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04498
Policy Entropy: 4.41863
Value Function Loss: 0.07320

Mean KL Divergence: 0.00061
SB3 Clip Fraction: 0.00075
Policy Update Magnitude: 0.10472
Value Function Update Magnitude: 0.07184

Collected Steps per Second: 24,682.14254
Overall Steps per Second: 17,782.83252

Timestep Collection Time: 2.02665
Timestep Consumption Time: 0.78629
PPO Batch Consumption Time: 0.05084
Total Iteration Time: 2.81294

Cumulative Model Updates: 1,532
Cumulative Timesteps: 25,607,874

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 25607874...
Checkpoint 25607874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00665
Policy Entropy: 4.41843
Value Function Loss: 0.07309

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00004
Policy Update Magnitude: 0.10405
Value Function Update Magnitude: 0.07498

Collected Steps per Second: 23,979.69338
Overall Steps per Second: 18,008.56984

Timestep Collection Time: 2.08610
Timestep Consumption Time: 0.69169
PPO Batch Consumption Time: 0.02914
Total Iteration Time: 2.77779

Cumulative Model Updates: 1,535
Cumulative Timesteps: 25,657,898

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03264
Policy Entropy: 4.42104
Value Function Loss: 0.06320

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.10168
Value Function Update Magnitude: 0.07510

Collected Steps per Second: 22,421.31376
Overall Steps per Second: 16,777.37288

Timestep Collection Time: 2.23252
Timestep Consumption Time: 0.75102
PPO Batch Consumption Time: 0.04853
Total Iteration Time: 2.98354

Cumulative Model Updates: 1,538
Cumulative Timesteps: 25,707,954

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 25707954...
Checkpoint 25707954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00264
Policy Entropy: 4.42496
Value Function Loss: 0.05108

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00009
Policy Update Magnitude: 0.09445
Value Function Update Magnitude: 0.07104

Collected Steps per Second: 24,674.66713
Overall Steps per Second: 16,466.88128

Timestep Collection Time: 2.02742
Timestep Consumption Time: 1.01055
PPO Batch Consumption Time: 0.12517
Total Iteration Time: 3.03798

Cumulative Model Updates: 1,541
Cumulative Timesteps: 25,757,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02519
Policy Entropy: 4.43072
Value Function Loss: 0.04628

Mean KL Divergence: 0.00071
SB3 Clip Fraction: 0.00154
Policy Update Magnitude: 0.09210
Value Function Update Magnitude: 0.05643

Collected Steps per Second: 26,007.54275
Overall Steps per Second: 19,225.12390

Timestep Collection Time: 1.92360
Timestep Consumption Time: 0.67862
PPO Batch Consumption Time: 0.05319
Total Iteration Time: 2.60222

Cumulative Model Updates: 1,544
Cumulative Timesteps: 25,808,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 25808008...
Checkpoint 25808008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01349
Policy Entropy: 4.43591
Value Function Loss: 0.04120

Mean KL Divergence: 0.00065
SB3 Clip Fraction: 0.00106
Policy Update Magnitude: 0.08699
Value Function Update Magnitude: 0.05007

Collected Steps per Second: 23,501.37723
Overall Steps per Second: 16,657.53127

Timestep Collection Time: 2.12822
Timestep Consumption Time: 0.87439
PPO Batch Consumption Time: 0.08435
Total Iteration Time: 3.00261

Cumulative Model Updates: 1,547
Cumulative Timesteps: 25,858,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02857
Policy Entropy: 4.44021
Value Function Loss: 0.05432

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00063
Policy Update Magnitude: 0.08830
Value Function Update Magnitude: 0.05530

Collected Steps per Second: 25,634.50473
Overall Steps per Second: 17,895.90129

Timestep Collection Time: 1.95112
Timestep Consumption Time: 0.84371
PPO Batch Consumption Time: 0.07901
Total Iteration Time: 2.79483

Cumulative Model Updates: 1,550
Cumulative Timesteps: 25,908,040

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 25908040...
Checkpoint 25908040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03960
Policy Entropy: 4.44537
Value Function Loss: 0.05668

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00015
Policy Update Magnitude: 0.09002
Value Function Update Magnitude: 0.07129

Collected Steps per Second: 26,433.91126
Overall Steps per Second: 18,779.03812

Timestep Collection Time: 1.89212
Timestep Consumption Time: 0.77128
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 2.66340

Cumulative Model Updates: 1,553
Cumulative Timesteps: 25,958,056

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02300
Policy Entropy: 4.45112
Value Function Loss: 0.07665

Mean KL Divergence: 0.00065
SB3 Clip Fraction: 0.00018
Policy Update Magnitude: 0.09639
Value Function Update Magnitude: 0.09525

Collected Steps per Second: 22,396.02134
Overall Steps per Second: 15,917.45969

Timestep Collection Time: 2.23263
Timestep Consumption Time: 0.90870
PPO Batch Consumption Time: 0.09719
Total Iteration Time: 3.14133

Cumulative Model Updates: 1,556
Cumulative Timesteps: 26,008,058

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 26008058...
Checkpoint 26008058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00699
Policy Entropy: 4.45508
Value Function Loss: 0.07759

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00011
Policy Update Magnitude: 0.09848
Value Function Update Magnitude: 0.10107

Collected Steps per Second: 25,192.91664
Overall Steps per Second: 18,590.54190

Timestep Collection Time: 1.98500
Timestep Consumption Time: 0.70497
PPO Batch Consumption Time: 0.05807
Total Iteration Time: 2.68997

Cumulative Model Updates: 1,559
Cumulative Timesteps: 26,058,066

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08452
Policy Entropy: 4.45896
Value Function Loss: 0.06526

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00005
Policy Update Magnitude: 0.10489
Value Function Update Magnitude: 0.09295

Collected Steps per Second: 25,889.27592
Overall Steps per Second: 18,436.92692

Timestep Collection Time: 1.93130
Timestep Consumption Time: 0.78065
PPO Batch Consumption Time: 0.06003
Total Iteration Time: 2.71195

Cumulative Model Updates: 1,562
Cumulative Timesteps: 26,108,066

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 26108066...
Checkpoint 26108066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04103
Policy Entropy: 4.46119
Value Function Loss: 0.04675

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.09942
Value Function Update Magnitude: 0.08430

Collected Steps per Second: 22,450.72373
Overall Steps per Second: 16,017.10524

Timestep Collection Time: 2.22763
Timestep Consumption Time: 0.89478
PPO Batch Consumption Time: 0.10105
Total Iteration Time: 3.12241

Cumulative Model Updates: 1,565
Cumulative Timesteps: 26,158,078

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01034
Policy Entropy: 4.46302
Value Function Loss: 0.03534

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00005
Policy Update Magnitude: 0.08693
Value Function Update Magnitude: 0.07281

Collected Steps per Second: 25,438.60792
Overall Steps per Second: 18,742.04323

Timestep Collection Time: 1.96567
Timestep Consumption Time: 0.70234
PPO Batch Consumption Time: 0.05897
Total Iteration Time: 2.66801

Cumulative Model Updates: 1,568
Cumulative Timesteps: 26,208,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 26208082...
Checkpoint 26208082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01658
Policy Entropy: 4.46464
Value Function Loss: 0.04475

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00011
Policy Update Magnitude: 0.08384
Value Function Update Magnitude: 0.06133

Collected Steps per Second: 23,185.65954
Overall Steps per Second: 16,112.88507

Timestep Collection Time: 2.15651
Timestep Consumption Time: 0.94660
PPO Batch Consumption Time: 0.10837
Total Iteration Time: 3.10311

Cumulative Model Updates: 1,571
Cumulative Timesteps: 26,258,082

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02687
Policy Entropy: 4.46662
Value Function Loss: 0.03669

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00020
Policy Update Magnitude: 0.08592
Value Function Update Magnitude: 0.06329

Collected Steps per Second: 25,834.54823
Overall Steps per Second: 18,592.96546

Timestep Collection Time: 1.93563
Timestep Consumption Time: 0.75389
PPO Batch Consumption Time: 0.06036
Total Iteration Time: 2.68951

Cumulative Model Updates: 1,574
Cumulative Timesteps: 26,308,088

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 26308088...
Checkpoint 26308088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00411
Policy Entropy: 4.46806
Value Function Loss: 0.02765

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00021
Policy Update Magnitude: 0.08261
Value Function Update Magnitude: 0.06462

Collected Steps per Second: 23,660.18481
Overall Steps per Second: 16,286.64813

Timestep Collection Time: 2.11427
Timestep Consumption Time: 0.95720
PPO Batch Consumption Time: 0.11758
Total Iteration Time: 3.07147

Cumulative Model Updates: 1,577
Cumulative Timesteps: 26,358,112

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01420
Policy Entropy: 4.46919
Value Function Loss: 0.02991

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00016
Policy Update Magnitude: 0.07487
Value Function Update Magnitude: 0.06550

Collected Steps per Second: 25,734.55929
Overall Steps per Second: 17,746.14018

Timestep Collection Time: 1.94423
Timestep Consumption Time: 0.87520
PPO Batch Consumption Time: 0.08191
Total Iteration Time: 2.81943

Cumulative Model Updates: 1,580
Cumulative Timesteps: 26,408,146

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 26408146...
Checkpoint 26408146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04659
Policy Entropy: 4.47081
Value Function Loss: 0.03994

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00012
Policy Update Magnitude: 0.07174
Value Function Update Magnitude: 0.04997

Collected Steps per Second: 24,975.10428
Overall Steps per Second: 18,534.35985

Timestep Collection Time: 2.00295
Timestep Consumption Time: 0.69603
PPO Batch Consumption Time: 0.05795
Total Iteration Time: 2.69899

Cumulative Model Updates: 1,583
Cumulative Timesteps: 26,458,170

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00559
Policy Entropy: 4.47241
Value Function Loss: 0.05660

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00002
Policy Update Magnitude: 0.07613
Value Function Update Magnitude: 0.07191

Collected Steps per Second: 25,133.41858
Overall Steps per Second: 18,038.31210

Timestep Collection Time: 1.98994
Timestep Consumption Time: 0.78271
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 2.77265

Cumulative Model Updates: 1,586
Cumulative Timesteps: 26,508,184

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 26508184...
Checkpoint 26508184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04736
Policy Entropy: 4.47397
Value Function Loss: 0.05192

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08124
Value Function Update Magnitude: 0.08641

Collected Steps per Second: 23,232.66819
Overall Steps per Second: 16,261.76843

Timestep Collection Time: 2.15249
Timestep Consumption Time: 0.92270
PPO Batch Consumption Time: 0.10501
Total Iteration Time: 3.07519

Cumulative Model Updates: 1,589
Cumulative Timesteps: 26,558,192

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04460
Policy Entropy: 4.47606
Value Function Loss: 0.04632

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08985
Value Function Update Magnitude: 0.06485

Collected Steps per Second: 26,777.19858
Overall Steps per Second: 17,909.13066

Timestep Collection Time: 1.86808
Timestep Consumption Time: 0.92502
PPO Batch Consumption Time: 0.10250
Total Iteration Time: 2.79310

Cumulative Model Updates: 1,592
Cumulative Timesteps: 26,608,214

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 26608214...
Checkpoint 26608214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03030
Policy Entropy: 4.47771
Value Function Loss: 0.03898

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08731
Value Function Update Magnitude: 0.05781

Collected Steps per Second: 25,662.21473
Overall Steps per Second: 18,191.98850

Timestep Collection Time: 1.94839
Timestep Consumption Time: 0.80007
PPO Batch Consumption Time: 0.06140
Total Iteration Time: 2.74846

Cumulative Model Updates: 1,595
Cumulative Timesteps: 26,658,214

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03004
Policy Entropy: 4.47806
Value Function Loss: 0.03463

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08200
Value Function Update Magnitude: 0.04893

Collected Steps per Second: 24,651.86316
Overall Steps per Second: 17,889.79854

Timestep Collection Time: 2.02889
Timestep Consumption Time: 0.76689
PPO Batch Consumption Time: 0.06168
Total Iteration Time: 2.79578

Cumulative Model Updates: 1,598
Cumulative Timesteps: 26,708,230

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 26708230...
Checkpoint 26708230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00086
Policy Entropy: 4.47734
Value Function Loss: 0.04478

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.08130
Value Function Update Magnitude: 0.03959

Collected Steps per Second: 26,792.63061
Overall Steps per Second: 17,836.15544

Timestep Collection Time: 1.86618
Timestep Consumption Time: 0.93711
PPO Batch Consumption Time: 0.10333
Total Iteration Time: 2.80329

Cumulative Model Updates: 1,601
Cumulative Timesteps: 26,758,230

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01644
Policy Entropy: 4.47563
Value Function Loss: 0.05012

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00024
Policy Update Magnitude: 0.08313
Value Function Update Magnitude: 0.03432

Collected Steps per Second: 25,743.85512
Overall Steps per Second: 18,310.85408

Timestep Collection Time: 1.94392
Timestep Consumption Time: 0.78910
PPO Batch Consumption Time: 0.06114
Total Iteration Time: 2.73302

Cumulative Model Updates: 1,604
Cumulative Timesteps: 26,808,274

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 26808274...
Checkpoint 26808274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02275
Policy Entropy: 4.47278
Value Function Loss: 0.03967

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.09100
Value Function Update Magnitude: 0.03990

Collected Steps per Second: 25,454.80771
Overall Steps per Second: 18,709.61003

Timestep Collection Time: 1.96474
Timestep Consumption Time: 0.70833
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 2.67306

Cumulative Model Updates: 1,607
Cumulative Timesteps: 26,858,286

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00248
Policy Entropy: 4.46925
Value Function Loss: 0.03214

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08779
Value Function Update Magnitude: 0.04626

Collected Steps per Second: 22,588.46139
Overall Steps per Second: 15,815.58267

Timestep Collection Time: 2.21458
Timestep Consumption Time: 0.94837
PPO Batch Consumption Time: 0.11002
Total Iteration Time: 3.16296

Cumulative Model Updates: 1,610
Cumulative Timesteps: 26,908,310

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 26908310...
Checkpoint 26908310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01149
Policy Entropy: 4.46627
Value Function Loss: 0.04162

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08016
Value Function Update Magnitude: 0.05183

Collected Steps per Second: 25,548.23032
Overall Steps per Second: 17,874.19453

Timestep Collection Time: 1.95763
Timestep Consumption Time: 0.84048
PPO Batch Consumption Time: 0.09495
Total Iteration Time: 2.79811

Cumulative Model Updates: 1,613
Cumulative Timesteps: 26,958,324

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00725
Policy Entropy: 4.46480
Value Function Loss: 0.06135

Mean KL Divergence: 0.00020
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08613
Value Function Update Magnitude: 0.07406

Collected Steps per Second: 25,937.42652
Overall Steps per Second: 18,397.48565

Timestep Collection Time: 1.92856
Timestep Consumption Time: 0.79039
PPO Batch Consumption Time: 0.06026
Total Iteration Time: 2.71896

Cumulative Model Updates: 1,616
Cumulative Timesteps: 27,008,346

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 27008346...
Checkpoint 27008346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02080
Policy Entropy: 4.46488
Value Function Loss: 0.05866

Mean KL Divergence: 0.00014
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09884
Value Function Update Magnitude: 0.06870

Collected Steps per Second: 25,471.24503
Overall Steps per Second: 17,946.31335

Timestep Collection Time: 1.96347
Timestep Consumption Time: 0.82329
PPO Batch Consumption Time: 0.06293
Total Iteration Time: 2.78676

Cumulative Model Updates: 1,619
Cumulative Timesteps: 27,058,358

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00001
Policy Entropy: 4.46697
Value Function Loss: 0.04393

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10363
Value Function Update Magnitude: 0.08032

Collected Steps per Second: 25,823.01299
Overall Steps per Second: 17,581.47042

Timestep Collection Time: 1.93626
Timestep Consumption Time: 0.90765
PPO Batch Consumption Time: 0.12379
Total Iteration Time: 2.84390

Cumulative Model Updates: 1,622
Cumulative Timesteps: 27,108,358

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 27108358...
Checkpoint 27108358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02413
Policy Entropy: 4.46986
Value Function Loss: 0.03382

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.09731
Value Function Update Magnitude: 0.06062

Collected Steps per Second: 26,134.45959
Overall Steps per Second: 18,626.18047

Timestep Collection Time: 1.91387
Timestep Consumption Time: 0.77149
PPO Batch Consumption Time: 0.05639
Total Iteration Time: 2.68536

Cumulative Model Updates: 1,625
Cumulative Timesteps: 27,158,376

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05392
Policy Entropy: 4.47297
Value Function Loss: 0.04657

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00002
Policy Update Magnitude: 0.09116
Value Function Update Magnitude: 0.07992

Collected Steps per Second: 23,211.34255
Overall Steps per Second: 16,183.76286

Timestep Collection Time: 2.15524
Timestep Consumption Time: 0.93588
PPO Batch Consumption Time: 0.12111
Total Iteration Time: 3.09112

Cumulative Model Updates: 1,628
Cumulative Timesteps: 27,208,402

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 27208402...
Checkpoint 27208402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01005
Policy Entropy: 4.47492
Value Function Loss: 0.04239

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08903
Value Function Update Magnitude: 0.08639

Collected Steps per Second: 25,859.90224
Overall Steps per Second: 18,358.71192

Timestep Collection Time: 1.93404
Timestep Consumption Time: 0.79023
PPO Batch Consumption Time: 0.06053
Total Iteration Time: 2.72427

Cumulative Model Updates: 1,631
Cumulative Timesteps: 27,258,416

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01667
Policy Entropy: 4.47546
Value Function Loss: 0.04059

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08870
Value Function Update Magnitude: 0.07451

Collected Steps per Second: 25,715.98406
Overall Steps per Second: 18,515.20520

Timestep Collection Time: 1.94525
Timestep Consumption Time: 0.75653
PPO Batch Consumption Time: 0.05864
Total Iteration Time: 2.70178

Cumulative Model Updates: 1,634
Cumulative Timesteps: 27,308,440

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 27308440...
Checkpoint 27308440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05039
Policy Entropy: 4.47506
Value Function Loss: 0.03856

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08454
Value Function Update Magnitude: 0.07754

Collected Steps per Second: 22,628.97759
Overall Steps per Second: 15,971.41908

Timestep Collection Time: 2.20956
Timestep Consumption Time: 0.92104
PPO Batch Consumption Time: 0.11905
Total Iteration Time: 3.13059

Cumulative Model Updates: 1,637
Cumulative Timesteps: 27,358,440

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02126
Policy Entropy: 4.47407
Value Function Loss: 0.05725

Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08438
Value Function Update Magnitude: 0.06169

Collected Steps per Second: 25,735.46305
Overall Steps per Second: 18,345.95259

Timestep Collection Time: 1.94347
Timestep Consumption Time: 0.78280
PPO Batch Consumption Time: 0.06214
Total Iteration Time: 2.72627

Cumulative Model Updates: 1,640
Cumulative Timesteps: 27,408,456

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 27408456...
Checkpoint 27408456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01594
Policy Entropy: 4.47259
Value Function Loss: 0.06509

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09145
Value Function Update Magnitude: 0.07100

Collected Steps per Second: 25,769.73379
Overall Steps per Second: 18,931.23936

Timestep Collection Time: 1.94150
Timestep Consumption Time: 0.70133
PPO Batch Consumption Time: 0.05821
Total Iteration Time: 2.64283

Cumulative Model Updates: 1,643
Cumulative Timesteps: 27,458,488

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00834
Policy Entropy: 4.47169
Value Function Loss: 0.05490

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10025
Value Function Update Magnitude: 0.07818

Collected Steps per Second: 22,720.11985
Overall Steps per Second: 15,636.90754

Timestep Collection Time: 2.20096
Timestep Consumption Time: 0.99699
PPO Batch Consumption Time: 0.12196
Total Iteration Time: 3.19795

Cumulative Model Updates: 1,646
Cumulative Timesteps: 27,508,494

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 27508494...
Checkpoint 27508494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00254
Policy Entropy: 4.47154
Value Function Loss: 0.03323

Mean KL Divergence: 0.00023
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09697
Value Function Update Magnitude: 0.08370

Collected Steps per Second: 25,158.55160
Overall Steps per Second: 17,784.65523

Timestep Collection Time: 1.98755
Timestep Consumption Time: 0.82408
PPO Batch Consumption Time: 0.07667
Total Iteration Time: 2.81164

Cumulative Model Updates: 1,649
Cumulative Timesteps: 27,558,498

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04030
Policy Entropy: 4.47177
Value Function Loss: 0.04267

Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08535
Value Function Update Magnitude: 0.07717

Collected Steps per Second: 25,334.89819
Overall Steps per Second: 18,468.26198

Timestep Collection Time: 1.97411
Timestep Consumption Time: 0.73399
PPO Batch Consumption Time: 0.05787
Total Iteration Time: 2.70811

Cumulative Model Updates: 1,652
Cumulative Timesteps: 27,608,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 27608512...
Checkpoint 27608512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02364
Policy Entropy: 4.47307
Value Function Loss: 0.05581

Mean KL Divergence: 0.00013
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08133
Value Function Update Magnitude: 0.07850

Collected Steps per Second: 25,839.86671
Overall Steps per Second: 18,383.39487

Timestep Collection Time: 1.93546
Timestep Consumption Time: 0.78504
PPO Batch Consumption Time: 0.06149
Total Iteration Time: 2.72050

Cumulative Model Updates: 1,655
Cumulative Timesteps: 27,658,524

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03412
Policy Entropy: 4.47413
Value Function Loss: 0.07777

Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08910
Value Function Update Magnitude: 0.08458

Collected Steps per Second: 22,997.17806
Overall Steps per Second: 16,993.72738

Timestep Collection Time: 2.17418
Timestep Consumption Time: 0.76808
PPO Batch Consumption Time: 0.07291
Total Iteration Time: 2.94226

Cumulative Model Updates: 1,658
Cumulative Timesteps: 27,708,524

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 27708524...
Checkpoint 27708524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01120
Policy Entropy: 4.47454
Value Function Loss: 0.07964

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09841
Value Function Update Magnitude: 0.09414

Collected Steps per Second: 25,815.34754
Overall Steps per Second: 18,323.97639

Timestep Collection Time: 1.93753
Timestep Consumption Time: 0.79212
PPO Batch Consumption Time: 0.05973
Total Iteration Time: 2.72965

Cumulative Model Updates: 1,661
Cumulative Timesteps: 27,758,542

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02702
Policy Entropy: 4.47356
Value Function Loss: 0.08591

Mean KL Divergence: 0.00019
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10526
Value Function Update Magnitude: 0.10278

Collected Steps per Second: 25,388.12309
Overall Steps per Second: 18,314.49995

Timestep Collection Time: 1.97021
Timestep Consumption Time: 0.76096
PPO Batch Consumption Time: 0.06112
Total Iteration Time: 2.73117

Cumulative Model Updates: 1,664
Cumulative Timesteps: 27,808,562

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 27808562...
Checkpoint 27808562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02094
Policy Entropy: 4.47022
Value Function Loss: 0.07215

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00241
Policy Update Magnitude: 0.11206
Value Function Update Magnitude: 0.10689

Collected Steps per Second: 21,621.69266
Overall Steps per Second: 15,315.65768

Timestep Collection Time: 2.31314
Timestep Consumption Time: 0.95241
PPO Batch Consumption Time: 0.11429
Total Iteration Time: 3.26555

Cumulative Model Updates: 1,667
Cumulative Timesteps: 27,858,576

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00197
Policy Entropy: 4.46417
Value Function Loss: 0.06768

Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.01235
Policy Update Magnitude: 0.10646
Value Function Update Magnitude: 0.10311

Collected Steps per Second: 23,991.34347
Overall Steps per Second: 16,864.47066

Timestep Collection Time: 2.08509
Timestep Consumption Time: 0.88115
PPO Batch Consumption Time: 0.06534
Total Iteration Time: 2.96624

Cumulative Model Updates: 1,670
Cumulative Timesteps: 27,908,600

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 27908600...
Checkpoint 27908600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00467
Policy Entropy: 4.46049
Value Function Loss: 0.06578

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.01021
Policy Update Magnitude: 0.09923
Value Function Update Magnitude: 0.10878

Collected Steps per Second: 24,085.53079
Overall Steps per Second: 17,520.81209

Timestep Collection Time: 2.07693
Timestep Consumption Time: 0.77819
PPO Batch Consumption Time: 0.06057
Total Iteration Time: 2.85512

Cumulative Model Updates: 1,673
Cumulative Timesteps: 27,958,624

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02694
Policy Entropy: 4.45913
Value Function Loss: 0.06887

Mean KL Divergence: 0.00054
SB3 Clip Fraction: 0.00023
Policy Update Magnitude: 0.09856
Value Function Update Magnitude: 0.11104

Collected Steps per Second: 22,641.02428
Overall Steps per Second: 15,724.01935

Timestep Collection Time: 2.20900
Timestep Consumption Time: 0.97174
PPO Batch Consumption Time: 0.11953
Total Iteration Time: 3.18074

Cumulative Model Updates: 1,676
Cumulative Timesteps: 28,008,638

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 28008638...
Checkpoint 28008638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00652
Policy Entropy: 4.45897
Value Function Loss: 0.08124

Mean KL Divergence: 0.00026
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09983
Value Function Update Magnitude: 0.08379

Collected Steps per Second: 25,885.11654
Overall Steps per Second: 18,457.19199

Timestep Collection Time: 1.93277
Timestep Consumption Time: 0.77783
PPO Batch Consumption Time: 0.05811
Total Iteration Time: 2.71060

Cumulative Model Updates: 1,679
Cumulative Timesteps: 28,058,668

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06493
Policy Entropy: 4.46027
Value Function Loss: 0.08553

Mean KL Divergence: 0.00023
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10747
Value Function Update Magnitude: 0.08920

Collected Steps per Second: 25,708.43370
Overall Steps per Second: 17,682.12963

Timestep Collection Time: 1.94590
Timestep Consumption Time: 0.88329
PPO Batch Consumption Time: 0.11655
Total Iteration Time: 2.82918

Cumulative Model Updates: 1,682
Cumulative Timesteps: 28,108,694

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 28108694...
Checkpoint 28108694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00052
Policy Entropy: 4.46246
Value Function Loss: 0.09907

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.11294
Value Function Update Magnitude: 0.08780

Collected Steps per Second: 25,821.44084
Overall Steps per Second: 18,472.54335

Timestep Collection Time: 1.93653
Timestep Consumption Time: 0.77041
PPO Batch Consumption Time: 0.05957
Total Iteration Time: 2.70694

Cumulative Model Updates: 1,685
Cumulative Timesteps: 28,158,698

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04181
Policy Entropy: 4.46273
Value Function Loss: 0.08426

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00014
Policy Update Magnitude: 0.11611
Value Function Update Magnitude: 0.10142

Collected Steps per Second: 22,867.64323
Overall Steps per Second: 16,204.35101

Timestep Collection Time: 2.18789
Timestep Consumption Time: 0.89967
PPO Batch Consumption Time: 0.09632
Total Iteration Time: 3.08757

Cumulative Model Updates: 1,688
Cumulative Timesteps: 28,208,730

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 28208730...
Checkpoint 28208730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00624
Policy Entropy: 4.46285
Value Function Loss: 0.07634

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.12014
Value Function Update Magnitude: 0.09001

Collected Steps per Second: 26,589.60816
Overall Steps per Second: 18,637.26678

Timestep Collection Time: 1.88096
Timestep Consumption Time: 0.80259
PPO Batch Consumption Time: 0.05866
Total Iteration Time: 2.68355

Cumulative Model Updates: 1,691
Cumulative Timesteps: 28,258,744

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01970
Policy Entropy: 4.46174
Value Function Loss: 0.07893

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.11606
Value Function Update Magnitude: 0.07710

Collected Steps per Second: 23,289.12290
Overall Steps per Second: 16,233.44741

Timestep Collection Time: 2.14727
Timestep Consumption Time: 0.93328
PPO Batch Consumption Time: 0.10678
Total Iteration Time: 3.08055

Cumulative Model Updates: 1,694
Cumulative Timesteps: 28,308,752

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 28308752...
Checkpoint 28308752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00285
Policy Entropy: 4.45804
Value Function Loss: 0.07213

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00027
Policy Update Magnitude: 0.11707
Value Function Update Magnitude: 0.07782

Collected Steps per Second: 25,580.22974
Overall Steps per Second: 17,890.29447

Timestep Collection Time: 1.95526
Timestep Consumption Time: 0.84045
PPO Batch Consumption Time: 0.09365
Total Iteration Time: 2.79571

Cumulative Model Updates: 1,697
Cumulative Timesteps: 28,358,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00717
Policy Entropy: 4.44996
Value Function Loss: 0.06280

Mean KL Divergence: 0.00103
SB3 Clip Fraction: 0.00692
Policy Update Magnitude: 0.11453
Value Function Update Magnitude: 0.08191

Collected Steps per Second: 25,850.86666
Overall Steps per Second: 18,519.33432

Timestep Collection Time: 1.93518
Timestep Consumption Time: 0.76611
PPO Batch Consumption Time: 0.05986
Total Iteration Time: 2.70128

Cumulative Model Updates: 1,700
Cumulative Timesteps: 28,408,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 28408794...
Checkpoint 28408794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02065
Policy Entropy: 4.44144
Value Function Loss: 0.03810

Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.01135
Policy Update Magnitude: 0.10098
Value Function Update Magnitude: 0.07939

Collected Steps per Second: 25,552.63580
Overall Steps per Second: 18,395.06989

Timestep Collection Time: 1.95675
Timestep Consumption Time: 0.76137
PPO Batch Consumption Time: 0.05890
Total Iteration Time: 2.71812

Cumulative Model Updates: 1,703
Cumulative Timesteps: 28,458,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05222
Policy Entropy: 4.43708
Value Function Loss: 0.04696

Mean KL Divergence: 0.00085
SB3 Clip Fraction: 0.00411
Policy Update Magnitude: 0.08889
Value Function Update Magnitude: 0.06702

Collected Steps per Second: 21,954.33146
Overall Steps per Second: 15,922.39783

Timestep Collection Time: 2.27800
Timestep Consumption Time: 0.86298
PPO Batch Consumption Time: 0.10624
Total Iteration Time: 3.14098

Cumulative Model Updates: 1,706
Cumulative Timesteps: 28,508,806

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 28508806...
Checkpoint 28508806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05392
Policy Entropy: 4.43309
Value Function Loss: 0.05686

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.08658
Value Function Update Magnitude: 0.07342

Collected Steps per Second: 25,745.82842
Overall Steps per Second: 17,724.47906

Timestep Collection Time: 1.94292
Timestep Consumption Time: 0.87928
PPO Batch Consumption Time: 0.08111
Total Iteration Time: 2.82220

Cumulative Model Updates: 1,709
Cumulative Timesteps: 28,558,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03139
Policy Entropy: 4.42595
Value Function Loss: 0.07281

Mean KL Divergence: 0.00060
SB3 Clip Fraction: 0.00019
Policy Update Magnitude: 0.10099
Value Function Update Magnitude: 0.07391

Collected Steps per Second: 24,299.42961
Overall Steps per Second: 16,903.37761

Timestep Collection Time: 2.05807
Timestep Consumption Time: 0.90051
PPO Batch Consumption Time: 0.09834
Total Iteration Time: 2.95858

Cumulative Model Updates: 1,712
Cumulative Timesteps: 28,608,838

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 28608838...
Checkpoint 28608838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04322
Policy Entropy: 4.40935
Value Function Loss: 0.07149

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.01278
Policy Update Magnitude: 0.10645
Value Function Update Magnitude: 0.08572

Collected Steps per Second: 25,692.67979
Overall Steps per Second: 18,365.20713

Timestep Collection Time: 1.94608
Timestep Consumption Time: 0.77646
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 2.72254

Cumulative Model Updates: 1,715
Cumulative Timesteps: 28,658,838

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01741
Policy Entropy: 4.40129
Value Function Loss: 0.07789

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.00840
Policy Update Magnitude: 0.11194
Value Function Update Magnitude: 0.08375

Collected Steps per Second: 25,514.90999
Overall Steps per Second: 18,210.55556

Timestep Collection Time: 1.96074
Timestep Consumption Time: 0.78646
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 2.74720

Cumulative Model Updates: 1,718
Cumulative Timesteps: 28,708,866

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 28708866...
Checkpoint 28708866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00362
Policy Entropy: 4.40231
Value Function Loss: 0.06763

Mean KL Divergence: 0.00114
SB3 Clip Fraction: 0.00049
Policy Update Magnitude: 0.11656
Value Function Update Magnitude: 0.07926

Collected Steps per Second: 23,229.46081
Overall Steps per Second: 16,284.96746

Timestep Collection Time: 2.15287
Timestep Consumption Time: 0.91806
PPO Batch Consumption Time: 0.12213
Total Iteration Time: 3.07093

Cumulative Model Updates: 1,721
Cumulative Timesteps: 28,758,876

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03049
Policy Entropy: 4.39803
Value Function Loss: 0.06546

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.00513
Policy Update Magnitude: 0.11835
Value Function Update Magnitude: 0.09326

Collected Steps per Second: 25,450.49089
Overall Steps per Second: 17,743.87700

Timestep Collection Time: 1.96483
Timestep Consumption Time: 0.85338
PPO Batch Consumption Time: 0.08063
Total Iteration Time: 2.81821

Cumulative Model Updates: 1,724
Cumulative Timesteps: 28,808,882

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 28808882...
Checkpoint 28808882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06815
Policy Entropy: 4.39421
Value Function Loss: 0.05604

Mean KL Divergence: 0.00124
SB3 Clip Fraction: 0.00253
Policy Update Magnitude: 0.11562
Value Function Update Magnitude: 0.08751

Collected Steps per Second: 25,675.39093
Overall Steps per Second: 18,416.89873

Timestep Collection Time: 1.94770
Timestep Consumption Time: 0.76763
PPO Batch Consumption Time: 0.05989
Total Iteration Time: 2.71533

Cumulative Model Updates: 1,727
Cumulative Timesteps: 28,858,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00289
Policy Entropy: 4.39569
Value Function Loss: 0.04632

Mean KL Divergence: 0.00091
SB3 Clip Fraction: 0.00071
Policy Update Magnitude: 0.11652
Value Function Update Magnitude: 0.06792

Collected Steps per Second: 25,763.36099
Overall Steps per Second: 18,885.70633

Timestep Collection Time: 1.94159
Timestep Consumption Time: 0.70708
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 2.64867

Cumulative Model Updates: 1,730
Cumulative Timesteps: 28,908,912

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 28908912...
Checkpoint 28908912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00925
Policy Entropy: 4.40296
Value Function Loss: 0.04796

Mean KL Divergence: 0.00096
SB3 Clip Fraction: 0.00069
Policy Update Magnitude: 0.10900
Value Function Update Magnitude: 0.06276

Collected Steps per Second: 22,842.69361
Overall Steps per Second: 15,785.18165

Timestep Collection Time: 2.18950
Timestep Consumption Time: 0.97892
PPO Batch Consumption Time: 0.12101
Total Iteration Time: 3.16841

Cumulative Model Updates: 1,733
Cumulative Timesteps: 28,958,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03377
Policy Entropy: 4.41327
Value Function Loss: 0.06112

Mean KL Divergence: 0.00117
SB3 Clip Fraction: 0.00245
Policy Update Magnitude: 0.09986
Value Function Update Magnitude: 0.06532

Collected Steps per Second: 25,543.36067
Overall Steps per Second: 17,736.11293

Timestep Collection Time: 1.95832
Timestep Consumption Time: 0.86203
PPO Batch Consumption Time: 0.08239
Total Iteration Time: 2.82035

Cumulative Model Updates: 1,736
Cumulative Timesteps: 29,008,948

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 29008948...
Checkpoint 29008948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05612
Policy Entropy: 4.41729
Value Function Loss: 0.08153

Mean KL Divergence: 0.00082
SB3 Clip Fraction: 0.00082
Policy Update Magnitude: 0.10276
Value Function Update Magnitude: 0.07171

Collected Steps per Second: 26,728.76522
Overall Steps per Second: 18,808.19476

Timestep Collection Time: 1.87169
Timestep Consumption Time: 0.78821
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 2.65990

Cumulative Model Updates: 1,739
Cumulative Timesteps: 29,058,976

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00499
Policy Entropy: 4.41133
Value Function Loss: 0.08503

Mean KL Divergence: 0.00066
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.11917
Value Function Update Magnitude: 0.06883

Collected Steps per Second: 22,937.24490
Overall Steps per Second: 16,077.72284

Timestep Collection Time: 2.18073
Timestep Consumption Time: 0.93040
PPO Batch Consumption Time: 0.09738
Total Iteration Time: 3.11114

Cumulative Model Updates: 1,742
Cumulative Timesteps: 29,108,996

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 29108996...
Checkpoint 29108996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08593
Policy Entropy: 4.40010
Value Function Loss: 0.08301

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.00101
Policy Update Magnitude: 0.12949
Value Function Update Magnitude: 0.06490

Collected Steps per Second: 25,534.91491
Overall Steps per Second: 18,655.71774

Timestep Collection Time: 1.95857
Timestep Consumption Time: 0.72221
PPO Batch Consumption Time: 0.05861
Total Iteration Time: 2.68079

Cumulative Model Updates: 1,745
Cumulative Timesteps: 29,159,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02663
Policy Entropy: 4.38977
Value Function Loss: 0.07062

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.00917
Policy Update Magnitude: 0.12361
Value Function Update Magnitude: 0.06983

Collected Steps per Second: 23,682.12413
Overall Steps per Second: 16,252.15174

Timestep Collection Time: 2.11130
Timestep Consumption Time: 0.96522
PPO Batch Consumption Time: 0.11614
Total Iteration Time: 3.07652

Cumulative Model Updates: 1,748
Cumulative Timesteps: 29,209,008

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 29209008...
Checkpoint 29209008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03044
Policy Entropy: 4.38291
Value Function Loss: 0.06309

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01129
Policy Update Magnitude: 0.11309
Value Function Update Magnitude: 0.07438

Collected Steps per Second: 25,768.44845
Overall Steps per Second: 17,849.26204

Timestep Collection Time: 1.94137
Timestep Consumption Time: 0.86133
PPO Batch Consumption Time: 0.08966
Total Iteration Time: 2.80269

Cumulative Model Updates: 1,751
Cumulative Timesteps: 29,259,034

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00420
Policy Entropy: 4.38349
Value Function Loss: 0.06203

Mean KL Divergence: 0.00133
SB3 Clip Fraction: 0.00234
Policy Update Magnitude: 0.11726
Value Function Update Magnitude: 0.07069

Collected Steps per Second: 25,706.83912
Overall Steps per Second: 18,869.86398

Timestep Collection Time: 1.94524
Timestep Consumption Time: 0.70480
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 2.65005

Cumulative Model Updates: 1,754
Cumulative Timesteps: 29,309,040

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 29309040...
Checkpoint 29309040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04767
Policy Entropy: 4.38443
Value Function Loss: 0.05128

Mean KL Divergence: 0.00112
SB3 Clip Fraction: 0.00190
Policy Update Magnitude: 0.11416
Value Function Update Magnitude: 0.05980

Collected Steps per Second: 23,312.47105
Overall Steps per Second: 16,104.22406

Timestep Collection Time: 2.14555
Timestep Consumption Time: 0.96035
PPO Batch Consumption Time: 0.11608
Total Iteration Time: 3.10589

Cumulative Model Updates: 1,757
Cumulative Timesteps: 29,359,058

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04224
Policy Entropy: 4.38565
Value Function Loss: 0.05284

Mean KL Divergence: 0.00113
SB3 Clip Fraction: 0.00198
Policy Update Magnitude: 0.10724
Value Function Update Magnitude: 0.05507

Collected Steps per Second: 25,844.98249
Overall Steps per Second: 18,606.26489

Timestep Collection Time: 1.93554
Timestep Consumption Time: 0.75302
PPO Batch Consumption Time: 0.05976
Total Iteration Time: 2.68856

Cumulative Model Updates: 1,760
Cumulative Timesteps: 29,409,082

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 29409082...
Checkpoint 29409082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07820
Policy Entropy: 4.38336
Value Function Loss: 0.06095

Mean KL Divergence: 0.00096
SB3 Clip Fraction: 0.00025
Policy Update Magnitude: 0.09915
Value Function Update Magnitude: 0.05216

Collected Steps per Second: 23,460.05834
Overall Steps per Second: 16,188.98100

Timestep Collection Time: 2.13145
Timestep Consumption Time: 0.95732
PPO Batch Consumption Time: 0.10980
Total Iteration Time: 3.08877

Cumulative Model Updates: 1,763
Cumulative Timesteps: 29,459,086

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00512
Policy Entropy: 4.37490
Value Function Loss: 0.07280

Mean KL Divergence: 0.00103
SB3 Clip Fraction: 0.00316
Policy Update Magnitude: 0.10507
Value Function Update Magnitude: 0.04872

Collected Steps per Second: 25,637.37170
Overall Steps per Second: 17,753.50472

Timestep Collection Time: 1.95082
Timestep Consumption Time: 0.86631
PPO Batch Consumption Time: 0.07877
Total Iteration Time: 2.81713

Cumulative Model Updates: 1,766
Cumulative Timesteps: 29,509,100

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 29509100...
Checkpoint 29509100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04558
Policy Entropy: 4.36639
Value Function Loss: 0.07214

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.00538
Policy Update Magnitude: 0.11664
Value Function Update Magnitude: 0.05695

Collected Steps per Second: 25,630.76890
Overall Steps per Second: 18,453.94445

Timestep Collection Time: 1.95094
Timestep Consumption Time: 0.75873
PPO Batch Consumption Time: 0.06035
Total Iteration Time: 2.70966

Cumulative Model Updates: 1,769
Cumulative Timesteps: 29,559,104

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14541
Policy Entropy: 4.35666
Value Function Loss: 0.06930

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.01625
Policy Update Magnitude: 0.11612
Value Function Update Magnitude: 0.05758

Collected Steps per Second: 25,812.89301
Overall Steps per Second: 18,203.28133

Timestep Collection Time: 1.93787
Timestep Consumption Time: 0.81010
PPO Batch Consumption Time: 0.06145
Total Iteration Time: 2.74797

Cumulative Model Updates: 1,772
Cumulative Timesteps: 29,609,126

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 29609126...
Checkpoint 29609126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07477
Policy Entropy: 4.35188
Value Function Loss: 0.07460

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.01203
Policy Update Magnitude: 0.11136
Value Function Update Magnitude: 0.06271

Collected Steps per Second: 22,371.24358
Overall Steps per Second: 16,150.12506

Timestep Collection Time: 2.23582
Timestep Consumption Time: 0.86125
PPO Batch Consumption Time: 0.08425
Total Iteration Time: 3.09707

Cumulative Model Updates: 1,775
Cumulative Timesteps: 29,659,144

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03713
Policy Entropy: 4.35124
Value Function Loss: 0.08622

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.00151
Policy Update Magnitude: 0.11836
Value Function Update Magnitude: 0.06546

Collected Steps per Second: 26,393.62682
Overall Steps per Second: 17,945.15201

Timestep Collection Time: 1.89508
Timestep Consumption Time: 0.89219
PPO Batch Consumption Time: 0.09298
Total Iteration Time: 2.78727

Cumulative Model Updates: 1,778
Cumulative Timesteps: 29,709,162

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 29709162...
Checkpoint 29709162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01812
Policy Entropy: 4.35361
Value Function Loss: 0.10091

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.00638
Policy Update Magnitude: 0.12302
Value Function Update Magnitude: 0.06668

Collected Steps per Second: 25,204.33242
Overall Steps per Second: 18,171.02116

Timestep Collection Time: 1.98498
Timestep Consumption Time: 0.76831
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 2.75329

Cumulative Model Updates: 1,781
Cumulative Timesteps: 29,759,192

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00952
Policy Entropy: 4.35627
Value Function Loss: 0.08257

Mean KL Divergence: 0.00126
SB3 Clip Fraction: 0.00221
Policy Update Magnitude: 0.12436
Value Function Update Magnitude: 0.07648

Collected Steps per Second: 22,461.87543
Overall Steps per Second: 16,489.99645

Timestep Collection Time: 2.22688
Timestep Consumption Time: 0.80647
PPO Batch Consumption Time: 0.07204
Total Iteration Time: 3.03335

Cumulative Model Updates: 1,784
Cumulative Timesteps: 29,809,212

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 29809212...
Checkpoint 29809212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00995
Policy Entropy: 4.35159
Value Function Loss: 0.07543

Mean KL Divergence: 0.00138
SB3 Clip Fraction: 0.00373
Policy Update Magnitude: 0.11675
Value Function Update Magnitude: 0.08749

Collected Steps per Second: 26,386.03148
Overall Steps per Second: 18,620.54253

Timestep Collection Time: 1.89585
Timestep Consumption Time: 0.79064
PPO Batch Consumption Time: 0.05907
Total Iteration Time: 2.68650

Cumulative Model Updates: 1,787
Cumulative Timesteps: 29,859,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09466
Policy Entropy: 4.34751
Value Function Loss: 0.07523

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.00411
Policy Update Magnitude: 0.11292
Value Function Update Magnitude: 0.08966

Collected Steps per Second: 25,616.30660
Overall Steps per Second: 17,390.27896

Timestep Collection Time: 1.95282
Timestep Consumption Time: 0.92373
PPO Batch Consumption Time: 0.10108
Total Iteration Time: 2.87655

Cumulative Model Updates: 1,790
Cumulative Timesteps: 29,909,260

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 29909260...
Checkpoint 29909260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03680
Policy Entropy: 4.35049
Value Function Loss: 0.07184

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.00413
Policy Update Magnitude: 0.12011
Value Function Update Magnitude: 0.10116

Collected Steps per Second: 24,966.50175
Overall Steps per Second: 18,454.83251

Timestep Collection Time: 2.00316
Timestep Consumption Time: 0.70680
PPO Batch Consumption Time: 0.06078
Total Iteration Time: 2.70997

Cumulative Model Updates: 1,793
Cumulative Timesteps: 29,959,272

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00370
Policy Entropy: 4.35285
Value Function Loss: 0.07597

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01168
Policy Update Magnitude: 0.11721
Value Function Update Magnitude: 0.10415

Collected Steps per Second: 25,779.57331
Overall Steps per Second: 18,342.14153

Timestep Collection Time: 1.93983
Timestep Consumption Time: 0.78657
PPO Batch Consumption Time: 0.05935
Total Iteration Time: 2.72640

Cumulative Model Updates: 1,796
Cumulative Timesteps: 30,009,280

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 30009280...
Checkpoint 30009280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01845
Policy Entropy: 4.35342
Value Function Loss: 0.07454

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.01079
Policy Update Magnitude: 0.10605
Value Function Update Magnitude: 0.09510

Collected Steps per Second: 23,126.05883
Overall Steps per Second: 16,102.85387

Timestep Collection Time: 2.16388
Timestep Consumption Time: 0.94377
PPO Batch Consumption Time: 0.11208
Total Iteration Time: 3.10765

Cumulative Model Updates: 1,799
Cumulative Timesteps: 30,059,322

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06577
Policy Entropy: 4.35474
Value Function Loss: 0.09788

Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.00159
Policy Update Magnitude: 0.10439
Value Function Update Magnitude: 0.09283

Collected Steps per Second: 26,711.56365
Overall Steps per Second: 17,879.21206

Timestep Collection Time: 1.87267
Timestep Consumption Time: 0.92510
PPO Batch Consumption Time: 0.10500
Total Iteration Time: 2.79777

Cumulative Model Updates: 1,802
Cumulative Timesteps: 30,109,344

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 30109344...
Checkpoint 30109344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00075
Policy Entropy: 4.36251
Value Function Loss: 0.09235

Mean KL Divergence: 0.00107
SB3 Clip Fraction: 0.00074
Policy Update Magnitude: 0.11282
Value Function Update Magnitude: 0.08493

Collected Steps per Second: 25,478.05997
Overall Steps per Second: 18,224.95523

Timestep Collection Time: 1.96334
Timestep Consumption Time: 0.78136
PPO Batch Consumption Time: 0.06086
Total Iteration Time: 2.74470

Cumulative Model Updates: 1,805
Cumulative Timesteps: 30,159,366

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04803
Policy Entropy: 4.37317
Value Function Loss: 0.08022

Mean KL Divergence: 0.00135
SB3 Clip Fraction: 0.00219
Policy Update Magnitude: 0.10989
Value Function Update Magnitude: 0.07809

Collected Steps per Second: 25,801.10731
Overall Steps per Second: 18,915.79970

Timestep Collection Time: 1.93875
Timestep Consumption Time: 0.70570
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 2.64446

Cumulative Model Updates: 1,808
Cumulative Timesteps: 30,209,388

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 30209388...
Checkpoint 30209388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03368
Policy Entropy: 4.38012
Value Function Loss: 0.06347

Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.00352
Policy Update Magnitude: 0.10568
Value Function Update Magnitude: 0.06810

Collected Steps per Second: 22,426.74974
Overall Steps per Second: 15,803.63477

Timestep Collection Time: 2.23010
Timestep Consumption Time: 0.93461
PPO Batch Consumption Time: 0.10996
Total Iteration Time: 3.16471

Cumulative Model Updates: 1,811
Cumulative Timesteps: 30,259,402

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02892
Policy Entropy: 4.37775
Value Function Loss: 0.05479

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01383
Policy Update Magnitude: 0.09792
Value Function Update Magnitude: 0.05975

Collected Steps per Second: 25,709.26388
Overall Steps per Second: 17,806.94271

Timestep Collection Time: 1.94545
Timestep Consumption Time: 0.86335
PPO Batch Consumption Time: 0.08829
Total Iteration Time: 2.80879

Cumulative Model Updates: 1,814
Cumulative Timesteps: 30,309,418

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 30309418...
Checkpoint 30309418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00706
Policy Entropy: 4.37824
Value Function Loss: 0.04598

Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.01131
Policy Update Magnitude: 0.08794
Value Function Update Magnitude: 0.06019

Collected Steps per Second: 25,744.33977
Overall Steps per Second: 18,883.62917

Timestep Collection Time: 1.94272
Timestep Consumption Time: 0.70582
PPO Batch Consumption Time: 0.05744
Total Iteration Time: 2.64854

Cumulative Model Updates: 1,817
Cumulative Timesteps: 30,359,432

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00822
Policy Entropy: 4.38235
Value Function Loss: 0.05082

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08679
Value Function Update Magnitude: 0.06204

Collected Steps per Second: 23,337.54514
Overall Steps per Second: 16,091.82505

Timestep Collection Time: 2.14350
Timestep Consumption Time: 0.96516
PPO Batch Consumption Time: 0.11750
Total Iteration Time: 3.10866

Cumulative Model Updates: 1,820
Cumulative Timesteps: 30,409,456

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 30409456...
Checkpoint 30409456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00738
Policy Entropy: 4.38497
Value Function Loss: 0.04946

Mean KL Divergence: 0.00070
SB3 Clip Fraction: 0.00093
Policy Update Magnitude: 0.08793
Value Function Update Magnitude: 0.05832

Collected Steps per Second: 25,433.97198
Overall Steps per Second: 18,304.04275

Timestep Collection Time: 1.96650
Timestep Consumption Time: 0.76601
PPO Batch Consumption Time: 0.06137
Total Iteration Time: 2.73251

Cumulative Model Updates: 1,823
Cumulative Timesteps: 30,459,472

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02578
Policy Entropy: 4.38276
Value Function Loss: 0.07410

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00071
Policy Update Magnitude: 0.09283
Value Function Update Magnitude: 0.05651

Collected Steps per Second: 26,648.14162
Overall Steps per Second: 18,888.56855

Timestep Collection Time: 1.87638
Timestep Consumption Time: 0.77083
PPO Batch Consumption Time: 0.05760
Total Iteration Time: 2.64721

Cumulative Model Updates: 1,826
Cumulative Timesteps: 30,509,474

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 30509474...
Checkpoint 30509474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00084
Policy Entropy: 4.37899
Value Function Loss: 0.07676

Mean KL Divergence: 0.00066
SB3 Clip Fraction: 0.00008
Policy Update Magnitude: 0.09996
Value Function Update Magnitude: 0.05696

Collected Steps per Second: 23,023.34852
Overall Steps per Second: 15,747.04864

Timestep Collection Time: 2.17206
Timestep Consumption Time: 1.00365
PPO Batch Consumption Time: 0.12656
Total Iteration Time: 3.17571

Cumulative Model Updates: 1,829
Cumulative Timesteps: 30,559,482

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04752
Policy Entropy: 4.37655
Value Function Loss: 0.09530

Mean KL Divergence: 0.00086
SB3 Clip Fraction: 0.00071
Policy Update Magnitude: 0.10832
Value Function Update Magnitude: 0.05516

Collected Steps per Second: 24,778.79490
Overall Steps per Second: 17,991.44164

Timestep Collection Time: 2.01907
Timestep Consumption Time: 0.76170
PPO Batch Consumption Time: 0.06133
Total Iteration Time: 2.78077

Cumulative Model Updates: 1,832
Cumulative Timesteps: 30,609,512

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 30609512...
Checkpoint 30609512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01042
Policy Entropy: 4.38064
Value Function Loss: 0.07354

Mean KL Divergence: 0.00078
SB3 Clip Fraction: 0.00045
Policy Update Magnitude: 0.11346
Value Function Update Magnitude: 0.06338

Collected Steps per Second: 22,633.42288
Overall Steps per Second: 15,636.28895

Timestep Collection Time: 2.20921
Timestep Consumption Time: 0.98861
PPO Batch Consumption Time: 0.11309
Total Iteration Time: 3.19782

Cumulative Model Updates: 1,835
Cumulative Timesteps: 30,659,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01456
Policy Entropy: 4.38520
Value Function Loss: 0.05980

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01194
Policy Update Magnitude: 0.10911
Value Function Update Magnitude: 0.06789

Collected Steps per Second: 25,881.50466
Overall Steps per Second: 18,538.52548

Timestep Collection Time: 1.93250
Timestep Consumption Time: 0.76545
PPO Batch Consumption Time: 0.06133
Total Iteration Time: 2.69795

Cumulative Model Updates: 1,838
Cumulative Timesteps: 30,709,530

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 30709530...
Checkpoint 30709530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09326
Policy Entropy: 4.38363
Value Function Loss: 0.06205

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01379
Policy Update Magnitude: 0.09919
Value Function Update Magnitude: 0.06540

Collected Steps per Second: 23,651.03070
Overall Steps per Second: 16,202.05813

Timestep Collection Time: 2.11492
Timestep Consumption Time: 0.97234
PPO Batch Consumption Time: 0.10747
Total Iteration Time: 3.08726

Cumulative Model Updates: 1,841
Cumulative Timesteps: 30,759,550

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05202
Policy Entropy: 4.37746
Value Function Loss: 0.06319

Mean KL Divergence: 0.00080
SB3 Clip Fraction: 0.00053
Policy Update Magnitude: 0.09823
Value Function Update Magnitude: 0.05941

Collected Steps per Second: 25,901.83842
Overall Steps per Second: 18,423.63564

Timestep Collection Time: 1.93137
Timestep Consumption Time: 0.78395
PPO Batch Consumption Time: 0.06089
Total Iteration Time: 2.71532

Cumulative Model Updates: 1,844
Cumulative Timesteps: 30,809,576

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 30809576...
Checkpoint 30809576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02386
Policy Entropy: 4.37280
Value Function Loss: 0.06921

Mean KL Divergence: 0.00086
SB3 Clip Fraction: 0.00075
Policy Update Magnitude: 0.10148
Value Function Update Magnitude: 0.06164

Collected Steps per Second: 25,645.24276
Overall Steps per Second: 18,811.10379

Timestep Collection Time: 1.95054
Timestep Consumption Time: 0.70864
PPO Batch Consumption Time: 0.05759
Total Iteration Time: 2.65917

Cumulative Model Updates: 1,847
Cumulative Timesteps: 30,859,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03167
Policy Entropy: 4.37575
Value Function Loss: 0.05988

Mean KL Divergence: 0.00086
SB3 Clip Fraction: 0.00045
Policy Update Magnitude: 0.10291
Value Function Update Magnitude: 0.06938

Collected Steps per Second: 23,160.98165
Overall Steps per Second: 16,638.94175

Timestep Collection Time: 2.15906
Timestep Consumption Time: 0.84630
PPO Batch Consumption Time: 0.07377
Total Iteration Time: 3.00536

Cumulative Model Updates: 1,850
Cumulative Timesteps: 30,909,604

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 30909604...
Checkpoint 30909604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01060
Policy Entropy: 4.38134
Value Function Loss: 0.06073

Mean KL Divergence: 0.00098
SB3 Clip Fraction: 0.00099
Policy Update Magnitude: 0.10141
Value Function Update Magnitude: 0.06915

Collected Steps per Second: 25,517.04627
Overall Steps per Second: 18,433.95236

Timestep Collection Time: 1.95963
Timestep Consumption Time: 0.75297
PPO Batch Consumption Time: 0.05964
Total Iteration Time: 2.71260

Cumulative Model Updates: 1,853
Cumulative Timesteps: 30,959,608

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05188
Policy Entropy: 4.38333
Value Function Loss: 0.07339

Mean KL Divergence: 0.00090
SB3 Clip Fraction: 0.00101
Policy Update Magnitude: 0.09999
Value Function Update Magnitude: 0.08020

Collected Steps per Second: 26,501.03906
Overall Steps per Second: 17,635.17655

Timestep Collection Time: 1.88762
Timestep Consumption Time: 0.94898
PPO Batch Consumption Time: 0.11892
Total Iteration Time: 2.83660

Cumulative Model Updates: 1,856
Cumulative Timesteps: 31,009,632

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 31009632...
Checkpoint 31009632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05219
Policy Entropy: 4.38178
Value Function Loss: 0.06822

Mean KL Divergence: 0.00064
SB3 Clip Fraction: 0.00074
Policy Update Magnitude: 0.09739
Value Function Update Magnitude: 0.07511

Collected Steps per Second: 25,850.37016
Overall Steps per Second: 18,441.07517

Timestep Collection Time: 1.93514
Timestep Consumption Time: 0.77750
PPO Batch Consumption Time: 0.05950
Total Iteration Time: 2.71264

Cumulative Model Updates: 1,859
Cumulative Timesteps: 31,059,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03441
Policy Entropy: 4.38056
Value Function Loss: 0.09220

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00015
Policy Update Magnitude: 0.09921
Value Function Update Magnitude: 0.07273

Collected Steps per Second: 25,701.97531
Overall Steps per Second: 18,909.84966

Timestep Collection Time: 1.94553
Timestep Consumption Time: 0.69880
PPO Batch Consumption Time: 0.05876
Total Iteration Time: 2.64434

Cumulative Model Updates: 1,862
Cumulative Timesteps: 31,109,660

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 31109660...
Checkpoint 31109660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09495
Policy Entropy: 4.38094
Value Function Loss: 0.08751

Mean KL Divergence: 0.00068
SB3 Clip Fraction: 0.00054
Policy Update Magnitude: 0.09747
Value Function Update Magnitude: 0.08297

Collected Steps per Second: 24,254.24900
Overall Steps per Second: 16,646.49172

Timestep Collection Time: 2.06224
Timestep Consumption Time: 0.94248
PPO Batch Consumption Time: 0.10890
Total Iteration Time: 3.00472

Cumulative Model Updates: 1,865
Cumulative Timesteps: 31,159,678

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00476
Policy Entropy: 4.38455
Value Function Loss: 0.08600

Mean KL Divergence: 0.00069
SB3 Clip Fraction: 0.00084
Policy Update Magnitude: 0.10648
Value Function Update Magnitude: 0.08467

Collected Steps per Second: 25,816.85581
Overall Steps per Second: 18,603.80961

Timestep Collection Time: 1.93718
Timestep Consumption Time: 0.75108
PPO Batch Consumption Time: 0.05883
Total Iteration Time: 2.68827

Cumulative Model Updates: 1,868
Cumulative Timesteps: 31,209,690

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 31209690...
Checkpoint 31209690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00772
Policy Entropy: 4.38210
Value Function Loss: 0.06236

Mean KL Divergence: 0.00065
SB3 Clip Fraction: 0.00161
Policy Update Magnitude: 0.11295
Value Function Update Magnitude: 0.07885

Collected Steps per Second: 22,526.36756
Overall Steps per Second: 16,208.67645

Timestep Collection Time: 2.22060
Timestep Consumption Time: 0.86553
PPO Batch Consumption Time: 0.11110
Total Iteration Time: 3.08612

Cumulative Model Updates: 1,871
Cumulative Timesteps: 31,259,712

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03342
Policy Entropy: 4.37701
Value Function Loss: 0.05098

Mean KL Divergence: 0.00091
SB3 Clip Fraction: 0.00783
Policy Update Magnitude: 0.10435
Value Function Update Magnitude: 0.06978

Collected Steps per Second: 25,270.72529
Overall Steps per Second: 18,132.05074

Timestep Collection Time: 1.97913
Timestep Consumption Time: 0.77919
PPO Batch Consumption Time: 0.06183
Total Iteration Time: 2.75832

Cumulative Model Updates: 1,874
Cumulative Timesteps: 31,309,726

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 31309726...
Checkpoint 31309726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02544
Policy Entropy: 4.38210
Value Function Loss: 0.04927

Mean KL Divergence: 0.00065
SB3 Clip Fraction: 0.00026
Policy Update Magnitude: 0.10064
Value Function Update Magnitude: 0.06920

Collected Steps per Second: 25,624.88775
Overall Steps per Second: 18,923.19307

Timestep Collection Time: 1.95209
Timestep Consumption Time: 0.69134
PPO Batch Consumption Time: 0.05775
Total Iteration Time: 2.64342

Cumulative Model Updates: 1,877
Cumulative Timesteps: 31,359,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00422
Policy Entropy: 4.38673
Value Function Loss: 0.05451

Mean KL Divergence: 0.00090
SB3 Clip Fraction: 0.00282
Policy Update Magnitude: 0.09590
Value Function Update Magnitude: 0.07137

Collected Steps per Second: 22,645.46104
Overall Steps per Second: 15,723.12558

Timestep Collection Time: 2.20804
Timestep Consumption Time: 0.97212
PPO Batch Consumption Time: 0.11082
Total Iteration Time: 3.18016

Cumulative Model Updates: 1,880
Cumulative Timesteps: 31,409,750

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 31409750...
Checkpoint 31409750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03027
Policy Entropy: 4.38782
Value Function Loss: 0.08286

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00002
Policy Update Magnitude: 0.09943
Value Function Update Magnitude: 0.07651

Collected Steps per Second: 25,718.18986
Overall Steps per Second: 18,538.57290

Timestep Collection Time: 1.94430
Timestep Consumption Time: 0.75299
PPO Batch Consumption Time: 0.06003
Total Iteration Time: 2.69730

Cumulative Model Updates: 1,883
Cumulative Timesteps: 31,459,754

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00147
Policy Entropy: 4.37815
Value Function Loss: 0.09968

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01617
Policy Update Magnitude: 0.10442
Value Function Update Magnitude: 0.07891

Collected Steps per Second: 25,811.81437
Overall Steps per Second: 18,850.09805

Timestep Collection Time: 1.93834
Timestep Consumption Time: 0.71587
PPO Batch Consumption Time: 0.05930
Total Iteration Time: 2.65420

Cumulative Model Updates: 1,886
Cumulative Timesteps: 31,509,786

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 31509786...
Checkpoint 31509786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00483
Policy Entropy: 4.37618
Value Function Loss: 0.10857

Mean KL Divergence: 0.00097
SB3 Clip Fraction: 0.00277
Policy Update Magnitude: 0.12217
Value Function Update Magnitude: 0.07519

Collected Steps per Second: 22,629.47354
Overall Steps per Second: 15,668.11115

Timestep Collection Time: 2.21075
Timestep Consumption Time: 0.98224
PPO Batch Consumption Time: 0.11208
Total Iteration Time: 3.19298

Cumulative Model Updates: 1,889
Cumulative Timesteps: 31,559,814

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00269
Policy Entropy: 4.36906
Value Function Loss: 0.08482

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.01191
Policy Update Magnitude: 0.12428
Value Function Update Magnitude: 0.08061

Collected Steps per Second: 25,758.41489
Overall Steps per Second: 17,893.18514

Timestep Collection Time: 1.94158
Timestep Consumption Time: 0.85345
PPO Batch Consumption Time: 0.10437
Total Iteration Time: 2.79503

Cumulative Model Updates: 1,892
Cumulative Timesteps: 31,609,826

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 31609826...
Checkpoint 31609826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02850
Policy Entropy: 4.34888
Value Function Loss: 0.07830

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02522
Policy Update Magnitude: 0.11730
Value Function Update Magnitude: 0.07601

Collected Steps per Second: 25,607.43431
Overall Steps per Second: 18,129.03397

Timestep Collection Time: 1.95350
Timestep Consumption Time: 0.80584
PPO Batch Consumption Time: 0.06053
Total Iteration Time: 2.75933

Cumulative Model Updates: 1,895
Cumulative Timesteps: 31,659,850

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00629
Policy Entropy: 4.33531
Value Function Loss: 0.07931

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02389
Policy Update Magnitude: 0.10701
Value Function Update Magnitude: 0.07238

Collected Steps per Second: 25,273.19145
Overall Steps per Second: 18,241.15357

Timestep Collection Time: 1.97854
Timestep Consumption Time: 0.76273
PPO Batch Consumption Time: 0.05655
Total Iteration Time: 2.74127

Cumulative Model Updates: 1,898
Cumulative Timesteps: 31,709,854

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 31709854...
Checkpoint 31709854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04564
Policy Entropy: 4.33671
Value Function Loss: 0.06982

Mean KL Divergence: 0.00112
SB3 Clip Fraction: 0.00606
Policy Update Magnitude: 0.11021
Value Function Update Magnitude: 0.07294

Collected Steps per Second: 24,988.28518
Overall Steps per Second: 17,406.47915

Timestep Collection Time: 2.00174
Timestep Consumption Time: 0.87190
PPO Batch Consumption Time: 0.09698
Total Iteration Time: 2.87364

Cumulative Model Updates: 1,901
Cumulative Timesteps: 31,759,874

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00454
Policy Entropy: 4.34538
Value Function Loss: 0.05603

Mean KL Divergence: 0.00083
SB3 Clip Fraction: 0.00076
Policy Update Magnitude: 0.11240
Value Function Update Magnitude: 0.06948

Collected Steps per Second: 25,538.87204
Overall Steps per Second: 18,129.02280

Timestep Collection Time: 1.95874
Timestep Consumption Time: 0.80059
PPO Batch Consumption Time: 0.05967
Total Iteration Time: 2.75933

Cumulative Model Updates: 1,904
Cumulative Timesteps: 31,809,898

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 31809898...
Checkpoint 31809898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00611
Policy Entropy: 4.35561
Value Function Loss: 0.04975

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.00187
Policy Update Magnitude: 0.10518
Value Function Update Magnitude: 0.06519

Collected Steps per Second: 22,731.49635
Overall Steps per Second: 16,597.78515

Timestep Collection Time: 2.20082
Timestep Consumption Time: 0.81331
PPO Batch Consumption Time: 0.08877
Total Iteration Time: 3.01414

Cumulative Model Updates: 1,907
Cumulative Timesteps: 31,859,926

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02965
Policy Entropy: 4.36063
Value Function Loss: 0.06140

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.00575
Policy Update Magnitude: 0.10513
Value Function Update Magnitude: 0.06439

Collected Steps per Second: 25,954.66894
Overall Steps per Second: 18,390.75963

Timestep Collection Time: 1.92728
Timestep Consumption Time: 0.79267
PPO Batch Consumption Time: 0.06059
Total Iteration Time: 2.71995

Cumulative Model Updates: 1,910
Cumulative Timesteps: 31,909,948

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 31909948...
Checkpoint 31909948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00113
Policy Entropy: 4.36008
Value Function Loss: 0.07178

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.01507
Policy Update Magnitude: 0.11251
Value Function Update Magnitude: 0.07240

Collected Steps per Second: 25,798.40403
Overall Steps per Second: 18,564.58079

Timestep Collection Time: 1.93911
Timestep Consumption Time: 0.75559
PPO Batch Consumption Time: 0.06080
Total Iteration Time: 2.69470

Cumulative Model Updates: 1,913
Cumulative Timesteps: 31,959,974

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14266
Policy Entropy: 4.36222
Value Function Loss: 0.07208

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02127
Policy Update Magnitude: 0.10947
Value Function Update Magnitude: 0.06670

Collected Steps per Second: 22,473.08604
Overall Steps per Second: 15,965.62718

Timestep Collection Time: 2.22631
Timestep Consumption Time: 0.90742
PPO Batch Consumption Time: 0.12471
Total Iteration Time: 3.13373

Cumulative Model Updates: 1,916
Cumulative Timesteps: 32,010,006

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 32010006...
Checkpoint 32010006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04036
Policy Entropy: 4.37559
Value Function Loss: 0.07694

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.00357
Policy Update Magnitude: 0.11313
Value Function Update Magnitude: 0.07183

Collected Steps per Second: 25,746.56545
Overall Steps per Second: 18,127.90077

Timestep Collection Time: 1.94240
Timestep Consumption Time: 0.81634
PPO Batch Consumption Time: 0.06143
Total Iteration Time: 2.75873

Cumulative Model Updates: 1,919
Cumulative Timesteps: 32,060,016

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01365
Policy Entropy: 4.39531
Value Function Loss: 0.09229

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01779
Policy Update Magnitude: 0.11025
Value Function Update Magnitude: 0.07098

Collected Steps per Second: 25,652.33051
Overall Steps per Second: 18,924.10164

Timestep Collection Time: 1.94992
Timestep Consumption Time: 0.69327
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 2.64319

Cumulative Model Updates: 1,922
Cumulative Timesteps: 32,110,036

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 32110036...
Checkpoint 32110036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00036
Policy Entropy: 4.40506
Value Function Loss: 0.09982

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02316
Policy Update Magnitude: 0.09964
Value Function Update Magnitude: 0.06638

Collected Steps per Second: 22,895.15402
Overall Steps per Second: 15,847.87711

Timestep Collection Time: 2.18474
Timestep Consumption Time: 0.97152
PPO Batch Consumption Time: 0.11970
Total Iteration Time: 3.15626

Cumulative Model Updates: 1,925
Cumulative Timesteps: 32,160,056

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03579
Policy Entropy: 4.39515
Value Function Loss: 0.09018

Mean KL Divergence: 0.00092
SB3 Clip Fraction: 0.00520
Policy Update Magnitude: 0.11115
Value Function Update Magnitude: 0.06632

Collected Steps per Second: 25,986.22510
Overall Steps per Second: 17,808.29117

Timestep Collection Time: 1.92456
Timestep Consumption Time: 0.88380
PPO Batch Consumption Time: 0.09778
Total Iteration Time: 2.80835

Cumulative Model Updates: 1,928
Cumulative Timesteps: 32,210,068

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 32210068...
Checkpoint 32210068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02001
Policy Entropy: 4.38826
Value Function Loss: 0.06330

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01747
Policy Update Magnitude: 0.10437
Value Function Update Magnitude: 0.05929

Collected Steps per Second: 25,268.79292
Overall Steps per Second: 18,580.46123

Timestep Collection Time: 1.97920
Timestep Consumption Time: 0.71244
PPO Batch Consumption Time: 0.05951
Total Iteration Time: 2.69164

Cumulative Model Updates: 1,931
Cumulative Timesteps: 32,260,080

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02960
Policy Entropy: 4.39361
Value Function Loss: 0.03420

Mean KL Divergence: 0.00061
SB3 Clip Fraction: 0.00057
Policy Update Magnitude: 0.09647
Value Function Update Magnitude: 0.05533

Collected Steps per Second: 22,785.68665
Overall Steps per Second: 16,198.27439

Timestep Collection Time: 2.19480
Timestep Consumption Time: 0.89257
PPO Batch Consumption Time: 0.09592
Total Iteration Time: 3.08737

Cumulative Model Updates: 1,934
Cumulative Timesteps: 32,310,090

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 32310090...
Checkpoint 32310090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03890
Policy Entropy: 4.39582
Value Function Loss: 0.04837

Mean KL Divergence: 0.00109
SB3 Clip Fraction: 0.00679
Policy Update Magnitude: 0.08712
Value Function Update Magnitude: 0.05938

Collected Steps per Second: 25,610.77196
Overall Steps per Second: 18,474.48905

Timestep Collection Time: 1.95340
Timestep Consumption Time: 0.75455
PPO Batch Consumption Time: 0.05957
Total Iteration Time: 2.70795

Cumulative Model Updates: 1,937
Cumulative Timesteps: 32,360,118

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10909
Policy Entropy: 4.39247
Value Function Loss: 0.06490

Mean KL Divergence: 0.00080
SB3 Clip Fraction: 0.00151
Policy Update Magnitude: 0.08914
Value Function Update Magnitude: 0.06227

Collected Steps per Second: 26,125.53672
Overall Steps per Second: 18,476.52393

Timestep Collection Time: 1.91430
Timestep Consumption Time: 0.79249
PPO Batch Consumption Time: 0.05912
Total Iteration Time: 2.70679

Cumulative Model Updates: 1,940
Cumulative Timesteps: 32,410,130

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 32410130...
Checkpoint 32410130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01027
Policy Entropy: 4.38769
Value Function Loss: 0.08687

Mean KL Divergence: 0.00088
SB3 Clip Fraction: 0.00073
Policy Update Magnitude: 0.10627
Value Function Update Magnitude: 0.06589

Collected Steps per Second: 22,516.51913
Overall Steps per Second: 15,918.39999

Timestep Collection Time: 2.22059
Timestep Consumption Time: 0.92043
PPO Batch Consumption Time: 0.10881
Total Iteration Time: 3.14102

Cumulative Model Updates: 1,943
Cumulative Timesteps: 32,460,130

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03521
Policy Entropy: 4.37880
Value Function Loss: 0.07668

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.00563
Policy Update Magnitude: 0.11544
Value Function Update Magnitude: 0.06774

Collected Steps per Second: 25,593.37181
Overall Steps per Second: 18,897.63589

Timestep Collection Time: 1.95480
Timestep Consumption Time: 0.69262
PPO Batch Consumption Time: 0.05802
Total Iteration Time: 2.64742

Cumulative Model Updates: 1,946
Cumulative Timesteps: 32,510,160

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 32510160...
Checkpoint 32510160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03108
Policy Entropy: 4.36703
Value Function Loss: 0.06448

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.01939
Policy Update Magnitude: 0.10303
Value Function Update Magnitude: 0.06934

Collected Steps per Second: 22,356.02920
Overall Steps per Second: 15,937.71912

Timestep Collection Time: 2.23707
Timestep Consumption Time: 0.90089
PPO Batch Consumption Time: 0.09069
Total Iteration Time: 3.13796

Cumulative Model Updates: 1,949
Cumulative Timesteps: 32,560,172

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12390
Policy Entropy: 4.35942
Value Function Loss: 0.05738

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.00345
Policy Update Magnitude: 0.09304
Value Function Update Magnitude: 0.05734

Collected Steps per Second: 25,331.62855
Overall Steps per Second: 18,554.17526

Timestep Collection Time: 1.97421
Timestep Consumption Time: 0.72114
PPO Batch Consumption Time: 0.06007
Total Iteration Time: 2.69535

Cumulative Model Updates: 1,952
Cumulative Timesteps: 32,610,182

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 32610182...
Checkpoint 32610182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02531
Policy Entropy: 4.35122
Value Function Loss: 0.05479

Mean KL Divergence: 0.00085
SB3 Clip Fraction: 0.00020
Policy Update Magnitude: 0.09454
Value Function Update Magnitude: 0.05410

Collected Steps per Second: 25,814.47119
Overall Steps per Second: 17,452.63422

Timestep Collection Time: 1.93752
Timestep Consumption Time: 0.92830
PPO Batch Consumption Time: 0.10464
Total Iteration Time: 2.86581

Cumulative Model Updates: 1,955
Cumulative Timesteps: 32,660,198

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02378
Policy Entropy: 4.33769
Value Function Loss: 0.04689

Mean KL Divergence: 0.00113
SB3 Clip Fraction: 0.00073
Policy Update Magnitude: 0.09962
Value Function Update Magnitude: 0.05401

Collected Steps per Second: 25,715.61864
Overall Steps per Second: 18,429.50965

Timestep Collection Time: 1.94481
Timestep Consumption Time: 0.76888
PPO Batch Consumption Time: 0.06013
Total Iteration Time: 2.71369

Cumulative Model Updates: 1,958
Cumulative Timesteps: 32,710,210

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 32710210...
Checkpoint 32710210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01991
Policy Entropy: 4.32498
Value Function Loss: 0.04699

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.00399
Policy Update Magnitude: 0.09592
Value Function Update Magnitude: 0.05217

Collected Steps per Second: 25,353.37200
Overall Steps per Second: 18,618.15938

Timestep Collection Time: 1.97244
Timestep Consumption Time: 0.71354
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 2.68598

Cumulative Model Updates: 1,961
Cumulative Timesteps: 32,760,218

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04702
Policy Entropy: 4.31619
Value Function Loss: 0.04461

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.00575
Policy Update Magnitude: 0.09072
Value Function Update Magnitude: 0.05215

Collected Steps per Second: 21,718.29687
Overall Steps per Second: 15,739.81356

Timestep Collection Time: 2.30304
Timestep Consumption Time: 0.87477
PPO Batch Consumption Time: 0.08310
Total Iteration Time: 3.17780

Cumulative Model Updates: 1,964
Cumulative Timesteps: 32,810,236

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 32810236...
Checkpoint 32810236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04786
Policy Entropy: 4.31030
Value Function Loss: 0.05645

Mean KL Divergence: 0.00113
SB3 Clip Fraction: 0.00131
Policy Update Magnitude: 0.09108
Value Function Update Magnitude: 0.04767

Collected Steps per Second: 25,111.50742
Overall Steps per Second: 17,927.79028

Timestep Collection Time: 1.99215
Timestep Consumption Time: 0.79826
PPO Batch Consumption Time: 0.08062
Total Iteration Time: 2.79042

Cumulative Model Updates: 1,967
Cumulative Timesteps: 32,860,262

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00540
Policy Entropy: 4.30339
Value Function Loss: 0.07647

Mean KL Divergence: 0.00102
SB3 Clip Fraction: 0.00025
Policy Update Magnitude: 0.09370
Value Function Update Magnitude: 0.05509

Collected Steps per Second: 25,506.58414
Overall Steps per Second: 18,215.15778

Timestep Collection Time: 1.96122
Timestep Consumption Time: 0.78507
PPO Batch Consumption Time: 0.05926
Total Iteration Time: 2.74628

Cumulative Model Updates: 1,970
Cumulative Timesteps: 32,910,286

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 32910286...
Checkpoint 32910286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01336
Policy Entropy: 4.29237
Value Function Loss: 0.08791

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.00126
Policy Update Magnitude: 0.10749
Value Function Update Magnitude: 0.05347

Collected Steps per Second: 23,011.44857
Overall Steps per Second: 16,546.76149

Timestep Collection Time: 2.17292
Timestep Consumption Time: 0.84894
PPO Batch Consumption Time: 0.07981
Total Iteration Time: 3.02186

Cumulative Model Updates: 1,973
Cumulative Timesteps: 32,960,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09225
Policy Entropy: 4.27709
Value Function Loss: 0.08421

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.00511
Policy Update Magnitude: 0.11054
Value Function Update Magnitude: 0.05631

Collected Steps per Second: 25,571.49699
Overall Steps per Second: 18,834.60239

Timestep Collection Time: 1.95640
Timestep Consumption Time: 0.69978
PPO Batch Consumption Time: 0.05794
Total Iteration Time: 2.65618

Cumulative Model Updates: 1,976
Cumulative Timesteps: 33,010,316

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 33010316...
Checkpoint 33010316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00679
Policy Entropy: 4.26112
Value Function Loss: 0.07061

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01015
Policy Update Magnitude: 0.10186
Value Function Update Magnitude: 0.05825

Collected Steps per Second: 22,660.72317
Overall Steps per Second: 16,022.13861

Timestep Collection Time: 2.20734
Timestep Consumption Time: 0.91459
PPO Batch Consumption Time: 0.07325
Total Iteration Time: 3.12193

Cumulative Model Updates: 1,979
Cumulative Timesteps: 33,060,336

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04628
Policy Entropy: 4.25517
Value Function Loss: 0.04987

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.00179
Policy Update Magnitude: 0.09622
Value Function Update Magnitude: 0.06329

Collected Steps per Second: 23,681.02394
Overall Steps per Second: 16,703.48433

Timestep Collection Time: 2.11156
Timestep Consumption Time: 0.88206
PPO Batch Consumption Time: 0.07517
Total Iteration Time: 2.99363

Cumulative Model Updates: 1,982
Cumulative Timesteps: 33,110,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 33110340...
Checkpoint 33110340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00386
Policy Entropy: 4.25519
Value Function Loss: 0.05722

Mean KL Divergence: 0.00115
SB3 Clip Fraction: 0.00098
Policy Update Magnitude: 0.09469
Value Function Update Magnitude: 0.06633

Collected Steps per Second: 24,577.10345
Overall Steps per Second: 16,787.24253

Timestep Collection Time: 2.03498
Timestep Consumption Time: 0.94430
PPO Batch Consumption Time: 0.07498
Total Iteration Time: 2.97929

Cumulative Model Updates: 1,985
Cumulative Timesteps: 33,160,354

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01304
Policy Entropy: 4.25708
Value Function Loss: 0.06929

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.00995
Policy Update Magnitude: 0.09250
Value Function Update Magnitude: 0.05384

Collected Steps per Second: 26,148.84151
Overall Steps per Second: 17,912.96927

Timestep Collection Time: 1.91213
Timestep Consumption Time: 0.87914
PPO Batch Consumption Time: 0.08421
Total Iteration Time: 2.79127

Cumulative Model Updates: 1,988
Cumulative Timesteps: 33,210,354

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 33210354...
Checkpoint 33210354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01912
Policy Entropy: 4.27287
Value Function Loss: 0.07663

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01177
Policy Update Magnitude: 0.10181
Value Function Update Magnitude: 0.05490

Collected Steps per Second: 25,228.33413
Overall Steps per Second: 18,494.18475

Timestep Collection Time: 1.98222
Timestep Consumption Time: 0.72177
PPO Batch Consumption Time: 0.06027
Total Iteration Time: 2.70399

Cumulative Model Updates: 1,991
Cumulative Timesteps: 33,260,362

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03114
Policy Entropy: 4.29110
Value Function Loss: 0.07004

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.00450
Policy Update Magnitude: 0.10383
Value Function Update Magnitude: 0.05443

Collected Steps per Second: 25,531.16698
Overall Steps per Second: 18,122.58391

Timestep Collection Time: 1.95949
Timestep Consumption Time: 0.80105
PPO Batch Consumption Time: 0.06155
Total Iteration Time: 2.76053

Cumulative Model Updates: 1,994
Cumulative Timesteps: 33,310,390

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 33310390...
Checkpoint 33310390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01844
Policy Entropy: 4.30736
Value Function Loss: 0.07407

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.00765
Policy Update Magnitude: 0.10248
Value Function Update Magnitude: 0.06240

Collected Steps per Second: 23,285.39477
Overall Steps per Second: 16,283.99687

Timestep Collection Time: 2.14753
Timestep Consumption Time: 0.92334
PPO Batch Consumption Time: 0.11205
Total Iteration Time: 3.07087

Cumulative Model Updates: 1,997
Cumulative Timesteps: 33,360,396

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00825
Policy Entropy: 4.32093
Value Function Loss: 0.06836

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.00997
Policy Update Magnitude: 0.10366
Value Function Update Magnitude: 0.06621

Collected Steps per Second: 26,591.81359
Overall Steps per Second: 17,812.37762

Timestep Collection Time: 1.88080
Timestep Consumption Time: 0.92702
PPO Batch Consumption Time: 0.10558
Total Iteration Time: 2.80782

Cumulative Model Updates: 2,000
Cumulative Timesteps: 33,410,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 33410410...
Checkpoint 33410410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03011
Policy Entropy: 4.32646
Value Function Loss: 0.07406

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.01893
Policy Update Magnitude: 0.09475
Value Function Update Magnitude: 0.07325

Collected Steps per Second: 25,411.22232
Overall Steps per Second: 18,172.39968

Timestep Collection Time: 1.96779
Timestep Consumption Time: 0.78385
PPO Batch Consumption Time: 0.06005
Total Iteration Time: 2.75165

Cumulative Model Updates: 2,003
Cumulative Timesteps: 33,460,414

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00643
Policy Entropy: 4.33217
Value Function Loss: 0.06537

Mean KL Divergence: 0.00117
SB3 Clip Fraction: 0.00171
Policy Update Magnitude: 0.09241
Value Function Update Magnitude: 0.07851

Collected Steps per Second: 22,934.59989
Overall Steps per Second: 16,549.33085

Timestep Collection Time: 2.18098
Timestep Consumption Time: 0.84149
PPO Batch Consumption Time: 0.10622
Total Iteration Time: 3.02248

Cumulative Model Updates: 2,006
Cumulative Timesteps: 33,510,434

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 33510434...
Checkpoint 33510434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03054
Policy Entropy: 4.33596
Value Function Loss: 0.07768

Mean KL Divergence: 0.00078
SB3 Clip Fraction: 0.00029
Policy Update Magnitude: 0.09043
Value Function Update Magnitude: 0.07738

Collected Steps per Second: 25,667.50237
Overall Steps per Second: 18,118.76837

Timestep Collection Time: 1.94830
Timestep Consumption Time: 0.81171
PPO Batch Consumption Time: 0.05861
Total Iteration Time: 2.76001

Cumulative Model Updates: 2,009
Cumulative Timesteps: 33,560,442

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03616
Policy Entropy: 4.33380
Value Function Loss: 0.06856

Mean KL Divergence: 0.00073
SB3 Clip Fraction: 0.00022
Policy Update Magnitude: 0.09513
Value Function Update Magnitude: 0.07821

Collected Steps per Second: 22,508.37808
Overall Steps per Second: 15,642.10102

Timestep Collection Time: 2.22193
Timestep Consumption Time: 0.97534
PPO Batch Consumption Time: 0.12650
Total Iteration Time: 3.19727

Cumulative Model Updates: 2,012
Cumulative Timesteps: 33,610,454

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 33610454...
Checkpoint 33610454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03084
Policy Entropy: 4.32964
Value Function Loss: 0.06217

Mean KL Divergence: 0.00073
SB3 Clip Fraction: 0.00014
Policy Update Magnitude: 0.09756
Value Function Update Magnitude: 0.07135

Collected Steps per Second: 26,601.50198
Overall Steps per Second: 18,740.46336

Timestep Collection Time: 1.87967
Timestep Consumption Time: 0.78846
PPO Batch Consumption Time: 0.05957
Total Iteration Time: 2.66813

Cumulative Model Updates: 2,015
Cumulative Timesteps: 33,660,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00408
Policy Entropy: 4.32079
Value Function Loss: 0.05576

Mean KL Divergence: 0.00087
SB3 Clip Fraction: 0.00091
Policy Update Magnitude: 0.09544
Value Function Update Magnitude: 0.06954

Collected Steps per Second: 23,190.23877
Overall Steps per Second: 16,063.26086

Timestep Collection Time: 2.15694
Timestep Consumption Time: 0.95700
PPO Batch Consumption Time: 0.11433
Total Iteration Time: 3.11394

Cumulative Model Updates: 2,018
Cumulative Timesteps: 33,710,476

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 33710476...
Checkpoint 33710476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03599
Policy Entropy: 4.30857
Value Function Loss: 0.05767

Mean KL Divergence: 0.00107
SB3 Clip Fraction: 0.00303
Policy Update Magnitude: 0.09356
Value Function Update Magnitude: 0.07135

Collected Steps per Second: 25,107.18237
Overall Steps per Second: 16,808.71690

Timestep Collection Time: 1.99226
Timestep Consumption Time: 0.98358
PPO Batch Consumption Time: 0.12708
Total Iteration Time: 2.97584

Cumulative Model Updates: 2,021
Cumulative Timesteps: 33,760,496

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04935
Policy Entropy: 4.29765
Value Function Loss: 0.06627

Mean KL Divergence: 0.00143
SB3 Clip Fraction: 0.01070
Policy Update Magnitude: 0.08854
Value Function Update Magnitude: 0.07043

Collected Steps per Second: 26,912.75670
Overall Steps per Second: 17,848.64575

Timestep Collection Time: 1.85830
Timestep Consumption Time: 0.94370
PPO Batch Consumption Time: 0.10368
Total Iteration Time: 2.80201

Cumulative Model Updates: 2,024
Cumulative Timesteps: 33,810,508

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 33810508...
Checkpoint 33810508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04214
Policy Entropy: 4.29085
Value Function Loss: 0.07890

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.00563
Policy Update Magnitude: 0.09216
Value Function Update Magnitude: 0.07002

Collected Steps per Second: 25,593.62552
Overall Steps per Second: 18,377.48310

Timestep Collection Time: 1.95369
Timestep Consumption Time: 0.76714
PPO Batch Consumption Time: 0.06008
Total Iteration Time: 2.72083

Cumulative Model Updates: 2,027
Cumulative Timesteps: 33,860,510

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00546
Policy Entropy: 4.28506
Value Function Loss: 0.07833

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.00911
Policy Update Magnitude: 0.09419
Value Function Update Magnitude: 0.06301

Collected Steps per Second: 25,029.04424
Overall Steps per Second: 18,674.20465

Timestep Collection Time: 1.99816
Timestep Consumption Time: 0.67997
PPO Batch Consumption Time: 0.05423
Total Iteration Time: 2.67813

Cumulative Model Updates: 2,030
Cumulative Timesteps: 33,910,522

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 33910522...
Checkpoint 33910522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00402
Policy Entropy: 4.27296
Value Function Loss: 0.07623

Mean KL Divergence: 0.00139
SB3 Clip Fraction: 0.00469
Policy Update Magnitude: 0.09901
Value Function Update Magnitude: 0.06500

Collected Steps per Second: 21,361.71468
Overall Steps per Second: 14,935.66317

Timestep Collection Time: 2.34073
Timestep Consumption Time: 1.00710
PPO Batch Consumption Time: 0.12626
Total Iteration Time: 3.34783

Cumulative Model Updates: 2,033
Cumulative Timesteps: 33,960,524

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00237
Policy Entropy: 4.26755
Value Function Loss: 0.06881

Mean KL Divergence: 0.00143
SB3 Clip Fraction: 0.01023
Policy Update Magnitude: 0.09768
Value Function Update Magnitude: 0.06591

Collected Steps per Second: 25,253.70333
Overall Steps per Second: 18,169.42251

Timestep Collection Time: 1.98062
Timestep Consumption Time: 0.77225
PPO Batch Consumption Time: 0.06208
Total Iteration Time: 2.75287

Cumulative Model Updates: 2,036
Cumulative Timesteps: 34,010,542

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 34010542...
Checkpoint 34010542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03697
Policy Entropy: 4.26850
Value Function Loss: 0.06651

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.00635
Policy Update Magnitude: 0.09964
Value Function Update Magnitude: 0.06781

Collected Steps per Second: 26,508.69149
Overall Steps per Second: 18,936.58591

Timestep Collection Time: 1.88678
Timestep Consumption Time: 0.75446
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 2.64124

Cumulative Model Updates: 2,039
Cumulative Timesteps: 34,060,558

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00768
Policy Entropy: 4.26157
Value Function Loss: 0.05889

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.00547
Policy Update Magnitude: 0.09859
Value Function Update Magnitude: 0.06522

Collected Steps per Second: 23,119.70356
Overall Steps per Second: 16,640.38933

Timestep Collection Time: 2.16421
Timestep Consumption Time: 0.84269
PPO Batch Consumption Time: 0.07381
Total Iteration Time: 3.00690

Cumulative Model Updates: 2,042
Cumulative Timesteps: 34,110,594

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 34110594...
Checkpoint 34110594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03670
Policy Entropy: 4.25420
Value Function Loss: 0.05326

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.01566
Policy Update Magnitude: 0.08946
Value Function Update Magnitude: 0.06080

Collected Steps per Second: 25,498.62430
Overall Steps per Second: 18,769.54504

Timestep Collection Time: 1.96199
Timestep Consumption Time: 0.70339
PPO Batch Consumption Time: 0.05885
Total Iteration Time: 2.66538

Cumulative Model Updates: 2,045
Cumulative Timesteps: 34,160,622

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00285
Policy Entropy: 4.26298
Value Function Loss: 0.04767

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02197
Policy Update Magnitude: 0.08801
Value Function Update Magnitude: 0.06204

Collected Steps per Second: 22,925.26637
Overall Steps per Second: 16,088.31064

Timestep Collection Time: 2.18222
Timestep Consumption Time: 0.92737
PPO Batch Consumption Time: 0.09139
Total Iteration Time: 3.10959

Cumulative Model Updates: 2,048
Cumulative Timesteps: 34,210,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 34210650...
Checkpoint 34210650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09880
Policy Entropy: 4.28452
Value Function Loss: 0.05261

Mean KL Divergence: 0.00155
SB3 Clip Fraction: 0.00671
Policy Update Magnitude: 0.09092
Value Function Update Magnitude: 0.05747

Collected Steps per Second: 25,251.89918
Overall Steps per Second: 17,845.58951

Timestep Collection Time: 1.98045
Timestep Consumption Time: 0.82193
PPO Batch Consumption Time: 0.07814
Total Iteration Time: 2.80237

Cumulative Model Updates: 2,051
Cumulative Timesteps: 34,260,660

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00844
Policy Entropy: 4.30417
Value Function Loss: 0.07239

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01082
Policy Update Magnitude: 0.09181
Value Function Update Magnitude: 0.05862

Collected Steps per Second: 24,965.86094
Overall Steps per Second: 16,986.32799

Timestep Collection Time: 2.00394
Timestep Consumption Time: 0.94137
PPO Batch Consumption Time: 0.10544
Total Iteration Time: 2.94531

Cumulative Model Updates: 2,054
Cumulative Timesteps: 34,310,690

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 34310690...
Checkpoint 34310690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01363
Policy Entropy: 4.31707
Value Function Loss: 0.09892

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.00677
Policy Update Magnitude: 0.09318
Value Function Update Magnitude: 0.07303

Collected Steps per Second: 25,578.38176
Overall Steps per Second: 18,117.56114

Timestep Collection Time: 1.95595
Timestep Consumption Time: 0.80546
PPO Batch Consumption Time: 0.06347
Total Iteration Time: 2.76141

Cumulative Model Updates: 2,057
Cumulative Timesteps: 34,360,720

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08105
Policy Entropy: 4.32006
Value Function Loss: 0.10002

Mean KL Divergence: 0.00087
SB3 Clip Fraction: 0.00047
Policy Update Magnitude: 0.09788
Value Function Update Magnitude: 0.08730

Collected Steps per Second: 25,826.94532
Overall Steps per Second: 18,874.24146

Timestep Collection Time: 1.93658
Timestep Consumption Time: 0.71338
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 2.64996

Cumulative Model Updates: 2,060
Cumulative Timesteps: 34,410,736

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 34410736...
Checkpoint 34410736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00343
Policy Entropy: 4.31697
Value Function Loss: 0.09378

Mean KL Divergence: 0.00066
SB3 Clip Fraction: 0.00009
Policy Update Magnitude: 0.10304
Value Function Update Magnitude: 0.09968

Collected Steps per Second: 22,767.46767
Overall Steps per Second: 15,894.33991

Timestep Collection Time: 2.19691
Timestep Consumption Time: 0.95000
PPO Batch Consumption Time: 0.11090
Total Iteration Time: 3.14691

Cumulative Model Updates: 2,063
Cumulative Timesteps: 34,460,754

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03225
Policy Entropy: 4.30508
Value Function Loss: 0.06962

Mean KL Divergence: 0.00103
SB3 Clip Fraction: 0.00066
Policy Update Magnitude: 0.10372
Value Function Update Magnitude: 0.09143

Collected Steps per Second: 25,762.57866
Overall Steps per Second: 17,799.99823

Timestep Collection Time: 1.94127
Timestep Consumption Time: 0.86840
PPO Batch Consumption Time: 0.09516
Total Iteration Time: 2.80966

Cumulative Model Updates: 2,066
Cumulative Timesteps: 34,510,766

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 34510766...
Checkpoint 34510766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03503
Policy Entropy: 4.28817
Value Function Loss: 0.07379

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.00435
Policy Update Magnitude: 0.10385
Value Function Update Magnitude: 0.08429

Collected Steps per Second: 25,365.94943
Overall Steps per Second: 18,499.28926

Timestep Collection Time: 1.97217
Timestep Consumption Time: 0.73204
PPO Batch Consumption Time: 0.06058
Total Iteration Time: 2.70421

Cumulative Model Updates: 2,069
Cumulative Timesteps: 34,560,792

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01305
Policy Entropy: 4.27392
Value Function Loss: 0.06355

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.00257
Policy Update Magnitude: 0.10075
Value Function Update Magnitude: 0.08546

Collected Steps per Second: 25,820.52259
Overall Steps per Second: 18,297.65044

Timestep Collection Time: 1.93691
Timestep Consumption Time: 0.79634
PPO Batch Consumption Time: 0.06052
Total Iteration Time: 2.73325

Cumulative Model Updates: 2,072
Cumulative Timesteps: 34,610,804

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 34610804...
Checkpoint 34610804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00861
Policy Entropy: 4.26902
Value Function Loss: 0.07199

Mean KL Divergence: 0.00133
SB3 Clip Fraction: 0.00310
Policy Update Magnitude: 0.10150
Value Function Update Magnitude: 0.08379

Collected Steps per Second: 22,862.96186
Overall Steps per Second: 16,130.62381

Timestep Collection Time: 2.18791
Timestep Consumption Time: 0.91315
PPO Batch Consumption Time: 0.12085
Total Iteration Time: 3.10106

Cumulative Model Updates: 2,075
Cumulative Timesteps: 34,660,826

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01595
Policy Entropy: 4.26816
Value Function Loss: 0.06611

Mean KL Divergence: 0.00117
SB3 Clip Fraction: 0.00497
Policy Update Magnitude: 0.09657
Value Function Update Magnitude: 0.08168

Collected Steps per Second: 25,939.07802
Overall Steps per Second: 17,758.29440

Timestep Collection Time: 1.92821
Timestep Consumption Time: 0.88828
PPO Batch Consumption Time: 0.08582
Total Iteration Time: 2.81649

Cumulative Model Updates: 2,078
Cumulative Timesteps: 34,710,842

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 34710842...
Checkpoint 34710842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03465
Policy Entropy: 4.27097
Value Function Loss: 0.06297

Mean KL Divergence: 0.00123
SB3 Clip Fraction: 0.00380
Policy Update Magnitude: 0.09885
Value Function Update Magnitude: 0.07970

Collected Steps per Second: 25,511.96072
Overall Steps per Second: 18,405.54395

Timestep Collection Time: 1.96049
Timestep Consumption Time: 0.75695
PPO Batch Consumption Time: 0.05972
Total Iteration Time: 2.71744

Cumulative Model Updates: 2,081
Cumulative Timesteps: 34,760,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01047
Policy Entropy: 4.26024
Value Function Loss: 0.05934

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01149
Policy Update Magnitude: 0.09695
Value Function Update Magnitude: 0.07481

Collected Steps per Second: 24,810.92915
Overall Steps per Second: 17,882.23802

Timestep Collection Time: 2.01581
Timestep Consumption Time: 0.78105
PPO Batch Consumption Time: 0.06380
Total Iteration Time: 2.79685

Cumulative Model Updates: 2,084
Cumulative Timesteps: 34,810,872

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 34810872...
Checkpoint 34810872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00562
Policy Entropy: 4.23471
Value Function Loss: 0.06554

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.01121
Policy Update Magnitude: 0.09389
Value Function Update Magnitude: 0.06961

Collected Steps per Second: 25,831.16855
Overall Steps per Second: 17,627.26047

Timestep Collection Time: 1.93572
Timestep Consumption Time: 0.90091
PPO Batch Consumption Time: 0.09475
Total Iteration Time: 2.83663

Cumulative Model Updates: 2,087
Cumulative Timesteps: 34,860,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01632
Policy Entropy: 4.22423
Value Function Loss: 0.06180

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.00720
Policy Update Magnitude: 0.09274
Value Function Update Magnitude: 0.06929

Collected Steps per Second: 25,340.00542
Overall Steps per Second: 18,467.23568

Timestep Collection Time: 1.97395
Timestep Consumption Time: 0.73463
PPO Batch Consumption Time: 0.06072
Total Iteration Time: 2.70858

Cumulative Model Updates: 2,090
Cumulative Timesteps: 34,910,894

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 34910894...
Checkpoint 34910894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00642
Policy Entropy: 4.23015
Value Function Loss: 0.05967

Mean KL Divergence: 0.00135
SB3 Clip Fraction: 0.00553
Policy Update Magnitude: 0.09577
Value Function Update Magnitude: 0.07291

Collected Steps per Second: 25,684.10502
Overall Steps per Second: 18,281.52629

Timestep Collection Time: 1.94751
Timestep Consumption Time: 0.78859
PPO Batch Consumption Time: 0.05989
Total Iteration Time: 2.73610

Cumulative Model Updates: 2,093
Cumulative Timesteps: 34,960,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03343
Policy Entropy: 4.24679
Value Function Loss: 0.04734

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.00577
Policy Update Magnitude: 0.09281
Value Function Update Magnitude: 0.06547

Collected Steps per Second: 21,534.02261
Overall Steps per Second: 15,969.58318

Timestep Collection Time: 2.32191
Timestep Consumption Time: 0.80905
PPO Batch Consumption Time: 0.07045
Total Iteration Time: 3.13095

Cumulative Model Updates: 2,096
Cumulative Timesteps: 35,010,914

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 35010914...
Checkpoint 35010914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00986
Policy Entropy: 4.26034
Value Function Loss: 0.04644

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01230
Policy Update Magnitude: 0.08809
Value Function Update Magnitude: 0.06242

Collected Steps per Second: 24,926.82871
Overall Steps per Second: 17,837.86197

Timestep Collection Time: 2.00659
Timestep Consumption Time: 0.79744
PPO Batch Consumption Time: 0.07831
Total Iteration Time: 2.80404

Cumulative Model Updates: 2,099
Cumulative Timesteps: 35,060,932

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02477
Policy Entropy: 4.26788
Value Function Loss: 0.04262

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01158
Policy Update Magnitude: 0.08407
Value Function Update Magnitude: 0.05660

Collected Steps per Second: 24,083.70750
Overall Steps per Second: 16,843.36412

Timestep Collection Time: 2.07626
Timestep Consumption Time: 0.89251
PPO Batch Consumption Time: 0.09284
Total Iteration Time: 2.96877

Cumulative Model Updates: 2,102
Cumulative Timesteps: 35,110,936

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 35110936...
Checkpoint 35110936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07798
Policy Entropy: 4.28007
Value Function Loss: 0.04546

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.00696
Policy Update Magnitude: 0.08484
Value Function Update Magnitude: 0.05148

Collected Steps per Second: 25,401.89440
Overall Steps per Second: 18,781.37836

Timestep Collection Time: 1.96851
Timestep Consumption Time: 0.69391
PPO Batch Consumption Time: 0.05764
Total Iteration Time: 2.66242

Cumulative Model Updates: 2,105
Cumulative Timesteps: 35,160,940

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00148
Policy Entropy: 4.29625
Value Function Loss: 0.04575

Mean KL Divergence: 0.00135
SB3 Clip Fraction: 0.00523
Policy Update Magnitude: 0.08197
Value Function Update Magnitude: 0.05605

Collected Steps per Second: 23,245.07082
Overall Steps per Second: 16,157.73715

Timestep Collection Time: 2.15151
Timestep Consumption Time: 0.94373
PPO Batch Consumption Time: 0.10985
Total Iteration Time: 3.09524

Cumulative Model Updates: 2,108
Cumulative Timesteps: 35,210,952

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 35210952...
Checkpoint 35210952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01140
Policy Entropy: 4.30767
Value Function Loss: 0.05081

Mean KL Divergence: 0.00144
SB3 Clip Fraction: 0.00461
Policy Update Magnitude: 0.07802
Value Function Update Magnitude: 0.06146

Collected Steps per Second: 25,292.07030
Overall Steps per Second: 18,172.34015

Timestep Collection Time: 1.97690
Timestep Consumption Time: 0.77453
PPO Batch Consumption Time: 0.06297
Total Iteration Time: 2.75143

Cumulative Model Updates: 2,111
Cumulative Timesteps: 35,260,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04429
Policy Entropy: 4.31251
Value Function Loss: 0.04768

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.00841
Policy Update Magnitude: 0.07993
Value Function Update Magnitude: 0.05763

Collected Steps per Second: 25,555.25650
Overall Steps per Second: 17,712.89580

Timestep Collection Time: 1.95764
Timestep Consumption Time: 0.86674
PPO Batch Consumption Time: 0.10809
Total Iteration Time: 2.82438

Cumulative Model Updates: 2,114
Cumulative Timesteps: 35,310,980

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 35310980...
Checkpoint 35310980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00802
Policy Entropy: 4.32008
Value Function Loss: 0.04996

Mean KL Divergence: 0.00104
SB3 Clip Fraction: 0.00100
Policy Update Magnitude: 0.08155
Value Function Update Magnitude: 0.05837

Collected Steps per Second: 25,454.55434
Overall Steps per Second: 18,122.42710

Timestep Collection Time: 1.96436
Timestep Consumption Time: 0.79476
PPO Batch Consumption Time: 0.06095
Total Iteration Time: 2.75912

Cumulative Model Updates: 2,117
Cumulative Timesteps: 35,360,982

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01632
Policy Entropy: 4.33011
Value Function Loss: 0.03584

Mean KL Divergence: 0.00080
SB3 Clip Fraction: 0.00131
Policy Update Magnitude: 0.07896
Value Function Update Magnitude: 0.06126

Collected Steps per Second: 25,630.30249
Overall Steps per Second: 19,000.05387

Timestep Collection Time: 1.95121
Timestep Consumption Time: 0.68089
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 2.63210

Cumulative Model Updates: 2,120
Cumulative Timesteps: 35,410,992

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 35410992...
Checkpoint 35410992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00846
Policy Entropy: 4.33815
Value Function Loss: 0.05103

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.01042
Policy Update Magnitude: 0.07145
Value Function Update Magnitude: 0.06414

Collected Steps per Second: 22,684.83467
Overall Steps per Second: 15,801.76771

Timestep Collection Time: 2.20509
Timestep Consumption Time: 0.96051
PPO Batch Consumption Time: 0.11758
Total Iteration Time: 3.16560

Cumulative Model Updates: 2,123
Cumulative Timesteps: 35,461,014

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05141
Policy Entropy: 4.34008
Value Function Loss: 0.06845

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00051
Policy Update Magnitude: 0.07832
Value Function Update Magnitude: 0.06718

Collected Steps per Second: 25,711.80652
Overall Steps per Second: 17,781.53884

Timestep Collection Time: 1.94533
Timestep Consumption Time: 0.86759
PPO Batch Consumption Time: 0.09103
Total Iteration Time: 2.81292

Cumulative Model Updates: 2,126
Cumulative Timesteps: 35,511,032

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 35511032...
Checkpoint 35511032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01213
Policy Entropy: 4.33315
Value Function Loss: 0.08256

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01368
Policy Update Magnitude: 0.07318
Value Function Update Magnitude: 0.07842

Collected Steps per Second: 24,927.07341
Overall Steps per Second: 18,405.17936

Timestep Collection Time: 2.00633
Timestep Consumption Time: 0.71095
PPO Batch Consumption Time: 0.05969
Total Iteration Time: 2.71728

Cumulative Model Updates: 2,129
Cumulative Timesteps: 35,561,044

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05121
Policy Entropy: 4.34457
Value Function Loss: 0.08036

Mean KL Divergence: 0.00076
SB3 Clip Fraction: 0.00289
Policy Update Magnitude: 0.08284
Value Function Update Magnitude: 0.06884

Collected Steps per Second: 25,733.13966
Overall Steps per Second: 18,228.70456

Timestep Collection Time: 1.94450
Timestep Consumption Time: 0.80051
PPO Batch Consumption Time: 0.06075
Total Iteration Time: 2.74501

Cumulative Model Updates: 2,132
Cumulative Timesteps: 35,611,082

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 35611082...
Checkpoint 35611082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00283
Policy Entropy: 4.34825
Value Function Loss: 0.06437

Mean KL Divergence: 0.00104
SB3 Clip Fraction: 0.01075
Policy Update Magnitude: 0.08092
Value Function Update Magnitude: 0.07127

Collected Steps per Second: 22,481.17620
Overall Steps per Second: 16,142.26835

Timestep Collection Time: 2.22462
Timestep Consumption Time: 0.87358
PPO Batch Consumption Time: 0.08688
Total Iteration Time: 3.09820

Cumulative Model Updates: 2,135
Cumulative Timesteps: 35,661,094

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00695
Policy Entropy: 4.34720
Value Function Loss: 0.05463

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00127
Policy Update Magnitude: 0.07998
Value Function Update Magnitude: 0.06545

Collected Steps per Second: 26,579.19697
Overall Steps per Second: 17,951.54368

Timestep Collection Time: 1.88125
Timestep Consumption Time: 0.90414
PPO Batch Consumption Time: 0.09990
Total Iteration Time: 2.78539

Cumulative Model Updates: 2,138
Cumulative Timesteps: 35,711,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 35711096...
Checkpoint 35711096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16188
Policy Entropy: 4.34710
Value Function Loss: 0.06005

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00002
Policy Update Magnitude: 0.07850
Value Function Update Magnitude: 0.07059

Collected Steps per Second: 25,616.02246
Overall Steps per Second: 18,169.67124

Timestep Collection Time: 1.95206
Timestep Consumption Time: 0.80000
PPO Batch Consumption Time: 0.05985
Total Iteration Time: 2.75206

Cumulative Model Updates: 2,141
Cumulative Timesteps: 35,761,100

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01701
Policy Entropy: 4.35013
Value Function Loss: 0.07485

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00039
Policy Update Magnitude: 0.07866
Value Function Update Magnitude: 0.07285

Collected Steps per Second: 25,898.69894
Overall Steps per Second: 19,062.68913

Timestep Collection Time: 1.93153
Timestep Consumption Time: 0.69266
PPO Batch Consumption Time: 0.05751
Total Iteration Time: 2.62418

Cumulative Model Updates: 2,144
Cumulative Timesteps: 35,811,124

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 35811124...
Checkpoint 35811124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01497
Policy Entropy: 4.34846
Value Function Loss: 0.07821

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00009
Policy Update Magnitude: 0.08570
Value Function Update Magnitude: 0.07533

Collected Steps per Second: 22,337.91017
Overall Steps per Second: 15,723.86299

Timestep Collection Time: 2.23951
Timestep Consumption Time: 0.94202
PPO Batch Consumption Time: 0.10395
Total Iteration Time: 3.18153

Cumulative Model Updates: 2,147
Cumulative Timesteps: 35,861,150

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02301
Policy Entropy: 4.33943
Value Function Loss: 0.07104

Mean KL Divergence: 0.00083
SB3 Clip Fraction: 0.00753
Policy Update Magnitude: 0.08425
Value Function Update Magnitude: 0.06742

Collected Steps per Second: 25,297.82643
Overall Steps per Second: 17,829.08095

Timestep Collection Time: 1.97756
Timestep Consumption Time: 0.82842
PPO Batch Consumption Time: 0.07512
Total Iteration Time: 2.80598

Cumulative Model Updates: 2,150
Cumulative Timesteps: 35,911,178

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 35911178...
Checkpoint 35911178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03936
Policy Entropy: 4.33605
Value Function Loss: 0.05211

Mean KL Divergence: 0.00084
SB3 Clip Fraction: 0.00689
Policy Update Magnitude: 0.08067
Value Function Update Magnitude: 0.07521

Collected Steps per Second: 26,535.37078
Overall Steps per Second: 18,734.08140

Timestep Collection Time: 1.88563
Timestep Consumption Time: 0.78522
PPO Batch Consumption Time: 0.05890
Total Iteration Time: 2.67085

Cumulative Model Updates: 2,153
Cumulative Timesteps: 35,961,214

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04968
Policy Entropy: 4.33534
Value Function Loss: 0.06384

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00062
Policy Update Magnitude: 0.08057
Value Function Update Magnitude: 0.06992

Collected Steps per Second: 23,521.41780
Overall Steps per Second: 16,232.44234

Timestep Collection Time: 2.12572
Timestep Consumption Time: 0.95453
PPO Batch Consumption Time: 0.10866
Total Iteration Time: 3.08025

Cumulative Model Updates: 2,156
Cumulative Timesteps: 36,011,214

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 36011214...
Checkpoint 36011214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01864
Policy Entropy: 4.33574
Value Function Loss: 0.05929

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00105
Policy Update Magnitude: 0.08237
Value Function Update Magnitude: 0.06814

Collected Steps per Second: 25,185.02743
Overall Steps per Second: 18,343.21234

Timestep Collection Time: 1.98626
Timestep Consumption Time: 0.74085
PPO Batch Consumption Time: 0.06096
Total Iteration Time: 2.72711

Cumulative Model Updates: 2,159
Cumulative Timesteps: 36,061,238

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04949
Policy Entropy: 4.32662
Value Function Loss: 0.06620

Mean KL Divergence: 0.00134
SB3 Clip Fraction: 0.01064
Policy Update Magnitude: 0.08467
Value Function Update Magnitude: 0.07883

Collected Steps per Second: 24,972.85722
Overall Steps per Second: 17,461.78559

Timestep Collection Time: 2.00329
Timestep Consumption Time: 0.86170
PPO Batch Consumption Time: 0.08844
Total Iteration Time: 2.86500

Cumulative Model Updates: 2,162
Cumulative Timesteps: 36,111,266

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 36111266...
Checkpoint 36111266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06144
Policy Entropy: 4.33383
Value Function Loss: 0.06343

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00089
Policy Update Magnitude: 0.08485
Value Function Update Magnitude: 0.08315

Collected Steps per Second: 25,139.40003
Overall Steps per Second: 18,274.15878

Timestep Collection Time: 1.98971
Timestep Consumption Time: 0.74749
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 2.73720

Cumulative Model Updates: 2,165
Cumulative Timesteps: 36,161,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00019
Policy Entropy: 4.34289
Value Function Loss: 0.06874

Mean KL Divergence: 0.00120
SB3 Clip Fraction: 0.01472
Policy Update Magnitude: 0.08186
Value Function Update Magnitude: 0.07584

Collected Steps per Second: 25,135.78738
Overall Steps per Second: 17,582.43798

Timestep Collection Time: 1.98967
Timestep Consumption Time: 0.85476
PPO Batch Consumption Time: 0.07989
Total Iteration Time: 2.84443

Cumulative Model Updates: 2,168
Cumulative Timesteps: 36,211,298

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 36211298...
Checkpoint 36211298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02538
Policy Entropy: 4.34756
Value Function Loss: 0.07849

Mean KL Divergence: 0.00110
SB3 Clip Fraction: 0.01304
Policy Update Magnitude: 0.08275
Value Function Update Magnitude: 0.06718

Collected Steps per Second: 25,649.55532
Overall Steps per Second: 17,802.48728

Timestep Collection Time: 1.95005
Timestep Consumption Time: 0.85955
PPO Batch Consumption Time: 0.07719
Total Iteration Time: 2.80961

Cumulative Model Updates: 2,171
Cumulative Timesteps: 36,261,316

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00143
Policy Entropy: 4.34344
Value Function Loss: 0.07559

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00018
Policy Update Magnitude: 0.08526
Value Function Update Magnitude: 0.07234

Collected Steps per Second: 23,953.28520
Overall Steps per Second: 16,882.05729

Timestep Collection Time: 2.08831
Timestep Consumption Time: 0.87471
PPO Batch Consumption Time: 0.08738
Total Iteration Time: 2.96303

Cumulative Model Updates: 2,174
Cumulative Timesteps: 36,311,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 36311338...
Checkpoint 36311338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02083
Policy Entropy: 4.33682
Value Function Loss: 0.07754

Mean KL Divergence: 0.00104
SB3 Clip Fraction: 0.00779
Policy Update Magnitude: 0.08746
Value Function Update Magnitude: 0.06422

Collected Steps per Second: 26,502.82115
Overall Steps per Second: 18,924.26280

Timestep Collection Time: 1.88682
Timestep Consumption Time: 0.75561
PPO Batch Consumption Time: 0.05775
Total Iteration Time: 2.64243

Cumulative Model Updates: 2,177
Cumulative Timesteps: 36,361,344

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00253
Policy Entropy: 4.34454
Value Function Loss: 0.08936

Mean KL Divergence: 0.00072
SB3 Clip Fraction: 0.00219
Policy Update Magnitude: 0.08934
Value Function Update Magnitude: 0.05795

Collected Steps per Second: 22,292.32850
Overall Steps per Second: 15,994.26012

Timestep Collection Time: 2.24418
Timestep Consumption Time: 0.88369
PPO Batch Consumption Time: 0.09880
Total Iteration Time: 3.12787

Cumulative Model Updates: 2,180
Cumulative Timesteps: 36,411,372

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 36411372...
Checkpoint 36411372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02829
Policy Entropy: 4.35018
Value Function Loss: 0.08277

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00041
Policy Update Magnitude: 0.09213
Value Function Update Magnitude: 0.05151

Collected Steps per Second: 25,457.34376
Overall Steps per Second: 18,669.23543

Timestep Collection Time: 1.96470
Timestep Consumption Time: 0.71436
PPO Batch Consumption Time: 0.05880
Total Iteration Time: 2.67906

Cumulative Model Updates: 2,183
Cumulative Timesteps: 36,461,388

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02290
Policy Entropy: 4.34876
Value Function Loss: 0.08438

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.00920
Policy Update Magnitude: 0.09878
Value Function Update Magnitude: 0.04829

Collected Steps per Second: 23,062.28685
Overall Steps per Second: 16,147.35884

Timestep Collection Time: 2.16917
Timestep Consumption Time: 0.92892
PPO Batch Consumption Time: 0.10599
Total Iteration Time: 3.09809

Cumulative Model Updates: 2,186
Cumulative Timesteps: 36,511,414

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 36511414...
Checkpoint 36511414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01002
Policy Entropy: 4.35841
Value Function Loss: 0.08134

Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.00663
Policy Update Magnitude: 0.09606
Value Function Update Magnitude: 0.04799

Collected Steps per Second: 25,337.25208
Overall Steps per Second: 17,910.39987

Timestep Collection Time: 1.97393
Timestep Consumption Time: 0.81852
PPO Batch Consumption Time: 0.07511
Total Iteration Time: 2.79246

Cumulative Model Updates: 2,189
Cumulative Timesteps: 36,561,428

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02479
Policy Entropy: 4.36790
Value Function Loss: 0.09057

Mean KL Divergence: 0.00096
SB3 Clip Fraction: 0.00185
Policy Update Magnitude: 0.09015
Value Function Update Magnitude: 0.04681

Collected Steps per Second: 25,904.92509
Overall Steps per Second: 18,572.42602

Timestep Collection Time: 1.93013
Timestep Consumption Time: 0.76203
PPO Batch Consumption Time: 0.05893
Total Iteration Time: 2.69216

Cumulative Model Updates: 2,192
Cumulative Timesteps: 36,611,428

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 36611428...
Checkpoint 36611428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00223
Policy Entropy: 4.36735
Value Function Loss: 0.10817

Mean KL Divergence: 0.00070
SB3 Clip Fraction: 0.00103
Policy Update Magnitude: 0.09419
Value Function Update Magnitude: 0.04680

Collected Steps per Second: 25,787.45512
Overall Steps per Second: 18,384.01015

Timestep Collection Time: 1.93978
Timestep Consumption Time: 0.78117
PPO Batch Consumption Time: 0.05920
Total Iteration Time: 2.72095

Cumulative Model Updates: 2,195
Cumulative Timesteps: 36,661,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04277
Policy Entropy: 4.35634
Value Function Loss: 0.09757

Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.01659
Policy Update Magnitude: 0.09196
Value Function Update Magnitude: 0.04626

Collected Steps per Second: 22,940.33605
Overall Steps per Second: 15,984.29445

Timestep Collection Time: 2.18070
Timestep Consumption Time: 0.94900
PPO Batch Consumption Time: 0.11696
Total Iteration Time: 3.12970

Cumulative Model Updates: 2,198
Cumulative Timesteps: 36,711,476

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 36711476...
Checkpoint 36711476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05603
Policy Entropy: 4.37467
Value Function Loss: 0.08781

Mean KL Divergence: 0.00065
SB3 Clip Fraction: 0.00187
Policy Update Magnitude: 0.09597
Value Function Update Magnitude: 0.05232

Collected Steps per Second: 26,435.15987
Overall Steps per Second: 17,900.80545

Timestep Collection Time: 1.89225
Timestep Consumption Time: 0.90215
PPO Batch Consumption Time: 0.09767
Total Iteration Time: 2.79440

Cumulative Model Updates: 2,201
Cumulative Timesteps: 36,761,498

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03625
Policy Entropy: 4.38696
Value Function Loss: 0.06773

Mean KL Divergence: 0.00125
SB3 Clip Fraction: 0.01733
Policy Update Magnitude: 0.08890
Value Function Update Magnitude: 0.05283

Collected Steps per Second: 25,752.29271
Overall Steps per Second: 18,457.16621

Timestep Collection Time: 1.94157
Timestep Consumption Time: 0.76740
PPO Batch Consumption Time: 0.05944
Total Iteration Time: 2.70897

Cumulative Model Updates: 2,204
Cumulative Timesteps: 36,811,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 36811498...
Checkpoint 36811498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03099
Policy Entropy: 4.37631
Value Function Loss: 0.08458

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00188
Policy Update Magnitude: 0.08431
Value Function Update Magnitude: 0.04739

Collected Steps per Second: 25,573.24954
Overall Steps per Second: 18,776.75415

Timestep Collection Time: 1.95595
Timestep Consumption Time: 0.70798
PPO Batch Consumption Time: 0.05764
Total Iteration Time: 2.66393

Cumulative Model Updates: 2,207
Cumulative Timesteps: 36,861,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00144
Policy Entropy: 4.37110
Value Function Loss: 0.07820

Mean KL Divergence: 0.00086
SB3 Clip Fraction: 0.00573
Policy Update Magnitude: 0.08116
Value Function Update Magnitude: 0.05061

Collected Steps per Second: 22,435.67391
Overall Steps per Second: 15,708.48054

Timestep Collection Time: 2.22975
Timestep Consumption Time: 0.95490
PPO Batch Consumption Time: 0.10971
Total Iteration Time: 3.18465

Cumulative Model Updates: 2,210
Cumulative Timesteps: 36,911,544

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 36911544...
Checkpoint 36911544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02304
Policy Entropy: 4.38199
Value Function Loss: 0.08447

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00079
Policy Update Magnitude: 0.08685
Value Function Update Magnitude: 0.06183

Collected Steps per Second: 25,357.05584
Overall Steps per Second: 17,815.85664

Timestep Collection Time: 1.97200
Timestep Consumption Time: 0.83472
PPO Batch Consumption Time: 0.07373
Total Iteration Time: 2.80671

Cumulative Model Updates: 2,213
Cumulative Timesteps: 36,961,548

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05893
Policy Entropy: 4.39575
Value Function Loss: 0.04506

Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.01581
Policy Update Magnitude: 0.07761
Value Function Update Magnitude: 0.06556

Collected Steps per Second: 26,593.48833
Overall Steps per Second: 18,928.10721

Timestep Collection Time: 1.88121
Timestep Consumption Time: 0.76184
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 2.64305

Cumulative Model Updates: 2,216
Cumulative Timesteps: 37,011,576

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 37011576...
Checkpoint 37011576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00339
Policy Entropy: 4.39799
Value Function Loss: 0.04530

Mean KL Divergence: 0.00061
SB3 Clip Fraction: 0.00380
Policy Update Magnitude: 0.07308
Value Function Update Magnitude: 0.05938

Collected Steps per Second: 23,054.28105
Overall Steps per Second: 16,037.10120

Timestep Collection Time: 2.16932
Timestep Consumption Time: 0.94920
PPO Batch Consumption Time: 0.10704
Total Iteration Time: 3.11852

Cumulative Model Updates: 2,219
Cumulative Timesteps: 37,061,588

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02669
Policy Entropy: 4.39200
Value Function Loss: 0.02905

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00050
Policy Update Magnitude: 0.06713
Value Function Update Magnitude: 0.05830

Collected Steps per Second: 25,421.86075
Overall Steps per Second: 18,608.95131

Timestep Collection Time: 1.96705
Timestep Consumption Time: 0.72015
PPO Batch Consumption Time: 0.06012
Total Iteration Time: 2.68720

Cumulative Model Updates: 2,222
Cumulative Timesteps: 37,111,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 37111594...
Checkpoint 37111594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00019
Policy Entropy: 4.39304
Value Function Loss: 0.03103

Mean KL Divergence: 0.00061
SB3 Clip Fraction: 0.00238
Policy Update Magnitude: 0.06456
Value Function Update Magnitude: 0.05212

Collected Steps per Second: 23,015.09638
Overall Steps per Second: 16,177.09980

Timestep Collection Time: 2.17257
Timestep Consumption Time: 0.91834
PPO Batch Consumption Time: 0.10035
Total Iteration Time: 3.09091

Cumulative Model Updates: 2,225
Cumulative Timesteps: 37,161,596

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02060
Policy Entropy: 4.39510
Value Function Loss: 0.02777

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05938
Value Function Update Magnitude: 0.04209

Collected Steps per Second: 24,839.89943
Overall Steps per Second: 17,605.89404

Timestep Collection Time: 2.01394
Timestep Consumption Time: 0.82750
PPO Batch Consumption Time: 0.07672
Total Iteration Time: 2.84143

Cumulative Model Updates: 2,228
Cumulative Timesteps: 37,211,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 37211622...
Checkpoint 37211622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03231
Policy Entropy: 4.40076
Value Function Loss: 0.03144

Mean KL Divergence: 0.00026
SB3 Clip Fraction: 0.00002
Policy Update Magnitude: 0.05762
Value Function Update Magnitude: 0.04176

Collected Steps per Second: 24,195.76367
Overall Steps per Second: 17,026.82649

Timestep Collection Time: 2.06739
Timestep Consumption Time: 0.87045
PPO Batch Consumption Time: 0.08575
Total Iteration Time: 2.93783

Cumulative Model Updates: 2,231
Cumulative Timesteps: 37,261,644

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12269
Policy Entropy: 4.40050
Value Function Loss: 0.05175

Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.06640
Value Function Update Magnitude: 0.04725

Collected Steps per Second: 25,801.29106
Overall Steps per Second: 18,374.43730

Timestep Collection Time: 1.93828
Timestep Consumption Time: 0.78344
PPO Batch Consumption Time: 0.06161
Total Iteration Time: 2.72172

Cumulative Model Updates: 2,234
Cumulative Timesteps: 37,311,654

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 37311654...
Checkpoint 37311654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10113
Policy Entropy: 4.39561
Value Function Loss: 0.05292

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00009
Policy Update Magnitude: 0.07323
Value Function Update Magnitude: 0.05665

Collected Steps per Second: 25,634.63009
Overall Steps per Second: 18,346.30898

Timestep Collection Time: 1.95088
Timestep Consumption Time: 0.77501
PPO Batch Consumption Time: 0.06078
Total Iteration Time: 2.72589

Cumulative Model Updates: 2,237
Cumulative Timesteps: 37,361,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04409
Policy Entropy: 4.38331
Value Function Loss: 0.06250

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.01112
Policy Update Magnitude: 0.07829
Value Function Update Magnitude: 0.05477

Collected Steps per Second: 23,063.93734
Overall Steps per Second: 16,124.19279

Timestep Collection Time: 2.16806
Timestep Consumption Time: 0.93312
PPO Batch Consumption Time: 0.10937
Total Iteration Time: 3.10118

Cumulative Model Updates: 2,240
Cumulative Timesteps: 37,411,668

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 37411668...
Checkpoint 37411668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00496
Policy Entropy: 4.39078
Value Function Loss: 0.07221

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00103
Policy Update Magnitude: 0.08544
Value Function Update Magnitude: 0.05863

Collected Steps per Second: 25,258.13450
Overall Steps per Second: 16,802.29398

Timestep Collection Time: 1.97996
Timestep Consumption Time: 0.99642
PPO Batch Consumption Time: 0.12252
Total Iteration Time: 2.97638

Cumulative Model Updates: 2,243
Cumulative Timesteps: 37,461,678

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01365
Policy Entropy: 4.40639
Value Function Loss: 0.07802

Mean KL Divergence: 0.00089
SB3 Clip Fraction: 0.00764
Policy Update Magnitude: 0.08238
Value Function Update Magnitude: 0.06774

Collected Steps per Second: 25,551.24169
Overall Steps per Second: 17,806.51295

Timestep Collection Time: 1.95795
Timestep Consumption Time: 0.85159
PPO Batch Consumption Time: 0.10060
Total Iteration Time: 2.80953

Cumulative Model Updates: 2,246
Cumulative Timesteps: 37,511,706

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 37511706...
Checkpoint 37511706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00202
Policy Entropy: 4.40918
Value Function Loss: 0.07230

Mean KL Divergence: 0.00077
SB3 Clip Fraction: 0.01025
Policy Update Magnitude: 0.08636
Value Function Update Magnitude: 0.07884

Collected Steps per Second: 25,125.32775
Overall Steps per Second: 18,017.87133

Timestep Collection Time: 1.99074
Timestep Consumption Time: 0.78528
PPO Batch Consumption Time: 0.05765
Total Iteration Time: 2.77602

Cumulative Model Updates: 2,249
Cumulative Timesteps: 37,561,724

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03229
Policy Entropy: 4.40398
Value Function Loss: 0.06963

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00002
Policy Update Magnitude: 0.08583
Value Function Update Magnitude: 0.07855

Collected Steps per Second: 22,471.30323
Overall Steps per Second: 15,699.01884

Timestep Collection Time: 2.22542
Timestep Consumption Time: 0.96001
PPO Batch Consumption Time: 0.11896
Total Iteration Time: 3.18542

Cumulative Model Updates: 2,252
Cumulative Timesteps: 37,611,732

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 37611732...
Checkpoint 37611732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02836
Policy Entropy: 4.39153
Value Function Loss: 0.06321

Mean KL Divergence: 0.00080
SB3 Clip Fraction: 0.00729
Policy Update Magnitude: 0.08322
Value Function Update Magnitude: 0.07873

Collected Steps per Second: 26,371.35528
Overall Steps per Second: 18,616.00444

Timestep Collection Time: 1.89713
Timestep Consumption Time: 0.79034
PPO Batch Consumption Time: 0.05940
Total Iteration Time: 2.68747

Cumulative Model Updates: 2,255
Cumulative Timesteps: 37,661,762

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02513
Policy Entropy: 4.39015
Value Function Loss: 0.07174

Mean KL Divergence: 0.00069
SB3 Clip Fraction: 0.00724
Policy Update Magnitude: 0.08333
Value Function Update Magnitude: 0.07174

Collected Steps per Second: 22,543.19555
Overall Steps per Second: 16,041.56142

Timestep Collection Time: 2.21859
Timestep Consumption Time: 0.89919
PPO Batch Consumption Time: 0.09016
Total Iteration Time: 3.11778

Cumulative Model Updates: 2,258
Cumulative Timesteps: 37,711,776

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 37711776...
Checkpoint 37711776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00945
Policy Entropy: 4.40134
Value Function Loss: 0.04937

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00026
Policy Update Magnitude: 0.08302
Value Function Update Magnitude: 0.06318

Collected Steps per Second: 25,440.33422
Overall Steps per Second: 18,322.03276

Timestep Collection Time: 1.96546
Timestep Consumption Time: 0.76360
PPO Batch Consumption Time: 0.06024
Total Iteration Time: 2.72906

Cumulative Model Updates: 2,261
Cumulative Timesteps: 37,761,778

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02002
Policy Entropy: 4.41086
Value Function Loss: 0.06704

Mean KL Divergence: 0.00109
SB3 Clip Fraction: 0.01130
Policy Update Magnitude: 0.07765
Value Function Update Magnitude: 0.06141

Collected Steps per Second: 26,616.01168
Overall Steps per Second: 18,821.34250

Timestep Collection Time: 1.87864
Timestep Consumption Time: 0.77802
PPO Batch Consumption Time: 0.05810
Total Iteration Time: 2.65666

Cumulative Model Updates: 2,264
Cumulative Timesteps: 37,811,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 37811780...
Checkpoint 37811780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06739
Policy Entropy: 4.40821
Value Function Loss: 0.06097

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00232
Policy Update Magnitude: 0.07727
Value Function Update Magnitude: 0.05911

Collected Steps per Second: 22,517.46603
Overall Steps per Second: 15,897.35108

Timestep Collection Time: 2.22085
Timestep Consumption Time: 0.92483
PPO Batch Consumption Time: 0.11102
Total Iteration Time: 3.14568

Cumulative Model Updates: 2,267
Cumulative Timesteps: 37,861,788

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03669
Policy Entropy: 4.39853
Value Function Loss: 0.07895

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00252
Policy Update Magnitude: 0.08164
Value Function Update Magnitude: 0.05845

Collected Steps per Second: 25,462.14034
Overall Steps per Second: 18,735.84035

Timestep Collection Time: 1.96386
Timestep Consumption Time: 0.70504
PPO Batch Consumption Time: 0.05856
Total Iteration Time: 2.66890

Cumulative Model Updates: 2,270
Cumulative Timesteps: 37,911,792

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 37911792...
Checkpoint 37911792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01554
Policy Entropy: 4.39159
Value Function Loss: 0.07791

Mean KL Divergence: 0.00087
SB3 Clip Fraction: 0.01093
Policy Update Magnitude: 0.08320
Value Function Update Magnitude: 0.06020

Collected Steps per Second: 22,397.88736
Overall Steps per Second: 16,002.42878

Timestep Collection Time: 2.23235
Timestep Consumption Time: 0.89217
PPO Batch Consumption Time: 0.09214
Total Iteration Time: 3.12453

Cumulative Model Updates: 2,273
Cumulative Timesteps: 37,961,792

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01110
Policy Entropy: 4.39412
Value Function Loss: 0.06383

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00059
Policy Update Magnitude: 0.08574
Value Function Update Magnitude: 0.06461

Collected Steps per Second: 25,621.88084
Overall Steps per Second: 18,304.91549

Timestep Collection Time: 1.95193
Timestep Consumption Time: 0.78024
PPO Batch Consumption Time: 0.06032
Total Iteration Time: 2.73216

Cumulative Model Updates: 2,276
Cumulative Timesteps: 38,011,804

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 38011804...
Checkpoint 38011804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00428
Policy Entropy: 4.39866
Value Function Loss: 0.05313

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00034
Policy Update Magnitude: 0.08134
Value Function Update Magnitude: 0.05537

Collected Steps per Second: 26,803.90110
Overall Steps per Second: 17,733.32551

Timestep Collection Time: 1.86630
Timestep Consumption Time: 0.95461
PPO Batch Consumption Time: 0.11848
Total Iteration Time: 2.82090

Cumulative Model Updates: 2,279
Cumulative Timesteps: 38,061,828

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01153
Policy Entropy: 4.39887
Value Function Loss: 0.05028

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00045
Policy Update Magnitude: 0.07354
Value Function Update Magnitude: 0.05712

Collected Steps per Second: 26,012.74682
Overall Steps per Second: 18,409.96101

Timestep Collection Time: 1.92252
Timestep Consumption Time: 0.79395
PPO Batch Consumption Time: 0.05864
Total Iteration Time: 2.71646

Cumulative Model Updates: 2,282
Cumulative Timesteps: 38,111,838

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 38111838...
Checkpoint 38111838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01868
Policy Entropy: 4.40124
Value Function Loss: 0.07764

Mean KL Divergence: 0.00020
SB3 Clip Fraction: 0.00007
Policy Update Magnitude: 0.07311
Value Function Update Magnitude: 0.06267

Collected Steps per Second: 24,556.66421
Overall Steps per Second: 18,141.26446

Timestep Collection Time: 2.03635
Timestep Consumption Time: 0.72013
PPO Batch Consumption Time: 0.05983
Total Iteration Time: 2.75648

Cumulative Model Updates: 2,285
Cumulative Timesteps: 38,161,844

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00408
Policy Entropy: 4.39777
Value Function Loss: 0.07049

Mean KL Divergence: 0.00018
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.07658
Value Function Update Magnitude: 0.06621

Collected Steps per Second: 22,733.84689
Overall Steps per Second: 16,074.12865

Timestep Collection Time: 2.20042
Timestep Consumption Time: 0.91166
PPO Batch Consumption Time: 0.09967
Total Iteration Time: 3.11208

Cumulative Model Updates: 2,288
Cumulative Timesteps: 38,211,868

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 38211868...
Checkpoint 38211868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03561
Policy Entropy: 4.38782
Value Function Loss: 0.06374

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00179
Policy Update Magnitude: 0.08125
Value Function Update Magnitude: 0.07857

Collected Steps per Second: 25,420.86602
Overall Steps per Second: 17,927.41519

Timestep Collection Time: 1.96767
Timestep Consumption Time: 0.82247
PPO Batch Consumption Time: 0.07924
Total Iteration Time: 2.79014

Cumulative Model Updates: 2,291
Cumulative Timesteps: 38,261,888

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02208
Policy Entropy: 4.37244
Value Function Loss: 0.04448

Mean KL Divergence: 0.00115
SB3 Clip Fraction: 0.01397
Policy Update Magnitude: 0.07606
Value Function Update Magnitude: 0.07178

Collected Steps per Second: 25,161.75486
Overall Steps per Second: 18,612.11956

Timestep Collection Time: 1.98714
Timestep Consumption Time: 0.69928
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 2.68642

Cumulative Model Updates: 2,294
Cumulative Timesteps: 38,311,888

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 38311888...
Checkpoint 38311888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02945
Policy Entropy: 4.37463
Value Function Loss: 0.04409

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00267
Policy Update Magnitude: 0.07230
Value Function Update Magnitude: 0.06389

Collected Steps per Second: 22,801.83859
Overall Steps per Second: 16,215.95761

Timestep Collection Time: 2.19403
Timestep Consumption Time: 0.89108
PPO Batch Consumption Time: 0.09084
Total Iteration Time: 3.08511

Cumulative Model Updates: 2,297
Cumulative Timesteps: 38,361,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11546
Policy Entropy: 4.37759
Value Function Loss: 0.04418

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00006
Policy Update Magnitude: 0.06646
Value Function Update Magnitude: 0.06486

Collected Steps per Second: 25,197.03988
Overall Steps per Second: 18,214.04191

Timestep Collection Time: 1.98460
Timestep Consumption Time: 0.76087
PPO Batch Consumption Time: 0.06085
Total Iteration Time: 2.74546

Cumulative Model Updates: 2,300
Cumulative Timesteps: 38,411,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 38411922...
Checkpoint 38411922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02139
Policy Entropy: 4.37460
Value Function Loss: 0.05278

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00022
Policy Update Magnitude: 0.06917
Value Function Update Magnitude: 0.06397

Collected Steps per Second: 26,706.41277
Overall Steps per Second: 18,910.81897

Timestep Collection Time: 1.87228
Timestep Consumption Time: 0.77181
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 2.64409

Cumulative Model Updates: 2,303
Cumulative Timesteps: 38,461,924

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04860
Policy Entropy: 4.37490
Value Function Loss: 0.05945

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00045
Policy Update Magnitude: 0.07607
Value Function Update Magnitude: 0.06501

Collected Steps per Second: 22,812.13773
Overall Steps per Second: 15,834.55636

Timestep Collection Time: 2.19287
Timestep Consumption Time: 0.96630
PPO Batch Consumption Time: 0.11251
Total Iteration Time: 3.15917

Cumulative Model Updates: 2,306
Cumulative Timesteps: 38,511,948

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 38511948...
Checkpoint 38511948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00551
Policy Entropy: 4.36934
Value Function Loss: 0.05453

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00183
Policy Update Magnitude: 0.08072
Value Function Update Magnitude: 0.07124

Collected Steps per Second: 25,342.63127
Overall Steps per Second: 18,631.02793

Timestep Collection Time: 1.97430
Timestep Consumption Time: 0.71122
PPO Batch Consumption Time: 0.06003
Total Iteration Time: 2.68552

Cumulative Model Updates: 2,309
Cumulative Timesteps: 38,561,982

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04642
Policy Entropy: 4.36382
Value Function Loss: 0.06716

Mean KL Divergence: 0.00054
SB3 Clip Fraction: 0.00159
Policy Update Magnitude: 0.08148
Value Function Update Magnitude: 0.07137

Collected Steps per Second: 23,211.32835
Overall Steps per Second: 16,117.09811

Timestep Collection Time: 2.15455
Timestep Consumption Time: 0.94836
PPO Batch Consumption Time: 0.10709
Total Iteration Time: 3.10292

Cumulative Model Updates: 2,312
Cumulative Timesteps: 38,611,992

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 38611992...
Checkpoint 38611992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03452
Policy Entropy: 4.36082
Value Function Loss: 0.06618

Mean KL Divergence: 0.00060
SB3 Clip Fraction: 0.00102
Policy Update Magnitude: 0.08959
Value Function Update Magnitude: 0.06511

Collected Steps per Second: 25,550.14149
Overall Steps per Second: 18,364.60039

Timestep Collection Time: 1.95772
Timestep Consumption Time: 0.76600
PPO Batch Consumption Time: 0.06200
Total Iteration Time: 2.72372

Cumulative Model Updates: 2,315
Cumulative Timesteps: 38,662,012

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03187
Policy Entropy: 4.35970
Value Function Loss: 0.10171

Mean KL Divergence: 0.00078
SB3 Clip Fraction: 0.00213
Policy Update Magnitude: 0.09442
Value Function Update Magnitude: 0.06182

Collected Steps per Second: 26,417.63869
Overall Steps per Second: 18,660.42280

Timestep Collection Time: 1.89336
Timestep Consumption Time: 0.78708
PPO Batch Consumption Time: 0.05838
Total Iteration Time: 2.68043

Cumulative Model Updates: 2,318
Cumulative Timesteps: 38,712,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 38712030...
Checkpoint 38712030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00068
Policy Entropy: 4.36120
Value Function Loss: 0.10160

Mean KL Divergence: 0.00076
SB3 Clip Fraction: 0.00330
Policy Update Magnitude: 0.09582
Value Function Update Magnitude: 0.06467

Collected Steps per Second: 22,523.80977
Overall Steps per Second: 15,840.66163

Timestep Collection Time: 2.22032
Timestep Consumption Time: 0.93675
PPO Batch Consumption Time: 0.11238
Total Iteration Time: 3.15707

Cumulative Model Updates: 2,321
Cumulative Timesteps: 38,762,040

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02580
Policy Entropy: 4.35955
Value Function Loss: 0.10748

Mean KL Divergence: 0.00075
SB3 Clip Fraction: 0.00425
Policy Update Magnitude: 0.10052
Value Function Update Magnitude: 0.06766

Collected Steps per Second: 25,601.70584
Overall Steps per Second: 18,837.64211

Timestep Collection Time: 1.95432
Timestep Consumption Time: 0.70174
PPO Batch Consumption Time: 0.05977
Total Iteration Time: 2.65606

Cumulative Model Updates: 2,324
Cumulative Timesteps: 38,812,074

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 38812074...
Checkpoint 38812074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09074
Policy Entropy: 4.35990
Value Function Loss: 0.09088

Mean KL Divergence: 0.00068
SB3 Clip Fraction: 0.00243
Policy Update Magnitude: 0.10365
Value Function Update Magnitude: 0.07142

Collected Steps per Second: 22,506.07980
Overall Steps per Second: 15,992.97348

Timestep Collection Time: 2.22216
Timestep Consumption Time: 0.90497
PPO Batch Consumption Time: 0.09094
Total Iteration Time: 3.12712

Cumulative Model Updates: 2,327
Cumulative Timesteps: 38,862,086

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00671
Policy Entropy: 4.35824
Value Function Loss: 0.07613

Mean KL Divergence: 0.00071
SB3 Clip Fraction: 0.00252
Policy Update Magnitude: 0.09856
Value Function Update Magnitude: 0.06596

Collected Steps per Second: 25,623.65744
Overall Steps per Second: 18,428.99473

Timestep Collection Time: 1.95140
Timestep Consumption Time: 0.76182
PPO Batch Consumption Time: 0.05999
Total Iteration Time: 2.71322

Cumulative Model Updates: 2,330
Cumulative Timesteps: 38,912,088

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 38912088...
Checkpoint 38912088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05031
Policy Entropy: 4.35693
Value Function Loss: 0.09995

Mean KL Divergence: 0.00069
SB3 Clip Fraction: 0.00212
Policy Update Magnitude: 0.09978
Value Function Update Magnitude: 0.07352

Collected Steps per Second: 26,365.32657
Overall Steps per Second: 17,618.95356

Timestep Collection Time: 1.89757
Timestep Consumption Time: 0.94199
PPO Batch Consumption Time: 0.11379
Total Iteration Time: 2.83956

Cumulative Model Updates: 2,333
Cumulative Timesteps: 38,962,118

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00159
Policy Entropy: 4.34931
Value Function Loss: 0.08311

Mean KL Divergence: 0.00082
SB3 Clip Fraction: 0.00169
Policy Update Magnitude: 0.09965
Value Function Update Magnitude: 0.06335

Collected Steps per Second: 25,907.88469
Overall Steps per Second: 18,205.63624

Timestep Collection Time: 1.93015
Timestep Consumption Time: 0.81659
PPO Batch Consumption Time: 0.06183
Total Iteration Time: 2.74673

Cumulative Model Updates: 2,336
Cumulative Timesteps: 39,012,124

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 39012124...
Checkpoint 39012124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03027
Policy Entropy: 4.32863
Value Function Loss: 0.09608

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.00983
Policy Update Magnitude: 0.10043
Value Function Update Magnitude: 0.07092

Collected Steps per Second: 25,545.69875
Overall Steps per Second: 18,396.10153

Timestep Collection Time: 1.95782
Timestep Consumption Time: 0.76090
PPO Batch Consumption Time: 0.05992
Total Iteration Time: 2.71873

Cumulative Model Updates: 2,339
Cumulative Timesteps: 39,062,138

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02377
Policy Entropy: 4.31474
Value Function Loss: 0.07073

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.00882
Policy Update Magnitude: 0.09259
Value Function Update Magnitude: 0.06828

Collected Steps per Second: 24,043.58370
Overall Steps per Second: 17,090.51417

Timestep Collection Time: 2.08089
Timestep Consumption Time: 0.84658
PPO Batch Consumption Time: 0.07234
Total Iteration Time: 2.92747

Cumulative Model Updates: 2,342
Cumulative Timesteps: 39,112,170

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 39112170...
Checkpoint 39112170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01487
Policy Entropy: 4.31136
Value Function Loss: 0.08807

Mean KL Divergence: 0.00125
SB3 Clip Fraction: 0.00164
Policy Update Magnitude: 0.09465
Value Function Update Magnitude: 0.07271

Collected Steps per Second: 25,622.33952
Overall Steps per Second: 18,301.85836

Timestep Collection Time: 1.95181
Timestep Consumption Time: 0.78070
PPO Batch Consumption Time: 0.05996
Total Iteration Time: 2.73251

Cumulative Model Updates: 2,345
Cumulative Timesteps: 39,162,180

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06217
Policy Entropy: 4.29252
Value Function Loss: 0.08926

Mean KL Divergence: 0.00138
SB3 Clip Fraction: 0.00291
Policy Update Magnitude: 0.09812
Value Function Update Magnitude: 0.06287

Collected Steps per Second: 25,154.63011
Overall Steps per Second: 18,487.67656

Timestep Collection Time: 1.98834
Timestep Consumption Time: 0.71703
PPO Batch Consumption Time: 0.06123
Total Iteration Time: 2.70537

Cumulative Model Updates: 2,348
Cumulative Timesteps: 39,212,196

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 39212196...
Checkpoint 39212196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00194
Policy Entropy: 4.28567
Value Function Loss: 0.09412

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.00911
Policy Update Magnitude: 0.09835
Value Function Update Magnitude: 0.06713

Collected Steps per Second: 22,455.22221
Overall Steps per Second: 16,069.88969

Timestep Collection Time: 2.22754
Timestep Consumption Time: 0.88511
PPO Batch Consumption Time: 0.08681
Total Iteration Time: 3.11265

Cumulative Model Updates: 2,351
Cumulative Timesteps: 39,262,216

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12654
Policy Entropy: 4.28606
Value Function Loss: 0.09745

Mean KL Divergence: 0.00077
SB3 Clip Fraction: 0.00121
Policy Update Magnitude: 0.09859
Value Function Update Magnitude: 0.07425

Collected Steps per Second: 25,688.58920
Overall Steps per Second: 17,881.61572

Timestep Collection Time: 1.94655
Timestep Consumption Time: 0.84985
PPO Batch Consumption Time: 0.07873
Total Iteration Time: 2.79639

Cumulative Model Updates: 2,354
Cumulative Timesteps: 39,312,220

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 39312220...
Checkpoint 39312220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00031
Policy Entropy: 4.28792
Value Function Loss: 0.08967

Mean KL Divergence: 0.00083
SB3 Clip Fraction: 0.00165
Policy Update Magnitude: 0.10106
Value Function Update Magnitude: 0.07224

Collected Steps per Second: 26,556.05378
Overall Steps per Second: 18,641.69698

Timestep Collection Time: 1.88364
Timestep Consumption Time: 0.79970
PPO Batch Consumption Time: 0.05888
Total Iteration Time: 2.68334

Cumulative Model Updates: 2,357
Cumulative Timesteps: 39,362,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01903
Policy Entropy: 4.28632
Value Function Loss: 0.09120

Mean KL Divergence: 0.00128
SB3 Clip Fraction: 0.00433
Policy Update Magnitude: 0.10074
Value Function Update Magnitude: 0.07345

Collected Steps per Second: 22,079.55375
Overall Steps per Second: 15,324.25407

Timestep Collection Time: 2.26563
Timestep Consumption Time: 0.99874
PPO Batch Consumption Time: 0.12306
Total Iteration Time: 3.26437

Cumulative Model Updates: 2,360
Cumulative Timesteps: 39,412,266

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 39412266...
Checkpoint 39412266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00751
Policy Entropy: 4.27828
Value Function Loss: 0.08885

Mean KL Divergence: 0.00168
SB3 Clip Fraction: 0.00847
Policy Update Magnitude: 0.09722
Value Function Update Magnitude: 0.06554

Collected Steps per Second: 25,140.76835
Overall Steps per Second: 18,564.30843

Timestep Collection Time: 1.98928
Timestep Consumption Time: 0.70471
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 2.69399

Cumulative Model Updates: 2,363
Cumulative Timesteps: 39,462,278

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02954
Policy Entropy: 4.26490
Value Function Loss: 0.08259

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.00611
Policy Update Magnitude: 0.09534
Value Function Update Magnitude: 0.06590

Collected Steps per Second: 24,141.50631
Overall Steps per Second: 17,163.51908

Timestep Collection Time: 2.07112
Timestep Consumption Time: 0.84203
PPO Batch Consumption Time: 0.07611
Total Iteration Time: 2.91316

Cumulative Model Updates: 2,366
Cumulative Timesteps: 39,512,278

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 39512278...
Checkpoint 39512278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07834
Policy Entropy: 4.24471
Value Function Loss: 0.10921

Mean KL Divergence: 0.00155
SB3 Clip Fraction: 0.01219
Policy Update Magnitude: 0.09801
Value Function Update Magnitude: 0.06623

Collected Steps per Second: 25,266.51537
Overall Steps per Second: 17,960.76041

Timestep Collection Time: 1.97993
Timestep Consumption Time: 0.80536
PPO Batch Consumption Time: 0.07388
Total Iteration Time: 2.78529

Cumulative Model Updates: 2,369
Cumulative Timesteps: 39,562,304

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04826
Policy Entropy: 4.25204
Value Function Loss: 0.11069

Mean KL Divergence: 0.00122
SB3 Clip Fraction: 0.00259
Policy Update Magnitude: 0.10371
Value Function Update Magnitude: 0.06727

Collected Steps per Second: 26,521.30257
Overall Steps per Second: 18,774.08772

Timestep Collection Time: 1.88641
Timestep Consumption Time: 0.77844
PPO Batch Consumption Time: 0.05770
Total Iteration Time: 2.66484

Cumulative Model Updates: 2,372
Cumulative Timesteps: 39,612,334

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 39612334...
Checkpoint 39612334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00154
Policy Entropy: 4.25919
Value Function Loss: 0.10741

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01240
Policy Update Magnitude: 0.10966
Value Function Update Magnitude: 0.07070

Collected Steps per Second: 22,941.58759
Overall Steps per Second: 16,128.88762

Timestep Collection Time: 2.17954
Timestep Consumption Time: 0.92062
PPO Batch Consumption Time: 0.09944
Total Iteration Time: 3.10015

Cumulative Model Updates: 2,375
Cumulative Timesteps: 39,662,336

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00853
Policy Entropy: 4.24696
Value Function Loss: 0.07674

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01868
Policy Update Magnitude: 0.10144
Value Function Update Magnitude: 0.07228

Collected Steps per Second: 25,503.87207
Overall Steps per Second: 18,759.06434

Timestep Collection Time: 1.96080
Timestep Consumption Time: 0.70500
PPO Batch Consumption Time: 0.05889
Total Iteration Time: 2.66580

Cumulative Model Updates: 2,378
Cumulative Timesteps: 39,712,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 39712344...
Checkpoint 39712344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02069
Policy Entropy: 4.26259
Value Function Loss: 0.05908

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.00945
Policy Update Magnitude: 0.09942
Value Function Update Magnitude: 0.06407

Collected Steps per Second: 23,106.00772
Overall Steps per Second: 16,112.10719

Timestep Collection Time: 2.16532
Timestep Consumption Time: 0.93992
PPO Batch Consumption Time: 0.10416
Total Iteration Time: 3.10524

Cumulative Model Updates: 2,381
Cumulative Timesteps: 39,762,376

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03757
Policy Entropy: 4.27072
Value Function Loss: 0.04682

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03315
Policy Update Magnitude: 0.08580
Value Function Update Magnitude: 0.06160

Collected Steps per Second: 25,760.65354
Overall Steps per Second: 17,860.86634

Timestep Collection Time: 1.94188
Timestep Consumption Time: 0.85888
PPO Batch Consumption Time: 0.09280
Total Iteration Time: 2.80076

Cumulative Model Updates: 2,384
Cumulative Timesteps: 39,812,400

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 39812400...
Checkpoint 39812400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04846
Policy Entropy: 4.25332
Value Function Loss: 0.03688

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.00937
Policy Update Magnitude: 0.08128
Value Function Update Magnitude: 0.06258

Collected Steps per Second: 25,005.80310
Overall Steps per Second: 18,431.26191

Timestep Collection Time: 2.00066
Timestep Consumption Time: 0.71365
PPO Batch Consumption Time: 0.06122
Total Iteration Time: 2.71430

Cumulative Model Updates: 2,387
Cumulative Timesteps: 39,862,428

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03198
Policy Entropy: 4.24410
Value Function Loss: 0.03075

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01498
Policy Update Magnitude: 0.07494
Value Function Update Magnitude: 0.05879

Collected Steps per Second: 25,623.20968
Overall Steps per Second: 18,172.11994

Timestep Collection Time: 1.95143
Timestep Consumption Time: 0.80014
PPO Batch Consumption Time: 0.06198
Total Iteration Time: 2.75158

Cumulative Model Updates: 2,390
Cumulative Timesteps: 39,912,430

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 39912430...
Checkpoint 39912430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04170
Policy Entropy: 4.25748
Value Function Loss: 0.03826

Mean KL Divergence: 0.00077
SB3 Clip Fraction: 0.00061
Policy Update Magnitude: 0.07227
Value Function Update Magnitude: 0.05524

Collected Steps per Second: 22,427.57914
Overall Steps per Second: 16,219.41593

Timestep Collection Time: 2.22975
Timestep Consumption Time: 0.85346
PPO Batch Consumption Time: 0.10623
Total Iteration Time: 3.08322

Cumulative Model Updates: 2,393
Cumulative Timesteps: 39,962,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01875
Policy Entropy: 4.26399
Value Function Loss: 0.06097

Mean KL Divergence: 0.00083
SB3 Clip Fraction: 0.00344
Policy Update Magnitude: 0.07230
Value Function Update Magnitude: 0.05393

Collected Steps per Second: 25,749.30620
Overall Steps per Second: 17,847.57236

Timestep Collection Time: 1.94289
Timestep Consumption Time: 0.86018
PPO Batch Consumption Time: 0.08191
Total Iteration Time: 2.80307

Cumulative Model Updates: 2,396
Cumulative Timesteps: 40,012,466

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 40012466...
Checkpoint 40012466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03421
Policy Entropy: 4.26328
Value Function Loss: 0.09093

Mean KL Divergence: 0.00068
SB3 Clip Fraction: 0.00066
Policy Update Magnitude: 0.07665
Value Function Update Magnitude: 0.05515

Collected Steps per Second: 25,335.22855
Overall Steps per Second: 18,195.37635

Timestep Collection Time: 1.97417
Timestep Consumption Time: 0.77466
PPO Batch Consumption Time: 0.05895
Total Iteration Time: 2.74883

Cumulative Model Updates: 2,399
Cumulative Timesteps: 40,062,482

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04621
Policy Entropy: 4.26425
Value Function Loss: 0.09380

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.00767
Policy Update Magnitude: 0.08884
Value Function Update Magnitude: 0.06502

Collected Steps per Second: 22,734.98083
Overall Steps per Second: 16,537.38711

Timestep Collection Time: 2.19987
Timestep Consumption Time: 0.82443
PPO Batch Consumption Time: 0.09849
Total Iteration Time: 3.02430

Cumulative Model Updates: 2,402
Cumulative Timesteps: 40,112,496

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 40112496...
Checkpoint 40112496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04301
Policy Entropy: 4.28506
Value Function Loss: 0.07700

Mean KL Divergence: 0.00106
SB3 Clip Fraction: 0.00401
Policy Update Magnitude: 0.09155
Value Function Update Magnitude: 0.06400

Collected Steps per Second: 25,942.47714
Overall Steps per Second: 18,348.19631

Timestep Collection Time: 1.92742
Timestep Consumption Time: 0.79775
PPO Batch Consumption Time: 0.05905
Total Iteration Time: 2.72517

Cumulative Model Updates: 2,405
Cumulative Timesteps: 40,162,498

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01210
Policy Entropy: 4.29375
Value Function Loss: 0.05069

Mean KL Divergence: 0.00121
SB3 Clip Fraction: 0.00887
Policy Update Magnitude: 0.07911
Value Function Update Magnitude: 0.05394

Collected Steps per Second: 25,221.73889
Overall Steps per Second: 18,530.46514

Timestep Collection Time: 1.98345
Timestep Consumption Time: 0.71621
PPO Batch Consumption Time: 0.06037
Total Iteration Time: 2.69966

Cumulative Model Updates: 2,408
Cumulative Timesteps: 40,212,524

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 40212524...
Checkpoint 40212524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01480
Policy Entropy: 4.29486
Value Function Loss: 0.04527

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00069
Policy Update Magnitude: 0.07179
Value Function Update Magnitude: 0.05038

Collected Steps per Second: 22,294.90936
Overall Steps per Second: 15,954.73682

Timestep Collection Time: 2.24374
Timestep Consumption Time: 0.89163
PPO Batch Consumption Time: 0.09251
Total Iteration Time: 3.13537

Cumulative Model Updates: 2,411
Cumulative Timesteps: 40,262,548

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01221
Policy Entropy: 4.29466
Value Function Loss: 0.04788

Mean KL Divergence: 0.00054
SB3 Clip Fraction: 0.00074
Policy Update Magnitude: 0.06994
Value Function Update Magnitude: 0.04865

Collected Steps per Second: 25,617.88329
Overall Steps per Second: 18,316.05920

Timestep Collection Time: 1.95246
Timestep Consumption Time: 0.77836
PPO Batch Consumption Time: 0.06106
Total Iteration Time: 2.73083

Cumulative Model Updates: 2,414
Cumulative Timesteps: 40,312,566

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 40312566...
Checkpoint 40312566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01201
Policy Entropy: 4.29694
Value Function Loss: 0.07217

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00025
Policy Update Magnitude: 0.07364
Value Function Update Magnitude: 0.05000

Collected Steps per Second: 25,331.59540
Overall Steps per Second: 18,593.08115

Timestep Collection Time: 1.97469
Timestep Consumption Time: 0.71567
PPO Batch Consumption Time: 0.05959
Total Iteration Time: 2.69036

Cumulative Model Updates: 2,417
Cumulative Timesteps: 40,362,588

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01710
Policy Entropy: 4.29425
Value Function Loss: 0.06461

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00047
Policy Update Magnitude: 0.07701
Value Function Update Magnitude: 0.05858

Collected Steps per Second: 22,787.48739
Overall Steps per Second: 15,931.11806

Timestep Collection Time: 2.19533
Timestep Consumption Time: 0.94482
PPO Batch Consumption Time: 0.10631
Total Iteration Time: 3.14014

Cumulative Model Updates: 2,420
Cumulative Timesteps: 40,412,614

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 40412614...
Checkpoint 40412614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07920
Policy Entropy: 4.28905
Value Function Loss: 0.07089

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00057
Policy Update Magnitude: 0.08263
Value Function Update Magnitude: 0.06137

Collected Steps per Second: 25,601.39681
Overall Steps per Second: 17,893.49552

Timestep Collection Time: 1.95325
Timestep Consumption Time: 0.84139
PPO Batch Consumption Time: 0.08476
Total Iteration Time: 2.79465

Cumulative Model Updates: 2,423
Cumulative Timesteps: 40,462,620

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00550
Policy Entropy: 4.27704
Value Function Loss: 0.07006

Mean KL Divergence: 0.00102
SB3 Clip Fraction: 0.00617
Policy Update Magnitude: 0.07787
Value Function Update Magnitude: 0.05396

Collected Steps per Second: 26,060.16346
Overall Steps per Second: 18,729.78532

Timestep Collection Time: 1.91925
Timestep Consumption Time: 0.75115
PPO Batch Consumption Time: 0.05432
Total Iteration Time: 2.67040

Cumulative Model Updates: 2,426
Cumulative Timesteps: 40,512,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 40512636...
Checkpoint 40512636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03498
Policy Entropy: 4.28045
Value Function Loss: 0.07965

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00167
Policy Update Magnitude: 0.08288
Value Function Update Magnitude: 0.05280

Collected Steps per Second: 22,934.68301
Overall Steps per Second: 16,145.48925

Timestep Collection Time: 2.18106
Timestep Consumption Time: 0.91714
PPO Batch Consumption Time: 0.09143
Total Iteration Time: 3.09820

Cumulative Model Updates: 2,429
Cumulative Timesteps: 40,562,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00177
Policy Entropy: 4.29192
Value Function Loss: 0.07904

Mean KL Divergence: 0.00068
SB3 Clip Fraction: 0.00137
Policy Update Magnitude: 0.09018
Value Function Update Magnitude: 0.05459

Collected Steps per Second: 25,649.67758
Overall Steps per Second: 18,822.91783

Timestep Collection Time: 1.95036
Timestep Consumption Time: 0.70736
PPO Batch Consumption Time: 0.05833
Total Iteration Time: 2.65772

Cumulative Model Updates: 2,432
Cumulative Timesteps: 40,612,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 40612684...
Checkpoint 40612684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01331
Policy Entropy: 4.29900
Value Function Loss: 0.06779

Mean KL Divergence: 0.00094
SB3 Clip Fraction: 0.00335
Policy Update Magnitude: 0.09723
Value Function Update Magnitude: 0.05752

Collected Steps per Second: 22,597.00737
Overall Steps per Second: 16,021.52676

Timestep Collection Time: 2.21295
Timestep Consumption Time: 0.90823
PPO Batch Consumption Time: 0.09847
Total Iteration Time: 3.12118

Cumulative Model Updates: 2,435
Cumulative Timesteps: 40,662,690

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05963
Policy Entropy: 4.29658
Value Function Loss: 0.06402

Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.00519
Policy Update Magnitude: 0.09625
Value Function Update Magnitude: 0.05256

Collected Steps per Second: 25,688.74506
Overall Steps per Second: 17,857.85578

Timestep Collection Time: 1.94669
Timestep Consumption Time: 0.85365
PPO Batch Consumption Time: 0.08335
Total Iteration Time: 2.80034

Cumulative Model Updates: 2,438
Cumulative Timesteps: 40,712,698

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 40712698...
Checkpoint 40712698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01986
Policy Entropy: 4.30411
Value Function Loss: 0.05982

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.00732
Policy Update Magnitude: 0.08873
Value Function Update Magnitude: 0.04815

Collected Steps per Second: 26,549.45630
Overall Steps per Second: 18,865.00318

Timestep Collection Time: 1.88343
Timestep Consumption Time: 0.76719
PPO Batch Consumption Time: 0.05769
Total Iteration Time: 2.65062

Cumulative Model Updates: 2,441
Cumulative Timesteps: 40,762,702

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02746
Policy Entropy: 4.32263
Value Function Loss: 0.06436

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.00416
Policy Update Magnitude: 0.08734
Value Function Update Magnitude: 0.04848

Collected Steps per Second: 21,866.80061
Overall Steps per Second: 15,154.44786

Timestep Collection Time: 2.28721
Timestep Consumption Time: 1.01307
PPO Batch Consumption Time: 0.12501
Total Iteration Time: 3.30029

Cumulative Model Updates: 2,444
Cumulative Timesteps: 40,812,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 40812716...
Checkpoint 40812716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02516
Policy Entropy: 4.32986
Value Function Loss: 0.05885

Mean KL Divergence: 0.00108
SB3 Clip Fraction: 0.00546
Policy Update Magnitude: 0.08265
Value Function Update Magnitude: 0.04498

Collected Steps per Second: 25,084.55948
Overall Steps per Second: 18,394.42313

Timestep Collection Time: 1.99445
Timestep Consumption Time: 0.72539
PPO Batch Consumption Time: 0.06053
Total Iteration Time: 2.71985

Cumulative Model Updates: 2,447
Cumulative Timesteps: 40,862,746

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00327
Policy Entropy: 4.32518
Value Function Loss: 0.05856

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00035
Policy Update Magnitude: 0.08085
Value Function Update Magnitude: 0.04042

Collected Steps per Second: 25,836.57065
Overall Steps per Second: 18,357.83025

Timestep Collection Time: 1.93640
Timestep Consumption Time: 0.78887
PPO Batch Consumption Time: 0.05981
Total Iteration Time: 2.72527

Cumulative Model Updates: 2,450
Cumulative Timesteps: 40,912,776

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 40912776...
Checkpoint 40912776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04393
Policy Entropy: 4.32930
Value Function Loss: 0.05515

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00077
Policy Update Magnitude: 0.08021
Value Function Update Magnitude: 0.04282

Collected Steps per Second: 22,010.54781
Overall Steps per Second: 15,947.74496

Timestep Collection Time: 2.27255
Timestep Consumption Time: 0.86395
PPO Batch Consumption Time: 0.07634
Total Iteration Time: 3.13649

Cumulative Model Updates: 2,453
Cumulative Timesteps: 40,962,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03502
Policy Entropy: 4.33062
Value Function Loss: 0.06029

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01491
Policy Update Magnitude: 0.08159
Value Function Update Magnitude: 0.04858

Collected Steps per Second: 26,296.82838
Overall Steps per Second: 17,966.13705

Timestep Collection Time: 1.90251
Timestep Consumption Time: 0.88217
PPO Batch Consumption Time: 0.08739
Total Iteration Time: 2.78468

Cumulative Model Updates: 2,456
Cumulative Timesteps: 41,012,826

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 41012826...
Checkpoint 41012826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01558
Policy Entropy: 4.31484
Value Function Loss: 0.06402

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.00525
Policy Update Magnitude: 0.08073
Value Function Update Magnitude: 0.05352

Collected Steps per Second: 25,484.70767
Overall Steps per Second: 18,154.30352

Timestep Collection Time: 1.96196
Timestep Consumption Time: 0.79221
PPO Batch Consumption Time: 0.05792
Total Iteration Time: 2.75417

Cumulative Model Updates: 2,459
Cumulative Timesteps: 41,062,826

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06898
Policy Entropy: 4.29070
Value Function Loss: 0.06124

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.02006
Policy Update Magnitude: 0.06670
Value Function Update Magnitude: 0.05262

Collected Steps per Second: 23,102.81362
Overall Steps per Second: 16,581.44386

Timestep Collection Time: 2.16554
Timestep Consumption Time: 0.85169
PPO Batch Consumption Time: 0.10148
Total Iteration Time: 3.01723

Cumulative Model Updates: 2,462
Cumulative Timesteps: 41,112,856

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 41112856...
Checkpoint 41112856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00198
Policy Entropy: 4.30181
Value Function Loss: 0.06039

Mean KL Divergence: 0.00079
SB3 Clip Fraction: 0.00299
Policy Update Magnitude: 0.07547
Value Function Update Magnitude: 0.05079

Collected Steps per Second: 25,754.97144
Overall Steps per Second: 18,212.33825

Timestep Collection Time: 1.94199
Timestep Consumption Time: 0.80428
PPO Batch Consumption Time: 0.06059
Total Iteration Time: 2.74627

Cumulative Model Updates: 2,465
Cumulative Timesteps: 41,162,872

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00938
Policy Entropy: 4.31234
Value Function Loss: 0.05218

Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.01533
Policy Update Magnitude: 0.07171
Value Function Update Magnitude: 0.04623

Collected Steps per Second: 25,523.54421
Overall Steps per Second: 18,246.56807

Timestep Collection Time: 1.95952
Timestep Consumption Time: 0.78148
PPO Batch Consumption Time: 0.06214
Total Iteration Time: 2.74101

Cumulative Model Updates: 2,468
Cumulative Timesteps: 41,212,886

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 41212886...
Checkpoint 41212886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05362
Policy Entropy: 4.30351
Value Function Loss: 0.06276

Mean KL Divergence: 0.00080
SB3 Clip Fraction: 0.00183
Policy Update Magnitude: 0.07171
Value Function Update Magnitude: 0.05202

Collected Steps per Second: 26,568.47864
Overall Steps per Second: 18,714.49031

Timestep Collection Time: 1.88246
Timestep Consumption Time: 0.79002
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 2.67247

Cumulative Model Updates: 2,471
Cumulative Timesteps: 41,262,900

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14365
Policy Entropy: 4.29448
Value Function Loss: 0.06448

Mean KL Divergence: 0.00113
SB3 Clip Fraction: 0.00820
Policy Update Magnitude: 0.07099
Value Function Update Magnitude: 0.05174

Collected Steps per Second: 22,173.17894
Overall Steps per Second: 15,470.82458

Timestep Collection Time: 2.25642
Timestep Consumption Time: 0.97754
PPO Batch Consumption Time: 0.10918
Total Iteration Time: 3.23396

Cumulative Model Updates: 2,474
Cumulative Timesteps: 41,312,932

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 41312932...
Checkpoint 41312932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05519
Policy Entropy: 4.30768
Value Function Loss: 0.05189

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00111
Policy Update Magnitude: 0.07669
Value Function Update Magnitude: 0.04628

Collected Steps per Second: 25,315.02034
Overall Steps per Second: 18,706.46346

Timestep Collection Time: 1.97543
Timestep Consumption Time: 0.69787
PPO Batch Consumption Time: 0.05841
Total Iteration Time: 2.67330

Cumulative Model Updates: 2,477
Cumulative Timesteps: 41,362,940

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09605
Policy Entropy: 4.32272
Value Function Loss: 0.05312

Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.01444
Policy Update Magnitude: 0.06930
Value Function Update Magnitude: 0.04401

Collected Steps per Second: 25,798.75516
Overall Steps per Second: 18,463.96009

Timestep Collection Time: 1.93839
Timestep Consumption Time: 0.77002
PPO Batch Consumption Time: 0.05941
Total Iteration Time: 2.70841

Cumulative Model Updates: 2,480
Cumulative Timesteps: 41,412,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 41412948...
Checkpoint 41412948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00190
Policy Entropy: 4.33132
Value Function Loss: 0.06061

Mean KL Divergence: 0.00107
SB3 Clip Fraction: 0.00800
Policy Update Magnitude: 0.06935
Value Function Update Magnitude: 0.04842

Collected Steps per Second: 22,430.19700
Overall Steps per Second: 15,953.14777

Timestep Collection Time: 2.22914
Timestep Consumption Time: 0.90504
PPO Batch Consumption Time: 0.10214
Total Iteration Time: 3.13418

Cumulative Model Updates: 2,483
Cumulative Timesteps: 41,462,948

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03354
Policy Entropy: 4.33410
Value Function Loss: 0.06611

Mean KL Divergence: 0.00070
SB3 Clip Fraction: 0.00044
Policy Update Magnitude: 0.07704
Value Function Update Magnitude: 0.05208

Collected Steps per Second: 24,979.39614
Overall Steps per Second: 18,439.41770

Timestep Collection Time: 2.00181
Timestep Consumption Time: 0.70999
PPO Batch Consumption Time: 0.06034
Total Iteration Time: 2.71180

Cumulative Model Updates: 2,486
Cumulative Timesteps: 41,512,952

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 41512952...
Checkpoint 41512952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03318
Policy Entropy: 4.33950
Value Function Loss: 0.05906

Mean KL Divergence: 0.00091
SB3 Clip Fraction: 0.00143
Policy Update Magnitude: 0.07625
Value Function Update Magnitude: 0.04944

Collected Steps per Second: 25,423.28695
Overall Steps per Second: 17,980.65861

Timestep Collection Time: 1.96780
Timestep Consumption Time: 0.81452
PPO Batch Consumption Time: 0.06519
Total Iteration Time: 2.78232

Cumulative Model Updates: 2,489
Cumulative Timesteps: 41,562,980

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02278
Policy Entropy: 4.33938
Value Function Loss: 0.07151

Mean KL Divergence: 0.00101
SB3 Clip Fraction: 0.00551
Policy Update Magnitude: 0.07129
Value Function Update Magnitude: 0.04945

Collected Steps per Second: 25,250.47456
Overall Steps per Second: 17,408.60630

Timestep Collection Time: 1.98135
Timestep Consumption Time: 0.89252
PPO Batch Consumption Time: 0.09617
Total Iteration Time: 2.87387

Cumulative Model Updates: 2,492
Cumulative Timesteps: 41,613,010

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 41613010...
Checkpoint 41613010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01061
Policy Entropy: 4.35218
Value Function Loss: 0.07930

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00041
Policy Update Magnitude: 0.07632
Value Function Update Magnitude: 0.05654

Collected Steps per Second: 25,944.05457
Overall Steps per Second: 18,493.08459

Timestep Collection Time: 1.92807
Timestep Consumption Time: 0.77683
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 2.70490

Cumulative Model Updates: 2,495
Cumulative Timesteps: 41,663,032

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00872
Policy Entropy: 4.35761
Value Function Loss: 0.07372

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00039
Policy Update Magnitude: 0.08040
Value Function Update Magnitude: 0.05591

Collected Steps per Second: 25,631.30755
Overall Steps per Second: 18,125.06162

Timestep Collection Time: 1.95090
Timestep Consumption Time: 0.80794
PPO Batch Consumption Time: 0.06285
Total Iteration Time: 2.75883

Cumulative Model Updates: 2,498
Cumulative Timesteps: 41,713,036

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 41713036...
Checkpoint 41713036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05939
Policy Entropy: 4.35995
Value Function Loss: 0.04970

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00084
Policy Update Magnitude: 0.07957
Value Function Update Magnitude: 0.05309

Collected Steps per Second: 22,453.79314
Overall Steps per Second: 16,169.03570

Timestep Collection Time: 2.22760
Timestep Consumption Time: 0.86585
PPO Batch Consumption Time: 0.10579
Total Iteration Time: 3.09344

Cumulative Model Updates: 2,501
Cumulative Timesteps: 41,763,054

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01401
Policy Entropy: 4.35431
Value Function Loss: 0.04080

Mean KL Divergence: 0.00102
SB3 Clip Fraction: 0.00623
Policy Update Magnitude: 0.07186
Value Function Update Magnitude: 0.04794

Collected Steps per Second: 25,823.72879
Overall Steps per Second: 17,855.26288

Timestep Collection Time: 1.93744
Timestep Consumption Time: 0.86464
PPO Batch Consumption Time: 0.08324
Total Iteration Time: 2.80209

Cumulative Model Updates: 2,504
Cumulative Timesteps: 41,813,086

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 41813086...
Checkpoint 41813086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01828
Policy Entropy: 4.36140
Value Function Loss: 0.05121

Mean KL Divergence: 0.00061
SB3 Clip Fraction: 0.00204
Policy Update Magnitude: 0.06412
Value Function Update Magnitude: 0.04478

Collected Steps per Second: 25,263.48592
Overall Steps per Second: 18,262.03856

Timestep Collection Time: 1.97930
Timestep Consumption Time: 0.75884
PPO Batch Consumption Time: 0.05980
Total Iteration Time: 2.73814

Cumulative Model Updates: 2,507
Cumulative Timesteps: 41,863,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00654
Policy Entropy: 4.36160
Value Function Loss: 0.05958

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00006
Policy Update Magnitude: 0.06411
Value Function Update Magnitude: 0.04695

Collected Steps per Second: 26,191.79695
Overall Steps per Second: 18,504.77002

Timestep Collection Time: 1.90907
Timestep Consumption Time: 0.79304
PPO Batch Consumption Time: 0.06039
Total Iteration Time: 2.70211

Cumulative Model Updates: 2,510
Cumulative Timesteps: 41,913,092

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 41913092...
Checkpoint 41913092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08007
Policy Entropy: 4.35368
Value Function Loss: 0.08483

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00039
Policy Update Magnitude: 0.07199
Value Function Update Magnitude: 0.05360

Collected Steps per Second: 22,231.95745
Overall Steps per Second: 16,026.31852

Timestep Collection Time: 2.24910
Timestep Consumption Time: 0.87089
PPO Batch Consumption Time: 0.07724
Total Iteration Time: 3.11999

Cumulative Model Updates: 2,513
Cumulative Timesteps: 41,963,094

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00015
Policy Entropy: 4.34686
Value Function Loss: 0.06815

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00233
Policy Update Magnitude: 0.07662
Value Function Update Magnitude: 0.05247

Collected Steps per Second: 25,593.72901
Overall Steps per Second: 17,948.37980

Timestep Collection Time: 1.95368
Timestep Consumption Time: 0.83220
PPO Batch Consumption Time: 0.10285
Total Iteration Time: 2.78588

Cumulative Model Updates: 2,516
Cumulative Timesteps: 42,013,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 42013096...
Checkpoint 42013096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05503
Policy Entropy: 4.35141
Value Function Loss: 0.06909

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00050
Policy Update Magnitude: 0.08389
Value Function Update Magnitude: 0.05644

Collected Steps per Second: 25,614.03895
Overall Steps per Second: 18,278.05513

Timestep Collection Time: 1.95205
Timestep Consumption Time: 0.78347
PPO Batch Consumption Time: 0.06038
Total Iteration Time: 2.73552

Cumulative Model Updates: 2,519
Cumulative Timesteps: 42,063,096

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15257
Policy Entropy: 4.36793
Value Function Loss: 0.05196

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.02367
Policy Update Magnitude: 0.07575
Value Function Update Magnitude: 0.04897

Collected Steps per Second: 25,674.50631
Overall Steps per Second: 18,384.53397

Timestep Collection Time: 1.94816
Timestep Consumption Time: 0.77250
PPO Batch Consumption Time: 0.06088
Total Iteration Time: 2.72066

Cumulative Model Updates: 2,522
Cumulative Timesteps: 42,113,114

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 42113114...
Checkpoint 42113114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01295
Policy Entropy: 4.35940
Value Function Loss: 0.06207

Mean KL Divergence: 0.00112
SB3 Clip Fraction: 0.01211
Policy Update Magnitude: 0.07198
Value Function Update Magnitude: 0.04430

Collected Steps per Second: 22,970.90915
Overall Steps per Second: 16,132.91822

Timestep Collection Time: 2.17754
Timestep Consumption Time: 0.92296
PPO Batch Consumption Time: 0.10398
Total Iteration Time: 3.10049

Cumulative Model Updates: 2,525
Cumulative Timesteps: 42,163,134

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09068
Policy Entropy: 4.34278
Value Function Loss: 0.04900

Mean KL Divergence: 0.00076
SB3 Clip Fraction: 0.00543
Policy Update Magnitude: 0.06659
Value Function Update Magnitude: 0.04538

Collected Steps per Second: 25,559.36079
Overall Steps per Second: 17,847.84864

Timestep Collection Time: 1.95678
Timestep Consumption Time: 0.84546
PPO Batch Consumption Time: 0.07822
Total Iteration Time: 2.80224

Cumulative Model Updates: 2,528
Cumulative Timesteps: 42,213,148

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 42213148...
Checkpoint 42213148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00517
Policy Entropy: 4.34009
Value Function Loss: 0.05869

Mean KL Divergence: 0.00105
SB3 Clip Fraction: 0.01291
Policy Update Magnitude: 0.06309
Value Function Update Magnitude: 0.04750

Collected Steps per Second: 25,193.82706
Overall Steps per Second: 18,642.40048

Timestep Collection Time: 1.98477
Timestep Consumption Time: 0.69750
PPO Batch Consumption Time: 0.05864
Total Iteration Time: 2.68227

Cumulative Model Updates: 2,531
Cumulative Timesteps: 42,263,152

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08849
Policy Entropy: 4.35182
Value Function Loss: 0.05140

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00001
Policy Update Magnitude: 0.06360
Value Function Update Magnitude: 0.04777

Collected Steps per Second: 23,239.03169
Overall Steps per Second: 16,205.99400

Timestep Collection Time: 2.15233
Timestep Consumption Time: 0.93406
PPO Batch Consumption Time: 0.10169
Total Iteration Time: 3.08639

Cumulative Model Updates: 2,534
Cumulative Timesteps: 42,313,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 42313170...
Checkpoint 42313170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02108
Policy Entropy: 4.35677
Value Function Loss: 0.05852

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00093
Policy Update Magnitude: 0.06235
Value Function Update Magnitude: 0.04885

Collected Steps per Second: 25,416.51499
Overall Steps per Second: 18,163.47410

Timestep Collection Time: 1.96833
Timestep Consumption Time: 0.78599
PPO Batch Consumption Time: 0.06162
Total Iteration Time: 2.75432

Cumulative Model Updates: 2,537
Cumulative Timesteps: 42,363,198

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02372
Policy Entropy: 4.36024
Value Function Loss: 0.05376

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00113
Policy Update Magnitude: 0.06208
Value Function Update Magnitude: 0.04641

Collected Steps per Second: 25,589.22070
Overall Steps per Second: 18,753.42916

Timestep Collection Time: 1.95403
Timestep Consumption Time: 0.71226
PPO Batch Consumption Time: 0.06056
Total Iteration Time: 2.66629

Cumulative Model Updates: 2,540
Cumulative Timesteps: 42,413,200

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 42413200...
Checkpoint 42413200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12877
Policy Entropy: 4.36127
Value Function Loss: 0.06104

Mean KL Divergence: 0.00023
SB3 Clip Fraction: 0.00027
Policy Update Magnitude: 0.06279
Value Function Update Magnitude: 0.04864

Collected Steps per Second: 22,227.06656
Overall Steps per Second: 15,915.88500

Timestep Collection Time: 2.25005
Timestep Consumption Time: 0.89222
PPO Batch Consumption Time: 0.08991
Total Iteration Time: 3.14227

Cumulative Model Updates: 2,543
Cumulative Timesteps: 42,463,212

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01725
Policy Entropy: 4.36258
Value Function Loss: 0.07365

Mean KL Divergence: 0.00019
SB3 Clip Fraction: 0.00021
Policy Update Magnitude: 0.06743
Value Function Update Magnitude: 0.05059

Collected Steps per Second: 25,487.46262
Overall Steps per Second: 18,389.29380

Timestep Collection Time: 1.96340
Timestep Consumption Time: 0.75786
PPO Batch Consumption Time: 0.06104
Total Iteration Time: 2.72126

Cumulative Model Updates: 2,546
Cumulative Timesteps: 42,513,254

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 42513254...
Checkpoint 42513254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00864
Policy Entropy: 4.36155
Value Function Loss: 0.06911

Mean KL Divergence: 0.00018
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.07320
Value Function Update Magnitude: 0.05221

Collected Steps per Second: 26,281.33322
Overall Steps per Second: 18,546.93776

Timestep Collection Time: 1.90310
Timestep Consumption Time: 0.79363
PPO Batch Consumption Time: 0.06112
Total Iteration Time: 2.69673

Cumulative Model Updates: 2,549
Cumulative Timesteps: 42,563,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05728
Policy Entropy: 4.36497
Value Function Loss: 0.07588

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00009
Policy Update Magnitude: 0.07973
Value Function Update Magnitude: 0.04972

Collected Steps per Second: 22,666.10078
Overall Steps per Second: 15,913.76448

Timestep Collection Time: 2.20611
Timestep Consumption Time: 0.93607
PPO Batch Consumption Time: 0.10678
Total Iteration Time: 3.14219

Cumulative Model Updates: 2,552
Cumulative Timesteps: 42,613,274

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 42613274...
Checkpoint 42613274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01083
Policy Entropy: 4.35693
Value Function Loss: 0.06680

Mean KL Divergence: 0.00066
SB3 Clip Fraction: 0.00613
Policy Update Magnitude: 0.07917
Value Function Update Magnitude: 0.04925

Collected Steps per Second: 25,606.54453
Overall Steps per Second: 17,965.67784

Timestep Collection Time: 1.95388
Timestep Consumption Time: 0.83099
PPO Batch Consumption Time: 0.09477
Total Iteration Time: 2.78487

Cumulative Model Updates: 2,555
Cumulative Timesteps: 42,663,306

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01686
Policy Entropy: 4.35055
Value Function Loss: 0.05935

Mean KL Divergence: 0.00086
SB3 Clip Fraction: 0.00967
Policy Update Magnitude: 0.07339
Value Function Update Magnitude: 0.04914

Collected Steps per Second: 25,131.25142
Overall Steps per Second: 18,068.98172

Timestep Collection Time: 1.99011
Timestep Consumption Time: 0.77784
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 2.76795

Cumulative Model Updates: 2,558
Cumulative Timesteps: 42,713,320

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 42713320...
Checkpoint 42713320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03608
Policy Entropy: 4.35175
Value Function Loss: 0.04801

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00278
Policy Update Magnitude: 0.06818
Value Function Update Magnitude: 0.05221

Collected Steps per Second: 21,920.39261
Overall Steps per Second: 15,618.71350

Timestep Collection Time: 2.28135
Timestep Consumption Time: 0.92045
PPO Batch Consumption Time: 0.10556
Total Iteration Time: 3.20180

Cumulative Model Updates: 2,561
Cumulative Timesteps: 42,763,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02360
Policy Entropy: 4.35313
Value Function Loss: 0.05566

Mean KL Divergence: 0.00017
SB3 Clip Fraction: 0.00002
Policy Update Magnitude: 0.06322
Value Function Update Magnitude: 0.05512

Collected Steps per Second: 26,685.80492
Overall Steps per Second: 18,792.79770

Timestep Collection Time: 1.87478
Timestep Consumption Time: 0.78741
PPO Batch Consumption Time: 0.05924
Total Iteration Time: 2.66219

Cumulative Model Updates: 2,564
Cumulative Timesteps: 42,813,358

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 42813358...
Checkpoint 42813358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05957
Policy Entropy: 4.35722
Value Function Loss: 0.06337

Mean KL Divergence: 0.00020
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.06595
Value Function Update Magnitude: 0.05611

Collected Steps per Second: 22,999.39094
Overall Steps per Second: 16,057.06376

Timestep Collection Time: 2.17484
Timestep Consumption Time: 0.94030
PPO Batch Consumption Time: 0.10789
Total Iteration Time: 3.11514

Cumulative Model Updates: 2,567
Cumulative Timesteps: 42,863,378

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01498
Policy Entropy: 4.36616
Value Function Loss: 0.08653

Mean KL Divergence: 0.00087
SB3 Clip Fraction: 0.00649
Policy Update Magnitude: 0.06805
Value Function Update Magnitude: 0.06068

Collected Steps per Second: 25,357.23353
Overall Steps per Second: 18,560.42163

Timestep Collection Time: 1.97222
Timestep Consumption Time: 0.72222
PPO Batch Consumption Time: 0.06042
Total Iteration Time: 2.69444

Cumulative Model Updates: 2,570
Cumulative Timesteps: 42,913,388

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 42913388...
Checkpoint 42913388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01009
Policy Entropy: 4.36692
Value Function Loss: 0.07147

Mean KL Divergence: 0.00069
SB3 Clip Fraction: 0.00502
Policy Update Magnitude: 0.07442
Value Function Update Magnitude: 0.06898

Collected Steps per Second: 22,863.14787
Overall Steps per Second: 16,228.95025

Timestep Collection Time: 2.18789
Timestep Consumption Time: 0.89438
PPO Batch Consumption Time: 0.09514
Total Iteration Time: 3.08227

Cumulative Model Updates: 2,573
Cumulative Timesteps: 42,963,410

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01758
Policy Entropy: 4.36259
Value Function Loss: 0.06999

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00088
Policy Update Magnitude: 0.07693
Value Function Update Magnitude: 0.06652

Collected Steps per Second: 25,446.28037
Overall Steps per Second: 17,873.41650

Timestep Collection Time: 1.96555
Timestep Consumption Time: 0.83279
PPO Batch Consumption Time: 0.08002
Total Iteration Time: 2.79835

Cumulative Model Updates: 2,576
Cumulative Timesteps: 43,013,426

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 43013426...
Checkpoint 43013426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02656
Policy Entropy: 4.36165
Value Function Loss: 0.06366

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00187
Policy Update Magnitude: 0.07734
Value Function Update Magnitude: 0.05522

Collected Steps per Second: 26,322.83923
Overall Steps per Second: 18,603.99523

Timestep Collection Time: 1.90040
Timestep Consumption Time: 0.78848
PPO Batch Consumption Time: 0.05917
Total Iteration Time: 2.68888

Cumulative Model Updates: 2,579
Cumulative Timesteps: 43,063,450

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02437
Policy Entropy: 4.37115
Value Function Loss: 0.07639

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00063
Policy Update Magnitude: 0.07315
Value Function Update Magnitude: 0.04733

Collected Steps per Second: 25,817.67502
Overall Steps per Second: 18,248.68599

Timestep Collection Time: 1.93674
Timestep Consumption Time: 0.80330
PPO Batch Consumption Time: 0.06026
Total Iteration Time: 2.74003

Cumulative Model Updates: 2,582
Cumulative Timesteps: 43,113,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 43113452...
Checkpoint 43113452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00035
Policy Entropy: 4.36944
Value Function Loss: 0.07912

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00082
Policy Update Magnitude: 0.07371
Value Function Update Magnitude: 0.05058

Collected Steps per Second: 22,066.91625
Overall Steps per Second: 16,018.96697

Timestep Collection Time: 2.26584
Timestep Consumption Time: 0.85546
PPO Batch Consumption Time: 0.10522
Total Iteration Time: 3.12130

Cumulative Model Updates: 2,585
Cumulative Timesteps: 43,163,452

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03181
Policy Entropy: 4.36516
Value Function Loss: 0.07324

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00033
Policy Update Magnitude: 0.07551
Value Function Update Magnitude: 0.04899

Collected Steps per Second: 25,793.25368
Overall Steps per Second: 17,859.28592

Timestep Collection Time: 1.93911
Timestep Consumption Time: 0.86145
PPO Batch Consumption Time: 0.07785
Total Iteration Time: 2.80056

Cumulative Model Updates: 2,588
Cumulative Timesteps: 43,213,468

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 43213468...
Checkpoint 43213468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03491
Policy Entropy: 4.34877
Value Function Loss: 0.06123

Mean KL Divergence: 0.00082
SB3 Clip Fraction: 0.00490
Policy Update Magnitude: 0.07387
Value Function Update Magnitude: 0.04340

Collected Steps per Second: 25,642.57315
Overall Steps per Second: 18,451.66653

Timestep Collection Time: 1.95019
Timestep Consumption Time: 0.76002
PPO Batch Consumption Time: 0.06034
Total Iteration Time: 2.71022

Cumulative Model Updates: 2,591
Cumulative Timesteps: 43,263,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00822
Policy Entropy: 4.35234
Value Function Loss: 0.05352

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00091
Policy Update Magnitude: 0.07077
Value Function Update Magnitude: 0.04271

Collected Steps per Second: 25,365.85752
Overall Steps per Second: 18,523.13611

Timestep Collection Time: 1.97210
Timestep Consumption Time: 0.72852
PPO Batch Consumption Time: 0.06023
Total Iteration Time: 2.70062

Cumulative Model Updates: 2,594
Cumulative Timesteps: 43,313,500

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 43313500...
Checkpoint 43313500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03064
Policy Entropy: 4.35576
Value Function Loss: 0.04774

Mean KL Divergence: 0.00091
SB3 Clip Fraction: 0.00662
Policy Update Magnitude: 0.06646
Value Function Update Magnitude: 0.04540

Collected Steps per Second: 22,546.37013
Overall Steps per Second: 15,923.20385

Timestep Collection Time: 2.21801
Timestep Consumption Time: 0.92257
PPO Batch Consumption Time: 0.09997
Total Iteration Time: 3.14057

Cumulative Model Updates: 2,597
Cumulative Timesteps: 43,363,508

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00795
Policy Entropy: 4.35871
Value Function Loss: 0.03659

Mean KL Divergence: 0.00096
SB3 Clip Fraction: 0.01018
Policy Update Magnitude: 0.06096
Value Function Update Magnitude: 0.04295

Collected Steps per Second: 25,726.98564
Overall Steps per Second: 17,874.88886

Timestep Collection Time: 1.94411
Timestep Consumption Time: 0.85401
PPO Batch Consumption Time: 0.08226
Total Iteration Time: 2.79812

Cumulative Model Updates: 2,600
Cumulative Timesteps: 43,413,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 43413524...
Checkpoint 43413524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00687
Policy Entropy: 4.35635
Value Function Loss: 0.03198

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00152
Policy Update Magnitude: 0.05968
Value Function Update Magnitude: 0.04843

Collected Steps per Second: 26,440.79748
Overall Steps per Second: 18,648.09999

Timestep Collection Time: 1.89177
Timestep Consumption Time: 0.79054
PPO Batch Consumption Time: 0.05904
Total Iteration Time: 2.68231

Cumulative Model Updates: 2,603
Cumulative Timesteps: 43,463,544

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04228
Policy Entropy: 4.36171
Value Function Loss: 0.02893

Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.05113

Collected Steps per Second: 23,061.73299
Overall Steps per Second: 16,192.12907

Timestep Collection Time: 2.16887
Timestep Consumption Time: 0.92016
PPO Batch Consumption Time: 0.09427
Total Iteration Time: 3.08903

Cumulative Model Updates: 2,606
Cumulative Timesteps: 43,513,562

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 43513562...
Checkpoint 43513562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00127
Policy Entropy: 4.36571
Value Function Loss: 0.04386

Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00004
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.04853

Collected Steps per Second: 25,518.19480
Overall Steps per Second: 18,756.44303

Timestep Collection Time: 1.95954
Timestep Consumption Time: 0.70642
PPO Batch Consumption Time: 0.05854
Total Iteration Time: 2.66596

Cumulative Model Updates: 2,609
Cumulative Timesteps: 43,563,566

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00854
Policy Entropy: 4.36536
Value Function Loss: 0.04706

Mean KL Divergence: 0.00015
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06206
Value Function Update Magnitude: 0.04489

Collected Steps per Second: 22,824.81894
Overall Steps per Second: 16,086.37402

Timestep Collection Time: 2.19104
Timestep Consumption Time: 0.91781
PPO Batch Consumption Time: 0.10203
Total Iteration Time: 3.10884

Cumulative Model Updates: 2,612
Cumulative Timesteps: 43,613,576

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 43613576...
Checkpoint 43613576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00210
Policy Entropy: 4.35139
Value Function Loss: 0.04003

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00460
Policy Update Magnitude: 0.06491
Value Function Update Magnitude: 0.04257

Collected Steps per Second: 24,801.38244
Overall Steps per Second: 16,850.34561

Timestep Collection Time: 2.01690
Timestep Consumption Time: 0.95170
PPO Batch Consumption Time: 0.11783
Total Iteration Time: 2.96860

Cumulative Model Updates: 2,615
Cumulative Timesteps: 43,663,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01953
Policy Entropy: 4.34826
Value Function Loss: 0.02804

Mean KL Divergence: 0.00069
SB3 Clip Fraction: 0.00563
Policy Update Magnitude: 0.06206
Value Function Update Magnitude: 0.04446

Collected Steps per Second: 27,018.29091
Overall Steps per Second: 17,891.62270

Timestep Collection Time: 1.85097
Timestep Consumption Time: 0.94419
PPO Batch Consumption Time: 0.11566
Total Iteration Time: 2.79516

Cumulative Model Updates: 2,618
Cumulative Timesteps: 43,713,608

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 43713608...
Checkpoint 43713608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00081
Policy Entropy: 4.34441
Value Function Loss: 0.01663

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00021
Policy Update Magnitude: 0.05666
Value Function Update Magnitude: 0.04043

Collected Steps per Second: 25,705.60487
Overall Steps per Second: 18,150.77418

Timestep Collection Time: 1.94533
Timestep Consumption Time: 0.80970
PPO Batch Consumption Time: 0.06768
Total Iteration Time: 2.75503

Cumulative Model Updates: 2,621
Cumulative Timesteps: 43,763,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01566
Policy Entropy: 4.34198
Value Function Loss: 0.02931

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00019
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.04394

Collected Steps per Second: 25,031.35045
Overall Steps per Second: 18,631.83404

Timestep Collection Time: 1.99957
Timestep Consumption Time: 0.68680
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 2.68637

Cumulative Model Updates: 2,624
Cumulative Timesteps: 43,813,666

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 43813666...
Checkpoint 43813666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00541
Policy Entropy: 4.32779
Value Function Loss: 0.04991

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00074
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.05415

Collected Steps per Second: 22,082.46319
Overall Steps per Second: 15,918.02339

Timestep Collection Time: 2.26442
Timestep Consumption Time: 0.87692
PPO Batch Consumption Time: 0.08135
Total Iteration Time: 3.14134

Cumulative Model Updates: 2,627
Cumulative Timesteps: 43,863,670

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01772
Policy Entropy: 4.31773
Value Function Loss: 0.05926

Mean KL Divergence: 0.00095
SB3 Clip Fraction: 0.00542
Policy Update Magnitude: 0.06835
Value Function Update Magnitude: 0.06742

Collected Steps per Second: 25,757.36900
Overall Steps per Second: 17,917.47627

Timestep Collection Time: 1.94127
Timestep Consumption Time: 0.84941
PPO Batch Consumption Time: 0.07915
Total Iteration Time: 2.79068

Cumulative Model Updates: 2,630
Cumulative Timesteps: 43,913,672

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 43913672...
Checkpoint 43913672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03523
Policy Entropy: 4.31860
Value Function Loss: 0.05749

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00065
Policy Update Magnitude: 0.07821
Value Function Update Magnitude: 0.05756

Collected Steps per Second: 26,457.00800
Overall Steps per Second: 18,684.97118

Timestep Collection Time: 1.89046
Timestep Consumption Time: 0.78634
PPO Batch Consumption Time: 0.05837
Total Iteration Time: 2.67680

Cumulative Model Updates: 2,633
Cumulative Timesteps: 43,963,688

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03273
Policy Entropy: 4.32235
Value Function Loss: 0.04988

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00070
Policy Update Magnitude: 0.07787
Value Function Update Magnitude: 0.05066

Collected Steps per Second: 23,296.79180
Overall Steps per Second: 16,187.33843

Timestep Collection Time: 2.14699
Timestep Consumption Time: 0.94296
PPO Batch Consumption Time: 0.10463
Total Iteration Time: 3.08995

Cumulative Model Updates: 2,636
Cumulative Timesteps: 44,013,706

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 44013706...
Checkpoint 44013706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04531
Policy Entropy: 4.31047
Value Function Loss: 0.05408

Mean KL Divergence: 0.00104
SB3 Clip Fraction: 0.00800
Policy Update Magnitude: 0.07633
Value Function Update Magnitude: 0.05662

Collected Steps per Second: 25,242.31099
Overall Steps per Second: 18,253.92448

Timestep Collection Time: 1.98104
Timestep Consumption Time: 0.75843
PPO Batch Consumption Time: 0.06088
Total Iteration Time: 2.73947

Cumulative Model Updates: 2,639
Cumulative Timesteps: 44,063,712

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01439
Policy Entropy: 4.30147
Value Function Loss: 0.04851

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01544
Policy Update Magnitude: 0.07229
Value Function Update Magnitude: 0.05456

Collected Steps per Second: 26,699.69333
Overall Steps per Second: 18,827.60754

Timestep Collection Time: 1.87283
Timestep Consumption Time: 0.78306
PPO Batch Consumption Time: 0.05818
Total Iteration Time: 2.65589

Cumulative Model Updates: 2,642
Cumulative Timesteps: 44,113,716

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 44113716...
Checkpoint 44113716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01791
Policy Entropy: 4.30667
Value Function Loss: 0.04084

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00033
Policy Update Magnitude: 0.07298
Value Function Update Magnitude: 0.05347

Collected Steps per Second: 22,628.54410
Overall Steps per Second: 15,863.86711

Timestep Collection Time: 2.21031
Timestep Consumption Time: 0.94252
PPO Batch Consumption Time: 0.10997
Total Iteration Time: 3.15283

Cumulative Model Updates: 2,645
Cumulative Timesteps: 44,163,732

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03013
Policy Entropy: 4.30150
Value Function Loss: 0.02868

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00057
Policy Update Magnitude: 0.07172
Value Function Update Magnitude: 0.04564

Collected Steps per Second: 25,581.71467
Overall Steps per Second: 18,765.17029

Timestep Collection Time: 1.95476
Timestep Consumption Time: 0.71007
PPO Batch Consumption Time: 0.05922
Total Iteration Time: 2.66483

Cumulative Model Updates: 2,648
Cumulative Timesteps: 44,213,738

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 44213738...
Checkpoint 44213738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03392
Policy Entropy: 4.29402
Value Function Loss: 0.02996

Mean KL Divergence: 0.00072
SB3 Clip Fraction: 0.00561
Policy Update Magnitude: 0.06933
Value Function Update Magnitude: 0.04286

Collected Steps per Second: 23,431.60878
Overall Steps per Second: 16,135.67079

Timestep Collection Time: 2.13387
Timestep Consumption Time: 0.96485
PPO Batch Consumption Time: 0.11536
Total Iteration Time: 3.09872

Cumulative Model Updates: 2,651
Cumulative Timesteps: 44,263,738

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02744
Policy Entropy: 4.28900
Value Function Loss: 0.06055

Mean KL Divergence: 0.00105
SB3 Clip Fraction: 0.01134
Policy Update Magnitude: 0.06467
Value Function Update Magnitude: 0.03514

Collected Steps per Second: 25,557.11815
Overall Steps per Second: 18,319.68152

Timestep Collection Time: 1.95750
Timestep Consumption Time: 0.77334
PPO Batch Consumption Time: 0.06128
Total Iteration Time: 2.73083

Cumulative Model Updates: 2,654
Cumulative Timesteps: 44,313,766

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 44313766...
Checkpoint 44313766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02034
Policy Entropy: 4.30859
Value Function Loss: 0.06089

Mean KL Divergence: 0.00064
SB3 Clip Fraction: 0.00161
Policy Update Magnitude: 0.07546
Value Function Update Magnitude: 0.03421

Collected Steps per Second: 26,350.01147
Overall Steps per Second: 17,609.62210

Timestep Collection Time: 1.89867
Timestep Consumption Time: 0.94239
PPO Batch Consumption Time: 0.11442
Total Iteration Time: 2.84106

Cumulative Model Updates: 2,657
Cumulative Timesteps: 44,363,796

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02315
Policy Entropy: 4.31991
Value Function Loss: 0.09015

Mean KL Divergence: 0.00095
SB3 Clip Fraction: 0.00576
Policy Update Magnitude: 0.08272
Value Function Update Magnitude: 0.03761

Collected Steps per Second: 25,889.15611
Overall Steps per Second: 18,318.85726

Timestep Collection Time: 1.93332
Timestep Consumption Time: 0.79895
PPO Batch Consumption Time: 0.06213
Total Iteration Time: 2.73227

Cumulative Model Updates: 2,660
Cumulative Timesteps: 44,413,848

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 44413848...
Checkpoint 44413848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00591
Policy Entropy: 4.30208
Value Function Loss: 0.07875

Mean KL Divergence: 0.00105
SB3 Clip Fraction: 0.01006
Policy Update Magnitude: 0.08234
Value Function Update Magnitude: 0.04492

Collected Steps per Second: 24,924.24812
Overall Steps per Second: 18,379.98206

Timestep Collection Time: 2.00688
Timestep Consumption Time: 0.71456
PPO Batch Consumption Time: 0.06024
Total Iteration Time: 2.72144

Cumulative Model Updates: 2,663
Cumulative Timesteps: 44,463,868

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03626
Policy Entropy: 4.31603
Value Function Loss: 0.09404

Mean KL Divergence: 0.00112
SB3 Clip Fraction: 0.00962
Policy Update Magnitude: 0.09460
Value Function Update Magnitude: 0.04931

Collected Steps per Second: 22,255.77008
Overall Steps per Second: 15,921.69684

Timestep Collection Time: 2.24661
Timestep Consumption Time: 0.89376
PPO Batch Consumption Time: 0.09376
Total Iteration Time: 3.14037

Cumulative Model Updates: 2,666
Cumulative Timesteps: 44,513,868

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 44513868...
Checkpoint 44513868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01851
Policy Entropy: 4.32032
Value Function Loss: 0.08529

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.02100
Policy Update Magnitude: 0.08339
Value Function Update Magnitude: 0.05047

Collected Steps per Second: 25,277.79906
Overall Steps per Second: 17,787.57402

Timestep Collection Time: 1.97873
Timestep Consumption Time: 0.83323
PPO Batch Consumption Time: 0.07859
Total Iteration Time: 2.81196

Cumulative Model Updates: 2,669
Cumulative Timesteps: 44,563,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00359
Policy Entropy: 4.29735
Value Function Loss: 0.06274

Mean KL Divergence: 0.00115
SB3 Clip Fraction: 0.01156
Policy Update Magnitude: 0.08189
Value Function Update Magnitude: 0.05253

Collected Steps per Second: 25,464.92266
Overall Steps per Second: 17,025.52205

Timestep Collection Time: 1.96458
Timestep Consumption Time: 0.97383
PPO Batch Consumption Time: 0.11099
Total Iteration Time: 2.93841

Cumulative Model Updates: 2,672
Cumulative Timesteps: 44,613,914

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 44613914...
Checkpoint 44613914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02779
Policy Entropy: 4.30841
Value Function Loss: 0.05233

Mean KL Divergence: 0.00093
SB3 Clip Fraction: 0.00567
Policy Update Magnitude: 0.08427
Value Function Update Magnitude: 0.05203

Collected Steps per Second: 25,570.33130
Overall Steps per Second: 18,094.70867

Timestep Collection Time: 1.95555
Timestep Consumption Time: 0.80791
PPO Batch Consumption Time: 0.06090
Total Iteration Time: 2.76346

Cumulative Model Updates: 2,675
Cumulative Timesteps: 44,663,918

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07892
Policy Entropy: 4.31673
Value Function Loss: 0.04441

Mean KL Divergence: 0.00121
SB3 Clip Fraction: 0.01016
Policy Update Magnitude: 0.07458
Value Function Update Magnitude: 0.04800

Collected Steps per Second: 25,438.57615
Overall Steps per Second: 18,659.50807

Timestep Collection Time: 1.96623
Timestep Consumption Time: 0.71434
PPO Batch Consumption Time: 0.05954
Total Iteration Time: 2.68056

Cumulative Model Updates: 2,678
Cumulative Timesteps: 44,713,936

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 44713936...
Checkpoint 44713936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03961
Policy Entropy: 4.29248
Value Function Loss: 0.08244

Mean KL Divergence: 0.00113
SB3 Clip Fraction: 0.01143
Policy Update Magnitude: 0.07566
Value Function Update Magnitude: 0.04873

Collected Steps per Second: 22,687.10293
Overall Steps per Second: 15,963.68261

Timestep Collection Time: 2.20434
Timestep Consumption Time: 0.92840
PPO Batch Consumption Time: 0.09552
Total Iteration Time: 3.13274

Cumulative Model Updates: 2,681
Cumulative Timesteps: 44,763,946

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01256
Policy Entropy: 4.28561
Value Function Loss: 0.10176

Mean KL Divergence: 0.00133
SB3 Clip Fraction: 0.01502
Policy Update Magnitude: 0.07871
Value Function Update Magnitude: 0.04933

Collected Steps per Second: 25,490.59791
Overall Steps per Second: 17,851.48225

Timestep Collection Time: 1.96159
Timestep Consumption Time: 0.83941
PPO Batch Consumption Time: 0.08034
Total Iteration Time: 2.80100

Cumulative Model Updates: 2,684
Cumulative Timesteps: 44,813,948

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 44813948...
Checkpoint 44813948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02424
Policy Entropy: 4.29239
Value Function Loss: 0.08817

Mean KL Divergence: 0.00072
SB3 Clip Fraction: 0.00353
Policy Update Magnitude: 0.08385
Value Function Update Magnitude: 0.05626

Collected Steps per Second: 26,049.88291
Overall Steps per Second: 18,315.16322

Timestep Collection Time: 1.91947
Timestep Consumption Time: 0.81062
PPO Batch Consumption Time: 0.07009
Total Iteration Time: 2.73009

Cumulative Model Updates: 2,687
Cumulative Timesteps: 44,863,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01325
Policy Entropy: 4.28065
Value Function Loss: 0.07786

Mean KL Divergence: 0.00078
SB3 Clip Fraction: 0.00397
Policy Update Magnitude: 0.09104
Value Function Update Magnitude: 0.05496

Collected Steps per Second: 25,175.06622
Overall Steps per Second: 18,002.71772

Timestep Collection Time: 1.98665
Timestep Consumption Time: 0.79149
PPO Batch Consumption Time: 0.06158
Total Iteration Time: 2.77814

Cumulative Model Updates: 2,690
Cumulative Timesteps: 44,913,964

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 44913964...
Checkpoint 44913964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01755
Policy Entropy: 4.25132
Value Function Loss: 0.05454

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02357
Policy Update Magnitude: 0.08113
Value Function Update Magnitude: 0.05031

Collected Steps per Second: 25,094.79677
Overall Steps per Second: 17,603.32643

Timestep Collection Time: 1.99268
Timestep Consumption Time: 0.84803
PPO Batch Consumption Time: 0.09312
Total Iteration Time: 2.84071

Cumulative Model Updates: 2,693
Cumulative Timesteps: 44,963,970

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03094
Policy Entropy: 4.26204
Value Function Loss: 0.05152

Mean KL Divergence: 0.00093
SB3 Clip Fraction: 0.00675
Policy Update Magnitude: 0.07831
Value Function Update Magnitude: 0.04879

Collected Steps per Second: 25,486.10686
Overall Steps per Second: 18,142.29894

Timestep Collection Time: 1.96303
Timestep Consumption Time: 0.79461
PPO Batch Consumption Time: 0.06020
Total Iteration Time: 2.75764

Cumulative Model Updates: 2,696
Cumulative Timesteps: 45,014,000

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 45014000...
Checkpoint 45014000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00814
Policy Entropy: 4.28166
Value Function Loss: 0.03136

Mean KL Divergence: 0.00109
SB3 Clip Fraction: 0.00760
Policy Update Magnitude: 0.07526
Value Function Update Magnitude: 0.04372

Collected Steps per Second: 23,219.53508
Overall Steps per Second: 16,546.24588

Timestep Collection Time: 2.15431
Timestep Consumption Time: 0.86886
PPO Batch Consumption Time: 0.08681
Total Iteration Time: 3.02316

Cumulative Model Updates: 2,699
Cumulative Timesteps: 45,064,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04077
Policy Entropy: 4.28724
Value Function Loss: 0.03773

Mean KL Divergence: 0.00101
SB3 Clip Fraction: 0.00589
Policy Update Magnitude: 0.06594
Value Function Update Magnitude: 0.05064

Collected Steps per Second: 25,633.60097
Overall Steps per Second: 18,840.43114

Timestep Collection Time: 1.95088
Timestep Consumption Time: 0.70341
PPO Batch Consumption Time: 0.05996
Total Iteration Time: 2.65429

Cumulative Model Updates: 2,702
Cumulative Timesteps: 45,114,030

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 45114030...
Checkpoint 45114030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02363
Policy Entropy: 4.27097
Value Function Loss: 0.04846

Mean KL Divergence: 0.00122
SB3 Clip Fraction: 0.01283
Policy Update Magnitude: 0.06075
Value Function Update Magnitude: 0.05807

Collected Steps per Second: 22,514.22939
Overall Steps per Second: 16,032.04666

Timestep Collection Time: 2.22153
Timestep Consumption Time: 0.89822
PPO Batch Consumption Time: 0.08755
Total Iteration Time: 3.11975

Cumulative Model Updates: 2,705
Cumulative Timesteps: 45,164,046

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04873
Policy Entropy: 4.27332
Value Function Loss: 0.05415

Mean KL Divergence: 0.00087
SB3 Clip Fraction: 0.00865
Policy Update Magnitude: 0.06343
Value Function Update Magnitude: 0.06174

Collected Steps per Second: 25,653.32888
Overall Steps per Second: 17,900.34309

Timestep Collection Time: 1.94945
Timestep Consumption Time: 0.84435
PPO Batch Consumption Time: 0.08284
Total Iteration Time: 2.79380

Cumulative Model Updates: 2,708
Cumulative Timesteps: 45,214,056

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 45214056...
Checkpoint 45214056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00596
Policy Entropy: 4.27421
Value Function Loss: 0.06467

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00018
Policy Update Magnitude: 0.06676
Value Function Update Magnitude: 0.06491

Collected Steps per Second: 26,622.75780
Overall Steps per Second: 18,866.16584

Timestep Collection Time: 1.87862
Timestep Consumption Time: 0.77237
PPO Batch Consumption Time: 0.05877
Total Iteration Time: 2.65099

Cumulative Model Updates: 2,711
Cumulative Timesteps: 45,264,070

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02406
Policy Entropy: 4.26539
Value Function Loss: 0.06805

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00289
Policy Update Magnitude: 0.07421
Value Function Update Magnitude: 0.05825

Collected Steps per Second: 22,886.10093
Overall Steps per Second: 16,039.26478

Timestep Collection Time: 2.18578
Timestep Consumption Time: 0.93307
PPO Batch Consumption Time: 0.09852
Total Iteration Time: 3.11885

Cumulative Model Updates: 2,714
Cumulative Timesteps: 45,314,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 45314094...
Checkpoint 45314094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05798
Policy Entropy: 4.24809
Value Function Loss: 0.08302

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01533
Policy Update Magnitude: 0.07632
Value Function Update Magnitude: 0.05545

Collected Steps per Second: 25,362.04515
Overall Steps per Second: 18,604.01532

Timestep Collection Time: 1.97247
Timestep Consumption Time: 0.71651
PPO Batch Consumption Time: 0.05980
Total Iteration Time: 2.68899

Cumulative Model Updates: 2,717
Cumulative Timesteps: 45,364,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01633
Policy Entropy: 4.26031
Value Function Loss: 0.07147

Mean KL Divergence: 0.00099
SB3 Clip Fraction: 0.00765
Policy Update Magnitude: 0.08581
Value Function Update Magnitude: 0.04744

Collected Steps per Second: 25,692.71584
Overall Steps per Second: 18,212.34045

Timestep Collection Time: 1.94686
Timestep Consumption Time: 0.79963
PPO Batch Consumption Time: 0.06020
Total Iteration Time: 2.74649

Cumulative Model Updates: 2,720
Cumulative Timesteps: 45,414,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 45414140...
Checkpoint 45414140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02379
Policy Entropy: 4.25760
Value Function Loss: 0.07076

Mean KL Divergence: 0.00100
SB3 Clip Fraction: 0.00711
Policy Update Magnitude: 0.08896
Value Function Update Magnitude: 0.04678

Collected Steps per Second: 22,818.41561
Overall Steps per Second: 16,032.09959

Timestep Collection Time: 2.19174
Timestep Consumption Time: 0.92775
PPO Batch Consumption Time: 0.10967
Total Iteration Time: 3.11949

Cumulative Model Updates: 2,723
Cumulative Timesteps: 45,464,152

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05487
Policy Entropy: 4.24535
Value Function Loss: 0.06381

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01852
Policy Update Magnitude: 0.07890
Value Function Update Magnitude: 0.04521

Collected Steps per Second: 26,382.64809
Overall Steps per Second: 18,693.28426

Timestep Collection Time: 1.89579
Timestep Consumption Time: 0.77982
PPO Batch Consumption Time: 0.05934
Total Iteration Time: 2.67561

Cumulative Model Updates: 2,726
Cumulative Timesteps: 45,514,168

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 45514168...
Checkpoint 45514168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00455
Policy Entropy: 4.24424
Value Function Loss: 0.06826

Mean KL Divergence: 0.00108
SB3 Clip Fraction: 0.00981
Policy Update Magnitude: 0.07453
Value Function Update Magnitude: 0.04417

Collected Steps per Second: 22,700.52352
Overall Steps per Second: 16,084.53621

Timestep Collection Time: 2.20321
Timestep Consumption Time: 0.90624
PPO Batch Consumption Time: 0.09390
Total Iteration Time: 3.10945

Cumulative Model Updates: 2,729
Cumulative Timesteps: 45,564,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03895
Policy Entropy: 4.25002
Value Function Loss: 0.06818

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00167
Policy Update Magnitude: 0.07453
Value Function Update Magnitude: 0.04561

Collected Steps per Second: 25,647.73558
Overall Steps per Second: 19,013.57219

Timestep Collection Time: 1.95004
Timestep Consumption Time: 0.68040
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 2.63044

Cumulative Model Updates: 2,732
Cumulative Timesteps: 45,614,196

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 45614196...
Checkpoint 45614196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02065
Policy Entropy: 4.23353
Value Function Loss: 0.07087

Mean KL Divergence: 0.00066
SB3 Clip Fraction: 0.00188
Policy Update Magnitude: 0.08014
Value Function Update Magnitude: 0.04770

Collected Steps per Second: 22,302.45423
Overall Steps per Second: 15,925.36432

Timestep Collection Time: 2.24316
Timestep Consumption Time: 0.89824
PPO Batch Consumption Time: 0.09639
Total Iteration Time: 3.14140

Cumulative Model Updates: 2,735
Cumulative Timesteps: 45,664,224

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00549
Policy Entropy: 4.21334
Value Function Loss: 0.05298

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01572
Policy Update Magnitude: 0.08232
Value Function Update Magnitude: 0.04781

Collected Steps per Second: 25,342.18306
Overall Steps per Second: 17,855.16970

Timestep Collection Time: 1.97347
Timestep Consumption Time: 0.82751
PPO Batch Consumption Time: 0.07660
Total Iteration Time: 2.80098

Cumulative Model Updates: 2,738
Cumulative Timesteps: 45,714,236

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 45714236...
Checkpoint 45714236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05299
Policy Entropy: 4.23568
Value Function Loss: 0.04164

Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.00912
Policy Update Magnitude: 0.08286
Value Function Update Magnitude: 0.04625

Collected Steps per Second: 26,566.50734
Overall Steps per Second: 18,608.41487

Timestep Collection Time: 1.88252
Timestep Consumption Time: 0.80508
PPO Batch Consumption Time: 0.05899
Total Iteration Time: 2.68760

Cumulative Model Updates: 2,741
Cumulative Timesteps: 45,764,248

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03125
Policy Entropy: 4.24665
Value Function Loss: 0.03067

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02218
Policy Update Magnitude: 0.06943
Value Function Update Magnitude: 0.04224

Collected Steps per Second: 25,652.30341
Overall Steps per Second: 18,173.23219

Timestep Collection Time: 1.94938
Timestep Consumption Time: 0.80225
PPO Batch Consumption Time: 0.06064
Total Iteration Time: 2.75163

Cumulative Model Updates: 2,744
Cumulative Timesteps: 45,814,254

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 45814254...
Checkpoint 45814254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01226
Policy Entropy: 4.23225
Value Function Loss: 0.04618

Mean KL Divergence: 0.00101
SB3 Clip Fraction: 0.00730
Policy Update Magnitude: 0.06281
Value Function Update Magnitude: 0.04461

Collected Steps per Second: 22,714.01600
Overall Steps per Second: 16,160.49100

Timestep Collection Time: 2.20128
Timestep Consumption Time: 0.89268
PPO Batch Consumption Time: 0.11522
Total Iteration Time: 3.09397

Cumulative Model Updates: 2,747
Cumulative Timesteps: 45,864,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00810
Policy Entropy: 4.22352
Value Function Loss: 0.07998

Mean KL Divergence: 0.00077
SB3 Clip Fraction: 0.01059
Policy Update Magnitude: 0.06363
Value Function Update Magnitude: 0.04480

Collected Steps per Second: 25,872.47559
Overall Steps per Second: 17,767.31195

Timestep Collection Time: 1.93279
Timestep Consumption Time: 0.88171
PPO Batch Consumption Time: 0.09096
Total Iteration Time: 2.81449

Cumulative Model Updates: 2,750
Cumulative Timesteps: 45,914,260

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 45914260...
Checkpoint 45914260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00976
Policy Entropy: 4.22932
Value Function Loss: 0.09226

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00068
Policy Update Magnitude: 0.08032
Value Function Update Magnitude: 0.04357

Collected Steps per Second: 25,471.15968
Overall Steps per Second: 18,186.51797

Timestep Collection Time: 1.96395
Timestep Consumption Time: 0.78666
PPO Batch Consumption Time: 0.06575
Total Iteration Time: 2.75061

Cumulative Model Updates: 2,753
Cumulative Timesteps: 45,964,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00982
Policy Entropy: 4.22390
Value Function Loss: 0.10556

Mean KL Divergence: 0.00083
SB3 Clip Fraction: 0.00457
Policy Update Magnitude: 0.09565
Value Function Update Magnitude: 0.05178

Collected Steps per Second: 25,017.21384
Overall Steps per Second: 18,311.81712

Timestep Collection Time: 1.99926
Timestep Consumption Time: 0.73209
PPO Batch Consumption Time: 0.05987
Total Iteration Time: 2.73135

Cumulative Model Updates: 2,756
Cumulative Timesteps: 46,014,300

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 46014300...
Checkpoint 46014300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00879
Policy Entropy: 4.20672
Value Function Loss: 0.09029

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01677
Policy Update Magnitude: 0.09311
Value Function Update Magnitude: 0.05466

Collected Steps per Second: 25,049.20594
Overall Steps per Second: 17,386.68067

Timestep Collection Time: 1.99671
Timestep Consumption Time: 0.87997
PPO Batch Consumption Time: 0.08179
Total Iteration Time: 2.87668

Cumulative Model Updates: 2,759
Cumulative Timesteps: 46,064,316

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10878
Policy Entropy: 4.21576
Value Function Loss: 0.08595

Mean KL Divergence: 0.00106
SB3 Clip Fraction: 0.00643
Policy Update Magnitude: 0.09706
Value Function Update Magnitude: 0.05638

Collected Steps per Second: 25,580.26225
Overall Steps per Second: 18,815.86097

Timestep Collection Time: 1.95534
Timestep Consumption Time: 0.70295
PPO Batch Consumption Time: 0.05884
Total Iteration Time: 2.65829

Cumulative Model Updates: 2,762
Cumulative Timesteps: 46,114,334

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 46114334...
Checkpoint 46114334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03982
Policy Entropy: 4.22721
Value Function Loss: 0.07505

Mean KL Divergence: 0.00081
SB3 Clip Fraction: 0.00376
Policy Update Magnitude: 0.09168
Value Function Update Magnitude: 0.05038

Collected Steps per Second: 22,906.64354
Overall Steps per Second: 16,081.84962

Timestep Collection Time: 2.18303
Timestep Consumption Time: 0.92643
PPO Batch Consumption Time: 0.10323
Total Iteration Time: 3.10947

Cumulative Model Updates: 2,765
Cumulative Timesteps: 46,164,340

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16960
Policy Entropy: 4.21051
Value Function Loss: 0.07891

Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.00913
Policy Update Magnitude: 0.08853
Value Function Update Magnitude: 0.04388

Collected Steps per Second: 25,996.29555
Overall Steps per Second: 18,755.44323

Timestep Collection Time: 1.92412
Timestep Consumption Time: 0.74284
PPO Batch Consumption Time: 0.05863
Total Iteration Time: 2.66696

Cumulative Model Updates: 2,768
Cumulative Timesteps: 46,214,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 46214360...
Checkpoint 46214360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03530
Policy Entropy: 4.21084
Value Function Loss: 0.08005

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01078
Policy Update Magnitude: 0.08702
Value Function Update Magnitude: 0.04452

Collected Steps per Second: 20,366.38328
Overall Steps per Second: 15,146.90785

Timestep Collection Time: 2.45728
Timestep Consumption Time: 0.84676
PPO Batch Consumption Time: 0.10432
Total Iteration Time: 3.30404

Cumulative Model Updates: 2,771
Cumulative Timesteps: 46,264,406

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02513
Policy Entropy: 4.24495
Value Function Loss: 0.08040

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01725
Policy Update Magnitude: 0.08478
Value Function Update Magnitude: 0.04992

Collected Steps per Second: 25,898.72779
Overall Steps per Second: 18,170.91537

Timestep Collection Time: 1.93137
Timestep Consumption Time: 0.82138
PPO Batch Consumption Time: 0.06157
Total Iteration Time: 2.75275

Cumulative Model Updates: 2,774
Cumulative Timesteps: 46,314,426

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 46314426...
Checkpoint 46314426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.22287
Policy Entropy: 4.22893
Value Function Loss: 0.08639

Mean KL Divergence: 0.00125
SB3 Clip Fraction: 0.01096
Policy Update Magnitude: 0.08742
Value Function Update Magnitude: 0.05140

Collected Steps per Second: 25,910.90853
Overall Steps per Second: 17,807.59814

Timestep Collection Time: 1.93085
Timestep Consumption Time: 0.87863
PPO Batch Consumption Time: 0.11271
Total Iteration Time: 2.80947

Cumulative Model Updates: 2,777
Cumulative Timesteps: 46,364,456

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06903
Policy Entropy: 4.20997
Value Function Loss: 0.09440

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01042
Policy Update Magnitude: 0.08726
Value Function Update Magnitude: 0.05093

Collected Steps per Second: 25,867.93871
Overall Steps per Second: 18,257.64232

Timestep Collection Time: 1.93320
Timestep Consumption Time: 0.80581
PPO Batch Consumption Time: 0.06251
Total Iteration Time: 2.73902

Cumulative Model Updates: 2,780
Cumulative Timesteps: 46,414,464

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 46414464...
Checkpoint 46414464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00277
Policy Entropy: 4.22584
Value Function Loss: 0.10545

Mean KL Divergence: 0.00087
SB3 Clip Fraction: 0.00453
Policy Update Magnitude: 0.08921
Value Function Update Magnitude: 0.05870

Collected Steps per Second: 26,063.27561
Overall Steps per Second: 18,737.81452

Timestep Collection Time: 1.91918
Timestep Consumption Time: 0.75029
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 2.66947

Cumulative Model Updates: 2,783
Cumulative Timesteps: 46,464,484

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05031
Policy Entropy: 4.23545
Value Function Loss: 0.07907

Mean KL Divergence: 0.00103
SB3 Clip Fraction: 0.01443
Policy Update Magnitude: 0.08762
Value Function Update Magnitude: 0.06313

Collected Steps per Second: 22,375.91256
Overall Steps per Second: 16,750.58982

Timestep Collection Time: 2.23571
Timestep Consumption Time: 0.75081
PPO Batch Consumption Time: 0.07222
Total Iteration Time: 2.98652

Cumulative Model Updates: 2,786
Cumulative Timesteps: 46,514,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 46514510...
Checkpoint 46514510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01541
Policy Entropy: 4.23868
Value Function Loss: 0.06220

Mean KL Divergence: 0.00060
SB3 Clip Fraction: 0.00192
Policy Update Magnitude: 0.08438
Value Function Update Magnitude: 0.06509

Collected Steps per Second: 26,008.66772
Overall Steps per Second: 17,998.39926

Timestep Collection Time: 1.92344
Timestep Consumption Time: 0.85603
PPO Batch Consumption Time: 0.08269
Total Iteration Time: 2.77947

Cumulative Model Updates: 2,789
Cumulative Timesteps: 46,564,536

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00432
Policy Entropy: 4.23228
Value Function Loss: 0.05631

Mean KL Divergence: 0.00067
SB3 Clip Fraction: 0.00379
Policy Update Magnitude: 0.07680
Value Function Update Magnitude: 0.05610

Collected Steps per Second: 25,475.24718
Overall Steps per Second: 18,718.18310

Timestep Collection Time: 1.96379
Timestep Consumption Time: 0.70891
PPO Batch Consumption Time: 0.05976
Total Iteration Time: 2.67270

Cumulative Model Updates: 2,792
Cumulative Timesteps: 46,614,564

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 46614564...
Checkpoint 46614564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04834
Policy Entropy: 4.21870
Value Function Loss: 0.07391

Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.01215
Policy Update Magnitude: 0.07334
Value Function Update Magnitude: 0.05356

Collected Steps per Second: 22,819.25656
Overall Steps per Second: 16,143.96242

Timestep Collection Time: 2.19218
Timestep Consumption Time: 0.90644
PPO Batch Consumption Time: 0.09669
Total Iteration Time: 3.09862

Cumulative Model Updates: 2,795
Cumulative Timesteps: 46,664,588

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02934
Policy Entropy: 4.22802
Value Function Loss: 0.07593

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00153
Policy Update Magnitude: 0.08125
Value Function Update Magnitude: 0.04882

Collected Steps per Second: 25,712.75585
Overall Steps per Second: 17,863.95996

Timestep Collection Time: 1.94472
Timestep Consumption Time: 0.85444
PPO Batch Consumption Time: 0.08524
Total Iteration Time: 2.79916

Cumulative Model Updates: 2,798
Cumulative Timesteps: 46,714,592

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 46714592...
Checkpoint 46714592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03515
Policy Entropy: 4.25749
Value Function Loss: 0.07401

Mean KL Divergence: 0.00105
SB3 Clip Fraction: 0.00589
Policy Update Magnitude: 0.07902
Value Function Update Magnitude: 0.04555

Collected Steps per Second: 25,904.58389
Overall Steps per Second: 19,088.58275

Timestep Collection Time: 1.93109
Timestep Consumption Time: 0.68954
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 2.62062

Cumulative Model Updates: 2,801
Cumulative Timesteps: 46,764,616

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01155
Policy Entropy: 4.25223
Value Function Loss: 0.06705

Mean KL Divergence: 0.00091
SB3 Clip Fraction: 0.00415
Policy Update Magnitude: 0.08283
Value Function Update Magnitude: 0.04603

Collected Steps per Second: 22,245.62691
Overall Steps per Second: 15,861.79848

Timestep Collection Time: 2.24817
Timestep Consumption Time: 0.90481
PPO Batch Consumption Time: 0.09634
Total Iteration Time: 3.15298

Cumulative Model Updates: 2,804
Cumulative Timesteps: 46,814,628

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 46814628...
Checkpoint 46814628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02570
Policy Entropy: 4.23065
Value Function Loss: 0.06452

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.02039
Policy Update Magnitude: 0.07565
Value Function Update Magnitude: 0.04989

Collected Steps per Second: 25,559.22167
Overall Steps per Second: 18,720.80885

Timestep Collection Time: 1.95702
Timestep Consumption Time: 0.71487
PPO Batch Consumption Time: 0.05850
Total Iteration Time: 2.67189

Cumulative Model Updates: 2,807
Cumulative Timesteps: 46,864,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02834
Policy Entropy: 4.24460
Value Function Loss: 0.06493

Mean KL Divergence: 0.00106
SB3 Clip Fraction: 0.00609
Policy Update Magnitude: 0.07637
Value Function Update Magnitude: 0.04587

Collected Steps per Second: 23,253.54260
Overall Steps per Second: 16,195.48024

Timestep Collection Time: 2.15116
Timestep Consumption Time: 0.93748
PPO Batch Consumption Time: 0.10743
Total Iteration Time: 3.08864

Cumulative Model Updates: 2,810
Cumulative Timesteps: 46,914,670

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 46914670...
Checkpoint 46914670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11604
Policy Entropy: 4.25368
Value Function Loss: 0.06513

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01415
Policy Update Magnitude: 0.07241
Value Function Update Magnitude: 0.04871

Collected Steps per Second: 25,433.96674
Overall Steps per Second: 17,857.83981

Timestep Collection Time: 1.96627
Timestep Consumption Time: 0.83418
PPO Batch Consumption Time: 0.08627
Total Iteration Time: 2.80045

Cumulative Model Updates: 2,813
Cumulative Timesteps: 46,964,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00755
Policy Entropy: 4.23617
Value Function Loss: 0.07507

Mean KL Divergence: 0.00073
SB3 Clip Fraction: 0.00277
Policy Update Magnitude: 0.07838
Value Function Update Magnitude: 0.04897

Collected Steps per Second: 25,633.18440
Overall Steps per Second: 18,850.50015

Timestep Collection Time: 1.95122
Timestep Consumption Time: 0.70208
PPO Batch Consumption Time: 0.05811
Total Iteration Time: 2.65330

Cumulative Model Updates: 2,816
Cumulative Timesteps: 47,014,696

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 47014696...
Checkpoint 47014696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05045
Policy Entropy: 4.20983
Value Function Loss: 0.07029

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.01509
Policy Update Magnitude: 0.08007
Value Function Update Magnitude: 0.04638

Collected Steps per Second: 22,708.59675
Overall Steps per Second: 15,876.71270

Timestep Collection Time: 2.20251
Timestep Consumption Time: 0.94776
PPO Batch Consumption Time: 0.10623
Total Iteration Time: 3.15027

Cumulative Model Updates: 2,819
Cumulative Timesteps: 47,064,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05695
Policy Entropy: 4.21227
Value Function Loss: 0.06464

Mean KL Divergence: 0.00081
SB3 Clip Fraction: 0.00297
Policy Update Magnitude: 0.07860
Value Function Update Magnitude: 0.04644

Collected Steps per Second: 25,606.34976
Overall Steps per Second: 18,712.59165

Timestep Collection Time: 1.95303
Timestep Consumption Time: 0.71950
PPO Batch Consumption Time: 0.05843
Total Iteration Time: 2.67253

Cumulative Model Updates: 2,822
Cumulative Timesteps: 47,114,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 47114722...
Checkpoint 47114722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00221
Policy Entropy: 4.22909
Value Function Loss: 0.05305

Mean KL Divergence: 0.00088
SB3 Clip Fraction: 0.00423
Policy Update Magnitude: 0.07228
Value Function Update Magnitude: 0.04770

Collected Steps per Second: 24,149.93060
Overall Steps per Second: 16,403.24046

Timestep Collection Time: 2.07131
Timestep Consumption Time: 0.97821
PPO Batch Consumption Time: 0.12368
Total Iteration Time: 3.04952

Cumulative Model Updates: 2,825
Cumulative Timesteps: 47,164,744

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10083
Policy Entropy: 4.22220
Value Function Loss: 0.04910

Mean KL Divergence: 0.00068
SB3 Clip Fraction: 0.00436
Policy Update Magnitude: 0.06840
Value Function Update Magnitude: 0.04582

Collected Steps per Second: 25,789.25108
Overall Steps per Second: 17,760.07098

Timestep Collection Time: 1.93902
Timestep Consumption Time: 0.87662
PPO Batch Consumption Time: 0.09555
Total Iteration Time: 2.81564

Cumulative Model Updates: 2,828
Cumulative Timesteps: 47,214,750

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 47214750...
Checkpoint 47214750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04571
Policy Entropy: 4.19978
Value Function Loss: 0.06176

Mean KL Divergence: 0.00108
SB3 Clip Fraction: 0.00673
Policy Update Magnitude: 0.07166
Value Function Update Magnitude: 0.04700

Collected Steps per Second: 25,843.15836
Overall Steps per Second: 18,729.30322

Timestep Collection Time: 1.93506
Timestep Consumption Time: 0.73498
PPO Batch Consumption Time: 0.05853
Total Iteration Time: 2.67004

Cumulative Model Updates: 2,831
Cumulative Timesteps: 47,264,758

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04060
Policy Entropy: 4.17676
Value Function Loss: 0.07466

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.03134
Policy Update Magnitude: 0.07153
Value Function Update Magnitude: 0.04378

Collected Steps per Second: 23,401.61627
Overall Steps per Second: 16,169.05971

Timestep Collection Time: 2.13746
Timestep Consumption Time: 0.95610
PPO Batch Consumption Time: 0.10971
Total Iteration Time: 3.09356

Cumulative Model Updates: 2,834
Cumulative Timesteps: 47,314,778

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 47314778...
Checkpoint 47314778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.22180
Policy Entropy: 4.18761
Value Function Loss: 0.08493

Mean KL Divergence: 0.00128
SB3 Clip Fraction: 0.00885
Policy Update Magnitude: 0.07728
Value Function Update Magnitude: 0.04953

Collected Steps per Second: 25,825.35266
Overall Steps per Second: 18,835.83610

Timestep Collection Time: 1.93647
Timestep Consumption Time: 0.71858
PPO Batch Consumption Time: 0.05869
Total Iteration Time: 2.65505

Cumulative Model Updates: 2,837
Cumulative Timesteps: 47,364,788

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00168
Policy Entropy: 4.18092
Value Function Loss: 0.08414

Mean KL Divergence: 0.00112
SB3 Clip Fraction: 0.01203
Policy Update Magnitude: 0.08272
Value Function Update Magnitude: 0.05203

Collected Steps per Second: 22,860.02029
Overall Steps per Second: 16,007.87122

Timestep Collection Time: 2.18766
Timestep Consumption Time: 0.93643
PPO Batch Consumption Time: 0.10750
Total Iteration Time: 3.12409

Cumulative Model Updates: 2,840
Cumulative Timesteps: 47,414,798

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 47414798...
Checkpoint 47414798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06925
Policy Entropy: 4.15861
Value Function Loss: 0.08180

Mean KL Divergence: 0.00107
SB3 Clip Fraction: 0.00623
Policy Update Magnitude: 0.08857
Value Function Update Magnitude: 0.05317

Collected Steps per Second: 25,453.98125
Overall Steps per Second: 17,857.20408

Timestep Collection Time: 1.96449
Timestep Consumption Time: 0.83573
PPO Batch Consumption Time: 0.08221
Total Iteration Time: 2.80021

Cumulative Model Updates: 2,843
Cumulative Timesteps: 47,464,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01338
Policy Entropy: 4.16355
Value Function Loss: 0.08901

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01350
Policy Update Magnitude: 0.08618
Value Function Update Magnitude: 0.05748

Collected Steps per Second: 25,330.17430
Overall Steps per Second: 18,578.42783

Timestep Collection Time: 1.97440
Timestep Consumption Time: 0.71754
PPO Batch Consumption Time: 0.05946
Total Iteration Time: 2.69194

Cumulative Model Updates: 2,846
Cumulative Timesteps: 47,514,814

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 47514814...
Checkpoint 47514814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05648
Policy Entropy: 4.18787
Value Function Loss: 0.07909

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01243
Policy Update Magnitude: 0.08284
Value Function Update Magnitude: 0.06088

Collected Steps per Second: 23,396.20379
Overall Steps per Second: 16,282.47553

Timestep Collection Time: 2.13838
Timestep Consumption Time: 0.93425
PPO Batch Consumption Time: 0.10323
Total Iteration Time: 3.07263

Cumulative Model Updates: 2,849
Cumulative Timesteps: 47,564,844

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03049
Policy Entropy: 4.18614
Value Function Loss: 0.09308

Mean KL Divergence: 0.00121
SB3 Clip Fraction: 0.01070
Policy Update Magnitude: 0.08462
Value Function Update Magnitude: 0.06030

Collected Steps per Second: 25,878.26001
Overall Steps per Second: 19,091.88351

Timestep Collection Time: 1.93274
Timestep Consumption Time: 0.68701
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 2.61975

Cumulative Model Updates: 2,852
Cumulative Timesteps: 47,614,860

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 47614860...
Checkpoint 47614860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03048
Policy Entropy: 4.18908
Value Function Loss: 0.09772

Mean KL Divergence: 0.00074
SB3 Clip Fraction: 0.00334
Policy Update Magnitude: 0.08547
Value Function Update Magnitude: 0.05867

Collected Steps per Second: 22,346.70526
Overall Steps per Second: 15,846.51457

Timestep Collection Time: 2.23765
Timestep Consumption Time: 0.91788
PPO Batch Consumption Time: 0.10504
Total Iteration Time: 3.15552

Cumulative Model Updates: 2,855
Cumulative Timesteps: 47,664,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04926
Policy Entropy: 4.20324
Value Function Loss: 0.10352

Mean KL Divergence: 0.00104
SB3 Clip Fraction: 0.00693
Policy Update Magnitude: 0.09130
Value Function Update Magnitude: 0.05908

Collected Steps per Second: 25,948.54958
Overall Steps per Second: 17,853.13403

Timestep Collection Time: 1.92712
Timestep Consumption Time: 0.87384
PPO Batch Consumption Time: 0.08588
Total Iteration Time: 2.80096

Cumulative Model Updates: 2,858
Cumulative Timesteps: 47,714,870

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 47714870...
Checkpoint 47714870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06557
Policy Entropy: 4.21598
Value Function Loss: 0.09184

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.02210
Policy Update Magnitude: 0.08508
Value Function Update Magnitude: 0.05376

Collected Steps per Second: 25,535.12243
Overall Steps per Second: 18,691.99389

Timestep Collection Time: 1.95895
Timestep Consumption Time: 0.71717
PPO Batch Consumption Time: 0.05825
Total Iteration Time: 2.67612

Cumulative Model Updates: 2,861
Cumulative Timesteps: 47,764,892

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06779
Policy Entropy: 4.18714
Value Function Loss: 0.07686

Mean KL Divergence: 0.00107
SB3 Clip Fraction: 0.00541
Policy Update Magnitude: 0.08458
Value Function Update Magnitude: 0.04501

Collected Steps per Second: 22,973.20574
Overall Steps per Second: 16,157.73589

Timestep Collection Time: 2.17714
Timestep Consumption Time: 0.91834
PPO Batch Consumption Time: 0.09962
Total Iteration Time: 3.09548

Cumulative Model Updates: 2,864
Cumulative Timesteps: 47,814,908

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 47814908...
Checkpoint 47814908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04252
Policy Entropy: 4.17844
Value Function Loss: 0.08335

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01494
Policy Update Magnitude: 0.08126
Value Function Update Magnitude: 0.04129

Collected Steps per Second: 25,463.05715
Overall Steps per Second: 18,331.40041

Timestep Collection Time: 1.96363
Timestep Consumption Time: 0.76393
PPO Batch Consumption Time: 0.06036
Total Iteration Time: 2.72756

Cumulative Model Updates: 2,867
Cumulative Timesteps: 47,864,908

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05378
Policy Entropy: 4.19656
Value Function Loss: 0.06798

Mean KL Divergence: 0.00070
SB3 Clip Fraction: 0.00177
Policy Update Magnitude: 0.08206
Value Function Update Magnitude: 0.04634

Collected Steps per Second: 26,814.83656
Overall Steps per Second: 17,680.90829

Timestep Collection Time: 1.86501
Timestep Consumption Time: 0.96346
PPO Batch Consumption Time: 0.12102
Total Iteration Time: 2.82847

Cumulative Model Updates: 2,870
Cumulative Timesteps: 47,914,918

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 47914918...
Checkpoint 47914918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01944
Policy Entropy: 4.19500
Value Function Loss: 0.06336

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00175
Policy Update Magnitude: 0.08586
Value Function Update Magnitude: 0.05666

Collected Steps per Second: 26,075.81774
Overall Steps per Second: 18,508.75509

Timestep Collection Time: 1.91848
Timestep Consumption Time: 0.78435
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 2.70283

Cumulative Model Updates: 2,873
Cumulative Timesteps: 47,964,944

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06837
Policy Entropy: 4.16950
Value Function Loss: 0.04298

Mean KL Divergence: 0.00109
SB3 Clip Fraction: 0.00603
Policy Update Magnitude: 0.08009
Value Function Update Magnitude: 0.05776

Collected Steps per Second: 22,917.27834
Overall Steps per Second: 16,238.67112

Timestep Collection Time: 2.18220
Timestep Consumption Time: 0.89749
PPO Batch Consumption Time: 0.11455
Total Iteration Time: 3.07969

Cumulative Model Updates: 2,876
Cumulative Timesteps: 48,014,954

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 48014954...
Checkpoint 48014954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02319
Policy Entropy: 4.16268
Value Function Loss: 0.05939

Mean KL Divergence: 0.00101
SB3 Clip Fraction: 0.00593
Policy Update Magnitude: 0.06992
Value Function Update Magnitude: 0.04803

Collected Steps per Second: 25,998.50549
Overall Steps per Second: 18,429.13575

Timestep Collection Time: 1.92411
Timestep Consumption Time: 0.79029
PPO Batch Consumption Time: 0.05982
Total Iteration Time: 2.71440

Cumulative Model Updates: 2,879
Cumulative Timesteps: 48,064,978

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04882
Policy Entropy: 4.15695
Value Function Loss: 0.07023

Mean KL Divergence: 0.00080
SB3 Clip Fraction: 0.00276
Policy Update Magnitude: 0.07450
Value Function Update Magnitude: 0.05008

Collected Steps per Second: 22,949.05971
Overall Steps per Second: 16,238.68885

Timestep Collection Time: 2.17926
Timestep Consumption Time: 0.90054
PPO Batch Consumption Time: 0.09707
Total Iteration Time: 3.07981

Cumulative Model Updates: 2,882
Cumulative Timesteps: 48,114,990

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 48114990...
Checkpoint 48114990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00186
Policy Entropy: 4.13935
Value Function Loss: 0.07963

Mean KL Divergence: 0.00143
SB3 Clip Fraction: 0.01518
Policy Update Magnitude: 0.08090
Value Function Update Magnitude: 0.05866

Collected Steps per Second: 26,413.74719
Overall Steps per Second: 17,973.28543

Timestep Collection Time: 1.89303
Timestep Consumption Time: 0.88899
PPO Batch Consumption Time: 0.09680
Total Iteration Time: 2.78202

Cumulative Model Updates: 2,885
Cumulative Timesteps: 48,164,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16443
Policy Entropy: 4.16240
Value Function Loss: 0.07596

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01114
Policy Update Magnitude: 0.08629
Value Function Update Magnitude: 0.06554

Collected Steps per Second: 26,022.25376
Overall Steps per Second: 18,650.84303

Timestep Collection Time: 1.92151
Timestep Consumption Time: 0.75944
PPO Batch Consumption Time: 0.05871
Total Iteration Time: 2.68095

Cumulative Model Updates: 2,888
Cumulative Timesteps: 48,214,994

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 48214994...
Checkpoint 48214994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00389
Policy Entropy: 4.16912
Value Function Loss: 0.07369

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02631
Policy Update Magnitude: 0.08539
Value Function Update Magnitude: 0.06224

Collected Steps per Second: 22,718.71671
Overall Steps per Second: 16,249.37887

Timestep Collection Time: 2.20127
Timestep Consumption Time: 0.87639
PPO Batch Consumption Time: 0.11685
Total Iteration Time: 3.07766

Cumulative Model Updates: 2,891
Cumulative Timesteps: 48,265,004

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00789
Policy Entropy: 4.14885
Value Function Loss: 0.09435

Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.01422
Policy Update Magnitude: 0.08041
Value Function Update Magnitude: 0.05901

Collected Steps per Second: 25,752.70525
Overall Steps per Second: 18,316.70486

Timestep Collection Time: 1.94255
Timestep Consumption Time: 0.78861
PPO Batch Consumption Time: 0.06089
Total Iteration Time: 2.73117

Cumulative Model Updates: 2,894
Cumulative Timesteps: 48,315,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 48315030...
Checkpoint 48315030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02523
Policy Entropy: 4.15502
Value Function Loss: 0.10497

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01471
Policy Update Magnitude: 0.08316
Value Function Update Magnitude: 0.05372

Collected Steps per Second: 25,720.03390
Overall Steps per Second: 17,572.23129

Timestep Collection Time: 1.94417
Timestep Consumption Time: 0.90146
PPO Batch Consumption Time: 0.11373
Total Iteration Time: 2.84563

Cumulative Model Updates: 2,897
Cumulative Timesteps: 48,365,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01910
Policy Entropy: 4.17743
Value Function Loss: 0.10855

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01541
Policy Update Magnitude: 0.09342
Value Function Update Magnitude: 0.04845

Collected Steps per Second: 26,810.70479
Overall Steps per Second: 18,845.81195

Timestep Collection Time: 1.86567
Timestep Consumption Time: 0.78850
PPO Batch Consumption Time: 0.05848
Total Iteration Time: 2.65417

Cumulative Model Updates: 2,900
Cumulative Timesteps: 48,415,054

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 48415054...
Checkpoint 48415054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06222
Policy Entropy: 4.12118
Value Function Loss: 0.08889

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03366
Policy Update Magnitude: 0.08650
Value Function Update Magnitude: 0.05525

Collected Steps per Second: 22,907.01395
Overall Steps per Second: 15,951.08682

Timestep Collection Time: 2.18300
Timestep Consumption Time: 0.95196
PPO Batch Consumption Time: 0.11055
Total Iteration Time: 3.13496

Cumulative Model Updates: 2,903
Cumulative Timesteps: 48,465,060

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04794
Policy Entropy: 4.16138
Value Function Loss: 0.08128

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02421
Policy Update Magnitude: 0.08976
Value Function Update Magnitude: 0.05820

Collected Steps per Second: 25,617.46209
Overall Steps per Second: 18,400.01690

Timestep Collection Time: 1.95195
Timestep Consumption Time: 0.76566
PPO Batch Consumption Time: 0.06107
Total Iteration Time: 2.71761

Cumulative Model Updates: 2,906
Cumulative Timesteps: 48,515,064

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 48515064...
Checkpoint 48515064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14392
Policy Entropy: 4.16435
Value Function Loss: 0.11316

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.03087
Policy Update Magnitude: 0.08804
Value Function Update Magnitude: 0.06187

Collected Steps per Second: 26,616.36116
Overall Steps per Second: 17,625.11807

Timestep Collection Time: 1.87892
Timestep Consumption Time: 0.95851
PPO Batch Consumption Time: 0.11962
Total Iteration Time: 2.83743

Cumulative Model Updates: 2,909
Cumulative Timesteps: 48,565,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01755
Policy Entropy: 4.13416
Value Function Loss: 0.11188

Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.01513
Policy Update Magnitude: 0.08830
Value Function Update Magnitude: 0.06870

Collected Steps per Second: 25,961.67549
Overall Steps per Second: 18,723.58481

Timestep Collection Time: 1.92684
Timestep Consumption Time: 0.74487
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 2.67171

Cumulative Model Updates: 2,912
Cumulative Timesteps: 48,615,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 48615098...
Checkpoint 48615098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12303
Policy Entropy: 4.16188
Value Function Loss: 0.10635

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01659
Policy Update Magnitude: 0.08887
Value Function Update Magnitude: 0.07202

Collected Steps per Second: 22,656.29859
Overall Steps per Second: 16,107.20031

Timestep Collection Time: 2.20769
Timestep Consumption Time: 0.89763
PPO Batch Consumption Time: 0.12161
Total Iteration Time: 3.10532

Cumulative Model Updates: 2,915
Cumulative Timesteps: 48,665,116

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02038
Policy Entropy: 4.15191
Value Function Loss: 0.06198

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02739
Policy Update Magnitude: 0.08427
Value Function Update Magnitude: 0.06494

Collected Steps per Second: 25,868.08528
Overall Steps per Second: 18,284.45485

Timestep Collection Time: 1.93397
Timestep Consumption Time: 0.80213
PPO Batch Consumption Time: 0.06235
Total Iteration Time: 2.73609

Cumulative Model Updates: 2,918
Cumulative Timesteps: 48,715,144

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 48715144...
Checkpoint 48715144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02592
Policy Entropy: 4.12882
Value Function Loss: 0.05137

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02597
Policy Update Magnitude: 0.07388
Value Function Update Magnitude: 0.06124

Collected Steps per Second: 25,541.42342
Overall Steps per Second: 17,606.09250

Timestep Collection Time: 1.95784
Timestep Consumption Time: 0.88243
PPO Batch Consumption Time: 0.10119
Total Iteration Time: 2.84027

Cumulative Model Updates: 2,921
Cumulative Timesteps: 48,765,150

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00723
Policy Entropy: 4.16341
Value Function Loss: 0.05311

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.00975
Policy Update Magnitude: 0.07263
Value Function Update Magnitude: 0.05312

Collected Steps per Second: 26,318.13261
Overall Steps per Second: 18,713.06693

Timestep Collection Time: 1.90029
Timestep Consumption Time: 0.77228
PPO Batch Consumption Time: 0.05926
Total Iteration Time: 2.67257

Cumulative Model Updates: 2,924
Cumulative Timesteps: 48,815,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 48815162...
Checkpoint 48815162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01508
Policy Entropy: 4.17948
Value Function Loss: 0.06824

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02666
Policy Update Magnitude: 0.06891
Value Function Update Magnitude: 0.05096

Collected Steps per Second: 22,416.80262
Overall Steps per Second: 16,003.43585

Timestep Collection Time: 2.23074
Timestep Consumption Time: 0.89397
PPO Batch Consumption Time: 0.07823
Total Iteration Time: 3.12470

Cumulative Model Updates: 2,927
Cumulative Timesteps: 48,865,168

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05178
Policy Entropy: 4.14856
Value Function Loss: 0.08625

Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.01337
Policy Update Magnitude: 0.07273
Value Function Update Magnitude: 0.05799

Collected Steps per Second: 25,791.14792
Overall Steps per Second: 18,976.92938

Timestep Collection Time: 1.93873
Timestep Consumption Time: 0.69616
PPO Batch Consumption Time: 0.05780
Total Iteration Time: 2.63488

Cumulative Model Updates: 2,930
Cumulative Timesteps: 48,915,170

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 48915170...
Checkpoint 48915170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05498
Policy Entropy: 4.14362
Value Function Loss: 0.10116

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.01404
Policy Update Magnitude: 0.08121
Value Function Update Magnitude: 0.05507

Collected Steps per Second: 22,489.73947
Overall Steps per Second: 15,973.90046

Timestep Collection Time: 2.22332
Timestep Consumption Time: 0.90691
PPO Batch Consumption Time: 0.10222
Total Iteration Time: 3.13023

Cumulative Model Updates: 2,933
Cumulative Timesteps: 48,965,172

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08182
Policy Entropy: 4.16673
Value Function Loss: 0.10735

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02641
Policy Update Magnitude: 0.07755
Value Function Update Magnitude: 0.06456

Collected Steps per Second: 25,580.56957
Overall Steps per Second: 17,870.86847

Timestep Collection Time: 1.95586
Timestep Consumption Time: 0.84378
PPO Batch Consumption Time: 0.08462
Total Iteration Time: 2.79964

Cumulative Model Updates: 2,936
Cumulative Timesteps: 49,015,204

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 49015204...
Checkpoint 49015204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00081
Policy Entropy: 4.14540
Value Function Loss: 0.10087

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.00996
Policy Update Magnitude: 0.08150
Value Function Update Magnitude: 0.05999

Collected Steps per Second: 26,812.76462
Overall Steps per Second: 18,722.41159

Timestep Collection Time: 1.86531
Timestep Consumption Time: 0.80604
PPO Batch Consumption Time: 0.05947
Total Iteration Time: 2.67134

Cumulative Model Updates: 2,939
Cumulative Timesteps: 49,065,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04428
Policy Entropy: 4.13792
Value Function Loss: 0.09621

Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.01498
Policy Update Magnitude: 0.08510
Value Function Update Magnitude: 0.06146

Collected Steps per Second: 22,960.63922
Overall Steps per Second: 16,126.38225

Timestep Collection Time: 2.17886
Timestep Consumption Time: 0.92339
PPO Batch Consumption Time: 0.09875
Total Iteration Time: 3.10225

Cumulative Model Updates: 2,942
Cumulative Timesteps: 49,115,246

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 49115246...
Checkpoint 49115246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04111
Policy Entropy: 4.14828
Value Function Loss: 0.11959

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.00657
Policy Update Magnitude: 0.08292
Value Function Update Magnitude: 0.07171

Collected Steps per Second: 25,648.46059
Overall Steps per Second: 18,445.74634

Timestep Collection Time: 1.94990
Timestep Consumption Time: 0.76140
PPO Batch Consumption Time: 0.06046
Total Iteration Time: 2.71130

Cumulative Model Updates: 2,945
Cumulative Timesteps: 49,165,258

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05908
Policy Entropy: 4.13944
Value Function Loss: 0.11636

Mean KL Divergence: 0.00099
SB3 Clip Fraction: 0.00736
Policy Update Magnitude: 0.08694
Value Function Update Magnitude: 0.06892

Collected Steps per Second: 26,730.52155
Overall Steps per Second: 17,584.60142

Timestep Collection Time: 1.87149
Timestep Consumption Time: 0.97338
PPO Batch Consumption Time: 0.12297
Total Iteration Time: 2.84488

Cumulative Model Updates: 2,948
Cumulative Timesteps: 49,215,284

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 49215284...
Checkpoint 49215284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12722
Policy Entropy: 4.10509
Value Function Loss: 0.10451

Mean KL Divergence: 0.00151
SB3 Clip Fraction: 0.01319
Policy Update Magnitude: 0.08600
Value Function Update Magnitude: 0.06461

Collected Steps per Second: 26,112.39977
Overall Steps per Second: 18,675.07087

Timestep Collection Time: 1.91495
Timestep Consumption Time: 0.76263
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 2.67758

Cumulative Model Updates: 2,951
Cumulative Timesteps: 49,265,288

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00639
Policy Entropy: 4.13064
Value Function Loss: 0.06572

Mean KL Divergence: 0.00098
SB3 Clip Fraction: 0.00411
Policy Update Magnitude: 0.08681
Value Function Update Magnitude: 0.05495

Collected Steps per Second: 22,512.94033
Overall Steps per Second: 16,118.69809

Timestep Collection Time: 2.22094
Timestep Consumption Time: 0.88104
PPO Batch Consumption Time: 0.11267
Total Iteration Time: 3.10199

Cumulative Model Updates: 2,954
Cumulative Timesteps: 49,315,288

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 49315288...
Checkpoint 49315288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01107
Policy Entropy: 4.15820
Value Function Loss: 0.06737

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02552
Policy Update Magnitude: 0.07467
Value Function Update Magnitude: 0.05180

Collected Steps per Second: 25,697.21417
Overall Steps per Second: 18,377.81571

Timestep Collection Time: 1.94651
Timestep Consumption Time: 0.77525
PPO Batch Consumption Time: 0.06116
Total Iteration Time: 2.72176

Cumulative Model Updates: 2,957
Cumulative Timesteps: 49,365,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07645
Policy Entropy: 4.13493
Value Function Loss: 0.07709

Mean KL Divergence: 0.00109
SB3 Clip Fraction: 0.00668
Policy Update Magnitude: 0.07196
Value Function Update Magnitude: 0.04678

Collected Steps per Second: 25,810.03033
Overall Steps per Second: 17,503.81279

Timestep Collection Time: 1.93762
Timestep Consumption Time: 0.91947
PPO Batch Consumption Time: 0.10833
Total Iteration Time: 2.85709

Cumulative Model Updates: 2,960
Cumulative Timesteps: 49,415,318

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 49415318...
Checkpoint 49415318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18129
Policy Entropy: 4.12586
Value Function Loss: 0.07772

Mean KL Divergence: 0.00102
SB3 Clip Fraction: 0.00597
Policy Update Magnitude: 0.07167
Value Function Update Magnitude: 0.04758

Collected Steps per Second: 26,647.67789
Overall Steps per Second: 18,787.82671

Timestep Collection Time: 1.87634
Timestep Consumption Time: 0.78496
PPO Batch Consumption Time: 0.05933
Total Iteration Time: 2.66130

Cumulative Model Updates: 2,963
Cumulative Timesteps: 49,465,318

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04859
Policy Entropy: 4.14791
Value Function Loss: 0.07099

Mean KL Divergence: 0.00072
SB3 Clip Fraction: 0.00291
Policy Update Magnitude: 0.07497
Value Function Update Magnitude: 0.05161

Collected Steps per Second: 23,315.71115
Overall Steps per Second: 16,061.81671

Timestep Collection Time: 2.14542
Timestep Consumption Time: 0.96892
PPO Batch Consumption Time: 0.11684
Total Iteration Time: 3.11434

Cumulative Model Updates: 2,966
Cumulative Timesteps: 49,515,340

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 49515340...
Checkpoint 49515340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06996
Policy Entropy: 4.16767
Value Function Loss: 0.05752

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01149
Policy Update Magnitude: 0.07431
Value Function Update Magnitude: 0.04742

Collected Steps per Second: 25,916.05539
Overall Steps per Second: 18,870.85106

Timestep Collection Time: 1.92946
Timestep Consumption Time: 0.72034
PPO Batch Consumption Time: 0.05836
Total Iteration Time: 2.64980

Cumulative Model Updates: 2,969
Cumulative Timesteps: 49,565,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01487
Policy Entropy: 4.15279
Value Function Loss: 0.08448

Mean KL Divergence: 0.00077
SB3 Clip Fraction: 0.00353
Policy Update Magnitude: 0.07307
Value Function Update Magnitude: 0.04583

Collected Steps per Second: 22,429.68653
Overall Steps per Second: 15,900.11262

Timestep Collection Time: 2.22928
Timestep Consumption Time: 0.91548
PPO Batch Consumption Time: 0.09658
Total Iteration Time: 3.14476

Cumulative Model Updates: 2,972
Cumulative Timesteps: 49,615,346

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 49615346...
Checkpoint 49615346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04680
Policy Entropy: 4.15985
Value Function Loss: 0.10600

Mean KL Divergence: 0.00089
SB3 Clip Fraction: 0.00709
Policy Update Magnitude: 0.07612
Value Function Update Magnitude: 0.04591

Collected Steps per Second: 25,414.14352
Overall Steps per Second: 17,914.70948

Timestep Collection Time: 1.96788
Timestep Consumption Time: 0.82379
PPO Batch Consumption Time: 0.07452
Total Iteration Time: 2.79167

Cumulative Model Updates: 2,975
Cumulative Timesteps: 49,665,358

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07144
Policy Entropy: 4.17115
Value Function Loss: 0.10723

Mean KL Divergence: 0.00068
SB3 Clip Fraction: 0.00276
Policy Update Magnitude: 0.08465
Value Function Update Magnitude: 0.05072

Collected Steps per Second: 26,369.41401
Overall Steps per Second: 18,609.49347

Timestep Collection Time: 1.89667
Timestep Consumption Time: 0.79089
PPO Batch Consumption Time: 0.05976
Total Iteration Time: 2.68755

Cumulative Model Updates: 2,978
Cumulative Timesteps: 49,715,372

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 49715372...
Checkpoint 49715372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04091
Policy Entropy: 4.15526
Value Function Loss: 0.09613

Mean KL Divergence: 0.00084
SB3 Clip Fraction: 0.00467
Policy Update Magnitude: 0.08923
Value Function Update Magnitude: 0.05383

Collected Steps per Second: 23,664.58659
Overall Steps per Second: 16,323.78854

Timestep Collection Time: 2.11312
Timestep Consumption Time: 0.95027
PPO Batch Consumption Time: 0.10726
Total Iteration Time: 3.06338

Cumulative Model Updates: 2,981
Cumulative Timesteps: 49,765,378

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10523
Policy Entropy: 4.12878
Value Function Loss: 0.09356

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.02389
Policy Update Magnitude: 0.08186
Value Function Update Magnitude: 0.05608

Collected Steps per Second: 25,627.36986
Overall Steps per Second: 18,746.88581

Timestep Collection Time: 1.95127
Timestep Consumption Time: 0.71616
PPO Batch Consumption Time: 0.05880
Total Iteration Time: 2.66743

Cumulative Model Updates: 2,984
Cumulative Timesteps: 49,815,384

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 49815384...
Checkpoint 49815384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03712
Policy Entropy: 4.15268
Value Function Loss: 0.11394

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.00835
Policy Update Magnitude: 0.08154
Value Function Update Magnitude: 0.05917

Collected Steps per Second: 22,660.00987
Overall Steps per Second: 16,014.00077

Timestep Collection Time: 2.20715
Timestep Consumption Time: 0.91599
PPO Batch Consumption Time: 0.09719
Total Iteration Time: 3.12314

Cumulative Model Updates: 2,987
Cumulative Timesteps: 49,865,398

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04660
Policy Entropy: 4.14375
Value Function Loss: 0.10980

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.00926
Policy Update Magnitude: 0.09061
Value Function Update Magnitude: 0.05771

Collected Steps per Second: 25,486.48113
Overall Steps per Second: 17,860.42224

Timestep Collection Time: 1.96292
Timestep Consumption Time: 0.83813
PPO Batch Consumption Time: 0.07600
Total Iteration Time: 2.80105

Cumulative Model Updates: 2,990
Cumulative Timesteps: 49,915,426

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 49915426...
Checkpoint 49915426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03271
Policy Entropy: 4.13083
Value Function Loss: 0.12226

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01880
Policy Update Magnitude: 0.09242
Value Function Update Magnitude: 0.06881

Collected Steps per Second: 26,126.50505
Overall Steps per Second: 18,332.00392

Timestep Collection Time: 1.91415
Timestep Consumption Time: 0.81387
PPO Batch Consumption Time: 0.06095
Total Iteration Time: 2.72802

Cumulative Model Updates: 2,993
Cumulative Timesteps: 49,965,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07863
Policy Entropy: 4.16156
Value Function Loss: 0.11260

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01654
Policy Update Magnitude: 0.09704
Value Function Update Magnitude: 0.07773

Collected Steps per Second: 25,627.20735
Overall Steps per Second: 18,162.84949

Timestep Collection Time: 1.95152
Timestep Consumption Time: 0.80201
PPO Batch Consumption Time: 0.06132
Total Iteration Time: 2.75353

Cumulative Model Updates: 2,996
Cumulative Timesteps: 50,015,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 50015448...
Checkpoint 50015448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00626
Policy Entropy: 4.16739
Value Function Loss: 0.10904

Mean KL Divergence: 0.00143
SB3 Clip Fraction: 0.01493
Policy Update Magnitude: 0.10097
Value Function Update Magnitude: 0.08355

Collected Steps per Second: 25,773.21182
Overall Steps per Second: 17,556.83494

Timestep Collection Time: 1.94039
Timestep Consumption Time: 0.90808
PPO Batch Consumption Time: 0.12263
Total Iteration Time: 2.84846

Cumulative Model Updates: 2,999
Cumulative Timesteps: 50,065,458

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05444
Policy Entropy: 4.14558
Value Function Loss: 0.08595

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01383
Policy Update Magnitude: 0.09044
Value Function Update Magnitude: 0.08323

Collected Steps per Second: 26,185.86383
Overall Steps per Second: 18,490.22630

Timestep Collection Time: 1.91034
Timestep Consumption Time: 0.79509
PPO Batch Consumption Time: 0.05758
Total Iteration Time: 2.70543

Cumulative Model Updates: 3,002
Cumulative Timesteps: 50,115,482

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 50115482...
Checkpoint 50115482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06817
Policy Entropy: 4.16945
Value Function Loss: 0.06909

Mean KL Divergence: 0.00089
SB3 Clip Fraction: 0.00547
Policy Update Magnitude: 0.08814
Value Function Update Magnitude: 0.07266

Collected Steps per Second: 22,564.76302
Overall Steps per Second: 16,177.79135

Timestep Collection Time: 2.21602
Timestep Consumption Time: 0.87488
PPO Batch Consumption Time: 0.09205
Total Iteration Time: 3.09090

Cumulative Model Updates: 3,005
Cumulative Timesteps: 50,165,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00639
Policy Entropy: 4.18706
Value Function Loss: 0.06228

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01797
Policy Update Magnitude: 0.08014
Value Function Update Magnitude: 0.06467

Collected Steps per Second: 26,888.92580
Overall Steps per Second: 18,943.80827

Timestep Collection Time: 1.86017
Timestep Consumption Time: 0.78016
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 2.64033

Cumulative Model Updates: 3,008
Cumulative Timesteps: 50,215,504

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 50215504...
Checkpoint 50215504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02369
Policy Entropy: 4.16600
Value Function Loss: 0.06814

Mean KL Divergence: 0.00102
SB3 Clip Fraction: 0.00637
Policy Update Magnitude: 0.07813
Value Function Update Magnitude: 0.05984

Collected Steps per Second: 23,319.23061
Overall Steps per Second: 16,024.69753

Timestep Collection Time: 2.14535
Timestep Consumption Time: 0.97658
PPO Batch Consumption Time: 0.11371
Total Iteration Time: 3.12193

Cumulative Model Updates: 3,011
Cumulative Timesteps: 50,265,532

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15197
Policy Entropy: 4.15842
Value Function Loss: 0.09666

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.01511
Policy Update Magnitude: 0.07729
Value Function Update Magnitude: 0.06448

Collected Steps per Second: 25,444.19211
Overall Steps per Second: 17,772.80262

Timestep Collection Time: 1.96532
Timestep Consumption Time: 0.84830
PPO Batch Consumption Time: 0.08536
Total Iteration Time: 2.81362

Cumulative Model Updates: 3,014
Cumulative Timesteps: 50,315,538

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 50315538...
Checkpoint 50315538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01947
Policy Entropy: 4.17634
Value Function Loss: 0.10289

Mean KL Divergence: 0.00113
SB3 Clip Fraction: 0.00885
Policy Update Magnitude: 0.08629
Value Function Update Magnitude: 0.07012

Collected Steps per Second: 27,127.95475
Overall Steps per Second: 19,074.54358

Timestep Collection Time: 1.84312
Timestep Consumption Time: 0.77818
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 2.62129

Cumulative Model Updates: 3,017
Cumulative Timesteps: 50,365,538

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09697
Policy Entropy: 4.16579
Value Function Loss: 0.08278

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01267
Policy Update Magnitude: 0.08863
Value Function Update Magnitude: 0.07322

Collected Steps per Second: 22,934.92256
Overall Steps per Second: 15,811.51935

Timestep Collection Time: 2.18052
Timestep Consumption Time: 0.98237
PPO Batch Consumption Time: 0.12406
Total Iteration Time: 3.16288

Cumulative Model Updates: 3,020
Cumulative Timesteps: 50,415,548

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 50415548...
Checkpoint 50415548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05309
Policy Entropy: 4.15313
Value Function Loss: 0.07961

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01401
Policy Update Magnitude: 0.07572
Value Function Update Magnitude: 0.06316

Collected Steps per Second: 25,393.92750
Overall Steps per Second: 18,729.57970

Timestep Collection Time: 1.96968
Timestep Consumption Time: 0.70085
PPO Batch Consumption Time: 0.05833
Total Iteration Time: 2.67054

Cumulative Model Updates: 3,023
Cumulative Timesteps: 50,465,566

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00489
Policy Entropy: 4.16840
Value Function Loss: 0.07830

Mean KL Divergence: 0.00054
SB3 Clip Fraction: 0.00100
Policy Update Magnitude: 0.07313
Value Function Update Magnitude: 0.05949

Collected Steps per Second: 24,032.16792
Overall Steps per Second: 16,278.12060

Timestep Collection Time: 2.08163
Timestep Consumption Time: 0.99158
PPO Batch Consumption Time: 0.12105
Total Iteration Time: 3.07320

Cumulative Model Updates: 3,026
Cumulative Timesteps: 50,515,592

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 50515592...
Checkpoint 50515592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11595
Policy Entropy: 4.17851
Value Function Loss: 0.10026

Mean KL Divergence: 0.00067
SB3 Clip Fraction: 0.00469
Policy Update Magnitude: 0.07500
Value Function Update Magnitude: 0.05908

Collected Steps per Second: 25,717.09499
Overall Steps per Second: 17,849.52064

Timestep Collection Time: 1.94509
Timestep Consumption Time: 0.85734
PPO Batch Consumption Time: 0.08999
Total Iteration Time: 2.80243

Cumulative Model Updates: 3,029
Cumulative Timesteps: 50,565,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06972
Policy Entropy: 4.17884
Value Function Loss: 0.07848

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00293
Policy Update Magnitude: 0.07396
Value Function Update Magnitude: 0.06458

Collected Steps per Second: 26,801.30291
Overall Steps per Second: 18,964.47923

Timestep Collection Time: 1.86640
Timestep Consumption Time: 0.77127
PPO Batch Consumption Time: 0.05777
Total Iteration Time: 2.63767

Cumulative Model Updates: 3,032
Cumulative Timesteps: 50,615,636

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 50615636...
Checkpoint 50615636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01804
Policy Entropy: 4.18294
Value Function Loss: 0.06873

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00127
Policy Update Magnitude: 0.07358
Value Function Update Magnitude: 0.06615

Collected Steps per Second: 22,674.08249
Overall Steps per Second: 15,847.27991

Timestep Collection Time: 2.20525
Timestep Consumption Time: 0.94999
PPO Batch Consumption Time: 0.11385
Total Iteration Time: 3.15524

Cumulative Model Updates: 3,035
Cumulative Timesteps: 50,665,638

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05027
Policy Entropy: 4.19403
Value Function Loss: 0.07298

Mean KL Divergence: 0.00060
SB3 Clip Fraction: 0.00225
Policy Update Magnitude: 0.07115
Value Function Update Magnitude: 0.06796

Collected Steps per Second: 25,686.54697
Overall Steps per Second: 18,836.21698

Timestep Collection Time: 1.94662
Timestep Consumption Time: 0.70794
PPO Batch Consumption Time: 0.05778
Total Iteration Time: 2.65457

Cumulative Model Updates: 3,038
Cumulative Timesteps: 50,715,640

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 50715640...
Checkpoint 50715640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01585
Policy Entropy: 4.19410
Value Function Loss: 0.06663

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00223
Policy Update Magnitude: 0.07089
Value Function Update Magnitude: 0.06565

Collected Steps per Second: 23,127.38714
Overall Steps per Second: 16,137.90512

Timestep Collection Time: 2.16228
Timestep Consumption Time: 0.93651
PPO Batch Consumption Time: 0.10104
Total Iteration Time: 3.09879

Cumulative Model Updates: 3,041
Cumulative Timesteps: 50,765,648

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05827
Policy Entropy: 4.18887
Value Function Loss: 0.06500

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00019
Policy Update Magnitude: 0.07394
Value Function Update Magnitude: 0.06071

Collected Steps per Second: 25,997.71642
Overall Steps per Second: 17,881.26013

Timestep Collection Time: 1.92417
Timestep Consumption Time: 0.87340
PPO Batch Consumption Time: 0.09470
Total Iteration Time: 2.79757

Cumulative Model Updates: 3,044
Cumulative Timesteps: 50,815,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 50815672...
Checkpoint 50815672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02435
Policy Entropy: 4.17571
Value Function Loss: 0.06412

Mean KL Divergence: 0.00099
SB3 Clip Fraction: 0.00627
Policy Update Magnitude: 0.07145
Value Function Update Magnitude: 0.05652

Collected Steps per Second: 25,892.84827
Overall Steps per Second: 18,412.29562

Timestep Collection Time: 1.93188
Timestep Consumption Time: 0.78489
PPO Batch Consumption Time: 0.06135
Total Iteration Time: 2.71677

Cumulative Model Updates: 3,047
Cumulative Timesteps: 50,865,694

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02481
Policy Entropy: 4.17241
Value Function Loss: 0.07072

Mean KL Divergence: 0.00093
SB3 Clip Fraction: 0.00713
Policy Update Magnitude: 0.06726
Value Function Update Magnitude: 0.05558

Collected Steps per Second: 25,869.32355
Overall Steps per Second: 18,344.86445

Timestep Collection Time: 1.93302
Timestep Consumption Time: 0.79286
PPO Batch Consumption Time: 0.06052
Total Iteration Time: 2.72589

Cumulative Model Updates: 3,050
Cumulative Timesteps: 50,915,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 50915700...
Checkpoint 50915700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00772
Policy Entropy: 4.17457
Value Function Loss: 0.08460

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00102
Policy Update Magnitude: 0.06921
Value Function Update Magnitude: 0.05494

Collected Steps per Second: 22,487.63405
Overall Steps per Second: 16,058.14113

Timestep Collection Time: 2.22433
Timestep Consumption Time: 0.89060
PPO Batch Consumption Time: 0.09834
Total Iteration Time: 3.11493

Cumulative Model Updates: 3,053
Cumulative Timesteps: 50,965,720

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06460
Policy Entropy: 4.17314
Value Function Loss: 0.07788

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00169
Policy Update Magnitude: 0.07365
Value Function Update Magnitude: 0.04993

Collected Steps per Second: 27,074.49496
Overall Steps per Second: 17,995.78444

Timestep Collection Time: 1.84779
Timestep Consumption Time: 0.93219
PPO Batch Consumption Time: 0.10413
Total Iteration Time: 2.77998

Cumulative Model Updates: 3,056
Cumulative Timesteps: 51,015,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 51015748...
Checkpoint 51015748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07935
Policy Entropy: 4.19288
Value Function Loss: 0.09164

Mean KL Divergence: 0.00101
SB3 Clip Fraction: 0.00807
Policy Update Magnitude: 0.07440
Value Function Update Magnitude: 0.04609

Collected Steps per Second: 25,770.02921
Overall Steps per Second: 18,333.70855

Timestep Collection Time: 1.94032
Timestep Consumption Time: 0.78701
PPO Batch Consumption Time: 0.06087
Total Iteration Time: 2.72733

Cumulative Model Updates: 3,059
Cumulative Timesteps: 51,065,750

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01277
Policy Entropy: 4.18387
Value Function Loss: 0.10058

Mean KL Divergence: 0.00078
SB3 Clip Fraction: 0.00744
Policy Update Magnitude: 0.07668
Value Function Update Magnitude: 0.04850

Collected Steps per Second: 25,524.19141
Overall Steps per Second: 18,817.48034

Timestep Collection Time: 1.95932
Timestep Consumption Time: 0.69832
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 2.65764

Cumulative Model Updates: 3,062
Cumulative Timesteps: 51,115,760

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 51115760...
Checkpoint 51115760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03246
Policy Entropy: 4.17539
Value Function Loss: 0.09488

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00437
Policy Update Magnitude: 0.07651
Value Function Update Magnitude: 0.05791

Collected Steps per Second: 23,141.01471
Overall Steps per Second: 16,681.08679

Timestep Collection Time: 2.16118
Timestep Consumption Time: 0.83694
PPO Batch Consumption Time: 0.07163
Total Iteration Time: 2.99813

Cumulative Model Updates: 3,065
Cumulative Timesteps: 51,165,772

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01517
Policy Entropy: 4.17177
Value Function Loss: 0.09407

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00053
Policy Update Magnitude: 0.07841
Value Function Update Magnitude: 0.05868

Collected Steps per Second: 25,735.37033
Overall Steps per Second: 17,967.00421

Timestep Collection Time: 1.94402
Timestep Consumption Time: 0.84053
PPO Batch Consumption Time: 0.08944
Total Iteration Time: 2.78455

Cumulative Model Updates: 3,068
Cumulative Timesteps: 51,215,802

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 51215802...
Checkpoint 51215802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01209
Policy Entropy: 4.16973
Value Function Loss: 0.10015

Mean KL Divergence: 0.00081
SB3 Clip Fraction: 0.00557
Policy Update Magnitude: 0.08216
Value Function Update Magnitude: 0.05494

Collected Steps per Second: 26,654.60033
Overall Steps per Second: 18,899.52145

Timestep Collection Time: 1.87607
Timestep Consumption Time: 0.76981
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 2.64589

Cumulative Model Updates: 3,071
Cumulative Timesteps: 51,265,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03392
Policy Entropy: 4.16303
Value Function Loss: 0.13311

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.02125
Policy Update Magnitude: 0.07535
Value Function Update Magnitude: 0.06047

Collected Steps per Second: 23,235.04407
Overall Steps per Second: 16,066.97236

Timestep Collection Time: 2.15227
Timestep Consumption Time: 0.96021
PPO Batch Consumption Time: 0.11643
Total Iteration Time: 3.11247

Cumulative Model Updates: 3,074
Cumulative Timesteps: 51,315,816

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 51315816...
Checkpoint 51315816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00822
Policy Entropy: 4.18518
Value Function Loss: 0.11604

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00321
Policy Update Magnitude: 0.08839
Value Function Update Magnitude: 0.06245

Collected Steps per Second: 25,566.69744
Overall Steps per Second: 17,867.48392

Timestep Collection Time: 1.95598
Timestep Consumption Time: 0.84285
PPO Batch Consumption Time: 0.09958
Total Iteration Time: 2.79883

Cumulative Model Updates: 3,077
Cumulative Timesteps: 51,365,824

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10964
Policy Entropy: 4.20552
Value Function Loss: 0.10647

Mean KL Divergence: 0.00113
SB3 Clip Fraction: 0.00741
Policy Update Magnitude: 0.08780
Value Function Update Magnitude: 0.06282

Collected Steps per Second: 25,708.80136
Overall Steps per Second: 18,325.32486

Timestep Collection Time: 1.94548
Timestep Consumption Time: 0.78386
PPO Batch Consumption Time: 0.06177
Total Iteration Time: 2.72934

Cumulative Model Updates: 3,080
Cumulative Timesteps: 51,415,840

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 51415840...
Checkpoint 51415840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10116
Policy Entropy: 4.18336
Value Function Loss: 0.08635

Mean KL Divergence: 0.00097
SB3 Clip Fraction: 0.00958
Policy Update Magnitude: 0.08183
Value Function Update Magnitude: 0.06232

Collected Steps per Second: 25,427.02982
Overall Steps per Second: 18,348.04162

Timestep Collection Time: 1.96704
Timestep Consumption Time: 0.75892
PPO Batch Consumption Time: 0.06072
Total Iteration Time: 2.72596

Cumulative Model Updates: 3,083
Cumulative Timesteps: 51,465,856

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03472
Policy Entropy: 4.17281
Value Function Loss: 0.11187

Mean KL Divergence: 0.00081
SB3 Clip Fraction: 0.00907
Policy Update Magnitude: 0.07923
Value Function Update Magnitude: 0.06032

Collected Steps per Second: 23,740.00593
Overall Steps per Second: 16,153.02381

Timestep Collection Time: 2.10682
Timestep Consumption Time: 0.98956
PPO Batch Consumption Time: 0.11771
Total Iteration Time: 3.09639

Cumulative Model Updates: 3,086
Cumulative Timesteps: 51,515,872

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 51515872...
Checkpoint 51515872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04850
Policy Entropy: 4.19260
Value Function Loss: 0.11216

Mean KL Divergence: 0.00113
SB3 Clip Fraction: 0.00899
Policy Update Magnitude: 0.08063
Value Function Update Magnitude: 0.05324

Collected Steps per Second: 25,416.93948
Overall Steps per Second: 17,792.08736

Timestep Collection Time: 1.96719
Timestep Consumption Time: 0.84305
PPO Batch Consumption Time: 0.07930
Total Iteration Time: 2.81024

Cumulative Model Updates: 3,089
Cumulative Timesteps: 51,565,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00029
Policy Entropy: 4.19776
Value Function Loss: 0.10350

Mean KL Divergence: 0.00077
SB3 Clip Fraction: 0.00340
Policy Update Magnitude: 0.07777
Value Function Update Magnitude: 0.04762

Collected Steps per Second: 25,759.45779
Overall Steps per Second: 19,085.79493

Timestep Collection Time: 1.94189
Timestep Consumption Time: 0.67901
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 2.62090

Cumulative Model Updates: 3,092
Cumulative Timesteps: 51,615,894

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 51615894...
Checkpoint 51615894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04689
Policy Entropy: 4.18573
Value Function Loss: 0.07196

Mean KL Divergence: 0.00087
SB3 Clip Fraction: 0.00518
Policy Update Magnitude: 0.07479
Value Function Update Magnitude: 0.05137

Collected Steps per Second: 22,831.25238
Overall Steps per Second: 15,814.84966

Timestep Collection Time: 2.19103
Timestep Consumption Time: 0.97207
PPO Batch Consumption Time: 0.12006
Total Iteration Time: 3.16310

Cumulative Model Updates: 3,095
Cumulative Timesteps: 51,665,918

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03508
Policy Entropy: 4.19264
Value Function Loss: 0.10269

Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.01339
Policy Update Magnitude: 0.07605
Value Function Update Magnitude: 0.05977

Collected Steps per Second: 25,630.78210
Overall Steps per Second: 18,334.64946

Timestep Collection Time: 1.95195
Timestep Consumption Time: 0.77676
PPO Batch Consumption Time: 0.05955
Total Iteration Time: 2.72871

Cumulative Model Updates: 3,098
Cumulative Timesteps: 51,715,948

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 51715948...
Checkpoint 51715948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00673
Policy Entropy: 4.20903
Value Function Loss: 0.10376

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.02491
Policy Update Magnitude: 0.07151
Value Function Update Magnitude: 0.06660

Collected Steps per Second: 26,680.62770
Overall Steps per Second: 17,772.95593

Timestep Collection Time: 1.87417
Timestep Consumption Time: 0.93932
PPO Batch Consumption Time: 0.11134
Total Iteration Time: 2.81349

Cumulative Model Updates: 3,101
Cumulative Timesteps: 51,765,952

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04564
Policy Entropy: 4.18994
Value Function Loss: 0.10862

Mean KL Divergence: 0.00101
SB3 Clip Fraction: 0.01092
Policy Update Magnitude: 0.08079
Value Function Update Magnitude: 0.06426

Collected Steps per Second: 25,675.05479
Overall Steps per Second: 18,167.92227

Timestep Collection Time: 1.94773
Timestep Consumption Time: 0.80482
PPO Batch Consumption Time: 0.06353
Total Iteration Time: 2.75254

Cumulative Model Updates: 3,104
Cumulative Timesteps: 51,815,960

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 51815960...
Checkpoint 51815960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06622
Policy Entropy: 4.19184
Value Function Loss: 0.06939

Mean KL Divergence: 0.00099
SB3 Clip Fraction: 0.01023
Policy Update Magnitude: 0.07809
Value Function Update Magnitude: 0.05865

Collected Steps per Second: 25,663.12834
Overall Steps per Second: 18,897.57211

Timestep Collection Time: 1.94894
Timestep Consumption Time: 0.69775
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 2.64669

Cumulative Model Updates: 3,107
Cumulative Timesteps: 51,865,976

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01374
Policy Entropy: 4.18984
Value Function Loss: 0.05589

Mean KL Divergence: 0.00066
SB3 Clip Fraction: 0.00417
Policy Update Magnitude: 0.07225
Value Function Update Magnitude: 0.05101

Collected Steps per Second: 22,394.97888
Overall Steps per Second: 15,730.71264

Timestep Collection Time: 2.23389
Timestep Consumption Time: 0.94638
PPO Batch Consumption Time: 0.10786
Total Iteration Time: 3.18028

Cumulative Model Updates: 3,110
Cumulative Timesteps: 51,916,004

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 51916004...
Checkpoint 51916004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00876
Policy Entropy: 4.17225
Value Function Loss: 0.05928

Mean KL Divergence: 0.00079
SB3 Clip Fraction: 0.00598
Policy Update Magnitude: 0.06815
Value Function Update Magnitude: 0.05137

Collected Steps per Second: 25,583.16785
Overall Steps per Second: 17,891.85067

Timestep Collection Time: 1.95519
Timestep Consumption Time: 0.84049
PPO Batch Consumption Time: 0.07464
Total Iteration Time: 2.79569

Cumulative Model Updates: 3,113
Cumulative Timesteps: 51,966,024

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00914
Policy Entropy: 4.14914
Value Function Loss: 0.07259

Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.00987
Policy Update Magnitude: 0.06846
Value Function Update Magnitude: 0.05061

Collected Steps per Second: 26,749.53896
Overall Steps per Second: 19,032.92698

Timestep Collection Time: 1.86964
Timestep Consumption Time: 0.75802
PPO Batch Consumption Time: 0.05836
Total Iteration Time: 2.62766

Cumulative Model Updates: 3,116
Cumulative Timesteps: 52,016,036

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 52016036...
Checkpoint 52016036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07037
Policy Entropy: 4.15724
Value Function Loss: 0.09269

Mean KL Divergence: 0.00117
SB3 Clip Fraction: 0.01270
Policy Update Magnitude: 0.07488
Value Function Update Magnitude: 0.04611

Collected Steps per Second: 22,324.36632
Overall Steps per Second: 15,785.83773

Timestep Collection Time: 2.24069
Timestep Consumption Time: 0.92810
PPO Batch Consumption Time: 0.10162
Total Iteration Time: 3.16879

Cumulative Model Updates: 3,119
Cumulative Timesteps: 52,066,058

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04818
Policy Entropy: 4.15402
Value Function Loss: 0.09852

Mean KL Divergence: 0.00125
SB3 Clip Fraction: 0.01525
Policy Update Magnitude: 0.07567
Value Function Update Magnitude: 0.04705

Collected Steps per Second: 25,712.68204
Overall Steps per Second: 18,410.79581

Timestep Collection Time: 1.94464
Timestep Consumption Time: 0.77126
PPO Batch Consumption Time: 0.05898
Total Iteration Time: 2.71591

Cumulative Model Updates: 3,122
Cumulative Timesteps: 52,116,060

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 52116060...
Checkpoint 52116060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02743
Policy Entropy: 4.13597
Value Function Loss: 0.07926

Mean KL Divergence: 0.00097
SB3 Clip Fraction: 0.00551
Policy Update Magnitude: 0.07977
Value Function Update Magnitude: 0.04934

Collected Steps per Second: 26,802.72749
Overall Steps per Second: 17,785.17632

Timestep Collection Time: 1.86630
Timestep Consumption Time: 0.94626
PPO Batch Consumption Time: 0.11199
Total Iteration Time: 2.81257

Cumulative Model Updates: 3,125
Cumulative Timesteps: 52,166,082

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10250
Policy Entropy: 4.14441
Value Function Loss: 0.07971

Mean KL Divergence: 0.00076
SB3 Clip Fraction: 0.00409
Policy Update Magnitude: 0.07814
Value Function Update Magnitude: 0.04868

Collected Steps per Second: 26,066.30416
Overall Steps per Second: 18,734.42668

Timestep Collection Time: 1.91918
Timestep Consumption Time: 0.75109
PPO Batch Consumption Time: 0.05918
Total Iteration Time: 2.67027

Cumulative Model Updates: 3,128
Cumulative Timesteps: 52,216,108

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 52216108...
Checkpoint 52216108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06023
Policy Entropy: 4.14115
Value Function Loss: 0.08903

Mean KL Divergence: 0.00089
SB3 Clip Fraction: 0.00489
Policy Update Magnitude: 0.08086
Value Function Update Magnitude: 0.04867

Collected Steps per Second: 22,210.22078
Overall Steps per Second: 16,042.75913

Timestep Collection Time: 2.25140
Timestep Consumption Time: 0.86552
PPO Batch Consumption Time: 0.10747
Total Iteration Time: 3.11692

Cumulative Model Updates: 3,131
Cumulative Timesteps: 52,266,112

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00400
Policy Entropy: 4.12801
Value Function Loss: 0.09144

Mean KL Divergence: 0.00133
SB3 Clip Fraction: 0.01384
Policy Update Magnitude: 0.07520
Value Function Update Magnitude: 0.04965

Collected Steps per Second: 25,747.45887
Overall Steps per Second: 18,355.50394

Timestep Collection Time: 1.94233
Timestep Consumption Time: 0.78220
PPO Batch Consumption Time: 0.06079
Total Iteration Time: 2.72452

Cumulative Model Updates: 3,134
Cumulative Timesteps: 52,316,122

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 52316122...
Checkpoint 52316122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06223
Policy Entropy: 4.13617
Value Function Loss: 0.08974

Mean KL Divergence: 0.00095
SB3 Clip Fraction: 0.00585
Policy Update Magnitude: 0.07809
Value Function Update Magnitude: 0.05810

Collected Steps per Second: 26,001.84051
Overall Steps per Second: 17,599.81905

Timestep Collection Time: 1.92294
Timestep Consumption Time: 0.91800
PPO Batch Consumption Time: 0.11534
Total Iteration Time: 2.84094

Cumulative Model Updates: 3,137
Cumulative Timesteps: 52,366,122

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13802
Policy Entropy: 4.12143
Value Function Loss: 0.08129

Mean KL Divergence: 0.00100
SB3 Clip Fraction: 0.00700
Policy Update Magnitude: 0.07638
Value Function Update Magnitude: 0.06964

Collected Steps per Second: 26,593.89524
Overall Steps per Second: 18,763.54812

Timestep Collection Time: 1.88096
Timestep Consumption Time: 0.78496
PPO Batch Consumption Time: 0.05934
Total Iteration Time: 2.66591

Cumulative Model Updates: 3,140
Cumulative Timesteps: 52,416,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 52416144...
Checkpoint 52416144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00337
Policy Entropy: 4.09349
Value Function Loss: 0.11212

Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.01313
Policy Update Magnitude: 0.07637
Value Function Update Magnitude: 0.05925

Collected Steps per Second: 22,577.66524
Overall Steps per Second: 15,981.31533

Timestep Collection Time: 2.21493
Timestep Consumption Time: 0.91422
PPO Batch Consumption Time: 0.09382
Total Iteration Time: 3.12915

Cumulative Model Updates: 3,143
Cumulative Timesteps: 52,466,152

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01481
Policy Entropy: 4.10530
Value Function Loss: 0.12132

Mean KL Divergence: 0.00084
SB3 Clip Fraction: 0.00426
Policy Update Magnitude: 0.08691
Value Function Update Magnitude: 0.05887

Collected Steps per Second: 25,439.90665
Overall Steps per Second: 18,798.53422

Timestep Collection Time: 1.96581
Timestep Consumption Time: 0.69450
PPO Batch Consumption Time: 0.05784
Total Iteration Time: 2.66031

Cumulative Model Updates: 3,146
Cumulative Timesteps: 52,516,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 52516162...
Checkpoint 52516162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04445
Policy Entropy: 4.13401
Value Function Loss: 0.11098

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.02321
Policy Update Magnitude: 0.08212
Value Function Update Magnitude: 0.06185

Collected Steps per Second: 23,427.51539
Overall Steps per Second: 16,147.37502

Timestep Collection Time: 2.13493
Timestep Consumption Time: 0.96254
PPO Batch Consumption Time: 0.11864
Total Iteration Time: 3.09747

Cumulative Model Updates: 3,149
Cumulative Timesteps: 52,566,178

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03841
Policy Entropy: 4.08329
Value Function Loss: 0.08684

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.02069
Policy Update Magnitude: 0.07591
Value Function Update Magnitude: 0.05421

Collected Steps per Second: 25,598.23999
Overall Steps per Second: 17,739.85570

Timestep Collection Time: 1.95381
Timestep Consumption Time: 0.86550
PPO Batch Consumption Time: 0.08256
Total Iteration Time: 2.81930

Cumulative Model Updates: 3,152
Cumulative Timesteps: 52,616,192

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 52616192...
Checkpoint 52616192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02253
Policy Entropy: 4.09540
Value Function Loss: 0.07984

Mean KL Divergence: 0.00125
SB3 Clip Fraction: 0.01305
Policy Update Magnitude: 0.07492
Value Function Update Magnitude: 0.04771

Collected Steps per Second: 25,542.11481
Overall Steps per Second: 18,588.59403

Timestep Collection Time: 1.95763
Timestep Consumption Time: 0.73230
PPO Batch Consumption Time: 0.06061
Total Iteration Time: 2.68993

Cumulative Model Updates: 3,155
Cumulative Timesteps: 52,666,194

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15859
Policy Entropy: 4.11979
Value Function Loss: 0.08277

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.00902
Policy Update Magnitude: 0.06762
Value Function Update Magnitude: 0.04396

Collected Steps per Second: 25,361.70348
Overall Steps per Second: 18,045.92867

Timestep Collection Time: 1.97187
Timestep Consumption Time: 0.79939
PPO Batch Consumption Time: 0.06219
Total Iteration Time: 2.77126

Cumulative Model Updates: 3,158
Cumulative Timesteps: 52,716,204

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 52716204...
Checkpoint 52716204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00083
Policy Entropy: 4.08906
Value Function Loss: 0.07338

Mean KL Divergence: 0.00132
SB3 Clip Fraction: 0.01305
Policy Update Magnitude: 0.07681
Value Function Update Magnitude: 0.04216

Collected Steps per Second: 22,451.49086
Overall Steps per Second: 16,163.49962

Timestep Collection Time: 2.22702
Timestep Consumption Time: 0.86637
PPO Batch Consumption Time: 0.08740
Total Iteration Time: 3.09339

Cumulative Model Updates: 3,161
Cumulative Timesteps: 52,766,204

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03369
Policy Entropy: 4.07530
Value Function Loss: 0.06782

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.02527
Policy Update Magnitude: 0.07090
Value Function Update Magnitude: 0.04059

Collected Steps per Second: 26,307.70876
Overall Steps per Second: 17,950.61664

Timestep Collection Time: 1.90089
Timestep Consumption Time: 0.88498
PPO Batch Consumption Time: 0.09656
Total Iteration Time: 2.78587

Cumulative Model Updates: 3,164
Cumulative Timesteps: 52,816,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 52816212...
Checkpoint 52816212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00035
Policy Entropy: 4.09941
Value Function Loss: 0.08333

Mean KL Divergence: 0.00080
SB3 Clip Fraction: 0.00307
Policy Update Magnitude: 0.06852
Value Function Update Magnitude: 0.04669

Collected Steps per Second: 25,799.73556
Overall Steps per Second: 18,386.43008

Timestep Collection Time: 1.93816
Timestep Consumption Time: 0.78145
PPO Batch Consumption Time: 0.06135
Total Iteration Time: 2.71961

Cumulative Model Updates: 3,167
Cumulative Timesteps: 52,866,216

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09267
Policy Entropy: 4.09602
Value Function Loss: 0.11610

Mean KL Divergence: 0.00097
SB3 Clip Fraction: 0.00400
Policy Update Magnitude: 0.07556
Value Function Update Magnitude: 0.06011

Collected Steps per Second: 25,667.96252
Overall Steps per Second: 18,826.67989

Timestep Collection Time: 1.94795
Timestep Consumption Time: 0.70785
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 2.65581

Cumulative Model Updates: 3,170
Cumulative Timesteps: 52,916,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 52916216...
Checkpoint 52916216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00562
Policy Entropy: 4.07240
Value Function Loss: 0.12110

Mean KL Divergence: 0.00128
SB3 Clip Fraction: 0.00902
Policy Update Magnitude: 0.08108
Value Function Update Magnitude: 0.06721

Collected Steps per Second: 22,377.83014
Overall Steps per Second: 15,726.05200

Timestep Collection Time: 2.23489
Timestep Consumption Time: 0.94531
PPO Batch Consumption Time: 0.10804
Total Iteration Time: 3.18020

Cumulative Model Updates: 3,173
Cumulative Timesteps: 52,966,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04066
Policy Entropy: 4.08004
Value Function Loss: 0.10971

Mean KL Divergence: 0.00124
SB3 Clip Fraction: 0.00957
Policy Update Magnitude: 0.08457
Value Function Update Magnitude: 0.06676

Collected Steps per Second: 25,725.56910
Overall Steps per Second: 17,872.45189

Timestep Collection Time: 1.94359
Timestep Consumption Time: 0.85401
PPO Batch Consumption Time: 0.08878
Total Iteration Time: 2.79760

Cumulative Model Updates: 3,176
Cumulative Timesteps: 53,016,228

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 53016228...
Checkpoint 53016228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01803
Policy Entropy: 4.08561
Value Function Loss: 0.12176

Mean KL Divergence: 0.00103
SB3 Clip Fraction: 0.00727
Policy Update Magnitude: 0.08861
Value Function Update Magnitude: 0.06261

Collected Steps per Second: 26,559.17944
Overall Steps per Second: 18,841.27976

Timestep Collection Time: 1.88296
Timestep Consumption Time: 0.77131
PPO Batch Consumption Time: 0.05866
Total Iteration Time: 2.65428

Cumulative Model Updates: 3,179
Cumulative Timesteps: 53,066,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08386
Policy Entropy: 4.06388
Value Function Loss: 0.12883

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.02083
Policy Update Magnitude: 0.07977
Value Function Update Magnitude: 0.05924

Collected Steps per Second: 22,268.74148
Overall Steps per Second: 15,842.75833

Timestep Collection Time: 2.24557
Timestep Consumption Time: 0.91083
PPO Batch Consumption Time: 0.10037
Total Iteration Time: 3.15639

Cumulative Model Updates: 3,182
Cumulative Timesteps: 53,116,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 53116244...
Checkpoint 53116244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00133
Policy Entropy: 4.07474
Value Function Loss: 0.11594

Mean KL Divergence: 0.00117
SB3 Clip Fraction: 0.00989
Policy Update Magnitude: 0.08154
Value Function Update Magnitude: 0.05841

Collected Steps per Second: 25,896.64545
Overall Steps per Second: 18,976.38567

Timestep Collection Time: 1.93075
Timestep Consumption Time: 0.70410
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 2.63485

Cumulative Model Updates: 3,185
Cumulative Timesteps: 53,166,244

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08042
Policy Entropy: 4.05857
Value Function Loss: 0.08437

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01824
Policy Update Magnitude: 0.08518
Value Function Update Magnitude: 0.05323

Collected Steps per Second: 23,112.47362
Overall Steps per Second: 16,154.72722

Timestep Collection Time: 2.16385
Timestep Consumption Time: 0.93196
PPO Batch Consumption Time: 0.10484
Total Iteration Time: 3.09581

Cumulative Model Updates: 3,188
Cumulative Timesteps: 53,216,256

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 53216256...
Checkpoint 53216256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00618
Policy Entropy: 4.03417
Value Function Loss: 0.07274

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03865
Policy Update Magnitude: 0.07190
Value Function Update Magnitude: 0.04922

Collected Steps per Second: 24,817.96168
Overall Steps per Second: 16,827.04460

Timestep Collection Time: 2.01580
Timestep Consumption Time: 0.95727
PPO Batch Consumption Time: 0.11805
Total Iteration Time: 2.97307

Cumulative Model Updates: 3,191
Cumulative Timesteps: 53,266,284

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06585
Policy Entropy: 4.05941
Value Function Loss: 0.09061

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01480
Policy Update Magnitude: 0.06843
Value Function Update Magnitude: 0.04768

Collected Steps per Second: 26,672.98640
Overall Steps per Second: 17,860.31575

Timestep Collection Time: 1.87561
Timestep Consumption Time: 0.92546
PPO Batch Consumption Time: 0.10393
Total Iteration Time: 2.80107

Cumulative Model Updates: 3,194
Cumulative Timesteps: 53,316,312

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 53316312...
Checkpoint 53316312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03203
Policy Entropy: 4.05956
Value Function Loss: 0.09992

Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.00731
Policy Update Magnitude: 0.07467
Value Function Update Magnitude: 0.04763

Collected Steps per Second: 26,064.61027
Overall Steps per Second: 18,486.99854

Timestep Collection Time: 1.91854
Timestep Consumption Time: 0.78639
PPO Batch Consumption Time: 0.05953
Total Iteration Time: 2.70493

Cumulative Model Updates: 3,197
Cumulative Timesteps: 53,366,318

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04695
Policy Entropy: 4.03054
Value Function Loss: 0.09893

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01749
Policy Update Magnitude: 0.07112
Value Function Update Magnitude: 0.05067

Collected Steps per Second: 22,518.46494
Overall Steps per Second: 16,215.41437

Timestep Collection Time: 2.22084
Timestep Consumption Time: 0.86326
PPO Batch Consumption Time: 0.10172
Total Iteration Time: 3.08410

Cumulative Model Updates: 3,200
Cumulative Timesteps: 53,416,328

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 53416328...
Checkpoint 53416328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02694
Policy Entropy: 4.04976
Value Function Loss: 0.07859

Mean KL Divergence: 0.00086
SB3 Clip Fraction: 0.00348
Policy Update Magnitude: 0.07792
Value Function Update Magnitude: 0.05099

Collected Steps per Second: 26,019.53411
Overall Steps per Second: 18,490.61894

Timestep Collection Time: 1.92225
Timestep Consumption Time: 0.78269
PPO Batch Consumption Time: 0.05935
Total Iteration Time: 2.70494

Cumulative Model Updates: 3,203
Cumulative Timesteps: 53,466,344

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18115
Policy Entropy: 4.06360
Value Function Loss: 0.06749

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01757
Policy Update Magnitude: 0.06969
Value Function Update Magnitude: 0.05023

Collected Steps per Second: 25,952.26595
Overall Steps per Second: 17,512.02358

Timestep Collection Time: 1.92692
Timestep Consumption Time: 0.92872
PPO Batch Consumption Time: 0.11717
Total Iteration Time: 2.85564

Cumulative Model Updates: 3,206
Cumulative Timesteps: 53,516,352

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 53516352...
Checkpoint 53516352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01223
Policy Entropy: 4.03490
Value Function Loss: 0.09070

Mean KL Divergence: 0.00090
SB3 Clip Fraction: 0.00428
Policy Update Magnitude: 0.07059
Value Function Update Magnitude: 0.04946

Collected Steps per Second: 26,722.45199
Overall Steps per Second: 18,778.21097

Timestep Collection Time: 1.87146
Timestep Consumption Time: 0.79173
PPO Batch Consumption Time: 0.05829
Total Iteration Time: 2.66319

Cumulative Model Updates: 3,209
Cumulative Timesteps: 53,566,362

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02597
Policy Entropy: 4.02190
Value Function Loss: 0.11832

Mean KL Divergence: 0.00110
SB3 Clip Fraction: 0.00717
Policy Update Magnitude: 0.07705
Value Function Update Magnitude: 0.05079

Collected Steps per Second: 23,037.54074
Overall Steps per Second: 15,126.73601

Timestep Collection Time: 2.17124
Timestep Consumption Time: 1.13549
PPO Batch Consumption Time: 0.15744
Total Iteration Time: 3.30673

Cumulative Model Updates: 3,212
Cumulative Timesteps: 53,616,382

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 53616382...
Checkpoint 53616382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01024
Policy Entropy: 4.04163
Value Function Loss: 0.12514

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.02191
Policy Update Magnitude: 0.07898
Value Function Update Magnitude: 0.04921

Collected Steps per Second: 17,643.70639
Overall Steps per Second: 13,793.98048

Timestep Collection Time: 2.83535
Timestep Consumption Time: 0.79131
PPO Batch Consumption Time: 0.07026
Total Iteration Time: 3.62665

Cumulative Model Updates: 3,215
Cumulative Timesteps: 53,666,408

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06390
Policy Entropy: 4.02473
Value Function Loss: 0.12369

Mean KL Divergence: 0.00155
SB3 Clip Fraction: 0.01594
Policy Update Magnitude: 0.08710
Value Function Update Magnitude: 0.04892

Collected Steps per Second: 22,508.48443
Overall Steps per Second: 15,765.17819

Timestep Collection Time: 2.22272
Timestep Consumption Time: 0.95073
PPO Batch Consumption Time: 0.10714
Total Iteration Time: 3.17345

Cumulative Model Updates: 3,218
Cumulative Timesteps: 53,716,438

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 53716438...
Checkpoint 53716438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02485
Policy Entropy: 4.00644
Value Function Loss: 0.08408

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.03762
Policy Update Magnitude: 0.07562
Value Function Update Magnitude: 0.05145

Collected Steps per Second: 25,639.14589
Overall Steps per Second: 17,896.17463

Timestep Collection Time: 1.95061
Timestep Consumption Time: 0.84395
PPO Batch Consumption Time: 0.07665
Total Iteration Time: 2.79456

Cumulative Model Updates: 3,221
Cumulative Timesteps: 53,766,450

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02337
Policy Entropy: 4.03083
Value Function Loss: 0.08761

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.02212
Policy Update Magnitude: 0.07997
Value Function Update Magnitude: 0.05042

Collected Steps per Second: 25,762.96864
Overall Steps per Second: 18,934.93346

Timestep Collection Time: 1.94170
Timestep Consumption Time: 0.70019
PPO Batch Consumption Time: 0.05868
Total Iteration Time: 2.64189

Cumulative Model Updates: 3,224
Cumulative Timesteps: 53,816,474

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 53816474...
Checkpoint 53816474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01709
Policy Entropy: 4.01985
Value Function Loss: 0.08331

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02715
Policy Update Magnitude: 0.07080
Value Function Update Magnitude: 0.05129

Collected Steps per Second: 22,784.75282
Overall Steps per Second: 15,925.36802

Timestep Collection Time: 2.19550
Timestep Consumption Time: 0.94565
PPO Batch Consumption Time: 0.11607
Total Iteration Time: 3.14115

Cumulative Model Updates: 3,227
Cumulative Timesteps: 53,866,498

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02420
Policy Entropy: 3.98853
Value Function Loss: 0.10511

Mean KL Divergence: 0.00155
SB3 Clip Fraction: 0.01671
Policy Update Magnitude: 0.06806
Value Function Update Magnitude: 0.04952

Collected Steps per Second: 25,529.02557
Overall Steps per Second: 18,340.48838

Timestep Collection Time: 1.95879
Timestep Consumption Time: 0.76775
PPO Batch Consumption Time: 0.06018
Total Iteration Time: 2.72654

Cumulative Model Updates: 3,230
Cumulative Timesteps: 53,916,504

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 53916504...
Checkpoint 53916504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03488
Policy Entropy: 3.98079
Value Function Loss: 0.10977

Mean KL Divergence: 0.00110
SB3 Clip Fraction: 0.00885
Policy Update Magnitude: 0.07332
Value Function Update Magnitude: 0.05202

Collected Steps per Second: 26,659.55972
Overall Steps per Second: 17,749.15106

Timestep Collection Time: 1.87648
Timestep Consumption Time: 0.94203
PPO Batch Consumption Time: 0.11452
Total Iteration Time: 2.81850

Cumulative Model Updates: 3,233
Cumulative Timesteps: 53,966,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04080
Policy Entropy: 3.98996
Value Function Loss: 0.12852

Mean KL Divergence: 0.00110
SB3 Clip Fraction: 0.00981
Policy Update Magnitude: 0.07388
Value Function Update Magnitude: 0.05689

Collected Steps per Second: 25,958.31478
Overall Steps per Second: 18,446.70962

Timestep Collection Time: 1.92732
Timestep Consumption Time: 0.78482
PPO Batch Consumption Time: 0.05965
Total Iteration Time: 2.71214

Cumulative Model Updates: 3,236
Cumulative Timesteps: 54,016,560

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 54016560...
Checkpoint 54016560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02188
Policy Entropy: 3.96707
Value Function Loss: 0.16364

Mean KL Divergence: 0.00067
SB3 Clip Fraction: 0.00309
Policy Update Magnitude: 0.08308
Value Function Update Magnitude: 0.07654

Collected Steps per Second: 22,916.57405
Overall Steps per Second: 16,247.80159

Timestep Collection Time: 2.18183
Timestep Consumption Time: 0.89551
PPO Batch Consumption Time: 0.09627
Total Iteration Time: 3.07734

Cumulative Model Updates: 3,239
Cumulative Timesteps: 54,066,560

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10527
Policy Entropy: 3.93227
Value Function Loss: 0.16784

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01077
Policy Update Magnitude: 0.09156
Value Function Update Magnitude: 0.07625

Collected Steps per Second: 26,139.59655
Overall Steps per Second: 18,537.46710

Timestep Collection Time: 1.91296
Timestep Consumption Time: 0.78450
PPO Batch Consumption Time: 0.06025
Total Iteration Time: 2.69746

Cumulative Model Updates: 3,242
Cumulative Timesteps: 54,116,564

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 54116564...
Checkpoint 54116564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02528
Policy Entropy: 3.93708
Value Function Loss: 0.14778

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01428
Policy Update Magnitude: 0.09436
Value Function Update Magnitude: 0.08139

Collected Steps per Second: 23,118.20177
Overall Steps per Second: 16,276.27668

Timestep Collection Time: 2.16297
Timestep Consumption Time: 0.90923
PPO Batch Consumption Time: 0.10260
Total Iteration Time: 3.07220

Cumulative Model Updates: 3,245
Cumulative Timesteps: 54,166,568

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00183
Policy Entropy: 3.95358
Value Function Loss: 0.11339

Mean KL Divergence: 0.00116
SB3 Clip Fraction: 0.00982
Policy Update Magnitude: 0.08818
Value Function Update Magnitude: 0.07618

Collected Steps per Second: 25,596.48373
Overall Steps per Second: 17,877.24272

Timestep Collection Time: 1.95425
Timestep Consumption Time: 0.84383
PPO Batch Consumption Time: 0.09353
Total Iteration Time: 2.79808

Cumulative Model Updates: 3,248
Cumulative Timesteps: 54,216,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 54216590...
Checkpoint 54216590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02538
Policy Entropy: 3.95468
Value Function Loss: 0.10472

Mean KL Divergence: 0.00116
SB3 Clip Fraction: 0.00475
Policy Update Magnitude: 0.08766
Value Function Update Magnitude: 0.08272

Collected Steps per Second: 25,778.81427
Overall Steps per Second: 18,278.42593

Timestep Collection Time: 1.93997
Timestep Consumption Time: 0.79605
PPO Batch Consumption Time: 0.05988
Total Iteration Time: 2.73601

Cumulative Model Updates: 3,251
Cumulative Timesteps: 54,266,600

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00883
Policy Entropy: 3.91693
Value Function Loss: 0.10232

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01924
Policy Update Magnitude: 0.07966
Value Function Update Magnitude: 0.07636

Collected Steps per Second: 25,783.16054
Overall Steps per Second: 18,475.50038

Timestep Collection Time: 1.93933
Timestep Consumption Time: 0.76707
PPO Batch Consumption Time: 0.06024
Total Iteration Time: 2.70639

Cumulative Model Updates: 3,254
Cumulative Timesteps: 54,316,602

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 54316602...
Checkpoint 54316602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08785
Policy Entropy: 3.94262
Value Function Loss: 0.12356

Mean KL Divergence: 0.00085
SB3 Clip Fraction: 0.00583
Policy Update Magnitude: 0.07883
Value Function Update Magnitude: 0.08832

Collected Steps per Second: 23,195.66059
Overall Steps per Second: 16,116.18454

Timestep Collection Time: 2.15558
Timestep Consumption Time: 0.94690
PPO Batch Consumption Time: 0.11169
Total Iteration Time: 3.10247

Cumulative Model Updates: 3,257
Cumulative Timesteps: 54,366,602

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01818
Policy Entropy: 3.90421
Value Function Loss: 0.12889

Mean KL Divergence: 0.00151
SB3 Clip Fraction: 0.01279
Policy Update Magnitude: 0.08750
Value Function Update Magnitude: 0.07441

Collected Steps per Second: 25,730.65101
Overall Steps per Second: 17,790.70245

Timestep Collection Time: 1.94422
Timestep Consumption Time: 0.86770
PPO Batch Consumption Time: 0.08574
Total Iteration Time: 2.81192

Cumulative Model Updates: 3,260
Cumulative Timesteps: 54,416,628

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 54416628...
Checkpoint 54416628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02843
Policy Entropy: 3.90469
Value Function Loss: 0.12051

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01675
Policy Update Magnitude: 0.08191
Value Function Update Magnitude: 0.07267

Collected Steps per Second: 25,460.39291
Overall Steps per Second: 18,718.79133

Timestep Collection Time: 1.96431
Timestep Consumption Time: 0.70745
PPO Batch Consumption Time: 0.05906
Total Iteration Time: 2.67175

Cumulative Model Updates: 3,263
Cumulative Timesteps: 54,466,640

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01267
Policy Entropy: 3.95730
Value Function Loss: 0.12385

Mean KL Divergence: 0.00151
SB3 Clip Fraction: 0.01376
Policy Update Magnitude: 0.07928
Value Function Update Magnitude: 0.06423

Collected Steps per Second: 23,674.55888
Overall Steps per Second: 16,245.63599

Timestep Collection Time: 2.11265
Timestep Consumption Time: 0.96609
PPO Batch Consumption Time: 0.12057
Total Iteration Time: 3.07873

Cumulative Model Updates: 3,266
Cumulative Timesteps: 54,516,656

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 54516656...
Checkpoint 54516656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00069
Policy Entropy: 3.96779
Value Function Loss: 0.13118

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01681
Policy Update Magnitude: 0.08169
Value Function Update Magnitude: 0.07331

Collected Steps per Second: 25,711.85469
Overall Steps per Second: 18,454.51721

Timestep Collection Time: 1.94509
Timestep Consumption Time: 0.76492
PPO Batch Consumption Time: 0.06070
Total Iteration Time: 2.71001

Cumulative Model Updates: 3,269
Cumulative Timesteps: 54,566,668

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08451
Policy Entropy: 3.94354
Value Function Loss: 0.14281

Mean KL Divergence: 0.00115
SB3 Clip Fraction: 0.00891
Policy Update Magnitude: 0.08588
Value Function Update Magnitude: 0.10333

Collected Steps per Second: 25,583.83747
Overall Steps per Second: 17,468.83612

Timestep Collection Time: 1.95522
Timestep Consumption Time: 0.90828
PPO Batch Consumption Time: 0.12331
Total Iteration Time: 2.86350

Cumulative Model Updates: 3,272
Cumulative Timesteps: 54,616,690

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 54616690...
Checkpoint 54616690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02970
Policy Entropy: 3.94153
Value Function Loss: 0.12646

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01891
Policy Update Magnitude: 0.08862
Value Function Update Magnitude: 0.10680

Collected Steps per Second: 26,454.94388
Overall Steps per Second: 18,765.44985

Timestep Collection Time: 1.89023
Timestep Consumption Time: 0.77456
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 2.66479

Cumulative Model Updates: 3,275
Cumulative Timesteps: 54,666,696

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03504
Policy Entropy: 3.93921
Value Function Loss: 0.12850

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.02187
Policy Update Magnitude: 0.08954
Value Function Update Magnitude: 0.09821

Collected Steps per Second: 22,558.56956
Overall Steps per Second: 16,008.67863

Timestep Collection Time: 2.21707
Timestep Consumption Time: 0.90711
PPO Batch Consumption Time: 0.10670
Total Iteration Time: 3.12418

Cumulative Model Updates: 3,278
Cumulative Timesteps: 54,716,710

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 54716710...
Checkpoint 54716710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01382
Policy Entropy: 3.89142
Value Function Loss: 0.10324

Mean KL Divergence: 0.00144
SB3 Clip Fraction: 0.01020
Policy Update Magnitude: 0.08988
Value Function Update Magnitude: 0.08640

Collected Steps per Second: 26,611.13495
Overall Steps per Second: 18,809.49338

Timestep Collection Time: 1.87981
Timestep Consumption Time: 0.77969
PPO Batch Consumption Time: 0.05917
Total Iteration Time: 2.65951

Cumulative Model Updates: 3,281
Cumulative Timesteps: 54,766,734

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08836
Policy Entropy: 3.89618
Value Function Loss: 0.09340

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01279
Policy Update Magnitude: 0.09194
Value Function Update Magnitude: 0.08453

Collected Steps per Second: 22,981.06754
Overall Steps per Second: 16,013.83922

Timestep Collection Time: 2.17640
Timestep Consumption Time: 0.94690
PPO Batch Consumption Time: 0.10500
Total Iteration Time: 3.12330

Cumulative Model Updates: 3,284
Cumulative Timesteps: 54,816,750

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 54816750...
Checkpoint 54816750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00007
Policy Entropy: 3.91621
Value Function Loss: 0.09825

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01431
Policy Update Magnitude: 0.08906
Value Function Update Magnitude: 0.07797

Collected Steps per Second: 25,273.32475
Overall Steps per Second: 17,947.82748

Timestep Collection Time: 1.97861
Timestep Consumption Time: 0.80758
PPO Batch Consumption Time: 0.08725
Total Iteration Time: 2.78619

Cumulative Model Updates: 3,287
Cumulative Timesteps: 54,866,756

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08827
Policy Entropy: 3.88977
Value Function Loss: 0.11597

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.02109
Policy Update Magnitude: 0.08312
Value Function Update Magnitude: 0.07826

Collected Steps per Second: 25,662.73813
Overall Steps per Second: 18,125.59843

Timestep Collection Time: 1.94890
Timestep Consumption Time: 0.81041
PPO Batch Consumption Time: 0.06095
Total Iteration Time: 2.75930

Cumulative Model Updates: 3,290
Cumulative Timesteps: 54,916,770

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 54916770...
Checkpoint 54916770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12449
Policy Entropy: 3.88473
Value Function Loss: 0.13180

Mean KL Divergence: 0.00074
SB3 Clip Fraction: 0.00280
Policy Update Magnitude: 0.08784
Value Function Update Magnitude: 0.08015

Collected Steps per Second: 25,716.92984
Overall Steps per Second: 18,308.36933

Timestep Collection Time: 1.94533
Timestep Consumption Time: 0.78719
PPO Batch Consumption Time: 0.06084
Total Iteration Time: 2.73252

Cumulative Model Updates: 3,293
Cumulative Timesteps: 54,966,798

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01229
Policy Entropy: 3.90185
Value Function Loss: 0.12521

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01458
Policy Update Magnitude: 0.08383
Value Function Update Magnitude: 0.07450

Collected Steps per Second: 26,814.24151
Overall Steps per Second: 17,510.79228

Timestep Collection Time: 1.86498
Timestep Consumption Time: 0.99086
PPO Batch Consumption Time: 0.12351
Total Iteration Time: 2.85584

Cumulative Model Updates: 3,296
Cumulative Timesteps: 55,016,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 55016806...
Checkpoint 55016806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00249
Policy Entropy: 3.89486
Value Function Loss: 0.13734

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01743
Policy Update Magnitude: 0.08341
Value Function Update Magnitude: 0.07218

Collected Steps per Second: 25,939.06342
Overall Steps per Second: 18,480.68345

Timestep Collection Time: 1.92852
Timestep Consumption Time: 0.77831
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 2.70683

Cumulative Model Updates: 3,299
Cumulative Timesteps: 55,066,830

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01568
Policy Entropy: 3.88916
Value Function Loss: 0.16216

Mean KL Divergence: 0.00097
SB3 Clip Fraction: 0.00521
Policy Update Magnitude: 0.09484
Value Function Update Magnitude: 0.08217

Collected Steps per Second: 23,482.94818
Overall Steps per Second: 17,232.86926

Timestep Collection Time: 2.13040
Timestep Consumption Time: 0.77266
PPO Batch Consumption Time: 0.07746
Total Iteration Time: 2.90306

Cumulative Model Updates: 3,302
Cumulative Timesteps: 55,116,858

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 55116858...
Checkpoint 55116858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05749
Policy Entropy: 3.91578
Value Function Loss: 0.20619

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02083
Policy Update Magnitude: 0.09214
Value Function Update Magnitude: 0.09863

Collected Steps per Second: 25,589.81851
Overall Steps per Second: 16,966.40088

Timestep Collection Time: 1.95461
Timestep Consumption Time: 0.99346
PPO Batch Consumption Time: 0.12552
Total Iteration Time: 2.94806

Cumulative Model Updates: 3,305
Cumulative Timesteps: 55,166,876

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04759
Policy Entropy: 3.92414
Value Function Loss: 0.18679

Mean KL Divergence: 0.00122
SB3 Clip Fraction: 0.00951
Policy Update Magnitude: 0.09874
Value Function Update Magnitude: 0.10130

Collected Steps per Second: 26,022.53420
Overall Steps per Second: 17,751.65527

Timestep Collection Time: 1.92218
Timestep Consumption Time: 0.89559
PPO Batch Consumption Time: 0.09083
Total Iteration Time: 2.81777

Cumulative Model Updates: 3,308
Cumulative Timesteps: 55,216,896

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 55216896...
Checkpoint 55216896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00767
Policy Entropy: 3.89266
Value Function Loss: 0.15784

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01578
Policy Update Magnitude: 0.10043
Value Function Update Magnitude: 0.09420

Collected Steps per Second: 25,724.42330
Overall Steps per Second: 18,994.98259

Timestep Collection Time: 1.94422
Timestep Consumption Time: 0.68879
PPO Batch Consumption Time: 0.05753
Total Iteration Time: 2.63301

Cumulative Model Updates: 3,311
Cumulative Timesteps: 55,266,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02093
Policy Entropy: 3.90082
Value Function Loss: 0.11231

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01111
Policy Update Magnitude: 0.08891
Value Function Update Magnitude: 0.08981

Collected Steps per Second: 23,262.62042
Overall Steps per Second: 15,978.96953

Timestep Collection Time: 2.15014
Timestep Consumption Time: 0.98009
PPO Batch Consumption Time: 0.11915
Total Iteration Time: 3.13024

Cumulative Model Updates: 3,314
Cumulative Timesteps: 55,316,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 55316928...
Checkpoint 55316928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04164
Policy Entropy: 3.86618
Value Function Loss: 0.14171

Mean KL Divergence: 0.00091
SB3 Clip Fraction: 0.00589
Policy Update Magnitude: 0.08685
Value Function Update Magnitude: 0.08322

Collected Steps per Second: 25,867.69049
Overall Steps per Second: 18,357.06304

Timestep Collection Time: 1.93345
Timestep Consumption Time: 0.79106
PPO Batch Consumption Time: 0.06125
Total Iteration Time: 2.72451

Cumulative Model Updates: 3,317
Cumulative Timesteps: 55,366,942

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00601
Policy Entropy: 3.85481
Value Function Loss: 0.13061

Mean KL Divergence: 0.00082
SB3 Clip Fraction: 0.00435
Policy Update Magnitude: 0.09136
Value Function Update Magnitude: 0.08170

Collected Steps per Second: 26,756.23631
Overall Steps per Second: 17,601.37625

Timestep Collection Time: 1.86992
Timestep Consumption Time: 0.97259
PPO Batch Consumption Time: 0.12029
Total Iteration Time: 2.84250

Cumulative Model Updates: 3,320
Cumulative Timesteps: 55,416,974

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 55416974...
Checkpoint 55416974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05473
Policy Entropy: 3.86083
Value Function Loss: 0.14011

Mean KL Divergence: 0.00085
SB3 Clip Fraction: 0.00474
Policy Update Magnitude: 0.09575
Value Function Update Magnitude: 0.08647

Collected Steps per Second: 26,232.52412
Overall Steps per Second: 18,618.35451

Timestep Collection Time: 1.90725
Timestep Consumption Time: 0.77999
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 2.68724

Cumulative Model Updates: 3,323
Cumulative Timesteps: 55,467,006

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10022
Policy Entropy: 3.88406
Value Function Loss: 0.13697

Mean KL Divergence: 0.00105
SB3 Clip Fraction: 0.00625
Policy Update Magnitude: 0.08790
Value Function Update Magnitude: 0.08404

Collected Steps per Second: 23,144.28115
Overall Steps per Second: 17,114.16776

Timestep Collection Time: 2.16157
Timestep Consumption Time: 0.76162
PPO Batch Consumption Time: 0.07707
Total Iteration Time: 2.92319

Cumulative Model Updates: 3,326
Cumulative Timesteps: 55,517,034

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 55517034...
Checkpoint 55517034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00939
Policy Entropy: 3.85603
Value Function Loss: 0.15514

Mean KL Divergence: 0.00089
SB3 Clip Fraction: 0.00259
Policy Update Magnitude: 0.08901
Value Function Update Magnitude: 0.09339

Collected Steps per Second: 25,754.21817
Overall Steps per Second: 17,832.00590

Timestep Collection Time: 1.94259
Timestep Consumption Time: 0.86303
PPO Batch Consumption Time: 0.08079
Total Iteration Time: 2.80563

Cumulative Model Updates: 3,329
Cumulative Timesteps: 55,567,064

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00734
Policy Entropy: 3.84264
Value Function Loss: 0.17239

Mean KL Divergence: 0.00105
SB3 Clip Fraction: 0.00703
Policy Update Magnitude: 0.09020
Value Function Update Magnitude: 0.09413

Collected Steps per Second: 24,023.74014
Overall Steps per Second: 16,874.79658

Timestep Collection Time: 2.08177
Timestep Consumption Time: 0.88194
PPO Batch Consumption Time: 0.09290
Total Iteration Time: 2.96371

Cumulative Model Updates: 3,332
Cumulative Timesteps: 55,617,076

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 55617076...
Checkpoint 55617076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08252
Policy Entropy: 3.86501
Value Function Loss: 0.18423

Mean KL Divergence: 0.00107
SB3 Clip Fraction: 0.00834
Policy Update Magnitude: 0.09391
Value Function Update Magnitude: 0.08350

Collected Steps per Second: 26,942.96120
Overall Steps per Second: 19,015.49735

Timestep Collection Time: 1.85659
Timestep Consumption Time: 0.77400
PPO Batch Consumption Time: 0.05735
Total Iteration Time: 2.63059

Cumulative Model Updates: 3,335
Cumulative Timesteps: 55,667,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01557
Policy Entropy: 3.87771
Value Function Loss: 0.18544

Mean KL Divergence: 0.00106
SB3 Clip Fraction: 0.00664
Policy Update Magnitude: 0.09612
Value Function Update Magnitude: 0.09094

Collected Steps per Second: 22,148.40699
Overall Steps per Second: 15,742.71503

Timestep Collection Time: 2.25849
Timestep Consumption Time: 0.91898
PPO Batch Consumption Time: 0.10100
Total Iteration Time: 3.17747

Cumulative Model Updates: 3,338
Cumulative Timesteps: 55,717,120

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 55717120...
Checkpoint 55717120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02169
Policy Entropy: 3.85775
Value Function Loss: 0.16344

Mean KL Divergence: 0.00107
SB3 Clip Fraction: 0.00903
Policy Update Magnitude: 0.09406
Value Function Update Magnitude: 0.09848

Collected Steps per Second: 25,332.52549
Overall Steps per Second: 18,638.41896

Timestep Collection Time: 1.97414
Timestep Consumption Time: 0.70903
PPO Batch Consumption Time: 0.05830
Total Iteration Time: 2.68317

Cumulative Model Updates: 3,341
Cumulative Timesteps: 55,767,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12574
Policy Entropy: 3.88175
Value Function Loss: 0.17011

Mean KL Divergence: 0.00116
SB3 Clip Fraction: 0.00747
Policy Update Magnitude: 0.09173
Value Function Update Magnitude: 0.09808

Collected Steps per Second: 25,950.34177
Overall Steps per Second: 17,572.14936

Timestep Collection Time: 1.92753
Timestep Consumption Time: 0.91902
PPO Batch Consumption Time: 0.10256
Total Iteration Time: 2.84655

Cumulative Model Updates: 3,344
Cumulative Timesteps: 55,817,150

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 55817150...
Checkpoint 55817150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13776
Policy Entropy: 3.88018
Value Function Loss: 0.18260

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.00831
Policy Update Magnitude: 0.09345
Value Function Update Magnitude: 0.08891

Collected Steps per Second: 25,836.96793
Overall Steps per Second: 18,446.61261

Timestep Collection Time: 1.93614
Timestep Consumption Time: 0.77569
PPO Batch Consumption Time: 0.06076
Total Iteration Time: 2.71183

Cumulative Model Updates: 3,347
Cumulative Timesteps: 55,867,174

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01643
Policy Entropy: 3.87215
Value Function Loss: 0.19824

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.01320
Policy Update Magnitude: 0.09176
Value Function Update Magnitude: 0.08480

Collected Steps per Second: 25,417.23796
Overall Steps per Second: 18,652.06941

Timestep Collection Time: 1.96835
Timestep Consumption Time: 0.71393
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 2.68228

Cumulative Model Updates: 3,350
Cumulative Timesteps: 55,917,204

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 55917204...
Checkpoint 55917204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00542
Policy Entropy: 3.91024
Value Function Loss: 0.16331

Mean KL Divergence: 0.00105
SB3 Clip Fraction: 0.00835
Policy Update Magnitude: 0.09323
Value Function Update Magnitude: 0.07751

Collected Steps per Second: 23,004.73851
Overall Steps per Second: 15,828.56351

Timestep Collection Time: 2.17355
Timestep Consumption Time: 0.98542
PPO Batch Consumption Time: 0.12097
Total Iteration Time: 3.15897

Cumulative Model Updates: 3,353
Cumulative Timesteps: 55,967,206

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02467
Policy Entropy: 3.91610
Value Function Loss: 0.14370

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01090
Policy Update Magnitude: 0.09052
Value Function Update Magnitude: 0.07333

Collected Steps per Second: 25,763.83893
Overall Steps per Second: 17,769.72376

Timestep Collection Time: 1.94078
Timestep Consumption Time: 0.87311
PPO Batch Consumption Time: 0.09147
Total Iteration Time: 2.81389

Cumulative Model Updates: 3,356
Cumulative Timesteps: 56,017,208

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 56017208...
Checkpoint 56017208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08119
Policy Entropy: 3.89600
Value Function Loss: 0.13550

Mean KL Divergence: 0.00090
SB3 Clip Fraction: 0.00347
Policy Update Magnitude: 0.08582
Value Function Update Magnitude: 0.07020

Collected Steps per Second: 26,739.44746
Overall Steps per Second: 18,940.73950

Timestep Collection Time: 1.87042
Timestep Consumption Time: 0.77013
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 2.64055

Cumulative Model Updates: 3,359
Cumulative Timesteps: 56,067,222

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04172
Policy Entropy: 3.91218
Value Function Loss: 0.14848

Mean KL Divergence: 0.00070
SB3 Clip Fraction: 0.00224
Policy Update Magnitude: 0.09355
Value Function Update Magnitude: 0.07514

Collected Steps per Second: 22,681.27877
Overall Steps per Second: 15,925.99210

Timestep Collection Time: 2.20464
Timestep Consumption Time: 0.93514
PPO Batch Consumption Time: 0.09160
Total Iteration Time: 3.13977

Cumulative Model Updates: 3,362
Cumulative Timesteps: 56,117,226

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 56117226...
Checkpoint 56117226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00976
Policy Entropy: 3.92266
Value Function Loss: 0.15498

Mean KL Divergence: 0.00155
SB3 Clip Fraction: 0.01638
Policy Update Magnitude: 0.09035
Value Function Update Magnitude: 0.08371

Collected Steps per Second: 25,525.93082
Overall Steps per Second: 18,884.88930

Timestep Collection Time: 1.95981
Timestep Consumption Time: 0.68919
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 2.64900

Cumulative Model Updates: 3,365
Cumulative Timesteps: 56,167,252

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.35398
Policy Entropy: 3.90104
Value Function Loss: 0.14594

Mean KL Divergence: 0.00087
SB3 Clip Fraction: 0.00575
Policy Update Magnitude: 0.09055
Value Function Update Magnitude: 0.08177

Collected Steps per Second: 23,347.92271
Overall Steps per Second: 16,101.04405

Timestep Collection Time: 2.14160
Timestep Consumption Time: 0.96391
PPO Batch Consumption Time: 0.11529
Total Iteration Time: 3.10551

Cumulative Model Updates: 3,368
Cumulative Timesteps: 56,217,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 56217254...
Checkpoint 56217254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05477
Policy Entropy: 3.89391
Value Function Loss: 0.12076

Mean KL Divergence: 0.00095
SB3 Clip Fraction: 0.00399
Policy Update Magnitude: 0.08634
Value Function Update Magnitude: 0.07414

Collected Steps per Second: 25,191.29476
Overall Steps per Second: 17,809.27346

Timestep Collection Time: 1.98513
Timestep Consumption Time: 0.82285
PPO Batch Consumption Time: 0.07934
Total Iteration Time: 2.80798

Cumulative Model Updates: 3,371
Cumulative Timesteps: 56,267,262

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01401
Policy Entropy: 3.90688
Value Function Loss: 0.12702

Mean KL Divergence: 0.00071
SB3 Clip Fraction: 0.00363
Policy Update Magnitude: 0.07999
Value Function Update Magnitude: 0.06899

Collected Steps per Second: 26,871.76925
Overall Steps per Second: 18,861.18160

Timestep Collection Time: 1.86151
Timestep Consumption Time: 0.79061
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 2.65211

Cumulative Model Updates: 3,374
Cumulative Timesteps: 56,317,284

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 56317284...
Checkpoint 56317284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.21951
Policy Entropy: 3.90691
Value Function Loss: 0.12976

Mean KL Divergence: 0.00075
SB3 Clip Fraction: 0.00559
Policy Update Magnitude: 0.07834
Value Function Update Magnitude: 0.06962

Collected Steps per Second: 23,227.41570
Overall Steps per Second: 15,979.47952

Timestep Collection Time: 2.15383
Timestep Consumption Time: 0.97693
PPO Batch Consumption Time: 0.11963
Total Iteration Time: 3.13077

Cumulative Model Updates: 3,377
Cumulative Timesteps: 56,367,312

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04996
Policy Entropy: 3.93003
Value Function Loss: 0.13726

Mean KL Divergence: 0.00054
SB3 Clip Fraction: 0.00244
Policy Update Magnitude: 0.08604
Value Function Update Magnitude: 0.07495

Collected Steps per Second: 25,523.15634
Overall Steps per Second: 18,831.88060

Timestep Collection Time: 1.96010
Timestep Consumption Time: 0.69646
PPO Batch Consumption Time: 0.05850
Total Iteration Time: 2.65656

Cumulative Model Updates: 3,380
Cumulative Timesteps: 56,417,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 56417340...
Checkpoint 56417340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09855
Policy Entropy: 3.92300
Value Function Loss: 0.12820

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00286
Policy Update Magnitude: 0.08862
Value Function Update Magnitude: 0.07928

Collected Steps per Second: 22,944.89916
Overall Steps per Second: 16,133.11205

Timestep Collection Time: 2.17931
Timestep Consumption Time: 0.92016
PPO Batch Consumption Time: 0.10383
Total Iteration Time: 3.09946

Cumulative Model Updates: 3,383
Cumulative Timesteps: 56,467,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08329
Policy Entropy: 3.92237
Value Function Loss: 0.13689

Mean KL Divergence: 0.00064
SB3 Clip Fraction: 0.00396
Policy Update Magnitude: 0.08921
Value Function Update Magnitude: 0.07914

Collected Steps per Second: 25,768.08813
Overall Steps per Second: 17,858.39181

Timestep Collection Time: 1.94116
Timestep Consumption Time: 0.85976
PPO Batch Consumption Time: 0.08646
Total Iteration Time: 2.80092

Cumulative Model Updates: 3,386
Cumulative Timesteps: 56,517,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 56517364...
Checkpoint 56517364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10578
Policy Entropy: 3.89562
Value Function Loss: 0.15330

Mean KL Divergence: 0.00088
SB3 Clip Fraction: 0.00520
Policy Update Magnitude: 0.09299
Value Function Update Magnitude: 0.06826

Collected Steps per Second: 26,581.04451
Overall Steps per Second: 18,914.05269

Timestep Collection Time: 1.88104
Timestep Consumption Time: 0.76250
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 2.64354

Cumulative Model Updates: 3,389
Cumulative Timesteps: 56,567,364

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00317
Policy Entropy: 3.88842
Value Function Loss: 0.15011

Mean KL Divergence: 0.00086
SB3 Clip Fraction: 0.00368
Policy Update Magnitude: 0.09340
Value Function Update Magnitude: 0.06012

Collected Steps per Second: 22,894.07831
Overall Steps per Second: 15,871.17713

Timestep Collection Time: 2.18432
Timestep Consumption Time: 0.96655
PPO Batch Consumption Time: 0.11280
Total Iteration Time: 3.15087

Cumulative Model Updates: 3,392
Cumulative Timesteps: 56,617,372

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 56617372...
Checkpoint 56617372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04649
Policy Entropy: 3.89306
Value Function Loss: 0.14257

Mean KL Divergence: 0.00112
SB3 Clip Fraction: 0.00861
Policy Update Magnitude: 0.09044
Value Function Update Magnitude: 0.06447

Collected Steps per Second: 25,493.97767
Overall Steps per Second: 18,333.54309

Timestep Collection Time: 1.96219
Timestep Consumption Time: 0.76636
PPO Batch Consumption Time: 0.05985
Total Iteration Time: 2.72855

Cumulative Model Updates: 3,395
Cumulative Timesteps: 56,667,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03413
Policy Entropy: 3.87378
Value Function Loss: 0.12949

Mean KL Divergence: 0.00079
SB3 Clip Fraction: 0.00309
Policy Update Magnitude: 0.09363
Value Function Update Magnitude: 0.06500

Collected Steps per Second: 26,776.98291
Overall Steps per Second: 17,772.47837

Timestep Collection Time: 1.86765
Timestep Consumption Time: 0.94625
PPO Batch Consumption Time: 0.10605
Total Iteration Time: 2.81390

Cumulative Model Updates: 3,398
Cumulative Timesteps: 56,717,406

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 56717406...
Checkpoint 56717406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00866
Policy Entropy: 3.87330
Value Function Loss: 0.14694

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.01608
Policy Update Magnitude: 0.08889
Value Function Update Magnitude: 0.06220

Collected Steps per Second: 25,517.46817
Overall Steps per Second: 18,059.72451

Timestep Collection Time: 1.95960
Timestep Consumption Time: 0.80921
PPO Batch Consumption Time: 0.06007
Total Iteration Time: 2.76881

Cumulative Model Updates: 3,401
Cumulative Timesteps: 56,767,410

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01969
Policy Entropy: 3.89741
Value Function Loss: 0.13183

Mean KL Divergence: 0.00114
SB3 Clip Fraction: 0.00972
Policy Update Magnitude: 0.08603
Value Function Update Magnitude: 0.05912

Collected Steps per Second: 22,514.90022
Overall Steps per Second: 16,520.17656

Timestep Collection Time: 2.22084
Timestep Consumption Time: 0.80588
PPO Batch Consumption Time: 0.08667
Total Iteration Time: 3.02672

Cumulative Model Updates: 3,404
Cumulative Timesteps: 56,817,412

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 56817412...
Checkpoint 56817412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02726
Policy Entropy: 3.89486
Value Function Loss: 0.13103

Mean KL Divergence: 0.00072
SB3 Clip Fraction: 0.00205
Policy Update Magnitude: 0.08555
Value Function Update Magnitude: 0.05625

Collected Steps per Second: 25,702.21273
Overall Steps per Second: 18,375.53349

Timestep Collection Time: 1.94645
Timestep Consumption Time: 0.77609
PPO Batch Consumption Time: 0.05960
Total Iteration Time: 2.72253

Cumulative Model Updates: 3,407
Cumulative Timesteps: 56,867,440

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03454
Policy Entropy: 3.88858
Value Function Loss: 0.11718

Mean KL Divergence: 0.00122
SB3 Clip Fraction: 0.00595
Policy Update Magnitude: 0.08088
Value Function Update Magnitude: 0.05675

Collected Steps per Second: 25,970.03204
Overall Steps per Second: 18,638.27203

Timestep Collection Time: 1.92630
Timestep Consumption Time: 0.75775
PPO Batch Consumption Time: 0.07772
Total Iteration Time: 2.68405

Cumulative Model Updates: 3,410
Cumulative Timesteps: 56,917,466

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 56917466...
Checkpoint 56917466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06456
Policy Entropy: 3.89792
Value Function Loss: 0.11838

Mean KL Divergence: 0.00095
SB3 Clip Fraction: 0.00653
Policy Update Magnitude: 0.08711
Value Function Update Magnitude: 0.05852

Collected Steps per Second: 24,465.86650
Overall Steps per Second: 17,067.54057

Timestep Collection Time: 2.04407
Timestep Consumption Time: 0.88605
PPO Batch Consumption Time: 0.09215
Total Iteration Time: 2.93012

Cumulative Model Updates: 3,413
Cumulative Timesteps: 56,967,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01578
Policy Entropy: 3.89813
Value Function Loss: 0.12875

Mean KL Divergence: 0.00101
SB3 Clip Fraction: 0.00971
Policy Update Magnitude: 0.08390
Value Function Update Magnitude: 0.06230

Collected Steps per Second: 25,794.11767
Overall Steps per Second: 18,599.61225

Timestep Collection Time: 1.93874
Timestep Consumption Time: 0.74992
PPO Batch Consumption Time: 0.05955
Total Iteration Time: 2.68866

Cumulative Model Updates: 3,416
Cumulative Timesteps: 57,017,484

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 57017484...
Checkpoint 57017484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01568
Policy Entropy: 3.88792
Value Function Loss: 0.12432

Mean KL Divergence: 0.00078
SB3 Clip Fraction: 0.00487
Policy Update Magnitude: 0.09289
Value Function Update Magnitude: 0.06198

Collected Steps per Second: 23,117.75146
Overall Steps per Second: 16,233.16346

Timestep Collection Time: 2.16345
Timestep Consumption Time: 0.91753
PPO Batch Consumption Time: 0.12293
Total Iteration Time: 3.08098

Cumulative Model Updates: 3,419
Cumulative Timesteps: 57,067,498

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04147
Policy Entropy: 3.88509
Value Function Loss: 0.14913

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00156
Policy Update Magnitude: 0.09791
Value Function Update Magnitude: 0.06516

Collected Steps per Second: 26,046.92435
Overall Steps per Second: 18,301.42719

Timestep Collection Time: 1.92030
Timestep Consumption Time: 0.81271
PPO Batch Consumption Time: 0.02892
Total Iteration Time: 2.73301

Cumulative Model Updates: 3,422
Cumulative Timesteps: 57,117,516

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 57117516...
Checkpoint 57117516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02404
Policy Entropy: 3.88079
Value Function Loss: 0.13467

Mean KL Divergence: 0.00081
SB3 Clip Fraction: 0.00384
Policy Update Magnitude: 0.08980
Value Function Update Magnitude: 0.06193

Collected Steps per Second: 16,027.28696
Overall Steps per Second: 11,237.54201

Timestep Collection Time: 3.12055
Timestep Consumption Time: 1.33006
PPO Batch Consumption Time: 0.03452
Total Iteration Time: 4.45062

Cumulative Model Updates: 3,425
Cumulative Timesteps: 57,167,530

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01988
Policy Entropy: 3.86904
Value Function Loss: 0.14290

Mean KL Divergence: 0.00065
SB3 Clip Fraction: 0.00271
Policy Update Magnitude: 0.08116
Value Function Update Magnitude: 0.05999

Collected Steps per Second: 13,451.13135
Overall Steps per Second: 10,346.24618

Timestep Collection Time: 3.71879
Timestep Consumption Time: 1.11600
PPO Batch Consumption Time: 0.11660
Total Iteration Time: 4.83480

Cumulative Model Updates: 3,428
Cumulative Timesteps: 57,217,552

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 57217552...
Checkpoint 57217552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05799
Policy Entropy: 3.86537
Value Function Loss: 0.14852

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00098
Policy Update Magnitude: 0.07630
Value Function Update Magnitude: 0.05980

Collected Steps per Second: 22,858.50714
Overall Steps per Second: 16,913.74592

Timestep Collection Time: 2.18807
Timestep Consumption Time: 0.76905
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 2.95712

Cumulative Model Updates: 3,431
Cumulative Timesteps: 57,267,568

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06084
Policy Entropy: 3.88291
Value Function Loss: 0.15748

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00035
Policy Update Magnitude: 0.08067
Value Function Update Magnitude: 0.05597

Collected Steps per Second: 21,889.01116
Overall Steps per Second: 15,485.40105

Timestep Collection Time: 2.28425
Timestep Consumption Time: 0.94460
PPO Batch Consumption Time: 0.11094
Total Iteration Time: 3.22885

Cumulative Model Updates: 3,434
Cumulative Timesteps: 57,317,568

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 57317568...
Checkpoint 57317568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06972
Policy Entropy: 3.88285
Value Function Loss: 0.14525

Mean KL Divergence: 0.00061
SB3 Clip Fraction: 0.00252
Policy Update Magnitude: 0.08157
Value Function Update Magnitude: 0.05387

Collected Steps per Second: 24,629.72418
Overall Steps per Second: 17,761.83540

Timestep Collection Time: 2.03023
Timestep Consumption Time: 0.78502
PPO Batch Consumption Time: 0.06013
Total Iteration Time: 2.81525

Cumulative Model Updates: 3,437
Cumulative Timesteps: 57,367,572

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08931
Policy Entropy: 3.87655
Value Function Loss: 0.12597

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00133
Policy Update Magnitude: 0.07892
Value Function Update Magnitude: 0.05474

Collected Steps per Second: 22,247.04398
Overall Steps per Second: 16,021.02303

Timestep Collection Time: 2.24767
Timestep Consumption Time: 0.87348
PPO Batch Consumption Time: 0.10504
Total Iteration Time: 3.12115

Cumulative Model Updates: 3,440
Cumulative Timesteps: 57,417,576

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 57417576...
Checkpoint 57417576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04291
Policy Entropy: 3.90279
Value Function Loss: 0.13568

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00149
Policy Update Magnitude: 0.08136
Value Function Update Magnitude: 0.06405

Collected Steps per Second: 25,676.88903
Overall Steps per Second: 18,300.11531

Timestep Collection Time: 1.94813
Timestep Consumption Time: 0.78529
PPO Batch Consumption Time: 0.05968
Total Iteration Time: 2.73343

Cumulative Model Updates: 3,443
Cumulative Timesteps: 57,467,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18691
Policy Entropy: 3.94404
Value Function Loss: 0.16182

Mean KL Divergence: 0.00112
SB3 Clip Fraction: 0.00913
Policy Update Magnitude: 0.08023
Value Function Update Magnitude: 0.07059

Collected Steps per Second: 25,403.64583
Overall Steps per Second: 18,235.35853

Timestep Collection Time: 1.96924
Timestep Consumption Time: 0.77411
PPO Batch Consumption Time: 0.06206
Total Iteration Time: 2.74335

Cumulative Model Updates: 3,446
Cumulative Timesteps: 57,517,624

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 57517624...
Checkpoint 57517624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02889
Policy Entropy: 3.91962
Value Function Loss: 0.14443

Mean KL Divergence: 0.00078
SB3 Clip Fraction: 0.00539
Policy Update Magnitude: 0.08616
Value Function Update Magnitude: 0.07392

Collected Steps per Second: 22,363.69194
Overall Steps per Second: 16,237.32025

Timestep Collection Time: 2.23693
Timestep Consumption Time: 0.84400
PPO Batch Consumption Time: 0.09659
Total Iteration Time: 3.08093

Cumulative Model Updates: 3,449
Cumulative Timesteps: 57,567,650

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09556
Policy Entropy: 3.91190
Value Function Loss: 0.13292

Mean KL Divergence: 0.00107
SB3 Clip Fraction: 0.01131
Policy Update Magnitude: 0.08817
Value Function Update Magnitude: 0.07108

Collected Steps per Second: 25,136.31792
Overall Steps per Second: 17,910.68928

Timestep Collection Time: 1.99035
Timestep Consumption Time: 0.80296
PPO Batch Consumption Time: 0.05827
Total Iteration Time: 2.79330

Cumulative Model Updates: 3,452
Cumulative Timesteps: 57,617,680

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 57617680...
Checkpoint 57617680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00413
Policy Entropy: 3.92377
Value Function Loss: 0.11079

Mean KL Divergence: 0.00103
SB3 Clip Fraction: 0.00977
Policy Update Magnitude: 0.07874
Value Function Update Magnitude: 0.06216

Collected Steps per Second: 22,199.88051
Overall Steps per Second: 15,822.03801

Timestep Collection Time: 2.25299
Timestep Consumption Time: 0.90818
PPO Batch Consumption Time: 0.12024
Total Iteration Time: 3.16116

Cumulative Model Updates: 3,455
Cumulative Timesteps: 57,667,696

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05979
Policy Entropy: 3.89481
Value Function Loss: 0.12981

Mean KL Divergence: 0.00083
SB3 Clip Fraction: 0.00473
Policy Update Magnitude: 0.07868
Value Function Update Magnitude: 0.06441

Collected Steps per Second: 25,194.16725
Overall Steps per Second: 17,997.48566

Timestep Collection Time: 1.98475
Timestep Consumption Time: 0.79364
PPO Batch Consumption Time: 0.06177
Total Iteration Time: 2.77839

Cumulative Model Updates: 3,458
Cumulative Timesteps: 57,717,700

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 57717700...
Checkpoint 57717700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04815
Policy Entropy: 3.88668
Value Function Loss: 0.13623

Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.01365
Policy Update Magnitude: 0.08078
Value Function Update Magnitude: 0.06907

Collected Steps per Second: 25,631.77955
Overall Steps per Second: 18,378.38021

Timestep Collection Time: 1.95148
Timestep Consumption Time: 0.77019
PPO Batch Consumption Time: 0.06242
Total Iteration Time: 2.72168

Cumulative Model Updates: 3,461
Cumulative Timesteps: 57,767,720

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04127
Policy Entropy: 3.91908
Value Function Loss: 0.15377

Mean KL Divergence: 0.00106
SB3 Clip Fraction: 0.01061
Policy Update Magnitude: 0.07792
Value Function Update Magnitude: 0.06538

Collected Steps per Second: 21,853.15927
Overall Steps per Second: 16,179.16732

Timestep Collection Time: 2.28800
Timestep Consumption Time: 0.80240
PPO Batch Consumption Time: 0.08146
Total Iteration Time: 3.09039

Cumulative Model Updates: 3,464
Cumulative Timesteps: 57,817,720

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 57817720...
Checkpoint 57817720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07518
Policy Entropy: 3.87613
Value Function Loss: 0.18120

Mean KL Divergence: 0.00079
SB3 Clip Fraction: 0.00364
Policy Update Magnitude: 0.08389
Value Function Update Magnitude: 0.07040

Collected Steps per Second: 25,173.72036
Overall Steps per Second: 16,825.89141

Timestep Collection Time: 1.98723
Timestep Consumption Time: 0.98592
PPO Batch Consumption Time: 0.10669
Total Iteration Time: 2.97316

Cumulative Model Updates: 3,467
Cumulative Timesteps: 57,867,746

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07317
Policy Entropy: 3.86660
Value Function Loss: 0.18003

Mean KL Divergence: 0.00120
SB3 Clip Fraction: 0.00979
Policy Update Magnitude: 0.08950
Value Function Update Magnitude: 0.07133

Collected Steps per Second: 25,544.54350
Overall Steps per Second: 17,903.17179

Timestep Collection Time: 1.95854
Timestep Consumption Time: 0.83594
PPO Batch Consumption Time: 0.09582
Total Iteration Time: 2.79448

Cumulative Model Updates: 3,470
Cumulative Timesteps: 57,917,776

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 57917776...
Checkpoint 57917776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09826
Policy Entropy: 3.89408
Value Function Loss: 0.15870

Mean KL Divergence: 0.00086
SB3 Clip Fraction: 0.00701
Policy Update Magnitude: 0.08754
Value Function Update Magnitude: 0.06934

Collected Steps per Second: 25,215.45639
Overall Steps per Second: 17,978.22599

Timestep Collection Time: 1.98355
Timestep Consumption Time: 0.79849
PPO Batch Consumption Time: 0.05636
Total Iteration Time: 2.78203

Cumulative Model Updates: 3,473
Cumulative Timesteps: 57,967,792

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02679
Policy Entropy: 3.88832
Value Function Loss: 0.11498

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00283
Policy Update Magnitude: 0.08734
Value Function Update Magnitude: 0.07253

Collected Steps per Second: 22,098.00762
Overall Steps per Second: 15,670.20560

Timestep Collection Time: 2.26382
Timestep Consumption Time: 0.92860
PPO Batch Consumption Time: 0.10563
Total Iteration Time: 3.19243

Cumulative Model Updates: 3,476
Cumulative Timesteps: 58,017,818

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 58017818...
Checkpoint 58017818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02492
Policy Entropy: 3.87445
Value Function Loss: 0.11520

Mean KL Divergence: 0.00096
SB3 Clip Fraction: 0.00859
Policy Update Magnitude: 0.07979
Value Function Update Magnitude: 0.06431

Collected Steps per Second: 25,071.96671
Overall Steps per Second: 18,413.85445

Timestep Collection Time: 1.99450
Timestep Consumption Time: 0.72117
PPO Batch Consumption Time: 0.06008
Total Iteration Time: 2.71567

Cumulative Model Updates: 3,479
Cumulative Timesteps: 58,067,824

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00512
Policy Entropy: 3.88284
Value Function Loss: 0.12763

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00664
Policy Update Magnitude: 0.07691
Value Function Update Magnitude: 0.06021

Collected Steps per Second: 25,861.98428
Overall Steps per Second: 18,365.56327

Timestep Collection Time: 1.93411
Timestep Consumption Time: 0.78946
PPO Batch Consumption Time: 0.06062
Total Iteration Time: 2.72358

Cumulative Model Updates: 3,482
Cumulative Timesteps: 58,117,844

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 58117844...
Checkpoint 58117844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00220
Policy Entropy: 3.87948
Value Function Loss: 0.13981

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00322
Policy Update Magnitude: 0.07654
Value Function Update Magnitude: 0.06042

Collected Steps per Second: 21,720.66077
Overall Steps per Second: 15,975.97375

Timestep Collection Time: 2.30260
Timestep Consumption Time: 0.82798
PPO Batch Consumption Time: 0.07377
Total Iteration Time: 3.13058

Cumulative Model Updates: 3,485
Cumulative Timesteps: 58,167,858

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06394
Policy Entropy: 3.85946
Value Function Loss: 0.13645

Mean KL Divergence: 0.00081
SB3 Clip Fraction: 0.00509
Policy Update Magnitude: 0.07606
Value Function Update Magnitude: 0.05861

Collected Steps per Second: 24,324.98270
Overall Steps per Second: 16,619.36950

Timestep Collection Time: 2.05665
Timestep Consumption Time: 0.95357
PPO Batch Consumption Time: 0.09210
Total Iteration Time: 3.01022

Cumulative Model Updates: 3,488
Cumulative Timesteps: 58,217,886

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 58217886...
Checkpoint 58217886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06260
Policy Entropy: 3.84397
Value Function Loss: 0.13663

Mean KL Divergence: 0.00082
SB3 Clip Fraction: 0.00687
Policy Update Magnitude: 0.08380
Value Function Update Magnitude: 0.05944

Collected Steps per Second: 24,604.09867
Overall Steps per Second: 16,923.19147

Timestep Collection Time: 2.03243
Timestep Consumption Time: 0.92245
PPO Batch Consumption Time: 0.09651
Total Iteration Time: 2.95488

Cumulative Model Updates: 3,491
Cumulative Timesteps: 58,267,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00079
Policy Entropy: 3.85448
Value Function Loss: 0.13916

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.01180
Policy Update Magnitude: 0.08471
Value Function Update Magnitude: 0.06434

Collected Steps per Second: 25,083.10704
Overall Steps per Second: 17,852.49757

Timestep Collection Time: 1.99345
Timestep Consumption Time: 0.80739
PPO Batch Consumption Time: 0.08497
Total Iteration Time: 2.80084

Cumulative Model Updates: 3,494
Cumulative Timesteps: 58,317,894

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 58317894...
Checkpoint 58317894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01324
Policy Entropy: 3.84125
Value Function Loss: 0.14223

Mean KL Divergence: 0.00120
SB3 Clip Fraction: 0.01148
Policy Update Magnitude: 0.08402
Value Function Update Magnitude: 0.05527

Collected Steps per Second: 25,364.02319
Overall Steps per Second: 18,236.24974

Timestep Collection Time: 1.97130
Timestep Consumption Time: 0.77050
PPO Batch Consumption Time: 0.05882
Total Iteration Time: 2.74179

Cumulative Model Updates: 3,497
Cumulative Timesteps: 58,367,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06373
Policy Entropy: 3.87153
Value Function Loss: 0.13702

Mean KL Divergence: 0.00080
SB3 Clip Fraction: 0.00542
Policy Update Magnitude: 0.08585
Value Function Update Magnitude: 0.06257

Collected Steps per Second: 22,914.16499
Overall Steps per Second: 16,514.17167

Timestep Collection Time: 2.18345
Timestep Consumption Time: 0.84619
PPO Batch Consumption Time: 0.08316
Total Iteration Time: 3.02964

Cumulative Model Updates: 3,500
Cumulative Timesteps: 58,417,926

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 58417926...
Checkpoint 58417926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01476
Policy Entropy: 3.89288
Value Function Loss: 0.14794

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00429
Policy Update Magnitude: 0.08404
Value Function Update Magnitude: 0.05319

Collected Steps per Second: 26,464.52390
Overall Steps per Second: 18,669.04097

Timestep Collection Time: 1.88940
Timestep Consumption Time: 0.78894
PPO Batch Consumption Time: 0.05840
Total Iteration Time: 2.67834

Cumulative Model Updates: 3,503
Cumulative Timesteps: 58,467,928

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01822
Policy Entropy: 3.86463
Value Function Loss: 0.16084

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00279
Policy Update Magnitude: 0.08783
Value Function Update Magnitude: 0.05656

Collected Steps per Second: 22,166.35599
Overall Steps per Second: 16,122.29139

Timestep Collection Time: 2.25630
Timestep Consumption Time: 0.84586
PPO Batch Consumption Time: 0.07862
Total Iteration Time: 3.10216

Cumulative Model Updates: 3,506
Cumulative Timesteps: 58,517,942

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 58517942...
Checkpoint 58517942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05650
Policy Entropy: 3.85809
Value Function Loss: 0.15912

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00333
Policy Update Magnitude: 0.09057
Value Function Update Magnitude: 0.05590

Collected Steps per Second: 25,580.14675
Overall Steps per Second: 17,989.13661

Timestep Collection Time: 1.95550
Timestep Consumption Time: 0.82518
PPO Batch Consumption Time: 0.08000
Total Iteration Time: 2.78068

Cumulative Model Updates: 3,509
Cumulative Timesteps: 58,567,964

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01997
Policy Entropy: 3.87607
Value Function Loss: 0.14902

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00399
Policy Update Magnitude: 0.09347
Value Function Update Magnitude: 0.05553

Collected Steps per Second: 25,745.47880
Overall Steps per Second: 18,357.82892

Timestep Collection Time: 1.94240
Timestep Consumption Time: 0.78167
PPO Batch Consumption Time: 0.06140
Total Iteration Time: 2.72407

Cumulative Model Updates: 3,512
Cumulative Timesteps: 58,617,972

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 58617972...
Checkpoint 58617972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00934
Policy Entropy: 3.86359
Value Function Loss: 0.13442

Mean KL Divergence: 0.00069
SB3 Clip Fraction: 0.00471
Policy Update Magnitude: 0.08978
Value Function Update Magnitude: 0.05632

Collected Steps per Second: 25,312.40459
Overall Steps per Second: 17,873.50604

Timestep Collection Time: 1.97540
Timestep Consumption Time: 0.82215
PPO Batch Consumption Time: 0.06331
Total Iteration Time: 2.79755

Cumulative Model Updates: 3,515
Cumulative Timesteps: 58,667,974

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06032
Policy Entropy: 3.88584
Value Function Loss: 0.12717

Mean KL Divergence: 0.00060
SB3 Clip Fraction: 0.00399
Policy Update Magnitude: 0.08658
Value Function Update Magnitude: 0.05869

Collected Steps per Second: 25,514.15163
Overall Steps per Second: 17,697.28923

Timestep Collection Time: 1.96001
Timestep Consumption Time: 0.86573
PPO Batch Consumption Time: 0.11000
Total Iteration Time: 2.82574

Cumulative Model Updates: 3,518
Cumulative Timesteps: 58,717,982

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 58717982...
Checkpoint 58717982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.23632
Policy Entropy: 3.89731
Value Function Loss: 0.13633

Mean KL Divergence: 0.00096
SB3 Clip Fraction: 0.00955
Policy Update Magnitude: 0.08613
Value Function Update Magnitude: 0.05637

Collected Steps per Second: 25,712.14864
Overall Steps per Second: 18,046.78772

Timestep Collection Time: 1.94538
Timestep Consumption Time: 0.82630
PPO Batch Consumption Time: 0.06079
Total Iteration Time: 2.77168

Cumulative Model Updates: 3,521
Cumulative Timesteps: 58,768,002

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13883
Policy Entropy: 3.88378
Value Function Loss: 0.13611

Mean KL Divergence: 0.00067
SB3 Clip Fraction: 0.00450
Policy Update Magnitude: 0.08612
Value Function Update Magnitude: 0.05482

Collected Steps per Second: 22,397.83044
Overall Steps per Second: 16,530.23752

Timestep Collection Time: 2.23352
Timestep Consumption Time: 0.79281
PPO Batch Consumption Time: 0.08261
Total Iteration Time: 3.02633

Cumulative Model Updates: 3,524
Cumulative Timesteps: 58,818,028

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 58818028...
Checkpoint 58818028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00110
Policy Entropy: 3.83657
Value Function Loss: 0.17198

Mean KL Divergence: 0.00085
SB3 Clip Fraction: 0.00567
Policy Update Magnitude: 0.08449
Value Function Update Magnitude: 0.06115

Collected Steps per Second: 25,173.63990
Overall Steps per Second: 18,065.57970

Timestep Collection Time: 1.98732
Timestep Consumption Time: 0.78193
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 2.76924

Cumulative Model Updates: 3,527
Cumulative Timesteps: 58,868,056

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13598
Policy Entropy: 3.85703
Value Function Loss: 0.14979

Mean KL Divergence: 0.00139
SB3 Clip Fraction: 0.01537
Policy Update Magnitude: 0.08392
Value Function Update Magnitude: 0.06660

Collected Steps per Second: 22,602.97648
Overall Steps per Second: 15,737.29791

Timestep Collection Time: 2.21343
Timestep Consumption Time: 0.96565
PPO Batch Consumption Time: 0.12222
Total Iteration Time: 3.17907

Cumulative Model Updates: 3,530
Cumulative Timesteps: 58,918,086

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 58918086...
Checkpoint 58918086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02153
Policy Entropy: 3.84496
Value Function Loss: 0.14321

Mean KL Divergence: 0.00088
SB3 Clip Fraction: 0.00687
Policy Update Magnitude: 0.08569
Value Function Update Magnitude: 0.06379

Collected Steps per Second: 24,412.07719
Overall Steps per Second: 18,048.74800

Timestep Collection Time: 2.04923
Timestep Consumption Time: 0.72248
PPO Batch Consumption Time: 0.06059
Total Iteration Time: 2.77172

Cumulative Model Updates: 3,533
Cumulative Timesteps: 58,968,112

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08972
Policy Entropy: 3.85218
Value Function Loss: 0.13837

Mean KL Divergence: 0.00084
SB3 Clip Fraction: 0.00514
Policy Update Magnitude: 0.08766
Value Function Update Magnitude: 0.05886

Collected Steps per Second: 22,701.04902
Overall Steps per Second: 16,490.04336

Timestep Collection Time: 2.20325
Timestep Consumption Time: 0.82986
PPO Batch Consumption Time: 0.07165
Total Iteration Time: 3.03310

Cumulative Model Updates: 3,536
Cumulative Timesteps: 59,018,128

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 59018128...
Checkpoint 59018128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12373
Policy Entropy: 3.91152
Value Function Loss: 0.14236

Mean KL Divergence: 0.00125
SB3 Clip Fraction: 0.01368
Policy Update Magnitude: 0.08448
Value Function Update Magnitude: 0.05681

Collected Steps per Second: 24,665.89248
Overall Steps per Second: 16,893.75398

Timestep Collection Time: 2.02733
Timestep Consumption Time: 0.93269
PPO Batch Consumption Time: 0.10563
Total Iteration Time: 2.96003

Cumulative Model Updates: 3,539
Cumulative Timesteps: 59,068,134

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00334
Policy Entropy: 3.87416
Value Function Loss: 0.14904

Mean KL Divergence: 0.00087
SB3 Clip Fraction: 0.00793
Policy Update Magnitude: 0.08776
Value Function Update Magnitude: 0.05582

Collected Steps per Second: 26,659.11504
Overall Steps per Second: 17,813.91950

Timestep Collection Time: 1.87651
Timestep Consumption Time: 0.93175
PPO Batch Consumption Time: 0.09913
Total Iteration Time: 2.80825

Cumulative Model Updates: 3,542
Cumulative Timesteps: 59,118,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 59118160...
Checkpoint 59118160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03264
Policy Entropy: 3.90105
Value Function Loss: 0.11145

Mean KL Divergence: 0.00122
SB3 Clip Fraction: 0.01418
Policy Update Magnitude: 0.08763
Value Function Update Magnitude: 0.06103

Collected Steps per Second: 25,260.37065
Overall Steps per Second: 17,998.24618

Timestep Collection Time: 1.97954
Timestep Consumption Time: 0.79873
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 2.77827

Cumulative Model Updates: 3,545
Cumulative Timesteps: 59,168,164

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11298
Policy Entropy: 3.93844
Value Function Loss: 0.09681

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.02105
Policy Update Magnitude: 0.07784
Value Function Update Magnitude: 0.06377

Collected Steps per Second: 21,721.06246
Overall Steps per Second: 15,719.17949

Timestep Collection Time: 2.30302
Timestep Consumption Time: 0.87934
PPO Batch Consumption Time: 0.11035
Total Iteration Time: 3.18235

Cumulative Model Updates: 3,548
Cumulative Timesteps: 59,218,188

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 59218188...
Checkpoint 59218188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00145
Policy Entropy: 3.94063
Value Function Loss: 0.08815

Mean KL Divergence: 0.00069
SB3 Clip Fraction: 0.00542
Policy Update Magnitude: 0.07753
Value Function Update Magnitude: 0.06234

Collected Steps per Second: 24,378.98830
Overall Steps per Second: 17,643.79634

Timestep Collection Time: 2.05210
Timestep Consumption Time: 0.78335
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 2.83544

Cumulative Model Updates: 3,551
Cumulative Timesteps: 59,268,216

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01399
Policy Entropy: 3.91521
Value Function Loss: 0.11326

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00223
Policy Update Magnitude: 0.08105
Value Function Update Magnitude: 0.07418

Collected Steps per Second: 21,009.61804
Overall Steps per Second: 14,998.70561

Timestep Collection Time: 2.37986
Timestep Consumption Time: 0.95376
PPO Batch Consumption Time: 0.11837
Total Iteration Time: 3.33362

Cumulative Model Updates: 3,554
Cumulative Timesteps: 59,318,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 59318216...
Checkpoint 59318216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01637
Policy Entropy: 3.92150
Value Function Loss: 0.13460

Mean KL Divergence: 0.00092
SB3 Clip Fraction: 0.00675
Policy Update Magnitude: 0.08220
Value Function Update Magnitude: 0.06307

Collected Steps per Second: 26,127.04632
Overall Steps per Second: 17,842.76159

Timestep Collection Time: 1.91373
Timestep Consumption Time: 0.88853
PPO Batch Consumption Time: 0.09429
Total Iteration Time: 2.80226

Cumulative Model Updates: 3,557
Cumulative Timesteps: 59,368,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08244
Policy Entropy: 3.91437
Value Function Loss: 0.12669

Mean KL Divergence: 0.00065
SB3 Clip Fraction: 0.00317
Policy Update Magnitude: 0.08917
Value Function Update Magnitude: 0.06700

Collected Steps per Second: 25,075.24881
Overall Steps per Second: 18,113.34554

Timestep Collection Time: 1.99432
Timestep Consumption Time: 0.76652
PPO Batch Consumption Time: 0.05948
Total Iteration Time: 2.76084

Cumulative Model Updates: 3,560
Cumulative Timesteps: 59,418,224

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 59418224...
Checkpoint 59418224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06510
Policy Entropy: 3.88896
Value Function Loss: 0.11230

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00244
Policy Update Magnitude: 0.09036
Value Function Update Magnitude: 0.07705

Collected Steps per Second: 22,563.48575
Overall Steps per Second: 15,641.99095

Timestep Collection Time: 2.21650
Timestep Consumption Time: 0.98079
PPO Batch Consumption Time: 0.11504
Total Iteration Time: 3.19729

Cumulative Model Updates: 3,563
Cumulative Timesteps: 59,468,236

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12313
Policy Entropy: 3.90212
Value Function Loss: 0.12114

Mean KL Divergence: 0.00086
SB3 Clip Fraction: 0.00495
Policy Update Magnitude: 0.08393
Value Function Update Magnitude: 0.07166

Collected Steps per Second: 26,265.81133
Overall Steps per Second: 18,619.87883

Timestep Collection Time: 1.90415
Timestep Consumption Time: 0.78191
PPO Batch Consumption Time: 0.05922
Total Iteration Time: 2.68605

Cumulative Model Updates: 3,566
Cumulative Timesteps: 59,518,250

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 59518250...
Checkpoint 59518250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04452
Policy Entropy: 3.89523
Value Function Loss: 0.13725

Mean KL Divergence: 0.00074
SB3 Clip Fraction: 0.00449
Policy Update Magnitude: 0.08715
Value Function Update Magnitude: 0.07269

Collected Steps per Second: 22,488.21995
Overall Steps per Second: 16,091.84432

Timestep Collection Time: 2.22365
Timestep Consumption Time: 0.88388
PPO Batch Consumption Time: 0.09832
Total Iteration Time: 3.10754

Cumulative Model Updates: 3,569
Cumulative Timesteps: 59,568,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09029
Policy Entropy: 3.90796
Value Function Loss: 0.14950

Mean KL Divergence: 0.00095
SB3 Clip Fraction: 0.00690
Policy Update Magnitude: 0.09165
Value Function Update Magnitude: 0.07063

Collected Steps per Second: 25,437.39590
Overall Steps per Second: 18,620.50811

Timestep Collection Time: 1.96687
Timestep Consumption Time: 0.72006
PPO Batch Consumption Time: 0.05957
Total Iteration Time: 2.68693

Cumulative Model Updates: 3,572
Cumulative Timesteps: 59,618,288

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 59618288...
Checkpoint 59618288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14688
Policy Entropy: 3.91163
Value Function Loss: 0.15916

Mean KL Divergence: 0.00102
SB3 Clip Fraction: 0.00881
Policy Update Magnitude: 0.08597
Value Function Update Magnitude: 0.07641

Collected Steps per Second: 23,143.04607
Overall Steps per Second: 16,217.91125

Timestep Collection Time: 2.16143
Timestep Consumption Time: 0.92294
PPO Batch Consumption Time: 0.09728
Total Iteration Time: 3.08437

Cumulative Model Updates: 3,575
Cumulative Timesteps: 59,668,310

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09786
Policy Entropy: 3.89792
Value Function Loss: 0.16214

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00235
Policy Update Magnitude: 0.08548
Value Function Update Magnitude: 0.07563

Collected Steps per Second: 25,663.29723
Overall Steps per Second: 17,877.88344

Timestep Collection Time: 1.94948
Timestep Consumption Time: 0.84895
PPO Batch Consumption Time: 0.08734
Total Iteration Time: 2.79843

Cumulative Model Updates: 3,578
Cumulative Timesteps: 59,718,340

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 59718340...
Checkpoint 59718340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.19241
Policy Entropy: 3.88020
Value Function Loss: 0.15369

Mean KL Divergence: 0.00079
SB3 Clip Fraction: 0.00941
Policy Update Magnitude: 0.08707
Value Function Update Magnitude: 0.07295

Collected Steps per Second: 25,696.56682
Overall Steps per Second: 18,303.91391

Timestep Collection Time: 1.94672
Timestep Consumption Time: 0.78625
PPO Batch Consumption Time: 0.06063
Total Iteration Time: 2.73297

Cumulative Model Updates: 3,581
Cumulative Timesteps: 59,768,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01434
Policy Entropy: 3.89094
Value Function Loss: 0.12773

Mean KL Divergence: 0.00082
SB3 Clip Fraction: 0.01097
Policy Update Magnitude: 0.08367
Value Function Update Magnitude: 0.06715

Collected Steps per Second: 25,662.25820
Overall Steps per Second: 18,272.13035

Timestep Collection Time: 1.94839
Timestep Consumption Time: 0.78802
PPO Batch Consumption Time: 0.06218
Total Iteration Time: 2.73641

Cumulative Model Updates: 3,584
Cumulative Timesteps: 59,818,364

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 59818364...
Checkpoint 59818364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07747
Policy Entropy: 3.90681
Value Function Loss: 0.13313

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00064
Policy Update Magnitude: 0.08295
Value Function Update Magnitude: 0.06742

Collected Steps per Second: 22,252.58243
Overall Steps per Second: 16,228.45268

Timestep Collection Time: 2.24702
Timestep Consumption Time: 0.83411
PPO Batch Consumption Time: 0.10206
Total Iteration Time: 3.08113

Cumulative Model Updates: 3,587
Cumulative Timesteps: 59,868,366

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06315
Policy Entropy: 3.90673
Value Function Loss: 0.13599

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00097
Policy Update Magnitude: 0.08455
Value Function Update Magnitude: 0.07155

Collected Steps per Second: 25,698.20453
Overall Steps per Second: 17,812.55131

Timestep Collection Time: 1.94589
Timestep Consumption Time: 0.86145
PPO Batch Consumption Time: 0.07421
Total Iteration Time: 2.80735

Cumulative Model Updates: 3,590
Cumulative Timesteps: 59,918,372

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 59918372...
Checkpoint 59918372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02483
Policy Entropy: 3.88523
Value Function Loss: 0.15657

Mean KL Divergence: 0.00061
SB3 Clip Fraction: 0.00279
Policy Update Magnitude: 0.08525
Value Function Update Magnitude: 0.07127

Collected Steps per Second: 25,309.76533
Overall Steps per Second: 18,226.13126

Timestep Collection Time: 1.97639
Timestep Consumption Time: 0.76813
PPO Batch Consumption Time: 0.05907
Total Iteration Time: 2.74452

Cumulative Model Updates: 3,593
Cumulative Timesteps: 59,968,394

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04127
Policy Entropy: 3.88589
Value Function Loss: 0.13470

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00136
Policy Update Magnitude: 0.08958
Value Function Update Magnitude: 0.06768

Collected Steps per Second: 23,810.55863
Overall Steps per Second: 16,538.32694

Timestep Collection Time: 2.10066
Timestep Consumption Time: 0.92370
PPO Batch Consumption Time: 0.09817
Total Iteration Time: 3.02437

Cumulative Model Updates: 3,596
Cumulative Timesteps: 60,018,412

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 60018412...
Checkpoint 60018412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14867
Policy Entropy: 3.91880
Value Function Loss: 0.11429

Mean KL Divergence: 0.00105
SB3 Clip Fraction: 0.00999
Policy Update Magnitude: 0.08780
Value Function Update Magnitude: 0.06360

Collected Steps per Second: 25,081.89503
Overall Steps per Second: 17,865.39786

Timestep Collection Time: 1.99411
Timestep Consumption Time: 0.80549
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 2.79960

Cumulative Model Updates: 3,599
Cumulative Timesteps: 60,068,428

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11833
Policy Entropy: 3.91292
Value Function Loss: 0.09602

Mean KL Divergence: 0.00060
SB3 Clip Fraction: 0.00318
Policy Update Magnitude: 0.08525
Value Function Update Magnitude: 0.05938

Collected Steps per Second: 22,106.30755
Overall Steps per Second: 15,824.41733

Timestep Collection Time: 2.26180
Timestep Consumption Time: 0.89788
PPO Batch Consumption Time: 0.11668
Total Iteration Time: 3.15967

Cumulative Model Updates: 3,602
Cumulative Timesteps: 60,118,428

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 60118428...
Checkpoint 60118428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09725
Policy Entropy: 3.91804
Value Function Loss: 0.10645

Mean KL Divergence: 0.00054
SB3 Clip Fraction: 0.00168
Policy Update Magnitude: 0.08486
Value Function Update Magnitude: 0.05488

Collected Steps per Second: 25,390.51899
Overall Steps per Second: 18,040.80911

Timestep Collection Time: 1.96948
Timestep Consumption Time: 0.80235
PPO Batch Consumption Time: 0.06102
Total Iteration Time: 2.77183

Cumulative Model Updates: 3,605
Cumulative Timesteps: 60,168,434

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05446
Policy Entropy: 3.93693
Value Function Loss: 0.12208

Mean KL Divergence: 0.00085
SB3 Clip Fraction: 0.00515
Policy Update Magnitude: 0.08471
Value Function Update Magnitude: 0.05522

Collected Steps per Second: 22,379.43433
Overall Steps per Second: 15,627.66388

Timestep Collection Time: 2.23473
Timestep Consumption Time: 0.96549
PPO Batch Consumption Time: 0.12530
Total Iteration Time: 3.20022

Cumulative Model Updates: 3,608
Cumulative Timesteps: 60,218,446

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 60218446...
Checkpoint 60218446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05738
Policy Entropy: 3.91950
Value Function Loss: 0.11949

Mean KL Divergence: 0.00090
SB3 Clip Fraction: 0.00700
Policy Update Magnitude: 0.08117
Value Function Update Magnitude: 0.06243

Collected Steps per Second: 26,313.63210
Overall Steps per Second: 18,229.04573

Timestep Collection Time: 1.90046
Timestep Consumption Time: 0.84285
PPO Batch Consumption Time: 0.06311
Total Iteration Time: 2.74331

Cumulative Model Updates: 3,611
Cumulative Timesteps: 60,268,454

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07751
Policy Entropy: 3.91322
Value Function Loss: 0.12615

Mean KL Divergence: 0.00077
SB3 Clip Fraction: 0.00584
Policy Update Magnitude: 0.08630
Value Function Update Magnitude: 0.06284

Collected Steps per Second: 24,417.32764
Overall Steps per Second: 16,334.00349

Timestep Collection Time: 2.04830
Timestep Consumption Time: 1.01366
PPO Batch Consumption Time: 0.11933
Total Iteration Time: 3.06196

Cumulative Model Updates: 3,614
Cumulative Timesteps: 60,318,468

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 60318468...
Checkpoint 60318468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13458
Policy Entropy: 3.89382
Value Function Loss: 0.11678

Mean KL Divergence: 0.00077
SB3 Clip Fraction: 0.00632
Policy Update Magnitude: 0.08283
Value Function Update Magnitude: 0.05205

Collected Steps per Second: 24,756.86756
Overall Steps per Second: 17,934.12138

Timestep Collection Time: 2.02142
Timestep Consumption Time: 0.76902
PPO Batch Consumption Time: 0.07341
Total Iteration Time: 2.79043

Cumulative Model Updates: 3,617
Cumulative Timesteps: 60,368,512

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04137
Policy Entropy: 3.88455
Value Function Loss: 0.11548

Mean KL Divergence: 0.00071
SB3 Clip Fraction: 0.00537
Policy Update Magnitude: 0.07907
Value Function Update Magnitude: 0.04919

Collected Steps per Second: 25,153.63788
Overall Steps per Second: 18,045.79974

Timestep Collection Time: 1.98818
Timestep Consumption Time: 0.78310
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 2.77128

Cumulative Model Updates: 3,620
Cumulative Timesteps: 60,418,522

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 60418522...
Checkpoint 60418522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03099
Policy Entropy: 3.89007
Value Function Loss: 0.10077

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00288
Policy Update Magnitude: 0.07808
Value Function Update Magnitude: 0.04825

Collected Steps per Second: 22,052.82449
Overall Steps per Second: 15,700.79784

Timestep Collection Time: 2.26801
Timestep Consumption Time: 0.91756
PPO Batch Consumption Time: 0.10460
Total Iteration Time: 3.18557

Cumulative Model Updates: 3,623
Cumulative Timesteps: 60,468,538

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00562
Policy Entropy: 3.88733
Value Function Loss: 0.09945

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00065
Policy Update Magnitude: 0.07858
Value Function Update Magnitude: 0.05247

Collected Steps per Second: 26,480.84273
Overall Steps per Second: 18,702.67204

Timestep Collection Time: 1.88921
Timestep Consumption Time: 0.78570
PPO Batch Consumption Time: 0.06012
Total Iteration Time: 2.67491

Cumulative Model Updates: 3,626
Cumulative Timesteps: 60,518,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 60518566...
Checkpoint 60518566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10128
Policy Entropy: 3.87126
Value Function Loss: 0.10394

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00321
Policy Update Magnitude: 0.07862
Value Function Update Magnitude: 0.05271

Collected Steps per Second: 22,255.37772
Overall Steps per Second: 16,078.66918

Timestep Collection Time: 2.24746
Timestep Consumption Time: 0.86337
PPO Batch Consumption Time: 0.07627
Total Iteration Time: 3.11083

Cumulative Model Updates: 3,629
Cumulative Timesteps: 60,568,584

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08261
Policy Entropy: 3.85420
Value Function Loss: 0.10878

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00169
Policy Update Magnitude: 0.08084
Value Function Update Magnitude: 0.05667

Collected Steps per Second: 25,443.48554
Overall Steps per Second: 18,850.04049

Timestep Collection Time: 1.96569
Timestep Consumption Time: 0.68757
PPO Batch Consumption Time: 0.05860
Total Iteration Time: 2.65326

Cumulative Model Updates: 3,632
Cumulative Timesteps: 60,618,598

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 60618598...
Checkpoint 60618598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03347
Policy Entropy: 3.85691
Value Function Loss: 0.11877

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00486
Policy Update Magnitude: 0.08218
Value Function Update Magnitude: 0.06190

Collected Steps per Second: 22,542.31699
Overall Steps per Second: 16,061.14076

Timestep Collection Time: 2.21841
Timestep Consumption Time: 0.89520
PPO Batch Consumption Time: 0.09251
Total Iteration Time: 3.11360

Cumulative Model Updates: 3,635
Cumulative Timesteps: 60,668,606

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09361
Policy Entropy: 3.81391
Value Function Loss: 0.12207

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.02421
Policy Update Magnitude: 0.07848
Value Function Update Magnitude: 0.05760

Collected Steps per Second: 25,256.12176
Overall Steps per Second: 16,823.39186

Timestep Collection Time: 1.98003
Timestep Consumption Time: 0.99249
PPO Batch Consumption Time: 0.11676
Total Iteration Time: 2.97253

Cumulative Model Updates: 3,638
Cumulative Timesteps: 60,718,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 60718614...
Checkpoint 60718614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01436
Policy Entropy: 3.85656
Value Function Loss: 0.11539

Mean KL Divergence: 0.00079
SB3 Clip Fraction: 0.00587
Policy Update Magnitude: 0.08052
Value Function Update Magnitude: 0.05206

Collected Steps per Second: 25,462.49398
Overall Steps per Second: 17,876.79628

Timestep Collection Time: 1.96446
Timestep Consumption Time: 0.83358
PPO Batch Consumption Time: 0.10191
Total Iteration Time: 2.79804

Cumulative Model Updates: 3,641
Cumulative Timesteps: 60,768,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08514
Policy Entropy: 3.86434
Value Function Loss: 0.10376

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00305
Policy Update Magnitude: 0.08404
Value Function Update Magnitude: 0.05054

Collected Steps per Second: 25,455.86419
Overall Steps per Second: 18,202.98677

Timestep Collection Time: 1.96552
Timestep Consumption Time: 0.78315
PPO Batch Consumption Time: 0.06135
Total Iteration Time: 2.74867

Cumulative Model Updates: 3,644
Cumulative Timesteps: 60,818,668

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 60818668...
Checkpoint 60818668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09504
Policy Entropy: 3.85482
Value Function Loss: 0.10317

Mean KL Divergence: 0.00089
SB3 Clip Fraction: 0.00784
Policy Update Magnitude: 0.08068
Value Function Update Magnitude: 0.05091

Collected Steps per Second: 25,227.26736
Overall Steps per Second: 18,690.76586

Timestep Collection Time: 1.98238
Timestep Consumption Time: 0.69327
PPO Batch Consumption Time: 0.05962
Total Iteration Time: 2.67565

Cumulative Model Updates: 3,647
Cumulative Timesteps: 60,868,678

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01299
Policy Entropy: 3.87157
Value Function Loss: 0.10476

Mean KL Divergence: 0.00135
SB3 Clip Fraction: 0.01383
Policy Update Magnitude: 0.08012
Value Function Update Magnitude: 0.05077

Collected Steps per Second: 22,629.75733
Overall Steps per Second: 15,889.76185

Timestep Collection Time: 2.21019
Timestep Consumption Time: 0.93750
PPO Batch Consumption Time: 0.10641
Total Iteration Time: 3.14769

Cumulative Model Updates: 3,650
Cumulative Timesteps: 60,918,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 60918694...
Checkpoint 60918694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02513
Policy Entropy: 3.84191
Value Function Loss: 0.10170

Mean KL Divergence: 0.00093
SB3 Clip Fraction: 0.00775
Policy Update Magnitude: 0.08667
Value Function Update Magnitude: 0.05242

Collected Steps per Second: 25,174.44588
Overall Steps per Second: 17,739.09591

Timestep Collection Time: 1.98678
Timestep Consumption Time: 0.83276
PPO Batch Consumption Time: 0.07799
Total Iteration Time: 2.81953

Cumulative Model Updates: 3,653
Cumulative Timesteps: 60,968,710

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03696
Policy Entropy: 3.80986
Value Function Loss: 0.10039

Mean KL Divergence: 0.00112
SB3 Clip Fraction: 0.01060
Policy Update Magnitude: 0.08283
Value Function Update Magnitude: 0.05308

Collected Steps per Second: 23,483.63498
Overall Steps per Second: 16,910.77107

Timestep Collection Time: 2.12982
Timestep Consumption Time: 0.82782
PPO Batch Consumption Time: 0.09231
Total Iteration Time: 2.95764

Cumulative Model Updates: 3,656
Cumulative Timesteps: 61,018,726

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 61018726...
Checkpoint 61018726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00729
Policy Entropy: 3.84176
Value Function Loss: 0.09628

Mean KL Divergence: 0.00077
SB3 Clip Fraction: 0.00565
Policy Update Magnitude: 0.07710
Value Function Update Magnitude: 0.04967

Collected Steps per Second: 25,549.80552
Overall Steps per Second: 18,072.17338

Timestep Collection Time: 1.95790
Timestep Consumption Time: 0.81011
PPO Batch Consumption Time: 0.05799
Total Iteration Time: 2.76801

Cumulative Model Updates: 3,659
Cumulative Timesteps: 61,068,750

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02482
Policy Entropy: 3.82058
Value Function Loss: 0.09859

Mean KL Divergence: 0.00064
SB3 Clip Fraction: 0.00338
Policy Update Magnitude: 0.07951
Value Function Update Magnitude: 0.05217

Collected Steps per Second: 22,109.47553
Overall Steps per Second: 15,702.54416

Timestep Collection Time: 2.26283
Timestep Consumption Time: 0.92328
PPO Batch Consumption Time: 0.12398
Total Iteration Time: 3.18611

Cumulative Model Updates: 3,662
Cumulative Timesteps: 61,118,780

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 61118780...
Checkpoint 61118780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05162
Policy Entropy: 3.82657
Value Function Loss: 0.08550

Mean KL Divergence: 0.00065
SB3 Clip Fraction: 0.00393
Policy Update Magnitude: 0.07875
Value Function Update Magnitude: 0.05887

Collected Steps per Second: 25,483.03370
Overall Steps per Second: 18,078.63785

Timestep Collection Time: 1.96295
Timestep Consumption Time: 0.80396
PPO Batch Consumption Time: 0.06179
Total Iteration Time: 2.76691

Cumulative Model Updates: 3,665
Cumulative Timesteps: 61,168,802

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05474
Policy Entropy: 3.84401
Value Function Loss: 0.11409

Mean KL Divergence: 0.00095
SB3 Clip Fraction: 0.00695
Policy Update Magnitude: 0.07531
Value Function Update Magnitude: 0.05945

Collected Steps per Second: 25,645.42806
Overall Steps per Second: 18,315.41207

Timestep Collection Time: 1.94998
Timestep Consumption Time: 0.78040
PPO Batch Consumption Time: 0.06277
Total Iteration Time: 2.73038

Cumulative Model Updates: 3,668
Cumulative Timesteps: 61,218,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 61218810...
Checkpoint 61218810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05563
Policy Entropy: 3.84314
Value Function Loss: 0.11869

Mean KL Divergence: 0.00061
SB3 Clip Fraction: 0.00269
Policy Update Magnitude: 0.08356
Value Function Update Magnitude: 0.05512

Collected Steps per Second: 22,327.02969
Overall Steps per Second: 16,244.26774

Timestep Collection Time: 2.24007
Timestep Consumption Time: 0.83881
PPO Batch Consumption Time: 0.09784
Total Iteration Time: 3.07887

Cumulative Model Updates: 3,671
Cumulative Timesteps: 61,268,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00724
Policy Entropy: 3.82902
Value Function Loss: 0.12429

Mean KL Divergence: 0.00097
SB3 Clip Fraction: 0.00773
Policy Update Magnitude: 0.08599
Value Function Update Magnitude: 0.05736

Collected Steps per Second: 24,970.89866
Overall Steps per Second: 16,801.38134

Timestep Collection Time: 2.00257
Timestep Consumption Time: 0.97373
PPO Batch Consumption Time: 0.11960
Total Iteration Time: 2.97630

Cumulative Model Updates: 3,674
Cumulative Timesteps: 61,318,830

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 61318830...
Checkpoint 61318830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03503
Policy Entropy: 3.84668
Value Function Loss: 0.10500

Mean KL Divergence: 0.00109
SB3 Clip Fraction: 0.01061
Policy Update Magnitude: 0.08520
Value Function Update Magnitude: 0.05338

Collected Steps per Second: 24,946.59271
Overall Steps per Second: 17,830.79928

Timestep Collection Time: 2.00492
Timestep Consumption Time: 0.80011
PPO Batch Consumption Time: 0.07899
Total Iteration Time: 2.80503

Cumulative Model Updates: 3,677
Cumulative Timesteps: 61,368,846

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12485
Policy Entropy: 3.82724
Value Function Loss: 0.10894

Mean KL Divergence: 0.00114
SB3 Clip Fraction: 0.01209
Policy Update Magnitude: 0.08443
Value Function Update Magnitude: 0.05304

Collected Steps per Second: 25,108.62940
Overall Steps per Second: 18,110.20998

Timestep Collection Time: 1.99143
Timestep Consumption Time: 0.76956
PPO Batch Consumption Time: 0.05351
Total Iteration Time: 2.76098

Cumulative Model Updates: 3,680
Cumulative Timesteps: 61,418,848

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 61418848...
Checkpoint 61418848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06624
Policy Entropy: 3.79103
Value Function Loss: 0.12873

Mean KL Divergence: 0.00096
SB3 Clip Fraction: 0.00926
Policy Update Magnitude: 0.08134
Value Function Update Magnitude: 0.05840

Collected Steps per Second: 22,282.88539
Overall Steps per Second: 15,575.17425

Timestep Collection Time: 2.24522
Timestep Consumption Time: 0.96694
PPO Batch Consumption Time: 0.11377
Total Iteration Time: 3.21216

Cumulative Model Updates: 3,683
Cumulative Timesteps: 61,468,878

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09454
Policy Entropy: 3.80955
Value Function Loss: 0.12751

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00376
Policy Update Magnitude: 0.08732
Value Function Update Magnitude: 0.06042

Collected Steps per Second: 25,685.25949
Overall Steps per Second: 18,600.24821

Timestep Collection Time: 1.94734
Timestep Consumption Time: 0.74176
PPO Batch Consumption Time: 0.05880
Total Iteration Time: 2.68910

Cumulative Model Updates: 3,686
Cumulative Timesteps: 61,518,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 61518896...
Checkpoint 61518896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02050
Policy Entropy: 3.81541
Value Function Loss: 0.12577

Mean KL Divergence: 0.00101
SB3 Clip Fraction: 0.00760
Policy Update Magnitude: 0.09422
Value Function Update Magnitude: 0.05768

Collected Steps per Second: 23,983.54767
Overall Steps per Second: 16,341.32945

Timestep Collection Time: 2.08535
Timestep Consumption Time: 0.97524
PPO Batch Consumption Time: 0.11785
Total Iteration Time: 3.06058

Cumulative Model Updates: 3,689
Cumulative Timesteps: 61,568,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01899
Policy Entropy: 3.80714
Value Function Loss: 0.13021

Mean KL Divergence: 0.00132
SB3 Clip Fraction: 0.01206
Policy Update Magnitude: 0.09136
Value Function Update Magnitude: 0.05353

Collected Steps per Second: 25,052.21507
Overall Steps per Second: 18,399.26200

Timestep Collection Time: 1.99703
Timestep Consumption Time: 0.72210
PPO Batch Consumption Time: 0.06160
Total Iteration Time: 2.71913

Cumulative Model Updates: 3,692
Cumulative Timesteps: 61,618,940

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 61618940...
Checkpoint 61618940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.29657
Policy Entropy: 3.79675
Value Function Loss: 0.14616

Mean KL Divergence: 0.00125
SB3 Clip Fraction: 0.00856
Policy Update Magnitude: 0.08328
Value Function Update Magnitude: 0.05512

Collected Steps per Second: 25,616.43616
Overall Steps per Second: 18,273.74473

Timestep Collection Time: 1.95195
Timestep Consumption Time: 0.78433
PPO Batch Consumption Time: 0.05938
Total Iteration Time: 2.73628

Cumulative Model Updates: 3,695
Cumulative Timesteps: 61,668,942

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03539
Policy Entropy: 3.79476
Value Function Loss: 0.13548

Mean KL Divergence: 0.00093
SB3 Clip Fraction: 0.00395
Policy Update Magnitude: 0.09045
Value Function Update Magnitude: 0.05929

Collected Steps per Second: 21,991.17689
Overall Steps per Second: 15,946.44138

Timestep Collection Time: 2.27500
Timestep Consumption Time: 0.86237
PPO Batch Consumption Time: 0.08329
Total Iteration Time: 3.13738

Cumulative Model Updates: 3,698
Cumulative Timesteps: 61,718,972

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 61718972...
Checkpoint 61718972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07942
Policy Entropy: 3.78988
Value Function Loss: 0.11809

Mean KL Divergence: 0.00102
SB3 Clip Fraction: 0.00543
Policy Update Magnitude: 0.08643
Value Function Update Magnitude: 0.06158

Collected Steps per Second: 25,326.84655
Overall Steps per Second: 18,719.28767

Timestep Collection Time: 1.97569
Timestep Consumption Time: 0.69738
PPO Batch Consumption Time: 0.05882
Total Iteration Time: 2.67307

Cumulative Model Updates: 3,701
Cumulative Timesteps: 61,769,010

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08223
Policy Entropy: 3.81261
Value Function Loss: 0.09208

Mean KL Divergence: 0.00083
SB3 Clip Fraction: 0.00269
Policy Update Magnitude: 0.08799
Value Function Update Magnitude: 0.06267

Collected Steps per Second: 22,710.27474
Overall Steps per Second: 16,082.27715

Timestep Collection Time: 2.20200
Timestep Consumption Time: 0.90751
PPO Batch Consumption Time: 0.08002
Total Iteration Time: 3.10951

Cumulative Model Updates: 3,704
Cumulative Timesteps: 61,819,018

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 61819018...
Checkpoint 61819018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00870
Policy Entropy: 3.79812
Value Function Loss: 0.09884

Mean KL Divergence: 0.00081
SB3 Clip Fraction: 0.00261
Policy Update Magnitude: 0.08602
Value Function Update Magnitude: 0.05374

Collected Steps per Second: 22,045.18677
Overall Steps per Second: 16,680.56825

Timestep Collection Time: 2.26852
Timestep Consumption Time: 0.72958
PPO Batch Consumption Time: 0.05126
Total Iteration Time: 2.99810

Cumulative Model Updates: 3,707
Cumulative Timesteps: 61,869,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00352
Policy Entropy: 3.78193
Value Function Loss: 0.09102

Mean KL Divergence: 0.00087
SB3 Clip Fraction: 0.00365
Policy Update Magnitude: 0.08086
Value Function Update Magnitude: 0.05357

Collected Steps per Second: 22,252.48306
Overall Steps per Second: 15,805.90623

Timestep Collection Time: 2.24757
Timestep Consumption Time: 0.91669
PPO Batch Consumption Time: 0.09413
Total Iteration Time: 3.16426

Cumulative Model Updates: 3,710
Cumulative Timesteps: 61,919,042

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 61919042...
Checkpoint 61919042 saved!
