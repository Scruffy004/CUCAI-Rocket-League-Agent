Created new wandb run! 2przdse2
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.19654
Policy Entropy: 4.49939
Value Function Loss: nan

Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.31195
Value Function Update Magnitude: 0.30868

Collected Steps per Second: 14,776.90232
Overall Steps per Second: 11,038.15796

Timestep Collection Time: 3.38366
Timestep Consumption Time: 1.14608
PPO Batch Consumption Time: 0.18931
Total Iteration Time: 4.52974

Cumulative Model Updates: 2
Cumulative Timesteps: 50,000

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.88097
Policy Entropy: 4.49931
Value Function Loss: 81.17600

Mean KL Divergence: 0.00006
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.24244
Value Function Update Magnitude: 0.27272

Collected Steps per Second: 14,821.04890
Overall Steps per Second: 11,126.83095

Timestep Collection Time: 3.37547
Timestep Consumption Time: 1.12069
PPO Batch Consumption Time: 0.14655
Total Iteration Time: 4.49616

Cumulative Model Updates: 4
Cumulative Timesteps: 100,028

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 100028...
Checkpoint 100028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.88760
Policy Entropy: 4.49893
Value Function Loss: 54.07911

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.37434
Value Function Update Magnitude: 0.49078

Collected Steps per Second: 15,440.67886
Overall Steps per Second: 10,964.14897

Timestep Collection Time: 3.23962
Timestep Consumption Time: 1.32270
PPO Batch Consumption Time: 0.12848
Total Iteration Time: 4.56232

Cumulative Model Updates: 8
Cumulative Timesteps: 150,050

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.33270
Policy Entropy: 4.49731
Value Function Loss: 0.49848

Mean KL Divergence: 0.00090
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.36949
Value Function Update Magnitude: 0.57755

Collected Steps per Second: 15,992.84167
Overall Steps per Second: 10,629.18586

Timestep Collection Time: 3.12877
Timestep Consumption Time: 1.57883
PPO Batch Consumption Time: 0.12629
Total Iteration Time: 4.70760

Cumulative Model Updates: 14
Cumulative Timesteps: 200,088

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 200088...
Checkpoint 200088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.20754
Policy Entropy: 4.49425
Value Function Loss: 0.60128

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.00118
Policy Update Magnitude: 0.23144
Value Function Update Magnitude: 0.43037

Collected Steps per Second: 15,569.61789
Overall Steps per Second: 10,420.42665

Timestep Collection Time: 3.21254
Timestep Consumption Time: 1.58746
PPO Batch Consumption Time: 0.13332
Total Iteration Time: 4.80000

Cumulative Model Updates: 20
Cumulative Timesteps: 250,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.79699
Policy Entropy: 4.49053
Value Function Loss: 0.64074

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.00298
Policy Update Magnitude: 0.19722
Value Function Update Magnitude: 0.52042

Collected Steps per Second: 13,722.92077
Overall Steps per Second: 9,848.30898

Timestep Collection Time: 3.64383
Timestep Consumption Time: 1.43359
PPO Batch Consumption Time: 0.12248
Total Iteration Time: 5.07742

Cumulative Model Updates: 26
Cumulative Timesteps: 300,110

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 300110...
Checkpoint 300110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.30595
Policy Entropy: 4.48672
Value Function Loss: 0.67305

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.00164
Policy Update Magnitude: 0.19850
Value Function Update Magnitude: 0.58074

Collected Steps per Second: 15,250.57542
Overall Steps per Second: 10,245.09828

Timestep Collection Time: 3.27975
Timestep Consumption Time: 1.60239
PPO Batch Consumption Time: 0.12792
Total Iteration Time: 4.88214

Cumulative Model Updates: 32
Cumulative Timesteps: 350,128

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.09705
Policy Entropy: 4.48254
Value Function Loss: 0.69897

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.00365
Policy Update Magnitude: 0.21316
Value Function Update Magnitude: 0.56448

Collected Steps per Second: 14,566.94606
Overall Steps per Second: 9,886.65834

Timestep Collection Time: 3.43449
Timestep Consumption Time: 1.62587
PPO Batch Consumption Time: 0.13722
Total Iteration Time: 5.06035

Cumulative Model Updates: 38
Cumulative Timesteps: 400,158

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 400158...
Checkpoint 400158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.62916
Policy Entropy: 4.47716
Value Function Loss: 0.72148

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.00907
Policy Update Magnitude: 0.21882
Value Function Update Magnitude: 0.56039

Collected Steps per Second: 15,067.56375
Overall Steps per Second: 9,953.60950

Timestep Collection Time: 3.32104
Timestep Consumption Time: 1.70628
PPO Batch Consumption Time: 0.14635
Total Iteration Time: 5.02732

Cumulative Model Updates: 44
Cumulative Timesteps: 450,198

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.98046
Policy Entropy: 4.47178
Value Function Loss: 0.75957

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.01272
Policy Update Magnitude: 0.21891
Value Function Update Magnitude: 0.45601

Collected Steps per Second: 13,739.89633
Overall Steps per Second: 9,588.16201

Timestep Collection Time: 3.64035
Timestep Consumption Time: 1.57629
PPO Batch Consumption Time: 0.12319
Total Iteration Time: 5.21664

Cumulative Model Updates: 50
Cumulative Timesteps: 500,216

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 500216...
Checkpoint 500216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.59896
Policy Entropy: 4.46522
Value Function Loss: 0.77678

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.01094
Policy Update Magnitude: 0.21884
Value Function Update Magnitude: 0.31978

Collected Steps per Second: 15,373.96794
Overall Steps per Second: 10,729.91050

Timestep Collection Time: 3.25264
Timestep Consumption Time: 1.40779
PPO Batch Consumption Time: 0.11841
Total Iteration Time: 4.66043

Cumulative Model Updates: 56
Cumulative Timesteps: 550,222

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.66724
Policy Entropy: 4.46116
Value Function Loss: 0.81280

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.01055
Policy Update Magnitude: 0.22033
Value Function Update Magnitude: 0.36702

Collected Steps per Second: 15,309.89228
Overall Steps per Second: 10,292.69862

Timestep Collection Time: 3.26586
Timestep Consumption Time: 1.59195
PPO Batch Consumption Time: 0.12713
Total Iteration Time: 4.85781

Cumulative Model Updates: 62
Cumulative Timesteps: 600,222

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 600222...
Checkpoint 600222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.77112
Policy Entropy: 4.45868
Value Function Loss: 0.87721

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.01037
Policy Update Magnitude: 0.23682
Value Function Update Magnitude: 0.34232

Collected Steps per Second: 15,623.27195
Overall Steps per Second: 10,548.28876

Timestep Collection Time: 3.20176
Timestep Consumption Time: 1.54043
PPO Batch Consumption Time: 0.12602
Total Iteration Time: 4.74219

Cumulative Model Updates: 68
Cumulative Timesteps: 650,244

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.97880
Policy Entropy: 4.45503
Value Function Loss: 0.97478

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.01811
Policy Update Magnitude: 0.23919
Value Function Update Magnitude: 0.31964

Collected Steps per Second: 15,742.04400
Overall Steps per Second: 10,610.27224

Timestep Collection Time: 3.17722
Timestep Consumption Time: 1.53670
PPO Batch Consumption Time: 0.12364
Total Iteration Time: 4.71392

Cumulative Model Updates: 74
Cumulative Timesteps: 700,260

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 700260...
Checkpoint 700260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.56633
Policy Entropy: 4.45047
Value Function Loss: 1.00123

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.02961
Policy Update Magnitude: 0.23873
Value Function Update Magnitude: 0.31035

Collected Steps per Second: 15,925.37352
Overall Steps per Second: 10,657.26384

Timestep Collection Time: 3.14128
Timestep Consumption Time: 1.55280
PPO Batch Consumption Time: 0.12501
Total Iteration Time: 4.69408

Cumulative Model Updates: 80
Cumulative Timesteps: 750,286

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.11792
Policy Entropy: 4.44722
Value Function Loss: 1.03187

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02043
Policy Update Magnitude: 0.24625
Value Function Update Magnitude: 0.35416

Collected Steps per Second: 14,956.79353
Overall Steps per Second: 9,980.07418

Timestep Collection Time: 3.34363
Timestep Consumption Time: 1.66735
PPO Batch Consumption Time: 0.15173
Total Iteration Time: 5.01098

Cumulative Model Updates: 86
Cumulative Timesteps: 800,296

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 800296...
Checkpoint 800296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.64158
Policy Entropy: 4.43799
Value Function Loss: 1.03707

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02649
Policy Update Magnitude: 0.24204
Value Function Update Magnitude: 0.31721

Collected Steps per Second: 14,008.75770
Overall Steps per Second: 9,609.99670

Timestep Collection Time: 3.56991
Timestep Consumption Time: 1.63405
PPO Batch Consumption Time: 0.13108
Total Iteration Time: 5.20396

Cumulative Model Updates: 92
Cumulative Timesteps: 850,306

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.58467
Policy Entropy: 4.43220
Value Function Loss: 1.08135

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02037
Policy Update Magnitude: 0.25131
Value Function Update Magnitude: 0.29160

Collected Steps per Second: 15,520.88025
Overall Steps per Second: 10,065.16418

Timestep Collection Time: 3.22263
Timestep Consumption Time: 1.74679
PPO Batch Consumption Time: 0.16132
Total Iteration Time: 4.96942

Cumulative Model Updates: 98
Cumulative Timesteps: 900,324

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 900324...
Checkpoint 900324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.76872
Policy Entropy: 4.42187
Value Function Loss: 1.12464

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02620
Policy Update Magnitude: 0.25201
Value Function Update Magnitude: 0.30592

Collected Steps per Second: 13,496.65822
Overall Steps per Second: 9,362.26161

Timestep Collection Time: 3.70699
Timestep Consumption Time: 1.63702
PPO Batch Consumption Time: 0.13814
Total Iteration Time: 5.34401

Cumulative Model Updates: 104
Cumulative Timesteps: 950,356

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.42283
Policy Entropy: 4.41695
Value Function Loss: 1.15038

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.01730
Policy Update Magnitude: 0.27996
Value Function Update Magnitude: 0.31172

Collected Steps per Second: 14,415.83158
Overall Steps per Second: 9,873.20622

Timestep Collection Time: 3.46994
Timestep Consumption Time: 1.59650
PPO Batch Consumption Time: 0.13213
Total Iteration Time: 5.06644

Cumulative Model Updates: 110
Cumulative Timesteps: 1,000,378

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1000378...
Checkpoint 1000378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.32504
Policy Entropy: 4.40728
Value Function Loss: 1.13364

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02940
Policy Update Magnitude: 0.27192
Value Function Update Magnitude: 0.31513

Collected Steps per Second: 14,993.88478
Overall Steps per Second: 10,202.66816

Timestep Collection Time: 3.33496
Timestep Consumption Time: 1.56611
PPO Batch Consumption Time: 0.12690
Total Iteration Time: 4.90107

Cumulative Model Updates: 116
Cumulative Timesteps: 1,050,382

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.61004
Policy Entropy: 4.40450
Value Function Loss: 1.10017

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.01443
Policy Update Magnitude: 0.28045
Value Function Update Magnitude: 0.29817

Collected Steps per Second: 16,346.41269
Overall Steps per Second: 10,786.31229

Timestep Collection Time: 3.05951
Timestep Consumption Time: 1.57711
PPO Batch Consumption Time: 0.12908
Total Iteration Time: 4.63662

Cumulative Model Updates: 122
Cumulative Timesteps: 1,100,394

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1100394...
Checkpoint 1100394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.28424
Policy Entropy: 4.39325
Value Function Loss: 1.11443

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.03723
Policy Update Magnitude: 0.28175
Value Function Update Magnitude: 0.29580

Collected Steps per Second: 14,088.92880
Overall Steps per Second: 9,494.86664

Timestep Collection Time: 3.55031
Timestep Consumption Time: 1.71780
PPO Batch Consumption Time: 0.13794
Total Iteration Time: 5.26811

Cumulative Model Updates: 128
Cumulative Timesteps: 1,150,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.69775
Policy Entropy: 4.38492
Value Function Loss: 1.12760

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02769
Policy Update Magnitude: 0.29779
Value Function Update Magnitude: 0.29199

Collected Steps per Second: 14,041.04513
Overall Steps per Second: 9,745.29752

Timestep Collection Time: 3.56213
Timestep Consumption Time: 1.57019
PPO Batch Consumption Time: 0.13910
Total Iteration Time: 5.13232

Cumulative Model Updates: 134
Cumulative Timesteps: 1,200,430

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1200430...
Checkpoint 1200430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.36284
Policy Entropy: 4.37071
Value Function Loss: 1.16727

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.03260
Policy Update Magnitude: 0.29462
Value Function Update Magnitude: 0.26841

Collected Steps per Second: 15,140.32493
Overall Steps per Second: 10,192.77686

Timestep Collection Time: 3.30416
Timestep Consumption Time: 1.60383
PPO Batch Consumption Time: 0.13303
Total Iteration Time: 4.90799

Cumulative Model Updates: 140
Cumulative Timesteps: 1,250,456

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.85018
Policy Entropy: 4.35471
Value Function Loss: 1.15512

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.02953
Policy Update Magnitude: 0.31346
Value Function Update Magnitude: 0.25204

Collected Steps per Second: 14,274.78190
Overall Steps per Second: 9,824.30363

Timestep Collection Time: 3.50296
Timestep Consumption Time: 1.58687
PPO Batch Consumption Time: 0.12972
Total Iteration Time: 5.08983

Cumulative Model Updates: 146
Cumulative Timesteps: 1,300,460

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1300460...
Checkpoint 1300460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.35735
Policy Entropy: 4.34291
Value Function Loss: 1.19542

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.03514
Policy Update Magnitude: 0.31942
Value Function Update Magnitude: 0.24945

Collected Steps per Second: 15,097.20615
Overall Steps per Second: 9,838.93185

Timestep Collection Time: 3.31320
Timestep Consumption Time: 1.77069
PPO Batch Consumption Time: 0.15449
Total Iteration Time: 5.08389

Cumulative Model Updates: 152
Cumulative Timesteps: 1,350,480

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.99421
Policy Entropy: 4.33026
Value Function Loss: 1.17095

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.04383
Policy Update Magnitude: 0.31328
Value Function Update Magnitude: 0.21265

Collected Steps per Second: 15,080.93052
Overall Steps per Second: 10,207.10523

Timestep Collection Time: 3.31704
Timestep Consumption Time: 1.58386
PPO Batch Consumption Time: 0.12900
Total Iteration Time: 4.90090

Cumulative Model Updates: 158
Cumulative Timesteps: 1,400,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1400504...
Checkpoint 1400504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60.97226
Policy Entropy: 4.32297
Value Function Loss: 1.18396

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.03794
Policy Update Magnitude: 0.33967
Value Function Update Magnitude: 0.20414

Collected Steps per Second: 15,361.56892
Overall Steps per Second: 10,337.54156

Timestep Collection Time: 3.25670
Timestep Consumption Time: 1.58275
PPO Batch Consumption Time: 0.14227
Total Iteration Time: 4.83945

Cumulative Model Updates: 164
Cumulative Timesteps: 1,450,532

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.61157
Policy Entropy: 4.31376
Value Function Loss: 1.18071

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.04820
Policy Update Magnitude: 0.35400
Value Function Update Magnitude: 0.21163

Collected Steps per Second: 14,886.37045
Overall Steps per Second: 10,016.35297

Timestep Collection Time: 3.36012
Timestep Consumption Time: 1.63371
PPO Batch Consumption Time: 0.13846
Total Iteration Time: 4.99383

Cumulative Model Updates: 170
Cumulative Timesteps: 1,500,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1500552...
Checkpoint 1500552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.22600
Policy Entropy: 4.31785
Value Function Loss: 1.20492

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.04075
Policy Update Magnitude: 0.35987
Value Function Update Magnitude: 0.21824

Collected Steps per Second: 14,766.28166
Overall Steps per Second: 9,939.16476

Timestep Collection Time: 3.38609
Timestep Consumption Time: 1.64451
PPO Batch Consumption Time: 0.14130
Total Iteration Time: 5.03060

Cumulative Model Updates: 176
Cumulative Timesteps: 1,550,552

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.92861
Policy Entropy: 4.30207
Value Function Loss: 1.23576

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.03708
Policy Update Magnitude: 0.37798
Value Function Update Magnitude: 0.21331

Collected Steps per Second: 15,174.87385
Overall Steps per Second: 10,291.62062

Timestep Collection Time: 3.29518
Timestep Consumption Time: 1.56353
PPO Batch Consumption Time: 0.12943
Total Iteration Time: 4.85871

Cumulative Model Updates: 182
Cumulative Timesteps: 1,600,556

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1600556...
Checkpoint 1600556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.78080
Policy Entropy: 4.29452
Value Function Loss: 1.27123

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05007
Policy Update Magnitude: 0.38802
Value Function Update Magnitude: 0.21070

Collected Steps per Second: 13,969.42752
Overall Steps per Second: 9,422.46751

Timestep Collection Time: 3.58039
Timestep Consumption Time: 1.72777
PPO Batch Consumption Time: 0.14635
Total Iteration Time: 5.30816

Cumulative Model Updates: 188
Cumulative Timesteps: 1,650,572

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.92390
Policy Entropy: 4.27902
Value Function Loss: 1.34384

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05496
Policy Update Magnitude: 0.37459
Value Function Update Magnitude: 0.15574

Collected Steps per Second: 14,289.90378
Overall Steps per Second: 9,885.67842

Timestep Collection Time: 3.50093
Timestep Consumption Time: 1.55972
PPO Batch Consumption Time: 0.13831
Total Iteration Time: 5.06065

Cumulative Model Updates: 194
Cumulative Timesteps: 1,700,600

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1700600...
Checkpoint 1700600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.49735
Policy Entropy: 4.27043
Value Function Loss: 1.35089

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.04830
Policy Update Magnitude: 0.38467
Value Function Update Magnitude: 0.16442

Collected Steps per Second: 16,318.34220
Overall Steps per Second: 10,789.30352

Timestep Collection Time: 3.06416
Timestep Consumption Time: 1.57025
PPO Batch Consumption Time: 0.12573
Total Iteration Time: 4.63440

Cumulative Model Updates: 200
Cumulative Timesteps: 1,750,602

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.09029
Policy Entropy: 4.25149
Value Function Loss: 1.25434

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05063
Policy Update Magnitude: 0.38999
Value Function Update Magnitude: 0.16626

Collected Steps per Second: 15,276.60858
Overall Steps per Second: 10,344.03629

Timestep Collection Time: 3.27468
Timestep Consumption Time: 1.56154
PPO Batch Consumption Time: 0.12757
Total Iteration Time: 4.83622

Cumulative Model Updates: 206
Cumulative Timesteps: 1,800,628

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1800628...
Checkpoint 1800628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.92527
Policy Entropy: 4.23933
Value Function Loss: 1.27871

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.06047
Policy Update Magnitude: 0.37602
Value Function Update Magnitude: 0.19532

Collected Steps per Second: 15,503.98845
Overall Steps per Second: 10,349.95142

Timestep Collection Time: 3.22549
Timestep Consumption Time: 1.60622
PPO Batch Consumption Time: 0.13107
Total Iteration Time: 4.83171

Cumulative Model Updates: 212
Cumulative Timesteps: 1,850,636

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.06679
Policy Entropy: 4.23228
Value Function Loss: 1.23768

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.09524
Policy Update Magnitude: 0.32096
Value Function Update Magnitude: 0.14862

Collected Steps per Second: 15,080.09775
Overall Steps per Second: 10,345.18345

Timestep Collection Time: 3.31576
Timestep Consumption Time: 1.51760
PPO Batch Consumption Time: 0.11542
Total Iteration Time: 4.83336

Cumulative Model Updates: 218
Cumulative Timesteps: 1,900,638

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1900638...
Checkpoint 1900638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97.13837
Policy Entropy: 4.23248
Value Function Loss: 1.27986

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07923
Policy Update Magnitude: 0.30136
Value Function Update Magnitude: 0.11136

Collected Steps per Second: 16,051.35973
Overall Steps per Second: 10,568.61114

Timestep Collection Time: 3.11625
Timestep Consumption Time: 1.61664
PPO Batch Consumption Time: 0.13260
Total Iteration Time: 4.73288

Cumulative Model Updates: 224
Cumulative Timesteps: 1,950,658

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.51097
Policy Entropy: 4.21916
Value Function Loss: 1.25976

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05403
Policy Update Magnitude: 0.30452
Value Function Update Magnitude: 0.10546

Collected Steps per Second: 15,595.03761
Overall Steps per Second: 10,491.04478

Timestep Collection Time: 3.20730
Timestep Consumption Time: 1.56038
PPO Batch Consumption Time: 0.12383
Total Iteration Time: 4.76769

Cumulative Model Updates: 230
Cumulative Timesteps: 2,000,676

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2000676...
Checkpoint 2000676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.01430
Policy Entropy: 4.20378
Value Function Loss: 1.23469

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06222
Policy Update Magnitude: 0.32123
Value Function Update Magnitude: 0.10193

Collected Steps per Second: 16,493.73621
Overall Steps per Second: 11,058.53137

Timestep Collection Time: 3.03158
Timestep Consumption Time: 1.49000
PPO Batch Consumption Time: 0.11589
Total Iteration Time: 4.52158

Cumulative Model Updates: 236
Cumulative Timesteps: 2,050,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.97072
Policy Entropy: 4.16854
Value Function Loss: 1.16873

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07534
Policy Update Magnitude: 0.29951
Value Function Update Magnitude: 0.09561

Collected Steps per Second: 15,792.76666
Overall Steps per Second: 10,970.56192

Timestep Collection Time: 3.16639
Timestep Consumption Time: 1.39181
PPO Batch Consumption Time: 0.11297
Total Iteration Time: 4.55820

Cumulative Model Updates: 242
Cumulative Timesteps: 2,100,684

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2100684...
Checkpoint 2100684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113.55925
Policy Entropy: 4.17557
Value Function Loss: 1.16213

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.04579
Policy Update Magnitude: 0.28681
Value Function Update Magnitude: 0.08642

Collected Steps per Second: 16,705.71836
Overall Steps per Second: 11,170.67604

Timestep Collection Time: 2.99466
Timestep Consumption Time: 1.48385
PPO Batch Consumption Time: 0.11309
Total Iteration Time: 4.47851

Cumulative Model Updates: 248
Cumulative Timesteps: 2,150,712

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.09055
Policy Entropy: 4.16142
Value Function Loss: 1.11578

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.04597
Policy Update Magnitude: 0.29729
Value Function Update Magnitude: 0.07850

Collected Steps per Second: 17,285.34592
Overall Steps per Second: 11,467.48721

Timestep Collection Time: 2.89436
Timestep Consumption Time: 1.46841
PPO Batch Consumption Time: 0.11312
Total Iteration Time: 4.36277

Cumulative Model Updates: 254
Cumulative Timesteps: 2,200,742

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2200742...
Checkpoint 2200742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113.30034
Policy Entropy: 4.13923
Value Function Loss: 1.09413

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.04899
Policy Update Magnitude: 0.29941
Value Function Update Magnitude: 0.07047

Collected Steps per Second: 17,355.82087
Overall Steps per Second: 11,507.17221

Timestep Collection Time: 2.88168
Timestep Consumption Time: 1.46465
PPO Batch Consumption Time: 0.11044
Total Iteration Time: 4.34633

Cumulative Model Updates: 260
Cumulative Timesteps: 2,250,756

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.61724
Policy Entropy: 4.11378
Value Function Loss: 1.10141

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.07051
Policy Update Magnitude: 0.30074
Value Function Update Magnitude: 0.06763

Collected Steps per Second: 17,118.98089
Overall Steps per Second: 11,258.44662

Timestep Collection Time: 2.92307
Timestep Consumption Time: 1.52159
PPO Batch Consumption Time: 0.12048
Total Iteration Time: 4.44466

Cumulative Model Updates: 266
Cumulative Timesteps: 2,300,796

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2300796...
Checkpoint 2300796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129.87148
Policy Entropy: 4.10613
Value Function Loss: 1.12474

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05120
Policy Update Magnitude: 0.29683
Value Function Update Magnitude: 0.07241

Collected Steps per Second: 16,246.14943
Overall Steps per Second: 11,224.31072

Timestep Collection Time: 3.07864
Timestep Consumption Time: 1.37740
PPO Batch Consumption Time: 0.11049
Total Iteration Time: 4.45604

Cumulative Model Updates: 272
Cumulative Timesteps: 2,350,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.91861
Policy Entropy: 4.07862
Value Function Loss: 1.07883

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.04867
Policy Update Magnitude: 0.30470
Value Function Update Magnitude: 0.07650

Collected Steps per Second: 17,606.71554
Overall Steps per Second: 11,619.18572

Timestep Collection Time: 2.84005
Timestep Consumption Time: 1.46352
PPO Batch Consumption Time: 0.11317
Total Iteration Time: 4.30357

Cumulative Model Updates: 278
Cumulative Timesteps: 2,400,816

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2400816...
Checkpoint 2400816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119.22377
Policy Entropy: 4.07659
Value Function Loss: 1.05030

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.03479
Policy Update Magnitude: 0.29909
Value Function Update Magnitude: 0.07187

Collected Steps per Second: 17,171.66345
Overall Steps per Second: 11,481.67862

Timestep Collection Time: 2.91224
Timestep Consumption Time: 1.44322
PPO Batch Consumption Time: 0.11261
Total Iteration Time: 4.35546

Cumulative Model Updates: 284
Cumulative Timesteps: 2,450,824

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.77617
Policy Entropy: 4.04697
Value Function Loss: 1.00759

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.04798
Policy Update Magnitude: 0.29279
Value Function Update Magnitude: 0.07491

Collected Steps per Second: 15,734.39857
Overall Steps per Second: 10,631.04714

Timestep Collection Time: 3.17839
Timestep Consumption Time: 1.52576
PPO Batch Consumption Time: 0.11658
Total Iteration Time: 4.70415

Cumulative Model Updates: 290
Cumulative Timesteps: 2,500,834

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2500834...
Checkpoint 2500834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145.04462
Policy Entropy: 4.03183
Value Function Loss: 1.01652

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09760
Policy Update Magnitude: 0.25212
Value Function Update Magnitude: 0.06791

Collected Steps per Second: 17,140.15082
Overall Steps per Second: 11,353.70091

Timestep Collection Time: 2.91783
Timestep Consumption Time: 1.48708
PPO Batch Consumption Time: 0.11276
Total Iteration Time: 4.40491

Cumulative Model Updates: 296
Cumulative Timesteps: 2,550,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.18230
Policy Entropy: 4.01851
Value Function Loss: 0.96117

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10798
Policy Update Magnitude: 0.20721
Value Function Update Magnitude: 0.06121

Collected Steps per Second: 16,665.40676
Overall Steps per Second: 11,188.15039

Timestep Collection Time: 3.00155
Timestep Consumption Time: 1.46943
PPO Batch Consumption Time: 0.11335
Total Iteration Time: 4.47098

Cumulative Model Updates: 302
Cumulative Timesteps: 2,600,868

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2600868...
Checkpoint 2600868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130.07308
Policy Entropy: 4.00786
Value Function Loss: 0.99299

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.04377
Policy Update Magnitude: 0.21208
Value Function Update Magnitude: 0.06529

Collected Steps per Second: 16,107.24357
Overall Steps per Second: 11,263.70873

Timestep Collection Time: 3.10593
Timestep Consumption Time: 1.33559
PPO Batch Consumption Time: 0.08899
Total Iteration Time: 4.44152

Cumulative Model Updates: 308
Cumulative Timesteps: 2,650,896

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.85734
Policy Entropy: 3.97699
Value Function Loss: 0.96852

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.05851
Policy Update Magnitude: 0.20630
Value Function Update Magnitude: 0.07238

Collected Steps per Second: 18,590.94990
Overall Steps per Second: 11,873.90936

Timestep Collection Time: 2.69077
Timestep Consumption Time: 1.52216
PPO Batch Consumption Time: 0.10250
Total Iteration Time: 4.21293

Cumulative Model Updates: 314
Cumulative Timesteps: 2,700,920

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2700920...
Checkpoint 2700920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152.96846
Policy Entropy: 3.97310
Value Function Loss: 0.95982

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.04496
Policy Update Magnitude: 0.21523
Value Function Update Magnitude: 0.07180

Collected Steps per Second: 19,833.96961
Overall Steps per Second: 12,767.04357

Timestep Collection Time: 2.52194
Timestep Consumption Time: 1.39596
PPO Batch Consumption Time: 0.10718
Total Iteration Time: 3.91790

Cumulative Model Updates: 320
Cumulative Timesteps: 2,750,940

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.56032
Policy Entropy: 3.94729
Value Function Loss: 0.95198

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.03498
Policy Update Magnitude: 0.22151
Value Function Update Magnitude: 0.07429

Collected Steps per Second: 19,900.58937
Overall Steps per Second: 12,688.20924

Timestep Collection Time: 2.51319
Timestep Consumption Time: 1.42858
PPO Batch Consumption Time: 0.10490
Total Iteration Time: 3.94177

Cumulative Model Updates: 326
Cumulative Timesteps: 2,800,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2800954...
Checkpoint 2800954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151.91174
Policy Entropy: 3.94150
Value Function Loss: 0.96670

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.06688
Policy Update Magnitude: 0.22011
Value Function Update Magnitude: 0.07733

Collected Steps per Second: 20,584.53479
Overall Steps per Second: 13,788.44709

Timestep Collection Time: 2.43027
Timestep Consumption Time: 1.19784
PPO Batch Consumption Time: 0.07674
Total Iteration Time: 3.62811

Cumulative Model Updates: 332
Cumulative Timesteps: 2,850,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.04072
Policy Entropy: 3.90646
Value Function Loss: 1.01092

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06381
Policy Update Magnitude: 0.20236
Value Function Update Magnitude: 0.07336

Collected Steps per Second: 22,495.31842
Overall Steps per Second: 14,053.85039

Timestep Collection Time: 2.22393
Timestep Consumption Time: 1.33581
PPO Batch Consumption Time: 0.09963
Total Iteration Time: 3.55974

Cumulative Model Updates: 338
Cumulative Timesteps: 2,901,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2901008...
Checkpoint 2901008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147.62381
Policy Entropy: 3.90736
Value Function Loss: 0.96453

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.04572
Policy Update Magnitude: 0.20803
Value Function Update Magnitude: 0.06943

Collected Steps per Second: 23,071.61638
Overall Steps per Second: 14,202.39860

Timestep Collection Time: 2.16925
Timestep Consumption Time: 1.35467
PPO Batch Consumption Time: 0.10106
Total Iteration Time: 3.52391

Cumulative Model Updates: 344
Cumulative Timesteps: 2,951,056

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.40762
Policy Entropy: 3.89550
Value Function Loss: 0.94424

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.05771
Policy Update Magnitude: 0.20163
Value Function Update Magnitude: 0.06214

Collected Steps per Second: 21,801.81831
Overall Steps per Second: 13,928.63878

Timestep Collection Time: 2.29366
Timestep Consumption Time: 1.29650
PPO Batch Consumption Time: 0.10096
Total Iteration Time: 3.59016

Cumulative Model Updates: 350
Cumulative Timesteps: 3,001,062

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3001062...
Checkpoint 3001062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163.63659
Policy Entropy: 3.87316
Value Function Loss: 0.89560

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.04871
Policy Update Magnitude: 0.19701
Value Function Update Magnitude: 0.06150

Collected Steps per Second: 23,325.15838
Overall Steps per Second: 14,383.71687

Timestep Collection Time: 2.14387
Timestep Consumption Time: 1.33270
PPO Batch Consumption Time: 0.09680
Total Iteration Time: 3.47657

Cumulative Model Updates: 356
Cumulative Timesteps: 3,051,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.65028
Policy Entropy: 3.86723
Value Function Loss: 0.88502

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.04048
Policy Update Magnitude: 0.19085
Value Function Update Magnitude: 0.06562

Collected Steps per Second: 21,838.53160
Overall Steps per Second: 13,896.71593

Timestep Collection Time: 2.29063
Timestep Consumption Time: 1.30907
PPO Batch Consumption Time: 0.09347
Total Iteration Time: 3.59970

Cumulative Model Updates: 362
Cumulative Timesteps: 3,101,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3101092...
Checkpoint 3101092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.30072
Policy Entropy: 3.85185
Value Function Loss: 0.87734

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07556
Policy Update Magnitude: 0.17382
Value Function Update Magnitude: 0.07072

Collected Steps per Second: 24,129.35116
Overall Steps per Second: 14,811.70614

Timestep Collection Time: 2.07233
Timestep Consumption Time: 1.30365
PPO Batch Consumption Time: 0.09099
Total Iteration Time: 3.37598

Cumulative Model Updates: 368
Cumulative Timesteps: 3,151,096

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.05222
Policy Entropy: 3.85809
Value Function Loss: 0.86662

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06692
Policy Update Magnitude: 0.17123
Value Function Update Magnitude: 0.06597

Collected Steps per Second: 23,625.84137
Overall Steps per Second: 14,098.38247

Timestep Collection Time: 2.11641
Timestep Consumption Time: 1.43024
PPO Batch Consumption Time: 0.10304
Total Iteration Time: 3.54665

Cumulative Model Updates: 374
Cumulative Timesteps: 3,201,098

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3201098...
Checkpoint 3201098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153.92732
Policy Entropy: 3.82623
Value Function Loss: 0.86796

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.08755
Policy Update Magnitude: 0.17015
Value Function Update Magnitude: 0.05669

Collected Steps per Second: 22,652.02082
Overall Steps per Second: 14,352.49000

Timestep Collection Time: 2.20828
Timestep Consumption Time: 1.27697
PPO Batch Consumption Time: 0.10139
Total Iteration Time: 3.48525

Cumulative Model Updates: 380
Cumulative Timesteps: 3,251,120

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.60755
Policy Entropy: 3.82677
Value Function Loss: 0.85087

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06848
Policy Update Magnitude: 0.15805
Value Function Update Magnitude: 0.05101

Collected Steps per Second: 23,114.23565
Overall Steps per Second: 14,285.01903

Timestep Collection Time: 2.16386
Timestep Consumption Time: 1.33743
PPO Batch Consumption Time: 0.09806
Total Iteration Time: 3.50129

Cumulative Model Updates: 386
Cumulative Timesteps: 3,301,136

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3301136...
Checkpoint 3301136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160.35277
Policy Entropy: 3.81632
Value Function Loss: 0.85005

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.15207
Value Function Update Magnitude: 0.05276

Collected Steps per Second: 22,697.16116
Overall Steps per Second: 14,487.14398

Timestep Collection Time: 2.20309
Timestep Consumption Time: 1.24852
PPO Batch Consumption Time: 0.07672
Total Iteration Time: 3.45161

Cumulative Model Updates: 392
Cumulative Timesteps: 3,351,140

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.84497
Policy Entropy: 3.80899
Value Function Loss: 0.84145

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07743
Policy Update Magnitude: 0.14152
Value Function Update Magnitude: 0.05425

Collected Steps per Second: 22,652.12134
Overall Steps per Second: 14,349.19507

Timestep Collection Time: 2.20827
Timestep Consumption Time: 1.27778
PPO Batch Consumption Time: 0.09860
Total Iteration Time: 3.48605

Cumulative Model Updates: 398
Cumulative Timesteps: 3,401,162

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3401162...
Checkpoint 3401162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147.10724
Policy Entropy: 3.80073
Value Function Loss: 0.84161

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.05666
Policy Update Magnitude: 0.15077
Value Function Update Magnitude: 0.05018

Collected Steps per Second: 22,657.12659
Overall Steps per Second: 13,671.02557

Timestep Collection Time: 2.20831
Timestep Consumption Time: 1.45155
PPO Batch Consumption Time: 0.11813
Total Iteration Time: 3.65986

Cumulative Model Updates: 404
Cumulative Timesteps: 3,451,196

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.27093
Policy Entropy: 3.78174
Value Function Loss: 0.84362

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.10551
Policy Update Magnitude: 0.14144
Value Function Update Magnitude: 0.05188

Collected Steps per Second: 21,317.68463
Overall Steps per Second: 13,516.51506

Timestep Collection Time: 2.34707
Timestep Consumption Time: 1.35463
PPO Batch Consumption Time: 0.10229
Total Iteration Time: 3.70169

Cumulative Model Updates: 410
Cumulative Timesteps: 3,501,230

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 3501230...
Checkpoint 3501230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.66755
Policy Entropy: 3.76886
Value Function Loss: 0.79946

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08484
Policy Update Magnitude: 0.13337
Value Function Update Magnitude: 0.05455

Collected Steps per Second: 19,783.82763
Overall Steps per Second: 12,631.61052

Timestep Collection Time: 2.52873
Timestep Consumption Time: 1.43181
PPO Batch Consumption Time: 0.10283
Total Iteration Time: 3.96054

Cumulative Model Updates: 416
Cumulative Timesteps: 3,551,258

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.09508
Policy Entropy: 3.76420
Value Function Loss: 0.77695

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08145
Policy Update Magnitude: 0.13513
Value Function Update Magnitude: 0.05599

Collected Steps per Second: 23,708.13465
Overall Steps per Second: 14,525.24985

Timestep Collection Time: 2.10974
Timestep Consumption Time: 1.33378
PPO Batch Consumption Time: 0.09456
Total Iteration Time: 3.44352

Cumulative Model Updates: 422
Cumulative Timesteps: 3,601,276

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3601276...
Checkpoint 3601276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.65891
Policy Entropy: 3.74403
Value Function Loss: 0.73324

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.10026
Policy Update Magnitude: 0.12647
Value Function Update Magnitude: 0.05161

Collected Steps per Second: 21,110.84921
Overall Steps per Second: 13,617.78070

Timestep Collection Time: 2.37110
Timestep Consumption Time: 1.30468
PPO Batch Consumption Time: 0.10055
Total Iteration Time: 3.67578

Cumulative Model Updates: 428
Cumulative Timesteps: 3,651,332

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.86255
Policy Entropy: 3.76217
Value Function Loss: 0.77082

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.06405
Policy Update Magnitude: 0.12177
Value Function Update Magnitude: 0.04885

Collected Steps per Second: 23,653.22349
Overall Steps per Second: 14,508.38343

Timestep Collection Time: 2.11498
Timestep Consumption Time: 1.33310
PPO Batch Consumption Time: 0.09711
Total Iteration Time: 3.44808

Cumulative Model Updates: 434
Cumulative Timesteps: 3,701,358

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3701358...
Checkpoint 3701358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.02291
Policy Entropy: 3.74133
Value Function Loss: 0.78303

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.06511
Policy Update Magnitude: 0.12667
Value Function Update Magnitude: 0.05904

Collected Steps per Second: 23,250.24388
Overall Steps per Second: 14,422.31813

Timestep Collection Time: 2.15103
Timestep Consumption Time: 1.31665
PPO Batch Consumption Time: 0.10124
Total Iteration Time: 3.46768

Cumulative Model Updates: 440
Cumulative Timesteps: 3,751,370

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.88206
Policy Entropy: 3.72926
Value Function Loss: 0.82136

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.06341
Policy Update Magnitude: 0.13462
Value Function Update Magnitude: 0.06045

Collected Steps per Second: 23,309.47679
Overall Steps per Second: 14,219.59602

Timestep Collection Time: 2.14539
Timestep Consumption Time: 1.37144
PPO Batch Consumption Time: 0.09912
Total Iteration Time: 3.51684

Cumulative Model Updates: 446
Cumulative Timesteps: 3,801,378

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3801378...
Checkpoint 3801378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.93579
Policy Entropy: 3.71873
Value Function Loss: 0.84354

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.03727
Policy Update Magnitude: 0.14485
Value Function Update Magnitude: 0.06201

Collected Steps per Second: 19,860.68372
Overall Steps per Second: 12,772.53502

Timestep Collection Time: 2.51804
Timestep Consumption Time: 1.39739
PPO Batch Consumption Time: 0.10226
Total Iteration Time: 3.91543

Cumulative Model Updates: 452
Cumulative Timesteps: 3,851,388

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.07316
Policy Entropy: 3.69302
Value Function Loss: 0.83344

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06560
Policy Update Magnitude: 0.15172
Value Function Update Magnitude: 0.06795

Collected Steps per Second: 20,949.75080
Overall Steps per Second: 13,866.71260

Timestep Collection Time: 2.38733
Timestep Consumption Time: 1.21944
PPO Batch Consumption Time: 0.07575
Total Iteration Time: 3.60677

Cumulative Model Updates: 458
Cumulative Timesteps: 3,901,402

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3901402...
Checkpoint 3901402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.69007
Policy Entropy: 3.68304
Value Function Loss: 0.83753

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.05527
Policy Update Magnitude: 0.14947
Value Function Update Magnitude: 0.06936

Collected Steps per Second: 20,511.32620
Overall Steps per Second: 13,279.17801

Timestep Collection Time: 2.43934
Timestep Consumption Time: 1.32852
PPO Batch Consumption Time: 0.09187
Total Iteration Time: 3.76785

Cumulative Model Updates: 464
Cumulative Timesteps: 3,951,436

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.97913
Policy Entropy: 3.69112
Value Function Loss: 0.83209

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06124
Policy Update Magnitude: 0.13568
Value Function Update Magnitude: 0.06420

Collected Steps per Second: 23,532.67149
Overall Steps per Second: 14,247.50452

Timestep Collection Time: 2.12505
Timestep Consumption Time: 1.38490
PPO Batch Consumption Time: 0.10523
Total Iteration Time: 3.50995

Cumulative Model Updates: 470
Cumulative Timesteps: 4,001,444

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 4001444...
Checkpoint 4001444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.84082
Policy Entropy: 3.70416
Value Function Loss: 0.85096

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.04641
Policy Update Magnitude: 0.12927
Value Function Update Magnitude: 0.06658

Collected Steps per Second: 22,208.09253
Overall Steps per Second: 14,424.38460

Timestep Collection Time: 2.25278
Timestep Consumption Time: 1.21565
PPO Batch Consumption Time: 0.09258
Total Iteration Time: 3.46843

Cumulative Model Updates: 476
Cumulative Timesteps: 4,051,474

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.31738
Policy Entropy: 3.71343
Value Function Loss: 0.86472

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.04627
Policy Update Magnitude: 0.13792
Value Function Update Magnitude: 0.06617

Collected Steps per Second: 22,864.15479
Overall Steps per Second: 14,057.62587

Timestep Collection Time: 2.18762
Timestep Consumption Time: 1.37045
PPO Batch Consumption Time: 0.10304
Total Iteration Time: 3.55807

Cumulative Model Updates: 482
Cumulative Timesteps: 4,101,492

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 4101492...
Checkpoint 4101492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.93501
Policy Entropy: 3.69528
Value Function Loss: 0.87646

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05148
Policy Update Magnitude: 0.14321
Value Function Update Magnitude: 0.06566

Collected Steps per Second: 23,523.40839
Overall Steps per Second: 14,301.12002

Timestep Collection Time: 2.12665
Timestep Consumption Time: 1.37140
PPO Batch Consumption Time: 0.10202
Total Iteration Time: 3.49805

Cumulative Model Updates: 488
Cumulative Timesteps: 4,151,518

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.31194
Policy Entropy: 3.69866
Value Function Loss: 0.97352

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.09113
Policy Update Magnitude: 0.16008
Value Function Update Magnitude: 0.06681

Collected Steps per Second: 24,303.47567
Overall Steps per Second: 14,682.74759

Timestep Collection Time: 2.05740
Timestep Consumption Time: 1.34809
PPO Batch Consumption Time: 0.10123
Total Iteration Time: 3.40549

Cumulative Model Updates: 494
Cumulative Timesteps: 4,201,520

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 4201520...
Checkpoint 4201520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155.75766
Policy Entropy: 3.67991
Value Function Loss: 1.00929

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.07308
Policy Update Magnitude: 0.15102
Value Function Update Magnitude: 0.06630

Collected Steps per Second: 22,965.30974
Overall Steps per Second: 14,150.77909

Timestep Collection Time: 2.17755
Timestep Consumption Time: 1.35639
PPO Batch Consumption Time: 0.10167
Total Iteration Time: 3.53394

Cumulative Model Updates: 500
Cumulative Timesteps: 4,251,528

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.36843
Policy Entropy: 3.67238
Value Function Loss: 1.01703

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.05586
Policy Update Magnitude: 0.14303
Value Function Update Magnitude: 0.06421

Collected Steps per Second: 23,366.96790
Overall Steps per Second: 14,525.13168

Timestep Collection Time: 2.14071
Timestep Consumption Time: 1.30311
PPO Batch Consumption Time: 0.10062
Total Iteration Time: 3.44382

Cumulative Model Updates: 506
Cumulative Timesteps: 4,301,550

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 4301550...
Checkpoint 4301550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.61072
Policy Entropy: 3.63867
Value Function Loss: 0.91636

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.08367
Policy Update Magnitude: 0.14287
Value Function Update Magnitude: 0.06068

Collected Steps per Second: 23,376.35483
Overall Steps per Second: 14,541.82874

Timestep Collection Time: 2.13943
Timestep Consumption Time: 1.29976
PPO Batch Consumption Time: 0.09312
Total Iteration Time: 3.43918

Cumulative Model Updates: 512
Cumulative Timesteps: 4,351,562

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.72324
Policy Entropy: 3.65188
Value Function Loss: 0.84360

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.05946
Policy Update Magnitude: 0.14362
Value Function Update Magnitude: 0.05582

Collected Steps per Second: 23,341.75650
Overall Steps per Second: 14,416.40100

Timestep Collection Time: 2.14345
Timestep Consumption Time: 1.32704
PPO Batch Consumption Time: 0.10082
Total Iteration Time: 3.47049

Cumulative Model Updates: 518
Cumulative Timesteps: 4,401,594

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 4401594...
Checkpoint 4401594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164.02447
Policy Entropy: 3.60725
Value Function Loss: 0.88605

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.08067
Policy Update Magnitude: 0.12951
Value Function Update Magnitude: 0.05429

Collected Steps per Second: 23,767.64730
Overall Steps per Second: 14,427.70091

Timestep Collection Time: 2.10437
Timestep Consumption Time: 1.36229
PPO Batch Consumption Time: 0.09777
Total Iteration Time: 3.46666

Cumulative Model Updates: 524
Cumulative Timesteps: 4,451,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.36491
Policy Entropy: 3.59095
Value Function Loss: 0.89251

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07125
Policy Update Magnitude: 0.13377
Value Function Update Magnitude: 0.05583

Collected Steps per Second: 23,641.83308
Overall Steps per Second: 14,380.80601

Timestep Collection Time: 2.11549
Timestep Consumption Time: 1.36234
PPO Batch Consumption Time: 0.10051
Total Iteration Time: 3.47783

Cumulative Model Updates: 530
Cumulative Timesteps: 4,501,624

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 4501624...
Checkpoint 4501624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.37678
Policy Entropy: 3.59825
Value Function Loss: 0.90446

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.05464
Policy Update Magnitude: 0.14875
Value Function Update Magnitude: 0.05746

Collected Steps per Second: 22,354.11651
Overall Steps per Second: 14,364.68346

Timestep Collection Time: 2.23816
Timestep Consumption Time: 1.24483
PPO Batch Consumption Time: 0.09430
Total Iteration Time: 3.48299

Cumulative Model Updates: 536
Cumulative Timesteps: 4,551,656

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.67878
Policy Entropy: 3.54971
Value Function Loss: 0.84136

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08363
Policy Update Magnitude: 0.13141
Value Function Update Magnitude: 0.05704

Collected Steps per Second: 23,560.78320
Overall Steps per Second: 14,297.50791

Timestep Collection Time: 2.12243
Timestep Consumption Time: 1.37511
PPO Batch Consumption Time: 0.10000
Total Iteration Time: 3.49753

Cumulative Model Updates: 542
Cumulative Timesteps: 4,601,662

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 4601662...
Checkpoint 4601662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.00305
Policy Entropy: 3.54003
Value Function Loss: 0.88964

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07330
Policy Update Magnitude: 0.13490
Value Function Update Magnitude: 0.06206

Collected Steps per Second: 23,252.99899
Overall Steps per Second: 14,515.36781

Timestep Collection Time: 2.15129
Timestep Consumption Time: 1.29499
PPO Batch Consumption Time: 0.09796
Total Iteration Time: 3.44628

Cumulative Model Updates: 548
Cumulative Timesteps: 4,651,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.26465
Policy Entropy: 3.50331
Value Function Loss: 0.92048

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.06439
Policy Update Magnitude: 0.13213
Value Function Update Magnitude: 0.06178

Collected Steps per Second: 24,083.09496
Overall Steps per Second: 14,680.31980

Timestep Collection Time: 2.07648
Timestep Consumption Time: 1.32999
PPO Batch Consumption Time: 0.09846
Total Iteration Time: 3.40647

Cumulative Model Updates: 554
Cumulative Timesteps: 4,701,694

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 4701694...
Checkpoint 4701694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.21224
Policy Entropy: 3.49912
Value Function Loss: 1.04011

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.05780
Policy Update Magnitude: 0.13729
Value Function Update Magnitude: 0.06732

Collected Steps per Second: 23,421.79038
Overall Steps per Second: 14,118.39143

Timestep Collection Time: 2.13673
Timestep Consumption Time: 1.40801
PPO Batch Consumption Time: 0.10341
Total Iteration Time: 3.54474

Cumulative Model Updates: 560
Cumulative Timesteps: 4,751,740

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.27287
Policy Entropy: 3.50807
Value Function Loss: 1.11300

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07541
Policy Update Magnitude: 0.14427
Value Function Update Magnitude: 0.07839

Collected Steps per Second: 23,450.42966
Overall Steps per Second: 14,608.74891

Timestep Collection Time: 2.13275
Timestep Consumption Time: 1.29081
PPO Batch Consumption Time: 0.09410
Total Iteration Time: 3.42356

Cumulative Model Updates: 566
Cumulative Timesteps: 4,801,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 4801754...
Checkpoint 4801754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.82407
Policy Entropy: 3.47274
Value Function Loss: 1.19829

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06545
Policy Update Magnitude: 0.15483
Value Function Update Magnitude: 0.08570

Collected Steps per Second: 23,701.88801
Overall Steps per Second: 14,484.77187

Timestep Collection Time: 2.11131
Timestep Consumption Time: 1.34349
PPO Batch Consumption Time: 0.10049
Total Iteration Time: 3.45480

Cumulative Model Updates: 572
Cumulative Timesteps: 4,851,796

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.30536
Policy Entropy: 3.47436
Value Function Loss: 1.20991

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.05615
Policy Update Magnitude: 0.16196
Value Function Update Magnitude: 0.07613

Collected Steps per Second: 23,363.17850
Overall Steps per Second: 14,319.91813

Timestep Collection Time: 2.14080
Timestep Consumption Time: 1.35195
PPO Batch Consumption Time: 0.09739
Total Iteration Time: 3.49276

Cumulative Model Updates: 578
Cumulative Timesteps: 4,901,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 4901812...
Checkpoint 4901812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164.06168
Policy Entropy: 3.40623
Value Function Loss: 1.27102

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08626
Policy Update Magnitude: 0.15375
Value Function Update Magnitude: 0.08169

Collected Steps per Second: 23,384.74879
Overall Steps per Second: 14,823.58942

Timestep Collection Time: 2.13849
Timestep Consumption Time: 1.23505
PPO Batch Consumption Time: 0.09536
Total Iteration Time: 3.37354

Cumulative Model Updates: 584
Cumulative Timesteps: 4,951,820

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.76881
Policy Entropy: 3.40626
Value Function Loss: 1.26267

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05565
Policy Update Magnitude: 0.16411
Value Function Update Magnitude: 0.08613

Collected Steps per Second: 23,281.75434
Overall Steps per Second: 14,213.27957

Timestep Collection Time: 2.14795
Timestep Consumption Time: 1.37045
PPO Batch Consumption Time: 0.10312
Total Iteration Time: 3.51840

Cumulative Model Updates: 590
Cumulative Timesteps: 5,001,828

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 5001828...
Checkpoint 5001828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172.48774
Policy Entropy: 3.37643
Value Function Loss: 1.24502

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.10145
Policy Update Magnitude: 0.16423
Value Function Update Magnitude: 0.07399

Collected Steps per Second: 23,523.78913
Overall Steps per Second: 14,498.75905

Timestep Collection Time: 2.12670
Timestep Consumption Time: 1.32380
PPO Batch Consumption Time: 0.09100
Total Iteration Time: 3.45050

Cumulative Model Updates: 596
Cumulative Timesteps: 5,051,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.77956
Policy Entropy: 3.38087
Value Function Loss: 1.21025

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.15764
Policy Update Magnitude: 0.14897
Value Function Update Magnitude: 0.07130

Collected Steps per Second: 24,480.37071
Overall Steps per Second: 14,820.87015

Timestep Collection Time: 2.04376
Timestep Consumption Time: 1.33202
PPO Batch Consumption Time: 0.09574
Total Iteration Time: 3.37578

Cumulative Model Updates: 602
Cumulative Timesteps: 5,101,888

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 5101888...
Checkpoint 5101888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172.15048
Policy Entropy: 3.37723
Value Function Loss: 1.14955

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.16567
Policy Update Magnitude: 0.14036
Value Function Update Magnitude: 0.07473

Collected Steps per Second: 22,910.89168
Overall Steps per Second: 14,093.23883

Timestep Collection Time: 2.18298
Timestep Consumption Time: 1.36581
PPO Batch Consumption Time: 0.10218
Total Iteration Time: 3.54879

Cumulative Model Updates: 608
Cumulative Timesteps: 5,151,902

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.88961
Policy Entropy: 3.36019
Value Function Loss: 1.15230

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.12153
Policy Update Magnitude: 0.13194
Value Function Update Magnitude: 0.08238

Collected Steps per Second: 23,697.31469
Overall Steps per Second: 14,573.08137

Timestep Collection Time: 2.11020
Timestep Consumption Time: 1.32120
PPO Batch Consumption Time: 0.09514
Total Iteration Time: 3.43140

Cumulative Model Updates: 614
Cumulative Timesteps: 5,201,908

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 5201908...
Checkpoint 5201908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.83913
Policy Entropy: 3.36100
Value Function Loss: 1.12743

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.08040
Policy Update Magnitude: 0.14191
Value Function Update Magnitude: 0.08029

Collected Steps per Second: 24,382.24469
Overall Steps per Second: 14,874.93027

Timestep Collection Time: 2.05264
Timestep Consumption Time: 1.31195
PPO Batch Consumption Time: 0.09268
Total Iteration Time: 3.36459

Cumulative Model Updates: 620
Cumulative Timesteps: 5,251,956

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.43384
Policy Entropy: 3.30451
Value Function Loss: 1.18096

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.09734
Policy Update Magnitude: 0.14718
Value Function Update Magnitude: 0.08091

Collected Steps per Second: 23,591.94038
Overall Steps per Second: 14,756.07655

Timestep Collection Time: 2.11988
Timestep Consumption Time: 1.26937
PPO Batch Consumption Time: 0.09181
Total Iteration Time: 3.38925

Cumulative Model Updates: 626
Cumulative Timesteps: 5,301,968

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 5301968...
Checkpoint 5301968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.13581
Policy Entropy: 3.32252
Value Function Loss: 1.22109

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.08071
Policy Update Magnitude: 0.14686
Value Function Update Magnitude: 0.07906

Collected Steps per Second: 23,340.37278
Overall Steps per Second: 14,391.75621

Timestep Collection Time: 2.14264
Timestep Consumption Time: 1.33227
PPO Batch Consumption Time: 0.10138
Total Iteration Time: 3.47491

Cumulative Model Updates: 632
Cumulative Timesteps: 5,351,978

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.79682
Policy Entropy: 3.32148
Value Function Loss: 1.40719

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07750
Policy Update Magnitude: 0.15331
Value Function Update Magnitude: 0.09519

Collected Steps per Second: 24,113.18539
Overall Steps per Second: 14,586.98399

Timestep Collection Time: 2.07389
Timestep Consumption Time: 1.35438
PPO Batch Consumption Time: 0.10313
Total Iteration Time: 3.42826

Cumulative Model Updates: 638
Cumulative Timesteps: 5,401,986

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 5401986...
Checkpoint 5401986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.44531
Policy Entropy: 3.32458
Value Function Loss: 1.57168

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07163
Policy Update Magnitude: 0.15293
Value Function Update Magnitude: 0.09627

Collected Steps per Second: 22,559.63430
Overall Steps per Second: 14,119.11800

Timestep Collection Time: 2.21670
Timestep Consumption Time: 1.32516
PPO Batch Consumption Time: 0.10048
Total Iteration Time: 3.54186

Cumulative Model Updates: 644
Cumulative Timesteps: 5,451,994

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.52975
Policy Entropy: 3.28815
Value Function Loss: 1.73945

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06092
Policy Update Magnitude: 0.16615
Value Function Update Magnitude: 0.09216

Collected Steps per Second: 24,485.96150
Overall Steps per Second: 14,547.86809

Timestep Collection Time: 2.04272
Timestep Consumption Time: 1.39545
PPO Batch Consumption Time: 0.09897
Total Iteration Time: 3.43817

Cumulative Model Updates: 650
Cumulative Timesteps: 5,502,012

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 5502012...
Checkpoint 5502012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.06321
Policy Entropy: 3.31650
Value Function Loss: 1.75232

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07453
Policy Update Magnitude: 0.16143
Value Function Update Magnitude: 0.08384

Collected Steps per Second: 23,624.00427
Overall Steps per Second: 14,347.33320

Timestep Collection Time: 2.11675
Timestep Consumption Time: 1.36864
PPO Batch Consumption Time: 0.10178
Total Iteration Time: 3.48539

Cumulative Model Updates: 656
Cumulative Timesteps: 5,552,018

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.98752
Policy Entropy: 3.29475
Value Function Loss: 1.94038

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.09051
Policy Update Magnitude: 0.15361
Value Function Update Magnitude: 0.09259

Collected Steps per Second: 22,738.06296
Overall Steps per Second: 14,304.28255

Timestep Collection Time: 2.20001
Timestep Consumption Time: 1.29712
PPO Batch Consumption Time: 0.09622
Total Iteration Time: 3.49713

Cumulative Model Updates: 662
Cumulative Timesteps: 5,602,042

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 5602042...
Checkpoint 5602042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156.18520
Policy Entropy: 3.28035
Value Function Loss: 2.02759

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.09346
Policy Update Magnitude: 0.15144
Value Function Update Magnitude: 0.09366

Collected Steps per Second: 23,634.00446
Overall Steps per Second: 14,416.20580

Timestep Collection Time: 2.11568
Timestep Consumption Time: 1.35278
PPO Batch Consumption Time: 0.10144
Total Iteration Time: 3.46846

Cumulative Model Updates: 668
Cumulative Timesteps: 5,652,044

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.24771
Policy Entropy: 3.26576
Value Function Loss: 2.00544

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.11375
Policy Update Magnitude: 0.14506
Value Function Update Magnitude: 0.10764

Collected Steps per Second: 23,915.91036
Overall Steps per Second: 14,547.90711

Timestep Collection Time: 2.09241
Timestep Consumption Time: 1.34739
PPO Batch Consumption Time: 0.10323
Total Iteration Time: 3.43981

Cumulative Model Updates: 674
Cumulative Timesteps: 5,702,086

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 5702086...
Checkpoint 5702086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.87980
Policy Entropy: 3.26595
Value Function Loss: 1.98226

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.08114
Policy Update Magnitude: 0.14871
Value Function Update Magnitude: 0.10629

Collected Steps per Second: 22,650.54591
Overall Steps per Second: 14,625.31833

Timestep Collection Time: 2.20816
Timestep Consumption Time: 1.21166
PPO Batch Consumption Time: 0.09287
Total Iteration Time: 3.41982

Cumulative Model Updates: 680
Cumulative Timesteps: 5,752,102

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.41765
Policy Entropy: 3.23791
Value Function Loss: 1.93662

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.10591
Policy Update Magnitude: 0.15624
Value Function Update Magnitude: 0.10738

Collected Steps per Second: 23,829.17947
Overall Steps per Second: 14,420.42411

Timestep Collection Time: 2.09936
Timestep Consumption Time: 1.36975
PPO Batch Consumption Time: 0.10292
Total Iteration Time: 3.46911

Cumulative Model Updates: 686
Cumulative Timesteps: 5,802,128

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 5802128...
Checkpoint 5802128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.47025
Policy Entropy: 3.22570
Value Function Loss: 1.96308

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.15356
Policy Update Magnitude: 0.15045
Value Function Update Magnitude: 0.09821

Collected Steps per Second: 23,403.00206
Overall Steps per Second: 14,462.56203

Timestep Collection Time: 2.13656
Timestep Consumption Time: 1.32078
PPO Batch Consumption Time: 0.09912
Total Iteration Time: 3.45734

Cumulative Model Updates: 692
Cumulative Timesteps: 5,852,130

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.74826
Policy Entropy: 3.21303
Value Function Loss: 1.80411

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.12641
Policy Update Magnitude: 0.14552
Value Function Update Magnitude: 0.10016

Collected Steps per Second: 24,186.99606
Overall Steps per Second: 14,730.51662

Timestep Collection Time: 2.06747
Timestep Consumption Time: 1.32725
PPO Batch Consumption Time: 0.09801
Total Iteration Time: 3.39472

Cumulative Model Updates: 698
Cumulative Timesteps: 5,902,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 5902136...
Checkpoint 5902136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.77786
Policy Entropy: 3.23016
Value Function Loss: 1.69011

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07278
Policy Update Magnitude: 0.13878
Value Function Update Magnitude: 0.09118

Collected Steps per Second: 22,650.19199
Overall Steps per Second: 13,898.35492

Timestep Collection Time: 2.20863
Timestep Consumption Time: 1.39078
PPO Batch Consumption Time: 0.09452
Total Iteration Time: 3.59942

Cumulative Model Updates: 704
Cumulative Timesteps: 5,952,162

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.33694
Policy Entropy: 3.22893
Value Function Loss: 1.60466

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.09313
Policy Update Magnitude: 0.13473
Value Function Update Magnitude: 0.09093

Collected Steps per Second: 23,601.19103
Overall Steps per Second: 14,732.15561

Timestep Collection Time: 2.11905
Timestep Consumption Time: 1.27571
PPO Batch Consumption Time: 0.09298
Total Iteration Time: 3.39475

Cumulative Model Updates: 710
Cumulative Timesteps: 6,002,174

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 6002174...
Checkpoint 6002174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.32320
Policy Entropy: 3.19459
Value Function Loss: 1.69307

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08486
Policy Update Magnitude: 0.13863
Value Function Update Magnitude: 0.09948

Collected Steps per Second: 23,650.76331
Overall Steps per Second: 14,410.92948

Timestep Collection Time: 2.11427
Timestep Consumption Time: 1.35560
PPO Batch Consumption Time: 0.10181
Total Iteration Time: 3.46987

Cumulative Model Updates: 716
Cumulative Timesteps: 6,052,178

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.50679
Policy Entropy: 3.18942
Value Function Loss: 1.83645

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.05891
Policy Update Magnitude: 0.15498
Value Function Update Magnitude: 0.11281

Collected Steps per Second: 23,680.37172
Overall Steps per Second: 14,478.89724

Timestep Collection Time: 2.11154
Timestep Consumption Time: 1.34190
PPO Batch Consumption Time: 0.10020
Total Iteration Time: 3.45344

Cumulative Model Updates: 722
Cumulative Timesteps: 6,102,180

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 6102180...
Checkpoint 6102180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.83011
Policy Entropy: 3.17088
Value Function Loss: 1.96694

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.07847
Policy Update Magnitude: 0.16665
Value Function Update Magnitude: 0.12862

Collected Steps per Second: 23,358.41292
Overall Steps per Second: 14,714.81487

Timestep Collection Time: 2.14176
Timestep Consumption Time: 1.25808
PPO Batch Consumption Time: 0.09217
Total Iteration Time: 3.39984

Cumulative Model Updates: 728
Cumulative Timesteps: 6,152,208

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.63980
Policy Entropy: 3.16159
Value Function Loss: 2.05165

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.10138
Policy Update Magnitude: 0.17528
Value Function Update Magnitude: 0.14195

Collected Steps per Second: 22,981.73731
Overall Steps per Second: 14,186.04350

Timestep Collection Time: 2.17677
Timestep Consumption Time: 1.34965
PPO Batch Consumption Time: 0.10246
Total Iteration Time: 3.52642

Cumulative Model Updates: 734
Cumulative Timesteps: 6,202,234

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 6202234...
Checkpoint 6202234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.20410
Policy Entropy: 3.12151
Value Function Loss: 1.95620

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14463
Policy Update Magnitude: 0.15049
Value Function Update Magnitude: 0.14991

Collected Steps per Second: 23,818.33377
Overall Steps per Second: 14,619.78860

Timestep Collection Time: 2.09989
Timestep Consumption Time: 1.32122
PPO Batch Consumption Time: 0.09713
Total Iteration Time: 3.42112

Cumulative Model Updates: 740
Cumulative Timesteps: 6,252,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.27979
Policy Entropy: 3.09771
Value Function Loss: 1.90021

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.13867
Value Function Update Magnitude: 0.15069

Collected Steps per Second: 24,374.05250
Overall Steps per Second: 14,772.99374

Timestep Collection Time: 2.05153
Timestep Consumption Time: 1.33330
PPO Batch Consumption Time: 0.09664
Total Iteration Time: 3.38483

Cumulative Model Updates: 746
Cumulative Timesteps: 6,302,254

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 6302254...
Checkpoint 6302254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147.07468
Policy Entropy: 3.07363
Value Function Loss: 1.84046

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08363
Policy Update Magnitude: 0.15034
Value Function Update Magnitude: 0.13070

Collected Steps per Second: 22,874.20468
Overall Steps per Second: 14,107.80778

Timestep Collection Time: 2.18700
Timestep Consumption Time: 1.35897
PPO Batch Consumption Time: 0.09832
Total Iteration Time: 3.54598

Cumulative Model Updates: 752
Cumulative Timesteps: 6,352,280

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.90286
Policy Entropy: 3.06129
Value Function Loss: 1.99661

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08325
Policy Update Magnitude: 0.16441
Value Function Update Magnitude: 0.13083

Collected Steps per Second: 23,529.24016
Overall Steps per Second: 14,711.42313

Timestep Collection Time: 2.12527
Timestep Consumption Time: 1.27386
PPO Batch Consumption Time: 0.09982
Total Iteration Time: 3.39913

Cumulative Model Updates: 758
Cumulative Timesteps: 6,402,286

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 6402286...
Checkpoint 6402286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.06337
Policy Entropy: 3.05129
Value Function Loss: 2.01731

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11881
Policy Update Magnitude: 0.14961
Value Function Update Magnitude: 0.14792

Collected Steps per Second: 23,769.17549
Overall Steps per Second: 14,701.02664

Timestep Collection Time: 2.10542
Timestep Consumption Time: 1.29870
PPO Batch Consumption Time: 0.09204
Total Iteration Time: 3.40412

Cumulative Model Updates: 764
Cumulative Timesteps: 6,452,330

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.63549
Policy Entropy: 3.03038
Value Function Loss: 1.95345

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06401
Policy Update Magnitude: 0.14532
Value Function Update Magnitude: 0.15437

Collected Steps per Second: 23,086.48044
Overall Steps per Second: 14,169.66047

Timestep Collection Time: 2.16603
Timestep Consumption Time: 1.36306
PPO Batch Consumption Time: 0.10350
Total Iteration Time: 3.52909

Cumulative Model Updates: 770
Cumulative Timesteps: 6,502,336

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 6502336...
Checkpoint 6502336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.52721
Policy Entropy: 3.00491
Value Function Loss: 1.93547

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07707
Policy Update Magnitude: 0.15444
Value Function Update Magnitude: 0.14273

Collected Steps per Second: 23,700.32577
Overall Steps per Second: 14,751.52301

Timestep Collection Time: 2.11060
Timestep Consumption Time: 1.28037
PPO Batch Consumption Time: 0.10158
Total Iteration Time: 3.39097

Cumulative Model Updates: 776
Cumulative Timesteps: 6,552,358

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.65401
Policy Entropy: 2.97545
Value Function Loss: 1.98880

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.12494
Policy Update Magnitude: 0.15914
Value Function Update Magnitude: 0.14390

Collected Steps per Second: 23,825.28745
Overall Steps per Second: 14,628.50769

Timestep Collection Time: 2.09886
Timestep Consumption Time: 1.31953
PPO Batch Consumption Time: 0.09338
Total Iteration Time: 3.41839

Cumulative Model Updates: 782
Cumulative Timesteps: 6,602,364

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 6602364...
Checkpoint 6602364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.69523
Policy Entropy: 2.96647
Value Function Loss: 2.12074

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06550
Policy Update Magnitude: 0.15080
Value Function Update Magnitude: 0.17372

Collected Steps per Second: 23,159.00500
Overall Steps per Second: 14,284.75027

Timestep Collection Time: 2.15899
Timestep Consumption Time: 1.34125
PPO Batch Consumption Time: 0.10219
Total Iteration Time: 3.50024

Cumulative Model Updates: 788
Cumulative Timesteps: 6,652,364

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.84770
Policy Entropy: 2.95033
Value Function Loss: 2.04591

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07527
Policy Update Magnitude: 0.16562
Value Function Update Magnitude: 0.17420

Collected Steps per Second: 24,455.12776
Overall Steps per Second: 14,617.88910

Timestep Collection Time: 2.04587
Timestep Consumption Time: 1.37679
PPO Batch Consumption Time: 0.10297
Total Iteration Time: 3.42266

Cumulative Model Updates: 794
Cumulative Timesteps: 6,702,396

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 6702396...
Checkpoint 6702396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.06664
Policy Entropy: 2.91409
Value Function Loss: 2.11973

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 0.16404
Value Function Update Magnitude: 0.14781

Collected Steps per Second: 23,257.16455
Overall Steps per Second: 14,228.75675

Timestep Collection Time: 2.15065
Timestep Consumption Time: 1.36463
PPO Batch Consumption Time: 0.10224
Total Iteration Time: 3.51528

Cumulative Model Updates: 800
Cumulative Timesteps: 6,752,414

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.46778
Policy Entropy: 2.93110
Value Function Loss: 2.12373

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.05911
Policy Update Magnitude: 0.17997
Value Function Update Magnitude: 0.14532

Collected Steps per Second: 22,329.48721
Overall Steps per Second: 14,385.62264

Timestep Collection Time: 2.24000
Timestep Consumption Time: 1.23695
PPO Batch Consumption Time: 0.09469
Total Iteration Time: 3.47694

Cumulative Model Updates: 806
Cumulative Timesteps: 6,802,432

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 6802432...
Checkpoint 6802432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164.61130
Policy Entropy: 2.87427
Value Function Loss: 2.19583

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.06568
Policy Update Magnitude: 0.19191
Value Function Update Magnitude: 0.13898

Collected Steps per Second: 23,575.38962
Overall Steps per Second: 14,375.40239

Timestep Collection Time: 2.12179
Timestep Consumption Time: 1.35791
PPO Batch Consumption Time: 0.10185
Total Iteration Time: 3.47969

Cumulative Model Updates: 812
Cumulative Timesteps: 6,852,454

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.31157
Policy Entropy: 2.87078
Value Function Loss: 2.14798

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.05542
Policy Update Magnitude: 0.17160
Value Function Update Magnitude: 0.14358

Collected Steps per Second: 23,593.22250
Overall Steps per Second: 14,480.97817

Timestep Collection Time: 2.11976
Timestep Consumption Time: 1.33387
PPO Batch Consumption Time: 0.10011
Total Iteration Time: 3.45363

Cumulative Model Updates: 818
Cumulative Timesteps: 6,902,466

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 6902466...
Checkpoint 6902466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.18343
Policy Entropy: 2.84106
Value Function Loss: 2.12567

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.05948
Policy Update Magnitude: 0.18598
Value Function Update Magnitude: 0.13819

Collected Steps per Second: 23,790.80306
Overall Steps per Second: 14,703.88000

Timestep Collection Time: 2.10207
Timestep Consumption Time: 1.29907
PPO Batch Consumption Time: 0.09134
Total Iteration Time: 3.40114

Cumulative Model Updates: 824
Cumulative Timesteps: 6,952,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.88825
Policy Entropy: 2.84382
Value Function Loss: 2.24871

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.04854
Policy Update Magnitude: 0.20244
Value Function Update Magnitude: 0.16539

Collected Steps per Second: 23,800.59083
Overall Steps per Second: 14,745.47286

Timestep Collection Time: 2.10163
Timestep Consumption Time: 1.29060
PPO Batch Consumption Time: 0.09240
Total Iteration Time: 3.39223

Cumulative Model Updates: 830
Cumulative Timesteps: 7,002,496

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 7002496...
Checkpoint 7002496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.71590
Policy Entropy: 2.79855
Value Function Loss: 2.30325

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.06957
Policy Update Magnitude: 0.20341
Value Function Update Magnitude: 0.18713

Collected Steps per Second: 22,365.17015
Overall Steps per Second: 14,120.66285

Timestep Collection Time: 2.23768
Timestep Consumption Time: 1.30649
PPO Batch Consumption Time: 0.09887
Total Iteration Time: 3.54417

Cumulative Model Updates: 836
Cumulative Timesteps: 7,052,542

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.38847
Policy Entropy: 2.78479
Value Function Loss: 2.40768

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.09176
Policy Update Magnitude: 0.18351
Value Function Update Magnitude: 0.20911

Collected Steps per Second: 22,978.84244
Overall Steps per Second: 14,125.38693

Timestep Collection Time: 2.17626
Timestep Consumption Time: 1.36403
PPO Batch Consumption Time: 0.10339
Total Iteration Time: 3.54029

Cumulative Model Updates: 842
Cumulative Timesteps: 7,102,550

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 7102550...
Checkpoint 7102550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149.23019
Policy Entropy: 2.75719
Value Function Loss: 2.40342

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07631
Policy Update Magnitude: 0.15479
Value Function Update Magnitude: 0.19992

Collected Steps per Second: 23,738.92874
Overall Steps per Second: 14,581.65722

Timestep Collection Time: 2.10692
Timestep Consumption Time: 1.32314
PPO Batch Consumption Time: 0.09614
Total Iteration Time: 3.43006

Cumulative Model Updates: 848
Cumulative Timesteps: 7,152,566

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.59241
Policy Entropy: 2.74792
Value Function Loss: 2.43637

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07762
Policy Update Magnitude: 0.14124
Value Function Update Magnitude: 0.22432

Collected Steps per Second: 23,982.61778
Overall Steps per Second: 14,743.42562

Timestep Collection Time: 2.08484
Timestep Consumption Time: 1.30650
PPO Batch Consumption Time: 0.09376
Total Iteration Time: 3.39134

Cumulative Model Updates: 854
Cumulative Timesteps: 7,202,566

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 7202566...
Checkpoint 7202566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156.71025
Policy Entropy: 2.69022
Value Function Loss: 2.48470

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.16321
Policy Update Magnitude: 0.11758
Value Function Update Magnitude: 0.22002

Collected Steps per Second: 23,090.65191
Overall Steps per Second: 14,128.85510

Timestep Collection Time: 2.16624
Timestep Consumption Time: 1.37403
PPO Batch Consumption Time: 0.10216
Total Iteration Time: 3.54027

Cumulative Model Updates: 860
Cumulative Timesteps: 7,252,586

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.04120
Policy Entropy: 2.70405
Value Function Loss: 2.55678

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12370
Policy Update Magnitude: 0.11895
Value Function Update Magnitude: 0.22400

Collected Steps per Second: 23,744.36991
Overall Steps per Second: 14,773.51621

Timestep Collection Time: 2.10703
Timestep Consumption Time: 1.27944
PPO Batch Consumption Time: 0.10054
Total Iteration Time: 3.38647

Cumulative Model Updates: 866
Cumulative Timesteps: 7,302,616

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 7302616...
Checkpoint 7302616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158.49343
Policy Entropy: 2.64021
Value Function Loss: 2.51160

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.11115
Policy Update Magnitude: 0.13630
Value Function Update Magnitude: 0.22460

Collected Steps per Second: 23,076.48480
Overall Steps per Second: 14,202.36796

Timestep Collection Time: 2.16757
Timestep Consumption Time: 1.35437
PPO Batch Consumption Time: 0.10246
Total Iteration Time: 3.52195

Cumulative Model Updates: 872
Cumulative Timesteps: 7,352,636

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.56832
Policy Entropy: 2.64522
Value Function Loss: 2.43385

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.13386
Value Function Update Magnitude: 0.25077

Collected Steps per Second: 23,472.98492
Overall Steps per Second: 14,512.87815

Timestep Collection Time: 2.13011
Timestep Consumption Time: 1.31511
PPO Batch Consumption Time: 0.09985
Total Iteration Time: 3.44522

Cumulative Model Updates: 878
Cumulative Timesteps: 7,402,636

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 7402636...
Checkpoint 7402636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.47262
Policy Entropy: 2.62205
Value Function Loss: 2.36806

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.08451
Policy Update Magnitude: 0.13827
Value Function Update Magnitude: 0.27994

Collected Steps per Second: 23,559.58622
Overall Steps per Second: 14,862.66324

Timestep Collection Time: 2.12381
Timestep Consumption Time: 1.24275
PPO Batch Consumption Time: 0.09790
Total Iteration Time: 3.36656

Cumulative Model Updates: 884
Cumulative Timesteps: 7,452,672

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.57876
Policy Entropy: 2.59663
Value Function Loss: 2.43993

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12499
Policy Update Magnitude: 0.13053
Value Function Update Magnitude: 0.34852

Collected Steps per Second: 23,167.90505
Overall Steps per Second: 14,264.22819

Timestep Collection Time: 2.15876
Timestep Consumption Time: 1.34749
PPO Batch Consumption Time: 0.10160
Total Iteration Time: 3.50625

Cumulative Model Updates: 890
Cumulative Timesteps: 7,502,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 7502686...
Checkpoint 7502686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.16127
Policy Entropy: 2.61159
Value Function Loss: 2.39615

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09924
Policy Update Magnitude: 0.12575
Value Function Update Magnitude: 0.31776

Collected Steps per Second: 22,016.13845
Overall Steps per Second: 13,736.66112

Timestep Collection Time: 2.27106
Timestep Consumption Time: 1.36883
PPO Batch Consumption Time: 0.10247
Total Iteration Time: 3.63989

Cumulative Model Updates: 896
Cumulative Timesteps: 7,552,686

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.98948
Policy Entropy: 2.58003
Value Function Loss: 2.47454

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06881
Policy Update Magnitude: 0.14520
Value Function Update Magnitude: 0.28004

Collected Steps per Second: 24,377.28756
Overall Steps per Second: 14,712.31462

Timestep Collection Time: 2.05248
Timestep Consumption Time: 1.34834
PPO Batch Consumption Time: 0.09855
Total Iteration Time: 3.40082

Cumulative Model Updates: 902
Cumulative Timesteps: 7,602,720

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 7602720...
Checkpoint 7602720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.18831
Policy Entropy: 2.55634
Value Function Loss: 2.42603

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.15037
Value Function Update Magnitude: 0.37304

Collected Steps per Second: 22,888.59445
Overall Steps per Second: 14,084.20672

Timestep Collection Time: 2.18458
Timestep Consumption Time: 1.36564
PPO Batch Consumption Time: 0.10432
Total Iteration Time: 3.55022

Cumulative Model Updates: 908
Cumulative Timesteps: 7,652,722

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.42547
Policy Entropy: 2.54883
Value Function Loss: 2.59870

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.08531
Policy Update Magnitude: 0.15206
Value Function Update Magnitude: 0.29392

Collected Steps per Second: 21,295.76793
Overall Steps per Second: 13,722.33938

Timestep Collection Time: 2.34948
Timestep Consumption Time: 1.29669
PPO Batch Consumption Time: 0.09370
Total Iteration Time: 3.64617

Cumulative Model Updates: 914
Cumulative Timesteps: 7,702,756

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 7702756...
Checkpoint 7702756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.79094
Policy Entropy: 2.52474
Value Function Loss: 2.51379

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.14014
Value Function Update Magnitude: 0.24635

Collected Steps per Second: 19,670.04624
Overall Steps per Second: 12,636.87537

Timestep Collection Time: 2.54224
Timestep Consumption Time: 1.41491
PPO Batch Consumption Time: 0.09857
Total Iteration Time: 3.95715

Cumulative Model Updates: 920
Cumulative Timesteps: 7,752,762

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.29907
Policy Entropy: 2.51316
Value Function Loss: 2.65159

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.07335
Policy Update Magnitude: 0.16846
Value Function Update Magnitude: 0.21337

Collected Steps per Second: 21,705.94944
Overall Steps per Second: 13,975.18674

Timestep Collection Time: 2.30416
Timestep Consumption Time: 1.27461
PPO Batch Consumption Time: 0.09245
Total Iteration Time: 3.57877

Cumulative Model Updates: 926
Cumulative Timesteps: 7,802,776

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 7802776...
Checkpoint 7802776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.52625
Policy Entropy: 2.47747
Value Function Loss: 2.56994

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08188
Policy Update Magnitude: 0.16143
Value Function Update Magnitude: 0.23395

Collected Steps per Second: 24,133.41004
Overall Steps per Second: 14,848.74624

Timestep Collection Time: 2.07339
Timestep Consumption Time: 1.29646
PPO Batch Consumption Time: 0.09251
Total Iteration Time: 3.36985

Cumulative Model Updates: 932
Cumulative Timesteps: 7,852,814

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.78092
Policy Entropy: 2.47722
Value Function Loss: 2.63499

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.08181
Policy Update Magnitude: 0.14652
Value Function Update Magnitude: 0.24017

Collected Steps per Second: 23,731.77400
Overall Steps per Second: 14,446.38116

Timestep Collection Time: 2.10688
Timestep Consumption Time: 1.35419
PPO Batch Consumption Time: 0.10132
Total Iteration Time: 3.46107

Cumulative Model Updates: 938
Cumulative Timesteps: 7,902,814

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 7902814...
Checkpoint 7902814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125.01905
Policy Entropy: 2.46214
Value Function Loss: 2.65232

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.13662
Value Function Update Magnitude: 0.27548

Collected Steps per Second: 23,085.61043
Overall Steps per Second: 14,487.49194

Timestep Collection Time: 2.16654
Timestep Consumption Time: 1.28581
PPO Batch Consumption Time: 0.10280
Total Iteration Time: 3.45236

Cumulative Model Updates: 944
Cumulative Timesteps: 7,952,830

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.72989
Policy Entropy: 2.46971
Value Function Loss: 2.49804

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.07703
Policy Update Magnitude: 0.14831
Value Function Update Magnitude: 0.24533

Collected Steps per Second: 23,420.45305
Overall Steps per Second: 14,542.14378

Timestep Collection Time: 2.13514
Timestep Consumption Time: 1.30355
PPO Batch Consumption Time: 0.09313
Total Iteration Time: 3.43870

Cumulative Model Updates: 950
Cumulative Timesteps: 8,002,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 8002836...
Checkpoint 8002836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147.86213
Policy Entropy: 2.42830
Value Function Loss: 2.50191

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.07403
Policy Update Magnitude: 0.14467
Value Function Update Magnitude: 0.22947

Collected Steps per Second: 23,356.83638
Overall Steps per Second: 14,367.17909

Timestep Collection Time: 2.14079
Timestep Consumption Time: 1.33951
PPO Batch Consumption Time: 0.10218
Total Iteration Time: 3.48029

Cumulative Model Updates: 956
Cumulative Timesteps: 8,052,838

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.47259
Policy Entropy: 2.45193
Value Function Loss: 2.31388

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08555
Policy Update Magnitude: 0.14199
Value Function Update Magnitude: 0.23655

Collected Steps per Second: 24,647.93469
Overall Steps per Second: 14,748.31715

Timestep Collection Time: 2.02946
Timestep Consumption Time: 1.36225
PPO Batch Consumption Time: 0.10486
Total Iteration Time: 3.39171

Cumulative Model Updates: 962
Cumulative Timesteps: 8,102,860

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 8102860...
Checkpoint 8102860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.64269
Policy Entropy: 2.45508
Value Function Loss: 2.34148

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.13357
Value Function Update Magnitude: 0.25305

Collected Steps per Second: 23,163.92737
Overall Steps per Second: 14,114.20057

Timestep Collection Time: 2.15913
Timestep Consumption Time: 1.38439
PPO Batch Consumption Time: 0.10086
Total Iteration Time: 3.54352

Cumulative Model Updates: 968
Cumulative Timesteps: 8,152,874

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.16702
Policy Entropy: 2.47282
Value Function Loss: 2.29068

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.12334
Value Function Update Magnitude: 0.24086

Collected Steps per Second: 23,349.13706
Overall Steps per Second: 14,607.17529

Timestep Collection Time: 2.14192
Timestep Consumption Time: 1.28188
PPO Batch Consumption Time: 0.10110
Total Iteration Time: 3.42380

Cumulative Model Updates: 974
Cumulative Timesteps: 8,202,886

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 8202886...
Checkpoint 8202886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.03428
Policy Entropy: 2.46130
Value Function Loss: 2.37678

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12913
Policy Update Magnitude: 0.11162
Value Function Update Magnitude: 0.28152

Collected Steps per Second: 23,567.62525
Overall Steps per Second: 14,573.21060

Timestep Collection Time: 2.12232
Timestep Consumption Time: 1.30987
PPO Batch Consumption Time: 0.09508
Total Iteration Time: 3.43219

Cumulative Model Updates: 980
Cumulative Timesteps: 8,252,904

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.75642
Policy Entropy: 2.46917
Value Function Loss: 2.35883

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.12476
Value Function Update Magnitude: 0.23394

Collected Steps per Second: 23,319.60024
Overall Steps per Second: 14,284.69889

Timestep Collection Time: 2.14506
Timestep Consumption Time: 1.35673
PPO Batch Consumption Time: 0.10270
Total Iteration Time: 3.50179

Cumulative Model Updates: 986
Cumulative Timesteps: 8,302,926

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 8302926...
Checkpoint 8302926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.68891
Policy Entropy: 2.48557
Value Function Loss: 2.34631

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.05914
Policy Update Magnitude: 0.14293
Value Function Update Magnitude: 0.17975

Collected Steps per Second: 24,623.50567
Overall Steps per Second: 14,870.51965

Timestep Collection Time: 2.03172
Timestep Consumption Time: 1.33252
PPO Batch Consumption Time: 0.10023
Total Iteration Time: 3.36424

Cumulative Model Updates: 992
Cumulative Timesteps: 8,352,954

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.83908
Policy Entropy: 2.44989
Value Function Loss: 2.39282

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.08718
Policy Update Magnitude: 0.14756
Value Function Update Magnitude: 0.17571

Collected Steps per Second: 23,162.30334
Overall Steps per Second: 14,415.49334

Timestep Collection Time: 2.15894
Timestep Consumption Time: 1.30997
PPO Batch Consumption Time: 0.09699
Total Iteration Time: 3.46891

Cumulative Model Updates: 998
Cumulative Timesteps: 8,402,960

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 8402960...
Checkpoint 8402960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.39799
Policy Entropy: 2.44978
Value Function Loss: 2.41431

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05432
Policy Update Magnitude: 0.16511
Value Function Update Magnitude: 0.17499

Collected Steps per Second: 23,151.45046
Overall Steps per Second: 14,775.46644

Timestep Collection Time: 2.16038
Timestep Consumption Time: 1.22469
PPO Batch Consumption Time: 0.09293
Total Iteration Time: 3.38507

Cumulative Model Updates: 1,004
Cumulative Timesteps: 8,452,976

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.24182
Policy Entropy: 2.43003
Value Function Loss: 2.51045

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06716
Policy Update Magnitude: 0.17510
Value Function Update Magnitude: 0.15676

Collected Steps per Second: 23,874.46577
Overall Steps per Second: 14,732.75474

Timestep Collection Time: 2.09487
Timestep Consumption Time: 1.29987
PPO Batch Consumption Time: 0.09431
Total Iteration Time: 3.39475

Cumulative Model Updates: 1,010
Cumulative Timesteps: 8,502,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 8502990...
Checkpoint 8502990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.83477
Policy Entropy: 2.40802
Value Function Loss: 2.54667

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07083
Policy Update Magnitude: 0.17335
Value Function Update Magnitude: 0.18800

Collected Steps per Second: 21,854.56146
Overall Steps per Second: 13,964.38482

Timestep Collection Time: 2.28849
Timestep Consumption Time: 1.29305
PPO Batch Consumption Time: 0.09286
Total Iteration Time: 3.58154

Cumulative Model Updates: 1,016
Cumulative Timesteps: 8,553,004

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.33881
Policy Entropy: 2.40330
Value Function Loss: 2.60949

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.07106
Policy Update Magnitude: 0.17542
Value Function Update Magnitude: 0.20037

Collected Steps per Second: 23,963.27744
Overall Steps per Second: 14,308.42085

Timestep Collection Time: 2.08811
Timestep Consumption Time: 1.40899
PPO Batch Consumption Time: 0.10668
Total Iteration Time: 3.49710

Cumulative Model Updates: 1,022
Cumulative Timesteps: 8,603,042

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 8603042...
Checkpoint 8603042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.47855
Policy Entropy: 2.42902
Value Function Loss: 2.48172

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.06614
Policy Update Magnitude: 0.17115
Value Function Update Magnitude: 0.21755

Collected Steps per Second: 23,561.31289
Overall Steps per Second: 14,512.28602

Timestep Collection Time: 2.12229
Timestep Consumption Time: 1.32334
PPO Batch Consumption Time: 0.09365
Total Iteration Time: 3.44563

Cumulative Model Updates: 1,028
Cumulative Timesteps: 8,653,046

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.33187
Policy Entropy: 2.40549
Value Function Loss: 2.37758

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05077
Policy Update Magnitude: 0.17530
Value Function Update Magnitude: 0.29724

Collected Steps per Second: 23,067.66560
Overall Steps per Second: 14,206.15087

Timestep Collection Time: 2.16814
Timestep Consumption Time: 1.35244
PPO Batch Consumption Time: 0.10271
Total Iteration Time: 3.52059

Cumulative Model Updates: 1,034
Cumulative Timesteps: 8,703,060

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 8703060...
Checkpoint 8703060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.41040
Policy Entropy: 2.38320
Value Function Loss: 2.32640

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.08585
Policy Update Magnitude: 0.17645
Value Function Update Magnitude: 0.31662

Collected Steps per Second: 23,936.98900
Overall Steps per Second: 14,604.38585

Timestep Collection Time: 2.08924
Timestep Consumption Time: 1.33508
PPO Batch Consumption Time: 0.09666
Total Iteration Time: 3.42431

Cumulative Model Updates: 1,040
Cumulative Timesteps: 8,753,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.34695
Policy Entropy: 2.40252
Value Function Loss: 2.29062

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.08288
Policy Update Magnitude: 0.15132
Value Function Update Magnitude: 0.31843

Collected Steps per Second: 23,582.87263
Overall Steps per Second: 14,400.25201

Timestep Collection Time: 2.12179
Timestep Consumption Time: 1.35301
PPO Batch Consumption Time: 0.10100
Total Iteration Time: 3.47480

Cumulative Model Updates: 1,046
Cumulative Timesteps: 8,803,108

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 8803108...
Checkpoint 8803108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.00506
Policy Entropy: 2.41129
Value Function Loss: 2.16195

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.07497
Policy Update Magnitude: 0.16819
Value Function Update Magnitude: 0.25726

Collected Steps per Second: 22,663.26278
Overall Steps per Second: 14,354.48401

Timestep Collection Time: 2.20701
Timestep Consumption Time: 1.27748
PPO Batch Consumption Time: 0.09851
Total Iteration Time: 3.48449

Cumulative Model Updates: 1,052
Cumulative Timesteps: 8,853,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.62135
Policy Entropy: 2.38832
Value Function Loss: 2.04255

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.08370
Policy Update Magnitude: 0.15017
Value Function Update Magnitude: 0.19706

Collected Steps per Second: 23,292.73388
Overall Steps per Second: 14,216.95569

Timestep Collection Time: 2.14745
Timestep Consumption Time: 1.37088
PPO Batch Consumption Time: 0.10222
Total Iteration Time: 3.51833

Cumulative Model Updates: 1,058
Cumulative Timesteps: 8,903,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 8903146...
Checkpoint 8903146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.28511
Policy Entropy: 2.40390
Value Function Loss: 2.04773

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06938
Policy Update Magnitude: 0.16097
Value Function Update Magnitude: 0.17174

Collected Steps per Second: 23,409.05990
Overall Steps per Second: 14,533.78865

Timestep Collection Time: 2.13763
Timestep Consumption Time: 1.30538
PPO Batch Consumption Time: 0.09736
Total Iteration Time: 3.44301

Cumulative Model Updates: 1,064
Cumulative Timesteps: 8,953,186

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.84607
Policy Entropy: 2.36496
Value Function Loss: 2.08958

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.06494
Policy Update Magnitude: 0.17562
Value Function Update Magnitude: 0.16292

Collected Steps per Second: 24,055.37884
Overall Steps per Second: 14,738.39742

Timestep Collection Time: 2.07912
Timestep Consumption Time: 1.31433
PPO Batch Consumption Time: 0.09746
Total Iteration Time: 3.39345

Cumulative Model Updates: 1,070
Cumulative Timesteps: 9,003,200

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 9003200...
Checkpoint 9003200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174.70044
Policy Entropy: 2.40039
Value Function Loss: 2.07019

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.17615
Value Function Update Magnitude: 0.15417

Collected Steps per Second: 23,361.66842
Overall Steps per Second: 14,241.59357

Timestep Collection Time: 2.14111
Timestep Consumption Time: 1.37113
PPO Batch Consumption Time: 0.10260
Total Iteration Time: 3.51225

Cumulative Model Updates: 1,076
Cumulative Timesteps: 9,053,220

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.33746
Policy Entropy: 2.37055
Value Function Loss: 2.07849

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12345
Policy Update Magnitude: 0.15308
Value Function Update Magnitude: 0.16523

Collected Steps per Second: 23,080.59566
Overall Steps per Second: 14,502.31143

Timestep Collection Time: 2.16762
Timestep Consumption Time: 1.28217
PPO Batch Consumption Time: 0.09470
Total Iteration Time: 3.44979

Cumulative Model Updates: 1,082
Cumulative Timesteps: 9,103,250

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 9103250...
Checkpoint 9103250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.56967
Policy Entropy: 2.41575
Value Function Loss: 1.97851

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.08572
Policy Update Magnitude: 0.13848
Value Function Update Magnitude: 0.18556

Collected Steps per Second: 23,667.68172
Overall Steps per Second: 14,466.01341

Timestep Collection Time: 2.11385
Timestep Consumption Time: 1.34460
PPO Batch Consumption Time: 0.10092
Total Iteration Time: 3.45845

Cumulative Model Updates: 1,088
Cumulative Timesteps: 9,153,280

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.81469
Policy Entropy: 2.38477
Value Function Loss: 1.99360

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09807
Policy Update Magnitude: 0.13647
Value Function Update Magnitude: 0.18581

Collected Steps per Second: 23,489.86638
Overall Steps per Second: 14,347.12657

Timestep Collection Time: 2.12926
Timestep Consumption Time: 1.35687
PPO Batch Consumption Time: 0.09778
Total Iteration Time: 3.48613

Cumulative Model Updates: 1,094
Cumulative Timesteps: 9,203,296

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 9203296...
Checkpoint 9203296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.42497
Policy Entropy: 2.40112
Value Function Loss: 1.94034

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05688
Policy Update Magnitude: 0.14617
Value Function Update Magnitude: 0.23917

Collected Steps per Second: 23,322.11227
Overall Steps per Second: 14,806.15696

Timestep Collection Time: 2.14397
Timestep Consumption Time: 1.23313
PPO Batch Consumption Time: 0.09674
Total Iteration Time: 3.37711

Cumulative Model Updates: 1,100
Cumulative Timesteps: 9,253,298

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.77333
Policy Entropy: 2.35239
Value Function Loss: 1.87486

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07800
Policy Update Magnitude: 0.15736
Value Function Update Magnitude: 0.25387

Collected Steps per Second: 23,326.38917
Overall Steps per Second: 14,238.18860

Timestep Collection Time: 2.14444
Timestep Consumption Time: 1.36879
PPO Batch Consumption Time: 0.10157
Total Iteration Time: 3.51323

Cumulative Model Updates: 1,106
Cumulative Timesteps: 9,303,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 9303320...
Checkpoint 9303320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.49985
Policy Entropy: 2.36026
Value Function Loss: 1.91451

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.14049
Value Function Update Magnitude: 0.21867

Collected Steps per Second: 23,145.60535
Overall Steps per Second: 14,462.90136

Timestep Collection Time: 2.16024
Timestep Consumption Time: 1.29688
PPO Batch Consumption Time: 0.09181
Total Iteration Time: 3.45712

Cumulative Model Updates: 1,112
Cumulative Timesteps: 9,353,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.77396
Policy Entropy: 2.30495
Value Function Loss: 1.85614

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.13593
Value Function Update Magnitude: 0.20026

Collected Steps per Second: 24,482.08267
Overall Steps per Second: 14,797.37303

Timestep Collection Time: 2.04239
Timestep Consumption Time: 1.33672
PPO Batch Consumption Time: 0.09796
Total Iteration Time: 3.37911

Cumulative Model Updates: 1,118
Cumulative Timesteps: 9,403,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 9403322...
Checkpoint 9403322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.18428
Policy Entropy: 2.30685
Value Function Loss: 1.90068

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05458
Policy Update Magnitude: 0.17925
Value Function Update Magnitude: 0.21911

Collected Steps per Second: 22,938.80310
Overall Steps per Second: 14,011.85598

Timestep Collection Time: 2.18032
Timestep Consumption Time: 1.38908
PPO Batch Consumption Time: 0.10864
Total Iteration Time: 3.56941

Cumulative Model Updates: 1,124
Cumulative Timesteps: 9,453,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.99576
Policy Entropy: 2.27462
Value Function Loss: 1.88490

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05999
Policy Update Magnitude: 0.17228
Value Function Update Magnitude: 0.19481

Collected Steps per Second: 23,824.20949
Overall Steps per Second: 14,633.77932

Timestep Collection Time: 2.09971
Timestep Consumption Time: 1.31868
PPO Batch Consumption Time: 0.10022
Total Iteration Time: 3.41839

Cumulative Model Updates: 1,130
Cumulative Timesteps: 9,503,360

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 9503360...
Checkpoint 9503360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.70898
Policy Entropy: 2.26985
Value Function Loss: 1.94783

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05780
Policy Update Magnitude: 0.20111
Value Function Update Magnitude: 0.18084

Collected Steps per Second: 23,275.69226
Overall Steps per Second: 14,253.24237

Timestep Collection Time: 2.14842
Timestep Consumption Time: 1.35997
PPO Batch Consumption Time: 0.10247
Total Iteration Time: 3.50839

Cumulative Model Updates: 1,136
Cumulative Timesteps: 9,553,366

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.00302
Policy Entropy: 2.24999
Value Function Loss: 1.92855

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05046
Policy Update Magnitude: 0.22032
Value Function Update Magnitude: 0.17123

Collected Steps per Second: 23,251.99691
Overall Steps per Second: 14,585.06443

Timestep Collection Time: 2.15070
Timestep Consumption Time: 1.27802
PPO Batch Consumption Time: 0.09388
Total Iteration Time: 3.42871

Cumulative Model Updates: 1,142
Cumulative Timesteps: 9,603,374

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 9603374...
Checkpoint 9603374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.57042
Policy Entropy: 2.22865
Value Function Loss: 1.85106

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05099
Policy Update Magnitude: 0.21559
Value Function Update Magnitude: 0.26224

Collected Steps per Second: 23,946.60690
Overall Steps per Second: 14,343.22542

Timestep Collection Time: 2.08848
Timestep Consumption Time: 1.39832
PPO Batch Consumption Time: 0.10185
Total Iteration Time: 3.48680

Cumulative Model Updates: 1,148
Cumulative Timesteps: 9,653,386

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.84588
Policy Entropy: 2.22691
Value Function Loss: 1.78914

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05495
Policy Update Magnitude: 0.20806
Value Function Update Magnitude: 0.27129

Collected Steps per Second: 23,749.54148
Overall Steps per Second: 14,484.30253

Timestep Collection Time: 2.10598
Timestep Consumption Time: 1.34714
PPO Batch Consumption Time: 0.09871
Total Iteration Time: 3.45312

Cumulative Model Updates: 1,154
Cumulative Timesteps: 9,703,402

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 9703402...
Checkpoint 9703402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.54963
Policy Entropy: 2.21193
Value Function Loss: 1.74880

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04594
Policy Update Magnitude: 0.20303
Value Function Update Magnitude: 0.20981

Collected Steps per Second: 23,034.44578
Overall Steps per Second: 14,139.68979

Timestep Collection Time: 2.17110
Timestep Consumption Time: 1.36576
PPO Batch Consumption Time: 0.10357
Total Iteration Time: 3.53685

Cumulative Model Updates: 1,160
Cumulative Timesteps: 9,753,412

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.69609
Policy Entropy: 2.19128
Value Function Loss: 1.76742

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05527
Policy Update Magnitude: 0.21542
Value Function Update Magnitude: 0.17197

Collected Steps per Second: 24,586.24294
Overall Steps per Second: 14,657.59719

Timestep Collection Time: 2.03382
Timestep Consumption Time: 1.37765
PPO Batch Consumption Time: 0.09976
Total Iteration Time: 3.41147

Cumulative Model Updates: 1,166
Cumulative Timesteps: 9,803,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 9803416...
Checkpoint 9803416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.77744
Policy Entropy: 2.17821
Value Function Loss: 1.74184

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05474
Policy Update Magnitude: 0.21718
Value Function Update Magnitude: 0.16624

Collected Steps per Second: 23,599.82941
Overall Steps per Second: 14,696.82200

Timestep Collection Time: 2.11942
Timestep Consumption Time: 1.28390
PPO Batch Consumption Time: 0.09132
Total Iteration Time: 3.40332

Cumulative Model Updates: 1,172
Cumulative Timesteps: 9,853,434

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.16107
Policy Entropy: 2.18004
Value Function Loss: 1.88638

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05264
Policy Update Magnitude: 0.22308
Value Function Update Magnitude: 0.15779

Collected Steps per Second: 23,163.98701
Overall Steps per Second: 14,792.24792

Timestep Collection Time: 2.15904
Timestep Consumption Time: 1.22192
PPO Batch Consumption Time: 0.09272
Total Iteration Time: 3.38096

Cumulative Model Updates: 1,178
Cumulative Timesteps: 9,903,446

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 9903446...
Checkpoint 9903446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.64590
Policy Entropy: 2.16511
Value Function Loss: 1.86843

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08991
Policy Update Magnitude: 0.17887
Value Function Update Magnitude: 0.14098

Collected Steps per Second: 23,066.82991
Overall Steps per Second: 14,062.97490

Timestep Collection Time: 2.16918
Timestep Consumption Time: 1.38882
PPO Batch Consumption Time: 0.09870
Total Iteration Time: 3.55800

Cumulative Model Updates: 1,184
Cumulative Timesteps: 9,953,482

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.38621
Policy Entropy: 2.15637
Value Function Loss: 1.86668

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09926
Policy Update Magnitude: 0.15737
Value Function Update Magnitude: 0.12994

Collected Steps per Second: 23,742.84471
Overall Steps per Second: 14,698.04518

Timestep Collection Time: 2.10657
Timestep Consumption Time: 1.29633
PPO Batch Consumption Time: 0.09473
Total Iteration Time: 3.40290

Cumulative Model Updates: 1,190
Cumulative Timesteps: 10,003,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 10003498...
Checkpoint 10003498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.89555
Policy Entropy: 2.12425
Value Function Loss: 1.80932

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09327
Policy Update Magnitude: 0.14281
Value Function Update Magnitude: 0.12006

Collected Steps per Second: 23,364.11274
Overall Steps per Second: 14,267.92807

Timestep Collection Time: 2.14089
Timestep Consumption Time: 1.36487
PPO Batch Consumption Time: 0.10275
Total Iteration Time: 3.50576

Cumulative Model Updates: 1,196
Cumulative Timesteps: 10,053,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.52643
Policy Entropy: 2.11353
Value Function Loss: 1.70939

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07005
Policy Update Magnitude: 0.15190
Value Function Update Magnitude: 0.10839

Collected Steps per Second: 23,750.36013
Overall Steps per Second: 14,499.57660

Timestep Collection Time: 2.10582
Timestep Consumption Time: 1.34352
PPO Batch Consumption Time: 0.09534
Total Iteration Time: 3.44934

Cumulative Model Updates: 1,202
Cumulative Timesteps: 10,103,532

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 10103532...
Checkpoint 10103532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.22103
Policy Entropy: 2.10730
Value Function Loss: 1.72566

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05687
Policy Update Magnitude: 0.18388
Value Function Update Magnitude: 0.10686

Collected Steps per Second: 23,340.50852
Overall Steps per Second: 14,845.91337

Timestep Collection Time: 2.14220
Timestep Consumption Time: 1.22573
PPO Batch Consumption Time: 0.09392
Total Iteration Time: 3.36793

Cumulative Model Updates: 1,208
Cumulative Timesteps: 10,153,532

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.62899
Policy Entropy: 2.07275
Value Function Loss: 1.70138

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05647
Policy Update Magnitude: 0.18004
Value Function Update Magnitude: 0.10439

Collected Steps per Second: 23,234.70988
Overall Steps per Second: 14,192.90699

Timestep Collection Time: 2.15212
Timestep Consumption Time: 1.37104
PPO Batch Consumption Time: 0.10231
Total Iteration Time: 3.52317

Cumulative Model Updates: 1,214
Cumulative Timesteps: 10,203,536

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 10203536...
Checkpoint 10203536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.55263
Policy Entropy: 2.06298
Value Function Loss: 1.65067

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.06003
Policy Update Magnitude: 0.17992
Value Function Update Magnitude: 0.10723

Collected Steps per Second: 23,611.26706
Overall Steps per Second: 14,585.91341

Timestep Collection Time: 2.11967
Timestep Consumption Time: 1.31159
PPO Batch Consumption Time: 0.09686
Total Iteration Time: 3.43126

Cumulative Model Updates: 1,220
Cumulative Timesteps: 10,253,584

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.06418
Policy Entropy: 2.03010
Value Function Loss: 1.59256

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03379
Policy Update Magnitude: 0.18544
Value Function Update Magnitude: 0.10892

Collected Steps per Second: 24,531.45644
Overall Steps per Second: 14,854.66462

Timestep Collection Time: 2.03934
Timestep Consumption Time: 1.32849
PPO Batch Consumption Time: 0.10024
Total Iteration Time: 3.36783

Cumulative Model Updates: 1,226
Cumulative Timesteps: 10,303,612

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 10303612...
Checkpoint 10303612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.66267
Policy Entropy: 2.00526
Value Function Loss: 1.60039

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.08038
Policy Update Magnitude: 0.16652
Value Function Update Magnitude: 0.10734

Collected Steps per Second: 23,021.54273
Overall Steps per Second: 13,958.17259

Timestep Collection Time: 2.17249
Timestep Consumption Time: 1.41065
PPO Batch Consumption Time: 0.10843
Total Iteration Time: 3.58313

Cumulative Model Updates: 1,232
Cumulative Timesteps: 10,353,626

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.87473
Policy Entropy: 2.00721
Value Function Loss: 1.63310

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07247
Policy Update Magnitude: 0.15018
Value Function Update Magnitude: 0.10490

Collected Steps per Second: 23,398.15089
Overall Steps per Second: 14,194.81031

Timestep Collection Time: 2.13692
Timestep Consumption Time: 1.38549
PPO Batch Consumption Time: 0.10747
Total Iteration Time: 3.52241

Cumulative Model Updates: 1,238
Cumulative Timesteps: 10,403,626

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 10403626...
Checkpoint 10403626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.13108
Policy Entropy: 1.99824
Value Function Loss: 1.62978

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06875
Policy Update Magnitude: 0.14573
Value Function Update Magnitude: 0.10699

Collected Steps per Second: 23,833.87894
Overall Steps per Second: 14,582.15783

Timestep Collection Time: 2.09861
Timestep Consumption Time: 1.33147
PPO Batch Consumption Time: 0.09713
Total Iteration Time: 3.43008

Cumulative Model Updates: 1,244
Cumulative Timesteps: 10,453,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.46644
Policy Entropy: 1.96323
Value Function Loss: 1.59634

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06748
Policy Update Magnitude: 0.15808
Value Function Update Magnitude: 0.11857

Collected Steps per Second: 23,309.78546
Overall Steps per Second: 14,284.14758

Timestep Collection Time: 2.14622
Timestep Consumption Time: 1.35612
PPO Batch Consumption Time: 0.10127
Total Iteration Time: 3.50234

Cumulative Model Updates: 1,250
Cumulative Timesteps: 10,503,672

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 10503672...
Checkpoint 10503672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.57980
Policy Entropy: 1.97358
Value Function Loss: 1.57565

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.07359
Policy Update Magnitude: 0.14807
Value Function Update Magnitude: 0.12138

Collected Steps per Second: 23,297.00769
Overall Steps per Second: 14,552.31472

Timestep Collection Time: 2.14714
Timestep Consumption Time: 1.29025
PPO Batch Consumption Time: 0.10195
Total Iteration Time: 3.43739

Cumulative Model Updates: 1,256
Cumulative Timesteps: 10,553,694

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.54980
Policy Entropy: 1.98354
Value Function Loss: 1.54392

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.06138
Policy Update Magnitude: 0.16300
Value Function Update Magnitude: 0.11381

Collected Steps per Second: 23,924.28246
Overall Steps per Second: 14,596.97940

Timestep Collection Time: 2.09101
Timestep Consumption Time: 1.33613
PPO Batch Consumption Time: 0.09545
Total Iteration Time: 3.42715

Cumulative Model Updates: 1,262
Cumulative Timesteps: 10,603,720

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 10603720...
Checkpoint 10603720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.17465
Policy Entropy: 1.94388
Value Function Loss: 1.54388

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09415
Policy Update Magnitude: 0.14441
Value Function Update Magnitude: 0.10776

Collected Steps per Second: 22,865.88361
Overall Steps per Second: 14,132.91361

Timestep Collection Time: 2.18850
Timestep Consumption Time: 1.35231
PPO Batch Consumption Time: 0.10248
Total Iteration Time: 3.54081

Cumulative Model Updates: 1,268
Cumulative Timesteps: 10,653,762

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.91274
Policy Entropy: 1.93393
Value Function Loss: 1.54295

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.06702
Policy Update Magnitude: 0.12987
Value Function Update Magnitude: 0.10833

Collected Steps per Second: 24,498.14048
Overall Steps per Second: 14,704.91532

Timestep Collection Time: 2.04195
Timestep Consumption Time: 1.35990
PPO Batch Consumption Time: 0.09796
Total Iteration Time: 3.40186

Cumulative Model Updates: 1,274
Cumulative Timesteps: 10,703,786

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 10703786...
Checkpoint 10703786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.18495
Policy Entropy: 1.92539
Value Function Loss: 1.55626

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06666
Policy Update Magnitude: 0.12718
Value Function Update Magnitude: 0.10428

Collected Steps per Second: 23,670.32550
Overall Steps per Second: 14,407.30817

Timestep Collection Time: 2.11362
Timestep Consumption Time: 1.35893
PPO Batch Consumption Time: 0.10099
Total Iteration Time: 3.47254

Cumulative Model Updates: 1,280
Cumulative Timesteps: 10,753,816

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.45686
Policy Entropy: 1.89753
Value Function Loss: 1.58229

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.07273
Policy Update Magnitude: 0.11831
Value Function Update Magnitude: 0.10454

Collected Steps per Second: 23,017.51188
Overall Steps per Second: 14,451.44567

Timestep Collection Time: 2.17330
Timestep Consumption Time: 1.28822
PPO Batch Consumption Time: 0.10189
Total Iteration Time: 3.46152

Cumulative Model Updates: 1,286
Cumulative Timesteps: 10,803,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 10803840...
Checkpoint 10803840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.89655
Policy Entropy: 1.91962
Value Function Loss: 1.56024

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06946
Policy Update Magnitude: 0.14936
Value Function Update Magnitude: 0.11122

Collected Steps per Second: 23,267.26336
Overall Steps per Second: 14,189.08473

Timestep Collection Time: 2.14980
Timestep Consumption Time: 1.37544
PPO Batch Consumption Time: 0.10309
Total Iteration Time: 3.52525

Cumulative Model Updates: 1,292
Cumulative Timesteps: 10,853,860

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.21031
Policy Entropy: 1.89968
Value Function Loss: 1.48682

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.07100
Policy Update Magnitude: 0.14148
Value Function Update Magnitude: 0.10726

Collected Steps per Second: 23,928.26916
Overall Steps per Second: 14,559.79543

Timestep Collection Time: 2.09025
Timestep Consumption Time: 1.34497
PPO Batch Consumption Time: 0.10358
Total Iteration Time: 3.43521

Cumulative Model Updates: 1,298
Cumulative Timesteps: 10,903,876

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 10903876...
Checkpoint 10903876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.68542
Policy Entropy: 1.89133
Value Function Loss: 1.40389

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.07070
Policy Update Magnitude: 0.13023
Value Function Update Magnitude: 0.10709

Collected Steps per Second: 23,957.81654
Overall Steps per Second: 14,691.06279

Timestep Collection Time: 2.08759
Timestep Consumption Time: 1.31680
PPO Batch Consumption Time: 0.09555
Total Iteration Time: 3.40438

Cumulative Model Updates: 1,304
Cumulative Timesteps: 10,953,890

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.37309
Policy Entropy: 1.90010
Value Function Loss: 1.45654

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06623
Policy Update Magnitude: 0.14486
Value Function Update Magnitude: 0.12307

Collected Steps per Second: 23,472.46046
Overall Steps per Second: 14,324.44932

Timestep Collection Time: 2.13024
Timestep Consumption Time: 1.36043
PPO Batch Consumption Time: 0.10193
Total Iteration Time: 3.49068

Cumulative Model Updates: 1,310
Cumulative Timesteps: 11,003,892

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 11003892...
Checkpoint 11003892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.22944
Policy Entropy: 1.86371
Value Function Loss: 1.46527

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.05228
Policy Update Magnitude: 0.16701
Value Function Update Magnitude: 0.13292

Collected Steps per Second: 23,193.51502
Overall Steps per Second: 14,432.19378

Timestep Collection Time: 2.15603
Timestep Consumption Time: 1.30886
PPO Batch Consumption Time: 0.09554
Total Iteration Time: 3.46489

Cumulative Model Updates: 1,316
Cumulative Timesteps: 11,053,898

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.80243
Policy Entropy: 1.86244
Value Function Loss: 1.47113

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.07040
Policy Update Magnitude: 0.15528
Value Function Update Magnitude: 0.13363

Collected Steps per Second: 24,174.35659
Overall Steps per Second: 14,749.08334

Timestep Collection Time: 2.06889
Timestep Consumption Time: 1.32210
PPO Batch Consumption Time: 0.09762
Total Iteration Time: 3.39099

Cumulative Model Updates: 1,322
Cumulative Timesteps: 11,103,912

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 11103912...
Checkpoint 11103912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.42586
Policy Entropy: 1.86598
Value Function Loss: 1.46556

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05878
Policy Update Magnitude: 0.14723
Value Function Update Magnitude: 0.12249

Collected Steps per Second: 22,566.50665
Overall Steps per Second: 13,963.31200

Timestep Collection Time: 2.21691
Timestep Consumption Time: 1.36590
PPO Batch Consumption Time: 0.09427
Total Iteration Time: 3.58282

Cumulative Model Updates: 1,328
Cumulative Timesteps: 11,153,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.23537
Policy Entropy: 1.84027
Value Function Loss: 1.54839

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06099
Policy Update Magnitude: 0.14949
Value Function Update Magnitude: 0.11698

Collected Steps per Second: 23,414.39407
Overall Steps per Second: 14,780.73801

Timestep Collection Time: 2.13757
Timestep Consumption Time: 1.24859
PPO Batch Consumption Time: 0.09426
Total Iteration Time: 3.38616

Cumulative Model Updates: 1,334
Cumulative Timesteps: 11,203,990

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 11203990...
Checkpoint 11203990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.03500
Policy Entropy: 1.81829
Value Function Loss: 1.56288

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06848
Policy Update Magnitude: 0.16190
Value Function Update Magnitude: 0.11421

Collected Steps per Second: 22,987.84536
Overall Steps per Second: 14,051.88572

Timestep Collection Time: 2.17567
Timestep Consumption Time: 1.38357
PPO Batch Consumption Time: 0.10653
Total Iteration Time: 3.55924

Cumulative Model Updates: 1,340
Cumulative Timesteps: 11,254,004

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.12352
Policy Entropy: 1.83479
Value Function Loss: 1.51335

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04441
Policy Update Magnitude: 0.16717
Value Function Update Magnitude: 0.10754

Collected Steps per Second: 23,546.62774
Overall Steps per Second: 14,605.13223

Timestep Collection Time: 2.12498
Timestep Consumption Time: 1.30094
PPO Batch Consumption Time: 0.09631
Total Iteration Time: 3.42592

Cumulative Model Updates: 1,346
Cumulative Timesteps: 11,304,040

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 11304040...
Checkpoint 11304040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.89259
Policy Entropy: 1.80858
Value Function Loss: 1.44706

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05446
Policy Update Magnitude: 0.16302
Value Function Update Magnitude: 0.13817

Collected Steps per Second: 23,882.15247
Overall Steps per Second: 14,596.11117

Timestep Collection Time: 2.09412
Timestep Consumption Time: 1.33228
PPO Batch Consumption Time: 0.09983
Total Iteration Time: 3.42639

Cumulative Model Updates: 1,352
Cumulative Timesteps: 11,354,052

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.67300
Policy Entropy: 1.79302
Value Function Loss: 1.41494

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.04835
Policy Update Magnitude: 0.16052
Value Function Update Magnitude: 0.15194

Collected Steps per Second: 23,079.82605
Overall Steps per Second: 14,316.43982

Timestep Collection Time: 2.16648
Timestep Consumption Time: 1.32615
PPO Batch Consumption Time: 0.09724
Total Iteration Time: 3.49263

Cumulative Model Updates: 1,358
Cumulative Timesteps: 11,404,054

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 11404054...
Checkpoint 11404054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.85913
Policy Entropy: 1.80148
Value Function Loss: 1.37366

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05261
Policy Update Magnitude: 0.14998
Value Function Update Magnitude: 0.13280

Collected Steps per Second: 23,459.15153
Overall Steps per Second: 14,815.21816

Timestep Collection Time: 2.13171
Timestep Consumption Time: 1.24374
PPO Batch Consumption Time: 0.09533
Total Iteration Time: 3.37545

Cumulative Model Updates: 1,364
Cumulative Timesteps: 11,454,062

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.96881
Policy Entropy: 1.75593
Value Function Loss: 1.32690

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.07193
Policy Update Magnitude: 0.12858
Value Function Update Magnitude: 0.12525

Collected Steps per Second: 23,822.04690
Overall Steps per Second: 14,708.40561

Timestep Collection Time: 2.09898
Timestep Consumption Time: 1.30057
PPO Batch Consumption Time: 0.09355
Total Iteration Time: 3.39955

Cumulative Model Updates: 1,370
Cumulative Timesteps: 11,504,064

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 11504064...
Checkpoint 11504064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.95028
Policy Entropy: 1.77222
Value Function Loss: 1.32440

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.07037
Policy Update Magnitude: 0.10957
Value Function Update Magnitude: 0.12052

Collected Steps per Second: 22,865.42655
Overall Steps per Second: 14,502.06836

Timestep Collection Time: 2.18784
Timestep Consumption Time: 1.26173
PPO Batch Consumption Time: 0.10063
Total Iteration Time: 3.44958

Cumulative Model Updates: 1,376
Cumulative Timesteps: 11,554,090

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.75099
Policy Entropy: 1.72027
Value Function Loss: 1.37185

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06853
Policy Update Magnitude: 0.09770
Value Function Update Magnitude: 0.11812

Collected Steps per Second: 23,547.74764
Overall Steps per Second: 14,381.30620

Timestep Collection Time: 2.12377
Timestep Consumption Time: 1.35366
PPO Batch Consumption Time: 0.10060
Total Iteration Time: 3.47743

Cumulative Model Updates: 1,382
Cumulative Timesteps: 11,604,100

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 11604100...
Checkpoint 11604100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.00919
Policy Entropy: 1.72143
Value Function Loss: 1.40110

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06468
Policy Update Magnitude: 0.08973
Value Function Update Magnitude: 0.11089

Collected Steps per Second: 23,644.90531
Overall Steps per Second: 14,743.01401

Timestep Collection Time: 2.11538
Timestep Consumption Time: 1.27728
PPO Batch Consumption Time: 0.09448
Total Iteration Time: 3.39266

Cumulative Model Updates: 1,388
Cumulative Timesteps: 11,654,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.26477
Policy Entropy: 1.71393
Value Function Loss: 1.44113

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06283
Policy Update Magnitude: 0.10016
Value Function Update Magnitude: 0.10720

Collected Steps per Second: 23,232.97481
Overall Steps per Second: 14,755.61579

Timestep Collection Time: 2.15297
Timestep Consumption Time: 1.23692
PPO Batch Consumption Time: 0.09492
Total Iteration Time: 3.38990

Cumulative Model Updates: 1,394
Cumulative Timesteps: 11,704,138

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 11704138...
Checkpoint 11704138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.42786
Policy Entropy: 1.69160
Value Function Loss: 1.46444

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.07067
Policy Update Magnitude: 0.10759
Value Function Update Magnitude: 0.10829

Collected Steps per Second: 23,483.40786
Overall Steps per Second: 14,400.15261

Timestep Collection Time: 2.12933
Timestep Consumption Time: 1.34313
PPO Batch Consumption Time: 0.10131
Total Iteration Time: 3.47246

Cumulative Model Updates: 1,400
Cumulative Timesteps: 11,754,142

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.29584
Policy Entropy: 1.70016
Value Function Loss: 1.51385

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.08193
Policy Update Magnitude: 0.11916
Value Function Update Magnitude: 0.11200

Collected Steps per Second: 23,687.17028
Overall Steps per Second: 14,518.00156

Timestep Collection Time: 2.11228
Timestep Consumption Time: 1.33406
PPO Batch Consumption Time: 0.10217
Total Iteration Time: 3.44634

Cumulative Model Updates: 1,406
Cumulative Timesteps: 11,804,176

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 11804176...
Checkpoint 11804176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.46044
Policy Entropy: 1.70069
Value Function Loss: 1.46630

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06560
Policy Update Magnitude: 0.10563
Value Function Update Magnitude: 0.11156

Collected Steps per Second: 23,832.19981
Overall Steps per Second: 14,631.67711

Timestep Collection Time: 2.09851
Timestep Consumption Time: 1.31956
PPO Batch Consumption Time: 0.09383
Total Iteration Time: 3.41806

Cumulative Model Updates: 1,412
Cumulative Timesteps: 11,854,188

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.33652
Policy Entropy: 1.69509
Value Function Loss: 1.46476

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.06239
Policy Update Magnitude: 0.10531
Value Function Update Magnitude: 0.13415

Collected Steps per Second: 23,255.14339
Overall Steps per Second: 14,230.04835

Timestep Collection Time: 2.15023
Timestep Consumption Time: 1.36374
PPO Batch Consumption Time: 0.10238
Total Iteration Time: 3.51397

Cumulative Model Updates: 1,418
Cumulative Timesteps: 11,904,192

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 11904192...
Checkpoint 11904192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.19022
Policy Entropy: 1.70264
Value Function Loss: 1.42763

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.04541
Policy Update Magnitude: 0.11102
Value Function Update Magnitude: 0.11850

Collected Steps per Second: 23,465.12760
Overall Steps per Second: 14,709.09361

Timestep Collection Time: 2.13116
Timestep Consumption Time: 1.26864
PPO Batch Consumption Time: 0.10231
Total Iteration Time: 3.39980

Cumulative Model Updates: 1,424
Cumulative Timesteps: 11,954,200

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.41886
Policy Entropy: 1.69056
Value Function Loss: 1.43933

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05209
Policy Update Magnitude: 0.12149
Value Function Update Magnitude: 0.11924

Collected Steps per Second: 23,512.64672
Overall Steps per Second: 14,584.63882

Timestep Collection Time: 2.12754
Timestep Consumption Time: 1.30237
PPO Batch Consumption Time: 0.09184
Total Iteration Time: 3.42991

Cumulative Model Updates: 1,430
Cumulative Timesteps: 12,004,224

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 12004224...
Checkpoint 12004224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.80752
Policy Entropy: 1.71231
Value Function Loss: 1.40951

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.05078
Policy Update Magnitude: 0.12682
Value Function Update Magnitude: 0.12395

Collected Steps per Second: 23,399.95278
Overall Steps per Second: 14,362.98977

Timestep Collection Time: 2.13718
Timestep Consumption Time: 1.34468
PPO Batch Consumption Time: 0.10215
Total Iteration Time: 3.48187

Cumulative Model Updates: 1,436
Cumulative Timesteps: 12,054,234

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.90302
Policy Entropy: 1.67776
Value Function Loss: 1.38971

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05735
Policy Update Magnitude: 0.13329
Value Function Update Magnitude: 0.11786

Collected Steps per Second: 24,391.64933
Overall Steps per Second: 14,672.30388

Timestep Collection Time: 2.05128
Timestep Consumption Time: 1.35882
PPO Batch Consumption Time: 0.10192
Total Iteration Time: 3.41010

Cumulative Model Updates: 1,442
Cumulative Timesteps: 12,104,268

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 12104268...
Checkpoint 12104268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.51297
Policy Entropy: 1.66442
Value Function Loss: 1.36189

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.08162
Policy Update Magnitude: 0.10829
Value Function Update Magnitude: 0.11865

Collected Steps per Second: 23,027.63975
Overall Steps per Second: 14,131.04018

Timestep Collection Time: 2.17226
Timestep Consumption Time: 1.36761
PPO Batch Consumption Time: 0.10153
Total Iteration Time: 3.53987

Cumulative Model Updates: 1,448
Cumulative Timesteps: 12,154,290

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.78716
Policy Entropy: 1.69582
Value Function Loss: 1.33826

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.11240
Policy Update Magnitude: 0.11051
Value Function Update Magnitude: 0.11489

Collected Steps per Second: 23,406.02701
Overall Steps per Second: 14,662.89240

Timestep Collection Time: 2.13740
Timestep Consumption Time: 1.27448
PPO Batch Consumption Time: 0.10040
Total Iteration Time: 3.41188

Cumulative Model Updates: 1,454
Cumulative Timesteps: 12,204,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 12204318...
Checkpoint 12204318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.69568
Policy Entropy: 1.63489
Value Function Loss: 1.39324

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.14510
Policy Update Magnitude: 0.08445
Value Function Update Magnitude: 0.12233

Collected Steps per Second: 23,047.92836
Overall Steps per Second: 14,229.45209

Timestep Collection Time: 2.16965
Timestep Consumption Time: 1.34461
PPO Batch Consumption Time: 0.09942
Total Iteration Time: 3.51426

Cumulative Model Updates: 1,460
Cumulative Timesteps: 12,254,324

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.41309
Policy Entropy: 1.66254
Value Function Loss: 1.44944

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07920
Policy Update Magnitude: 0.09311
Value Function Update Magnitude: 0.13429

Collected Steps per Second: 23,225.14596
Overall Steps per Second: 14,349.25319

Timestep Collection Time: 2.15284
Timestep Consumption Time: 1.33166
PPO Batch Consumption Time: 0.10052
Total Iteration Time: 3.48450

Cumulative Model Updates: 1,466
Cumulative Timesteps: 12,304,324

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 12304324...
Checkpoint 12304324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.91915
Policy Entropy: 1.62089
Value Function Loss: 1.47578

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08148
Policy Update Magnitude: 0.09084
Value Function Update Magnitude: 0.11672

Collected Steps per Second: 24,341.57533
Overall Steps per Second: 14,809.93034

Timestep Collection Time: 2.05426
Timestep Consumption Time: 1.32212
PPO Batch Consumption Time: 0.09836
Total Iteration Time: 3.37638

Cumulative Model Updates: 1,472
Cumulative Timesteps: 12,354,328

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.26657
Policy Entropy: 1.62137
Value Function Loss: 1.48510

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06532
Policy Update Magnitude: 0.10335
Value Function Update Magnitude: 0.12718

Collected Steps per Second: 23,511.20010
Overall Steps per Second: 14,688.87796

Timestep Collection Time: 2.12818
Timestep Consumption Time: 1.27821
PPO Batch Consumption Time: 0.09371
Total Iteration Time: 3.40639

Cumulative Model Updates: 1,478
Cumulative Timesteps: 12,404,364

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 12404364...
Checkpoint 12404364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.91859
Policy Entropy: 1.63456
Value Function Loss: 1.46833

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05665
Policy Update Magnitude: 0.11996
Value Function Update Magnitude: 0.13570

Collected Steps per Second: 22,677.71004
Overall Steps per Second: 14,280.68726

Timestep Collection Time: 2.20543
Timestep Consumption Time: 1.29679
PPO Batch Consumption Time: 0.10175
Total Iteration Time: 3.50221

Cumulative Model Updates: 1,484
Cumulative Timesteps: 12,454,378

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.36081
Policy Entropy: 1.59986
Value Function Loss: 1.46649

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05631
Policy Update Magnitude: 0.11159
Value Function Update Magnitude: 0.12383

Collected Steps per Second: 23,904.84695
Overall Steps per Second: 14,597.39733

Timestep Collection Time: 2.09288
Timestep Consumption Time: 1.33444
PPO Batch Consumption Time: 0.09951
Total Iteration Time: 3.42732

Cumulative Model Updates: 1,490
Cumulative Timesteps: 12,504,408

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 12504408...
Checkpoint 12504408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.54838
Policy Entropy: 1.61639
Value Function Loss: 1.42111

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.06340
Policy Update Magnitude: 0.10800
Value Function Update Magnitude: 0.12096

Collected Steps per Second: 23,170.21312
Overall Steps per Second: 14,258.00236

Timestep Collection Time: 2.15924
Timestep Consumption Time: 1.34967
PPO Batch Consumption Time: 0.10159
Total Iteration Time: 3.50891

Cumulative Model Updates: 1,496
Cumulative Timesteps: 12,554,438

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.65445
Policy Entropy: 1.62702
Value Function Loss: 1.38716

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.06330
Policy Update Magnitude: 0.09864
Value Function Update Magnitude: 0.12223

Collected Steps per Second: 24,724.69501
Overall Steps per Second: 14,772.07717

Timestep Collection Time: 2.02259
Timestep Consumption Time: 1.36271
PPO Batch Consumption Time: 0.10050
Total Iteration Time: 3.38531

Cumulative Model Updates: 1,502
Cumulative Timesteps: 12,604,446

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 12604446...
Checkpoint 12604446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.05028
Policy Entropy: 1.63649
Value Function Loss: 1.37986

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03757
Policy Update Magnitude: 0.12068
Value Function Update Magnitude: 0.11678

Collected Steps per Second: 23,799.15697
Overall Steps per Second: 14,493.25556

Timestep Collection Time: 2.10125
Timestep Consumption Time: 1.34918
PPO Batch Consumption Time: 0.09749
Total Iteration Time: 3.45043

Cumulative Model Updates: 1,508
Cumulative Timesteps: 12,654,454

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.08055
Policy Entropy: 1.60574
Value Function Loss: 1.37281

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.04508
Policy Update Magnitude: 0.12774
Value Function Update Magnitude: 0.12157

Collected Steps per Second: 23,620.67204
Overall Steps per Second: 14,797.00974

Timestep Collection Time: 2.11679
Timestep Consumption Time: 1.26227
PPO Batch Consumption Time: 0.09984
Total Iteration Time: 3.37906

Cumulative Model Updates: 1,514
Cumulative Timesteps: 12,704,454

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 12704454...
Checkpoint 12704454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.21322
Policy Entropy: 1.59109
Value Function Loss: 1.37285

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04253
Policy Update Magnitude: 0.12293
Value Function Update Magnitude: 0.11548

Collected Steps per Second: 23,631.04465
Overall Steps per Second: 14,322.55312

Timestep Collection Time: 2.11671
Timestep Consumption Time: 1.37569
PPO Batch Consumption Time: 0.10120
Total Iteration Time: 3.49239

Cumulative Model Updates: 1,520
Cumulative Timesteps: 12,754,474

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.60370
Policy Entropy: 1.57125
Value Function Loss: 1.37029

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05692
Policy Update Magnitude: 0.10861
Value Function Update Magnitude: 0.11664

Collected Steps per Second: 23,745.78137
Overall Steps per Second: 14,470.97840

Timestep Collection Time: 2.10572
Timestep Consumption Time: 1.34961
PPO Batch Consumption Time: 0.10203
Total Iteration Time: 3.45533

Cumulative Model Updates: 1,526
Cumulative Timesteps: 12,804,476

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 12804476...
Checkpoint 12804476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.69827
Policy Entropy: 1.56718
Value Function Loss: 1.34858

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.06146
Policy Update Magnitude: 0.09893
Value Function Update Magnitude: 0.12100

Collected Steps per Second: 24,065.56075
Overall Steps per Second: 14,711.32814

Timestep Collection Time: 2.07766
Timestep Consumption Time: 1.32108
PPO Batch Consumption Time: 0.09472
Total Iteration Time: 3.39874

Cumulative Model Updates: 1,532
Cumulative Timesteps: 12,854,476

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.16845
Policy Entropy: 1.57140
Value Function Loss: 1.31190

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05252
Policy Update Magnitude: 0.10395
Value Function Update Magnitude: 0.11887

Collected Steps per Second: 23,734.94904
Overall Steps per Second: 14,378.54406

Timestep Collection Time: 2.10744
Timestep Consumption Time: 1.37135
PPO Batch Consumption Time: 0.10136
Total Iteration Time: 3.47879

Cumulative Model Updates: 1,538
Cumulative Timesteps: 12,904,496

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 12904496...
Checkpoint 12904496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.99142
Policy Entropy: 1.55404
Value Function Loss: 1.34384

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.06453
Policy Update Magnitude: 0.10647
Value Function Update Magnitude: 0.11068

Collected Steps per Second: 23,317.08433
Overall Steps per Second: 14,553.08465

Timestep Collection Time: 2.14547
Timestep Consumption Time: 1.29202
PPO Batch Consumption Time: 0.10264
Total Iteration Time: 3.43748

Cumulative Model Updates: 1,544
Cumulative Timesteps: 12,954,522

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.21316
Policy Entropy: 1.54961
Value Function Loss: 1.37894

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05460
Policy Update Magnitude: 0.10733
Value Function Update Magnitude: 0.11590

Collected Steps per Second: 23,485.85852
Overall Steps per Second: 14,566.31742

Timestep Collection Time: 2.12954
Timestep Consumption Time: 1.30400
PPO Batch Consumption Time: 0.09545
Total Iteration Time: 3.43354

Cumulative Model Updates: 1,550
Cumulative Timesteps: 13,004,536

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 13004536...
Checkpoint 13004536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.26583
Policy Entropy: 1.51319
Value Function Loss: 1.38335

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.06214
Policy Update Magnitude: 0.10570
Value Function Update Magnitude: 0.12915

Collected Steps per Second: 23,317.38756
Overall Steps per Second: 14,305.35104

Timestep Collection Time: 2.14544
Timestep Consumption Time: 1.35158
PPO Batch Consumption Time: 0.10224
Total Iteration Time: 3.49701

Cumulative Model Updates: 1,556
Cumulative Timesteps: 13,054,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.91119
Policy Entropy: 1.50783
Value Function Loss: 1.35166

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.06241
Policy Update Magnitude: 0.09989
Value Function Update Magnitude: 0.13104

Collected Steps per Second: 23,460.98988
Overall Steps per Second: 14,674.41569

Timestep Collection Time: 2.13214
Timestep Consumption Time: 1.27665
PPO Batch Consumption Time: 0.10087
Total Iteration Time: 3.40879

Cumulative Model Updates: 1,562
Cumulative Timesteps: 13,104,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 13104584...
Checkpoint 13104584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.08480
Policy Entropy: 1.48823
Value Function Loss: 1.41449

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.05715
Policy Update Magnitude: 0.11470
Value Function Update Magnitude: 0.13498

Collected Steps per Second: 23,015.40562
Overall Steps per Second: 14,154.87257

Timestep Collection Time: 2.17298
Timestep Consumption Time: 1.36022
PPO Batch Consumption Time: 0.09930
Total Iteration Time: 3.53320

Cumulative Model Updates: 1,568
Cumulative Timesteps: 13,154,596

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.28633
Policy Entropy: 1.48876
Value Function Loss: 1.43264

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06873
Policy Update Magnitude: 0.10283
Value Function Update Magnitude: 0.14117

Collected Steps per Second: 23,610.40323
Overall Steps per Second: 14,463.43928

Timestep Collection Time: 2.11822
Timestep Consumption Time: 1.33960
PPO Batch Consumption Time: 0.09963
Total Iteration Time: 3.45782

Cumulative Model Updates: 1,574
Cumulative Timesteps: 13,204,608

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 13204608...
Checkpoint 13204608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.50043
Policy Entropy: 1.48966
Value Function Loss: 1.38605

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04486
Policy Update Magnitude: 0.11012
Value Function Update Magnitude: 0.13132

Collected Steps per Second: 24,219.63748
Overall Steps per Second: 14,795.21775

Timestep Collection Time: 2.06510
Timestep Consumption Time: 1.31545
PPO Batch Consumption Time: 0.09696
Total Iteration Time: 3.38055

Cumulative Model Updates: 1,580
Cumulative Timesteps: 13,254,624

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.77265
Policy Entropy: 1.49374
Value Function Loss: 1.36751

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04632
Policy Update Magnitude: 0.12126
Value Function Update Magnitude: 0.12221

Collected Steps per Second: 23,147.49345
Overall Steps per Second: 14,247.66659

Timestep Collection Time: 2.16032
Timestep Consumption Time: 1.34945
PPO Batch Consumption Time: 0.10162
Total Iteration Time: 3.50977

Cumulative Model Updates: 1,586
Cumulative Timesteps: 13,304,630

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 13304630...
Checkpoint 13304630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.55707
Policy Entropy: 1.46420
Value Function Loss: 1.37330

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.06208
Policy Update Magnitude: 0.10551
Value Function Update Magnitude: 0.11470

Collected Steps per Second: 23,405.24726
Overall Steps per Second: 14,526.27306

Timestep Collection Time: 2.13679
Timestep Consumption Time: 1.30608
PPO Batch Consumption Time: 0.09894
Total Iteration Time: 3.44287

Cumulative Model Updates: 1,592
Cumulative Timesteps: 13,354,642

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.17860
Policy Entropy: 1.44866
Value Function Loss: 1.42023

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.06093
Policy Update Magnitude: 0.09261
Value Function Update Magnitude: 0.11256

Collected Steps per Second: 24,045.25018
Overall Steps per Second: 14,687.69705

Timestep Collection Time: 2.08033
Timestep Consumption Time: 1.32538
PPO Batch Consumption Time: 0.09613
Total Iteration Time: 3.40571

Cumulative Model Updates: 1,598
Cumulative Timesteps: 13,404,664

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 13404664...
Checkpoint 13404664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.19220
Policy Entropy: 1.43857
Value Function Loss: 1.36680

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05912
Policy Update Magnitude: 0.08272
Value Function Update Magnitude: 0.11623

Collected Steps per Second: 22,580.51832
Overall Steps per Second: 14,108.82031

Timestep Collection Time: 2.21510
Timestep Consumption Time: 1.33006
PPO Batch Consumption Time: 0.10055
Total Iteration Time: 3.54516

Cumulative Model Updates: 1,604
Cumulative Timesteps: 13,454,682

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.64278
Policy Entropy: 1.45124
Value Function Loss: 1.41465

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03115
Policy Update Magnitude: 0.11011
Value Function Update Magnitude: 0.12432

Collected Steps per Second: 24,731.69180
Overall Steps per Second: 14,767.59839

Timestep Collection Time: 2.02251
Timestep Consumption Time: 1.36464
PPO Batch Consumption Time: 0.10235
Total Iteration Time: 3.38715

Cumulative Model Updates: 1,610
Cumulative Timesteps: 13,504,702

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 13504702...
Checkpoint 13504702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.31780
Policy Entropy: 1.45674
Value Function Loss: 1.38839

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05515
Policy Update Magnitude: 0.11754
Value Function Update Magnitude: 0.11872

Collected Steps per Second: 23,511.45249
Overall Steps per Second: 14,679.59758

Timestep Collection Time: 2.12756
Timestep Consumption Time: 1.28003
PPO Batch Consumption Time: 0.09114
Total Iteration Time: 3.40759

Cumulative Model Updates: 1,616
Cumulative Timesteps: 13,554,724

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.84936
Policy Entropy: 1.47243
Value Function Loss: 1.43767

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04860
Policy Update Magnitude: 0.11435
Value Function Update Magnitude: 0.12325

Collected Steps per Second: 22,975.63195
Overall Steps per Second: 14,752.64422

Timestep Collection Time: 2.17657
Timestep Consumption Time: 1.21320
PPO Batch Consumption Time: 0.09093
Total Iteration Time: 3.38977

Cumulative Model Updates: 1,622
Cumulative Timesteps: 13,604,732

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 13604732...
Checkpoint 13604732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.00993
Policy Entropy: 1.42752
Value Function Loss: 1.44250

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.07386
Policy Update Magnitude: 0.10751
Value Function Update Magnitude: 0.12031

Collected Steps per Second: 23,438.49188
Overall Steps per Second: 14,438.10116

Timestep Collection Time: 2.13452
Timestep Consumption Time: 1.33061
PPO Batch Consumption Time: 0.10129
Total Iteration Time: 3.46514

Cumulative Model Updates: 1,628
Cumulative Timesteps: 13,654,762

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.17879
Policy Entropy: 1.43793
Value Function Loss: 1.50904

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.06321
Policy Update Magnitude: 0.10427
Value Function Update Magnitude: 0.11568

Collected Steps per Second: 23,712.46750
Overall Steps per Second: 14,550.57884

Timestep Collection Time: 2.11070
Timestep Consumption Time: 1.32902
PPO Batch Consumption Time: 0.10321
Total Iteration Time: 3.43973

Cumulative Model Updates: 1,634
Cumulative Timesteps: 13,704,812

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 13704812...
Checkpoint 13704812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.98007
Policy Entropy: 1.43473
Value Function Loss: 1.51750

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07598
Policy Update Magnitude: 0.09468
Value Function Update Magnitude: 0.11340

Collected Steps per Second: 23,720.07504
Overall Steps per Second: 14,235.93000

Timestep Collection Time: 2.10876
Timestep Consumption Time: 1.40488
PPO Batch Consumption Time: 0.10245
Total Iteration Time: 3.51364

Cumulative Model Updates: 1,640
Cumulative Timesteps: 13,754,832

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.85629
Policy Entropy: 1.44155
Value Function Loss: 1.55443

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.08748
Policy Update Magnitude: 0.09056
Value Function Update Magnitude: 0.11499

Collected Steps per Second: 23,625.27491
Overall Steps per Second: 14,432.83038

Timestep Collection Time: 2.11655
Timestep Consumption Time: 1.34805
PPO Batch Consumption Time: 0.09973
Total Iteration Time: 3.46460

Cumulative Model Updates: 1,646
Cumulative Timesteps: 13,804,836

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 13804836...
Checkpoint 13804836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.51598
Policy Entropy: 1.44452
Value Function Loss: 1.49342

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06722
Policy Update Magnitude: 0.09260
Value Function Update Magnitude: 0.11845

Collected Steps per Second: 23,302.06839
Overall Steps per Second: 14,771.21495

Timestep Collection Time: 2.14642
Timestep Consumption Time: 1.23963
PPO Batch Consumption Time: 0.09706
Total Iteration Time: 3.38605

Cumulative Model Updates: 1,652
Cumulative Timesteps: 13,854,852

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.42348
Policy Entropy: 1.45392
Value Function Loss: 1.44089

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06435
Policy Update Magnitude: 0.09747
Value Function Update Magnitude: 0.11262

Collected Steps per Second: 22,968.14838
Overall Steps per Second: 14,055.48535

Timestep Collection Time: 2.17719
Timestep Consumption Time: 1.38057
PPO Batch Consumption Time: 0.10449
Total Iteration Time: 3.55776

Cumulative Model Updates: 1,658
Cumulative Timesteps: 13,904,858

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 13904858...
Checkpoint 13904858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.84978
Policy Entropy: 1.44997
Value Function Loss: 1.38539

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06925
Policy Update Magnitude: 0.11243
Value Function Update Magnitude: 0.11104

Collected Steps per Second: 23,515.69514
Overall Steps per Second: 14,638.84494

Timestep Collection Time: 2.12726
Timestep Consumption Time: 1.28995
PPO Batch Consumption Time: 0.09474
Total Iteration Time: 3.41721

Cumulative Model Updates: 1,664
Cumulative Timesteps: 13,954,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.25855
Policy Entropy: 1.45179
Value Function Loss: 1.42732

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04752
Policy Update Magnitude: 0.10879
Value Function Update Magnitude: 0.12116

Collected Steps per Second: 23,388.39105
Overall Steps per Second: 14,839.59163

Timestep Collection Time: 2.13901
Timestep Consumption Time: 1.23224
PPO Batch Consumption Time: 0.09292
Total Iteration Time: 3.37125

Cumulative Model Updates: 1,670
Cumulative Timesteps: 14,004,910

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 14004910...
Checkpoint 14004910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.69350
Policy Entropy: 1.44000
Value Function Loss: 1.45049

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05684
Policy Update Magnitude: 0.10471
Value Function Update Magnitude: 0.11923

Collected Steps per Second: 22,828.06581
Overall Steps per Second: 14,114.83947

Timestep Collection Time: 2.19099
Timestep Consumption Time: 1.35252
PPO Batch Consumption Time: 0.10083
Total Iteration Time: 3.54350

Cumulative Model Updates: 1,676
Cumulative Timesteps: 14,054,926

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.03459
Policy Entropy: 1.38908
Value Function Loss: 1.46900

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06918
Policy Update Magnitude: 0.09900
Value Function Update Magnitude: 0.11468

Collected Steps per Second: 23,957.80116
Overall Steps per Second: 14,665.98217

Timestep Collection Time: 2.08734
Timestep Consumption Time: 1.32246
PPO Batch Consumption Time: 0.09803
Total Iteration Time: 3.40980

Cumulative Model Updates: 1,682
Cumulative Timesteps: 14,104,934

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 14104934...
Checkpoint 14104934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.33347
Policy Entropy: 1.41232
Value Function Loss: 1.44676

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.06011
Policy Update Magnitude: 0.09390
Value Function Update Magnitude: 0.11418

Collected Steps per Second: 24,215.82719
Overall Steps per Second: 14,788.83312

Timestep Collection Time: 2.06576
Timestep Consumption Time: 1.31680
PPO Batch Consumption Time: 0.09566
Total Iteration Time: 3.38255

Cumulative Model Updates: 1,688
Cumulative Timesteps: 14,154,958

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.94330
Policy Entropy: 1.42014
Value Function Loss: 1.47331

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.06150
Policy Update Magnitude: 0.10179
Value Function Update Magnitude: 0.11887

Collected Steps per Second: 23,439.81541
Overall Steps per Second: 14,336.59538

Timestep Collection Time: 2.13381
Timestep Consumption Time: 1.35489
PPO Batch Consumption Time: 0.10158
Total Iteration Time: 3.48869

Cumulative Model Updates: 1,694
Cumulative Timesteps: 14,204,974

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 14204974...
Checkpoint 14204974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.84397
Policy Entropy: 1.41520
Value Function Loss: 1.53230

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08141
Policy Update Magnitude: 0.09891
Value Function Update Magnitude: 0.12373

Collected Steps per Second: 23,260.96068
Overall Steps per Second: 14,591.47090

Timestep Collection Time: 2.15038
Timestep Consumption Time: 1.27765
PPO Batch Consumption Time: 0.10195
Total Iteration Time: 3.42803

Cumulative Model Updates: 1,700
Cumulative Timesteps: 14,254,994

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.77321
Policy Entropy: 1.38299
Value Function Loss: 1.58172

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.06466
Policy Update Magnitude: 0.08874
Value Function Update Magnitude: 0.12025

Collected Steps per Second: 23,464.51621
Overall Steps per Second: 14,544.66943

Timestep Collection Time: 2.13139
Timestep Consumption Time: 1.30712
PPO Batch Consumption Time: 0.09303
Total Iteration Time: 3.43851

Cumulative Model Updates: 1,706
Cumulative Timesteps: 14,305,006

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 14305006...
Checkpoint 14305006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.74566
Policy Entropy: 1.36726
Value Function Loss: 1.57269

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.05421
Policy Update Magnitude: 0.09832
Value Function Update Magnitude: 0.12735

Collected Steps per Second: 23,270.67261
Overall Steps per Second: 14,439.71034

Timestep Collection Time: 2.14940
Timestep Consumption Time: 1.31452
PPO Batch Consumption Time: 0.10070
Total Iteration Time: 3.46392

Cumulative Model Updates: 1,712
Cumulative Timesteps: 14,355,024

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.36924
Policy Entropy: 1.36669
Value Function Loss: 1.54421

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.07148
Policy Update Magnitude: 0.09535
Value Function Update Magnitude: 0.13108

Collected Steps per Second: 24,781.95020
Overall Steps per Second: 15,172.98449

Timestep Collection Time: 2.01824
Timestep Consumption Time: 1.27814
PPO Batch Consumption Time: 0.09119
Total Iteration Time: 3.29639

Cumulative Model Updates: 1,718
Cumulative Timesteps: 14,405,040

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 14405040...
Checkpoint 14405040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.40870
Policy Entropy: 1.38361
Value Function Loss: 1.47098

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.07701
Policy Update Magnitude: 0.09909
Value Function Update Magnitude: 0.14661

Collected Steps per Second: 23,268.65379
Overall Steps per Second: 14,201.18679

Timestep Collection Time: 2.15010
Timestep Consumption Time: 1.37284
PPO Batch Consumption Time: 0.10308
Total Iteration Time: 3.52294

Cumulative Model Updates: 1,724
Cumulative Timesteps: 14,455,070

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.06605
Policy Entropy: 1.38881
Value Function Loss: 1.53100

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.08142
Policy Update Magnitude: 0.09774
Value Function Update Magnitude: 0.12716

Collected Steps per Second: 23,467.93305
Overall Steps per Second: 14,701.13565

Timestep Collection Time: 2.13116
Timestep Consumption Time: 1.27089
PPO Batch Consumption Time: 0.09943
Total Iteration Time: 3.40205

Cumulative Model Updates: 1,730
Cumulative Timesteps: 14,505,084

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 14505084...
Checkpoint 14505084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.57680
Policy Entropy: 1.42852
Value Function Loss: 1.51079

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06891
Policy Update Magnitude: 0.10578
Value Function Update Magnitude: 0.12599

Collected Steps per Second: 23,761.36139
Overall Steps per Second: 14,711.84458

Timestep Collection Time: 2.10577
Timestep Consumption Time: 1.29530
PPO Batch Consumption Time: 0.09283
Total Iteration Time: 3.40107

Cumulative Model Updates: 1,736
Cumulative Timesteps: 14,555,120

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.86265
Policy Entropy: 1.40931
Value Function Loss: 1.57748

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05865
Policy Update Magnitude: 0.10332
Value Function Update Magnitude: 0.11594

Collected Steps per Second: 23,381.70835
Overall Steps per Second: 14,377.16288

Timestep Collection Time: 2.13928
Timestep Consumption Time: 1.33985
PPO Batch Consumption Time: 0.10152
Total Iteration Time: 3.47913

Cumulative Model Updates: 1,742
Cumulative Timesteps: 14,605,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 14605140...
Checkpoint 14605140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.27564
Policy Entropy: 1.40483
Value Function Loss: 1.52094

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.06657
Policy Update Magnitude: 0.13120
Value Function Update Magnitude: 0.14702

Collected Steps per Second: 24,306.13148
Overall Steps per Second: 14,542.66652

Timestep Collection Time: 2.05767
Timestep Consumption Time: 1.38145
PPO Batch Consumption Time: 0.10015
Total Iteration Time: 3.43912

Cumulative Model Updates: 1,748
Cumulative Timesteps: 14,655,154

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.65743
Policy Entropy: 1.39306
Value Function Loss: 1.53689

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.07485
Policy Update Magnitude: 0.12399
Value Function Update Magnitude: 0.16653

Collected Steps per Second: 24,077.24363
Overall Steps per Second: 14,648.56195

Timestep Collection Time: 2.07682
Timestep Consumption Time: 1.33676
PPO Batch Consumption Time: 0.09693
Total Iteration Time: 3.41358

Cumulative Model Updates: 1,754
Cumulative Timesteps: 14,705,158

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 14705158...
Checkpoint 14705158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.81165
Policy Entropy: 1.39316
Value Function Loss: 1.54324

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08517
Policy Update Magnitude: 0.11785
Value Function Update Magnitude: 0.18480

Collected Steps per Second: 22,858.32541
Overall Steps per Second: 14,467.98884

Timestep Collection Time: 2.18800
Timestep Consumption Time: 1.26887
PPO Batch Consumption Time: 0.10083
Total Iteration Time: 3.45687

Cumulative Model Updates: 1,760
Cumulative Timesteps: 14,755,172

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.09826
Policy Entropy: 1.38108
Value Function Loss: 1.53444

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.11346
Value Function Update Magnitude: 0.19835

Collected Steps per Second: 24,110.19949
Overall Steps per Second: 14,511.97949

Timestep Collection Time: 2.07456
Timestep Consumption Time: 1.37211
PPO Batch Consumption Time: 0.09571
Total Iteration Time: 3.44667

Cumulative Model Updates: 1,766
Cumulative Timesteps: 14,805,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 14805190...
Checkpoint 14805190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.66324
Policy Entropy: 1.36633
Value Function Loss: 1.52823

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.09252
Policy Update Magnitude: 0.10684
Value Function Update Magnitude: 0.19532

Collected Steps per Second: 23,383.36667
Overall Steps per Second: 14,595.02682

Timestep Collection Time: 2.13861
Timestep Consumption Time: 1.28776
PPO Batch Consumption Time: 0.09605
Total Iteration Time: 3.42637

Cumulative Model Updates: 1,772
Cumulative Timesteps: 14,855,198

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.34369
Policy Entropy: 1.37265
Value Function Loss: 1.46725

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.07650
Policy Update Magnitude: 0.11349
Value Function Update Magnitude: 0.18428

Collected Steps per Second: 24,893.05917
Overall Steps per Second: 14,890.81675

Timestep Collection Time: 2.00948
Timestep Consumption Time: 1.34978
PPO Batch Consumption Time: 0.10144
Total Iteration Time: 3.35925

Cumulative Model Updates: 1,778
Cumulative Timesteps: 14,905,220

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 14905220...
Checkpoint 14905220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.69091
Policy Entropy: 1.34831
Value Function Loss: 1.43587

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06911
Policy Update Magnitude: 0.12814
Value Function Update Magnitude: 0.18887

Collected Steps per Second: 23,652.05734
Overall Steps per Second: 14,647.31952

Timestep Collection Time: 2.11483
Timestep Consumption Time: 1.30013
PPO Batch Consumption Time: 0.09289
Total Iteration Time: 3.41496

Cumulative Model Updates: 1,784
Cumulative Timesteps: 14,955,240

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.58464
Policy Entropy: 1.32707
Value Function Loss: 1.38282

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.08380
Policy Update Magnitude: 0.11082
Value Function Update Magnitude: 0.17457

Collected Steps per Second: 23,953.82699
Overall Steps per Second: 14,962.45901

Timestep Collection Time: 2.08919
Timestep Consumption Time: 1.25545
PPO Batch Consumption Time: 0.10080
Total Iteration Time: 3.34464

Cumulative Model Updates: 1,790
Cumulative Timesteps: 15,005,284

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 15005284...
Checkpoint 15005284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.63047
Policy Entropy: 1.33561
Value Function Loss: 1.39652

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.08155
Policy Update Magnitude: 0.12563
Value Function Update Magnitude: 0.15708

Collected Steps per Second: 23,709.15455
Overall Steps per Second: 14,703.37380

Timestep Collection Time: 2.10897
Timestep Consumption Time: 1.29174
PPO Batch Consumption Time: 0.09432
Total Iteration Time: 3.40072

Cumulative Model Updates: 1,796
Cumulative Timesteps: 15,055,286

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.71694
Policy Entropy: 1.37018
Value Function Loss: 1.41419

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06270
Policy Update Magnitude: 0.11908
Value Function Update Magnitude: 0.15658

Collected Steps per Second: 24,040.80836
Overall Steps per Second: 14,838.09403

Timestep Collection Time: 2.08138
Timestep Consumption Time: 1.29089
PPO Batch Consumption Time: 0.09921
Total Iteration Time: 3.37227

Cumulative Model Updates: 1,802
Cumulative Timesteps: 15,105,324

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 15105324...
Checkpoint 15105324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.03479
Policy Entropy: 1.40382
Value Function Loss: 1.39839

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.07110
Policy Update Magnitude: 0.14965
Value Function Update Magnitude: 0.15868

Collected Steps per Second: 23,573.22508
Overall Steps per Second: 14,817.71552

Timestep Collection Time: 2.12173
Timestep Consumption Time: 1.25369
PPO Batch Consumption Time: 0.09675
Total Iteration Time: 3.37542

Cumulative Model Updates: 1,808
Cumulative Timesteps: 15,155,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.14168
Policy Entropy: 1.39362
Value Function Loss: 1.34166

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.08235
Policy Update Magnitude: 0.13788
Value Function Update Magnitude: 0.15232

Collected Steps per Second: 23,816.96342
Overall Steps per Second: 14,668.02270

Timestep Collection Time: 2.09976
Timestep Consumption Time: 1.30969
PPO Batch Consumption Time: 0.09472
Total Iteration Time: 3.40946

Cumulative Model Updates: 1,814
Cumulative Timesteps: 15,205,350

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 15205350...
Checkpoint 15205350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.30699
Policy Entropy: 1.39458
Value Function Loss: 1.29814

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.06746
Policy Update Magnitude: 0.14456
Value Function Update Magnitude: 0.14735

Collected Steps per Second: 23,759.36835
Overall Steps per Second: 14,835.51829

Timestep Collection Time: 2.10536
Timestep Consumption Time: 1.26641
PPO Batch Consumption Time: 0.09152
Total Iteration Time: 3.37177

Cumulative Model Updates: 1,820
Cumulative Timesteps: 15,255,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.97951
Policy Entropy: 1.35670
Value Function Loss: 1.26522

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07872
Policy Update Magnitude: 0.13135
Value Function Update Magnitude: 0.14978

Collected Steps per Second: 24,922.57715
Overall Steps per Second: 14,950.14313

Timestep Collection Time: 2.00726
Timestep Consumption Time: 1.33893
PPO Batch Consumption Time: 0.10071
Total Iteration Time: 3.34619

Cumulative Model Updates: 1,826
Cumulative Timesteps: 15,305,398

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 15305398...
Checkpoint 15305398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.55357
Policy Entropy: 1.35106
Value Function Loss: 1.29938

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05420
Policy Update Magnitude: 0.14403
Value Function Update Magnitude: 0.14634

Collected Steps per Second: 23,569.64347
Overall Steps per Second: 14,396.88615

Timestep Collection Time: 2.12265
Timestep Consumption Time: 1.35241
PPO Batch Consumption Time: 0.10135
Total Iteration Time: 3.47506

Cumulative Model Updates: 1,832
Cumulative Timesteps: 15,355,428

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.36775
Policy Entropy: 1.33478
Value Function Loss: 1.28844

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.06734
Policy Update Magnitude: 0.14985
Value Function Update Magnitude: 0.13387

Collected Steps per Second: 24,100.59701
Overall Steps per Second: 15,082.30238

Timestep Collection Time: 2.07580
Timestep Consumption Time: 1.24120
PPO Batch Consumption Time: 0.09466
Total Iteration Time: 3.31700

Cumulative Model Updates: 1,838
Cumulative Timesteps: 15,405,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 15405456...
Checkpoint 15405456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.83845
Policy Entropy: 1.31973
Value Function Loss: 1.33074

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.06318
Policy Update Magnitude: 0.14039
Value Function Update Magnitude: 0.12681

Collected Steps per Second: 23,924.64631
Overall Steps per Second: 14,506.11921

Timestep Collection Time: 2.09098
Timestep Consumption Time: 1.35763
PPO Batch Consumption Time: 0.10030
Total Iteration Time: 3.44861

Cumulative Model Updates: 1,844
Cumulative Timesteps: 15,455,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.21504
Policy Entropy: 1.30071
Value Function Loss: 1.33558

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.07227
Policy Update Magnitude: 0.12741
Value Function Update Magnitude: 0.11897

Collected Steps per Second: 23,776.10067
Overall Steps per Second: 14,615.66549

Timestep Collection Time: 2.10405
Timestep Consumption Time: 1.31872
PPO Batch Consumption Time: 0.10145
Total Iteration Time: 3.42277

Cumulative Model Updates: 1,850
Cumulative Timesteps: 15,505,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 15505508...
Checkpoint 15505508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.33261
Policy Entropy: 1.27160
Value Function Loss: 1.35180

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08483
Policy Update Magnitude: 0.11621
Value Function Update Magnitude: 0.11727

Collected Steps per Second: 24,727.81656
Overall Steps per Second: 14,838.74573

Timestep Collection Time: 2.02307
Timestep Consumption Time: 1.34824
PPO Batch Consumption Time: 0.10162
Total Iteration Time: 3.37131

Cumulative Model Updates: 1,856
Cumulative Timesteps: 15,555,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.53421
Policy Entropy: 1.28491
Value Function Loss: 1.31653

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07663
Policy Update Magnitude: 0.10833
Value Function Update Magnitude: 0.11845

Collected Steps per Second: 24,052.07953
Overall Steps per Second: 14,563.51630

Timestep Collection Time: 2.07940
Timestep Consumption Time: 1.35479
PPO Batch Consumption Time: 0.10200
Total Iteration Time: 3.43420

Cumulative Model Updates: 1,862
Cumulative Timesteps: 15,605,548

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 15605548...
Checkpoint 15605548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.69590
Policy Entropy: 1.25442
Value Function Loss: 1.27866

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07397
Policy Update Magnitude: 0.10036
Value Function Update Magnitude: 0.11530

Collected Steps per Second: 23,186.33885
Overall Steps per Second: 14,726.91021

Timestep Collection Time: 2.15791
Timestep Consumption Time: 1.23955
PPO Batch Consumption Time: 0.09609
Total Iteration Time: 3.39745

Cumulative Model Updates: 1,868
Cumulative Timesteps: 15,655,582

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.78111
Policy Entropy: 1.27375
Value Function Loss: 1.24682

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05416
Policy Update Magnitude: 0.11544
Value Function Update Magnitude: 0.11592

Collected Steps per Second: 24,171.52282
Overall Steps per Second: 14,734.97443

Timestep Collection Time: 2.06963
Timestep Consumption Time: 1.32543
PPO Batch Consumption Time: 0.09685
Total Iteration Time: 3.39505

Cumulative Model Updates: 1,874
Cumulative Timesteps: 15,705,608

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 15705608...
Checkpoint 15705608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.98452
Policy Entropy: 1.26781
Value Function Loss: 1.19125

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04076
Policy Update Magnitude: 0.15117
Value Function Update Magnitude: 0.13296

Collected Steps per Second: 23,542.03339
Overall Steps per Second: 14,803.64534

Timestep Collection Time: 2.12539
Timestep Consumption Time: 1.25459
PPO Batch Consumption Time: 0.09190
Total Iteration Time: 3.37998

Cumulative Model Updates: 1,880
Cumulative Timesteps: 15,755,644

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.72039
Policy Entropy: 1.26348
Value Function Loss: 1.19097

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.07216
Policy Update Magnitude: 0.14965
Value Function Update Magnitude: 0.13958

Collected Steps per Second: 24,656.20143
Overall Steps per Second: 14,899.42471

Timestep Collection Time: 2.02846
Timestep Consumption Time: 1.32832
PPO Batch Consumption Time: 0.09869
Total Iteration Time: 3.35677

Cumulative Model Updates: 1,886
Cumulative Timesteps: 15,805,658

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 15805658...
Checkpoint 15805658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.77451
Policy Entropy: 1.25357
Value Function Loss: 1.16568

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.06235
Policy Update Magnitude: 0.13089
Value Function Update Magnitude: 0.13163

Collected Steps per Second: 23,625.53443
Overall Steps per Second: 14,414.82725

Timestep Collection Time: 2.11754
Timestep Consumption Time: 1.35305
PPO Batch Consumption Time: 0.10104
Total Iteration Time: 3.47059

Cumulative Model Updates: 1,892
Cumulative Timesteps: 15,855,686

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.76506
Policy Entropy: 1.26121
Value Function Loss: 1.19972

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07873
Policy Update Magnitude: 0.12603
Value Function Update Magnitude: 0.11728

Collected Steps per Second: 23,275.20707
Overall Steps per Second: 14,739.64524

Timestep Collection Time: 2.14821
Timestep Consumption Time: 1.24400
PPO Batch Consumption Time: 0.09751
Total Iteration Time: 3.39221

Cumulative Model Updates: 1,898
Cumulative Timesteps: 15,905,686

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 15905686...
Checkpoint 15905686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.75067
Policy Entropy: 1.25444
Value Function Loss: 1.15044

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07400
Policy Update Magnitude: 0.11982
Value Function Update Magnitude: 0.10440

Collected Steps per Second: 23,416.82572
Overall Steps per Second: 14,400.57962

Timestep Collection Time: 2.13607
Timestep Consumption Time: 1.33740
PPO Batch Consumption Time: 0.09964
Total Iteration Time: 3.47347

Cumulative Model Updates: 1,904
Cumulative Timesteps: 15,955,706

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.25745
Policy Entropy: 1.24731
Value Function Loss: 1.19920

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06902
Policy Update Magnitude: 0.11492
Value Function Update Magnitude: 0.10381

Collected Steps per Second: 24,068.74418
Overall Steps per Second: 14,767.17525

Timestep Collection Time: 2.07738
Timestep Consumption Time: 1.30850
PPO Batch Consumption Time: 0.09861
Total Iteration Time: 3.38589

Cumulative Model Updates: 1,910
Cumulative Timesteps: 16,005,706

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 16005706...
Checkpoint 16005706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.56152
Policy Entropy: 1.21039
Value Function Loss: 1.20931

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.10883
Value Function Update Magnitude: 0.11305

Collected Steps per Second: 24,537.09850
Overall Steps per Second: 14,811.49038

Timestep Collection Time: 2.03822
Timestep Consumption Time: 1.33835
PPO Batch Consumption Time: 0.09773
Total Iteration Time: 3.37657

Cumulative Model Updates: 1,916
Cumulative Timesteps: 16,055,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.65461
Policy Entropy: 1.19596
Value Function Loss: 1.21836

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10176
Policy Update Magnitude: 0.10442
Value Function Update Magnitude: 0.11695

Collected Steps per Second: 23,876.16933
Overall Steps per Second: 14,690.34912

Timestep Collection Time: 2.09456
Timestep Consumption Time: 1.30972
PPO Batch Consumption Time: 0.09511
Total Iteration Time: 3.40428

Cumulative Model Updates: 1,922
Cumulative Timesteps: 16,105,728

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 16105728...
Checkpoint 16105728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.21758
Policy Entropy: 1.18271
Value Function Loss: 1.18947

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06972
Policy Update Magnitude: 0.10101
Value Function Update Magnitude: 0.13400

Collected Steps per Second: 23,549.09347
Overall Steps per Second: 14,932.62274

Timestep Collection Time: 2.12416
Timestep Consumption Time: 1.22569
PPO Batch Consumption Time: 0.09640
Total Iteration Time: 3.34985

Cumulative Model Updates: 1,928
Cumulative Timesteps: 16,155,750

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.32691
Policy Entropy: 1.18520
Value Function Loss: 1.17232

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08588
Policy Update Magnitude: 0.10005
Value Function Update Magnitude: 0.18468

Collected Steps per Second: 23,821.45603
Overall Steps per Second: 14,645.35502

Timestep Collection Time: 2.09996
Timestep Consumption Time: 1.31573
PPO Batch Consumption Time: 0.09332
Total Iteration Time: 3.41569

Cumulative Model Updates: 1,934
Cumulative Timesteps: 16,205,774

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 16205774...
Checkpoint 16205774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.22786
Policy Entropy: 1.18237
Value Function Loss: 1.33011

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.06519
Policy Update Magnitude: 0.10763
Value Function Update Magnitude: 0.18875

Collected Steps per Second: 23,265.45660
Overall Steps per Second: 14,407.40978

Timestep Collection Time: 2.14937
Timestep Consumption Time: 1.32149
PPO Batch Consumption Time: 0.10174
Total Iteration Time: 3.47085

Cumulative Model Updates: 1,940
Cumulative Timesteps: 16,255,780

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.58348
Policy Entropy: 1.16950
Value Function Loss: 1.36571

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06602
Policy Update Magnitude: 0.10670
Value Function Update Magnitude: 0.16555

Collected Steps per Second: 24,884.48391
Overall Steps per Second: 14,890.27768

Timestep Collection Time: 2.01009
Timestep Consumption Time: 1.34915
PPO Batch Consumption Time: 0.10039
Total Iteration Time: 3.35924

Cumulative Model Updates: 1,946
Cumulative Timesteps: 16,305,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 16305800...
Checkpoint 16305800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.30190
Policy Entropy: 1.17563
Value Function Loss: 1.39198

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03745
Policy Update Magnitude: 0.11791
Value Function Update Magnitude: 0.16567

Collected Steps per Second: 23,475.94446
Overall Steps per Second: 14,432.23148

Timestep Collection Time: 2.13069
Timestep Consumption Time: 1.33516
PPO Batch Consumption Time: 0.09783
Total Iteration Time: 3.46585

Cumulative Model Updates: 1,952
Cumulative Timesteps: 16,355,820

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.87066
Policy Entropy: 1.16739
Value Function Loss: 1.31256

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04470
Policy Update Magnitude: 0.14648
Value Function Update Magnitude: 0.16424

Collected Steps per Second: 20,720.32666
Overall Steps per Second: 13,886.89955

Timestep Collection Time: 2.41444
Timestep Consumption Time: 1.18809
PPO Batch Consumption Time: 0.07619
Total Iteration Time: 3.60253

Cumulative Model Updates: 1,958
Cumulative Timesteps: 16,405,848

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 16405848...
Checkpoint 16405848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.40710
Policy Entropy: 1.16355
Value Function Loss: 1.27984

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03508
Policy Update Magnitude: 0.15479
Value Function Update Magnitude: 0.21824

Collected Steps per Second: 21,700.81916
Overall Steps per Second: 13,460.30060

Timestep Collection Time: 2.30526
Timestep Consumption Time: 1.41130
PPO Batch Consumption Time: 0.10742
Total Iteration Time: 3.71656

Cumulative Model Updates: 1,964
Cumulative Timesteps: 16,455,874

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.54630
Policy Entropy: 1.14113
Value Function Loss: 1.35212

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04742
Policy Update Magnitude: 0.14016
Value Function Update Magnitude: 0.21822

Collected Steps per Second: 20,822.05094
Overall Steps per Second: 13,911.38696

Timestep Collection Time: 2.40197
Timestep Consumption Time: 1.19321
PPO Batch Consumption Time: 0.07504
Total Iteration Time: 3.59518

Cumulative Model Updates: 1,970
Cumulative Timesteps: 16,505,888

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 16505888...
Checkpoint 16505888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.89581
Policy Entropy: 1.16354
Value Function Loss: 1.42104

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.05191
Policy Update Magnitude: 0.13495
Value Function Update Magnitude: 0.19355

Collected Steps per Second: 22,490.88053
Overall Steps per Second: 14,204.70278

Timestep Collection Time: 2.22392
Timestep Consumption Time: 1.29730
PPO Batch Consumption Time: 0.10315
Total Iteration Time: 3.52123

Cumulative Model Updates: 1,976
Cumulative Timesteps: 16,555,906

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.85568
Policy Entropy: 1.15701
Value Function Loss: 1.33367

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04487
Policy Update Magnitude: 0.13299
Value Function Update Magnitude: 0.15955

Collected Steps per Second: 20,266.04297
Overall Steps per Second: 12,980.69299

Timestep Collection Time: 2.46787
Timestep Consumption Time: 1.38508
PPO Batch Consumption Time: 0.09969
Total Iteration Time: 3.85295

Cumulative Model Updates: 1,982
Cumulative Timesteps: 16,605,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 16605920...
Checkpoint 16605920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.33441
Policy Entropy: 1.16624
Value Function Loss: 1.28376

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.06102
Policy Update Magnitude: 0.12774
Value Function Update Magnitude: 0.17658

Collected Steps per Second: 22,052.10711
Overall Steps per Second: 13,885.96461

Timestep Collection Time: 2.26935
Timestep Consumption Time: 1.33457
PPO Batch Consumption Time: 0.09975
Total Iteration Time: 3.60393

Cumulative Model Updates: 1,988
Cumulative Timesteps: 16,655,964

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.67303
Policy Entropy: 1.14832
Value Function Loss: 1.27636

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07410
Policy Update Magnitude: 0.14059
Value Function Update Magnitude: 0.19280

Collected Steps per Second: 22,138.64788
Overall Steps per Second: 14,340.59756

Timestep Collection Time: 2.26066
Timestep Consumption Time: 1.22929
PPO Batch Consumption Time: 0.07999
Total Iteration Time: 3.48995

Cumulative Model Updates: 1,994
Cumulative Timesteps: 16,706,012

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 16706012...
Checkpoint 16706012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.29416
Policy Entropy: 1.15522
Value Function Loss: 1.33117

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07730
Policy Update Magnitude: 0.11960
Value Function Update Magnitude: 0.21414

Collected Steps per Second: 21,521.37259
Overall Steps per Second: 13,552.77522

Timestep Collection Time: 2.32420
Timestep Consumption Time: 1.36656
PPO Batch Consumption Time: 0.09902
Total Iteration Time: 3.69076

Cumulative Model Updates: 2,000
Cumulative Timesteps: 16,756,032

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.18373
Policy Entropy: 1.12935
Value Function Loss: 1.34542

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.11927
Value Function Update Magnitude: 0.19860

Collected Steps per Second: 21,229.38037
Overall Steps per Second: 14,252.23546

Timestep Collection Time: 2.35692
Timestep Consumption Time: 1.15383
PPO Batch Consumption Time: 0.07981
Total Iteration Time: 3.51075

Cumulative Model Updates: 2,006
Cumulative Timesteps: 16,806,068

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 16806068...
Checkpoint 16806068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.12317
Policy Entropy: 1.14642
Value Function Loss: 1.39956

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10613
Policy Update Magnitude: 0.10194
Value Function Update Magnitude: 0.24310

Collected Steps per Second: 19,853.18503
Overall Steps per Second: 12,755.20320

Timestep Collection Time: 2.51929
Timestep Consumption Time: 1.40193
PPO Batch Consumption Time: 0.10203
Total Iteration Time: 3.92122

Cumulative Model Updates: 2,012
Cumulative Timesteps: 16,856,084

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.21605
Policy Entropy: 1.13136
Value Function Loss: 1.36392

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07459
Policy Update Magnitude: 0.09274
Value Function Update Magnitude: 0.29642

Collected Steps per Second: 21,134.22243
Overall Steps per Second: 13,125.20968

Timestep Collection Time: 2.36649
Timestep Consumption Time: 1.44404
PPO Batch Consumption Time: 0.10626
Total Iteration Time: 3.81053

Cumulative Model Updates: 2,018
Cumulative Timesteps: 16,906,098

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 16906098...
Checkpoint 16906098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.35465
Policy Entropy: 1.12504
Value Function Loss: 1.33468

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.11117
Policy Update Magnitude: 0.09645
Value Function Update Magnitude: 0.26668

Collected Steps per Second: 21,201.87060
Overall Steps per Second: 13,572.30070

Timestep Collection Time: 2.35894
Timestep Consumption Time: 1.32606
PPO Batch Consumption Time: 0.08125
Total Iteration Time: 3.68501

Cumulative Model Updates: 2,024
Cumulative Timesteps: 16,956,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.25238
Policy Entropy: 1.13705
Value Function Loss: 1.32462

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.08340
Value Function Update Magnitude: 0.21723

Collected Steps per Second: 20,547.59796
Overall Steps per Second: 13,303.28696

Timestep Collection Time: 2.43406
Timestep Consumption Time: 1.32547
PPO Batch Consumption Time: 0.09199
Total Iteration Time: 3.75952

Cumulative Model Updates: 2,030
Cumulative Timesteps: 17,006,126

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 17006126...
Checkpoint 17006126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.97387
Policy Entropy: 1.12556
Value Function Loss: 1.36928

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05886
Policy Update Magnitude: 0.11021
Value Function Update Magnitude: 0.23301

Collected Steps per Second: 18,230.22444
Overall Steps per Second: 12,205.48435

Timestep Collection Time: 2.74555
Timestep Consumption Time: 1.35523
PPO Batch Consumption Time: 0.10473
Total Iteration Time: 4.10078

Cumulative Model Updates: 2,036
Cumulative Timesteps: 17,056,178

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.20037
Policy Entropy: 1.09433
Value Function Loss: 1.36692

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05824
Policy Update Magnitude: 0.12115
Value Function Update Magnitude: 0.21733

Collected Steps per Second: 14,333.58311
Overall Steps per Second: 10,491.41360

Timestep Collection Time: 3.48915
Timestep Consumption Time: 1.27780
PPO Batch Consumption Time: 0.07682
Total Iteration Time: 4.76695

Cumulative Model Updates: 2,042
Cumulative Timesteps: 17,106,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 17106190...
Checkpoint 17106190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.05032
Policy Entropy: 1.08999
Value Function Loss: 1.36347

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05861
Policy Update Magnitude: 0.12650
Value Function Update Magnitude: 0.17813

Collected Steps per Second: 14,596.20952
Overall Steps per Second: 10,289.05265

Timestep Collection Time: 3.42692
Timestep Consumption Time: 1.43456
PPO Batch Consumption Time: 0.09763
Total Iteration Time: 4.86148

Cumulative Model Updates: 2,048
Cumulative Timesteps: 17,156,210

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.54315
Policy Entropy: 1.08844
Value Function Loss: 1.34885

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.06302
Policy Update Magnitude: 0.12549
Value Function Update Magnitude: 0.15948

Collected Steps per Second: 15,271.83500
Overall Steps per Second: 10,305.01696

Timestep Collection Time: 3.27400
Timestep Consumption Time: 1.57800
PPO Batch Consumption Time: 0.12508
Total Iteration Time: 4.85201

Cumulative Model Updates: 2,054
Cumulative Timesteps: 17,206,210

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 17206210...
Checkpoint 17206210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.96856
Policy Entropy: 1.07491
Value Function Loss: 1.31740

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.08414
Policy Update Magnitude: 0.12912
Value Function Update Magnitude: 0.17572

Collected Steps per Second: 16,393.99227
Overall Steps per Second: 10,596.64671

Timestep Collection Time: 3.05112
Timestep Consumption Time: 1.66924
PPO Batch Consumption Time: 0.13725
Total Iteration Time: 4.72036

Cumulative Model Updates: 2,060
Cumulative Timesteps: 17,256,230

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.63756
Policy Entropy: 1.07641
Value Function Loss: 1.27451

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09741
Policy Update Magnitude: 0.10390
Value Function Update Magnitude: 0.17944

Collected Steps per Second: 16,137.63002
Overall Steps per Second: 10,784.95014

Timestep Collection Time: 3.10021
Timestep Consumption Time: 1.53866
PPO Batch Consumption Time: 0.13854
Total Iteration Time: 4.63887

Cumulative Model Updates: 2,066
Cumulative Timesteps: 17,306,260

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 17306260...
Checkpoint 17306260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.94143
Policy Entropy: 1.08272
Value Function Loss: 1.30320

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.06857
Policy Update Magnitude: 0.08645
Value Function Update Magnitude: 0.15854

Collected Steps per Second: 16,147.12143
Overall Steps per Second: 10,768.51026

Timestep Collection Time: 3.09702
Timestep Consumption Time: 1.54689
PPO Batch Consumption Time: 0.12229
Total Iteration Time: 4.64391

Cumulative Model Updates: 2,072
Cumulative Timesteps: 17,356,268

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.88727
Policy Entropy: 1.04864
Value Function Loss: 1.37785

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.05160
Policy Update Magnitude: 0.09115
Value Function Update Magnitude: 0.11580

Collected Steps per Second: 14,972.43284
Overall Steps per Second: 10,119.20281

Timestep Collection Time: 3.34041
Timestep Consumption Time: 1.60208
PPO Batch Consumption Time: 0.13164
Total Iteration Time: 4.94248

Cumulative Model Updates: 2,078
Cumulative Timesteps: 17,406,282

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 17406282...
Checkpoint 17406282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.49185
Policy Entropy: 1.07127
Value Function Loss: 1.33738

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04793
Policy Update Magnitude: 0.10280
Value Function Update Magnitude: 0.09747

Collected Steps per Second: 15,319.39511
Overall Steps per Second: 10,208.71563

Timestep Collection Time: 3.26423
Timestep Consumption Time: 1.63414
PPO Batch Consumption Time: 0.13784
Total Iteration Time: 4.89836

Cumulative Model Updates: 2,084
Cumulative Timesteps: 17,456,288

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.23183
Policy Entropy: 1.05992
Value Function Loss: 1.41026

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03242
Policy Update Magnitude: 0.11160
Value Function Update Magnitude: 0.10258

Collected Steps per Second: 15,686.57512
Overall Steps per Second: 10,573.99651

Timestep Collection Time: 3.18833
Timestep Consumption Time: 1.54157
PPO Batch Consumption Time: 0.12460
Total Iteration Time: 4.72991

Cumulative Model Updates: 2,090
Cumulative Timesteps: 17,506,302

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 17506302...
Checkpoint 17506302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.16482
Policy Entropy: 1.07190
Value Function Loss: 1.48498

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03157
Policy Update Magnitude: 0.12069
Value Function Update Magnitude: 0.10133

Collected Steps per Second: 15,929.12127
Overall Steps per Second: 10,937.32623

Timestep Collection Time: 3.13891
Timestep Consumption Time: 1.43260
PPO Batch Consumption Time: 0.12497
Total Iteration Time: 4.57150

Cumulative Model Updates: 2,096
Cumulative Timesteps: 17,556,302

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.53512
Policy Entropy: 1.06480
Value Function Loss: 1.53623

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03039
Policy Update Magnitude: 0.14026
Value Function Update Magnitude: 0.09845

Collected Steps per Second: 16,224.71226
Overall Steps per Second: 10,710.63647

Timestep Collection Time: 3.08270
Timestep Consumption Time: 1.58705
PPO Batch Consumption Time: 0.12395
Total Iteration Time: 4.66975

Cumulative Model Updates: 2,102
Cumulative Timesteps: 17,606,318

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 17606318...
Checkpoint 17606318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.11737
Policy Entropy: 1.02127
Value Function Loss: 1.48373

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.05287
Policy Update Magnitude: 0.13008
Value Function Update Magnitude: 0.09723

Collected Steps per Second: 15,992.53145
Overall Steps per Second: 10,726.24928

Timestep Collection Time: 3.12971
Timestep Consumption Time: 1.53660
PPO Batch Consumption Time: 0.12568
Total Iteration Time: 4.66631

Cumulative Model Updates: 2,108
Cumulative Timesteps: 17,656,370

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.00876
Policy Entropy: 1.05062
Value Function Loss: 1.35275

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06078
Policy Update Magnitude: 0.10040
Value Function Update Magnitude: 0.09310

Collected Steps per Second: 17,176.65387
Overall Steps per Second: 10,997.23561

Timestep Collection Time: 2.91267
Timestep Consumption Time: 1.63665
PPO Batch Consumption Time: 0.13128
Total Iteration Time: 4.54933

Cumulative Model Updates: 2,114
Cumulative Timesteps: 17,706,400

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 17706400...
Checkpoint 17706400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.24722
Policy Entropy: 1.04654
Value Function Loss: 1.35047

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03583
Policy Update Magnitude: 0.10152
Value Function Update Magnitude: 0.09159

Collected Steps per Second: 13,960.66577
Overall Steps per Second: 9,780.06561

Timestep Collection Time: 3.58393
Timestep Consumption Time: 1.53199
PPO Batch Consumption Time: 0.12434
Total Iteration Time: 5.11592

Cumulative Model Updates: 2,120
Cumulative Timesteps: 17,756,434

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.05771
Policy Entropy: 1.03326
Value Function Loss: 1.42602

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03779
Policy Update Magnitude: 0.12414
Value Function Update Magnitude: 0.09873

Collected Steps per Second: 16,227.23501
Overall Steps per Second: 11,044.06018

Timestep Collection Time: 3.08284
Timestep Consumption Time: 1.44683
PPO Batch Consumption Time: 0.12443
Total Iteration Time: 4.52967

Cumulative Model Updates: 2,126
Cumulative Timesteps: 17,806,460

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 17806460...
Checkpoint 17806460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.13887
Policy Entropy: 1.01193
Value Function Loss: 1.53392

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03596
Policy Update Magnitude: 0.12835
Value Function Update Magnitude: 0.10424

Collected Steps per Second: 15,345.68861
Overall Steps per Second: 10,265.21363

Timestep Collection Time: 3.25850
Timestep Consumption Time: 1.61270
PPO Batch Consumption Time: 0.12622
Total Iteration Time: 4.87121

Cumulative Model Updates: 2,132
Cumulative Timesteps: 17,856,464

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.37105
Policy Entropy: 1.02187
Value Function Loss: 1.50162

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03892
Policy Update Magnitude: 0.14328
Value Function Update Magnitude: 0.10968

Collected Steps per Second: 15,948.01181
Overall Steps per Second: 10,563.60914

Timestep Collection Time: 3.13782
Timestep Consumption Time: 1.59939
PPO Batch Consumption Time: 0.12796
Total Iteration Time: 4.73721

Cumulative Model Updates: 2,138
Cumulative Timesteps: 17,906,506

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 17906506...
Checkpoint 17906506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.65268
Policy Entropy: 1.01653
Value Function Loss: 1.47535

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04464
Policy Update Magnitude: 0.13957
Value Function Update Magnitude: 0.11161

Collected Steps per Second: 16,972.19652
Overall Steps per Second: 10,986.36237

Timestep Collection Time: 2.94647
Timestep Consumption Time: 1.60536
PPO Batch Consumption Time: 0.13512
Total Iteration Time: 4.55183

Cumulative Model Updates: 2,144
Cumulative Timesteps: 17,956,514

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.95202
Policy Entropy: 1.03636
Value Function Loss: 1.47908

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05666
Policy Update Magnitude: 0.14059
Value Function Update Magnitude: 0.10969

Collected Steps per Second: 15,994.67074
Overall Steps per Second: 10,296.82471

Timestep Collection Time: 3.12929
Timestep Consumption Time: 1.73162
PPO Batch Consumption Time: 0.14956
Total Iteration Time: 4.86092

Cumulative Model Updates: 2,150
Cumulative Timesteps: 18,006,566

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 18006566...
Checkpoint 18006566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.24945
Policy Entropy: 1.01511
Value Function Loss: 1.52849

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05916
Policy Update Magnitude: 0.13255
Value Function Update Magnitude: 0.10381

Collected Steps per Second: 15,880.26944
Overall Steps per Second: 10,862.76979

Timestep Collection Time: 3.14919
Timestep Consumption Time: 1.45461
PPO Batch Consumption Time: 0.11225
Total Iteration Time: 4.60380

Cumulative Model Updates: 2,156
Cumulative Timesteps: 18,056,576

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.23513
Policy Entropy: 1.03686
Value Function Loss: 1.58090

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07469
Policy Update Magnitude: 0.12993
Value Function Update Magnitude: 0.12435

Collected Steps per Second: 17,474.12269
Overall Steps per Second: 11,270.03154

Timestep Collection Time: 2.86412
Timestep Consumption Time: 1.57668
PPO Batch Consumption Time: 0.11394
Total Iteration Time: 4.44080

Cumulative Model Updates: 2,162
Cumulative Timesteps: 18,106,624

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 18106624...
Checkpoint 18106624 saved!
