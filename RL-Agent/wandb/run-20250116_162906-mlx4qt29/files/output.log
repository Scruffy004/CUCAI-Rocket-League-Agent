Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 106.16219
Policy Entropy: 3.68247
Value Function Loss: 394.66431

Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.12117
Value Function Update Magnitude: 0.02104

Collected Steps per Second: 3,934.58690
Overall Steps per Second: 2,668.64175

Timestep Collection Time: 12.71239
Timestep Consumption Time: 6.03048
PPO Batch Consumption Time: 4.57519
Total Iteration Time: 18.74287

Cumulative Model Updates: 3,711
Cumulative Timesteps: 61,969,060

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.01426
Policy Entropy: 3.78298
Value Function Loss: 262.46103

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04406
Policy Update Magnitude: 0.22569
Value Function Update Magnitude: 0.06310

Collected Steps per Second: 6,091.39518
Overall Steps per Second: 5,446.69971

Timestep Collection Time: 8.21290
Timestep Consumption Time: 0.97211
PPO Batch Consumption Time: 0.10887
Total Iteration Time: 9.18501

Cumulative Model Updates: 3,713
Cumulative Timesteps: 62,019,088

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 62019088...
Checkpoint 62019088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132.65561
Policy Entropy: 3.71079
Value Function Loss: 215.50623

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.06665
Policy Update Magnitude: 0.25014
Value Function Update Magnitude: 0.14258

Collected Steps per Second: 6,737.75101
Overall Steps per Second: 5,823.03593

Timestep Collection Time: 7.42503
Timestep Consumption Time: 1.16637
PPO Batch Consumption Time: 0.10018
Total Iteration Time: 8.59139

Cumulative Model Updates: 3,716
Cumulative Timesteps: 62,069,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.71305
Policy Entropy: 3.76700
Value Function Loss: 121.54128

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.06285
Policy Update Magnitude: 0.22757
Value Function Update Magnitude: 0.18126

Collected Steps per Second: 9,358.24954
Overall Steps per Second: 7,839.50486

Timestep Collection Time: 5.34373
Timestep Consumption Time: 1.03524
PPO Batch Consumption Time: 0.04465
Total Iteration Time: 6.37897

Cumulative Model Updates: 3,719
Cumulative Timesteps: 62,119,124

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 62119124...
Checkpoint 62119124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.39382
Policy Entropy: 3.76656
Value Function Loss: 112.20717

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.04231
Policy Update Magnitude: 0.20782
Value Function Update Magnitude: 0.20274

Collected Steps per Second: 6,007.05160
Overall Steps per Second: 5,290.83482

Timestep Collection Time: 8.32954
Timestep Consumption Time: 1.12756
PPO Batch Consumption Time: 0.11088
Total Iteration Time: 9.45711

Cumulative Model Updates: 3,722
Cumulative Timesteps: 62,169,160

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.07524
Policy Entropy: 3.74627
Value Function Loss: 108.20076

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.03611
Policy Update Magnitude: 0.18409
Value Function Update Magnitude: 0.20247

Collected Steps per Second: 5,084.30121
Overall Steps per Second: 4,521.89669

Timestep Collection Time: 9.84049
Timestep Consumption Time: 1.22390
PPO Batch Consumption Time: 0.10954
Total Iteration Time: 11.06438

Cumulative Model Updates: 3,725
Cumulative Timesteps: 62,219,192

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 62219192...
Checkpoint 62219192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.41187
Policy Entropy: 3.67269
Value Function Loss: 104.40568

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.04759
Policy Update Magnitude: 0.20961
Value Function Update Magnitude: 0.20881

Collected Steps per Second: 5,053.57939
Overall Steps per Second: 4,576.44043

Timestep Collection Time: 9.90031
Timestep Consumption Time: 1.03220
PPO Batch Consumption Time: 0.10703
Total Iteration Time: 10.93251

Cumulative Model Updates: 3,728
Cumulative Timesteps: 62,269,224

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.86052
Policy Entropy: 3.63172
Value Function Loss: 103.99150

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.03713
Policy Update Magnitude: 0.20374
Value Function Update Magnitude: 0.23518

Collected Steps per Second: 5,098.68400
Overall Steps per Second: 4,564.11377

Timestep Collection Time: 9.81037
Timestep Consumption Time: 1.14904
PPO Batch Consumption Time: 0.11105
Total Iteration Time: 10.95941

Cumulative Model Updates: 3,731
Cumulative Timesteps: 62,319,244

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 62319244...
Checkpoint 62319244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97.23645
Policy Entropy: 3.60834
Value Function Loss: 95.78451

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.03965
Policy Update Magnitude: 0.19076
Value Function Update Magnitude: 0.23527

Collected Steps per Second: 5,052.36989
Overall Steps per Second: 4,493.18515

Timestep Collection Time: 9.89793
Timestep Consumption Time: 1.23181
PPO Batch Consumption Time: 0.11188
Total Iteration Time: 11.12974

Cumulative Model Updates: 3,734
Cumulative Timesteps: 62,369,252

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.66139
Policy Entropy: 3.62036
Value Function Loss: 92.47936

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.03617
Policy Update Magnitude: 0.19571
Value Function Update Magnitude: 0.25865

Collected Steps per Second: 5,070.42407
Overall Steps per Second: 4,580.17706

Timestep Collection Time: 9.86702
Timestep Consumption Time: 1.05613
PPO Batch Consumption Time: 0.11121
Total Iteration Time: 10.92316

Cumulative Model Updates: 3,737
Cumulative Timesteps: 62,419,282

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 62419282...
Checkpoint 62419282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.07264
Policy Entropy: 3.63112
Value Function Loss: 85.73389

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.03086
Policy Update Magnitude: 0.17789
Value Function Update Magnitude: 0.27037

Collected Steps per Second: 5,058.35236
Overall Steps per Second: 4,542.31090

Timestep Collection Time: 9.88662
Timestep Consumption Time: 1.12320
PPO Batch Consumption Time: 0.10603
Total Iteration Time: 11.00981

Cumulative Model Updates: 3,740
Cumulative Timesteps: 62,469,292

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.03879
Policy Entropy: 3.64788
Value Function Loss: 84.77739

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02412
Policy Update Magnitude: 0.17979
Value Function Update Magnitude: 0.28619

Collected Steps per Second: 5,088.46182
Overall Steps per Second: 4,608.65749

Timestep Collection Time: 9.83008
Timestep Consumption Time: 1.02340
PPO Batch Consumption Time: 0.10854
Total Iteration Time: 10.85349

Cumulative Model Updates: 3,743
Cumulative Timesteps: 62,519,312

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 62519312...
Checkpoint 62519312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.80233
Policy Entropy: 3.64805
Value Function Loss: 78.45975

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.01605
Policy Update Magnitude: 0.18741
Value Function Update Magnitude: 0.27911

Collected Steps per Second: 5,129.15263
Overall Steps per Second: 4,591.17193

Timestep Collection Time: 9.74820
Timestep Consumption Time: 1.14227
PPO Batch Consumption Time: 0.10703
Total Iteration Time: 10.89047

Cumulative Model Updates: 3,746
Cumulative Timesteps: 62,569,312

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.32859
Policy Entropy: 3.66901
Value Function Loss: 76.32886

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.00711
Policy Update Magnitude: 0.23426
Value Function Update Magnitude: 0.25747

Collected Steps per Second: 5,134.55449
Overall Steps per Second: 4,606.61120

Timestep Collection Time: 9.73794
Timestep Consumption Time: 1.11602
PPO Batch Consumption Time: 0.10938
Total Iteration Time: 10.85397

Cumulative Model Updates: 3,749
Cumulative Timesteps: 62,619,312

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 62619312...
Checkpoint 62619312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.39383
Policy Entropy: 3.65434
Value Function Loss: 74.44450

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.01949
Policy Update Magnitude: 0.25382
Value Function Update Magnitude: 0.25363

Collected Steps per Second: 4,999.64977
Overall Steps per Second: 4,531.37042

Timestep Collection Time: 10.00350
Timestep Consumption Time: 1.03378
PPO Batch Consumption Time: 0.10954
Total Iteration Time: 11.03728

Cumulative Model Updates: 3,752
Cumulative Timesteps: 62,669,326

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.57160
Policy Entropy: 3.61283
Value Function Loss: 73.77413

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.01473
Policy Update Magnitude: 0.24834
Value Function Update Magnitude: 0.25094

Collected Steps per Second: 5,349.98471
Overall Steps per Second: 4,761.40806

Timestep Collection Time: 9.34806
Timestep Consumption Time: 1.15555
PPO Batch Consumption Time: 0.11439
Total Iteration Time: 10.50362

Cumulative Model Updates: 3,755
Cumulative Timesteps: 62,719,338

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 62719338...
Checkpoint 62719338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140.78285
Policy Entropy: 3.59395
Value Function Loss: 70.94662

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01053
Policy Update Magnitude: 0.26262
Value Function Update Magnitude: 0.25481

Collected Steps per Second: 5,460.08581
Overall Steps per Second: 4,893.36487

Timestep Collection Time: 9.15956
Timestep Consumption Time: 1.06081
PPO Batch Consumption Time: 0.11623
Total Iteration Time: 10.22037

Cumulative Model Updates: 3,758
Cumulative Timesteps: 62,769,350

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.26924
Policy Entropy: 3.60299
Value Function Loss: 67.93619

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.01538
Policy Update Magnitude: 0.25058
Value Function Update Magnitude: 0.24856

Collected Steps per Second: 5,442.27427
Overall Steps per Second: 4,825.07753

Timestep Collection Time: 9.19101
Timestep Consumption Time: 1.17566
PPO Batch Consumption Time: 0.11640
Total Iteration Time: 10.36667

Cumulative Model Updates: 3,761
Cumulative Timesteps: 62,819,370

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 62819370...
Checkpoint 62819370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.01142
Policy Entropy: 3.63733
Value Function Loss: 64.13632

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01028
Policy Update Magnitude: 0.24885
Value Function Update Magnitude: 0.22352

Collected Steps per Second: 5,383.45842
Overall Steps per Second: 4,772.27571

Timestep Collection Time: 9.29254
Timestep Consumption Time: 1.19009
PPO Batch Consumption Time: 0.11774
Total Iteration Time: 10.48263

Cumulative Model Updates: 3,764
Cumulative Timesteps: 62,869,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.67787
Policy Entropy: 3.68156
Value Function Loss: 60.95455

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.00675
Policy Update Magnitude: 0.25384
Value Function Update Magnitude: 0.21062

Collected Steps per Second: 5,380.13206
Overall Steps per Second: 4,771.10907

Timestep Collection Time: 9.29568
Timestep Consumption Time: 1.18658
PPO Batch Consumption Time: 0.11205
Total Iteration Time: 10.48226

Cumulative Model Updates: 3,767
Cumulative Timesteps: 62,919,408

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 62919408...
Checkpoint 62919408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126.71957
Policy Entropy: 3.67160
Value Function Loss: 58.45409

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.00643
Policy Update Magnitude: 0.23698
Value Function Update Magnitude: 0.18568

Collected Steps per Second: 5,122.47030
Overall Steps per Second: 4,513.22689

Timestep Collection Time: 9.76248
Timestep Consumption Time: 1.31784
PPO Batch Consumption Time: 0.10921
Total Iteration Time: 11.08032

Cumulative Model Updates: 3,770
Cumulative Timesteps: 62,969,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.54045
Policy Entropy: 3.66506
Value Function Loss: 59.61232

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.00999
Policy Update Magnitude: 0.23800
Value Function Update Magnitude: 0.18917

Collected Steps per Second: 5,216.29443
Overall Steps per Second: 4,623.02617

Timestep Collection Time: 9.59072
Timestep Consumption Time: 1.23077
PPO Batch Consumption Time: 0.11272
Total Iteration Time: 10.82148

Cumulative Model Updates: 3,773
Cumulative Timesteps: 63,019,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 63019444...
Checkpoint 63019444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.51210
Policy Entropy: 3.64973
Value Function Loss: 60.95301

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.00678
Policy Update Magnitude: 0.23691
Value Function Update Magnitude: 0.17725

Collected Steps per Second: 5,296.34274
Overall Steps per Second: 4,652.73767

Timestep Collection Time: 9.44539
Timestep Consumption Time: 1.30656
PPO Batch Consumption Time: 0.10837
Total Iteration Time: 10.75195

Cumulative Model Updates: 3,776
Cumulative Timesteps: 63,069,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.24228
Policy Entropy: 3.63777
Value Function Loss: 60.28403

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.00861
Policy Update Magnitude: 0.23410
Value Function Update Magnitude: 0.18886

Collected Steps per Second: 5,492.00895
Overall Steps per Second: 4,816.66257

Timestep Collection Time: 9.10887
Timestep Consumption Time: 1.27716
PPO Batch Consumption Time: 0.10670
Total Iteration Time: 10.38603

Cumulative Model Updates: 3,779
Cumulative Timesteps: 63,119,496

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 63119496...
Checkpoint 63119496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.63217
Policy Entropy: 3.62031
Value Function Loss: 58.93228

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.00751
Policy Update Magnitude: 0.23173
Value Function Update Magnitude: 0.20323

Collected Steps per Second: 5,213.93600
Overall Steps per Second: 4,600.74465

Timestep Collection Time: 9.59467
Timestep Consumption Time: 1.27879
PPO Batch Consumption Time: 0.11857
Total Iteration Time: 10.87346

Cumulative Model Updates: 3,782
Cumulative Timesteps: 63,169,522

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.20734
Policy Entropy: 3.60622
Value Function Loss: 55.73085

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.01982
Policy Update Magnitude: 0.21793
Value Function Update Magnitude: 0.20504

Collected Steps per Second: 5,011.24184
Overall Steps per Second: 4,371.92342

Timestep Collection Time: 9.98515
Timestep Consumption Time: 1.46016
PPO Batch Consumption Time: 0.12075
Total Iteration Time: 11.44531

Cumulative Model Updates: 3,785
Cumulative Timesteps: 63,219,560

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 63219560...
Checkpoint 63219560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.45920
Policy Entropy: 3.59006
Value Function Loss: 54.74699

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.01569
Policy Update Magnitude: 0.19387
Value Function Update Magnitude: 0.19507

Collected Steps per Second: 5,215.48406
Overall Steps per Second: 4,457.21834

Timestep Collection Time: 9.58914
Timestep Consumption Time: 1.63131
PPO Batch Consumption Time: 0.12560
Total Iteration Time: 11.22045

Cumulative Model Updates: 3,788
Cumulative Timesteps: 63,269,572

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.10318
Policy Entropy: 3.62062
Value Function Loss: 50.57844

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.01469
Policy Update Magnitude: 0.18504
Value Function Update Magnitude: 0.18605

Collected Steps per Second: 5,137.32704
Overall Steps per Second: 4,474.59364

Timestep Collection Time: 9.73463
Timestep Consumption Time: 1.44180
PPO Batch Consumption Time: 0.11071
Total Iteration Time: 11.17643

Cumulative Model Updates: 3,791
Cumulative Timesteps: 63,319,582

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 63319582...
Checkpoint 63319582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118.00842
Policy Entropy: 3.58996
Value Function Loss: 50.22900

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01326
Policy Update Magnitude: 0.18953
Value Function Update Magnitude: 0.19637

Collected Steps per Second: 5,252.25895
Overall Steps per Second: 4,609.66217

Timestep Collection Time: 9.52048
Timestep Consumption Time: 1.32717
PPO Batch Consumption Time: 0.10620
Total Iteration Time: 10.84765

Cumulative Model Updates: 3,794
Cumulative Timesteps: 63,369,586

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.30934
Policy Entropy: 3.60903
Value Function Loss: 48.97174

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01163
Policy Update Magnitude: 0.18149
Value Function Update Magnitude: 0.19988

Collected Steps per Second: 5,089.01693
Overall Steps per Second: 4,510.98199

Timestep Collection Time: 9.82508
Timestep Consumption Time: 1.25898
PPO Batch Consumption Time: 0.11573
Total Iteration Time: 11.08406

Cumulative Model Updates: 3,797
Cumulative Timesteps: 63,419,586

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 63419586...
Checkpoint 63419586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.63011
Policy Entropy: 3.59704
Value Function Loss: 48.92057

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.01159
Policy Update Magnitude: 0.18834
Value Function Update Magnitude: 0.18801

Collected Steps per Second: 4,883.77007
Overall Steps per Second: 4,293.55515

Timestep Collection Time: 10.24168
Timestep Consumption Time: 1.40788
PPO Batch Consumption Time: 0.11540
Total Iteration Time: 11.64955

Cumulative Model Updates: 3,800
Cumulative Timesteps: 63,469,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.01730
Policy Entropy: 3.60263
Value Function Loss: 49.33637

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01255
Policy Update Magnitude: 0.17529
Value Function Update Magnitude: 0.16874

Collected Steps per Second: 4,888.86533
Overall Steps per Second: 4,375.81155

Timestep Collection Time: 10.22773
Timestep Consumption Time: 1.19918
PPO Batch Consumption Time: 0.09031
Total Iteration Time: 11.42691

Cumulative Model Updates: 3,803
Cumulative Timesteps: 63,519,606

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 63519606...
Checkpoint 63519606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175.72830
Policy Entropy: 3.56695
Value Function Loss: 48.33263

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.01647
Policy Update Magnitude: 0.17383
Value Function Update Magnitude: 0.16147

Collected Steps per Second: 5,238.58724
Overall Steps per Second: 4,511.53246

Timestep Collection Time: 9.54990
Timestep Consumption Time: 1.53901
PPO Batch Consumption Time: 0.11339
Total Iteration Time: 11.08891

Cumulative Model Updates: 3,806
Cumulative Timesteps: 63,569,634

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.23514
Policy Entropy: 3.56553
Value Function Loss: 46.93971

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01112
Policy Update Magnitude: 0.17266
Value Function Update Magnitude: 0.17317

Collected Steps per Second: 5,045.49261
Overall Steps per Second: 4,401.29383

Timestep Collection Time: 9.91856
Timestep Consumption Time: 1.45174
PPO Batch Consumption Time: 0.11590
Total Iteration Time: 11.37029

Cumulative Model Updates: 3,809
Cumulative Timesteps: 63,619,678

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 63619678...
Checkpoint 63619678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158.01630
Policy Entropy: 3.55478
Value Function Loss: 43.99182

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.00971
Policy Update Magnitude: 0.16693
Value Function Update Magnitude: 0.15891

Collected Steps per Second: 5,099.98696
Overall Steps per Second: 4,524.52423

Timestep Collection Time: 9.80434
Timestep Consumption Time: 1.24699
PPO Batch Consumption Time: 0.10620
Total Iteration Time: 11.05133

Cumulative Model Updates: 3,812
Cumulative Timesteps: 63,669,680

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.04279
Policy Entropy: 3.54600
Value Function Loss: 43.58979

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01362
Policy Update Magnitude: 0.15536
Value Function Update Magnitude: 0.14246

Collected Steps per Second: 5,053.41178
Overall Steps per Second: 4,427.15361

Timestep Collection Time: 9.89589
Timestep Consumption Time: 1.39986
PPO Batch Consumption Time: 0.11690
Total Iteration Time: 11.29575

Cumulative Model Updates: 3,815
Cumulative Timesteps: 63,719,688

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 63719688...
Checkpoint 63719688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128.67693
Policy Entropy: 3.54240
Value Function Loss: 42.92847

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.00827
Policy Update Magnitude: 0.15832
Value Function Update Magnitude: 0.11931

Collected Steps per Second: 4,921.84194
Overall Steps per Second: 4,367.17005

Timestep Collection Time: 10.16896
Timestep Consumption Time: 1.29155
PPO Batch Consumption Time: 0.11356
Total Iteration Time: 11.46051

Cumulative Model Updates: 3,818
Cumulative Timesteps: 63,769,738

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.86766
Policy Entropy: 3.53707
Value Function Loss: 43.10873

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.00885
Policy Update Magnitude: 0.16310
Value Function Update Magnitude: 0.12379

Collected Steps per Second: 4,847.59881
Overall Steps per Second: 4,265.49132

Timestep Collection Time: 10.31604
Timestep Consumption Time: 1.40782
PPO Batch Consumption Time: 0.11439
Total Iteration Time: 11.72385

Cumulative Model Updates: 3,821
Cumulative Timesteps: 63,819,746

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 63819746...
Checkpoint 63819746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154.28308
Policy Entropy: 3.52441
Value Function Loss: 42.19654

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.01457
Policy Update Magnitude: 0.16784
Value Function Update Magnitude: 0.12485

Collected Steps per Second: 5,027.66239
Overall Steps per Second: 4,422.39742

Timestep Collection Time: 9.95294
Timestep Consumption Time: 1.36219
PPO Batch Consumption Time: 0.11456
Total Iteration Time: 11.31513

Cumulative Model Updates: 3,824
Cumulative Timesteps: 63,869,786

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.44153
Policy Entropy: 3.51976
Value Function Loss: 41.76557

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.01395
Policy Update Magnitude: 0.15152
Value Function Update Magnitude: 0.12174

Collected Steps per Second: 5,251.95196
Overall Steps per Second: 4,614.75082

Timestep Collection Time: 9.52484
Timestep Consumption Time: 1.31518
PPO Batch Consumption Time: 0.10687
Total Iteration Time: 10.84002

Cumulative Model Updates: 3,827
Cumulative Timesteps: 63,919,810

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 63919810...
Checkpoint 63919810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.96794
Policy Entropy: 3.52356
Value Function Loss: 40.61935

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01483
Policy Update Magnitude: 0.13800
Value Function Update Magnitude: 0.10960

Collected Steps per Second: 5,147.14577
Overall Steps per Second: 4,514.77584

Timestep Collection Time: 9.71995
Timestep Consumption Time: 1.36144
PPO Batch Consumption Time: 0.10921
Total Iteration Time: 11.08139

Cumulative Model Updates: 3,830
Cumulative Timesteps: 63,969,840

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.95585
Policy Entropy: 3.53113
Value Function Loss: 39.98754

Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.00508
Policy Update Magnitude: 0.14406
Value Function Update Magnitude: 0.11271

Collected Steps per Second: 5,154.40719
Overall Steps per Second: 4,534.71672

Timestep Collection Time: 9.70354
Timestep Consumption Time: 1.32603
PPO Batch Consumption Time: 0.12928
Total Iteration Time: 11.02958

Cumulative Model Updates: 3,833
Cumulative Timesteps: 64,019,856

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 64019856...
Checkpoint 64019856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152.66681
Policy Entropy: 3.51717
Value Function Loss: 38.48108

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.00855
Policy Update Magnitude: 0.15819
Value Function Update Magnitude: 0.10691

Collected Steps per Second: 4,958.62927
Overall Steps per Second: 4,339.08535

Timestep Collection Time: 10.09231
Timestep Consumption Time: 1.44100
PPO Batch Consumption Time: 0.11740
Total Iteration Time: 11.53331

Cumulative Model Updates: 3,836
Cumulative Timesteps: 64,069,900

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.54402
Policy Entropy: 3.52549
Value Function Loss: 36.90855

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.01582
Policy Update Magnitude: 0.15731
Value Function Update Magnitude: 0.10681

Collected Steps per Second: 4,911.02242
Overall Steps per Second: 4,342.22801

Timestep Collection Time: 10.18688
Timestep Consumption Time: 1.33439
PPO Batch Consumption Time: 0.11239
Total Iteration Time: 11.52127

Cumulative Model Updates: 3,839
Cumulative Timesteps: 64,119,928

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 64119928...
Checkpoint 64119928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147.99426
Policy Entropy: 3.51273
Value Function Loss: 34.74856

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.00996
Policy Update Magnitude: 0.13776
Value Function Update Magnitude: 0.10197

Collected Steps per Second: 4,960.75295
Overall Steps per Second: 4,417.03428

Timestep Collection Time: 10.08597
Timestep Consumption Time: 1.24154
PPO Batch Consumption Time: 0.10837
Total Iteration Time: 11.32751

Cumulative Model Updates: 3,842
Cumulative Timesteps: 64,169,962

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.95688
Policy Entropy: 3.51663
Value Function Loss: 33.50691

Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.00715
Policy Update Magnitude: 0.13236
Value Function Update Magnitude: 0.10062

Collected Steps per Second: 5,097.65873
Overall Steps per Second: 4,430.87705

Timestep Collection Time: 9.81431
Timestep Consumption Time: 1.47691
PPO Batch Consumption Time: 0.11573
Total Iteration Time: 11.29122

Cumulative Model Updates: 3,845
Cumulative Timesteps: 64,219,992

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 64219992...
Checkpoint 64219992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111.36585
Policy Entropy: 3.51807
Value Function Loss: 33.70259

Mean KL Divergence: 0.00138
SB3 Clip Fraction: 0.00806
Policy Update Magnitude: 0.14002
Value Function Update Magnitude: 0.09993

Collected Steps per Second: 5,251.48195
Overall Steps per Second: 4,542.99930

Timestep Collection Time: 9.52417
Timestep Consumption Time: 1.48530
PPO Batch Consumption Time: 0.12058
Total Iteration Time: 11.00947

Cumulative Model Updates: 3,848
Cumulative Timesteps: 64,270,008

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.07725
Policy Entropy: 3.50259
Value Function Loss: 33.51304

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01305
Policy Update Magnitude: 0.13875
Value Function Update Magnitude: 0.10938

Collected Steps per Second: 5,204.43144
Overall Steps per Second: 4,533.74840

Timestep Collection Time: 9.60912
Timestep Consumption Time: 1.42149
PPO Batch Consumption Time: 0.11406
Total Iteration Time: 11.03061

Cumulative Model Updates: 3,851
Cumulative Timesteps: 64,320,018

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 64320018...
Checkpoint 64320018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.44552
Policy Entropy: 3.51284
Value Function Loss: 33.71616

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01319
Policy Update Magnitude: 0.13351
Value Function Update Magnitude: 0.10384

Collected Steps per Second: 4,967.05556
Overall Steps per Second: 4,354.18752

Timestep Collection Time: 10.06633
Timestep Consumption Time: 1.41687
PPO Batch Consumption Time: 0.12660
Total Iteration Time: 11.48320

Cumulative Model Updates: 3,854
Cumulative Timesteps: 64,370,018

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.62823
Policy Entropy: 3.50017
Value Function Loss: 32.89035

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01087
Policy Update Magnitude: 0.12404
Value Function Update Magnitude: 0.09148

Collected Steps per Second: 4,875.05273
Overall Steps per Second: 4,322.69027

Timestep Collection Time: 10.26163
Timestep Consumption Time: 1.31125
PPO Batch Consumption Time: 0.12326
Total Iteration Time: 11.57289

Cumulative Model Updates: 3,857
Cumulative Timesteps: 64,420,044

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 64420044...
Checkpoint 64420044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152.09856
Policy Entropy: 3.50362
Value Function Loss: 31.53826

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01258
Policy Update Magnitude: 0.12212
Value Function Update Magnitude: 0.08061

Collected Steps per Second: 4,848.28778
Overall Steps per Second: 4,258.49693

Timestep Collection Time: 10.31869
Timestep Consumption Time: 1.42911
PPO Batch Consumption Time: 0.11356
Total Iteration Time: 11.74781

Cumulative Model Updates: 3,860
Cumulative Timesteps: 64,470,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.14053
Policy Entropy: 3.47816
Value Function Loss: 31.71884

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01061
Policy Update Magnitude: 0.12363
Value Function Update Magnitude: 0.08284

Collected Steps per Second: 5,031.84659
Overall Steps per Second: 4,404.25342

Timestep Collection Time: 9.94227
Timestep Consumption Time: 1.41674
PPO Batch Consumption Time: 0.11824
Total Iteration Time: 11.35902

Cumulative Model Updates: 3,863
Cumulative Timesteps: 64,520,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 64520100...
Checkpoint 64520100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156.86203
Policy Entropy: 3.47201
Value Function Loss: 30.81631

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.01237
Policy Update Magnitude: 0.12688
Value Function Update Magnitude: 0.07747

Collected Steps per Second: 5,454.33374
Overall Steps per Second: 4,652.96250

Timestep Collection Time: 9.17436
Timestep Consumption Time: 1.58008
PPO Batch Consumption Time: 0.11021
Total Iteration Time: 10.75444

Cumulative Model Updates: 3,866
Cumulative Timesteps: 64,570,140

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.65193
Policy Entropy: 3.44873
Value Function Loss: 31.62834

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.01283
Policy Update Magnitude: 0.12690
Value Function Update Magnitude: 0.06760

Collected Steps per Second: 12,979.18355
Overall Steps per Second: 10,039.94477

Timestep Collection Time: 3.85309
Timestep Consumption Time: 1.12801
PPO Batch Consumption Time: 0.06322
Total Iteration Time: 4.98110

Cumulative Model Updates: 3,869
Cumulative Timesteps: 64,620,150

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 64620150...
Checkpoint 64620150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133.42259
Policy Entropy: 3.44069
Value Function Loss: 29.02981

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01469
Policy Update Magnitude: 0.11811
Value Function Update Magnitude: 0.06060

Collected Steps per Second: 5,537.37498
Overall Steps per Second: 4,809.82127

Timestep Collection Time: 9.03027
Timestep Consumption Time: 1.36596
PPO Batch Consumption Time: 0.10871
Total Iteration Time: 10.39623

Cumulative Model Updates: 3,872
Cumulative Timesteps: 64,670,154

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.08609
Policy Entropy: 3.40971
Value Function Loss: 28.41551

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01049
Policy Update Magnitude: 0.12019
Value Function Update Magnitude: 0.06014

Collected Steps per Second: 5,046.88655
Overall Steps per Second: 4,450.17253

Timestep Collection Time: 9.91383
Timestep Consumption Time: 1.32932
PPO Batch Consumption Time: 0.11774
Total Iteration Time: 11.24316

Cumulative Model Updates: 3,875
Cumulative Timesteps: 64,720,188

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 64720188...
Checkpoint 64720188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101.99804
Policy Entropy: 3.39562
Value Function Loss: 27.74622

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.01897
Policy Update Magnitude: 0.11851
Value Function Update Magnitude: 0.05680

Collected Steps per Second: 4,850.54138
Overall Steps per Second: 4,331.43487

Timestep Collection Time: 10.30978
Timestep Consumption Time: 1.23559
PPO Batch Consumption Time: 0.10787
Total Iteration Time: 11.54537

Cumulative Model Updates: 3,878
Cumulative Timesteps: 64,770,196

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.46327
Policy Entropy: 3.39908
Value Function Loss: 27.17903

Mean KL Divergence: 0.00168
SB3 Clip Fraction: 0.00709
Policy Update Magnitude: 0.12696
Value Function Update Magnitude: 0.05470

Collected Steps per Second: 4,833.93058
Overall Steps per Second: 4,270.13150

Timestep Collection Time: 10.34603
Timestep Consumption Time: 1.36602
PPO Batch Consumption Time: 0.11339
Total Iteration Time: 11.71205

Cumulative Model Updates: 3,881
Cumulative Timesteps: 64,820,208

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 64820208...
Checkpoint 64820208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115.64206
Policy Entropy: 3.39659
Value Function Loss: 25.53749

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01449
Policy Update Magnitude: 0.13453
Value Function Update Magnitude: 0.08141

Collected Steps per Second: 4,873.14805
Overall Steps per Second: 4,265.02646

Timestep Collection Time: 10.26318
Timestep Consumption Time: 1.46336
PPO Batch Consumption Time: 0.12158
Total Iteration Time: 11.72654

Cumulative Model Updates: 3,884
Cumulative Timesteps: 64,870,222

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.52572
Policy Entropy: 3.36747
Value Function Loss: 24.51647

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02058
Policy Update Magnitude: 0.12842
Value Function Update Magnitude: 0.08467

Collected Steps per Second: 4,795.73188
Overall Steps per Second: 4,168.79870

Timestep Collection Time: 10.42677
Timestep Consumption Time: 1.56805
PPO Batch Consumption Time: 0.12292
Total Iteration Time: 11.99482

Cumulative Model Updates: 3,887
Cumulative Timesteps: 64,920,226

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 64920226...
Checkpoint 64920226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117.51271
Policy Entropy: 3.36255
Value Function Loss: 25.04580

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01217
Policy Update Magnitude: 0.13347
Value Function Update Magnitude: 0.07496

Collected Steps per Second: 4,755.08689
Overall Steps per Second: 4,159.64364

Timestep Collection Time: 10.52052
Timestep Consumption Time: 1.50599
PPO Batch Consumption Time: 0.12576
Total Iteration Time: 12.02651

Cumulative Model Updates: 3,890
Cumulative Timesteps: 64,970,252

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.12287
Policy Entropy: 3.33359
Value Function Loss: 24.65207

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.00928
Policy Update Magnitude: 0.13799
Value Function Update Magnitude: 0.06488

Collected Steps per Second: 4,696.98783
Overall Steps per Second: 4,134.94347

Timestep Collection Time: 10.64640
Timestep Consumption Time: 1.44712
PPO Batch Consumption Time: 0.11820
Total Iteration Time: 12.09351

Cumulative Model Updates: 3,893
Cumulative Timesteps: 65,020,258

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 65020258...
Checkpoint 65020258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156.28656
Policy Entropy: 3.30225
Value Function Loss: 24.72131

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 0.13599
Value Function Update Magnitude: 0.07239

Collected Steps per Second: 4,722.74544
Overall Steps per Second: 4,212.32787

Timestep Collection Time: 10.59087
Timestep Consumption Time: 1.28332
PPO Batch Consumption Time: 0.12108
Total Iteration Time: 11.87419

Cumulative Model Updates: 3,896
Cumulative Timesteps: 65,070,276

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.28838
Policy Entropy: 3.28153
Value Function Loss: 23.72238

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.01517
Policy Update Magnitude: 0.13600
Value Function Update Magnitude: 0.06214

Collected Steps per Second: 4,744.73215
Overall Steps per Second: 4,179.66350

Timestep Collection Time: 10.54306
Timestep Consumption Time: 1.42537
PPO Batch Consumption Time: 0.11707
Total Iteration Time: 11.96843

Cumulative Model Updates: 3,899
Cumulative Timesteps: 65,120,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 65120300...
Checkpoint 65120300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136.45468
Policy Entropy: 3.29933
Value Function Loss: 23.28101

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.01917
Policy Update Magnitude: 0.13176
Value Function Update Magnitude: 0.05583

Collected Steps per Second: 4,819.22191
Overall Steps per Second: 4,246.40604

Timestep Collection Time: 10.38093
Timestep Consumption Time: 1.40033
PPO Batch Consumption Time: 0.11673
Total Iteration Time: 11.78126

Cumulative Model Updates: 3,902
Cumulative Timesteps: 65,170,328

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.65490
Policy Entropy: 3.29065
Value Function Loss: 23.01832

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.01501
Policy Update Magnitude: 0.12362
Value Function Update Magnitude: 0.07137

Collected Steps per Second: 4,774.86878
Overall Steps per Second: 4,195.29710

Timestep Collection Time: 10.47401
Timestep Consumption Time: 1.44696
PPO Batch Consumption Time: 0.12526
Total Iteration Time: 11.92097

Cumulative Model Updates: 3,905
Cumulative Timesteps: 65,220,340

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 65220340...
Checkpoint 65220340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.65829
Policy Entropy: 3.30813
Value Function Loss: 23.04676

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.01011
Policy Update Magnitude: 0.12281
Value Function Update Magnitude: 0.09333

Collected Steps per Second: 5,084.94752
Overall Steps per Second: 4,461.39878

Timestep Collection Time: 9.83373
Timestep Consumption Time: 1.37441
PPO Batch Consumption Time: 0.11138
Total Iteration Time: 11.20814

Cumulative Model Updates: 3,908
Cumulative Timesteps: 65,270,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.30447
Policy Entropy: 3.26336
Value Function Loss: 23.94684

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.00954
Policy Update Magnitude: 0.12764
Value Function Update Magnitude: 0.08216

Collected Steps per Second: 5,109.49438
Overall Steps per Second: 4,546.45883

Timestep Collection Time: 9.79158
Timestep Consumption Time: 1.21259
PPO Batch Consumption Time: 0.10871
Total Iteration Time: 11.00417

Cumulative Model Updates: 3,911
Cumulative Timesteps: 65,320,374

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 65320374...
Checkpoint 65320374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.30698
Policy Entropy: 3.24249
Value Function Loss: 23.79476

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.00915
Policy Update Magnitude: 0.13588
Value Function Update Magnitude: 0.06995

Collected Steps per Second: 4,830.41682
Overall Steps per Second: 1,046.06410

Timestep Collection Time: 10.35604
Timestep Consumption Time: 37.46512
PPO Batch Consumption Time: 12.11891
Total Iteration Time: 47.82116

Cumulative Model Updates: 3,914
Cumulative Timesteps: 65,370,398

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.27336
Policy Entropy: 3.22037
Value Function Loss: 23.57937

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.01862
Policy Update Magnitude: 0.12960
Value Function Update Magnitude: 0.05969

Collected Steps per Second: 5,066.26994
Overall Steps per Second: 4,440.02095

Timestep Collection Time: 9.87314
Timestep Consumption Time: 1.39257
PPO Batch Consumption Time: 0.11322
Total Iteration Time: 11.26571

Cumulative Model Updates: 3,917
Cumulative Timesteps: 65,420,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 65420418...
Checkpoint 65420418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.05341
Policy Entropy: 3.22760
Value Function Loss: 22.25174

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01017
Policy Update Magnitude: 0.13150
Value Function Update Magnitude: 0.05651

Collected Steps per Second: 4,901.50698
Overall Steps per Second: 4,273.94948

Timestep Collection Time: 10.20135
Timestep Consumption Time: 1.49790
PPO Batch Consumption Time: 0.12694
Total Iteration Time: 11.69925

Cumulative Model Updates: 3,920
Cumulative Timesteps: 65,470,420

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.58638
Policy Entropy: 3.22717
Value Function Loss: 21.64695

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.00872
Policy Update Magnitude: 0.12717
Value Function Update Magnitude: 0.06390

Collected Steps per Second: 4,614.16999
Overall Steps per Second: 4,060.41312

Timestep Collection Time: 10.84009
Timestep Consumption Time: 1.47836
PPO Batch Consumption Time: 0.12025
Total Iteration Time: 12.31845

Cumulative Model Updates: 3,923
Cumulative Timesteps: 65,520,438

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 65520438...
Checkpoint 65520438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136.57897
Policy Entropy: 3.23297
Value Function Loss: 20.91702

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.00751
Policy Update Magnitude: 0.12723
Value Function Update Magnitude: 0.05809

Collected Steps per Second: 5,284.03527
Overall Steps per Second: 4,600.33877

Timestep Collection Time: 9.47004
Timestep Consumption Time: 1.40742
PPO Batch Consumption Time: 0.09499
Total Iteration Time: 10.87746

Cumulative Model Updates: 3,926
Cumulative Timesteps: 65,570,478

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.01606
Policy Entropy: 3.21216
Value Function Loss: 21.32799

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.00823
Policy Update Magnitude: 0.12761
Value Function Update Magnitude: 0.05523

Collected Steps per Second: 5,148.22867
Overall Steps per Second: 2,945.45377

Timestep Collection Time: 9.71480
Timestep Consumption Time: 7.26527
PPO Batch Consumption Time: 2.05973
Total Iteration Time: 16.98007

Cumulative Model Updates: 3,929
Cumulative Timesteps: 65,620,492

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 65620492...
Checkpoint 65620492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.38817
Policy Entropy: 3.18763
Value Function Loss: 20.51884

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.01492
Policy Update Magnitude: 0.13201
Value Function Update Magnitude: 0.05258

Collected Steps per Second: 4,791.23898
Overall Steps per Second: 2,961.55663

Timestep Collection Time: 10.43905
Timestep Consumption Time: 6.44936
PPO Batch Consumption Time: 1.78813
Total Iteration Time: 16.88842

Cumulative Model Updates: 3,932
Cumulative Timesteps: 65,670,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.07529
Policy Entropy: 3.14506
Value Function Loss: 20.57054

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02569
Policy Update Magnitude: 0.12688
Value Function Update Magnitude: 0.05045

Collected Steps per Second: 12,431.86275
Overall Steps per Second: 10,069.09166

Timestep Collection Time: 4.02418
Timestep Consumption Time: 0.94430
PPO Batch Consumption Time: 0.08028
Total Iteration Time: 4.96847

Cumulative Model Updates: 3,935
Cumulative Timesteps: 65,720,536

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 65720536...
Checkpoint 65720536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.76288
Policy Entropy: 3.12085
Value Function Loss: 20.47669

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.01203
Policy Update Magnitude: 0.12696
Value Function Update Magnitude: 0.04791

Collected Steps per Second: 5,645.38258
Overall Steps per Second: 4,893.35357

Timestep Collection Time: 8.86282
Timestep Consumption Time: 1.36207
PPO Batch Consumption Time: 0.12058
Total Iteration Time: 10.22489

Cumulative Model Updates: 3,938
Cumulative Timesteps: 65,770,570

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.44131
Policy Entropy: 3.10712
Value Function Loss: 20.16311

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.00938
Policy Update Magnitude: 0.13553
Value Function Update Magnitude: 0.04828

Collected Steps per Second: 4,998.10081
Overall Steps per Second: 4,390.30571

Timestep Collection Time: 10.00980
Timestep Consumption Time: 1.38576
PPO Batch Consumption Time: 0.11606
Total Iteration Time: 11.39556

Cumulative Model Updates: 3,941
Cumulative Timesteps: 65,820,600

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 65820600...
Checkpoint 65820600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.78011
Policy Entropy: 3.10331
Value Function Loss: 19.79976

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.00883
Policy Update Magnitude: 0.13533
Value Function Update Magnitude: 0.04644

Collected Steps per Second: 5,059.45610
Overall Steps per Second: 4,453.19144

Timestep Collection Time: 9.88328
Timestep Consumption Time: 1.34553
PPO Batch Consumption Time: 0.10603
Total Iteration Time: 11.22880

Cumulative Model Updates: 3,944
Cumulative Timesteps: 65,870,604

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.38739
Policy Entropy: 3.09115
Value Function Loss: 19.07541

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.00635
Policy Update Magnitude: 0.13198
Value Function Update Magnitude: 0.06186

Collected Steps per Second: 4,983.83168
Overall Steps per Second: 4,407.36168

Timestep Collection Time: 10.03886
Timestep Consumption Time: 1.31305
PPO Batch Consumption Time: 0.11055
Total Iteration Time: 11.35192

Cumulative Model Updates: 3,947
Cumulative Timesteps: 65,920,636

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 65920636...
Checkpoint 65920636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.66423
Policy Entropy: 3.06780
Value Function Loss: 19.51007

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.00874
Policy Update Magnitude: 0.12866
Value Function Update Magnitude: 0.06250

Collected Steps per Second: 5,113.24901
Overall Steps per Second: 4,548.18570

Timestep Collection Time: 9.78439
Timestep Consumption Time: 1.21561
PPO Batch Consumption Time: 0.10235
Total Iteration Time: 10.99999

Cumulative Model Updates: 3,950
Cumulative Timesteps: 65,970,666

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.66630
Policy Entropy: 3.04886
Value Function Loss: 19.81020

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.00968
Policy Update Magnitude: 0.11912
Value Function Update Magnitude: 0.06148

Collected Steps per Second: 5,000.39137
Overall Steps per Second: 4,384.64208

Timestep Collection Time: 10.00842
Timestep Consumption Time: 1.40551
PPO Batch Consumption Time: 0.11038
Total Iteration Time: 11.41393

Cumulative Model Updates: 3,953
Cumulative Timesteps: 66,020,712

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 66020712...
Checkpoint 66020712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.71736
Policy Entropy: 3.03236
Value Function Loss: 19.92231

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01227
Policy Update Magnitude: 0.12519
Value Function Update Magnitude: 0.05592

Collected Steps per Second: 4,836.42877
Overall Steps per Second: 4,258.94335

Timestep Collection Time: 10.34193
Timestep Consumption Time: 1.40230
PPO Batch Consumption Time: 0.11439
Total Iteration Time: 11.74423

Cumulative Model Updates: 3,956
Cumulative Timesteps: 66,070,730

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.21772
Policy Entropy: 3.00670
Value Function Loss: 20.42428

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.01933
Policy Update Magnitude: 0.13148
Value Function Update Magnitude: 0.05517

Collected Steps per Second: 4,910.91167
Overall Steps per Second: 4,366.46153

Timestep Collection Time: 10.18548
Timestep Consumption Time: 1.27002
PPO Batch Consumption Time: 0.12192
Total Iteration Time: 11.45550

Cumulative Model Updates: 3,959
Cumulative Timesteps: 66,120,750

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 66120750...
Checkpoint 66120750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161.41428
Policy Entropy: 2.96912
Value Function Loss: 21.04023

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02844
Policy Update Magnitude: 0.12527
Value Function Update Magnitude: 0.04882

Collected Steps per Second: 5,248.41736
Overall Steps per Second: 4,600.28831

Timestep Collection Time: 9.53011
Timestep Consumption Time: 1.34269
PPO Batch Consumption Time: 0.10603
Total Iteration Time: 10.87280

Cumulative Model Updates: 3,962
Cumulative Timesteps: 66,170,768

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.40744
Policy Entropy: 2.97395
Value Function Loss: 20.09531

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02139
Policy Update Magnitude: 0.12376
Value Function Update Magnitude: 0.04731

Collected Steps per Second: 4,912.16089
Overall Steps per Second: 4,309.29422

Timestep Collection Time: 10.17963
Timestep Consumption Time: 1.42412
PPO Batch Consumption Time: 0.11807
Total Iteration Time: 11.60376

Cumulative Model Updates: 3,965
Cumulative Timesteps: 66,220,772

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 66220772...
Checkpoint 66220772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.59783
Policy Entropy: 2.97942
Value Function Loss: 19.39281

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01446
Policy Update Magnitude: 0.12559
Value Function Update Magnitude: 0.07126

Collected Steps per Second: 5,110.26393
Overall Steps per Second: 4,448.61470

Timestep Collection Time: 9.78501
Timestep Consumption Time: 1.45534
PPO Batch Consumption Time: 0.11289
Total Iteration Time: 11.24035

Cumulative Model Updates: 3,968
Cumulative Timesteps: 66,270,776

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.78527
Policy Entropy: 2.98279
Value Function Loss: 18.42877

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.00765
Policy Update Magnitude: 0.13092
Value Function Update Magnitude: 0.07176

Collected Steps per Second: 5,095.28733
Overall Steps per Second: 4,485.03616

Timestep Collection Time: 9.81534
Timestep Consumption Time: 1.33551
PPO Batch Consumption Time: 0.09583
Total Iteration Time: 11.15086

Cumulative Model Updates: 3,971
Cumulative Timesteps: 66,320,788

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 66320788...
Checkpoint 66320788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154.50259
Policy Entropy: 2.93830
Value Function Loss: 18.59455

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.01767
Policy Update Magnitude: 0.12929
Value Function Update Magnitude: 0.10513

Collected Steps per Second: 5,300.24038
Overall Steps per Second: 4,648.03284

Timestep Collection Time: 9.43618
Timestep Consumption Time: 1.32408
PPO Batch Consumption Time: 0.11189
Total Iteration Time: 10.76025

Cumulative Model Updates: 3,974
Cumulative Timesteps: 66,370,802

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.18678
Policy Entropy: 2.92487
Value Function Loss: 18.34178

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.01633
Policy Update Magnitude: 0.12657
Value Function Update Magnitude: 0.11972

Collected Steps per Second: 4,989.64214
Overall Steps per Second: 4,345.91982

Timestep Collection Time: 10.02316
Timestep Consumption Time: 1.48464
PPO Batch Consumption Time: 0.11623
Total Iteration Time: 11.50781

Cumulative Model Updates: 3,977
Cumulative Timesteps: 66,420,814

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 66420814...
Checkpoint 66420814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.78349
Policy Entropy: 2.90373
Value Function Loss: 18.90215

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.01715
Policy Update Magnitude: 0.12530
Value Function Update Magnitude: 0.11589

Collected Steps per Second: 4,761.28705
Overall Steps per Second: 4,188.87783

Timestep Collection Time: 10.50808
Timestep Consumption Time: 1.43593
PPO Batch Consumption Time: 0.10503
Total Iteration Time: 11.94401

Cumulative Model Updates: 3,980
Cumulative Timesteps: 66,470,846

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.84778
Policy Entropy: 2.90525
Value Function Loss: 18.73105

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01212
Policy Update Magnitude: 0.12851
Value Function Update Magnitude: 0.10470

Collected Steps per Second: 5,057.44367
Overall Steps per Second: 4,386.12303

Timestep Collection Time: 9.88721
Timestep Consumption Time: 1.51329
PPO Batch Consumption Time: 0.11239
Total Iteration Time: 11.40050

Cumulative Model Updates: 3,983
Cumulative Timesteps: 66,520,850

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 66520850...
Checkpoint 66520850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.72375
Policy Entropy: 2.89833
Value Function Loss: 18.18513

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02091
Policy Update Magnitude: 0.12126
Value Function Update Magnitude: 0.10151

Collected Steps per Second: 4,850.31102
Overall Steps per Second: 4,254.86446

Timestep Collection Time: 10.31068
Timestep Consumption Time: 1.44293
PPO Batch Consumption Time: 0.10151
Total Iteration Time: 11.75361

Cumulative Model Updates: 3,986
Cumulative Timesteps: 66,570,860

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.83106
Policy Entropy: 2.86775
Value Function Loss: 18.17180

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02621
Policy Update Magnitude: 0.11504
Value Function Update Magnitude: 0.10454

Collected Steps per Second: 5,139.63066
Overall Steps per Second: 4,479.31259

Timestep Collection Time: 9.73416
Timestep Consumption Time: 1.43496
PPO Batch Consumption Time: 0.11724
Total Iteration Time: 11.16912

Cumulative Model Updates: 3,989
Cumulative Timesteps: 66,620,890

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 66620890...
Checkpoint 66620890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.63212
Policy Entropy: 2.87508
Value Function Loss: 18.46725

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01311
Policy Update Magnitude: 0.11509
Value Function Update Magnitude: 0.09175

Collected Steps per Second: 4,687.12424
Overall Steps per Second: 4,113.17048

Timestep Collection Time: 10.67392
Timestep Consumption Time: 1.48944
PPO Batch Consumption Time: 0.12209
Total Iteration Time: 12.16337

Cumulative Model Updates: 3,992
Cumulative Timesteps: 66,670,920

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.59778
Policy Entropy: 2.85427
Value Function Loss: 18.98303

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02079
Policy Update Magnitude: 0.11260
Value Function Update Magnitude: 0.08791

Collected Steps per Second: 4,653.22795
Overall Steps per Second: 4,092.41775

Timestep Collection Time: 10.75383
Timestep Consumption Time: 1.47367
PPO Batch Consumption Time: 0.11289
Total Iteration Time: 12.22749

Cumulative Model Updates: 3,995
Cumulative Timesteps: 66,720,960

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 66720960...
Checkpoint 66720960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.10808
Policy Entropy: 2.79818
Value Function Loss: 18.47582

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02116
Policy Update Magnitude: 0.12013
Value Function Update Magnitude: 0.07316

Collected Steps per Second: 4,650.57142
Overall Steps per Second: 4,042.94567

Timestep Collection Time: 10.75696
Timestep Consumption Time: 1.61669
PPO Batch Consumption Time: 0.12627
Total Iteration Time: 12.37365

Cumulative Model Updates: 3,998
Cumulative Timesteps: 66,770,986

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.39358
Policy Entropy: 2.76710
Value Function Loss: 18.23315

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02489
Policy Update Magnitude: 0.12032
Value Function Update Magnitude: 0.07462

Collected Steps per Second: 4,726.96415
Overall Steps per Second: 4,197.98732

Timestep Collection Time: 10.58396
Timestep Consumption Time: 1.33366
PPO Batch Consumption Time: 0.06556
Total Iteration Time: 11.91762

Cumulative Model Updates: 4,001
Cumulative Timesteps: 66,821,016

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 66821016...
Checkpoint 66821016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.66349
Policy Entropy: 2.77398
Value Function Loss: 17.75121

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02871
Policy Update Magnitude: 0.10727
Value Function Update Magnitude: 0.06436

Collected Steps per Second: 4,999.25553
Overall Steps per Second: 4,424.27999

Timestep Collection Time: 10.00309
Timestep Consumption Time: 1.29999
PPO Batch Consumption Time: 0.10687
Total Iteration Time: 11.30308

Cumulative Model Updates: 4,004
Cumulative Timesteps: 66,871,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.45236
Policy Entropy: 2.74869
Value Function Loss: 17.28006

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02558
Policy Update Magnitude: 0.10272
Value Function Update Magnitude: 0.06912

Collected Steps per Second: 5,070.15241
Overall Steps per Second: 4,418.17713

Timestep Collection Time: 9.86716
Timestep Consumption Time: 1.45606
PPO Batch Consumption Time: 0.11138
Total Iteration Time: 11.32322

Cumulative Model Updates: 4,007
Cumulative Timesteps: 66,921,052

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 66921052...
Checkpoint 66921052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.68925
Policy Entropy: 2.74593
Value Function Loss: 16.99277

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02554
Policy Update Magnitude: 0.10454
Value Function Update Magnitude: 0.06150

Collected Steps per Second: 4,879.10985
Overall Steps per Second: 4,256.07566

Timestep Collection Time: 10.25105
Timestep Consumption Time: 1.50062
PPO Batch Consumption Time: 0.11590
Total Iteration Time: 11.75167

Cumulative Model Updates: 4,010
Cumulative Timesteps: 66,971,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.54043
Policy Entropy: 2.73850
Value Function Loss: 17.89713

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02944
Policy Update Magnitude: 0.09698
Value Function Update Magnitude: 0.08053

Collected Steps per Second: 4,839.57056
Overall Steps per Second: 4,247.06638

Timestep Collection Time: 10.33356
Timestep Consumption Time: 1.44163
PPO Batch Consumption Time: 0.11255
Total Iteration Time: 11.77519

Cumulative Model Updates: 4,013
Cumulative Timesteps: 67,021,078

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 67021078...
Checkpoint 67021078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.77705
Policy Entropy: 2.74183
Value Function Loss: 17.63586

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02768
Policy Update Magnitude: 0.10083
Value Function Update Magnitude: 0.09141

Collected Steps per Second: 5,496.62305
Overall Steps per Second: 4,733.13047

Timestep Collection Time: 9.09977
Timestep Consumption Time: 1.46787
PPO Batch Consumption Time: 0.10770
Total Iteration Time: 10.56764

Cumulative Model Updates: 4,016
Cumulative Timesteps: 67,071,096

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.22286
Policy Entropy: 2.71606
Value Function Loss: 17.52524

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02667
Policy Update Magnitude: 0.10747
Value Function Update Magnitude: 0.08380

Collected Steps per Second: 4,988.27151
Overall Steps per Second: 4,392.17195

Timestep Collection Time: 10.02512
Timestep Consumption Time: 1.36060
PPO Batch Consumption Time: 0.10988
Total Iteration Time: 11.38571

Cumulative Model Updates: 4,019
Cumulative Timesteps: 67,121,104

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 67121104...
Checkpoint 67121104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.81477
Policy Entropy: 2.70164
Value Function Loss: 16.57104

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03533
Policy Update Magnitude: 0.08829
Value Function Update Magnitude: 0.08301

Collected Steps per Second: 5,132.94368
Overall Steps per Second: 4,443.11610

Timestep Collection Time: 9.74451
Timestep Consumption Time: 1.51291
PPO Batch Consumption Time: 0.12041
Total Iteration Time: 11.25741

Cumulative Model Updates: 4,022
Cumulative Timesteps: 67,171,122

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.66048
Policy Entropy: 2.69668
Value Function Loss: 16.81819

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.01979
Policy Update Magnitude: 0.09653
Value Function Update Magnitude: 0.08367

Collected Steps per Second: 4,785.04085
Overall Steps per Second: 4,239.44872

Timestep Collection Time: 10.45717
Timestep Consumption Time: 1.34578
PPO Batch Consumption Time: 0.11105
Total Iteration Time: 11.80295

Cumulative Model Updates: 4,025
Cumulative Timesteps: 67,221,160

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 67221160...
Checkpoint 67221160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.23335
Policy Entropy: 2.72620
Value Function Loss: 17.22129

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03185
Policy Update Magnitude: 0.09151
Value Function Update Magnitude: 0.07360

Collected Steps per Second: 6,415.91852
Overall Steps per Second: 5,596.90640

Timestep Collection Time: 7.79655
Timestep Consumption Time: 1.14089
PPO Batch Consumption Time: 0.10218
Total Iteration Time: 8.93744

Cumulative Model Updates: 4,028
Cumulative Timesteps: 67,271,182

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.57419
Policy Entropy: 2.74683
Value Function Loss: 17.32745

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02523
Policy Update Magnitude: 0.09168
Value Function Update Magnitude: 0.07157

Collected Steps per Second: 5,526.25057
Overall Steps per Second: 4,754.37850

Timestep Collection Time: 9.05460
Timestep Consumption Time: 1.47001
PPO Batch Consumption Time: 0.13363
Total Iteration Time: 10.52461

Cumulative Model Updates: 4,031
Cumulative Timesteps: 67,321,220

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 67321220...
Checkpoint 67321220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.18831
Policy Entropy: 2.73435
Value Function Loss: 17.10814

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.01765
Policy Update Magnitude: 0.10010
Value Function Update Magnitude: 0.08440

Collected Steps per Second: 11,718.77563
Overall Steps per Second: 9,671.63645

Timestep Collection Time: 4.26734
Timestep Consumption Time: 0.90324
PPO Batch Consumption Time: 0.03696
Total Iteration Time: 5.17058

Cumulative Model Updates: 4,034
Cumulative Timesteps: 67,371,228

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.55031
Policy Entropy: 2.70568
Value Function Loss: 16.77407

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02266
Policy Update Magnitude: 0.09589
Value Function Update Magnitude: 0.08111

Collected Steps per Second: 6,701.41759
Overall Steps per Second: 5,778.39235

Timestep Collection Time: 7.46350
Timestep Consumption Time: 1.19220
PPO Batch Consumption Time: 0.10586
Total Iteration Time: 8.65569

Cumulative Model Updates: 4,037
Cumulative Timesteps: 67,421,244

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 67421244...
Checkpoint 67421244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.25842
Policy Entropy: 2.64833
Value Function Loss: 17.12910

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02745
Policy Update Magnitude: 0.09571
Value Function Update Magnitude: 0.07583

Collected Steps per Second: 5,986.91176
Overall Steps per Second: 5,248.67886

Timestep Collection Time: 8.35322
Timestep Consumption Time: 1.17489
PPO Batch Consumption Time: 0.10687
Total Iteration Time: 9.52811

Cumulative Model Updates: 4,040
Cumulative Timesteps: 67,471,254

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.43994
Policy Entropy: 2.63424
Value Function Loss: 17.80717

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02082
Policy Update Magnitude: 0.10461
Value Function Update Magnitude: 0.07558

Collected Steps per Second: 6,038.95520
Overall Steps per Second: 5,317.71954

Timestep Collection Time: 8.27958
Timestep Consumption Time: 1.12295
PPO Batch Consumption Time: 0.10637
Total Iteration Time: 9.40253

Cumulative Model Updates: 4,043
Cumulative Timesteps: 67,521,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 67521254...
Checkpoint 67521254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.98057
Policy Entropy: 2.65489
Value Function Loss: 18.07127

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02813
Policy Update Magnitude: 0.10585
Value Function Update Magnitude: 0.05928

Collected Steps per Second: 6,036.01924
Overall Steps per Second: 5,273.26612

Timestep Collection Time: 8.28626
Timestep Consumption Time: 1.19857
PPO Batch Consumption Time: 0.10553
Total Iteration Time: 9.48482

Cumulative Model Updates: 4,046
Cumulative Timesteps: 67,571,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.02620
Policy Entropy: 2.66520
Value Function Loss: 17.78743

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02807
Policy Update Magnitude: 0.09598
Value Function Update Magnitude: 0.05063

Collected Steps per Second: 5,897.35085
Overall Steps per Second: 5,171.44333

Timestep Collection Time: 8.48279
Timestep Consumption Time: 1.19072
PPO Batch Consumption Time: 0.10754
Total Iteration Time: 9.67351

Cumulative Model Updates: 4,049
Cumulative Timesteps: 67,621,296

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 67621296...
Checkpoint 67621296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.72913
Policy Entropy: 2.64587
Value Function Loss: 17.43774

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02175
Policy Update Magnitude: 0.08596
Value Function Update Magnitude: 0.06526

Collected Steps per Second: 6,080.87557
Overall Steps per Second: 5,314.37255

Timestep Collection Time: 8.22579
Timestep Consumption Time: 1.18642
PPO Batch Consumption Time: 0.10587
Total Iteration Time: 9.41221

Cumulative Model Updates: 4,052
Cumulative Timesteps: 67,671,316

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.25678
Policy Entropy: 2.60379
Value Function Loss: 17.69285

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.01756
Policy Update Magnitude: 0.08989
Value Function Update Magnitude: 0.07449

Collected Steps per Second: 6,041.56478
Overall Steps per Second: 5,282.00112

Timestep Collection Time: 8.27733
Timestep Consumption Time: 1.19030
PPO Batch Consumption Time: 0.10703
Total Iteration Time: 9.46762

Cumulative Model Updates: 4,055
Cumulative Timesteps: 67,721,324

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 67721324...
Checkpoint 67721324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.67547
Policy Entropy: 2.58824
Value Function Loss: 17.66917

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.01889
Policy Update Magnitude: 0.08911
Value Function Update Magnitude: 0.06794

Collected Steps per Second: 5,942.65989
Overall Steps per Second: 5,260.88768

Timestep Collection Time: 8.41845
Timestep Consumption Time: 1.09097
PPO Batch Consumption Time: 0.11172
Total Iteration Time: 9.50942

Cumulative Model Updates: 4,058
Cumulative Timesteps: 67,771,352

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.12051
Policy Entropy: 2.56317
Value Function Loss: 17.97498

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02291
Policy Update Magnitude: 0.09692
Value Function Update Magnitude: 0.05515

Collected Steps per Second: 6,114.88943
Overall Steps per Second: 5,336.32732

Timestep Collection Time: 8.17938
Timestep Consumption Time: 1.19336
PPO Batch Consumption Time: 0.10954
Total Iteration Time: 9.37274

Cumulative Model Updates: 4,061
Cumulative Timesteps: 67,821,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 67821368...
Checkpoint 67821368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.57700
Policy Entropy: 2.56812
Value Function Loss: 17.42326

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.01532
Policy Update Magnitude: 0.10466
Value Function Update Magnitude: 0.06755

Collected Steps per Second: 6,013.72670
Overall Steps per Second: 5,265.25227

Timestep Collection Time: 8.31531
Timestep Consumption Time: 1.18205
PPO Batch Consumption Time: 0.10570
Total Iteration Time: 9.49736

Cumulative Model Updates: 4,064
Cumulative Timesteps: 67,871,374

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.30040
Policy Entropy: 2.56125
Value Function Loss: 17.68700

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01596
Policy Update Magnitude: 0.10142
Value Function Update Magnitude: 0.08647

Collected Steps per Second: 6,082.44632
Overall Steps per Second: 5,318.02534

Timestep Collection Time: 8.22268
Timestep Consumption Time: 1.18194
PPO Batch Consumption Time: 0.10787
Total Iteration Time: 9.40462

Cumulative Model Updates: 4,067
Cumulative Timesteps: 67,921,388

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 67921388...
Checkpoint 67921388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.21363
Policy Entropy: 2.57568
Value Function Loss: 17.54626

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03207
Policy Update Magnitude: 0.09841
Value Function Update Magnitude: 0.07451

Collected Steps per Second: 6,068.52044
Overall Steps per Second: 5,321.59261

Timestep Collection Time: 8.24254
Timestep Consumption Time: 1.15691
PPO Batch Consumption Time: 0.10854
Total Iteration Time: 9.39944

Cumulative Model Updates: 4,070
Cumulative Timesteps: 67,971,408

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.60869
Policy Entropy: 2.54255
Value Function Loss: 17.38848

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02291
Policy Update Magnitude: 0.09674
Value Function Update Magnitude: 0.07408

Collected Steps per Second: 6,112.08185
Overall Steps per Second: 5,423.81560

Timestep Collection Time: 8.18804
Timestep Consumption Time: 1.03904
PPO Batch Consumption Time: 0.10436
Total Iteration Time: 9.22708

Cumulative Model Updates: 4,073
Cumulative Timesteps: 68,021,454

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 68021454...
Checkpoint 68021454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.52432
Policy Entropy: 2.53618
Value Function Loss: 17.27637

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02107
Policy Update Magnitude: 0.09773
Value Function Update Magnitude: 0.08379

Collected Steps per Second: 6,342.44428
Overall Steps per Second: 5,537.22086

Timestep Collection Time: 7.88939
Timestep Consumption Time: 1.14728
PPO Batch Consumption Time: 0.10921
Total Iteration Time: 9.03666

Cumulative Model Updates: 4,076
Cumulative Timesteps: 68,071,492

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.00419
Policy Entropy: 2.53899
Value Function Loss: 17.28521

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.01125
Policy Update Magnitude: 0.10276
Value Function Update Magnitude: 0.07327

Collected Steps per Second: 6,094.02181
Overall Steps per Second: 5,320.67081

Timestep Collection Time: 8.20575
Timestep Consumption Time: 1.19269
PPO Batch Consumption Time: 0.11205
Total Iteration Time: 9.39844

Cumulative Model Updates: 4,079
Cumulative Timesteps: 68,121,498

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 68121498...
Checkpoint 68121498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.61114
Policy Entropy: 2.55534
Value Function Loss: 17.02558

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.01470
Policy Update Magnitude: 0.10739
Value Function Update Magnitude: 0.08332

Collected Steps per Second: 6,106.58547
Overall Steps per Second: 5,326.00380

Timestep Collection Time: 8.19443
Timestep Consumption Time: 1.20098
PPO Batch Consumption Time: 0.11055
Total Iteration Time: 9.39541

Cumulative Model Updates: 4,082
Cumulative Timesteps: 68,171,538

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.86536
Policy Entropy: 2.54075
Value Function Loss: 16.52839

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01895
Policy Update Magnitude: 0.09887
Value Function Update Magnitude: 0.07272

Collected Steps per Second: 6,081.48160
Overall Steps per Second: 5,315.90073

Timestep Collection Time: 8.22892
Timestep Consumption Time: 1.18511
PPO Batch Consumption Time: 0.10904
Total Iteration Time: 9.41402

Cumulative Model Updates: 4,085
Cumulative Timesteps: 68,221,582

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 68221582...
Checkpoint 68221582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.04427
Policy Entropy: 2.54727
Value Function Loss: 16.70827

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.01373
Policy Update Magnitude: 0.10252
Value Function Update Magnitude: 0.07608

Collected Steps per Second: 6,031.11260
Overall Steps per Second: 5,355.02724

Timestep Collection Time: 8.29499
Timestep Consumption Time: 1.04726
PPO Batch Consumption Time: 0.10871
Total Iteration Time: 9.34225

Cumulative Model Updates: 4,088
Cumulative Timesteps: 68,271,610

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.61741
Policy Entropy: 2.55016
Value Function Loss: 17.53872

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01319
Policy Update Magnitude: 0.10721
Value Function Update Magnitude: 0.07990

Collected Steps per Second: 6,290.50552
Overall Steps per Second: 5,501.34646

Timestep Collection Time: 7.95262
Timestep Consumption Time: 1.14079
PPO Batch Consumption Time: 0.10770
Total Iteration Time: 9.09341

Cumulative Model Updates: 4,091
Cumulative Timesteps: 68,321,636

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 68321636...
Checkpoint 68321636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.86827
Policy Entropy: 2.52935
Value Function Loss: 18.44493

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01493
Policy Update Magnitude: 0.10384
Value Function Update Magnitude: 0.08045

Collected Steps per Second: 6,197.62416
Overall Steps per Second: 5,405.27897

Timestep Collection Time: 8.07277
Timestep Consumption Time: 1.18337
PPO Batch Consumption Time: 0.10687
Total Iteration Time: 9.25614

Cumulative Model Updates: 4,094
Cumulative Timesteps: 68,371,668

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.93744
Policy Entropy: 2.51654
Value Function Loss: 18.21672

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01169
Policy Update Magnitude: 0.10829
Value Function Update Magnitude: 0.08330

Collected Steps per Second: 6,171.87982
Overall Steps per Second: 5,426.51190

Timestep Collection Time: 8.10450
Timestep Consumption Time: 1.11321
PPO Batch Consumption Time: 0.09867
Total Iteration Time: 9.21771

Cumulative Model Updates: 4,097
Cumulative Timesteps: 68,421,688

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 68421688...
Checkpoint 68421688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.46047
Policy Entropy: 2.50103
Value Function Loss: 17.61303

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01229
Policy Update Magnitude: 0.11178
Value Function Update Magnitude: 0.07802

Collected Steps per Second: 13,690.77133
Overall Steps per Second: 11,017.00116

Timestep Collection Time: 3.65283
Timestep Consumption Time: 0.88652
PPO Batch Consumption Time: 0.05368
Total Iteration Time: 4.53935

Cumulative Model Updates: 4,100
Cumulative Timesteps: 68,471,698

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.11987
Policy Entropy: 2.50224
Value Function Loss: 17.36751

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02144
Policy Update Magnitude: 0.10654
Value Function Update Magnitude: 0.10235

Collected Steps per Second: 21,503.59203
Overall Steps per Second: 16,176.21192

Timestep Collection Time: 2.32612
Timestep Consumption Time: 0.76607
PPO Batch Consumption Time: 0.03060
Total Iteration Time: 3.09219

Cumulative Model Updates: 4,103
Cumulative Timesteps: 68,521,718

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 68521718...
Checkpoint 68521718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.41929
Policy Entropy: 2.49918
Value Function Loss: 17.34583

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02320
Policy Update Magnitude: 0.10726
Value Function Update Magnitude: 0.09184

Collected Steps per Second: 18,350.19147
Overall Steps per Second: 14,091.83133

Timestep Collection Time: 2.72488
Timestep Consumption Time: 0.82342
PPO Batch Consumption Time: 0.03077
Total Iteration Time: 3.54830

Cumulative Model Updates: 4,106
Cumulative Timesteps: 68,571,720

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.43714
Policy Entropy: 2.50517
Value Function Loss: 17.89944

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02193
Policy Update Magnitude: 0.10740
Value Function Update Magnitude: 0.09273

Collected Steps per Second: 19,261.55562
Overall Steps per Second: 14,118.34661

Timestep Collection Time: 2.59605
Timestep Consumption Time: 0.94572
PPO Batch Consumption Time: 0.06957
Total Iteration Time: 3.54177

Cumulative Model Updates: 4,109
Cumulative Timesteps: 68,621,724

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 68621724...
Checkpoint 68621724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.41315
Policy Entropy: 2.48614
Value Function Loss: 17.90325

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02987
Policy Update Magnitude: 0.09908
Value Function Update Magnitude: 0.09813

Collected Steps per Second: 19,688.71637
Overall Steps per Second: 15,226.43243

Timestep Collection Time: 2.53973
Timestep Consumption Time: 0.74430
PPO Batch Consumption Time: 0.03366
Total Iteration Time: 3.28403

Cumulative Model Updates: 4,112
Cumulative Timesteps: 68,671,728

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.45249
Policy Entropy: 2.48933
Value Function Loss: 18.21758

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02216
Policy Update Magnitude: 0.10003
Value Function Update Magnitude: 0.09022

Collected Steps per Second: 19,488.40445
Overall Steps per Second: 14,461.34190

Timestep Collection Time: 2.56686
Timestep Consumption Time: 0.89229
PPO Batch Consumption Time: 0.06850
Total Iteration Time: 3.45915

Cumulative Model Updates: 4,115
Cumulative Timesteps: 68,721,752

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 68721752...
Checkpoint 68721752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.00248
Policy Entropy: 2.46936
Value Function Loss: 18.21230

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.01915
Policy Update Magnitude: 0.10335
Value Function Update Magnitude: 0.09103

Collected Steps per Second: 20,262.40187
Overall Steps per Second: 15,121.31572

Timestep Collection Time: 2.46891
Timestep Consumption Time: 0.83940
PPO Batch Consumption Time: 0.06586
Total Iteration Time: 3.30831

Cumulative Model Updates: 4,118
Cumulative Timesteps: 68,771,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.39652
Policy Entropy: 2.43497
Value Function Loss: 18.19041

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02311
Policy Update Magnitude: 0.10107
Value Function Update Magnitude: 0.09133

Collected Steps per Second: 21,769.72932
Overall Steps per Second: 15,745.30826

Timestep Collection Time: 2.29704
Timestep Consumption Time: 0.87889
PPO Batch Consumption Time: 0.07010
Total Iteration Time: 3.17593

Cumulative Model Updates: 4,121
Cumulative Timesteps: 68,821,784

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 68821784...
Checkpoint 68821784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.51467
Policy Entropy: 2.43717
Value Function Loss: 17.32578

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03039
Policy Update Magnitude: 0.09781
Value Function Update Magnitude: 0.08338

Collected Steps per Second: 21,221.61943
Overall Steps per Second: 15,472.49638

Timestep Collection Time: 2.35703
Timestep Consumption Time: 0.87580
PPO Batch Consumption Time: 0.06539
Total Iteration Time: 3.23283

Cumulative Model Updates: 4,124
Cumulative Timesteps: 68,871,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.75911
Policy Entropy: 2.41973
Value Function Loss: 17.34124

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.01779
Policy Update Magnitude: 0.10341
Value Function Update Magnitude: 0.08062

Collected Steps per Second: 20,583.20366
Overall Steps per Second: 15,583.04656

Timestep Collection Time: 2.43091
Timestep Consumption Time: 0.78001
PPO Batch Consumption Time: 0.06756
Total Iteration Time: 3.21093

Cumulative Model Updates: 4,127
Cumulative Timesteps: 68,921,840

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 68921840...
Checkpoint 68921840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.52795
Policy Entropy: 2.40338
Value Function Loss: 17.24249

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01633
Policy Update Magnitude: 0.10949
Value Function Update Magnitude: 0.07716

Collected Steps per Second: 20,320.25882
Overall Steps per Second: 15,072.26414

Timestep Collection Time: 2.46109
Timestep Consumption Time: 0.85692
PPO Batch Consumption Time: 0.06563
Total Iteration Time: 3.31802

Cumulative Model Updates: 4,130
Cumulative Timesteps: 68,971,850

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.59484
Policy Entropy: 2.37758
Value Function Loss: 17.35929

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02400
Policy Update Magnitude: 0.09848
Value Function Update Magnitude: 0.07790

Collected Steps per Second: 20,794.96924
Overall Steps per Second: 15,179.16918

Timestep Collection Time: 2.40568
Timestep Consumption Time: 0.89002
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 3.29570

Cumulative Model Updates: 4,133
Cumulative Timesteps: 69,021,876

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 69021876...
Checkpoint 69021876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.64580
Policy Entropy: 2.34797
Value Function Loss: 17.13834

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02839
Policy Update Magnitude: 0.09433
Value Function Update Magnitude: 0.07113

Collected Steps per Second: 20,989.86645
Overall Steps per Second: 15,194.82775

Timestep Collection Time: 2.38248
Timestep Consumption Time: 0.90864
PPO Batch Consumption Time: 0.10844
Total Iteration Time: 3.29112

Cumulative Model Updates: 4,136
Cumulative Timesteps: 69,071,884

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.13132
Policy Entropy: 2.34935
Value Function Loss: 17.10118

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.01751
Policy Update Magnitude: 0.10026
Value Function Update Magnitude: 0.06220

Collected Steps per Second: 19,906.97314
Overall Steps per Second: 14,795.50669

Timestep Collection Time: 2.51198
Timestep Consumption Time: 0.86783
PPO Batch Consumption Time: 0.07181
Total Iteration Time: 3.37981

Cumulative Model Updates: 4,139
Cumulative Timesteps: 69,121,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 69121890...
Checkpoint 69121890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.57896
Policy Entropy: 2.34201
Value Function Loss: 17.54473

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.01577
Policy Update Magnitude: 0.11286
Value Function Update Magnitude: 0.07023

Collected Steps per Second: 19,658.61880
Overall Steps per Second: 14,644.32463

Timestep Collection Time: 2.54402
Timestep Consumption Time: 0.87109
PPO Batch Consumption Time: 0.06582
Total Iteration Time: 3.41511

Cumulative Model Updates: 4,142
Cumulative Timesteps: 69,171,902

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.29859
Policy Entropy: 2.33618
Value Function Loss: 17.55305

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.01975
Policy Update Magnitude: 0.11092
Value Function Update Magnitude: 0.06768

Collected Steps per Second: 23,939.51996
Overall Steps per Second: 17,834.49114

Timestep Collection Time: 2.08860
Timestep Consumption Time: 0.71496
PPO Batch Consumption Time: 0.02977
Total Iteration Time: 2.80356

Cumulative Model Updates: 4,145
Cumulative Timesteps: 69,221,902

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 69221902...
Checkpoint 69221902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276.58146
Policy Entropy: 2.34258
Value Function Loss: 17.79316

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02077
Policy Update Magnitude: 0.10452
Value Function Update Magnitude: 0.08777

Collected Steps per Second: 23,039.39671
Overall Steps per Second: 17,185.77815

Timestep Collection Time: 2.17115
Timestep Consumption Time: 0.73951
PPO Batch Consumption Time: 0.03001
Total Iteration Time: 2.91066

Cumulative Model Updates: 4,148
Cumulative Timesteps: 69,271,924

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.92037
Policy Entropy: 2.30614
Value Function Loss: 17.58746

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02084
Policy Update Magnitude: 0.10297
Value Function Update Magnitude: 0.08327

Collected Steps per Second: 23,606.75440
Overall Steps per Second: 18,095.92127

Timestep Collection Time: 2.11812
Timestep Consumption Time: 0.64504
PPO Batch Consumption Time: 0.02906
Total Iteration Time: 2.76316

Cumulative Model Updates: 4,151
Cumulative Timesteps: 69,321,926

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 69321926...
Checkpoint 69321926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.98138
Policy Entropy: 2.30740
Value Function Loss: 17.87937

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.01451
Policy Update Magnitude: 0.10285
Value Function Update Magnitude: 0.07971

Collected Steps per Second: 22,389.80486
Overall Steps per Second: 15,402.43550

Timestep Collection Time: 2.23432
Timestep Consumption Time: 1.01361
PPO Batch Consumption Time: 0.11294
Total Iteration Time: 3.24793

Cumulative Model Updates: 4,154
Cumulative Timesteps: 69,371,952

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.24459
Policy Entropy: 2.31054
Value Function Loss: 17.69431

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.01991
Policy Update Magnitude: 0.09806
Value Function Update Magnitude: 0.08675

Collected Steps per Second: 23,677.82183
Overall Steps per Second: 17,046.83559

Timestep Collection Time: 2.11278
Timestep Consumption Time: 0.82184
PPO Batch Consumption Time: 0.06544
Total Iteration Time: 2.93462

Cumulative Model Updates: 4,157
Cumulative Timesteps: 69,421,978

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 69421978...
Checkpoint 69421978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.00563
Policy Entropy: 2.30099
Value Function Loss: 17.95816

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.01550
Policy Update Magnitude: 0.09553
Value Function Update Magnitude: 0.09683

Collected Steps per Second: 23,932.11248
Overall Steps per Second: 17,087.30749

Timestep Collection Time: 2.09025
Timestep Consumption Time: 0.83731
PPO Batch Consumption Time: 0.06187
Total Iteration Time: 2.92755

Cumulative Model Updates: 4,160
Cumulative Timesteps: 69,472,002

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.93003
Policy Entropy: 2.27224
Value Function Loss: 18.10357

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01533
Policy Update Magnitude: 0.09782
Value Function Update Magnitude: 0.09237

Collected Steps per Second: 23,119.75332
Overall Steps per Second: 17,186.80440

Timestep Collection Time: 2.16360
Timestep Consumption Time: 0.74688
PPO Batch Consumption Time: 0.02968
Total Iteration Time: 2.91049

Cumulative Model Updates: 4,163
Cumulative Timesteps: 69,522,024

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 69522024...
Checkpoint 69522024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.93159
Policy Entropy: 2.26294
Value Function Loss: 18.10108

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.01675
Policy Update Magnitude: 0.10102
Value Function Update Magnitude: 0.09466

Collected Steps per Second: 21,579.64466
Overall Steps per Second: 15,685.99056

Timestep Collection Time: 2.31700
Timestep Consumption Time: 0.87056
PPO Batch Consumption Time: 0.09572
Total Iteration Time: 3.18756

Cumulative Model Updates: 4,166
Cumulative Timesteps: 69,572,024

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.04506
Policy Entropy: 2.22434
Value Function Loss: 18.13851

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02901
Policy Update Magnitude: 0.09451
Value Function Update Magnitude: 0.08817

Collected Steps per Second: 22,903.10822
Overall Steps per Second: 16,482.12673

Timestep Collection Time: 2.18311
Timestep Consumption Time: 0.85048
PPO Batch Consumption Time: 0.06518
Total Iteration Time: 3.03359

Cumulative Model Updates: 4,169
Cumulative Timesteps: 69,622,024

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 69622024...
Checkpoint 69622024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.16832
Policy Entropy: 2.23864
Value Function Loss: 17.92236

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04082
Policy Update Magnitude: 0.09116
Value Function Update Magnitude: 0.08121

Collected Steps per Second: 19,475.20529
Overall Steps per Second: 14,614.57393

Timestep Collection Time: 2.56798
Timestep Consumption Time: 0.85408
PPO Batch Consumption Time: 0.07460
Total Iteration Time: 3.42206

Cumulative Model Updates: 4,172
Cumulative Timesteps: 69,672,036

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.13051
Policy Entropy: 2.23301
Value Function Loss: 17.78071

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03465
Policy Update Magnitude: 0.08334
Value Function Update Magnitude: 0.07573

Collected Steps per Second: 24,369.52167
Overall Steps per Second: 18,182.08578

Timestep Collection Time: 2.05306
Timestep Consumption Time: 0.69866
PPO Batch Consumption Time: 0.02944
Total Iteration Time: 2.75172

Cumulative Model Updates: 4,175
Cumulative Timesteps: 69,722,068

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 69722068...
Checkpoint 69722068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.91931
Policy Entropy: 2.22567
Value Function Loss: 17.15056

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02309
Policy Update Magnitude: 0.08182
Value Function Update Magnitude: 0.06675

Collected Steps per Second: 22,471.91314
Overall Steps per Second: 15,920.42993

Timestep Collection Time: 2.22642
Timestep Consumption Time: 0.91620
PPO Batch Consumption Time: 0.08548
Total Iteration Time: 3.14263

Cumulative Model Updates: 4,178
Cumulative Timesteps: 69,772,100

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.17947
Policy Entropy: 2.25596
Value Function Loss: 17.30330

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.01702
Policy Update Magnitude: 0.08601
Value Function Update Magnitude: 0.06023

Collected Steps per Second: 23,151.34240
Overall Steps per Second: 16,709.01309

Timestep Collection Time: 2.16100
Timestep Consumption Time: 0.83319
PPO Batch Consumption Time: 0.08612
Total Iteration Time: 2.99419

Cumulative Model Updates: 4,181
Cumulative Timesteps: 69,822,130

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 69822130...
Checkpoint 69822130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.13308
Policy Entropy: 2.26019
Value Function Loss: 17.49209

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01252
Policy Update Magnitude: 0.08723
Value Function Update Magnitude: 0.05786

Collected Steps per Second: 23,092.37328
Overall Steps per Second: 15,915.43034

Timestep Collection Time: 2.16686
Timestep Consumption Time: 0.97713
PPO Batch Consumption Time: 0.10807
Total Iteration Time: 3.14399

Cumulative Model Updates: 4,184
Cumulative Timesteps: 69,872,168

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.75128
Policy Entropy: 2.25918
Value Function Loss: 17.77170

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01059
Policy Update Magnitude: 0.09394
Value Function Update Magnitude: 0.06830

Collected Steps per Second: 22,903.92766
Overall Steps per Second: 16,638.04165

Timestep Collection Time: 2.18347
Timestep Consumption Time: 0.82229
PPO Batch Consumption Time: 0.05379
Total Iteration Time: 3.00576

Cumulative Model Updates: 4,187
Cumulative Timesteps: 69,922,178

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 69922178...
Checkpoint 69922178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.23933
Policy Entropy: 2.23785
Value Function Loss: 17.73211

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02551
Policy Update Magnitude: 0.08954
Value Function Update Magnitude: 0.07969

Collected Steps per Second: 22,486.43612
Overall Steps per Second: 17,389.94235

Timestep Collection Time: 2.22383
Timestep Consumption Time: 0.65174
PPO Batch Consumption Time: 0.03041
Total Iteration Time: 2.87557

Cumulative Model Updates: 4,190
Cumulative Timesteps: 69,972,184

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.64920
Policy Entropy: 2.20947
Value Function Loss: 17.10486

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02510
Policy Update Magnitude: 0.08420
Value Function Update Magnitude: 0.07381

Collected Steps per Second: 23,138.29413
Overall Steps per Second: 16,025.48490

Timestep Collection Time: 2.16118
Timestep Consumption Time: 0.95923
PPO Batch Consumption Time: 0.09230
Total Iteration Time: 3.12040

Cumulative Model Updates: 4,193
Cumulative Timesteps: 70,022,190

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 70022190...
Checkpoint 70022190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.34988
Policy Entropy: 2.21089
Value Function Loss: 17.52370

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02867
Policy Update Magnitude: 0.08040
Value Function Update Magnitude: 0.06659

Collected Steps per Second: 21,436.36778
Overall Steps per Second: 15,868.91914

Timestep Collection Time: 2.33332
Timestep Consumption Time: 0.81862
PPO Batch Consumption Time: 0.07482
Total Iteration Time: 3.15195

Cumulative Model Updates: 4,196
Cumulative Timesteps: 70,072,208

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.24765
Policy Entropy: 2.20219
Value Function Loss: 17.21803

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03264
Policy Update Magnitude: 0.07475
Value Function Update Magnitude: 0.08406

Collected Steps per Second: 21,031.60568
Overall Steps per Second: 15,384.15454

Timestep Collection Time: 2.37842
Timestep Consumption Time: 0.87311
PPO Batch Consumption Time: 0.06565
Total Iteration Time: 3.25153

Cumulative Model Updates: 4,199
Cumulative Timesteps: 70,122,230

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 70122230...
Checkpoint 70122230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.08347
Policy Entropy: 2.20295
Value Function Loss: 18.01642

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02453
Policy Update Magnitude: 0.06911
Value Function Update Magnitude: 0.08479

Collected Steps per Second: 17,971.70129
Overall Steps per Second: 14,414.24245

Timestep Collection Time: 2.78326
Timestep Consumption Time: 0.68691
PPO Batch Consumption Time: 0.02977
Total Iteration Time: 3.47018

Cumulative Model Updates: 4,202
Cumulative Timesteps: 70,172,250

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.87945
Policy Entropy: 2.21813
Value Function Loss: 17.43925

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02069
Policy Update Magnitude: 0.07554
Value Function Update Magnitude: 0.08563

Collected Steps per Second: 23,694.58951
Overall Steps per Second: 18,159.44183

Timestep Collection Time: 2.11044
Timestep Consumption Time: 0.64328
PPO Batch Consumption Time: 0.02964
Total Iteration Time: 2.75372

Cumulative Model Updates: 4,205
Cumulative Timesteps: 70,222,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 70222256...
Checkpoint 70222256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.42284
Policy Entropy: 2.20839
Value Function Loss: 17.74169

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.01912
Policy Update Magnitude: 0.07602
Value Function Update Magnitude: 0.08452

Collected Steps per Second: 23,027.45362
Overall Steps per Second: 17,169.61316

Timestep Collection Time: 2.17202
Timestep Consumption Time: 0.74104
PPO Batch Consumption Time: 0.03102
Total Iteration Time: 2.91305

Cumulative Model Updates: 4,208
Cumulative Timesteps: 70,272,272

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.37111
Policy Entropy: 2.20364
Value Function Loss: 17.82890

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02119
Policy Update Magnitude: 0.08097
Value Function Update Magnitude: 0.09425

Collected Steps per Second: 23,725.23238
Overall Steps per Second: 17,794.30577

Timestep Collection Time: 2.10839
Timestep Consumption Time: 0.70274
PPO Batch Consumption Time: 0.05247
Total Iteration Time: 2.81112

Cumulative Model Updates: 4,211
Cumulative Timesteps: 70,322,294

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 70322294...
Checkpoint 70322294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.67605
Policy Entropy: 2.19049
Value Function Loss: 17.44098

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02803
Policy Update Magnitude: 0.07142
Value Function Update Magnitude: 0.11062

Collected Steps per Second: 22,682.12474
Overall Steps per Second: 17,102.00696

Timestep Collection Time: 2.20482
Timestep Consumption Time: 0.71940
PPO Batch Consumption Time: 0.03021
Total Iteration Time: 2.92422

Cumulative Model Updates: 4,214
Cumulative Timesteps: 70,372,304

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.10833
Policy Entropy: 2.20341
Value Function Loss: 16.98571

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.02758
Policy Update Magnitude: 0.06220
Value Function Update Magnitude: 0.11732

Collected Steps per Second: 22,948.42064
Overall Steps per Second: 16,318.74132

Timestep Collection Time: 2.17985
Timestep Consumption Time: 0.88559
PPO Batch Consumption Time: 0.08195
Total Iteration Time: 3.06543

Cumulative Model Updates: 4,217
Cumulative Timesteps: 70,422,328

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 70422328...
Checkpoint 70422328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.15738
Policy Entropy: 2.18754
Value Function Loss: 15.95481

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.01564
Policy Update Magnitude: 0.06481
Value Function Update Magnitude: 0.10590

Collected Steps per Second: 22,531.16916
Overall Steps per Second: 15,986.76478

Timestep Collection Time: 2.22057
Timestep Consumption Time: 0.90902
PPO Batch Consumption Time: 0.11590
Total Iteration Time: 3.12959

Cumulative Model Updates: 4,220
Cumulative Timesteps: 70,472,360

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.04392
Policy Entropy: 2.19163
Value Function Loss: 16.34218

Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.01090
Policy Update Magnitude: 0.06735
Value Function Update Magnitude: 0.08904

Collected Steps per Second: 24,044.46399
Overall Steps per Second: 17,487.78269

Timestep Collection Time: 2.08048
Timestep Consumption Time: 0.78003
PPO Batch Consumption Time: 0.04401
Total Iteration Time: 2.86051

Cumulative Model Updates: 4,223
Cumulative Timesteps: 70,522,384

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 70522384...
Checkpoint 70522384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.52286
Policy Entropy: 2.19702
Value Function Loss: 16.11967

Mean KL Divergence: 0.00155
SB3 Clip Fraction: 0.01001
Policy Update Magnitude: 0.08113
Value Function Update Magnitude: 0.10427

Collected Steps per Second: 23,347.93065
Overall Steps per Second: 17,648.21096

Timestep Collection Time: 2.14263
Timestep Consumption Time: 0.69199
PPO Batch Consumption Time: 0.02937
Total Iteration Time: 2.83462

Cumulative Model Updates: 4,226
Cumulative Timesteps: 70,572,410

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.67208
Policy Entropy: 2.17687
Value Function Loss: 16.30783

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.00938
Policy Update Magnitude: 0.09529
Value Function Update Magnitude: 0.10836

Collected Steps per Second: 23,580.98364
Overall Steps per Second: 16,216.33487

Timestep Collection Time: 2.12095
Timestep Consumption Time: 0.96323
PPO Batch Consumption Time: 0.10199
Total Iteration Time: 3.08417

Cumulative Model Updates: 4,229
Cumulative Timesteps: 70,622,424

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 70622424...
Checkpoint 70622424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.08757
Policy Entropy: 2.13540
Value Function Loss: 16.15470

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02611
Policy Update Magnitude: 0.08640
Value Function Update Magnitude: 0.09658

Collected Steps per Second: 24,080.47749
Overall Steps per Second: 17,834.97023

Timestep Collection Time: 2.07745
Timestep Consumption Time: 0.72749
PPO Batch Consumption Time: 0.02938
Total Iteration Time: 2.80494

Cumulative Model Updates: 4,232
Cumulative Timesteps: 70,672,450

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.86274
Policy Entropy: 2.14097
Value Function Loss: 16.23800

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.01863
Policy Update Magnitude: 0.08709
Value Function Update Magnitude: 0.09002

Collected Steps per Second: 23,407.91461
Overall Steps per Second: 16,619.50564

Timestep Collection Time: 2.13714
Timestep Consumption Time: 0.87294
PPO Batch Consumption Time: 0.07696
Total Iteration Time: 3.01008

Cumulative Model Updates: 4,235
Cumulative Timesteps: 70,722,476

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 70722476...
Checkpoint 70722476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.92912
Policy Entropy: 2.12904
Value Function Loss: 16.79612

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02367
Policy Update Magnitude: 0.08667
Value Function Update Magnitude: 0.08005

Collected Steps per Second: 23,020.51784
Overall Steps per Second: 17,297.06939

Timestep Collection Time: 2.17267
Timestep Consumption Time: 0.71892
PPO Batch Consumption Time: 0.02966
Total Iteration Time: 2.89159

Cumulative Model Updates: 4,238
Cumulative Timesteps: 70,772,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.46026
Policy Entropy: 2.12057
Value Function Loss: 16.48253

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01776
Policy Update Magnitude: 0.08648
Value Function Update Magnitude: 0.07435

Collected Steps per Second: 21,525.68083
Overall Steps per Second: 15,574.79223

Timestep Collection Time: 2.32355
Timestep Consumption Time: 0.88779
PPO Batch Consumption Time: 0.05108
Total Iteration Time: 3.21134

Cumulative Model Updates: 4,241
Cumulative Timesteps: 70,822,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 70822508...
Checkpoint 70822508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289.30812
Policy Entropy: 2.14272
Value Function Loss: 16.02739

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02246
Policy Update Magnitude: 0.08117
Value Function Update Magnitude: 0.07521

Collected Steps per Second: 21,775.51515
Overall Steps per Second: 15,600.52087

Timestep Collection Time: 2.29689
Timestep Consumption Time: 0.90916
PPO Batch Consumption Time: 0.11119
Total Iteration Time: 3.20605

Cumulative Model Updates: 4,244
Cumulative Timesteps: 70,872,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.12003
Policy Entropy: 2.14917
Value Function Loss: 15.16032

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02249
Policy Update Magnitude: 0.07947
Value Function Update Magnitude: 0.07008

Collected Steps per Second: 23,717.38918
Overall Steps per Second: 17,002.31842

Timestep Collection Time: 2.10866
Timestep Consumption Time: 0.83282
PPO Batch Consumption Time: 0.06522
Total Iteration Time: 2.94148

Cumulative Model Updates: 4,247
Cumulative Timesteps: 70,922,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 70922536...
Checkpoint 70922536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.55312
Policy Entropy: 2.12338
Value Function Loss: 14.99778

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01441
Policy Update Magnitude: 0.08178
Value Function Update Magnitude: 0.06217

Collected Steps per Second: 22,750.53805
Overall Steps per Second: 16,510.55593

Timestep Collection Time: 2.19845
Timestep Consumption Time: 0.83088
PPO Batch Consumption Time: 0.06256
Total Iteration Time: 3.02933

Cumulative Model Updates: 4,250
Cumulative Timesteps: 70,972,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.88405
Policy Entropy: 2.12354
Value Function Loss: 14.59813

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02909
Policy Update Magnitude: 0.09261
Value Function Update Magnitude: 0.05059

Collected Steps per Second: 21,644.67514
Overall Steps per Second: 16,001.96069

Timestep Collection Time: 2.31124
Timestep Consumption Time: 0.81500
PPO Batch Consumption Time: 0.05064
Total Iteration Time: 3.12624

Cumulative Model Updates: 4,253
Cumulative Timesteps: 71,022,578

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 71022578...
Checkpoint 71022578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.40958
Policy Entropy: 2.12162
Value Function Loss: 14.50316

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03315
Policy Update Magnitude: 0.08382
Value Function Update Magnitude: 0.05868

Collected Steps per Second: 23,670.89617
Overall Steps per Second: 17,668.98983

Timestep Collection Time: 2.11297
Timestep Consumption Time: 0.71775
PPO Batch Consumption Time: 0.02959
Total Iteration Time: 2.83072

Cumulative Model Updates: 4,256
Cumulative Timesteps: 71,072,594

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.06670
Policy Entropy: 2.09092
Value Function Loss: 14.90196

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03177
Policy Update Magnitude: 0.07898
Value Function Update Magnitude: 0.06856

Collected Steps per Second: 23,007.41247
Overall Steps per Second: 16,603.63466

Timestep Collection Time: 2.17426
Timestep Consumption Time: 0.83858
PPO Batch Consumption Time: 0.08932
Total Iteration Time: 3.01283

Cumulative Model Updates: 4,259
Cumulative Timesteps: 71,122,618

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 71122618...
Checkpoint 71122618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.24480
Policy Entropy: 2.04248
Value Function Loss: 15.70276

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.03843
Policy Update Magnitude: 0.06839
Value Function Update Magnitude: 0.07494

Collected Steps per Second: 24,487.56039
Overall Steps per Second: 17,482.88111

Timestep Collection Time: 2.04234
Timestep Consumption Time: 0.81828
PPO Batch Consumption Time: 0.06187
Total Iteration Time: 2.86063

Cumulative Model Updates: 4,262
Cumulative Timesteps: 71,172,630

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.14466
Policy Entropy: 1.99931
Value Function Loss: 15.87842

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.01916
Policy Update Magnitude: 0.06879
Value Function Update Magnitude: 0.08377

Collected Steps per Second: 21,815.71168
Overall Steps per Second: 15,985.11074

Timestep Collection Time: 2.29211
Timestep Consumption Time: 0.83605
PPO Batch Consumption Time: 0.07310
Total Iteration Time: 3.12816

Cumulative Model Updates: 4,265
Cumulative Timesteps: 71,222,634

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 71222634...
Checkpoint 71222634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.97763
Policy Entropy: 1.96864
Value Function Loss: 15.65286

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02014
Policy Update Magnitude: 0.07660
Value Function Update Magnitude: 0.07219

Collected Steps per Second: 24,917.65214
Overall Steps per Second: 17,820.53566

Timestep Collection Time: 2.00661
Timestep Consumption Time: 0.79914
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 2.80575

Cumulative Model Updates: 4,268
Cumulative Timesteps: 71,272,634

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.80917
Policy Entropy: 1.97617
Value Function Loss: 15.28267

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03395
Policy Update Magnitude: 0.07115
Value Function Update Magnitude: 0.08227

Collected Steps per Second: 21,837.77762
Overall Steps per Second: 15,709.86619

Timestep Collection Time: 2.29181
Timestep Consumption Time: 0.89396
PPO Batch Consumption Time: 0.08026
Total Iteration Time: 3.18577

Cumulative Model Updates: 4,271
Cumulative Timesteps: 71,322,682

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 71322682...
Checkpoint 71322682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.88885
Policy Entropy: 1.98979
Value Function Loss: 14.95840

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02123
Policy Update Magnitude: 0.06705
Value Function Update Magnitude: 0.08657

Collected Steps per Second: 24,322.67643
Overall Steps per Second: 17,708.70149

Timestep Collection Time: 2.05652
Timestep Consumption Time: 0.76808
PPO Batch Consumption Time: 0.05968
Total Iteration Time: 2.82460

Cumulative Model Updates: 4,274
Cumulative Timesteps: 71,372,702

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.99922
Policy Entropy: 1.99527
Value Function Loss: 14.85874

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02529
Policy Update Magnitude: 0.06921
Value Function Update Magnitude: 0.07680

Collected Steps per Second: 22,944.59805
Overall Steps per Second: 16,015.13501

Timestep Collection Time: 2.17934
Timestep Consumption Time: 0.94296
PPO Batch Consumption Time: 0.10303
Total Iteration Time: 3.12230

Cumulative Model Updates: 4,277
Cumulative Timesteps: 71,422,706

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 71422706...
Checkpoint 71422706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.28115
Policy Entropy: 1.99219
Value Function Loss: 14.50083

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.01981
Policy Update Magnitude: 0.07033
Value Function Update Magnitude: 0.06968

Collected Steps per Second: 24,508.56528
Overall Steps per Second: 17,519.06924

Timestep Collection Time: 2.04010
Timestep Consumption Time: 0.81393
PPO Batch Consumption Time: 0.06164
Total Iteration Time: 2.85403

Cumulative Model Updates: 4,280
Cumulative Timesteps: 71,472,706

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.39756
Policy Entropy: 1.98395
Value Function Loss: 14.49255

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02107
Policy Update Magnitude: 0.07976
Value Function Update Magnitude: 0.06578

Collected Steps per Second: 21,865.50258
Overall Steps per Second: 15,973.34930

Timestep Collection Time: 2.28671
Timestep Consumption Time: 0.84351
PPO Batch Consumption Time: 0.09370
Total Iteration Time: 3.13021

Cumulative Model Updates: 4,283
Cumulative Timesteps: 71,522,706

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 71522706...
Checkpoint 71522706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.44617
Policy Entropy: 2.00327
Value Function Loss: 13.96699

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02044
Policy Update Magnitude: 0.07994
Value Function Update Magnitude: 0.05678

Collected Steps per Second: 24,252.45318
Overall Steps per Second: 17,378.67023

Timestep Collection Time: 2.06264
Timestep Consumption Time: 0.81583
PPO Batch Consumption Time: 0.06250
Total Iteration Time: 2.87847

Cumulative Model Updates: 4,286
Cumulative Timesteps: 71,572,730

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.33239
Policy Entropy: 1.97710
Value Function Loss: 13.95248

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.03654
Policy Update Magnitude: 0.07970
Value Function Update Magnitude: 0.05324

Collected Steps per Second: 24,775.75612
Overall Steps per Second: 17,606.94538

Timestep Collection Time: 2.01851
Timestep Consumption Time: 0.82185
PPO Batch Consumption Time: 0.06423
Total Iteration Time: 2.84036

Cumulative Model Updates: 4,289
Cumulative Timesteps: 71,622,740

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 71622740...
Checkpoint 71622740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.20706
Policy Entropy: 1.96264
Value Function Loss: 13.94854

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01597
Policy Update Magnitude: 0.07698
Value Function Update Magnitude: 0.05567

Collected Steps per Second: 21,074.05444
Overall Steps per Second: 14,566.79218

Timestep Collection Time: 2.37287
Timestep Consumption Time: 1.06001
PPO Batch Consumption Time: 0.11018
Total Iteration Time: 3.43288

Cumulative Model Updates: 4,292
Cumulative Timesteps: 71,672,746

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.11618
Policy Entropy: 1.97324
Value Function Loss: 14.36660

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01503
Policy Update Magnitude: 0.08204
Value Function Update Magnitude: 0.05955

Collected Steps per Second: 22,597.81728
Overall Steps per Second: 16,303.60460

Timestep Collection Time: 2.21313
Timestep Consumption Time: 0.85441
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 3.06754

Cumulative Model Updates: 4,295
Cumulative Timesteps: 71,722,758

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 71722758...
Checkpoint 71722758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.82903
Policy Entropy: 1.98181
Value Function Loss: 14.58893

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.01817
Policy Update Magnitude: 0.08954
Value Function Update Magnitude: 0.06776

Collected Steps per Second: 20,957.04246
Overall Steps per Second: 16,270.65659

Timestep Collection Time: 2.38660
Timestep Consumption Time: 0.68740
PPO Batch Consumption Time: 0.03025
Total Iteration Time: 3.07400

Cumulative Model Updates: 4,298
Cumulative Timesteps: 71,772,774

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.10334
Policy Entropy: 1.94471
Value Function Loss: 15.38664

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01275
Policy Update Magnitude: 0.09292
Value Function Update Magnitude: 0.08830

Collected Steps per Second: 23,016.21354
Overall Steps per Second: 15,994.08607

Timestep Collection Time: 2.17334
Timestep Consumption Time: 0.95419
PPO Batch Consumption Time: 0.07619
Total Iteration Time: 3.12753

Cumulative Model Updates: 4,301
Cumulative Timesteps: 71,822,796

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 71822796...
Checkpoint 71822796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.85678
Policy Entropy: 1.93294
Value Function Loss: 14.92151

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02822
Policy Update Magnitude: 0.08994
Value Function Update Magnitude: 0.08317

Collected Steps per Second: 21,015.02901
Overall Steps per Second: 16,268.33136

Timestep Collection Time: 2.37934
Timestep Consumption Time: 0.69423
PPO Batch Consumption Time: 0.02967
Total Iteration Time: 3.07358

Cumulative Model Updates: 4,304
Cumulative Timesteps: 71,872,798

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.91870
Policy Entropy: 1.96195
Value Function Loss: 14.59091

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02376
Policy Update Magnitude: 0.08761
Value Function Update Magnitude: 0.07450

Collected Steps per Second: 24,061.50068
Overall Steps per Second: 18,162.18660

Timestep Collection Time: 2.07851
Timestep Consumption Time: 0.67513
PPO Batch Consumption Time: 0.04014
Total Iteration Time: 2.75363

Cumulative Model Updates: 4,307
Cumulative Timesteps: 71,922,810

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 71922810...
Checkpoint 71922810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.37557
Policy Entropy: 1.97058
Value Function Loss: 13.73426

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.01630
Policy Update Magnitude: 0.08493
Value Function Update Magnitude: 0.06528

Collected Steps per Second: 23,539.54364
Overall Steps per Second: 16,876.62213

Timestep Collection Time: 2.12561
Timestep Consumption Time: 0.83920
PPO Batch Consumption Time: 0.06284
Total Iteration Time: 2.96481

Cumulative Model Updates: 4,310
Cumulative Timesteps: 71,972,846

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.38698
Policy Entropy: 1.93463
Value Function Loss: 13.38247

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02062
Policy Update Magnitude: 0.08905
Value Function Update Magnitude: 0.08028

Collected Steps per Second: 23,813.14975
Overall Steps per Second: 17,867.45103

Timestep Collection Time: 2.10060
Timestep Consumption Time: 0.69901
PPO Batch Consumption Time: 0.02887
Total Iteration Time: 2.79962

Cumulative Model Updates: 4,313
Cumulative Timesteps: 72,022,868

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 72022868...
Checkpoint 72022868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.40675
Policy Entropy: 1.89813
Value Function Loss: 13.68128

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02225
Policy Update Magnitude: 0.08812
Value Function Update Magnitude: 0.09075

Collected Steps per Second: 23,852.46553
Overall Steps per Second: 16,491.05314

Timestep Collection Time: 2.09681
Timestep Consumption Time: 0.93599
PPO Batch Consumption Time: 0.10187
Total Iteration Time: 3.03280

Cumulative Model Updates: 4,316
Cumulative Timesteps: 72,072,882

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.19318
Policy Entropy: 1.90803
Value Function Loss: 13.49226

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03671
Policy Update Magnitude: 0.08334
Value Function Update Magnitude: 0.07432

Collected Steps per Second: 23,984.93231
Overall Steps per Second: 17,069.14146

Timestep Collection Time: 2.08531
Timestep Consumption Time: 0.84489
PPO Batch Consumption Time: 0.06499
Total Iteration Time: 2.93020

Cumulative Model Updates: 4,319
Cumulative Timesteps: 72,122,898

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 72122898...
Checkpoint 72122898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.00287
Policy Entropy: 1.87244
Value Function Loss: 13.55711

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02580
Policy Update Magnitude: 0.08100
Value Function Update Magnitude: 0.07689

Collected Steps per Second: 23,305.30089
Overall Steps per Second: 16,427.99382

Timestep Collection Time: 2.14569
Timestep Consumption Time: 0.89826
PPO Batch Consumption Time: 0.11256
Total Iteration Time: 3.04395

Cumulative Model Updates: 4,322
Cumulative Timesteps: 72,172,904

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.53399
Policy Entropy: 1.86302
Value Function Loss: 13.45984

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.01936
Policy Update Magnitude: 0.07614
Value Function Update Magnitude: 0.07205

Collected Steps per Second: 23,963.58295
Overall Steps per Second: 17,011.93792

Timestep Collection Time: 2.08658
Timestep Consumption Time: 0.85265
PPO Batch Consumption Time: 0.06600
Total Iteration Time: 2.93923

Cumulative Model Updates: 4,325
Cumulative Timesteps: 72,222,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 72222906...
Checkpoint 72222906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.18322
Policy Entropy: 1.87808
Value Function Loss: 13.66150

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.01487
Policy Update Magnitude: 0.07955
Value Function Update Magnitude: 0.06735

Collected Steps per Second: 23,653.96967
Overall Steps per Second: 17,813.00414

Timestep Collection Time: 2.11381
Timestep Consumption Time: 0.69313
PPO Batch Consumption Time: 0.02999
Total Iteration Time: 2.80694

Cumulative Model Updates: 4,328
Cumulative Timesteps: 72,272,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.42746
Policy Entropy: 1.86781
Value Function Loss: 13.75325

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.01436
Policy Update Magnitude: 0.08679
Value Function Update Magnitude: 0.06151

Collected Steps per Second: 24,702.79145
Overall Steps per Second: 17,759.93865

Timestep Collection Time: 2.02568
Timestep Consumption Time: 0.79190
PPO Batch Consumption Time: 0.02897
Total Iteration Time: 2.81758

Cumulative Model Updates: 4,331
Cumulative Timesteps: 72,322,946

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 72322946...
Checkpoint 72322946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.92250
Policy Entropy: 1.84140
Value Function Loss: 13.31802

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03982
Policy Update Magnitude: 0.07537
Value Function Update Magnitude: 0.05866

Collected Steps per Second: 20,762.04767
Overall Steps per Second: 14,733.72315

Timestep Collection Time: 2.40920
Timestep Consumption Time: 0.98573
PPO Batch Consumption Time: 0.09730
Total Iteration Time: 3.39493

Cumulative Model Updates: 4,334
Cumulative Timesteps: 72,372,966

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.25314
Policy Entropy: 1.84494
Value Function Loss: 13.41520

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01721
Policy Update Magnitude: 0.07421
Value Function Update Magnitude: 0.06246

Collected Steps per Second: 24,156.70320
Overall Steps per Second: 18,420.24641

Timestep Collection Time: 2.07056
Timestep Consumption Time: 0.64482
PPO Batch Consumption Time: 0.02920
Total Iteration Time: 2.71538

Cumulative Model Updates: 4,337
Cumulative Timesteps: 72,422,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 72422984...
Checkpoint 72422984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.52506
Policy Entropy: 1.85973
Value Function Loss: 13.23246

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01139
Policy Update Magnitude: 0.06852
Value Function Update Magnitude: 0.06751

Collected Steps per Second: 23,878.15534
Overall Steps per Second: 17,391.94104

Timestep Collection Time: 2.09497
Timestep Consumption Time: 0.78131
PPO Batch Consumption Time: 0.05137
Total Iteration Time: 2.87627

Cumulative Model Updates: 4,340
Cumulative Timesteps: 72,473,008

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.14403
Policy Entropy: 1.86642
Value Function Loss: 13.15388

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.01657
Policy Update Magnitude: 0.07393
Value Function Update Magnitude: 0.07113

Collected Steps per Second: 20,888.22061
Overall Steps per Second: 14,682.05338

Timestep Collection Time: 2.39369
Timestep Consumption Time: 1.01182
PPO Batch Consumption Time: 0.12534
Total Iteration Time: 3.40552

Cumulative Model Updates: 4,343
Cumulative Timesteps: 72,523,008

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 72523008...
Checkpoint 72523008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.35326
Policy Entropy: 1.85220
Value Function Loss: 12.69124

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03112
Policy Update Magnitude: 0.06728
Value Function Update Magnitude: 0.06844

Collected Steps per Second: 24,310.71290
Overall Steps per Second: 17,395.83132

Timestep Collection Time: 2.05761
Timestep Consumption Time: 0.81791
PPO Batch Consumption Time: 0.06163
Total Iteration Time: 2.87552

Cumulative Model Updates: 4,346
Cumulative Timesteps: 72,573,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.04814
Policy Entropy: 1.86319
Value Function Loss: 12.77920

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02802
Policy Update Magnitude: 0.06090
Value Function Update Magnitude: 0.06396

Collected Steps per Second: 23,892.22455
Overall Steps per Second: 17,827.61621

Timestep Collection Time: 2.09415
Timestep Consumption Time: 0.71239
PPO Batch Consumption Time: 0.02880
Total Iteration Time: 2.80654

Cumulative Model Updates: 4,349
Cumulative Timesteps: 72,623,064

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 72623064...
Checkpoint 72623064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.34321
Policy Entropy: 1.84965
Value Function Loss: 12.56489

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02273
Policy Update Magnitude: 0.06470
Value Function Update Magnitude: 0.06658

Collected Steps per Second: 22,860.36840
Overall Steps per Second: 17,710.01577

Timestep Collection Time: 2.18754
Timestep Consumption Time: 0.63617
PPO Batch Consumption Time: 0.02992
Total Iteration Time: 2.82371

Cumulative Model Updates: 4,352
Cumulative Timesteps: 72,673,072

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.55522
Policy Entropy: 1.85853
Value Function Loss: 12.85805

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.01773
Policy Update Magnitude: 0.06521
Value Function Update Magnitude: 0.08247

Collected Steps per Second: 22,229.56770
Overall Steps per Second: 15,580.42987

Timestep Collection Time: 2.25052
Timestep Consumption Time: 0.96044
PPO Batch Consumption Time: 0.10001
Total Iteration Time: 3.21095

Cumulative Model Updates: 4,355
Cumulative Timesteps: 72,723,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 72723100...
Checkpoint 72723100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.42442
Policy Entropy: 1.85805
Value Function Loss: 12.45797

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02508
Policy Update Magnitude: 0.06076
Value Function Update Magnitude: 0.08641

Collected Steps per Second: 23,666.37843
Overall Steps per Second: 17,166.04716

Timestep Collection Time: 2.11388
Timestep Consumption Time: 0.80047
PPO Batch Consumption Time: 0.06429
Total Iteration Time: 2.91436

Cumulative Model Updates: 4,358
Cumulative Timesteps: 72,773,128

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.04718
Policy Entropy: 1.82681
Value Function Loss: 12.57834

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.03895
Policy Update Magnitude: 0.05790
Value Function Update Magnitude: 0.07940

Collected Steps per Second: 23,778.89932
Overall Steps per Second: 18,215.94539

Timestep Collection Time: 2.10313
Timestep Consumption Time: 0.64227
PPO Batch Consumption Time: 0.02926
Total Iteration Time: 2.74540

Cumulative Model Updates: 4,361
Cumulative Timesteps: 72,823,138

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 72823138...
Checkpoint 72823138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297.40774
Policy Entropy: 1.82979
Value Function Loss: 12.52268

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02027
Policy Update Magnitude: 0.05503
Value Function Update Magnitude: 0.07442

Collected Steps per Second: 23,315.53118
Overall Steps per Second: 16,137.59720

Timestep Collection Time: 2.14527
Timestep Consumption Time: 0.95420
PPO Batch Consumption Time: 0.10281
Total Iteration Time: 3.09947

Cumulative Model Updates: 4,364
Cumulative Timesteps: 72,873,156

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.31882
Policy Entropy: 1.79671
Value Function Loss: 12.79537

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01918
Policy Update Magnitude: 0.06321
Value Function Update Magnitude: 0.06658

Collected Steps per Second: 23,041.47465
Overall Steps per Second: 16,421.16059

Timestep Collection Time: 2.17113
Timestep Consumption Time: 0.87531
PPO Batch Consumption Time: 0.08278
Total Iteration Time: 3.04644

Cumulative Model Updates: 4,367
Cumulative Timesteps: 72,923,182

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 72923182...
Checkpoint 72923182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370.80147
Policy Entropy: 1.79683
Value Function Loss: 12.92048

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02682
Policy Update Magnitude: 0.06515
Value Function Update Magnitude: 0.06156

Collected Steps per Second: 23,984.57490
Overall Steps per Second: 17,839.10675

Timestep Collection Time: 2.08517
Timestep Consumption Time: 0.71833
PPO Batch Consumption Time: 0.02969
Total Iteration Time: 2.80350

Cumulative Model Updates: 4,370
Cumulative Timesteps: 72,973,194

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.68340
Policy Entropy: 1.78965
Value Function Loss: 13.00240

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02627
Policy Update Magnitude: 0.06565
Value Function Update Magnitude: 0.05466

Collected Steps per Second: 23,571.47816
Overall Steps per Second: 16,064.28180

Timestep Collection Time: 2.12163
Timestep Consumption Time: 0.99149
PPO Batch Consumption Time: 0.10899
Total Iteration Time: 3.11312

Cumulative Model Updates: 4,373
Cumulative Timesteps: 73,023,204

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 73023204...
Checkpoint 73023204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.92446
Policy Entropy: 1.77555
Value Function Loss: 13.00812

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03438
Policy Update Magnitude: 0.06063
Value Function Update Magnitude: 0.06855

Collected Steps per Second: 23,304.72151
Overall Steps per Second: 16,472.08247

Timestep Collection Time: 2.14643
Timestep Consumption Time: 0.89034
PPO Batch Consumption Time: 0.08324
Total Iteration Time: 3.03677

Cumulative Model Updates: 4,376
Cumulative Timesteps: 73,073,226

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.29359
Policy Entropy: 1.77663
Value Function Loss: 12.58259

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02933
Policy Update Magnitude: 0.05906
Value Function Update Magnitude: 0.05796

Collected Steps per Second: 23,826.69715
Overall Steps per Second: 15,995.97750

Timestep Collection Time: 2.09891
Timestep Consumption Time: 1.02750
PPO Batch Consumption Time: 0.12444
Total Iteration Time: 3.12641

Cumulative Model Updates: 4,379
Cumulative Timesteps: 73,123,236

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 73123236...
Checkpoint 73123236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.92264
Policy Entropy: 1.76883
Value Function Loss: 12.16495

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02982
Policy Update Magnitude: 0.06089
Value Function Update Magnitude: 0.05336

Collected Steps per Second: 23,406.48414
Overall Steps per Second: 17,043.92478

Timestep Collection Time: 2.13633
Timestep Consumption Time: 0.79750
PPO Batch Consumption Time: 0.06244
Total Iteration Time: 2.93383

Cumulative Model Updates: 4,382
Cumulative Timesteps: 73,173,240

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.53365
Policy Entropy: 1.77188
Value Function Loss: 11.71758

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02601
Policy Update Magnitude: 0.05677
Value Function Update Magnitude: 0.06150

Collected Steps per Second: 23,772.40673
Overall Steps per Second: 18,302.87704

Timestep Collection Time: 2.10345
Timestep Consumption Time: 0.62858
PPO Batch Consumption Time: 0.02985
Total Iteration Time: 2.73203

Cumulative Model Updates: 4,385
Cumulative Timesteps: 73,223,244

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 73223244...
Checkpoint 73223244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.16382
Policy Entropy: 1.77951
Value Function Loss: 11.56631

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02715
Policy Update Magnitude: 0.05654
Value Function Update Magnitude: 0.06480

Collected Steps per Second: 23,807.24634
Overall Steps per Second: 17,409.50518

Timestep Collection Time: 2.10028
Timestep Consumption Time: 0.77182
PPO Batch Consumption Time: 0.05054
Total Iteration Time: 2.87211

Cumulative Model Updates: 4,388
Cumulative Timesteps: 73,273,246

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.38140
Policy Entropy: 1.76371
Value Function Loss: 11.55471

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03299
Policy Update Magnitude: 0.05698
Value Function Update Magnitude: 0.06805

Collected Steps per Second: 22,988.70759
Overall Steps per Second: 16,369.50511

Timestep Collection Time: 2.17533
Timestep Consumption Time: 0.87962
PPO Batch Consumption Time: 0.08073
Total Iteration Time: 3.05495

Cumulative Model Updates: 4,391
Cumulative Timesteps: 73,323,254

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 73323254...
Checkpoint 73323254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.62468
Policy Entropy: 1.74580
Value Function Loss: 11.70758

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02775
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.07076

Collected Steps per Second: 24,064.16881
Overall Steps per Second: 17,942.65777

Timestep Collection Time: 2.07794
Timestep Consumption Time: 0.70893
PPO Batch Consumption Time: 0.03067
Total Iteration Time: 2.78688

Cumulative Model Updates: 4,394
Cumulative Timesteps: 73,373,258

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.88768
Policy Entropy: 1.76073
Value Function Loss: 11.63152

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02789
Policy Update Magnitude: 0.05590
Value Function Update Magnitude: 0.06273

Collected Steps per Second: 24,495.71457
Overall Steps per Second: 18,080.91446

Timestep Collection Time: 2.04142
Timestep Consumption Time: 0.72426
PPO Batch Consumption Time: 0.03087
Total Iteration Time: 2.76568

Cumulative Model Updates: 4,397
Cumulative Timesteps: 73,423,264

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 73423264...
Checkpoint 73423264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.20177
Policy Entropy: 1.76567
Value Function Loss: 11.51500

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02669
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.06579

Collected Steps per Second: 21,031.34404
Overall Steps per Second: 15,704.33450

Timestep Collection Time: 2.37816
Timestep Consumption Time: 0.80669
PPO Batch Consumption Time: 0.07939
Total Iteration Time: 3.18485

Cumulative Model Updates: 4,400
Cumulative Timesteps: 73,473,280

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.98565
Policy Entropy: 1.72835
Value Function Loss: 11.37139

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.01936
Policy Update Magnitude: 0.05743
Value Function Update Magnitude: 0.05687

Collected Steps per Second: 23,665.35908
Overall Steps per Second: 17,024.15450

Timestep Collection Time: 2.11288
Timestep Consumption Time: 0.82424
PPO Batch Consumption Time: 0.06553
Total Iteration Time: 2.93712

Cumulative Model Updates: 4,403
Cumulative Timesteps: 73,523,282

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 73523282...
Checkpoint 73523282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.36726
Policy Entropy: 1.73272
Value Function Loss: 10.91155

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.01721
Policy Update Magnitude: 0.05713
Value Function Update Magnitude: 0.05335

Collected Steps per Second: 23,409.59797
Overall Steps per Second: 16,926.44161

Timestep Collection Time: 2.13596
Timestep Consumption Time: 0.81811
PPO Batch Consumption Time: 0.06371
Total Iteration Time: 2.95408

Cumulative Model Updates: 4,406
Cumulative Timesteps: 73,573,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.45107
Policy Entropy: 1.73204
Value Function Loss: 10.71892

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01807
Policy Update Magnitude: 0.05988
Value Function Update Magnitude: 0.04521

Collected Steps per Second: 24,379.49205
Overall Steps per Second: 17,447.25447

Timestep Collection Time: 2.05115
Timestep Consumption Time: 0.81497
PPO Batch Consumption Time: 0.05987
Total Iteration Time: 2.86612

Cumulative Model Updates: 4,409
Cumulative Timesteps: 73,623,290

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 73623290...
Checkpoint 73623290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.00180
Policy Entropy: 1.72392
Value Function Loss: 10.71474

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02233
Policy Update Magnitude: 0.05888
Value Function Update Magnitude: 0.04943

Collected Steps per Second: 20,016.18631
Overall Steps per Second: 14,765.62755

Timestep Collection Time: 2.49878
Timestep Consumption Time: 0.88855
PPO Batch Consumption Time: 0.07446
Total Iteration Time: 3.38733

Cumulative Model Updates: 4,412
Cumulative Timesteps: 73,673,306

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.46370
Policy Entropy: 1.70918
Value Function Loss: 10.97310

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.01933
Policy Update Magnitude: 0.06047
Value Function Update Magnitude: 0.05457

Collected Steps per Second: 23,639.34911
Overall Steps per Second: 18,174.44333

Timestep Collection Time: 2.11588
Timestep Consumption Time: 0.63623
PPO Batch Consumption Time: 0.02916
Total Iteration Time: 2.75211

Cumulative Model Updates: 4,415
Cumulative Timesteps: 73,723,324

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 73723324...
Checkpoint 73723324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.22613
Policy Entropy: 1.70685
Value Function Loss: 11.10705

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02291
Policy Update Magnitude: 0.06393
Value Function Update Magnitude: 0.04938

Collected Steps per Second: 22,927.05877
Overall Steps per Second: 16,296.12142

Timestep Collection Time: 2.18100
Timestep Consumption Time: 0.88746
PPO Batch Consumption Time: 0.08020
Total Iteration Time: 3.06846

Cumulative Model Updates: 4,418
Cumulative Timesteps: 73,773,328

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.71960
Policy Entropy: 1.71140
Value Function Loss: 11.02241

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02401
Policy Update Magnitude: 0.06663
Value Function Update Magnitude: 0.04534

Collected Steps per Second: 23,249.82955
Overall Steps per Second: 15,969.66141

Timestep Collection Time: 2.15133
Timestep Consumption Time: 0.98074
PPO Batch Consumption Time: 0.12384
Total Iteration Time: 3.13206

Cumulative Model Updates: 4,421
Cumulative Timesteps: 73,823,346

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 73823346...
Checkpoint 73823346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.93310
Policy Entropy: 1.74127
Value Function Loss: 11.44839

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03177
Policy Update Magnitude: 0.06053
Value Function Update Magnitude: 0.04781

Collected Steps per Second: 24,050.70231
Overall Steps per Second: 18,365.89784

Timestep Collection Time: 2.07927
Timestep Consumption Time: 0.64360
PPO Batch Consumption Time: 0.02905
Total Iteration Time: 2.72287

Cumulative Model Updates: 4,424
Cumulative Timesteps: 73,873,354

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.82791
Policy Entropy: 1.70207
Value Function Loss: 11.35143

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02082
Policy Update Magnitude: 0.05985
Value Function Update Magnitude: 0.06585

Collected Steps per Second: 23,513.54793
Overall Steps per Second: 16,257.77812

Timestep Collection Time: 2.12737
Timestep Consumption Time: 0.94943
PPO Batch Consumption Time: 0.08981
Total Iteration Time: 3.07680

Cumulative Model Updates: 4,427
Cumulative Timesteps: 73,923,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 73923376...
Checkpoint 73923376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.48941
Policy Entropy: 1.70740
Value Function Loss: 10.89879

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02226
Policy Update Magnitude: 0.06271
Value Function Update Magnitude: 0.07572

Collected Steps per Second: 23,321.58114
Overall Steps per Second: 17,583.00859

Timestep Collection Time: 2.14428
Timestep Consumption Time: 0.69983
PPO Batch Consumption Time: 0.02960
Total Iteration Time: 2.84411

Cumulative Model Updates: 4,430
Cumulative Timesteps: 73,973,384

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.38275
Policy Entropy: 1.69521
Value Function Loss: 10.21150

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01985
Policy Update Magnitude: 0.06410
Value Function Update Magnitude: 0.07935

Collected Steps per Second: 23,833.70913
Overall Steps per Second: 17,751.39574

Timestep Collection Time: 2.09946
Timestep Consumption Time: 0.71936
PPO Batch Consumption Time: 0.02916
Total Iteration Time: 2.81882

Cumulative Model Updates: 4,433
Cumulative Timesteps: 74,023,422

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 74023422...
Checkpoint 74023422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.85661
Policy Entropy: 1.69602
Value Function Loss: 9.90038

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02436
Policy Update Magnitude: 0.06444
Value Function Update Magnitude: 0.07107

Collected Steps per Second: 22,614.48794
Overall Steps per Second: 16,159.32533

Timestep Collection Time: 2.21230
Timestep Consumption Time: 0.88375
PPO Batch Consumption Time: 0.07866
Total Iteration Time: 3.09605

Cumulative Model Updates: 4,436
Cumulative Timesteps: 74,073,452

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.92079
Policy Entropy: 1.68680
Value Function Loss: 10.41667

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03789
Policy Update Magnitude: 0.06154
Value Function Update Magnitude: 0.05969

Collected Steps per Second: 23,531.95059
Overall Steps per Second: 16,703.52099

Timestep Collection Time: 2.12511
Timestep Consumption Time: 0.86875
PPO Batch Consumption Time: 0.09374
Total Iteration Time: 2.99386

Cumulative Model Updates: 4,439
Cumulative Timesteps: 74,123,460

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 74123460...
Checkpoint 74123460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.43944
Policy Entropy: 1.66639
Value Function Loss: 10.70722

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01606
Policy Update Magnitude: 0.06244
Value Function Update Magnitude: 0.05661

Collected Steps per Second: 23,245.43991
Overall Steps per Second: 16,795.15469

Timestep Collection Time: 2.15139
Timestep Consumption Time: 0.82625
PPO Batch Consumption Time: 0.05861
Total Iteration Time: 2.97764

Cumulative Model Updates: 4,442
Cumulative Timesteps: 74,173,470

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.50821
Policy Entropy: 1.65674
Value Function Loss: 10.96600

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02271
Policy Update Magnitude: 0.06480
Value Function Update Magnitude: 0.04768

Collected Steps per Second: 20,150.00307
Overall Steps per Second: 15,715.01808

Timestep Collection Time: 2.48139
Timestep Consumption Time: 0.70028
PPO Batch Consumption Time: 0.02936
Total Iteration Time: 3.18167

Cumulative Model Updates: 4,445
Cumulative Timesteps: 74,223,470

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 74223470...
Checkpoint 74223470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.96772
Policy Entropy: 1.60834
Value Function Loss: 10.37768

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02461
Policy Update Magnitude: 0.06364
Value Function Update Magnitude: 0.04724

Collected Steps per Second: 24,822.91234
Overall Steps per Second: 18,290.45889

Timestep Collection Time: 2.01532
Timestep Consumption Time: 0.71977
PPO Batch Consumption Time: 0.03076
Total Iteration Time: 2.73509

Cumulative Model Updates: 4,448
Cumulative Timesteps: 74,273,496

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.02598
Policy Entropy: 1.60173
Value Function Loss: 10.41657

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02151
Policy Update Magnitude: 0.06177
Value Function Update Magnitude: 0.04999

Collected Steps per Second: 22,920.81144
Overall Steps per Second: 16,282.93026

Timestep Collection Time: 2.18151
Timestep Consumption Time: 0.88931
PPO Batch Consumption Time: 0.07554
Total Iteration Time: 3.07082

Cumulative Model Updates: 4,451
Cumulative Timesteps: 74,323,498

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 74323498...
Checkpoint 74323498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.28604
Policy Entropy: 1.61588
Value Function Loss: 10.56695

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02852
Policy Update Magnitude: 0.06260
Value Function Update Magnitude: 0.04452

Collected Steps per Second: 23,360.54183
Overall Steps per Second: 17,371.65945

Timestep Collection Time: 2.14088
Timestep Consumption Time: 0.73807
PPO Batch Consumption Time: 0.06164
Total Iteration Time: 2.87894

Cumulative Model Updates: 4,454
Cumulative Timesteps: 74,373,510

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.36000
Policy Entropy: 1.60906
Value Function Loss: 10.84617

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02850
Policy Update Magnitude: 0.05949
Value Function Update Magnitude: 0.05539

Collected Steps per Second: 23,935.18529
Overall Steps per Second: 16,135.83683

Timestep Collection Time: 2.08948
Timestep Consumption Time: 1.00996
PPO Batch Consumption Time: 0.11453
Total Iteration Time: 3.09944

Cumulative Model Updates: 4,457
Cumulative Timesteps: 74,423,522

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 74423522...
Checkpoint 74423522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.22901
Policy Entropy: 1.61299
Value Function Loss: 10.84137

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01835
Policy Update Magnitude: 0.06082
Value Function Update Magnitude: 0.06329

Collected Steps per Second: 23,420.62158
Overall Steps per Second: 17,036.78416

Timestep Collection Time: 2.13572
Timestep Consumption Time: 0.80028
PPO Batch Consumption Time: 0.06465
Total Iteration Time: 2.93600

Cumulative Model Updates: 4,460
Cumulative Timesteps: 74,473,542

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.95709
Policy Entropy: 1.61945
Value Function Loss: 10.44331

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02022
Policy Update Magnitude: 0.06543
Value Function Update Magnitude: 0.05559

Collected Steps per Second: 23,035.50586
Overall Steps per Second: 17,260.27830

Timestep Collection Time: 2.17143
Timestep Consumption Time: 0.72655
PPO Batch Consumption Time: 0.02912
Total Iteration Time: 2.89798

Cumulative Model Updates: 4,463
Cumulative Timesteps: 74,523,562

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 74523562...
Checkpoint 74523562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.99311
Policy Entropy: 1.61675
Value Function Loss: 10.11873

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03166
Policy Update Magnitude: 0.06509
Value Function Update Magnitude: 0.05086

Collected Steps per Second: 23,778.79707
Overall Steps per Second: 16,144.03267

Timestep Collection Time: 2.10271
Timestep Consumption Time: 0.99441
PPO Batch Consumption Time: 0.11280
Total Iteration Time: 3.09712

Cumulative Model Updates: 4,466
Cumulative Timesteps: 74,573,562

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.09745
Policy Entropy: 1.61463
Value Function Loss: 9.74116

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02329
Policy Update Magnitude: 0.06461
Value Function Update Magnitude: 0.04794

Collected Steps per Second: 23,754.88003
Overall Steps per Second: 16,695.23916

Timestep Collection Time: 2.10567
Timestep Consumption Time: 0.89039
PPO Batch Consumption Time: 0.10984
Total Iteration Time: 2.99606

Cumulative Model Updates: 4,469
Cumulative Timesteps: 74,623,582

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 74623582...
Checkpoint 74623582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.93302
Policy Entropy: 1.59940
Value Function Loss: 10.06862

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.01991
Policy Update Magnitude: 0.06617
Value Function Update Magnitude: 0.04653

Collected Steps per Second: 23,840.43529
Overall Steps per Second: 16,701.65540

Timestep Collection Time: 2.09862
Timestep Consumption Time: 0.89701
PPO Batch Consumption Time: 0.07734
Total Iteration Time: 2.99563

Cumulative Model Updates: 4,472
Cumulative Timesteps: 74,673,614

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.51601
Policy Entropy: 1.61032
Value Function Loss: 10.35855

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01675
Policy Update Magnitude: 0.06494
Value Function Update Magnitude: 0.04345

Collected Steps per Second: 23,367.86054
Overall Steps per Second: 17,540.57068

Timestep Collection Time: 2.14012
Timestep Consumption Time: 0.71099
PPO Batch Consumption Time: 0.02896
Total Iteration Time: 2.85110

Cumulative Model Updates: 4,475
Cumulative Timesteps: 74,723,624

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 74723624...
Checkpoint 74723624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.56080
Policy Entropy: 1.58564
Value Function Loss: 10.58792

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01643
Policy Update Magnitude: 0.06948
Value Function Update Magnitude: 0.04167

Collected Steps per Second: 20,774.47495
Overall Steps per Second: 16,156.93111

Timestep Collection Time: 2.40747
Timestep Consumption Time: 0.68804
PPO Batch Consumption Time: 0.04928
Total Iteration Time: 3.09551

Cumulative Model Updates: 4,478
Cumulative Timesteps: 74,773,638

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.57139
Policy Entropy: 1.58520
Value Function Loss: 10.31441

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.01782
Policy Update Magnitude: 0.07305
Value Function Update Magnitude: 0.04812

Collected Steps per Second: 21,087.29738
Overall Steps per Second: 14,664.69816

Timestep Collection Time: 2.37176
Timestep Consumption Time: 1.03874
PPO Batch Consumption Time: 0.11637
Total Iteration Time: 3.41050

Cumulative Model Updates: 4,481
Cumulative Timesteps: 74,823,652

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 74823652...
Checkpoint 74823652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.71125
Policy Entropy: 1.57243
Value Function Loss: 10.00251

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02005
Policy Update Magnitude: 0.06644
Value Function Update Magnitude: 0.04952

Collected Steps per Second: 20,749.80660
Overall Steps per Second: 15,046.64107

Timestep Collection Time: 2.40976
Timestep Consumption Time: 0.91338
PPO Batch Consumption Time: 0.05808
Total Iteration Time: 3.32313

Cumulative Model Updates: 4,484
Cumulative Timesteps: 74,873,654

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.91739
Policy Entropy: 1.56001
Value Function Loss: 9.99533

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01544
Policy Update Magnitude: 0.06536
Value Function Update Magnitude: 0.04232

Collected Steps per Second: 22,479.21917
Overall Steps per Second: 16,305.33613

Timestep Collection Time: 2.22534
Timestep Consumption Time: 0.84261
PPO Batch Consumption Time: 0.05800
Total Iteration Time: 3.06795

Cumulative Model Updates: 4,487
Cumulative Timesteps: 74,923,678

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 74923678...
Checkpoint 74923678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.24453
Policy Entropy: 1.53904
Value Function Loss: 9.93422

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.01629
Policy Update Magnitude: 0.06459
Value Function Update Magnitude: 0.04074

Collected Steps per Second: 20,364.37798
Overall Steps per Second: 14,891.88023

Timestep Collection Time: 2.45596
Timestep Consumption Time: 0.90252
PPO Batch Consumption Time: 0.08289
Total Iteration Time: 3.35847

Cumulative Model Updates: 4,490
Cumulative Timesteps: 74,973,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.97448
Policy Entropy: 1.52819
Value Function Loss: 10.09057

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02364
Policy Update Magnitude: 0.06415
Value Function Update Magnitude: 0.04523

Collected Steps per Second: 23,691.33804
Overall Steps per Second: 16,989.12960

Timestep Collection Time: 2.11098
Timestep Consumption Time: 0.83278
PPO Batch Consumption Time: 0.06380
Total Iteration Time: 2.94376

Cumulative Model Updates: 4,493
Cumulative Timesteps: 75,023,704

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 75023704...
Checkpoint 75023704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.78133
Policy Entropy: 1.54093
Value Function Loss: 10.29911

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02051
Policy Update Magnitude: 0.06359
Value Function Update Magnitude: 0.04551

Collected Steps per Second: 24,742.21586
Overall Steps per Second: 18,286.04446

Timestep Collection Time: 2.02302
Timestep Consumption Time: 0.71426
PPO Batch Consumption Time: 0.02996
Total Iteration Time: 2.73728

Cumulative Model Updates: 4,496
Cumulative Timesteps: 75,073,758

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.06642
Policy Entropy: 1.54286
Value Function Loss: 10.31007

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02430
Policy Update Magnitude: 0.06207
Value Function Update Magnitude: 0.04965

Collected Steps per Second: 22,698.27143
Overall Steps per Second: 15,314.86604

Timestep Collection Time: 2.20343
Timestep Consumption Time: 1.06229
PPO Batch Consumption Time: 0.11942
Total Iteration Time: 3.26572

Cumulative Model Updates: 4,499
Cumulative Timesteps: 75,123,772

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 75123772...
Checkpoint 75123772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.07077
Policy Entropy: 1.53455
Value Function Loss: 10.26625

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01891
Policy Update Magnitude: 0.06417
Value Function Update Magnitude: 0.04410

Collected Steps per Second: 21,971.42713
Overall Steps per Second: 15,658.95008

Timestep Collection Time: 2.27650
Timestep Consumption Time: 0.91771
PPO Batch Consumption Time: 0.10269
Total Iteration Time: 3.19421

Cumulative Model Updates: 4,502
Cumulative Timesteps: 75,173,790

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.09075
Policy Entropy: 1.54094
Value Function Loss: 9.97476

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.01995
Policy Update Magnitude: 0.06344
Value Function Update Magnitude: 0.05241

Collected Steps per Second: 22,111.19607
Overall Steps per Second: 15,716.15257

Timestep Collection Time: 2.26157
Timestep Consumption Time: 0.92025
PPO Batch Consumption Time: 0.07030
Total Iteration Time: 3.18182

Cumulative Model Updates: 4,505
Cumulative Timesteps: 75,223,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 75223796...
Checkpoint 75223796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.44864
Policy Entropy: 1.52039
Value Function Loss: 9.86622

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.01725
Policy Update Magnitude: 0.06442
Value Function Update Magnitude: 0.04631

Collected Steps per Second: 19,809.93477
Overall Steps per Second: 14,610.29664

Timestep Collection Time: 2.52399
Timestep Consumption Time: 0.89826
PPO Batch Consumption Time: 0.08303
Total Iteration Time: 3.42224

Cumulative Model Updates: 4,508
Cumulative Timesteps: 75,273,796

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.67284
Policy Entropy: 1.51079
Value Function Loss: 9.70194

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01382
Policy Update Magnitude: 0.06752
Value Function Update Magnitude: 0.04462

Collected Steps per Second: 21,788.51993
Overall Steps per Second: 15,982.91203

Timestep Collection Time: 2.29626
Timestep Consumption Time: 0.83409
PPO Batch Consumption Time: 0.07207
Total Iteration Time: 3.13034

Cumulative Model Updates: 4,511
Cumulative Timesteps: 75,323,828

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 75323828...
Checkpoint 75323828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.95396
Policy Entropy: 1.50096
Value Function Loss: 9.47008

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02493
Policy Update Magnitude: 0.06652
Value Function Update Magnitude: 0.04402

Collected Steps per Second: 21,864.63194
Overall Steps per Second: 16,665.26079

Timestep Collection Time: 2.28698
Timestep Consumption Time: 0.71351
PPO Batch Consumption Time: 0.02917
Total Iteration Time: 3.00049

Cumulative Model Updates: 4,514
Cumulative Timesteps: 75,373,832

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.38734
Policy Entropy: 1.49909
Value Function Loss: 9.68082

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01721
Policy Update Magnitude: 0.06752
Value Function Update Magnitude: 0.04598

Collected Steps per Second: 23,211.99845
Overall Steps per Second: 16,481.58570

Timestep Collection Time: 2.15518
Timestep Consumption Time: 0.88009
PPO Batch Consumption Time: 0.08491
Total Iteration Time: 3.03527

Cumulative Model Updates: 4,517
Cumulative Timesteps: 75,423,858

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 75423858...
Checkpoint 75423858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.08109
Policy Entropy: 1.50265
Value Function Loss: 9.78690

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01927
Policy Update Magnitude: 0.06360
Value Function Update Magnitude: 0.04598

Collected Steps per Second: 23,678.67560
Overall Steps per Second: 17,747.78809

Timestep Collection Time: 2.11228
Timestep Consumption Time: 0.70587
PPO Batch Consumption Time: 0.02960
Total Iteration Time: 2.81815

Cumulative Model Updates: 4,520
Cumulative Timesteps: 75,473,874

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.06497
Policy Entropy: 1.48462
Value Function Loss: 9.80568

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01760
Policy Update Magnitude: 0.06754
Value Function Update Magnitude: 0.04084

Collected Steps per Second: 23,204.05060
Overall Steps per Second: 16,152.78838

Timestep Collection Time: 2.15583
Timestep Consumption Time: 0.94110
PPO Batch Consumption Time: 0.10028
Total Iteration Time: 3.09693

Cumulative Model Updates: 4,523
Cumulative Timesteps: 75,523,898

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 75523898...
Checkpoint 75523898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.58537
Policy Entropy: 1.48572
Value Function Loss: 9.17707

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01331
Policy Update Magnitude: 0.06973
Value Function Update Magnitude: 0.04371

Collected Steps per Second: 23,326.76102
Overall Steps per Second: 16,598.31124

Timestep Collection Time: 2.14415
Timestep Consumption Time: 0.86917
PPO Batch Consumption Time: 0.06873
Total Iteration Time: 3.01332

Cumulative Model Updates: 4,526
Cumulative Timesteps: 75,573,914

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.13925
Policy Entropy: 1.47925
Value Function Loss: 9.16348

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01202
Policy Update Magnitude: 0.06465
Value Function Update Magnitude: 0.04891

Collected Steps per Second: 21,218.78167
Overall Steps per Second: 15,915.28582

Timestep Collection Time: 2.35697
Timestep Consumption Time: 0.78542
PPO Batch Consumption Time: 0.02959
Total Iteration Time: 3.14239

Cumulative Model Updates: 4,529
Cumulative Timesteps: 75,623,926

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 75623926...
Checkpoint 75623926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.80429
Policy Entropy: 1.47170
Value Function Loss: 9.21037

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01190
Policy Update Magnitude: 0.06734
Value Function Update Magnitude: 0.04714

Collected Steps per Second: 23,452.37202
Overall Steps per Second: 17,018.56688

Timestep Collection Time: 2.13283
Timestep Consumption Time: 0.80631
PPO Batch Consumption Time: 0.05444
Total Iteration Time: 2.93914

Cumulative Model Updates: 4,532
Cumulative Timesteps: 75,673,946

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.22862
Policy Entropy: 1.44555
Value Function Loss: 9.75353

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02579
Policy Update Magnitude: 0.05928
Value Function Update Magnitude: 0.04611

Collected Steps per Second: 22,592.10204
Overall Steps per Second: 16,117.37101

Timestep Collection Time: 2.21414
Timestep Consumption Time: 0.88947
PPO Batch Consumption Time: 0.08463
Total Iteration Time: 3.10361

Cumulative Model Updates: 4,535
Cumulative Timesteps: 75,723,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 75723968...
Checkpoint 75723968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.24147
Policy Entropy: 1.45409
Value Function Loss: 9.24969

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.01258
Policy Update Magnitude: 0.06158
Value Function Update Magnitude: 0.04928

Collected Steps per Second: 22,272.78403
Overall Steps per Second: 15,922.46842

Timestep Collection Time: 2.24570
Timestep Consumption Time: 0.89565
PPO Batch Consumption Time: 0.07835
Total Iteration Time: 3.14135

Cumulative Model Updates: 4,538
Cumulative Timesteps: 75,773,986

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.26169
Policy Entropy: 1.45085
Value Function Loss: 8.93664

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01511
Policy Update Magnitude: 0.06354
Value Function Update Magnitude: 0.05260

Collected Steps per Second: 23,352.55401
Overall Steps per Second: 16,878.54938

Timestep Collection Time: 2.14221
Timestep Consumption Time: 0.82167
PPO Batch Consumption Time: 0.06177
Total Iteration Time: 2.96388

Cumulative Model Updates: 4,541
Cumulative Timesteps: 75,824,012

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 75824012...
Checkpoint 75824012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.42971
Policy Entropy: 1.44020
Value Function Loss: 8.87302

Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.01120
Policy Update Magnitude: 0.06319
Value Function Update Magnitude: 0.04676

Collected Steps per Second: 19,578.85764
Overall Steps per Second: 14,681.10560

Timestep Collection Time: 2.55429
Timestep Consumption Time: 0.85213
PPO Batch Consumption Time: 0.08962
Total Iteration Time: 3.40642

Cumulative Model Updates: 4,544
Cumulative Timesteps: 75,874,022

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.87434
Policy Entropy: 1.40603
Value Function Loss: 9.32149

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.01807
Policy Update Magnitude: 0.06388
Value Function Update Magnitude: 0.05267

Collected Steps per Second: 24,095.08404
Overall Steps per Second: 16,698.90208

Timestep Collection Time: 2.07544
Timestep Consumption Time: 0.91924
PPO Batch Consumption Time: 0.08465
Total Iteration Time: 2.99469

Cumulative Model Updates: 4,547
Cumulative Timesteps: 75,924,030

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 75924030...
Checkpoint 75924030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370.05233
Policy Entropy: 1.40312
Value Function Loss: 9.40925

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.00993
Policy Update Magnitude: 0.06959
Value Function Update Magnitude: 0.04935

Collected Steps per Second: 23,582.56539
Overall Steps per Second: 16,701.25275

Timestep Collection Time: 2.12038
Timestep Consumption Time: 0.87365
PPO Batch Consumption Time: 0.08129
Total Iteration Time: 2.99403

Cumulative Model Updates: 4,550
Cumulative Timesteps: 75,974,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.31486
Policy Entropy: 1.38427
Value Function Loss: 9.22981

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02141
Policy Update Magnitude: 0.07150
Value Function Update Magnitude: 0.04820

Collected Steps per Second: 23,790.22314
Overall Steps per Second: 16,792.45728

Timestep Collection Time: 2.10170
Timestep Consumption Time: 0.87582
PPO Batch Consumption Time: 0.05996
Total Iteration Time: 2.97753

Cumulative Model Updates: 4,553
Cumulative Timesteps: 76,024,034

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 76024034...
Checkpoint 76024034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.80110
Policy Entropy: 1.37555
Value Function Loss: 8.98026

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02117
Policy Update Magnitude: 0.06313
Value Function Update Magnitude: 0.04686

Collected Steps per Second: 21,116.69936
Overall Steps per Second: 16,181.04709

Timestep Collection Time: 2.36874
Timestep Consumption Time: 0.72253
PPO Batch Consumption Time: 0.02927
Total Iteration Time: 3.09127

Cumulative Model Updates: 4,556
Cumulative Timesteps: 76,074,054

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.99855
Policy Entropy: 1.34980
Value Function Loss: 8.95660

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.01990
Policy Update Magnitude: 0.05722
Value Function Update Magnitude: 0.04631

Collected Steps per Second: 24,084.75639
Overall Steps per Second: 17,879.69034

Timestep Collection Time: 2.07683
Timestep Consumption Time: 0.72076
PPO Batch Consumption Time: 0.05266
Total Iteration Time: 2.79759

Cumulative Model Updates: 4,559
Cumulative Timesteps: 76,124,074

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 76124074...
Checkpoint 76124074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396.85401
Policy Entropy: 1.33707
Value Function Loss: 8.99631

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.01182
Policy Update Magnitude: 0.06156
Value Function Update Magnitude: 0.04868

Collected Steps per Second: 22,485.78182
Overall Steps per Second: 15,457.40807

Timestep Collection Time: 2.22407
Timestep Consumption Time: 1.01127
PPO Batch Consumption Time: 0.12300
Total Iteration Time: 3.23534

Cumulative Model Updates: 4,562
Cumulative Timesteps: 76,174,084

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.14258
Policy Entropy: 1.32263
Value Function Loss: 9.25661

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02079
Policy Update Magnitude: 0.05864
Value Function Update Magnitude: 0.04244

Collected Steps per Second: 24,078.54305
Overall Steps per Second: 17,281.45860

Timestep Collection Time: 2.07762
Timestep Consumption Time: 0.81716
PPO Batch Consumption Time: 0.06157
Total Iteration Time: 2.89478

Cumulative Model Updates: 4,565
Cumulative Timesteps: 76,224,110

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 76224110...
Checkpoint 76224110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.85748
Policy Entropy: 1.29008
Value Function Loss: 9.28699

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03315
Policy Update Magnitude: 0.05741
Value Function Update Magnitude: 0.04093

Collected Steps per Second: 20,941.50274
Overall Steps per Second: 16,326.14110

Timestep Collection Time: 2.38875
Timestep Consumption Time: 0.67529
PPO Batch Consumption Time: 0.02901
Total Iteration Time: 3.06404

Cumulative Model Updates: 4,568
Cumulative Timesteps: 76,274,134

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.33162
Policy Entropy: 1.29909
Value Function Loss: 9.16137

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01909
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.03945

Collected Steps per Second: 24,047.42770
Overall Steps per Second: 17,892.38505

Timestep Collection Time: 2.08047
Timestep Consumption Time: 0.71569
PPO Batch Consumption Time: 0.02923
Total Iteration Time: 2.79616

Cumulative Model Updates: 4,571
Cumulative Timesteps: 76,324,164

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 76324164...
Checkpoint 76324164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.06138
Policy Entropy: 1.28040
Value Function Loss: 8.69678

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.01555
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.03947

Collected Steps per Second: 21,803.93431
Overall Steps per Second: 15,559.17246

Timestep Collection Time: 2.29445
Timestep Consumption Time: 0.92089
PPO Batch Consumption Time: 0.09559
Total Iteration Time: 3.21534

Cumulative Model Updates: 4,574
Cumulative Timesteps: 76,374,192

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.48592
Policy Entropy: 1.28035
Value Function Loss: 8.72797

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02155
Policy Update Magnitude: 0.05365
Value Function Update Magnitude: 0.03506

Collected Steps per Second: 24,887.97995
Overall Steps per Second: 18,277.52692

Timestep Collection Time: 2.00948
Timestep Consumption Time: 0.72677
PPO Batch Consumption Time: 0.02913
Total Iteration Time: 2.73626

Cumulative Model Updates: 4,577
Cumulative Timesteps: 76,424,204

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 76424204...
Checkpoint 76424204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.82811
Policy Entropy: 1.28354
Value Function Loss: 8.19504

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02288
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.03928

Collected Steps per Second: 23,963.32350
Overall Steps per Second: 17,471.42678

Timestep Collection Time: 2.08744
Timestep Consumption Time: 0.77563
PPO Batch Consumption Time: 0.03002
Total Iteration Time: 2.86307

Cumulative Model Updates: 4,580
Cumulative Timesteps: 76,474,226

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.70007
Policy Entropy: 1.28140
Value Function Loss: 8.42777

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.01457
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.04115

Collected Steps per Second: 22,865.82822
Overall Steps per Second: 16,444.03728

Timestep Collection Time: 2.18693
Timestep Consumption Time: 0.85405
PPO Batch Consumption Time: 0.07447
Total Iteration Time: 3.04098

Cumulative Model Updates: 4,583
Cumulative Timesteps: 76,524,232

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 76524232...
Checkpoint 76524232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.15074
Policy Entropy: 1.27947
Value Function Loss: 8.72659

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.01691
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.03970

Collected Steps per Second: 22,670.55863
Overall Steps per Second: 17,170.84524

Timestep Collection Time: 2.20612
Timestep Consumption Time: 0.70661
PPO Batch Consumption Time: 0.02987
Total Iteration Time: 2.91273

Cumulative Model Updates: 4,586
Cumulative Timesteps: 76,574,246

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.99664
Policy Entropy: 1.26906
Value Function Loss: 9.20701

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01848
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.04119

Collected Steps per Second: 24,532.09551
Overall Steps per Second: 18,138.72269

Timestep Collection Time: 2.03937
Timestep Consumption Time: 0.71882
PPO Batch Consumption Time: 0.02938
Total Iteration Time: 2.75819

Cumulative Model Updates: 4,589
Cumulative Timesteps: 76,624,276

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 76624276...
Checkpoint 76624276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353.28182
Policy Entropy: 1.24943
Value Function Loss: 9.00883

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.01651
Policy Update Magnitude: 0.05952
Value Function Update Magnitude: 0.04172

Collected Steps per Second: 22,750.56164
Overall Steps per Second: 15,327.25429

Timestep Collection Time: 2.19828
Timestep Consumption Time: 1.06467
PPO Batch Consumption Time: 0.11187
Total Iteration Time: 3.26295

Cumulative Model Updates: 4,592
Cumulative Timesteps: 76,674,288

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.94525
Policy Entropy: 1.23913
Value Function Loss: 8.87871

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01795
Policy Update Magnitude: 0.06426
Value Function Update Magnitude: 0.04348

Collected Steps per Second: 21,748.39492
Overall Steps per Second: 15,844.24209

Timestep Collection Time: 2.29957
Timestep Consumption Time: 0.85691
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 3.15648

Cumulative Model Updates: 4,595
Cumulative Timesteps: 76,724,300

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 76724300...
Checkpoint 76724300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.76338
Policy Entropy: 1.21736
Value Function Loss: 8.55462

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01392
Policy Update Magnitude: 0.06221
Value Function Update Magnitude: 0.03996

Collected Steps per Second: 18,604.87395
Overall Steps per Second: 13,937.14595

Timestep Collection Time: 2.68897
Timestep Consumption Time: 0.90057
PPO Batch Consumption Time: 0.08185
Total Iteration Time: 3.58954

Cumulative Model Updates: 4,598
Cumulative Timesteps: 76,774,328

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.71020
Policy Entropy: 1.22736
Value Function Loss: 8.72539

Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.01037
Policy Update Magnitude: 0.06046
Value Function Update Magnitude: 0.03859

Collected Steps per Second: 23,337.67054
Overall Steps per Second: 17,357.39087

Timestep Collection Time: 2.14254
Timestep Consumption Time: 0.73819
PPO Batch Consumption Time: 0.06437
Total Iteration Time: 2.88073

Cumulative Model Updates: 4,601
Cumulative Timesteps: 76,824,330

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 76824330...
Checkpoint 76824330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.22492
Policy Entropy: 1.23935
Value Function Loss: 8.53856

Mean KL Divergence: 0.00112
SB3 Clip Fraction: 0.00721
Policy Update Magnitude: 0.06118
Value Function Update Magnitude: 0.04195

Collected Steps per Second: 23,600.46625
Overall Steps per Second: 16,286.91602

Timestep Collection Time: 2.11877
Timestep Consumption Time: 0.95142
PPO Batch Consumption Time: 0.09810
Total Iteration Time: 3.07019

Cumulative Model Updates: 4,604
Cumulative Timesteps: 76,874,334

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.19492
Policy Entropy: 1.23652
Value Function Loss: 8.63753

Mean KL Divergence: 0.00122
SB3 Clip Fraction: 0.00693
Policy Update Magnitude: 0.06662
Value Function Update Magnitude: 0.04972

Collected Steps per Second: 24,260.71951
Overall Steps per Second: 18,171.30964

Timestep Collection Time: 2.06193
Timestep Consumption Time: 0.69098
PPO Batch Consumption Time: 0.02892
Total Iteration Time: 2.75291

Cumulative Model Updates: 4,607
Cumulative Timesteps: 76,924,358

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 76924358...
Checkpoint 76924358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.28228
Policy Entropy: 1.21756
Value Function Loss: 8.52108

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02452
Policy Update Magnitude: 0.06380
Value Function Update Magnitude: 0.04561

Collected Steps per Second: 23,565.03546
Overall Steps per Second: 16,567.90162

Timestep Collection Time: 2.12298
Timestep Consumption Time: 0.89660
PPO Batch Consumption Time: 0.11302
Total Iteration Time: 3.01957

Cumulative Model Updates: 4,610
Cumulative Timesteps: 76,974,386

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.61540
Policy Entropy: 1.21028
Value Function Loss: 8.43494

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02454
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.04435

Collected Steps per Second: 23,925.48674
Overall Steps per Second: 17,028.51814

Timestep Collection Time: 2.09032
Timestep Consumption Time: 0.84663
PPO Batch Consumption Time: 0.06275
Total Iteration Time: 2.93696

Cumulative Model Updates: 4,613
Cumulative Timesteps: 77,024,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 77024398...
Checkpoint 77024398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.31011
Policy Entropy: 1.20887
Value Function Loss: 8.35990

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.01925
Policy Update Magnitude: 0.05038
Value Function Update Magnitude: 0.04710

Collected Steps per Second: 23,582.47497
Overall Steps per Second: 16,458.76805

Timestep Collection Time: 2.12107
Timestep Consumption Time: 0.91804
PPO Batch Consumption Time: 0.10575
Total Iteration Time: 3.03911

Cumulative Model Updates: 4,616
Cumulative Timesteps: 77,074,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.67191
Policy Entropy: 1.21911
Value Function Loss: 8.47002

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.01539
Policy Update Magnitude: 0.05316
Value Function Update Magnitude: 0.05390

Collected Steps per Second: 23,968.63556
Overall Steps per Second: 17,773.39522

Timestep Collection Time: 2.08664
Timestep Consumption Time: 0.72734
PPO Batch Consumption Time: 0.05810
Total Iteration Time: 2.81398

Cumulative Model Updates: 4,619
Cumulative Timesteps: 77,124,432

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 77124432...
Checkpoint 77124432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.56920
Policy Entropy: 1.20867
Value Function Loss: 8.68984

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01240
Policy Update Magnitude: 0.05731
Value Function Update Magnitude: 0.04707

Collected Steps per Second: 22,785.46348
Overall Steps per Second: 17,081.93422

Timestep Collection Time: 2.19587
Timestep Consumption Time: 0.73319
PPO Batch Consumption Time: 0.02941
Total Iteration Time: 2.92906

Cumulative Model Updates: 4,622
Cumulative Timesteps: 77,174,466

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.50853
Policy Entropy: 1.21690
Value Function Loss: 8.67611

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02119
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.04398

Collected Steps per Second: 23,025.38451
Overall Steps per Second: 16,518.61242

Timestep Collection Time: 2.17195
Timestep Consumption Time: 0.85554
PPO Batch Consumption Time: 0.09622
Total Iteration Time: 3.02749

Cumulative Model Updates: 4,625
Cumulative Timesteps: 77,224,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 77224476...
Checkpoint 77224476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.17034
Policy Entropy: 1.21306
Value Function Loss: 8.77761

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.00837
Policy Update Magnitude: 0.05835
Value Function Update Magnitude: 0.03848

Collected Steps per Second: 21,782.85824
Overall Steps per Second: 16,590.42493

Timestep Collection Time: 2.29667
Timestep Consumption Time: 0.71881
PPO Batch Consumption Time: 0.02984
Total Iteration Time: 3.01547

Cumulative Model Updates: 4,628
Cumulative Timesteps: 77,274,504

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.09130
Policy Entropy: 1.21539
Value Function Loss: 8.26192

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.00971
Policy Update Magnitude: 0.05980
Value Function Update Magnitude: 0.04340

Collected Steps per Second: 24,086.94770
Overall Steps per Second: 16,868.80798

Timestep Collection Time: 2.07598
Timestep Consumption Time: 0.88831
PPO Batch Consumption Time: 0.08342
Total Iteration Time: 2.96429

Cumulative Model Updates: 4,631
Cumulative Timesteps: 77,324,508

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 77324508...
Checkpoint 77324508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.01526
Policy Entropy: 1.22406
Value Function Loss: 8.24267

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.01887
Policy Update Magnitude: 0.06256
Value Function Update Magnitude: 0.04476

Collected Steps per Second: 23,654.54152
Overall Steps per Second: 18,167.36918

Timestep Collection Time: 2.11410
Timestep Consumption Time: 0.63853
PPO Batch Consumption Time: 0.02977
Total Iteration Time: 2.75263

Cumulative Model Updates: 4,634
Cumulative Timesteps: 77,374,516

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.82787
Policy Entropy: 1.22587
Value Function Loss: 7.85946

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.01727
Policy Update Magnitude: 0.05876
Value Function Update Magnitude: 0.05858

Collected Steps per Second: 24,278.15227
Overall Steps per Second: 18,073.89009

Timestep Collection Time: 2.06062
Timestep Consumption Time: 0.70735
PPO Batch Consumption Time: 0.03017
Total Iteration Time: 2.76797

Cumulative Model Updates: 4,637
Cumulative Timesteps: 77,424,544

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 77424544...
Checkpoint 77424544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.46371
Policy Entropy: 1.25387
Value Function Loss: 8.05451

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02120
Policy Update Magnitude: 0.05453
Value Function Update Magnitude: 0.05114

Collected Steps per Second: 22,713.40849
Overall Steps per Second: 16,473.59362

Timestep Collection Time: 2.20187
Timestep Consumption Time: 0.83402
PPO Batch Consumption Time: 0.09162
Total Iteration Time: 3.03589

Cumulative Model Updates: 4,640
Cumulative Timesteps: 77,474,556

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.27946
Policy Entropy: 1.26487
Value Function Loss: 7.85851

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02319
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.05134

Collected Steps per Second: 24,060.24876
Overall Steps per Second: 17,081.82720

Timestep Collection Time: 2.07878
Timestep Consumption Time: 0.84924
PPO Batch Consumption Time: 0.07142
Total Iteration Time: 2.92802

Cumulative Model Updates: 4,643
Cumulative Timesteps: 77,524,572

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 77524572...
Checkpoint 77524572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.22511
Policy Entropy: 1.25170
Value Function Loss: 8.17219

Mean KL Divergence: 0.00144
SB3 Clip Fraction: 0.00981
Policy Update Magnitude: 0.05718
Value Function Update Magnitude: 0.04998

Collected Steps per Second: 23,462.02134
Overall Steps per Second: 17,448.01757

Timestep Collection Time: 2.13153
Timestep Consumption Time: 0.73470
PPO Batch Consumption Time: 0.03030
Total Iteration Time: 2.86623

Cumulative Model Updates: 4,646
Cumulative Timesteps: 77,574,582

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.25569
Policy Entropy: 1.24430
Value Function Loss: 8.16036

Mean KL Divergence: 0.00168
SB3 Clip Fraction: 0.01631
Policy Update Magnitude: 0.05941
Value Function Update Magnitude: 0.04743

Collected Steps per Second: 23,363.95769
Overall Steps per Second: 16,829.13598

Timestep Collection Time: 2.14056
Timestep Consumption Time: 0.83119
PPO Batch Consumption Time: 0.09106
Total Iteration Time: 2.97175

Cumulative Model Updates: 4,649
Cumulative Timesteps: 77,624,594

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 77624594...
Checkpoint 77624594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.24421
Policy Entropy: 1.23721
Value Function Loss: 8.69047

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03613
Policy Update Magnitude: 0.06453
Value Function Update Magnitude: 0.04078

Collected Steps per Second: 23,451.93773
Overall Steps per Second: 16,907.89681

Timestep Collection Time: 2.13330
Timestep Consumption Time: 0.82567
PPO Batch Consumption Time: 0.05937
Total Iteration Time: 2.95897

Cumulative Model Updates: 4,652
Cumulative Timesteps: 77,674,624

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.67455
Policy Entropy: 1.24157
Value Function Loss: 8.59834

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.05041
Policy Update Magnitude: 0.05659
Value Function Update Magnitude: 0.03821

Collected Steps per Second: 21,266.20842
Overall Steps per Second: 15,489.95451

Timestep Collection Time: 2.35209
Timestep Consumption Time: 0.87710
PPO Batch Consumption Time: 0.08244
Total Iteration Time: 3.22919

Cumulative Model Updates: 4,655
Cumulative Timesteps: 77,724,644

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 77724644...
Checkpoint 77724644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.80368
Policy Entropy: 1.25600
Value Function Loss: 8.60743

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04497
Policy Update Magnitude: 0.05082
Value Function Update Magnitude: 0.03529

Collected Steps per Second: 19,998.97246
Overall Steps per Second: 15,009.40293

Timestep Collection Time: 2.50113
Timestep Consumption Time: 0.83145
PPO Batch Consumption Time: 0.06111
Total Iteration Time: 3.33258

Cumulative Model Updates: 4,658
Cumulative Timesteps: 77,774,664

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.43641
Policy Entropy: 1.24711
Value Function Loss: 8.18115

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03757
Policy Update Magnitude: 0.04396
Value Function Update Magnitude: 0.03788

Collected Steps per Second: 23,867.36873
Overall Steps per Second: 17,159.10539

Timestep Collection Time: 2.09592
Timestep Consumption Time: 0.81939
PPO Batch Consumption Time: 0.06373
Total Iteration Time: 2.91530

Cumulative Model Updates: 4,661
Cumulative Timesteps: 77,824,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 77824688...
Checkpoint 77824688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.32363
Policy Entropy: 1.26027
Value Function Loss: 8.20170

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02476
Policy Update Magnitude: 0.04069
Value Function Update Magnitude: 0.04578

Collected Steps per Second: 20,680.19503
Overall Steps per Second: 15,115.44548

Timestep Collection Time: 2.41893
Timestep Consumption Time: 0.89053
PPO Batch Consumption Time: 0.08283
Total Iteration Time: 3.30946

Cumulative Model Updates: 4,664
Cumulative Timesteps: 77,874,712

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.76634
Policy Entropy: 1.23029
Value Function Loss: 8.28874

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.01920
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.04726

Collected Steps per Second: 24,331.28132
Overall Steps per Second: 17,424.20495

Timestep Collection Time: 2.05587
Timestep Consumption Time: 0.81496
PPO Batch Consumption Time: 0.06029
Total Iteration Time: 2.87083

Cumulative Model Updates: 4,667
Cumulative Timesteps: 77,924,734

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 77924734...
Checkpoint 77924734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403.75569
Policy Entropy: 1.23311
Value Function Loss: 7.96890

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02853
Policy Update Magnitude: 0.04587
Value Function Update Magnitude: 0.04613

Collected Steps per Second: 21,724.43418
Overall Steps per Second: 15,222.93372

Timestep Collection Time: 2.30257
Timestep Consumption Time: 0.98339
PPO Batch Consumption Time: 0.11069
Total Iteration Time: 3.28596

Cumulative Model Updates: 4,670
Cumulative Timesteps: 77,974,756

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.64113
Policy Entropy: 1.21373
Value Function Loss: 7.67694

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02289
Policy Update Magnitude: 0.04316
Value Function Update Magnitude: 0.04078

Collected Steps per Second: 23,607.94503
Overall Steps per Second: 16,648.84462

Timestep Collection Time: 2.11912
Timestep Consumption Time: 0.88578
PPO Batch Consumption Time: 0.08547
Total Iteration Time: 3.00489

Cumulative Model Updates: 4,673
Cumulative Timesteps: 78,024,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 78024784...
Checkpoint 78024784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.52676
Policy Entropy: 1.23798
Value Function Loss: 7.78715

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01195
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.03560

Collected Steps per Second: 24,369.72935
Overall Steps per Second: 18,037.03328

Timestep Collection Time: 2.05173
Timestep Consumption Time: 0.72035
PPO Batch Consumption Time: 0.02990
Total Iteration Time: 2.77207

Cumulative Model Updates: 4,676
Cumulative Timesteps: 78,074,784

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.98291
Policy Entropy: 1.24090
Value Function Loss: 7.85876

Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.01124
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.03923

Collected Steps per Second: 23,779.42848
Overall Steps per Second: 17,621.51519

Timestep Collection Time: 2.10442
Timestep Consumption Time: 0.73540
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 2.83982

Cumulative Model Updates: 4,679
Cumulative Timesteps: 78,124,826

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 78124826...
Checkpoint 78124826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471.66123
Policy Entropy: 1.23316
Value Function Loss: 8.09676

Mean KL Divergence: 0.00151
SB3 Clip Fraction: 0.01208
Policy Update Magnitude: 0.05640
Value Function Update Magnitude: 0.04724

Collected Steps per Second: 22,719.80514
Overall Steps per Second: 16,015.98729

Timestep Collection Time: 2.20072
Timestep Consumption Time: 0.92116
PPO Batch Consumption Time: 0.11947
Total Iteration Time: 3.12188

Cumulative Model Updates: 4,682
Cumulative Timesteps: 78,174,826

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.29110
Policy Entropy: 1.23850
Value Function Loss: 7.86391

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01497
Policy Update Magnitude: 0.05979
Value Function Update Magnitude: 0.03472

Collected Steps per Second: 23,941.29616
Overall Steps per Second: 17,089.93383

Timestep Collection Time: 2.08944
Timestep Consumption Time: 0.83766
PPO Batch Consumption Time: 0.06332
Total Iteration Time: 2.92710

Cumulative Model Updates: 4,685
Cumulative Timesteps: 78,224,850

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 78224850...
Checkpoint 78224850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415.65272
Policy Entropy: 1.23956
Value Function Loss: 8.26109

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01894
Policy Update Magnitude: 0.05823
Value Function Update Magnitude: 0.03247

Collected Steps per Second: 22,684.01023
Overall Steps per Second: 17,120.88107

Timestep Collection Time: 2.20446
Timestep Consumption Time: 0.71630
PPO Batch Consumption Time: 0.02991
Total Iteration Time: 2.92076

Cumulative Model Updates: 4,688
Cumulative Timesteps: 78,274,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.07522
Policy Entropy: 1.24937
Value Function Loss: 8.54585

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01541
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.02915

Collected Steps per Second: 23,721.62554
Overall Steps per Second: 18,183.04672

Timestep Collection Time: 2.10888
Timestep Consumption Time: 0.64237
PPO Batch Consumption Time: 0.02928
Total Iteration Time: 2.75124

Cumulative Model Updates: 4,691
Cumulative Timesteps: 78,324,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 78324882...
Checkpoint 78324882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.10581
Policy Entropy: 1.24089
Value Function Loss: 8.81226

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02182
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.03268

Collected Steps per Second: 22,577.40515
Overall Steps per Second: 15,828.95937

Timestep Collection Time: 2.21505
Timestep Consumption Time: 0.94435
PPO Batch Consumption Time: 0.09641
Total Iteration Time: 3.15940

Cumulative Model Updates: 4,694
Cumulative Timesteps: 78,374,892

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.73006
Policy Entropy: 1.25325
Value Function Loss: 8.74160

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01382
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.02875

Collected Steps per Second: 23,830.65085
Overall Steps per Second: 17,311.39066

Timestep Collection Time: 2.09864
Timestep Consumption Time: 0.79032
PPO Batch Consumption Time: 0.06318
Total Iteration Time: 2.88896

Cumulative Model Updates: 4,697
Cumulative Timesteps: 78,424,904

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 78424904...
Checkpoint 78424904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.36015
Policy Entropy: 1.25334
Value Function Loss: 8.41360

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02267
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.02855

Collected Steps per Second: 21,414.11948
Overall Steps per Second: 15,279.85798

Timestep Collection Time: 2.33622
Timestep Consumption Time: 0.93790
PPO Batch Consumption Time: 0.12096
Total Iteration Time: 3.27411

Cumulative Model Updates: 4,700
Cumulative Timesteps: 78,474,932

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.13051
Policy Entropy: 1.22812
Value Function Loss: 8.26779

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01769
Policy Update Magnitude: 0.05695
Value Function Update Magnitude: 0.03131

Collected Steps per Second: 24,319.28776
Overall Steps per Second: 17,978.53045

Timestep Collection Time: 2.05647
Timestep Consumption Time: 0.72529
PPO Batch Consumption Time: 0.03001
Total Iteration Time: 2.78176

Cumulative Model Updates: 4,703
Cumulative Timesteps: 78,524,944

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 78524944...
Checkpoint 78524944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468.09030
Policy Entropy: 1.22427
Value Function Loss: 8.15583

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02113
Policy Update Magnitude: 0.05925
Value Function Update Magnitude: 0.02923

Collected Steps per Second: 22,479.02869
Overall Steps per Second: 15,521.14891

Timestep Collection Time: 2.22554
Timestep Consumption Time: 0.99767
PPO Batch Consumption Time: 0.10787
Total Iteration Time: 3.22321

Cumulative Model Updates: 4,706
Cumulative Timesteps: 78,574,972

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.24225
Policy Entropy: 1.21939
Value Function Loss: 8.23109

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.01889
Policy Update Magnitude: 0.06175
Value Function Update Magnitude: 0.03109

Collected Steps per Second: 24,634.40024
Overall Steps per Second: 17,056.01654

Timestep Collection Time: 2.03001
Timestep Consumption Time: 0.90198
PPO Batch Consumption Time: 0.07144
Total Iteration Time: 2.93199

Cumulative Model Updates: 4,709
Cumulative Timesteps: 78,624,980

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 78624980...
Checkpoint 78624980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408.18024
Policy Entropy: 1.18806
Value Function Loss: 8.35203

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.01981
Policy Update Magnitude: 0.06108
Value Function Update Magnitude: 0.03746

Collected Steps per Second: 23,329.98971
Overall Steps per Second: 16,875.55220

Timestep Collection Time: 2.14428
Timestep Consumption Time: 0.82013
PPO Batch Consumption Time: 0.06281
Total Iteration Time: 2.96441

Cumulative Model Updates: 4,712
Cumulative Timesteps: 78,675,006

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.02896
Policy Entropy: 1.18178
Value Function Loss: 8.26070

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02177
Policy Update Magnitude: 0.05990
Value Function Update Magnitude: 0.05738

Collected Steps per Second: 24,077.47726
Overall Steps per Second: 16,422.68466

Timestep Collection Time: 2.07763
Timestep Consumption Time: 0.96840
PPO Batch Consumption Time: 0.11935
Total Iteration Time: 3.04603

Cumulative Model Updates: 4,715
Cumulative Timesteps: 78,725,030

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 78725030...
Checkpoint 78725030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.46343
Policy Entropy: 1.16711
Value Function Loss: 8.05505

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.01851
Policy Update Magnitude: 0.06285
Value Function Update Magnitude: 0.06190

Collected Steps per Second: 24,469.13929
Overall Steps per Second: 17,534.61209

Timestep Collection Time: 2.04494
Timestep Consumption Time: 0.80873
PPO Batch Consumption Time: 0.05922
Total Iteration Time: 2.85367

Cumulative Model Updates: 4,718
Cumulative Timesteps: 78,775,068

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.24163
Policy Entropy: 1.16593
Value Function Loss: 8.01109

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02225
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.05675

Collected Steps per Second: 21,517.63233
Overall Steps per Second: 16,440.64072

Timestep Collection Time: 2.32461
Timestep Consumption Time: 0.71786
PPO Batch Consumption Time: 0.02930
Total Iteration Time: 3.04246

Cumulative Model Updates: 4,721
Cumulative Timesteps: 78,825,088

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 78825088...
Checkpoint 78825088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.53155
Policy Entropy: 1.18081
Value Function Loss: 8.16116

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01994
Policy Update Magnitude: 0.05387
Value Function Update Magnitude: 0.05970

Collected Steps per Second: 23,801.93441
Overall Steps per Second: 17,814.29528

Timestep Collection Time: 2.10193
Timestep Consumption Time: 0.70649
PPO Batch Consumption Time: 0.03004
Total Iteration Time: 2.80842

Cumulative Model Updates: 4,724
Cumulative Timesteps: 78,875,118

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.63690
Policy Entropy: 1.18161
Value Function Loss: 8.23131

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.01901
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.05918

Collected Steps per Second: 22,934.69546
Overall Steps per Second: 16,343.62459

Timestep Collection Time: 2.18071
Timestep Consumption Time: 0.87944
PPO Batch Consumption Time: 0.07814
Total Iteration Time: 3.06015

Cumulative Model Updates: 4,727
Cumulative Timesteps: 78,925,132

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 78925132...
Checkpoint 78925132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.06896
Policy Entropy: 1.17899
Value Function Loss: 7.97617

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01571
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.05378

Collected Steps per Second: 23,148.73832
Overall Steps per Second: 16,812.51708

Timestep Collection Time: 2.16115
Timestep Consumption Time: 0.81449
PPO Batch Consumption Time: 0.06037
Total Iteration Time: 2.97564

Cumulative Model Updates: 4,730
Cumulative Timesteps: 78,975,160

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.79633
Policy Entropy: 1.16537
Value Function Loss: 7.80022

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01388
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.04401

Collected Steps per Second: 22,082.59579
Overall Steps per Second: 16,860.73702

Timestep Collection Time: 2.26559
Timestep Consumption Time: 0.70166
PPO Batch Consumption Time: 0.02851
Total Iteration Time: 2.96725

Cumulative Model Updates: 4,733
Cumulative Timesteps: 79,025,190

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 79025190...
Checkpoint 79025190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.89627
Policy Entropy: 1.17158
Value Function Loss: 7.70822

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01663
Policy Update Magnitude: 0.05495
Value Function Update Magnitude: 0.04025

Collected Steps per Second: 23,600.13035
Overall Steps per Second: 17,687.19523

Timestep Collection Time: 2.11982
Timestep Consumption Time: 0.70867
PPO Batch Consumption Time: 0.05381
Total Iteration Time: 2.82849

Cumulative Model Updates: 4,736
Cumulative Timesteps: 79,075,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.38448
Policy Entropy: 1.17809
Value Function Loss: 7.78107

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01507
Policy Update Magnitude: 0.05403
Value Function Update Magnitude: 0.04079

Collected Steps per Second: 20,966.67860
Overall Steps per Second: 15,999.81160

Timestep Collection Time: 2.38493
Timestep Consumption Time: 0.74036
PPO Batch Consumption Time: 0.02930
Total Iteration Time: 3.12529

Cumulative Model Updates: 4,739
Cumulative Timesteps: 79,125,222

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 79125222...
Checkpoint 79125222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.42489
Policy Entropy: 1.18675
Value Function Loss: 7.83966

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.01925
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.03897

Collected Steps per Second: 23,566.07475
Overall Steps per Second: 16,590.24079

Timestep Collection Time: 2.12229
Timestep Consumption Time: 0.89238
PPO Batch Consumption Time: 0.09636
Total Iteration Time: 3.01466

Cumulative Model Updates: 4,742
Cumulative Timesteps: 79,175,236

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.36732
Policy Entropy: 1.18721
Value Function Loss: 7.94974

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01286
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.03781

Collected Steps per Second: 24,003.93964
Overall Steps per Second: 17,794.61431

Timestep Collection Time: 2.08466
Timestep Consumption Time: 0.72743
PPO Batch Consumption Time: 0.05931
Total Iteration Time: 2.81209

Cumulative Model Updates: 4,745
Cumulative Timesteps: 79,225,276

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 79225276...
Checkpoint 79225276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.18003
Policy Entropy: 1.18023
Value Function Loss: 8.12999

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01271
Policy Update Magnitude: 0.05217
Value Function Update Magnitude: 0.04205

Collected Steps per Second: 21,900.75182
Overall Steps per Second: 16,617.88557

Timestep Collection Time: 2.28412
Timestep Consumption Time: 0.72613
PPO Batch Consumption Time: 0.02988
Total Iteration Time: 3.01025

Cumulative Model Updates: 4,748
Cumulative Timesteps: 79,275,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.20024
Policy Entropy: 1.16713
Value Function Loss: 7.45637

Mean KL Divergence: 0.00143
SB3 Clip Fraction: 0.00857
Policy Update Magnitude: 0.05314
Value Function Update Magnitude: 0.03763

Collected Steps per Second: 23,376.59995
Overall Steps per Second: 16,660.43699

Timestep Collection Time: 2.13992
Timestep Consumption Time: 0.86264
PPO Batch Consumption Time: 0.07842
Total Iteration Time: 3.00256

Cumulative Model Updates: 4,751
Cumulative Timesteps: 79,325,324

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 79325324...
Checkpoint 79325324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.32031
Policy Entropy: 1.17505
Value Function Loss: 7.48464

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.01945
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.04188

Collected Steps per Second: 22,591.93026
Overall Steps per Second: 15,951.15321

Timestep Collection Time: 2.21371
Timestep Consumption Time: 0.92161
PPO Batch Consumption Time: 0.11744
Total Iteration Time: 3.13532

Cumulative Model Updates: 4,754
Cumulative Timesteps: 79,375,336

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.82983
Policy Entropy: 1.17307
Value Function Loss: 7.14023

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01721
Policy Update Magnitude: 0.04752
Value Function Update Magnitude: 0.03643

Collected Steps per Second: 23,823.64332
Overall Steps per Second: 17,032.37520

Timestep Collection Time: 2.09993
Timestep Consumption Time: 0.83730
PPO Batch Consumption Time: 0.06636
Total Iteration Time: 2.93723

Cumulative Model Updates: 4,757
Cumulative Timesteps: 79,425,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 79425364...
Checkpoint 79425364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.58928
Policy Entropy: 1.19309
Value Function Loss: 7.45532

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01875
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.04010

Collected Steps per Second: 23,725.68236
Overall Steps per Second: 17,849.35947

Timestep Collection Time: 2.10869
Timestep Consumption Time: 0.69422
PPO Batch Consumption Time: 0.02981
Total Iteration Time: 2.80290

Cumulative Model Updates: 4,760
Cumulative Timesteps: 79,475,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.54997
Policy Entropy: 1.17204
Value Function Loss: 7.53542

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01708
Policy Update Magnitude: 0.04803
Value Function Update Magnitude: 0.03791

Collected Steps per Second: 23,840.73111
Overall Steps per Second: 17,346.11212

Timestep Collection Time: 2.09826
Timestep Consumption Time: 0.78562
PPO Batch Consumption Time: 0.07377
Total Iteration Time: 2.88387

Cumulative Model Updates: 4,763
Cumulative Timesteps: 79,525,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 79525418...
Checkpoint 79525418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396.56453
Policy Entropy: 1.18764
Value Function Loss: 7.99012

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01595
Policy Update Magnitude: 0.04584
Value Function Update Magnitude: 0.04208

Collected Steps per Second: 21,539.57130
Overall Steps per Second: 16,495.43057

Timestep Collection Time: 2.32261
Timestep Consumption Time: 0.71023
PPO Batch Consumption Time: 0.02989
Total Iteration Time: 3.03284

Cumulative Model Updates: 4,766
Cumulative Timesteps: 79,575,446

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.25795
Policy Entropy: 1.15806
Value Function Loss: 8.01736

Mean KL Divergence: 0.00132
SB3 Clip Fraction: 0.00837
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.03820

Collected Steps per Second: 23,962.72010
Overall Steps per Second: 17,426.48511

Timestep Collection Time: 2.08741
Timestep Consumption Time: 0.78293
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 2.87034

Cumulative Model Updates: 4,769
Cumulative Timesteps: 79,625,466

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 79625466...
Checkpoint 79625466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420.86890
Policy Entropy: 1.13887
Value Function Loss: 7.91736

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.01642
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.04061

Collected Steps per Second: 22,333.45178
Overall Steps per Second: 17,118.10869

Timestep Collection Time: 2.23897
Timestep Consumption Time: 0.68214
PPO Batch Consumption Time: 0.02974
Total Iteration Time: 2.92112

Cumulative Model Updates: 4,772
Cumulative Timesteps: 79,675,470

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.23815
Policy Entropy: 1.14358
Value Function Loss: 7.58056

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01784
Policy Update Magnitude: 0.05286
Value Function Update Magnitude: 0.03717

Collected Steps per Second: 23,753.40464
Overall Steps per Second: 17,640.81182

Timestep Collection Time: 2.10521
Timestep Consumption Time: 0.72946
PPO Batch Consumption Time: 0.02892
Total Iteration Time: 2.83468

Cumulative Model Updates: 4,775
Cumulative Timesteps: 79,725,476

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 79725476...
Checkpoint 79725476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.40990
Policy Entropy: 1.13638
Value Function Loss: 7.54146

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02415
Policy Update Magnitude: 0.05129
Value Function Update Magnitude: 0.03758

Collected Steps per Second: 22,878.05534
Overall Steps per Second: 17,333.18867

Timestep Collection Time: 2.18707
Timestep Consumption Time: 0.69964
PPO Batch Consumption Time: 0.02993
Total Iteration Time: 2.88672

Cumulative Model Updates: 4,778
Cumulative Timesteps: 79,775,512

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.79264
Policy Entropy: 1.14357
Value Function Loss: 7.75526

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02793
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.03837

Collected Steps per Second: 24,890.56703
Overall Steps per Second: 18,287.38190

Timestep Collection Time: 2.00984
Timestep Consumption Time: 0.72571
PPO Batch Consumption Time: 0.02954
Total Iteration Time: 2.73555

Cumulative Model Updates: 4,781
Cumulative Timesteps: 79,825,538

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 79825538...
Checkpoint 79825538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.17241
Policy Entropy: 1.14065
Value Function Loss: 7.78441

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03945
Policy Update Magnitude: 0.04506
Value Function Update Magnitude: 0.04088

Collected Steps per Second: 21,531.25972
Overall Steps per Second: 15,640.85827

Timestep Collection Time: 2.32258
Timestep Consumption Time: 0.87469
PPO Batch Consumption Time: 0.07926
Total Iteration Time: 3.19727

Cumulative Model Updates: 4,784
Cumulative Timesteps: 79,875,546

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427.29669
Policy Entropy: 1.13666
Value Function Loss: 8.38916

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03489
Policy Update Magnitude: 0.03942
Value Function Update Magnitude: 0.04273

Collected Steps per Second: 23,807.86126
Overall Steps per Second: 17,952.65313

Timestep Collection Time: 2.10090
Timestep Consumption Time: 0.68520
PPO Batch Consumption Time: 0.02918
Total Iteration Time: 2.78611

Cumulative Model Updates: 4,787
Cumulative Timesteps: 79,925,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 79925564...
Checkpoint 79925564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.51568
Policy Entropy: 1.14461
Value Function Loss: 8.11757

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02143
Policy Update Magnitude: 0.04326
Value Function Update Magnitude: 0.03900

Collected Steps per Second: 24,721.69806
Overall Steps per Second: 16,826.66880

Timestep Collection Time: 2.02365
Timestep Consumption Time: 0.94949
PPO Batch Consumption Time: 0.10336
Total Iteration Time: 2.97314

Cumulative Model Updates: 4,790
Cumulative Timesteps: 79,975,592

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.00237
Policy Entropy: 1.13397
Value Function Loss: 8.17918

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01237
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.04027

Collected Steps per Second: 23,830.31693
Overall Steps per Second: 17,079.63281

Timestep Collection Time: 2.09834
Timestep Consumption Time: 0.82936
PPO Batch Consumption Time: 0.06473
Total Iteration Time: 2.92770

Cumulative Model Updates: 4,793
Cumulative Timesteps: 80,025,596

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 80025596...
Checkpoint 80025596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.67474
Policy Entropy: 1.11135
Value Function Loss: 7.67844

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.01973
Policy Update Magnitude: 0.04893
Value Function Update Magnitude: 0.04814

Collected Steps per Second: 23,663.86879
Overall Steps per Second: 16,421.63677

Timestep Collection Time: 2.11369
Timestep Consumption Time: 0.93217
PPO Batch Consumption Time: 0.10262
Total Iteration Time: 3.04586

Cumulative Model Updates: 4,796
Cumulative Timesteps: 80,075,614

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.36915
Policy Entropy: 1.10902
Value Function Loss: 7.47262

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02422
Policy Update Magnitude: 0.05039
Value Function Update Magnitude: 0.04404

Collected Steps per Second: 22,839.54061
Overall Steps per Second: 16,933.52109

Timestep Collection Time: 2.19050
Timestep Consumption Time: 0.76400
PPO Batch Consumption Time: 0.07067
Total Iteration Time: 2.95449

Cumulative Model Updates: 4,799
Cumulative Timesteps: 80,125,644

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 80125644...
Checkpoint 80125644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457.91257
Policy Entropy: 1.12871
Value Function Loss: 7.59175

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03499
Policy Update Magnitude: 0.04603
Value Function Update Magnitude: 0.04181

Collected Steps per Second: 20,374.72853
Overall Steps per Second: 14,407.63185

Timestep Collection Time: 2.45559
Timestep Consumption Time: 1.01701
PPO Batch Consumption Time: 0.09366
Total Iteration Time: 3.47260

Cumulative Model Updates: 4,802
Cumulative Timesteps: 80,175,676

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.72612
Policy Entropy: 1.14980
Value Function Loss: 7.90679

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03387
Policy Update Magnitude: 0.04133
Value Function Update Magnitude: 0.04686

Collected Steps per Second: 22,106.50216
Overall Steps per Second: 16,393.61455

Timestep Collection Time: 2.26268
Timestep Consumption Time: 0.78851
PPO Batch Consumption Time: 0.05777
Total Iteration Time: 3.05119

Cumulative Model Updates: 4,805
Cumulative Timesteps: 80,225,696

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 80225696...
Checkpoint 80225696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.93676
Policy Entropy: 1.13718
Value Function Loss: 7.81393

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02655
Policy Update Magnitude: 0.04046
Value Function Update Magnitude: 0.03928

Collected Steps per Second: 20,700.78401
Overall Steps per Second: 15,079.73645

Timestep Collection Time: 2.41566
Timestep Consumption Time: 0.90045
PPO Batch Consumption Time: 0.08421
Total Iteration Time: 3.31611

Cumulative Model Updates: 4,808
Cumulative Timesteps: 80,275,702

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.84194
Policy Entropy: 1.12835
Value Function Loss: 7.94649

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01161
Policy Update Magnitude: 0.04537
Value Function Update Magnitude: 0.03714

Collected Steps per Second: 23,507.48132
Overall Steps per Second: 17,578.61256

Timestep Collection Time: 2.12715
Timestep Consumption Time: 0.71744
PPO Batch Consumption Time: 0.02833
Total Iteration Time: 2.84459

Cumulative Model Updates: 4,811
Cumulative Timesteps: 80,325,706

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 80325706...
Checkpoint 80325706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.22378
Policy Entropy: 1.11394
Value Function Loss: 7.56604

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01279
Policy Update Magnitude: 0.05702
Value Function Update Magnitude: 0.03831

Collected Steps per Second: 20,796.23853
Overall Steps per Second: 15,151.35770

Timestep Collection Time: 2.40476
Timestep Consumption Time: 0.89593
PPO Batch Consumption Time: 0.08045
Total Iteration Time: 3.30069

Cumulative Model Updates: 4,814
Cumulative Timesteps: 80,375,716

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.46214
Policy Entropy: 1.10580
Value Function Loss: 7.85040

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01834
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.04663

Collected Steps per Second: 22,258.68428
Overall Steps per Second: 16,865.32622

Timestep Collection Time: 2.24757
Timestep Consumption Time: 0.71875
PPO Batch Consumption Time: 0.06061
Total Iteration Time: 2.96632

Cumulative Model Updates: 4,817
Cumulative Timesteps: 80,425,744

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 80425744...
Checkpoint 80425744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.70681
Policy Entropy: 1.10829
Value Function Loss: 7.50461

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.01693
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.04144

Collected Steps per Second: 21,836.65156
Overall Steps per Second: 15,684.24511

Timestep Collection Time: 2.29009
Timestep Consumption Time: 0.89833
PPO Batch Consumption Time: 0.08725
Total Iteration Time: 3.18842

Cumulative Model Updates: 4,820
Cumulative Timesteps: 80,475,752

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.92784
Policy Entropy: 1.10167
Value Function Loss: 7.38255

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.01520
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.03446

Collected Steps per Second: 24,670.98164
Overall Steps per Second: 17,907.57511

Timestep Collection Time: 2.02716
Timestep Consumption Time: 0.76563
PPO Batch Consumption Time: 0.05785
Total Iteration Time: 2.79278

Cumulative Model Updates: 4,823
Cumulative Timesteps: 80,525,764

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 80525764...
Checkpoint 80525764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425.29733
Policy Entropy: 1.08556
Value Function Loss: 7.10120

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02140
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.03440

Collected Steps per Second: 20,975.80358
Overall Steps per Second: 15,711.49122

Timestep Collection Time: 2.38389
Timestep Consumption Time: 0.79875
PPO Batch Consumption Time: 0.08273
Total Iteration Time: 3.18264

Cumulative Model Updates: 4,826
Cumulative Timesteps: 80,575,768

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.07913
Policy Entropy: 1.09746
Value Function Loss: 7.36325

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02063
Policy Update Magnitude: 0.04843
Value Function Update Magnitude: 0.03951

Collected Steps per Second: 25,128.39346
Overall Steps per Second: 17,612.20360

Timestep Collection Time: 1.99074
Timestep Consumption Time: 0.84957
PPO Batch Consumption Time: 0.06643
Total Iteration Time: 2.84030

Cumulative Model Updates: 4,829
Cumulative Timesteps: 80,625,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 80625792...
Checkpoint 80625792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427.33411
Policy Entropy: 1.08684
Value Function Loss: 7.59800

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02035
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.04851

Collected Steps per Second: 21,660.81082
Overall Steps per Second: 15,055.64866

Timestep Collection Time: 2.30952
Timestep Consumption Time: 1.01322
PPO Batch Consumption Time: 0.12948
Total Iteration Time: 3.32274

Cumulative Model Updates: 4,832
Cumulative Timesteps: 80,675,818

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.09269
Policy Entropy: 1.09130
Value Function Loss: 7.90434

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.04623
Value Function Update Magnitude: 0.04279

Collected Steps per Second: 24,995.58325
Overall Steps per Second: 17,727.69742

Timestep Collection Time: 2.00147
Timestep Consumption Time: 0.82055
PPO Batch Consumption Time: 0.08790
Total Iteration Time: 2.82202

Cumulative Model Updates: 4,835
Cumulative Timesteps: 80,725,846

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 80725846...
Checkpoint 80725846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.00805
Policy Entropy: 1.05201
Value Function Loss: 7.67127

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02461
Policy Update Magnitude: 0.04600
Value Function Update Magnitude: 0.03862

Collected Steps per Second: 24,594.12997
Overall Steps per Second: 17,643.46767

Timestep Collection Time: 2.03325
Timestep Consumption Time: 0.80100
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 2.83425

Cumulative Model Updates: 4,838
Cumulative Timesteps: 80,775,852

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.65823
Policy Entropy: 1.06729
Value Function Loss: 7.75820

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01687
Policy Update Magnitude: 0.04966
Value Function Update Magnitude: 0.04006

Collected Steps per Second: 20,524.22356
Overall Steps per Second: 15,057.69553

Timestep Collection Time: 2.43732
Timestep Consumption Time: 0.88484
PPO Batch Consumption Time: 0.08932
Total Iteration Time: 3.32216

Cumulative Model Updates: 4,841
Cumulative Timesteps: 80,825,876

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 80825876...
Checkpoint 80825876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.93571
Policy Entropy: 1.04942
Value Function Loss: 7.74738

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02693
Policy Update Magnitude: 0.04506
Value Function Update Magnitude: 0.04246

Collected Steps per Second: 24,526.50292
Overall Steps per Second: 16,920.93512

Timestep Collection Time: 2.03943
Timestep Consumption Time: 0.91667
PPO Batch Consumption Time: 0.12075
Total Iteration Time: 2.95610

Cumulative Model Updates: 4,844
Cumulative Timesteps: 80,875,896

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.43203
Policy Entropy: 1.06138
Value Function Loss: 7.72203

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.01667
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.03966

Collected Steps per Second: 25,371.50756
Overall Steps per Second: 17,582.15339

Timestep Collection Time: 1.97158
Timestep Consumption Time: 0.87346
PPO Batch Consumption Time: 0.07750
Total Iteration Time: 2.84504

Cumulative Model Updates: 4,847
Cumulative Timesteps: 80,925,918

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 80925918...
Checkpoint 80925918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.55228
Policy Entropy: 1.06289
Value Function Loss: 7.50946

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.01783
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.04132

Collected Steps per Second: 22,856.61747
Overall Steps per Second: 15,954.04744

Timestep Collection Time: 2.18834
Timestep Consumption Time: 0.94679
PPO Batch Consumption Time: 0.11253
Total Iteration Time: 3.13513

Cumulative Model Updates: 4,850
Cumulative Timesteps: 80,975,936

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.09258
Policy Entropy: 1.04330
Value Function Loss: 7.40070

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01565
Policy Update Magnitude: 0.05280
Value Function Update Magnitude: 0.03641

Collected Steps per Second: 24,673.45538
Overall Steps per Second: 17,761.17117

Timestep Collection Time: 2.02687
Timestep Consumption Time: 0.78882
PPO Batch Consumption Time: 0.08328
Total Iteration Time: 2.81569

Cumulative Model Updates: 4,853
Cumulative Timesteps: 81,025,946

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 81025946...
Checkpoint 81025946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.63295
Policy Entropy: 1.03310
Value Function Loss: 7.30995

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02022
Policy Update Magnitude: 0.05189
Value Function Update Magnitude: 0.03940

Collected Steps per Second: 24,279.49820
Overall Steps per Second: 17,437.08523

Timestep Collection Time: 2.06009
Timestep Consumption Time: 0.80839
PPO Batch Consumption Time: 0.06033
Total Iteration Time: 2.86848

Cumulative Model Updates: 4,856
Cumulative Timesteps: 81,075,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.31213
Policy Entropy: 1.03903
Value Function Loss: 7.21189

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01355
Policy Update Magnitude: 0.05089
Value Function Update Magnitude: 0.05082

Collected Steps per Second: 21,717.13668
Overall Steps per Second: 15,226.19658

Timestep Collection Time: 2.30362
Timestep Consumption Time: 0.98203
PPO Batch Consumption Time: 0.11215
Total Iteration Time: 3.28565

Cumulative Model Updates: 4,859
Cumulative Timesteps: 81,125,992

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 81125992...
Checkpoint 81125992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430.57773
Policy Entropy: 1.03383
Value Function Loss: 6.93497

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01190
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.04990

Collected Steps per Second: 24,359.08578
Overall Steps per Second: 16,797.60415

Timestep Collection Time: 2.05279
Timestep Consumption Time: 0.92407
PPO Batch Consumption Time: 0.12276
Total Iteration Time: 2.97685

Cumulative Model Updates: 4,862
Cumulative Timesteps: 81,175,996

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.57318
Policy Entropy: 1.04595
Value Function Loss: 6.90940

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02379
Policy Update Magnitude: 0.04953
Value Function Update Magnitude: 0.05118

Collected Steps per Second: 25,373.56985
Overall Steps per Second: 17,587.64926

Timestep Collection Time: 1.97158
Timestep Consumption Time: 0.87280
PPO Batch Consumption Time: 0.07993
Total Iteration Time: 2.84438

Cumulative Model Updates: 4,865
Cumulative Timesteps: 81,226,022

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 81226022...
Checkpoint 81226022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.08922
Policy Entropy: 1.03063
Value Function Loss: 7.18332

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02005
Policy Update Magnitude: 0.04733
Value Function Update Magnitude: 0.05895

Collected Steps per Second: 22,891.67277
Overall Steps per Second: 15,940.00204

Timestep Collection Time: 2.18438
Timestep Consumption Time: 0.95264
PPO Batch Consumption Time: 0.11621
Total Iteration Time: 3.13701

Cumulative Model Updates: 4,868
Cumulative Timesteps: 81,276,026

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.91485
Policy Entropy: 1.04047
Value Function Loss: 7.30653

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02612
Policy Update Magnitude: 0.04277
Value Function Update Magnitude: 0.06110

Collected Steps per Second: 24,909.48963
Overall Steps per Second: 17,771.30438

Timestep Collection Time: 2.00847
Timestep Consumption Time: 0.80674
PPO Batch Consumption Time: 0.08357
Total Iteration Time: 2.81521

Cumulative Model Updates: 4,871
Cumulative Timesteps: 81,326,056

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 81326056...
Checkpoint 81326056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.36532
Policy Entropy: 1.04600
Value Function Loss: 7.30473

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01475
Policy Update Magnitude: 0.04154
Value Function Update Magnitude: 0.05684

Collected Steps per Second: 24,368.18435
Overall Steps per Second: 17,474.30939

Timestep Collection Time: 2.05276
Timestep Consumption Time: 0.80984
PPO Batch Consumption Time: 0.06015
Total Iteration Time: 2.86260

Cumulative Model Updates: 4,874
Cumulative Timesteps: 81,376,078

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.40377
Policy Entropy: 1.04848
Value Function Loss: 6.87194

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.01585
Policy Update Magnitude: 0.04278
Value Function Update Magnitude: 0.05061

Collected Steps per Second: 22,662.18450
Overall Steps per Second: 16,094.91112

Timestep Collection Time: 2.20676
Timestep Consumption Time: 0.90043
PPO Batch Consumption Time: 0.09327
Total Iteration Time: 3.10719

Cumulative Model Updates: 4,877
Cumulative Timesteps: 81,426,088

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 81426088...
Checkpoint 81426088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.99884
Policy Entropy: 1.03447
Value Function Loss: 6.59192

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01526
Policy Update Magnitude: 0.04396
Value Function Update Magnitude: 0.05232

Collected Steps per Second: 24,553.01642
Overall Steps per Second: 18,184.68656

Timestep Collection Time: 2.03747
Timestep Consumption Time: 0.71353
PPO Batch Consumption Time: 0.05918
Total Iteration Time: 2.75100

Cumulative Model Updates: 4,880
Cumulative Timesteps: 81,476,114

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.94137
Policy Entropy: 1.02856
Value Function Loss: 6.80532

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02357
Policy Update Magnitude: 0.04146
Value Function Update Magnitude: 0.05004

Collected Steps per Second: 22,098.79521
Overall Steps per Second: 15,543.42292

Timestep Collection Time: 2.26311
Timestep Consumption Time: 0.95446
PPO Batch Consumption Time: 0.10836
Total Iteration Time: 3.21757

Cumulative Model Updates: 4,883
Cumulative Timesteps: 81,526,126

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 81526126...
Checkpoint 81526126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.85325
Policy Entropy: 1.02513
Value Function Loss: 7.12971

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01217
Policy Update Magnitude: 0.04047
Value Function Update Magnitude: 0.04589

Collected Steps per Second: 24,663.19813
Overall Steps per Second: 17,736.64453

Timestep Collection Time: 2.02731
Timestep Consumption Time: 0.79171
PPO Batch Consumption Time: 0.05898
Total Iteration Time: 2.81902

Cumulative Model Updates: 4,886
Cumulative Timesteps: 81,576,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.53808
Policy Entropy: 1.01419
Value Function Loss: 7.37849

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.01742
Policy Update Magnitude: 0.04030
Value Function Update Magnitude: 0.04093

Collected Steps per Second: 22,095.84382
Overall Steps per Second: 15,817.53349

Timestep Collection Time: 2.26287
Timestep Consumption Time: 0.89818
PPO Batch Consumption Time: 0.10850
Total Iteration Time: 3.16105

Cumulative Model Updates: 4,889
Cumulative Timesteps: 81,626,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 81626126...
Checkpoint 81626126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.51905
Policy Entropy: 1.01332
Value Function Loss: 7.06395

Mean KL Divergence: 0.00115
SB3 Clip Fraction: 0.00683
Policy Update Magnitude: 0.04364
Value Function Update Magnitude: 0.03993

Collected Steps per Second: 24,395.54726
Overall Steps per Second: 17,627.00761

Timestep Collection Time: 2.05070
Timestep Consumption Time: 0.78744
PPO Batch Consumption Time: 0.06055
Total Iteration Time: 2.83814

Cumulative Model Updates: 4,892
Cumulative Timesteps: 81,676,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.97599
Policy Entropy: 1.00473
Value Function Loss: 7.03236

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.00765
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.03688

Collected Steps per Second: 22,056.45981
Overall Steps per Second: 15,784.47802

Timestep Collection Time: 2.26836
Timestep Consumption Time: 0.90134
PPO Batch Consumption Time: 0.08498
Total Iteration Time: 3.16970

Cumulative Model Updates: 4,895
Cumulative Timesteps: 81,726,186

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 81726186...
Checkpoint 81726186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.09628
Policy Entropy: 0.99382
Value Function Loss: 7.32931

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01371
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.04098

Collected Steps per Second: 24,830.46295
Overall Steps per Second: 18,168.53534

Timestep Collection Time: 2.01406
Timestep Consumption Time: 0.73850
PPO Batch Consumption Time: 0.06300
Total Iteration Time: 2.75256

Cumulative Model Updates: 4,898
Cumulative Timesteps: 81,776,196

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.28808
Policy Entropy: 0.99078
Value Function Loss: 7.48762

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01614
Policy Update Magnitude: 0.04767
Value Function Update Magnitude: 0.03926

Collected Steps per Second: 22,265.61886
Overall Steps per Second: 15,647.51217

Timestep Collection Time: 2.24651
Timestep Consumption Time: 0.95016
PPO Batch Consumption Time: 0.10134
Total Iteration Time: 3.19667

Cumulative Model Updates: 4,901
Cumulative Timesteps: 81,826,216

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 81826216...
Checkpoint 81826216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406.86666
Policy Entropy: 0.99543
Value Function Loss: 7.46046

Mean KL Divergence: 0.00132
SB3 Clip Fraction: 0.00979
Policy Update Magnitude: 0.04731
Value Function Update Magnitude: 0.04555

Collected Steps per Second: 24,489.67438
Overall Steps per Second: 17,798.61152

Timestep Collection Time: 2.04192
Timestep Consumption Time: 0.76762
PPO Batch Consumption Time: 0.05793
Total Iteration Time: 2.80954

Cumulative Model Updates: 4,904
Cumulative Timesteps: 81,876,222

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.89992
Policy Entropy: 0.98220
Value Function Loss: 7.00049

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.01809
Policy Update Magnitude: 0.04560
Value Function Update Magnitude: 0.04097

Collected Steps per Second: 21,988.06941
Overall Steps per Second: 15,845.90631

Timestep Collection Time: 2.27514
Timestep Consumption Time: 0.88189
PPO Batch Consumption Time: 0.10993
Total Iteration Time: 3.15703

Cumulative Model Updates: 4,907
Cumulative Timesteps: 81,926,248

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 81926248...
Checkpoint 81926248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442.22410
Policy Entropy: 0.97822
Value Function Loss: 6.96425

Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.01207
Policy Update Magnitude: 0.04627
Value Function Update Magnitude: 0.03518

Collected Steps per Second: 24,442.22868
Overall Steps per Second: 17,533.71735

Timestep Collection Time: 2.04605
Timestep Consumption Time: 0.80617
PPO Batch Consumption Time: 0.06163
Total Iteration Time: 2.85222

Cumulative Model Updates: 4,910
Cumulative Timesteps: 81,976,258

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.67590
Policy Entropy: 0.97275
Value Function Loss: 7.02134

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01645
Policy Update Magnitude: 0.04586
Value Function Update Magnitude: 0.02911

Collected Steps per Second: 22,418.64936
Overall Steps per Second: 15,959.34451

Timestep Collection Time: 2.23100
Timestep Consumption Time: 0.90296
PPO Batch Consumption Time: 0.09455
Total Iteration Time: 3.13396

Cumulative Model Updates: 4,913
Cumulative Timesteps: 82,026,274

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 82026274...
Checkpoint 82026274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397.95725
Policy Entropy: 0.97642
Value Function Loss: 7.27660

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01991
Policy Update Magnitude: 0.04454
Value Function Update Magnitude: 0.02824

Collected Steps per Second: 24,747.36712
Overall Steps per Second: 18,215.19163

Timestep Collection Time: 2.02114
Timestep Consumption Time: 0.72481
PPO Batch Consumption Time: 0.06046
Total Iteration Time: 2.74595

Cumulative Model Updates: 4,916
Cumulative Timesteps: 82,076,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.16651
Policy Entropy: 0.97984
Value Function Loss: 7.42170

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01553
Policy Update Magnitude: 0.04558
Value Function Update Magnitude: 0.02470

Collected Steps per Second: 25,004.95150
Overall Steps per Second: 17,878.51765

Timestep Collection Time: 2.00040
Timestep Consumption Time: 0.79737
PPO Batch Consumption Time: 0.06108
Total Iteration Time: 2.79777

Cumulative Model Updates: 4,919
Cumulative Timesteps: 82,126,312

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 82126312...
Checkpoint 82126312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412.42978
Policy Entropy: 0.99428
Value Function Loss: 6.94463

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01764
Policy Update Magnitude: 0.04458
Value Function Update Magnitude: 0.02276

Collected Steps per Second: 24,588.52180
Overall Steps per Second: 16,705.48993

Timestep Collection Time: 2.03404
Timestep Consumption Time: 0.95983
PPO Batch Consumption Time: 0.11910
Total Iteration Time: 2.99387

Cumulative Model Updates: 4,922
Cumulative Timesteps: 82,176,326

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.85244
Policy Entropy: 0.96457
Value Function Loss: 6.79794

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02365
Policy Update Magnitude: 0.04713
Value Function Update Magnitude: 0.03631

Collected Steps per Second: 25,294.97910
Overall Steps per Second: 17,768.18846

Timestep Collection Time: 1.97683
Timestep Consumption Time: 0.83741
PPO Batch Consumption Time: 0.09115
Total Iteration Time: 2.81424

Cumulative Model Updates: 4,925
Cumulative Timesteps: 82,226,330

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 82226330...
Checkpoint 82226330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.07013
Policy Entropy: 0.96621
Value Function Loss: 6.76163

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02345
Policy Update Magnitude: 0.04241
Value Function Update Magnitude: 0.05117

Collected Steps per Second: 24,893.92016
Overall Steps per Second: 17,833.49776

Timestep Collection Time: 2.00941
Timestep Consumption Time: 0.79554
PPO Batch Consumption Time: 0.05756
Total Iteration Time: 2.80495

Cumulative Model Updates: 4,928
Cumulative Timesteps: 82,276,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504.38022
Policy Entropy: 0.94055
Value Function Loss: 7.08360

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02264
Policy Update Magnitude: 0.04139
Value Function Update Magnitude: 0.04764

Collected Steps per Second: 21,685.15851
Overall Steps per Second: 15,713.20392

Timestep Collection Time: 2.30591
Timestep Consumption Time: 0.87638
PPO Batch Consumption Time: 0.08205
Total Iteration Time: 3.18229

Cumulative Model Updates: 4,931
Cumulative Timesteps: 82,326,356

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 82326356...
Checkpoint 82326356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535.81118
Policy Entropy: 0.95033
Value Function Loss: 7.10013

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02301
Policy Update Magnitude: 0.04045
Value Function Update Magnitude: 0.04755

Collected Steps per Second: 24,235.14544
Overall Steps per Second: 17,568.64407

Timestep Collection Time: 2.06427
Timestep Consumption Time: 0.78330
PPO Batch Consumption Time: 0.06000
Total Iteration Time: 2.84757

Cumulative Model Updates: 4,934
Cumulative Timesteps: 82,376,384

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.15561
Policy Entropy: 0.95466
Value Function Loss: 6.98154

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02344
Policy Update Magnitude: 0.04084
Value Function Update Magnitude: 0.03947

Collected Steps per Second: 22,968.25353
Overall Steps per Second: 16,039.41542

Timestep Collection Time: 2.17805
Timestep Consumption Time: 0.94089
PPO Batch Consumption Time: 0.10073
Total Iteration Time: 3.11894

Cumulative Model Updates: 4,937
Cumulative Timesteps: 82,426,410

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 82426410...
Checkpoint 82426410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.40646
Policy Entropy: 0.97071
Value Function Loss: 6.98841

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02335
Policy Update Magnitude: 0.04165
Value Function Update Magnitude: 0.03480

Collected Steps per Second: 24,224.00184
Overall Steps per Second: 17,388.07042

Timestep Collection Time: 2.06481
Timestep Consumption Time: 0.81176
PPO Batch Consumption Time: 0.06300
Total Iteration Time: 2.87657

Cumulative Model Updates: 4,940
Cumulative Timesteps: 82,476,428

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.58941
Policy Entropy: 0.94601
Value Function Loss: 7.06754

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03705
Policy Update Magnitude: 0.04107
Value Function Update Magnitude: 0.03468

Collected Steps per Second: 22,051.38184
Overall Steps per Second: 16,093.81173

Timestep Collection Time: 2.26743
Timestep Consumption Time: 0.83935
PPO Batch Consumption Time: 0.09120
Total Iteration Time: 3.10678

Cumulative Model Updates: 4,943
Cumulative Timesteps: 82,526,428

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 82526428...
Checkpoint 82526428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453.88222
Policy Entropy: 0.95765
Value Function Loss: 7.03672

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02581
Policy Update Magnitude: 0.03862
Value Function Update Magnitude: 0.03395

Collected Steps per Second: 24,563.71913
Overall Steps per Second: 17,635.85262

Timestep Collection Time: 2.03560
Timestep Consumption Time: 0.79964
PPO Batch Consumption Time: 0.06157
Total Iteration Time: 2.83525

Cumulative Model Updates: 4,946
Cumulative Timesteps: 82,576,430

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.73873
Policy Entropy: 0.95088
Value Function Loss: 6.84888

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02653
Policy Update Magnitude: 0.03720
Value Function Update Magnitude: 0.04055

Collected Steps per Second: 21,885.93969
Overall Steps per Second: 15,067.99606

Timestep Collection Time: 2.28549
Timestep Consumption Time: 1.03413
PPO Batch Consumption Time: 0.12371
Total Iteration Time: 3.31962

Cumulative Model Updates: 4,949
Cumulative Timesteps: 82,626,450

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 82626450...
Checkpoint 82626450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 418.33515
Policy Entropy: 0.94506
Value Function Loss: 6.76065

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01857
Policy Update Magnitude: 0.03756
Value Function Update Magnitude: 0.03974

Collected Steps per Second: 24,465.98462
Overall Steps per Second: 17,815.12779

Timestep Collection Time: 2.04365
Timestep Consumption Time: 0.76295
PPO Batch Consumption Time: 0.07263
Total Iteration Time: 2.80660

Cumulative Model Updates: 4,952
Cumulative Timesteps: 82,676,450

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.52303
Policy Entropy: 0.94121
Value Function Loss: 6.70583

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02945
Policy Update Magnitude: 0.03886
Value Function Update Magnitude: 0.04281

Collected Steps per Second: 25,023.21819
Overall Steps per Second: 17,976.67683

Timestep Collection Time: 1.99886
Timestep Consumption Time: 0.78352
PPO Batch Consumption Time: 0.05650
Total Iteration Time: 2.78238

Cumulative Model Updates: 4,955
Cumulative Timesteps: 82,726,468

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 82726468...
Checkpoint 82726468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.21399
Policy Entropy: 0.94715
Value Function Loss: 6.93436

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02860
Policy Update Magnitude: 0.04096
Value Function Update Magnitude: 0.04632

Collected Steps per Second: 21,262.23711
Overall Steps per Second: 14,753.52715

Timestep Collection Time: 2.35206
Timestep Consumption Time: 1.03764
PPO Batch Consumption Time: 0.12956
Total Iteration Time: 3.38970

Cumulative Model Updates: 4,958
Cumulative Timesteps: 82,776,478

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.19481
Policy Entropy: 0.96015
Value Function Loss: 6.83059

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02195
Policy Update Magnitude: 0.04002
Value Function Update Magnitude: 0.05037

Collected Steps per Second: 24,403.96242
Overall Steps per Second: 17,693.06699

Timestep Collection Time: 2.04975
Timestep Consumption Time: 0.77746
PPO Batch Consumption Time: 0.07763
Total Iteration Time: 2.82721

Cumulative Model Updates: 4,961
Cumulative Timesteps: 82,826,500

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 82826500...
Checkpoint 82826500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 398.48992
Policy Entropy: 0.95636
Value Function Loss: 6.89078

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01997
Policy Update Magnitude: 0.04409
Value Function Update Magnitude: 0.04838

Collected Steps per Second: 21,476.09183
Overall Steps per Second: 15,060.47906

Timestep Collection Time: 2.32873
Timestep Consumption Time: 0.99202
PPO Batch Consumption Time: 0.12193
Total Iteration Time: 3.32074

Cumulative Model Updates: 4,964
Cumulative Timesteps: 82,876,512

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.82511
Policy Entropy: 0.96504
Value Function Loss: 6.97943

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.01620
Policy Update Magnitude: 0.04587
Value Function Update Magnitude: 0.04103

Collected Steps per Second: 24,970.25003
Overall Steps per Second: 17,810.08652

Timestep Collection Time: 2.00294
Timestep Consumption Time: 0.80524
PPO Batch Consumption Time: 0.05989
Total Iteration Time: 2.80818

Cumulative Model Updates: 4,967
Cumulative Timesteps: 82,926,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 82926526...
Checkpoint 82926526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.30867
Policy Entropy: 0.96464
Value Function Loss: 7.28346

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02693
Policy Update Magnitude: 0.04368
Value Function Update Magnitude: 0.04085

Collected Steps per Second: 21,295.76653
Overall Steps per Second: 15,651.68403

Timestep Collection Time: 2.34854
Timestep Consumption Time: 0.84690
PPO Batch Consumption Time: 0.08013
Total Iteration Time: 3.19544

Cumulative Model Updates: 4,970
Cumulative Timesteps: 82,976,540

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.49221
Policy Entropy: 0.95485
Value Function Loss: 7.27640

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02797
Policy Update Magnitude: 0.04383
Value Function Update Magnitude: 0.03657

Collected Steps per Second: 25,964.91647
Overall Steps per Second: 18,310.86399

Timestep Collection Time: 1.92606
Timestep Consumption Time: 0.80511
PPO Batch Consumption Time: 0.06088
Total Iteration Time: 2.73117

Cumulative Model Updates: 4,973
Cumulative Timesteps: 83,026,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 83026550...
Checkpoint 83026550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.02499
Policy Entropy: 0.94351
Value Function Loss: 7.15247

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.04057
Policy Update Magnitude: 0.04021
Value Function Update Magnitude: 0.03333

Collected Steps per Second: 24,678.48002
Overall Steps per Second: 16,589.70643

Timestep Collection Time: 2.02719
Timestep Consumption Time: 0.98841
PPO Batch Consumption Time: 0.11222
Total Iteration Time: 3.01560

Cumulative Model Updates: 4,976
Cumulative Timesteps: 83,076,578

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.31780
Policy Entropy: 0.93091
Value Function Loss: 6.99707

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03182
Policy Update Magnitude: 0.03856
Value Function Update Magnitude: 0.03201

Collected Steps per Second: 24,412.28002
Overall Steps per Second: 16,713.63353

Timestep Collection Time: 2.04930
Timestep Consumption Time: 0.94395
PPO Batch Consumption Time: 0.11502
Total Iteration Time: 2.99325

Cumulative Model Updates: 4,979
Cumulative Timesteps: 83,126,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 83126606...
Checkpoint 83126606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443.33765
Policy Entropy: 0.93820
Value Function Loss: 7.14440

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.03702
Value Function Update Magnitude: 0.03407

Collected Steps per Second: 24,567.75731
Overall Steps per Second: 17,664.01723

Timestep Collection Time: 2.03625
Timestep Consumption Time: 0.79584
PPO Batch Consumption Time: 0.07956
Total Iteration Time: 2.83209

Cumulative Model Updates: 4,982
Cumulative Timesteps: 83,176,632

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.22713
Policy Entropy: 0.90880
Value Function Loss: 6.92463

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02322
Policy Update Magnitude: 0.03973
Value Function Update Magnitude: 0.03376

Collected Steps per Second: 22,304.88080
Overall Steps per Second: 15,818.50848

Timestep Collection Time: 2.24175
Timestep Consumption Time: 0.91923
PPO Batch Consumption Time: 0.09802
Total Iteration Time: 3.16098

Cumulative Model Updates: 4,985
Cumulative Timesteps: 83,226,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 83226634...
Checkpoint 83226634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.62072
Policy Entropy: 0.91653
Value Function Loss: 6.75094

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02045
Policy Update Magnitude: 0.04337
Value Function Update Magnitude: 0.03867

Collected Steps per Second: 24,489.65439
Overall Steps per Second: 16,860.44398

Timestep Collection Time: 2.04184
Timestep Consumption Time: 0.92392
PPO Batch Consumption Time: 0.10490
Total Iteration Time: 2.96576

Cumulative Model Updates: 4,988
Cumulative Timesteps: 83,276,638

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.34111
Policy Entropy: 0.90751
Value Function Loss: 6.59685

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02592
Policy Update Magnitude: 0.04282
Value Function Update Magnitude: 0.03530

Collected Steps per Second: 24,939.31195
Overall Steps per Second: 17,768.19948

Timestep Collection Time: 2.00575
Timestep Consumption Time: 0.80951
PPO Batch Consumption Time: 0.08364
Total Iteration Time: 2.81525

Cumulative Model Updates: 4,991
Cumulative Timesteps: 83,326,660

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 83326660...
Checkpoint 83326660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466.83049
Policy Entropy: 0.90238
Value Function Loss: 6.90861

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02632
Policy Update Magnitude: 0.04593
Value Function Update Magnitude: 0.03989

Collected Steps per Second: 24,635.28026
Overall Steps per Second: 17,719.98637

Timestep Collection Time: 2.02985
Timestep Consumption Time: 0.79216
PPO Batch Consumption Time: 0.06030
Total Iteration Time: 2.82201

Cumulative Model Updates: 4,994
Cumulative Timesteps: 83,376,666

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.76977
Policy Entropy: 0.90375
Value Function Loss: 6.95550

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02477
Policy Update Magnitude: 0.04340
Value Function Update Magnitude: 0.03798

Collected Steps per Second: 21,857.55963
Overall Steps per Second: 15,832.96973

Timestep Collection Time: 2.28873
Timestep Consumption Time: 0.87088
PPO Batch Consumption Time: 0.07499
Total Iteration Time: 3.15961

Cumulative Model Updates: 4,997
Cumulative Timesteps: 83,426,692

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 83426692...
Checkpoint 83426692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.83905
Policy Entropy: 0.89118
Value Function Loss: 6.97985

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.01949
Policy Update Magnitude: 0.04217
Value Function Update Magnitude: 0.04964

Collected Steps per Second: 24,455.26575
Overall Steps per Second: 18,129.01175

Timestep Collection Time: 2.04520
Timestep Consumption Time: 0.71369
PPO Batch Consumption Time: 0.05808
Total Iteration Time: 2.75889

Cumulative Model Updates: 5,000
Cumulative Timesteps: 83,476,708

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.85731
Policy Entropy: 0.87503
Value Function Loss: 6.82909

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01527
Policy Update Magnitude: 0.04515
Value Function Update Magnitude: 0.04831

Collected Steps per Second: 21,937.83348
Overall Steps per Second: 15,600.16964

Timestep Collection Time: 2.28035
Timestep Consumption Time: 0.92641
PPO Batch Consumption Time: 0.09661
Total Iteration Time: 3.20676

Cumulative Model Updates: 5,003
Cumulative Timesteps: 83,526,734

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 83526734...
Checkpoint 83526734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.06925
Policy Entropy: 0.88521
Value Function Loss: 7.03357

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02101
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.03702

Collected Steps per Second: 24,229.99725
Overall Steps per Second: 17,495.95860

Timestep Collection Time: 2.06471
Timestep Consumption Time: 0.79469
PPO Batch Consumption Time: 0.06166
Total Iteration Time: 2.85940

Cumulative Model Updates: 5,006
Cumulative Timesteps: 83,576,762

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.62389
Policy Entropy: 0.86366
Value Function Loss: 6.95781

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.01813
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.03692

Collected Steps per Second: 21,986.40145
Overall Steps per Second: 16,050.10523

Timestep Collection Time: 2.27532
Timestep Consumption Time: 0.84155
PPO Batch Consumption Time: 0.09332
Total Iteration Time: 3.11686

Cumulative Model Updates: 5,009
Cumulative Timesteps: 83,626,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 83626788...
Checkpoint 83626788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420.76840
Policy Entropy: 0.87441
Value Function Loss: 6.99673

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01863
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.05978

Collected Steps per Second: 24,606.20938
Overall Steps per Second: 17,672.93098

Timestep Collection Time: 2.03250
Timestep Consumption Time: 0.79737
PPO Batch Consumption Time: 0.06080
Total Iteration Time: 2.82986

Cumulative Model Updates: 5,012
Cumulative Timesteps: 83,676,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.51047
Policy Entropy: 0.87098
Value Function Loss: 7.09363

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.01854
Policy Update Magnitude: 0.04784
Value Function Update Magnitude: 0.06434

Collected Steps per Second: 21,640.38459
Overall Steps per Second: 15,046.31746

Timestep Collection Time: 2.31151
Timestep Consumption Time: 1.01302
PPO Batch Consumption Time: 0.12450
Total Iteration Time: 3.32453

Cumulative Model Updates: 5,015
Cumulative Timesteps: 83,726,822

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 83726822...
Checkpoint 83726822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.87141
Policy Entropy: 0.88741
Value Function Loss: 7.30942

Mean KL Divergence: 0.00123
SB3 Clip Fraction: 0.00875
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.05888

Collected Steps per Second: 24,237.98714
Overall Steps per Second: 16,729.66163

Timestep Collection Time: 2.06304
Timestep Consumption Time: 0.92590
PPO Batch Consumption Time: 0.10666
Total Iteration Time: 2.98894

Cumulative Model Updates: 5,018
Cumulative Timesteps: 83,776,826

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.60178
Policy Entropy: 0.90109
Value Function Loss: 7.24193

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.01856
Policy Update Magnitude: 0.04772
Value Function Update Magnitude: 0.04882

Collected Steps per Second: 24,791.29434
Overall Steps per Second: 17,661.68924

Timestep Collection Time: 2.01748
Timestep Consumption Time: 0.81441
PPO Batch Consumption Time: 0.08432
Total Iteration Time: 2.83189

Cumulative Model Updates: 5,021
Cumulative Timesteps: 83,826,842

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 83826842...
Checkpoint 83826842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.45594
Policy Entropy: 0.88427
Value Function Loss: 6.90200

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01365
Policy Update Magnitude: 0.04799
Value Function Update Magnitude: 0.04321

Collected Steps per Second: 24,434.17384
Overall Steps per Second: 17,539.81525

Timestep Collection Time: 2.04705
Timestep Consumption Time: 0.80463
PPO Batch Consumption Time: 0.05931
Total Iteration Time: 2.85168

Cumulative Model Updates: 5,024
Cumulative Timesteps: 83,876,860

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563.09884
Policy Entropy: 0.88800
Value Function Loss: 6.63053

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02409
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.03957

Collected Steps per Second: 21,449.51236
Overall Steps per Second: 15,216.77271

Timestep Collection Time: 2.33255
Timestep Consumption Time: 0.95540
PPO Batch Consumption Time: 0.11210
Total Iteration Time: 3.28795

Cumulative Model Updates: 5,027
Cumulative Timesteps: 83,926,892

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 83926892...
Checkpoint 83926892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.98822
Policy Entropy: 0.87356
Value Function Loss: 6.48988

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02486
Policy Update Magnitude: 0.04255
Value Function Update Magnitude: 0.04634

Collected Steps per Second: 24,422.65252
Overall Steps per Second: 17,669.59843

Timestep Collection Time: 2.04793
Timestep Consumption Time: 0.78269
PPO Batch Consumption Time: 0.07740
Total Iteration Time: 2.83062

Cumulative Model Updates: 5,030
Cumulative Timesteps: 83,976,908

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.44504
Policy Entropy: 0.88037
Value Function Loss: 6.79878

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.01969
Policy Update Magnitude: 0.04107
Value Function Update Magnitude: 0.04083

Collected Steps per Second: 23,417.78574
Overall Steps per Second: 15,918.17381

Timestep Collection Time: 2.13547
Timestep Consumption Time: 1.00610
PPO Batch Consumption Time: 0.12191
Total Iteration Time: 3.14157

Cumulative Model Updates: 5,033
Cumulative Timesteps: 84,026,916

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 84026916...
Checkpoint 84026916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.63728
Policy Entropy: 0.88432
Value Function Loss: 7.00528

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01975
Policy Update Magnitude: 0.04211
Value Function Update Magnitude: 0.03802

Collected Steps per Second: 24,612.57604
Overall Steps per Second: 16,766.28941

Timestep Collection Time: 2.03246
Timestep Consumption Time: 0.95115
PPO Batch Consumption Time: 0.11377
Total Iteration Time: 2.98361

Cumulative Model Updates: 5,036
Cumulative Timesteps: 84,076,940

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.68147
Policy Entropy: 0.88299
Value Function Loss: 7.05510

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01065
Policy Update Magnitude: 0.04584
Value Function Update Magnitude: 0.03221

Collected Steps per Second: 24,701.80016
Overall Steps per Second: 17,760.33454

Timestep Collection Time: 2.02503
Timestep Consumption Time: 0.79147
PPO Batch Consumption Time: 0.07961
Total Iteration Time: 2.81650

Cumulative Model Updates: 5,039
Cumulative Timesteps: 84,126,962

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 84126962...
Checkpoint 84126962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441.27326
Policy Entropy: 0.87905
Value Function Loss: 6.94358

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01451
Policy Update Magnitude: 0.04715
Value Function Update Magnitude: 0.02899

Collected Steps per Second: 24,691.95914
Overall Steps per Second: 17,693.44084

Timestep Collection Time: 2.02503
Timestep Consumption Time: 0.80099
PPO Batch Consumption Time: 0.06023
Total Iteration Time: 2.82602

Cumulative Model Updates: 5,042
Cumulative Timesteps: 84,176,964

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.90341
Policy Entropy: 0.88111
Value Function Loss: 7.17717

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01319
Policy Update Magnitude: 0.04416
Value Function Update Magnitude: 0.02818

Collected Steps per Second: 21,765.13297
Overall Steps per Second: 15,862.47786

Timestep Collection Time: 2.29927
Timestep Consumption Time: 0.85559
PPO Batch Consumption Time: 0.07342
Total Iteration Time: 3.15487

Cumulative Model Updates: 5,045
Cumulative Timesteps: 84,227,008

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 84227008...
Checkpoint 84227008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.11813
Policy Entropy: 0.86242
Value Function Loss: 7.26149

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.01831
Policy Update Magnitude: 0.04601
Value Function Update Magnitude: 0.02660

Collected Steps per Second: 23,921.77395
Overall Steps per Second: 17,762.85505

Timestep Collection Time: 2.09023
Timestep Consumption Time: 0.72475
PPO Batch Consumption Time: 0.06028
Total Iteration Time: 2.81498

Cumulative Model Updates: 5,048
Cumulative Timesteps: 84,277,010

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.44383
Policy Entropy: 0.88120
Value Function Loss: 7.32015

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04507
Policy Update Magnitude: 0.03953
Value Function Update Magnitude: 0.03116

Collected Steps per Second: 22,027.08089
Overall Steps per Second: 15,825.62190

Timestep Collection Time: 2.26993
Timestep Consumption Time: 0.88950
PPO Batch Consumption Time: 0.08859
Total Iteration Time: 3.15943

Cumulative Model Updates: 5,051
Cumulative Timesteps: 84,327,010

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 84327010...
Checkpoint 84327010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.23524
Policy Entropy: 0.85574
Value Function Loss: 7.05988

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03946
Policy Update Magnitude: 0.03483
Value Function Update Magnitude: 0.03015

Collected Steps per Second: 24,217.74603
Overall Steps per Second: 17,413.95552

Timestep Collection Time: 2.06468
Timestep Consumption Time: 0.80669
PPO Batch Consumption Time: 0.06155
Total Iteration Time: 2.87138

Cumulative Model Updates: 5,054
Cumulative Timesteps: 84,377,012

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.34140
Policy Entropy: 0.88379
Value Function Loss: 6.72622

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03773
Policy Update Magnitude: 0.03322
Value Function Update Magnitude: 0.02757

Collected Steps per Second: 22,138.73572
Overall Steps per Second: 16,104.23500

Timestep Collection Time: 2.25921
Timestep Consumption Time: 0.84656
PPO Batch Consumption Time: 0.07623
Total Iteration Time: 3.10577

Cumulative Model Updates: 5,057
Cumulative Timesteps: 84,427,028

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 84427028...
Checkpoint 84427028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364.23125
Policy Entropy: 0.86002
Value Function Loss: 6.44553

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02049
Policy Update Magnitude: 0.03247
Value Function Update Magnitude: 0.04117

Collected Steps per Second: 25,296.21934
Overall Steps per Second: 18,134.43989

Timestep Collection Time: 1.97777
Timestep Consumption Time: 0.78107
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 2.75884

Cumulative Model Updates: 5,060
Cumulative Timesteps: 84,477,058

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.46482
Policy Entropy: 0.85812
Value Function Loss: 6.32606

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01443
Policy Update Magnitude: 0.03982
Value Function Update Magnitude: 0.04182

Collected Steps per Second: 21,895.63591
Overall Steps per Second: 15,579.87973

Timestep Collection Time: 2.28447
Timestep Consumption Time: 0.92608
PPO Batch Consumption Time: 0.09606
Total Iteration Time: 3.21055

Cumulative Model Updates: 5,063
Cumulative Timesteps: 84,527,078

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 84527078...
Checkpoint 84527078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.97989
Policy Entropy: 0.86567
Value Function Loss: 6.51405

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.01776
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.03709

Collected Steps per Second: 21,616.53092
Overall Steps per Second: 16,080.21516

Timestep Collection Time: 2.31434
Timestep Consumption Time: 0.79681
PPO Batch Consumption Time: 0.06729
Total Iteration Time: 3.11115

Cumulative Model Updates: 5,066
Cumulative Timesteps: 84,577,106

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.10315
Policy Entropy: 0.84904
Value Function Loss: 6.72701

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01582
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.04152

Collected Steps per Second: 24,875.58973
Overall Steps per Second: 17,479.80320

Timestep Collection Time: 2.01089
Timestep Consumption Time: 0.85082
PPO Batch Consumption Time: 0.10052
Total Iteration Time: 2.86170

Cumulative Model Updates: 5,069
Cumulative Timesteps: 84,627,128

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 84627128...
Checkpoint 84627128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397.33776
Policy Entropy: 0.86398
Value Function Loss: 6.94465

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02697
Policy Update Magnitude: 0.04982
Value Function Update Magnitude: 0.03793

Collected Steps per Second: 23,826.56479
Overall Steps per Second: 17,167.10378

Timestep Collection Time: 2.09858
Timestep Consumption Time: 0.81408
PPO Batch Consumption Time: 0.06368
Total Iteration Time: 2.91266

Cumulative Model Updates: 5,072
Cumulative Timesteps: 84,677,130

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.75856
Policy Entropy: 0.84878
Value Function Loss: 6.86881

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02785
Policy Update Magnitude: 0.04490
Value Function Update Magnitude: 0.03854

Collected Steps per Second: 24,598.82278
Overall Steps per Second: 17,394.06127

Timestep Collection Time: 2.03270
Timestep Consumption Time: 0.84196
PPO Batch Consumption Time: 0.07499
Total Iteration Time: 2.87466

Cumulative Model Updates: 5,075
Cumulative Timesteps: 84,727,132

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 84727132...
Checkpoint 84727132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.14770
Policy Entropy: 0.87147
Value Function Loss: 6.72907

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.04076
Policy Update Magnitude: 0.03904
Value Function Update Magnitude: 0.03437

Collected Steps per Second: 24,763.43841
Overall Steps per Second: 18,261.97833

Timestep Collection Time: 2.01959
Timestep Consumption Time: 0.71900
PPO Batch Consumption Time: 0.05930
Total Iteration Time: 2.73859

Cumulative Model Updates: 5,078
Cumulative Timesteps: 84,777,144

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.76347
Policy Entropy: 0.84919
Value Function Loss: 6.50205

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02599
Policy Update Magnitude: 0.03668
Value Function Update Magnitude: 0.03671

Collected Steps per Second: 22,824.33377
Overall Steps per Second: 16,459.65065

Timestep Collection Time: 2.19117
Timestep Consumption Time: 0.84729
PPO Batch Consumption Time: 0.07172
Total Iteration Time: 3.03846

Cumulative Model Updates: 5,081
Cumulative Timesteps: 84,827,156

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 84827156...
Checkpoint 84827156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408.10513
Policy Entropy: 0.86654
Value Function Loss: 6.63873

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01544
Policy Update Magnitude: 0.03695
Value Function Update Magnitude: 0.03347

Collected Steps per Second: 24,199.50496
Overall Steps per Second: 16,790.49136

Timestep Collection Time: 2.06657
Timestep Consumption Time: 0.91190
PPO Batch Consumption Time: 0.09528
Total Iteration Time: 2.97847

Cumulative Model Updates: 5,084
Cumulative Timesteps: 84,877,166

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.07901
Policy Entropy: 0.85547
Value Function Loss: 6.57851

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01723
Policy Update Magnitude: 0.04197
Value Function Update Magnitude: 0.03428

Collected Steps per Second: 24,579.62095
Overall Steps per Second: 17,692.98242

Timestep Collection Time: 2.03445
Timestep Consumption Time: 0.79187
PPO Batch Consumption Time: 0.08157
Total Iteration Time: 2.82632

Cumulative Model Updates: 5,087
Cumulative Timesteps: 84,927,172

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 84927172...
Checkpoint 84927172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536.96898
Policy Entropy: 0.86134
Value Function Loss: 6.73334

Mean KL Divergence: 0.00168
SB3 Clip Fraction: 0.01400
Policy Update Magnitude: 0.03946
Value Function Update Magnitude: 0.03376

Collected Steps per Second: 23,807.25097
Overall Steps per Second: 17,320.28481

Timestep Collection Time: 2.10037
Timestep Consumption Time: 0.78665
PPO Batch Consumption Time: 0.05837
Total Iteration Time: 2.88702

Cumulative Model Updates: 5,090
Cumulative Timesteps: 84,977,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.26666
Policy Entropy: 0.86228
Value Function Loss: 6.75575

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01893
Policy Update Magnitude: 0.03959
Value Function Update Magnitude: 0.03235

Collected Steps per Second: 24,679.73728
Overall Steps per Second: 16,529.37518

Timestep Collection Time: 2.02660
Timestep Consumption Time: 0.99928
PPO Batch Consumption Time: 0.12562
Total Iteration Time: 3.02589

Cumulative Model Updates: 5,093
Cumulative Timesteps: 85,027,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 85027192...
Checkpoint 85027192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467.53389
Policy Entropy: 0.85713
Value Function Loss: 6.93063

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.01377
Policy Update Magnitude: 0.03714
Value Function Update Magnitude: 0.03014

Collected Steps per Second: 24,798.32710
Overall Steps per Second: 17,960.07959

Timestep Collection Time: 2.01747
Timestep Consumption Time: 0.76815
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 2.78562

Cumulative Model Updates: 5,096
Cumulative Timesteps: 85,077,222

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.33268
Policy Entropy: 0.86122
Value Function Loss: 6.87744

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01713
Policy Update Magnitude: 0.03699
Value Function Update Magnitude: 0.03583

Collected Steps per Second: 21,671.70722
Overall Steps per Second: 15,634.01072

Timestep Collection Time: 2.30762
Timestep Consumption Time: 0.89118
PPO Batch Consumption Time: 0.11282
Total Iteration Time: 3.19880

Cumulative Model Updates: 5,099
Cumulative Timesteps: 85,127,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 85127232...
Checkpoint 85127232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.20506
Policy Entropy: 0.84223
Value Function Loss: 6.83558

Mean KL Divergence: 0.00104
SB3 Clip Fraction: 0.00651
Policy Update Magnitude: 0.04472
Value Function Update Magnitude: 0.03527

Collected Steps per Second: 24,523.36359
Overall Steps per Second: 17,526.67096

Timestep Collection Time: 2.03928
Timestep Consumption Time: 0.81409
PPO Batch Consumption Time: 0.06230
Total Iteration Time: 2.85337

Cumulative Model Updates: 5,102
Cumulative Timesteps: 85,177,242

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.10564
Policy Entropy: 0.85743
Value Function Loss: 6.77455

Mean KL Divergence: 0.00093
SB3 Clip Fraction: 0.00574
Policy Update Magnitude: 0.04728
Value Function Update Magnitude: 0.03641

Collected Steps per Second: 21,385.74662
Overall Steps per Second: 15,047.27313

Timestep Collection Time: 2.33932
Timestep Consumption Time: 0.98541
PPO Batch Consumption Time: 0.11800
Total Iteration Time: 3.32472

Cumulative Model Updates: 5,105
Cumulative Timesteps: 85,227,270

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 85227270...
Checkpoint 85227270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506.84354
Policy Entropy: 0.85982
Value Function Loss: 6.93770

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01488
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.04751

Collected Steps per Second: 24,444.34757
Overall Steps per Second: 16,763.26255

Timestep Collection Time: 2.04612
Timestep Consumption Time: 0.93755
PPO Batch Consumption Time: 0.11326
Total Iteration Time: 2.98367

Cumulative Model Updates: 5,108
Cumulative Timesteps: 85,277,286

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.73012
Policy Entropy: 0.86907
Value Function Loss: 6.96795

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01558
Policy Update Magnitude: 0.05005
Value Function Update Magnitude: 0.04209

Collected Steps per Second: 25,755.65618
Overall Steps per Second: 17,763.29614

Timestep Collection Time: 1.94140
Timestep Consumption Time: 0.87351
PPO Batch Consumption Time: 0.08164
Total Iteration Time: 2.81491

Cumulative Model Updates: 5,111
Cumulative Timesteps: 85,327,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 85327288...
Checkpoint 85327288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.91873
Policy Entropy: 0.85825
Value Function Loss: 6.98952

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01492
Policy Update Magnitude: 0.04638
Value Function Update Magnitude: 0.04414

Collected Steps per Second: 24,355.94835
Overall Steps per Second: 17,563.59867

Timestep Collection Time: 2.05289
Timestep Consumption Time: 0.79391
PPO Batch Consumption Time: 0.06102
Total Iteration Time: 2.84680

Cumulative Model Updates: 5,114
Cumulative Timesteps: 85,377,288

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418.90773
Policy Entropy: 0.84177
Value Function Loss: 6.92802

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.01091
Policy Update Magnitude: 0.04703
Value Function Update Magnitude: 0.03986

Collected Steps per Second: 21,728.39712
Overall Steps per Second: 15,965.80955

Timestep Collection Time: 2.30206
Timestep Consumption Time: 0.83089
PPO Batch Consumption Time: 0.07888
Total Iteration Time: 3.13294

Cumulative Model Updates: 5,117
Cumulative Timesteps: 85,427,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 85427308...
Checkpoint 85427308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.56793
Policy Entropy: 0.84299
Value Function Loss: 7.06940

Mean KL Divergence: 0.00104
SB3 Clip Fraction: 0.00804
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.03936

Collected Steps per Second: 24,636.63549
Overall Steps per Second: 18,242.22915

Timestep Collection Time: 2.02950
Timestep Consumption Time: 0.71140
PPO Batch Consumption Time: 0.05892
Total Iteration Time: 2.74089

Cumulative Model Updates: 5,120
Cumulative Timesteps: 85,477,308

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.77087
Policy Entropy: 0.85046
Value Function Loss: 6.88964

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02119
Policy Update Magnitude: 0.04391
Value Function Update Magnitude: 0.03497

Collected Steps per Second: 22,931.66895
Overall Steps per Second: 16,459.12208

Timestep Collection Time: 2.18039
Timestep Consumption Time: 0.85744
PPO Batch Consumption Time: 0.07431
Total Iteration Time: 3.03783

Cumulative Model Updates: 5,123
Cumulative Timesteps: 85,527,308

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 85527308...
Checkpoint 85527308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.78341
Policy Entropy: 0.85918
Value Function Loss: 7.08964

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01724
Policy Update Magnitude: 0.04312
Value Function Update Magnitude: 0.03970

Collected Steps per Second: 24,336.70652
Overall Steps per Second: 17,565.12381

Timestep Collection Time: 2.05541
Timestep Consumption Time: 0.79239
PPO Batch Consumption Time: 0.06018
Total Iteration Time: 2.84780

Cumulative Model Updates: 5,126
Cumulative Timesteps: 85,577,330

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.24235
Policy Entropy: 0.87603
Value Function Loss: 7.04658

Mean KL Divergence: 0.00133
SB3 Clip Fraction: 0.01093
Policy Update Magnitude: 0.04498
Value Function Update Magnitude: 0.03358

Collected Steps per Second: 21,582.39579
Overall Steps per Second: 16,001.11677

Timestep Collection Time: 2.31772
Timestep Consumption Time: 0.80843
PPO Batch Consumption Time: 0.08747
Total Iteration Time: 3.12616

Cumulative Model Updates: 5,129
Cumulative Timesteps: 85,627,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 85627352...
Checkpoint 85627352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.25674
Policy Entropy: 0.89292
Value Function Loss: 7.39385

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.06315
Policy Update Magnitude: 0.04835
Value Function Update Magnitude: 0.03375

Collected Steps per Second: 24,439.87315
Overall Steps per Second: 17,607.56568

Timestep Collection Time: 2.04649
Timestep Consumption Time: 0.79411
PPO Batch Consumption Time: 0.05976
Total Iteration Time: 2.84060

Cumulative Model Updates: 5,132
Cumulative Timesteps: 85,677,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.47800
Policy Entropy: 0.89306
Value Function Loss: 6.97620

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03177
Policy Update Magnitude: 0.03701
Value Function Update Magnitude: 0.03077

Collected Steps per Second: 22,084.59830
Overall Steps per Second: 15,921.84871

Timestep Collection Time: 2.26438
Timestep Consumption Time: 0.87646
PPO Batch Consumption Time: 0.08249
Total Iteration Time: 3.14084

Cumulative Model Updates: 5,135
Cumulative Timesteps: 85,727,376

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 85727376...
Checkpoint 85727376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402.60103
Policy Entropy: 0.89409
Value Function Loss: 6.89857

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02125
Policy Update Magnitude: 0.03793
Value Function Update Magnitude: 0.02920

Collected Steps per Second: 24,004.82458
Overall Steps per Second: 17,512.69707

Timestep Collection Time: 2.08383
Timestep Consumption Time: 0.77250
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 2.85633

Cumulative Model Updates: 5,138
Cumulative Timesteps: 85,777,398

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.35114
Policy Entropy: 0.88039
Value Function Loss: 6.68589

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.01981
Policy Update Magnitude: 0.03657
Value Function Update Magnitude: 0.02732

Collected Steps per Second: 21,947.12949
Overall Steps per Second: 16,068.21483

Timestep Collection Time: 2.27866
Timestep Consumption Time: 0.83370
PPO Batch Consumption Time: 0.09268
Total Iteration Time: 3.11236

Cumulative Model Updates: 5,141
Cumulative Timesteps: 85,827,408

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 85827408...
Checkpoint 85827408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.17148
Policy Entropy: 0.88367
Value Function Loss: 7.00206

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01335
Policy Update Magnitude: 0.04311
Value Function Update Magnitude: 0.04383

Collected Steps per Second: 24,418.48847
Overall Steps per Second: 17,559.27546

Timestep Collection Time: 2.04779
Timestep Consumption Time: 0.79993
PPO Batch Consumption Time: 0.06108
Total Iteration Time: 2.84773

Cumulative Model Updates: 5,144
Cumulative Timesteps: 85,877,412

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.92996
Policy Entropy: 0.88060
Value Function Loss: 6.93977

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01412
Policy Update Magnitude: 0.04460
Value Function Update Magnitude: 0.04713

Collected Steps per Second: 21,868.51322
Overall Steps per Second: 15,933.37628

Timestep Collection Time: 2.28658
Timestep Consumption Time: 0.85174
PPO Batch Consumption Time: 0.07843
Total Iteration Time: 3.13832

Cumulative Model Updates: 5,147
Cumulative Timesteps: 85,927,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 85927416...
Checkpoint 85927416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.60419
Policy Entropy: 0.86534
Value Function Loss: 6.96541

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01990
Policy Update Magnitude: 0.04572
Value Function Update Magnitude: 0.04624

Collected Steps per Second: 24,283.14123
Overall Steps per Second: 17,623.80450

Timestep Collection Time: 2.05987
Timestep Consumption Time: 0.77834
PPO Batch Consumption Time: 0.05954
Total Iteration Time: 2.83821

Cumulative Model Updates: 5,150
Cumulative Timesteps: 85,977,436

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.07405
Policy Entropy: 0.87081
Value Function Loss: 6.76676

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02689
Policy Update Magnitude: 0.04941
Value Function Update Magnitude: 0.04347

Collected Steps per Second: 21,837.27168
Overall Steps per Second: 15,949.25574

Timestep Collection Time: 2.29049
Timestep Consumption Time: 0.84558
PPO Batch Consumption Time: 0.09520
Total Iteration Time: 3.13607

Cumulative Model Updates: 5,153
Cumulative Timesteps: 86,027,454

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 86027454...
Checkpoint 86027454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.77052
Policy Entropy: 0.84836
Value Function Loss: 6.75267

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.01848
Policy Update Magnitude: 0.04580
Value Function Update Magnitude: 0.04126

Collected Steps per Second: 24,564.68624
Overall Steps per Second: 17,653.54469

Timestep Collection Time: 2.03617
Timestep Consumption Time: 0.79714
PPO Batch Consumption Time: 0.06025
Total Iteration Time: 2.83331

Cumulative Model Updates: 5,156
Cumulative Timesteps: 86,077,472

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.21571
Policy Entropy: 0.84644
Value Function Loss: 6.78618

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01941
Policy Update Magnitude: 0.04776
Value Function Update Magnitude: 0.03812

Collected Steps per Second: 22,316.23237
Overall Steps per Second: 15,905.64141

Timestep Collection Time: 2.24151
Timestep Consumption Time: 0.90341
PPO Batch Consumption Time: 0.08741
Total Iteration Time: 3.14492

Cumulative Model Updates: 5,159
Cumulative Timesteps: 86,127,494

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 86127494...
Checkpoint 86127494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.57796
Policy Entropy: 0.83026
Value Function Loss: 6.99925

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02634
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.03687

Collected Steps per Second: 24,698.60876
Overall Steps per Second: 17,811.80409

Timestep Collection Time: 2.02449
Timestep Consumption Time: 0.78275
PPO Batch Consumption Time: 0.05815
Total Iteration Time: 2.80724

Cumulative Model Updates: 5,162
Cumulative Timesteps: 86,177,496

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.81417
Policy Entropy: 0.81900
Value Function Loss: 7.10782

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04705
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.03660

Collected Steps per Second: 22,894.24837
Overall Steps per Second: 15,874.13105

Timestep Collection Time: 2.18404
Timestep Consumption Time: 0.96586
PPO Batch Consumption Time: 0.11267
Total Iteration Time: 3.14990

Cumulative Model Updates: 5,165
Cumulative Timesteps: 86,227,498

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 86227498...
Checkpoint 86227498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432.18650
Policy Entropy: 0.82775
Value Function Loss: 6.83689

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.05283
Policy Update Magnitude: 0.04222
Value Function Update Magnitude: 0.03508

Collected Steps per Second: 24,552.74234
Overall Steps per Second: 17,534.10822

Timestep Collection Time: 2.03643
Timestep Consumption Time: 0.81515
PPO Batch Consumption Time: 0.06127
Total Iteration Time: 2.85158

Cumulative Model Updates: 5,168
Cumulative Timesteps: 86,277,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.81112
Policy Entropy: 0.80931
Value Function Loss: 6.64830

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.05181
Policy Update Magnitude: 0.03578
Value Function Update Magnitude: 0.03420

Collected Steps per Second: 21,396.97052
Overall Steps per Second: 15,076.52766

Timestep Collection Time: 2.33809
Timestep Consumption Time: 0.98018
PPO Batch Consumption Time: 0.12667
Total Iteration Time: 3.31827

Cumulative Model Updates: 5,171
Cumulative Timesteps: 86,327,526

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 86327526...
Checkpoint 86327526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522.41796
Policy Entropy: 0.81293
Value Function Loss: 6.43158

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04676
Policy Update Magnitude: 0.03609
Value Function Update Magnitude: 0.03120

Collected Steps per Second: 24,432.89074
Overall Steps per Second: 18,084.31472

Timestep Collection Time: 2.04773
Timestep Consumption Time: 0.71886
PPO Batch Consumption Time: 0.06103
Total Iteration Time: 2.76660

Cumulative Model Updates: 5,174
Cumulative Timesteps: 86,377,558

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.31312
Policy Entropy: 0.80153
Value Function Loss: 6.72957

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.04493
Policy Update Magnitude: 0.03846
Value Function Update Magnitude: 0.03603

Collected Steps per Second: 25,014.31690
Overall Steps per Second: 17,885.24994

Timestep Collection Time: 1.99973
Timestep Consumption Time: 0.79709
PPO Batch Consumption Time: 0.06170
Total Iteration Time: 2.79683

Cumulative Model Updates: 5,177
Cumulative Timesteps: 86,427,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 86427580...
Checkpoint 86427580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.23820
Policy Entropy: 0.80805
Value Function Loss: 6.62801

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.04453
Policy Update Magnitude: 0.03705
Value Function Update Magnitude: 0.03502

Collected Steps per Second: 24,200.47393
Overall Steps per Second: 16,639.35904

Timestep Collection Time: 2.06715
Timestep Consumption Time: 0.93934
PPO Batch Consumption Time: 0.10403
Total Iteration Time: 3.00649

Cumulative Model Updates: 5,180
Cumulative Timesteps: 86,477,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.57748
Policy Entropy: 0.78849
Value Function Loss: 6.72757

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03977
Policy Update Magnitude: 0.03456
Value Function Update Magnitude: 0.03537

Collected Steps per Second: 24,895.56187
Overall Steps per Second: 17,812.38479

Timestep Collection Time: 2.00839
Timestep Consumption Time: 0.79865
PPO Batch Consumption Time: 0.08515
Total Iteration Time: 2.80704

Cumulative Model Updates: 5,183
Cumulative Timesteps: 86,527,606

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 86527606...
Checkpoint 86527606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486.63401
Policy Entropy: 0.79365
Value Function Loss: 6.35017

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03971
Policy Update Magnitude: 0.03395
Value Function Update Magnitude: 0.03155

Collected Steps per Second: 24,867.17706
Overall Steps per Second: 17,915.05360

Timestep Collection Time: 2.01100
Timestep Consumption Time: 0.78039
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 2.79140

Cumulative Model Updates: 5,186
Cumulative Timesteps: 86,577,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468.88419
Policy Entropy: 0.79400
Value Function Loss: 6.25617

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03272
Policy Update Magnitude: 0.03367
Value Function Update Magnitude: 0.02970

Collected Steps per Second: 21,488.37851
Overall Steps per Second: 15,649.29116

Timestep Collection Time: 2.32730
Timestep Consumption Time: 0.86837
PPO Batch Consumption Time: 0.07553
Total Iteration Time: 3.19567

Cumulative Model Updates: 5,189
Cumulative Timesteps: 86,627,624

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 86627624...
Checkpoint 86627624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.37216
Policy Entropy: 0.80462
Value Function Loss: 6.40168

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01901
Policy Update Magnitude: 0.03462
Value Function Update Magnitude: 0.03119

Collected Steps per Second: 24,459.62224
Overall Steps per Second: 18,167.49586

Timestep Collection Time: 2.04517
Timestep Consumption Time: 0.70832
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 2.75349

Cumulative Model Updates: 5,192
Cumulative Timesteps: 86,677,648

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.26153
Policy Entropy: 0.81039
Value Function Loss: 6.54079

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01908
Policy Update Magnitude: 0.04080
Value Function Update Magnitude: 0.03239

Collected Steps per Second: 21,900.08906
Overall Steps per Second: 15,600.54910

Timestep Collection Time: 2.28410
Timestep Consumption Time: 0.92233
PPO Batch Consumption Time: 0.09755
Total Iteration Time: 3.20643

Cumulative Model Updates: 5,195
Cumulative Timesteps: 86,727,670

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 86727670...
Checkpoint 86727670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.59734
Policy Entropy: 0.82397
Value Function Loss: 6.59906

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02269
Policy Update Magnitude: 0.04069
Value Function Update Magnitude: 0.03371

Collected Steps per Second: 24,039.30618
Overall Steps per Second: 17,435.48831

Timestep Collection Time: 2.08043
Timestep Consumption Time: 0.78798
PPO Batch Consumption Time: 0.05849
Total Iteration Time: 2.86840

Cumulative Model Updates: 5,198
Cumulative Timesteps: 86,777,682

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.81022
Policy Entropy: 0.82601
Value Function Loss: 6.34388

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01700
Policy Update Magnitude: 0.04263
Value Function Update Magnitude: 0.03294

Collected Steps per Second: 21,356.53489
Overall Steps per Second: 15,200.56514

Timestep Collection Time: 2.34223
Timestep Consumption Time: 0.94856
PPO Batch Consumption Time: 0.11242
Total Iteration Time: 3.29080

Cumulative Model Updates: 5,201
Cumulative Timesteps: 86,827,704

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 86827704...
Checkpoint 86827704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.96046
Policy Entropy: 0.82429
Value Function Loss: 6.34084

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.01300
Policy Update Magnitude: 0.04445
Value Function Update Magnitude: 0.03101

Collected Steps per Second: 24,462.48214
Overall Steps per Second: 17,666.80686

Timestep Collection Time: 2.04493
Timestep Consumption Time: 0.78660
PPO Batch Consumption Time: 0.07948
Total Iteration Time: 2.83152

Cumulative Model Updates: 5,204
Cumulative Timesteps: 86,877,728

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.18428
Policy Entropy: 0.80694
Value Function Loss: 6.27020

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01809
Policy Update Magnitude: 0.04422
Value Function Update Magnitude: 0.03068

Collected Steps per Second: 23,065.96155
Overall Steps per Second: 15,910.97640

Timestep Collection Time: 2.16856
Timestep Consumption Time: 0.97518
PPO Batch Consumption Time: 0.11492
Total Iteration Time: 3.14374

Cumulative Model Updates: 5,207
Cumulative Timesteps: 86,927,748

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 86927748...
Checkpoint 86927748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425.78891
Policy Entropy: 0.80584
Value Function Loss: 6.29764

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02089
Policy Update Magnitude: 0.04297
Value Function Update Magnitude: 0.03235

Collected Steps per Second: 24,087.59145
Overall Steps per Second: 16,737.25745

Timestep Collection Time: 2.07642
Timestep Consumption Time: 0.91188
PPO Batch Consumption Time: 0.10370
Total Iteration Time: 2.98830

Cumulative Model Updates: 5,210
Cumulative Timesteps: 86,977,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.11722
Policy Entropy: 0.80105
Value Function Loss: 6.43701

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02387
Policy Update Magnitude: 0.04138
Value Function Update Magnitude: 0.03082

Collected Steps per Second: 24,769.19445
Overall Steps per Second: 16,738.88606

Timestep Collection Time: 2.01952
Timestep Consumption Time: 0.96885
PPO Batch Consumption Time: 0.12052
Total Iteration Time: 2.98837

Cumulative Model Updates: 5,213
Cumulative Timesteps: 87,027,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 87027786...
Checkpoint 87027786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505.61242
Policy Entropy: 0.80211
Value Function Loss: 6.52410

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.01861
Policy Update Magnitude: 0.03896
Value Function Update Magnitude: 0.03907

Collected Steps per Second: 25,506.44239
Overall Steps per Second: 17,791.10411

Timestep Collection Time: 1.96123
Timestep Consumption Time: 0.85051
PPO Batch Consumption Time: 0.07582
Total Iteration Time: 2.81174

Cumulative Model Updates: 5,216
Cumulative Timesteps: 87,077,810

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.88705
Policy Entropy: 0.79111
Value Function Loss: 6.60212

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.01724
Policy Update Magnitude: 0.04251
Value Function Update Magnitude: 0.03692

Collected Steps per Second: 24,906.26422
Overall Steps per Second: 17,731.54530

Timestep Collection Time: 2.00865
Timestep Consumption Time: 0.81276
PPO Batch Consumption Time: 0.06037
Total Iteration Time: 2.82141

Cumulative Model Updates: 5,219
Cumulative Timesteps: 87,127,838

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 87127838...
Checkpoint 87127838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.37063
Policy Entropy: 0.78021
Value Function Loss: 6.52263

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03512
Policy Update Magnitude: 0.04243
Value Function Update Magnitude: 0.03776

Collected Steps per Second: 21,265.25775
Overall Steps per Second: 15,031.58620

Timestep Collection Time: 2.35191
Timestep Consumption Time: 0.97535
PPO Batch Consumption Time: 0.12553
Total Iteration Time: 3.32726

Cumulative Model Updates: 5,222
Cumulative Timesteps: 87,177,852

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.59938
Policy Entropy: 0.80020
Value Function Loss: 6.35503

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04515
Policy Update Magnitude: 0.03412
Value Function Update Magnitude: 0.03674

Collected Steps per Second: 24,851.47929
Overall Steps per Second: 17,745.24904

Timestep Collection Time: 2.01219
Timestep Consumption Time: 0.80580
PPO Batch Consumption Time: 0.07922
Total Iteration Time: 2.81799

Cumulative Model Updates: 5,225
Cumulative Timesteps: 87,227,858

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 87227858...
Checkpoint 87227858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.12101
Policy Entropy: 0.77843
Value Function Loss: 6.38791

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03110
Policy Update Magnitude: 0.03125
Value Function Update Magnitude: 0.03335

Collected Steps per Second: 24,541.43915
Overall Steps per Second: 17,645.08346

Timestep Collection Time: 2.03786
Timestep Consumption Time: 0.79647
PPO Batch Consumption Time: 0.06019
Total Iteration Time: 2.83433

Cumulative Model Updates: 5,228
Cumulative Timesteps: 87,277,870

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.75499
Policy Entropy: 0.77927
Value Function Loss: 6.36472

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.04730
Policy Update Magnitude: 0.03314
Value Function Update Magnitude: 0.02869

Collected Steps per Second: 21,573.58703
Overall Steps per Second: 15,069.38944

Timestep Collection Time: 2.31783
Timestep Consumption Time: 1.00042
PPO Batch Consumption Time: 0.12307
Total Iteration Time: 3.31825

Cumulative Model Updates: 5,231
Cumulative Timesteps: 87,327,874

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 87327874...
Checkpoint 87327874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.04954
Policy Entropy: 0.76819
Value Function Loss: 6.38234

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.04001
Policy Update Magnitude: 0.03580
Value Function Update Magnitude: 0.03658

Collected Steps per Second: 24,317.75958
Overall Steps per Second: 16,790.43729

Timestep Collection Time: 2.05710
Timestep Consumption Time: 0.92222
PPO Batch Consumption Time: 0.12150
Total Iteration Time: 2.97931

Cumulative Model Updates: 5,234
Cumulative Timesteps: 87,377,898

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.63724
Policy Entropy: 0.76131
Value Function Loss: 6.22588

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04539
Policy Update Magnitude: 0.03291
Value Function Update Magnitude: 0.03422

Collected Steps per Second: 25,267.85135
Overall Steps per Second: 17,538.35678

Timestep Collection Time: 1.97919
Timestep Consumption Time: 0.87227
PPO Batch Consumption Time: 0.07760
Total Iteration Time: 2.85146

Cumulative Model Updates: 5,237
Cumulative Timesteps: 87,427,908

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 87427908...
Checkpoint 87427908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499.88575
Policy Entropy: 0.76065
Value Function Loss: 6.17071

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03820
Policy Update Magnitude: 0.03098
Value Function Update Magnitude: 0.03483

Collected Steps per Second: 23,147.36172
Overall Steps per Second: 15,977.66437

Timestep Collection Time: 2.16051
Timestep Consumption Time: 0.96949
PPO Batch Consumption Time: 0.11188
Total Iteration Time: 3.12999

Cumulative Model Updates: 5,240
Cumulative Timesteps: 87,477,918

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.43116
Policy Entropy: 0.75019
Value Function Loss: 6.27774

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03269
Policy Update Magnitude: 0.02679
Value Function Update Magnitude: 0.03150

Collected Steps per Second: 24,824.23364
Overall Steps per Second: 16,750.49953

Timestep Collection Time: 2.01505
Timestep Consumption Time: 0.97125
PPO Batch Consumption Time: 0.12357
Total Iteration Time: 2.98630

Cumulative Model Updates: 5,243
Cumulative Timesteps: 87,527,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 87527940...
Checkpoint 87527940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490.68707
Policy Entropy: 0.74698
Value Function Loss: 6.25504

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01859
Policy Update Magnitude: 0.03630
Value Function Update Magnitude: 0.03994

Collected Steps per Second: 24,574.19770
Overall Steps per Second: 17,781.45816

Timestep Collection Time: 2.03596
Timestep Consumption Time: 0.77776
PPO Batch Consumption Time: 0.07353
Total Iteration Time: 2.81372

Cumulative Model Updates: 5,246
Cumulative Timesteps: 87,577,972

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470.60972
Policy Entropy: 0.74960
Value Function Loss: 6.30991

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02396
Policy Update Magnitude: 0.03784
Value Function Update Magnitude: 0.03781

Collected Steps per Second: 24,880.27035
Overall Steps per Second: 17,844.05108

Timestep Collection Time: 2.01051
Timestep Consumption Time: 0.79278
PPO Batch Consumption Time: 0.05890
Total Iteration Time: 2.80329

Cumulative Model Updates: 5,249
Cumulative Timesteps: 87,627,994

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 87627994...
Checkpoint 87627994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.60349
Policy Entropy: 0.75362
Value Function Loss: 6.18864

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02345
Policy Update Magnitude: 0.03498
Value Function Update Magnitude: 0.03306

Collected Steps per Second: 21,401.71344
Overall Steps per Second: 15,749.85496

Timestep Collection Time: 2.33822
Timestep Consumption Time: 0.83908
PPO Batch Consumption Time: 0.07479
Total Iteration Time: 3.17730

Cumulative Model Updates: 5,252
Cumulative Timesteps: 87,678,036

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.24098
Policy Entropy: 0.75053
Value Function Loss: 6.32334

Mean KL Divergence: 0.00155
SB3 Clip Fraction: 0.01508
Policy Update Magnitude: 0.03736
Value Function Update Magnitude: 0.03414

Collected Steps per Second: 24,490.79570
Overall Steps per Second: 18,076.27347

Timestep Collection Time: 2.04207
Timestep Consumption Time: 0.72465
PPO Batch Consumption Time: 0.05748
Total Iteration Time: 2.76672

Cumulative Model Updates: 5,255
Cumulative Timesteps: 87,728,048

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 87728048...
Checkpoint 87728048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.69657
Policy Entropy: 0.77256
Value Function Loss: 6.32379

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02291
Policy Update Magnitude: 0.03852
Value Function Update Magnitude: 0.03983

Collected Steps per Second: 21,457.55798
Overall Steps per Second: 15,615.78868

Timestep Collection Time: 2.33167
Timestep Consumption Time: 0.87226
PPO Batch Consumption Time: 0.08098
Total Iteration Time: 3.20394

Cumulative Model Updates: 5,258
Cumulative Timesteps: 87,778,080

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.00346
Policy Entropy: 0.76258
Value Function Loss: 6.42602

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02515
Policy Update Magnitude: 0.03732
Value Function Update Magnitude: 0.04426

Collected Steps per Second: 24,203.57514
Overall Steps per Second: 17,460.86008

Timestep Collection Time: 2.06705
Timestep Consumption Time: 0.79822
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 2.86527

Cumulative Model Updates: 5,261
Cumulative Timesteps: 87,828,110

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 87828110...
Checkpoint 87828110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.99094
Policy Entropy: 0.76444
Value Function Loss: 6.35923

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03236
Policy Update Magnitude: 0.03630
Value Function Update Magnitude: 0.04687

Collected Steps per Second: 21,524.77454
Overall Steps per Second: 15,221.32461

Timestep Collection Time: 2.32346
Timestep Consumption Time: 0.96219
PPO Batch Consumption Time: 0.11475
Total Iteration Time: 3.28565

Cumulative Model Updates: 5,264
Cumulative Timesteps: 87,878,122

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.75716
Policy Entropy: 0.75901
Value Function Loss: 6.24701

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.04193
Policy Update Magnitude: 0.03281
Value Function Update Magnitude: 0.04902

Collected Steps per Second: 24,420.06735
Overall Steps per Second: 17,736.53409

Timestep Collection Time: 2.04782
Timestep Consumption Time: 0.77167
PPO Batch Consumption Time: 0.07369
Total Iteration Time: 2.81949

Cumulative Model Updates: 5,267
Cumulative Timesteps: 87,928,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 87928130...
Checkpoint 87928130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.55995
Policy Entropy: 0.76746
Value Function Loss: 6.24994

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.04478
Policy Update Magnitude: 0.02780
Value Function Update Magnitude: 0.04478

Collected Steps per Second: 23,666.96167
Overall Steps per Second: 16,924.44480

Timestep Collection Time: 2.11375
Timestep Consumption Time: 0.84209
PPO Batch Consumption Time: 0.06074
Total Iteration Time: 2.95584

Cumulative Model Updates: 5,270
Cumulative Timesteps: 87,978,156

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.44859
Policy Entropy: 0.77022
Value Function Loss: 6.25202

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.04245
Policy Update Magnitude: 0.02824
Value Function Update Magnitude: 0.03796

Collected Steps per Second: 20,173.05607
Overall Steps per Second: 14,498.24061

Timestep Collection Time: 2.47935
Timestep Consumption Time: 0.97045
PPO Batch Consumption Time: 0.09563
Total Iteration Time: 3.44980

Cumulative Model Updates: 5,273
Cumulative Timesteps: 88,028,172

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 88028172...
Checkpoint 88028172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449.42062
Policy Entropy: 0.77039
Value Function Loss: 6.17728

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03767
Policy Update Magnitude: 0.02953
Value Function Update Magnitude: 0.03279

Collected Steps per Second: 23,289.11198
Overall Steps per Second: 16,932.37640

Timestep Collection Time: 2.14804
Timestep Consumption Time: 0.80642
PPO Batch Consumption Time: 0.05818
Total Iteration Time: 2.95446

Cumulative Model Updates: 5,276
Cumulative Timesteps: 88,078,198

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.03978
Policy Entropy: 0.77037
Value Function Loss: 5.99836

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.04075
Policy Update Magnitude: 0.02834
Value Function Update Magnitude: 0.03086

Collected Steps per Second: 20,490.54900
Overall Steps per Second: 14,785.58259

Timestep Collection Time: 2.44083
Timestep Consumption Time: 0.94179
PPO Batch Consumption Time: 0.10884
Total Iteration Time: 3.38262

Cumulative Model Updates: 5,279
Cumulative Timesteps: 88,128,212

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 88128212...
Checkpoint 88128212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.45972
Policy Entropy: 0.75545
Value Function Loss: 5.76600

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.04074
Policy Update Magnitude: 0.03090
Value Function Update Magnitude: 0.04085

Collected Steps per Second: 22,465.37079
Overall Steps per Second: 15,700.90975

Timestep Collection Time: 2.22681
Timestep Consumption Time: 0.95938
PPO Batch Consumption Time: 0.09679
Total Iteration Time: 3.18618

Cumulative Model Updates: 5,282
Cumulative Timesteps: 88,178,238

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.67783
Policy Entropy: 0.74966
Value Function Loss: 5.84370

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03741
Policy Update Magnitude: 0.02890
Value Function Update Magnitude: 0.04209

Collected Steps per Second: 23,188.53907
Overall Steps per Second: 16,798.56175

Timestep Collection Time: 2.15745
Timestep Consumption Time: 0.82067
PPO Batch Consumption Time: 0.06303
Total Iteration Time: 2.97811

Cumulative Model Updates: 5,285
Cumulative Timesteps: 88,228,266

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 88228266...
Checkpoint 88228266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.40858
Policy Entropy: 0.75092
Value Function Loss: 5.87162

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03195
Policy Update Magnitude: 0.03091
Value Function Update Magnitude: 0.04054

Collected Steps per Second: 21,662.17747
Overall Steps per Second: 15,621.30146

Timestep Collection Time: 2.30836
Timestep Consumption Time: 0.89266
PPO Batch Consumption Time: 0.08972
Total Iteration Time: 3.20101

Cumulative Model Updates: 5,288
Cumulative Timesteps: 88,278,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.74802
Policy Entropy: 0.74428
Value Function Loss: 6.00109

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02834
Policy Update Magnitude: 0.03179
Value Function Update Magnitude: 0.04042

Collected Steps per Second: 25,648.28594
Overall Steps per Second: 18,179.11962

Timestep Collection Time: 1.94984
Timestep Consumption Time: 0.80112
PPO Batch Consumption Time: 0.06240
Total Iteration Time: 2.75096

Cumulative Model Updates: 5,291
Cumulative Timesteps: 88,328,280

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 88328280...
Checkpoint 88328280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702.67187
Policy Entropy: 0.76034
Value Function Loss: 6.01866

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01819
Policy Update Magnitude: 0.03256
Value Function Update Magnitude: 0.04049

Collected Steps per Second: 24,254.98092
Overall Steps per Second: 17,472.29886

Timestep Collection Time: 2.06308
Timestep Consumption Time: 0.80088
PPO Batch Consumption Time: 0.06173
Total Iteration Time: 2.86396

Cumulative Model Updates: 5,294
Cumulative Timesteps: 88,378,320

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.95348
Policy Entropy: 0.74770
Value Function Loss: 6.09951

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02243
Policy Update Magnitude: 0.03494
Value Function Update Magnitude: 0.03726

Collected Steps per Second: 21,475.87450
Overall Steps per Second: 15,681.20831

Timestep Collection Time: 2.32819
Timestep Consumption Time: 0.86034
PPO Batch Consumption Time: 0.08749
Total Iteration Time: 3.18853

Cumulative Model Updates: 5,297
Cumulative Timesteps: 88,428,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 88428320...
Checkpoint 88428320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479.68140
Policy Entropy: 0.76087
Value Function Loss: 6.10155

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02625
Policy Update Magnitude: 0.03410
Value Function Update Magnitude: 0.03220

Collected Steps per Second: 24,218.78022
Overall Steps per Second: 18,108.07239

Timestep Collection Time: 2.06559
Timestep Consumption Time: 0.69705
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 2.76264

Cumulative Model Updates: 5,300
Cumulative Timesteps: 88,478,346

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566.69586
Policy Entropy: 0.74061
Value Function Loss: 6.05182

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.03051
Policy Update Magnitude: 0.03129
Value Function Update Magnitude: 0.03061

Collected Steps per Second: 21,669.77068
Overall Steps per Second: 15,707.17934

Timestep Collection Time: 2.30819
Timestep Consumption Time: 0.87621
PPO Batch Consumption Time: 0.07930
Total Iteration Time: 3.18440

Cumulative Model Updates: 5,303
Cumulative Timesteps: 88,528,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 88528364...
Checkpoint 88528364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.18118
Policy Entropy: 0.76126
Value Function Loss: 6.13614

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02359
Policy Update Magnitude: 0.03274
Value Function Update Magnitude: 0.03006

Collected Steps per Second: 24,397.14275
Overall Steps per Second: 17,555.24364

Timestep Collection Time: 2.04983
Timestep Consumption Time: 0.79889
PPO Batch Consumption Time: 0.05973
Total Iteration Time: 2.84872

Cumulative Model Updates: 5,306
Cumulative Timesteps: 88,578,374

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618.13470
Policy Entropy: 0.76772
Value Function Loss: 6.17317

Mean KL Divergence: 0.00135
SB3 Clip Fraction: 0.01177
Policy Update Magnitude: 0.03508
Value Function Update Magnitude: 0.03168

Collected Steps per Second: 22,077.41998
Overall Steps per Second: 16,010.38892

Timestep Collection Time: 2.26557
Timestep Consumption Time: 0.85852
PPO Batch Consumption Time: 0.08040
Total Iteration Time: 3.12410

Cumulative Model Updates: 5,309
Cumulative Timesteps: 88,628,392

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 88628392...
Checkpoint 88628392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.24817
Policy Entropy: 0.76066
Value Function Loss: 6.33324

Mean KL Divergence: 0.00109
SB3 Clip Fraction: 0.00735
Policy Update Magnitude: 0.04233
Value Function Update Magnitude: 0.02948

Collected Steps per Second: 24,391.90909
Overall Steps per Second: 17,991.27349

Timestep Collection Time: 2.05060
Timestep Consumption Time: 0.72953
PPO Batch Consumption Time: 0.05761
Total Iteration Time: 2.78013

Cumulative Model Updates: 5,312
Cumulative Timesteps: 88,678,410

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.92303
Policy Entropy: 0.76790
Value Function Loss: 6.01624

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02635
Policy Update Magnitude: 0.04257
Value Function Update Magnitude: 0.03241

Collected Steps per Second: 20,675.43303
Overall Steps per Second: 14,728.31082

Timestep Collection Time: 2.41881
Timestep Consumption Time: 0.97669
PPO Batch Consumption Time: 0.09586
Total Iteration Time: 3.39550

Cumulative Model Updates: 5,315
Cumulative Timesteps: 88,728,420

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 88728420...
Checkpoint 88728420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.62898
Policy Entropy: 0.75749
Value Function Loss: 5.98720

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.03064
Policy Update Magnitude: 0.03722
Value Function Update Magnitude: 0.03121

Collected Steps per Second: 23,632.64169
Overall Steps per Second: 16,939.33329

Timestep Collection Time: 2.11580
Timestep Consumption Time: 0.83603
PPO Batch Consumption Time: 0.06144
Total Iteration Time: 2.95183

Cumulative Model Updates: 5,318
Cumulative Timesteps: 88,778,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.96282
Policy Entropy: 0.76255
Value Function Loss: 5.91636

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02629
Policy Update Magnitude: 0.03436
Value Function Update Magnitude: 0.03785

Collected Steps per Second: 23,569.18040
Overall Steps per Second: 16,504.62274

Timestep Collection Time: 2.12328
Timestep Consumption Time: 0.90884
PPO Batch Consumption Time: 0.09496
Total Iteration Time: 3.03212

Cumulative Model Updates: 5,321
Cumulative Timesteps: 88,828,466

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 88828466...
Checkpoint 88828466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.53646
Policy Entropy: 0.76398
Value Function Loss: 6.00520

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02386
Policy Update Magnitude: 0.03670
Value Function Update Magnitude: 0.03227

Collected Steps per Second: 23,095.82532
Overall Steps per Second: 17,183.86714

Timestep Collection Time: 2.16507
Timestep Consumption Time: 0.74487
PPO Batch Consumption Time: 0.06172
Total Iteration Time: 2.90994

Cumulative Model Updates: 5,324
Cumulative Timesteps: 88,878,470

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.84085
Policy Entropy: 0.76905
Value Function Loss: 6.14758

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03357
Policy Update Magnitude: 0.03676
Value Function Update Magnitude: 0.03381

Collected Steps per Second: 23,521.71350
Overall Steps per Second: 16,384.89942

Timestep Collection Time: 2.12638
Timestep Consumption Time: 0.92619
PPO Batch Consumption Time: 0.09402
Total Iteration Time: 3.05257

Cumulative Model Updates: 5,327
Cumulative Timesteps: 88,928,486

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 88928486...
Checkpoint 88928486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570.79447
Policy Entropy: 0.75804
Value Function Loss: 6.03095

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03329
Policy Update Magnitude: 0.03282
Value Function Update Magnitude: 0.03596

Collected Steps per Second: 23,260.15839
Overall Steps per Second: 16,691.22473

Timestep Collection Time: 2.14977
Timestep Consumption Time: 0.84606
PPO Batch Consumption Time: 0.06054
Total Iteration Time: 2.99583

Cumulative Model Updates: 5,330
Cumulative Timesteps: 88,978,490

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610.05611
Policy Entropy: 0.76238
Value Function Loss: 6.10734

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03298
Policy Update Magnitude: 0.03212
Value Function Update Magnitude: 0.04955

Collected Steps per Second: 20,933.31577
Overall Steps per Second: 14,821.81062

Timestep Collection Time: 2.39007
Timestep Consumption Time: 0.98550
PPO Batch Consumption Time: 0.11267
Total Iteration Time: 3.37557

Cumulative Model Updates: 5,333
Cumulative Timesteps: 89,028,522

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 89028522...
Checkpoint 89028522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.48056
Policy Entropy: 0.75559
Value Function Loss: 6.09507

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02283
Policy Update Magnitude: 0.03115
Value Function Update Magnitude: 0.04349

Collected Steps per Second: 23,415.63630
Overall Steps per Second: 17,306.80993

Timestep Collection Time: 2.13550
Timestep Consumption Time: 0.75377
PPO Batch Consumption Time: 0.06320
Total Iteration Time: 2.88927

Cumulative Model Updates: 5,336
Cumulative Timesteps: 89,078,526

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.53077
Policy Entropy: 0.74269
Value Function Loss: 6.06392

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01958
Policy Update Magnitude: 0.03351
Value Function Update Magnitude: 0.03620

Collected Steps per Second: 21,432.06953
Overall Steps per Second: 15,191.77474

Timestep Collection Time: 2.33351
Timestep Consumption Time: 0.95853
PPO Batch Consumption Time: 0.09966
Total Iteration Time: 3.29204

Cumulative Model Updates: 5,339
Cumulative Timesteps: 89,128,538

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 89128538...
Checkpoint 89128538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467.74936
Policy Entropy: 0.73605
Value Function Loss: 6.15890

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02570
Policy Update Magnitude: 0.03125
Value Function Update Magnitude: 0.03334

Collected Steps per Second: 23,195.74409
Overall Steps per Second: 16,733.91091

Timestep Collection Time: 2.15617
Timestep Consumption Time: 0.83261
PPO Batch Consumption Time: 0.06120
Total Iteration Time: 2.98878

Cumulative Model Updates: 5,342
Cumulative Timesteps: 89,178,552

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476.74509
Policy Entropy: 0.74134
Value Function Loss: 6.08913

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03379
Policy Update Magnitude: 0.02985
Value Function Update Magnitude: 0.03637

Collected Steps per Second: 19,557.11549
Overall Steps per Second: 14,695.18511

Timestep Collection Time: 2.55702
Timestep Consumption Time: 0.84600
PPO Batch Consumption Time: 0.08921
Total Iteration Time: 3.40302

Cumulative Model Updates: 5,345
Cumulative Timesteps: 89,228,560

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 89228560...
Checkpoint 89228560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524.93477
Policy Entropy: 0.73962
Value Function Loss: 6.08826

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01653
Policy Update Magnitude: 0.03418
Value Function Update Magnitude: 0.03838

Collected Steps per Second: 23,475.69055
Overall Steps per Second: 16,891.86735

Timestep Collection Time: 2.12986
Timestep Consumption Time: 0.83014
PPO Batch Consumption Time: 0.05801
Total Iteration Time: 2.96000

Cumulative Model Updates: 5,348
Cumulative Timesteps: 89,278,560

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.41058
Policy Entropy: 0.72988
Value Function Loss: 5.87872

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02178
Policy Update Magnitude: 0.03583
Value Function Update Magnitude: 0.04847

Collected Steps per Second: 20,928.67380
Overall Steps per Second: 14,784.80286

Timestep Collection Time: 2.38935
Timestep Consumption Time: 0.99290
PPO Batch Consumption Time: 0.10685
Total Iteration Time: 3.38226

Cumulative Model Updates: 5,351
Cumulative Timesteps: 89,328,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 89328566...
Checkpoint 89328566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.30333
Policy Entropy: 0.73076
Value Function Loss: 5.70594

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02349
Policy Update Magnitude: 0.03406
Value Function Update Magnitude: 0.04567

Collected Steps per Second: 23,597.09141
Overall Steps per Second: 16,784.41614

Timestep Collection Time: 2.12009
Timestep Consumption Time: 0.86053
PPO Batch Consumption Time: 0.09821
Total Iteration Time: 2.98062

Cumulative Model Updates: 5,354
Cumulative Timesteps: 89,378,594

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.20452
Policy Entropy: 0.71679
Value Function Loss: 5.84019

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.02037
Policy Update Magnitude: 0.03285
Value Function Update Magnitude: 0.04164

Collected Steps per Second: 24,128.65205
Overall Steps per Second: 16,691.38680

Timestep Collection Time: 2.07272
Timestep Consumption Time: 0.92355
PPO Batch Consumption Time: 0.09211
Total Iteration Time: 2.99628

Cumulative Model Updates: 5,357
Cumulative Timesteps: 89,428,606

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 89428606...
Checkpoint 89428606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.89652
Policy Entropy: 0.73168
Value Function Loss: 5.85431

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01301
Policy Update Magnitude: 0.03429
Value Function Update Magnitude: 0.04138

Collected Steps per Second: 23,438.08767
Overall Steps per Second: 15,822.65865

Timestep Collection Time: 2.13371
Timestep Consumption Time: 1.02695
PPO Batch Consumption Time: 0.12002
Total Iteration Time: 3.16066

Cumulative Model Updates: 5,360
Cumulative Timesteps: 89,478,616

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543.51072
Policy Entropy: 0.73378
Value Function Loss: 5.91911

Mean KL Divergence: 0.00151
SB3 Clip Fraction: 0.01331
Policy Update Magnitude: 0.03834
Value Function Update Magnitude: 0.03430

Collected Steps per Second: 23,579.64960
Overall Steps per Second: 16,902.79275

Timestep Collection Time: 2.12064
Timestep Consumption Time: 0.83769
PPO Batch Consumption Time: 0.06683
Total Iteration Time: 2.95833

Cumulative Model Updates: 5,363
Cumulative Timesteps: 89,528,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 89528620...
Checkpoint 89528620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412.48430
Policy Entropy: 0.71828
Value Function Loss: 5.74731

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01613
Policy Update Magnitude: 0.04060
Value Function Update Magnitude: 0.02812

Collected Steps per Second: 23,500.04162
Overall Steps per Second: 17,299.58792

Timestep Collection Time: 2.12893
Timestep Consumption Time: 0.76304
PPO Batch Consumption Time: 0.06163
Total Iteration Time: 2.89198

Cumulative Model Updates: 5,366
Cumulative Timesteps: 89,578,650

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589.21297
Policy Entropy: 0.71664
Value Function Loss: 5.66044

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01695
Policy Update Magnitude: 0.03756
Value Function Update Magnitude: 0.02790

Collected Steps per Second: 21,114.97863
Overall Steps per Second: 14,845.87878

Timestep Collection Time: 2.36827
Timestep Consumption Time: 1.00007
PPO Batch Consumption Time: 0.11507
Total Iteration Time: 3.36834

Cumulative Model Updates: 5,369
Cumulative Timesteps: 89,628,656

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 89628656...
Checkpoint 89628656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.01620
Policy Entropy: 0.70815
Value Function Loss: 5.57187

Mean KL Divergence: 0.00132
SB3 Clip Fraction: 0.01193
Policy Update Magnitude: 0.03735
Value Function Update Magnitude: 0.02786

Collected Steps per Second: 23,618.48041
Overall Steps per Second: 16,879.36596

Timestep Collection Time: 2.11749
Timestep Consumption Time: 0.84541
PPO Batch Consumption Time: 0.05899
Total Iteration Time: 2.96291

Cumulative Model Updates: 5,372
Cumulative Timesteps: 89,678,668

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.45274
Policy Entropy: 0.70811
Value Function Loss: 5.56160

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01611
Policy Update Magnitude: 0.03800
Value Function Update Magnitude: 0.03695

Collected Steps per Second: 20,812.50384
Overall Steps per Second: 14,710.36070

Timestep Collection Time: 2.40384
Timestep Consumption Time: 0.99716
PPO Batch Consumption Time: 0.11740
Total Iteration Time: 3.40100

Cumulative Model Updates: 5,375
Cumulative Timesteps: 89,728,698

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 89728698...
Checkpoint 89728698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526.23997
Policy Entropy: 0.71423
Value Function Loss: 5.72197

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01871
Policy Update Magnitude: 0.03679
Value Function Update Magnitude: 0.03570

Collected Steps per Second: 23,271.25448
Overall Steps per Second: 17,301.46474

Timestep Collection Time: 2.14943
Timestep Consumption Time: 0.74165
PPO Batch Consumption Time: 0.06196
Total Iteration Time: 2.89108

Cumulative Model Updates: 5,378
Cumulative Timesteps: 89,778,718

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.60545
Policy Entropy: 0.70513
Value Function Loss: 5.74410

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01215
Policy Update Magnitude: 0.03483
Value Function Update Magnitude: 0.03518

Collected Steps per Second: 24,824.36548
Overall Steps per Second: 17,713.91663

Timestep Collection Time: 2.01479
Timestep Consumption Time: 0.80875
PPO Batch Consumption Time: 0.06455
Total Iteration Time: 2.82354

Cumulative Model Updates: 5,381
Cumulative Timesteps: 89,828,734

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 89828734...
Checkpoint 89828734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.01268
Policy Entropy: 0.70625
Value Function Loss: 5.79749

Mean KL Divergence: 0.00124
SB3 Clip Fraction: 0.01079
Policy Update Magnitude: 0.03884
Value Function Update Magnitude: 0.03224

Collected Steps per Second: 23,995.98403
Overall Steps per Second: 16,601.31283

Timestep Collection Time: 2.08368
Timestep Consumption Time: 0.92813
PPO Batch Consumption Time: 0.10310
Total Iteration Time: 3.01181

Cumulative Model Updates: 5,384
Cumulative Timesteps: 89,878,734

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557.11892
Policy Entropy: 0.69979
Value Function Loss: 5.73609

Mean KL Divergence: 0.00110
SB3 Clip Fraction: 0.00801
Policy Update Magnitude: 0.04041
Value Function Update Magnitude: 0.03307

Collected Steps per Second: 24,231.89993
Overall Steps per Second: 16,725.44884

Timestep Collection Time: 2.06414
Timestep Consumption Time: 0.92639
PPO Batch Consumption Time: 0.10880
Total Iteration Time: 2.99053

Cumulative Model Updates: 5,387
Cumulative Timesteps: 89,928,752

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 89928752...
Checkpoint 89928752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.60315
Policy Entropy: 0.69558
Value Function Loss: 5.74776

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01730
Policy Update Magnitude: 0.04137
Value Function Update Magnitude: 0.03149

Collected Steps per Second: 25,393.22023
Overall Steps per Second: 17,632.87471

Timestep Collection Time: 1.96966
Timestep Consumption Time: 0.86686
PPO Batch Consumption Time: 0.07903
Total Iteration Time: 2.83652

Cumulative Model Updates: 5,390
Cumulative Timesteps: 89,978,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471.37150
Policy Entropy: 0.70203
Value Function Loss: 5.79929

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01692
Policy Update Magnitude: 0.03788
Value Function Update Magnitude: 0.03766

Collected Steps per Second: 23,343.96241
Overall Steps per Second: 15,956.95692

Timestep Collection Time: 2.14274
Timestep Consumption Time: 0.99194
PPO Batch Consumption Time: 0.12294
Total Iteration Time: 3.13468

Cumulative Model Updates: 5,393
Cumulative Timesteps: 90,028,788

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 90028788...
Checkpoint 90028788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.77275
Policy Entropy: 0.68978
Value Function Loss: 5.71266

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01543
Policy Update Magnitude: 0.03741
Value Function Update Magnitude: 0.03802

Collected Steps per Second: 24,323.98209
Overall Steps per Second: 16,640.96462

Timestep Collection Time: 2.05567
Timestep Consumption Time: 0.94909
PPO Batch Consumption Time: 0.09836
Total Iteration Time: 3.00475

Cumulative Model Updates: 5,396
Cumulative Timesteps: 90,078,790

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.32218
Policy Entropy: 0.69320
Value Function Loss: 5.71423

Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.01279
Policy Update Magnitude: 0.03854
Value Function Update Magnitude: 0.03590

Collected Steps per Second: 24,484.97241
Overall Steps per Second: 16,792.73020

Timestep Collection Time: 2.04289
Timestep Consumption Time: 0.93578
PPO Batch Consumption Time: 0.10912
Total Iteration Time: 2.97867

Cumulative Model Updates: 5,399
Cumulative Timesteps: 90,128,810

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 90128810...
Checkpoint 90128810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.45798
Policy Entropy: 0.69148
Value Function Loss: 5.90626

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01328
Policy Update Magnitude: 0.04249
Value Function Update Magnitude: 0.03462

Collected Steps per Second: 24,439.01073
Overall Steps per Second: 16,783.75077

Timestep Collection Time: 2.04697
Timestep Consumption Time: 0.93365
PPO Batch Consumption Time: 0.11605
Total Iteration Time: 2.98062

Cumulative Model Updates: 5,402
Cumulative Timesteps: 90,178,836

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641.89122
Policy Entropy: 0.69886
Value Function Loss: 6.02155

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01781
Policy Update Magnitude: 0.03785
Value Function Update Magnitude: 0.03264

Collected Steps per Second: 25,058.35757
Overall Steps per Second: 16,707.27002

Timestep Collection Time: 1.99670
Timestep Consumption Time: 0.99805
PPO Batch Consumption Time: 0.12002
Total Iteration Time: 2.99474

Cumulative Model Updates: 5,405
Cumulative Timesteps: 90,228,870

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 90228870...
Checkpoint 90228870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516.93706
Policy Entropy: 0.69683
Value Function Loss: 6.17811

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.01918
Policy Update Magnitude: 0.03540
Value Function Update Magnitude: 0.03088

Collected Steps per Second: 23,990.06056
Overall Steps per Second: 16,663.84705

Timestep Collection Time: 2.08495
Timestep Consumption Time: 0.91664
PPO Batch Consumption Time: 0.08778
Total Iteration Time: 3.00159

Cumulative Model Updates: 5,408
Cumulative Timesteps: 90,278,888

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583.39347
Policy Entropy: 0.68041
Value Function Loss: 5.86556

Mean KL Divergence: 0.00168
SB3 Clip Fraction: 0.01813
Policy Update Magnitude: 0.03245
Value Function Update Magnitude: 0.03188

Collected Steps per Second: 23,277.68123
Overall Steps per Second: 16,737.26963

Timestep Collection Time: 2.14901
Timestep Consumption Time: 0.83977
PPO Batch Consumption Time: 0.09949
Total Iteration Time: 2.98878

Cumulative Model Updates: 5,411
Cumulative Timesteps: 90,328,912

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 90328912...
Checkpoint 90328912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554.19966
Policy Entropy: 0.67551
Value Function Loss: 5.93252

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.03019
Policy Update Magnitude: 0.03291
Value Function Update Magnitude: 0.03132

Collected Steps per Second: 24,245.35309
Overall Steps per Second: 16,751.70874

Timestep Collection Time: 2.06349
Timestep Consumption Time: 0.92307
PPO Batch Consumption Time: 0.09262
Total Iteration Time: 2.98656

Cumulative Model Updates: 5,414
Cumulative Timesteps: 90,378,942

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.33291
Policy Entropy: 0.67442
Value Function Loss: 5.74457

Mean KL Divergence: 0.00151
SB3 Clip Fraction: 0.01401
Policy Update Magnitude: 0.03000
Value Function Update Magnitude: 0.03081

Collected Steps per Second: 24,387.97925
Overall Steps per Second: 16,742.99499

Timestep Collection Time: 2.05060
Timestep Consumption Time: 0.93632
PPO Batch Consumption Time: 0.10398
Total Iteration Time: 2.98692

Cumulative Model Updates: 5,417
Cumulative Timesteps: 90,428,952

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 90428952...
Checkpoint 90428952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544.77082
Policy Entropy: 0.68068
Value Function Loss: 5.85316

Mean KL Divergence: 0.00106
SB3 Clip Fraction: 0.00706
Policy Update Magnitude: 0.03550
Value Function Update Magnitude: 0.03715

Collected Steps per Second: 23,760.45623
Overall Steps per Second: 16,750.26902

Timestep Collection Time: 2.10560
Timestep Consumption Time: 0.88122
PPO Batch Consumption Time: 0.09122
Total Iteration Time: 2.98682

Cumulative Model Updates: 5,420
Cumulative Timesteps: 90,478,982

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.96973
Policy Entropy: 0.68770
Value Function Loss: 5.73937

Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.01030
Policy Update Magnitude: 0.03710
Value Function Update Magnitude: 0.04118

Collected Steps per Second: 24,302.28946
Overall Steps per Second: 16,814.95514

Timestep Collection Time: 2.05808
Timestep Consumption Time: 0.91642
PPO Batch Consumption Time: 0.11941
Total Iteration Time: 2.97449

Cumulative Model Updates: 5,423
Cumulative Timesteps: 90,528,998

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 90528998...
Checkpoint 90528998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617.87611
Policy Entropy: 0.68480
Value Function Loss: 5.90197

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01730
Policy Update Magnitude: 0.03884
Value Function Update Magnitude: 0.03733

Collected Steps per Second: 23,541.93600
Overall Steps per Second: 16,622.54636

Timestep Collection Time: 2.12463
Timestep Consumption Time: 0.88441
PPO Batch Consumption Time: 0.08591
Total Iteration Time: 3.00905

Cumulative Model Updates: 5,426
Cumulative Timesteps: 90,579,016

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.49171
Policy Entropy: 0.67480
Value Function Loss: 5.90288

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01105
Policy Update Magnitude: 0.03634
Value Function Update Magnitude: 0.03334

Collected Steps per Second: 24,748.50988
Overall Steps per Second: 16,817.78138

Timestep Collection Time: 2.02121
Timestep Consumption Time: 0.95314
PPO Batch Consumption Time: 0.10415
Total Iteration Time: 2.97435

Cumulative Model Updates: 5,429
Cumulative Timesteps: 90,629,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 90629038...
Checkpoint 90629038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408.37725
Policy Entropy: 0.67750
Value Function Loss: 5.89645

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01601
Policy Update Magnitude: 0.03899
Value Function Update Magnitude: 0.03056

Collected Steps per Second: 24,228.08821
Overall Steps per Second: 16,727.58772

Timestep Collection Time: 2.06405
Timestep Consumption Time: 0.92550
PPO Batch Consumption Time: 0.10128
Total Iteration Time: 2.98955

Cumulative Model Updates: 5,432
Cumulative Timesteps: 90,679,046

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 784.52620
Policy Entropy: 0.68985
Value Function Loss: 5.84869

Mean KL Divergence: 0.00128
SB3 Clip Fraction: 0.01040
Policy Update Magnitude: 0.03852
Value Function Update Magnitude: 0.03190

Collected Steps per Second: 24,283.16417
Overall Steps per Second: 16,779.80670

Timestep Collection Time: 2.05912
Timestep Consumption Time: 0.92077
PPO Batch Consumption Time: 0.12144
Total Iteration Time: 2.97989

Cumulative Model Updates: 5,435
Cumulative Timesteps: 90,729,048

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 90729048...
Checkpoint 90729048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.74406
Policy Entropy: 0.68421
Value Function Loss: 5.86275

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01810
Policy Update Magnitude: 0.03809
Value Function Update Magnitude: 0.03648

Collected Steps per Second: 24,635.61866
Overall Steps per Second: 16,746.10409

Timestep Collection Time: 2.03039
Timestep Consumption Time: 0.95657
PPO Batch Consumption Time: 0.11329
Total Iteration Time: 2.98696

Cumulative Model Updates: 5,438
Cumulative Timesteps: 90,779,068

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.05901
Policy Entropy: 0.68935
Value Function Loss: 5.86710

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.01528
Policy Update Magnitude: 0.03773
Value Function Update Magnitude: 0.03239

Collected Steps per Second: 24,918.33028
Overall Steps per Second: 16,722.41473

Timestep Collection Time: 2.00760
Timestep Consumption Time: 0.98396
PPO Batch Consumption Time: 0.11968
Total Iteration Time: 2.99155

Cumulative Model Updates: 5,441
Cumulative Timesteps: 90,829,094

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 90829094...
Checkpoint 90829094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678.44827
Policy Entropy: 0.67902
Value Function Loss: 5.68691

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.02127
Policy Update Magnitude: 0.03340
Value Function Update Magnitude: 0.03852

Collected Steps per Second: 24,215.45195
Overall Steps per Second: 16,698.32152

Timestep Collection Time: 2.06488
Timestep Consumption Time: 0.92955
PPO Batch Consumption Time: 0.10430
Total Iteration Time: 2.99443

Cumulative Model Updates: 5,444
Cumulative Timesteps: 90,879,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493.91233
Policy Entropy: 0.68053
Value Function Loss: 5.68493

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01799
Policy Update Magnitude: 0.03419
Value Function Update Magnitude: 0.03639

Collected Steps per Second: 24,786.87442
Overall Steps per Second: 17,826.04520

Timestep Collection Time: 2.01752
Timestep Consumption Time: 0.78781
PPO Batch Consumption Time: 0.08071
Total Iteration Time: 2.80533

Cumulative Model Updates: 5,447
Cumulative Timesteps: 90,929,104

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 90929104...
Checkpoint 90929104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640.72387
Policy Entropy: 0.67332
Value Function Loss: 5.67661

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.03195
Policy Update Magnitude: 0.03063
Value Function Update Magnitude: 0.04020

Collected Steps per Second: 24,410.05058
Overall Steps per Second: 17,527.57695

Timestep Collection Time: 2.04858
Timestep Consumption Time: 0.80441
PPO Batch Consumption Time: 0.06093
Total Iteration Time: 2.85299

Cumulative Model Updates: 5,450
Cumulative Timesteps: 90,979,110

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.71006
Policy Entropy: 0.66139
Value Function Loss: 5.69109

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01830
Policy Update Magnitude: 0.03147
Value Function Update Magnitude: 0.04185

Collected Steps per Second: 21,416.63421
Overall Steps per Second: 15,138.51154

Timestep Collection Time: 2.33519
Timestep Consumption Time: 0.96843
PPO Batch Consumption Time: 0.11128
Total Iteration Time: 3.30363

Cumulative Model Updates: 5,453
Cumulative Timesteps: 91,029,122

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 91029122...
Checkpoint 91029122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525.92398
Policy Entropy: 0.66084
Value Function Loss: 5.58311

Mean KL Divergence: 0.00168
SB3 Clip Fraction: 0.01730
Policy Update Magnitude: 0.03251
Value Function Update Magnitude: 0.03617

Collected Steps per Second: 24,112.36350
Overall Steps per Second: 16,710.49311

Timestep Collection Time: 2.07379
Timestep Consumption Time: 0.91858
PPO Batch Consumption Time: 0.10463
Total Iteration Time: 2.99237

Cumulative Model Updates: 5,456
Cumulative Timesteps: 91,079,126

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451.32684
Policy Entropy: 0.66706
Value Function Loss: 5.64962

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.02039
Policy Update Magnitude: 0.03417
Value Function Update Magnitude: 0.03961

Collected Steps per Second: 24,906.67589
Overall Steps per Second: 17,836.62884

Timestep Collection Time: 2.00862
Timestep Consumption Time: 0.79617
PPO Batch Consumption Time: 0.07790
Total Iteration Time: 2.80479

Cumulative Model Updates: 5,459
Cumulative Timesteps: 91,129,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 91129154...
Checkpoint 91129154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.61341
Policy Entropy: 0.68191
Value Function Loss: 5.81754

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03439
Policy Update Magnitude: 0.03636
Value Function Update Magnitude: 0.03805

Collected Steps per Second: 24,502.55661
Overall Steps per Second: 17,625.44716

Timestep Collection Time: 2.04166
Timestep Consumption Time: 0.79662
PPO Batch Consumption Time: 0.06045
Total Iteration Time: 2.83828

Cumulative Model Updates: 5,462
Cumulative Timesteps: 91,179,180

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.26845
Policy Entropy: 0.68110
Value Function Loss: 5.91776

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.05044
Policy Update Magnitude: 0.03098
Value Function Update Magnitude: 0.03447

Collected Steps per Second: 21,359.89296
Overall Steps per Second: 15,074.87676

Timestep Collection Time: 2.34084
Timestep Consumption Time: 0.97594
PPO Batch Consumption Time: 0.11407
Total Iteration Time: 3.31678

Cumulative Model Updates: 5,465
Cumulative Timesteps: 91,229,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 91229180...
Checkpoint 91229180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592.50937
Policy Entropy: 0.67599
Value Function Loss: 5.70964

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.04461
Policy Update Magnitude: 0.02927
Value Function Update Magnitude: 0.03738

Collected Steps per Second: 24,575.98006
Overall Steps per Second: 17,801.78151

Timestep Collection Time: 2.03475
Timestep Consumption Time: 0.77429
PPO Batch Consumption Time: 0.07433
Total Iteration Time: 2.80904

Cumulative Model Updates: 5,468
Cumulative Timesteps: 91,279,186

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.43793
Policy Entropy: 0.66103
Value Function Loss: 5.72767

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02450
Policy Update Magnitude: 0.03000
Value Function Update Magnitude: 0.03486

Collected Steps per Second: 24,634.70902
Overall Steps per Second: 17,819.28009

Timestep Collection Time: 2.03031
Timestep Consumption Time: 0.77654
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 2.80685

Cumulative Model Updates: 5,471
Cumulative Timesteps: 91,329,202

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 91329202...
Checkpoint 91329202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524.73780
Policy Entropy: 0.66286
Value Function Loss: 5.67276

Mean KL Divergence: 0.00126
SB3 Clip Fraction: 0.01102
Policy Update Magnitude: 0.03674
Value Function Update Magnitude: 0.03892

Collected Steps per Second: 20,769.20212
Overall Steps per Second: 14,916.06760

Timestep Collection Time: 2.40818
Timestep Consumption Time: 0.94498
PPO Batch Consumption Time: 0.10383
Total Iteration Time: 3.35316

Cumulative Model Updates: 5,474
Cumulative Timesteps: 91,379,218

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567.43466
Policy Entropy: 0.66786
Value Function Loss: 5.59329

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01900
Policy Update Magnitude: 0.03772
Value Function Update Magnitude: 0.04007

Collected Steps per Second: 24,511.26979
Overall Steps per Second: 16,710.12525

Timestep Collection Time: 2.03988
Timestep Consumption Time: 0.95232
PPO Batch Consumption Time: 0.10366
Total Iteration Time: 2.99220

Cumulative Model Updates: 5,477
Cumulative Timesteps: 91,429,218

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 91429218...
Checkpoint 91429218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559.45480
Policy Entropy: 0.65633
Value Function Loss: 5.38348

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02658
Policy Update Magnitude: 0.03296
Value Function Update Magnitude: 0.03760

Collected Steps per Second: 24,543.83636
Overall Steps per Second: 16,806.80234

Timestep Collection Time: 2.03742
Timestep Consumption Time: 0.93793
PPO Batch Consumption Time: 0.10843
Total Iteration Time: 2.97534

Cumulative Model Updates: 5,480
Cumulative Timesteps: 91,479,224

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.06594
Policy Entropy: 0.65922
Value Function Loss: 5.30437

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01800
Policy Update Magnitude: 0.03234
Value Function Update Magnitude: 0.03098

Collected Steps per Second: 25,676.50945
Overall Steps per Second: 17,788.12228

Timestep Collection Time: 1.94816
Timestep Consumption Time: 0.86394
PPO Batch Consumption Time: 0.08085
Total Iteration Time: 2.81210

Cumulative Model Updates: 5,483
Cumulative Timesteps: 91,529,246

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 91529246...
Checkpoint 91529246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.01625
Policy Entropy: 0.65629
Value Function Loss: 5.50885

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01939
Policy Update Magnitude: 0.03334
Value Function Update Magnitude: 0.02827

Collected Steps per Second: 24,461.73184
Overall Steps per Second: 17,612.50379

Timestep Collection Time: 2.04442
Timestep Consumption Time: 0.79504
PPO Batch Consumption Time: 0.06024
Total Iteration Time: 2.83946

Cumulative Model Updates: 5,486
Cumulative Timesteps: 91,579,256

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451.26133
Policy Entropy: 0.65329
Value Function Loss: 5.77236

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04355
Policy Update Magnitude: 0.03238
Value Function Update Magnitude: 0.02950

Collected Steps per Second: 22,030.03484
Overall Steps per Second: 15,917.74723

Timestep Collection Time: 2.26981
Timestep Consumption Time: 0.87159
PPO Batch Consumption Time: 0.07808
Total Iteration Time: 3.14140

Cumulative Model Updates: 5,489
Cumulative Timesteps: 91,629,260

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 91629260...
Checkpoint 91629260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.71858
Policy Entropy: 0.66112
Value Function Loss: 5.86028

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03337
Policy Update Magnitude: 0.02841
Value Function Update Magnitude: 0.02959

Collected Steps per Second: 24,296.55673
Overall Steps per Second: 18,058.06808

Timestep Collection Time: 2.05856
Timestep Consumption Time: 0.71117
PPO Batch Consumption Time: 0.05648
Total Iteration Time: 2.76973

Cumulative Model Updates: 5,492
Cumulative Timesteps: 91,679,276

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653.12065
Policy Entropy: 0.64328
Value Function Loss: 5.99206

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02579
Policy Update Magnitude: 0.02705
Value Function Update Magnitude: 0.03543

Collected Steps per Second: 21,581.40261
Overall Steps per Second: 15,599.10780

Timestep Collection Time: 2.31737
Timestep Consumption Time: 0.88872
PPO Batch Consumption Time: 0.08360
Total Iteration Time: 3.20608

Cumulative Model Updates: 5,495
Cumulative Timesteps: 91,729,288

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 91729288...
Checkpoint 91729288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518.88807
Policy Entropy: 0.65732
Value Function Loss: 5.85198

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.02235
Policy Update Magnitude: 0.03017
Value Function Update Magnitude: 0.03526

Collected Steps per Second: 24,249.21610
Overall Steps per Second: 17,527.20153

Timestep Collection Time: 2.06308
Timestep Consumption Time: 0.79123
PPO Batch Consumption Time: 0.06081
Total Iteration Time: 2.85431

Cumulative Model Updates: 5,498
Cumulative Timesteps: 91,779,316

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.53261
Policy Entropy: 0.65451
Value Function Loss: 5.94588

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.03261
Policy Update Magnitude: 0.02690
Value Function Update Magnitude: 0.03828

Collected Steps per Second: 21,775.33045
Overall Steps per Second: 16,011.74066

Timestep Collection Time: 2.29636
Timestep Consumption Time: 0.82660
PPO Batch Consumption Time: 0.07397
Total Iteration Time: 3.12296

Cumulative Model Updates: 5,501
Cumulative Timesteps: 91,829,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 91829320...
Checkpoint 91829320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599.64991
Policy Entropy: 0.65453
Value Function Loss: 5.65903

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01037
Policy Update Magnitude: 0.03138
Value Function Update Magnitude: 0.03663

Collected Steps per Second: 24,283.48615
Overall Steps per Second: 17,555.78795

Timestep Collection Time: 2.05951
Timestep Consumption Time: 0.78924
PPO Batch Consumption Time: 0.06096
Total Iteration Time: 2.84875

Cumulative Model Updates: 5,504
Cumulative Timesteps: 91,879,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.81163
Policy Entropy: 0.65830
Value Function Loss: 5.59672

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01607
Policy Update Magnitude: 0.03547
Value Function Update Magnitude: 0.03323

Collected Steps per Second: 22,248.74859
Overall Steps per Second: 16,001.67076

Timestep Collection Time: 2.24741
Timestep Consumption Time: 0.87739
PPO Batch Consumption Time: 0.08175
Total Iteration Time: 3.12480

Cumulative Model Updates: 5,507
Cumulative Timesteps: 91,929,334

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 91929334...
Checkpoint 91929334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543.39060
Policy Entropy: 0.66087
Value Function Loss: 5.49633

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01870
Policy Update Magnitude: 0.03263
Value Function Update Magnitude: 0.03075

Collected Steps per Second: 24,436.53560
Overall Steps per Second: 17,475.49404

Timestep Collection Time: 2.04693
Timestep Consumption Time: 0.81536
PPO Batch Consumption Time: 0.06042
Total Iteration Time: 2.86229

Cumulative Model Updates: 5,510
Cumulative Timesteps: 91,979,354

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.84449
Policy Entropy: 0.65734
Value Function Loss: 5.49330

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01792
Policy Update Magnitude: 0.03032
Value Function Update Magnitude: 0.02920

Collected Steps per Second: 21,877.15639
Overall Steps per Second: 16,050.21711

Timestep Collection Time: 2.28695
Timestep Consumption Time: 0.83026
PPO Batch Consumption Time: 0.07684
Total Iteration Time: 3.11722

Cumulative Model Updates: 5,513
Cumulative Timesteps: 92,029,386

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 92029386...
Checkpoint 92029386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637.19548
Policy Entropy: 0.65392
Value Function Loss: 5.76185

Mean KL Divergence: 0.00112
SB3 Clip Fraction: 0.00937
Policy Update Magnitude: 0.03218
Value Function Update Magnitude: 0.02895

Collected Steps per Second: 24,269.21882
Overall Steps per Second: 18,063.99709

Timestep Collection Time: 2.06129
Timestep Consumption Time: 0.70808
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 2.76938

Cumulative Model Updates: 5,516
Cumulative Timesteps: 92,079,412

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.49199
Policy Entropy: 0.65452
Value Function Loss: 5.74578

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.01354
Policy Update Magnitude: 0.03566
Value Function Update Magnitude: 0.03145

Collected Steps per Second: 21,875.03771
Overall Steps per Second: 15,633.18899

Timestep Collection Time: 2.28717
Timestep Consumption Time: 0.91320
PPO Batch Consumption Time: 0.09575
Total Iteration Time: 3.20037

Cumulative Model Updates: 5,519
Cumulative Timesteps: 92,129,444

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 92129444...
Checkpoint 92129444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.15205
Policy Entropy: 0.65616
Value Function Loss: 5.69972

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01692
Policy Update Magnitude: 0.03397
Value Function Update Magnitude: 0.03074

Collected Steps per Second: 24,465.42183
Overall Steps per Second: 17,519.12735

Timestep Collection Time: 2.04419
Timestep Consumption Time: 0.81052
PPO Batch Consumption Time: 0.06124
Total Iteration Time: 2.85471

Cumulative Model Updates: 5,522
Cumulative Timesteps: 92,179,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693.76608
Policy Entropy: 0.64870
Value Function Loss: 5.50930

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02107
Policy Update Magnitude: 0.03420
Value Function Update Magnitude: 0.03010

Collected Steps per Second: 21,384.62771
Overall Steps per Second: 15,154.96497

Timestep Collection Time: 2.33906
Timestep Consumption Time: 0.96151
PPO Batch Consumption Time: 0.11559
Total Iteration Time: 3.30057

Cumulative Model Updates: 5,525
Cumulative Timesteps: 92,229,476

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 92229476...
Checkpoint 92229476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509.67383
Policy Entropy: 0.64247
Value Function Loss: 5.52747

Mean KL Divergence: 0.00135
SB3 Clip Fraction: 0.01221
Policy Update Magnitude: 0.03254
Value Function Update Magnitude: 0.02752

Collected Steps per Second: 24,460.28841
Overall Steps per Second: 16,759.42354

Timestep Collection Time: 2.04511
Timestep Consumption Time: 0.93972
PPO Batch Consumption Time: 0.10652
Total Iteration Time: 2.98483

Cumulative Model Updates: 5,528
Cumulative Timesteps: 92,279,500

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.59785
Policy Entropy: 0.64161
Value Function Loss: 5.54431

Mean KL Divergence: 0.00101
SB3 Clip Fraction: 0.00819
Policy Update Magnitude: 0.03457
Value Function Update Magnitude: 0.03114

Collected Steps per Second: 24,799.48012
Overall Steps per Second: 17,751.09236

Timestep Collection Time: 2.01738
Timestep Consumption Time: 0.80104
PPO Batch Consumption Time: 0.08472
Total Iteration Time: 2.81842

Cumulative Model Updates: 5,531
Cumulative Timesteps: 92,329,530

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 92329530...
Checkpoint 92329530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.30904
Policy Entropy: 0.64454
Value Function Loss: 5.53675

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.02081
Policy Update Magnitude: 0.03536
Value Function Update Magnitude: 0.03283

Collected Steps per Second: 23,652.85415
Overall Steps per Second: 17,182.81529

Timestep Collection Time: 2.11467
Timestep Consumption Time: 0.79626
PPO Batch Consumption Time: 0.05913
Total Iteration Time: 2.91093

Cumulative Model Updates: 5,534
Cumulative Timesteps: 92,379,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.12292
Policy Entropy: 0.63210
Value Function Loss: 5.50375

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02609
Policy Update Magnitude: 0.03459
Value Function Update Magnitude: 0.04092

Collected Steps per Second: 24,099.97718
Overall Steps per Second: 16,457.09958

Timestep Collection Time: 2.07577
Timestep Consumption Time: 0.96401
PPO Batch Consumption Time: 0.11353
Total Iteration Time: 3.03978

Cumulative Model Updates: 5,537
Cumulative Timesteps: 92,429,574

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 92429574...
Checkpoint 92429574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714.71951
Policy Entropy: 0.64067
Value Function Loss: 5.47074

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02069
Policy Update Magnitude: 0.03151
Value Function Update Magnitude: 0.04737

Collected Steps per Second: 24,440.23181
Overall Steps per Second: 17,722.74586

Timestep Collection Time: 2.04654
Timestep Consumption Time: 0.77571
PPO Batch Consumption Time: 0.05772
Total Iteration Time: 2.82225

Cumulative Model Updates: 5,540
Cumulative Timesteps: 92,479,592

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601.05188
Policy Entropy: 0.64413
Value Function Loss: 5.54153

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01914
Policy Update Magnitude: 0.03306
Value Function Update Magnitude: 0.04555

Collected Steps per Second: 22,143.66374
Overall Steps per Second: 15,746.71559

Timestep Collection Time: 2.25861
Timestep Consumption Time: 0.91754
PPO Batch Consumption Time: 0.09536
Total Iteration Time: 3.17615

Cumulative Model Updates: 5,543
Cumulative Timesteps: 92,529,606

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 92529606...
Checkpoint 92529606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.55106
Policy Entropy: 0.64634
Value Function Loss: 5.46244

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02131
Policy Update Magnitude: 0.03264
Value Function Update Magnitude: 0.03823

Collected Steps per Second: 24,523.96382
Overall Steps per Second: 17,608.51275

Timestep Collection Time: 2.03956
Timestep Consumption Time: 0.80100
PPO Batch Consumption Time: 0.06013
Total Iteration Time: 2.84056

Cumulative Model Updates: 5,546
Cumulative Timesteps: 92,579,624

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.62768
Policy Entropy: 0.62810
Value Function Loss: 5.59261

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01529
Policy Update Magnitude: 0.03052
Value Function Update Magnitude: 0.03499

Collected Steps per Second: 21,716.00261
Overall Steps per Second: 15,091.86900

Timestep Collection Time: 2.30383
Timestep Consumption Time: 1.01120
PPO Batch Consumption Time: 0.12408
Total Iteration Time: 3.31503

Cumulative Model Updates: 5,549
Cumulative Timesteps: 92,629,654

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 92629654...
Checkpoint 92629654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644.80039
Policy Entropy: 0.63395
Value Function Loss: 5.56824

Mean KL Divergence: 0.00134
SB3 Clip Fraction: 0.01255
Policy Update Magnitude: 0.03385
Value Function Update Magnitude: 0.03781

Collected Steps per Second: 24,072.74673
Overall Steps per Second: 16,722.41753

Timestep Collection Time: 2.07837
Timestep Consumption Time: 0.91355
PPO Batch Consumption Time: 0.10385
Total Iteration Time: 2.99191

Cumulative Model Updates: 5,552
Cumulative Timesteps: 92,679,686

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.48450
Policy Entropy: 0.62435
Value Function Loss: 5.72716

Mean KL Divergence: 0.00097
SB3 Clip Fraction: 0.00749
Policy Update Magnitude: 0.03540
Value Function Update Magnitude: 0.03407

Collected Steps per Second: 25,613.59658
Overall Steps per Second: 17,801.25183

Timestep Collection Time: 1.95310
Timestep Consumption Time: 0.85715
PPO Batch Consumption Time: 0.07771
Total Iteration Time: 2.81025

Cumulative Model Updates: 5,555
Cumulative Timesteps: 92,729,712

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 92729712...
Checkpoint 92729712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652.23981
Policy Entropy: 0.63329
Value Function Loss: 5.62190

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01496
Policy Update Magnitude: 0.03548
Value Function Update Magnitude: 0.03822

Collected Steps per Second: 24,536.13366
Overall Steps per Second: 17,579.79357

Timestep Collection Time: 2.03797
Timestep Consumption Time: 0.80643
PPO Batch Consumption Time: 0.06018
Total Iteration Time: 2.84440

Cumulative Model Updates: 5,558
Cumulative Timesteps: 92,779,716

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652.17637
Policy Entropy: 0.62628
Value Function Loss: 5.51532

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01523
Policy Update Magnitude: 0.03622
Value Function Update Magnitude: 0.03985

Collected Steps per Second: 21,823.53847
Overall Steps per Second: 15,140.13111

Timestep Collection Time: 2.29220
Timestep Consumption Time: 1.01186
PPO Batch Consumption Time: 0.12440
Total Iteration Time: 3.30407

Cumulative Model Updates: 5,561
Cumulative Timesteps: 92,829,740

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 92829740...
Checkpoint 92829740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646.62538
Policy Entropy: 0.63139
Value Function Loss: 5.30997

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01762
Policy Update Magnitude: 0.03668
Value Function Update Magnitude: 0.04286

Collected Steps per Second: 24,565.25974
Overall Steps per Second: 16,748.18275

Timestep Collection Time: 2.03580
Timestep Consumption Time: 0.95019
PPO Batch Consumption Time: 0.11379
Total Iteration Time: 2.98600

Cumulative Model Updates: 5,564
Cumulative Timesteps: 92,879,750

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.06508
Policy Entropy: 0.62862
Value Function Loss: 5.21685

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.03317
Policy Update Magnitude: 0.03343
Value Function Update Magnitude: 0.03888

Collected Steps per Second: 24,738.85799
Overall Steps per Second: 17,757.23691

Timestep Collection Time: 2.02168
Timestep Consumption Time: 0.79486
PPO Batch Consumption Time: 0.07970
Total Iteration Time: 2.81654

Cumulative Model Updates: 5,567
Cumulative Timesteps: 92,929,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 92929764...
Checkpoint 92929764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.82559
Policy Entropy: 0.61732
Value Function Loss: 5.24626

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02177
Policy Update Magnitude: 0.03438
Value Function Update Magnitude: 0.03830

Collected Steps per Second: 24,330.08493
Overall Steps per Second: 17,568.44639

Timestep Collection Time: 2.05614
Timestep Consumption Time: 0.79135
PPO Batch Consumption Time: 0.06009
Total Iteration Time: 2.84749

Cumulative Model Updates: 5,570
Cumulative Timesteps: 92,979,790

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.85002
Policy Entropy: 0.60989
Value Function Loss: 5.29977

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01595
Policy Update Magnitude: 0.03174
Value Function Update Magnitude: 0.03633

Collected Steps per Second: 21,925.92385
Overall Steps per Second: 15,141.76631

Timestep Collection Time: 2.28141
Timestep Consumption Time: 1.02217
PPO Batch Consumption Time: 0.12657
Total Iteration Time: 3.30358

Cumulative Model Updates: 5,573
Cumulative Timesteps: 93,029,812

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 93029812...
Checkpoint 93029812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558.76550
Policy Entropy: 0.60754
Value Function Loss: 5.40352

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01443
Policy Update Magnitude: 0.03473
Value Function Update Magnitude: 0.03969

Collected Steps per Second: 24,544.49885
Overall Steps per Second: 16,752.01475

Timestep Collection Time: 2.03793
Timestep Consumption Time: 0.94798
PPO Batch Consumption Time: 0.10739
Total Iteration Time: 2.98591

Cumulative Model Updates: 5,576
Cumulative Timesteps: 93,079,832

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.40636
Policy Entropy: 0.60194
Value Function Loss: 5.35370

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.01975
Policy Update Magnitude: 0.03446
Value Function Update Magnitude: 0.04997

Collected Steps per Second: 24,470.90976
Overall Steps per Second: 16,723.96545

Timestep Collection Time: 2.04439
Timestep Consumption Time: 0.94701
PPO Batch Consumption Time: 0.11550
Total Iteration Time: 2.99140

Cumulative Model Updates: 5,579
Cumulative Timesteps: 93,129,860

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 93129860...
Checkpoint 93129860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659.43127
Policy Entropy: 0.60603
Value Function Loss: 5.36934

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01826
Policy Update Magnitude: 0.03221
Value Function Update Magnitude: 0.04592

Collected Steps per Second: 24,521.49043
Overall Steps per Second: 17,646.42228

Timestep Collection Time: 2.03960
Timestep Consumption Time: 0.79463
PPO Batch Consumption Time: 0.08004
Total Iteration Time: 2.83423

Cumulative Model Updates: 5,582
Cumulative Timesteps: 93,179,874

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.36723
Policy Entropy: 0.60284
Value Function Loss: 5.34537

Mean KL Divergence: 0.00132
SB3 Clip Fraction: 0.01255
Policy Update Magnitude: 0.03653
Value Function Update Magnitude: 0.03774

Collected Steps per Second: 23,308.39694
Overall Steps per Second: 15,916.73216

Timestep Collection Time: 2.14558
Timestep Consumption Time: 0.99640
PPO Batch Consumption Time: 0.12134
Total Iteration Time: 3.14198

Cumulative Model Updates: 5,585
Cumulative Timesteps: 93,229,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 93229884...
Checkpoint 93229884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572.27884
Policy Entropy: 0.61135
Value Function Loss: 5.37841

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01709
Policy Update Magnitude: 0.03922
Value Function Update Magnitude: 0.03734

Collected Steps per Second: 24,070.73003
Overall Steps per Second: 16,660.07691

Timestep Collection Time: 2.07804
Timestep Consumption Time: 0.92434
PPO Batch Consumption Time: 0.09182
Total Iteration Time: 3.00239

Cumulative Model Updates: 5,588
Cumulative Timesteps: 93,279,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617.74796
Policy Entropy: 0.61188
Value Function Loss: 5.46667

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.02253
Policy Update Magnitude: 0.03465
Value Function Update Magnitude: 0.03802

Collected Steps per Second: 23,746.72590
Overall Steps per Second: 16,673.98643

Timestep Collection Time: 2.10623
Timestep Consumption Time: 0.89342
PPO Batch Consumption Time: 0.08458
Total Iteration Time: 2.99964

Cumulative Model Updates: 5,591
Cumulative Timesteps: 93,329,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 93329920...
Checkpoint 93329920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525.55401
Policy Entropy: 0.59925
Value Function Loss: 5.53622

Mean KL Divergence: 0.00155
SB3 Clip Fraction: 0.01587
Policy Update Magnitude: 0.03597
Value Function Update Magnitude: 0.03604

Collected Steps per Second: 23,006.81071
Overall Steps per Second: 15,867.38270

Timestep Collection Time: 2.17327
Timestep Consumption Time: 0.97785
PPO Batch Consumption Time: 0.12769
Total Iteration Time: 3.15112

Cumulative Model Updates: 5,594
Cumulative Timesteps: 93,379,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641.36184
Policy Entropy: 0.60650
Value Function Loss: 5.48530

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01635
Policy Update Magnitude: 0.03473
Value Function Update Magnitude: 0.04080

Collected Steps per Second: 24,453.31313
Overall Steps per Second: 18,144.54226

Timestep Collection Time: 2.04545
Timestep Consumption Time: 0.71119
PPO Batch Consumption Time: 0.05791
Total Iteration Time: 2.75664

Cumulative Model Updates: 5,597
Cumulative Timesteps: 93,429,938

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 93429938...
Checkpoint 93429938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.61486
Policy Entropy: 0.59435
Value Function Loss: 5.41204

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01888
Policy Update Magnitude: 0.03753
Value Function Update Magnitude: 0.05604

Collected Steps per Second: 24,402.67209
Overall Steps per Second: 17,615.25765

Timestep Collection Time: 2.05002
Timestep Consumption Time: 0.78990
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 2.83992

Cumulative Model Updates: 5,600
Cumulative Timesteps: 93,479,964

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 946.76193
Policy Entropy: 0.60552
Value Function Loss: 5.42277

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01969
Policy Update Magnitude: 0.03652
Value Function Update Magnitude: 0.04895

Collected Steps per Second: 21,707.96720
Overall Steps per Second: 15,622.60027

Timestep Collection Time: 2.30358
Timestep Consumption Time: 0.89730
PPO Batch Consumption Time: 0.08497
Total Iteration Time: 3.20088

Cumulative Model Updates: 5,603
Cumulative Timesteps: 93,529,970

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 93529970...
Checkpoint 93529970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637.93055
Policy Entropy: 0.58488
Value Function Loss: 5.45778

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03325
Policy Update Magnitude: 0.03482
Value Function Update Magnitude: 0.03789

Collected Steps per Second: 24,165.13937
Overall Steps per Second: 16,783.68992

Timestep Collection Time: 2.06951
Timestep Consumption Time: 0.91017
PPO Batch Consumption Time: 0.09503
Total Iteration Time: 2.97968

Cumulative Model Updates: 5,606
Cumulative Timesteps: 93,579,980

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.48247
Policy Entropy: 0.59796
Value Function Loss: 5.49186

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.01467
Policy Update Magnitude: 0.03541
Value Function Update Magnitude: 0.03624

Collected Steps per Second: 24,626.33959
Overall Steps per Second: 17,645.05698

Timestep Collection Time: 2.03091
Timestep Consumption Time: 0.80353
PPO Batch Consumption Time: 0.07854
Total Iteration Time: 2.83445

Cumulative Model Updates: 5,609
Cumulative Timesteps: 93,629,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 93629994...
Checkpoint 93629994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546.36043
Policy Entropy: 0.59468
Value Function Loss: 5.39934

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01351
Policy Update Magnitude: 0.03853
Value Function Update Magnitude: 0.03052

Collected Steps per Second: 23,178.46402
Overall Steps per Second: 16,019.10992

Timestep Collection Time: 2.15761
Timestep Consumption Time: 0.96429
PPO Batch Consumption Time: 0.11256
Total Iteration Time: 3.12190

Cumulative Model Updates: 5,612
Cumulative Timesteps: 93,680,004

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.27112
Policy Entropy: 0.59569
Value Function Loss: 5.28332

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.02001
Policy Update Magnitude: 0.03774
Value Function Update Magnitude: 0.03179

Collected Steps per Second: 24,773.79879
Overall Steps per Second: 16,703.10418

Timestep Collection Time: 2.01899
Timestep Consumption Time: 0.97555
PPO Batch Consumption Time: 0.11898
Total Iteration Time: 2.99453

Cumulative Model Updates: 5,615
Cumulative Timesteps: 93,730,022

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 93730022...
Checkpoint 93730022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508.02430
Policy Entropy: 0.59139
Value Function Loss: 5.06803

Mean KL Divergence: 0.00105
SB3 Clip Fraction: 0.00845
Policy Update Magnitude: 0.03727
Value Function Update Magnitude: 0.03310

Collected Steps per Second: 24,430.83833
Overall Steps per Second: 16,761.87837

Timestep Collection Time: 2.04774
Timestep Consumption Time: 0.93689
PPO Batch Consumption Time: 0.10858
Total Iteration Time: 2.98463

Cumulative Model Updates: 5,618
Cumulative Timesteps: 93,780,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.01290
Policy Entropy: 0.58928
Value Function Loss: 5.10350

Mean KL Divergence: 0.00116
SB3 Clip Fraction: 0.01024
Policy Update Magnitude: 0.03978
Value Function Update Magnitude: 0.03521

Collected Steps per Second: 24,837.71769
Overall Steps per Second: 16,725.17199

Timestep Collection Time: 2.01339
Timestep Consumption Time: 0.97659
PPO Batch Consumption Time: 0.12234
Total Iteration Time: 2.98998

Cumulative Model Updates: 5,621
Cumulative Timesteps: 93,830,058

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 93830058...
Checkpoint 93830058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.16075
Policy Entropy: 0.59446
Value Function Loss: 5.08814

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01553
Policy Update Magnitude: 0.04035
Value Function Update Magnitude: 0.03454

Collected Steps per Second: 24,808.07960
Overall Steps per Second: 17,812.55931

Timestep Collection Time: 2.01628
Timestep Consumption Time: 0.79185
PPO Batch Consumption Time: 0.08197
Total Iteration Time: 2.80813

Cumulative Model Updates: 5,624
Cumulative Timesteps: 93,880,078

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.54700
Policy Entropy: 0.60474
Value Function Loss: 5.15542

Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.01302
Policy Update Magnitude: 0.03608
Value Function Update Magnitude: 0.04003

Collected Steps per Second: 24,529.43959
Overall Steps per Second: 17,553.62513

Timestep Collection Time: 2.03886
Timestep Consumption Time: 0.81024
PPO Batch Consumption Time: 0.06252
Total Iteration Time: 2.84910

Cumulative Model Updates: 5,627
Cumulative Timesteps: 93,930,090

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 93930090...
Checkpoint 93930090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648.22650
Policy Entropy: 0.60303
Value Function Loss: 5.08282

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.01108
Policy Update Magnitude: 0.03657
Value Function Update Magnitude: 0.05147

Collected Steps per Second: 21,206.66168
Overall Steps per Second: 15,063.09104

Timestep Collection Time: 2.35784
Timestep Consumption Time: 0.96166
PPO Batch Consumption Time: 0.10721
Total Iteration Time: 3.31950

Cumulative Model Updates: 5,630
Cumulative Timesteps: 93,980,092

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639.38929
Policy Entropy: 0.59587
Value Function Loss: 5.25897

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01341
Policy Update Magnitude: 0.04166
Value Function Update Magnitude: 0.05000

Collected Steps per Second: 24,752.25605
Overall Steps per Second: 16,814.17494

Timestep Collection Time: 2.02131
Timestep Consumption Time: 0.95427
PPO Batch Consumption Time: 0.11586
Total Iteration Time: 2.97558

Cumulative Model Updates: 5,633
Cumulative Timesteps: 94,030,124

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 94030124...
Checkpoint 94030124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534.86091
Policy Entropy: 0.58470
Value Function Loss: 5.43898

Mean KL Divergence: 0.00153
SB3 Clip Fraction: 0.01652
Policy Update Magnitude: 0.04146
Value Function Update Magnitude: 0.04159

Collected Steps per Second: 24,090.73148
Overall Steps per Second: 16,674.97748

Timestep Collection Time: 2.07549
Timestep Consumption Time: 0.92302
PPO Batch Consumption Time: 0.10475
Total Iteration Time: 2.99850

Cumulative Model Updates: 5,636
Cumulative Timesteps: 94,080,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603.97933
Policy Entropy: 0.58394
Value Function Loss: 5.59241

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01601
Policy Update Magnitude: 0.03806
Value Function Update Magnitude: 0.03630

Collected Steps per Second: 25,883.45859
Overall Steps per Second: 17,836.66355

Timestep Collection Time: 1.93189
Timestep Consumption Time: 0.87155
PPO Batch Consumption Time: 0.08295
Total Iteration Time: 2.80344

Cumulative Model Updates: 5,639
Cumulative Timesteps: 94,130,128

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 94130128...
Checkpoint 94130128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679.42987
Policy Entropy: 0.58973
Value Function Loss: 5.52096

Mean KL Divergence: 0.00090
SB3 Clip Fraction: 0.00723
Policy Update Magnitude: 0.03720
Value Function Update Magnitude: 0.03681

Collected Steps per Second: 24,620.96957
Overall Steps per Second: 17,651.65370

Timestep Collection Time: 2.03095
Timestep Consumption Time: 0.80187
PPO Batch Consumption Time: 0.06021
Total Iteration Time: 2.83282

Cumulative Model Updates: 5,642
Cumulative Timesteps: 94,180,132

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 751.01792
Policy Entropy: 0.59867
Value Function Loss: 5.42610

Mean KL Divergence: 0.00103
SB3 Clip Fraction: 0.00805
Policy Update Magnitude: 0.03962
Value Function Update Magnitude: 0.03584

Collected Steps per Second: 21,761.24798
Overall Steps per Second: 15,067.50797

Timestep Collection Time: 2.29849
Timestep Consumption Time: 1.02110
PPO Batch Consumption Time: 0.12392
Total Iteration Time: 3.31959

Cumulative Model Updates: 5,645
Cumulative Timesteps: 94,230,150

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 94230150...
Checkpoint 94230150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.87066
Policy Entropy: 0.59849
Value Function Loss: 5.40193

Mean KL Divergence: 0.00125
SB3 Clip Fraction: 0.01097
Policy Update Magnitude: 0.03616
Value Function Update Magnitude: 0.03167

Collected Steps per Second: 24,290.26090
Overall Steps per Second: 16,743.79318

Timestep Collection Time: 2.05918
Timestep Consumption Time: 0.92808
PPO Batch Consumption Time: 0.11155
Total Iteration Time: 2.98726

Cumulative Model Updates: 5,648
Cumulative Timesteps: 94,280,168

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 771.76328
Policy Entropy: 0.60084
Value Function Loss: 5.42728

Mean KL Divergence: 0.00144
SB3 Clip Fraction: 0.01401
Policy Update Magnitude: 0.03670
Value Function Update Magnitude: 0.03871

Collected Steps per Second: 24,889.83896
Overall Steps per Second: 17,783.12247

Timestep Collection Time: 2.01006
Timestep Consumption Time: 0.80328
PPO Batch Consumption Time: 0.08134
Total Iteration Time: 2.81334

Cumulative Model Updates: 5,651
Cumulative Timesteps: 94,330,198

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 94330198...
Checkpoint 94330198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607.94253
Policy Entropy: 0.59825
Value Function Loss: 5.37515

Mean KL Divergence: 0.00132
SB3 Clip Fraction: 0.01341
Policy Update Magnitude: 0.03741
Value Function Update Magnitude: 0.03940

Collected Steps per Second: 24,737.40495
Overall Steps per Second: 17,820.26163

Timestep Collection Time: 2.02188
Timestep Consumption Time: 0.78482
PPO Batch Consumption Time: 0.05807
Total Iteration Time: 2.80669

Cumulative Model Updates: 5,654
Cumulative Timesteps: 94,380,214

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.55637
Policy Entropy: 0.58225
Value Function Loss: 5.43075

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.02133
Policy Update Magnitude: 0.03575
Value Function Update Magnitude: 0.03728

Collected Steps per Second: 21,608.76434
Overall Steps per Second: 15,737.12598

Timestep Collection Time: 2.31397
Timestep Consumption Time: 0.86336
PPO Batch Consumption Time: 0.07552
Total Iteration Time: 3.17733

Cumulative Model Updates: 5,657
Cumulative Timesteps: 94,430,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 94430216...
Checkpoint 94430216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.41180
Policy Entropy: 0.57917
Value Function Loss: 5.42254

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01730
Policy Update Magnitude: 0.03558
Value Function Update Magnitude: 0.02690

Collected Steps per Second: 23,909.68536
Overall Steps per Second: 17,302.91766

Timestep Collection Time: 2.09162
Timestep Consumption Time: 0.79864
PPO Batch Consumption Time: 0.05959
Total Iteration Time: 2.89026

Cumulative Model Updates: 5,660
Cumulative Timesteps: 94,480,226

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.27687
Policy Entropy: 0.57499
Value Function Loss: 5.48622

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01697
Policy Update Magnitude: 0.03794
Value Function Update Magnitude: 0.02455

Collected Steps per Second: 24,108.42970
Overall Steps per Second: 16,373.68195

Timestep Collection Time: 2.07430
Timestep Consumption Time: 0.97987
PPO Batch Consumption Time: 0.12121
Total Iteration Time: 3.05417

Cumulative Model Updates: 5,663
Cumulative Timesteps: 94,530,234

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 94530234...
Checkpoint 94530234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453.28721
Policy Entropy: 0.57760
Value Function Loss: 5.59050

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01648
Policy Update Magnitude: 0.03438
Value Function Update Magnitude: 0.02170

Collected Steps per Second: 24,685.48973
Overall Steps per Second: 18,213.83528

Timestep Collection Time: 2.02637
Timestep Consumption Time: 0.72000
PPO Batch Consumption Time: 0.05849
Total Iteration Time: 2.74637

Cumulative Model Updates: 5,666
Cumulative Timesteps: 94,580,256

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.29897
Policy Entropy: 0.57762
Value Function Loss: 5.53107

Mean KL Divergence: 0.00126
SB3 Clip Fraction: 0.01191
Policy Update Magnitude: 0.03468
Value Function Update Magnitude: 0.02417

Collected Steps per Second: 24,877.70188
Overall Steps per Second: 17,801.88982

Timestep Collection Time: 2.01039
Timestep Consumption Time: 0.79908
PPO Batch Consumption Time: 0.06400
Total Iteration Time: 2.80948

Cumulative Model Updates: 5,669
Cumulative Timesteps: 94,630,270

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 94630270...
Checkpoint 94630270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 845.83736
Policy Entropy: 0.57950
Value Function Loss: 5.40882

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02936
Policy Update Magnitude: 0.03726
Value Function Update Magnitude: 0.02993

Collected Steps per Second: 24,535.78813
Overall Steps per Second: 16,628.38896

Timestep Collection Time: 2.03800
Timestep Consumption Time: 0.96914
PPO Batch Consumption Time: 0.11452
Total Iteration Time: 3.00715

Cumulative Model Updates: 5,672
Cumulative Timesteps: 94,680,274

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.04547
Policy Entropy: 0.56735
Value Function Loss: 5.22293

Mean KL Divergence: 0.00139
SB3 Clip Fraction: 0.01318
Policy Update Magnitude: 0.03180
Value Function Update Magnitude: 0.02945

Collected Steps per Second: 24,595.18660
Overall Steps per Second: 16,722.58915

Timestep Collection Time: 2.03389
Timestep Consumption Time: 0.95751
PPO Batch Consumption Time: 0.12102
Total Iteration Time: 2.99140

Cumulative Model Updates: 5,675
Cumulative Timesteps: 94,730,298

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 94730298...
Checkpoint 94730298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631.07720
Policy Entropy: 0.57768
Value Function Loss: 5.22626

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.00879
Policy Update Magnitude: 0.03666
Value Function Update Magnitude: 0.02828

Collected Steps per Second: 24,211.72676
Overall Steps per Second: 17,603.42726

Timestep Collection Time: 2.06520
Timestep Consumption Time: 0.77527
PPO Batch Consumption Time: 0.07799
Total Iteration Time: 2.84047

Cumulative Model Updates: 5,678
Cumulative Timesteps: 94,780,300

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.57381
Policy Entropy: 0.57348
Value Function Loss: 5.34424

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01459
Policy Update Magnitude: 0.03743
Value Function Update Magnitude: 0.03116

Collected Steps per Second: 23,362.24071
Overall Steps per Second: 15,949.91309

Timestep Collection Time: 2.14158
Timestep Consumption Time: 0.99524
PPO Batch Consumption Time: 0.12497
Total Iteration Time: 3.13682

Cumulative Model Updates: 5,681
Cumulative Timesteps: 94,830,332

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 94830332...
Checkpoint 94830332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681.92713
Policy Entropy: 0.57260
Value Function Loss: 5.30357

Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.01487
Policy Update Magnitude: 0.03769
Value Function Update Magnitude: 0.03224

Collected Steps per Second: 24,304.17854
Overall Steps per Second: 16,708.83250

Timestep Collection Time: 2.05734
Timestep Consumption Time: 0.93521
PPO Batch Consumption Time: 0.10441
Total Iteration Time: 2.99255

Cumulative Model Updates: 5,684
Cumulative Timesteps: 94,880,334

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.56685
Policy Entropy: 0.57324
Value Function Loss: 5.32957

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01814
Policy Update Magnitude: 0.03595
Value Function Update Magnitude: 0.03029

Collected Steps per Second: 24,517.04428
Overall Steps per Second: 16,737.40500

Timestep Collection Time: 2.03956
Timestep Consumption Time: 0.94800
PPO Batch Consumption Time: 0.11547
Total Iteration Time: 2.98756

Cumulative Model Updates: 5,687
Cumulative Timesteps: 94,930,338

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 94930338...
Checkpoint 94930338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 776.19597
Policy Entropy: 0.57408
Value Function Loss: 5.35663

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01568
Policy Update Magnitude: 0.03327
Value Function Update Magnitude: 0.03141

Collected Steps per Second: 24,298.94512
Overall Steps per Second: 16,750.45634

Timestep Collection Time: 2.05877
Timestep Consumption Time: 0.92777
PPO Batch Consumption Time: 0.10905
Total Iteration Time: 2.98655

Cumulative Model Updates: 5,690
Cumulative Timesteps: 94,980,364

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.76169
Policy Entropy: 0.56637
Value Function Loss: 5.42693

Mean KL Divergence: 0.00121
SB3 Clip Fraction: 0.01023
Policy Update Magnitude: 0.03443
Value Function Update Magnitude: 0.03350

Collected Steps per Second: 24,689.88053
Overall Steps per Second: 17,775.99572

Timestep Collection Time: 2.02545
Timestep Consumption Time: 0.78779
PPO Batch Consumption Time: 0.08006
Total Iteration Time: 2.81323

Cumulative Model Updates: 5,693
Cumulative Timesteps: 95,030,372

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 95030372...
Checkpoint 95030372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.97603
Policy Entropy: 0.56932
Value Function Loss: 5.44794

Mean KL Divergence: 0.00108
SB3 Clip Fraction: 0.00972
Policy Update Magnitude: 0.03516
Value Function Update Magnitude: 0.03101

Collected Steps per Second: 24,409.01586
Overall Steps per Second: 17,560.46151

Timestep Collection Time: 2.04924
Timestep Consumption Time: 0.79920
PPO Batch Consumption Time: 0.06052
Total Iteration Time: 2.84844

Cumulative Model Updates: 5,696
Cumulative Timesteps: 95,080,392

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585.35749
Policy Entropy: 0.56574
Value Function Loss: 5.44808

Mean KL Divergence: 0.00138
SB3 Clip Fraction: 0.01347
Policy Update Magnitude: 0.03764
Value Function Update Magnitude: 0.03318

Collected Steps per Second: 21,975.41109
Overall Steps per Second: 15,973.77720

Timestep Collection Time: 2.27618
Timestep Consumption Time: 0.85520
PPO Batch Consumption Time: 0.07740
Total Iteration Time: 3.13138

Cumulative Model Updates: 5,699
Cumulative Timesteps: 95,130,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 95130412...
Checkpoint 95130412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558.32811
Policy Entropy: 0.57000
Value Function Loss: 5.47012

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.02053
Policy Update Magnitude: 0.03296
Value Function Update Magnitude: 0.02908

Collected Steps per Second: 24,545.39047
Overall Steps per Second: 17,835.49889

Timestep Collection Time: 2.03729
Timestep Consumption Time: 0.76645
PPO Batch Consumption Time: 0.05749
Total Iteration Time: 2.80373

Cumulative Model Updates: 5,702
Cumulative Timesteps: 95,180,418

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.17434
Policy Entropy: 0.56159
Value Function Loss: 5.22041

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01768
Policy Update Magnitude: 0.03338
Value Function Update Magnitude: 0.02511

Collected Steps per Second: 21,794.76823
Overall Steps per Second: 15,772.81645

Timestep Collection Time: 2.29505
Timestep Consumption Time: 0.87623
PPO Batch Consumption Time: 0.08688
Total Iteration Time: 3.17128

Cumulative Model Updates: 5,705
Cumulative Timesteps: 95,230,438

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 95230438...
Checkpoint 95230438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.95404
Policy Entropy: 0.55907
Value Function Loss: 5.20170

Mean KL Divergence: 0.00126
SB3 Clip Fraction: 0.01098
Policy Update Magnitude: 0.03294
Value Function Update Magnitude: 0.02432

Collected Steps per Second: 23,899.95107
Overall Steps per Second: 17,789.29637

Timestep Collection Time: 2.09390
Timestep Consumption Time: 0.71926
PPO Batch Consumption Time: 0.05877
Total Iteration Time: 2.81315

Cumulative Model Updates: 5,708
Cumulative Timesteps: 95,280,482

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801.85147
Policy Entropy: 0.55780
Value Function Loss: 5.28866

Mean KL Divergence: 0.00133
SB3 Clip Fraction: 0.01217
Policy Update Magnitude: 0.03744
Value Function Update Magnitude: 0.02402

Collected Steps per Second: 21,332.40775
Overall Steps per Second: 14,968.37630

Timestep Collection Time: 2.34404
Timestep Consumption Time: 0.99660
PPO Batch Consumption Time: 0.12417
Total Iteration Time: 3.34064

Cumulative Model Updates: 5,711
Cumulative Timesteps: 95,330,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 95330486...
Checkpoint 95330486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678.03638
Policy Entropy: 0.56142
Value Function Loss: 5.34278

Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.01239
Policy Update Magnitude: 0.03728
Value Function Update Magnitude: 0.02713

Collected Steps per Second: 24,693.16376
Overall Steps per Second: 16,749.82627

Timestep Collection Time: 2.02509
Timestep Consumption Time: 0.96037
PPO Batch Consumption Time: 0.11162
Total Iteration Time: 2.98546

Cumulative Model Updates: 5,714
Cumulative Timesteps: 95,380,492

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.36632
Policy Entropy: 0.55648
Value Function Loss: 5.34094

Mean KL Divergence: 0.00106
SB3 Clip Fraction: 0.00813
Policy Update Magnitude: 0.03816
Value Function Update Magnitude: 0.03095

Collected Steps per Second: 24,692.16736
Overall Steps per Second: 16,734.23927

Timestep Collection Time: 2.02574
Timestep Consumption Time: 0.96334
PPO Batch Consumption Time: 0.12063
Total Iteration Time: 2.98908

Cumulative Model Updates: 5,717
Cumulative Timesteps: 95,430,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 95430512...
Checkpoint 95430512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.21484
Policy Entropy: 0.56373
Value Function Loss: 5.36586

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01416
Policy Update Magnitude: 0.03827
Value Function Update Magnitude: 0.02518

Collected Steps per Second: 24,625.91996
Overall Steps per Second: 17,790.45850

Timestep Collection Time: 2.03038
Timestep Consumption Time: 0.78011
PPO Batch Consumption Time: 0.07648
Total Iteration Time: 2.81050

Cumulative Model Updates: 5,720
Cumulative Timesteps: 95,480,512

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693.28892
Policy Entropy: 0.56145
Value Function Loss: 5.32289

Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.01065
Policy Update Magnitude: 0.03763
Value Function Update Magnitude: 0.02527

Collected Steps per Second: 24,345.75470
Overall Steps per Second: 17,503.78999

Timestep Collection Time: 2.05399
Timestep Consumption Time: 0.80287
PPO Batch Consumption Time: 0.05876
Total Iteration Time: 2.85687

Cumulative Model Updates: 5,723
Cumulative Timesteps: 95,530,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 95530518...
Checkpoint 95530518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559.34014
Policy Entropy: 0.56980
Value Function Loss: 5.44752

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.02047
Policy Update Magnitude: 0.03695
Value Function Update Magnitude: 0.02492

Collected Steps per Second: 21,248.11567
Overall Steps per Second: 15,112.96777

Timestep Collection Time: 2.35409
Timestep Consumption Time: 0.95565
PPO Batch Consumption Time: 0.10232
Total Iteration Time: 3.30974

Cumulative Model Updates: 5,726
Cumulative Timesteps: 95,580,538

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652.04571
Policy Entropy: 0.56150
Value Function Loss: 5.28988

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01889
Policy Update Magnitude: 0.03527
Value Function Update Magnitude: 0.02393

Collected Steps per Second: 24,754.66386
Overall Steps per Second: 16,784.47836

Timestep Collection Time: 2.01990
Timestep Consumption Time: 0.95916
PPO Batch Consumption Time: 0.10598
Total Iteration Time: 2.97906

Cumulative Model Updates: 5,729
Cumulative Timesteps: 95,630,540

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 95630540...
Checkpoint 95630540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698.29688
Policy Entropy: 0.55990
Value Function Loss: 5.43036

Mean KL Divergence: 0.00123
SB3 Clip Fraction: 0.01269
Policy Update Magnitude: 0.03308
Value Function Update Magnitude: 0.02646

Collected Steps per Second: 24,328.25538
Overall Steps per Second: 16,769.84997

Timestep Collection Time: 2.05605
Timestep Consumption Time: 0.92669
PPO Batch Consumption Time: 0.10581
Total Iteration Time: 2.98273

Cumulative Model Updates: 5,732
Cumulative Timesteps: 95,680,560

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.15969
Policy Entropy: 0.57527
Value Function Loss: 5.29342

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02344
Policy Update Magnitude: 0.03247
Value Function Update Magnitude: 0.02630

Collected Steps per Second: 24,843.91977
Overall Steps per Second: 17,764.51346

Timestep Collection Time: 2.01369
Timestep Consumption Time: 0.80248
PPO Batch Consumption Time: 0.08125
Total Iteration Time: 2.81618

Cumulative Model Updates: 5,735
Cumulative Timesteps: 95,730,588

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 95730588...
Checkpoint 95730588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.99764
Policy Entropy: 0.56789
Value Function Loss: 5.31166

Mean KL Divergence: 0.00139
SB3 Clip Fraction: 0.01367
Policy Update Magnitude: 0.02942
Value Function Update Magnitude: 0.02331

Collected Steps per Second: 24,388.54551
Overall Steps per Second: 17,580.93826

Timestep Collection Time: 2.05072
Timestep Consumption Time: 0.79407
PPO Batch Consumption Time: 0.06038
Total Iteration Time: 2.84479

Cumulative Model Updates: 5,738
Cumulative Timesteps: 95,780,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.27627
Policy Entropy: 0.57084
Value Function Loss: 5.16181

Mean KL Divergence: 0.00133
SB3 Clip Fraction: 0.01379
Policy Update Magnitude: 0.03417
Value Function Update Magnitude: 0.04044

Collected Steps per Second: 21,690.46412
Overall Steps per Second: 15,111.65420

Timestep Collection Time: 2.30590
Timestep Consumption Time: 1.00387
PPO Batch Consumption Time: 0.12426
Total Iteration Time: 3.30976

Cumulative Model Updates: 5,741
Cumulative Timesteps: 95,830,618

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 95830618...
Checkpoint 95830618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 899.22504
Policy Entropy: 0.56519
Value Function Loss: 5.17811

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01869
Policy Update Magnitude: 0.03323
Value Function Update Magnitude: 0.04799

Collected Steps per Second: 24,513.84878
Overall Steps per Second: 16,754.22991

Timestep Collection Time: 2.04023
Timestep Consumption Time: 0.94492
PPO Batch Consumption Time: 0.11124
Total Iteration Time: 2.98516

Cumulative Model Updates: 5,744
Cumulative Timesteps: 95,880,632

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.72263
Policy Entropy: 0.56456
Value Function Loss: 5.22817

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.02093
Policy Update Magnitude: 0.03428
Value Function Update Magnitude: 0.04571

Collected Steps per Second: 24,981.53853
Overall Steps per Second: 17,789.63216

Timestep Collection Time: 2.00228
Timestep Consumption Time: 0.80947
PPO Batch Consumption Time: 0.08860
Total Iteration Time: 2.81175

Cumulative Model Updates: 5,747
Cumulative Timesteps: 95,930,652

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 95930652...
Checkpoint 95930652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680.80102
Policy Entropy: 0.57408
Value Function Loss: 5.40911

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02738
Policy Update Magnitude: 0.03561
Value Function Update Magnitude: 0.03804

Collected Steps per Second: 24,684.69182
Overall Steps per Second: 17,856.93504

Timestep Collection Time: 2.02644
Timestep Consumption Time: 0.77483
PPO Batch Consumption Time: 0.05782
Total Iteration Time: 2.80126

Cumulative Model Updates: 5,750
Cumulative Timesteps: 95,980,674

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639.14266
Policy Entropy: 0.55978
Value Function Loss: 5.43098

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03941
Policy Update Magnitude: 0.03111
Value Function Update Magnitude: 0.03179

Collected Steps per Second: 22,249.10404
Overall Steps per Second: 15,769.73265

Timestep Collection Time: 2.24836
Timestep Consumption Time: 0.92379
PPO Batch Consumption Time: 0.09985
Total Iteration Time: 3.17215

Cumulative Model Updates: 5,753
Cumulative Timesteps: 96,030,698

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 96030698...
Checkpoint 96030698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 899.87829
Policy Entropy: 0.56441
Value Function Loss: 5.42885

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.04295
Policy Update Magnitude: 0.02727
Value Function Update Magnitude: 0.02626

Collected Steps per Second: 24,647.75790
Overall Steps per Second: 17,633.83192

Timestep Collection Time: 2.02956
Timestep Consumption Time: 0.80726
PPO Batch Consumption Time: 0.05967
Total Iteration Time: 2.83682

Cumulative Model Updates: 5,756
Cumulative Timesteps: 96,080,722

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 892.73769
Policy Entropy: 0.54924
Value Function Loss: 5.38958

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04661
Policy Update Magnitude: 0.02735
Value Function Update Magnitude: 0.02917

Collected Steps per Second: 21,702.22692
Overall Steps per Second: 15,870.42905

Timestep Collection Time: 2.30419
Timestep Consumption Time: 0.84670
PPO Batch Consumption Time: 0.07724
Total Iteration Time: 3.15089

Cumulative Model Updates: 5,759
Cumulative Timesteps: 96,130,728

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 96130728...
Checkpoint 96130728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 783.19621
Policy Entropy: 0.54121
Value Function Loss: 5.45480

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04747
Policy Update Magnitude: 0.02261
Value Function Update Magnitude: 0.02951

Collected Steps per Second: 24,192.00207
Overall Steps per Second: 17,915.94119

Timestep Collection Time: 2.06787
Timestep Consumption Time: 0.72439
PPO Batch Consumption Time: 0.05816
Total Iteration Time: 2.79226

Cumulative Model Updates: 5,762
Cumulative Timesteps: 96,180,754

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.85095
Policy Entropy: 0.54626
Value Function Loss: 5.48960

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03617
Policy Update Magnitude: 0.01979
Value Function Update Magnitude: 0.02440

Collected Steps per Second: 21,307.16125
Overall Steps per Second: 14,908.75296

Timestep Collection Time: 2.34766
Timestep Consumption Time: 1.00755
PPO Batch Consumption Time: 0.12633
Total Iteration Time: 3.35521

Cumulative Model Updates: 5,765
Cumulative Timesteps: 96,230,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 96230776...
Checkpoint 96230776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623.41937
Policy Entropy: 0.54338
Value Function Loss: 5.48922

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01975
Policy Update Magnitude: 0.02124
Value Function Update Magnitude: 0.03117

Collected Steps per Second: 24,384.19287
Overall Steps per Second: 16,695.89984

Timestep Collection Time: 2.05166
Timestep Consumption Time: 0.94477
PPO Batch Consumption Time: 0.10466
Total Iteration Time: 2.99642

Cumulative Model Updates: 5,768
Cumulative Timesteps: 96,280,804

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565.28678
Policy Entropy: 0.53895
Value Function Loss: 5.47782

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.01256
Policy Update Magnitude: 0.02678
Value Function Update Magnitude: 0.03311

Collected Steps per Second: 24,614.64601
Overall Steps per Second: 16,771.38504

Timestep Collection Time: 2.03294
Timestep Consumption Time: 0.95072
PPO Batch Consumption Time: 0.10554
Total Iteration Time: 2.98365

Cumulative Model Updates: 5,771
Cumulative Timesteps: 96,330,844

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 96330844...
Checkpoint 96330844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632.43718
Policy Entropy: 0.53779
Value Function Loss: 5.23238

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01325
Policy Update Magnitude: 0.02687
Value Function Update Magnitude: 0.03176

Collected Steps per Second: 24,558.24909
Overall Steps per Second: 16,776.83045

Timestep Collection Time: 2.03646
Timestep Consumption Time: 0.94455
PPO Batch Consumption Time: 0.11207
Total Iteration Time: 2.98102

Cumulative Model Updates: 5,774
Cumulative Timesteps: 96,380,856

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 872.07988
Policy Entropy: 0.54349
Value Function Loss: 5.23372

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.01529
Policy Update Magnitude: 0.02766
Value Function Update Magnitude: 0.03735

Collected Steps per Second: 24,707.08977
Overall Steps per Second: 17,756.53928

Timestep Collection Time: 2.02484
Timestep Consumption Time: 0.79260
PPO Batch Consumption Time: 0.08014
Total Iteration Time: 2.81744

Cumulative Model Updates: 5,777
Cumulative Timesteps: 96,430,884

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 96430884...
Checkpoint 96430884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669.56726
Policy Entropy: 0.55346
Value Function Loss: 5.13727

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.02073
Policy Update Magnitude: 0.02928
Value Function Update Magnitude: 0.04234

Collected Steps per Second: 24,435.53528
Overall Steps per Second: 17,628.86357

Timestep Collection Time: 2.04686
Timestep Consumption Time: 0.79031
PPO Batch Consumption Time: 0.05971
Total Iteration Time: 2.83717

Cumulative Model Updates: 5,780
Cumulative Timesteps: 96,480,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702.68367
Policy Entropy: 0.54808
Value Function Loss: 5.25964

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.02243
Policy Update Magnitude: 0.03116
Value Function Update Magnitude: 0.03893

Collected Steps per Second: 22,083.17088
Overall Steps per Second: 15,923.45081

Timestep Collection Time: 2.26525
Timestep Consumption Time: 0.87628
PPO Batch Consumption Time: 0.08360
Total Iteration Time: 3.14153

Cumulative Model Updates: 5,783
Cumulative Timesteps: 96,530,924

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 96530924...
Checkpoint 96530924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573.97380
Policy Entropy: 0.54600
Value Function Loss: 5.18652

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01547
Policy Update Magnitude: 0.03216
Value Function Update Magnitude: 0.03957

Collected Steps per Second: 23,703.48717
Overall Steps per Second: 17,139.79243

Timestep Collection Time: 2.10998
Timestep Consumption Time: 0.80802
PPO Batch Consumption Time: 0.05947
Total Iteration Time: 2.91800

Cumulative Model Updates: 5,786
Cumulative Timesteps: 96,580,938

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 798.86950
Policy Entropy: 0.54724
Value Function Loss: 5.22487

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01767
Policy Update Magnitude: 0.03104
Value Function Update Magnitude: 0.03799

Collected Steps per Second: 24,353.79006
Overall Steps per Second: 16,409.40841

Timestep Collection Time: 2.05331
Timestep Consumption Time: 0.99408
PPO Batch Consumption Time: 0.13274
Total Iteration Time: 3.04740

Cumulative Model Updates: 5,789
Cumulative Timesteps: 96,630,944

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 96630944...
Checkpoint 96630944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529.39059
Policy Entropy: 0.53907
Value Function Loss: 5.27978

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01171
Policy Update Magnitude: 0.03370
Value Function Update Magnitude: 0.04036

Collected Steps per Second: 24,415.14867
Overall Steps per Second: 18,113.29858

Timestep Collection Time: 2.04947
Timestep Consumption Time: 0.71304
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 2.76250

Cumulative Model Updates: 5,792
Cumulative Timesteps: 96,680,982

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.39397
Policy Entropy: 0.53824
Value Function Loss: 5.17310

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01599
Policy Update Magnitude: 0.03489
Value Function Update Magnitude: 0.03857

Collected Steps per Second: 22,625.59429
Overall Steps per Second: 15,624.75392

Timestep Collection Time: 2.20998
Timestep Consumption Time: 0.99020
PPO Batch Consumption Time: 0.11648
Total Iteration Time: 3.20018

Cumulative Model Updates: 5,795
Cumulative Timesteps: 96,730,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 96730984...
Checkpoint 96730984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565.34016
Policy Entropy: 0.54191
Value Function Loss: 5.16111

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.02173
Policy Update Magnitude: 0.03384
Value Function Update Magnitude: 0.03450

Collected Steps per Second: 24,144.93682
Overall Steps per Second: 17,491.91424

Timestep Collection Time: 2.07149
Timestep Consumption Time: 0.78789
PPO Batch Consumption Time: 0.06088
Total Iteration Time: 2.85938

Cumulative Model Updates: 5,798
Cumulative Timesteps: 96,781,000

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664.71619
Policy Entropy: 0.54709
Value Function Loss: 5.06549

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03237
Policy Update Magnitude: 0.03115
Value Function Update Magnitude: 0.03659

Collected Steps per Second: 21,987.36311
Overall Steps per Second: 15,900.78520

Timestep Collection Time: 2.27494
Timestep Consumption Time: 0.87081
PPO Batch Consumption Time: 0.07972
Total Iteration Time: 3.14576

Cumulative Model Updates: 5,801
Cumulative Timesteps: 96,831,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 96831020...
Checkpoint 96831020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656.99078
Policy Entropy: 0.54876
Value Function Loss: 5.01457

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02420
Policy Update Magnitude: 0.02881
Value Function Update Magnitude: 0.03456

Collected Steps per Second: 24,314.80050
Overall Steps per Second: 17,733.53473

Timestep Collection Time: 2.05743
Timestep Consumption Time: 0.76355
PPO Batch Consumption Time: 0.05933
Total Iteration Time: 2.82098

Cumulative Model Updates: 5,804
Cumulative Timesteps: 96,881,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.11945
Policy Entropy: 0.55005
Value Function Loss: 4.94648

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.03101
Policy Update Magnitude: 0.02852
Value Function Update Magnitude: 0.03553

Collected Steps per Second: 22,052.82926
Overall Steps per Second: 15,914.41989

Timestep Collection Time: 2.26810
Timestep Consumption Time: 0.87484
PPO Batch Consumption Time: 0.10735
Total Iteration Time: 3.14294

Cumulative Model Updates: 5,807
Cumulative Timesteps: 96,931,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 96931064...
Checkpoint 96931064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649.56541
Policy Entropy: 0.55128
Value Function Loss: 5.07075

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01715
Policy Update Magnitude: 0.03006
Value Function Update Magnitude: 0.03560

Collected Steps per Second: 24,886.55507
Overall Steps per Second: 17,882.03916

Timestep Collection Time: 2.01040
Timestep Consumption Time: 0.78749
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 2.79789

Cumulative Model Updates: 5,810
Cumulative Timesteps: 96,981,096

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.91310
Policy Entropy: 0.55645
Value Function Loss: 5.08577

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02177
Policy Update Magnitude: 0.03104
Value Function Update Magnitude: 0.04889

Collected Steps per Second: 21,947.09949
Overall Steps per Second: 15,697.23568

Timestep Collection Time: 2.27893
Timestep Consumption Time: 0.90736
PPO Batch Consumption Time: 0.09534
Total Iteration Time: 3.18629

Cumulative Model Updates: 5,813
Cumulative Timesteps: 97,031,112

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 97031112...
Checkpoint 97031112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 856.97519
Policy Entropy: 0.55463
Value Function Loss: 5.14630

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.02113
Policy Update Magnitude: 0.02710
Value Function Update Magnitude: 0.04485

Collected Steps per Second: 24,227.58002
Overall Steps per Second: 17,469.57098

Timestep Collection Time: 2.06492
Timestep Consumption Time: 0.79880
PPO Batch Consumption Time: 0.06045
Total Iteration Time: 2.86372

Cumulative Model Updates: 5,816
Cumulative Timesteps: 97,081,140

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.23454
Policy Entropy: 0.54904
Value Function Loss: 5.15908

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02181
Policy Update Magnitude: 0.02866
Value Function Update Magnitude: 0.04191

Collected Steps per Second: 21,347.94486
Overall Steps per Second: 15,189.67685

Timestep Collection Time: 2.34233
Timestep Consumption Time: 0.94964
PPO Batch Consumption Time: 0.11517
Total Iteration Time: 3.29197

Cumulative Model Updates: 5,819
Cumulative Timesteps: 97,131,144

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 97131144...
Checkpoint 97131144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 859.41327
Policy Entropy: 0.54885
Value Function Loss: 5.30227

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01764
Policy Update Magnitude: 0.03141
Value Function Update Magnitude: 0.03977

Collected Steps per Second: 24,251.06416
Overall Steps per Second: 16,794.22037

Timestep Collection Time: 2.06259
Timestep Consumption Time: 0.91582
PPO Batch Consumption Time: 0.12120
Total Iteration Time: 2.97841

Cumulative Model Updates: 5,822
Cumulative Timesteps: 97,181,164

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757.50687
Policy Entropy: 0.55142
Value Function Loss: 5.18340

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02673
Policy Update Magnitude: 0.03527
Value Function Update Magnitude: 0.03798

Collected Steps per Second: 25,183.86857
Overall Steps per Second: 17,589.12962

Timestep Collection Time: 1.98635
Timestep Consumption Time: 0.85768
PPO Batch Consumption Time: 0.07967
Total Iteration Time: 2.84403

Cumulative Model Updates: 5,825
Cumulative Timesteps: 97,231,188

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 97231188...
Checkpoint 97231188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583.83159
Policy Entropy: 0.55579
Value Function Loss: 4.96380

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03444
Policy Update Magnitude: 0.03337
Value Function Update Magnitude: 0.03629

Collected Steps per Second: 22,963.69012
Overall Steps per Second: 15,947.43985

Timestep Collection Time: 2.17744
Timestep Consumption Time: 0.95799
PPO Batch Consumption Time: 0.11004
Total Iteration Time: 3.13542

Cumulative Model Updates: 5,828
Cumulative Timesteps: 97,281,190

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 834.99759
Policy Entropy: 0.55714
Value Function Loss: 4.89652

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03298
Policy Update Magnitude: 0.02802
Value Function Update Magnitude: 0.04957

Collected Steps per Second: 24,740.42711
Overall Steps per Second: 16,697.69089

Timestep Collection Time: 2.02139
Timestep Consumption Time: 0.97364
PPO Batch Consumption Time: 0.11342
Total Iteration Time: 2.99502

Cumulative Model Updates: 5,831
Cumulative Timesteps: 97,331,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 97331200...
Checkpoint 97331200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633.41968
Policy Entropy: 0.55812
Value Function Loss: 5.05538

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02401
Policy Update Magnitude: 0.02605
Value Function Update Magnitude: 0.05360

Collected Steps per Second: 24,583.94380
Overall Steps per Second: 16,769.38274

Timestep Collection Time: 2.03491
Timestep Consumption Time: 0.94827
PPO Batch Consumption Time: 0.10429
Total Iteration Time: 2.98317

Cumulative Model Updates: 5,834
Cumulative Timesteps: 97,381,226

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648.62064
Policy Entropy: 0.55672
Value Function Loss: 5.03804

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01833
Policy Update Magnitude: 0.02765
Value Function Update Magnitude: 0.05302

Collected Steps per Second: 24,690.77886
Overall Steps per Second: 16,719.53886

Timestep Collection Time: 2.02505
Timestep Consumption Time: 0.96547
PPO Batch Consumption Time: 0.12113
Total Iteration Time: 2.99051

Cumulative Model Updates: 5,837
Cumulative Timesteps: 97,431,226

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 97431226...
Checkpoint 97431226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585.70676
Policy Entropy: 0.55960
Value Function Loss: 4.94403

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01689
Policy Update Magnitude: 0.03280
Value Function Update Magnitude: 0.05358

Collected Steps per Second: 24,525.24153
Overall Steps per Second: 17,794.09702

Timestep Collection Time: 2.03904
Timestep Consumption Time: 0.77133
PPO Batch Consumption Time: 0.07563
Total Iteration Time: 2.81037

Cumulative Model Updates: 5,840
Cumulative Timesteps: 97,481,234

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.68678
Policy Entropy: 0.55534
Value Function Loss: 4.88953

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02652
Policy Update Magnitude: 0.03256
Value Function Update Magnitude: 0.04735

Collected Steps per Second: 24,952.56403
Overall Steps per Second: 17,801.44976

Timestep Collection Time: 2.00412
Timestep Consumption Time: 0.80509
PPO Batch Consumption Time: 0.05917
Total Iteration Time: 2.80921

Cumulative Model Updates: 5,843
Cumulative Timesteps: 97,531,242

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 97531242...
Checkpoint 97531242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.91518
Policy Entropy: 0.55446
Value Function Loss: 4.97860

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03339
Policy Update Magnitude: 0.02985
Value Function Update Magnitude: 0.04193

Collected Steps per Second: 20,388.87111
Overall Steps per Second: 14,853.35123

Timestep Collection Time: 2.45251
Timestep Consumption Time: 0.91400
PPO Batch Consumption Time: 0.09347
Total Iteration Time: 3.36651

Cumulative Model Updates: 5,846
Cumulative Timesteps: 97,581,246

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.70745
Policy Entropy: 0.55387
Value Function Loss: 5.00881

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02961
Policy Update Magnitude: 0.02788
Value Function Update Magnitude: 0.03811

Collected Steps per Second: 24,143.64659
Overall Steps per Second: 16,788.11331

Timestep Collection Time: 2.07160
Timestep Consumption Time: 0.90765
PPO Batch Consumption Time: 0.10428
Total Iteration Time: 2.97925

Cumulative Model Updates: 5,849
Cumulative Timesteps: 97,631,262

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 97631262...
Checkpoint 97631262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684.60661
Policy Entropy: 0.55131
Value Function Loss: 5.00889

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.03403
Policy Update Magnitude: 0.02707
Value Function Update Magnitude: 0.03472

Collected Steps per Second: 24,277.05036
Overall Steps per Second: 17,514.81388

Timestep Collection Time: 2.06038
Timestep Consumption Time: 0.79549
PPO Batch Consumption Time: 0.08004
Total Iteration Time: 2.85587

Cumulative Model Updates: 5,852
Cumulative Timesteps: 97,681,282

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476.91299
Policy Entropy: 0.54122
Value Function Loss: 5.06608

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01851
Policy Update Magnitude: 0.02615
Value Function Update Magnitude: 0.04437

Collected Steps per Second: 23,837.80571
Overall Steps per Second: 17,010.98419

Timestep Collection Time: 2.09843
Timestep Consumption Time: 0.84214
PPO Batch Consumption Time: 0.07349
Total Iteration Time: 2.94057

Cumulative Model Updates: 5,855
Cumulative Timesteps: 97,731,304

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 97731304...
Checkpoint 97731304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 830.90370
Policy Entropy: 0.53208
Value Function Loss: 4.92273

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02589
Policy Update Magnitude: 0.03044
Value Function Update Magnitude: 0.04103

Collected Steps per Second: 24,196.28366
Overall Steps per Second: 17,408.93523

Timestep Collection Time: 2.06767
Timestep Consumption Time: 0.80614
PPO Batch Consumption Time: 0.06114
Total Iteration Time: 2.87381

Cumulative Model Updates: 5,858
Cumulative Timesteps: 97,781,334

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 919.97609
Policy Entropy: 0.54547
Value Function Loss: 4.94024

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.02304
Policy Update Magnitude: 0.03032
Value Function Update Magnitude: 0.03540

Collected Steps per Second: 22,063.93496
Overall Steps per Second: 15,288.36949

Timestep Collection Time: 2.26741
Timestep Consumption Time: 1.00488
PPO Batch Consumption Time: 0.12560
Total Iteration Time: 3.27229

Cumulative Model Updates: 5,861
Cumulative Timesteps: 97,831,362

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 97831362...
Checkpoint 97831362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560.10773
Policy Entropy: 0.54625
Value Function Loss: 4.92382

Mean KL Divergence: 0.00135
SB3 Clip Fraction: 0.01286
Policy Update Magnitude: 0.03070
Value Function Update Magnitude: 0.03698

Collected Steps per Second: 24,247.54660
Overall Steps per Second: 16,676.74221

Timestep Collection Time: 2.06297
Timestep Consumption Time: 0.93654
PPO Batch Consumption Time: 0.10455
Total Iteration Time: 2.99951

Cumulative Model Updates: 5,864
Cumulative Timesteps: 97,881,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 725.19173
Policy Entropy: 0.55098
Value Function Loss: 4.97142

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01970
Policy Update Magnitude: 0.03192
Value Function Update Magnitude: 0.04373

Collected Steps per Second: 24,770.81719
Overall Steps per Second: 17,829.18131

Timestep Collection Time: 2.01899
Timestep Consumption Time: 0.78608
PPO Batch Consumption Time: 0.07805
Total Iteration Time: 2.80506

Cumulative Model Updates: 5,867
Cumulative Timesteps: 97,931,396

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 97931396...
Checkpoint 97931396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615.98699
Policy Entropy: 0.54625
Value Function Loss: 4.82011

Mean KL Divergence: 0.00094
SB3 Clip Fraction: 0.00729
Policy Update Magnitude: 0.03305
Value Function Update Magnitude: 0.04875

Collected Steps per Second: 24,515.01054
Overall Steps per Second: 17,711.91613

Timestep Collection Time: 2.03973
Timestep Consumption Time: 0.78345
PPO Batch Consumption Time: 0.05863
Total Iteration Time: 2.82318

Cumulative Model Updates: 5,870
Cumulative Timesteps: 97,981,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.45785
Policy Entropy: 0.54084
Value Function Loss: 4.91263

Mean KL Divergence: 0.00110
SB3 Clip Fraction: 0.01139
Policy Update Magnitude: 0.03803
Value Function Update Magnitude: 0.04258

Collected Steps per Second: 21,946.40034
Overall Steps per Second: 15,839.60901

Timestep Collection Time: 2.27901
Timestep Consumption Time: 0.87865
PPO Batch Consumption Time: 0.08236
Total Iteration Time: 3.15765

Cumulative Model Updates: 5,873
Cumulative Timesteps: 98,031,416

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 98031416...
Checkpoint 98031416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560.32168
Policy Entropy: 0.53809
Value Function Loss: 4.92884

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01993
Policy Update Magnitude: 0.03725
Value Function Update Magnitude: 0.04276

Collected Steps per Second: 24,196.16245
Overall Steps per Second: 17,559.97253

Timestep Collection Time: 2.06760
Timestep Consumption Time: 0.78138
PPO Batch Consumption Time: 0.06009
Total Iteration Time: 2.84898

Cumulative Model Updates: 5,876
Cumulative Timesteps: 98,081,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591.53698
Policy Entropy: 0.55535
Value Function Loss: 5.04875

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03912
Policy Update Magnitude: 0.03223
Value Function Update Magnitude: 0.03694

Collected Steps per Second: 21,251.91598
Overall Steps per Second: 15,143.30715

Timestep Collection Time: 2.35329
Timestep Consumption Time: 0.94929
PPO Batch Consumption Time: 0.11109
Total Iteration Time: 3.30258

Cumulative Model Updates: 5,879
Cumulative Timesteps: 98,131,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 98131456...
Checkpoint 98131456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.67565
Policy Entropy: 0.54577
Value Function Loss: 4.86329

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03533
Policy Update Magnitude: 0.03043
Value Function Update Magnitude: 0.04073

Collected Steps per Second: 24,581.86214
Overall Steps per Second: 17,629.78716

Timestep Collection Time: 2.03491
Timestep Consumption Time: 0.80244
PPO Batch Consumption Time: 0.07912
Total Iteration Time: 2.83736

Cumulative Model Updates: 5,882
Cumulative Timesteps: 98,181,478

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.17039
Policy Entropy: 0.55027
Value Function Loss: 4.89200

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.03094
Policy Update Magnitude: 0.02818
Value Function Update Magnitude: 0.05274

Collected Steps per Second: 23,057.75455
Overall Steps per Second: 15,931.42563

Timestep Collection Time: 2.16942
Timestep Consumption Time: 0.97041
PPO Batch Consumption Time: 0.11484
Total Iteration Time: 3.13983

Cumulative Model Updates: 5,885
Cumulative Timesteps: 98,231,500

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 98231500...
Checkpoint 98231500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 752.85960
Policy Entropy: 0.54812
Value Function Loss: 5.00058

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02648
Policy Update Magnitude: 0.02906
Value Function Update Magnitude: 0.04554

Collected Steps per Second: 24,423.98125
Overall Steps per Second: 16,736.76236

Timestep Collection Time: 2.04774
Timestep Consumption Time: 0.94053
PPO Batch Consumption Time: 0.10441
Total Iteration Time: 2.98827

Cumulative Model Updates: 5,888
Cumulative Timesteps: 98,281,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593.31169
Policy Entropy: 0.55128
Value Function Loss: 5.20800

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.02060
Policy Update Magnitude: 0.02946
Value Function Update Magnitude: 0.03824

Collected Steps per Second: 24,448.45394
Overall Steps per Second: 16,716.56361

Timestep Collection Time: 2.04520
Timestep Consumption Time: 0.94596
PPO Batch Consumption Time: 0.10485
Total Iteration Time: 2.99117

Cumulative Model Updates: 5,891
Cumulative Timesteps: 98,331,516

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 98331516...
Checkpoint 98331516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.83272
Policy Entropy: 0.55254
Value Function Loss: 5.13857

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02559
Policy Update Magnitude: 0.03014
Value Function Update Magnitude: 0.04044

Collected Steps per Second: 24,298.37578
Overall Steps per Second: 16,769.97163

Timestep Collection Time: 2.05849
Timestep Consumption Time: 0.92410
PPO Batch Consumption Time: 0.10970
Total Iteration Time: 2.98259

Cumulative Model Updates: 5,894
Cumulative Timesteps: 98,381,534

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 946.85493
Policy Entropy: 0.54889
Value Function Loss: 5.12641

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.02257
Policy Update Magnitude: 0.03326
Value Function Update Magnitude: 0.03784

Collected Steps per Second: 24,667.05808
Overall Steps per Second: 17,758.89655

Timestep Collection Time: 2.02805
Timestep Consumption Time: 0.78891
PPO Batch Consumption Time: 0.07845
Total Iteration Time: 2.81695

Cumulative Model Updates: 5,897
Cumulative Timesteps: 98,431,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 98431560...
Checkpoint 98431560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684.40197
Policy Entropy: 0.55717
Value Function Loss: 5.07338

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.02209
Policy Update Magnitude: 0.03169
Value Function Update Magnitude: 0.04397

Collected Steps per Second: 24,474.55242
Overall Steps per Second: 17,520.80228

Timestep Collection Time: 2.04490
Timestep Consumption Time: 0.81159
PPO Batch Consumption Time: 0.06075
Total Iteration Time: 2.85649

Cumulative Model Updates: 5,900
Cumulative Timesteps: 98,481,608

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565.63010
Policy Entropy: 0.55529
Value Function Loss: 5.23234

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02869
Policy Update Magnitude: 0.03011
Value Function Update Magnitude: 0.04896

Collected Steps per Second: 21,753.61029
Overall Steps per Second: 15,184.56557

Timestep Collection Time: 2.29930
Timestep Consumption Time: 0.99471
PPO Batch Consumption Time: 0.11812
Total Iteration Time: 3.29400

Cumulative Model Updates: 5,903
Cumulative Timesteps: 98,531,626

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 98531626...
Checkpoint 98531626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 781.43520
Policy Entropy: 0.54775
Value Function Loss: 5.13795

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02383
Policy Update Magnitude: 0.02713
Value Function Update Magnitude: 0.03976

Collected Steps per Second: 23,996.97008
Overall Steps per Second: 16,661.69193

Timestep Collection Time: 2.08401
Timestep Consumption Time: 0.91748
PPO Batch Consumption Time: 0.09465
Total Iteration Time: 3.00150

Cumulative Model Updates: 5,906
Cumulative Timesteps: 98,581,636

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.29493
Policy Entropy: 0.55674
Value Function Loss: 5.17770

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02437
Policy Update Magnitude: 0.02643
Value Function Update Magnitude: 0.04175

Collected Steps per Second: 24,323.88815
Overall Steps per Second: 16,780.56602

Timestep Collection Time: 2.05658
Timestep Consumption Time: 0.92449
PPO Batch Consumption Time: 0.10362
Total Iteration Time: 2.98107

Cumulative Model Updates: 5,909
Cumulative Timesteps: 98,631,660

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 98631660...
Checkpoint 98631660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.84670
Policy Entropy: 0.55725
Value Function Loss: 5.05431

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01708
Policy Update Magnitude: 0.02940
Value Function Update Magnitude: 0.04588

Collected Steps per Second: 24,127.87581
Overall Steps per Second: 16,794.95230

Timestep Collection Time: 2.07262
Timestep Consumption Time: 0.90494
PPO Batch Consumption Time: 0.11532
Total Iteration Time: 2.97756

Cumulative Model Updates: 5,912
Cumulative Timesteps: 98,681,668

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.19109
Policy Entropy: 0.56101
Value Function Loss: 5.08783

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01912
Policy Update Magnitude: 0.02915
Value Function Update Magnitude: 0.04136

Collected Steps per Second: 24,986.35573
Overall Steps per Second: 16,632.43424

Timestep Collection Time: 2.00157
Timestep Consumption Time: 1.00532
PPO Batch Consumption Time: 0.11953
Total Iteration Time: 3.00690

Cumulative Model Updates: 5,915
Cumulative Timesteps: 98,731,680

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 98731680...
Checkpoint 98731680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.83276
Policy Entropy: 0.56713
Value Function Loss: 5.08390

Mean KL Divergence: 0.00144
SB3 Clip Fraction: 0.01455
Policy Update Magnitude: 0.03043
Value Function Update Magnitude: 0.04644

Collected Steps per Second: 24,880.45304
Overall Steps per Second: 16,822.63216

Timestep Collection Time: 2.01017
Timestep Consumption Time: 0.96285
PPO Batch Consumption Time: 0.11221
Total Iteration Time: 2.97302

Cumulative Model Updates: 5,918
Cumulative Timesteps: 98,781,694

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718.71101
Policy Entropy: 0.56652
Value Function Loss: 4.90633

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01738
Policy Update Magnitude: 0.03012
Value Function Update Magnitude: 0.05524

Collected Steps per Second: 24,970.89666
Overall Steps per Second: 16,735.43918

Timestep Collection Time: 2.00329
Timestep Consumption Time: 0.98581
PPO Batch Consumption Time: 0.12012
Total Iteration Time: 2.98911

Cumulative Model Updates: 5,921
Cumulative Timesteps: 98,831,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 98831718...
Checkpoint 98831718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 773.03247
Policy Entropy: 0.57134
Value Function Loss: 4.94626

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01465
Policy Update Magnitude: 0.03165
Value Function Update Magnitude: 0.04971

Collected Steps per Second: 24,693.73838
Overall Steps per Second: 16,741.73942

Timestep Collection Time: 2.02480
Timestep Consumption Time: 0.96174
PPO Batch Consumption Time: 0.11336
Total Iteration Time: 2.98655

Cumulative Model Updates: 5,924
Cumulative Timesteps: 98,881,718

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 841.51469
Policy Entropy: 0.56851
Value Function Loss: 4.86927

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.02284
Policy Update Magnitude: 0.03241
Value Function Update Magnitude: 0.04168

Collected Steps per Second: 25,000.77097
Overall Steps per Second: 17,727.83394

Timestep Collection Time: 2.00074
Timestep Consumption Time: 0.82081
PPO Batch Consumption Time: 0.07611
Total Iteration Time: 2.82155

Cumulative Model Updates: 5,927
Cumulative Timesteps: 98,931,738

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 98931738...
Checkpoint 98931738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682.76399
Policy Entropy: 0.55671
Value Function Loss: 5.03505

Mean KL Divergence: 0.00126
SB3 Clip Fraction: 0.01163
Policy Update Magnitude: 0.03394
Value Function Update Magnitude: 0.03686

Collected Steps per Second: 24,203.79071
Overall Steps per Second: 17,619.80892

Timestep Collection Time: 2.06654
Timestep Consumption Time: 0.77220
PPO Batch Consumption Time: 0.05990
Total Iteration Time: 2.83874

Cumulative Model Updates: 5,930
Cumulative Timesteps: 98,981,756

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 857.36582
Policy Entropy: 0.56210
Value Function Loss: 4.99007

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01347
Policy Update Magnitude: 0.03425
Value Function Update Magnitude: 0.03400

Collected Steps per Second: 21,862.00280
Overall Steps per Second: 15,965.76313

Timestep Collection Time: 2.28744
Timestep Consumption Time: 0.84476
PPO Batch Consumption Time: 0.09571
Total Iteration Time: 3.13220

Cumulative Model Updates: 5,933
Cumulative Timesteps: 99,031,764

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 99031764...
Checkpoint 99031764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572.50611
Policy Entropy: 0.55369
Value Function Loss: 5.07804

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02669
Policy Update Magnitude: 0.03159
Value Function Update Magnitude: 0.03209

Collected Steps per Second: 24,301.23976
Overall Steps per Second: 17,602.82343

Timestep Collection Time: 2.05833
Timestep Consumption Time: 0.78326
PPO Batch Consumption Time: 0.05923
Total Iteration Time: 2.84159

Cumulative Model Updates: 5,936
Cumulative Timesteps: 99,081,784

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 769.20436
Policy Entropy: 0.56442
Value Function Loss: 4.91832

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02297
Policy Update Magnitude: 0.02754
Value Function Update Magnitude: 0.02725

Collected Steps per Second: 21,440.70105
Overall Steps per Second: 15,089.10797

Timestep Collection Time: 2.33201
Timestep Consumption Time: 0.98164
PPO Batch Consumption Time: 0.11688
Total Iteration Time: 3.31365

Cumulative Model Updates: 5,939
Cumulative Timesteps: 99,131,784

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 99131784...
Checkpoint 99131784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.28520
Policy Entropy: 0.55559
Value Function Loss: 5.00580

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02704
Policy Update Magnitude: 0.03306
Value Function Update Magnitude: 0.02727

Collected Steps per Second: 24,471.30993
Overall Steps per Second: 16,741.76162

Timestep Collection Time: 2.04329
Timestep Consumption Time: 0.94337
PPO Batch Consumption Time: 0.10512
Total Iteration Time: 2.98666

Cumulative Model Updates: 5,942
Cumulative Timesteps: 99,181,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.19991
Policy Entropy: 0.55615
Value Function Loss: 4.97150

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02175
Policy Update Magnitude: 0.02771
Value Function Update Magnitude: 0.02678

Collected Steps per Second: 24,817.80765
Overall Steps per Second: 16,722.40188

Timestep Collection Time: 2.01525
Timestep Consumption Time: 0.97559
PPO Batch Consumption Time: 0.11825
Total Iteration Time: 2.99084

Cumulative Model Updates: 5,945
Cumulative Timesteps: 99,231,800

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 99231800...
Checkpoint 99231800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679.05192
Policy Entropy: 0.54770
Value Function Loss: 5.00184

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.01713
Policy Update Magnitude: 0.02905
Value Function Update Magnitude: 0.02532

Collected Steps per Second: 24,241.13517
Overall Steps per Second: 16,771.41001

Timestep Collection Time: 2.06302
Timestep Consumption Time: 0.91884
PPO Batch Consumption Time: 0.12025
Total Iteration Time: 2.98186

Cumulative Model Updates: 5,948
Cumulative Timesteps: 99,281,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 810.94433
Policy Entropy: 0.54839
Value Function Loss: 4.94044

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01373
Policy Update Magnitude: 0.02904
Value Function Update Magnitude: 0.02616

Collected Steps per Second: 25,189.04504
Overall Steps per Second: 17,575.27376

Timestep Collection Time: 1.98499
Timestep Consumption Time: 0.85992
PPO Batch Consumption Time: 0.07990
Total Iteration Time: 2.84491

Cumulative Model Updates: 5,951
Cumulative Timesteps: 99,331,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 99331810...
Checkpoint 99331810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679.06411
Policy Entropy: 0.55161
Value Function Loss: 4.95267

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.02266
Policy Update Magnitude: 0.03086
Value Function Update Magnitude: 0.02869

Collected Steps per Second: 22,797.73913
Overall Steps per Second: 15,929.73061

Timestep Collection Time: 2.19434
Timestep Consumption Time: 0.94608
PPO Batch Consumption Time: 0.10418
Total Iteration Time: 3.14042

Cumulative Model Updates: 5,954
Cumulative Timesteps: 99,381,836

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601.03955
Policy Entropy: 0.53875
Value Function Loss: 4.86502

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02573
Policy Update Magnitude: 0.03452
Value Function Update Magnitude: 0.04606

Collected Steps per Second: 24,855.48785
Overall Steps per Second: 16,777.61756

Timestep Collection Time: 2.01275
Timestep Consumption Time: 0.96908
PPO Batch Consumption Time: 0.11297
Total Iteration Time: 2.98183

Cumulative Model Updates: 5,957
Cumulative Timesteps: 99,431,864

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 99431864...
Checkpoint 99431864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.20858
Policy Entropy: 0.53699
Value Function Loss: 4.96428

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03279
Policy Update Magnitude: 0.02959
Value Function Update Magnitude: 0.05092

Collected Steps per Second: 24,447.66477
Overall Steps per Second: 16,752.17900

Timestep Collection Time: 2.04617
Timestep Consumption Time: 0.93995
PPO Batch Consumption Time: 0.11003
Total Iteration Time: 2.98612

Cumulative Model Updates: 5,960
Cumulative Timesteps: 99,481,888

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 907.05255
Policy Entropy: 0.53601
Value Function Loss: 4.93775

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03261
Policy Update Magnitude: 0.02655
Value Function Update Magnitude: 0.04946

Collected Steps per Second: 24,636.21496
Overall Steps per Second: 17,771.10311

Timestep Collection Time: 2.03059
Timestep Consumption Time: 0.78443
PPO Batch Consumption Time: 0.07784
Total Iteration Time: 2.81502

Cumulative Model Updates: 5,963
Cumulative Timesteps: 99,531,914

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 99531914...
Checkpoint 99531914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.40017
Policy Entropy: 0.53344
Value Function Loss: 5.07586

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02765
Policy Update Magnitude: 0.02524
Value Function Update Magnitude: 0.05012

Collected Steps per Second: 24,198.59506
Overall Steps per Second: 17,389.66737

Timestep Collection Time: 2.06748
Timestep Consumption Time: 0.80952
PPO Batch Consumption Time: 0.06194
Total Iteration Time: 2.87700

Cumulative Model Updates: 5,966
Cumulative Timesteps: 99,581,944

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596.22887
Policy Entropy: 0.53575
Value Function Loss: 4.89723

Mean KL Divergence: 0.00155
SB3 Clip Fraction: 0.01663
Policy Update Magnitude: 0.02691
Value Function Update Magnitude: 0.05652

Collected Steps per Second: 21,780.41719
Overall Steps per Second: 15,267.42065

Timestep Collection Time: 2.29693
Timestep Consumption Time: 0.97986
PPO Batch Consumption Time: 0.11621
Total Iteration Time: 3.27678

Cumulative Model Updates: 5,969
Cumulative Timesteps: 99,631,972

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 99631972...
Checkpoint 99631972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 963.59497
Policy Entropy: 0.52539
Value Function Loss: 4.83095

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02723
Policy Update Magnitude: 0.02690
Value Function Update Magnitude: 0.05699

Collected Steps per Second: 24,321.82436
Overall Steps per Second: 16,720.21335

Timestep Collection Time: 2.05700
Timestep Consumption Time: 0.93519
PPO Batch Consumption Time: 0.10335
Total Iteration Time: 2.99219

Cumulative Model Updates: 5,972
Cumulative Timesteps: 99,682,002

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 858.21953
Policy Entropy: 0.53052
Value Function Loss: 4.78916

Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.01593
Policy Update Magnitude: 0.02728
Value Function Update Magnitude: 0.06214

Collected Steps per Second: 24,051.80148
Overall Steps per Second: 16,759.51748

Timestep Collection Time: 2.07968
Timestep Consumption Time: 0.90489
PPO Batch Consumption Time: 0.10497
Total Iteration Time: 2.98457

Cumulative Model Updates: 5,975
Cumulative Timesteps: 99,732,022

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 99732022...
Checkpoint 99732022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 862.14780
Policy Entropy: 0.53822
Value Function Loss: 4.85290

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01813
Policy Update Magnitude: 0.02908
Value Function Update Magnitude: 0.05679

Collected Steps per Second: 24,145.59880
Overall Steps per Second: 16,657.30660

Timestep Collection Time: 2.07168
Timestep Consumption Time: 0.93132
PPO Batch Consumption Time: 0.10461
Total Iteration Time: 3.00301

Cumulative Model Updates: 5,978
Cumulative Timesteps: 99,782,044

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584.12584
Policy Entropy: 0.53453
Value Function Loss: 4.92261

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01873
Policy Update Magnitude: 0.02764
Value Function Update Magnitude: 0.04487

Collected Steps per Second: 24,394.51863
Overall Steps per Second: 16,845.85764

Timestep Collection Time: 2.05062
Timestep Consumption Time: 0.91889
PPO Batch Consumption Time: 0.12248
Total Iteration Time: 2.96951

Cumulative Model Updates: 5,981
Cumulative Timesteps: 99,832,068

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 99832068...
Checkpoint 99832068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 744.51280
Policy Entropy: 0.52903
Value Function Loss: 4.99505

Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.01645
Policy Update Magnitude: 0.03089
Value Function Update Magnitude: 0.04377

Collected Steps per Second: 24,931.34637
Overall Steps per Second: 16,740.26455

Timestep Collection Time: 2.00703
Timestep Consumption Time: 0.98205
PPO Batch Consumption Time: 0.11747
Total Iteration Time: 2.98908

Cumulative Model Updates: 5,984
Cumulative Timesteps: 99,882,106

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 860.17840
Policy Entropy: 0.52312
Value Function Loss: 5.16537

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01811
Policy Update Magnitude: 0.03065
Value Function Update Magnitude: 0.04719

Collected Steps per Second: 25,074.70507
Overall Steps per Second: 16,707.35632

Timestep Collection Time: 1.99404
Timestep Consumption Time: 0.99865
PPO Batch Consumption Time: 0.11984
Total Iteration Time: 2.99269

Cumulative Model Updates: 5,987
Cumulative Timesteps: 99,932,106

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 99932106...
Checkpoint 99932106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714.24221
Policy Entropy: 0.51305
Value Function Loss: 5.06039

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01838
Policy Update Magnitude: 0.03339
Value Function Update Magnitude: 0.03908

Collected Steps per Second: 24,225.36076
Overall Steps per Second: 16,728.82498

Timestep Collection Time: 2.06445
Timestep Consumption Time: 0.92512
PPO Batch Consumption Time: 0.10356
Total Iteration Time: 2.98957

Cumulative Model Updates: 5,990
Cumulative Timesteps: 99,982,118

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 812.78177
Policy Entropy: 0.51551
Value Function Loss: 5.03152

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01773
Policy Update Magnitude: 0.03120
Value Function Update Magnitude: 0.03620

Collected Steps per Second: 24,568.35609
Overall Steps per Second: 16,732.39318

Timestep Collection Time: 2.03514
Timestep Consumption Time: 0.95308
PPO Batch Consumption Time: 0.11676
Total Iteration Time: 2.98822

Cumulative Model Updates: 5,993
Cumulative Timesteps: 100,032,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 100032118...
Checkpoint 100032118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 877.49442
Policy Entropy: 0.51318
Value Function Loss: 4.99945

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.02350
Policy Update Magnitude: 0.03109
Value Function Update Magnitude: 0.03664

Collected Steps per Second: 24,493.94027
Overall Steps per Second: 16,784.30590

Timestep Collection Time: 2.04222
Timestep Consumption Time: 0.93806
PPO Batch Consumption Time: 0.11586
Total Iteration Time: 2.98028

Cumulative Model Updates: 5,996
Cumulative Timesteps: 100,082,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 811.67910
Policy Entropy: 0.51344
Value Function Loss: 4.92416

Mean KL Divergence: 0.00132
SB3 Clip Fraction: 0.01254
Policy Update Magnitude: 0.02952
Value Function Update Magnitude: 0.04451

Collected Steps per Second: 24,626.16550
Overall Steps per Second: 17,748.66520

Timestep Collection Time: 2.03117
Timestep Consumption Time: 0.78707
PPO Batch Consumption Time: 0.07826
Total Iteration Time: 2.81824

Cumulative Model Updates: 5,999
Cumulative Timesteps: 100,132,160

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 100132160...
Checkpoint 100132160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636.83895
Policy Entropy: 0.51479
Value Function Loss: 5.00590

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01447
Policy Update Magnitude: 0.03357
Value Function Update Magnitude: 0.05433

Collected Steps per Second: 24,064.72418
Overall Steps per Second: 17,314.97605

Timestep Collection Time: 2.07839
Timestep Consumption Time: 0.81020
PPO Batch Consumption Time: 0.06165
Total Iteration Time: 2.88860

Cumulative Model Updates: 6,002
Cumulative Timesteps: 100,182,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 735.38800
Policy Entropy: 0.52011
Value Function Loss: 4.95837

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02449
Policy Update Magnitude: 0.03231
Value Function Update Magnitude: 0.04964

Collected Steps per Second: 22,124.14035
Overall Steps per Second: 16,134.09533

Timestep Collection Time: 2.26133
Timestep Consumption Time: 0.83956
PPO Batch Consumption Time: 0.07165
Total Iteration Time: 3.10089

Cumulative Model Updates: 6,005
Cumulative Timesteps: 100,232,206

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 100232206...
Checkpoint 100232206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 978.55395
Policy Entropy: 0.51698
Value Function Loss: 5.08199

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01926
Policy Update Magnitude: 0.03151
Value Function Update Magnitude: 0.04110

Collected Steps per Second: 24,302.02353
Overall Steps per Second: 17,574.96901

Timestep Collection Time: 2.05884
Timestep Consumption Time: 0.78805
PPO Batch Consumption Time: 0.06094
Total Iteration Time: 2.84689

Cumulative Model Updates: 6,008
Cumulative Timesteps: 100,282,240

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 867.85123
Policy Entropy: 0.51646
Value Function Loss: 4.93729

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01731
Policy Update Magnitude: 0.03111
Value Function Update Magnitude: 0.04175

Collected Steps per Second: 21,318.39903
Overall Steps per Second: 16,013.45709

Timestep Collection Time: 2.34671
Timestep Consumption Time: 0.77742
PPO Batch Consumption Time: 0.07246
Total Iteration Time: 3.12412

Cumulative Model Updates: 6,011
Cumulative Timesteps: 100,332,268

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 100332268...
Checkpoint 100332268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.30969
Policy Entropy: 0.52063
Value Function Loss: 4.90396

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01794
Policy Update Magnitude: 0.02986
Value Function Update Magnitude: 0.03579

Collected Steps per Second: 24,423.90844
Overall Steps per Second: 17,525.60646

Timestep Collection Time: 2.04840
Timestep Consumption Time: 0.80628
PPO Batch Consumption Time: 0.06048
Total Iteration Time: 2.85468

Cumulative Model Updates: 6,014
Cumulative Timesteps: 100,382,298

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713.24417
Policy Entropy: 0.52269
Value Function Loss: 4.91072

Mean KL Divergence: 0.00151
SB3 Clip Fraction: 0.01607
Policy Update Magnitude: 0.03320
Value Function Update Magnitude: 0.04149

Collected Steps per Second: 21,859.43030
Overall Steps per Second: 15,199.47710

Timestep Collection Time: 2.28762
Timestep Consumption Time: 1.00236
PPO Batch Consumption Time: 0.12409
Total Iteration Time: 3.28998

Cumulative Model Updates: 6,017
Cumulative Timesteps: 100,432,304

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 100432304...
Checkpoint 100432304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705.56628
Policy Entropy: 0.52739
Value Function Loss: 4.89295

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.02097
Policy Update Magnitude: 0.03745
Value Function Update Magnitude: 0.04626

Collected Steps per Second: 24,436.60338
Overall Steps per Second: 16,756.49535

Timestep Collection Time: 2.04652
Timestep Consumption Time: 0.93799
PPO Batch Consumption Time: 0.10456
Total Iteration Time: 2.98451

Cumulative Model Updates: 6,020
Cumulative Timesteps: 100,482,314

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.39186
Policy Entropy: 0.53313
Value Function Loss: 4.79492

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02554
Policy Update Magnitude: 0.03499
Value Function Update Magnitude: 0.04552

Collected Steps per Second: 24,733.44334
Overall Steps per Second: 16,705.90869

Timestep Collection Time: 2.02188
Timestep Consumption Time: 0.97155
PPO Batch Consumption Time: 0.11228
Total Iteration Time: 2.99343

Cumulative Model Updates: 6,023
Cumulative Timesteps: 100,532,322

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 100532322...
Checkpoint 100532322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.40724
Policy Entropy: 0.52293
Value Function Loss: 4.63860

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02510
Policy Update Magnitude: 0.02968
Value Function Update Magnitude: 0.04626

Collected Steps per Second: 24,336.56986
Overall Steps per Second: 16,746.95322

Timestep Collection Time: 2.05518
Timestep Consumption Time: 0.93139
PPO Batch Consumption Time: 0.10804
Total Iteration Time: 2.98657

Cumulative Model Updates: 6,026
Cumulative Timesteps: 100,582,338

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.07897
Policy Entropy: 0.52024
Value Function Loss: 4.67606

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.02081
Policy Update Magnitude: 0.02875
Value Function Update Magnitude: 0.04366

Collected Steps per Second: 24,454.68603
Overall Steps per Second: 17,587.48847

Timestep Collection Time: 2.04517
Timestep Consumption Time: 0.79856
PPO Batch Consumption Time: 0.08160
Total Iteration Time: 2.84373

Cumulative Model Updates: 6,029
Cumulative Timesteps: 100,632,352

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 100632352...
Checkpoint 100632352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 853.43551
Policy Entropy: 0.52236
Value Function Loss: 4.92620

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.02053
Policy Update Magnitude: 0.03072
Value Function Update Magnitude: 0.05281

Collected Steps per Second: 21,647.27120
Overall Steps per Second: 15,899.39906

Timestep Collection Time: 2.31022
Timestep Consumption Time: 0.83518
PPO Batch Consumption Time: 0.09357
Total Iteration Time: 3.14540

Cumulative Model Updates: 6,032
Cumulative Timesteps: 100,682,362

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 864.45874
Policy Entropy: 0.52757
Value Function Loss: 4.95163

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02803
Policy Update Magnitude: 0.03107
Value Function Update Magnitude: 0.04621

Collected Steps per Second: 24,844.82909
Overall Steps per Second: 16,798.34301

Timestep Collection Time: 2.01338
Timestep Consumption Time: 0.96442
PPO Batch Consumption Time: 0.11161
Total Iteration Time: 2.97779

Cumulative Model Updates: 6,035
Cumulative Timesteps: 100,732,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 100732384...
Checkpoint 100732384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551.80110
Policy Entropy: 0.52872
Value Function Loss: 4.96496

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02985
Policy Update Magnitude: 0.03292
Value Function Update Magnitude: 0.04207

Collected Steps per Second: 24,163.88727
Overall Steps per Second: 16,688.85907

Timestep Collection Time: 2.06945
Timestep Consumption Time: 0.92692
PPO Batch Consumption Time: 0.09846
Total Iteration Time: 2.99637

Cumulative Model Updates: 6,038
Cumulative Timesteps: 100,782,390

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 881.83136
Policy Entropy: 0.52634
Value Function Loss: 4.75513

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02887
Policy Update Magnitude: 0.03046
Value Function Update Magnitude: 0.03999

Collected Steps per Second: 24,111.25956
Overall Steps per Second: 16,643.44721

Timestep Collection Time: 2.07380
Timestep Consumption Time: 0.93050
PPO Batch Consumption Time: 0.09634
Total Iteration Time: 3.00431

Cumulative Model Updates: 6,041
Cumulative Timesteps: 100,832,392

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 100832392...
Checkpoint 100832392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651.96757
Policy Entropy: 0.51978
Value Function Loss: 4.74753

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01894
Policy Update Magnitude: 0.03246
Value Function Update Magnitude: 0.04423

Collected Steps per Second: 24,523.73140
Overall Steps per Second: 16,834.49652

Timestep Collection Time: 2.03892
Timestep Consumption Time: 0.93129
PPO Batch Consumption Time: 0.10477
Total Iteration Time: 2.97021

Cumulative Model Updates: 6,044
Cumulative Timesteps: 100,882,394

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615.23150
Policy Entropy: 0.52563
Value Function Loss: 4.70196

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02261
Policy Update Magnitude: 0.03443
Value Function Update Magnitude: 0.04082

Collected Steps per Second: 24,536.84413
Overall Steps per Second: 17,646.84979

Timestep Collection Time: 2.03800
Timestep Consumption Time: 0.79571
PPO Batch Consumption Time: 0.08147
Total Iteration Time: 2.83371

Cumulative Model Updates: 6,047
Cumulative Timesteps: 100,932,400

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 100932400...
Checkpoint 100932400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 826.35218
Policy Entropy: 0.51518
Value Function Loss: 4.80733

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.03404
Value Function Update Magnitude: 0.03745

Collected Steps per Second: 22,365.21717
Overall Steps per Second: 15,889.71189

Timestep Collection Time: 2.23660
Timestep Consumption Time: 0.91148
PPO Batch Consumption Time: 0.09455
Total Iteration Time: 3.14807

Cumulative Model Updates: 6,050
Cumulative Timesteps: 100,982,422

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.69407
Policy Entropy: 0.51815
Value Function Loss: 4.83489

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03517
Policy Update Magnitude: 0.03111
Value Function Update Magnitude: 0.03561

Collected Steps per Second: 24,902.78867
Overall Steps per Second: 16,808.05658

Timestep Collection Time: 2.00869
Timestep Consumption Time: 0.96738
PPO Batch Consumption Time: 0.11266
Total Iteration Time: 2.97607

Cumulative Model Updates: 6,053
Cumulative Timesteps: 101,032,444

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 101032444...
Checkpoint 101032444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.58984
Policy Entropy: 0.51782
Value Function Loss: 4.85819

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.03249
Policy Update Magnitude: 0.02609
Value Function Update Magnitude: 0.03409

Collected Steps per Second: 24,182.41956
Overall Steps per Second: 16,711.08535

Timestep Collection Time: 2.06844
Timestep Consumption Time: 0.92478
PPO Batch Consumption Time: 0.10167
Total Iteration Time: 2.99322

Cumulative Model Updates: 6,056
Cumulative Timesteps: 101,082,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650.80512
Policy Entropy: 0.50850
Value Function Loss: 4.83244

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.02207
Policy Update Magnitude: 0.02335
Value Function Update Magnitude: 0.03588

Collected Steps per Second: 24,626.73398
Overall Steps per Second: 16,779.40719

Timestep Collection Time: 2.03104
Timestep Consumption Time: 0.94987
PPO Batch Consumption Time: 0.11418
Total Iteration Time: 2.98092

Cumulative Model Updates: 6,059
Cumulative Timesteps: 101,132,482

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 101132482...
Checkpoint 101132482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 808.30206
Policy Entropy: 0.51036
Value Function Loss: 4.79617

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01951
Policy Update Magnitude: 0.02922
Value Function Update Magnitude: 0.03322

Collected Steps per Second: 24,500.44135
Overall Steps per Second: 16,747.03478

Timestep Collection Time: 2.04192
Timestep Consumption Time: 0.94535
PPO Batch Consumption Time: 0.11131
Total Iteration Time: 2.98728

Cumulative Model Updates: 6,062
Cumulative Timesteps: 101,182,510

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 987.97599
Policy Entropy: 0.50967
Value Function Loss: 4.75620

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.01721
Policy Update Magnitude: 0.02962
Value Function Update Magnitude: 0.03688

Collected Steps per Second: 24,800.46837
Overall Steps per Second: 17,767.72654

Timestep Collection Time: 2.01617
Timestep Consumption Time: 0.79803
PPO Batch Consumption Time: 0.08187
Total Iteration Time: 2.81420

Cumulative Model Updates: 6,065
Cumulative Timesteps: 101,232,512

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 101232512...
Checkpoint 101232512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.55528
Policy Entropy: 0.50852
Value Function Loss: 4.61558

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.02213
Policy Update Magnitude: 0.02965
Value Function Update Magnitude: 0.04109

Collected Steps per Second: 24,712.80983
Overall Steps per Second: 17,699.48591

Timestep Collection Time: 2.02349
Timestep Consumption Time: 0.80179
PPO Batch Consumption Time: 0.05973
Total Iteration Time: 2.82528

Cumulative Model Updates: 6,068
Cumulative Timesteps: 101,282,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 784.55166
Policy Entropy: 0.51402
Value Function Loss: 4.74058

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02546
Policy Update Magnitude: 0.02851
Value Function Update Magnitude: 0.03846

Collected Steps per Second: 21,789.92287
Overall Steps per Second: 15,838.40595

Timestep Collection Time: 2.29519
Timestep Consumption Time: 0.86245
PPO Batch Consumption Time: 0.08010
Total Iteration Time: 3.15764

Cumulative Model Updates: 6,071
Cumulative Timesteps: 101,332,530

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 101332530...
Checkpoint 101332530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698.30478
Policy Entropy: 0.51270
Value Function Loss: 4.67288

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02576
Policy Update Magnitude: 0.02713
Value Function Update Magnitude: 0.03223

Collected Steps per Second: 24,537.81137
Overall Steps per Second: 17,639.63450

Timestep Collection Time: 2.03832
Timestep Consumption Time: 0.79711
PPO Batch Consumption Time: 0.06032
Total Iteration Time: 2.83543

Cumulative Model Updates: 6,074
Cumulative Timesteps: 101,382,546

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760.20909
Policy Entropy: 0.51335
Value Function Loss: 4.78610

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01763
Policy Update Magnitude: 0.02621
Value Function Update Magnitude: 0.03136

Collected Steps per Second: 21,780.42780
Overall Steps per Second: 15,875.36666

Timestep Collection Time: 2.29591
Timestep Consumption Time: 0.85400
PPO Batch Consumption Time: 0.07367
Total Iteration Time: 3.14991

Cumulative Model Updates: 6,077
Cumulative Timesteps: 101,432,552

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 101432552...
Checkpoint 101432552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634.86131
Policy Entropy: 0.51174
Value Function Loss: 4.68021

Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.01557
Policy Update Magnitude: 0.02916
Value Function Update Magnitude: 0.03146

Collected Steps per Second: 24,314.83930
Overall Steps per Second: 17,656.61384

Timestep Collection Time: 2.05710
Timestep Consumption Time: 0.77572
PPO Batch Consumption Time: 0.05938
Total Iteration Time: 2.83282

Cumulative Model Updates: 6,080
Cumulative Timesteps: 101,482,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 857.17563
Policy Entropy: 0.51780
Value Function Loss: 4.64114

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01801
Policy Update Magnitude: 0.02919
Value Function Update Magnitude: 0.03465

Collected Steps per Second: 22,151.68875
Overall Steps per Second: 15,985.05675

Timestep Collection Time: 2.25753
Timestep Consumption Time: 0.87090
PPO Batch Consumption Time: 0.10265
Total Iteration Time: 3.12842

Cumulative Model Updates: 6,083
Cumulative Timesteps: 101,532,578

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 101532578...
Checkpoint 101532578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 735.75699
Policy Entropy: 0.51889
Value Function Loss: 4.53111

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.02065
Policy Update Magnitude: 0.03017
Value Function Update Magnitude: 0.03480

Collected Steps per Second: 24,394.68178
Overall Steps per Second: 17,563.50179

Timestep Collection Time: 2.05053
Timestep Consumption Time: 0.79754
PPO Batch Consumption Time: 0.06042
Total Iteration Time: 2.84807

Cumulative Model Updates: 6,086
Cumulative Timesteps: 101,582,600

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640.04172
Policy Entropy: 0.51507
Value Function Loss: 4.57496

Mean KL Divergence: 0.00132
SB3 Clip Fraction: 0.01350
Policy Update Magnitude: 0.03112
Value Function Update Magnitude: 0.03366

Collected Steps per Second: 21,783.13437
Overall Steps per Second: 15,931.37196

Timestep Collection Time: 2.29737
Timestep Consumption Time: 0.84385
PPO Batch Consumption Time: 0.07526
Total Iteration Time: 3.14122

Cumulative Model Updates: 6,089
Cumulative Timesteps: 101,632,644

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 101632644...
Checkpoint 101632644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674.53623
Policy Entropy: 0.50811
Value Function Loss: 4.71903

Mean KL Divergence: 0.00144
SB3 Clip Fraction: 0.01529
Policy Update Magnitude: 0.03065
Value Function Update Magnitude: 0.03434

Collected Steps per Second: 24,396.31986
Overall Steps per Second: 17,528.94270

Timestep Collection Time: 2.05006
Timestep Consumption Time: 0.80316
PPO Batch Consumption Time: 0.06082
Total Iteration Time: 2.85322

Cumulative Model Updates: 6,092
Cumulative Timesteps: 101,682,658

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 916.65571
Policy Entropy: 0.52154
Value Function Loss: 4.69473

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01571
Policy Update Magnitude: 0.03181
Value Function Update Magnitude: 0.03050

Collected Steps per Second: 21,843.09581
Overall Steps per Second: 16,024.34013

Timestep Collection Time: 2.29006
Timestep Consumption Time: 0.83157
PPO Batch Consumption Time: 0.07472
Total Iteration Time: 3.12163

Cumulative Model Updates: 6,095
Cumulative Timesteps: 101,732,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 101732680...
Checkpoint 101732680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 882.63225
Policy Entropy: 0.51755
Value Function Loss: 4.67184

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02129
Policy Update Magnitude: 0.03081
Value Function Update Magnitude: 0.02640

Collected Steps per Second: 24,129.11944
Overall Steps per Second: 17,968.78446

Timestep Collection Time: 2.07301
Timestep Consumption Time: 0.71070
PPO Batch Consumption Time: 0.05677
Total Iteration Time: 2.78372

Cumulative Model Updates: 6,098
Cumulative Timesteps: 101,782,700

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.45346
Policy Entropy: 0.52174
Value Function Loss: 4.60490

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01492
Policy Update Magnitude: 0.02860
Value Function Update Magnitude: 0.02305

Collected Steps per Second: 21,425.84560
Overall Steps per Second: 14,859.71468

Timestep Collection Time: 2.33428
Timestep Consumption Time: 1.03146
PPO Batch Consumption Time: 0.11312
Total Iteration Time: 3.36574

Cumulative Model Updates: 6,101
Cumulative Timesteps: 101,832,714

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 101832714...
Checkpoint 101832714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 895.28959
Policy Entropy: 0.50827
Value Function Loss: 4.78559

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.01275
Policy Update Magnitude: 0.02980
Value Function Update Magnitude: 0.02789

Collected Steps per Second: 24,390.75073
Overall Steps per Second: 16,653.19477

Timestep Collection Time: 2.05004
Timestep Consumption Time: 0.95251
PPO Batch Consumption Time: 0.10745
Total Iteration Time: 3.00255

Cumulative Model Updates: 6,104
Cumulative Timesteps: 101,882,716

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 868.58493
Policy Entropy: 0.52091
Value Function Loss: 4.72317

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02382
Policy Update Magnitude: 0.03400
Value Function Update Magnitude: 0.03524

Collected Steps per Second: 24,651.21324
Overall Steps per Second: 16,816.83290

Timestep Collection Time: 2.02846
Timestep Consumption Time: 0.94499
PPO Batch Consumption Time: 0.10583
Total Iteration Time: 2.97345

Cumulative Model Updates: 6,107
Cumulative Timesteps: 101,932,720

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 101932720...
Checkpoint 101932720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 826.00217
Policy Entropy: 0.51524
Value Function Loss: 4.70617

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.02335
Policy Update Magnitude: 0.02889
Value Function Update Magnitude: 0.04469

Collected Steps per Second: 24,045.34144
Overall Steps per Second: 16,739.15089

Timestep Collection Time: 2.07999
Timestep Consumption Time: 0.90786
PPO Batch Consumption Time: 0.10504
Total Iteration Time: 2.98785

Cumulative Model Updates: 6,110
Cumulative Timesteps: 101,982,734

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684.11599
Policy Entropy: 0.52770
Value Function Loss: 4.58655

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02440
Policy Update Magnitude: 0.02828
Value Function Update Magnitude: 0.06652

Collected Steps per Second: 24,702.93515
Overall Steps per Second: 16,727.39620

Timestep Collection Time: 2.02421
Timestep Consumption Time: 0.96513
PPO Batch Consumption Time: 0.12000
Total Iteration Time: 2.98935

Cumulative Model Updates: 6,113
Cumulative Timesteps: 102,032,738

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 102032738...
Checkpoint 102032738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.36807
Policy Entropy: 0.51722
Value Function Loss: 4.55705

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01787
Policy Update Magnitude: 0.02798
Value Function Update Magnitude: 0.04728

Collected Steps per Second: 24,510.00095
Overall Steps per Second: 17,806.41390

Timestep Collection Time: 2.04015
Timestep Consumption Time: 0.76805
PPO Batch Consumption Time: 0.07486
Total Iteration Time: 2.80820

Cumulative Model Updates: 6,116
Cumulative Timesteps: 102,082,742

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688.47127
Policy Entropy: 0.52678
Value Function Loss: 4.63078

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01806
Policy Update Magnitude: 0.02999
Value Function Update Magnitude: 0.04587

Collected Steps per Second: 24,951.37798
Overall Steps per Second: 17,797.53352

Timestep Collection Time: 2.00470
Timestep Consumption Time: 0.80580
PPO Batch Consumption Time: 0.05854
Total Iteration Time: 2.81050

Cumulative Model Updates: 6,119
Cumulative Timesteps: 102,132,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 102132762...
Checkpoint 102132762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617.04995
Policy Entropy: 0.51804
Value Function Loss: 4.61605

Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.01241
Policy Update Magnitude: 0.02913
Value Function Update Magnitude: 0.03630

Collected Steps per Second: 21,515.69625
Overall Steps per Second: 14,979.71818

Timestep Collection Time: 2.32519
Timestep Consumption Time: 1.01453
PPO Batch Consumption Time: 0.12636
Total Iteration Time: 3.33972

Cumulative Model Updates: 6,122
Cumulative Timesteps: 102,182,790

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610.40341
Policy Entropy: 0.52248
Value Function Loss: 4.66183

Mean KL Divergence: 0.00107
SB3 Clip Fraction: 0.00879
Policy Update Magnitude: 0.03355
Value Function Update Magnitude: 0.04141

Collected Steps per Second: 24,652.51633
Overall Steps per Second: 16,702.76639

Timestep Collection Time: 2.02900
Timestep Consumption Time: 0.96571
PPO Batch Consumption Time: 0.11309
Total Iteration Time: 2.99471

Cumulative Model Updates: 6,125
Cumulative Timesteps: 102,232,810

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 102232810...
Checkpoint 102232810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570.88678
Policy Entropy: 0.52174
Value Function Loss: 4.62300

Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.01004
Policy Update Magnitude: 0.03461
Value Function Update Magnitude: 0.03743

Collected Steps per Second: 24,291.53730
Overall Steps per Second: 16,710.94197

Timestep Collection Time: 2.05907
Timestep Consumption Time: 0.93406
PPO Batch Consumption Time: 0.10417
Total Iteration Time: 2.99313

Cumulative Model Updates: 6,128
Cumulative Timesteps: 102,282,828

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 897.45352
Policy Entropy: 0.52203
Value Function Loss: 4.65219

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01540
Policy Update Magnitude: 0.03596
Value Function Update Magnitude: 0.03586

Collected Steps per Second: 24,454.16008
Overall Steps per Second: 17,625.89367

Timestep Collection Time: 2.04571
Timestep Consumption Time: 0.79251
PPO Batch Consumption Time: 0.07793
Total Iteration Time: 2.83821

Cumulative Model Updates: 6,131
Cumulative Timesteps: 102,332,854

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 102332854...
Checkpoint 102332854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.94147
Policy Entropy: 0.52076
Value Function Loss: 4.58114

Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.01089
Policy Update Magnitude: 0.03502
Value Function Update Magnitude: 0.03365

Collected Steps per Second: 22,165.49120
Overall Steps per Second: 15,996.77992

Timestep Collection Time: 2.25630
Timestep Consumption Time: 0.87008
PPO Batch Consumption Time: 0.10840
Total Iteration Time: 3.12638

Cumulative Model Updates: 6,134
Cumulative Timesteps: 102,382,866

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.83296
Policy Entropy: 0.51961
Value Function Loss: 4.63266

Mean KL Divergence: 0.00107
SB3 Clip Fraction: 0.00898
Policy Update Magnitude: 0.03629
Value Function Update Magnitude: 0.03545

Collected Steps per Second: 24,931.14175
Overall Steps per Second: 16,721.29429

Timestep Collection Time: 2.00601
Timestep Consumption Time: 0.98491
PPO Batch Consumption Time: 0.12148
Total Iteration Time: 2.99092

Cumulative Model Updates: 6,137
Cumulative Timesteps: 102,432,878

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 102432878...
Checkpoint 102432878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.47375
Policy Entropy: 0.52258
Value Function Loss: 4.59955

Mean KL Divergence: 0.00135
SB3 Clip Fraction: 0.01453
Policy Update Magnitude: 0.03508
Value Function Update Magnitude: 0.03612

Collected Steps per Second: 24,366.93485
Overall Steps per Second: 16,732.94867

Timestep Collection Time: 2.05196
Timestep Consumption Time: 0.93616
PPO Batch Consumption Time: 0.10346
Total Iteration Time: 2.98812

Cumulative Model Updates: 6,140
Cumulative Timesteps: 102,482,878

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,427.88228
Policy Entropy: 0.52760
Value Function Loss: 4.57581

Mean KL Divergence: 0.00134
SB3 Clip Fraction: 0.01388
Policy Update Magnitude: 0.03513
Value Function Update Magnitude: 0.03835

Collected Steps per Second: 24,360.68544
Overall Steps per Second: 16,685.29800

Timestep Collection Time: 2.05298
Timestep Consumption Time: 0.94439
PPO Batch Consumption Time: 0.10445
Total Iteration Time: 2.99737

Cumulative Model Updates: 6,143
Cumulative Timesteps: 102,532,890

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 102532890...
Checkpoint 102532890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.82294
Policy Entropy: 0.52249
Value Function Loss: 4.51945

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01972
Policy Update Magnitude: 0.03186
Value Function Update Magnitude: 0.03722

Collected Steps per Second: 24,274.78332
Overall Steps per Second: 16,797.86485

Timestep Collection Time: 2.05992
Timestep Consumption Time: 0.91689
PPO Batch Consumption Time: 0.10530
Total Iteration Time: 2.97681

Cumulative Model Updates: 6,146
Cumulative Timesteps: 102,582,894

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754.84491
Policy Entropy: 0.51469
Value Function Loss: 4.52649

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03207
Policy Update Magnitude: 0.02847
Value Function Update Magnitude: 0.03743

Collected Steps per Second: 24,579.41572
Overall Steps per Second: 16,705.02151

Timestep Collection Time: 2.03495
Timestep Consumption Time: 0.95923
PPO Batch Consumption Time: 0.11560
Total Iteration Time: 2.99419

Cumulative Model Updates: 6,149
Cumulative Timesteps: 102,632,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 102632912...
Checkpoint 102632912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 975.39224
Policy Entropy: 0.51457
Value Function Loss: 4.69756

Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.01323
Policy Update Magnitude: 0.02857
Value Function Update Magnitude: 0.04851

Collected Steps per Second: 24,351.44842
Overall Steps per Second: 17,641.48859

Timestep Collection Time: 2.05392
Timestep Consumption Time: 0.78121
PPO Batch Consumption Time: 0.07912
Total Iteration Time: 2.83513

Cumulative Model Updates: 6,152
Cumulative Timesteps: 102,682,928

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683.02351
Policy Entropy: 0.51446
Value Function Loss: 4.70036

Mean KL Divergence: 0.00109
SB3 Clip Fraction: 0.00957
Policy Update Magnitude: 0.03069
Value Function Update Magnitude: 0.04322

Collected Steps per Second: 23,162.31659
Overall Steps per Second: 15,930.51016

Timestep Collection Time: 2.15937
Timestep Consumption Time: 0.98027
PPO Batch Consumption Time: 0.11449
Total Iteration Time: 3.13964

Cumulative Model Updates: 6,155
Cumulative Timesteps: 102,732,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 102732944...
Checkpoint 102732944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.14681
Policy Entropy: 0.51597
Value Function Loss: 4.75743

Mean KL Divergence: 0.00135
SB3 Clip Fraction: 0.01386
Policy Update Magnitude: 0.03210
Value Function Update Magnitude: 0.03775

Collected Steps per Second: 24,266.76517
Overall Steps per Second: 16,696.39414

Timestep Collection Time: 2.06093
Timestep Consumption Time: 0.93445
PPO Batch Consumption Time: 0.10417
Total Iteration Time: 2.99538

Cumulative Model Updates: 6,158
Cumulative Timesteps: 102,782,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.59973
Policy Entropy: 0.50925
Value Function Loss: 4.84726

Mean KL Divergence: 0.00124
SB3 Clip Fraction: 0.01104
Policy Update Magnitude: 0.03117
Value Function Update Magnitude: 0.03443

Collected Steps per Second: 24,417.77549
Overall Steps per Second: 16,730.41448

Timestep Collection Time: 2.04900
Timestep Consumption Time: 0.94148
PPO Batch Consumption Time: 0.10402
Total Iteration Time: 2.99048

Cumulative Model Updates: 6,161
Cumulative Timesteps: 102,832,988

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 102832988...
Checkpoint 102832988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609.65270
Policy Entropy: 0.50613
Value Function Loss: 4.84012

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01296
Policy Update Magnitude: 0.03556
Value Function Update Magnitude: 0.03400

Collected Steps per Second: 23,657.57300
Overall Steps per Second: 16,683.51877

Timestep Collection Time: 2.11383
Timestep Consumption Time: 0.88362
PPO Batch Consumption Time: 0.08627
Total Iteration Time: 2.99745

Cumulative Model Updates: 6,164
Cumulative Timesteps: 102,882,996

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.11953
Policy Entropy: 0.50606
Value Function Loss: 4.80919

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03684
Policy Update Magnitude: 0.03569
Value Function Update Magnitude: 0.04356

Collected Steps per Second: 24,629.84067
Overall Steps per Second: 16,728.13743

Timestep Collection Time: 2.03030
Timestep Consumption Time: 0.95903
PPO Batch Consumption Time: 0.11660
Total Iteration Time: 2.98933

Cumulative Model Updates: 6,167
Cumulative Timesteps: 102,933,002

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 102933002...
Checkpoint 102933002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.74176
Policy Entropy: 0.49032
Value Function Loss: 4.60506

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03645
Policy Update Magnitude: 0.03145
Value Function Update Magnitude: 0.04200

Collected Steps per Second: 24,294.89739
Overall Steps per Second: 16,871.58864

Timestep Collection Time: 2.05870
Timestep Consumption Time: 0.90581
PPO Batch Consumption Time: 0.11526
Total Iteration Time: 2.96451

Cumulative Model Updates: 6,170
Cumulative Timesteps: 102,983,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 751.52715
Policy Entropy: 0.50432
Value Function Loss: 4.59457

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03352
Policy Update Magnitude: 0.02587
Value Function Update Magnitude: 0.04071

Collected Steps per Second: 24,689.73951
Overall Steps per Second: 16,718.05636

Timestep Collection Time: 2.02594
Timestep Consumption Time: 0.96603
PPO Batch Consumption Time: 0.11572
Total Iteration Time: 2.99197

Cumulative Model Updates: 6,173
Cumulative Timesteps: 103,033,038

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 103033038...
Checkpoint 103033038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 739.56949
Policy Entropy: 0.50304
Value Function Loss: 4.46602

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02871
Policy Update Magnitude: 0.02302
Value Function Update Magnitude: 0.03984

Collected Steps per Second: 24,531.18215
Overall Steps per Second: 16,754.88323

Timestep Collection Time: 2.03879
Timestep Consumption Time: 0.94625
PPO Batch Consumption Time: 0.10767
Total Iteration Time: 2.98504

Cumulative Model Updates: 6,176
Cumulative Timesteps: 103,083,052

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 745.73138
Policy Entropy: 0.51262
Value Function Loss: 4.40364

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03623
Policy Update Magnitude: 0.02344
Value Function Update Magnitude: 0.04033

Collected Steps per Second: 24,167.59316
Overall Steps per Second: 16,639.01924

Timestep Collection Time: 2.06963
Timestep Consumption Time: 0.93644
PPO Batch Consumption Time: 0.10449
Total Iteration Time: 3.00607

Cumulative Model Updates: 6,179
Cumulative Timesteps: 103,133,070

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 103133070...
Checkpoint 103133070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675.89194
Policy Entropy: 0.49745
Value Function Loss: 4.42593

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.03219
Policy Update Magnitude: 0.02500
Value Function Update Magnitude: 0.03716

Collected Steps per Second: 24,123.31232
Overall Steps per Second: 16,738.98404

Timestep Collection Time: 2.07318
Timestep Consumption Time: 0.91457
PPO Batch Consumption Time: 0.09308
Total Iteration Time: 2.98776

Cumulative Model Updates: 6,182
Cumulative Timesteps: 103,183,082

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.56301
Policy Entropy: 0.50198
Value Function Loss: 4.45675

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01995
Policy Update Magnitude: 0.02443
Value Function Update Magnitude: 0.04177

Collected Steps per Second: 24,675.59980
Overall Steps per Second: 16,801.96769

Timestep Collection Time: 2.02646
Timestep Consumption Time: 0.94962
PPO Batch Consumption Time: 0.11040
Total Iteration Time: 2.97608

Cumulative Model Updates: 6,185
Cumulative Timesteps: 103,233,086

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 103233086...
Checkpoint 103233086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443.07153
Policy Entropy: 0.49590
Value Function Loss: 4.51994

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01495
Policy Update Magnitude: 0.02615
Value Function Update Magnitude: 0.04418

Collected Steps per Second: 24,352.25604
Overall Steps per Second: 16,753.70598

Timestep Collection Time: 2.05361
Timestep Consumption Time: 0.93140
PPO Batch Consumption Time: 0.10840
Total Iteration Time: 2.98501

Cumulative Model Updates: 6,188
Cumulative Timesteps: 103,283,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700.26427
Policy Entropy: 0.50718
Value Function Loss: 4.56482

Mean KL Divergence: 0.00139
SB3 Clip Fraction: 0.01565
Policy Update Magnitude: 0.03245
Value Function Update Magnitude: 0.04631

Collected Steps per Second: 24,071.09895
Overall Steps per Second: 16,719.07111

Timestep Collection Time: 2.07834
Timestep Consumption Time: 0.91393
PPO Batch Consumption Time: 0.12134
Total Iteration Time: 2.99227

Cumulative Model Updates: 6,191
Cumulative Timesteps: 103,333,124

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 103333124...
Checkpoint 103333124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 797.67595
Policy Entropy: 0.50806
Value Function Loss: 4.51730

Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.01569
Policy Update Magnitude: 0.03179
Value Function Update Magnitude: 0.04175

Collected Steps per Second: 24,014.14158
Overall Steps per Second: 16,771.07744

Timestep Collection Time: 2.08311
Timestep Consumption Time: 0.89965
PPO Batch Consumption Time: 0.11722
Total Iteration Time: 2.98275

Cumulative Model Updates: 6,194
Cumulative Timesteps: 103,383,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 900.57366
Policy Entropy: 0.50388
Value Function Loss: 4.40143

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02429
Policy Update Magnitude: 0.02948
Value Function Update Magnitude: 0.04320

Collected Steps per Second: 25,118.34877
Overall Steps per Second: 16,724.67137

Timestep Collection Time: 1.99090
Timestep Consumption Time: 0.99918
PPO Batch Consumption Time: 0.12239
Total Iteration Time: 2.99007

Cumulative Model Updates: 6,197
Cumulative Timesteps: 103,433,156

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 103433156...
Checkpoint 103433156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642.90209
Policy Entropy: 0.49643
Value Function Loss: 4.40220

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01905
Policy Update Magnitude: 0.02952
Value Function Update Magnitude: 0.04008

Collected Steps per Second: 24,697.86494
Overall Steps per Second: 16,747.41877

Timestep Collection Time: 2.02520
Timestep Consumption Time: 0.96141
PPO Batch Consumption Time: 0.11151
Total Iteration Time: 2.98661

Cumulative Model Updates: 6,200
Cumulative Timesteps: 103,483,174

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633.34668
Policy Entropy: 0.48360
Value Function Loss: 4.43982

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.02100
Policy Update Magnitude: 0.02983
Value Function Update Magnitude: 0.04349

Collected Steps per Second: 24,454.11396
Overall Steps per Second: 16,715.80021

Timestep Collection Time: 2.04489
Timestep Consumption Time: 0.94665
PPO Batch Consumption Time: 0.11299
Total Iteration Time: 2.99154

Cumulative Model Updates: 6,203
Cumulative Timesteps: 103,533,180

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 103533180...
Checkpoint 103533180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.48101
Policy Entropy: 0.49287
Value Function Loss: 4.47647

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02305
Policy Update Magnitude: 0.02673
Value Function Update Magnitude: 0.04611

Collected Steps per Second: 24,465.39022
Overall Steps per Second: 16,769.26981

Timestep Collection Time: 2.04379
Timestep Consumption Time: 0.93798
PPO Batch Consumption Time: 0.11754
Total Iteration Time: 2.98176

Cumulative Model Updates: 6,206
Cumulative Timesteps: 103,583,182

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 807.99176
Policy Entropy: 0.48795
Value Function Loss: 4.39568

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02831
Policy Update Magnitude: 0.02676
Value Function Update Magnitude: 0.04169

Collected Steps per Second: 24,730.50468
Overall Steps per Second: 17,746.06273

Timestep Collection Time: 2.02285
Timestep Consumption Time: 0.79615
PPO Batch Consumption Time: 0.08077
Total Iteration Time: 2.81899

Cumulative Model Updates: 6,209
Cumulative Timesteps: 103,633,208

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 103633208...
Checkpoint 103633208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.07677
Policy Entropy: 0.50096
Value Function Loss: 4.28269

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02488
Policy Update Magnitude: 0.02467
Value Function Update Magnitude: 0.05375

Collected Steps per Second: 23,438.29981
Overall Steps per Second: 17,356.72341

Timestep Collection Time: 2.13428
Timestep Consumption Time: 0.74783
PPO Batch Consumption Time: 0.06126
Total Iteration Time: 2.88211

Cumulative Model Updates: 6,212
Cumulative Timesteps: 103,683,232

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.59753
Policy Entropy: 0.49167
Value Function Loss: 4.22207

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.02081
Policy Update Magnitude: 0.02546
Value Function Update Magnitude: 0.05255

Collected Steps per Second: 22,145.58430
Overall Steps per Second: 15,293.27399

Timestep Collection Time: 2.25824
Timestep Consumption Time: 1.01183
PPO Batch Consumption Time: 0.12196
Total Iteration Time: 3.27006

Cumulative Model Updates: 6,215
Cumulative Timesteps: 103,733,242

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 103733242...
Checkpoint 103733242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446.57070
Policy Entropy: 0.49206
Value Function Loss: 4.21315

Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.01503
Policy Update Magnitude: 0.02937
Value Function Update Magnitude: 0.05700

Collected Steps per Second: 24,254.74659
Overall Steps per Second: 16,730.08552

Timestep Collection Time: 2.06277
Timestep Consumption Time: 0.92777
PPO Batch Consumption Time: 0.10400
Total Iteration Time: 2.99054

Cumulative Model Updates: 6,218
Cumulative Timesteps: 103,783,274

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.60794
Policy Entropy: 0.49088
Value Function Loss: 4.28088

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03345
Policy Update Magnitude: 0.03132
Value Function Update Magnitude: 0.05938

Collected Steps per Second: 24,601.33160
Overall Steps per Second: 16,714.73582

Timestep Collection Time: 2.03265
Timestep Consumption Time: 0.95908
PPO Batch Consumption Time: 0.10963
Total Iteration Time: 2.99173

Cumulative Model Updates: 6,221
Cumulative Timesteps: 103,833,280

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 103833280...
Checkpoint 103833280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.67744
Policy Entropy: 0.49101
Value Function Loss: 4.43349

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04919
Policy Update Magnitude: 0.02837
Value Function Update Magnitude: 0.05677

Collected Steps per Second: 24,207.33890
Overall Steps per Second: 16,780.11115

Timestep Collection Time: 2.06582
Timestep Consumption Time: 0.91437
PPO Batch Consumption Time: 0.10570
Total Iteration Time: 2.98019

Cumulative Model Updates: 6,224
Cumulative Timesteps: 103,883,288

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 934.33636
Policy Entropy: 0.49744
Value Function Loss: 4.37702

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.04471
Policy Update Magnitude: 0.02293
Value Function Update Magnitude: 0.06011

Collected Steps per Second: 24,066.05489
Overall Steps per Second: 16,687.90545

Timestep Collection Time: 2.07870
Timestep Consumption Time: 0.91904
PPO Batch Consumption Time: 0.10423
Total Iteration Time: 2.99774

Cumulative Model Updates: 6,227
Cumulative Timesteps: 103,933,314

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 103933314...
Checkpoint 103933314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 888.77211
Policy Entropy: 0.49157
Value Function Loss: 4.37714

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03951
Policy Update Magnitude: 0.02117
Value Function Update Magnitude: 0.06060

Collected Steps per Second: 23,951.36034
Overall Steps per Second: 16,687.76000

Timestep Collection Time: 2.08756
Timestep Consumption Time: 0.90864
PPO Batch Consumption Time: 0.11671
Total Iteration Time: 2.99621

Cumulative Model Updates: 6,230
Cumulative Timesteps: 103,983,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 974.28088
Policy Entropy: 0.49028
Value Function Loss: 4.28464

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02825
Policy Update Magnitude: 0.02018
Value Function Update Magnitude: 0.05012

Collected Steps per Second: 24,897.82887
Overall Steps per Second: 16,799.55315

Timestep Collection Time: 2.00925
Timestep Consumption Time: 0.96857
PPO Batch Consumption Time: 0.11228
Total Iteration Time: 2.97782

Cumulative Model Updates: 6,233
Cumulative Timesteps: 104,033,340

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 104033340...
Checkpoint 104033340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.59172
Policy Entropy: 0.49273
Value Function Loss: 4.31955

Mean KL Divergence: 0.00128
SB3 Clip Fraction: 0.01495
Policy Update Magnitude: 0.02792
Value Function Update Magnitude: 0.04365

Collected Steps per Second: 24,627.37090
Overall Steps per Second: 16,753.52114

Timestep Collection Time: 2.03042
Timestep Consumption Time: 0.95426
PPO Batch Consumption Time: 0.10866
Total Iteration Time: 2.98469

Cumulative Model Updates: 6,236
Cumulative Timesteps: 104,083,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647.15660
Policy Entropy: 0.49251
Value Function Loss: 4.29082

Mean KL Divergence: 0.00168
SB3 Clip Fraction: 0.01991
Policy Update Magnitude: 0.03045
Value Function Update Magnitude: 0.04190

Collected Steps per Second: 24,611.63713
Overall Steps per Second: 16,716.00132

Timestep Collection Time: 2.03197
Timestep Consumption Time: 0.95978
PPO Batch Consumption Time: 0.11227
Total Iteration Time: 2.99174

Cumulative Model Updates: 6,239
Cumulative Timesteps: 104,133,354

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 104133354...
Checkpoint 104133354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.98283
Policy Entropy: 0.47643
Value Function Loss: 4.40957

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04657
Policy Update Magnitude: 0.02896
Value Function Update Magnitude: 0.04492

Collected Steps per Second: 24,221.77335
Overall Steps per Second: 16,700.43527

Timestep Collection Time: 2.06492
Timestep Consumption Time: 0.92997
PPO Batch Consumption Time: 0.09879
Total Iteration Time: 2.99489

Cumulative Model Updates: 6,242
Cumulative Timesteps: 104,183,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.86916
Policy Entropy: 0.49197
Value Function Loss: 4.44607

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.03216
Policy Update Magnitude: 0.02308
Value Function Update Magnitude: 0.04273

Collected Steps per Second: 24,424.20243
Overall Steps per Second: 16,781.87557

Timestep Collection Time: 2.04805
Timestep Consumption Time: 0.93267
PPO Batch Consumption Time: 0.11346
Total Iteration Time: 2.98072

Cumulative Model Updates: 6,245
Cumulative Timesteps: 104,233,392

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 104233392...
Checkpoint 104233392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.84251
Policy Entropy: 0.48967
Value Function Loss: 4.44346

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.02167
Policy Update Magnitude: 0.02284
Value Function Update Magnitude: 0.04104

Collected Steps per Second: 24,287.78559
Overall Steps per Second: 16,749.14509

Timestep Collection Time: 2.05964
Timestep Consumption Time: 0.92702
PPO Batch Consumption Time: 0.10975
Total Iteration Time: 2.98666

Cumulative Model Updates: 6,248
Cumulative Timesteps: 104,283,416

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.51520
Policy Entropy: 0.51171
Value Function Loss: 4.23403

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03573
Policy Update Magnitude: 0.02437
Value Function Update Magnitude: 0.04303

Collected Steps per Second: 24,480.22472
Overall Steps per Second: 17,759.64317

Timestep Collection Time: 2.04312
Timestep Consumption Time: 0.77315
PPO Batch Consumption Time: 0.07326
Total Iteration Time: 2.81627

Cumulative Model Updates: 6,251
Cumulative Timesteps: 104,333,432

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 104333432...
Checkpoint 104333432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 887.61742
Policy Entropy: 0.50098
Value Function Loss: 4.16026

Mean KL Divergence: 0.00143
SB3 Clip Fraction: 0.01452
Policy Update Magnitude: 0.02658
Value Function Update Magnitude: 0.03965

Collected Steps per Second: 23,785.92798
Overall Steps per Second: 17,642.00339

Timestep Collection Time: 2.10318
Timestep Consumption Time: 0.73244
PPO Batch Consumption Time: 0.05954
Total Iteration Time: 2.83562

Cumulative Model Updates: 6,254
Cumulative Timesteps: 104,383,458

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.16124
Policy Entropy: 0.50902
Value Function Loss: 4.07379

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01428
Policy Update Magnitude: 0.02947
Value Function Update Magnitude: 0.03778

Collected Steps per Second: 21,945.88291
Overall Steps per Second: 15,912.65718

Timestep Collection Time: 2.27952
Timestep Consumption Time: 0.86427
PPO Batch Consumption Time: 0.07796
Total Iteration Time: 3.14379

Cumulative Model Updates: 6,257
Cumulative Timesteps: 104,433,484

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 104433484...
Checkpoint 104433484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 844.69431
Policy Entropy: 0.49605
Value Function Loss: 4.06016

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.02139
Policy Update Magnitude: 0.03337
Value Function Update Magnitude: 0.04111

Collected Steps per Second: 24,501.84112
Overall Steps per Second: 17,541.97432

Timestep Collection Time: 2.04197
Timestep Consumption Time: 0.81016
PPO Batch Consumption Time: 0.06093
Total Iteration Time: 2.85213

Cumulative Model Updates: 6,260
Cumulative Timesteps: 104,483,516

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 742.19369
Policy Entropy: 0.49205
Value Function Loss: 3.95131

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.02047
Policy Update Magnitude: 0.03172
Value Function Update Magnitude: 0.04297

Collected Steps per Second: 21,868.40282
Overall Steps per Second: 15,180.52073

Timestep Collection Time: 2.28668
Timestep Consumption Time: 1.00741
PPO Batch Consumption Time: 0.12592
Total Iteration Time: 3.29409

Cumulative Model Updates: 6,263
Cumulative Timesteps: 104,533,522

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 104533522...
Checkpoint 104533522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.08263
Policy Entropy: 0.49220
Value Function Loss: 4.01653

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02349
Policy Update Magnitude: 0.03072
Value Function Update Magnitude: 0.04321

Collected Steps per Second: 24,407.81191
Overall Steps per Second: 16,739.80514

Timestep Collection Time: 2.04918
Timestep Consumption Time: 0.93867
PPO Batch Consumption Time: 0.10633
Total Iteration Time: 2.98785

Cumulative Model Updates: 6,266
Cumulative Timesteps: 104,583,538

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 709.19719
Policy Entropy: 0.48004
Value Function Loss: 4.10250

Mean KL Divergence: 0.00114
SB3 Clip Fraction: 0.01013
Policy Update Magnitude: 0.03129
Value Function Update Magnitude: 0.04075

Collected Steps per Second: 24,613.07820
Overall Steps per Second: 16,694.02931

Timestep Collection Time: 2.03152
Timestep Consumption Time: 0.96368
PPO Batch Consumption Time: 0.10956
Total Iteration Time: 2.99520

Cumulative Model Updates: 6,269
Cumulative Timesteps: 104,633,540

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 104633540...
Checkpoint 104633540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480.26364
Policy Entropy: 0.48974
Value Function Loss: 4.24368

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01948
Policy Update Magnitude: 0.03453
Value Function Update Magnitude: 0.04783

Collected Steps per Second: 24,027.96821
Overall Steps per Second: 16,700.02865

Timestep Collection Time: 2.08099
Timestep Consumption Time: 0.91314
PPO Batch Consumption Time: 0.10490
Total Iteration Time: 2.99413

Cumulative Model Updates: 6,272
Cumulative Timesteps: 104,683,542

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 929.37214
Policy Entropy: 0.47963
Value Function Loss: 4.23128

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.02094
Policy Update Magnitude: 0.03000
Value Function Update Magnitude: 0.04562

Collected Steps per Second: 24,473.18478
Overall Steps per Second: 16,772.14004

Timestep Collection Time: 2.04362
Timestep Consumption Time: 0.93834
PPO Batch Consumption Time: 0.11058
Total Iteration Time: 2.98197

Cumulative Model Updates: 6,275
Cumulative Timesteps: 104,733,556

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 104733556...
Checkpoint 104733556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 988.85522
Policy Entropy: 0.49295
Value Function Loss: 4.22964

Mean KL Divergence: 0.00153
SB3 Clip Fraction: 0.01599
Policy Update Magnitude: 0.02945
Value Function Update Magnitude: 0.04834

Collected Steps per Second: 23,955.58029
Overall Steps per Second: 16,787.27140

Timestep Collection Time: 2.08761
Timestep Consumption Time: 0.89143
PPO Batch Consumption Time: 0.11530
Total Iteration Time: 2.97904

Cumulative Model Updates: 6,278
Cumulative Timesteps: 104,783,566

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.59935
Policy Entropy: 0.49152
Value Function Loss: 4.22347

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01775
Policy Update Magnitude: 0.03280
Value Function Update Magnitude: 0.05679

Collected Steps per Second: 24,557.07027
Overall Steps per Second: 16,684.77681

Timestep Collection Time: 2.03664
Timestep Consumption Time: 0.96094
PPO Batch Consumption Time: 0.11061
Total Iteration Time: 2.99758

Cumulative Model Updates: 6,281
Cumulative Timesteps: 104,833,580

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 104833580...
Checkpoint 104833580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703.12884
Policy Entropy: 0.50187
Value Function Loss: 4.06725

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.01643
Policy Update Magnitude: 0.03336
Value Function Update Magnitude: 0.05833

Collected Steps per Second: 24,331.92264
Overall Steps per Second: 16,709.79216

Timestep Collection Time: 2.05615
Timestep Consumption Time: 0.93791
PPO Batch Consumption Time: 0.10319
Total Iteration Time: 2.99405

Cumulative Model Updates: 6,284
Cumulative Timesteps: 104,883,610

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.86857
Policy Entropy: 0.49659
Value Function Loss: 4.02890

Mean KL Divergence: 0.00138
SB3 Clip Fraction: 0.01362
Policy Update Magnitude: 0.03484
Value Function Update Magnitude: 0.05426

Collected Steps per Second: 24,820.64470
Overall Steps per Second: 16,798.03887

Timestep Collection Time: 2.01558
Timestep Consumption Time: 0.96262
PPO Batch Consumption Time: 0.11383
Total Iteration Time: 2.97820

Cumulative Model Updates: 6,287
Cumulative Timesteps: 104,933,638

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 104933638...
Checkpoint 104933638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 789.79258
Policy Entropy: 0.49849
Value Function Loss: 4.02372

Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.01238
Policy Update Magnitude: 0.03293
Value Function Update Magnitude: 0.04732

Collected Steps per Second: 23,791.21277
Overall Steps per Second: 16,657.76432

Timestep Collection Time: 2.10204
Timestep Consumption Time: 0.90017
PPO Batch Consumption Time: 0.09105
Total Iteration Time: 3.00220

Cumulative Model Updates: 6,290
Cumulative Timesteps: 104,983,648

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.54408
Policy Entropy: 0.49796
Value Function Loss: 4.15280

Mean KL Divergence: 0.00098
SB3 Clip Fraction: 0.00946
Policy Update Magnitude: 0.03648
Value Function Update Magnitude: 0.04359

Collected Steps per Second: 24,740.80409
Overall Steps per Second: 16,701.50460

Timestep Collection Time: 2.02136
Timestep Consumption Time: 0.97298
PPO Batch Consumption Time: 0.11710
Total Iteration Time: 2.99434

Cumulative Model Updates: 6,293
Cumulative Timesteps: 105,033,658

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 105033658...
Checkpoint 105033658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.88169
Policy Entropy: 0.49939
Value Function Loss: 4.15445

Mean KL Divergence: 0.00133
SB3 Clip Fraction: 0.01389
Policy Update Magnitude: 0.03682
Value Function Update Magnitude: 0.04912

Collected Steps per Second: 24,245.11479
Overall Steps per Second: 16,811.35660

Timestep Collection Time: 2.06244
Timestep Consumption Time: 0.91198
PPO Batch Consumption Time: 0.10150
Total Iteration Time: 2.97442

Cumulative Model Updates: 6,296
Cumulative Timesteps: 105,083,662

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 982.25848
Policy Entropy: 0.49147
Value Function Loss: 4.06932

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01907
Policy Update Magnitude: 0.03163
Value Function Update Magnitude: 0.05212

Collected Steps per Second: 24,495.62015
Overall Steps per Second: 17,642.90444

Timestep Collection Time: 2.04200
Timestep Consumption Time: 0.79314
PPO Batch Consumption Time: 0.08230
Total Iteration Time: 2.83513

Cumulative Model Updates: 6,299
Cumulative Timesteps: 105,133,682

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 105133682...
Checkpoint 105133682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 923.21942
Policy Entropy: 0.50357
Value Function Loss: 4.00790

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02345
Policy Update Magnitude: 0.02998
Value Function Update Magnitude: 0.04854

Collected Steps per Second: 22,381.24766
Overall Steps per Second: 15,982.03865

Timestep Collection Time: 2.23419
Timestep Consumption Time: 0.89457
PPO Batch Consumption Time: 0.11313
Total Iteration Time: 3.12876

Cumulative Model Updates: 6,302
Cumulative Timesteps: 105,183,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 796.42385
Policy Entropy: 0.49536
Value Function Loss: 3.94247

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01862
Policy Update Magnitude: 0.02628
Value Function Update Magnitude: 0.04493

Collected Steps per Second: 24,705.97451
Overall Steps per Second: 16,705.10950

Timestep Collection Time: 2.02477
Timestep Consumption Time: 0.96976
PPO Batch Consumption Time: 0.11245
Total Iteration Time: 2.99453

Cumulative Model Updates: 6,305
Cumulative Timesteps: 105,233,710

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 105233710...
Checkpoint 105233710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.79998
Policy Entropy: 0.50206
Value Function Loss: 3.96243

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01425
Policy Update Magnitude: 0.02907
Value Function Update Magnitude: 0.03868

Collected Steps per Second: 24,440.19370
Overall Steps per Second: 16,698.65461

Timestep Collection Time: 2.04581
Timestep Consumption Time: 0.94844
PPO Batch Consumption Time: 0.10411
Total Iteration Time: 2.99425

Cumulative Model Updates: 6,308
Cumulative Timesteps: 105,283,710

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701.41185
Policy Entropy: 0.50087
Value Function Loss: 3.96563

Mean KL Divergence: 0.00151
SB3 Clip Fraction: 0.01646
Policy Update Magnitude: 0.02877
Value Function Update Magnitude: 0.03401

Collected Steps per Second: 24,580.29710
Overall Steps per Second: 16,757.27076

Timestep Collection Time: 2.03472
Timestep Consumption Time: 0.94990
PPO Batch Consumption Time: 0.11043
Total Iteration Time: 2.98461

Cumulative Model Updates: 6,311
Cumulative Timesteps: 105,333,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 105333724...
Checkpoint 105333724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 718.63790
Policy Entropy: 0.49731
Value Function Loss: 3.96515

Mean KL Divergence: 0.00125
SB3 Clip Fraction: 0.01249
Policy Update Magnitude: 0.03053
Value Function Update Magnitude: 0.03144

Collected Steps per Second: 24,227.31875
Overall Steps per Second: 16,781.81045

Timestep Collection Time: 2.06387
Timestep Consumption Time: 0.91567
PPO Batch Consumption Time: 0.10595
Total Iteration Time: 2.97954

Cumulative Model Updates: 6,314
Cumulative Timesteps: 105,383,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741.05482
Policy Entropy: 0.48787
Value Function Loss: 3.92769

Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.01258
Policy Update Magnitude: 0.03069
Value Function Update Magnitude: 0.04241

Collected Steps per Second: 24,608.04568
Overall Steps per Second: 17,749.07715

Timestep Collection Time: 2.03307
Timestep Consumption Time: 0.78566
PPO Batch Consumption Time: 0.07421
Total Iteration Time: 2.81874

Cumulative Model Updates: 6,317
Cumulative Timesteps: 105,433,756

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 105433756...
Checkpoint 105433756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.76449
Policy Entropy: 0.49463
Value Function Loss: 3.92001

Mean KL Divergence: 0.00102
SB3 Clip Fraction: 0.00973
Policy Update Magnitude: 0.03109
Value Function Update Magnitude: 0.03910

Collected Steps per Second: 23,617.31820
Overall Steps per Second: 17,598.15459

Timestep Collection Time: 2.11709
Timestep Consumption Time: 0.72412
PPO Batch Consumption Time: 0.05968
Total Iteration Time: 2.84121

Cumulative Model Updates: 6,320
Cumulative Timesteps: 105,483,756

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430.24213
Policy Entropy: 0.49982
Value Function Loss: 3.92166

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01986
Policy Update Magnitude: 0.03084
Value Function Update Magnitude: 0.03818

Collected Steps per Second: 21,765.59032
Overall Steps per Second: 15,111.76383

Timestep Collection Time: 2.29757
Timestep Consumption Time: 1.01164
PPO Batch Consumption Time: 0.12604
Total Iteration Time: 3.30921

Cumulative Model Updates: 6,323
Cumulative Timesteps: 105,533,764

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 105533764...
Checkpoint 105533764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 902.84736
Policy Entropy: 0.50754
Value Function Loss: 3.89591

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.01817
Policy Update Magnitude: 0.02952
Value Function Update Magnitude: 0.03344

Collected Steps per Second: 24,213.33068
Overall Steps per Second: 16,725.74311

Timestep Collection Time: 2.06498
Timestep Consumption Time: 0.92443
PPO Batch Consumption Time: 0.10438
Total Iteration Time: 2.98940

Cumulative Model Updates: 6,326
Cumulative Timesteps: 105,583,764

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 874.38703
Policy Entropy: 0.49632
Value Function Loss: 3.83868

Mean KL Divergence: 0.00132
SB3 Clip Fraction: 0.01549
Policy Update Magnitude: 0.03296
Value Function Update Magnitude: 0.03299

Collected Steps per Second: 24,859.32436
Overall Steps per Second: 16,742.56843

Timestep Collection Time: 2.01172
Timestep Consumption Time: 0.97528
PPO Batch Consumption Time: 0.11553
Total Iteration Time: 2.98700

Cumulative Model Updates: 6,329
Cumulative Timesteps: 105,633,774

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 105633774...
Checkpoint 105633774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567.74329
Policy Entropy: 0.49908
Value Function Loss: 3.85254

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.02194
Policy Update Magnitude: 0.02893
Value Function Update Magnitude: 0.03465

Collected Steps per Second: 24,195.05481
Overall Steps per Second: 16,694.11799

Timestep Collection Time: 2.06695
Timestep Consumption Time: 0.92871
PPO Batch Consumption Time: 0.10041
Total Iteration Time: 2.99567

Cumulative Model Updates: 6,332
Cumulative Timesteps: 105,683,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 725.60807
Policy Entropy: 0.49591
Value Function Loss: 3.79438

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01756
Policy Update Magnitude: 0.03060
Value Function Update Magnitude: 0.03123

Collected Steps per Second: 24,536.91360
Overall Steps per Second: 16,784.91978

Timestep Collection Time: 2.03775
Timestep Consumption Time: 0.94112
PPO Batch Consumption Time: 0.11134
Total Iteration Time: 2.97886

Cumulative Model Updates: 6,335
Cumulative Timesteps: 105,733,784

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 105733784...
Checkpoint 105733784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 832.06798
Policy Entropy: 0.48891
Value Function Loss: 3.85522

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02570
Policy Update Magnitude: 0.02422
Value Function Update Magnitude: 0.03710

Collected Steps per Second: 24,282.39848
Overall Steps per Second: 16,768.62390

Timestep Collection Time: 2.06018
Timestep Consumption Time: 0.92313
PPO Batch Consumption Time: 0.12035
Total Iteration Time: 2.98331

Cumulative Model Updates: 6,338
Cumulative Timesteps: 105,783,810

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.71880
Policy Entropy: 0.48632
Value Function Loss: 3.85471

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02609
Policy Update Magnitude: 0.02545
Value Function Update Magnitude: 0.04181

Collected Steps per Second: 24,144.61663
Overall Steps per Second: 16,717.25146

Timestep Collection Time: 2.07110
Timestep Consumption Time: 0.92018
PPO Batch Consumption Time: 0.12181
Total Iteration Time: 2.99128

Cumulative Model Updates: 6,341
Cumulative Timesteps: 105,833,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 105833816...
Checkpoint 105833816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 848.02615
Policy Entropy: 0.47802
Value Function Loss: 4.01409

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02540
Policy Update Magnitude: 0.02492
Value Function Update Magnitude: 0.05182

Collected Steps per Second: 24,536.04292
Overall Steps per Second: 16,716.47729

Timestep Collection Time: 2.03839
Timestep Consumption Time: 0.95351
PPO Batch Consumption Time: 0.10414
Total Iteration Time: 2.99190

Cumulative Model Updates: 6,344
Cumulative Timesteps: 105,883,830

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 998.80168
Policy Entropy: 0.47417
Value Function Loss: 3.93426

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.02197
Policy Update Magnitude: 0.02525
Value Function Update Magnitude: 0.05526

Collected Steps per Second: 24,833.41834
Overall Steps per Second: 16,726.87749

Timestep Collection Time: 2.01358
Timestep Consumption Time: 0.97586
PPO Batch Consumption Time: 0.11506
Total Iteration Time: 2.98944

Cumulative Model Updates: 6,347
Cumulative Timesteps: 105,933,834

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 105933834...
Checkpoint 105933834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 834.56920
Policy Entropy: 0.47401
Value Function Loss: 3.87564

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.02287
Policy Update Magnitude: 0.02927
Value Function Update Magnitude: 0.06274

Collected Steps per Second: 23,969.70769
Overall Steps per Second: 16,675.05097

Timestep Collection Time: 2.08705
Timestep Consumption Time: 0.91300
PPO Batch Consumption Time: 0.09364
Total Iteration Time: 3.00005

Cumulative Model Updates: 6,350
Cumulative Timesteps: 105,983,860

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 849.80926
Policy Entropy: 0.47257
Value Function Loss: 3.89049

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.03081
Policy Update Magnitude: 0.03071
Value Function Update Magnitude: 0.06804

Collected Steps per Second: 22,874.06471
Overall Steps per Second: 16,671.48209

Timestep Collection Time: 2.18632
Timestep Consumption Time: 0.81341
PPO Batch Consumption Time: 0.07044
Total Iteration Time: 2.99973

Cumulative Model Updates: 6,353
Cumulative Timesteps: 106,033,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 106033870...
Checkpoint 106033870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 904.27390
Policy Entropy: 0.48023
Value Function Loss: 4.01679

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04473
Policy Update Magnitude: 0.02555
Value Function Update Magnitude: 0.05782

Collected Steps per Second: 24,160.98889
Overall Steps per Second: 16,771.76402

Timestep Collection Time: 2.07028
Timestep Consumption Time: 0.91211
PPO Batch Consumption Time: 0.09577
Total Iteration Time: 2.98239

Cumulative Model Updates: 6,356
Cumulative Timesteps: 106,083,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736.02885
Policy Entropy: 0.46582
Value Function Loss: 4.07967

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.04173
Policy Update Magnitude: 0.02237
Value Function Update Magnitude: 0.05396

Collected Steps per Second: 24,680.90892
Overall Steps per Second: 17,673.39199

Timestep Collection Time: 2.02699
Timestep Consumption Time: 0.80370
PPO Batch Consumption Time: 0.07837
Total Iteration Time: 2.83070

Cumulative Model Updates: 6,359
Cumulative Timesteps: 106,133,918

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 106133918...
Checkpoint 106133918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650.73583
Policy Entropy: 0.46859
Value Function Loss: 3.96696

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02640
Policy Update Magnitude: 0.02368
Value Function Update Magnitude: 0.05530

Collected Steps per Second: 22,641.23619
Overall Steps per Second: 15,948.08632

Timestep Collection Time: 2.20969
Timestep Consumption Time: 0.92737
PPO Batch Consumption Time: 0.10210
Total Iteration Time: 3.13705

Cumulative Model Updates: 6,362
Cumulative Timesteps: 106,183,948

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721.60266
Policy Entropy: 0.46910
Value Function Loss: 3.93910

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02378
Policy Update Magnitude: 0.02733
Value Function Update Magnitude: 0.05314

Collected Steps per Second: 24,762.80161
Overall Steps per Second: 16,783.46303

Timestep Collection Time: 2.02021
Timestep Consumption Time: 0.96046
PPO Batch Consumption Time: 0.11074
Total Iteration Time: 2.98067

Cumulative Model Updates: 6,365
Cumulative Timesteps: 106,233,974

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 106233974...
Checkpoint 106233974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 851.89287
Policy Entropy: 0.47508
Value Function Loss: 3.93365

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.02169
Policy Update Magnitude: 0.02703
Value Function Update Magnitude: 0.04807

Collected Steps per Second: 24,453.08104
Overall Steps per Second: 16,707.43508

Timestep Collection Time: 2.04481
Timestep Consumption Time: 0.94799
PPO Batch Consumption Time: 0.10429
Total Iteration Time: 2.99280

Cumulative Model Updates: 6,368
Cumulative Timesteps: 106,283,976

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670.11003
Policy Entropy: 0.47429
Value Function Loss: 3.85597

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01967
Policy Update Magnitude: 0.02598
Value Function Update Magnitude: 0.04464

Collected Steps per Second: 24,764.60699
Overall Steps per Second: 16,785.80498

Timestep Collection Time: 2.01950
Timestep Consumption Time: 0.95993
PPO Batch Consumption Time: 0.11975
Total Iteration Time: 2.97942

Cumulative Model Updates: 6,371
Cumulative Timesteps: 106,333,988

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 106333988...
Checkpoint 106333988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 954.99244
Policy Entropy: 0.47238
Value Function Loss: 3.84138

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01829
Policy Update Magnitude: 0.03134
Value Function Update Magnitude: 0.04277

Collected Steps per Second: 23,812.47202
Overall Steps per Second: 16,738.50050

Timestep Collection Time: 2.09974
Timestep Consumption Time: 0.88739
PPO Batch Consumption Time: 0.11023
Total Iteration Time: 2.98713

Cumulative Model Updates: 6,374
Cumulative Timesteps: 106,383,988

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.58255
Policy Entropy: 0.46087
Value Function Loss: 3.73845

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.02071
Policy Update Magnitude: 0.02999
Value Function Update Magnitude: 0.04624

Collected Steps per Second: 23,957.56679
Overall Steps per Second: 16,709.56044

Timestep Collection Time: 2.08744
Timestep Consumption Time: 0.90546
PPO Batch Consumption Time: 0.11865
Total Iteration Time: 2.99290

Cumulative Model Updates: 6,377
Cumulative Timesteps: 106,433,998

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 106433998...
Checkpoint 106433998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 801.29317
Policy Entropy: 0.46800
Value Function Loss: 3.80963

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01878
Policy Update Magnitude: 0.02956
Value Function Update Magnitude: 0.04033

Collected Steps per Second: 24,584.42384
Overall Steps per Second: 16,763.63106

Timestep Collection Time: 2.03430
Timestep Consumption Time: 0.94907
PPO Batch Consumption Time: 0.10528
Total Iteration Time: 2.98336

Cumulative Model Updates: 6,380
Cumulative Timesteps: 106,484,010

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 999.65735
Policy Entropy: 0.46511
Value Function Loss: 3.85712

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04749
Policy Update Magnitude: 0.03250
Value Function Update Magnitude: 0.03975

Collected Steps per Second: 25,062.17175
Overall Steps per Second: 16,712.44635

Timestep Collection Time: 1.99512
Timestep Consumption Time: 0.99678
PPO Batch Consumption Time: 0.12197
Total Iteration Time: 2.99190

Cumulative Model Updates: 6,383
Cumulative Timesteps: 106,534,012

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 106534012...
Checkpoint 106534012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 691.63283
Policy Entropy: 0.45823
Value Function Loss: 3.94189

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03628
Policy Update Magnitude: 0.03610
Value Function Update Magnitude: 0.04053

Collected Steps per Second: 24,455.07584
Overall Steps per Second: 16,735.99004

Timestep Collection Time: 2.04514
Timestep Consumption Time: 0.94327
PPO Batch Consumption Time: 0.10389
Total Iteration Time: 2.98841

Cumulative Model Updates: 6,386
Cumulative Timesteps: 106,584,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.57405
Policy Entropy: 0.46248
Value Function Loss: 3.92926

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02417
Policy Update Magnitude: 0.03421
Value Function Update Magnitude: 0.03879

Collected Steps per Second: 24,777.63257
Overall Steps per Second: 16,732.10813

Timestep Collection Time: 2.01819
Timestep Consumption Time: 0.97043
PPO Batch Consumption Time: 0.11542
Total Iteration Time: 2.98863

Cumulative Model Updates: 6,389
Cumulative Timesteps: 106,634,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 106634032...
Checkpoint 106634032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.02674
Policy Entropy: 0.45423
Value Function Loss: 3.88646

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.03397
Policy Update Magnitude: 0.03010
Value Function Update Magnitude: 0.03794

Collected Steps per Second: 24,199.04481
Overall Steps per Second: 16,693.81924

Timestep Collection Time: 2.06645
Timestep Consumption Time: 0.92903
PPO Batch Consumption Time: 0.10465
Total Iteration Time: 2.99548

Cumulative Model Updates: 6,392
Cumulative Timesteps: 106,684,038

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 997.68797
Policy Entropy: 0.46507
Value Function Loss: 3.85558

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02697
Policy Update Magnitude: 0.02696
Value Function Update Magnitude: 0.04203

Collected Steps per Second: 24,534.38905
Overall Steps per Second: 16,760.94194

Timestep Collection Time: 2.03893
Timestep Consumption Time: 0.94562
PPO Batch Consumption Time: 0.11259
Total Iteration Time: 2.98456

Cumulative Model Updates: 6,395
Cumulative Timesteps: 106,734,062

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 106734062...
Checkpoint 106734062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.01952
Policy Entropy: 0.46519
Value Function Loss: 3.84492

Mean KL Divergence: 0.00133
SB3 Clip Fraction: 0.01315
Policy Update Magnitude: 0.03140
Value Function Update Magnitude: 0.03472

Collected Steps per Second: 24,489.00075
Overall Steps per Second: 17,822.86713

Timestep Collection Time: 2.04296
Timestep Consumption Time: 0.76411
PPO Batch Consumption Time: 0.07495
Total Iteration Time: 2.80707

Cumulative Model Updates: 6,398
Cumulative Timesteps: 106,784,092

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 850.95477
Policy Entropy: 0.47019
Value Function Loss: 3.81934

Mean KL Divergence: 0.00117
SB3 Clip Fraction: 0.01097
Policy Update Magnitude: 0.03750
Value Function Update Magnitude: 0.02773

Collected Steps per Second: 24,852.34728
Overall Steps per Second: 17,830.49778

Timestep Collection Time: 2.01285
Timestep Consumption Time: 0.79268
PPO Batch Consumption Time: 0.05874
Total Iteration Time: 2.80553

Cumulative Model Updates: 6,401
Cumulative Timesteps: 106,834,116

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 106834116...
Checkpoint 106834116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700.55302
Policy Entropy: 0.46467
Value Function Loss: 3.89177

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01457
Policy Update Magnitude: 0.03630
Value Function Update Magnitude: 0.02805

Collected Steps per Second: 21,004.03943
Overall Steps per Second: 14,946.79938

Timestep Collection Time: 2.38202
Timestep Consumption Time: 0.96532
PPO Batch Consumption Time: 0.11165
Total Iteration Time: 3.34734

Cumulative Model Updates: 6,404
Cumulative Timesteps: 106,884,148

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.74792
Policy Entropy: 0.46253
Value Function Loss: 3.89530

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.02087
Policy Update Magnitude: 0.03203
Value Function Update Magnitude: 0.03206

Collected Steps per Second: 24,836.84925
Overall Steps per Second: 16,734.50643

Timestep Collection Time: 2.01346
Timestep Consumption Time: 0.97486
PPO Batch Consumption Time: 0.11527
Total Iteration Time: 2.98832

Cumulative Model Updates: 6,407
Cumulative Timesteps: 106,934,156

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 106934156...
Checkpoint 106934156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 942.13541
Policy Entropy: 0.46042
Value Function Loss: 3.85187

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01927
Policy Update Magnitude: 0.02825
Value Function Update Magnitude: 0.03041

Collected Steps per Second: 24,492.43148
Overall Steps per Second: 16,722.10272

Timestep Collection Time: 2.04177
Timestep Consumption Time: 0.94876
PPO Batch Consumption Time: 0.10445
Total Iteration Time: 2.99053

Cumulative Model Updates: 6,410
Cumulative Timesteps: 106,984,164

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 748.05478
Policy Entropy: 0.46273
Value Function Loss: 3.80020

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02594
Policy Update Magnitude: 0.02722
Value Function Update Magnitude: 0.02453

Collected Steps per Second: 24,495.44370
Overall Steps per Second: 16,732.05741

Timestep Collection Time: 2.04234
Timestep Consumption Time: 0.94761
PPO Batch Consumption Time: 0.11631
Total Iteration Time: 2.98995

Cumulative Model Updates: 6,413
Cumulative Timesteps: 107,034,192

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 107034192...
Checkpoint 107034192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.09214
Policy Entropy: 0.46789
Value Function Loss: 3.84059

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.02393
Policy Update Magnitude: 0.02613
Value Function Update Magnitude: 0.02607

Collected Steps per Second: 24,103.84524
Overall Steps per Second: 16,698.35888

Timestep Collection Time: 2.07444
Timestep Consumption Time: 0.91999
PPO Batch Consumption Time: 0.10258
Total Iteration Time: 2.99443

Cumulative Model Updates: 6,416
Cumulative Timesteps: 107,084,194

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.28002
Policy Entropy: 0.47600
Value Function Loss: 3.82316

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03569
Policy Update Magnitude: 0.02680
Value Function Update Magnitude: 0.02559

Collected Steps per Second: 24,654.12550
Overall Steps per Second: 17,701.70597

Timestep Collection Time: 2.02863
Timestep Consumption Time: 0.79675
PPO Batch Consumption Time: 0.07746
Total Iteration Time: 2.82538

Cumulative Model Updates: 6,419
Cumulative Timesteps: 107,134,208

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 107134208...
Checkpoint 107134208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.79065
Policy Entropy: 0.47924
Value Function Loss: 3.83049

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03704
Policy Update Magnitude: 0.02446
Value Function Update Magnitude: 0.02474

Collected Steps per Second: 24,468.44117
Overall Steps per Second: 17,673.87002

Timestep Collection Time: 2.04361
Timestep Consumption Time: 0.78565
PPO Batch Consumption Time: 0.05899
Total Iteration Time: 2.82926

Cumulative Model Updates: 6,422
Cumulative Timesteps: 107,184,212

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 803.94594
Policy Entropy: 0.47935
Value Function Loss: 3.75767

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.04155
Policy Update Magnitude: 0.02496
Value Function Update Magnitude: 0.02835

Collected Steps per Second: 21,613.07437
Overall Steps per Second: 15,146.45771

Timestep Collection Time: 2.31388
Timestep Consumption Time: 0.98788
PPO Batch Consumption Time: 0.11873
Total Iteration Time: 3.30176

Cumulative Model Updates: 6,425
Cumulative Timesteps: 107,234,222

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 107234222...
Checkpoint 107234222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 912.51939
Policy Entropy: 0.48167
Value Function Loss: 3.65539

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03977
Policy Update Magnitude: 0.02253
Value Function Update Magnitude: 0.02659

Collected Steps per Second: 24,362.78308
Overall Steps per Second: 16,753.84099

Timestep Collection Time: 2.05321
Timestep Consumption Time: 0.93249
PPO Batch Consumption Time: 0.10394
Total Iteration Time: 2.98570

Cumulative Model Updates: 6,428
Cumulative Timesteps: 107,284,244

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 979.90057
Policy Entropy: 0.47914
Value Function Loss: 3.62972

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03850
Policy Update Magnitude: 0.02259
Value Function Update Magnitude: 0.02658

Collected Steps per Second: 24,378.86248
Overall Steps per Second: 16,688.41887

Timestep Collection Time: 2.05170
Timestep Consumption Time: 0.94547
PPO Batch Consumption Time: 0.10358
Total Iteration Time: 2.99717

Cumulative Model Updates: 6,431
Cumulative Timesteps: 107,334,262

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 107334262...
Checkpoint 107334262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680.74296
Policy Entropy: 0.48278
Value Function Loss: 3.60381

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03956
Policy Update Magnitude: 0.02451
Value Function Update Magnitude: 0.02597

Collected Steps per Second: 23,929.36549
Overall Steps per Second: 16,699.35900

Timestep Collection Time: 2.08948
Timestep Consumption Time: 0.90464
PPO Batch Consumption Time: 0.09166
Total Iteration Time: 2.99413

Cumulative Model Updates: 6,434
Cumulative Timesteps: 107,384,262

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703.78858
Policy Entropy: 0.48103
Value Function Loss: 3.61818

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03763
Policy Update Magnitude: 0.02340
Value Function Update Magnitude: 0.02465

Collected Steps per Second: 24,604.31504
Overall Steps per Second: 16,791.52192

Timestep Collection Time: 2.03257
Timestep Consumption Time: 0.94572
PPO Batch Consumption Time: 0.11330
Total Iteration Time: 2.97829

Cumulative Model Updates: 6,437
Cumulative Timesteps: 107,434,272

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 107434272...
Checkpoint 107434272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 727.92403
Policy Entropy: 0.48291
Value Function Loss: 3.62925

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03481
Policy Update Magnitude: 0.02300
Value Function Update Magnitude: 0.02853

Collected Steps per Second: 24,332.17505
Overall Steps per Second: 16,750.33125

Timestep Collection Time: 2.05555
Timestep Consumption Time: 0.93042
PPO Batch Consumption Time: 0.10971
Total Iteration Time: 2.98597

Cumulative Model Updates: 6,440
Cumulative Timesteps: 107,484,288

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 861.28495
Policy Entropy: 0.48681
Value Function Loss: 3.69608

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02920
Policy Update Magnitude: 0.02060
Value Function Update Magnitude: 0.02269

Collected Steps per Second: 24,694.69878
Overall Steps per Second: 17,783.62587

Timestep Collection Time: 2.02586
Timestep Consumption Time: 0.78729
PPO Batch Consumption Time: 0.07975
Total Iteration Time: 2.81315

Cumulative Model Updates: 6,443
Cumulative Timesteps: 107,534,316

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 107534316...
Checkpoint 107534316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609.52062
Policy Entropy: 0.48432
Value Function Loss: 3.66828

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.01924
Policy Update Magnitude: 0.02306
Value Function Update Magnitude: 0.02470

Collected Steps per Second: 24,350.20241
Overall Steps per Second: 17,647.82844

Timestep Collection Time: 2.05403
Timestep Consumption Time: 0.78009
PPO Batch Consumption Time: 0.05937
Total Iteration Time: 2.83412

Cumulative Model Updates: 6,446
Cumulative Timesteps: 107,584,332

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 993.20947
Policy Entropy: 0.48723
Value Function Loss: 3.59956

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.02149
Policy Update Magnitude: 0.02400
Value Function Update Magnitude: 0.02264

Collected Steps per Second: 21,559.46386
Overall Steps per Second: 15,063.13562

Timestep Collection Time: 2.31954
Timestep Consumption Time: 1.00035
PPO Batch Consumption Time: 0.12462
Total Iteration Time: 3.31989

Cumulative Model Updates: 6,449
Cumulative Timesteps: 107,634,340

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 107634340...
Checkpoint 107634340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646.04203
Policy Entropy: 0.48134
Value Function Loss: 3.58835

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.02257
Policy Update Magnitude: 0.02654
Value Function Update Magnitude: 0.02190

Collected Steps per Second: 23,929.07599
Overall Steps per Second: 16,659.29444

Timestep Collection Time: 2.08984
Timestep Consumption Time: 0.91197
PPO Batch Consumption Time: 0.09513
Total Iteration Time: 3.00181

Cumulative Model Updates: 6,452
Cumulative Timesteps: 107,684,348

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.12422
Policy Entropy: 0.46902
Value Function Loss: 3.60758

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01997
Policy Update Magnitude: 0.03243
Value Function Update Magnitude: 0.02249

Collected Steps per Second: 24,707.21759
Overall Steps per Second: 16,795.96975

Timestep Collection Time: 2.02378
Timestep Consumption Time: 0.95324
PPO Batch Consumption Time: 0.10897
Total Iteration Time: 2.97702

Cumulative Model Updates: 6,455
Cumulative Timesteps: 107,734,350

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 107734350...
Checkpoint 107734350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 785.51885
Policy Entropy: 0.48012
Value Function Loss: 3.61355

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.03142
Policy Update Magnitude: 0.03310
Value Function Update Magnitude: 0.02087

Collected Steps per Second: 24,191.83012
Overall Steps per Second: 16,696.86777

Timestep Collection Time: 2.06698
Timestep Consumption Time: 0.92783
PPO Batch Consumption Time: 0.09829
Total Iteration Time: 2.99481

Cumulative Model Updates: 6,458
Cumulative Timesteps: 107,784,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.47274
Policy Entropy: 0.47141
Value Function Loss: 3.56746

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02928
Policy Update Magnitude: 0.02371
Value Function Update Magnitude: 0.02240

Collected Steps per Second: 24,729.28392
Overall Steps per Second: 16,785.95968

Timestep Collection Time: 2.02214
Timestep Consumption Time: 0.95690
PPO Batch Consumption Time: 0.11357
Total Iteration Time: 2.97904

Cumulative Model Updates: 6,461
Cumulative Timesteps: 107,834,360

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 107834360...
Checkpoint 107834360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.70257
Policy Entropy: 0.47725
Value Function Loss: 3.51735

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.02167
Policy Update Magnitude: 0.02374
Value Function Update Magnitude: 0.02063

Collected Steps per Second: 24,303.31320
Overall Steps per Second: 17,595.31823

Timestep Collection Time: 2.05807
Timestep Consumption Time: 0.78461
PPO Batch Consumption Time: 0.07894
Total Iteration Time: 2.84269

Cumulative Model Updates: 6,464
Cumulative Timesteps: 107,884,378

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 794.13242
Policy Entropy: 0.47625
Value Function Loss: 3.62011

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01659
Policy Update Magnitude: 0.02531
Value Function Update Magnitude: 0.02076

Collected Steps per Second: 21,020.46836
Overall Steps per Second: 14,998.17155

Timestep Collection Time: 2.37997
Timestep Consumption Time: 0.95564
PPO Batch Consumption Time: 0.11089
Total Iteration Time: 3.33561

Cumulative Model Updates: 6,467
Cumulative Timesteps: 107,934,406

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 107934406...
Checkpoint 107934406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659.94421
Policy Entropy: 0.47726
Value Function Loss: 3.68469

Mean KL Divergence: 0.00121
SB3 Clip Fraction: 0.01331
Policy Update Magnitude: 0.03217
Value Function Update Magnitude: 0.01948

Collected Steps per Second: 24,438.84208
Overall Steps per Second: 17,254.42475

Timestep Collection Time: 2.04715
Timestep Consumption Time: 0.85240
PPO Batch Consumption Time: 0.06343
Total Iteration Time: 2.89955

Cumulative Model Updates: 6,470
Cumulative Timesteps: 107,984,436

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 810.09235
Policy Entropy: 0.47972
Value Function Loss: 3.71909

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01771
Policy Update Magnitude: 0.02880
Value Function Update Magnitude: 0.02904

Collected Steps per Second: 21,372.73937
Overall Steps per Second: 15,214.90946

Timestep Collection Time: 2.34027
Timestep Consumption Time: 0.94716
PPO Batch Consumption Time: 0.10641
Total Iteration Time: 3.28743

Cumulative Model Updates: 6,473
Cumulative Timesteps: 108,034,454

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 108034454...
Checkpoint 108034454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608.02551
Policy Entropy: 0.48602
Value Function Loss: 3.60210

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.01486
Policy Update Magnitude: 0.02870
Value Function Update Magnitude: 0.04272

Collected Steps per Second: 24,810.13068
Overall Steps per Second: 17,896.89737

Timestep Collection Time: 2.01603
Timestep Consumption Time: 0.77875
PPO Batch Consumption Time: 0.05797
Total Iteration Time: 2.79479

Cumulative Model Updates: 6,476
Cumulative Timesteps: 108,084,472

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.55908
Policy Entropy: 0.48367
Value Function Loss: 3.52127

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01909
Policy Update Magnitude: 0.03084
Value Function Update Magnitude: 0.04387

Collected Steps per Second: 21,497.51768
Overall Steps per Second: 15,640.83122

Timestep Collection Time: 2.32632
Timestep Consumption Time: 0.87109
PPO Batch Consumption Time: 0.07932
Total Iteration Time: 3.19740

Cumulative Model Updates: 6,479
Cumulative Timesteps: 108,134,482

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 108134482...
Checkpoint 108134482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.87460
Policy Entropy: 0.48635
Value Function Loss: 3.49635

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01743
Policy Update Magnitude: 0.02903
Value Function Update Magnitude: 0.04155

Collected Steps per Second: 24,370.34388
Overall Steps per Second: 17,726.57806

Timestep Collection Time: 2.05282
Timestep Consumption Time: 0.76938
PPO Batch Consumption Time: 0.06034
Total Iteration Time: 2.82220

Cumulative Model Updates: 6,482
Cumulative Timesteps: 108,184,510

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.19122
Policy Entropy: 0.48801
Value Function Loss: 3.50767

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02481
Policy Update Magnitude: 0.02867
Value Function Update Magnitude: 0.03863

Collected Steps per Second: 21,220.98193
Overall Steps per Second: 14,874.73675

Timestep Collection Time: 2.35729
Timestep Consumption Time: 1.00573
PPO Batch Consumption Time: 0.12565
Total Iteration Time: 3.36302

Cumulative Model Updates: 6,485
Cumulative Timesteps: 108,234,534

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 108234534...
Checkpoint 108234534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.72329
Policy Entropy: 0.47729
Value Function Loss: 3.47211

Mean KL Divergence: 0.00135
SB3 Clip Fraction: 0.01335
Policy Update Magnitude: 0.02665
Value Function Update Magnitude: 0.03981

Collected Steps per Second: 24,655.73264
Overall Steps per Second: 18,006.88688

Timestep Collection Time: 2.02817
Timestep Consumption Time: 0.74888
PPO Batch Consumption Time: 0.06701
Total Iteration Time: 2.77705

Cumulative Model Updates: 6,488
Cumulative Timesteps: 108,284,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723.14161
Policy Entropy: 0.48665
Value Function Loss: 3.46648

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.02189
Policy Update Magnitude: 0.02938
Value Function Update Magnitude: 0.03641

Collected Steps per Second: 24,892.99963
Overall Steps per Second: 16,863.55255

Timestep Collection Time: 2.00892
Timestep Consumption Time: 0.95653
PPO Batch Consumption Time: 0.11454
Total Iteration Time: 2.96545

Cumulative Model Updates: 6,491
Cumulative Timesteps: 108,334,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 108334548...
Checkpoint 108334548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 851.24941
Policy Entropy: 0.48173
Value Function Loss: 3.50802

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.03177
Policy Update Magnitude: 0.02739
Value Function Update Magnitude: 0.03867

Collected Steps per Second: 24,668.99043
Overall Steps per Second: 17,813.89773

Timestep Collection Time: 2.02740
Timestep Consumption Time: 0.78018
PPO Batch Consumption Time: 0.05894
Total Iteration Time: 2.80758

Cumulative Model Updates: 6,494
Cumulative Timesteps: 108,384,562

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.51925
Policy Entropy: 0.49008
Value Function Loss: 3.37953

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.04259
Policy Update Magnitude: 0.02860
Value Function Update Magnitude: 0.04909

Collected Steps per Second: 21,512.21742
Overall Steps per Second: 15,650.46032

Timestep Collection Time: 2.32435
Timestep Consumption Time: 0.87057
PPO Batch Consumption Time: 0.07857
Total Iteration Time: 3.19492

Cumulative Model Updates: 6,497
Cumulative Timesteps: 108,434,564

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 108434564...
Checkpoint 108434564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.26379
Policy Entropy: 0.48535
Value Function Loss: 3.39455

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04729
Policy Update Magnitude: 0.02501
Value Function Update Magnitude: 0.05270

Collected Steps per Second: 24,691.75675
Overall Steps per Second: 17,762.14772

Timestep Collection Time: 2.02497
Timestep Consumption Time: 0.79001
PPO Batch Consumption Time: 0.05882
Total Iteration Time: 2.81497

Cumulative Model Updates: 6,500
Cumulative Timesteps: 108,484,564

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720.24564
Policy Entropy: 0.48523
Value Function Loss: 3.25724

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04385
Policy Update Magnitude: 0.02325
Value Function Update Magnitude: 0.05466

Collected Steps per Second: 21,546.91884
Overall Steps per Second: 14,963.55696

Timestep Collection Time: 2.32098
Timestep Consumption Time: 1.02114
PPO Batch Consumption Time: 0.12961
Total Iteration Time: 3.34212

Cumulative Model Updates: 6,503
Cumulative Timesteps: 108,534,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 108534574...
Checkpoint 108534574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 962.77820
Policy Entropy: 0.47563
Value Function Loss: 3.47055

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.04215
Policy Update Magnitude: 0.02378
Value Function Update Magnitude: 0.04821

Collected Steps per Second: 24,517.40338
Overall Steps per Second: 16,916.52603

Timestep Collection Time: 2.04027
Timestep Consumption Time: 0.91673
PPO Batch Consumption Time: 0.10145
Total Iteration Time: 2.95699

Cumulative Model Updates: 6,506
Cumulative Timesteps: 108,584,596

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.45225
Policy Entropy: 0.47083
Value Function Loss: 3.46997

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.04123
Policy Update Magnitude: 0.02292
Value Function Update Magnitude: 0.04183

Collected Steps per Second: 24,831.31601
Overall Steps per Second: 17,780.63815

Timestep Collection Time: 2.01471
Timestep Consumption Time: 0.79891
PPO Batch Consumption Time: 0.08155
Total Iteration Time: 2.81362

Cumulative Model Updates: 6,509
Cumulative Timesteps: 108,634,624

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 108634624...
Checkpoint 108634624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 798.10874
Policy Entropy: 0.46164
Value Function Loss: 3.60267

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04211
Policy Update Magnitude: 0.02194
Value Function Update Magnitude: 0.04047

Collected Steps per Second: 24,435.77391
Overall Steps per Second: 17,637.58535

Timestep Collection Time: 2.04716
Timestep Consumption Time: 0.78905
PPO Batch Consumption Time: 0.06043
Total Iteration Time: 2.83622

Cumulative Model Updates: 6,512
Cumulative Timesteps: 108,684,648

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 892.92761
Policy Entropy: 0.47271
Value Function Loss: 3.41409

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03853
Policy Update Magnitude: 0.02051
Value Function Update Magnitude: 0.03589

Collected Steps per Second: 21,433.25925
Overall Steps per Second: 14,943.62167

Timestep Collection Time: 2.33432
Timestep Consumption Time: 1.01373
PPO Batch Consumption Time: 0.12423
Total Iteration Time: 3.34805

Cumulative Model Updates: 6,515
Cumulative Timesteps: 108,734,680

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 108734680...
Checkpoint 108734680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696.17361
Policy Entropy: 0.46843
Value Function Loss: 3.47586

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03570
Policy Update Magnitude: 0.02170
Value Function Update Magnitude: 0.03636

Collected Steps per Second: 24,738.24674
Overall Steps per Second: 16,925.06756

Timestep Collection Time: 2.02181
Timestep Consumption Time: 0.93333
PPO Batch Consumption Time: 0.10626
Total Iteration Time: 2.95514

Cumulative Model Updates: 6,518
Cumulative Timesteps: 108,784,696

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.55381
Policy Entropy: 0.47963
Value Function Loss: 3.45082

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03351
Policy Update Magnitude: 0.02166
Value Function Update Magnitude: 0.03586

Collected Steps per Second: 24,909.13987
Overall Steps per Second: 16,752.26550

Timestep Collection Time: 2.00754
Timestep Consumption Time: 0.97749
PPO Batch Consumption Time: 0.11703
Total Iteration Time: 2.98503

Cumulative Model Updates: 6,521
Cumulative Timesteps: 108,834,702

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 108834702...
Checkpoint 108834702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503.52971
Policy Entropy: 0.47190
Value Function Loss: 3.56389

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03787
Policy Update Magnitude: 0.02309
Value Function Update Magnitude: 0.03686

Collected Steps per Second: 24,748.22374
Overall Steps per Second: 16,731.67090

Timestep Collection Time: 2.02083
Timestep Consumption Time: 0.96823
PPO Batch Consumption Time: 0.11569
Total Iteration Time: 2.98906

Cumulative Model Updates: 6,524
Cumulative Timesteps: 108,884,714

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.82761
Policy Entropy: 0.47844
Value Function Loss: 3.54481

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03429
Policy Update Magnitude: 0.02180
Value Function Update Magnitude: 0.03552

Collected Steps per Second: 24,871.61569
Overall Steps per Second: 16,739.66124

Timestep Collection Time: 2.01057
Timestep Consumption Time: 0.97671
PPO Batch Consumption Time: 0.12647
Total Iteration Time: 2.98728

Cumulative Model Updates: 6,527
Cumulative Timesteps: 108,934,720

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 108934720...
Checkpoint 108934720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.42941
Policy Entropy: 0.47137
Value Function Loss: 3.58066

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03784
Policy Update Magnitude: 0.02419
Value Function Update Magnitude: 0.04117

Collected Steps per Second: 25,118.00295
Overall Steps per Second: 17,826.67429

Timestep Collection Time: 1.99188
Timestep Consumption Time: 0.81470
PPO Batch Consumption Time: 0.09124
Total Iteration Time: 2.80658

Cumulative Model Updates: 6,530
Cumulative Timesteps: 108,984,752

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.14671
Policy Entropy: 0.47120
Value Function Loss: 3.57098

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.03236
Policy Update Magnitude: 0.02279
Value Function Update Magnitude: 0.03753

Collected Steps per Second: 24,264.02534
Overall Steps per Second: 18,029.48401

Timestep Collection Time: 2.06174
Timestep Consumption Time: 0.71294
PPO Batch Consumption Time: 0.05859
Total Iteration Time: 2.77468

Cumulative Model Updates: 6,533
Cumulative Timesteps: 109,034,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 109034778...
Checkpoint 109034778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 873.88659
Policy Entropy: 0.47795
Value Function Loss: 3.51875

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02997
Policy Update Magnitude: 0.02106
Value Function Update Magnitude: 0.03632

Collected Steps per Second: 21,821.75476
Overall Steps per Second: 15,616.97969

Timestep Collection Time: 2.29157
Timestep Consumption Time: 0.91046
PPO Batch Consumption Time: 0.09411
Total Iteration Time: 3.20203

Cumulative Model Updates: 6,536
Cumulative Timesteps: 109,084,784

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.53988
Policy Entropy: 0.46917
Value Function Loss: 3.51119

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01961
Policy Update Magnitude: 0.02290
Value Function Update Magnitude: 0.03840

Collected Steps per Second: 24,951.81125
Overall Steps per Second: 17,958.66619

Timestep Collection Time: 2.00394
Timestep Consumption Time: 0.78034
PPO Batch Consumption Time: 0.05937
Total Iteration Time: 2.78428

Cumulative Model Updates: 6,539
Cumulative Timesteps: 109,134,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 109134786...
Checkpoint 109134786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.18839
Policy Entropy: 0.47844
Value Function Loss: 3.54193

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01359
Policy Update Magnitude: 0.02315
Value Function Update Magnitude: 0.04924

Collected Steps per Second: 21,400.51893
Overall Steps per Second: 14,812.31593

Timestep Collection Time: 2.33733
Timestep Consumption Time: 1.03959
PPO Batch Consumption Time: 0.12873
Total Iteration Time: 3.37692

Cumulative Model Updates: 6,542
Cumulative Timesteps: 109,184,806

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 780.89603
Policy Entropy: 0.48228
Value Function Loss: 3.56430

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01579
Policy Update Magnitude: 0.02454
Value Function Update Magnitude: 0.04091

Collected Steps per Second: 25,014.53089
Overall Steps per Second: 16,750.71266

Timestep Collection Time: 1.99988
Timestep Consumption Time: 0.98662
PPO Batch Consumption Time: 0.11932
Total Iteration Time: 2.98650

Cumulative Model Updates: 6,545
Cumulative Timesteps: 109,234,832

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 109234832...
Checkpoint 109234832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 888.87050
Policy Entropy: 0.48509
Value Function Loss: 3.50724

Mean KL Divergence: 0.00104
SB3 Clip Fraction: 0.00971
Policy Update Magnitude: 0.02482
Value Function Update Magnitude: 0.03778

Collected Steps per Second: 24,958.53094
Overall Steps per Second: 16,760.36624

Timestep Collection Time: 2.00396
Timestep Consumption Time: 0.98022
PPO Batch Consumption Time: 0.11641
Total Iteration Time: 2.98418

Cumulative Model Updates: 6,548
Cumulative Timesteps: 109,284,848

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 786.07843
Policy Entropy: 0.49244
Value Function Loss: 3.44902

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02479
Policy Update Magnitude: 0.02599
Value Function Update Magnitude: 0.03564

Collected Steps per Second: 25,011.12281
Overall Steps per Second: 17,570.82223

Timestep Collection Time: 1.99927
Timestep Consumption Time: 0.84658
PPO Batch Consumption Time: 0.08136
Total Iteration Time: 2.84585

Cumulative Model Updates: 6,551
Cumulative Timesteps: 109,334,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 109334852...
Checkpoint 109334852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711.21912
Policy Entropy: 0.49064
Value Function Loss: 3.44922

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.01441
Policy Update Magnitude: 0.02473
Value Function Update Magnitude: 0.03153

Collected Steps per Second: 22,882.39391
Overall Steps per Second: 16,024.32063

Timestep Collection Time: 2.18605
Timestep Consumption Time: 0.93558
PPO Batch Consumption Time: 0.12634
Total Iteration Time: 3.12163

Cumulative Model Updates: 6,554
Cumulative Timesteps: 109,384,874

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 898.34805
Policy Entropy: 0.49356
Value Function Loss: 3.46829

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03871
Policy Update Magnitude: 0.02456
Value Function Update Magnitude: 0.03747

Collected Steps per Second: 25,203.04553
Overall Steps per Second: 16,701.07123

Timestep Collection Time: 1.98428
Timestep Consumption Time: 1.01013
PPO Batch Consumption Time: 0.12426
Total Iteration Time: 2.99442

Cumulative Model Updates: 6,557
Cumulative Timesteps: 109,434,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 109434884...
Checkpoint 109434884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684.67878
Policy Entropy: 0.48236
Value Function Loss: 3.43178

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03781
Policy Update Magnitude: 0.02391
Value Function Update Magnitude: 0.04221

Collected Steps per Second: 25,499.34648
Overall Steps per Second: 17,763.80982

Timestep Collection Time: 1.96091
Timestep Consumption Time: 0.85391
PPO Batch Consumption Time: 0.07769
Total Iteration Time: 2.81482

Cumulative Model Updates: 6,560
Cumulative Timesteps: 109,484,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 725.39797
Policy Entropy: 0.47763
Value Function Loss: 3.48876

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02610
Policy Update Magnitude: 0.02248
Value Function Update Magnitude: 0.03528

Collected Steps per Second: 24,759.57555
Overall Steps per Second: 17,646.63118

Timestep Collection Time: 2.02055
Timestep Consumption Time: 0.81444
PPO Batch Consumption Time: 0.06095
Total Iteration Time: 2.83499

Cumulative Model Updates: 6,563
Cumulative Timesteps: 109,534,914

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 109534914...
Checkpoint 109534914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652.12175
Policy Entropy: 0.47036
Value Function Loss: 3.43072

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02719
Policy Update Magnitude: 0.02240
Value Function Update Magnitude: 0.03711

Collected Steps per Second: 21,329.75998
Overall Steps per Second: 14,916.39902

Timestep Collection Time: 2.34536
Timestep Consumption Time: 1.00840
PPO Batch Consumption Time: 0.12807
Total Iteration Time: 3.35376

Cumulative Model Updates: 6,566
Cumulative Timesteps: 109,584,940

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 777.53623
Policy Entropy: 0.47785
Value Function Loss: 3.46567

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.01213
Policy Update Magnitude: 0.02783
Value Function Update Magnitude: 0.04234

Collected Steps per Second: 25,137.72204
Overall Steps per Second: 16,948.84287

Timestep Collection Time: 1.98904
Timestep Consumption Time: 0.96101
PPO Batch Consumption Time: 0.11948
Total Iteration Time: 2.95005

Cumulative Model Updates: 6,569
Cumulative Timesteps: 109,634,940

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 109634940...
Checkpoint 109634940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 756.56748
Policy Entropy: 0.48183
Value Function Loss: 3.44395

Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.01521
Policy Update Magnitude: 0.03207
Value Function Update Magnitude: 0.04871

Collected Steps per Second: 24,650.76724
Overall Steps per Second: 17,770.84226

Timestep Collection Time: 2.02898
Timestep Consumption Time: 0.78551
PPO Batch Consumption Time: 0.08215
Total Iteration Time: 2.81450

Cumulative Model Updates: 6,572
Cumulative Timesteps: 109,684,956

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.72202
Policy Entropy: 0.48839
Value Function Loss: 3.49078

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02339
Policy Update Magnitude: 0.03116
Value Function Update Magnitude: 0.04188

Collected Steps per Second: 24,815.60674
Overall Steps per Second: 17,834.62307

Timestep Collection Time: 2.01591
Timestep Consumption Time: 0.78908
PPO Batch Consumption Time: 0.05893
Total Iteration Time: 2.80499

Cumulative Model Updates: 6,575
Cumulative Timesteps: 109,734,982

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 109734982...
Checkpoint 109734982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 932.87656
Policy Entropy: 0.48769
Value Function Loss: 3.57106

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01959
Policy Update Magnitude: 0.02756
Value Function Update Magnitude: 0.03838

Collected Steps per Second: 21,544.84554
Overall Steps per Second: 14,928.57325

Timestep Collection Time: 2.32167
Timestep Consumption Time: 1.02895
PPO Batch Consumption Time: 0.12934
Total Iteration Time: 3.35062

Cumulative Model Updates: 6,578
Cumulative Timesteps: 109,785,002

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738.97078
Policy Entropy: 0.48686
Value Function Loss: 3.50834

Mean KL Divergence: 0.00133
SB3 Clip Fraction: 0.01299
Policy Update Magnitude: 0.03110
Value Function Update Magnitude: 0.03169

Collected Steps per Second: 24,980.73871
Overall Steps per Second: 16,742.71080

Timestep Collection Time: 2.00194
Timestep Consumption Time: 0.98503
PPO Batch Consumption Time: 0.11734
Total Iteration Time: 2.98697

Cumulative Model Updates: 6,581
Cumulative Timesteps: 109,835,012

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 109835012...
Checkpoint 109835012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.13292
Policy Entropy: 0.49010
Value Function Loss: 3.41056

Mean KL Divergence: 0.00113
SB3 Clip Fraction: 0.01190
Policy Update Magnitude: 0.03459
Value Function Update Magnitude: 0.02672

Collected Steps per Second: 24,635.33551
Overall Steps per Second: 16,739.10954

Timestep Collection Time: 2.03009
Timestep Consumption Time: 0.95764
PPO Batch Consumption Time: 0.11130
Total Iteration Time: 2.98773

Cumulative Model Updates: 6,584
Cumulative Timesteps: 109,885,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 985.12303
Policy Entropy: 0.49397
Value Function Loss: 3.29177

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01566
Policy Update Magnitude: 0.03644
Value Function Update Magnitude: 0.04412

Collected Steps per Second: 24,514.60595
Overall Steps per Second: 16,700.36214

Timestep Collection Time: 2.04009
Timestep Consumption Time: 0.95458
PPO Batch Consumption Time: 0.10698
Total Iteration Time: 2.99467

Cumulative Model Updates: 6,587
Cumulative Timesteps: 109,935,036

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 109935036...
Checkpoint 109935036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.13698
Policy Entropy: 0.49564
Value Function Loss: 3.24237

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01338
Policy Update Magnitude: 0.03555
Value Function Update Magnitude: 0.05234

Collected Steps per Second: 24,593.07057
Overall Steps per Second: 16,775.16557

Timestep Collection Time: 2.03407
Timestep Consumption Time: 0.94796
PPO Batch Consumption Time: 0.11402
Total Iteration Time: 2.98203

Cumulative Model Updates: 6,590
Cumulative Timesteps: 109,985,060

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.84281
Policy Entropy: 0.50197
Value Function Loss: 3.26929

Mean KL Divergence: 0.00138
SB3 Clip Fraction: 0.01481
Policy Update Magnitude: 0.03461
Value Function Update Magnitude: 0.05144

Collected Steps per Second: 24,924.43299
Overall Steps per Second: 17,575.04686

Timestep Collection Time: 2.00703
Timestep Consumption Time: 0.83928
PPO Batch Consumption Time: 0.08116
Total Iteration Time: 2.84631

Cumulative Model Updates: 6,593
Cumulative Timesteps: 110,035,084

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 110035084...
Checkpoint 110035084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 840.21216
Policy Entropy: 0.48998
Value Function Loss: 3.46692

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01899
Policy Update Magnitude: 0.03357
Value Function Update Magnitude: 0.04443

Collected Steps per Second: 23,486.25163
Overall Steps per Second: 16,970.52107

Timestep Collection Time: 2.12942
Timestep Consumption Time: 0.81758
PPO Batch Consumption Time: 0.09072
Total Iteration Time: 2.94699

Cumulative Model Updates: 6,596
Cumulative Timesteps: 110,085,096

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 791.37989
Policy Entropy: 0.49122
Value Function Loss: 3.46630

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01862
Policy Update Magnitude: 0.03132
Value Function Update Magnitude: 0.04525

Collected Steps per Second: 24,254.92241
Overall Steps per Second: 18,068.44343

Timestep Collection Time: 2.06168
Timestep Consumption Time: 0.70590
PPO Batch Consumption Time: 0.05939
Total Iteration Time: 2.76759

Cumulative Model Updates: 6,599
Cumulative Timesteps: 110,135,102

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 110135102...
Checkpoint 110135102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 764.32974
Policy Entropy: 0.49349
Value Function Loss: 3.46055

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02534
Policy Update Magnitude: 0.03108
Value Function Update Magnitude: 0.03894

Collected Steps per Second: 21,487.05172
Overall Steps per Second: 15,435.57159

Timestep Collection Time: 2.32838
Timestep Consumption Time: 0.91284
PPO Batch Consumption Time: 0.08948
Total Iteration Time: 3.24121

Cumulative Model Updates: 6,602
Cumulative Timesteps: 110,185,132

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618.65897
Policy Entropy: 0.49544
Value Function Loss: 3.21538

Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.01569
Policy Update Magnitude: 0.02869
Value Function Update Magnitude: 0.03700

Collected Steps per Second: 25,159.36958
Overall Steps per Second: 18,109.50626

Timestep Collection Time: 1.98844
Timestep Consumption Time: 0.77408
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 2.76253

Cumulative Model Updates: 6,605
Cumulative Timesteps: 110,235,160

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 110235160...
Checkpoint 110235160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654.73297
Policy Entropy: 0.49965
Value Function Loss: 3.18705

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.02198
Policy Update Magnitude: 0.02841
Value Function Update Magnitude: 0.03299

Collected Steps per Second: 21,555.89159
Overall Steps per Second: 14,859.67821

Timestep Collection Time: 2.32094
Timestep Consumption Time: 1.04589
PPO Batch Consumption Time: 0.13060
Total Iteration Time: 3.36683

Cumulative Model Updates: 6,608
Cumulative Timesteps: 110,285,190

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 977.79749
Policy Entropy: 0.49504
Value Function Loss: 3.11354

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01968
Policy Update Magnitude: 0.02754
Value Function Update Magnitude: 0.04225

Collected Steps per Second: 20,339.37169
Overall Steps per Second: 12,622.21399

Timestep Collection Time: 2.45966
Timestep Consumption Time: 1.50383
PPO Batch Consumption Time: 0.25416
Total Iteration Time: 3.96349

Cumulative Model Updates: 6,611
Cumulative Timesteps: 110,335,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 110335218...
Checkpoint 110335218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 875.80579
Policy Entropy: 0.50163
Value Function Loss: 3.11815

Mean KL Divergence: 0.00133
SB3 Clip Fraction: 0.01347
Policy Update Magnitude: 0.02802
Value Function Update Magnitude: 0.04072

Collected Steps per Second: 10,452.22667
Overall Steps per Second: 8,564.06613

Timestep Collection Time: 4.78654
Timestep Consumption Time: 1.05531
PPO Batch Consumption Time: 0.08516
Total Iteration Time: 5.84185

Cumulative Model Updates: 6,614
Cumulative Timesteps: 110,385,248

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575.68121
Policy Entropy: 0.48933
Value Function Loss: 3.18696

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01423
Policy Update Magnitude: 0.02879
Value Function Update Magnitude: 0.03416

Collected Steps per Second: 21,691.82627
Overall Steps per Second: 16,111.87081

Timestep Collection Time: 2.30575
Timestep Consumption Time: 0.79854
PPO Batch Consumption Time: 0.06150
Total Iteration Time: 3.10430

Cumulative Model Updates: 6,617
Cumulative Timesteps: 110,435,264

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 110435264...
Checkpoint 110435264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.32454
Policy Entropy: 0.49839
Value Function Loss: 3.26986

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01463
Policy Update Magnitude: 0.03433
Value Function Update Magnitude: 0.04384

Collected Steps per Second: 21,413.41371
Overall Steps per Second: 15,607.06874

Timestep Collection Time: 2.33629
Timestep Consumption Time: 0.86918
PPO Batch Consumption Time: 0.08659
Total Iteration Time: 3.20547

Cumulative Model Updates: 6,620
Cumulative Timesteps: 110,485,292

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 884.95774
Policy Entropy: 0.49223
Value Function Loss: 3.33640

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02569
Policy Update Magnitude: 0.03000
Value Function Update Magnitude: 0.04766

Collected Steps per Second: 24,273.25735
Overall Steps per Second: 16,767.61866

Timestep Collection Time: 2.06004
Timestep Consumption Time: 0.92213
PPO Batch Consumption Time: 0.10270
Total Iteration Time: 2.98218

Cumulative Model Updates: 6,623
Cumulative Timesteps: 110,535,296

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 110535296...
Checkpoint 110535296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 834.47045
Policy Entropy: 0.50265
Value Function Loss: 3.26061

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01851
Policy Update Magnitude: 0.02884
Value Function Update Magnitude: 0.04250

Collected Steps per Second: 24,411.88008
Overall Steps per Second: 16,837.02562

Timestep Collection Time: 2.04851
Timestep Consumption Time: 0.92161
PPO Batch Consumption Time: 0.12078
Total Iteration Time: 2.97012

Cumulative Model Updates: 6,626
Cumulative Timesteps: 110,585,304

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 980.11175
Policy Entropy: 0.49645
Value Function Loss: 3.21674

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.01110
Policy Update Magnitude: 0.03139
Value Function Update Magnitude: 0.03977

Collected Steps per Second: 23,696.51072
Overall Steps per Second: 16,684.14716

Timestep Collection Time: 2.11103
Timestep Consumption Time: 0.88727
PPO Batch Consumption Time: 0.11123
Total Iteration Time: 2.99830

Cumulative Model Updates: 6,629
Cumulative Timesteps: 110,635,328

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 110635328...
Checkpoint 110635328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.39777
Policy Entropy: 0.51110
Value Function Loss: 3.20986

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01587
Policy Update Magnitude: 0.03174
Value Function Update Magnitude: 0.03871

Collected Steps per Second: 24,543.81855
Overall Steps per Second: 16,780.80216

Timestep Collection Time: 2.03791
Timestep Consumption Time: 0.94276
PPO Batch Consumption Time: 0.10445
Total Iteration Time: 2.98067

Cumulative Model Updates: 6,632
Cumulative Timesteps: 110,685,346

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659.02097
Policy Entropy: 0.51397
Value Function Loss: 3.19428

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01510
Policy Update Magnitude: 0.03331
Value Function Update Magnitude: 0.04421

Collected Steps per Second: 24,040.88171
Overall Steps per Second: 16,629.93140

Timestep Collection Time: 2.08087
Timestep Consumption Time: 0.92732
PPO Batch Consumption Time: 0.10309
Total Iteration Time: 3.00819

Cumulative Model Updates: 6,635
Cumulative Timesteps: 110,735,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 110735372...
Checkpoint 110735372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 907.29107
Policy Entropy: 0.50489
Value Function Loss: 3.16374

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01784
Policy Update Magnitude: 0.03253
Value Function Update Magnitude: 0.05713

Collected Steps per Second: 24,268.90329
Overall Steps per Second: 16,735.68892

Timestep Collection Time: 2.06132
Timestep Consumption Time: 0.92786
PPO Batch Consumption Time: 0.09087
Total Iteration Time: 2.98918

Cumulative Model Updates: 6,638
Cumulative Timesteps: 110,785,398

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.86634
Policy Entropy: 0.50007
Value Function Loss: 3.13698

Mean KL Divergence: 0.00138
SB3 Clip Fraction: 0.01436
Policy Update Magnitude: 0.03125
Value Function Update Magnitude: 0.04804

Collected Steps per Second: 24,265.15621
Overall Steps per Second: 16,803.25245

Timestep Collection Time: 2.06123
Timestep Consumption Time: 0.91534
PPO Batch Consumption Time: 0.10570
Total Iteration Time: 2.97657

Cumulative Model Updates: 6,641
Cumulative Timesteps: 110,835,414

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 110835414...
Checkpoint 110835414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 786.54725
Policy Entropy: 0.49391
Value Function Loss: 3.12208

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01381
Policy Update Magnitude: 0.03331
Value Function Update Magnitude: 0.04154

Collected Steps per Second: 22,711.15206
Overall Steps per Second: 15,751.67407

Timestep Collection Time: 2.20271
Timestep Consumption Time: 0.97321
PPO Batch Consumption Time: 0.12268
Total Iteration Time: 3.17592

Cumulative Model Updates: 6,644
Cumulative Timesteps: 110,885,440

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 844.15577
Policy Entropy: 0.49847
Value Function Loss: 3.12161

Mean KL Divergence: 0.00144
SB3 Clip Fraction: 0.01518
Policy Update Magnitude: 0.03154
Value Function Update Magnitude: 0.04470

Collected Steps per Second: 25,036.43996
Overall Steps per Second: 17,962.33002

Timestep Collection Time: 1.99829
Timestep Consumption Time: 0.78699
PPO Batch Consumption Time: 0.05848
Total Iteration Time: 2.78527

Cumulative Model Updates: 6,647
Cumulative Timesteps: 110,935,470

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 110935470...
Checkpoint 110935470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 877.06710
Policy Entropy: 0.50303
Value Function Loss: 3.13726

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.01628
Policy Update Magnitude: 0.03052
Value Function Update Magnitude: 0.03914

Collected Steps per Second: 21,222.89406
Overall Steps per Second: 15,586.53993

Timestep Collection Time: 2.35679
Timestep Consumption Time: 0.85226
PPO Batch Consumption Time: 0.10352
Total Iteration Time: 3.20905

Cumulative Model Updates: 6,650
Cumulative Timesteps: 110,985,488

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.58458
Policy Entropy: 0.50447
Value Function Loss: 3.08173

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.01256
Policy Update Magnitude: 0.03195
Value Function Update Magnitude: 0.03352

Collected Steps per Second: 23,993.24855
Overall Steps per Second: 17,781.48767

Timestep Collection Time: 2.08500
Timestep Consumption Time: 0.72837
PPO Batch Consumption Time: 0.06028
Total Iteration Time: 2.81338

Cumulative Model Updates: 6,653
Cumulative Timesteps: 111,035,514

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 111035514...
Checkpoint 111035514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.20316
Policy Entropy: 0.50541
Value Function Loss: 3.05672

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.02283
Policy Update Magnitude: 0.02914
Value Function Update Magnitude: 0.03481

Collected Steps per Second: 20,960.12200
Overall Steps per Second: 14,937.70064

Timestep Collection Time: 2.38796
Timestep Consumption Time: 0.96275
PPO Batch Consumption Time: 0.11543
Total Iteration Time: 3.35072

Cumulative Model Updates: 6,656
Cumulative Timesteps: 111,085,566

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 980.07000
Policy Entropy: 0.51044
Value Function Loss: 3.01487

Mean KL Divergence: 0.00094
SB3 Clip Fraction: 0.00880
Policy Update Magnitude: 0.02712
Value Function Update Magnitude: 0.04194

Collected Steps per Second: 24,134.75476
Overall Steps per Second: 17,333.31171

Timestep Collection Time: 2.07270
Timestep Consumption Time: 0.81331
PPO Batch Consumption Time: 0.06335
Total Iteration Time: 2.88600

Cumulative Model Updates: 6,659
Cumulative Timesteps: 111,135,590

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 111135590...
Checkpoint 111135590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 911.85790
Policy Entropy: 0.50438
Value Function Loss: 3.16302

Mean KL Divergence: 0.00151
SB3 Clip Fraction: 0.01673
Policy Update Magnitude: 0.02840
Value Function Update Magnitude: 0.03968

Collected Steps per Second: 21,150.07630
Overall Steps per Second: 15,141.24087

Timestep Collection Time: 2.36548
Timestep Consumption Time: 0.93874
PPO Batch Consumption Time: 0.09949
Total Iteration Time: 3.30422

Cumulative Model Updates: 6,662
Cumulative Timesteps: 111,185,620

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.42297
Policy Entropy: 0.50908
Value Function Loss: 3.24543

Mean KL Divergence: 0.00122
SB3 Clip Fraction: 0.01251
Policy Update Magnitude: 0.02929
Value Function Update Magnitude: 0.04299

Collected Steps per Second: 24,464.64147
Overall Steps per Second: 16,740.18790

Timestep Collection Time: 2.04377
Timestep Consumption Time: 0.94306
PPO Batch Consumption Time: 0.10419
Total Iteration Time: 2.98682

Cumulative Model Updates: 6,665
Cumulative Timesteps: 111,235,620

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 111235620...
Checkpoint 111235620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.49983
Policy Entropy: 0.50858
Value Function Loss: 3.18175

Mean KL Divergence: 0.00120
SB3 Clip Fraction: 0.01064
Policy Update Magnitude: 0.03317
Value Function Update Magnitude: 0.04156

Collected Steps per Second: 24,107.50236
Overall Steps per Second: 16,732.82956

Timestep Collection Time: 2.07479
Timestep Consumption Time: 0.91442
PPO Batch Consumption Time: 0.09271
Total Iteration Time: 2.98921

Cumulative Model Updates: 6,668
Cumulative Timesteps: 111,285,638

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 815.21757
Policy Entropy: 0.52118
Value Function Loss: 3.19907

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02367
Policy Update Magnitude: 0.03385
Value Function Update Magnitude: 0.04432

Collected Steps per Second: 24,539.50404
Overall Steps per Second: 16,802.40328

Timestep Collection Time: 2.03810
Timestep Consumption Time: 0.93850
PPO Batch Consumption Time: 0.11135
Total Iteration Time: 2.97660

Cumulative Model Updates: 6,671
Cumulative Timesteps: 111,335,652

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 111335652...
Checkpoint 111335652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.54269
Policy Entropy: 0.50423
Value Function Loss: 3.10606

Mean KL Divergence: 0.00115
SB3 Clip Fraction: 0.00933
Policy Update Magnitude: 0.03039
Value Function Update Magnitude: 0.05056

Collected Steps per Second: 24,123.33394
Overall Steps per Second: 16,636.87063

Timestep Collection Time: 2.07384
Timestep Consumption Time: 0.93321
PPO Batch Consumption Time: 0.11849
Total Iteration Time: 3.00706

Cumulative Model Updates: 6,674
Cumulative Timesteps: 111,385,680

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 756.41597
Policy Entropy: 0.51481
Value Function Loss: 3.26970

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.01209
Policy Update Magnitude: 0.03394
Value Function Update Magnitude: 0.04043

Collected Steps per Second: 23,960.11239
Overall Steps per Second: 16,753.70325

Timestep Collection Time: 2.08789
Timestep Consumption Time: 0.89808
PPO Batch Consumption Time: 0.11533
Total Iteration Time: 2.98597

Cumulative Model Updates: 6,677
Cumulative Timesteps: 111,435,706

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 111435706...
Checkpoint 111435706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.35982
Policy Entropy: 0.50904
Value Function Loss: 3.23367

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.02047
Policy Update Magnitude: 0.03174
Value Function Update Magnitude: 0.04186

Collected Steps per Second: 23,632.11180
Overall Steps per Second: 16,735.02230

Timestep Collection Time: 2.11712
Timestep Consumption Time: 0.87254
PPO Batch Consumption Time: 0.08513
Total Iteration Time: 2.98966

Cumulative Model Updates: 6,680
Cumulative Timesteps: 111,485,738

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 962.55048
Policy Entropy: 0.50886
Value Function Loss: 3.40326

Mean KL Divergence: 0.00153
SB3 Clip Fraction: 0.01556
Policy Update Magnitude: 0.03080
Value Function Update Magnitude: 0.04304

Collected Steps per Second: 24,929.66011
Overall Steps per Second: 16,824.73139

Timestep Collection Time: 2.00637
Timestep Consumption Time: 0.96652
PPO Batch Consumption Time: 0.11032
Total Iteration Time: 2.97289

Cumulative Model Updates: 6,683
Cumulative Timesteps: 111,535,756

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 111535756...
Checkpoint 111535756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.34800
Policy Entropy: 0.49601
Value Function Loss: 3.34252

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01311
Policy Update Magnitude: 0.03520
Value Function Update Magnitude: 0.03538

Collected Steps per Second: 23,741.69289
Overall Steps per Second: 16,671.16443

Timestep Collection Time: 2.10709
Timestep Consumption Time: 0.89366
PPO Batch Consumption Time: 0.08740
Total Iteration Time: 3.00075

Cumulative Model Updates: 6,686
Cumulative Timesteps: 111,585,782

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801.14744
Policy Entropy: 0.49767
Value Function Loss: 3.23356

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.00883
Policy Update Magnitude: 0.03645
Value Function Update Magnitude: 0.04268

Collected Steps per Second: 24,801.90485
Overall Steps per Second: 16,742.95665

Timestep Collection Time: 2.01662
Timestep Consumption Time: 0.97067
PPO Batch Consumption Time: 0.10765
Total Iteration Time: 2.98729

Cumulative Model Updates: 6,689
Cumulative Timesteps: 111,635,798

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 111635798...
Checkpoint 111635798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.73009
Policy Entropy: 0.50643
Value Function Loss: 3.05992

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.02100
Policy Update Magnitude: 0.03391
Value Function Update Magnitude: 0.04026

Collected Steps per Second: 24,508.55006
Overall Steps per Second: 16,843.75634

Timestep Collection Time: 2.04076
Timestep Consumption Time: 0.92865
PPO Batch Consumption Time: 0.10366
Total Iteration Time: 2.96941

Cumulative Model Updates: 6,692
Cumulative Timesteps: 111,685,814

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.77915
Policy Entropy: 0.51570
Value Function Loss: 3.03578

Mean KL Divergence: 0.00132
SB3 Clip Fraction: 0.01334
Policy Update Magnitude: 0.03309
Value Function Update Magnitude: 0.04281

Collected Steps per Second: 24,140.41344
Overall Steps per Second: 16,698.17536

Timestep Collection Time: 2.07196
Timestep Consumption Time: 0.92346
PPO Batch Consumption Time: 0.10897
Total Iteration Time: 2.99542

Cumulative Model Updates: 6,695
Cumulative Timesteps: 111,735,832

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 111735832...
Checkpoint 111735832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 920.51291
Policy Entropy: 0.50623
Value Function Loss: 3.06778

Mean KL Divergence: 0.00134
SB3 Clip Fraction: 0.01418
Policy Update Magnitude: 0.03143
Value Function Update Magnitude: 0.03897

Collected Steps per Second: 24,223.83290
Overall Steps per Second: 16,750.93990

Timestep Collection Time: 2.06483
Timestep Consumption Time: 0.92116
PPO Batch Consumption Time: 0.10449
Total Iteration Time: 2.98598

Cumulative Model Updates: 6,698
Cumulative Timesteps: 111,785,850

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,378.79206
Policy Entropy: 0.50735
Value Function Loss: 3.12479

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.02186
Policy Update Magnitude: 0.03243
Value Function Update Magnitude: 0.04145

Collected Steps per Second: 24,245.48542
Overall Steps per Second: 17,581.38641

Timestep Collection Time: 2.06298
Timestep Consumption Time: 0.78196
PPO Batch Consumption Time: 0.07994
Total Iteration Time: 2.84494

Cumulative Model Updates: 6,701
Cumulative Timesteps: 111,835,868

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 111835868...
Checkpoint 111835868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,828.25552
Policy Entropy: 0.51474
Value Function Loss: 3.03217

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01937
Policy Update Magnitude: 0.02980
Value Function Update Magnitude: 0.03899

Collected Steps per Second: 22,113.45586
Overall Steps per Second: 15,940.02752

Timestep Collection Time: 2.26242
Timestep Consumption Time: 0.87622
PPO Batch Consumption Time: 0.10577
Total Iteration Time: 3.13864

Cumulative Model Updates: 6,704
Cumulative Timesteps: 111,885,898

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.17553
Policy Entropy: 0.52083
Value Function Loss: 2.98188

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.01444
Policy Update Magnitude: 0.03742
Value Function Update Magnitude: 0.03699

Collected Steps per Second: 23,987.28096
Overall Steps per Second: 16,679.20047

Timestep Collection Time: 2.08519
Timestep Consumption Time: 0.91364
PPO Batch Consumption Time: 0.09082
Total Iteration Time: 2.99882

Cumulative Model Updates: 6,707
Cumulative Timesteps: 111,935,916

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 111935916...
Checkpoint 111935916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.64144
Policy Entropy: 0.51304
Value Function Loss: 2.99489

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02555
Policy Update Magnitude: 0.02901
Value Function Update Magnitude: 0.03600

Collected Steps per Second: 24,136.45767
Overall Steps per Second: 16,748.05171

Timestep Collection Time: 2.07313
Timestep Consumption Time: 0.91456
PPO Batch Consumption Time: 0.08507
Total Iteration Time: 2.98769

Cumulative Model Updates: 6,710
Cumulative Timesteps: 111,985,954

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.43386
Policy Entropy: 0.51741
Value Function Loss: 3.09486

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02500
Policy Update Magnitude: 0.02600
Value Function Update Magnitude: 0.04771

Collected Steps per Second: 24,864.02548
Overall Steps per Second: 16,829.12041

Timestep Collection Time: 2.01190
Timestep Consumption Time: 0.96056
PPO Batch Consumption Time: 0.11392
Total Iteration Time: 2.97247

Cumulative Model Updates: 6,713
Cumulative Timesteps: 112,035,978

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 112035978...
Checkpoint 112035978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.83442
Policy Entropy: 0.51350
Value Function Loss: 3.02728

Mean KL Divergence: 0.00079
SB3 Clip Fraction: 0.00603
Policy Update Magnitude: 0.03050
Value Function Update Magnitude: 0.04671

Collected Steps per Second: 23,855.26617
Overall Steps per Second: 16,681.14435

Timestep Collection Time: 2.09757
Timestep Consumption Time: 0.90211
PPO Batch Consumption Time: 0.09376
Total Iteration Time: 2.99967

Cumulative Model Updates: 6,716
Cumulative Timesteps: 112,086,016

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 731.48797
Policy Entropy: 0.51488
Value Function Loss: 2.98055

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.02050
Policy Update Magnitude: 0.03058
Value Function Update Magnitude: 0.03862

Collected Steps per Second: 24,626.83188
Overall Steps per Second: 16,802.66763

Timestep Collection Time: 2.03152
Timestep Consumption Time: 0.94598
PPO Batch Consumption Time: 0.11076
Total Iteration Time: 2.97750

Cumulative Model Updates: 6,719
Cumulative Timesteps: 112,136,046

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 112136046...
Checkpoint 112136046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.27355
Policy Entropy: 0.51273
Value Function Loss: 2.91028

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.01559
Policy Update Magnitude: 0.02840
Value Function Update Magnitude: 0.04041

Collected Steps per Second: 23,877.27425
Overall Steps per Second: 16,706.88472

Timestep Collection Time: 2.09572
Timestep Consumption Time: 0.89946
PPO Batch Consumption Time: 0.09806
Total Iteration Time: 2.99517

Cumulative Model Updates: 6,722
Cumulative Timesteps: 112,186,086

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 807.11258
Policy Entropy: 0.51168
Value Function Loss: 2.99556

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.02073
Policy Update Magnitude: 0.03037
Value Function Update Magnitude: 0.03546

Collected Steps per Second: 24,589.37789
Overall Steps per Second: 16,775.31533

Timestep Collection Time: 2.03446
Timestep Consumption Time: 0.94766
PPO Batch Consumption Time: 0.11888
Total Iteration Time: 2.98212

Cumulative Model Updates: 6,725
Cumulative Timesteps: 112,236,112

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 112236112...
Checkpoint 112236112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 960.48951
Policy Entropy: 0.51453
Value Function Loss: 2.98222

Mean KL Divergence: 0.00097
SB3 Clip Fraction: 0.00903
Policy Update Magnitude: 0.02887
Value Function Update Magnitude: 0.03820

Collected Steps per Second: 24,004.15733
Overall Steps per Second: 16,785.27974

Timestep Collection Time: 2.08422
Timestep Consumption Time: 0.89637
PPO Batch Consumption Time: 0.11232
Total Iteration Time: 2.98059

Cumulative Model Updates: 6,728
Cumulative Timesteps: 112,286,142

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,354.02841
Policy Entropy: 0.51127
Value Function Loss: 3.10619

Mean KL Divergence: 0.00099
SB3 Clip Fraction: 0.00902
Policy Update Magnitude: 0.03251
Value Function Update Magnitude: 0.03940

Collected Steps per Second: 23,366.83155
Overall Steps per Second: 16,638.81722

Timestep Collection Time: 2.14064
Timestep Consumption Time: 0.86558
PPO Batch Consumption Time: 0.10320
Total Iteration Time: 3.00622

Cumulative Model Updates: 6,731
Cumulative Timesteps: 112,336,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 112336162...
Checkpoint 112336162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 912.73924
Policy Entropy: 0.50687
Value Function Loss: 3.12874

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.01039
Policy Update Magnitude: 0.03392
Value Function Update Magnitude: 0.03855

Collected Steps per Second: 24,400.74168
Overall Steps per Second: 16,756.41194

Timestep Collection Time: 2.04945
Timestep Consumption Time: 0.93496
PPO Batch Consumption Time: 0.10254
Total Iteration Time: 2.98441

Cumulative Model Updates: 6,734
Cumulative Timesteps: 112,386,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.03513
Policy Entropy: 0.51858
Value Function Loss: 3.00416

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01939
Policy Update Magnitude: 0.03223
Value Function Update Magnitude: 0.03637

Collected Steps per Second: 24,530.40060
Overall Steps per Second: 16,633.99291

Timestep Collection Time: 2.03845
Timestep Consumption Time: 0.96768
PPO Batch Consumption Time: 0.10854
Total Iteration Time: 3.00613

Cumulative Model Updates: 6,737
Cumulative Timesteps: 112,436,174

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 112436174...
Checkpoint 112436174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,272.57291
Policy Entropy: 0.51984
Value Function Loss: 2.90802

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01916
Policy Update Magnitude: 0.03091
Value Function Update Magnitude: 0.03082

Collected Steps per Second: 24,307.43402
Overall Steps per Second: 16,788.81485

Timestep Collection Time: 2.05731
Timestep Consumption Time: 0.92134
PPO Batch Consumption Time: 0.10099
Total Iteration Time: 2.97865

Cumulative Model Updates: 6,740
Cumulative Timesteps: 112,486,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.40084
Policy Entropy: 0.51784
Value Function Loss: 2.88693

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.02019
Policy Update Magnitude: 0.03251
Value Function Update Magnitude: 0.03851

Collected Steps per Second: 23,242.10169
Overall Steps per Second: 16,534.76655

Timestep Collection Time: 2.15170
Timestep Consumption Time: 0.87284
PPO Batch Consumption Time: 0.07828
Total Iteration Time: 3.02454

Cumulative Model Updates: 6,743
Cumulative Timesteps: 112,536,192

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 112536192...
Checkpoint 112536192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.98286
Policy Entropy: 0.52692
Value Function Loss: 3.03026

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.03005
Policy Update Magnitude: 0.03042
Value Function Update Magnitude: 0.03662

Collected Steps per Second: 22,774.18256
Overall Steps per Second: 15,891.68423

Timestep Collection Time: 2.19696
Timestep Consumption Time: 0.95148
PPO Batch Consumption Time: 0.09612
Total Iteration Time: 3.14844

Cumulative Model Updates: 6,746
Cumulative Timesteps: 112,586,226

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.98128
Policy Entropy: 0.52889
Value Function Loss: 2.94274

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.03054
Policy Update Magnitude: 0.02598
Value Function Update Magnitude: 0.03565

Collected Steps per Second: 24,474.67840
Overall Steps per Second: 17,752.88121

Timestep Collection Time: 2.04358
Timestep Consumption Time: 0.77376
PPO Batch Consumption Time: 0.05997
Total Iteration Time: 2.81735

Cumulative Model Updates: 6,749
Cumulative Timesteps: 112,636,242

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 112636242...
Checkpoint 112636242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.86377
Policy Entropy: 0.52440
Value Function Loss: 2.97424

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02469
Policy Update Magnitude: 0.02315
Value Function Update Magnitude: 0.03394

Collected Steps per Second: 20,728.67532
Overall Steps per Second: 14,946.73421

Timestep Collection Time: 2.41260
Timestep Consumption Time: 0.93328
PPO Batch Consumption Time: 0.11209
Total Iteration Time: 3.34588

Cumulative Model Updates: 6,752
Cumulative Timesteps: 112,686,252

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 930.37649
Policy Entropy: 0.52408
Value Function Loss: 2.92286

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01615
Policy Update Magnitude: 0.02663
Value Function Update Magnitude: 0.03416

Collected Steps per Second: 24,568.67802
Overall Steps per Second: 17,761.80017

Timestep Collection Time: 2.03633
Timestep Consumption Time: 0.78039
PPO Batch Consumption Time: 0.06037
Total Iteration Time: 2.81672

Cumulative Model Updates: 6,755
Cumulative Timesteps: 112,736,282

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 112736282...
Checkpoint 112736282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 850.17784
Policy Entropy: 0.51057
Value Function Loss: 2.97005

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01619
Policy Update Magnitude: 0.03105
Value Function Update Magnitude: 0.03495

Collected Steps per Second: 21,170.24678
Overall Steps per Second: 15,761.17978

Timestep Collection Time: 2.36266
Timestep Consumption Time: 0.81084
PPO Batch Consumption Time: 0.08039
Total Iteration Time: 3.17349

Cumulative Model Updates: 6,758
Cumulative Timesteps: 112,786,300

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 733.85650
Policy Entropy: 0.51558
Value Function Loss: 2.91799

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.04016
Policy Update Magnitude: 0.02758
Value Function Update Magnitude: 0.03296

Collected Steps per Second: 24,892.93078
Overall Steps per Second: 17,897.54231

Timestep Collection Time: 2.00900
Timestep Consumption Time: 0.78523
PPO Batch Consumption Time: 0.05900
Total Iteration Time: 2.79424

Cumulative Model Updates: 6,761
Cumulative Timesteps: 112,836,310

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 112836310...
Checkpoint 112836310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.42026
Policy Entropy: 0.50414
Value Function Loss: 3.00017

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03293
Policy Update Magnitude: 0.02528
Value Function Update Magnitude: 0.03334

Collected Steps per Second: 21,481.45142
Overall Steps per Second: 15,712.80733

Timestep Collection Time: 2.32852
Timestep Consumption Time: 0.85487
PPO Batch Consumption Time: 0.07570
Total Iteration Time: 3.18339

Cumulative Model Updates: 6,764
Cumulative Timesteps: 112,886,330

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 916.24476
Policy Entropy: 0.52940
Value Function Loss: 2.89122

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03036
Policy Update Magnitude: 0.02391
Value Function Update Magnitude: 0.03351

Collected Steps per Second: 24,400.99637
Overall Steps per Second: 17,410.33836

Timestep Collection Time: 2.04967
Timestep Consumption Time: 0.82299
PPO Batch Consumption Time: 0.06323
Total Iteration Time: 2.87266

Cumulative Model Updates: 6,767
Cumulative Timesteps: 112,936,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 112936344...
Checkpoint 112936344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.95398
Policy Entropy: 0.52618
Value Function Loss: 2.88636

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02599
Policy Update Magnitude: 0.02386
Value Function Update Magnitude: 0.04540

Collected Steps per Second: 21,636.62740
Overall Steps per Second: 15,258.64110

Timestep Collection Time: 2.31219
Timestep Consumption Time: 0.96648
PPO Batch Consumption Time: 0.11290
Total Iteration Time: 3.27867

Cumulative Model Updates: 6,770
Cumulative Timesteps: 112,986,372

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.05100
Policy Entropy: 0.53084
Value Function Loss: 2.82090

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02597
Policy Update Magnitude: 0.02533
Value Function Update Magnitude: 0.04721

Collected Steps per Second: 23,704.73660
Overall Steps per Second: 16,618.11220

Timestep Collection Time: 2.11072
Timestep Consumption Time: 0.90009
PPO Batch Consumption Time: 0.08945
Total Iteration Time: 3.01081

Cumulative Model Updates: 6,773
Cumulative Timesteps: 113,036,406

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 113036406...
Checkpoint 113036406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.68360
Policy Entropy: 0.52808
Value Function Loss: 2.74276

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04363
Policy Update Magnitude: 0.02920
Value Function Update Magnitude: 0.04789

Collected Steps per Second: 24,329.33156
Overall Steps per Second: 16,777.69868

Timestep Collection Time: 2.05513
Timestep Consumption Time: 0.92501
PPO Batch Consumption Time: 0.10108
Total Iteration Time: 2.98015

Cumulative Model Updates: 6,776
Cumulative Timesteps: 113,086,406

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 974.40983
Policy Entropy: 0.50979
Value Function Loss: 2.69871

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06407
Policy Update Magnitude: 0.02475
Value Function Update Magnitude: 0.04252

Collected Steps per Second: 23,713.96781
Overall Steps per Second: 16,687.55058

Timestep Collection Time: 2.10846
Timestep Consumption Time: 0.88778
PPO Batch Consumption Time: 0.09141
Total Iteration Time: 2.99625

Cumulative Model Updates: 6,779
Cumulative Timesteps: 113,136,406

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 113136406...
Checkpoint 113136406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584.36087
Policy Entropy: 0.52211
Value Function Loss: 2.67421

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.05458
Policy Update Magnitude: 0.02002
Value Function Update Magnitude: 0.03922

Collected Steps per Second: 23,982.00232
Overall Steps per Second: 16,757.13594

Timestep Collection Time: 2.08498
Timestep Consumption Time: 0.89894
PPO Batch Consumption Time: 0.09170
Total Iteration Time: 2.98392

Cumulative Model Updates: 6,782
Cumulative Timesteps: 113,186,408

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485.89309
Policy Entropy: 0.52125
Value Function Loss: 2.77731

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.03215
Policy Update Magnitude: 0.02369
Value Function Update Magnitude: 0.03361

Collected Steps per Second: 24,547.53219
Overall Steps per Second: 16,818.49441

Timestep Collection Time: 2.03727
Timestep Consumption Time: 0.93624
PPO Batch Consumption Time: 0.10577
Total Iteration Time: 2.97351

Cumulative Model Updates: 6,785
Cumulative Timesteps: 113,236,418

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 113236418...
Checkpoint 113236418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710.69718
Policy Entropy: 0.50742
Value Function Loss: 2.81119

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03459
Policy Update Magnitude: 0.02404
Value Function Update Magnitude: 0.04187

Collected Steps per Second: 23,665.56390
Overall Steps per Second: 16,768.80964

Timestep Collection Time: 2.11430
Timestep Consumption Time: 0.86958
PPO Batch Consumption Time: 0.10542
Total Iteration Time: 2.98387

Cumulative Model Updates: 6,788
Cumulative Timesteps: 113,286,454

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 932.54736
Policy Entropy: 0.50815
Value Function Loss: 2.90075

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03545
Policy Update Magnitude: 0.02613
Value Function Update Magnitude: 0.03821

Collected Steps per Second: 23,763.90379
Overall Steps per Second: 16,731.47761

Timestep Collection Time: 2.10470
Timestep Consumption Time: 0.88463
PPO Batch Consumption Time: 0.11349
Total Iteration Time: 2.98934

Cumulative Model Updates: 6,791
Cumulative Timesteps: 113,336,470

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 113336470...
Checkpoint 113336470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 942.37239
Policy Entropy: 0.51018
Value Function Loss: 2.89993

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02860
Policy Update Magnitude: 0.02351
Value Function Update Magnitude: 0.04194

Collected Steps per Second: 23,701.24973
Overall Steps per Second: 16,621.10213

Timestep Collection Time: 2.10959
Timestep Consumption Time: 0.89863
PPO Batch Consumption Time: 0.08237
Total Iteration Time: 3.00822

Cumulative Model Updates: 6,794
Cumulative Timesteps: 113,386,470

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.93505
Policy Entropy: 0.51392
Value Function Loss: 2.83971

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01928
Policy Update Magnitude: 0.02410
Value Function Update Magnitude: 0.03473

Collected Steps per Second: 24,465.55901
Overall Steps per Second: 16,758.61696

Timestep Collection Time: 2.04377
Timestep Consumption Time: 0.93989
PPO Batch Consumption Time: 0.10252
Total Iteration Time: 2.98366

Cumulative Model Updates: 6,797
Cumulative Timesteps: 113,436,472

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 113436472...
Checkpoint 113436472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671.84044
Policy Entropy: 0.51306
Value Function Loss: 2.77578

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01931
Policy Update Magnitude: 0.02139
Value Function Update Magnitude: 0.03244

Collected Steps per Second: 24,291.40240
Overall Steps per Second: 16,710.87257

Timestep Collection Time: 2.05875
Timestep Consumption Time: 0.93391
PPO Batch Consumption Time: 0.09987
Total Iteration Time: 2.99266

Cumulative Model Updates: 6,800
Cumulative Timesteps: 113,486,482

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.24194
Policy Entropy: 0.51829
Value Function Loss: 2.82603

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01897
Policy Update Magnitude: 0.02596
Value Function Update Magnitude: 0.03275

Collected Steps per Second: 24,622.31892
Overall Steps per Second: 16,688.75859

Timestep Collection Time: 2.03084
Timestep Consumption Time: 0.96543
PPO Batch Consumption Time: 0.10729
Total Iteration Time: 2.99627

Cumulative Model Updates: 6,803
Cumulative Timesteps: 113,536,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 113536486...
Checkpoint 113536486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.37862
Policy Entropy: 0.51181
Value Function Loss: 2.82253

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02593
Policy Update Magnitude: 0.02546
Value Function Update Magnitude: 0.03273

Collected Steps per Second: 24,051.36330
Overall Steps per Second: 16,797.06238

Timestep Collection Time: 2.07988
Timestep Consumption Time: 0.89826
PPO Batch Consumption Time: 0.08789
Total Iteration Time: 2.97814

Cumulative Model Updates: 6,806
Cumulative Timesteps: 113,586,510

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.49782
Policy Entropy: 0.51949
Value Function Loss: 2.80416

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02906
Policy Update Magnitude: 0.02603
Value Function Update Magnitude: 0.03496

Collected Steps per Second: 23,517.07912
Overall Steps per Second: 16,698.72028

Timestep Collection Time: 2.12730
Timestep Consumption Time: 0.86861
PPO Batch Consumption Time: 0.08720
Total Iteration Time: 2.99592

Cumulative Model Updates: 6,809
Cumulative Timesteps: 113,636,538

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 113636538...
Checkpoint 113636538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 991.63675
Policy Entropy: 0.51586
Value Function Loss: 2.78431

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.03063
Policy Update Magnitude: 0.02344
Value Function Update Magnitude: 0.03340

Collected Steps per Second: 24,340.25078
Overall Steps per Second: 16,856.71305

Timestep Collection Time: 2.05487
Timestep Consumption Time: 0.91226
PPO Batch Consumption Time: 0.10446
Total Iteration Time: 2.96713

Cumulative Model Updates: 6,812
Cumulative Timesteps: 113,686,554

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,664.42575
Policy Entropy: 0.50542
Value Function Loss: 2.77746

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02353
Policy Update Magnitude: 0.02324
Value Function Update Magnitude: 0.03388

Collected Steps per Second: 24,251.51160
Overall Steps per Second: 16,763.01967

Timestep Collection Time: 2.06214
Timestep Consumption Time: 0.92121
PPO Batch Consumption Time: 0.12534
Total Iteration Time: 2.98335

Cumulative Model Updates: 6,815
Cumulative Timesteps: 113,736,564

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 113736564...
Checkpoint 113736564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618.07887
Policy Entropy: 0.52431
Value Function Loss: 2.75800

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.02331
Policy Update Magnitude: 0.02728
Value Function Update Magnitude: 0.03162

Collected Steps per Second: 23,970.02094
Overall Steps per Second: 16,714.54489

Timestep Collection Time: 2.08652
Timestep Consumption Time: 0.90572
PPO Batch Consumption Time: 0.11072
Total Iteration Time: 2.99224

Cumulative Model Updates: 6,818
Cumulative Timesteps: 113,786,578

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.22992
Policy Entropy: 0.52249
Value Function Loss: 2.77967

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02967
Policy Update Magnitude: 0.03001
Value Function Update Magnitude: 0.03343

Collected Steps per Second: 24,827.78997
Overall Steps per Second: 16,728.36567

Timestep Collection Time: 2.01452
Timestep Consumption Time: 0.97537
PPO Batch Consumption Time: 0.11487
Total Iteration Time: 2.98989

Cumulative Model Updates: 6,821
Cumulative Timesteps: 113,836,594

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 113836594...
Checkpoint 113836594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,502.47197
Policy Entropy: 0.51874
Value Function Loss: 2.79591

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03997
Policy Update Magnitude: 0.02471
Value Function Update Magnitude: 0.03259

Collected Steps per Second: 23,794.75421
Overall Steps per Second: 16,674.01370

Timestep Collection Time: 2.10181
Timestep Consumption Time: 0.89759
PPO Batch Consumption Time: 0.09238
Total Iteration Time: 2.99940

Cumulative Model Updates: 6,824
Cumulative Timesteps: 113,886,606

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.97762
Policy Entropy: 0.52415
Value Function Loss: 2.77403

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03589
Policy Update Magnitude: 0.02094
Value Function Update Magnitude: 0.03824

Collected Steps per Second: 24,748.70472
Overall Steps per Second: 16,791.15587

Timestep Collection Time: 2.02128
Timestep Consumption Time: 0.95791
PPO Batch Consumption Time: 0.11304
Total Iteration Time: 2.97919

Cumulative Model Updates: 6,827
Cumulative Timesteps: 113,936,630

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 113936630...
Checkpoint 113936630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.80205
Policy Entropy: 0.52466
Value Function Loss: 2.74351

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02978
Policy Update Magnitude: 0.02397
Value Function Update Magnitude: 0.03696

Collected Steps per Second: 24,043.72278
Overall Steps per Second: 16,674.44436

Timestep Collection Time: 2.07979
Timestep Consumption Time: 0.91917
PPO Batch Consumption Time: 0.09643
Total Iteration Time: 2.99896

Cumulative Model Updates: 6,830
Cumulative Timesteps: 113,986,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.32476
Policy Entropy: 0.52028
Value Function Loss: 2.69243

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02450
Policy Update Magnitude: 0.02311
Value Function Update Magnitude: 0.03659

Collected Steps per Second: 24,574.46538
Overall Steps per Second: 16,794.53717

Timestep Collection Time: 2.03496
Timestep Consumption Time: 0.94268
PPO Batch Consumption Time: 0.10503
Total Iteration Time: 2.97763

Cumulative Model Updates: 6,833
Cumulative Timesteps: 114,036,644

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 114036644...
Checkpoint 114036644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.63013
Policy Entropy: 0.52835
Value Function Loss: 2.77788

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03991
Policy Update Magnitude: 0.02402
Value Function Update Magnitude: 0.03422

Collected Steps per Second: 24,310.64592
Overall Steps per Second: 16,718.03178

Timestep Collection Time: 2.05753
Timestep Consumption Time: 0.93444
PPO Batch Consumption Time: 0.10137
Total Iteration Time: 2.99198

Cumulative Model Updates: 6,836
Cumulative Timesteps: 114,086,664

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.66908
Policy Entropy: 0.51404
Value Function Loss: 2.70351

Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.01571
Policy Update Magnitude: 0.02646
Value Function Update Magnitude: 0.03903

Collected Steps per Second: 24,237.93606
Overall Steps per Second: 16,688.71578

Timestep Collection Time: 2.06387
Timestep Consumption Time: 0.93360
PPO Batch Consumption Time: 0.10018
Total Iteration Time: 2.99747

Cumulative Model Updates: 6,839
Cumulative Timesteps: 114,136,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 114136688...
Checkpoint 114136688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.63958
Policy Entropy: 0.51708
Value Function Loss: 2.74645

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.05031
Policy Update Magnitude: 0.02476
Value Function Update Magnitude: 0.04692

Collected Steps per Second: 24,388.21673
Overall Steps per Second: 16,831.29295

Timestep Collection Time: 2.05140
Timestep Consumption Time: 0.92104
PPO Batch Consumption Time: 0.10358
Total Iteration Time: 2.97244

Cumulative Model Updates: 6,842
Cumulative Timesteps: 114,186,718

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.40322
Policy Entropy: 0.50867
Value Function Loss: 2.67177

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03476
Policy Update Magnitude: 0.02337
Value Function Update Magnitude: 0.03853

Collected Steps per Second: 24,059.61188
Overall Steps per Second: 16,730.25674

Timestep Collection Time: 2.07875
Timestep Consumption Time: 0.91068
PPO Batch Consumption Time: 0.11901
Total Iteration Time: 2.98943

Cumulative Model Updates: 6,845
Cumulative Timesteps: 114,236,732

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 114236732...
Checkpoint 114236732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.33353
Policy Entropy: 0.51275
Value Function Loss: 2.69700

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02418
Policy Update Magnitude: 0.02170
Value Function Update Magnitude: 0.04486

Collected Steps per Second: 23,599.36472
Overall Steps per Second: 16,754.35168

Timestep Collection Time: 2.11870
Timestep Consumption Time: 0.86560
PPO Batch Consumption Time: 0.10828
Total Iteration Time: 2.98430

Cumulative Model Updates: 6,848
Cumulative Timesteps: 114,286,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 924.39978
Policy Entropy: 0.49766
Value Function Loss: 2.62157

Mean KL Divergence: 0.00139
SB3 Clip Fraction: 0.01481
Policy Update Magnitude: 0.02575
Value Function Update Magnitude: 0.06382

Collected Steps per Second: 24,121.08344
Overall Steps per Second: 16,646.51696

Timestep Collection Time: 2.07354
Timestep Consumption Time: 0.93105
PPO Batch Consumption Time: 0.10220
Total Iteration Time: 3.00459

Cumulative Model Updates: 6,851
Cumulative Timesteps: 114,336,748

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 114336748...
Checkpoint 114336748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 947.07626
Policy Entropy: 0.49542
Value Function Loss: 2.59586

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01911
Policy Update Magnitude: 0.03012
Value Function Update Magnitude: 0.05366

Collected Steps per Second: 24,255.30152
Overall Steps per Second: 16,737.26085

Timestep Collection Time: 2.06198
Timestep Consumption Time: 0.92620
PPO Batch Consumption Time: 0.09480
Total Iteration Time: 2.98818

Cumulative Model Updates: 6,854
Cumulative Timesteps: 114,386,762

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.34780
Policy Entropy: 0.49461
Value Function Loss: 2.62292

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.03162
Policy Update Magnitude: 0.02708
Value Function Update Magnitude: 0.04563

Collected Steps per Second: 24,756.94357
Overall Steps per Second: 16,794.65417

Timestep Collection Time: 2.01972
Timestep Consumption Time: 0.95754
PPO Batch Consumption Time: 0.11059
Total Iteration Time: 2.97726

Cumulative Model Updates: 6,857
Cumulative Timesteps: 114,436,764

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 114436764...
Checkpoint 114436764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.76262
Policy Entropy: 0.49986
Value Function Loss: 2.59178

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03823
Policy Update Magnitude: 0.02692
Value Function Update Magnitude: 0.03869

Collected Steps per Second: 23,900.61839
Overall Steps per Second: 16,708.42157

Timestep Collection Time: 2.09233
Timestep Consumption Time: 0.90065
PPO Batch Consumption Time: 0.10193
Total Iteration Time: 2.99298

Cumulative Model Updates: 6,860
Cumulative Timesteps: 114,486,772

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 885.80963
Policy Entropy: 0.50602
Value Function Loss: 2.59414

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04487
Policy Update Magnitude: 0.02250
Value Function Update Magnitude: 0.04374

Collected Steps per Second: 24,719.64945
Overall Steps per Second: 16,687.22799

Timestep Collection Time: 2.02373
Timestep Consumption Time: 0.97413
PPO Batch Consumption Time: 0.12238
Total Iteration Time: 2.99786

Cumulative Model Updates: 6,863
Cumulative Timesteps: 114,536,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 114536798...
Checkpoint 114536798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633.54628
Policy Entropy: 0.51434
Value Function Loss: 2.61164

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04655
Policy Update Magnitude: 0.02296
Value Function Update Magnitude: 0.03857

Collected Steps per Second: 23,607.12420
Overall Steps per Second: 16,610.32665

Timestep Collection Time: 2.11800
Timestep Consumption Time: 0.89217
PPO Batch Consumption Time: 0.08731
Total Iteration Time: 3.01018

Cumulative Model Updates: 6,866
Cumulative Timesteps: 114,586,798

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.37911
Policy Entropy: 0.50997
Value Function Loss: 2.64453

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04586
Policy Update Magnitude: 0.02173
Value Function Update Magnitude: 0.03691

Collected Steps per Second: 24,302.37127
Overall Steps per Second: 16,935.54612

Timestep Collection Time: 2.05741
Timestep Consumption Time: 0.89496
PPO Batch Consumption Time: 0.11247
Total Iteration Time: 2.95237

Cumulative Model Updates: 6,869
Cumulative Timesteps: 114,636,798

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 114636798...
Checkpoint 114636798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.33019
Policy Entropy: 0.50403
Value Function Loss: 2.63987

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04447
Policy Update Magnitude: 0.02149
Value Function Update Magnitude: 0.03530

Collected Steps per Second: 22,966.79459
Overall Steps per Second: 16,673.80274

Timestep Collection Time: 2.17749
Timestep Consumption Time: 0.82182
PPO Batch Consumption Time: 0.09027
Total Iteration Time: 2.99932

Cumulative Model Updates: 6,872
Cumulative Timesteps: 114,686,808

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 968.05474
Policy Entropy: 0.51096
Value Function Loss: 2.51597

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.04675
Policy Update Magnitude: 0.02138
Value Function Update Magnitude: 0.03523

Collected Steps per Second: 24,924.17853
Overall Steps per Second: 16,786.74857

Timestep Collection Time: 2.00632
Timestep Consumption Time: 0.97257
PPO Batch Consumption Time: 0.11239
Total Iteration Time: 2.97890

Cumulative Model Updates: 6,875
Cumulative Timesteps: 114,736,814

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 114736814...
Checkpoint 114736814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709.55391
Policy Entropy: 0.51938
Value Function Loss: 2.49522

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04641
Policy Update Magnitude: 0.02020
Value Function Update Magnitude: 0.03032

Collected Steps per Second: 24,457.04012
Overall Steps per Second: 16,775.91726

Timestep Collection Time: 2.04546
Timestep Consumption Time: 0.93655
PPO Batch Consumption Time: 0.10510
Total Iteration Time: 2.98201

Cumulative Model Updates: 6,878
Cumulative Timesteps: 114,786,840

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 954.24648
Policy Entropy: 0.51713
Value Function Loss: 2.49964

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.04598
Policy Update Magnitude: 0.01944
Value Function Update Magnitude: 0.03328

Collected Steps per Second: 24,474.64631
Overall Steps per Second: 16,669.40992

Timestep Collection Time: 2.04416
Timestep Consumption Time: 0.95715
PPO Batch Consumption Time: 0.10456
Total Iteration Time: 3.00131

Cumulative Model Updates: 6,881
Cumulative Timesteps: 114,836,870

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 114836870...
Checkpoint 114836870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 822.99266
Policy Entropy: 0.50706
Value Function Loss: 2.57928

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.04217
Policy Update Magnitude: 0.02090
Value Function Update Magnitude: 0.03352

Collected Steps per Second: 24,274.22107
Overall Steps per Second: 16,749.91630

Timestep Collection Time: 2.06112
Timestep Consumption Time: 0.92588
PPO Batch Consumption Time: 0.10174
Total Iteration Time: 2.98700

Cumulative Model Updates: 6,884
Cumulative Timesteps: 114,886,902

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 823.07693
Policy Entropy: 0.50861
Value Function Loss: 2.63031

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.04568
Policy Update Magnitude: 0.02140
Value Function Update Magnitude: 0.03690

Collected Steps per Second: 24,137.70182
Overall Steps per Second: 16,683.96948

Timestep Collection Time: 2.07153
Timestep Consumption Time: 0.92548
PPO Batch Consumption Time: 0.09547
Total Iteration Time: 2.99701

Cumulative Model Updates: 6,887
Cumulative Timesteps: 114,936,904

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 114936904...
Checkpoint 114936904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.49934
Policy Entropy: 0.51188
Value Function Loss: 2.69233

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.04306
Policy Update Magnitude: 0.02029
Value Function Update Magnitude: 0.03623

Collected Steps per Second: 23,897.49357
Overall Steps per Second: 16,765.43072

Timestep Collection Time: 2.09344
Timestep Consumption Time: 0.89056
PPO Batch Consumption Time: 0.09679
Total Iteration Time: 2.98400

Cumulative Model Updates: 6,890
Cumulative Timesteps: 114,986,932

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706.03850
Policy Entropy: 0.50939
Value Function Loss: 2.68556

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04383
Policy Update Magnitude: 0.01828
Value Function Update Magnitude: 0.04160

Collected Steps per Second: 24,411.42301
Overall Steps per Second: 16,778.91636

Timestep Collection Time: 2.04896
Timestep Consumption Time: 0.93204
PPO Batch Consumption Time: 0.10963
Total Iteration Time: 2.98100

Cumulative Model Updates: 6,893
Cumulative Timesteps: 115,036,950

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 115036950...
Checkpoint 115036950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.55177
Policy Entropy: 0.51488
Value Function Loss: 2.58680

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.02349
Policy Update Magnitude: 0.01932
Value Function Update Magnitude: 0.03677

Collected Steps per Second: 23,719.37797
Overall Steps per Second: 16,751.64268

Timestep Collection Time: 2.10807
Timestep Consumption Time: 0.87684
PPO Batch Consumption Time: 0.10329
Total Iteration Time: 2.98490

Cumulative Model Updates: 6,896
Cumulative Timesteps: 115,086,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 944.53042
Policy Entropy: 0.51314
Value Function Loss: 2.49727

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01976
Policy Update Magnitude: 0.02670
Value Function Update Magnitude: 0.03733

Collected Steps per Second: 23,950.55091
Overall Steps per Second: 16,736.48120

Timestep Collection Time: 2.08839
Timestep Consumption Time: 0.90018
PPO Batch Consumption Time: 0.11865
Total Iteration Time: 2.98856

Cumulative Model Updates: 6,899
Cumulative Timesteps: 115,136,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 115136970...
Checkpoint 115136970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.29916
Policy Entropy: 0.50826
Value Function Loss: 2.52248

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.01713
Policy Update Magnitude: 0.02759
Value Function Update Magnitude: 0.03427

Collected Steps per Second: 24,259.58336
Overall Steps per Second: 16,754.93862

Timestep Collection Time: 2.06170
Timestep Consumption Time: 0.92345
PPO Batch Consumption Time: 0.10479
Total Iteration Time: 2.98515

Cumulative Model Updates: 6,902
Cumulative Timesteps: 115,186,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.08159
Policy Entropy: 0.50600
Value Function Loss: 2.57785

Mean KL Divergence: 0.00101
SB3 Clip Fraction: 0.00741
Policy Update Magnitude: 0.03120
Value Function Update Magnitude: 0.03269

Collected Steps per Second: 24,782.76810
Overall Steps per Second: 16,724.40433

Timestep Collection Time: 2.01866
Timestep Consumption Time: 0.97266
PPO Batch Consumption Time: 0.11630
Total Iteration Time: 2.99132

Cumulative Model Updates: 6,905
Cumulative Timesteps: 115,237,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 115237014...
Checkpoint 115237014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,630.36037
Policy Entropy: 0.50336
Value Function Loss: 2.49982

Mean KL Divergence: 0.00107
SB3 Clip Fraction: 0.00833
Policy Update Magnitude: 0.03349
Value Function Update Magnitude: 0.04532

Collected Steps per Second: 23,727.92561
Overall Steps per Second: 16,644.31010

Timestep Collection Time: 2.10806
Timestep Consumption Time: 0.89717
PPO Batch Consumption Time: 0.08552
Total Iteration Time: 3.00523

Cumulative Model Updates: 6,908
Cumulative Timesteps: 115,287,034

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 935.22838
Policy Entropy: 0.50994
Value Function Loss: 2.41196

Mean KL Divergence: 0.00081
SB3 Clip Fraction: 0.00482
Policy Update Magnitude: 0.03613
Value Function Update Magnitude: 0.05091

Collected Steps per Second: 24,806.57715
Overall Steps per Second: 16,817.70938

Timestep Collection Time: 2.01600
Timestep Consumption Time: 0.95765
PPO Batch Consumption Time: 0.10707
Total Iteration Time: 2.97365

Cumulative Model Updates: 6,911
Cumulative Timesteps: 115,337,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 115337044...
Checkpoint 115337044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,739.21264
Policy Entropy: 0.51120
Value Function Loss: 2.40263

Mean KL Divergence: 0.00095
SB3 Clip Fraction: 0.00723
Policy Update Magnitude: 0.03587
Value Function Update Magnitude: 0.06245

Collected Steps per Second: 24,029.89148
Overall Steps per Second: 15,830.15853

Timestep Collection Time: 2.08182
Timestep Consumption Time: 1.07835
PPO Batch Consumption Time: 0.11908
Total Iteration Time: 3.16017

Cumulative Model Updates: 6,914
Cumulative Timesteps: 115,387,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.41468
Policy Entropy: 0.51158
Value Function Loss: 2.43476

Mean KL Divergence: 0.00122
SB3 Clip Fraction: 0.01056
Policy Update Magnitude: 0.03517
Value Function Update Magnitude: 0.06630

Collected Steps per Second: 23,216.30081
Overall Steps per Second: 17,611.77449

Timestep Collection Time: 2.15383
Timestep Consumption Time: 0.68541
PPO Batch Consumption Time: 0.02919
Total Iteration Time: 2.83924

Cumulative Model Updates: 6,917
Cumulative Timesteps: 115,437,074

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 115437074...
Checkpoint 115437074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.33096
Policy Entropy: 0.50937
Value Function Loss: 2.47207

Mean KL Divergence: 0.00115
SB3 Clip Fraction: 0.01139
Policy Update Magnitude: 0.03594
Value Function Update Magnitude: 0.06920

Collected Steps per Second: 22,170.89087
Overall Steps per Second: 15,807.30461

Timestep Collection Time: 2.25593
Timestep Consumption Time: 0.90818
PPO Batch Consumption Time: 0.10366
Total Iteration Time: 3.16411

Cumulative Model Updates: 6,920
Cumulative Timesteps: 115,487,090

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288.41612
Policy Entropy: 0.50992
Value Function Loss: 2.43975

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02985
Policy Update Magnitude: 0.03262
Value Function Update Magnitude: 0.06791

Collected Steps per Second: 24,077.08326
Overall Steps per Second: 17,885.64276

Timestep Collection Time: 2.07691
Timestep Consumption Time: 0.71896
PPO Batch Consumption Time: 0.05837
Total Iteration Time: 2.79587

Cumulative Model Updates: 6,923
Cumulative Timesteps: 115,537,096

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 115537096...
Checkpoint 115537096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558.77008
Policy Entropy: 0.51220
Value Function Loss: 2.45442

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03489
Policy Update Magnitude: 0.03044
Value Function Update Magnitude: 0.06089

Collected Steps per Second: 20,940.25881
Overall Steps per Second: 15,658.62446

Timestep Collection Time: 2.38889
Timestep Consumption Time: 0.80577
PPO Batch Consumption Time: 0.08850
Total Iteration Time: 3.19466

Cumulative Model Updates: 6,926
Cumulative Timesteps: 115,587,120

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.53260
Policy Entropy: 0.51443
Value Function Loss: 2.42451

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.05333
Policy Update Magnitude: 0.02719
Value Function Update Magnitude: 0.05624

Collected Steps per Second: 24,496.40884
Overall Steps per Second: 17,741.43723

Timestep Collection Time: 2.04201
Timestep Consumption Time: 0.77749
PPO Batch Consumption Time: 0.05973
Total Iteration Time: 2.81950

Cumulative Model Updates: 6,929
Cumulative Timesteps: 115,637,142

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 115637142...
Checkpoint 115637142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.30529
Policy Entropy: 0.50888
Value Function Loss: 2.41072

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05485
Policy Update Magnitude: 0.02275
Value Function Update Magnitude: 0.05307

Collected Steps per Second: 21,970.45980
Overall Steps per Second: 15,841.01770

Timestep Collection Time: 2.27651
Timestep Consumption Time: 0.88086
PPO Batch Consumption Time: 0.07527
Total Iteration Time: 3.15737

Cumulative Model Updates: 6,932
Cumulative Timesteps: 115,687,158

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730.34697
Policy Entropy: 0.51207
Value Function Loss: 2.43689

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.04717
Policy Update Magnitude: 0.02048
Value Function Update Magnitude: 0.04713

Collected Steps per Second: 24,777.87082
Overall Steps per Second: 17,775.32957

Timestep Collection Time: 2.01914
Timestep Consumption Time: 0.79543
PPO Batch Consumption Time: 0.06002
Total Iteration Time: 2.81458

Cumulative Model Updates: 6,935
Cumulative Timesteps: 115,737,188

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 115737188...
Checkpoint 115737188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.76518
Policy Entropy: 0.50340
Value Function Loss: 2.42657

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03470
Policy Update Magnitude: 0.01980
Value Function Update Magnitude: 0.04197

Collected Steps per Second: 21,163.88056
Overall Steps per Second: 14,984.67931

Timestep Collection Time: 2.36318
Timestep Consumption Time: 0.97450
PPO Batch Consumption Time: 0.11096
Total Iteration Time: 3.33768

Cumulative Model Updates: 6,938
Cumulative Timesteps: 115,787,202

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,721.56673
Policy Entropy: 0.50189
Value Function Loss: 2.44786

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02680
Policy Update Magnitude: 0.02001
Value Function Update Magnitude: 0.04710

Collected Steps per Second: 24,841.26749
Overall Steps per Second: 17,937.27826

Timestep Collection Time: 2.01391
Timestep Consumption Time: 0.77515
PPO Batch Consumption Time: 0.06024
Total Iteration Time: 2.78905

Cumulative Model Updates: 6,941
Cumulative Timesteps: 115,837,230

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 115837230...
Checkpoint 115837230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 879.55072
Policy Entropy: 0.50290
Value Function Loss: 2.40073

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02605
Policy Update Magnitude: 0.02141
Value Function Update Magnitude: 0.04162

Collected Steps per Second: 20,983.71135
Overall Steps per Second: 14,794.92605

Timestep Collection Time: 2.38280
Timestep Consumption Time: 0.99674
PPO Batch Consumption Time: 0.12080
Total Iteration Time: 3.37954

Cumulative Model Updates: 6,944
Cumulative Timesteps: 115,887,230

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 858.02609
Policy Entropy: 0.50235
Value Function Loss: 2.32382

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02914
Policy Update Magnitude: 0.02445
Value Function Update Magnitude: 0.05086

Collected Steps per Second: 24,830.24625
Overall Steps per Second: 16,664.65248

Timestep Collection Time: 2.01480
Timestep Consumption Time: 0.98724
PPO Batch Consumption Time: 0.10541
Total Iteration Time: 3.00204

Cumulative Model Updates: 6,947
Cumulative Timesteps: 115,937,258

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 115937258...
Checkpoint 115937258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650.37053
Policy Entropy: 0.50962
Value Function Loss: 2.26020

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03522
Policy Update Magnitude: 0.02406
Value Function Update Magnitude: 0.05970

Collected Steps per Second: 24,344.06460
Overall Steps per Second: 16,728.61422

Timestep Collection Time: 2.05487
Timestep Consumption Time: 0.93545
PPO Batch Consumption Time: 0.10138
Total Iteration Time: 2.99033

Cumulative Model Updates: 6,950
Cumulative Timesteps: 115,987,282

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,676.22459
Policy Entropy: 0.50194
Value Function Loss: 2.25136

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03733
Policy Update Magnitude: 0.02436
Value Function Update Magnitude: 0.06752

Collected Steps per Second: 24,349.49307
Overall Steps per Second: 16,778.16888

Timestep Collection Time: 2.05401
Timestep Consumption Time: 0.92689
PPO Batch Consumption Time: 0.10658
Total Iteration Time: 2.98090

Cumulative Model Updates: 6,953
Cumulative Timesteps: 116,037,296

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 116037296...
Checkpoint 116037296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,547.64750
Policy Entropy: 0.49273
Value Function Loss: 2.31492

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03784
Policy Update Magnitude: 0.02638
Value Function Update Magnitude: 0.07490

Collected Steps per Second: 24,329.42994
Overall Steps per Second: 16,746.44425

Timestep Collection Time: 2.05529
Timestep Consumption Time: 0.93066
PPO Batch Consumption Time: 0.11269
Total Iteration Time: 2.98595

Cumulative Model Updates: 6,956
Cumulative Timesteps: 116,087,300

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,626.09436
Policy Entropy: 0.49043
Value Function Loss: 2.35669

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03124
Policy Update Magnitude: 0.02084
Value Function Update Magnitude: 0.08186

Collected Steps per Second: 24,286.84120
Overall Steps per Second: 16,712.54260

Timestep Collection Time: 2.05873
Timestep Consumption Time: 0.93304
PPO Batch Consumption Time: 0.11017
Total Iteration Time: 2.99176

Cumulative Model Updates: 6,959
Cumulative Timesteps: 116,137,300

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 116137300...
Checkpoint 116137300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,765.74222
Policy Entropy: 0.49283
Value Function Loss: 2.34125

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.02229
Policy Update Magnitude: 0.02412
Value Function Update Magnitude: 0.07214

Collected Steps per Second: 24,044.78001
Overall Steps per Second: 16,788.38244

Timestep Collection Time: 2.08029
Timestep Consumption Time: 0.89916
PPO Batch Consumption Time: 0.12063
Total Iteration Time: 2.97944

Cumulative Model Updates: 6,962
Cumulative Timesteps: 116,187,320

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.86294
Policy Entropy: 0.49797
Value Function Loss: 2.27750

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01966
Policy Update Magnitude: 0.02431
Value Function Update Magnitude: 0.06881

Collected Steps per Second: 23,891.36453
Overall Steps per Second: 16,718.79393

Timestep Collection Time: 2.09297
Timestep Consumption Time: 0.89791
PPO Batch Consumption Time: 0.12020
Total Iteration Time: 2.99089

Cumulative Model Updates: 6,965
Cumulative Timesteps: 116,237,324

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 116237324...
Checkpoint 116237324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.83313
Policy Entropy: 0.50611
Value Function Loss: 2.25337

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03187
Policy Update Magnitude: 0.02370
Value Function Update Magnitude: 0.07038

Collected Steps per Second: 23,445.07949
Overall Steps per Second: 16,696.12089

Timestep Collection Time: 2.13333
Timestep Consumption Time: 0.86234
PPO Batch Consumption Time: 0.10462
Total Iteration Time: 2.99567

Cumulative Model Updates: 6,968
Cumulative Timesteps: 116,287,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 893.08778
Policy Entropy: 0.50002
Value Function Loss: 2.27237

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03923
Policy Update Magnitude: 0.02261
Value Function Update Magnitude: 0.06973

Collected Steps per Second: 24,685.13374
Overall Steps per Second: 16,752.30183

Timestep Collection Time: 2.02592
Timestep Consumption Time: 0.95935
PPO Batch Consumption Time: 0.11302
Total Iteration Time: 2.98526

Cumulative Model Updates: 6,971
Cumulative Timesteps: 116,337,350

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 116337350...
Checkpoint 116337350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654.79447
Policy Entropy: 0.50263
Value Function Loss: 2.34395

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02766
Policy Update Magnitude: 0.02040
Value Function Update Magnitude: 0.06851

Collected Steps per Second: 23,477.78053
Overall Steps per Second: 16,623.78893

Timestep Collection Time: 2.12967
Timestep Consumption Time: 0.87806
PPO Batch Consumption Time: 0.07623
Total Iteration Time: 3.00774

Cumulative Model Updates: 6,974
Cumulative Timesteps: 116,387,350

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 946.63382
Policy Entropy: 0.50085
Value Function Loss: 2.37865

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03665
Policy Update Magnitude: 0.02237
Value Function Update Magnitude: 0.06645

Collected Steps per Second: 23,411.72715
Overall Steps per Second: 16,695.85197

Timestep Collection Time: 2.13594
Timestep Consumption Time: 0.85918
PPO Batch Consumption Time: 0.07656
Total Iteration Time: 2.99512

Cumulative Model Updates: 6,977
Cumulative Timesteps: 116,437,356

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 116437356...
Checkpoint 116437356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,614.54395
Policy Entropy: 0.50301
Value Function Loss: 2.36379

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03170
Policy Update Magnitude: 0.02160
Value Function Update Magnitude: 0.05970

Collected Steps per Second: 22,810.07939
Overall Steps per Second: 15,843.93016

Timestep Collection Time: 2.19298
Timestep Consumption Time: 0.96419
PPO Batch Consumption Time: 0.11122
Total Iteration Time: 3.15717

Cumulative Model Updates: 6,980
Cumulative Timesteps: 116,487,378

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 853.31601
Policy Entropy: 0.49639
Value Function Loss: 2.31213

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03551
Policy Update Magnitude: 0.01929
Value Function Update Magnitude: 0.05547

Collected Steps per Second: 24,662.63791
Overall Steps per Second: 17,373.62406

Timestep Collection Time: 2.02809
Timestep Consumption Time: 0.85087
PPO Batch Consumption Time: 0.06468
Total Iteration Time: 2.87896

Cumulative Model Updates: 6,983
Cumulative Timesteps: 116,537,396

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 116537396...
Checkpoint 116537396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 986.00135
Policy Entropy: 0.50330
Value Function Loss: 2.29387

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03314
Policy Update Magnitude: 0.01963
Value Function Update Magnitude: 0.06051

Collected Steps per Second: 21,682.75295
Overall Steps per Second: 15,107.29143

Timestep Collection Time: 2.30681
Timestep Consumption Time: 1.00404
PPO Batch Consumption Time: 0.10932
Total Iteration Time: 3.31085

Cumulative Model Updates: 6,986
Cumulative Timesteps: 116,587,414

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348.28233
Policy Entropy: 0.49610
Value Function Loss: 2.32110

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03555
Policy Update Magnitude: 0.02038
Value Function Update Magnitude: 0.06185

Collected Steps per Second: 23,736.48787
Overall Steps per Second: 17,185.87854

Timestep Collection Time: 2.10705
Timestep Consumption Time: 0.80313
PPO Batch Consumption Time: 0.06487
Total Iteration Time: 2.91018

Cumulative Model Updates: 6,989
Cumulative Timesteps: 116,637,428

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 116637428...
Checkpoint 116637428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 849.46461
Policy Entropy: 0.50674
Value Function Loss: 2.35916

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02888
Policy Update Magnitude: 0.02070
Value Function Update Magnitude: 0.05864

Collected Steps per Second: 24,742.06244
Overall Steps per Second: 17,438.67546

Timestep Collection Time: 2.02174
Timestep Consumption Time: 0.84671
PPO Batch Consumption Time: 0.08706
Total Iteration Time: 2.86845

Cumulative Model Updates: 6,992
Cumulative Timesteps: 116,687,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,857.49698
Policy Entropy: 0.49652
Value Function Loss: 2.35960

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.04122
Policy Update Magnitude: 0.02217
Value Function Update Magnitude: 0.05781

Collected Steps per Second: 24,551.67520
Overall Steps per Second: 17,849.80001

Timestep Collection Time: 2.03717
Timestep Consumption Time: 0.76488
PPO Batch Consumption Time: 0.05877
Total Iteration Time: 2.80205

Cumulative Model Updates: 6,995
Cumulative Timesteps: 116,737,466

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 116737466...
Checkpoint 116737466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 948.10203
Policy Entropy: 0.49326
Value Function Loss: 2.42654

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02859
Policy Update Magnitude: 0.02153
Value Function Update Magnitude: 0.05779

Collected Steps per Second: 21,615.04527
Overall Steps per Second: 15,779.61242

Timestep Collection Time: 2.31394
Timestep Consumption Time: 0.85572
PPO Batch Consumption Time: 0.10104
Total Iteration Time: 3.16966

Cumulative Model Updates: 6,998
Cumulative Timesteps: 116,787,482

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,591.00982
Policy Entropy: 0.49078
Value Function Loss: 2.43780

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.03369
Policy Update Magnitude: 0.02221
Value Function Update Magnitude: 0.05473

Collected Steps per Second: 23,678.16744
Overall Steps per Second: 17,569.57595

Timestep Collection Time: 2.11216
Timestep Consumption Time: 0.73435
PPO Batch Consumption Time: 0.06211
Total Iteration Time: 2.84651

Cumulative Model Updates: 7,001
Cumulative Timesteps: 116,837,494

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 116837494...
Checkpoint 116837494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.65069
Policy Entropy: 0.50663
Value Function Loss: 2.49151

Mean KL Divergence: 0.00116
SB3 Clip Fraction: 0.01020
Policy Update Magnitude: 0.02559
Value Function Update Magnitude: 0.04695

Collected Steps per Second: 20,713.28218
Overall Steps per Second: 15,108.56198

Timestep Collection Time: 2.41468
Timestep Consumption Time: 0.89576
PPO Batch Consumption Time: 0.11516
Total Iteration Time: 3.31044

Cumulative Model Updates: 7,004
Cumulative Timesteps: 116,887,510

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.13118
Policy Entropy: 0.50528
Value Function Loss: 2.42290

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01639
Policy Update Magnitude: 0.02626
Value Function Update Magnitude: 0.04220

Collected Steps per Second: 24,902.87203
Overall Steps per Second: 17,819.39872

Timestep Collection Time: 2.00884
Timestep Consumption Time: 0.79855
PPO Batch Consumption Time: 0.05877
Total Iteration Time: 2.80739

Cumulative Model Updates: 7,007
Cumulative Timesteps: 116,937,536

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 116937536...
Checkpoint 116937536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,535.64182
Policy Entropy: 0.51484
Value Function Loss: 2.39439

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01821
Policy Update Magnitude: 0.02839
Value Function Update Magnitude: 0.04088

Collected Steps per Second: 20,994.78249
Overall Steps per Second: 14,872.51737

Timestep Collection Time: 2.38250
Timestep Consumption Time: 0.98075
PPO Batch Consumption Time: 0.11919
Total Iteration Time: 3.36325

Cumulative Model Updates: 7,010
Cumulative Timesteps: 116,987,556

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 816.55104
Policy Entropy: 0.49898
Value Function Loss: 2.44160

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.02081
Policy Update Magnitude: 0.02733
Value Function Update Magnitude: 0.03628

Collected Steps per Second: 24,475.87027
Overall Steps per Second: 16,675.54987

Timestep Collection Time: 2.04356
Timestep Consumption Time: 0.95592
PPO Batch Consumption Time: 0.11087
Total Iteration Time: 2.99948

Cumulative Model Updates: 7,013
Cumulative Timesteps: 117,037,574

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 117037574...
Checkpoint 117037574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.02974
Policy Entropy: 0.50955
Value Function Loss: 2.40016

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01999
Policy Update Magnitude: 0.02455
Value Function Update Magnitude: 0.03363

Collected Steps per Second: 23,356.72726
Overall Steps per Second: 16,662.29588

Timestep Collection Time: 2.14140
Timestep Consumption Time: 0.86035
PPO Batch Consumption Time: 0.07686
Total Iteration Time: 3.00175

Cumulative Model Updates: 7,016
Cumulative Timesteps: 117,087,590

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 893.44225
Policy Entropy: 0.49956
Value Function Loss: 2.38346

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01679
Policy Update Magnitude: 0.02610
Value Function Update Magnitude: 0.03380

Collected Steps per Second: 24,100.21480
Overall Steps per Second: 16,749.55715

Timestep Collection Time: 2.07533
Timestep Consumption Time: 0.91077
PPO Batch Consumption Time: 0.09126
Total Iteration Time: 2.98611

Cumulative Model Updates: 7,019
Cumulative Timesteps: 117,137,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 117137606...
Checkpoint 117137606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 845.99401
Policy Entropy: 0.50882
Value Function Loss: 2.25989

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01897
Policy Update Magnitude: 0.02616
Value Function Update Magnitude: 0.03116

Collected Steps per Second: 24,209.56361
Overall Steps per Second: 16,781.37609

Timestep Collection Time: 2.06588
Timestep Consumption Time: 0.91445
PPO Batch Consumption Time: 0.09243
Total Iteration Time: 2.98033

Cumulative Model Updates: 7,022
Cumulative Timesteps: 117,187,620

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,449.55659
Policy Entropy: 0.50592
Value Function Loss: 2.34527

Mean KL Divergence: 0.00124
SB3 Clip Fraction: 0.01155
Policy Update Magnitude: 0.02561
Value Function Update Magnitude: 0.03053

Collected Steps per Second: 24,056.27074
Overall Steps per Second: 16,718.51866

Timestep Collection Time: 2.07879
Timestep Consumption Time: 0.91238
PPO Batch Consumption Time: 0.10387
Total Iteration Time: 2.99117

Cumulative Model Updates: 7,025
Cumulative Timesteps: 117,237,628

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 117237628...
Checkpoint 117237628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.43077
Policy Entropy: 0.51462
Value Function Loss: 2.32686

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.02321
Policy Update Magnitude: 0.02639
Value Function Update Magnitude: 0.02855

Collected Steps per Second: 24,113.18159
Overall Steps per Second: 16,763.34258

Timestep Collection Time: 2.07364
Timestep Consumption Time: 0.90918
PPO Batch Consumption Time: 0.10132
Total Iteration Time: 2.98282

Cumulative Model Updates: 7,028
Cumulative Timesteps: 117,287,630

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,877.56284
Policy Entropy: 0.50846
Value Function Loss: 2.36810

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.02119
Policy Update Magnitude: 0.02925
Value Function Update Magnitude: 0.03270

Collected Steps per Second: 23,945.51512
Overall Steps per Second: 16,689.21930

Timestep Collection Time: 2.08849
Timestep Consumption Time: 0.90805
PPO Batch Consumption Time: 0.10232
Total Iteration Time: 2.99655

Cumulative Model Updates: 7,031
Cumulative Timesteps: 117,337,640

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 117337640...
Checkpoint 117337640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.74273
Policy Entropy: 0.51125
Value Function Loss: 2.26084

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01923
Policy Update Magnitude: 0.02649
Value Function Update Magnitude: 0.03198

Collected Steps per Second: 24,165.15818
Overall Steps per Second: 16,833.68387

Timestep Collection Time: 2.07017
Timestep Consumption Time: 0.90161
PPO Batch Consumption Time: 0.11585
Total Iteration Time: 2.97178

Cumulative Model Updates: 7,034
Cumulative Timesteps: 117,387,666

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,135.44584
Policy Entropy: 0.52010
Value Function Loss: 2.28351

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.03259
Policy Update Magnitude: 0.02610
Value Function Update Magnitude: 0.03496

Collected Steps per Second: 24,009.00585
Overall Steps per Second: 16,603.53749

Timestep Collection Time: 2.08380
Timestep Consumption Time: 0.92941
PPO Batch Consumption Time: 0.12300
Total Iteration Time: 3.01321

Cumulative Model Updates: 7,037
Cumulative Timesteps: 117,437,696

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 117437696...
Checkpoint 117437696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.17211
Policy Entropy: 0.51519
Value Function Loss: 2.25545

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01889
Policy Update Magnitude: 0.02573
Value Function Update Magnitude: 0.03251

Collected Steps per Second: 23,080.12532
Overall Steps per Second: 16,783.59653

Timestep Collection Time: 2.16723
Timestep Consumption Time: 0.81306
PPO Batch Consumption Time: 0.09089
Total Iteration Time: 2.98029

Cumulative Model Updates: 7,040
Cumulative Timesteps: 117,487,716

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.35623
Policy Entropy: 0.51604
Value Function Loss: 2.34406

Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.01298
Policy Update Magnitude: 0.02513
Value Function Update Magnitude: 0.03838

Collected Steps per Second: 23,884.67336
Overall Steps per Second: 16,698.79051

Timestep Collection Time: 2.09348
Timestep Consumption Time: 0.90087
PPO Batch Consumption Time: 0.09039
Total Iteration Time: 2.99435

Cumulative Model Updates: 7,043
Cumulative Timesteps: 117,537,718

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 117537718...
Checkpoint 117537718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 846.80853
Policy Entropy: 0.51141
Value Function Loss: 2.36196

Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.01556
Policy Update Magnitude: 0.02721
Value Function Update Magnitude: 0.03009

Collected Steps per Second: 23,513.79874
Overall Steps per Second: 16,740.68807

Timestep Collection Time: 2.12658
Timestep Consumption Time: 0.86039
PPO Batch Consumption Time: 0.07628
Total Iteration Time: 2.98697

Cumulative Model Updates: 7,046
Cumulative Timesteps: 117,587,722

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.86688
Policy Entropy: 0.51837
Value Function Loss: 2.36358

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02466
Policy Update Magnitude: 0.02759
Value Function Update Magnitude: 0.02559

Collected Steps per Second: 24,482.35588
Overall Steps per Second: 16,761.40741

Timestep Collection Time: 2.04245
Timestep Consumption Time: 0.94083
PPO Batch Consumption Time: 0.10401
Total Iteration Time: 2.98328

Cumulative Model Updates: 7,049
Cumulative Timesteps: 117,637,726

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 117637726...
Checkpoint 117637726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,484.80387
Policy Entropy: 0.51916
Value Function Loss: 2.33631

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.02031
Policy Update Magnitude: 0.02664
Value Function Update Magnitude: 0.02450

Collected Steps per Second: 23,630.57484
Overall Steps per Second: 16,736.87477

Timestep Collection Time: 2.11726
Timestep Consumption Time: 0.87207
PPO Batch Consumption Time: 0.08635
Total Iteration Time: 2.98933

Cumulative Model Updates: 7,052
Cumulative Timesteps: 117,687,758

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 771.09514
Policy Entropy: 0.52019
Value Function Loss: 2.27232

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02705
Policy Update Magnitude: 0.02558
Value Function Update Magnitude: 0.02390

Collected Steps per Second: 24,659.83245
Overall Steps per Second: 16,722.67703

Timestep Collection Time: 2.02767
Timestep Consumption Time: 0.96240
PPO Batch Consumption Time: 0.09970
Total Iteration Time: 2.99007

Cumulative Model Updates: 7,055
Cumulative Timesteps: 117,737,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 117737760...
Checkpoint 117737760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,941.44486
Policy Entropy: 0.50887
Value Function Loss: 2.22864

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02858
Policy Update Magnitude: 0.02419
Value Function Update Magnitude: 0.02501

Collected Steps per Second: 23,922.94483
Overall Steps per Second: 16,775.40803

Timestep Collection Time: 2.09029
Timestep Consumption Time: 0.89062
PPO Batch Consumption Time: 0.09477
Total Iteration Time: 2.98091

Cumulative Model Updates: 7,058
Cumulative Timesteps: 117,787,766

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409.86517
Policy Entropy: 0.51437
Value Function Loss: 2.27076

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02851
Policy Update Magnitude: 0.02213
Value Function Update Magnitude: 0.02412

Collected Steps per Second: 23,762.91549
Overall Steps per Second: 16,712.43167

Timestep Collection Time: 2.10488
Timestep Consumption Time: 0.88799
PPO Batch Consumption Time: 0.09775
Total Iteration Time: 2.99286

Cumulative Model Updates: 7,061
Cumulative Timesteps: 117,837,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 117837784...
Checkpoint 117837784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.24378
Policy Entropy: 0.51452
Value Function Loss: 2.26492

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.02098
Policy Update Magnitude: 0.02498
Value Function Update Magnitude: 0.02053

Collected Steps per Second: 24,018.28894
Overall Steps per Second: 16,757.82305

Timestep Collection Time: 2.08191
Timestep Consumption Time: 0.90201
PPO Batch Consumption Time: 0.09601
Total Iteration Time: 2.98392

Cumulative Model Updates: 7,064
Cumulative Timesteps: 117,887,788

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,077.47697
Policy Entropy: 0.52335
Value Function Loss: 2.24958

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01696
Policy Update Magnitude: 0.02486
Value Function Update Magnitude: 0.02321

Collected Steps per Second: 24,199.17129
Overall Steps per Second: 16,766.67009

Timestep Collection Time: 2.06643
Timestep Consumption Time: 0.91603
PPO Batch Consumption Time: 0.10587
Total Iteration Time: 2.98246

Cumulative Model Updates: 7,067
Cumulative Timesteps: 117,937,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 117937794...
Checkpoint 117937794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 807.08263
Policy Entropy: 0.52528
Value Function Loss: 2.20403

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01987
Policy Update Magnitude: 0.02545
Value Function Update Magnitude: 0.02302

Collected Steps per Second: 24,150.83961
Overall Steps per Second: 16,800.58721

Timestep Collection Time: 2.07098
Timestep Consumption Time: 0.90605
PPO Batch Consumption Time: 0.11963
Total Iteration Time: 2.97704

Cumulative Model Updates: 7,070
Cumulative Timesteps: 117,987,810

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 834.98980
Policy Entropy: 0.53425
Value Function Loss: 2.19241

Mean KL Divergence: 0.00107
SB3 Clip Fraction: 0.00831
Policy Update Magnitude: 0.02745
Value Function Update Magnitude: 0.02140

Collected Steps per Second: 23,579.45990
Overall Steps per Second: 16,698.82123

Timestep Collection Time: 2.12083
Timestep Consumption Time: 0.87387
PPO Batch Consumption Time: 0.10557
Total Iteration Time: 2.99470

Cumulative Model Updates: 7,073
Cumulative Timesteps: 118,037,818

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 118037818...
Checkpoint 118037818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421.34795
Policy Entropy: 0.54529
Value Function Loss: 2.22417

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02831
Policy Update Magnitude: 0.02841
Value Function Update Magnitude: 0.02204

Collected Steps per Second: 23,892.84824
Overall Steps per Second: 16,662.72283

Timestep Collection Time: 2.09368
Timestep Consumption Time: 0.90847
PPO Batch Consumption Time: 0.08849
Total Iteration Time: 3.00215

Cumulative Model Updates: 7,076
Cumulative Timesteps: 118,087,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 880.96519
Policy Entropy: 0.53997
Value Function Loss: 2.23655

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02595
Policy Update Magnitude: 0.02502
Value Function Update Magnitude: 0.02430

Collected Steps per Second: 24,287.67101
Overall Steps per Second: 16,731.58971

Timestep Collection Time: 2.05890
Timestep Consumption Time: 0.92981
PPO Batch Consumption Time: 0.09821
Total Iteration Time: 2.98872

Cumulative Model Updates: 7,079
Cumulative Timesteps: 118,137,848

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 118137848...
Checkpoint 118137848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,083.54375
Policy Entropy: 0.52731
Value Function Loss: 2.22237

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01730
Policy Update Magnitude: 0.02783
Value Function Update Magnitude: 0.02342

Collected Steps per Second: 24,075.96148
Overall Steps per Second: 16,752.49007

Timestep Collection Time: 2.07693
Timestep Consumption Time: 0.90794
PPO Batch Consumption Time: 0.09696
Total Iteration Time: 2.98487

Cumulative Model Updates: 7,082
Cumulative Timesteps: 118,187,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.42940
Policy Entropy: 0.52415
Value Function Loss: 2.25361

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02707
Policy Update Magnitude: 0.02560
Value Function Update Magnitude: 0.02522

Collected Steps per Second: 24,520.68713
Overall Steps per Second: 16,789.88118

Timestep Collection Time: 2.04015
Timestep Consumption Time: 0.93938
PPO Batch Consumption Time: 0.10932
Total Iteration Time: 2.97953

Cumulative Model Updates: 7,085
Cumulative Timesteps: 118,237,878

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 118237878...
Checkpoint 118237878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,985.31448
Policy Entropy: 0.51835
Value Function Loss: 2.20606

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01889
Policy Update Magnitude: 0.02642
Value Function Update Magnitude: 0.02261

Collected Steps per Second: 23,452.77985
Overall Steps per Second: 15,725.37704

Timestep Collection Time: 2.13246
Timestep Consumption Time: 1.04788
PPO Batch Consumption Time: 0.11709
Total Iteration Time: 3.18034

Cumulative Model Updates: 7,088
Cumulative Timesteps: 118,287,890

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,538.23935
Policy Entropy: 0.51972
Value Function Loss: 2.19549

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.01512
Policy Update Magnitude: 0.03041
Value Function Update Magnitude: 0.02103

Collected Steps per Second: 23,562.02781
Overall Steps per Second: 16,825.49790

Timestep Collection Time: 2.12274
Timestep Consumption Time: 0.84989
PPO Batch Consumption Time: 0.06862
Total Iteration Time: 2.97263

Cumulative Model Updates: 7,091
Cumulative Timesteps: 118,337,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 118337906...
Checkpoint 118337906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 869.10660
Policy Entropy: 0.51485
Value Function Loss: 2.17935

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01240
Policy Update Magnitude: 0.03343
Value Function Update Magnitude: 0.02118

Collected Steps per Second: 24,104.08702
Overall Steps per Second: 17,404.04465

Timestep Collection Time: 2.07533
Timestep Consumption Time: 0.79894
PPO Batch Consumption Time: 0.06170
Total Iteration Time: 2.87427

Cumulative Model Updates: 7,094
Cumulative Timesteps: 118,387,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 857.52667
Policy Entropy: 0.50759
Value Function Loss: 2.20573

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01593
Policy Update Magnitude: 0.03111
Value Function Update Magnitude: 0.01965

Collected Steps per Second: 20,824.92930
Overall Steps per Second: 14,838.71764

Timestep Collection Time: 2.40212
Timestep Consumption Time: 0.96906
PPO Batch Consumption Time: 0.12111
Total Iteration Time: 3.37118

Cumulative Model Updates: 7,097
Cumulative Timesteps: 118,437,954

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 118437954...
Checkpoint 118437954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545.91011
Policy Entropy: 0.51314
Value Function Loss: 2.25647

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.02343
Policy Update Magnitude: 0.02905
Value Function Update Magnitude: 0.02214

Collected Steps per Second: 24,146.52522
Overall Steps per Second: 17,416.81554

Timestep Collection Time: 2.07185
Timestep Consumption Time: 0.80055
PPO Batch Consumption Time: 0.07072
Total Iteration Time: 2.87240

Cumulative Model Updates: 7,100
Cumulative Timesteps: 118,487,982

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.30683
Policy Entropy: 0.51245
Value Function Loss: 2.31624

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02640
Policy Update Magnitude: 0.02620
Value Function Update Magnitude: 0.02169

Collected Steps per Second: 24,384.52123
Overall Steps per Second: 17,240.51508

Timestep Collection Time: 2.05089
Timestep Consumption Time: 0.84983
PPO Batch Consumption Time: 0.08797
Total Iteration Time: 2.90073

Cumulative Model Updates: 7,103
Cumulative Timesteps: 118,537,992

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 118537992...
Checkpoint 118537992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,865.80619
Policy Entropy: 0.51559
Value Function Loss: 2.25133

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02453
Policy Update Magnitude: 0.02507
Value Function Update Magnitude: 0.02052

Collected Steps per Second: 23,716.93403
Overall Steps per Second: 17,384.54524

Timestep Collection Time: 2.10820
Timestep Consumption Time: 0.76792
PPO Batch Consumption Time: 0.05989
Total Iteration Time: 2.87612

Cumulative Model Updates: 7,106
Cumulative Timesteps: 118,587,992

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.19260
Policy Entropy: 0.51280
Value Function Loss: 2.26481

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01729
Policy Update Magnitude: 0.02304
Value Function Update Magnitude: 0.02350

Collected Steps per Second: 24,360.51102
Overall Steps per Second: 17,666.87549

Timestep Collection Time: 2.05349
Timestep Consumption Time: 0.77803
PPO Batch Consumption Time: 0.06400
Total Iteration Time: 2.83151

Cumulative Model Updates: 7,109
Cumulative Timesteps: 118,638,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 118638016...
Checkpoint 118638016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.48364
Policy Entropy: 0.51827
Value Function Loss: 2.15604

Mean KL Divergence: 0.00153
SB3 Clip Fraction: 0.01572
Policy Update Magnitude: 0.02699
Value Function Update Magnitude: 0.02281

Collected Steps per Second: 24,471.83187
Overall Steps per Second: 16,633.99441

Timestep Collection Time: 2.04349
Timestep Consumption Time: 0.96288
PPO Batch Consumption Time: 0.10738
Total Iteration Time: 3.00637

Cumulative Model Updates: 7,112
Cumulative Timesteps: 118,688,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.44592
Policy Entropy: 0.51559
Value Function Loss: 2.13878

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01875
Policy Update Magnitude: 0.03148
Value Function Update Magnitude: 0.02036

Collected Steps per Second: 24,366.79609
Overall Steps per Second: 16,700.00037

Timestep Collection Time: 2.05386
Timestep Consumption Time: 0.94291
PPO Batch Consumption Time: 0.11111
Total Iteration Time: 2.99677

Cumulative Model Updates: 7,115
Cumulative Timesteps: 118,738,070

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 118738070...
Checkpoint 118738070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 755.92329
Policy Entropy: 0.51016
Value Function Loss: 2.06224

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.02951
Value Function Update Magnitude: 0.03195

Collected Steps per Second: 23,874.26868
Overall Steps per Second: 16,783.36149

Timestep Collection Time: 2.09548
Timestep Consumption Time: 0.88533
PPO Batch Consumption Time: 0.11045
Total Iteration Time: 2.98081

Cumulative Model Updates: 7,118
Cumulative Timesteps: 118,788,098

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.12318
Policy Entropy: 0.50972
Value Function Loss: 2.06219

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01880
Policy Update Magnitude: 0.03050
Value Function Update Magnitude: 0.03438

Collected Steps per Second: 23,575.06224
Overall Steps per Second: 16,642.54268

Timestep Collection Time: 2.12190
Timestep Consumption Time: 0.88389
PPO Batch Consumption Time: 0.10037
Total Iteration Time: 3.00579

Cumulative Model Updates: 7,121
Cumulative Timesteps: 118,838,122

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 118838122...
Checkpoint 118838122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,626.53234
Policy Entropy: 0.51310
Value Function Loss: 2.09546

Mean KL Divergence: 0.00155
SB3 Clip Fraction: 0.01754
Policy Update Magnitude: 0.03323
Value Function Update Magnitude: 0.03721

Collected Steps per Second: 23,312.17617
Overall Steps per Second: 16,713.72957

Timestep Collection Time: 2.14600
Timestep Consumption Time: 0.84722
PPO Batch Consumption Time: 0.07691
Total Iteration Time: 2.99323

Cumulative Model Updates: 7,124
Cumulative Timesteps: 118,888,150

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,946.21489
Policy Entropy: 0.51619
Value Function Loss: 2.14908

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02731
Policy Update Magnitude: 0.03672
Value Function Update Magnitude: 0.03170

Collected Steps per Second: 24,333.54663
Overall Steps per Second: 16,735.72499

Timestep Collection Time: 2.05486
Timestep Consumption Time: 0.93288
PPO Batch Consumption Time: 0.09468
Total Iteration Time: 2.98774

Cumulative Model Updates: 7,127
Cumulative Timesteps: 118,938,152

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 118938152...
Checkpoint 118938152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.46482
Policy Entropy: 0.52242
Value Function Loss: 2.18564

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03977
Policy Update Magnitude: 0.03785
Value Function Update Magnitude: 0.03634

Collected Steps per Second: 24,144.21043
Overall Steps per Second: 16,791.74209

Timestep Collection Time: 2.07197
Timestep Consumption Time: 0.90724
PPO Batch Consumption Time: 0.09853
Total Iteration Time: 2.97920

Cumulative Model Updates: 7,130
Cumulative Timesteps: 118,988,178

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.66572
Policy Entropy: 0.51498
Value Function Loss: 2.24854

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04333
Policy Update Magnitude: 0.03560
Value Function Update Magnitude: 0.03846

Collected Steps per Second: 24,293.16000
Overall Steps per Second: 16,718.63810

Timestep Collection Time: 2.05935
Timestep Consumption Time: 0.93300
PPO Batch Consumption Time: 0.10371
Total Iteration Time: 2.99235

Cumulative Model Updates: 7,133
Cumulative Timesteps: 119,038,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 119038206...
Checkpoint 119038206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.20694
Policy Entropy: 0.51524
Value Function Loss: 2.29873

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04905
Policy Update Magnitude: 0.03031
Value Function Update Magnitude: 0.03730

Collected Steps per Second: 23,737.40339
Overall Steps per Second: 16,703.96953

Timestep Collection Time: 2.10722
Timestep Consumption Time: 0.88727
PPO Batch Consumption Time: 0.08558
Total Iteration Time: 2.99450

Cumulative Model Updates: 7,136
Cumulative Timesteps: 119,088,226

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.06562
Policy Entropy: 0.51568
Value Function Loss: 2.28272

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.05099
Policy Update Magnitude: 0.02574
Value Function Update Magnitude: 0.03459

Collected Steps per Second: 24,055.94392
Overall Steps per Second: 16,756.34586

Timestep Collection Time: 2.07915
Timestep Consumption Time: 0.90575
PPO Batch Consumption Time: 0.09456
Total Iteration Time: 2.98490

Cumulative Model Updates: 7,139
Cumulative Timesteps: 119,138,242

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 119138242...
Checkpoint 119138242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.73701
Policy Entropy: 0.51844
Value Function Loss: 2.25409

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.04976
Policy Update Magnitude: 0.02402
Value Function Update Magnitude: 0.04010

Collected Steps per Second: 24,349.17593
Overall Steps per Second: 16,840.28999

Timestep Collection Time: 2.05370
Timestep Consumption Time: 0.91572
PPO Batch Consumption Time: 0.10889
Total Iteration Time: 2.96943

Cumulative Model Updates: 7,142
Cumulative Timesteps: 119,188,248

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.92839
Policy Entropy: 0.52569
Value Function Loss: 2.18557

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.05011
Policy Update Magnitude: 0.02367
Value Function Update Magnitude: 0.03638

Collected Steps per Second: 24,002.70756
Overall Steps per Second: 16,687.70678

Timestep Collection Time: 2.08335
Timestep Consumption Time: 0.91323
PPO Batch Consumption Time: 0.10481
Total Iteration Time: 2.99658

Cumulative Model Updates: 7,145
Cumulative Timesteps: 119,238,254

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 119238254...
Checkpoint 119238254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408.86096
Policy Entropy: 0.51902
Value Function Loss: 2.26743

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04949
Policy Update Magnitude: 0.02241
Value Function Update Magnitude: 0.03627

Collected Steps per Second: 24,163.17001
Overall Steps per Second: 16,703.62030

Timestep Collection Time: 2.06960
Timestep Consumption Time: 0.92425
PPO Batch Consumption Time: 0.09690
Total Iteration Time: 2.99384

Cumulative Model Updates: 7,148
Cumulative Timesteps: 119,288,262

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,295.41950
Policy Entropy: 0.51683
Value Function Loss: 2.20143

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04949
Policy Update Magnitude: 0.02062
Value Function Update Magnitude: 0.03149

Collected Steps per Second: 24,776.41455
Overall Steps per Second: 17,859.25846

Timestep Collection Time: 2.01934
Timestep Consumption Time: 0.78212
PPO Batch Consumption Time: 0.07572
Total Iteration Time: 2.80146

Cumulative Model Updates: 7,151
Cumulative Timesteps: 119,338,294

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 119338294...
Checkpoint 119338294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.56047
Policy Entropy: 0.51308
Value Function Loss: 2.21014

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04655
Policy Update Magnitude: 0.02075
Value Function Update Magnitude: 0.03272

Collected Steps per Second: 23,370.33754
Overall Steps per Second: 17,510.30585

Timestep Collection Time: 2.14058
Timestep Consumption Time: 0.71637
PPO Batch Consumption Time: 0.06038
Total Iteration Time: 2.85695

Cumulative Model Updates: 7,154
Cumulative Timesteps: 119,388,320

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.81139
Policy Entropy: 0.52464
Value Function Loss: 2.11954

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04961
Policy Update Magnitude: 0.02182
Value Function Update Magnitude: 0.02926

Collected Steps per Second: 20,979.73825
Overall Steps per Second: 15,086.39154

Timestep Collection Time: 2.38373
Timestep Consumption Time: 0.93118
PPO Batch Consumption Time: 0.09605
Total Iteration Time: 3.31491

Cumulative Model Updates: 7,157
Cumulative Timesteps: 119,438,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 119438330...
Checkpoint 119438330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,483.60524
Policy Entropy: 0.52305
Value Function Loss: 2.20414

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04874
Policy Update Magnitude: 0.02130
Value Function Update Magnitude: 0.03532

Collected Steps per Second: 23,574.04921
Overall Steps per Second: 16,752.30163

Timestep Collection Time: 2.12225
Timestep Consumption Time: 0.86421
PPO Batch Consumption Time: 0.08275
Total Iteration Time: 2.98646

Cumulative Model Updates: 7,160
Cumulative Timesteps: 119,488,360

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,876.52093
Policy Entropy: 0.52915
Value Function Loss: 2.19043

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.05131
Policy Update Magnitude: 0.02094
Value Function Update Magnitude: 0.03609

Collected Steps per Second: 21,395.25207
Overall Steps per Second: 14,701.95834

Timestep Collection Time: 2.33781
Timestep Consumption Time: 1.06432
PPO Batch Consumption Time: 0.11762
Total Iteration Time: 3.40213

Cumulative Model Updates: 7,163
Cumulative Timesteps: 119,538,378

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 119538378...
Checkpoint 119538378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 787.24884
Policy Entropy: 0.51663
Value Function Loss: 2.28436

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04882
Policy Update Magnitude: 0.02187
Value Function Update Magnitude: 0.04087

Collected Steps per Second: 24,113.77768
Overall Steps per Second: 17,312.26048

Timestep Collection Time: 2.07350
Timestep Consumption Time: 0.81462
PPO Batch Consumption Time: 0.07062
Total Iteration Time: 2.88813

Cumulative Model Updates: 7,166
Cumulative Timesteps: 119,588,378

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,633.47081
Policy Entropy: 0.51186
Value Function Loss: 2.21732

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.05061
Policy Update Magnitude: 0.02064
Value Function Update Magnitude: 0.03587

Collected Steps per Second: 23,612.35189
Overall Steps per Second: 16,358.80999

Timestep Collection Time: 2.11864
Timestep Consumption Time: 0.93941
PPO Batch Consumption Time: 0.10878
Total Iteration Time: 3.05805

Cumulative Model Updates: 7,169
Cumulative Timesteps: 119,638,404

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 119638404...
Checkpoint 119638404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,540.54032
Policy Entropy: 0.50007
Value Function Loss: 2.25449

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04679
Policy Update Magnitude: 0.02272
Value Function Update Magnitude: 0.02793

Collected Steps per Second: 24,384.66881
Overall Steps per Second: 17,591.78451

Timestep Collection Time: 2.05137
Timestep Consumption Time: 0.79212
PPO Batch Consumption Time: 0.06104
Total Iteration Time: 2.84349

Cumulative Model Updates: 7,172
Cumulative Timesteps: 119,688,426

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.19256
Policy Entropy: 0.50106
Value Function Loss: 2.20501

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04986
Policy Update Magnitude: 0.02533
Value Function Update Magnitude: 0.02544

Collected Steps per Second: 21,210.08146
Overall Steps per Second: 15,020.51672

Timestep Collection Time: 2.35812
Timestep Consumption Time: 0.97172
PPO Batch Consumption Time: 0.12139
Total Iteration Time: 3.32985

Cumulative Model Updates: 7,175
Cumulative Timesteps: 119,738,442

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 119738442...
Checkpoint 119738442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681.69964
Policy Entropy: 0.49997
Value Function Loss: 2.23566

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04963
Policy Update Magnitude: 0.02315
Value Function Update Magnitude: 0.02339

Collected Steps per Second: 24,720.11240
Overall Steps per Second: 16,749.14290

Timestep Collection Time: 2.02370
Timestep Consumption Time: 0.96308
PPO Batch Consumption Time: 0.11754
Total Iteration Time: 2.98678

Cumulative Model Updates: 7,178
Cumulative Timesteps: 119,788,468

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,678.90992
Policy Entropy: 0.50391
Value Function Loss: 2.18143

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.05043
Policy Update Magnitude: 0.02570
Value Function Update Magnitude: 0.02864

Collected Steps per Second: 24,702.06097
Overall Steps per Second: 16,726.89298

Timestep Collection Time: 2.02437
Timestep Consumption Time: 0.96519
PPO Batch Consumption Time: 0.12158
Total Iteration Time: 2.98956

Cumulative Model Updates: 7,181
Cumulative Timesteps: 119,838,474

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 119838474...
Checkpoint 119838474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,428.28106
Policy Entropy: 0.49780
Value Function Loss: 2.21889

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04719
Policy Update Magnitude: 0.02646
Value Function Update Magnitude: 0.03060

Collected Steps per Second: 24,269.24712
Overall Steps per Second: 16,741.01258

Timestep Collection Time: 2.06039
Timestep Consumption Time: 0.92653
PPO Batch Consumption Time: 0.11257
Total Iteration Time: 2.98692

Cumulative Model Updates: 7,184
Cumulative Timesteps: 119,888,478

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,135.97746
Policy Entropy: 0.50455
Value Function Loss: 2.18715

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.05129
Policy Update Magnitude: 0.02516
Value Function Update Magnitude: 0.02740

Collected Steps per Second: 23,971.68525
Overall Steps per Second: 16,709.14719

Timestep Collection Time: 2.08655
Timestep Consumption Time: 0.90691
PPO Batch Consumption Time: 0.11816
Total Iteration Time: 2.99345

Cumulative Model Updates: 7,187
Cumulative Timesteps: 119,938,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 119938496...
Checkpoint 119938496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,566.54623
Policy Entropy: 0.50208
Value Function Loss: 2.18865

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04928
Policy Update Magnitude: 0.02482
Value Function Update Magnitude: 0.02436

Collected Steps per Second: 23,036.76166
Overall Steps per Second: 16,666.88766

Timestep Collection Time: 2.17166
Timestep Consumption Time: 0.82998
PPO Batch Consumption Time: 0.09353
Total Iteration Time: 3.00164

Cumulative Model Updates: 7,190
Cumulative Timesteps: 119,988,524

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.48331
Policy Entropy: 0.50734
Value Function Loss: 2.16859

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04549
Policy Update Magnitude: 0.02418
Value Function Update Magnitude: 0.02488

Collected Steps per Second: 24,462.90823
Overall Steps per Second: 16,714.50523

Timestep Collection Time: 2.04448
Timestep Consumption Time: 0.94777
PPO Batch Consumption Time: 0.09454
Total Iteration Time: 2.99225

Cumulative Model Updates: 7,193
Cumulative Timesteps: 120,038,538

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 120038538...
Checkpoint 120038538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,167.84673
Policy Entropy: 0.50482
Value Function Loss: 2.17155

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04718
Policy Update Magnitude: 0.02552
Value Function Update Magnitude: 0.02363

Collected Steps per Second: 21,457.50334
Overall Steps per Second: 15,684.33223

Timestep Collection Time: 2.33121
Timestep Consumption Time: 0.85808
PPO Batch Consumption Time: 0.08658
Total Iteration Time: 3.18930

Cumulative Model Updates: 7,196
Cumulative Timesteps: 120,088,560

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.45809
Policy Entropy: 0.50837
Value Function Loss: 2.16183

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04324
Policy Update Magnitude: 0.02454
Value Function Update Magnitude: 0.02394

Collected Steps per Second: 23,464.34863
Overall Steps per Second: 16,935.01659

Timestep Collection Time: 2.13183
Timestep Consumption Time: 0.82193
PPO Batch Consumption Time: 0.06261
Total Iteration Time: 2.95376

Cumulative Model Updates: 7,199
Cumulative Timesteps: 120,138,582

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 120138582...
Checkpoint 120138582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.47568
Policy Entropy: 0.50610
Value Function Loss: 2.10261

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03518
Policy Update Magnitude: 0.02031
Value Function Update Magnitude: 0.02211

Collected Steps per Second: 24,337.99922
Overall Steps per Second: 17,642.93854

Timestep Collection Time: 2.05506
Timestep Consumption Time: 0.77984
PPO Batch Consumption Time: 0.05897
Total Iteration Time: 2.83490

Cumulative Model Updates: 7,202
Cumulative Timesteps: 120,188,598

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 878.61509
Policy Entropy: 0.50565
Value Function Loss: 2.10185

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.03381
Policy Update Magnitude: 0.02167
Value Function Update Magnitude: 0.02410

Collected Steps per Second: 21,087.40508
Overall Steps per Second: 14,834.59559

Timestep Collection Time: 2.37156
Timestep Consumption Time: 0.99962
PPO Batch Consumption Time: 0.12484
Total Iteration Time: 3.37117

Cumulative Model Updates: 7,205
Cumulative Timesteps: 120,238,608

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 120238608...
Checkpoint 120238608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.18607
Policy Entropy: 0.49793
Value Function Loss: 2.14091

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02737
Policy Update Magnitude: 0.02223
Value Function Update Magnitude: 0.03029

Collected Steps per Second: 24,373.07155
Overall Steps per Second: 17,519.16785

Timestep Collection Time: 2.05194
Timestep Consumption Time: 0.80277
PPO Batch Consumption Time: 0.06251
Total Iteration Time: 2.85470

Cumulative Model Updates: 7,208
Cumulative Timesteps: 120,288,620

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.80477
Policy Entropy: 0.49833
Value Function Loss: 2.17888

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02855
Policy Update Magnitude: 0.02348
Value Function Update Magnitude: 0.03246

Collected Steps per Second: 21,344.34087
Overall Steps per Second: 15,120.96530

Timestep Collection Time: 2.34254
Timestep Consumption Time: 0.96413
PPO Batch Consumption Time: 0.12130
Total Iteration Time: 3.30667

Cumulative Model Updates: 7,211
Cumulative Timesteps: 120,338,620

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 120338620...
Checkpoint 120338620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.14535
Policy Entropy: 0.49832
Value Function Loss: 2.15381

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.03139
Policy Update Magnitude: 0.02584
Value Function Update Magnitude: 0.03963

Collected Steps per Second: 24,348.45816
Overall Steps per Second: 16,684.48037

Timestep Collection Time: 2.05368
Timestep Consumption Time: 0.94335
PPO Batch Consumption Time: 0.10670
Total Iteration Time: 2.99704

Cumulative Model Updates: 7,214
Cumulative Timesteps: 120,388,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.49880
Policy Entropy: 0.50296
Value Function Loss: 2.10563

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03779
Policy Update Magnitude: 0.02477
Value Function Update Magnitude: 0.03963

Collected Steps per Second: 24,721.58801
Overall Steps per Second: 16,774.64302

Timestep Collection Time: 2.02293
Timestep Consumption Time: 0.95836
PPO Batch Consumption Time: 0.11797
Total Iteration Time: 2.98129

Cumulative Model Updates: 7,217
Cumulative Timesteps: 120,438,634

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 120438634...
Checkpoint 120438634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.37025
Policy Entropy: 0.49809
Value Function Loss: 2.12023

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.03261
Policy Update Magnitude: 0.02773
Value Function Update Magnitude: 0.03452

Collected Steps per Second: 24,026.60850
Overall Steps per Second: 16,753.51965

Timestep Collection Time: 2.08219
Timestep Consumption Time: 0.90393
PPO Batch Consumption Time: 0.10382
Total Iteration Time: 2.98612

Cumulative Model Updates: 7,220
Cumulative Timesteps: 120,488,662

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.25016
Policy Entropy: 0.49927
Value Function Loss: 2.09991

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02284
Policy Update Magnitude: 0.02903
Value Function Update Magnitude: 0.03620

Collected Steps per Second: 24,612.92571
Overall Steps per Second: 17,750.49719

Timestep Collection Time: 2.03267
Timestep Consumption Time: 0.78584
PPO Batch Consumption Time: 0.07404
Total Iteration Time: 2.81851

Cumulative Model Updates: 7,223
Cumulative Timesteps: 120,538,692

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 120538692...
Checkpoint 120538692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,516.26485
Policy Entropy: 0.49927
Value Function Loss: 2.05188

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01738
Policy Update Magnitude: 0.03336
Value Function Update Magnitude: 0.03372

Collected Steps per Second: 22,828.74442
Overall Steps per Second: 17,152.95288

Timestep Collection Time: 2.19022
Timestep Consumption Time: 0.72473
PPO Batch Consumption Time: 0.05767
Total Iteration Time: 2.91495

Cumulative Model Updates: 7,226
Cumulative Timesteps: 120,588,692

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 938.22243
Policy Entropy: 0.49723
Value Function Loss: 2.01363

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02499
Policy Update Magnitude: 0.03369
Value Function Update Magnitude: 0.03443

Collected Steps per Second: 24,067.23928
Overall Steps per Second: 17,383.95648

Timestep Collection Time: 2.07801
Timestep Consumption Time: 0.79889
PPO Batch Consumption Time: 0.08453
Total Iteration Time: 2.87691

Cumulative Model Updates: 7,229
Cumulative Timesteps: 120,638,704

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 120638704...
Checkpoint 120638704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.30781
Policy Entropy: 0.50539
Value Function Loss: 2.00582

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01941
Policy Update Magnitude: 0.03601
Value Function Update Magnitude: 0.03822

Collected Steps per Second: 23,774.23569
Overall Steps per Second: 17,209.01637

Timestep Collection Time: 2.10505
Timestep Consumption Time: 0.80307
PPO Batch Consumption Time: 0.06075
Total Iteration Time: 2.90813

Cumulative Model Updates: 7,232
Cumulative Timesteps: 120,688,750

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801.45520
Policy Entropy: 0.50244
Value Function Loss: 2.03406

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02249
Policy Update Magnitude: 0.03920
Value Function Update Magnitude: 0.03918

Collected Steps per Second: 24,886.70364
Overall Steps per Second: 17,817.12561

Timestep Collection Time: 2.00927
Timestep Consumption Time: 0.79725
PPO Batch Consumption Time: 0.06398
Total Iteration Time: 2.80651

Cumulative Model Updates: 7,235
Cumulative Timesteps: 120,738,754

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 120738754...
Checkpoint 120738754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,583.05847
Policy Entropy: 0.50235
Value Function Loss: 2.00550

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02287
Policy Update Magnitude: 0.03474
Value Function Update Magnitude: 0.03595

Collected Steps per Second: 24,284.47141
Overall Steps per Second: 16,576.55046

Timestep Collection Time: 2.05893
Timestep Consumption Time: 0.95738
PPO Batch Consumption Time: 0.10375
Total Iteration Time: 3.01631

Cumulative Model Updates: 7,238
Cumulative Timesteps: 120,788,754

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.29087
Policy Entropy: 0.50241
Value Function Loss: 1.96983

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02530
Policy Update Magnitude: 0.03365
Value Function Update Magnitude: 0.03977

Collected Steps per Second: 24,416.33839
Overall Steps per Second: 16,710.03878

Timestep Collection Time: 2.04912
Timestep Consumption Time: 0.94501
PPO Batch Consumption Time: 0.09990
Total Iteration Time: 2.99413

Cumulative Model Updates: 7,241
Cumulative Timesteps: 120,838,786

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 120838786...
Checkpoint 120838786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,309.98473
Policy Entropy: 0.49800
Value Function Loss: 2.01105

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.02066
Policy Update Magnitude: 0.03142
Value Function Update Magnitude: 0.04392

Collected Steps per Second: 24,564.67190
Overall Steps per Second: 16,825.63394

Timestep Collection Time: 2.03577
Timestep Consumption Time: 0.93636
PPO Batch Consumption Time: 0.10437
Total Iteration Time: 2.97213

Cumulative Model Updates: 7,244
Cumulative Timesteps: 120,888,794

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.91101
Policy Entropy: 0.49790
Value Function Loss: 2.02350

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01936
Policy Update Magnitude: 0.03268
Value Function Update Magnitude: 0.04047

Collected Steps per Second: 24,465.73955
Overall Steps per Second: 16,720.70064

Timestep Collection Time: 2.04425
Timestep Consumption Time: 0.94690
PPO Batch Consumption Time: 0.10991
Total Iteration Time: 2.99114

Cumulative Model Updates: 7,247
Cumulative Timesteps: 120,938,808

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 120938808...
Checkpoint 120938808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.59658
Policy Entropy: 0.49628
Value Function Loss: 2.04540

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01935
Policy Update Magnitude: 0.03505
Value Function Update Magnitude: 0.03409

Collected Steps per Second: 24,101.74325
Overall Steps per Second: 16,687.39130

Timestep Collection Time: 2.07470
Timestep Consumption Time: 0.92181
PPO Batch Consumption Time: 0.09505
Total Iteration Time: 2.99651

Cumulative Model Updates: 7,250
Cumulative Timesteps: 120,988,812

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.00843
Policy Entropy: 0.48767
Value Function Loss: 2.03416

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02675
Policy Update Magnitude: 0.03108
Value Function Update Magnitude: 0.02929

Collected Steps per Second: 24,123.27337
Overall Steps per Second: 16,726.28438

Timestep Collection Time: 2.07377
Timestep Consumption Time: 0.91710
PPO Batch Consumption Time: 0.09818
Total Iteration Time: 2.99086

Cumulative Model Updates: 7,253
Cumulative Timesteps: 121,038,838

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 121038838...
Checkpoint 121038838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.76781
Policy Entropy: 0.49219
Value Function Loss: 2.01042

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02930
Policy Update Magnitude: 0.03042
Value Function Update Magnitude: 0.02724

Collected Steps per Second: 24,568.64057
Overall Steps per Second: 16,757.84419

Timestep Collection Time: 2.03625
Timestep Consumption Time: 0.94909
PPO Batch Consumption Time: 0.10334
Total Iteration Time: 2.98535

Cumulative Model Updates: 7,256
Cumulative Timesteps: 121,088,866

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.53186
Policy Entropy: 0.49983
Value Function Loss: 2.02325

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02845
Policy Update Magnitude: 0.02786
Value Function Update Magnitude: 0.02915

Collected Steps per Second: 24,562.45518
Overall Steps per Second: 16,798.31086

Timestep Collection Time: 2.03652
Timestep Consumption Time: 0.94128
PPO Batch Consumption Time: 0.11424
Total Iteration Time: 2.97780

Cumulative Model Updates: 7,259
Cumulative Timesteps: 121,138,888

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 121138888...
Checkpoint 121138888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,779.09109
Policy Entropy: 0.50759
Value Function Loss: 1.97152

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02467
Policy Update Magnitude: 0.02419
Value Function Update Magnitude: 0.02990

Collected Steps per Second: 23,622.02939
Overall Steps per Second: 16,675.06877

Timestep Collection Time: 2.11735
Timestep Consumption Time: 0.88210
PPO Batch Consumption Time: 0.09142
Total Iteration Time: 2.99945

Cumulative Model Updates: 7,262
Cumulative Timesteps: 121,188,904

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 952.17195
Policy Entropy: 0.50780
Value Function Loss: 2.00107

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01413
Policy Update Magnitude: 0.02715
Value Function Update Magnitude: 0.03475

Collected Steps per Second: 24,845.45832
Overall Steps per Second: 16,809.47327

Timestep Collection Time: 2.01365
Timestep Consumption Time: 0.96265
PPO Batch Consumption Time: 0.11992
Total Iteration Time: 2.97630

Cumulative Model Updates: 7,265
Cumulative Timesteps: 121,238,934

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 121238934...
Checkpoint 121238934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.53755
Policy Entropy: 0.50739
Value Function Loss: 1.99128

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01453
Policy Update Magnitude: 0.03182
Value Function Update Magnitude: 0.04171

Collected Steps per Second: 23,854.30612
Overall Steps per Second: 16,686.76427

Timestep Collection Time: 2.09623
Timestep Consumption Time: 0.90040
PPO Batch Consumption Time: 0.10002
Total Iteration Time: 2.99663

Cumulative Model Updates: 7,268
Cumulative Timesteps: 121,288,938

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580.24824
Policy Entropy: 0.50803
Value Function Loss: 1.98158

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01965
Policy Update Magnitude: 0.03418
Value Function Update Magnitude: 0.04382

Collected Steps per Second: 24,434.42673
Overall Steps per Second: 17,645.33608

Timestep Collection Time: 2.04637
Timestep Consumption Time: 0.78735
PPO Batch Consumption Time: 0.08022
Total Iteration Time: 2.83372

Cumulative Model Updates: 7,271
Cumulative Timesteps: 121,338,940

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 121338940...
Checkpoint 121338940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,396.18342
Policy Entropy: 0.51007
Value Function Loss: 1.95009

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02459
Policy Update Magnitude: 0.03478
Value Function Update Magnitude: 0.04455

Collected Steps per Second: 22,124.01420
Overall Steps per Second: 15,978.90118

Timestep Collection Time: 2.26026
Timestep Consumption Time: 0.86924
PPO Batch Consumption Time: 0.10820
Total Iteration Time: 3.12950

Cumulative Model Updates: 7,274
Cumulative Timesteps: 121,388,946

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,859.84901
Policy Entropy: 0.51040
Value Function Loss: 1.95279

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02941
Policy Update Magnitude: 0.03022
Value Function Update Magnitude: 0.03362

Collected Steps per Second: 24,816.35239
Overall Steps per Second: 16,696.46955

Timestep Collection Time: 2.01512
Timestep Consumption Time: 0.98000
PPO Batch Consumption Time: 0.10959
Total Iteration Time: 2.99512

Cumulative Model Updates: 7,277
Cumulative Timesteps: 121,438,954

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 121438954...
Checkpoint 121438954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,576.31359
Policy Entropy: 0.51450
Value Function Loss: 1.93989

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.02065
Policy Update Magnitude: 0.02916
Value Function Update Magnitude: 0.04732

Collected Steps per Second: 24,346.99071
Overall Steps per Second: 16,732.81108

Timestep Collection Time: 2.05438
Timestep Consumption Time: 0.93484
PPO Batch Consumption Time: 0.10305
Total Iteration Time: 2.98922

Cumulative Model Updates: 7,280
Cumulative Timesteps: 121,488,972

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,724.91338
Policy Entropy: 0.52067
Value Function Loss: 1.99769

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01659
Policy Update Magnitude: 0.03161
Value Function Update Magnitude: 0.05016

Collected Steps per Second: 24,259.85662
Overall Steps per Second: 16,730.64215

Timestep Collection Time: 2.06192
Timestep Consumption Time: 0.92792
PPO Batch Consumption Time: 0.10265
Total Iteration Time: 2.98984

Cumulative Model Updates: 7,283
Cumulative Timesteps: 121,538,994

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 121538994...
Checkpoint 121538994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.55297
Policy Entropy: 0.51323
Value Function Loss: 1.96220

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.02044
Policy Update Magnitude: 0.02912
Value Function Update Magnitude: 0.05228

Collected Steps per Second: 24,516.83881
Overall Steps per Second: 16,795.04517

Timestep Collection Time: 2.03990
Timestep Consumption Time: 0.93788
PPO Batch Consumption Time: 0.10503
Total Iteration Time: 2.97778

Cumulative Model Updates: 7,286
Cumulative Timesteps: 121,589,006

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,393.62092
Policy Entropy: 0.52035
Value Function Loss: 2.01144

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.05276
Policy Update Magnitude: 0.02930
Value Function Update Magnitude: 0.04596

Collected Steps per Second: 24,030.84902
Overall Steps per Second: 16,559.65285

Timestep Collection Time: 2.08191
Timestep Consumption Time: 0.93929
PPO Batch Consumption Time: 0.09871
Total Iteration Time: 3.02120

Cumulative Model Updates: 7,289
Cumulative Timesteps: 121,639,036

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 121639036...
Checkpoint 121639036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 816.65911
Policy Entropy: 0.50467
Value Function Loss: 2.01327

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.04575
Policy Update Magnitude: 0.02495
Value Function Update Magnitude: 0.05716

Collected Steps per Second: 24,475.73901
Overall Steps per Second: 16,761.30530

Timestep Collection Time: 2.04382
Timestep Consumption Time: 0.94067
PPO Batch Consumption Time: 0.10190
Total Iteration Time: 2.98449

Cumulative Model Updates: 7,292
Cumulative Timesteps: 121,689,060

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.98344
Policy Entropy: 0.50621
Value Function Loss: 2.03220

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.03259
Policy Update Magnitude: 0.02191
Value Function Update Magnitude: 0.05946

Collected Steps per Second: 24,359.12657
Overall Steps per Second: 16,867.93988

Timestep Collection Time: 2.05344
Timestep Consumption Time: 0.91195
PPO Batch Consumption Time: 0.10690
Total Iteration Time: 2.96539

Cumulative Model Updates: 7,295
Cumulative Timesteps: 121,739,080

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 121739080...
Checkpoint 121739080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 820.64696
Policy Entropy: 0.51595
Value Function Loss: 2.01894

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03525
Policy Update Magnitude: 0.02002
Value Function Update Magnitude: 0.05517

Collected Steps per Second: 23,814.03927
Overall Steps per Second: 16,679.43843

Timestep Collection Time: 2.10019
Timestep Consumption Time: 0.89835
PPO Batch Consumption Time: 0.09766
Total Iteration Time: 2.99854

Cumulative Model Updates: 7,298
Cumulative Timesteps: 121,789,094

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.75587
Policy Entropy: 0.52134
Value Function Loss: 1.99456

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01298
Policy Update Magnitude: 0.02354
Value Function Update Magnitude: 0.05019

Collected Steps per Second: 24,732.73361
Overall Steps per Second: 16,809.60171

Timestep Collection Time: 2.02266
Timestep Consumption Time: 0.95337
PPO Batch Consumption Time: 0.11803
Total Iteration Time: 2.97604

Cumulative Model Updates: 7,301
Cumulative Timesteps: 121,839,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 121839120...
Checkpoint 121839120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889.73966
Policy Entropy: 0.52674
Value Function Loss: 1.98560

Mean KL Divergence: 0.00096
SB3 Clip Fraction: 0.00697
Policy Update Magnitude: 0.02879
Value Function Update Magnitude: 0.05809

Collected Steps per Second: 24,131.79959
Overall Steps per Second: 16,738.36219

Timestep Collection Time: 2.07303
Timestep Consumption Time: 0.91567
PPO Batch Consumption Time: 0.10471
Total Iteration Time: 2.98870

Cumulative Model Updates: 7,304
Cumulative Timesteps: 121,889,146

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.60993
Policy Entropy: 0.51736
Value Function Loss: 1.99910

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03234
Policy Update Magnitude: 0.02887
Value Function Update Magnitude: 0.05348

Collected Steps per Second: 24,570.14770
Overall Steps per Second: 17,783.51627

Timestep Collection Time: 2.03532
Timestep Consumption Time: 0.77673
PPO Batch Consumption Time: 0.07797
Total Iteration Time: 2.81204

Cumulative Model Updates: 7,307
Cumulative Timesteps: 121,939,154

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 121939154...
Checkpoint 121939154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 765.26935
Policy Entropy: 0.52523
Value Function Loss: 1.96280

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02391
Policy Update Magnitude: 0.02517
Value Function Update Magnitude: 0.04382

Collected Steps per Second: 23,046.03901
Overall Steps per Second: 17,268.74259

Timestep Collection Time: 2.17070
Timestep Consumption Time: 0.72621
PPO Batch Consumption Time: 0.06304
Total Iteration Time: 2.89691

Cumulative Model Updates: 7,310
Cumulative Timesteps: 121,989,180

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 931.89831
Policy Entropy: 0.51697
Value Function Loss: 1.94393

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.01657
Policy Update Magnitude: 0.02651
Value Function Update Magnitude: 0.03749

Collected Steps per Second: 24,832.53082
Overall Steps per Second: 17,379.86981

Timestep Collection Time: 2.01453
Timestep Consumption Time: 0.86385
PPO Batch Consumption Time: 0.08600
Total Iteration Time: 2.87839

Cumulative Model Updates: 7,313
Cumulative Timesteps: 122,039,206

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 122039206...
Checkpoint 122039206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.95766
Policy Entropy: 0.52081
Value Function Loss: 1.90139

Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.01221
Policy Update Magnitude: 0.02903
Value Function Update Magnitude: 0.03340

Collected Steps per Second: 24,067.91920
Overall Steps per Second: 17,435.63106

Timestep Collection Time: 2.07779
Timestep Consumption Time: 0.79036
PPO Batch Consumption Time: 0.06115
Total Iteration Time: 2.86815

Cumulative Model Updates: 7,316
Cumulative Timesteps: 122,089,214

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 862.96539
Policy Entropy: 0.51843
Value Function Loss: 1.91591

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01900
Policy Update Magnitude: 0.03110
Value Function Update Magnitude: 0.03610

Collected Steps per Second: 21,423.56074
Overall Steps per Second: 15,202.79431

Timestep Collection Time: 2.33444
Timestep Consumption Time: 0.95522
PPO Batch Consumption Time: 0.10947
Total Iteration Time: 3.28966

Cumulative Model Updates: 7,319
Cumulative Timesteps: 122,139,226

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 122139226...
Checkpoint 122139226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.45762
Policy Entropy: 0.51964
Value Function Loss: 1.96811

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01444
Policy Update Magnitude: 0.03058
Value Function Update Magnitude: 0.03740

Collected Steps per Second: 24,690.72168
Overall Steps per Second: 17,766.88420

Timestep Collection Time: 2.02546
Timestep Consumption Time: 0.78933
PPO Batch Consumption Time: 0.05845
Total Iteration Time: 2.81479

Cumulative Model Updates: 7,322
Cumulative Timesteps: 122,189,236

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 980.99075
Policy Entropy: 0.52362
Value Function Loss: 2.01506

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.02120
Policy Update Magnitude: 0.02868
Value Function Update Magnitude: 0.04367

Collected Steps per Second: 21,250.06619
Overall Steps per Second: 14,887.35761

Timestep Collection Time: 2.35322
Timestep Consumption Time: 1.00574
PPO Batch Consumption Time: 0.12301
Total Iteration Time: 3.35896

Cumulative Model Updates: 7,325
Cumulative Timesteps: 122,239,242

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 122239242...
Checkpoint 122239242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.88384
Policy Entropy: 0.52983
Value Function Loss: 1.99668

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.02161
Policy Update Magnitude: 0.02811
Value Function Update Magnitude: 0.03966

Collected Steps per Second: 24,154.98478
Overall Steps per Second: 16,682.66998

Timestep Collection Time: 2.07088
Timestep Consumption Time: 0.92756
PPO Batch Consumption Time: 0.10413
Total Iteration Time: 2.99844

Cumulative Model Updates: 7,328
Cumulative Timesteps: 122,289,264

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.09892
Policy Entropy: 0.52977
Value Function Loss: 1.92022

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.01031
Policy Update Magnitude: 0.02843
Value Function Update Magnitude: 0.04284

Collected Steps per Second: 24,126.26914
Overall Steps per Second: 16,764.73632

Timestep Collection Time: 2.07351
Timestep Consumption Time: 0.91049
PPO Batch Consumption Time: 0.10378
Total Iteration Time: 2.98400

Cumulative Model Updates: 7,331
Cumulative Timesteps: 122,339,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 122339290...
Checkpoint 122339290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,879.05982
Policy Entropy: 0.54320
Value Function Loss: 1.83259

Mean KL Divergence: 0.00115
SB3 Clip Fraction: 0.00879
Policy Update Magnitude: 0.03110
Value Function Update Magnitude: 0.04181

Collected Steps per Second: 24,251.57761
Overall Steps per Second: 16,714.11108

Timestep Collection Time: 2.06263
Timestep Consumption Time: 0.93017
PPO Batch Consumption Time: 0.09814
Total Iteration Time: 2.99280

Cumulative Model Updates: 7,334
Cumulative Timesteps: 122,389,312

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.05530
Policy Entropy: 0.53749
Value Function Loss: 1.84370

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.03001
Policy Update Magnitude: 0.02972
Value Function Update Magnitude: 0.03573

Collected Steps per Second: 23,700.71847
Overall Steps per Second: 16,661.94713

Timestep Collection Time: 2.11074
Timestep Consumption Time: 0.89167
PPO Batch Consumption Time: 0.07639
Total Iteration Time: 3.00241

Cumulative Model Updates: 7,337
Cumulative Timesteps: 122,439,338

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 122439338...
Checkpoint 122439338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,784.01591
Policy Entropy: 0.54248
Value Function Loss: 1.89016

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.01432
Policy Update Magnitude: 0.02930
Value Function Update Magnitude: 0.03582

Collected Steps per Second: 23,901.43727
Overall Steps per Second: 16,819.44548

Timestep Collection Time: 2.09268
Timestep Consumption Time: 0.88114
PPO Batch Consumption Time: 0.09561
Total Iteration Time: 2.97382

Cumulative Model Updates: 7,340
Cumulative Timesteps: 122,489,356

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,410.32291
Policy Entropy: 0.53751
Value Function Loss: 1.97076

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.01192
Policy Update Magnitude: 0.02968
Value Function Update Magnitude: 0.03333

Collected Steps per Second: 24,464.37098
Overall Steps per Second: 17,674.25483

Timestep Collection Time: 2.04395
Timestep Consumption Time: 0.78525
PPO Batch Consumption Time: 0.07894
Total Iteration Time: 2.82920

Cumulative Model Updates: 7,343
Cumulative Timesteps: 122,539,360

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 122539360...
Checkpoint 122539360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,746.48890
Policy Entropy: 0.54165
Value Function Loss: 1.98991

Mean KL Divergence: 0.00139
SB3 Clip Fraction: 0.01440
Policy Update Magnitude: 0.03152
Value Function Update Magnitude: 0.03523

Collected Steps per Second: 21,318.96606
Overall Steps per Second: 15,867.21401

Timestep Collection Time: 2.34533
Timestep Consumption Time: 0.80582
PPO Batch Consumption Time: 0.08957
Total Iteration Time: 3.15115

Cumulative Model Updates: 7,346
Cumulative Timesteps: 122,589,360

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,583.57383
Policy Entropy: 0.54642
Value Function Loss: 1.94939

Mean KL Divergence: 0.00123
SB3 Clip Fraction: 0.01063
Policy Update Magnitude: 0.03436
Value Function Update Magnitude: 0.03349

Collected Steps per Second: 23,733.33200
Overall Steps per Second: 16,809.69949

Timestep Collection Time: 2.10699
Timestep Consumption Time: 0.86784
PPO Batch Consumption Time: 0.10731
Total Iteration Time: 2.97483

Cumulative Model Updates: 7,349
Cumulative Timesteps: 122,639,366

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 122639366...
Checkpoint 122639366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722.97033
Policy Entropy: 0.54558
Value Function Loss: 1.86771

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.02034
Policy Update Magnitude: 0.03487
Value Function Update Magnitude: 0.03486

Collected Steps per Second: 23,785.87613
Overall Steps per Second: 16,545.16005

Timestep Collection Time: 2.10259
Timestep Consumption Time: 0.92016
PPO Batch Consumption Time: 0.09453
Total Iteration Time: 3.02276

Cumulative Model Updates: 7,352
Cumulative Timesteps: 122,689,378

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,074.40875
Policy Entropy: 0.54185
Value Function Loss: 1.84717

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02427
Policy Update Magnitude: 0.03214
Value Function Update Magnitude: 0.03450

Collected Steps per Second: 24,881.36798
Overall Steps per Second: 16,784.42309

Timestep Collection Time: 2.01002
Timestep Consumption Time: 0.96965
PPO Batch Consumption Time: 0.10663
Total Iteration Time: 2.97967

Cumulative Model Updates: 7,355
Cumulative Timesteps: 122,739,390

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 122739390...
Checkpoint 122739390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,537.35524
Policy Entropy: 0.54094
Value Function Loss: 1.84692

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02357
Policy Update Magnitude: 0.03473
Value Function Update Magnitude: 0.03586

Collected Steps per Second: 23,187.94783
Overall Steps per Second: 15,847.40962

Timestep Collection Time: 2.15698
Timestep Consumption Time: 0.99912
PPO Batch Consumption Time: 0.11098
Total Iteration Time: 3.15610

Cumulative Model Updates: 7,358
Cumulative Timesteps: 122,789,406

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,840.16803
Policy Entropy: 0.53680
Value Function Loss: 1.87427

Mean KL Divergence: 0.00134
SB3 Clip Fraction: 0.01268
Policy Update Magnitude: 0.03364
Value Function Update Magnitude: 0.03268

Collected Steps per Second: 23,201.40425
Overall Steps per Second: 16,760.81055

Timestep Collection Time: 2.15642
Timestep Consumption Time: 0.82864
PPO Batch Consumption Time: 0.06360
Total Iteration Time: 2.98506

Cumulative Model Updates: 7,361
Cumulative Timesteps: 122,839,438

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 122839438...
Checkpoint 122839438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.64802
Policy Entropy: 0.53313
Value Function Loss: 1.90506

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02460
Policy Update Magnitude: 0.03119
Value Function Update Magnitude: 0.03398

Collected Steps per Second: 21,177.16533
Overall Steps per Second: 14,780.83493

Timestep Collection Time: 2.36160
Timestep Consumption Time: 1.02197
PPO Batch Consumption Time: 0.11966
Total Iteration Time: 3.38357

Cumulative Model Updates: 7,364
Cumulative Timesteps: 122,889,450

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.46011
Policy Entropy: 0.54457
Value Function Loss: 1.95781

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.03247
Policy Update Magnitude: 0.02732
Value Function Update Magnitude: 0.04380

Collected Steps per Second: 23,806.12062
Overall Steps per Second: 16,591.14416

Timestep Collection Time: 2.10097
Timestep Consumption Time: 0.91365
PPO Batch Consumption Time: 0.09349
Total Iteration Time: 3.01462

Cumulative Model Updates: 7,367
Cumulative Timesteps: 122,939,466

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 122939466...
Checkpoint 122939466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,987.15776
Policy Entropy: 0.55125
Value Function Loss: 1.98916

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01576
Policy Update Magnitude: 0.02844
Value Function Update Magnitude: 0.04577

Collected Steps per Second: 24,114.71047
Overall Steps per Second: 16,736.71414

Timestep Collection Time: 2.07434
Timestep Consumption Time: 0.91442
PPO Batch Consumption Time: 0.08677
Total Iteration Time: 2.98876

Cumulative Model Updates: 7,370
Cumulative Timesteps: 122,989,488

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,379.74679
Policy Entropy: 0.55180
Value Function Loss: 1.94595

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02499
Policy Update Magnitude: 0.02867
Value Function Update Magnitude: 0.04213

Collected Steps per Second: 24,670.99424
Overall Steps per Second: 16,851.45937

Timestep Collection Time: 2.02805
Timestep Consumption Time: 0.94107
PPO Batch Consumption Time: 0.11342
Total Iteration Time: 2.96912

Cumulative Model Updates: 7,373
Cumulative Timesteps: 123,039,522

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 123039522...
Checkpoint 123039522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,794.42326
Policy Entropy: 0.55146
Value Function Loss: 1.88121

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02713
Policy Update Magnitude: 0.02702
Value Function Update Magnitude: 0.03771

Collected Steps per Second: 23,915.04334
Overall Steps per Second: 17,125.77130

Timestep Collection Time: 2.09090
Timestep Consumption Time: 0.82891
PPO Batch Consumption Time: 0.07749
Total Iteration Time: 2.91981

Cumulative Model Updates: 7,376
Cumulative Timesteps: 123,089,526

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,738.50239
Policy Entropy: 0.53792
Value Function Loss: 1.88970

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03539
Policy Update Magnitude: 0.02709
Value Function Update Magnitude: 0.04412

Collected Steps per Second: 24,563.10428
Overall Steps per Second: 16,809.21693

Timestep Collection Time: 2.03582
Timestep Consumption Time: 0.93910
PPO Batch Consumption Time: 0.10881
Total Iteration Time: 2.97492

Cumulative Model Updates: 7,379
Cumulative Timesteps: 123,139,532

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 123139532...
Checkpoint 123139532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,762.99721
Policy Entropy: 0.52832
Value Function Loss: 1.86904

Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.01005
Policy Update Magnitude: 0.02938
Value Function Update Magnitude: 0.04254

Collected Steps per Second: 23,793.09995
Overall Steps per Second: 16,711.76309

Timestep Collection Time: 2.10162
Timestep Consumption Time: 0.89053
PPO Batch Consumption Time: 0.09576
Total Iteration Time: 2.99214

Cumulative Model Updates: 7,382
Cumulative Timesteps: 123,189,536

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.57274
Policy Entropy: 0.52989
Value Function Loss: 1.91729

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01603
Policy Update Magnitude: 0.03396
Value Function Update Magnitude: 0.04108

Collected Steps per Second: 24,742.68391
Overall Steps per Second: 17,824.01443

Timestep Collection Time: 2.02088
Timestep Consumption Time: 0.78444
PPO Batch Consumption Time: 0.07542
Total Iteration Time: 2.80532

Cumulative Model Updates: 7,385
Cumulative Timesteps: 123,239,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 123239538...
Checkpoint 123239538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.28732
Policy Entropy: 0.53536
Value Function Loss: 1.82727

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.03069
Policy Update Magnitude: 0.02951
Value Function Update Magnitude: 0.03815

Collected Steps per Second: 23,250.31394
Overall Steps per Second: 17,528.08453

Timestep Collection Time: 2.15137
Timestep Consumption Time: 0.70234
PPO Batch Consumption Time: 0.06006
Total Iteration Time: 2.85371

Cumulative Model Updates: 7,388
Cumulative Timesteps: 123,289,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.19995
Policy Entropy: 0.53230
Value Function Loss: 1.89573

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03635
Policy Update Magnitude: 0.02550
Value Function Update Magnitude: 0.03082

Collected Steps per Second: 21,313.91624
Overall Steps per Second: 16,008.13903

Timestep Collection Time: 2.34729
Timestep Consumption Time: 0.77799
PPO Batch Consumption Time: 0.07276
Total Iteration Time: 3.12529

Cumulative Model Updates: 7,391
Cumulative Timesteps: 123,339,588

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 123339588...
Checkpoint 123339588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,825.64683
Policy Entropy: 0.53034
Value Function Loss: 1.85918

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03458
Policy Update Magnitude: 0.02238
Value Function Update Magnitude: 0.02650

Collected Steps per Second: 24,639.67468
Overall Steps per Second: 17,678.19660

Timestep Collection Time: 2.02998
Timestep Consumption Time: 0.79938
PPO Batch Consumption Time: 0.06093
Total Iteration Time: 2.82936

Cumulative Model Updates: 7,394
Cumulative Timesteps: 123,389,606

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.48293
Policy Entropy: 0.52617
Value Function Loss: 1.88166

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.03097
Policy Update Magnitude: 0.02302
Value Function Update Magnitude: 0.02724

Collected Steps per Second: 21,737.85298
Overall Steps per Second: 15,093.74151

Timestep Collection Time: 2.30078
Timestep Consumption Time: 1.01278
PPO Batch Consumption Time: 0.12696
Total Iteration Time: 3.31356

Cumulative Model Updates: 7,397
Cumulative Timesteps: 123,439,620

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 123439620...
Checkpoint 123439620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,733.69550
Policy Entropy: 0.52546
Value Function Loss: 1.85809

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02807
Policy Update Magnitude: 0.02354
Value Function Update Magnitude: 0.02668

Collected Steps per Second: 24,338.97953
Overall Steps per Second: 16,740.86560

Timestep Collection Time: 2.05506
Timestep Consumption Time: 0.93272
PPO Batch Consumption Time: 0.10597
Total Iteration Time: 2.98778

Cumulative Model Updates: 7,400
Cumulative Timesteps: 123,489,638

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,628.44759
Policy Entropy: 0.52589
Value Function Loss: 1.86611

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02333
Policy Update Magnitude: 0.02264
Value Function Update Magnitude: 0.02642

Collected Steps per Second: 24,265.21819
Overall Steps per Second: 16,703.06307

Timestep Collection Time: 2.06073
Timestep Consumption Time: 0.93297
PPO Batch Consumption Time: 0.10395
Total Iteration Time: 2.99370

Cumulative Model Updates: 7,403
Cumulative Timesteps: 123,539,642

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 123539642...
Checkpoint 123539642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,651.83049
Policy Entropy: 0.52611
Value Function Loss: 1.87852

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.02204
Policy Update Magnitude: 0.02501
Value Function Update Magnitude: 0.03260

Collected Steps per Second: 24,396.50588
Overall Steps per Second: 16,687.48906

Timestep Collection Time: 2.05070
Timestep Consumption Time: 0.94735
PPO Batch Consumption Time: 0.10370
Total Iteration Time: 2.99805

Cumulative Model Updates: 7,406
Cumulative Timesteps: 123,589,672

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,614.39692
Policy Entropy: 0.52862
Value Function Loss: 1.82703

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.02169
Policy Update Magnitude: 0.02374
Value Function Update Magnitude: 0.03593

Collected Steps per Second: 24,600.11776
Overall Steps per Second: 16,803.34995

Timestep Collection Time: 2.03340
Timestep Consumption Time: 0.94350
PPO Batch Consumption Time: 0.10484
Total Iteration Time: 2.97691

Cumulative Model Updates: 7,409
Cumulative Timesteps: 123,639,694

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 123639694...
Checkpoint 123639694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,207.20628
Policy Entropy: 0.52330
Value Function Loss: 1.86461

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01824
Policy Update Magnitude: 0.03113
Value Function Update Magnitude: 0.03256

Collected Steps per Second: 23,906.50880
Overall Steps per Second: 16,670.20295

Timestep Collection Time: 2.09215
Timestep Consumption Time: 0.90817
PPO Batch Consumption Time: 0.09258
Total Iteration Time: 3.00032

Cumulative Model Updates: 7,412
Cumulative Timesteps: 123,689,710

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,376.92707
Policy Entropy: 0.52550
Value Function Loss: 1.88550

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02764
Policy Update Magnitude: 0.03468
Value Function Update Magnitude: 0.03935

Collected Steps per Second: 24,286.07645
Overall Steps per Second: 16,729.24724

Timestep Collection Time: 2.05986
Timestep Consumption Time: 0.93047
PPO Batch Consumption Time: 0.09872
Total Iteration Time: 2.99033

Cumulative Model Updates: 7,415
Cumulative Timesteps: 123,739,736

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 123739736...
Checkpoint 123739736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,603.42916
Policy Entropy: 0.52875
Value Function Loss: 1.88371

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02804
Policy Update Magnitude: 0.03158
Value Function Update Magnitude: 0.03669

Collected Steps per Second: 24,287.57342
Overall Steps per Second: 16,706.39641

Timestep Collection Time: 2.05949
Timestep Consumption Time: 0.93457
PPO Batch Consumption Time: 0.09433
Total Iteration Time: 2.99406

Cumulative Model Updates: 7,418
Cumulative Timesteps: 123,789,756

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,174.74101
Policy Entropy: 0.53891
Value Function Loss: 1.74724

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02317
Policy Update Magnitude: 0.02961
Value Function Update Magnitude: 0.03665

Collected Steps per Second: 24,106.28977
Overall Steps per Second: 16,769.37360

Timestep Collection Time: 2.07481
Timestep Consumption Time: 0.90777
PPO Batch Consumption Time: 0.10292
Total Iteration Time: 2.98258

Cumulative Model Updates: 7,421
Cumulative Timesteps: 123,839,772

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 123839772...
Checkpoint 123839772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,347.93887
Policy Entropy: 0.53701
Value Function Loss: 1.66722

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01765
Policy Update Magnitude: 0.02972
Value Function Update Magnitude: 0.03599

Collected Steps per Second: 23,613.93459
Overall Steps per Second: 16,766.71866

Timestep Collection Time: 2.11849
Timestep Consumption Time: 0.86515
PPO Batch Consumption Time: 0.08924
Total Iteration Time: 2.98365

Cumulative Model Updates: 7,424
Cumulative Timesteps: 123,889,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,945.06381
Policy Entropy: 0.54647
Value Function Loss: 1.66815

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.03063
Policy Update Magnitude: 0.02579
Value Function Update Magnitude: 0.03446

Collected Steps per Second: 24,376.27333
Overall Steps per Second: 16,736.39943

Timestep Collection Time: 2.05117
Timestep Consumption Time: 0.93633
PPO Batch Consumption Time: 0.10382
Total Iteration Time: 2.98750

Cumulative Model Updates: 7,427
Cumulative Timesteps: 123,939,798

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 123939798...
Checkpoint 123939798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 806.63478
Policy Entropy: 0.53615
Value Function Loss: 1.74520

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.02239
Policy Update Magnitude: 0.02597
Value Function Update Magnitude: 0.03221

Collected Steps per Second: 24,215.07996
Overall Steps per Second: 16,787.48421

Timestep Collection Time: 2.06516
Timestep Consumption Time: 0.91373
PPO Batch Consumption Time: 0.10304
Total Iteration Time: 2.97889

Cumulative Model Updates: 7,430
Cumulative Timesteps: 123,989,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.60266
Policy Entropy: 0.53640
Value Function Loss: 1.81048

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02863
Policy Update Magnitude: 0.02639
Value Function Update Magnitude: 0.03149

Collected Steps per Second: 24,132.70352
Overall Steps per Second: 16,733.72012

Timestep Collection Time: 2.07213
Timestep Consumption Time: 0.91621
PPO Batch Consumption Time: 0.10895
Total Iteration Time: 2.98834

Cumulative Model Updates: 7,433
Cumulative Timesteps: 124,039,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 124039812...
Checkpoint 124039812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,131.63741
Policy Entropy: 0.53214
Value Function Loss: 1.81538

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02743
Policy Update Magnitude: 0.02357
Value Function Update Magnitude: 0.03218

Collected Steps per Second: 24,147.08611
Overall Steps per Second: 16,762.85905

Timestep Collection Time: 2.07189
Timestep Consumption Time: 0.91269
PPO Batch Consumption Time: 0.10469
Total Iteration Time: 2.98457

Cumulative Model Updates: 7,436
Cumulative Timesteps: 124,089,842

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 926.42498
Policy Entropy: 0.53517
Value Function Loss: 1.79301

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02413
Policy Update Magnitude: 0.02161
Value Function Update Magnitude: 0.03106

Collected Steps per Second: 24,156.14750
Overall Steps per Second: 16,726.10681

Timestep Collection Time: 2.07111
Timestep Consumption Time: 0.92002
PPO Batch Consumption Time: 0.10580
Total Iteration Time: 2.99113

Cumulative Model Updates: 7,439
Cumulative Timesteps: 124,139,872

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 124139872...
Checkpoint 124139872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,500.61538
Policy Entropy: 0.54111
Value Function Loss: 1.80265

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02519
Policy Update Magnitude: 0.02954
Value Function Update Magnitude: 0.02859

Collected Steps per Second: 24,132.95039
Overall Steps per Second: 16,779.73152

Timestep Collection Time: 2.07244
Timestep Consumption Time: 0.90818
PPO Batch Consumption Time: 0.12063
Total Iteration Time: 2.98062

Cumulative Model Updates: 7,442
Cumulative Timesteps: 124,189,886

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889.03256
Policy Entropy: 0.56156
Value Function Loss: 1.87184

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03772
Policy Update Magnitude: 0.03391
Value Function Update Magnitude: 0.02819

Collected Steps per Second: 24,070.84484
Overall Steps per Second: 16,708.57451

Timestep Collection Time: 2.07795
Timestep Consumption Time: 0.91560
PPO Batch Consumption Time: 0.11873
Total Iteration Time: 2.99355

Cumulative Model Updates: 7,445
Cumulative Timesteps: 124,239,904

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 124239904...
Checkpoint 124239904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.59235
Policy Entropy: 0.55416
Value Function Loss: 1.81230

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02743
Policy Update Magnitude: 0.03361
Value Function Update Magnitude: 0.02569

Collected Steps per Second: 23,135.64605
Overall Steps per Second: 16,662.96922

Timestep Collection Time: 2.16316
Timestep Consumption Time: 0.84027
PPO Batch Consumption Time: 0.09201
Total Iteration Time: 3.00343

Cumulative Model Updates: 7,448
Cumulative Timesteps: 124,289,950

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.75023
Policy Entropy: 0.55780
Value Function Loss: 1.77477

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02677
Policy Update Magnitude: 0.03170
Value Function Update Magnitude: 0.02552

Collected Steps per Second: 23,646.60633
Overall Steps per Second: 16,774.00482

Timestep Collection Time: 2.11455
Timestep Consumption Time: 0.86637
PPO Batch Consumption Time: 0.10911
Total Iteration Time: 2.98092

Cumulative Model Updates: 7,451
Cumulative Timesteps: 124,339,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 124339952...
Checkpoint 124339952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580.89044
Policy Entropy: 0.54594
Value Function Loss: 1.75985

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01729
Policy Update Magnitude: 0.03312
Value Function Update Magnitude: 0.02462

Collected Steps per Second: 23,981.83895
Overall Steps per Second: 16,690.40241

Timestep Collection Time: 2.08508
Timestep Consumption Time: 0.91090
PPO Batch Consumption Time: 0.09766
Total Iteration Time: 2.99597

Cumulative Model Updates: 7,454
Cumulative Timesteps: 124,389,956

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,053.18485
Policy Entropy: 0.54955
Value Function Loss: 1.78579

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02205
Policy Update Magnitude: 0.03250
Value Function Update Magnitude: 0.02195

Collected Steps per Second: 24,507.44100
Overall Steps per Second: 16,774.86884

Timestep Collection Time: 2.04134
Timestep Consumption Time: 0.94098
PPO Batch Consumption Time: 0.10481
Total Iteration Time: 2.98232

Cumulative Model Updates: 7,457
Cumulative Timesteps: 124,439,984

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 124439984...
Checkpoint 124439984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,369.32401
Policy Entropy: 0.54560
Value Function Loss: 1.75318

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.03219
Policy Update Magnitude: 0.03031
Value Function Update Magnitude: 0.02270

Collected Steps per Second: 23,497.27664
Overall Steps per Second: 16,678.80760

Timestep Collection Time: 2.12910
Timestep Consumption Time: 0.87040
PPO Batch Consumption Time: 0.08567
Total Iteration Time: 2.99950

Cumulative Model Updates: 7,460
Cumulative Timesteps: 124,490,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,955.48472
Policy Entropy: 0.55233
Value Function Loss: 1.72221

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01667
Policy Update Magnitude: 0.02807
Value Function Update Magnitude: 0.02429

Collected Steps per Second: 24,438.24386
Overall Steps per Second: 16,739.95767

Timestep Collection Time: 2.04655
Timestep Consumption Time: 0.94116
PPO Batch Consumption Time: 0.10119
Total Iteration Time: 2.98770

Cumulative Model Updates: 7,463
Cumulative Timesteps: 124,540,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 124540026...
Checkpoint 124540026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673.20194
Policy Entropy: 0.55206
Value Function Loss: 1.74917

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01487
Policy Update Magnitude: 0.03024
Value Function Update Magnitude: 0.02597

Collected Steps per Second: 23,812.26416
Overall Steps per Second: 16,734.45315

Timestep Collection Time: 2.10001
Timestep Consumption Time: 0.88820
PPO Batch Consumption Time: 0.08830
Total Iteration Time: 2.98821

Cumulative Model Updates: 7,466
Cumulative Timesteps: 124,590,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545.41615
Policy Entropy: 0.55627
Value Function Loss: 1.73220

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01597
Policy Update Magnitude: 0.03019
Value Function Update Magnitude: 0.02344

Collected Steps per Second: 24,203.44095
Overall Steps per Second: 16,749.98670

Timestep Collection Time: 2.06590
Timestep Consumption Time: 0.91929
PPO Batch Consumption Time: 0.10150
Total Iteration Time: 2.98520

Cumulative Model Updates: 7,469
Cumulative Timesteps: 124,640,034

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 124640034...
Checkpoint 124640034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,557.36784
Policy Entropy: 0.55468
Value Function Loss: 1.72495

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01828
Policy Update Magnitude: 0.03390
Value Function Update Magnitude: 0.02501

Collected Steps per Second: 24,305.01939
Overall Steps per Second: 16,790.29631

Timestep Collection Time: 2.05809
Timestep Consumption Time: 0.92113
PPO Batch Consumption Time: 0.10338
Total Iteration Time: 2.97922

Cumulative Model Updates: 7,472
Cumulative Timesteps: 124,690,056

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.76065
Policy Entropy: 0.54644
Value Function Loss: 1.65415

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01639
Policy Update Magnitude: 0.03340
Value Function Update Magnitude: 0.02636

Collected Steps per Second: 23,967.86168
Overall Steps per Second: 16,664.27427

Timestep Collection Time: 2.08713
Timestep Consumption Time: 0.91474
PPO Batch Consumption Time: 0.09699
Total Iteration Time: 3.00187

Cumulative Model Updates: 7,475
Cumulative Timesteps: 124,740,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 124740080...
Checkpoint 124740080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,093.08572
Policy Entropy: 0.55530
Value Function Loss: 1.66372

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03887
Policy Update Magnitude: 0.02823
Value Function Update Magnitude: 0.03284

Collected Steps per Second: 23,796.25209
Overall Steps per Second: 16,721.91879

Timestep Collection Time: 2.10168
Timestep Consumption Time: 0.88913
PPO Batch Consumption Time: 0.08838
Total Iteration Time: 2.99081

Cumulative Model Updates: 7,478
Cumulative Timesteps: 124,790,092

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,500.03447
Policy Entropy: 0.54624
Value Function Loss: 1.73066

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.04045
Policy Update Magnitude: 0.02498
Value Function Update Magnitude: 0.03578

Collected Steps per Second: 24,253.55877
Overall Steps per Second: 16,690.80753

Timestep Collection Time: 2.06271
Timestep Consumption Time: 0.93463
PPO Batch Consumption Time: 0.10593
Total Iteration Time: 2.99734

Cumulative Model Updates: 7,481
Cumulative Timesteps: 124,840,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 124840120...
Checkpoint 124840120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,784.06241
Policy Entropy: 0.55147
Value Function Loss: 1.73205

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.03164
Policy Update Magnitude: 0.02271
Value Function Update Magnitude: 0.02982

Collected Steps per Second: 24,249.93256
Overall Steps per Second: 16,829.62798

Timestep Collection Time: 2.06252
Timestep Consumption Time: 0.90938
PPO Batch Consumption Time: 0.09315
Total Iteration Time: 2.97190

Cumulative Model Updates: 7,484
Cumulative Timesteps: 124,890,136

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565.45240
Policy Entropy: 0.55008
Value Function Loss: 1.66889

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01773
Policy Update Magnitude: 0.02279
Value Function Update Magnitude: 0.02542

Collected Steps per Second: 24,247.72610
Overall Steps per Second: 16,771.61979

Timestep Collection Time: 2.06263
Timestep Consumption Time: 0.91944
PPO Batch Consumption Time: 0.10654
Total Iteration Time: 2.98206

Cumulative Model Updates: 7,487
Cumulative Timesteps: 124,940,150

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 124940150...
Checkpoint 124940150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,094.82157
Policy Entropy: 0.54657
Value Function Loss: 1.62500

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02642
Policy Update Magnitude: 0.02717
Value Function Update Magnitude: 0.03119

Collected Steps per Second: 23,704.39634
Overall Steps per Second: 16,699.37122

Timestep Collection Time: 2.10982
Timestep Consumption Time: 0.88502
PPO Batch Consumption Time: 0.09440
Total Iteration Time: 2.99484

Cumulative Model Updates: 7,490
Cumulative Timesteps: 124,990,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,679.29461
Policy Entropy: 0.55341
Value Function Loss: 1.67048

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03635
Policy Update Magnitude: 0.02587
Value Function Update Magnitude: 0.03830

Collected Steps per Second: 24,811.15002
Overall Steps per Second: 17,846.99024

Timestep Collection Time: 2.01619
Timestep Consumption Time: 0.78675
PPO Batch Consumption Time: 0.08473
Total Iteration Time: 2.80294

Cumulative Model Updates: 7,493
Cumulative Timesteps: 125,040,186

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 125040186...
Checkpoint 125040186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,568.47607
Policy Entropy: 0.54405
Value Function Loss: 1.69029

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.04285
Policy Update Magnitude: 0.02596
Value Function Update Magnitude: 0.03543

Collected Steps per Second: 23,397.50024
Overall Steps per Second: 17,548.68407

Timestep Collection Time: 2.13749
Timestep Consumption Time: 0.71241
PPO Batch Consumption Time: 0.06004
Total Iteration Time: 2.84990

Cumulative Model Updates: 7,496
Cumulative Timesteps: 125,090,198

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,162.35842
Policy Entropy: 0.54249
Value Function Loss: 1.63517

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.04112
Policy Update Magnitude: 0.02286
Value Function Update Magnitude: 0.03807

Collected Steps per Second: 21,340.81015
Overall Steps per Second: 16,000.06294

Timestep Collection Time: 2.34424
Timestep Consumption Time: 0.78250
PPO Batch Consumption Time: 0.07964
Total Iteration Time: 3.12674

Cumulative Model Updates: 7,499
Cumulative Timesteps: 125,140,226

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 125140226...
Checkpoint 125140226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,841.39123
Policy Entropy: 0.53716
Value Function Loss: 1.62309

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.04600
Policy Update Magnitude: 0.02187
Value Function Update Magnitude: 0.05423

Collected Steps per Second: 23,596.42565
Overall Steps per Second: 17,601.59853

Timestep Collection Time: 2.11998
Timestep Consumption Time: 0.72203
PPO Batch Consumption Time: 0.06011
Total Iteration Time: 2.84201

Cumulative Model Updates: 7,502
Cumulative Timesteps: 125,190,250

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.06381
Policy Entropy: 0.52910
Value Function Loss: 1.63242

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03771
Policy Update Magnitude: 0.01992
Value Function Update Magnitude: 0.04995

Collected Steps per Second: 21,854.33456
Overall Steps per Second: 15,123.73161

Timestep Collection Time: 2.28815
Timestep Consumption Time: 1.01831
PPO Batch Consumption Time: 0.12642
Total Iteration Time: 3.30646

Cumulative Model Updates: 7,505
Cumulative Timesteps: 125,240,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 125240256...
Checkpoint 125240256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,509.71632
Policy Entropy: 0.53965
Value Function Loss: 1.64464

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.03113
Policy Update Magnitude: 0.02195
Value Function Update Magnitude: 0.06404

Collected Steps per Second: 24,280.90267
Overall Steps per Second: 16,728.33961

Timestep Collection Time: 2.05981
Timestep Consumption Time: 0.92997
PPO Batch Consumption Time: 0.10411
Total Iteration Time: 2.98978

Cumulative Model Updates: 7,508
Cumulative Timesteps: 125,290,270

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,502.30976
Policy Entropy: 0.53376
Value Function Loss: 1.62505

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.03443
Policy Update Magnitude: 0.02183
Value Function Update Magnitude: 0.05739

Collected Steps per Second: 23,988.58209
Overall Steps per Second: 16,645.03092

Timestep Collection Time: 2.08508
Timestep Consumption Time: 0.91991
PPO Batch Consumption Time: 0.10031
Total Iteration Time: 3.00498

Cumulative Model Updates: 7,511
Cumulative Timesteps: 125,340,288

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 125340288...
Checkpoint 125340288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,887.04718
Policy Entropy: 0.53335
Value Function Loss: 1.62129

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.03418
Policy Update Magnitude: 0.02110
Value Function Update Magnitude: 0.05391

Collected Steps per Second: 24,321.92930
Overall Steps per Second: 16,762.08043

Timestep Collection Time: 2.05584
Timestep Consumption Time: 0.92720
PPO Batch Consumption Time: 0.10023
Total Iteration Time: 2.98304

Cumulative Model Updates: 7,514
Cumulative Timesteps: 125,390,290

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.45846
Policy Entropy: 0.52463
Value Function Loss: 1.65693

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.02018
Policy Update Magnitude: 0.02202
Value Function Update Magnitude: 0.05238

Collected Steps per Second: 23,381.92418
Overall Steps per Second: 15,736.61081

Timestep Collection Time: 2.13866
Timestep Consumption Time: 1.03902
PPO Batch Consumption Time: 0.12392
Total Iteration Time: 3.17769

Cumulative Model Updates: 7,517
Cumulative Timesteps: 125,440,296

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 125440296...
Checkpoint 125440296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,743.43698
Policy Entropy: 0.53340
Value Function Loss: 1.66248

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02859
Policy Update Magnitude: 0.02476
Value Function Update Magnitude: 0.04402

Collected Steps per Second: 24,180.44857
Overall Steps per Second: 17,175.02065

Timestep Collection Time: 2.06787
Timestep Consumption Time: 0.84345
PPO Batch Consumption Time: 0.06263
Total Iteration Time: 2.91132

Cumulative Model Updates: 7,520
Cumulative Timesteps: 125,490,298

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.85444
Policy Entropy: 0.53088
Value Function Loss: 1.62684

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01974
Policy Update Magnitude: 0.02256
Value Function Update Magnitude: 0.04076

Collected Steps per Second: 24,705.00887
Overall Steps per Second: 17,651.96030

Timestep Collection Time: 2.02420
Timestep Consumption Time: 0.80879
PPO Batch Consumption Time: 0.06380
Total Iteration Time: 2.83300

Cumulative Model Updates: 7,523
Cumulative Timesteps: 125,540,306

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 125540306...
Checkpoint 125540306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,401.85535
Policy Entropy: 0.53828
Value Function Loss: 1.61723

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.01016
Policy Update Magnitude: 0.02525
Value Function Update Magnitude: 0.03831

Collected Steps per Second: 23,879.65927
Overall Steps per Second: 16,530.69664

Timestep Collection Time: 2.09459
Timestep Consumption Time: 0.93118
PPO Batch Consumption Time: 0.10412
Total Iteration Time: 3.02576

Cumulative Model Updates: 7,526
Cumulative Timesteps: 125,590,324

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.14759
Policy Entropy: 0.54244
Value Function Loss: 1.63713

Mean KL Divergence: 0.00153
SB3 Clip Fraction: 0.01564
Policy Update Magnitude: 0.02726
Value Function Update Magnitude: 0.03268

Collected Steps per Second: 24,639.08775
Overall Steps per Second: 16,772.08427

Timestep Collection Time: 2.03019
Timestep Consumption Time: 0.95227
PPO Batch Consumption Time: 0.11551
Total Iteration Time: 2.98246

Cumulative Model Updates: 7,529
Cumulative Timesteps: 125,640,346

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 125640346...
Checkpoint 125640346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345.41821
Policy Entropy: 0.54680
Value Function Loss: 1.62866

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.02181
Policy Update Magnitude: 0.02515
Value Function Update Magnitude: 0.04147

Collected Steps per Second: 23,841.69973
Overall Steps per Second: 16,667.33944

Timestep Collection Time: 2.09725
Timestep Consumption Time: 0.90275
PPO Batch Consumption Time: 0.10370
Total Iteration Time: 3.00000

Cumulative Model Updates: 7,532
Cumulative Timesteps: 125,690,348

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,000.60504
Policy Entropy: 0.55926
Value Function Loss: 1.64021

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.04037
Policy Update Magnitude: 0.02488
Value Function Update Magnitude: 0.04244

Collected Steps per Second: 24,550.48235
Overall Steps per Second: 16,804.95182

Timestep Collection Time: 2.03792
Timestep Consumption Time: 0.93929
PPO Batch Consumption Time: 0.11175
Total Iteration Time: 2.97722

Cumulative Model Updates: 7,535
Cumulative Timesteps: 125,740,380

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 125740380...
Checkpoint 125740380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,115.13226
Policy Entropy: 0.55131
Value Function Loss: 1.59298

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01651
Policy Update Magnitude: 0.02290
Value Function Update Magnitude: 0.03995

Collected Steps per Second: 24,252.44140
Overall Steps per Second: 16,790.78580

Timestep Collection Time: 2.06289
Timestep Consumption Time: 0.91673
PPO Batch Consumption Time: 0.10767
Total Iteration Time: 2.97961

Cumulative Model Updates: 7,538
Cumulative Timesteps: 125,790,410

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.10428
Policy Entropy: 0.55771
Value Function Loss: 1.58283

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02315
Policy Update Magnitude: 0.02509
Value Function Update Magnitude: 0.04466

Collected Steps per Second: 23,879.14677
Overall Steps per Second: 16,617.69724

Timestep Collection Time: 2.09455
Timestep Consumption Time: 0.91526
PPO Batch Consumption Time: 0.09967
Total Iteration Time: 3.00980

Cumulative Model Updates: 7,541
Cumulative Timesteps: 125,840,426

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 125840426...
Checkpoint 125840426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.93576
Policy Entropy: 0.54351
Value Function Loss: 1.61574

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01541
Policy Update Magnitude: 0.02552
Value Function Update Magnitude: 0.03838

Collected Steps per Second: 24,645.18878
Overall Steps per Second: 17,544.46291

Timestep Collection Time: 2.02887
Timestep Consumption Time: 0.82114
PPO Batch Consumption Time: 0.08792
Total Iteration Time: 2.85002

Cumulative Model Updates: 7,544
Cumulative Timesteps: 125,890,428

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 974.42484
Policy Entropy: 0.54288
Value Function Loss: 1.65307

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02415
Policy Update Magnitude: 0.02685
Value Function Update Magnitude: 0.04202

Collected Steps per Second: 22,528.52821
Overall Steps per Second: 16,069.59740

Timestep Collection Time: 2.22012
Timestep Consumption Time: 0.89234
PPO Batch Consumption Time: 0.11097
Total Iteration Time: 3.11246

Cumulative Model Updates: 7,547
Cumulative Timesteps: 125,940,444

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 125940444...
Checkpoint 125940444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,569.76932
Policy Entropy: 0.53316
Value Function Loss: 1.64248

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02629
Policy Update Magnitude: 0.02416
Value Function Update Magnitude: 0.04536

Collected Steps per Second: 24,299.93142
Overall Steps per Second: 16,692.52155

Timestep Collection Time: 2.05803
Timestep Consumption Time: 0.93792
PPO Batch Consumption Time: 0.10374
Total Iteration Time: 2.99595

Cumulative Model Updates: 7,550
Cumulative Timesteps: 125,990,454

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,336.31443
Policy Entropy: 0.54590
Value Function Loss: 1.56297

Mean KL Divergence: 0.00128
SB3 Clip Fraction: 0.01107
Policy Update Magnitude: 0.02820
Value Function Update Magnitude: 0.05645

Collected Steps per Second: 24,086.72453
Overall Steps per Second: 16,717.29653

Timestep Collection Time: 2.07691
Timestep Consumption Time: 0.91556
PPO Batch Consumption Time: 0.10118
Total Iteration Time: 2.99247

Cumulative Model Updates: 7,553
Cumulative Timesteps: 126,040,480

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 126040480...
Checkpoint 126040480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,365.21142
Policy Entropy: 0.55566
Value Function Loss: 1.52480

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01862
Policy Update Magnitude: 0.02690
Value Function Update Magnitude: 0.04846

Collected Steps per Second: 24,428.57291
Overall Steps per Second: 16,761.05621

Timestep Collection Time: 2.04793
Timestep Consumption Time: 0.93685
PPO Batch Consumption Time: 0.10160
Total Iteration Time: 2.98478

Cumulative Model Updates: 7,556
Cumulative Timesteps: 126,090,508

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643.52639
Policy Entropy: 0.56632
Value Function Loss: 1.53809

Mean KL Divergence: 0.00123
SB3 Clip Fraction: 0.00994
Policy Update Magnitude: 0.02688
Value Function Update Magnitude: 0.05788

Collected Steps per Second: 24,654.32567
Overall Steps per Second: 16,780.41825

Timestep Collection Time: 2.02812
Timestep Consumption Time: 0.95166
PPO Batch Consumption Time: 0.11530
Total Iteration Time: 2.97978

Cumulative Model Updates: 7,559
Cumulative Timesteps: 126,140,510

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 126140510...
Checkpoint 126140510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,902.72637
Policy Entropy: 0.56637
Value Function Loss: 1.55841

Mean KL Divergence: 0.00113
SB3 Clip Fraction: 0.00886
Policy Update Magnitude: 0.03068
Value Function Update Magnitude: 0.05520

Collected Steps per Second: 23,925.62647
Overall Steps per Second: 16,695.64507

Timestep Collection Time: 2.09023
Timestep Consumption Time: 0.90516
PPO Batch Consumption Time: 0.09223
Total Iteration Time: 2.99539

Cumulative Model Updates: 7,562
Cumulative Timesteps: 126,190,520

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,797.02784
Policy Entropy: 0.56560
Value Function Loss: 1.58770

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02130
Policy Update Magnitude: 0.02978
Value Function Update Magnitude: 0.04483

Collected Steps per Second: 24,475.13942
Overall Steps per Second: 16,744.23051

Timestep Collection Time: 2.04403
Timestep Consumption Time: 0.94374
PPO Batch Consumption Time: 0.10344
Total Iteration Time: 2.98778

Cumulative Model Updates: 7,565
Cumulative Timesteps: 126,240,548

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 126240548...
Checkpoint 126240548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,735.37507
Policy Entropy: 0.55357
Value Function Loss: 1.60904

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01905
Policy Update Magnitude: 0.02851
Value Function Update Magnitude: 0.04160

Collected Steps per Second: 24,029.70330
Overall Steps per Second: 16,718.83208

Timestep Collection Time: 2.08101
Timestep Consumption Time: 0.90999
PPO Batch Consumption Time: 0.09440
Total Iteration Time: 2.99100

Cumulative Model Updates: 7,568
Cumulative Timesteps: 126,290,554

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,221.01227
Policy Entropy: 0.55605
Value Function Loss: 1.58128

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02349
Policy Update Magnitude: 0.02764
Value Function Update Magnitude: 0.03647

Collected Steps per Second: 24,601.97380
Overall Steps per Second: 16,799.00896

Timestep Collection Time: 2.03317
Timestep Consumption Time: 0.94439
PPO Batch Consumption Time: 0.11156
Total Iteration Time: 2.97756

Cumulative Model Updates: 7,571
Cumulative Timesteps: 126,340,574

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 126340574...
Checkpoint 126340574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,028.76765
Policy Entropy: 0.56555
Value Function Loss: 1.51400

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03152
Policy Update Magnitude: 0.02777
Value Function Update Magnitude: 0.04244

Collected Steps per Second: 23,765.21925
Overall Steps per Second: 16,683.26677

Timestep Collection Time: 2.10459
Timestep Consumption Time: 0.89339
PPO Batch Consumption Time: 0.08955
Total Iteration Time: 2.99797

Cumulative Model Updates: 7,574
Cumulative Timesteps: 126,390,590

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,068.93583
Policy Entropy: 0.55372
Value Function Loss: 1.48002

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04005
Policy Update Magnitude: 0.02675
Value Function Update Magnitude: 0.03933

Collected Steps per Second: 24,332.66951
Overall Steps per Second: 16,695.28420

Timestep Collection Time: 2.05592
Timestep Consumption Time: 0.94050
PPO Batch Consumption Time: 0.09333
Total Iteration Time: 2.99642

Cumulative Model Updates: 7,577
Cumulative Timesteps: 126,440,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 126440616...
Checkpoint 126440616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,884.57433
Policy Entropy: 0.54983
Value Function Loss: 1.52552

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05373
Policy Update Magnitude: 0.02385
Value Function Update Magnitude: 0.03786

Collected Steps per Second: 24,319.26643
Overall Steps per Second: 16,855.54830

Timestep Collection Time: 2.05689
Timestep Consumption Time: 0.91080
PPO Batch Consumption Time: 0.10389
Total Iteration Time: 2.96769

Cumulative Model Updates: 7,580
Cumulative Timesteps: 126,490,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,023.22233
Policy Entropy: 0.54101
Value Function Loss: 1.55060

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04631
Policy Update Magnitude: 0.01958
Value Function Update Magnitude: 0.03175

Collected Steps per Second: 24,421.83521
Overall Steps per Second: 16,722.81720

Timestep Collection Time: 2.04849
Timestep Consumption Time: 0.94311
PPO Batch Consumption Time: 0.11304
Total Iteration Time: 2.99160

Cumulative Model Updates: 7,583
Cumulative Timesteps: 126,540,666

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 126540666...
Checkpoint 126540666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480.26478
Policy Entropy: 0.55408
Value Function Loss: 1.54753

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.04463
Policy Update Magnitude: 0.01975
Value Function Update Magnitude: 0.02676

Collected Steps per Second: 24,180.39016
Overall Steps per Second: 16,774.87219

Timestep Collection Time: 2.06862
Timestep Consumption Time: 0.91322
PPO Batch Consumption Time: 0.10498
Total Iteration Time: 2.98184

Cumulative Model Updates: 7,586
Cumulative Timesteps: 126,590,686

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,785.10784
Policy Entropy: 0.55080
Value Function Loss: 1.53051

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.05225
Policy Update Magnitude: 0.01983
Value Function Update Magnitude: 0.02219

Collected Steps per Second: 24,167.81003
Overall Steps per Second: 16,702.20246

Timestep Collection Time: 2.06912
Timestep Consumption Time: 0.92486
PPO Batch Consumption Time: 0.10934
Total Iteration Time: 2.99398

Cumulative Model Updates: 7,589
Cumulative Timesteps: 126,640,692

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 126640692...
Checkpoint 126640692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676.68184
Policy Entropy: 0.54962
Value Function Loss: 1.55345

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03913
Policy Update Magnitude: 0.01766
Value Function Update Magnitude: 0.02323

Collected Steps per Second: 24,104.31879
Overall Steps per Second: 16,702.06813

Timestep Collection Time: 2.07515
Timestep Consumption Time: 0.91969
PPO Batch Consumption Time: 0.10370
Total Iteration Time: 2.99484

Cumulative Model Updates: 7,592
Cumulative Timesteps: 126,690,712

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,528.77395
Policy Entropy: 0.55441
Value Function Loss: 1.53924

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.05021
Policy Update Magnitude: 0.02009
Value Function Update Magnitude: 0.02152

Collected Steps per Second: 24,199.87050
Overall Steps per Second: 16,768.77583

Timestep Collection Time: 2.06712
Timestep Consumption Time: 0.91604
PPO Batch Consumption Time: 0.10926
Total Iteration Time: 2.98316

Cumulative Model Updates: 7,595
Cumulative Timesteps: 126,740,736

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 126740736...
Checkpoint 126740736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,661.23757
Policy Entropy: 0.56522
Value Function Loss: 1.48392

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.04414
Policy Update Magnitude: 0.01909
Value Function Update Magnitude: 0.02024

Collected Steps per Second: 23,938.50194
Overall Steps per Second: 16,694.94776

Timestep Collection Time: 2.08935
Timestep Consumption Time: 0.90652
PPO Batch Consumption Time: 0.09741
Total Iteration Time: 2.99588

Cumulative Model Updates: 7,598
Cumulative Timesteps: 126,790,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,003.07517
Policy Entropy: 0.57049
Value Function Loss: 1.47859

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05670
Policy Update Magnitude: 0.02235
Value Function Update Magnitude: 0.02289

Collected Steps per Second: 24,724.35620
Overall Steps per Second: 17,851.46554

Timestep Collection Time: 2.02278
Timestep Consumption Time: 0.77878
PPO Batch Consumption Time: 0.07772
Total Iteration Time: 2.80156

Cumulative Model Updates: 7,601
Cumulative Timesteps: 126,840,764

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 126840764...
Checkpoint 126840764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,399.01558
Policy Entropy: 0.56270
Value Function Loss: 1.51343

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.04362
Policy Update Magnitude: 0.01999
Value Function Update Magnitude: 0.01889

Collected Steps per Second: 22,956.10459
Overall Steps per Second: 17,227.02951

Timestep Collection Time: 2.17929
Timestep Consumption Time: 0.72475
PPO Batch Consumption Time: 0.06157
Total Iteration Time: 2.90404

Cumulative Model Updates: 7,604
Cumulative Timesteps: 126,890,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827.15376
Policy Entropy: 0.55202
Value Function Loss: 1.50695

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04997
Policy Update Magnitude: 0.02060
Value Function Update Magnitude: 0.02399

Collected Steps per Second: 24,111.73012
Overall Steps per Second: 17,322.26258

Timestep Collection Time: 2.07459
Timestep Consumption Time: 0.81314
PPO Batch Consumption Time: 0.09053
Total Iteration Time: 2.88773

Cumulative Model Updates: 7,607
Cumulative Timesteps: 126,940,814

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 126940814...
Checkpoint 126940814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,111.11421
Policy Entropy: 0.55723
Value Function Loss: 1.50850

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.04369
Policy Update Magnitude: 0.02154
Value Function Update Magnitude: 0.02220

Collected Steps per Second: 23,149.81961
Overall Steps per Second: 17,426.40069

Timestep Collection Time: 2.16045
Timestep Consumption Time: 0.70956
PPO Batch Consumption Time: 0.05899
Total Iteration Time: 2.87001

Cumulative Model Updates: 7,610
Cumulative Timesteps: 126,990,828

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243.15621
Policy Entropy: 0.56068
Value Function Loss: 1.44745

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04427
Policy Update Magnitude: 0.01915
Value Function Update Magnitude: 0.02140

Collected Steps per Second: 23,539.87066
Overall Steps per Second: 17,125.24093

Timestep Collection Time: 2.12440
Timestep Consumption Time: 0.79574
PPO Batch Consumption Time: 0.06265
Total Iteration Time: 2.92013

Cumulative Model Updates: 7,613
Cumulative Timesteps: 127,040,836

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 127040836...
Checkpoint 127040836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,541.20099
Policy Entropy: 0.56789
Value Function Loss: 1.53671

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02915
Policy Update Magnitude: 0.01931
Value Function Update Magnitude: 0.02507

Collected Steps per Second: 20,937.67863
Overall Steps per Second: 14,787.18192

Timestep Collection Time: 2.38880
Timestep Consumption Time: 0.99359
PPO Batch Consumption Time: 0.12027
Total Iteration Time: 3.38239

Cumulative Model Updates: 7,616
Cumulative Timesteps: 127,090,852

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.33155
Policy Entropy: 0.56565
Value Function Loss: 1.50353

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01570
Policy Update Magnitude: 0.02145
Value Function Update Magnitude: 0.02190

Collected Steps per Second: 24,388.80251
Overall Steps per Second: 17,586.65077

Timestep Collection Time: 2.05086
Timestep Consumption Time: 0.79323
PPO Batch Consumption Time: 0.06126
Total Iteration Time: 2.84409

Cumulative Model Updates: 7,619
Cumulative Timesteps: 127,140,870

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 127140870...
Checkpoint 127140870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,910.75535
Policy Entropy: 0.56748
Value Function Loss: 1.48963

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.01965
Policy Update Magnitude: 0.02362
Value Function Update Magnitude: 0.02059

Collected Steps per Second: 21,567.09107
Overall Steps per Second: 15,262.42316

Timestep Collection Time: 2.31955
Timestep Consumption Time: 0.95817
PPO Batch Consumption Time: 0.11358
Total Iteration Time: 3.27772

Cumulative Model Updates: 7,622
Cumulative Timesteps: 127,190,896

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,002.83131
Policy Entropy: 0.55530
Value Function Loss: 1.45297

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03138
Policy Update Magnitude: 0.02559
Value Function Update Magnitude: 0.01880

Collected Steps per Second: 23,979.48856
Overall Steps per Second: 16,629.41871

Timestep Collection Time: 2.08578
Timestep Consumption Time: 0.92190
PPO Batch Consumption Time: 0.10334
Total Iteration Time: 3.00768

Cumulative Model Updates: 7,625
Cumulative Timesteps: 127,240,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 127240912...
Checkpoint 127240912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.33392
Policy Entropy: 0.55082
Value Function Loss: 1.46601

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03500
Policy Update Magnitude: 0.02233
Value Function Update Magnitude: 0.01903

Collected Steps per Second: 24,362.52307
Overall Steps per Second: 16,774.39283

Timestep Collection Time: 2.05340
Timestep Consumption Time: 0.92888
PPO Batch Consumption Time: 0.10123
Total Iteration Time: 2.98228

Cumulative Model Updates: 7,628
Cumulative Timesteps: 127,290,938

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,496.44427
Policy Entropy: 0.54562
Value Function Loss: 1.45624

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02174
Policy Update Magnitude: 0.02456
Value Function Update Magnitude: 0.01930

Collected Steps per Second: 24,564.57976
Overall Steps per Second: 16,769.95293

Timestep Collection Time: 2.03561
Timestep Consumption Time: 0.94615
PPO Batch Consumption Time: 0.10627
Total Iteration Time: 2.98176

Cumulative Model Updates: 7,631
Cumulative Timesteps: 127,340,942

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 127340942...
Checkpoint 127340942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.78363
Policy Entropy: 0.55155
Value Function Loss: 1.46775

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.03228
Policy Update Magnitude: 0.02506
Value Function Update Magnitude: 0.02129

Collected Steps per Second: 23,736.90133
Overall Steps per Second: 16,703.74118

Timestep Collection Time: 2.10642
Timestep Consumption Time: 0.88692
PPO Batch Consumption Time: 0.08043
Total Iteration Time: 2.99334

Cumulative Model Updates: 7,634
Cumulative Timesteps: 127,390,942

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629.39545
Policy Entropy: 0.55072
Value Function Loss: 1.47597

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.02349
Value Function Update Magnitude: 0.01824

Collected Steps per Second: 24,654.25008
Overall Steps per Second: 16,842.73414

Timestep Collection Time: 2.02991
Timestep Consumption Time: 0.94146
PPO Batch Consumption Time: 0.11089
Total Iteration Time: 2.97137

Cumulative Model Updates: 7,637
Cumulative Timesteps: 127,440,988

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 127440988...
Checkpoint 127440988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,732.04969
Policy Entropy: 0.55661
Value Function Loss: 1.52717

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01721
Policy Update Magnitude: 0.02436
Value Function Update Magnitude: 0.02032

Collected Steps per Second: 23,797.27981
Overall Steps per Second: 16,710.09839

Timestep Collection Time: 2.10327
Timestep Consumption Time: 0.89205
PPO Batch Consumption Time: 0.09768
Total Iteration Time: 2.99531

Cumulative Model Updates: 7,640
Cumulative Timesteps: 127,491,040

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,858.69072
Policy Entropy: 0.55254
Value Function Loss: 1.50436

Mean KL Divergence: 0.00114
SB3 Clip Fraction: 0.01051
Policy Update Magnitude: 0.02764
Value Function Update Magnitude: 0.01879

Collected Steps per Second: 24,529.39858
Overall Steps per Second: 16,768.14637

Timestep Collection Time: 2.03837
Timestep Consumption Time: 0.94347
PPO Batch Consumption Time: 0.11320
Total Iteration Time: 2.98184

Cumulative Model Updates: 7,643
Cumulative Timesteps: 127,541,040

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 127541040...
Checkpoint 127541040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,031.57578
Policy Entropy: 0.56467
Value Function Loss: 1.49979

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02253
Policy Update Magnitude: 0.02888
Value Function Update Magnitude: 0.02196

Collected Steps per Second: 24,116.63471
Overall Steps per Second: 16,790.13821

Timestep Collection Time: 2.07392
Timestep Consumption Time: 0.90497
PPO Batch Consumption Time: 0.12146
Total Iteration Time: 2.97889

Cumulative Model Updates: 7,646
Cumulative Timesteps: 127,591,056

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,183.21280
Policy Entropy: 0.56952
Value Function Loss: 1.44431

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.04029
Policy Update Magnitude: 0.02499
Value Function Update Magnitude: 0.02129

Collected Steps per Second: 24,131.72369
Overall Steps per Second: 17,574.53739

Timestep Collection Time: 2.07196
Timestep Consumption Time: 0.77306
PPO Batch Consumption Time: 0.07835
Total Iteration Time: 2.84503

Cumulative Model Updates: 7,649
Cumulative Timesteps: 127,641,056

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 127641056...
Checkpoint 127641056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,154.09489
Policy Entropy: 0.57267
Value Function Loss: 1.40437

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.05670
Policy Update Magnitude: 0.02249
Value Function Update Magnitude: 0.02104

Collected Steps per Second: 22,032.23251
Overall Steps per Second: 15,954.31491

Timestep Collection Time: 2.27031
Timestep Consumption Time: 0.86489
PPO Batch Consumption Time: 0.10632
Total Iteration Time: 3.13520

Cumulative Model Updates: 7,652
Cumulative Timesteps: 127,691,076

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,117.33430
Policy Entropy: 0.57573
Value Function Loss: 1.37651

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04589
Policy Update Magnitude: 0.01926
Value Function Update Magnitude: 0.01954

Collected Steps per Second: 23,345.49896
Overall Steps per Second: 16,704.17631

Timestep Collection Time: 2.14251
Timestep Consumption Time: 0.85183
PPO Batch Consumption Time: 0.10323
Total Iteration Time: 2.99434

Cumulative Model Updates: 7,655
Cumulative Timesteps: 127,741,094

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 127741094...
Checkpoint 127741094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,828.09572
Policy Entropy: 0.57031
Value Function Loss: 1.40850

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.05385
Policy Update Magnitude: 0.01903
Value Function Update Magnitude: 0.02059

Collected Steps per Second: 23,284.52967
Overall Steps per Second: 16,707.96655

Timestep Collection Time: 2.14743
Timestep Consumption Time: 0.84527
PPO Batch Consumption Time: 0.09813
Total Iteration Time: 2.99270

Cumulative Model Updates: 7,658
Cumulative Timesteps: 127,791,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 991.92518
Policy Entropy: 0.56792
Value Function Loss: 1.42605

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05994
Policy Update Magnitude: 0.01927
Value Function Update Magnitude: 0.02131

Collected Steps per Second: 24,372.65112
Overall Steps per Second: 16,776.34884

Timestep Collection Time: 2.05156
Timestep Consumption Time: 0.92894
PPO Batch Consumption Time: 0.10505
Total Iteration Time: 2.98051

Cumulative Model Updates: 7,661
Cumulative Timesteps: 127,841,098

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 127841098...
Checkpoint 127841098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.32311
Policy Entropy: 0.55984
Value Function Loss: 1.44039

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.04182
Policy Update Magnitude: 0.01732
Value Function Update Magnitude: 0.01947

Collected Steps per Second: 24,206.50513
Overall Steps per Second: 16,700.03535

Timestep Collection Time: 2.06606
Timestep Consumption Time: 0.92867
PPO Batch Consumption Time: 0.10324
Total Iteration Time: 2.99472

Cumulative Model Updates: 7,664
Cumulative Timesteps: 127,891,110

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,911.42210
Policy Entropy: 0.56293
Value Function Loss: 1.44403

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04376
Policy Update Magnitude: 0.01804
Value Function Update Magnitude: 0.02226

Collected Steps per Second: 23,971.91459
Overall Steps per Second: 16,670.25308

Timestep Collection Time: 2.08669
Timestep Consumption Time: 0.91398
PPO Batch Consumption Time: 0.08981
Total Iteration Time: 3.00067

Cumulative Model Updates: 7,667
Cumulative Timesteps: 127,941,132

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 127941132...
Checkpoint 127941132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,755.51085
Policy Entropy: 0.55981
Value Function Loss: 1.46521

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04871
Policy Update Magnitude: 0.02025
Value Function Update Magnitude: 0.02250

Collected Steps per Second: 23,967.70820
Overall Steps per Second: 16,632.99744

Timestep Collection Time: 2.08647
Timestep Consumption Time: 0.92008
PPO Batch Consumption Time: 0.08006
Total Iteration Time: 3.00655

Cumulative Model Updates: 7,670
Cumulative Timesteps: 127,991,140

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,499.21389
Policy Entropy: 0.56400
Value Function Loss: 1.45359

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.04119
Policy Update Magnitude: 0.01869
Value Function Update Magnitude: 0.02091

Collected Steps per Second: 24,729.84377
Overall Steps per Second: 17,922.28010

Timestep Collection Time: 2.02185
Timestep Consumption Time: 0.76797
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 2.78982

Cumulative Model Updates: 7,673
Cumulative Timesteps: 128,041,140

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 128041140...
Checkpoint 128041140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653.64386
Policy Entropy: 0.56468
Value Function Loss: 1.45915

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03455
Policy Update Magnitude: 0.01924
Value Function Update Magnitude: 0.02044

Collected Steps per Second: 21,116.83635
Overall Steps per Second: 14,985.37208

Timestep Collection Time: 2.36844
Timestep Consumption Time: 0.96908
PPO Batch Consumption Time: 0.11962
Total Iteration Time: 3.33752

Cumulative Model Updates: 7,676
Cumulative Timesteps: 128,091,154

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.54044
Policy Entropy: 0.56430
Value Function Loss: 1.42795

Mean KL Divergence: 0.00132
SB3 Clip Fraction: 0.01273
Policy Update Magnitude: 0.02299
Value Function Update Magnitude: 0.02206

Collected Steps per Second: 24,680.92789
Overall Steps per Second: 17,790.88812

Timestep Collection Time: 2.02618
Timestep Consumption Time: 0.78470
PPO Batch Consumption Time: 0.05924
Total Iteration Time: 2.81088

Cumulative Model Updates: 7,679
Cumulative Timesteps: 128,141,162

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 128141162...
Checkpoint 128141162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,534.21368
Policy Entropy: 0.57383
Value Function Loss: 1.45532

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.02113
Policy Update Magnitude: 0.03074
Value Function Update Magnitude: 0.02084

Collected Steps per Second: 21,147.81289
Overall Steps per Second: 15,667.23529

Timestep Collection Time: 2.36563
Timestep Consumption Time: 0.82753
PPO Batch Consumption Time: 0.07680
Total Iteration Time: 3.19316

Cumulative Model Updates: 7,682
Cumulative Timesteps: 128,191,190

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.88765
Policy Entropy: 0.57460
Value Function Loss: 1.43021

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02729
Policy Update Magnitude: 0.02496
Value Function Update Magnitude: 0.02064

Collected Steps per Second: 24,501.78009
Overall Steps per Second: 17,618.67647

Timestep Collection Time: 2.04263
Timestep Consumption Time: 0.79799
PPO Batch Consumption Time: 0.06266
Total Iteration Time: 2.84062

Cumulative Model Updates: 7,685
Cumulative Timesteps: 128,241,238

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 128241238...
Checkpoint 128241238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,057.40388
Policy Entropy: 0.58357
Value Function Loss: 1.44484

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01601
Policy Update Magnitude: 0.02528
Value Function Update Magnitude: 0.02176

Collected Steps per Second: 21,439.03487
Overall Steps per Second: 15,123.35335

Timestep Collection Time: 2.33247
Timestep Consumption Time: 0.97407
PPO Batch Consumption Time: 0.12665
Total Iteration Time: 3.30654

Cumulative Model Updates: 7,688
Cumulative Timesteps: 128,291,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,093.93652
Policy Entropy: 0.58354
Value Function Loss: 1.39791

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02710
Policy Update Magnitude: 0.02746
Value Function Update Magnitude: 0.02095

Collected Steps per Second: 24,129.81231
Overall Steps per Second: 17,636.56680

Timestep Collection Time: 2.07337
Timestep Consumption Time: 0.76335
PPO Batch Consumption Time: 0.06024
Total Iteration Time: 2.83672

Cumulative Model Updates: 7,691
Cumulative Timesteps: 128,341,274

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 128341274...
Checkpoint 128341274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,948.18307
Policy Entropy: 0.58730
Value Function Loss: 1.38796

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02651
Policy Update Magnitude: 0.02617
Value Function Update Magnitude: 0.02091

Collected Steps per Second: 21,077.57934
Overall Steps per Second: 14,979.69993

Timestep Collection Time: 2.37304
Timestep Consumption Time: 0.96601
PPO Batch Consumption Time: 0.11982
Total Iteration Time: 3.33905

Cumulative Model Updates: 7,694
Cumulative Timesteps: 128,391,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,651.79553
Policy Entropy: 0.58423
Value Function Loss: 1.35315

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.04089
Policy Update Magnitude: 0.02365
Value Function Update Magnitude: 0.01956

Collected Steps per Second: 24,111.25693
Overall Steps per Second: 16,622.90888

Timestep Collection Time: 2.07563
Timestep Consumption Time: 0.93504
PPO Batch Consumption Time: 0.10119
Total Iteration Time: 3.01066

Cumulative Model Updates: 7,697
Cumulative Timesteps: 128,441,338

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 128441338...
Checkpoint 128441338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,515.06526
Policy Entropy: 0.58031
Value Function Loss: 1.40944

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.03051
Policy Update Magnitude: 0.02305
Value Function Update Magnitude: 0.01909

Collected Steps per Second: 23,261.78257
Overall Steps per Second: 16,708.45004

Timestep Collection Time: 2.15039
Timestep Consumption Time: 0.84342
PPO Batch Consumption Time: 0.07833
Total Iteration Time: 2.99381

Cumulative Model Updates: 7,700
Cumulative Timesteps: 128,491,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,773.56008
Policy Entropy: 0.57911
Value Function Loss: 1.41498

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.00809
Policy Update Magnitude: 0.02932
Value Function Update Magnitude: 0.01974

Collected Steps per Second: 24,662.64907
Overall Steps per Second: 16,846.83004

Timestep Collection Time: 2.02784
Timestep Consumption Time: 0.94079
PPO Batch Consumption Time: 0.11544
Total Iteration Time: 2.96863

Cumulative Model Updates: 7,703
Cumulative Timesteps: 128,541,372

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 128541372...
Checkpoint 128541372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,930.25419
Policy Entropy: 0.58185
Value Function Loss: 1.47626

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02452
Policy Update Magnitude: 0.03077
Value Function Update Magnitude: 0.01821

Collected Steps per Second: 24,241.77197
Overall Steps per Second: 16,756.06260

Timestep Collection Time: 2.06272
Timestep Consumption Time: 0.92151
PPO Batch Consumption Time: 0.10464
Total Iteration Time: 2.98423

Cumulative Model Updates: 7,706
Cumulative Timesteps: 128,591,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,708.25468
Policy Entropy: 0.58483
Value Function Loss: 1.45245

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02119
Policy Update Magnitude: 0.02782
Value Function Update Magnitude: 0.02101

Collected Steps per Second: 24,787.23874
Overall Steps per Second: 16,727.65010

Timestep Collection Time: 2.01717
Timestep Consumption Time: 0.97190
PPO Batch Consumption Time: 0.11966
Total Iteration Time: 2.98906

Cumulative Model Updates: 7,709
Cumulative Timesteps: 128,641,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 128641376...
Checkpoint 128641376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,764.93779
Policy Entropy: 0.58232
Value Function Loss: 1.45675

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.02031
Policy Update Magnitude: 0.02798
Value Function Update Magnitude: 0.01918

Collected Steps per Second: 23,879.36928
Overall Steps per Second: 16,684.71977

Timestep Collection Time: 2.09486
Timestep Consumption Time: 0.90333
PPO Batch Consumption Time: 0.10254
Total Iteration Time: 2.99819

Cumulative Model Updates: 7,712
Cumulative Timesteps: 128,691,400

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.62452
Policy Entropy: 0.58597
Value Function Loss: 1.42705

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01746
Policy Update Magnitude: 0.02709
Value Function Update Magnitude: 0.02231

Collected Steps per Second: 24,719.60063
Overall Steps per Second: 17,833.64448

Timestep Collection Time: 2.02269
Timestep Consumption Time: 0.78100
PPO Batch Consumption Time: 0.08140
Total Iteration Time: 2.80369

Cumulative Model Updates: 7,715
Cumulative Timesteps: 128,741,400

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 128741400...
Checkpoint 128741400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,807.59159
Policy Entropy: 0.59188
Value Function Loss: 1.42143

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01999
Policy Update Magnitude: 0.02631
Value Function Update Magnitude: 0.02375

Collected Steps per Second: 23,344.59669
Overall Steps per Second: 17,553.52754

Timestep Collection Time: 2.14294
Timestep Consumption Time: 0.70697
PPO Batch Consumption Time: 0.05933
Total Iteration Time: 2.84991

Cumulative Model Updates: 7,718
Cumulative Timesteps: 128,791,426

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,936.67344
Policy Entropy: 0.60408
Value Function Loss: 1.37394

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03274
Policy Update Magnitude: 0.02580
Value Function Update Magnitude: 0.02087

Collected Steps per Second: 21,076.29465
Overall Steps per Second: 15,132.48750

Timestep Collection Time: 2.37243
Timestep Consumption Time: 0.93185
PPO Batch Consumption Time: 0.11950
Total Iteration Time: 3.30428

Cumulative Model Updates: 7,721
Cumulative Timesteps: 128,841,428

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 128841428...
Checkpoint 128841428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.46001
Policy Entropy: 0.60227
Value Function Loss: 1.37731

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02169
Policy Update Magnitude: 0.02372
Value Function Update Magnitude: 0.02584

Collected Steps per Second: 24,396.14374
Overall Steps per Second: 16,747.48919

Timestep Collection Time: 2.05008
Timestep Consumption Time: 0.93628
PPO Batch Consumption Time: 0.10438
Total Iteration Time: 2.98636

Cumulative Model Updates: 7,724
Cumulative Timesteps: 128,891,442

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,535.01562
Policy Entropy: 0.60881
Value Function Loss: 1.38366

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03753
Policy Update Magnitude: 0.02349
Value Function Update Magnitude: 0.02395

Collected Steps per Second: 24,205.70290
Overall Steps per Second: 16,633.27268

Timestep Collection Time: 2.06687
Timestep Consumption Time: 0.94096
PPO Batch Consumption Time: 0.09347
Total Iteration Time: 3.00783

Cumulative Model Updates: 7,727
Cumulative Timesteps: 128,941,472

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 128941472...
Checkpoint 128941472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.28669
Policy Entropy: 0.59289
Value Function Loss: 1.42091

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03233
Policy Update Magnitude: 0.02203
Value Function Update Magnitude: 0.02109

Collected Steps per Second: 23,885.21836
Overall Steps per Second: 16,764.05975

Timestep Collection Time: 2.09360
Timestep Consumption Time: 0.88933
PPO Batch Consumption Time: 0.09123
Total Iteration Time: 2.98293

Cumulative Model Updates: 7,730
Cumulative Timesteps: 128,991,478

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,855.62288
Policy Entropy: 0.59725
Value Function Loss: 1.45413

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01913
Policy Update Magnitude: 0.02348
Value Function Update Magnitude: 0.02516

Collected Steps per Second: 24,001.01243
Overall Steps per Second: 16,722.79482

Timestep Collection Time: 2.08450
Timestep Consumption Time: 0.90723
PPO Batch Consumption Time: 0.09318
Total Iteration Time: 2.99172

Cumulative Model Updates: 7,733
Cumulative Timesteps: 129,041,508

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 129041508...
Checkpoint 129041508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,274.81550
Policy Entropy: 0.59329
Value Function Loss: 1.44394

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01834
Policy Update Magnitude: 0.02640
Value Function Update Magnitude: 0.02334

Collected Steps per Second: 24,509.80873
Overall Steps per Second: 16,830.60379

Timestep Collection Time: 2.04041
Timestep Consumption Time: 0.93097
PPO Batch Consumption Time: 0.10436
Total Iteration Time: 2.97137

Cumulative Model Updates: 7,736
Cumulative Timesteps: 129,091,518

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,752.93380
Policy Entropy: 0.59560
Value Function Loss: 1.39482

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01922
Policy Update Magnitude: 0.02582
Value Function Update Magnitude: 0.02169

Collected Steps per Second: 24,546.25632
Overall Steps per Second: 16,730.01151

Timestep Collection Time: 2.03697
Timestep Consumption Time: 0.95167
PPO Batch Consumption Time: 0.11213
Total Iteration Time: 2.98864

Cumulative Model Updates: 7,739
Cumulative Timesteps: 129,141,518

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 129141518...
Checkpoint 129141518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,251.37823
Policy Entropy: 0.58212
Value Function Loss: 1.41026

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01784
Policy Update Magnitude: 0.02861
Value Function Update Magnitude: 0.02037

Collected Steps per Second: 24,080.01209
Overall Steps per Second: 16,683.68396

Timestep Collection Time: 2.07683
Timestep Consumption Time: 0.92071
PPO Batch Consumption Time: 0.09627
Total Iteration Time: 2.99754

Cumulative Model Updates: 7,742
Cumulative Timesteps: 129,191,528

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,145.87474
Policy Entropy: 0.59365
Value Function Loss: 1.37849

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02666
Policy Update Magnitude: 0.02744
Value Function Update Magnitude: 0.02025

Collected Steps per Second: 24,985.52235
Overall Steps per Second: 16,793.06342

Timestep Collection Time: 2.00188
Timestep Consumption Time: 0.97661
PPO Batch Consumption Time: 0.11479
Total Iteration Time: 2.97849

Cumulative Model Updates: 7,745
Cumulative Timesteps: 129,241,546

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 129241546...
Checkpoint 129241546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,670.04324
Policy Entropy: 0.58455
Value Function Loss: 1.45830

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03592
Policy Update Magnitude: 0.02370
Value Function Update Magnitude: 0.02086

Collected Steps per Second: 23,663.14356
Overall Steps per Second: 16,651.06032

Timestep Collection Time: 2.11384
Timestep Consumption Time: 0.89018
PPO Batch Consumption Time: 0.08907
Total Iteration Time: 3.00401

Cumulative Model Updates: 7,748
Cumulative Timesteps: 129,291,566

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 961.25719
Policy Entropy: 0.59228
Value Function Loss: 1.46108

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02428
Policy Update Magnitude: 0.02396
Value Function Update Magnitude: 0.02218

Collected Steps per Second: 24,702.93296
Overall Steps per Second: 16,828.77279

Timestep Collection Time: 2.02502
Timestep Consumption Time: 0.94751
PPO Batch Consumption Time: 0.11436
Total Iteration Time: 2.97253

Cumulative Model Updates: 7,751
Cumulative Timesteps: 129,341,590

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 129341590...
Checkpoint 129341590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,791.43460
Policy Entropy: 0.59149
Value Function Loss: 1.50968

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.02023
Policy Update Magnitude: 0.02573
Value Function Update Magnitude: 0.01949

Collected Steps per Second: 23,885.41190
Overall Steps per Second: 16,734.52006

Timestep Collection Time: 2.09450
Timestep Consumption Time: 0.89501
PPO Batch Consumption Time: 0.10437
Total Iteration Time: 2.98951

Cumulative Model Updates: 7,754
Cumulative Timesteps: 129,391,618

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 983.83502
Policy Entropy: 0.59213
Value Function Loss: 1.50064

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02113
Policy Update Magnitude: 0.02516
Value Function Update Magnitude: 0.02200

Collected Steps per Second: 24,367.65459
Overall Steps per Second: 16,720.67388

Timestep Collection Time: 2.05256
Timestep Consumption Time: 0.93871
PPO Batch Consumption Time: 0.11040
Total Iteration Time: 2.99127

Cumulative Model Updates: 7,757
Cumulative Timesteps: 129,441,634

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 129441634...
Checkpoint 129441634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,740.42541
Policy Entropy: 0.58561
Value Function Loss: 1.46299

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02519
Policy Update Magnitude: 0.02539
Value Function Update Magnitude: 0.02288

Collected Steps per Second: 24,418.78470
Overall Steps per Second: 16,775.74107

Timestep Collection Time: 2.04859
Timestep Consumption Time: 0.93334
PPO Batch Consumption Time: 0.11381
Total Iteration Time: 2.98192

Cumulative Model Updates: 7,760
Cumulative Timesteps: 129,491,658

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,962.46510
Policy Entropy: 0.58812
Value Function Loss: 1.43100

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02215
Policy Update Magnitude: 0.02594
Value Function Update Magnitude: 0.02073

Collected Steps per Second: 24,408.50303
Overall Steps per Second: 16,713.59665

Timestep Collection Time: 2.04896
Timestep Consumption Time: 0.94334
PPO Batch Consumption Time: 0.11229
Total Iteration Time: 2.99229

Cumulative Model Updates: 7,763
Cumulative Timesteps: 129,541,670

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 129541670...
Checkpoint 129541670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.32566
Policy Entropy: 0.58515
Value Function Loss: 1.40715

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01311
Policy Update Magnitude: 0.02657
Value Function Update Magnitude: 0.02267

Collected Steps per Second: 24,645.40744
Overall Steps per Second: 16,759.25056

Timestep Collection Time: 2.02886
Timestep Consumption Time: 0.95469
PPO Batch Consumption Time: 0.11698
Total Iteration Time: 2.98355

Cumulative Model Updates: 7,766
Cumulative Timesteps: 129,591,672

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,845.69679
Policy Entropy: 0.59618
Value Function Loss: 1.39904

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01655
Policy Update Magnitude: 0.02719
Value Function Update Magnitude: 0.02148

Collected Steps per Second: 24,430.78789
Overall Steps per Second: 17,758.13424

Timestep Collection Time: 2.04758
Timestep Consumption Time: 0.76938
PPO Batch Consumption Time: 0.07719
Total Iteration Time: 2.81696

Cumulative Model Updates: 7,769
Cumulative Timesteps: 129,641,696

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 129641696...
Checkpoint 129641696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,748.29573
Policy Entropy: 0.59290
Value Function Loss: 1.41243

Mean KL Divergence: 0.00135
SB3 Clip Fraction: 0.01169
Policy Update Magnitude: 0.03044
Value Function Update Magnitude: 0.02420

Collected Steps per Second: 23,922.83642
Overall Steps per Second: 18,004.30654

Timestep Collection Time: 2.09139
Timestep Consumption Time: 0.68750
PPO Batch Consumption Time: 0.05604
Total Iteration Time: 2.77889

Cumulative Model Updates: 7,772
Cumulative Timesteps: 129,691,728

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,774.90359
Policy Entropy: 0.60071
Value Function Loss: 1.39266

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02391
Policy Update Magnitude: 0.03368
Value Function Update Magnitude: 0.02067

Collected Steps per Second: 21,102.79084
Overall Steps per Second: 15,649.14676

Timestep Collection Time: 2.37030
Timestep Consumption Time: 0.82604
PPO Batch Consumption Time: 0.09348
Total Iteration Time: 3.19634

Cumulative Model Updates: 7,775
Cumulative Timesteps: 129,741,748

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 129741748...
Checkpoint 129741748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,139.67691
Policy Entropy: 0.59797
Value Function Loss: 1.41023

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02837
Policy Update Magnitude: 0.03232
Value Function Update Magnitude: 0.02304

Collected Steps per Second: 23,712.01651
Overall Steps per Second: 17,552.97538

Timestep Collection Time: 2.10880
Timestep Consumption Time: 0.73994
PPO Batch Consumption Time: 0.06150
Total Iteration Time: 2.84875

Cumulative Model Updates: 7,778
Cumulative Timesteps: 129,791,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,904.12525
Policy Entropy: 0.59798
Value Function Loss: 1.41869

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02468
Policy Update Magnitude: 0.02876
Value Function Update Magnitude: 0.02211

Collected Steps per Second: 22,038.61989
Overall Steps per Second: 15,971.91914

Timestep Collection Time: 2.27110
Timestep Consumption Time: 0.86265
PPO Batch Consumption Time: 0.07965
Total Iteration Time: 3.13375

Cumulative Model Updates: 7,781
Cumulative Timesteps: 129,841,804

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 129841804...
Checkpoint 129841804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.52095
Policy Entropy: 0.59011
Value Function Loss: 1.41045

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.02007
Policy Update Magnitude: 0.02707
Value Function Update Magnitude: 0.02185

Collected Steps per Second: 24,153.62941
Overall Steps per Second: 17,548.85466

Timestep Collection Time: 2.07083
Timestep Consumption Time: 0.77939
PPO Batch Consumption Time: 0.05982
Total Iteration Time: 2.85021

Cumulative Model Updates: 7,784
Cumulative Timesteps: 129,891,822

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,314.22504
Policy Entropy: 0.59200
Value Function Loss: 1.39515

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.01311
Policy Update Magnitude: 0.03265
Value Function Update Magnitude: 0.02287

Collected Steps per Second: 21,902.50516
Overall Steps per Second: 15,985.72545

Timestep Collection Time: 2.28294
Timestep Consumption Time: 0.84498
PPO Batch Consumption Time: 0.07569
Total Iteration Time: 3.12792

Cumulative Model Updates: 7,787
Cumulative Timesteps: 129,941,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 129941824...
Checkpoint 129941824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,209.51173
Policy Entropy: 0.59505
Value Function Loss: 1.39012

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01664
Policy Update Magnitude: 0.03355
Value Function Update Magnitude: 0.02132

Collected Steps per Second: 23,768.43148
Overall Steps per Second: 17,278.66309

Timestep Collection Time: 2.10380
Timestep Consumption Time: 0.79018
PPO Batch Consumption Time: 0.06154
Total Iteration Time: 2.89397

Cumulative Model Updates: 7,790
Cumulative Timesteps: 129,991,828

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,196.25213
Policy Entropy: 0.59111
Value Function Loss: 1.39758

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01845
Policy Update Magnitude: 0.03539
Value Function Update Magnitude: 0.02023

Collected Steps per Second: 24,304.95943
Overall Steps per Second: 17,230.53520

Timestep Collection Time: 2.05728
Timestep Consumption Time: 0.84467
PPO Batch Consumption Time: 0.07869
Total Iteration Time: 2.90194

Cumulative Model Updates: 7,793
Cumulative Timesteps: 130,041,830

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 130041830...
Checkpoint 130041830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,318.31523
Policy Entropy: 0.58476
Value Function Loss: 1.42992

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.02051
Policy Update Magnitude: 0.03609
Value Function Update Magnitude: 0.02098

Collected Steps per Second: 22,487.16660
Overall Steps per Second: 15,853.26586

Timestep Collection Time: 2.22385
Timestep Consumption Time: 0.93058
PPO Batch Consumption Time: 0.10588
Total Iteration Time: 3.15443

Cumulative Model Updates: 7,796
Cumulative Timesteps: 130,091,838

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,872.74053
Policy Entropy: 0.59109
Value Function Loss: 1.41261

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.03031
Policy Update Magnitude: 0.03130
Value Function Update Magnitude: 0.02011

Collected Steps per Second: 25,061.43363
Overall Steps per Second: 17,716.22860

Timestep Collection Time: 1.99598
Timestep Consumption Time: 0.82754
PPO Batch Consumption Time: 0.06030
Total Iteration Time: 2.82351

Cumulative Model Updates: 7,799
Cumulative Timesteps: 130,141,860

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 130141860...
Checkpoint 130141860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512.00728
Policy Entropy: 0.59991
Value Function Loss: 1.37480

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03191
Policy Update Magnitude: 0.02953
Value Function Update Magnitude: 0.01923

Collected Steps per Second: 21,327.69734
Overall Steps per Second: 14,998.56416

Timestep Collection Time: 2.34531
Timestep Consumption Time: 0.98968
PPO Batch Consumption Time: 0.12548
Total Iteration Time: 3.33499

Cumulative Model Updates: 7,802
Cumulative Timesteps: 130,191,880

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.90945
Policy Entropy: 0.60614
Value Function Loss: 1.39203

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02391
Policy Update Magnitude: 0.02784
Value Function Update Magnitude: 0.02320

Collected Steps per Second: 24,100.48157
Overall Steps per Second: 16,627.81359

Timestep Collection Time: 2.07548
Timestep Consumption Time: 0.93274
PPO Batch Consumption Time: 0.10003
Total Iteration Time: 3.00821

Cumulative Model Updates: 7,805
Cumulative Timesteps: 130,241,900

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 130241900...
Checkpoint 130241900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,314.02281
Policy Entropy: 0.60431
Value Function Loss: 1.34974

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01856
Policy Update Magnitude: 0.03467
Value Function Update Magnitude: 0.02614

Collected Steps per Second: 24,612.70597
Overall Steps per Second: 16,841.88689

Timestep Collection Time: 2.03180
Timestep Consumption Time: 0.93747
PPO Batch Consumption Time: 0.10800
Total Iteration Time: 2.96926

Cumulative Model Updates: 7,808
Cumulative Timesteps: 130,291,908

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,505.42078
Policy Entropy: 0.61132
Value Function Loss: 1.36339

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02730
Policy Update Magnitude: 0.03202
Value Function Update Magnitude: 0.02193

Collected Steps per Second: 24,365.44563
Overall Steps per Second: 16,706.14727

Timestep Collection Time: 2.05266
Timestep Consumption Time: 0.94109
PPO Batch Consumption Time: 0.11107
Total Iteration Time: 2.99375

Cumulative Model Updates: 7,811
Cumulative Timesteps: 130,341,922

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 130341922...
Checkpoint 130341922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,524.03541
Policy Entropy: 0.60623
Value Function Loss: 1.35434

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02265
Policy Update Magnitude: 0.02996
Value Function Update Magnitude: 0.02252

Collected Steps per Second: 24,334.03764
Overall Steps per Second: 16,742.77913

Timestep Collection Time: 2.05589
Timestep Consumption Time: 0.93215
PPO Batch Consumption Time: 0.10754
Total Iteration Time: 2.98803

Cumulative Model Updates: 7,814
Cumulative Timesteps: 130,391,950

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,051.87579
Policy Entropy: 0.60655
Value Function Loss: 1.37737

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02391
Policy Update Magnitude: 0.03374
Value Function Update Magnitude: 0.03071

Collected Steps per Second: 24,628.40183
Overall Steps per Second: 16,759.38818

Timestep Collection Time: 2.03026
Timestep Consumption Time: 0.95326
PPO Batch Consumption Time: 0.12318
Total Iteration Time: 2.98352

Cumulative Model Updates: 7,817
Cumulative Timesteps: 130,441,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 130441952...
Checkpoint 130441952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.36340
Policy Entropy: 0.60519
Value Function Loss: 1.37673

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03579
Policy Update Magnitude: 0.02780
Value Function Update Magnitude: 0.03302

Collected Steps per Second: 24,197.39922
Overall Steps per Second: 16,735.38415

Timestep Collection Time: 2.06700
Timestep Consumption Time: 0.92164
PPO Batch Consumption Time: 0.11042
Total Iteration Time: 2.98864

Cumulative Model Updates: 7,820
Cumulative Timesteps: 130,491,968

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,648.97642
Policy Entropy: 0.61250
Value Function Loss: 1.39270

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.04105
Policy Update Magnitude: 0.02557
Value Function Update Magnitude: 0.03087

Collected Steps per Second: 24,464.50756
Overall Steps per Second: 16,718.71323

Timestep Collection Time: 2.04476
Timestep Consumption Time: 0.94734
PPO Batch Consumption Time: 0.11496
Total Iteration Time: 2.99210

Cumulative Model Updates: 7,823
Cumulative Timesteps: 130,541,992

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 130541992...
Checkpoint 130541992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,835.22521
Policy Entropy: 0.60846
Value Function Loss: 1.37776

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04916
Policy Update Magnitude: 0.02420
Value Function Update Magnitude: 0.02700

Collected Steps per Second: 23,710.52567
Overall Steps per Second: 16,689.27437

Timestep Collection Time: 2.10961
Timestep Consumption Time: 0.88752
PPO Batch Consumption Time: 0.09768
Total Iteration Time: 2.99713

Cumulative Model Updates: 7,826
Cumulative Timesteps: 130,592,012

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,871.73742
Policy Entropy: 0.61387
Value Function Loss: 1.41930

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01937
Policy Update Magnitude: 0.02619
Value Function Update Magnitude: 0.03330

Collected Steps per Second: 24,801.13938
Overall Steps per Second: 17,845.75408

Timestep Collection Time: 2.01660
Timestep Consumption Time: 0.78597
PPO Batch Consumption Time: 0.08018
Total Iteration Time: 2.80257

Cumulative Model Updates: 7,829
Cumulative Timesteps: 130,642,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 130642026...
Checkpoint 130642026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,426.91195
Policy Entropy: 0.61753
Value Function Loss: 1.40503

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.03044
Policy Update Magnitude: 0.02957
Value Function Update Magnitude: 0.03237

Collected Steps per Second: 23,568.07725
Overall Steps per Second: 17,648.51059

Timestep Collection Time: 2.12270
Timestep Consumption Time: 0.71198
PPO Batch Consumption Time: 0.05962
Total Iteration Time: 2.83469

Cumulative Model Updates: 7,832
Cumulative Timesteps: 130,692,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.77532
Policy Entropy: 0.61246
Value Function Loss: 1.44207

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.04257
Policy Update Magnitude: 0.02723
Value Function Update Magnitude: 0.03396

Collected Steps per Second: 21,601.02096
Overall Steps per Second: 15,905.59142

Timestep Collection Time: 2.31554
Timestep Consumption Time: 0.82914
PPO Batch Consumption Time: 0.08738
Total Iteration Time: 3.14468

Cumulative Model Updates: 7,835
Cumulative Timesteps: 130,742,072

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 130742072...
Checkpoint 130742072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827.61487
Policy Entropy: 0.61117
Value Function Loss: 1.39273

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04353
Policy Update Magnitude: 0.02500
Value Function Update Magnitude: 0.03160

Collected Steps per Second: 23,716.30857
Overall Steps per Second: 17,769.77968

Timestep Collection Time: 2.10910
Timestep Consumption Time: 0.70579
PPO Batch Consumption Time: 0.05910
Total Iteration Time: 2.81489

Cumulative Model Updates: 7,838
Cumulative Timesteps: 130,792,092

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,553.89037
Policy Entropy: 0.61195
Value Function Loss: 1.35440

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03757
Policy Update Magnitude: 0.02193
Value Function Update Magnitude: 0.03531

Collected Steps per Second: 21,210.05655
Overall Steps per Second: 15,814.59191

Timestep Collection Time: 2.35756
Timestep Consumption Time: 0.80433
PPO Batch Consumption Time: 0.08524
Total Iteration Time: 3.16189

Cumulative Model Updates: 7,841
Cumulative Timesteps: 130,842,096

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 130842096...
Checkpoint 130842096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541.84216
Policy Entropy: 0.61004
Value Function Loss: 1.27610

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03539
Policy Update Magnitude: 0.02171
Value Function Update Magnitude: 0.04056

Collected Steps per Second: 23,654.77033
Overall Steps per Second: 17,780.28706

Timestep Collection Time: 2.11416
Timestep Consumption Time: 0.69850
PPO Batch Consumption Time: 0.05811
Total Iteration Time: 2.81267

Cumulative Model Updates: 7,844
Cumulative Timesteps: 130,892,106

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,577.83109
Policy Entropy: 0.61147
Value Function Loss: 1.26188

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04258
Policy Update Magnitude: 0.02275
Value Function Update Magnitude: 0.03843

Collected Steps per Second: 21,906.08517
Overall Steps per Second: 15,806.90272

Timestep Collection Time: 2.28338
Timestep Consumption Time: 0.88106
PPO Batch Consumption Time: 0.09303
Total Iteration Time: 3.16444

Cumulative Model Updates: 7,847
Cumulative Timesteps: 130,942,126

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 130942126...
Checkpoint 130942126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216.92299
Policy Entropy: 0.60575
Value Function Loss: 1.28061

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.04060
Policy Update Magnitude: 0.02473
Value Function Update Magnitude: 0.03786

Collected Steps per Second: 23,744.15453
Overall Steps per Second: 17,796.00357

Timestep Collection Time: 2.10620
Timestep Consumption Time: 0.70398
PPO Batch Consumption Time: 0.05892
Total Iteration Time: 2.81018

Cumulative Model Updates: 7,850
Cumulative Timesteps: 130,992,136

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,804.48000
Policy Entropy: 0.60050
Value Function Loss: 1.34697

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.06235
Policy Update Magnitude: 0.02470
Value Function Update Magnitude: 0.03766

Collected Steps per Second: 21,393.18409
Overall Steps per Second: 15,751.89804

Timestep Collection Time: 2.33944
Timestep Consumption Time: 0.83783
PPO Batch Consumption Time: 0.07427
Total Iteration Time: 3.17727

Cumulative Model Updates: 7,853
Cumulative Timesteps: 131,042,184

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 131042184...
Checkpoint 131042184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,640.64271
Policy Entropy: 0.60373
Value Function Loss: 1.35135

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.06156
Policy Update Magnitude: 0.02139
Value Function Update Magnitude: 0.03533

Collected Steps per Second: 24,219.34780
Overall Steps per Second: 17,329.63000

Timestep Collection Time: 2.06513
Timestep Consumption Time: 0.82103
PPO Batch Consumption Time: 0.05817
Total Iteration Time: 2.88616

Cumulative Model Updates: 7,856
Cumulative Timesteps: 131,092,200

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,843.56130
Policy Entropy: 0.60925
Value Function Loss: 1.34011

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05741
Policy Update Magnitude: 0.02133
Value Function Update Magnitude: 0.03481

Collected Steps per Second: 25,053.56370
Overall Steps per Second: 17,344.04409

Timestep Collection Time: 1.99692
Timestep Consumption Time: 0.88764
PPO Batch Consumption Time: 0.09463
Total Iteration Time: 2.88456

Cumulative Model Updates: 7,859
Cumulative Timesteps: 131,142,230

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 131142230...
Checkpoint 131142230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,312.38396
Policy Entropy: 0.60824
Value Function Loss: 1.32051

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04607
Policy Update Magnitude: 0.02255
Value Function Update Magnitude: 0.03094

Collected Steps per Second: 23,888.58059
Overall Steps per Second: 17,377.75416

Timestep Collection Time: 2.09355
Timestep Consumption Time: 0.78438
PPO Batch Consumption Time: 0.06182
Total Iteration Time: 2.87793

Cumulative Model Updates: 7,862
Cumulative Timesteps: 131,192,242

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,658.96551
Policy Entropy: 0.61260
Value Function Loss: 1.30696

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03237
Policy Update Magnitude: 0.02395
Value Function Update Magnitude: 0.02669

Collected Steps per Second: 24,795.52320
Overall Steps per Second: 17,869.85612

Timestep Collection Time: 2.01698
Timestep Consumption Time: 0.78170
PPO Batch Consumption Time: 0.06211
Total Iteration Time: 2.79868

Cumulative Model Updates: 7,865
Cumulative Timesteps: 131,242,254

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 131242254...
Checkpoint 131242254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,015.75626
Policy Entropy: 0.59928
Value Function Loss: 1.32193

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04415
Policy Update Magnitude: 0.02416
Value Function Update Magnitude: 0.03773

Collected Steps per Second: 24,002.57156
Overall Steps per Second: 16,392.55943

Timestep Collection Time: 2.08403
Timestep Consumption Time: 0.96748
PPO Batch Consumption Time: 0.11841
Total Iteration Time: 3.05151

Cumulative Model Updates: 7,868
Cumulative Timesteps: 131,292,276

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,798.10158
Policy Entropy: 0.60729
Value Function Loss: 1.31757

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05882
Policy Update Magnitude: 0.02311
Value Function Update Magnitude: 0.03579

Collected Steps per Second: 24,885.63907
Overall Steps per Second: 17,568.42986

Timestep Collection Time: 2.01048
Timestep Consumption Time: 0.83736
PPO Batch Consumption Time: 0.07791
Total Iteration Time: 2.84784

Cumulative Model Updates: 7,871
Cumulative Timesteps: 131,342,308

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 131342308...
Checkpoint 131342308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.78294
Policy Entropy: 0.59790
Value Function Loss: 1.35630

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.07357
Policy Update Magnitude: 0.02305
Value Function Update Magnitude: 0.03675

Collected Steps per Second: 21,985.45109
Overall Steps per Second: 15,880.57301

Timestep Collection Time: 2.27469
Timestep Consumption Time: 0.87444
PPO Batch Consumption Time: 0.08862
Total Iteration Time: 3.14913

Cumulative Model Updates: 7,874
Cumulative Timesteps: 131,392,318

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,828.90813
Policy Entropy: 0.60872
Value Function Loss: 1.30789

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.07686
Policy Update Magnitude: 0.02013
Value Function Update Magnitude: 0.03505

Collected Steps per Second: 24,741.92036
Overall Steps per Second: 16,761.31696

Timestep Collection Time: 2.02102
Timestep Consumption Time: 0.96227
PPO Batch Consumption Time: 0.10156
Total Iteration Time: 2.98330

Cumulative Model Updates: 7,877
Cumulative Timesteps: 131,442,322

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 131442322...
Checkpoint 131442322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,664.06565
Policy Entropy: 0.60807
Value Function Loss: 1.33668

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.08265
Policy Update Magnitude: 0.02059
Value Function Update Magnitude: 0.03663

Collected Steps per Second: 23,822.19898
Overall Steps per Second: 16,697.52413

Timestep Collection Time: 2.09897
Timestep Consumption Time: 0.89561
PPO Batch Consumption Time: 0.07811
Total Iteration Time: 2.99458

Cumulative Model Updates: 7,880
Cumulative Timesteps: 131,492,324

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,419.14992
Policy Entropy: 0.61735
Value Function Loss: 1.28407

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.08231
Policy Update Magnitude: 0.01872
Value Function Update Magnitude: 0.04054

Collected Steps per Second: 23,730.74149
Overall Steps per Second: 16,734.17415

Timestep Collection Time: 2.10765
Timestep Consumption Time: 0.88121
PPO Batch Consumption Time: 0.09633
Total Iteration Time: 2.98885

Cumulative Model Updates: 7,883
Cumulative Timesteps: 131,542,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 131542340...
Checkpoint 131542340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,439.18588
Policy Entropy: 0.60820
Value Function Loss: 1.35168

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.01955
Value Function Update Magnitude: 0.04057

Collected Steps per Second: 24,098.14894
Overall Steps per Second: 16,815.57007

Timestep Collection Time: 2.07568
Timestep Consumption Time: 0.89895
PPO Batch Consumption Time: 0.10358
Total Iteration Time: 2.97462

Cumulative Model Updates: 7,886
Cumulative Timesteps: 131,592,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,466.93112
Policy Entropy: 0.61492
Value Function Loss: 1.30034

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07662
Policy Update Magnitude: 0.01759
Value Function Update Magnitude: 0.03829

Collected Steps per Second: 24,182.95947
Overall Steps per Second: 16,757.40495

Timestep Collection Time: 2.06782
Timestep Consumption Time: 0.91629
PPO Batch Consumption Time: 0.11281
Total Iteration Time: 2.98411

Cumulative Model Updates: 7,889
Cumulative Timesteps: 131,642,366

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 131642366...
Checkpoint 131642366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,066.12626
Policy Entropy: 0.60226
Value Function Loss: 1.33796

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.07540
Policy Update Magnitude: 0.01825
Value Function Update Magnitude: 0.04364

Collected Steps per Second: 24,552.54219
Overall Steps per Second: 16,764.78762

Timestep Collection Time: 2.03645
Timestep Consumption Time: 0.94599
PPO Batch Consumption Time: 0.11455
Total Iteration Time: 2.98244

Cumulative Model Updates: 7,892
Cumulative Timesteps: 131,692,366

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,633.43387
Policy Entropy: 0.60784
Value Function Loss: 1.29836

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07753
Policy Update Magnitude: 0.01810
Value Function Update Magnitude: 0.03942

Collected Steps per Second: 24,597.25342
Overall Steps per Second: 16,730.46542

Timestep Collection Time: 2.03291
Timestep Consumption Time: 0.95589
PPO Batch Consumption Time: 0.12231
Total Iteration Time: 2.98880

Cumulative Model Updates: 7,895
Cumulative Timesteps: 131,742,370

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 131742370...
Checkpoint 131742370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,624.67773
Policy Entropy: 0.60098
Value Function Loss: 1.27401

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.07421
Policy Update Magnitude: 0.01818
Value Function Update Magnitude: 0.03726

Collected Steps per Second: 24,507.31244
Overall Steps per Second: 16,734.03240

Timestep Collection Time: 2.04029
Timestep Consumption Time: 0.94775
PPO Batch Consumption Time: 0.11142
Total Iteration Time: 2.98804

Cumulative Model Updates: 7,898
Cumulative Timesteps: 131,792,372

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,454.32792
Policy Entropy: 0.61035
Value Function Loss: 1.31208

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.07609
Policy Update Magnitude: 0.01824
Value Function Update Magnitude: 0.03644

Collected Steps per Second: 24,622.66204
Overall Steps per Second: 16,741.53664

Timestep Collection Time: 2.03081
Timestep Consumption Time: 0.95601
PPO Batch Consumption Time: 0.12107
Total Iteration Time: 2.98682

Cumulative Model Updates: 7,901
Cumulative Timesteps: 131,842,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 131842376...
Checkpoint 131842376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,819.78018
Policy Entropy: 0.60802
Value Function Loss: 1.32282

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07701
Policy Update Magnitude: 0.01765
Value Function Update Magnitude: 0.03463

Collected Steps per Second: 23,973.88700
Overall Steps per Second: 17,617.69655

Timestep Collection Time: 2.08610
Timestep Consumption Time: 0.75263
PPO Batch Consumption Time: 0.07686
Total Iteration Time: 2.83874

Cumulative Model Updates: 7,904
Cumulative Timesteps: 131,892,388

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.48726
Policy Entropy: 0.60646
Value Function Loss: 1.34444

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.07733
Policy Update Magnitude: 0.01799
Value Function Update Magnitude: 0.03819

Collected Steps per Second: 22,279.75326
Overall Steps per Second: 15,916.91434

Timestep Collection Time: 2.24509
Timestep Consumption Time: 0.89748
PPO Batch Consumption Time: 0.12098
Total Iteration Time: 3.14257

Cumulative Model Updates: 7,907
Cumulative Timesteps: 131,942,408

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 131942408...
Checkpoint 131942408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,355.34084
Policy Entropy: 0.60588
Value Function Loss: 1.33333

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.07525
Policy Update Magnitude: 0.01777
Value Function Update Magnitude: 0.03735

Collected Steps per Second: 22,879.62187
Overall Steps per Second: 16,658.46079

Timestep Collection Time: 2.18596
Timestep Consumption Time: 0.81636
PPO Batch Consumption Time: 0.09176
Total Iteration Time: 3.00232

Cumulative Model Updates: 7,910
Cumulative Timesteps: 131,992,422

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,803.57314
Policy Entropy: 0.61050
Value Function Loss: 1.32992

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.07482
Policy Update Magnitude: 0.01795
Value Function Update Magnitude: 0.03713

Collected Steps per Second: 23,814.76839
Overall Steps per Second: 16,788.27993

Timestep Collection Time: 2.10013
Timestep Consumption Time: 0.87898
PPO Batch Consumption Time: 0.10906
Total Iteration Time: 2.97910

Cumulative Model Updates: 7,913
Cumulative Timesteps: 132,042,436

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 132042436...
Checkpoint 132042436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,588.54304
Policy Entropy: 0.60550
Value Function Loss: 1.34005

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.07094
Policy Update Magnitude: 0.01796
Value Function Update Magnitude: 0.03473

Collected Steps per Second: 23,567.24346
Overall Steps per Second: 16,765.79651

Timestep Collection Time: 2.12184
Timestep Consumption Time: 0.86078
PPO Batch Consumption Time: 0.11072
Total Iteration Time: 2.98262

Cumulative Model Updates: 7,916
Cumulative Timesteps: 132,092,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,564.91115
Policy Entropy: 0.60130
Value Function Loss: 1.29275

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.07088
Policy Update Magnitude: 0.01754
Value Function Update Magnitude: 0.03798

Collected Steps per Second: 23,448.74284
Overall Steps per Second: 16,682.41747

Timestep Collection Time: 2.13316
Timestep Consumption Time: 0.86520
PPO Batch Consumption Time: 0.10427
Total Iteration Time: 2.99837

Cumulative Model Updates: 7,919
Cumulative Timesteps: 132,142,462

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 132142462...
Checkpoint 132142462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,084.87458
Policy Entropy: 0.58987
Value Function Loss: 1.32120

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06937
Policy Update Magnitude: 0.01780
Value Function Update Magnitude: 0.03656

Collected Steps per Second: 24,786.48838
Overall Steps per Second: 16,658.08149

Timestep Collection Time: 2.01771
Timestep Consumption Time: 0.98455
PPO Batch Consumption Time: 0.11846
Total Iteration Time: 3.00227

Cumulative Model Updates: 7,922
Cumulative Timesteps: 132,192,474

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.58499
Policy Entropy: 0.59267
Value Function Loss: 1.27413

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06989
Policy Update Magnitude: 0.01856
Value Function Update Magnitude: 0.03387

Collected Steps per Second: 24,299.57297
Overall Steps per Second: 16,804.39209

Timestep Collection Time: 2.05864
Timestep Consumption Time: 0.91820
PPO Batch Consumption Time: 0.10319
Total Iteration Time: 2.97684

Cumulative Model Updates: 7,925
Cumulative Timesteps: 132,242,498

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 132242498...
Checkpoint 132242498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,881.38515
Policy Entropy: 0.58841
Value Function Loss: 1.30192

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.07307
Policy Update Magnitude: 0.01898
Value Function Update Magnitude: 0.04375

Collected Steps per Second: 24,434.79215
Overall Steps per Second: 16,795.38009

Timestep Collection Time: 2.04684
Timestep Consumption Time: 0.93101
PPO Batch Consumption Time: 0.10700
Total Iteration Time: 2.97784

Cumulative Model Updates: 7,928
Cumulative Timesteps: 132,292,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,638.26919
Policy Entropy: 0.59504
Value Function Loss: 1.23218

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06969
Policy Update Magnitude: 0.01739
Value Function Update Magnitude: 0.04778

Collected Steps per Second: 24,740.91838
Overall Steps per Second: 16,730.69697

Timestep Collection Time: 2.02143
Timestep Consumption Time: 0.96781
PPO Batch Consumption Time: 0.12120
Total Iteration Time: 2.98924

Cumulative Model Updates: 7,931
Cumulative Timesteps: 132,342,524

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 132342524...
Checkpoint 132342524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,608.36216
Policy Entropy: 0.59771
Value Function Loss: 1.27775

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06977
Policy Update Magnitude: 0.01827
Value Function Update Magnitude: 0.03938

Collected Steps per Second: 24,795.83626
Overall Steps per Second: 16,729.90847

Timestep Collection Time: 2.01663
Timestep Consumption Time: 0.97227
PPO Batch Consumption Time: 0.11113
Total Iteration Time: 2.98890

Cumulative Model Updates: 7,934
Cumulative Timesteps: 132,392,528

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,600.09949
Policy Entropy: 0.60693
Value Function Loss: 1.21856

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06951
Policy Update Magnitude: 0.01750
Value Function Update Magnitude: 0.03354

Collected Steps per Second: 24,720.88696
Overall Steps per Second: 16,744.47341

Timestep Collection Time: 2.02379
Timestep Consumption Time: 0.96406
PPO Batch Consumption Time: 0.11510
Total Iteration Time: 2.98785

Cumulative Model Updates: 7,937
Cumulative Timesteps: 132,442,558

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 132442558...
Checkpoint 132442558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,198.20837
Policy Entropy: 0.60449
Value Function Loss: 1.21947

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06796
Policy Update Magnitude: 0.01854
Value Function Update Magnitude: 0.03662

Collected Steps per Second: 23,463.82156
Overall Steps per Second: 16,621.70467

Timestep Collection Time: 2.13145
Timestep Consumption Time: 0.87739
PPO Batch Consumption Time: 0.08442
Total Iteration Time: 3.00884

Cumulative Model Updates: 7,940
Cumulative Timesteps: 132,492,570

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,000.95106
Policy Entropy: 0.61310
Value Function Loss: 1.19457

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06841
Policy Update Magnitude: 0.01801
Value Function Update Magnitude: 0.03391

Collected Steps per Second: 24,535.96725
Overall Steps per Second: 16,829.53001

Timestep Collection Time: 2.03848
Timestep Consumption Time: 0.93344
PPO Batch Consumption Time: 0.10953
Total Iteration Time: 2.97192

Cumulative Model Updates: 7,943
Cumulative Timesteps: 132,542,586

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 132542586...
Checkpoint 132542586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,169.83165
Policy Entropy: 0.61035
Value Function Loss: 1.24275

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06855
Policy Update Magnitude: 0.01714
Value Function Update Magnitude: 0.03764

Collected Steps per Second: 23,878.36453
Overall Steps per Second: 16,638.87422

Timestep Collection Time: 2.09445
Timestep Consumption Time: 0.91128
PPO Batch Consumption Time: 0.07594
Total Iteration Time: 3.00573

Cumulative Model Updates: 7,946
Cumulative Timesteps: 132,592,598

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,508.13048
Policy Entropy: 0.61295
Value Function Loss: 1.23785

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.07193
Policy Update Magnitude: 0.01917
Value Function Update Magnitude: 0.03758

Collected Steps per Second: 24,666.03300
Overall Steps per Second: 16,757.62365

Timestep Collection Time: 2.02757
Timestep Consumption Time: 0.95687
PPO Batch Consumption Time: 0.11075
Total Iteration Time: 2.98443

Cumulative Model Updates: 7,949
Cumulative Timesteps: 132,642,610

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 132642610...
Checkpoint 132642610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319.99690
Policy Entropy: 0.59477
Value Function Loss: 1.31540

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06832
Policy Update Magnitude: 0.01758
Value Function Update Magnitude: 0.03962

Collected Steps per Second: 24,490.33926
Overall Steps per Second: 16,816.86909

Timestep Collection Time: 2.04178
Timestep Consumption Time: 0.93166
PPO Batch Consumption Time: 0.10312
Total Iteration Time: 2.97344

Cumulative Model Updates: 7,952
Cumulative Timesteps: 132,692,614

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,269.69764
Policy Entropy: 0.59423
Value Function Loss: 1.26038

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.06714
Policy Update Magnitude: 0.01758
Value Function Update Magnitude: 0.03163

Collected Steps per Second: 24,414.93160
Overall Steps per Second: 16,721.53581

Timestep Collection Time: 2.04842
Timestep Consumption Time: 0.94246
PPO Batch Consumption Time: 0.10972
Total Iteration Time: 2.99087

Cumulative Model Updates: 7,955
Cumulative Timesteps: 132,742,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 132742626...
Checkpoint 132742626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,514.58336
Policy Entropy: 0.59138
Value Function Loss: 1.31204

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06780
Policy Update Magnitude: 0.02031
Value Function Update Magnitude: 0.03016

Collected Steps per Second: 24,151.05111
Overall Steps per Second: 16,758.43851

Timestep Collection Time: 2.07121
Timestep Consumption Time: 0.91367
PPO Batch Consumption Time: 0.11017
Total Iteration Time: 2.98488

Cumulative Model Updates: 7,958
Cumulative Timesteps: 132,792,648

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.84472
Policy Entropy: 0.60210
Value Function Loss: 1.22745

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.06771
Policy Update Magnitude: 0.01875
Value Function Update Magnitude: 0.02497

Collected Steps per Second: 24,368.40436
Overall Steps per Second: 16,724.97265

Timestep Collection Time: 2.05233
Timestep Consumption Time: 0.93793
PPO Batch Consumption Time: 0.11916
Total Iteration Time: 2.99026

Cumulative Model Updates: 7,961
Cumulative Timesteps: 132,842,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 132842660...
Checkpoint 132842660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,477.65214
Policy Entropy: 0.60431
Value Function Loss: 1.22739

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06873
Policy Update Magnitude: 0.01914
Value Function Update Magnitude: 0.02452

Collected Steps per Second: 24,272.26044
Overall Steps per Second: 16,764.93135

Timestep Collection Time: 2.06071
Timestep Consumption Time: 0.92278
PPO Batch Consumption Time: 0.10900
Total Iteration Time: 2.98349

Cumulative Model Updates: 7,964
Cumulative Timesteps: 132,892,678

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,468.57610
Policy Entropy: 0.61203
Value Function Loss: 1.14674

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.06532
Policy Update Magnitude: 0.01748
Value Function Update Magnitude: 0.02418

Collected Steps per Second: 24,429.11308
Overall Steps per Second: 16,719.29498

Timestep Collection Time: 2.04739
Timestep Consumption Time: 0.94412
PPO Batch Consumption Time: 0.11850
Total Iteration Time: 2.99151

Cumulative Model Updates: 7,967
Cumulative Timesteps: 132,942,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 132942694...
Checkpoint 132942694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,063.09637
Policy Entropy: 0.61029
Value Function Loss: 1.21174

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06820
Policy Update Magnitude: 0.01768
Value Function Update Magnitude: 0.02429

Collected Steps per Second: 24,391.63595
Overall Steps per Second: 16,690.22843

Timestep Collection Time: 2.04997
Timestep Consumption Time: 0.94592
PPO Batch Consumption Time: 0.10715
Total Iteration Time: 2.99588

Cumulative Model Updates: 7,970
Cumulative Timesteps: 132,992,696

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,105.72975
Policy Entropy: 0.59919
Value Function Loss: 1.21962

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.06552
Policy Update Magnitude: 0.01806
Value Function Update Magnitude: 0.02609

Collected Steps per Second: 24,797.29945
Overall Steps per Second: 16,783.70966

Timestep Collection Time: 2.01740
Timestep Consumption Time: 0.96323
PPO Batch Consumption Time: 0.11945
Total Iteration Time: 2.98063

Cumulative Model Updates: 7,973
Cumulative Timesteps: 133,042,722

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 133042722...
Checkpoint 133042722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,408.99191
Policy Entropy: 0.58905
Value Function Loss: 1.24363

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.06650
Policy Update Magnitude: 0.01835
Value Function Update Magnitude: 0.02674

Collected Steps per Second: 16,976.18239
Overall Steps per Second: 13,556.56965

Timestep Collection Time: 2.94778
Timestep Consumption Time: 0.74357
PPO Batch Consumption Time: 0.02993
Total Iteration Time: 3.69135

Cumulative Model Updates: 7,976
Cumulative Timesteps: 133,092,764

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,913.45603
Policy Entropy: 0.59372
Value Function Loss: 1.19347

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.06621
Policy Update Magnitude: 0.01759
Value Function Update Magnitude: 0.05157

Collected Steps per Second: 23,495.82987
Overall Steps per Second: 17,914.55453

Timestep Collection Time: 2.12804
Timestep Consumption Time: 0.66299
PPO Batch Consumption Time: 0.02832
Total Iteration Time: 2.79103

Cumulative Model Updates: 7,979
Cumulative Timesteps: 133,142,764

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 133142764...
Checkpoint 133142764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,922.31495
Policy Entropy: 0.59690
Value Function Loss: 1.17860

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.06647
Policy Update Magnitude: 0.01822
Value Function Update Magnitude: 0.05581

Collected Steps per Second: 22,803.53628
Overall Steps per Second: 16,868.77682

Timestep Collection Time: 2.19299
Timestep Consumption Time: 0.77154
PPO Batch Consumption Time: 0.07724
Total Iteration Time: 2.96453

Cumulative Model Updates: 7,982
Cumulative Timesteps: 133,192,772

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,505.18978
Policy Entropy: 0.61101
Value Function Loss: 1.14367

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.06175
Policy Update Magnitude: 0.01734
Value Function Update Magnitude: 0.06098

Collected Steps per Second: 22,725.09853
Overall Steps per Second: 16,053.46277

Timestep Collection Time: 2.20144
Timestep Consumption Time: 0.91489
PPO Batch Consumption Time: 0.11024
Total Iteration Time: 3.11634

Cumulative Model Updates: 7,985
Cumulative Timesteps: 133,242,800

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 133242800...
Checkpoint 133242800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,136.18127
Policy Entropy: 0.60998
Value Function Loss: 1.15293

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.06610
Policy Update Magnitude: 0.01918
Value Function Update Magnitude: 0.04786

Collected Steps per Second: 23,230.51821
Overall Steps per Second: 16,726.86111

Timestep Collection Time: 2.15286
Timestep Consumption Time: 0.83706
PPO Batch Consumption Time: 0.10173
Total Iteration Time: 2.98992

Cumulative Model Updates: 7,988
Cumulative Timesteps: 133,292,812

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,303.89669
Policy Entropy: 0.62569
Value Function Loss: 1.11385

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.06180
Policy Update Magnitude: 0.01773
Value Function Update Magnitude: 0.05056

Collected Steps per Second: 23,333.10536
Overall Steps per Second: 16,712.29781

Timestep Collection Time: 2.14356
Timestep Consumption Time: 0.84920
PPO Batch Consumption Time: 0.09857
Total Iteration Time: 2.99277

Cumulative Model Updates: 7,991
Cumulative Timesteps: 133,342,828

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 133342828...
Checkpoint 133342828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,805.28246
Policy Entropy: 0.62070
Value Function Loss: 1.19395

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.06663
Policy Update Magnitude: 0.01966
Value Function Update Magnitude: 0.04690

Collected Steps per Second: 23,297.96858
Overall Steps per Second: 16,752.51970

Timestep Collection Time: 2.14697
Timestep Consumption Time: 0.83885
PPO Batch Consumption Time: 0.09727
Total Iteration Time: 2.98582

Cumulative Model Updates: 7,994
Cumulative Timesteps: 133,392,848

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.31420
Policy Entropy: 0.61661
Value Function Loss: 1.19244

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.06459
Policy Update Magnitude: 0.01996
Value Function Update Magnitude: 0.03769

Collected Steps per Second: 23,555.92299
Overall Steps per Second: 16,666.77167

Timestep Collection Time: 2.12261
Timestep Consumption Time: 0.87737
PPO Batch Consumption Time: 0.08844
Total Iteration Time: 2.99998

Cumulative Model Updates: 7,997
Cumulative Timesteps: 133,442,848

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 133442848...
Checkpoint 133442848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,531.21242
Policy Entropy: 0.60792
Value Function Loss: 1.22266

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06778
Policy Update Magnitude: 0.01874
Value Function Update Magnitude: 0.05712

Collected Steps per Second: 24,392.30340
Overall Steps per Second: 16,805.23209

Timestep Collection Time: 2.04999
Timestep Consumption Time: 0.92551
PPO Batch Consumption Time: 0.10113
Total Iteration Time: 2.97550

Cumulative Model Updates: 8,000
Cumulative Timesteps: 133,492,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,818.03286
Policy Entropy: 0.61495
Value Function Loss: 1.13997

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.07225
Policy Update Magnitude: 0.01938
Value Function Update Magnitude: 0.06729

Collected Steps per Second: 24,394.95316
Overall Steps per Second: 16,647.22748

Timestep Collection Time: 2.04993
Timestep Consumption Time: 0.95405
PPO Batch Consumption Time: 0.10584
Total Iteration Time: 3.00398

Cumulative Model Updates: 8,003
Cumulative Timesteps: 133,542,860

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 133542860...
Checkpoint 133542860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,057.36972
Policy Entropy: 0.61730
Value Function Loss: 1.12230

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.06481
Policy Update Magnitude: 0.01942
Value Function Update Magnitude: 0.06917

Collected Steps per Second: 22,984.81786
Overall Steps per Second: 17,188.02449

Timestep Collection Time: 2.17674
Timestep Consumption Time: 0.73412
PPO Batch Consumption Time: 0.03053
Total Iteration Time: 2.91086

Cumulative Model Updates: 8,006
Cumulative Timesteps: 133,592,892

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,265.96545
Policy Entropy: 0.61364
Value Function Loss: 1.14235

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06768
Policy Update Magnitude: 0.01761
Value Function Update Magnitude: 0.08183

Collected Steps per Second: 23,431.05409
Overall Steps per Second: 16,378.80880

Timestep Collection Time: 2.13435
Timestep Consumption Time: 0.91899
PPO Batch Consumption Time: 0.10089
Total Iteration Time: 3.05334

Cumulative Model Updates: 8,009
Cumulative Timesteps: 133,642,902

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 133642902...
Checkpoint 133642902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,419.97326
Policy Entropy: 0.60835
Value Function Loss: 1.18700

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.06059
Policy Update Magnitude: 0.01800
Value Function Update Magnitude: 0.08044

Collected Steps per Second: 23,951.94901
Overall Steps per Second: 16,736.25272

Timestep Collection Time: 2.08843
Timestep Consumption Time: 0.90041
PPO Batch Consumption Time: 0.09365
Total Iteration Time: 2.98884

Cumulative Model Updates: 8,012
Cumulative Timesteps: 133,692,924

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,197.61964
Policy Entropy: 0.60422
Value Function Loss: 1.18410

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.06008
Policy Update Magnitude: 0.01874
Value Function Update Magnitude: 0.05174

Collected Steps per Second: 24,633.28012
Overall Steps per Second: 16,799.70124

Timestep Collection Time: 2.03107
Timestep Consumption Time: 0.94707
PPO Batch Consumption Time: 0.11082
Total Iteration Time: 2.97815

Cumulative Model Updates: 8,015
Cumulative Timesteps: 133,742,956

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 133742956...
Checkpoint 133742956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983.83660
Policy Entropy: 0.60545
Value Function Loss: 1.17651

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05945
Policy Update Magnitude: 0.01931
Value Function Update Magnitude: 0.04570

Collected Steps per Second: 24,072.23132
Overall Steps per Second: 16,691.74544

Timestep Collection Time: 2.07791
Timestep Consumption Time: 0.91878
PPO Batch Consumption Time: 0.10075
Total Iteration Time: 2.99669

Cumulative Model Updates: 8,018
Cumulative Timesteps: 133,792,976

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,299.87159
Policy Entropy: 0.60743
Value Function Loss: 1.14800

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.06302
Policy Update Magnitude: 0.01905
Value Function Update Magnitude: 0.04496

Collected Steps per Second: 24,454.24956
Overall Steps per Second: 16,726.63319

Timestep Collection Time: 2.04578
Timestep Consumption Time: 0.94514
PPO Batch Consumption Time: 0.10277
Total Iteration Time: 2.99092

Cumulative Model Updates: 8,021
Cumulative Timesteps: 133,843,004

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 133843004...
Checkpoint 133843004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,405.74731
Policy Entropy: 0.60053
Value Function Loss: 1.19457

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.06273
Policy Update Magnitude: 0.01971
Value Function Update Magnitude: 0.04377

Collected Steps per Second: 24,087.60769
Overall Steps per Second: 16,739.48692

Timestep Collection Time: 2.07642
Timestep Consumption Time: 0.91148
PPO Batch Consumption Time: 0.09857
Total Iteration Time: 2.98791

Cumulative Model Updates: 8,024
Cumulative Timesteps: 133,893,020

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,552.90939
Policy Entropy: 0.60435
Value Function Loss: 1.17031

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.06028
Policy Update Magnitude: 0.02058
Value Function Update Magnitude: 0.04449

Collected Steps per Second: 24,310.14355
Overall Steps per Second: 16,722.91894

Timestep Collection Time: 2.05791
Timestep Consumption Time: 0.93368
PPO Batch Consumption Time: 0.09928
Total Iteration Time: 2.99158

Cumulative Model Updates: 8,027
Cumulative Timesteps: 133,943,048

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 133943048...
Checkpoint 133943048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,182.94604
Policy Entropy: 0.60283
Value Function Loss: 1.19561

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.06415
Policy Update Magnitude: 0.02007
Value Function Update Magnitude: 0.05774

Collected Steps per Second: 23,996.68912
Overall Steps per Second: 16,730.45942

Timestep Collection Time: 2.08404
Timestep Consumption Time: 0.90512
PPO Batch Consumption Time: 0.08702
Total Iteration Time: 2.98916

Cumulative Model Updates: 8,030
Cumulative Timesteps: 133,993,058

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,647.51945
Policy Entropy: 0.62038
Value Function Loss: 1.14259

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.06359
Policy Update Magnitude: 0.02046
Value Function Update Magnitude: 0.05896

Collected Steps per Second: 24,309.43094
Overall Steps per Second: 17,085.05136

Timestep Collection Time: 2.05714
Timestep Consumption Time: 0.86986
PPO Batch Consumption Time: 0.08958
Total Iteration Time: 2.92700

Cumulative Model Updates: 8,033
Cumulative Timesteps: 134,043,066

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 134043066...
Checkpoint 134043066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,073.19120
Policy Entropy: 0.61555
Value Function Loss: 1.14867

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.06264
Policy Update Magnitude: 0.01903
Value Function Update Magnitude: 0.05003

Collected Steps per Second: 23,977.46789
Overall Steps per Second: 18,141.44159

Timestep Collection Time: 2.08613
Timestep Consumption Time: 0.67110
PPO Batch Consumption Time: 0.02859
Total Iteration Time: 2.75722

Cumulative Model Updates: 8,036
Cumulative Timesteps: 134,093,086

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,479.44765
Policy Entropy: 0.61477
Value Function Loss: 1.15447

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.05772
Policy Update Magnitude: 0.01936
Value Function Update Magnitude: 0.04370

Collected Steps per Second: 22,235.05911
Overall Steps per Second: 16,180.72304

Timestep Collection Time: 2.24942
Timestep Consumption Time: 0.84166
PPO Batch Consumption Time: 0.08511
Total Iteration Time: 3.09109

Cumulative Model Updates: 8,039
Cumulative Timesteps: 134,143,102

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 134143102...
Checkpoint 134143102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,528.03583
Policy Entropy: 0.60353
Value Function Loss: 1.18898

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.06050
Policy Update Magnitude: 0.02143
Value Function Update Magnitude: 0.04212

Collected Steps per Second: 23,635.57945
Overall Steps per Second: 17,792.71013

Timestep Collection Time: 2.11639
Timestep Consumption Time: 0.69499
PPO Batch Consumption Time: 0.03169
Total Iteration Time: 2.81138

Cumulative Model Updates: 8,042
Cumulative Timesteps: 134,193,124

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,804.88712
Policy Entropy: 0.61235
Value Function Loss: 1.16040

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05961
Policy Update Magnitude: 0.02014
Value Function Update Magnitude: 0.03994

Collected Steps per Second: 22,857.17106
Overall Steps per Second: 17,108.51638

Timestep Collection Time: 2.18811
Timestep Consumption Time: 0.73523
PPO Batch Consumption Time: 0.05310
Total Iteration Time: 2.92334

Cumulative Model Updates: 8,045
Cumulative Timesteps: 134,243,138

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 134243138...
Checkpoint 134243138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.38167
Policy Entropy: 0.60486
Value Function Loss: 1.18790

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06802
Policy Update Magnitude: 0.02143
Value Function Update Magnitude: 0.03565

Collected Steps per Second: 22,732.93958
Overall Steps per Second: 16,399.52825

Timestep Collection Time: 2.20060
Timestep Consumption Time: 0.84986
PPO Batch Consumption Time: 0.08598
Total Iteration Time: 3.05045

Cumulative Model Updates: 8,048
Cumulative Timesteps: 134,293,164

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.53143
Policy Entropy: 0.60744
Value Function Loss: 1.13444

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.07093
Policy Update Magnitude: 0.02143
Value Function Update Magnitude: 0.04179

Collected Steps per Second: 24,345.01245
Overall Steps per Second: 17,712.69261

Timestep Collection Time: 2.05496
Timestep Consumption Time: 0.76946
PPO Batch Consumption Time: 0.06089
Total Iteration Time: 2.82442

Cumulative Model Updates: 8,051
Cumulative Timesteps: 134,343,192

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 134343192...
Checkpoint 134343192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,684.25500
Policy Entropy: 0.59788
Value Function Loss: 1.14569

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.07316
Policy Update Magnitude: 0.02043
Value Function Update Magnitude: 0.03985

Collected Steps per Second: 20,316.13214
Overall Steps per Second: 15,910.78764

Timestep Collection Time: 2.46248
Timestep Consumption Time: 0.68181
PPO Batch Consumption Time: 0.03043
Total Iteration Time: 3.14428

Cumulative Model Updates: 8,054
Cumulative Timesteps: 134,393,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.59555
Policy Entropy: 0.60869
Value Function Loss: 1.09154

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.07464
Policy Update Magnitude: 0.01929
Value Function Update Magnitude: 0.03547

Collected Steps per Second: 23,780.65299
Overall Steps per Second: 16,844.73535

Timestep Collection Time: 2.10263
Timestep Consumption Time: 0.86577
PPO Batch Consumption Time: 0.11009
Total Iteration Time: 2.96841

Cumulative Model Updates: 8,057
Cumulative Timesteps: 134,443,222

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 134443222...
Checkpoint 134443222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,974.25752
Policy Entropy: 0.61033
Value Function Loss: 1.10542

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.07221
Policy Update Magnitude: 0.02013
Value Function Update Magnitude: 0.03427

Collected Steps per Second: 22,771.09426
Overall Steps per Second: 17,367.48049

Timestep Collection Time: 2.19594
Timestep Consumption Time: 0.68323
PPO Batch Consumption Time: 0.03392
Total Iteration Time: 2.87917

Cumulative Model Updates: 8,060
Cumulative Timesteps: 134,493,226

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,203.94362
Policy Entropy: 0.60975
Value Function Loss: 1.09324

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.07463
Policy Update Magnitude: 0.02112
Value Function Update Magnitude: 0.03187

Collected Steps per Second: 21,657.90271
Overall Steps per Second: 16,988.43214

Timestep Collection Time: 2.31001
Timestep Consumption Time: 0.63493
PPO Batch Consumption Time: 0.02966
Total Iteration Time: 2.94495

Cumulative Model Updates: 8,063
Cumulative Timesteps: 134,543,256

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 134543256...
Checkpoint 134543256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.93231
Policy Entropy: 0.60944
Value Function Loss: 1.09508

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.07257
Policy Update Magnitude: 0.02117
Value Function Update Magnitude: 0.03700

Collected Steps per Second: 23,234.16123
Overall Steps per Second: 18,086.42342

Timestep Collection Time: 2.15226
Timestep Consumption Time: 0.61257
PPO Batch Consumption Time: 0.02951
Total Iteration Time: 2.76484

Cumulative Model Updates: 8,066
Cumulative Timesteps: 134,593,262

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,505.76424
Policy Entropy: 0.60678
Value Function Loss: 1.11591

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.07656
Policy Update Magnitude: 0.02127
Value Function Update Magnitude: 0.03513

Collected Steps per Second: 23,330.40724
Overall Steps per Second: 16,870.09554

Timestep Collection Time: 2.14450
Timestep Consumption Time: 0.82122
PPO Batch Consumption Time: 0.08823
Total Iteration Time: 2.96572

Cumulative Model Updates: 8,069
Cumulative Timesteps: 134,643,294

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 134643294...
Checkpoint 134643294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,896.35900
Policy Entropy: 0.61141
Value Function Loss: 1.13429

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.07489
Policy Update Magnitude: 0.02016
Value Function Update Magnitude: 0.03993

Collected Steps per Second: 24,493.24655
Overall Steps per Second: 17,652.93613

Timestep Collection Time: 2.04162
Timestep Consumption Time: 0.79111
PPO Batch Consumption Time: 0.06148
Total Iteration Time: 2.83273

Cumulative Model Updates: 8,072
Cumulative Timesteps: 134,693,300

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,012.19788
Policy Entropy: 0.61770
Value Function Loss: 1.15659

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.07382
Policy Update Magnitude: 0.01958
Value Function Update Magnitude: 0.03758

Collected Steps per Second: 21,565.66560
Overall Steps per Second: 15,055.30280

Timestep Collection Time: 2.31943
Timestep Consumption Time: 1.00299
PPO Batch Consumption Time: 0.12660
Total Iteration Time: 3.32242

Cumulative Model Updates: 8,075
Cumulative Timesteps: 134,743,320

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 134743320...
Checkpoint 134743320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.94660
Policy Entropy: 0.62111
Value Function Loss: 1.13292

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.07386
Policy Update Magnitude: 0.02074
Value Function Update Magnitude: 0.03346

Collected Steps per Second: 24,396.73839
Overall Steps per Second: 16,700.07115

Timestep Collection Time: 2.05052
Timestep Consumption Time: 0.94504
PPO Batch Consumption Time: 0.10751
Total Iteration Time: 2.99556

Cumulative Model Updates: 8,078
Cumulative Timesteps: 134,793,346

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,382.46642
Policy Entropy: 0.61582
Value Function Loss: 1.09966

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.07347
Policy Update Magnitude: 0.01973
Value Function Update Magnitude: 0.03445

Collected Steps per Second: 24,563.15539
Overall Steps per Second: 16,755.76745

Timestep Collection Time: 2.03630
Timestep Consumption Time: 0.94882
PPO Batch Consumption Time: 0.10715
Total Iteration Time: 2.98512

Cumulative Model Updates: 8,081
Cumulative Timesteps: 134,843,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 134843364...
Checkpoint 134843364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,320.67252
Policy Entropy: 0.60929
Value Function Loss: 1.05535

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.07014
Policy Update Magnitude: 0.01933
Value Function Update Magnitude: 0.03758

Collected Steps per Second: 24,150.95462
Overall Steps per Second: 16,707.50419

Timestep Collection Time: 2.07139
Timestep Consumption Time: 0.92284
PPO Batch Consumption Time: 0.10047
Total Iteration Time: 2.99422

Cumulative Model Updates: 8,084
Cumulative Timesteps: 134,893,390

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,361.57434
Policy Entropy: 0.61378
Value Function Loss: 1.06070

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06937
Policy Update Magnitude: 0.01928
Value Function Update Magnitude: 0.03340

Collected Steps per Second: 24,640.99984
Overall Steps per Second: 16,784.31978

Timestep Collection Time: 2.02971
Timestep Consumption Time: 0.95010
PPO Batch Consumption Time: 0.11109
Total Iteration Time: 2.97980

Cumulative Model Updates: 8,087
Cumulative Timesteps: 134,943,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 134943404...
Checkpoint 134943404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,620.05425
Policy Entropy: 0.62091
Value Function Loss: 1.06459

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.06660
Policy Update Magnitude: 0.01806
Value Function Update Magnitude: 0.03302

Collected Steps per Second: 24,328.76901
Overall Steps per Second: 16,713.08522

Timestep Collection Time: 2.05608
Timestep Consumption Time: 0.93690
PPO Batch Consumption Time: 0.10620
Total Iteration Time: 2.99298

Cumulative Model Updates: 8,090
Cumulative Timesteps: 134,993,426

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,388.05244
Policy Entropy: 0.62330
Value Function Loss: 1.08307

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04716
Policy Update Magnitude: 0.01586
Value Function Update Magnitude: 0.03117

Collected Steps per Second: 24,375.00070
Overall Steps per Second: 16,675.09891

Timestep Collection Time: 2.05177
Timestep Consumption Time: 0.94743
PPO Batch Consumption Time: 0.10366
Total Iteration Time: 2.99920

Cumulative Model Updates: 8,093
Cumulative Timesteps: 135,043,438

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 135043438...
Checkpoint 135043438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,871.09354
Policy Entropy: 0.61632
Value Function Loss: 1.08226

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03851
Policy Update Magnitude: 0.01940
Value Function Update Magnitude: 0.02837

Collected Steps per Second: 22,714.67276
Overall Steps per Second: 15,647.75350

Timestep Collection Time: 2.20148
Timestep Consumption Time: 0.99425
PPO Batch Consumption Time: 0.11528
Total Iteration Time: 3.19573

Cumulative Model Updates: 8,096
Cumulative Timesteps: 135,093,444

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,999.05318
Policy Entropy: 0.60575
Value Function Loss: 1.08194

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.03021
Policy Update Magnitude: 0.01991
Value Function Update Magnitude: 0.03917

Collected Steps per Second: 22,637.86316
Overall Steps per Second: 16,161.88089

Timestep Collection Time: 2.20975
Timestep Consumption Time: 0.88544
PPO Batch Consumption Time: 0.07291
Total Iteration Time: 3.09518

Cumulative Model Updates: 8,099
Cumulative Timesteps: 135,143,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 135143468...
Checkpoint 135143468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,422.69945
Policy Entropy: 0.60011
Value Function Loss: 1.04692

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02549
Policy Update Magnitude: 0.02522
Value Function Update Magnitude: 0.03559

Collected Steps per Second: 20,017.54726
Overall Steps per Second: 14,453.57067

Timestep Collection Time: 2.49931
Timestep Consumption Time: 0.96212
PPO Batch Consumption Time: 0.10415
Total Iteration Time: 3.46143

Cumulative Model Updates: 8,102
Cumulative Timesteps: 135,193,498

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,269.82807
Policy Entropy: 0.60154
Value Function Loss: 1.05755

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02718
Policy Update Magnitude: 0.02512
Value Function Update Magnitude: 0.03647

Collected Steps per Second: 23,857.65641
Overall Steps per Second: 17,149.20190

Timestep Collection Time: 2.09585
Timestep Consumption Time: 0.81986
PPO Batch Consumption Time: 0.06091
Total Iteration Time: 2.91570

Cumulative Model Updates: 8,105
Cumulative Timesteps: 135,243,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 135243500...
Checkpoint 135243500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,849.55193
Policy Entropy: 0.60252
Value Function Loss: 1.06861

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01848
Policy Update Magnitude: 0.02926
Value Function Update Magnitude: 0.03363

Collected Steps per Second: 24,244.04267
Overall Steps per Second: 17,633.73140

Timestep Collection Time: 2.06261
Timestep Consumption Time: 0.77321
PPO Batch Consumption Time: 0.06096
Total Iteration Time: 2.83581

Cumulative Model Updates: 8,108
Cumulative Timesteps: 135,293,506

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,793.95152
Policy Entropy: 0.60354
Value Function Loss: 1.11256

Mean KL Divergence: 0.00109
SB3 Clip Fraction: 0.00749
Policy Update Magnitude: 0.03557
Value Function Update Magnitude: 0.03477

Collected Steps per Second: 24,335.51708
Overall Steps per Second: 16,643.78078

Timestep Collection Time: 2.05584
Timestep Consumption Time: 0.95008
PPO Batch Consumption Time: 0.11387
Total Iteration Time: 3.00593

Cumulative Model Updates: 8,111
Cumulative Timesteps: 135,343,536

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 135343536...
Checkpoint 135343536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,527.55914
Policy Entropy: 0.59422
Value Function Loss: 1.14301

Mean KL Divergence: 0.00153
SB3 Clip Fraction: 0.01395
Policy Update Magnitude: 0.03562
Value Function Update Magnitude: 0.03425

Collected Steps per Second: 23,899.16701
Overall Steps per Second: 16,690.14229

Timestep Collection Time: 2.09338
Timestep Consumption Time: 0.90420
PPO Batch Consumption Time: 0.10224
Total Iteration Time: 2.99758

Cumulative Model Updates: 8,114
Cumulative Timesteps: 135,393,566

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,073.45121
Policy Entropy: 0.59920
Value Function Loss: 1.10089

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01269
Policy Update Magnitude: 0.03654
Value Function Update Magnitude: 0.05543

Collected Steps per Second: 24,358.87838
Overall Steps per Second: 16,790.01400

Timestep Collection Time: 2.05313
Timestep Consumption Time: 0.92554
PPO Batch Consumption Time: 0.10950
Total Iteration Time: 2.97868

Cumulative Model Updates: 8,117
Cumulative Timesteps: 135,443,578

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 135443578...
Checkpoint 135443578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,615.07184
Policy Entropy: 0.60521
Value Function Loss: 1.10923

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02653
Policy Update Magnitude: 0.03607
Value Function Update Magnitude: 0.05054

Collected Steps per Second: 24,380.44652
Overall Steps per Second: 16,739.88427

Timestep Collection Time: 2.05107
Timestep Consumption Time: 0.93617
PPO Batch Consumption Time: 0.11355
Total Iteration Time: 2.98724

Cumulative Model Updates: 8,120
Cumulative Timesteps: 135,493,584

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,874.01075
Policy Entropy: 0.59970
Value Function Loss: 1.09780

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.02138
Policy Update Magnitude: 0.03126
Value Function Update Magnitude: 0.04543

Collected Steps per Second: 24,279.27603
Overall Steps per Second: 17,566.00279

Timestep Collection Time: 2.06028
Timestep Consumption Time: 0.78738
PPO Batch Consumption Time: 0.08110
Total Iteration Time: 2.84766

Cumulative Model Updates: 8,123
Cumulative Timesteps: 135,543,606

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 135543606...
Checkpoint 135543606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.13740
Policy Entropy: 0.60634
Value Function Loss: 1.11340

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02797
Policy Update Magnitude: 0.02997
Value Function Update Magnitude: 0.04039

Collected Steps per Second: 22,265.73035
Overall Steps per Second: 16,002.33343

Timestep Collection Time: 2.24668
Timestep Consumption Time: 0.87936
PPO Batch Consumption Time: 0.11464
Total Iteration Time: 3.12604

Cumulative Model Updates: 8,126
Cumulative Timesteps: 135,593,630

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,076.74256
Policy Entropy: 0.60589
Value Function Loss: 1.07872

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03670
Policy Update Magnitude: 0.02857
Value Function Update Magnitude: 0.03875

Collected Steps per Second: 23,878.74071
Overall Steps per Second: 16,734.06152

Timestep Collection Time: 2.09500
Timestep Consumption Time: 0.89447
PPO Batch Consumption Time: 0.12295
Total Iteration Time: 2.98947

Cumulative Model Updates: 8,129
Cumulative Timesteps: 135,643,656

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 135643656...
Checkpoint 135643656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.29983
Policy Entropy: 0.61858
Value Function Loss: 1.00441

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.03103
Policy Update Magnitude: 0.02617
Value Function Update Magnitude: 0.03561

Collected Steps per Second: 23,423.20171
Overall Steps per Second: 16,666.96929

Timestep Collection Time: 2.13575
Timestep Consumption Time: 0.86576
PPO Batch Consumption Time: 0.09975
Total Iteration Time: 3.00151

Cumulative Model Updates: 8,132
Cumulative Timesteps: 135,693,682

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,186.23834
Policy Entropy: 0.62012
Value Function Loss: 0.99077

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02207
Policy Update Magnitude: 0.02426
Value Function Update Magnitude: 0.03747

Collected Steps per Second: 24,442.35261
Overall Steps per Second: 16,762.17755

Timestep Collection Time: 2.04563
Timestep Consumption Time: 0.93728
PPO Batch Consumption Time: 0.10544
Total Iteration Time: 2.98291

Cumulative Model Updates: 8,135
Cumulative Timesteps: 135,743,682

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 135743682...
Checkpoint 135743682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,863.03739
Policy Entropy: 0.61645
Value Function Loss: 1.00667

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.02007
Policy Update Magnitude: 0.02410
Value Function Update Magnitude: 0.03747

Collected Steps per Second: 24,428.51684
Overall Steps per Second: 16,726.13932

Timestep Collection Time: 2.04736
Timestep Consumption Time: 0.94281
PPO Batch Consumption Time: 0.11106
Total Iteration Time: 2.99017

Cumulative Model Updates: 8,138
Cumulative Timesteps: 135,793,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,160.21387
Policy Entropy: 0.61636
Value Function Loss: 1.04386

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03816
Policy Update Magnitude: 0.02477
Value Function Update Magnitude: 0.04688

Collected Steps per Second: 23,758.31067
Overall Steps per Second: 16,662.86326

Timestep Collection Time: 2.10646
Timestep Consumption Time: 0.89698
PPO Batch Consumption Time: 0.09541
Total Iteration Time: 3.00345

Cumulative Model Updates: 8,141
Cumulative Timesteps: 135,843,742

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 135843742...
Checkpoint 135843742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,447.89919
Policy Entropy: 0.61595
Value Function Loss: 1.07617

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03655
Policy Update Magnitude: 0.02288
Value Function Update Magnitude: 0.04643

Collected Steps per Second: 24,048.58038
Overall Steps per Second: 16,776.07718

Timestep Collection Time: 2.07937
Timestep Consumption Time: 0.90142
PPO Batch Consumption Time: 0.09627
Total Iteration Time: 2.98079

Cumulative Model Updates: 8,144
Cumulative Timesteps: 135,893,748

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,785.82906
Policy Entropy: 0.62325
Value Function Loss: 1.11851

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04480
Policy Update Magnitude: 0.02294
Value Function Update Magnitude: 0.04408

Collected Steps per Second: 24,605.59453
Overall Steps per Second: 16,796.46301

Timestep Collection Time: 2.03295
Timestep Consumption Time: 0.94517
PPO Batch Consumption Time: 0.11052
Total Iteration Time: 2.97813

Cumulative Model Updates: 8,147
Cumulative Timesteps: 135,943,770

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 135943770...
Checkpoint 135943770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,082.62190
Policy Entropy: 0.62659
Value Function Loss: 1.10757

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02180
Policy Update Magnitude: 0.02212
Value Function Update Magnitude: 0.03696

Collected Steps per Second: 24,149.00149
Overall Steps per Second: 16,708.88722

Timestep Collection Time: 2.07056
Timestep Consumption Time: 0.92198
PPO Batch Consumption Time: 0.10468
Total Iteration Time: 2.99254

Cumulative Model Updates: 8,150
Cumulative Timesteps: 135,993,772

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,332.50629
Policy Entropy: 0.62490
Value Function Loss: 1.08088

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02501
Policy Update Magnitude: 0.02459
Value Function Update Magnitude: 0.03257

Collected Steps per Second: 24,213.01764
Overall Steps per Second: 16,703.29632

Timestep Collection Time: 2.06608
Timestep Consumption Time: 0.92890
PPO Batch Consumption Time: 0.10276
Total Iteration Time: 2.99498

Cumulative Model Updates: 8,153
Cumulative Timesteps: 136,043,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 136043798...
Checkpoint 136043798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,126.33645
Policy Entropy: 0.62263
Value Function Loss: 1.08177

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03145
Policy Update Magnitude: 0.02537
Value Function Update Magnitude: 0.03594

Collected Steps per Second: 24,355.92865
Overall Steps per Second: 16,761.48915

Timestep Collection Time: 2.05363
Timestep Consumption Time: 0.93048
PPO Batch Consumption Time: 0.10704
Total Iteration Time: 2.98410

Cumulative Model Updates: 8,156
Cumulative Timesteps: 136,093,816

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,310.27154
Policy Entropy: 0.61808
Value Function Loss: 1.06708

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03618
Policy Update Magnitude: 0.02306
Value Function Update Magnitude: 0.02578

Collected Steps per Second: 24,229.69256
Overall Steps per Second: 16,725.25009

Timestep Collection Time: 2.06367
Timestep Consumption Time: 0.92595
PPO Batch Consumption Time: 0.10428
Total Iteration Time: 2.98961

Cumulative Model Updates: 8,159
Cumulative Timesteps: 136,143,818

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 136143818...
Checkpoint 136143818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,609.33271
Policy Entropy: 0.61975
Value Function Loss: 1.07212

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04493
Policy Update Magnitude: 0.02232
Value Function Update Magnitude: 0.04036

Collected Steps per Second: 23,773.51752
Overall Steps per Second: 16,561.94022

Timestep Collection Time: 2.10453
Timestep Consumption Time: 0.91638
PPO Batch Consumption Time: 0.08517
Total Iteration Time: 3.02090

Cumulative Model Updates: 8,162
Cumulative Timesteps: 136,193,850

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,373.04826
Policy Entropy: 0.61429
Value Function Loss: 1.08246

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02823
Policy Update Magnitude: 0.02203
Value Function Update Magnitude: 0.02992

Collected Steps per Second: 22,479.03774
Overall Steps per Second: 15,936.30882

Timestep Collection Time: 2.22429
Timestep Consumption Time: 0.91319
PPO Batch Consumption Time: 0.10054
Total Iteration Time: 3.13749

Cumulative Model Updates: 8,165
Cumulative Timesteps: 136,243,850

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 136243850...
Checkpoint 136243850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,945.14888
Policy Entropy: 0.62388
Value Function Loss: 1.10440

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02003
Policy Update Magnitude: 0.02475
Value Function Update Magnitude: 0.02584

Collected Steps per Second: 24,057.79180
Overall Steps per Second: 17,430.28253

Timestep Collection Time: 2.07924
Timestep Consumption Time: 0.79059
PPO Batch Consumption Time: 0.05914
Total Iteration Time: 2.86983

Cumulative Model Updates: 8,168
Cumulative Timesteps: 136,293,872

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,605.56633
Policy Entropy: 0.62707
Value Function Loss: 1.10364

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02280
Policy Update Magnitude: 0.02935
Value Function Update Magnitude: 0.02501

Collected Steps per Second: 20,831.54355
Overall Steps per Second: 14,997.88107

Timestep Collection Time: 2.40136
Timestep Consumption Time: 0.93405
PPO Batch Consumption Time: 0.10427
Total Iteration Time: 3.33540

Cumulative Model Updates: 8,171
Cumulative Timesteps: 136,343,896

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 136343896...
Checkpoint 136343896 saved!
