Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.14580
Policy Entropy: 3.31865
Value Function Loss: 0.00382

Mean KL Divergence: 0.00088
SB3 Clip Fraction: 0.00783
Policy Update Magnitude: 0.18574
Value Function Update Magnitude: 0.21045

Collected Steps per Second: 7,245.72346
Overall Steps per Second: 4,220.71798

Timestep Collection Time: 6.90200
Timestep Consumption Time: 4.94669
PPO Batch Consumption Time: 1.96770
Total Iteration Time: 11.84869

Cumulative Model Updates: 57,012
Cumulative Timesteps: 475,549,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767.91607
Policy Entropy: 3.30917
Value Function Loss: 0.00388

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02412
Policy Update Magnitude: 0.20356
Value Function Update Magnitude: 0.22178

Collected Steps per Second: 21,311.92556
Overall Steps per Second: 13,496.10513

Timestep Collection Time: 2.34676
Timestep Consumption Time: 1.35905
PPO Batch Consumption Time: 0.33907
Total Iteration Time: 3.70581

Cumulative Model Updates: 57,014
Cumulative Timesteps: 475,599,274

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 475599274...
Checkpoint 475599274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 929.64421
Policy Entropy: 3.32474
Value Function Loss: 0.00386

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.06417
Policy Update Magnitude: 0.39531
Value Function Update Magnitude: 0.42557

Collected Steps per Second: 21,739.75790
Overall Steps per Second: 11,883.57659

Timestep Collection Time: 2.30049
Timestep Consumption Time: 1.90801
PPO Batch Consumption Time: 0.30047
Total Iteration Time: 4.20850

Cumulative Model Updates: 57,018
Cumulative Timesteps: 475,649,286

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 996.10228
Policy Entropy: 3.32152
Value Function Loss: 0.00372

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07424
Policy Update Magnitude: 0.55718
Value Function Update Magnitude: 0.60224

Collected Steps per Second: 21,495.53211
Overall Steps per Second: 10,453.12890

Timestep Collection Time: 2.32634
Timestep Consumption Time: 2.45749
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.78383

Cumulative Model Updates: 57,024
Cumulative Timesteps: 475,699,292

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 475699292...
Checkpoint 475699292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 930.63236
Policy Entropy: 3.33437
Value Function Loss: 0.00359

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09120
Policy Update Magnitude: 0.53924
Value Function Update Magnitude: 0.57799

Collected Steps per Second: 22,564.49359
Overall Steps per Second: 10,622.41620

Timestep Collection Time: 2.21640
Timestep Consumption Time: 2.49175
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.70816

Cumulative Model Updates: 57,030
Cumulative Timesteps: 475,749,304

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 991.44111
Policy Entropy: 3.34312
Value Function Loss: 0.00356

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 0.53232
Value Function Update Magnitude: 0.55084

Collected Steps per Second: 21,865.55082
Overall Steps per Second: 10,594.42529

Timestep Collection Time: 2.28743
Timestep Consumption Time: 2.43354
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.72097

Cumulative Model Updates: 57,036
Cumulative Timesteps: 475,799,320

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 475799320...
Checkpoint 475799320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450.35461
Policy Entropy: 3.35284
Value Function Loss: 0.00350

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.12812
Policy Update Magnitude: 0.52231
Value Function Update Magnitude: 0.55577

Collected Steps per Second: 22,080.69830
Overall Steps per Second: 10,827.40964

Timestep Collection Time: 2.26496
Timestep Consumption Time: 2.35405
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.61902

Cumulative Model Updates: 57,042
Cumulative Timesteps: 475,849,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.47572
Policy Entropy: 3.34824
Value Function Loss: 0.00353

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12139
Policy Update Magnitude: 0.51879
Value Function Update Magnitude: 0.57789

Collected Steps per Second: 21,491.65153
Overall Steps per Second: 10,546.59891

Timestep Collection Time: 2.32825
Timestep Consumption Time: 2.41622
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.74447

Cumulative Model Updates: 57,048
Cumulative Timesteps: 475,899,370

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 475899370...
Checkpoint 475899370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.87877
Policy Entropy: 3.32855
Value Function Loss: 0.00349

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10280
Policy Update Magnitude: 0.52233
Value Function Update Magnitude: 0.60199

Collected Steps per Second: 21,802.81064
Overall Steps per Second: 10,657.80536

Timestep Collection Time: 2.29383
Timestep Consumption Time: 2.39869
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.69252

Cumulative Model Updates: 57,054
Cumulative Timesteps: 475,949,382

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.78310
Policy Entropy: 3.32235
Value Function Loss: 0.00344

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08677
Policy Update Magnitude: 0.52975
Value Function Update Magnitude: 0.59158

Collected Steps per Second: 21,513.47378
Overall Steps per Second: 10,406.49451

Timestep Collection Time: 2.32571
Timestep Consumption Time: 2.48225
PPO Batch Consumption Time: 0.29818
Total Iteration Time: 4.80796

Cumulative Model Updates: 57,060
Cumulative Timesteps: 475,999,416

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 475999416...
Checkpoint 475999416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935.13183
Policy Entropy: 3.32108
Value Function Loss: 0.00346

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.52185
Value Function Update Magnitude: 0.56963

Collected Steps per Second: 22,038.20617
Overall Steps per Second: 10,415.06808

Timestep Collection Time: 2.26897
Timestep Consumption Time: 2.53215
PPO Batch Consumption Time: 0.29565
Total Iteration Time: 4.80112

Cumulative Model Updates: 57,066
Cumulative Timesteps: 476,049,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 989.34475
Policy Entropy: 3.32462
Value Function Loss: 0.00350

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08051
Policy Update Magnitude: 0.51997
Value Function Update Magnitude: 0.57078

Collected Steps per Second: 22,631.50831
Overall Steps per Second: 10,658.89856

Timestep Collection Time: 2.21002
Timestep Consumption Time: 2.48240
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.69242

Cumulative Model Updates: 57,072
Cumulative Timesteps: 476,099,436

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 476099436...
Checkpoint 476099436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 836.29853
Policy Entropy: 3.32774
Value Function Loss: 0.00357

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08859
Policy Update Magnitude: 0.52834
Value Function Update Magnitude: 0.58985

Collected Steps per Second: 22,546.12326
Overall Steps per Second: 10,639.19497

Timestep Collection Time: 2.21821
Timestep Consumption Time: 2.48252
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.70073

Cumulative Model Updates: 57,078
Cumulative Timesteps: 476,149,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 979.43029
Policy Entropy: 3.33527
Value Function Loss: 0.00360

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08431
Policy Update Magnitude: 0.53079
Value Function Update Magnitude: 0.60233

Collected Steps per Second: 22,463.09448
Overall Steps per Second: 10,491.36166

Timestep Collection Time: 2.22587
Timestep Consumption Time: 2.53995
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.76583

Cumulative Model Updates: 57,084
Cumulative Timesteps: 476,199,448

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 476199448...
Checkpoint 476199448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634.48373
Policy Entropy: 3.34842
Value Function Loss: 0.00371

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.53229
Value Function Update Magnitude: 0.60585

Collected Steps per Second: 22,403.33290
Overall Steps per Second: 10,681.18928

Timestep Collection Time: 2.23306
Timestep Consumption Time: 2.45069
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.68375

Cumulative Model Updates: 57,090
Cumulative Timesteps: 476,249,476

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 722.44519
Policy Entropy: 3.33687
Value Function Loss: 0.00400

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09206
Policy Update Magnitude: 0.53700
Value Function Update Magnitude: 0.61947

Collected Steps per Second: 22,907.39642
Overall Steps per Second: 10,764.90553

Timestep Collection Time: 2.18349
Timestep Consumption Time: 2.46291
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.64639

Cumulative Model Updates: 57,096
Cumulative Timesteps: 476,299,494

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 476299494...
Checkpoint 476299494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.64453
Policy Entropy: 3.34230
Value Function Loss: 0.00394

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08393
Policy Update Magnitude: 0.54617
Value Function Update Magnitude: 0.62709

Collected Steps per Second: 22,242.55483
Overall Steps per Second: 10,542.77148

Timestep Collection Time: 2.24893
Timestep Consumption Time: 2.49574
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.74467

Cumulative Model Updates: 57,102
Cumulative Timesteps: 476,349,516

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 961.43532
Policy Entropy: 3.34762
Value Function Loss: 0.00398

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10723
Policy Update Magnitude: 0.54236
Value Function Update Magnitude: 0.62959

Collected Steps per Second: 22,680.65147
Overall Steps per Second: 10,666.18166

Timestep Collection Time: 2.20505
Timestep Consumption Time: 2.48379
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.68884

Cumulative Model Updates: 57,108
Cumulative Timesteps: 476,399,528

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 476399528...
Checkpoint 476399528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.40155
Policy Entropy: 3.35630
Value Function Loss: 0.00367

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11213
Policy Update Magnitude: 0.53392
Value Function Update Magnitude: 0.63597

Collected Steps per Second: 21,971.37841
Overall Steps per Second: 10,587.43493

Timestep Collection Time: 2.27569
Timestep Consumption Time: 2.44689
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.72258

Cumulative Model Updates: 57,114
Cumulative Timesteps: 476,449,528

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.58908
Policy Entropy: 3.36842
Value Function Loss: 0.00367

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10296
Policy Update Magnitude: 0.52871
Value Function Update Magnitude: 0.64254

Collected Steps per Second: 21,764.88570
Overall Steps per Second: 10,480.61382

Timestep Collection Time: 2.29746
Timestep Consumption Time: 2.47363
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.77109

Cumulative Model Updates: 57,120
Cumulative Timesteps: 476,499,532

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 476499532...
Checkpoint 476499532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.32638
Policy Entropy: 3.36657
Value Function Loss: 0.00349

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11063
Policy Update Magnitude: 0.52771
Value Function Update Magnitude: 0.64661

Collected Steps per Second: 21,981.23365
Overall Steps per Second: 10,557.36823

Timestep Collection Time: 2.27467
Timestep Consumption Time: 2.46136
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.73603

Cumulative Model Updates: 57,126
Cumulative Timesteps: 476,549,532

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 804.52951
Policy Entropy: 3.35464
Value Function Loss: 0.00356

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09320
Policy Update Magnitude: 0.52446
Value Function Update Magnitude: 0.63533

Collected Steps per Second: 22,037.19456
Overall Steps per Second: 10,596.61651

Timestep Collection Time: 2.26898
Timestep Consumption Time: 2.44969
PPO Batch Consumption Time: 0.28121
Total Iteration Time: 4.71868

Cumulative Model Updates: 57,132
Cumulative Timesteps: 476,599,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 476599534...
Checkpoint 476599534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.05438
Policy Entropy: 3.34902
Value Function Loss: 0.00357

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10124
Policy Update Magnitude: 0.52224
Value Function Update Magnitude: 0.63262

Collected Steps per Second: 22,035.08254
Overall Steps per Second: 10,509.01569

Timestep Collection Time: 2.26965
Timestep Consumption Time: 2.48931
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.75896

Cumulative Model Updates: 57,138
Cumulative Timesteps: 476,649,546

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.43043
Policy Entropy: 3.34835
Value Function Loss: 0.00355

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08374
Policy Update Magnitude: 0.51640
Value Function Update Magnitude: 0.61550

Collected Steps per Second: 22,088.64751
Overall Steps per Second: 10,430.06885

Timestep Collection Time: 2.26478
Timestep Consumption Time: 2.53154
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.79632

Cumulative Model Updates: 57,144
Cumulative Timesteps: 476,699,572

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 476699572...
Checkpoint 476699572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 792.53470
Policy Entropy: 3.34650
Value Function Loss: 0.00370

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10296
Policy Update Magnitude: 0.52417
Value Function Update Magnitude: 0.62287

Collected Steps per Second: 22,204.05432
Overall Steps per Second: 10,420.87928

Timestep Collection Time: 2.25220
Timestep Consumption Time: 2.54663
PPO Batch Consumption Time: 0.29677
Total Iteration Time: 4.79883

Cumulative Model Updates: 57,150
Cumulative Timesteps: 476,749,580

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 769.73345
Policy Entropy: 3.34150
Value Function Loss: 0.00372

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12162
Policy Update Magnitude: 0.52732
Value Function Update Magnitude: 0.62679

Collected Steps per Second: 22,814.13016
Overall Steps per Second: 10,695.35939

Timestep Collection Time: 2.19215
Timestep Consumption Time: 2.48390
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.67605

Cumulative Model Updates: 57,156
Cumulative Timesteps: 476,799,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 476799592...
Checkpoint 476799592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 728.28996
Policy Entropy: 3.34322
Value Function Loss: 0.00377

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.12330
Policy Update Magnitude: 0.53054
Value Function Update Magnitude: 0.62546

Collected Steps per Second: 22,128.47922
Overall Steps per Second: 10,500.13715

Timestep Collection Time: 2.26044
Timestep Consumption Time: 2.50331
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.76375

Cumulative Model Updates: 57,162
Cumulative Timesteps: 476,849,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,371.14224
Policy Entropy: 3.34512
Value Function Loss: 0.00371

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12039
Policy Update Magnitude: 0.52578
Value Function Update Magnitude: 0.62675

Collected Steps per Second: 22,815.18514
Overall Steps per Second: 10,746.33101

Timestep Collection Time: 2.19257
Timestep Consumption Time: 2.46241
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.65498

Cumulative Model Updates: 57,168
Cumulative Timesteps: 476,899,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 476899636...
Checkpoint 476899636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 940.26189
Policy Entropy: 3.36055
Value Function Loss: 0.00356

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11406
Policy Update Magnitude: 0.51706
Value Function Update Magnitude: 0.63660

Collected Steps per Second: 22,144.61930
Overall Steps per Second: 10,636.21567

Timestep Collection Time: 2.25888
Timestep Consumption Time: 2.44411
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.70299

Cumulative Model Updates: 57,174
Cumulative Timesteps: 476,949,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.95439
Policy Entropy: 3.36624
Value Function Loss: 0.00345

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09875
Policy Update Magnitude: 0.52153
Value Function Update Magnitude: 0.61289

Collected Steps per Second: 22,429.07089
Overall Steps per Second: 10,501.89079

Timestep Collection Time: 2.23050
Timestep Consumption Time: 2.53322
PPO Batch Consumption Time: 0.29721
Total Iteration Time: 4.76371

Cumulative Model Updates: 57,180
Cumulative Timesteps: 476,999,686

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 476999686...
Checkpoint 476999686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.95186
Policy Entropy: 3.37722
Value Function Loss: 0.00350

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09772
Policy Update Magnitude: 0.51793
Value Function Update Magnitude: 0.59383

Collected Steps per Second: 21,378.26365
Overall Steps per Second: 10,289.83226

Timestep Collection Time: 2.33939
Timestep Consumption Time: 2.52095
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.86033

Cumulative Model Updates: 57,186
Cumulative Timesteps: 477,049,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 787.04872
Policy Entropy: 3.38074
Value Function Loss: 0.00360

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08423
Policy Update Magnitude: 0.52280
Value Function Update Magnitude: 0.58631

Collected Steps per Second: 22,082.24909
Overall Steps per Second: 10,475.15467

Timestep Collection Time: 2.26553
Timestep Consumption Time: 2.51034
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.77587

Cumulative Model Updates: 57,192
Cumulative Timesteps: 477,099,726

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 477099726...
Checkpoint 477099726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 829.79506
Policy Entropy: 3.36444
Value Function Loss: 0.00358

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09841
Policy Update Magnitude: 0.52216
Value Function Update Magnitude: 0.61054

Collected Steps per Second: 21,957.39251
Overall Steps per Second: 10,452.27287

Timestep Collection Time: 2.27723
Timestep Consumption Time: 2.50661
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.78384

Cumulative Model Updates: 57,198
Cumulative Timesteps: 477,149,728

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.75122
Policy Entropy: 3.36631
Value Function Loss: 0.00341

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07432
Policy Update Magnitude: 0.52135
Value Function Update Magnitude: 0.60565

Collected Steps per Second: 22,021.10030
Overall Steps per Second: 10,457.52585

Timestep Collection Time: 2.27064
Timestep Consumption Time: 2.51080
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.78144

Cumulative Model Updates: 57,204
Cumulative Timesteps: 477,199,730

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 477199730...
Checkpoint 477199730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 917.34670
Policy Entropy: 3.35113
Value Function Loss: 0.00351

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07416
Policy Update Magnitude: 0.52465
Value Function Update Magnitude: 0.60677

Collected Steps per Second: 22,041.35225
Overall Steps per Second: 10,530.62827

Timestep Collection Time: 2.26973
Timestep Consumption Time: 2.48098
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.75071

Cumulative Model Updates: 57,210
Cumulative Timesteps: 477,249,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.19096
Policy Entropy: 3.35547
Value Function Loss: 0.00359

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08162
Policy Update Magnitude: 0.52366
Value Function Update Magnitude: 0.61294

Collected Steps per Second: 22,644.24684
Overall Steps per Second: 10,572.86809

Timestep Collection Time: 2.20895
Timestep Consumption Time: 2.52203
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.73098

Cumulative Model Updates: 57,216
Cumulative Timesteps: 477,299,778

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 477299778...
Checkpoint 477299778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 800.61763
Policy Entropy: 3.33956
Value Function Loss: 0.00357

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07546
Policy Update Magnitude: 0.52484
Value Function Update Magnitude: 0.60362

Collected Steps per Second: 21,975.18319
Overall Steps per Second: 10,497.68411

Timestep Collection Time: 2.27538
Timestep Consumption Time: 2.48776
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.76315

Cumulative Model Updates: 57,222
Cumulative Timesteps: 477,349,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.58845
Policy Entropy: 3.33965
Value Function Loss: 0.00357

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06926
Policy Update Magnitude: 0.52392
Value Function Update Magnitude: 0.60243

Collected Steps per Second: 22,480.56184
Overall Steps per Second: 10,587.37552

Timestep Collection Time: 2.22414
Timestep Consumption Time: 2.49846
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.72261

Cumulative Model Updates: 57,228
Cumulative Timesteps: 477,399,780

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 477399780...
Checkpoint 477399780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.39328
Policy Entropy: 3.34220
Value Function Loss: 0.00344

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07641
Policy Update Magnitude: 0.52325
Value Function Update Magnitude: 0.61503

Collected Steps per Second: 22,506.94064
Overall Steps per Second: 10,674.51277

Timestep Collection Time: 2.22163
Timestep Consumption Time: 2.46262
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.68424

Cumulative Model Updates: 57,234
Cumulative Timesteps: 477,449,782

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.97519
Policy Entropy: 3.35994
Value Function Loss: 0.00345

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.52127
Value Function Update Magnitude: 0.61278

Collected Steps per Second: 22,358.29333
Overall Steps per Second: 10,440.50160

Timestep Collection Time: 2.23640
Timestep Consumption Time: 2.55284
PPO Batch Consumption Time: 0.30074
Total Iteration Time: 4.78923

Cumulative Model Updates: 57,240
Cumulative Timesteps: 477,499,784

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 477499784...
Checkpoint 477499784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619.11453
Policy Entropy: 3.37396
Value Function Loss: 0.00343

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.52358
Value Function Update Magnitude: 0.61273

Collected Steps per Second: 22,341.36625
Overall Steps per Second: 10,640.48688

Timestep Collection Time: 2.23845
Timestep Consumption Time: 2.46152
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.69997

Cumulative Model Updates: 57,246
Cumulative Timesteps: 477,549,794

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 859.40959
Policy Entropy: 3.38050
Value Function Loss: 0.00353

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07628
Policy Update Magnitude: 0.53500
Value Function Update Magnitude: 0.63063

Collected Steps per Second: 22,654.59334
Overall Steps per Second: 10,526.22029

Timestep Collection Time: 2.20723
Timestep Consumption Time: 2.54319
PPO Batch Consumption Time: 0.29760
Total Iteration Time: 4.75042

Cumulative Model Updates: 57,252
Cumulative Timesteps: 477,599,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 477599798...
Checkpoint 477599798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594.25014
Policy Entropy: 3.38865
Value Function Loss: 0.00354

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07714
Policy Update Magnitude: 0.53614
Value Function Update Magnitude: 0.64724

Collected Steps per Second: 22,413.58263
Overall Steps per Second: 10,551.58943

Timestep Collection Time: 2.23141
Timestep Consumption Time: 2.50853
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.73995

Cumulative Model Updates: 57,258
Cumulative Timesteps: 477,649,812

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 963.80896
Policy Entropy: 3.38150
Value Function Loss: 0.00345

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07605
Policy Update Magnitude: 0.53295
Value Function Update Magnitude: 0.65012

Collected Steps per Second: 21,934.39753
Overall Steps per Second: 10,514.88029

Timestep Collection Time: 2.27980
Timestep Consumption Time: 2.47594
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.75574

Cumulative Model Updates: 57,264
Cumulative Timesteps: 477,699,818

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 477699818...
Checkpoint 477699818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 778.38266
Policy Entropy: 3.38465
Value Function Loss: 0.00332

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07842
Policy Update Magnitude: 0.53304
Value Function Update Magnitude: 0.63326

Collected Steps per Second: 22,021.60247
Overall Steps per Second: 10,535.82160

Timestep Collection Time: 2.27186
Timestep Consumption Time: 2.47670
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.74856

Cumulative Model Updates: 57,270
Cumulative Timesteps: 477,749,848

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 797.94286
Policy Entropy: 3.36826
Value Function Loss: 0.00340

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07729
Policy Update Magnitude: 0.52950
Value Function Update Magnitude: 0.63137

Collected Steps per Second: 22,147.30980
Overall Steps per Second: 10,460.98072

Timestep Collection Time: 2.25887
Timestep Consumption Time: 2.52347
PPO Batch Consumption Time: 0.29861
Total Iteration Time: 4.78234

Cumulative Model Updates: 57,276
Cumulative Timesteps: 477,799,876

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 477799876...
Checkpoint 477799876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.02087
Policy Entropy: 3.36448
Value Function Loss: 0.00343

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07865
Policy Update Magnitude: 0.52891
Value Function Update Magnitude: 0.63543

Collected Steps per Second: 22,129.25434
Overall Steps per Second: 10,589.30396

Timestep Collection Time: 2.25963
Timestep Consumption Time: 2.46249
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.72212

Cumulative Model Updates: 57,282
Cumulative Timesteps: 477,849,880

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 974.98330
Policy Entropy: 3.36191
Value Function Loss: 0.00345

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08217
Policy Update Magnitude: 0.53299
Value Function Update Magnitude: 0.63061

Collected Steps per Second: 22,459.26984
Overall Steps per Second: 10,521.29750

Timestep Collection Time: 2.22705
Timestep Consumption Time: 2.52692
PPO Batch Consumption Time: 0.29847
Total Iteration Time: 4.75398

Cumulative Model Updates: 57,288
Cumulative Timesteps: 477,899,898

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 477899898...
Checkpoint 477899898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 913.00762
Policy Entropy: 3.37671
Value Function Loss: 0.00341

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10284
Policy Update Magnitude: 0.53312
Value Function Update Magnitude: 0.61297

Collected Steps per Second: 21,972.13947
Overall Steps per Second: 10,572.85922

Timestep Collection Time: 2.27570
Timestep Consumption Time: 2.45358
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.72928

Cumulative Model Updates: 57,294
Cumulative Timesteps: 477,949,900

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724.72184
Policy Entropy: 3.38358
Value Function Loss: 0.00330

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09740
Policy Update Magnitude: 0.51909
Value Function Update Magnitude: 0.61103

Collected Steps per Second: 22,307.27536
Overall Steps per Second: 10,513.52279

Timestep Collection Time: 2.24268
Timestep Consumption Time: 2.51577
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.75844

Cumulative Model Updates: 57,300
Cumulative Timesteps: 477,999,928

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 477999928...
Checkpoint 477999928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.81031
Policy Entropy: 3.38459
Value Function Loss: 0.00329

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10520
Policy Update Magnitude: 0.51432
Value Function Update Magnitude: 0.60031

Collected Steps per Second: 22,007.88117
Overall Steps per Second: 10,634.48161

Timestep Collection Time: 2.27228
Timestep Consumption Time: 2.43016
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.70244

Cumulative Model Updates: 57,306
Cumulative Timesteps: 478,049,936

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.07117
Policy Entropy: 3.37040
Value Function Loss: 0.00340

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10941
Policy Update Magnitude: 0.51992
Value Function Update Magnitude: 0.57998

Collected Steps per Second: 22,571.71542
Overall Steps per Second: 10,574.95639

Timestep Collection Time: 2.21623
Timestep Consumption Time: 2.51420
PPO Batch Consumption Time: 0.29922
Total Iteration Time: 4.73042

Cumulative Model Updates: 57,312
Cumulative Timesteps: 478,099,960

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 478099960...
Checkpoint 478099960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707.53358
Policy Entropy: 3.36874
Value Function Loss: 0.00354

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10831
Policy Update Magnitude: 0.52590
Value Function Update Magnitude: 0.58851

Collected Steps per Second: 22,315.03767
Overall Steps per Second: 10,535.67412

Timestep Collection Time: 2.24091
Timestep Consumption Time: 2.50544
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.74635

Cumulative Model Updates: 57,318
Cumulative Timesteps: 478,149,966

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.73662
Policy Entropy: 3.36970
Value Function Loss: 0.00356

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.53257
Value Function Update Magnitude: 0.59535

Collected Steps per Second: 22,535.87265
Overall Steps per Second: 10,569.30450

Timestep Collection Time: 2.21984
Timestep Consumption Time: 2.51330
PPO Batch Consumption Time: 0.29829
Total Iteration Time: 4.73314

Cumulative Model Updates: 57,324
Cumulative Timesteps: 478,199,992

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 478199992...
Checkpoint 478199992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.69631
Policy Entropy: 3.36046
Value Function Loss: 0.00351

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.54165
Value Function Update Magnitude: 0.61310

Collected Steps per Second: 22,016.74765
Overall Steps per Second: 10,366.26359

Timestep Collection Time: 2.27109
Timestep Consumption Time: 2.55244
PPO Batch Consumption Time: 0.29742
Total Iteration Time: 4.82353

Cumulative Model Updates: 57,330
Cumulative Timesteps: 478,249,994

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688.00900
Policy Entropy: 3.35696
Value Function Loss: 0.00345

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09100
Policy Update Magnitude: 0.54401
Value Function Update Magnitude: 0.61375

Collected Steps per Second: 21,923.47835
Overall Steps per Second: 10,447.46937

Timestep Collection Time: 2.28102
Timestep Consumption Time: 2.50559
PPO Batch Consumption Time: 0.29581
Total Iteration Time: 4.78661

Cumulative Model Updates: 57,336
Cumulative Timesteps: 478,300,002

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 478300002...
Checkpoint 478300002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.40974
Policy Entropy: 3.36405
Value Function Loss: 0.00343

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.54082
Value Function Update Magnitude: 0.58534

Collected Steps per Second: 21,928.18163
Overall Steps per Second: 10,418.99385

Timestep Collection Time: 2.28117
Timestep Consumption Time: 2.51987
PPO Batch Consumption Time: 0.29932
Total Iteration Time: 4.80104

Cumulative Model Updates: 57,342
Cumulative Timesteps: 478,350,024

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.95614
Policy Entropy: 3.36905
Value Function Loss: 0.00337

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08616
Policy Update Magnitude: 0.52923
Value Function Update Magnitude: 0.56373

Collected Steps per Second: 22,335.05811
Overall Steps per Second: 10,518.84529

Timestep Collection Time: 2.23926
Timestep Consumption Time: 2.51544
PPO Batch Consumption Time: 0.29871
Total Iteration Time: 4.75470

Cumulative Model Updates: 57,348
Cumulative Timesteps: 478,400,038

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 478400038...
Checkpoint 478400038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.58700
Policy Entropy: 3.36502
Value Function Loss: 0.00351

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08640
Policy Update Magnitude: 0.52425
Value Function Update Magnitude: 0.56202

Collected Steps per Second: 21,591.41544
Overall Steps per Second: 10,505.92798

Timestep Collection Time: 2.31648
Timestep Consumption Time: 2.44426
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.76074

Cumulative Model Updates: 57,354
Cumulative Timesteps: 478,450,054

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,624.25295
Policy Entropy: 3.36616
Value Function Loss: 0.00348

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08196
Policy Update Magnitude: 0.52494
Value Function Update Magnitude: 0.57266

Collected Steps per Second: 22,336.13416
Overall Steps per Second: 10,492.15702

Timestep Collection Time: 2.23888
Timestep Consumption Time: 2.52734
PPO Batch Consumption Time: 0.29797
Total Iteration Time: 4.76623

Cumulative Model Updates: 57,360
Cumulative Timesteps: 478,500,062

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 478500062...
Checkpoint 478500062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675.29433
Policy Entropy: 3.36624
Value Function Loss: 0.00339

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08284
Policy Update Magnitude: 0.52999
Value Function Update Magnitude: 0.56215

Collected Steps per Second: 21,771.01328
Overall Steps per Second: 10,595.60089

Timestep Collection Time: 2.29672
Timestep Consumption Time: 2.42240
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.71913

Cumulative Model Updates: 57,366
Cumulative Timesteps: 478,550,064

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.66185
Policy Entropy: 3.36032
Value Function Loss: 0.00333

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07452
Policy Update Magnitude: 0.52523
Value Function Update Magnitude: 0.56037

Collected Steps per Second: 22,352.54027
Overall Steps per Second: 10,506.54614

Timestep Collection Time: 2.23697
Timestep Consumption Time: 2.52216
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.75913

Cumulative Model Updates: 57,372
Cumulative Timesteps: 478,600,066

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 478600066...
Checkpoint 478600066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 809.14552
Policy Entropy: 3.34442
Value Function Loss: 0.00355

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07877
Policy Update Magnitude: 0.53474
Value Function Update Magnitude: 0.57760

Collected Steps per Second: 22,394.97370
Overall Steps per Second: 10,587.45406

Timestep Collection Time: 2.23363
Timestep Consumption Time: 2.49102
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.72465

Cumulative Model Updates: 57,378
Cumulative Timesteps: 478,650,088

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.65055
Policy Entropy: 3.34255
Value Function Loss: 0.00363

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08168
Policy Update Magnitude: 0.54559
Value Function Update Magnitude: 0.58781

Collected Steps per Second: 22,502.60569
Overall Steps per Second: 10,538.03662

Timestep Collection Time: 2.22321
Timestep Consumption Time: 2.52416
PPO Batch Consumption Time: 0.29913
Total Iteration Time: 4.74737

Cumulative Model Updates: 57,384
Cumulative Timesteps: 478,700,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 478700116...
Checkpoint 478700116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.11887
Policy Entropy: 3.35370
Value Function Loss: 0.00356

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08120
Policy Update Magnitude: 0.54250
Value Function Update Magnitude: 0.58763

Collected Steps per Second: 22,234.16999
Overall Steps per Second: 10,648.95789

Timestep Collection Time: 2.24942
Timestep Consumption Time: 2.44719
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.69661

Cumulative Model Updates: 57,390
Cumulative Timesteps: 478,750,130

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.88955
Policy Entropy: 3.38384
Value Function Loss: 0.00340

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.07900
Policy Update Magnitude: 0.53426
Value Function Update Magnitude: 0.60283

Collected Steps per Second: 22,632.25833
Overall Steps per Second: 10,609.49401

Timestep Collection Time: 2.21012
Timestep Consumption Time: 2.50453
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.71465

Cumulative Model Updates: 57,396
Cumulative Timesteps: 478,800,150

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 478800150...
Checkpoint 478800150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 969.20132
Policy Entropy: 3.38056
Value Function Loss: 0.00336

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08968
Policy Update Magnitude: 0.52827
Value Function Update Magnitude: 0.60525

Collected Steps per Second: 22,128.72981
Overall Steps per Second: 10,416.15194

Timestep Collection Time: 2.25951
Timestep Consumption Time: 2.54073
PPO Batch Consumption Time: 0.30273
Total Iteration Time: 4.80024

Cumulative Model Updates: 57,402
Cumulative Timesteps: 478,850,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,579.94938
Policy Entropy: 3.37991
Value Function Loss: 0.00345

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09108
Policy Update Magnitude: 0.53056
Value Function Update Magnitude: 0.62309

Collected Steps per Second: 22,275.10805
Overall Steps per Second: 10,494.72963

Timestep Collection Time: 2.24547
Timestep Consumption Time: 2.52055
PPO Batch Consumption Time: 0.29922
Total Iteration Time: 4.76601

Cumulative Model Updates: 57,408
Cumulative Timesteps: 478,900,168

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 478900168...
Checkpoint 478900168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 982.54487
Policy Entropy: 3.35874
Value Function Loss: 0.00349

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10425
Policy Update Magnitude: 0.53946
Value Function Update Magnitude: 0.64782

Collected Steps per Second: 21,016.58737
Overall Steps per Second: 10,110.36076

Timestep Collection Time: 2.37936
Timestep Consumption Time: 2.56666
PPO Batch Consumption Time: 0.30652
Total Iteration Time: 4.94602

Cumulative Model Updates: 57,414
Cumulative Timesteps: 478,950,174

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 761.66220
Policy Entropy: 3.36007
Value Function Loss: 0.00358

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.53808
Value Function Update Magnitude: 0.66670

Collected Steps per Second: 22,099.83127
Overall Steps per Second: 10,560.74681

Timestep Collection Time: 2.26318
Timestep Consumption Time: 2.47284
PPO Batch Consumption Time: 0.29843
Total Iteration Time: 4.73603

Cumulative Model Updates: 57,420
Cumulative Timesteps: 479,000,190

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 479000190...
Checkpoint 479000190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.01965
Policy Entropy: 3.35706
Value Function Loss: 0.00352

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10354
Policy Update Magnitude: 0.53536
Value Function Update Magnitude: 0.65142

Collected Steps per Second: 21,089.59802
Overall Steps per Second: 10,211.50162

Timestep Collection Time: 2.37131
Timestep Consumption Time: 2.52611
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.89742

Cumulative Model Updates: 57,426
Cumulative Timesteps: 479,050,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.23479
Policy Entropy: 3.37000
Value Function Loss: 0.00340

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.52179
Value Function Update Magnitude: 0.64779

Collected Steps per Second: 21,954.63493
Overall Steps per Second: 10,345.10672

Timestep Collection Time: 2.27833
Timestep Consumption Time: 2.55680
PPO Batch Consumption Time: 0.29807
Total Iteration Time: 4.83514

Cumulative Model Updates: 57,432
Cumulative Timesteps: 479,100,220

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 479100220...
Checkpoint 479100220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,309.32088
Policy Entropy: 3.37853
Value Function Loss: 0.00332

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07165
Policy Update Magnitude: 0.52084
Value Function Update Magnitude: 0.63047

Collected Steps per Second: 21,964.60121
Overall Steps per Second: 10,465.08878

Timestep Collection Time: 2.27694
Timestep Consumption Time: 2.50200
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 4.77894

Cumulative Model Updates: 57,438
Cumulative Timesteps: 479,150,232

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,020.27943
Policy Entropy: 3.36342
Value Function Loss: 0.00329

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.52391
Value Function Update Magnitude: 0.61294

Collected Steps per Second: 22,623.30122
Overall Steps per Second: 10,650.42868

Timestep Collection Time: 2.21020
Timestep Consumption Time: 2.48464
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.69483

Cumulative Model Updates: 57,444
Cumulative Timesteps: 479,200,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 479200234...
Checkpoint 479200234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.27463
Policy Entropy: 3.35880
Value Function Loss: 0.00350

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07679
Policy Update Magnitude: 0.53179
Value Function Update Magnitude: 0.62207

Collected Steps per Second: 22,667.75807
Overall Steps per Second: 10,731.37531

Timestep Collection Time: 2.20622
Timestep Consumption Time: 2.45395
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.66017

Cumulative Model Updates: 57,450
Cumulative Timesteps: 479,250,244

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,519.82703
Policy Entropy: 3.35481
Value Function Loss: 0.00345

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08462
Policy Update Magnitude: 0.53868
Value Function Update Magnitude: 0.63284

Collected Steps per Second: 22,161.64501
Overall Steps per Second: 10,499.76103

Timestep Collection Time: 2.25633
Timestep Consumption Time: 2.50606
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.76239

Cumulative Model Updates: 57,456
Cumulative Timesteps: 479,300,248

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 479300248...
Checkpoint 479300248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 780.07553
Policy Entropy: 3.38028
Value Function Loss: 0.00350

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07661
Policy Update Magnitude: 0.53498
Value Function Update Magnitude: 0.64240

Collected Steps per Second: 22,486.03895
Overall Steps per Second: 10,580.02217

Timestep Collection Time: 2.22431
Timestep Consumption Time: 2.50309
PPO Batch Consumption Time: 0.29591
Total Iteration Time: 4.72740

Cumulative Model Updates: 57,462
Cumulative Timesteps: 479,350,264

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.02541
Policy Entropy: 3.38485
Value Function Loss: 0.00316

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08031
Policy Update Magnitude: 0.54125
Value Function Update Magnitude: 0.63860

Collected Steps per Second: 22,690.95940
Overall Steps per Second: 10,630.80563

Timestep Collection Time: 2.20405
Timestep Consumption Time: 2.50039
PPO Batch Consumption Time: 0.29678
Total Iteration Time: 4.70444

Cumulative Model Updates: 57,468
Cumulative Timesteps: 479,400,276

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 479400276...
Checkpoint 479400276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.73446
Policy Entropy: 3.39030
Value Function Loss: 0.00321

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07410
Policy Update Magnitude: 0.52840
Value Function Update Magnitude: 0.61297

Collected Steps per Second: 22,683.86465
Overall Steps per Second: 10,566.91651

Timestep Collection Time: 2.20544
Timestep Consumption Time: 2.52895
PPO Batch Consumption Time: 0.29828
Total Iteration Time: 4.73440

Cumulative Model Updates: 57,474
Cumulative Timesteps: 479,450,304

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.90292
Policy Entropy: 3.37705
Value Function Loss: 0.00347

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07319
Policy Update Magnitude: 0.53270
Value Function Update Magnitude: 0.59669

Collected Steps per Second: 22,349.43971
Overall Steps per Second: 10,512.25066

Timestep Collection Time: 2.23755
Timestep Consumption Time: 2.51957
PPO Batch Consumption Time: 0.29739
Total Iteration Time: 4.75712

Cumulative Model Updates: 57,480
Cumulative Timesteps: 479,500,312

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 479500312...
Checkpoint 479500312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,924.61080
Policy Entropy: 3.35799
Value Function Loss: 0.00344

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09257
Policy Update Magnitude: 0.53247
Value Function Update Magnitude: 0.61713

Collected Steps per Second: 22,108.44045
Overall Steps per Second: 10,549.99106

Timestep Collection Time: 2.26230
Timestep Consumption Time: 2.47855
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.74086

Cumulative Model Updates: 57,486
Cumulative Timesteps: 479,550,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,047.00845
Policy Entropy: 3.35960
Value Function Loss: 0.00334

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08249
Policy Update Magnitude: 0.52214
Value Function Update Magnitude: 0.60764

Collected Steps per Second: 21,951.65089
Overall Steps per Second: 10,352.19334

Timestep Collection Time: 2.27855
Timestep Consumption Time: 2.55308
PPO Batch Consumption Time: 0.30518
Total Iteration Time: 4.83163

Cumulative Model Updates: 57,492
Cumulative Timesteps: 479,600,346

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 479600346...
Checkpoint 479600346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.47166
Policy Entropy: 3.36657
Value Function Loss: 0.00307

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08227
Policy Update Magnitude: 0.50831
Value Function Update Magnitude: 0.59362

Collected Steps per Second: 22,132.26195
Overall Steps per Second: 10,665.13225

Timestep Collection Time: 2.25915
Timestep Consumption Time: 2.42903
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.68817

Cumulative Model Updates: 57,498
Cumulative Timesteps: 479,650,346

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.94841
Policy Entropy: 3.36853
Value Function Loss: 0.00309

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07392
Policy Update Magnitude: 0.50796
Value Function Update Magnitude: 0.58938

Collected Steps per Second: 21,576.83604
Overall Steps per Second: 10,500.27290

Timestep Collection Time: 2.31730
Timestep Consumption Time: 2.44448
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.76178

Cumulative Model Updates: 57,504
Cumulative Timesteps: 479,700,346

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 479700346...
Checkpoint 479700346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.04991
Policy Entropy: 3.36358
Value Function Loss: 0.00316

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.06565
Policy Update Magnitude: 0.51585
Value Function Update Magnitude: 0.59851

Collected Steps per Second: 22,318.00281
Overall Steps per Second: 10,555.85400

Timestep Collection Time: 2.24142
Timestep Consumption Time: 2.49756
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.73898

Cumulative Model Updates: 57,510
Cumulative Timesteps: 479,750,370

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.11686
Policy Entropy: 3.36683
Value Function Loss: 0.00323

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07426
Policy Update Magnitude: 0.51893
Value Function Update Magnitude: 0.58978

Collected Steps per Second: 22,110.75762
Overall Steps per Second: 10,542.80343

Timestep Collection Time: 2.26170
Timestep Consumption Time: 2.48163
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.74333

Cumulative Model Updates: 57,516
Cumulative Timesteps: 479,800,378

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 479800378...
Checkpoint 479800378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.36732
Policy Entropy: 3.36381
Value Function Loss: 0.00347

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07346
Policy Update Magnitude: 0.52503
Value Function Update Magnitude: 0.59183

Collected Steps per Second: 21,840.21381
Overall Steps per Second: 10,483.41596

Timestep Collection Time: 2.28963
Timestep Consumption Time: 2.48038
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.77001

Cumulative Model Updates: 57,522
Cumulative Timesteps: 479,850,384

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,538.54171
Policy Entropy: 3.35569
Value Function Loss: 0.00321

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07194
Policy Update Magnitude: 0.53651
Value Function Update Magnitude: 0.60883

Collected Steps per Second: 22,467.64698
Overall Steps per Second: 10,604.58229

Timestep Collection Time: 2.22551
Timestep Consumption Time: 2.48962
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.71513

Cumulative Model Updates: 57,528
Cumulative Timesteps: 479,900,386

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 479900386...
Checkpoint 479900386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 825.10396
Policy Entropy: 3.35050
Value Function Loss: 0.00340

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06497
Policy Update Magnitude: 0.54253
Value Function Update Magnitude: 0.60486

Collected Steps per Second: 22,510.53930
Overall Steps per Second: 10,650.26952

Timestep Collection Time: 2.22251
Timestep Consumption Time: 2.47502
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.69753

Cumulative Model Updates: 57,534
Cumulative Timesteps: 479,950,416

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.85710
Policy Entropy: 3.34337
Value Function Loss: 0.00344

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.06932
Policy Update Magnitude: 0.55185
Value Function Update Magnitude: 0.59811

Collected Steps per Second: 22,401.79386
Overall Steps per Second: 10,544.34651

Timestep Collection Time: 2.23286
Timestep Consumption Time: 2.51092
PPO Batch Consumption Time: 0.29843
Total Iteration Time: 4.74377

Cumulative Model Updates: 57,540
Cumulative Timesteps: 480,000,436

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 480000436...
Checkpoint 480000436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.39337
Policy Entropy: 3.33002
Value Function Loss: 0.00358

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09023
Policy Update Magnitude: 0.55674
Value Function Update Magnitude: 0.61078

Collected Steps per Second: 22,409.49423
Overall Steps per Second: 10,519.99869

Timestep Collection Time: 2.23182
Timestep Consumption Time: 2.52236
PPO Batch Consumption Time: 0.29926
Total Iteration Time: 4.75418

Cumulative Model Updates: 57,546
Cumulative Timesteps: 480,050,450

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.48340
Policy Entropy: 3.33850
Value Function Loss: 0.00347

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07570
Policy Update Magnitude: 0.55392
Value Function Update Magnitude: 0.60907

Collected Steps per Second: 22,436.33211
Overall Steps per Second: 10,517.82253

Timestep Collection Time: 2.22906
Timestep Consumption Time: 2.52591
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 4.75498

Cumulative Model Updates: 57,552
Cumulative Timesteps: 480,100,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 480100462...
Checkpoint 480100462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.64730
Policy Entropy: 3.34447
Value Function Loss: 0.00367

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.06992
Policy Update Magnitude: 0.55294
Value Function Update Magnitude: 0.60770

Collected Steps per Second: 22,602.88372
Overall Steps per Second: 10,608.88575

Timestep Collection Time: 2.21335
Timestep Consumption Time: 2.50232
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.71567

Cumulative Model Updates: 57,558
Cumulative Timesteps: 480,150,490

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.04990
Policy Entropy: 3.35524
Value Function Loss: 0.00359

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07509
Policy Update Magnitude: 0.55636
Value Function Update Magnitude: 0.61471

Collected Steps per Second: 22,015.72685
Overall Steps per Second: 10,405.36446

Timestep Collection Time: 2.27201
Timestep Consumption Time: 2.53512
PPO Batch Consumption Time: 0.30025
Total Iteration Time: 4.80714

Cumulative Model Updates: 57,564
Cumulative Timesteps: 480,200,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 480200510...
Checkpoint 480200510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.40367
Policy Entropy: 3.35562
Value Function Loss: 0.00363

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09139
Policy Update Magnitude: 0.54480
Value Function Update Magnitude: 0.61564

Collected Steps per Second: 21,811.79884
Overall Steps per Second: 10,566.87671

Timestep Collection Time: 2.29371
Timestep Consumption Time: 2.44089
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.73461

Cumulative Model Updates: 57,570
Cumulative Timesteps: 480,250,540

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 809.14460
Policy Entropy: 3.35432
Value Function Loss: 0.00353

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11134
Policy Update Magnitude: 0.53579
Value Function Update Magnitude: 0.61501

Collected Steps per Second: 21,557.54444
Overall Steps per Second: 10,490.36490

Timestep Collection Time: 2.32058
Timestep Consumption Time: 2.44818
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.76876

Cumulative Model Updates: 57,576
Cumulative Timesteps: 480,300,566

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 480300566...
Checkpoint 480300566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.67192
Policy Entropy: 3.34399
Value Function Loss: 0.00358

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.52631
Value Function Update Magnitude: 0.60794

Collected Steps per Second: 21,980.47518
Overall Steps per Second: 10,476.24918

Timestep Collection Time: 2.27557
Timestep Consumption Time: 2.49885
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.77442

Cumulative Model Updates: 57,582
Cumulative Timesteps: 480,350,584

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 979.90341
Policy Entropy: 3.34673
Value Function Loss: 0.00369

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12332
Policy Update Magnitude: 0.52617
Value Function Update Magnitude: 0.62493

Collected Steps per Second: 22,479.66146
Overall Steps per Second: 10,694.93650

Timestep Collection Time: 2.22477
Timestep Consumption Time: 2.45146
PPO Batch Consumption Time: 0.28406
Total Iteration Time: 4.67623

Cumulative Model Updates: 57,588
Cumulative Timesteps: 480,400,596

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 480400596...
Checkpoint 480400596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 805.00466
Policy Entropy: 3.34048
Value Function Loss: 0.00361

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10551
Policy Update Magnitude: 0.53804
Value Function Update Magnitude: 0.65710

Collected Steps per Second: 22,219.92922
Overall Steps per Second: 10,574.02097

Timestep Collection Time: 2.25032
Timestep Consumption Time: 2.47844
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.72876

Cumulative Model Updates: 57,594
Cumulative Timesteps: 480,450,598

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 829.79631
Policy Entropy: 3.36230
Value Function Loss: 0.00369

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10502
Policy Update Magnitude: 0.54853
Value Function Update Magnitude: 0.66584

Collected Steps per Second: 22,461.87180
Overall Steps per Second: 10,487.59694

Timestep Collection Time: 2.22697
Timestep Consumption Time: 2.54266
PPO Batch Consumption Time: 0.30128
Total Iteration Time: 4.76963

Cumulative Model Updates: 57,600
Cumulative Timesteps: 480,500,620

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 480500620...
Checkpoint 480500620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.57914
Policy Entropy: 3.36479
Value Function Loss: 0.00343

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 0.54370
Value Function Update Magnitude: 0.66471

Collected Steps per Second: 22,196.53155
Overall Steps per Second: 10,602.39045

Timestep Collection Time: 2.25278
Timestep Consumption Time: 2.46351
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.71629

Cumulative Model Updates: 57,606
Cumulative Timesteps: 480,550,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.70558
Policy Entropy: 3.36508
Value Function Loss: 0.00347

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08442
Policy Update Magnitude: 0.53791
Value Function Update Magnitude: 0.66929

Collected Steps per Second: 22,562.11210
Overall Steps per Second: 10,548.14200

Timestep Collection Time: 2.21735
Timestep Consumption Time: 2.52548
PPO Batch Consumption Time: 0.30049
Total Iteration Time: 4.74283

Cumulative Model Updates: 57,612
Cumulative Timesteps: 480,600,652

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 480600652...
Checkpoint 480600652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292.98585
Policy Entropy: 3.34604
Value Function Loss: 0.00347

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10764
Policy Update Magnitude: 0.53632
Value Function Update Magnitude: 0.66361

Collected Steps per Second: 22,496.98540
Overall Steps per Second: 10,630.96296

Timestep Collection Time: 2.22252
Timestep Consumption Time: 2.48072
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.70324

Cumulative Model Updates: 57,618
Cumulative Timesteps: 480,650,652

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,736.68952
Policy Entropy: 3.34836
Value Function Loss: 0.00361

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10587
Policy Update Magnitude: 0.53992
Value Function Update Magnitude: 0.64841

Collected Steps per Second: 22,298.31505
Overall Steps per Second: 10,467.55198

Timestep Collection Time: 2.24349
Timestep Consumption Time: 2.53566
PPO Batch Consumption Time: 0.29875
Total Iteration Time: 4.77915

Cumulative Model Updates: 57,624
Cumulative Timesteps: 480,700,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 480700678...
Checkpoint 480700678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,417.68195
Policy Entropy: 3.37621
Value Function Loss: 0.00353

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12546
Policy Update Magnitude: 0.53615
Value Function Update Magnitude: 0.63340

Collected Steps per Second: 22,438.09003
Overall Steps per Second: 10,620.76954

Timestep Collection Time: 2.22924
Timestep Consumption Time: 2.48039
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.70964

Cumulative Model Updates: 57,630
Cumulative Timesteps: 480,750,698

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,364.04372
Policy Entropy: 3.38662
Value Function Loss: 0.00346

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09606
Policy Update Magnitude: 0.53538
Value Function Update Magnitude: 0.63690

Collected Steps per Second: 22,229.00713
Overall Steps per Second: 10,405.47911

Timestep Collection Time: 2.24976
Timestep Consumption Time: 2.55636
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.80612

Cumulative Model Updates: 57,636
Cumulative Timesteps: 480,800,708

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 480800708...
Checkpoint 480800708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.49967
Policy Entropy: 3.37976
Value Function Loss: 0.00335

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.53374
Value Function Update Magnitude: 0.64455

Collected Steps per Second: 21,820.26768
Overall Steps per Second: 10,521.99225

Timestep Collection Time: 2.29145
Timestep Consumption Time: 2.46050
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.75195

Cumulative Model Updates: 57,642
Cumulative Timesteps: 480,850,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.60170
Policy Entropy: 3.37022
Value Function Loss: 0.00348

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09385
Policy Update Magnitude: 0.53001
Value Function Update Magnitude: 0.65942

Collected Steps per Second: 21,992.88612
Overall Steps per Second: 10,602.40774

Timestep Collection Time: 2.27437
Timestep Consumption Time: 2.44342
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.71780

Cumulative Model Updates: 57,648
Cumulative Timesteps: 480,900,728

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 480900728...
Checkpoint 480900728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,698.38740
Policy Entropy: 3.36537
Value Function Loss: 0.00349

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08247
Policy Update Magnitude: 0.54409
Value Function Update Magnitude: 0.65309

Collected Steps per Second: 21,662.41822
Overall Steps per Second: 10,529.66758

Timestep Collection Time: 2.30888
Timestep Consumption Time: 2.44112
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.75001

Cumulative Model Updates: 57,654
Cumulative Timesteps: 480,950,744

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 753.62131
Policy Entropy: 3.35542
Value Function Loss: 0.00356

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.54665
Value Function Update Magnitude: 0.66778

Collected Steps per Second: 22,122.44416
Overall Steps per Second: 10,597.07846

Timestep Collection Time: 2.26024
Timestep Consumption Time: 2.45823
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.71847

Cumulative Model Updates: 57,660
Cumulative Timesteps: 481,000,746

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 481000746...
Checkpoint 481000746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424.33387
Policy Entropy: 3.35663
Value Function Loss: 0.00350

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08118
Policy Update Magnitude: 0.54322
Value Function Update Magnitude: 0.66752

Collected Steps per Second: 21,997.28137
Overall Steps per Second: 10,545.71425

Timestep Collection Time: 2.27364
Timestep Consumption Time: 2.46895
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.74259

Cumulative Model Updates: 57,666
Cumulative Timesteps: 481,050,760

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 885.42455
Policy Entropy: 3.34487
Value Function Loss: 0.00352

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10209
Policy Update Magnitude: 0.53657
Value Function Update Magnitude: 0.68448

Collected Steps per Second: 22,220.24997
Overall Steps per Second: 10,515.15520

Timestep Collection Time: 2.25236
Timestep Consumption Time: 2.50725
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.75961

Cumulative Model Updates: 57,672
Cumulative Timesteps: 481,100,808

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 481100808...
Checkpoint 481100808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.44520
Policy Entropy: 3.35608
Value Function Loss: 0.00340

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11198
Policy Update Magnitude: 0.53070
Value Function Update Magnitude: 0.68856

Collected Steps per Second: 22,307.45467
Overall Steps per Second: 10,547.35019

Timestep Collection Time: 2.24158
Timestep Consumption Time: 2.49932
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.74091

Cumulative Model Updates: 57,678
Cumulative Timesteps: 481,150,812

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,287.86814
Policy Entropy: 3.35131
Value Function Loss: 0.00325

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12218
Policy Update Magnitude: 0.52312
Value Function Update Magnitude: 0.67145

Collected Steps per Second: 22,717.49622
Overall Steps per Second: 10,577.47511

Timestep Collection Time: 2.20148
Timestep Consumption Time: 2.52669
PPO Batch Consumption Time: 0.29990
Total Iteration Time: 4.72816

Cumulative Model Updates: 57,684
Cumulative Timesteps: 481,200,824

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 481200824...
Checkpoint 481200824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.29396
Policy Entropy: 3.35446
Value Function Loss: 0.00330

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.13100
Policy Update Magnitude: 0.52395
Value Function Update Magnitude: 0.65091

Collected Steps per Second: 22,487.47020
Overall Steps per Second: 10,600.61705

Timestep Collection Time: 2.22364
Timestep Consumption Time: 2.49345
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.71708

Cumulative Model Updates: 57,690
Cumulative Timesteps: 481,250,828

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,675.54423
Policy Entropy: 3.35039
Value Function Loss: 0.00340

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10653
Policy Update Magnitude: 0.53074
Value Function Update Magnitude: 0.64321

Collected Steps per Second: 22,424.37635
Overall Steps per Second: 10,455.25180

Timestep Collection Time: 2.23061
Timestep Consumption Time: 2.55359
PPO Batch Consumption Time: 0.29895
Total Iteration Time: 4.78420

Cumulative Model Updates: 57,696
Cumulative Timesteps: 481,300,848

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 481300848...
Checkpoint 481300848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430.93600
Policy Entropy: 3.36180
Value Function Loss: 0.00344

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09393
Policy Update Magnitude: 0.53571
Value Function Update Magnitude: 0.65086

Collected Steps per Second: 22,551.02444
Overall Steps per Second: 10,678.83181

Timestep Collection Time: 2.21773
Timestep Consumption Time: 2.46556
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.68328

Cumulative Model Updates: 57,702
Cumulative Timesteps: 481,350,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,418.12179
Policy Entropy: 3.35276
Value Function Loss: 0.00362

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.53623
Value Function Update Magnitude: 0.66215

Collected Steps per Second: 22,532.82076
Overall Steps per Second: 10,500.88336

Timestep Collection Time: 2.22005
Timestep Consumption Time: 2.54374
PPO Batch Consumption Time: 0.29742
Total Iteration Time: 4.76379

Cumulative Model Updates: 57,708
Cumulative Timesteps: 481,400,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 481400884...
Checkpoint 481400884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.46661
Policy Entropy: 3.35383
Value Function Loss: 0.00349

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09418
Policy Update Magnitude: 0.53369
Value Function Update Magnitude: 0.67198

Collected Steps per Second: 22,009.64144
Overall Steps per Second: 10,584.81315

Timestep Collection Time: 2.27200
Timestep Consumption Time: 2.45231
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.72432

Cumulative Model Updates: 57,714
Cumulative Timesteps: 481,450,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,924.77727
Policy Entropy: 3.35113
Value Function Loss: 0.00335

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08498
Policy Update Magnitude: 0.52704
Value Function Update Magnitude: 0.64619

Collected Steps per Second: 22,151.34500
Overall Steps per Second: 10,468.37997

Timestep Collection Time: 2.25855
Timestep Consumption Time: 2.52060
PPO Batch Consumption Time: 0.29710
Total Iteration Time: 4.77915

Cumulative Model Updates: 57,720
Cumulative Timesteps: 481,500,920

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 481500920...
Checkpoint 481500920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,825.02883
Policy Entropy: 3.36629
Value Function Loss: 0.00330

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07756
Policy Update Magnitude: 0.51699
Value Function Update Magnitude: 0.63208

Collected Steps per Second: 21,973.05175
Overall Steps per Second: 10,435.94431

Timestep Collection Time: 2.27597
Timestep Consumption Time: 2.51612
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.79209

Cumulative Model Updates: 57,726
Cumulative Timesteps: 481,550,930

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 860.16442
Policy Entropy: 3.36173
Value Function Loss: 0.00343

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.07931
Policy Update Magnitude: 0.52135
Value Function Update Magnitude: 0.64749

Collected Steps per Second: 22,256.49624
Overall Steps per Second: 10,614.32350

Timestep Collection Time: 2.24654
Timestep Consumption Time: 2.46408
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.71062

Cumulative Model Updates: 57,732
Cumulative Timesteps: 481,600,930

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 481600930...
Checkpoint 481600930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647.34609
Policy Entropy: 3.34571
Value Function Loss: 0.00360

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.53436
Value Function Update Magnitude: 0.65768

Collected Steps per Second: 21,630.17539
Overall Steps per Second: 10,510.00423

Timestep Collection Time: 2.31186
Timestep Consumption Time: 2.44608
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.75794

Cumulative Model Updates: 57,738
Cumulative Timesteps: 481,650,936

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 924.72660
Policy Entropy: 3.33727
Value Function Loss: 0.00351

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08715
Policy Update Magnitude: 0.54557
Value Function Update Magnitude: 0.63840

Collected Steps per Second: 21,716.81396
Overall Steps per Second: 10,495.98368

Timestep Collection Time: 2.30421
Timestep Consumption Time: 2.46333
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.76754

Cumulative Model Updates: 57,744
Cumulative Timesteps: 481,700,976

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 481700976...
Checkpoint 481700976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,444.95029
Policy Entropy: 3.34582
Value Function Loss: 0.00352

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07581
Policy Update Magnitude: 0.54489
Value Function Update Magnitude: 0.62680

Collected Steps per Second: 22,073.20409
Overall Steps per Second: 10,507.49208

Timestep Collection Time: 2.26582
Timestep Consumption Time: 2.49402
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.75984

Cumulative Model Updates: 57,750
Cumulative Timesteps: 481,750,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,109.47291
Policy Entropy: 3.35893
Value Function Loss: 0.00342

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08191
Policy Update Magnitude: 0.53410
Value Function Update Magnitude: 0.62373

Collected Steps per Second: 22,424.50526
Overall Steps per Second: 10,622.25414

Timestep Collection Time: 2.23042
Timestep Consumption Time: 2.47819
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.70861

Cumulative Model Updates: 57,756
Cumulative Timesteps: 481,801,006

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 481801006...
Checkpoint 481801006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.32439
Policy Entropy: 3.37850
Value Function Loss: 0.00346

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07579
Policy Update Magnitude: 0.53008
Value Function Update Magnitude: 0.63096

Collected Steps per Second: 22,292.46279
Overall Steps per Second: 10,691.66471

Timestep Collection Time: 2.24318
Timestep Consumption Time: 2.43392
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.67710

Cumulative Model Updates: 57,762
Cumulative Timesteps: 481,851,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 990.54878
Policy Entropy: 3.37202
Value Function Loss: 0.00336

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08589
Policy Update Magnitude: 0.53539
Value Function Update Magnitude: 0.64805

Collected Steps per Second: 22,609.27390
Overall Steps per Second: 10,610.74605

Timestep Collection Time: 2.21148
Timestep Consumption Time: 2.50072
PPO Batch Consumption Time: 0.29582
Total Iteration Time: 4.71220

Cumulative Model Updates: 57,768
Cumulative Timesteps: 481,901,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 481901012...
Checkpoint 481901012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 866.59321
Policy Entropy: 3.37235
Value Function Loss: 0.00331

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09116
Policy Update Magnitude: 0.52611
Value Function Update Magnitude: 0.64536

Collected Steps per Second: 22,947.26392
Overall Steps per Second: 10,796.63559

Timestep Collection Time: 2.17952
Timestep Consumption Time: 2.45285
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.63237

Cumulative Model Updates: 57,774
Cumulative Timesteps: 481,951,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.79969
Policy Entropy: 3.37212
Value Function Loss: 0.00334

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08699
Policy Update Magnitude: 0.52509
Value Function Update Magnitude: 0.64396

Collected Steps per Second: 22,522.83892
Overall Steps per Second: 10,597.53918

Timestep Collection Time: 2.22095
Timestep Consumption Time: 2.49921
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.72015

Cumulative Model Updates: 57,780
Cumulative Timesteps: 482,001,048

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 482001048...
Checkpoint 482001048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.93462
Policy Entropy: 3.38220
Value Function Loss: 0.00346

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08612
Policy Update Magnitude: 0.52985
Value Function Update Magnitude: 0.64017

Collected Steps per Second: 21,956.90462
Overall Steps per Second: 10,517.12176

Timestep Collection Time: 2.27728
Timestep Consumption Time: 2.47706
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.75434

Cumulative Model Updates: 57,786
Cumulative Timesteps: 482,051,050

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,704.93746
Policy Entropy: 3.37518
Value Function Loss: 0.00338

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.53248
Value Function Update Magnitude: 0.62968

Collected Steps per Second: 21,856.15020
Overall Steps per Second: 10,514.21661

Timestep Collection Time: 2.28897
Timestep Consumption Time: 2.46916
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.75813

Cumulative Model Updates: 57,792
Cumulative Timesteps: 482,101,078

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 482101078...
Checkpoint 482101078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 860.82464
Policy Entropy: 3.35384
Value Function Loss: 0.00336

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08643
Policy Update Magnitude: 0.52390
Value Function Update Magnitude: 0.60075

Collected Steps per Second: 21,628.63332
Overall Steps per Second: 10,265.38128

Timestep Collection Time: 2.31304
Timestep Consumption Time: 2.56042
PPO Batch Consumption Time: 0.29960
Total Iteration Time: 4.87347

Cumulative Model Updates: 57,798
Cumulative Timesteps: 482,151,106

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 828.10181
Policy Entropy: 3.35011
Value Function Loss: 0.00341

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08363
Policy Update Magnitude: 0.52399
Value Function Update Magnitude: 0.61704

Collected Steps per Second: 22,229.02942
Overall Steps per Second: 10,265.13763

Timestep Collection Time: 2.24958
Timestep Consumption Time: 2.62186
PPO Batch Consumption Time: 0.30775
Total Iteration Time: 4.87144

Cumulative Model Updates: 57,804
Cumulative Timesteps: 482,201,112

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 482201112...
Checkpoint 482201112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 905.86361
Policy Entropy: 3.35435
Value Function Loss: 0.00340

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09465
Policy Update Magnitude: 0.53549
Value Function Update Magnitude: 0.61968

Collected Steps per Second: 21,963.46740
Overall Steps per Second: 10,391.19923

Timestep Collection Time: 2.27669
Timestep Consumption Time: 2.53546
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.81215

Cumulative Model Updates: 57,810
Cumulative Timesteps: 482,251,116

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.77525
Policy Entropy: 3.38259
Value Function Loss: 0.00347

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08837
Policy Update Magnitude: 0.54135
Value Function Update Magnitude: 0.62179

Collected Steps per Second: 22,408.57002
Overall Steps per Second: 10,487.21606

Timestep Collection Time: 2.23200
Timestep Consumption Time: 2.53723
PPO Batch Consumption Time: 0.29899
Total Iteration Time: 4.76924

Cumulative Model Updates: 57,816
Cumulative Timesteps: 482,301,132

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 482301132...
Checkpoint 482301132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,488.53924
Policy Entropy: 3.39336
Value Function Loss: 0.00338

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.07828
Policy Update Magnitude: 0.53729
Value Function Update Magnitude: 0.61673

Collected Steps per Second: 22,017.35223
Overall Steps per Second: 10,610.97371

Timestep Collection Time: 2.27094
Timestep Consumption Time: 2.44117
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.71210

Cumulative Model Updates: 57,822
Cumulative Timesteps: 482,351,132

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,516.16769
Policy Entropy: 3.39283
Value Function Loss: 0.00353

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08779
Policy Update Magnitude: 0.52806
Value Function Update Magnitude: 0.61169

Collected Steps per Second: 22,683.56432
Overall Steps per Second: 10,475.91780

Timestep Collection Time: 2.20547
Timestep Consumption Time: 2.57005
PPO Batch Consumption Time: 0.29886
Total Iteration Time: 4.77552

Cumulative Model Updates: 57,828
Cumulative Timesteps: 482,401,160

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 482401160...
Checkpoint 482401160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392.34692
Policy Entropy: 3.37208
Value Function Loss: 0.00332

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08040
Policy Update Magnitude: 0.52367
Value Function Update Magnitude: 0.60544

Collected Steps per Second: 22,409.16437
Overall Steps per Second: 10,523.25929

Timestep Collection Time: 2.23212
Timestep Consumption Time: 2.52116
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.75328

Cumulative Model Updates: 57,834
Cumulative Timesteps: 482,451,180

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.94810
Policy Entropy: 3.36703
Value Function Loss: 0.00352

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08148
Policy Update Magnitude: 0.52781
Value Function Update Magnitude: 0.61401

Collected Steps per Second: 22,597.57156
Overall Steps per Second: 10,504.22969

Timestep Collection Time: 2.21378
Timestep Consumption Time: 2.54868
PPO Batch Consumption Time: 0.29788
Total Iteration Time: 4.76246

Cumulative Model Updates: 57,840
Cumulative Timesteps: 482,501,206

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 482501206...
Checkpoint 482501206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.80610
Policy Entropy: 3.36518
Value Function Loss: 0.00354

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07858
Policy Update Magnitude: 0.54870
Value Function Update Magnitude: 0.62739

Collected Steps per Second: 22,520.60473
Overall Steps per Second: 10,659.42587

Timestep Collection Time: 2.22197
Timestep Consumption Time: 2.47247
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.69444

Cumulative Model Updates: 57,846
Cumulative Timesteps: 482,551,246

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,429.41398
Policy Entropy: 3.35222
Value Function Loss: 0.00352

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08382
Policy Update Magnitude: 0.55200
Value Function Update Magnitude: 0.64521

Collected Steps per Second: 22,470.42484
Overall Steps per Second: 10,561.08794

Timestep Collection Time: 2.22559
Timestep Consumption Time: 2.50972
PPO Batch Consumption Time: 0.29795
Total Iteration Time: 4.73531

Cumulative Model Updates: 57,852
Cumulative Timesteps: 482,601,256

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 482601256...
Checkpoint 482601256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,853.98329
Policy Entropy: 3.34863
Value Function Loss: 0.00350

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08916
Policy Update Magnitude: 0.54425
Value Function Update Magnitude: 0.65300

Collected Steps per Second: 22,232.37897
Overall Steps per Second: 10,520.71615

Timestep Collection Time: 2.25050
Timestep Consumption Time: 2.50526
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.75576

Cumulative Model Updates: 57,858
Cumulative Timesteps: 482,651,290

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,338.46891
Policy Entropy: 3.35977
Value Function Loss: 0.00336

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07908
Policy Update Magnitude: 0.53499
Value Function Update Magnitude: 0.65834

Collected Steps per Second: 21,659.46258
Overall Steps per Second: 10,416.51303

Timestep Collection Time: 2.30855
Timestep Consumption Time: 2.49171
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.80026

Cumulative Model Updates: 57,864
Cumulative Timesteps: 482,701,292

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 482701292...
Checkpoint 482701292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.89876
Policy Entropy: 3.36258
Value Function Loss: 0.00344

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08352
Policy Update Magnitude: 0.53703
Value Function Update Magnitude: 0.65449

Collected Steps per Second: 22,050.83424
Overall Steps per Second: 10,612.38411

Timestep Collection Time: 2.26894
Timestep Consumption Time: 2.44555
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.71449

Cumulative Model Updates: 57,870
Cumulative Timesteps: 482,751,324

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,613.19878
Policy Entropy: 3.37094
Value Function Loss: 0.00344

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08032
Policy Update Magnitude: 0.52952
Value Function Update Magnitude: 0.65273

Collected Steps per Second: 22,004.29130
Overall Steps per Second: 10,533.11217

Timestep Collection Time: 2.27274
Timestep Consumption Time: 2.47515
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.74788

Cumulative Model Updates: 57,876
Cumulative Timesteps: 482,801,334

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 482801334...
Checkpoint 482801334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.19709
Policy Entropy: 3.37535
Value Function Loss: 0.00345

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08027
Policy Update Magnitude: 0.53091
Value Function Update Magnitude: 0.65352

Collected Steps per Second: 21,794.04838
Overall Steps per Second: 10,412.72655

Timestep Collection Time: 2.29485
Timestep Consumption Time: 2.50831
PPO Batch Consumption Time: 0.29666
Total Iteration Time: 4.80316

Cumulative Model Updates: 57,882
Cumulative Timesteps: 482,851,348

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 840.60609
Policy Entropy: 3.37555
Value Function Loss: 0.00335

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07233
Policy Update Magnitude: 0.52790
Value Function Update Magnitude: 0.63307

Collected Steps per Second: 22,435.26202
Overall Steps per Second: 10,586.29716

Timestep Collection Time: 2.22953
Timestep Consumption Time: 2.49545
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.72498

Cumulative Model Updates: 57,888
Cumulative Timesteps: 482,901,368

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 482901368...
Checkpoint 482901368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 996.52617
Policy Entropy: 3.38792
Value Function Loss: 0.00324

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.06619
Policy Update Magnitude: 0.53222
Value Function Update Magnitude: 0.63110

Collected Steps per Second: 22,017.38008
Overall Steps per Second: 10,484.55980

Timestep Collection Time: 2.27184
Timestep Consumption Time: 2.49898
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.77083

Cumulative Model Updates: 57,894
Cumulative Timesteps: 482,951,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.18935
Policy Entropy: 3.37394
Value Function Loss: 0.00323

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.06762
Policy Update Magnitude: 0.53001
Value Function Update Magnitude: 0.62027

Collected Steps per Second: 22,345.38649
Overall Steps per Second: 10,507.36275

Timestep Collection Time: 2.23867
Timestep Consumption Time: 2.52218
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.76085

Cumulative Model Updates: 57,900
Cumulative Timesteps: 483,001,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 483001412...
Checkpoint 483001412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.77876
Policy Entropy: 3.37907
Value Function Loss: 0.00312

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07081
Policy Update Magnitude: 0.52523
Value Function Update Magnitude: 0.61149

Collected Steps per Second: 22,354.87338
Overall Steps per Second: 10,476.55284

Timestep Collection Time: 2.23683
Timestep Consumption Time: 2.53612
PPO Batch Consumption Time: 0.30003
Total Iteration Time: 4.77294

Cumulative Model Updates: 57,906
Cumulative Timesteps: 483,051,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.64553
Policy Entropy: 3.37011
Value Function Loss: 0.00328

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07500
Policy Update Magnitude: 0.51887
Value Function Update Magnitude: 0.61562

Collected Steps per Second: 22,598.04376
Overall Steps per Second: 10,647.13091

Timestep Collection Time: 2.21258
Timestep Consumption Time: 2.48352
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.69610

Cumulative Model Updates: 57,912
Cumulative Timesteps: 483,101,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 483101416...
Checkpoint 483101416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.38082
Policy Entropy: 3.37587
Value Function Loss: 0.00325

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07542
Policy Update Magnitude: 0.52240
Value Function Update Magnitude: 0.61111

Collected Steps per Second: 22,471.01780
Overall Steps per Second: 10,546.69384

Timestep Collection Time: 2.22625
Timestep Consumption Time: 2.51704
PPO Batch Consumption Time: 0.29909
Total Iteration Time: 4.74329

Cumulative Model Updates: 57,918
Cumulative Timesteps: 483,151,442

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.62079
Policy Entropy: 3.36442
Value Function Loss: 0.00349

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09311
Policy Update Magnitude: 0.52866
Value Function Update Magnitude: 0.61645

Collected Steps per Second: 22,763.69164
Overall Steps per Second: 10,756.07251

Timestep Collection Time: 2.19753
Timestep Consumption Time: 2.45323
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.65077

Cumulative Model Updates: 57,924
Cumulative Timesteps: 483,201,466

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 483201466...
Checkpoint 483201466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 712.90068
Policy Entropy: 3.37027
Value Function Loss: 0.00357

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08727
Policy Update Magnitude: 0.53338
Value Function Update Magnitude: 0.63095

Collected Steps per Second: 22,044.74922
Overall Steps per Second: 10,567.72982

Timestep Collection Time: 2.26884
Timestep Consumption Time: 2.46406
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.73290

Cumulative Model Updates: 57,930
Cumulative Timesteps: 483,251,482

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,471.26545
Policy Entropy: 3.37260
Value Function Loss: 0.00347

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08716
Policy Update Magnitude: 0.54076
Value Function Update Magnitude: 0.63335

Collected Steps per Second: 22,797.13905
Overall Steps per Second: 10,570.07445

Timestep Collection Time: 2.19422
Timestep Consumption Time: 2.53819
PPO Batch Consumption Time: 0.30169
Total Iteration Time: 4.73242

Cumulative Model Updates: 57,936
Cumulative Timesteps: 483,301,504

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 483301504...
Checkpoint 483301504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.58975
Policy Entropy: 3.36985
Value Function Loss: 0.00334

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08105
Policy Update Magnitude: 0.53515
Value Function Update Magnitude: 0.62468

Collected Steps per Second: 22,109.30829
Overall Steps per Second: 10,627.70115

Timestep Collection Time: 2.26221
Timestep Consumption Time: 2.44398
PPO Batch Consumption Time: 0.28390
Total Iteration Time: 4.70619

Cumulative Model Updates: 57,942
Cumulative Timesteps: 483,351,520

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 763.85377
Policy Entropy: 3.37485
Value Function Loss: 0.00326

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09657
Policy Update Magnitude: 0.52741
Value Function Update Magnitude: 0.61825

Collected Steps per Second: 22,289.57915
Overall Steps per Second: 10,472.29090

Timestep Collection Time: 2.24410
Timestep Consumption Time: 2.53232
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.77641

Cumulative Model Updates: 57,948
Cumulative Timesteps: 483,401,540

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 483401540...
Checkpoint 483401540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,427.96367
Policy Entropy: 3.36996
Value Function Loss: 0.00326

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11473
Policy Update Magnitude: 0.52117
Value Function Update Magnitude: 0.60078

Collected Steps per Second: 21,857.90248
Overall Steps per Second: 10,576.40274

Timestep Collection Time: 2.28769
Timestep Consumption Time: 2.44020
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.72788

Cumulative Model Updates: 57,954
Cumulative Timesteps: 483,451,544

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 866.35916
Policy Entropy: 3.36603
Value Function Loss: 0.00321

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.11717
Policy Update Magnitude: 0.51412
Value Function Update Magnitude: 0.59406

Collected Steps per Second: 21,983.82942
Overall Steps per Second: 10,451.42408

Timestep Collection Time: 2.27522
Timestep Consumption Time: 2.51054
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.78576

Cumulative Model Updates: 57,960
Cumulative Timesteps: 483,501,562

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 483501562...
Checkpoint 483501562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.47701
Policy Entropy: 3.36603
Value Function Loss: 0.00326

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10359
Policy Update Magnitude: 0.52022
Value Function Update Magnitude: 0.57823

Collected Steps per Second: 22,305.14899
Overall Steps per Second: 10,516.97109

Timestep Collection Time: 2.24262
Timestep Consumption Time: 2.51369
PPO Batch Consumption Time: 0.29915
Total Iteration Time: 4.75631

Cumulative Model Updates: 57,966
Cumulative Timesteps: 483,551,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.47708
Policy Entropy: 3.35976
Value Function Loss: 0.00325

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09535
Policy Update Magnitude: 0.51991
Value Function Update Magnitude: 0.56674

Collected Steps per Second: 22,333.05127
Overall Steps per Second: 10,599.95845

Timestep Collection Time: 2.24027
Timestep Consumption Time: 2.47975
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.72002

Cumulative Model Updates: 57,972
Cumulative Timesteps: 483,601,616

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 483601616...
Checkpoint 483601616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546.00370
Policy Entropy: 3.36914
Value Function Loss: 0.00335

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08159
Policy Update Magnitude: 0.52920
Value Function Update Magnitude: 0.59156

Collected Steps per Second: 22,196.89938
Overall Steps per Second: 10,343.09605

Timestep Collection Time: 2.25383
Timestep Consumption Time: 2.58302
PPO Batch Consumption Time: 0.29955
Total Iteration Time: 4.83685

Cumulative Model Updates: 57,978
Cumulative Timesteps: 483,651,644

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 951.48699
Policy Entropy: 3.38149
Value Function Loss: 0.00338

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.07840
Policy Update Magnitude: 0.53069
Value Function Update Magnitude: 0.60799

Collected Steps per Second: 22,519.27642
Overall Steps per Second: 10,545.85253

Timestep Collection Time: 2.22165
Timestep Consumption Time: 2.52239
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.74405

Cumulative Model Updates: 57,984
Cumulative Timesteps: 483,701,674

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 483701674...
Checkpoint 483701674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 793.15800
Policy Entropy: 3.39470
Value Function Loss: 0.00339

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07817
Policy Update Magnitude: 0.53282
Value Function Update Magnitude: 0.61411

Collected Steps per Second: 22,637.38683
Overall Steps per Second: 10,473.13319

Timestep Collection Time: 2.20927
Timestep Consumption Time: 2.56600
PPO Batch Consumption Time: 0.30041
Total Iteration Time: 4.77527

Cumulative Model Updates: 57,990
Cumulative Timesteps: 483,751,686

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 863.59999
Policy Entropy: 3.39045
Value Function Loss: 0.00325

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06370
Policy Update Magnitude: 0.52867
Value Function Update Magnitude: 0.60563

Collected Steps per Second: 22,401.72354
Overall Steps per Second: 10,418.24670

Timestep Collection Time: 2.23206
Timestep Consumption Time: 2.56740
PPO Batch Consumption Time: 0.29912
Total Iteration Time: 4.79946

Cumulative Model Updates: 57,996
Cumulative Timesteps: 483,801,688

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 483801688...
Checkpoint 483801688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,610.70939
Policy Entropy: 3.39215
Value Function Loss: 0.00338

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06611
Policy Update Magnitude: 0.52507
Value Function Update Magnitude: 0.59566

Collected Steps per Second: 22,055.89911
Overall Steps per Second: 10,446.88564

Timestep Collection Time: 2.26742
Timestep Consumption Time: 2.51965
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.78707

Cumulative Model Updates: 58,002
Cumulative Timesteps: 483,851,698

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.02089
Policy Entropy: 3.39462
Value Function Loss: 0.00336

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06531
Policy Update Magnitude: 0.52550
Value Function Update Magnitude: 0.60419

Collected Steps per Second: 22,598.79755
Overall Steps per Second: 10,671.81655

Timestep Collection Time: 2.21286
Timestep Consumption Time: 2.47313
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.68599

Cumulative Model Updates: 58,008
Cumulative Timesteps: 483,901,706

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 483901706...
Checkpoint 483901706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,812.41490
Policy Entropy: 3.39448
Value Function Loss: 0.00336

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.06935
Policy Update Magnitude: 0.53022
Value Function Update Magnitude: 0.62169

Collected Steps per Second: 22,222.69126
Overall Steps per Second: 10,616.09253

Timestep Collection Time: 2.25049
Timestep Consumption Time: 2.46047
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.71096

Cumulative Model Updates: 58,014
Cumulative Timesteps: 483,951,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.91995
Policy Entropy: 3.38687
Value Function Loss: 0.00311

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08245
Policy Update Magnitude: 0.51725
Value Function Update Magnitude: 0.60661

Collected Steps per Second: 21,812.77185
Overall Steps per Second: 10,425.70974

Timestep Collection Time: 2.29260
Timestep Consumption Time: 2.50400
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.79660

Cumulative Model Updates: 58,020
Cumulative Timesteps: 484,001,726

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 484001726...
Checkpoint 484001726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,634.06587
Policy Entropy: 3.37976
Value Function Loss: 0.00321

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07825
Policy Update Magnitude: 0.51178
Value Function Update Magnitude: 0.59162

Collected Steps per Second: 21,881.92136
Overall Steps per Second: 10,354.70871

Timestep Collection Time: 2.28581
Timestep Consumption Time: 2.54465
PPO Batch Consumption Time: 0.29887
Total Iteration Time: 4.83046

Cumulative Model Updates: 58,026
Cumulative Timesteps: 484,051,744

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 811.57162
Policy Entropy: 3.37900
Value Function Loss: 0.00338

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.52585
Value Function Update Magnitude: 0.59401

Collected Steps per Second: 21,245.54922
Overall Steps per Second: 10,293.20567

Timestep Collection Time: 2.35343
Timestep Consumption Time: 2.50414
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.85757

Cumulative Model Updates: 58,032
Cumulative Timesteps: 484,101,744

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 484101744...
Checkpoint 484101744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 973.62119
Policy Entropy: 3.38628
Value Function Loss: 0.00349

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08583
Policy Update Magnitude: 0.53056
Value Function Update Magnitude: 0.60224

Collected Steps per Second: 21,515.81878
Overall Steps per Second: 10,201.49857

Timestep Collection Time: 2.32406
Timestep Consumption Time: 2.57758
PPO Batch Consumption Time: 0.30639
Total Iteration Time: 4.90163

Cumulative Model Updates: 58,038
Cumulative Timesteps: 484,151,748

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.27558
Policy Entropy: 3.38512
Value Function Loss: 0.00338

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07654
Policy Update Magnitude: 0.53479
Value Function Update Magnitude: 0.61361

Collected Steps per Second: 21,775.40568
Overall Steps per Second: 10,351.76482

Timestep Collection Time: 2.29681
Timestep Consumption Time: 2.53464
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.83145

Cumulative Model Updates: 58,044
Cumulative Timesteps: 484,201,762

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 484201762...
Checkpoint 484201762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.24061
Policy Entropy: 3.38235
Value Function Loss: 0.00328

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.07905
Policy Update Magnitude: 0.52600
Value Function Update Magnitude: 0.60762

Collected Steps per Second: 22,090.85124
Overall Steps per Second: 10,429.71219

Timestep Collection Time: 2.26438
Timestep Consumption Time: 2.53173
PPO Batch Consumption Time: 0.29819
Total Iteration Time: 4.79611

Cumulative Model Updates: 58,050
Cumulative Timesteps: 484,251,784

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 857.10000
Policy Entropy: 3.37960
Value Function Loss: 0.00338

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.06549
Policy Update Magnitude: 0.53300
Value Function Update Magnitude: 0.61337

Collected Steps per Second: 22,485.05929
Overall Steps per Second: 10,538.66418

Timestep Collection Time: 2.22494
Timestep Consumption Time: 2.52215
PPO Batch Consumption Time: 0.29720
Total Iteration Time: 4.74709

Cumulative Model Updates: 58,056
Cumulative Timesteps: 484,301,812

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 484301812...
Checkpoint 484301812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.67893
Policy Entropy: 3.37251
Value Function Loss: 0.00346

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07122
Policy Update Magnitude: 0.54101
Value Function Update Magnitude: 0.63141

Collected Steps per Second: 22,300.59229
Overall Steps per Second: 10,517.14587

Timestep Collection Time: 2.24218
Timestep Consumption Time: 2.51215
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.75433

Cumulative Model Updates: 58,062
Cumulative Timesteps: 484,351,814

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 818.35997
Policy Entropy: 3.35885
Value Function Loss: 0.00349

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07879
Policy Update Magnitude: 0.54600
Value Function Update Magnitude: 0.65143

Collected Steps per Second: 22,309.72118
Overall Steps per Second: 10,408.31180

Timestep Collection Time: 2.24198
Timestep Consumption Time: 2.56360
PPO Batch Consumption Time: 0.29827
Total Iteration Time: 4.80558

Cumulative Model Updates: 58,068
Cumulative Timesteps: 484,401,832

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 484401832...
Checkpoint 484401832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646.08617
Policy Entropy: 3.37198
Value Function Loss: 0.00325

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08700
Policy Update Magnitude: 0.54514
Value Function Update Magnitude: 0.65011

Collected Steps per Second: 22,353.62133
Overall Steps per Second: 10,690.43905

Timestep Collection Time: 2.23722
Timestep Consumption Time: 2.44079
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.67801

Cumulative Model Updates: 58,074
Cumulative Timesteps: 484,451,842

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,121.73661
Policy Entropy: 3.36501
Value Function Loss: 0.00330

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07845
Policy Update Magnitude: 0.53252
Value Function Update Magnitude: 0.62546

Collected Steps per Second: 22,516.30390
Overall Steps per Second: 10,528.62206

Timestep Collection Time: 2.22088
Timestep Consumption Time: 2.52865
PPO Batch Consumption Time: 0.29972
Total Iteration Time: 4.74953

Cumulative Model Updates: 58,080
Cumulative Timesteps: 484,501,848

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 484501848...
Checkpoint 484501848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.84067
Policy Entropy: 3.36952
Value Function Loss: 0.00328

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08399
Policy Update Magnitude: 0.52481
Value Function Update Magnitude: 0.62482

Collected Steps per Second: 22,681.62683
Overall Steps per Second: 10,541.45206

Timestep Collection Time: 2.20487
Timestep Consumption Time: 2.53926
PPO Batch Consumption Time: 0.29964
Total Iteration Time: 4.74413

Cumulative Model Updates: 58,086
Cumulative Timesteps: 484,551,858

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,895.23997
Policy Entropy: 3.36266
Value Function Loss: 0.00350

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07346
Policy Update Magnitude: 0.52877
Value Function Update Magnitude: 0.63524

Collected Steps per Second: 21,296.95692
Overall Steps per Second: 10,387.35072

Timestep Collection Time: 2.34907
Timestep Consumption Time: 2.46717
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.81624

Cumulative Model Updates: 58,092
Cumulative Timesteps: 484,601,886

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 484601886...
Checkpoint 484601886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.81342
Policy Entropy: 3.36926
Value Function Loss: 0.00345

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07214
Policy Update Magnitude: 0.54139
Value Function Update Magnitude: 0.63624

Collected Steps per Second: 22,206.04755
Overall Steps per Second: 10,611.04085

Timestep Collection Time: 2.25263
Timestep Consumption Time: 2.46152
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.71415

Cumulative Model Updates: 58,098
Cumulative Timesteps: 484,651,908

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640.90233
Policy Entropy: 3.36881
Value Function Loss: 0.00346

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07537
Policy Update Magnitude: 0.54344
Value Function Update Magnitude: 0.62180

Collected Steps per Second: 22,046.77234
Overall Steps per Second: 10,633.44243

Timestep Collection Time: 2.26863
Timestep Consumption Time: 2.43502
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.70365

Cumulative Model Updates: 58,104
Cumulative Timesteps: 484,701,924

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 484701924...
Checkpoint 484701924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 748.65512
Policy Entropy: 3.36254
Value Function Loss: 0.00351

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08031
Policy Update Magnitude: 0.54352
Value Function Update Magnitude: 0.61886

Collected Steps per Second: 22,231.85613
Overall Steps per Second: 10,563.82148

Timestep Collection Time: 2.24992
Timestep Consumption Time: 2.48510
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.73503

Cumulative Model Updates: 58,110
Cumulative Timesteps: 484,751,944

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 816.04257
Policy Entropy: 3.36803
Value Function Loss: 0.00365

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09719
Policy Update Magnitude: 0.54292
Value Function Update Magnitude: 0.64278

Collected Steps per Second: 22,563.81838
Overall Steps per Second: 10,471.76824

Timestep Collection Time: 2.21594
Timestep Consumption Time: 2.55881
PPO Batch Consumption Time: 0.30262
Total Iteration Time: 4.77474

Cumulative Model Updates: 58,116
Cumulative Timesteps: 484,801,944

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 484801944...
Checkpoint 484801944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 861.59888
Policy Entropy: 3.36853
Value Function Loss: 0.00362

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.55231
Value Function Update Magnitude: 0.64710

Collected Steps per Second: 22,139.46740
Overall Steps per Second: 10,368.02831

Timestep Collection Time: 2.25904
Timestep Consumption Time: 2.56483
PPO Batch Consumption Time: 0.29862
Total Iteration Time: 4.82387

Cumulative Model Updates: 58,122
Cumulative Timesteps: 484,851,958

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 806.12882
Policy Entropy: 3.36353
Value Function Loss: 0.00362

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.54924
Value Function Update Magnitude: 0.64518

Collected Steps per Second: 22,386.61028
Overall Steps per Second: 10,435.59297

Timestep Collection Time: 2.23455
Timestep Consumption Time: 2.55904
PPO Batch Consumption Time: 0.29721
Total Iteration Time: 4.79359

Cumulative Model Updates: 58,128
Cumulative Timesteps: 484,901,982

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 484901982...
Checkpoint 484901982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.07030
Policy Entropy: 3.35775
Value Function Loss: 0.00346

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09223
Policy Update Magnitude: 0.54352
Value Function Update Magnitude: 0.63689

Collected Steps per Second: 22,498.24005
Overall Steps per Second: 10,537.15389

Timestep Collection Time: 2.22364
Timestep Consumption Time: 2.52413
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.74777

Cumulative Model Updates: 58,134
Cumulative Timesteps: 484,952,010

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 997.31561
Policy Entropy: 3.36249
Value Function Loss: 0.00350

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09675
Policy Update Magnitude: 0.54162
Value Function Update Magnitude: 0.63071

Collected Steps per Second: 22,065.32598
Overall Steps per Second: 10,372.91985

Timestep Collection Time: 2.26645
Timestep Consumption Time: 2.55476
PPO Batch Consumption Time: 0.29774
Total Iteration Time: 4.82121

Cumulative Model Updates: 58,140
Cumulative Timesteps: 485,002,020

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 485002020...
Checkpoint 485002020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 876.05132
Policy Entropy: 3.38566
Value Function Loss: 0.00356

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09250
Policy Update Magnitude: 0.54137
Value Function Update Magnitude: 0.64847

Collected Steps per Second: 22,285.31619
Overall Steps per Second: 10,586.39666

Timestep Collection Time: 2.24498
Timestep Consumption Time: 2.48090
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.72588

Cumulative Model Updates: 58,146
Cumulative Timesteps: 485,052,050

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.24724
Policy Entropy: 3.40161
Value Function Loss: 0.00360

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.10219
Policy Update Magnitude: 0.54740
Value Function Update Magnitude: 0.66469

Collected Steps per Second: 22,385.21779
Overall Steps per Second: 10,538.75069

Timestep Collection Time: 2.23388
Timestep Consumption Time: 2.51108
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.74496

Cumulative Model Updates: 58,152
Cumulative Timesteps: 485,102,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 485102056...
Checkpoint 485102056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.33797
Policy Entropy: 3.39678
Value Function Loss: 0.00351

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.10896
Policy Update Magnitude: 0.54044
Value Function Update Magnitude: 0.65179

Collected Steps per Second: 22,785.64201
Overall Steps per Second: 10,633.41992

Timestep Collection Time: 2.19480
Timestep Consumption Time: 2.50829
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.70310

Cumulative Model Updates: 58,158
Cumulative Timesteps: 485,152,066

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728.94110
Policy Entropy: 3.38119
Value Function Loss: 0.00338

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10117
Policy Update Magnitude: 0.52806
Value Function Update Magnitude: 0.64925

Collected Steps per Second: 22,012.89324
Overall Steps per Second: 10,514.69044

Timestep Collection Time: 2.27285
Timestep Consumption Time: 2.48545
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.75830

Cumulative Model Updates: 58,164
Cumulative Timesteps: 485,202,098

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 485202098...
Checkpoint 485202098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 957.71232
Policy Entropy: 3.34912
Value Function Loss: 0.00331

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10721
Policy Update Magnitude: 0.52469
Value Function Update Magnitude: 0.63383

Collected Steps per Second: 21,992.66571
Overall Steps per Second: 10,573.46252

Timestep Collection Time: 2.27349
Timestep Consumption Time: 2.45533
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.72882

Cumulative Model Updates: 58,170
Cumulative Timesteps: 485,252,098

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628.63996
Policy Entropy: 3.33439
Value Function Loss: 0.00364

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09059
Policy Update Magnitude: 0.52901
Value Function Update Magnitude: 0.66491

Collected Steps per Second: 22,082.50799
Overall Steps per Second: 10,476.10948

Timestep Collection Time: 2.26532
Timestep Consumption Time: 2.50973
PPO Batch Consumption Time: 0.29586
Total Iteration Time: 4.77506

Cumulative Model Updates: 58,176
Cumulative Timesteps: 485,302,122

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 485302122...
Checkpoint 485302122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 864.89980
Policy Entropy: 3.34196
Value Function Loss: 0.00373

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10013
Policy Update Magnitude: 0.54025
Value Function Update Magnitude: 0.68004

Collected Steps per Second: 21,925.05796
Overall Steps per Second: 10,557.69211

Timestep Collection Time: 2.28150
Timestep Consumption Time: 2.45647
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.73797

Cumulative Model Updates: 58,182
Cumulative Timesteps: 485,352,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,503.66531
Policy Entropy: 3.35606
Value Function Loss: 0.00370

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08530
Policy Update Magnitude: 0.54376
Value Function Update Magnitude: 0.67760

Collected Steps per Second: 22,059.65572
Overall Steps per Second: 10,498.16582

Timestep Collection Time: 2.26722
Timestep Consumption Time: 2.49685
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.76407

Cumulative Model Updates: 58,188
Cumulative Timesteps: 485,402,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 485402158...
Checkpoint 485402158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701.83479
Policy Entropy: 3.35160
Value Function Loss: 0.00365

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07937
Policy Update Magnitude: 0.55033
Value Function Update Magnitude: 0.66535

Collected Steps per Second: 22,164.76655
Overall Steps per Second: 10,463.73546

Timestep Collection Time: 2.25592
Timestep Consumption Time: 2.52268
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.77860

Cumulative Model Updates: 58,194
Cumulative Timesteps: 485,452,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 909.80370
Policy Entropy: 3.34408
Value Function Loss: 0.00376

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10319
Policy Update Magnitude: 0.54597
Value Function Update Magnitude: 0.66472

Collected Steps per Second: 22,405.61490
Overall Steps per Second: 10,503.05202

Timestep Collection Time: 2.23274
Timestep Consumption Time: 2.53025
PPO Batch Consumption Time: 0.29728
Total Iteration Time: 4.76300

Cumulative Model Updates: 58,200
Cumulative Timesteps: 485,502,186

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 485502186...
Checkpoint 485502186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 810.30205
Policy Entropy: 3.33528
Value Function Loss: 0.00371

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11010
Policy Update Magnitude: 0.54156
Value Function Update Magnitude: 0.65159

Collected Steps per Second: 22,503.07660
Overall Steps per Second: 10,713.27322

Timestep Collection Time: 2.22307
Timestep Consumption Time: 2.44646
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.66953

Cumulative Model Updates: 58,206
Cumulative Timesteps: 485,552,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713.15291
Policy Entropy: 3.30266
Value Function Loss: 0.00380

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.53991
Value Function Update Magnitude: 0.63867

Collected Steps per Second: 22,388.72452
Overall Steps per Second: 10,554.10441

Timestep Collection Time: 2.23380
Timestep Consumption Time: 2.50483
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.73863

Cumulative Model Updates: 58,212
Cumulative Timesteps: 485,602,224

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 485602224...
Checkpoint 485602224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.22441
Policy Entropy: 3.30064
Value Function Loss: 0.00401

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11135
Policy Update Magnitude: 0.53915
Value Function Update Magnitude: 0.65069

Collected Steps per Second: 22,685.90665
Overall Steps per Second: 10,630.66169

Timestep Collection Time: 2.20454
Timestep Consumption Time: 2.49996
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.70450

Cumulative Model Updates: 58,218
Cumulative Timesteps: 485,652,236

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 885.19653
Policy Entropy: 3.28480
Value Function Loss: 0.00387

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10260
Policy Update Magnitude: 0.55036
Value Function Update Magnitude: 0.64879

Collected Steps per Second: 22,150.06844
Overall Steps per Second: 10,457.83184

Timestep Collection Time: 2.25823
Timestep Consumption Time: 2.52479
PPO Batch Consumption Time: 0.29897
Total Iteration Time: 4.78302

Cumulative Model Updates: 58,224
Cumulative Timesteps: 485,702,256

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 485702256...
Checkpoint 485702256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 851.11726
Policy Entropy: 3.29552
Value Function Loss: 0.00369

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10713
Policy Update Magnitude: 0.54220
Value Function Update Magnitude: 0.63077

Collected Steps per Second: 22,462.81309
Overall Steps per Second: 10,689.24194

Timestep Collection Time: 2.22644
Timestep Consumption Time: 2.45229
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.67872

Cumulative Model Updates: 58,230
Cumulative Timesteps: 485,752,268

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 816.24723
Policy Entropy: 3.30138
Value Function Loss: 0.00346

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09599
Policy Update Magnitude: 0.52689
Value Function Update Magnitude: 0.61502

Collected Steps per Second: 21,936.37932
Overall Steps per Second: 10,421.17282

Timestep Collection Time: 2.28005
Timestep Consumption Time: 2.51941
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.79946

Cumulative Model Updates: 58,236
Cumulative Timesteps: 485,802,284

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 485802284...
Checkpoint 485802284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415.13532
Policy Entropy: 3.31487
Value Function Loss: 0.00335

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08527
Policy Update Magnitude: 0.51719
Value Function Update Magnitude: 0.60608

Collected Steps per Second: 21,769.22248
Overall Steps per Second: 10,530.89885

Timestep Collection Time: 2.29737
Timestep Consumption Time: 2.45170
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.74907

Cumulative Model Updates: 58,242
Cumulative Timesteps: 485,852,296

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,753.82689
Policy Entropy: 3.32200
Value Function Loss: 0.00318

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07839
Policy Update Magnitude: 0.50868
Value Function Update Magnitude: 0.58505

Collected Steps per Second: 22,327.85976
Overall Steps per Second: 10,576.19181

Timestep Collection Time: 2.23971
Timestep Consumption Time: 2.48864
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.72836

Cumulative Model Updates: 58,248
Cumulative Timesteps: 485,902,304

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 485902304...
Checkpoint 485902304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.50959
Policy Entropy: 3.31440
Value Function Loss: 0.00329

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09236
Policy Update Magnitude: 0.50519
Value Function Update Magnitude: 0.58304

Collected Steps per Second: 21,716.67574
Overall Steps per Second: 10,531.22478

Timestep Collection Time: 2.30358
Timestep Consumption Time: 2.44668
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.75025

Cumulative Model Updates: 58,254
Cumulative Timesteps: 485,952,330

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.22543
Policy Entropy: 3.31992
Value Function Loss: 0.00322

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10798
Policy Update Magnitude: 0.50410
Value Function Update Magnitude: 0.59302

Collected Steps per Second: 22,246.47595
Overall Steps per Second: 10,509.77648

Timestep Collection Time: 2.24818
Timestep Consumption Time: 2.51063
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.75881

Cumulative Model Updates: 58,260
Cumulative Timesteps: 486,002,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 486002344...
Checkpoint 486002344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.79240
Policy Entropy: 3.31918
Value Function Loss: 0.00335

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10469
Policy Update Magnitude: 0.50971
Value Function Update Magnitude: 0.58638

Collected Steps per Second: 21,945.33354
Overall Steps per Second: 10,475.65873

Timestep Collection Time: 2.27966
Timestep Consumption Time: 2.49598
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.77564

Cumulative Model Updates: 58,266
Cumulative Timesteps: 486,052,372

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 877.88999
Policy Entropy: 3.32400
Value Function Loss: 0.00339

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10265
Policy Update Magnitude: 0.51191
Value Function Update Magnitude: 0.59102

Collected Steps per Second: 22,757.53884
Overall Steps per Second: 10,667.40422

Timestep Collection Time: 2.19778
Timestep Consumption Time: 2.49090
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.68868

Cumulative Model Updates: 58,272
Cumulative Timesteps: 486,102,388

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 486102388...
Checkpoint 486102388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 763.97005
Policy Entropy: 3.32005
Value Function Loss: 0.00351

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07445
Policy Update Magnitude: 0.51914
Value Function Update Magnitude: 0.60754

Collected Steps per Second: 22,042.62317
Overall Steps per Second: 10,521.97627

Timestep Collection Time: 2.26924
Timestep Consumption Time: 2.48462
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.75386

Cumulative Model Updates: 58,278
Cumulative Timesteps: 486,152,408

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.49135
Policy Entropy: 3.32804
Value Function Loss: 0.00348

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07196
Policy Update Magnitude: 0.52770
Value Function Update Magnitude: 0.60864

Collected Steps per Second: 22,034.19847
Overall Steps per Second: 10,590.25243

Timestep Collection Time: 2.26993
Timestep Consumption Time: 2.45291
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.72283

Cumulative Model Updates: 58,284
Cumulative Timesteps: 486,202,424

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 486202424...
Checkpoint 486202424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 951.13880
Policy Entropy: 3.31076
Value Function Loss: 0.00361

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08169
Policy Update Magnitude: 0.53159
Value Function Update Magnitude: 0.60221

Collected Steps per Second: 22,486.74205
Overall Steps per Second: 10,563.39456

Timestep Collection Time: 2.22478
Timestep Consumption Time: 2.51120
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.73598

Cumulative Model Updates: 58,290
Cumulative Timesteps: 486,252,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,807.34350
Policy Entropy: 3.30923
Value Function Loss: 0.00344

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07708
Policy Update Magnitude: 0.53190
Value Function Update Magnitude: 0.61098

Collected Steps per Second: 22,288.40154
Overall Steps per Second: 10,557.65891

Timestep Collection Time: 2.24431
Timestep Consumption Time: 2.49368
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.73798

Cumulative Model Updates: 58,296
Cumulative Timesteps: 486,302,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 486302474...
Checkpoint 486302474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,899.68518
Policy Entropy: 3.31324
Value Function Loss: 0.00364

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.53739
Value Function Update Magnitude: 0.61320

Collected Steps per Second: 22,243.12704
Overall Steps per Second: 10,601.80168

Timestep Collection Time: 2.24860
Timestep Consumption Time: 2.46908
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.71769

Cumulative Model Updates: 58,302
Cumulative Timesteps: 486,352,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.41439
Policy Entropy: 3.32069
Value Function Loss: 0.00350

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08726
Policy Update Magnitude: 0.54341
Value Function Update Magnitude: 0.63207

Collected Steps per Second: 22,674.39089
Overall Steps per Second: 10,620.97348

Timestep Collection Time: 2.20513
Timestep Consumption Time: 2.50254
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.70767

Cumulative Model Updates: 58,308
Cumulative Timesteps: 486,402,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 486402490...
Checkpoint 486402490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,405.51157
Policy Entropy: 3.32954
Value Function Loss: 0.00370

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08394
Policy Update Magnitude: 0.55082
Value Function Update Magnitude: 0.63606

Collected Steps per Second: 22,418.88075
Overall Steps per Second: 10,489.80390

Timestep Collection Time: 2.23035
Timestep Consumption Time: 2.53637
PPO Batch Consumption Time: 0.29885
Total Iteration Time: 4.76672

Cumulative Model Updates: 58,314
Cumulative Timesteps: 486,452,492

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,557.62152
Policy Entropy: 3.32640
Value Function Loss: 0.00360

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08701
Policy Update Magnitude: 0.54590
Value Function Update Magnitude: 0.65260

Collected Steps per Second: 22,101.10533
Overall Steps per Second: 10,423.59780

Timestep Collection Time: 2.26351
Timestep Consumption Time: 2.53580
PPO Batch Consumption Time: 0.29975
Total Iteration Time: 4.79930

Cumulative Model Updates: 58,320
Cumulative Timesteps: 486,502,518

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 486502518...
Checkpoint 486502518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.41603
Policy Entropy: 3.33419
Value Function Loss: 0.00346

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08725
Policy Update Magnitude: 0.54080
Value Function Update Magnitude: 0.64292

Collected Steps per Second: 21,268.54827
Overall Steps per Second: 10,294.29716

Timestep Collection Time: 2.35174
Timestep Consumption Time: 2.50707
PPO Batch Consumption Time: 0.29800
Total Iteration Time: 4.85881

Cumulative Model Updates: 58,326
Cumulative Timesteps: 486,552,536

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.05686
Policy Entropy: 3.32686
Value Function Loss: 0.00337

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09308
Policy Update Magnitude: 0.53500
Value Function Update Magnitude: 0.62635

Collected Steps per Second: 22,140.72357
Overall Steps per Second: 10,429.38246

Timestep Collection Time: 2.25882
Timestep Consumption Time: 2.53647
PPO Batch Consumption Time: 0.30087
Total Iteration Time: 4.79530

Cumulative Model Updates: 58,332
Cumulative Timesteps: 486,602,548

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 486602548...
Checkpoint 486602548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.24637
Policy Entropy: 3.33788
Value Function Loss: 0.00342

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10807
Policy Update Magnitude: 0.52416
Value Function Update Magnitude: 0.61505

Collected Steps per Second: 22,148.19314
Overall Steps per Second: 10,664.83151

Timestep Collection Time: 2.25779
Timestep Consumption Time: 2.43108
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.68887

Cumulative Model Updates: 58,338
Cumulative Timesteps: 486,652,554

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.38126
Policy Entropy: 3.34271
Value Function Loss: 0.00356

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.51494
Value Function Update Magnitude: 0.64192

Collected Steps per Second: 22,290.89353
Overall Steps per Second: 10,487.00373

Timestep Collection Time: 2.24406
Timestep Consumption Time: 2.52585
PPO Batch Consumption Time: 0.29989
Total Iteration Time: 4.76990

Cumulative Model Updates: 58,344
Cumulative Timesteps: 486,702,576

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 486702576...
Checkpoint 486702576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.47365
Policy Entropy: 3.34843
Value Function Loss: 0.00357

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10648
Policy Update Magnitude: 0.52557
Value Function Update Magnitude: 0.63038

Collected Steps per Second: 22,299.69804
Overall Steps per Second: 10,609.32636

Timestep Collection Time: 2.24308
Timestep Consumption Time: 2.47164
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.71472

Cumulative Model Updates: 58,350
Cumulative Timesteps: 486,752,596

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.62432
Policy Entropy: 3.34390
Value Function Loss: 0.00370

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11218
Policy Update Magnitude: 0.54051
Value Function Update Magnitude: 0.64238

Collected Steps per Second: 21,999.48360
Overall Steps per Second: 10,482.00345

Timestep Collection Time: 2.27342
Timestep Consumption Time: 2.49800
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.77142

Cumulative Model Updates: 58,356
Cumulative Timesteps: 486,802,610

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 486802610...
Checkpoint 486802610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.11150
Policy Entropy: 3.33309
Value Function Loss: 0.00370

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11860
Policy Update Magnitude: 0.54158
Value Function Update Magnitude: 0.65601

Collected Steps per Second: 22,148.22851
Overall Steps per Second: 10,543.88549

Timestep Collection Time: 2.25851
Timestep Consumption Time: 2.48566
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.74417

Cumulative Model Updates: 58,362
Cumulative Timesteps: 486,852,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,354.59911
Policy Entropy: 3.32667
Value Function Loss: 0.00371

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11618
Policy Update Magnitude: 0.53646
Value Function Update Magnitude: 0.67206

Collected Steps per Second: 22,413.70399
Overall Steps per Second: 10,536.59551

Timestep Collection Time: 2.23078
Timestep Consumption Time: 2.51459
PPO Batch Consumption Time: 0.29883
Total Iteration Time: 4.74537

Cumulative Model Updates: 58,368
Cumulative Timesteps: 486,902,632

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 486902632...
Checkpoint 486902632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 763.88658
Policy Entropy: 3.31002
Value Function Loss: 0.00362

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11999
Policy Update Magnitude: 0.53381
Value Function Update Magnitude: 0.65873

Collected Steps per Second: 22,246.85295
Overall Steps per Second: 10,584.74033

Timestep Collection Time: 2.24760
Timestep Consumption Time: 2.47637
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.72397

Cumulative Model Updates: 58,374
Cumulative Timesteps: 486,952,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801.55180
Policy Entropy: 3.31934
Value Function Loss: 0.00350

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09779
Policy Update Magnitude: 0.52129
Value Function Update Magnitude: 0.64740

Collected Steps per Second: 22,810.95929
Overall Steps per Second: 10,633.25573

Timestep Collection Time: 2.19254
Timestep Consumption Time: 2.51100
PPO Batch Consumption Time: 0.29517
Total Iteration Time: 4.70355

Cumulative Model Updates: 58,380
Cumulative Timesteps: 487,002,648

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 487002648...
Checkpoint 487002648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.15907
Policy Entropy: 3.33450
Value Function Loss: 0.00344

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08204
Policy Update Magnitude: 0.51384
Value Function Update Magnitude: 0.63534

Collected Steps per Second: 22,542.54596
Overall Steps per Second: 10,609.72429

Timestep Collection Time: 2.21936
Timestep Consumption Time: 2.49613
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.71549

Cumulative Model Updates: 58,386
Cumulative Timesteps: 487,052,678

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 791.61816
Policy Entropy: 3.34797
Value Function Loss: 0.00352

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07854
Policy Update Magnitude: 0.51904
Value Function Update Magnitude: 0.63913

Collected Steps per Second: 22,810.87858
Overall Steps per Second: 10,750.53026

Timestep Collection Time: 2.19316
Timestep Consumption Time: 2.46037
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.65354

Cumulative Model Updates: 58,392
Cumulative Timesteps: 487,102,706

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 487102706...
Checkpoint 487102706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726.65816
Policy Entropy: 3.34978
Value Function Loss: 0.00360

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08445
Policy Update Magnitude: 0.52575
Value Function Update Magnitude: 0.64482

Collected Steps per Second: 21,829.62090
Overall Steps per Second: 10,609.53656

Timestep Collection Time: 2.29147
Timestep Consumption Time: 2.42334
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.71481

Cumulative Model Updates: 58,398
Cumulative Timesteps: 487,152,728

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714.21994
Policy Entropy: 3.35032
Value Function Loss: 0.00380

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09298
Policy Update Magnitude: 0.54100
Value Function Update Magnitude: 0.65426

Collected Steps per Second: 22,022.81962
Overall Steps per Second: 10,495.74822

Timestep Collection Time: 2.27210
Timestep Consumption Time: 2.49536
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.76745

Cumulative Model Updates: 58,404
Cumulative Timesteps: 487,202,766

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 487202766...
Checkpoint 487202766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.76850
Policy Entropy: 3.33884
Value Function Loss: 0.00367

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.54287
Value Function Update Magnitude: 0.64688

Collected Steps per Second: 21,445.41147
Overall Steps per Second: 10,305.15298

Timestep Collection Time: 2.33215
Timestep Consumption Time: 2.52115
PPO Batch Consumption Time: 0.29933
Total Iteration Time: 4.85330

Cumulative Model Updates: 58,410
Cumulative Timesteps: 487,252,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.58554
Policy Entropy: 3.34530
Value Function Loss: 0.00364

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08950
Policy Update Magnitude: 0.57237
Value Function Update Magnitude: 0.63339

Collected Steps per Second: 22,194.20618
Overall Steps per Second: 10,486.58716

Timestep Collection Time: 2.25347
Timestep Consumption Time: 2.51586
PPO Batch Consumption Time: 0.29761
Total Iteration Time: 4.76933

Cumulative Model Updates: 58,416
Cumulative Timesteps: 487,302,794

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 487302794...
Checkpoint 487302794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.70332
Policy Entropy: 3.33119
Value Function Loss: 0.00349

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08632
Policy Update Magnitude: 0.54247
Value Function Update Magnitude: 0.62731

Collected Steps per Second: 21,795.19953
Overall Steps per Second: 10,568.91857

Timestep Collection Time: 2.29546
Timestep Consumption Time: 2.43823
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.73369

Cumulative Model Updates: 58,422
Cumulative Timesteps: 487,352,824

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.06889
Policy Entropy: 3.33765
Value Function Loss: 0.00347

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07619
Policy Update Magnitude: 0.53611
Value Function Update Magnitude: 0.62010

Collected Steps per Second: 22,665.62126
Overall Steps per Second: 10,561.06753

Timestep Collection Time: 2.20801
Timestep Consumption Time: 2.53071
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.73873

Cumulative Model Updates: 58,428
Cumulative Timesteps: 487,402,870

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 487402870...
Checkpoint 487402870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 751.37391
Policy Entropy: 3.34130
Value Function Loss: 0.00350

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07469
Policy Update Magnitude: 0.53915
Value Function Update Magnitude: 0.61783

Collected Steps per Second: 22,076.02069
Overall Steps per Second: 10,478.45238

Timestep Collection Time: 2.26581
Timestep Consumption Time: 2.50780
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.77361

Cumulative Model Updates: 58,434
Cumulative Timesteps: 487,452,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.96913
Policy Entropy: 3.34969
Value Function Loss: 0.00342

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07976
Policy Update Magnitude: 0.52878
Value Function Update Magnitude: 0.61604

Collected Steps per Second: 22,364.99566
Overall Steps per Second: 10,517.64169

Timestep Collection Time: 2.23608
Timestep Consumption Time: 2.51878
PPO Batch Consumption Time: 0.30024
Total Iteration Time: 4.75487

Cumulative Model Updates: 58,440
Cumulative Timesteps: 487,502,900

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 487502900...
Checkpoint 487502900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 835.93402
Policy Entropy: 3.35360
Value Function Loss: 0.00363

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08917
Policy Update Magnitude: 0.52506
Value Function Update Magnitude: 0.61046

Collected Steps per Second: 22,134.70533
Overall Steps per Second: 10,612.94185

Timestep Collection Time: 2.25935
Timestep Consumption Time: 2.45282
PPO Batch Consumption Time: 0.28516
Total Iteration Time: 4.71217

Cumulative Model Updates: 58,446
Cumulative Timesteps: 487,552,910

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 843.02648
Policy Entropy: 3.34869
Value Function Loss: 0.00362

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09457
Policy Update Magnitude: 0.52923
Value Function Update Magnitude: 0.61506

Collected Steps per Second: 22,753.85000
Overall Steps per Second: 10,637.50148

Timestep Collection Time: 2.19822
Timestep Consumption Time: 2.50382
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.70204

Cumulative Model Updates: 58,452
Cumulative Timesteps: 487,602,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 487602928...
Checkpoint 487602928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.35328
Policy Entropy: 3.36173
Value Function Loss: 0.00357

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08997
Policy Update Magnitude: 0.53389
Value Function Update Magnitude: 0.61626

Collected Steps per Second: 22,136.23964
Overall Steps per Second: 10,474.89968

Timestep Collection Time: 2.25901
Timestep Consumption Time: 2.51488
PPO Batch Consumption Time: 0.29662
Total Iteration Time: 4.77389

Cumulative Model Updates: 58,458
Cumulative Timesteps: 487,652,934

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 936.97940
Policy Entropy: 3.36652
Value Function Loss: 0.00348

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08733
Policy Update Magnitude: 0.53326
Value Function Update Magnitude: 0.62668

Collected Steps per Second: 22,480.99385
Overall Steps per Second: 10,528.96692

Timestep Collection Time: 2.22499
Timestep Consumption Time: 2.52571
PPO Batch Consumption Time: 0.29964
Total Iteration Time: 4.75070

Cumulative Model Updates: 58,464
Cumulative Timesteps: 487,702,954

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 487702954...
Checkpoint 487702954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390.85250
Policy Entropy: 3.37983
Value Function Loss: 0.00349

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08894
Policy Update Magnitude: 0.53534
Value Function Update Magnitude: 0.62901

Collected Steps per Second: 22,231.96167
Overall Steps per Second: 10,557.30459

Timestep Collection Time: 2.25018
Timestep Consumption Time: 2.48834
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.73852

Cumulative Model Updates: 58,470
Cumulative Timesteps: 487,752,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.28892
Policy Entropy: 3.38577
Value Function Loss: 0.00339

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08896
Policy Update Magnitude: 0.53010
Value Function Update Magnitude: 0.62933

Collected Steps per Second: 21,766.31487
Overall Steps per Second: 10,423.96472

Timestep Collection Time: 2.29823
Timestep Consumption Time: 2.50071
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.79894

Cumulative Model Updates: 58,476
Cumulative Timesteps: 487,803,004

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 487803004...
Checkpoint 487803004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 801.04803
Policy Entropy: 3.36707
Value Function Loss: 0.00357

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09585
Policy Update Magnitude: 0.52947
Value Function Update Magnitude: 0.64099

Collected Steps per Second: 22,212.08496
Overall Steps per Second: 10,580.93334

Timestep Collection Time: 2.25220
Timestep Consumption Time: 2.47574
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.72794

Cumulative Model Updates: 58,482
Cumulative Timesteps: 487,853,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.30719
Policy Entropy: 3.35667
Value Function Loss: 0.00363

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08745
Policy Update Magnitude: 0.53703
Value Function Update Magnitude: 0.64677

Collected Steps per Second: 22,221.59809
Overall Steps per Second: 10,582.31000

Timestep Collection Time: 2.25024
Timestep Consumption Time: 2.47500
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.72524

Cumulative Model Updates: 58,488
Cumulative Timesteps: 487,903,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 487903034...
Checkpoint 487903034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 906.93379
Policy Entropy: 3.33145
Value Function Loss: 0.00375

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08110
Policy Update Magnitude: 0.54614
Value Function Update Magnitude: 0.65594

Collected Steps per Second: 22,044.57166
Overall Steps per Second: 10,563.71969

Timestep Collection Time: 2.26895
Timestep Consumption Time: 2.46594
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.73489

Cumulative Model Updates: 58,494
Cumulative Timesteps: 487,953,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.89761
Policy Entropy: 3.33247
Value Function Loss: 0.00387

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09243
Policy Update Magnitude: 0.55134
Value Function Update Magnitude: 0.68141

Collected Steps per Second: 22,240.48254
Overall Steps per Second: 10,502.62865

Timestep Collection Time: 2.24932
Timestep Consumption Time: 2.51387
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.76319

Cumulative Model Updates: 58,500
Cumulative Timesteps: 488,003,078

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 488003078...
Checkpoint 488003078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 823.87208
Policy Entropy: 3.31978
Value Function Loss: 0.00401

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09632
Policy Update Magnitude: 0.56065
Value Function Update Magnitude: 0.69557

Collected Steps per Second: 22,100.27578
Overall Steps per Second: 10,636.46990

Timestep Collection Time: 2.26260
Timestep Consumption Time: 2.43859
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.70118

Cumulative Model Updates: 58,506
Cumulative Timesteps: 488,053,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 930.57328
Policy Entropy: 3.32148
Value Function Loss: 0.00398

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08829
Policy Update Magnitude: 0.57059
Value Function Update Magnitude: 0.69777

Collected Steps per Second: 21,824.46316
Overall Steps per Second: 10,380.85622

Timestep Collection Time: 2.29192
Timestep Consumption Time: 2.52656
PPO Batch Consumption Time: 0.30327
Total Iteration Time: 4.81849

Cumulative Model Updates: 58,512
Cumulative Timesteps: 488,103,102

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 488103102...
Checkpoint 488103102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.95908
Policy Entropy: 3.32358
Value Function Loss: 0.00401

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08228
Policy Update Magnitude: 0.57245
Value Function Update Magnitude: 0.70787

Collected Steps per Second: 21,026.48011
Overall Steps per Second: 10,377.46154

Timestep Collection Time: 2.37805
Timestep Consumption Time: 2.44028
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.81833

Cumulative Model Updates: 58,518
Cumulative Timesteps: 488,153,104

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 844.89578
Policy Entropy: 3.32687
Value Function Loss: 0.00412

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07609
Policy Update Magnitude: 0.57194
Value Function Update Magnitude: 0.71213

Collected Steps per Second: 21,618.62274
Overall Steps per Second: 10,455.24046

Timestep Collection Time: 2.31365
Timestep Consumption Time: 2.47036
PPO Batch Consumption Time: 0.29761
Total Iteration Time: 4.78401

Cumulative Model Updates: 58,524
Cumulative Timesteps: 488,203,122

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 488203122...
Checkpoint 488203122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,823.58499
Policy Entropy: 3.34863
Value Function Loss: 0.00388

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08285
Policy Update Magnitude: 0.56989
Value Function Update Magnitude: 0.70829

Collected Steps per Second: 21,849.60286
Overall Steps per Second: 10,536.15038

Timestep Collection Time: 2.28965
Timestep Consumption Time: 2.45857
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 4.74822

Cumulative Model Updates: 58,530
Cumulative Timesteps: 488,253,150

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 874.30174
Policy Entropy: 3.33933
Value Function Loss: 0.00379

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.55769
Value Function Update Magnitude: 0.70010

Collected Steps per Second: 21,371.26044
Overall Steps per Second: 10,388.79977

Timestep Collection Time: 2.34015
Timestep Consumption Time: 2.47388
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.81403

Cumulative Model Updates: 58,536
Cumulative Timesteps: 488,303,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 488303162...
Checkpoint 488303162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.74712
Policy Entropy: 3.33227
Value Function Loss: 0.00364

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.54957
Value Function Update Magnitude: 0.68661

Collected Steps per Second: 19,808.47373
Overall Steps per Second: 9,944.41063

Timestep Collection Time: 2.52498
Timestep Consumption Time: 2.50458
PPO Batch Consumption Time: 0.30048
Total Iteration Time: 5.02956

Cumulative Model Updates: 58,542
Cumulative Timesteps: 488,353,178

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.58699
Policy Entropy: 3.31800
Value Function Loss: 0.00385

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09537
Policy Update Magnitude: 0.55828
Value Function Update Magnitude: 0.68939

Collected Steps per Second: 22,716.32859
Overall Steps per Second: 10,685.62535

Timestep Collection Time: 2.20168
Timestep Consumption Time: 2.47882
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.68049

Cumulative Model Updates: 58,548
Cumulative Timesteps: 488,403,192

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 488403192...
Checkpoint 488403192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.45146
Policy Entropy: 3.32308
Value Function Loss: 0.00368

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09682
Policy Update Magnitude: 0.55952
Value Function Update Magnitude: 0.68332

Collected Steps per Second: 21,681.44161
Overall Steps per Second: 10,509.80363

Timestep Collection Time: 2.30732
Timestep Consumption Time: 2.45262
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 4.75994

Cumulative Model Updates: 58,554
Cumulative Timesteps: 488,453,218

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.38558
Policy Entropy: 3.34017
Value Function Loss: 0.00369

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07665
Policy Update Magnitude: 0.55329
Value Function Update Magnitude: 0.66486

Collected Steps per Second: 22,136.99210
Overall Steps per Second: 10,481.09074

Timestep Collection Time: 2.25930
Timestep Consumption Time: 2.51254
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.77183

Cumulative Model Updates: 58,560
Cumulative Timesteps: 488,503,232

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 488503232...
Checkpoint 488503232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481.47988
Policy Entropy: 3.33893
Value Function Loss: 0.00364

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08248
Policy Update Magnitude: 0.55684
Value Function Update Magnitude: 0.65703

Collected Steps per Second: 22,252.29602
Overall Steps per Second: 10,429.98491

Timestep Collection Time: 2.24714
Timestep Consumption Time: 2.54712
PPO Batch Consumption Time: 0.29909
Total Iteration Time: 4.79425

Cumulative Model Updates: 58,566
Cumulative Timesteps: 488,553,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638.75616
Policy Entropy: 3.33257
Value Function Loss: 0.00361

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08530
Policy Update Magnitude: 0.54620
Value Function Update Magnitude: 0.65902

Collected Steps per Second: 22,192.25958
Overall Steps per Second: 10,463.15400

Timestep Collection Time: 2.25340
Timestep Consumption Time: 2.52604
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.77944

Cumulative Model Updates: 58,572
Cumulative Timesteps: 488,603,244

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 488603244...
Checkpoint 488603244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 994.43595
Policy Entropy: 3.33492
Value Function Loss: 0.00375

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08062
Policy Update Magnitude: 0.54957
Value Function Update Magnitude: 0.66479

Collected Steps per Second: 22,418.78637
Overall Steps per Second: 10,672.68000

Timestep Collection Time: 2.23045
Timestep Consumption Time: 2.45478
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.68523

Cumulative Model Updates: 58,578
Cumulative Timesteps: 488,653,248

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.31315
Policy Entropy: 3.33847
Value Function Loss: 0.00373

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07619
Policy Update Magnitude: 0.55456
Value Function Update Magnitude: 0.66091

Collected Steps per Second: 22,254.56583
Overall Steps per Second: 10,432.89355

Timestep Collection Time: 2.24781
Timestep Consumption Time: 2.54703
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.79483

Cumulative Model Updates: 58,584
Cumulative Timesteps: 488,703,272

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 488703272...
Checkpoint 488703272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695.01731
Policy Entropy: 3.34548
Value Function Loss: 0.00355

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08761
Policy Update Magnitude: 0.54714
Value Function Update Magnitude: 0.65082

Collected Steps per Second: 22,424.62906
Overall Steps per Second: 10,527.45540

Timestep Collection Time: 2.23103
Timestep Consumption Time: 2.52131
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.75234

Cumulative Model Updates: 58,590
Cumulative Timesteps: 488,753,302

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801.40505
Policy Entropy: 3.34533
Value Function Loss: 0.00337

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07259
Policy Update Magnitude: 0.54256
Value Function Update Magnitude: 0.64357

Collected Steps per Second: 22,319.66819
Overall Steps per Second: 10,569.25279

Timestep Collection Time: 2.24054
Timestep Consumption Time: 2.49093
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.73146

Cumulative Model Updates: 58,596
Cumulative Timesteps: 488,803,310

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 488803310...
Checkpoint 488803310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 873.44628
Policy Entropy: 3.34094
Value Function Loss: 0.00343

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08439
Policy Update Magnitude: 0.53798
Value Function Update Magnitude: 0.64042

Collected Steps per Second: 22,255.92867
Overall Steps per Second: 10,570.33862

Timestep Collection Time: 2.24731
Timestep Consumption Time: 2.48442
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.73173

Cumulative Model Updates: 58,602
Cumulative Timesteps: 488,853,326

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,470.67598
Policy Entropy: 3.33824
Value Function Loss: 0.00351

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.07940
Policy Update Magnitude: 0.53859
Value Function Update Magnitude: 0.65381

Collected Steps per Second: 21,610.46843
Overall Steps per Second: 10,543.67825

Timestep Collection Time: 2.31508
Timestep Consumption Time: 2.42994
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.74502

Cumulative Model Updates: 58,608
Cumulative Timesteps: 488,903,356

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 488903356...
Checkpoint 488903356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.60594
Policy Entropy: 3.34475
Value Function Loss: 0.00348

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08262
Policy Update Magnitude: 0.55086
Value Function Update Magnitude: 0.66793

Collected Steps per Second: 22,693.43462
Overall Steps per Second: 10,606.73327

Timestep Collection Time: 2.20381
Timestep Consumption Time: 2.51131
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.71512

Cumulative Model Updates: 58,614
Cumulative Timesteps: 488,953,368

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.58971
Policy Entropy: 3.35240
Value Function Loss: 0.00331

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08254
Policy Update Magnitude: 0.54185
Value Function Update Magnitude: 0.65179

Collected Steps per Second: 22,477.91313
Overall Steps per Second: 10,487.36740

Timestep Collection Time: 2.22547
Timestep Consumption Time: 2.54446
PPO Batch Consumption Time: 0.29738
Total Iteration Time: 4.76993

Cumulative Model Updates: 58,620
Cumulative Timesteps: 489,003,392

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 489003392...
Checkpoint 489003392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,859.73848
Policy Entropy: 3.36715
Value Function Loss: 0.00329

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07822
Policy Update Magnitude: 0.53262
Value Function Update Magnitude: 0.62738

Collected Steps per Second: 22,033.17637
Overall Steps per Second: 10,487.57824

Timestep Collection Time: 2.27003
Timestep Consumption Time: 2.49904
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.76907

Cumulative Model Updates: 58,626
Cumulative Timesteps: 489,053,408

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.26449
Policy Entropy: 3.37964
Value Function Loss: 0.00344

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09378
Policy Update Magnitude: 0.53401
Value Function Update Magnitude: 0.61200

Collected Steps per Second: 22,201.68187
Overall Steps per Second: 10,529.32616

Timestep Collection Time: 2.25334
Timestep Consumption Time: 2.49796
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.75130

Cumulative Model Updates: 58,632
Cumulative Timesteps: 489,103,436

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 489103436...
Checkpoint 489103436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 824.14742
Policy Entropy: 3.37754
Value Function Loss: 0.00351

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09956
Policy Update Magnitude: 0.53657
Value Function Update Magnitude: 0.62423

Collected Steps per Second: 22,094.57059
Overall Steps per Second: 10,497.62675

Timestep Collection Time: 2.26436
Timestep Consumption Time: 2.50148
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.76584

Cumulative Model Updates: 58,638
Cumulative Timesteps: 489,153,466

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.88605
Policy Entropy: 3.38842
Value Function Loss: 0.00336

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.09841
Policy Update Magnitude: 0.53360
Value Function Update Magnitude: 0.62249

Collected Steps per Second: 22,692.80342
Overall Steps per Second: 10,696.44809

Timestep Collection Time: 2.20413
Timestep Consumption Time: 2.47200
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.67613

Cumulative Model Updates: 58,644
Cumulative Timesteps: 489,203,484

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 489203484...
Checkpoint 489203484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 848.49206
Policy Entropy: 3.39980
Value Function Loss: 0.00339

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08231
Policy Update Magnitude: 0.52734
Value Function Update Magnitude: 0.62178

Collected Steps per Second: 22,051.02585
Overall Steps per Second: 10,560.18388

Timestep Collection Time: 2.26783
Timestep Consumption Time: 2.46769
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.73552

Cumulative Model Updates: 58,650
Cumulative Timesteps: 489,253,492

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 904.45821
Policy Entropy: 3.38823
Value Function Loss: 0.00331

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07326
Policy Update Magnitude: 0.52492
Value Function Update Magnitude: 0.60823

Collected Steps per Second: 22,162.72114
Overall Steps per Second: 10,478.86937

Timestep Collection Time: 2.25613
Timestep Consumption Time: 2.51557
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.77170

Cumulative Model Updates: 58,656
Cumulative Timesteps: 489,303,494

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 489303494...
Checkpoint 489303494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 939.98168
Policy Entropy: 3.38838
Value Function Loss: 0.00329

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06690
Policy Update Magnitude: 0.52404
Value Function Update Magnitude: 0.61138

Collected Steps per Second: 22,665.37835
Overall Steps per Second: 10,647.87570

Timestep Collection Time: 2.20680
Timestep Consumption Time: 2.49066
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.69746

Cumulative Model Updates: 58,662
Cumulative Timesteps: 489,353,512

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 761.84417
Policy Entropy: 3.38491
Value Function Loss: 0.00334

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.06720
Policy Update Magnitude: 0.52646
Value Function Update Magnitude: 0.62798

Collected Steps per Second: 22,657.51343
Overall Steps per Second: 10,316.04829

Timestep Collection Time: 2.20766
Timestep Consumption Time: 2.64110
PPO Batch Consumption Time: 0.31192
Total Iteration Time: 4.84876

Cumulative Model Updates: 58,668
Cumulative Timesteps: 489,403,532

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 489403532...
Checkpoint 489403532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.71968
Policy Entropy: 3.39318
Value Function Loss: 0.00327

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.06406
Policy Update Magnitude: 0.52844
Value Function Update Magnitude: 0.62309

Collected Steps per Second: 23,087.24788
Overall Steps per Second: 10,739.48804

Timestep Collection Time: 2.16596
Timestep Consumption Time: 2.49032
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.65627

Cumulative Model Updates: 58,674
Cumulative Timesteps: 489,453,538

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.12772
Policy Entropy: 3.38760
Value Function Loss: 0.00339

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.06806
Policy Update Magnitude: 0.53213
Value Function Update Magnitude: 0.61902

Collected Steps per Second: 22,149.91205
Overall Steps per Second: 10,544.87091

Timestep Collection Time: 2.25744
Timestep Consumption Time: 2.48440
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.74183

Cumulative Model Updates: 58,680
Cumulative Timesteps: 489,503,540

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 489503540...
Checkpoint 489503540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.88883
Policy Entropy: 3.38557
Value Function Loss: 0.00351

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07289
Policy Update Magnitude: 0.54231
Value Function Update Magnitude: 0.62665

Collected Steps per Second: 22,278.31255
Overall Steps per Second: 10,611.35824

Timestep Collection Time: 2.24451
Timestep Consumption Time: 2.46779
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.71231

Cumulative Model Updates: 58,686
Cumulative Timesteps: 489,553,544

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.25020
Policy Entropy: 3.36574
Value Function Loss: 0.00343

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08158
Policy Update Magnitude: 0.54275
Value Function Update Magnitude: 0.61984

Collected Steps per Second: 21,771.36016
Overall Steps per Second: 10,477.56459

Timestep Collection Time: 2.29797
Timestep Consumption Time: 2.47699
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.77496

Cumulative Model Updates: 58,692
Cumulative Timesteps: 489,603,574

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 489603574...
Checkpoint 489603574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.82589
Policy Entropy: 3.36897
Value Function Loss: 0.00336

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08908
Policy Update Magnitude: 0.53661
Value Function Update Magnitude: 0.60386

Collected Steps per Second: 22,348.59728
Overall Steps per Second: 10,557.45931

Timestep Collection Time: 2.23808
Timestep Consumption Time: 2.49961
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.73769

Cumulative Model Updates: 58,698
Cumulative Timesteps: 489,653,592

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,632.57792
Policy Entropy: 3.36129
Value Function Loss: 0.00329

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07646
Policy Update Magnitude: 0.52443
Value Function Update Magnitude: 0.59535

Collected Steps per Second: 22,297.32717
Overall Steps per Second: 10,506.96373

Timestep Collection Time: 2.24350
Timestep Consumption Time: 2.51754
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.76103

Cumulative Model Updates: 58,704
Cumulative Timesteps: 489,703,616

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 489703616...
Checkpoint 489703616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.22267
Policy Entropy: 3.35825
Value Function Loss: 0.00334

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07796
Policy Update Magnitude: 0.51737
Value Function Update Magnitude: 0.60317

Collected Steps per Second: 21,932.08781
Overall Steps per Second: 10,444.67880

Timestep Collection Time: 2.27995
Timestep Consumption Time: 2.50756
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.78751

Cumulative Model Updates: 58,710
Cumulative Timesteps: 489,753,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 891.30884
Policy Entropy: 3.34330
Value Function Loss: 0.00341

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08610
Policy Update Magnitude: 0.52154
Value Function Update Magnitude: 0.60423

Collected Steps per Second: 22,100.66351
Overall Steps per Second: 10,551.32520

Timestep Collection Time: 2.26265
Timestep Consumption Time: 2.47666
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.73931

Cumulative Model Updates: 58,716
Cumulative Timesteps: 489,803,626

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 489803626...
Checkpoint 489803626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.86205
Policy Entropy: 3.35910
Value Function Loss: 0.00354

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08234
Policy Update Magnitude: 0.52770
Value Function Update Magnitude: 0.60426

Collected Steps per Second: 22,093.37660
Overall Steps per Second: 10,568.38285

Timestep Collection Time: 2.26312
Timestep Consumption Time: 2.46797
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.73109

Cumulative Model Updates: 58,722
Cumulative Timesteps: 489,853,626

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.68762
Policy Entropy: 3.36811
Value Function Loss: 0.00351

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07314
Policy Update Magnitude: 0.54037
Value Function Update Magnitude: 0.61336

Collected Steps per Second: 22,121.40124
Overall Steps per Second: 10,592.25354

Timestep Collection Time: 2.26071
Timestep Consumption Time: 2.46067
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.72137

Cumulative Model Updates: 58,728
Cumulative Timesteps: 489,903,636

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 489903636...
Checkpoint 489903636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 893.28478
Policy Entropy: 3.37319
Value Function Loss: 0.00340

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07899
Policy Update Magnitude: 0.55022
Value Function Update Magnitude: 0.61295

Collected Steps per Second: 21,959.41815
Overall Steps per Second: 10,581.75154

Timestep Collection Time: 2.27756
Timestep Consumption Time: 2.44887
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.72644

Cumulative Model Updates: 58,734
Cumulative Timesteps: 489,953,650

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,461.50095
Policy Entropy: 3.38021
Value Function Loss: 0.00326

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09342
Policy Update Magnitude: 0.54025
Value Function Update Magnitude: 0.60422

Collected Steps per Second: 22,477.62729
Overall Steps per Second: 10,590.95514

Timestep Collection Time: 2.22550
Timestep Consumption Time: 2.49777
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.72328

Cumulative Model Updates: 58,740
Cumulative Timesteps: 490,003,674

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 490003674...
Checkpoint 490003674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.29996
Policy Entropy: 3.37600
Value Function Loss: 0.00309

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08532
Policy Update Magnitude: 0.52167
Value Function Update Magnitude: 0.58703

Collected Steps per Second: 22,621.38801
Overall Steps per Second: 10,438.06066

Timestep Collection Time: 2.21092
Timestep Consumption Time: 2.58059
PPO Batch Consumption Time: 0.30483
Total Iteration Time: 4.79150

Cumulative Model Updates: 58,746
Cumulative Timesteps: 490,053,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.99065
Policy Entropy: 3.37666
Value Function Loss: 0.00322

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07591
Policy Update Magnitude: 0.51498
Value Function Update Magnitude: 0.57947

Collected Steps per Second: 22,347.17268
Overall Steps per Second: 10,547.62514

Timestep Collection Time: 2.23751
Timestep Consumption Time: 2.50308
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.74059

Cumulative Model Updates: 58,752
Cumulative Timesteps: 490,103,690

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 490103690...
Checkpoint 490103690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 818.68177
Policy Entropy: 3.37354
Value Function Loss: 0.00333

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07126
Policy Update Magnitude: 0.52821
Value Function Update Magnitude: 0.58691

Collected Steps per Second: 22,178.59091
Overall Steps per Second: 10,615.89782

Timestep Collection Time: 2.25506
Timestep Consumption Time: 2.45618
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.71124

Cumulative Model Updates: 58,758
Cumulative Timesteps: 490,153,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 898.80473
Policy Entropy: 3.37157
Value Function Loss: 0.00353

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07890
Policy Update Magnitude: 0.54373
Value Function Update Magnitude: 0.61674

Collected Steps per Second: 22,670.51116
Overall Steps per Second: 10,580.12871

Timestep Collection Time: 2.20648
Timestep Consumption Time: 2.52144
PPO Batch Consumption Time: 0.30081
Total Iteration Time: 4.72792

Cumulative Model Updates: 58,764
Cumulative Timesteps: 490,203,726

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 490203726...
Checkpoint 490203726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 978.67363
Policy Entropy: 3.36101
Value Function Loss: 0.00346

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08570
Policy Update Magnitude: 0.54773
Value Function Update Magnitude: 0.63746

Collected Steps per Second: 21,244.47040
Overall Steps per Second: 10,262.02733

Timestep Collection Time: 2.35487
Timestep Consumption Time: 2.52019
PPO Batch Consumption Time: 0.29725
Total Iteration Time: 4.87506

Cumulative Model Updates: 58,770
Cumulative Timesteps: 490,253,754

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.63582
Policy Entropy: 3.35853
Value Function Loss: 0.00333

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07637
Policy Update Magnitude: 0.53943
Value Function Update Magnitude: 0.60659

Collected Steps per Second: 22,041.45403
Overall Steps per Second: 10,445.38040

Timestep Collection Time: 2.26873
Timestep Consumption Time: 2.51865
PPO Batch Consumption Time: 0.30039
Total Iteration Time: 4.78738

Cumulative Model Updates: 58,776
Cumulative Timesteps: 490,303,760

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 490303760...
Checkpoint 490303760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.05567
Policy Entropy: 3.35102
Value Function Loss: 0.00335

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08377
Policy Update Magnitude: 0.53292
Value Function Update Magnitude: 0.59676

Collected Steps per Second: 21,991.00059
Overall Steps per Second: 10,642.40591

Timestep Collection Time: 2.27475
Timestep Consumption Time: 2.42569
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.70044

Cumulative Model Updates: 58,782
Cumulative Timesteps: 490,353,784

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 798.64971
Policy Entropy: 3.35302
Value Function Loss: 0.00320

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08052
Policy Update Magnitude: 0.52672
Value Function Update Magnitude: 0.60322

Collected Steps per Second: 22,430.74648
Overall Steps per Second: 10,541.01702

Timestep Collection Time: 2.22980
Timestep Consumption Time: 2.51510
PPO Batch Consumption Time: 0.29714
Total Iteration Time: 4.74489

Cumulative Model Updates: 58,788
Cumulative Timesteps: 490,403,800

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 490403800...
Checkpoint 490403800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 905.99842
Policy Entropy: 3.32828
Value Function Loss: 0.00339

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07106
Policy Update Magnitude: 0.53009
Value Function Update Magnitude: 0.60967

Collected Steps per Second: 22,145.05993
Overall Steps per Second: 10,441.15236

Timestep Collection Time: 2.25847
Timestep Consumption Time: 2.53161
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.79008

Cumulative Model Updates: 58,794
Cumulative Timesteps: 490,453,814

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.01091
Policy Entropy: 3.32402
Value Function Loss: 0.00343

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.53818
Value Function Update Magnitude: 0.62661

Collected Steps per Second: 22,483.48881
Overall Steps per Second: 10,508.41287

Timestep Collection Time: 2.22590
Timestep Consumption Time: 2.53657
PPO Batch Consumption Time: 0.29932
Total Iteration Time: 4.76247

Cumulative Model Updates: 58,800
Cumulative Timesteps: 490,503,860

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 490503860...
Checkpoint 490503860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.60192
Policy Entropy: 3.32206
Value Function Loss: 0.00361

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11058
Policy Update Magnitude: 0.54190
Value Function Update Magnitude: 0.61569

Collected Steps per Second: 22,388.35065
Overall Steps per Second: 10,640.02252

Timestep Collection Time: 2.23411
Timestep Consumption Time: 2.46682
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.70093

Cumulative Model Updates: 58,806
Cumulative Timesteps: 490,553,878

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,597.52481
Policy Entropy: 3.33996
Value Function Loss: 0.00341

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.12227
Policy Update Magnitude: 0.53468
Value Function Update Magnitude: 0.63126

Collected Steps per Second: 22,426.30468
Overall Steps per Second: 10,488.83089

Timestep Collection Time: 2.23042
Timestep Consumption Time: 2.53847
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.76888

Cumulative Model Updates: 58,812
Cumulative Timesteps: 490,603,898

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 490603898...
Checkpoint 490603898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.38260
Policy Entropy: 3.34011
Value Function Loss: 0.00348

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10865
Policy Update Magnitude: 0.52745
Value Function Update Magnitude: 0.61779

Collected Steps per Second: 22,222.43948
Overall Steps per Second: 10,529.80218

Timestep Collection Time: 2.25025
Timestep Consumption Time: 2.49875
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.74900

Cumulative Model Updates: 58,818
Cumulative Timesteps: 490,653,904

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.82017
Policy Entropy: 3.33251
Value Function Loss: 0.00342

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10652
Policy Update Magnitude: 0.52750
Value Function Update Magnitude: 0.62208

Collected Steps per Second: 22,557.18103
Overall Steps per Second: 10,444.79114

Timestep Collection Time: 2.21836
Timestep Consumption Time: 2.57254
PPO Batch Consumption Time: 0.30198
Total Iteration Time: 4.79090

Cumulative Model Updates: 58,824
Cumulative Timesteps: 490,703,944

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 490703944...
Checkpoint 490703944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.29026
Policy Entropy: 3.32414
Value Function Loss: 0.00343

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10383
Policy Update Magnitude: 0.52409
Value Function Update Magnitude: 0.61209

Collected Steps per Second: 18,803.24689
Overall Steps per Second: 9,820.46783

Timestep Collection Time: 2.66188
Timestep Consumption Time: 2.43482
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 5.09670

Cumulative Model Updates: 58,830
Cumulative Timesteps: 490,753,996

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 842.83896
Policy Entropy: 3.32422
Value Function Loss: 0.00335

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10084
Policy Update Magnitude: 0.52299
Value Function Update Magnitude: 0.63787

Collected Steps per Second: 22,698.37197
Overall Steps per Second: 10,592.31257

Timestep Collection Time: 2.20386
Timestep Consumption Time: 2.51881
PPO Batch Consumption Time: 0.29790
Total Iteration Time: 4.72267

Cumulative Model Updates: 58,836
Cumulative Timesteps: 490,804,020

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 490804020...
Checkpoint 490804020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.60409
Policy Entropy: 3.32382
Value Function Loss: 0.00327

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.53175
Value Function Update Magnitude: 0.64081

Collected Steps per Second: 22,505.41980
Overall Steps per Second: 10,607.83825

Timestep Collection Time: 2.22213
Timestep Consumption Time: 2.49231
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.71444

Cumulative Model Updates: 58,842
Cumulative Timesteps: 490,854,030

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.96949
Policy Entropy: 3.32046
Value Function Loss: 0.00333

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09636
Policy Update Magnitude: 0.52735
Value Function Update Magnitude: 0.63629

Collected Steps per Second: 22,089.64490
Overall Steps per Second: 10,460.56981

Timestep Collection Time: 2.26414
Timestep Consumption Time: 2.51705
PPO Batch Consumption Time: 0.29801
Total Iteration Time: 4.78119

Cumulative Model Updates: 58,848
Cumulative Timesteps: 490,904,044

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 490904044...
Checkpoint 490904044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,757.53053
Policy Entropy: 3.31276
Value Function Loss: 0.00341

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09451
Policy Update Magnitude: 0.52893
Value Function Update Magnitude: 0.62942

Collected Steps per Second: 22,097.04042
Overall Steps per Second: 10,653.61691

Timestep Collection Time: 2.26311
Timestep Consumption Time: 2.43088
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.69399

Cumulative Model Updates: 58,854
Cumulative Timesteps: 490,954,052

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 816.39434
Policy Entropy: 3.31399
Value Function Loss: 0.00344

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09569
Policy Update Magnitude: 0.54511
Value Function Update Magnitude: 0.62756

Collected Steps per Second: 22,474.92557
Overall Steps per Second: 10,606.10344

Timestep Collection Time: 2.22524
Timestep Consumption Time: 2.49016
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.71540

Cumulative Model Updates: 58,860
Cumulative Timesteps: 491,004,064

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 491004064...
Checkpoint 491004064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 809.19251
Policy Entropy: 3.29963
Value Function Loss: 0.00340

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09459
Policy Update Magnitude: 0.54726
Value Function Update Magnitude: 0.63500

Collected Steps per Second: 22,079.97593
Overall Steps per Second: 10,467.06544

Timestep Collection Time: 2.26549
Timestep Consumption Time: 2.51350
PPO Batch Consumption Time: 0.29772
Total Iteration Time: 4.77899

Cumulative Model Updates: 58,866
Cumulative Timesteps: 491,054,086

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.97163
Policy Entropy: 3.29960
Value Function Loss: 0.00345

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10566
Policy Update Magnitude: 0.54763
Value Function Update Magnitude: 0.64487

Collected Steps per Second: 22,350.96585
Overall Steps per Second: 10,599.24656

Timestep Collection Time: 2.23749
Timestep Consumption Time: 2.48077
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.71826

Cumulative Model Updates: 58,872
Cumulative Timesteps: 491,104,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 491104096...
Checkpoint 491104096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.17049
Policy Entropy: 3.30733
Value Function Loss: 0.00336

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10048
Policy Update Magnitude: 0.54724
Value Function Update Magnitude: 0.64318

Collected Steps per Second: 22,932.05448
Overall Steps per Second: 10,671.07326

Timestep Collection Time: 2.18070
Timestep Consumption Time: 2.50561
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.68631

Cumulative Model Updates: 58,878
Cumulative Timesteps: 491,154,104

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 878.94204
Policy Entropy: 3.32187
Value Function Loss: 0.00345

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.54525
Value Function Update Magnitude: 0.61394

Collected Steps per Second: 22,899.87129
Overall Steps per Second: 10,680.37248

Timestep Collection Time: 2.18464
Timestep Consumption Time: 2.49947
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.68411

Cumulative Model Updates: 58,884
Cumulative Timesteps: 491,204,132

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 491204132...
Checkpoint 491204132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 943.00676
Policy Entropy: 3.33449
Value Function Loss: 0.00341

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.53549
Value Function Update Magnitude: 0.61278

Collected Steps per Second: 22,408.47304
Overall Steps per Second: 10,673.17886

Timestep Collection Time: 2.23157
Timestep Consumption Time: 2.45364
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.68520

Cumulative Model Updates: 58,890
Cumulative Timesteps: 491,254,138

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 804.09722
Policy Entropy: 3.33884
Value Function Loss: 0.00350

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07763
Policy Update Magnitude: 0.53543
Value Function Update Magnitude: 0.60945

Collected Steps per Second: 22,992.11999
Overall Steps per Second: 10,840.49702

Timestep Collection Time: 2.17657
Timestep Consumption Time: 2.43982
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.61639

Cumulative Model Updates: 58,896
Cumulative Timesteps: 491,304,182

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 491304182...
Checkpoint 491304182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.58501
Policy Entropy: 3.33266
Value Function Loss: 0.00365

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08107
Policy Update Magnitude: 0.54159
Value Function Update Magnitude: 0.61199

Collected Steps per Second: 22,599.19775
Overall Steps per Second: 10,714.59137

Timestep Collection Time: 2.21371
Timestep Consumption Time: 2.45544
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.66915

Cumulative Model Updates: 58,902
Cumulative Timesteps: 491,354,210

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.08160
Policy Entropy: 3.32108
Value Function Loss: 0.00347

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.53459
Value Function Update Magnitude: 0.62036

Collected Steps per Second: 22,080.07557
Overall Steps per Second: 10,430.07772

Timestep Collection Time: 2.26494
Timestep Consumption Time: 2.52985
PPO Batch Consumption Time: 0.29824
Total Iteration Time: 4.79479

Cumulative Model Updates: 58,908
Cumulative Timesteps: 491,404,220

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 491404220...
Checkpoint 491404220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702.61785
Policy Entropy: 3.30675
Value Function Loss: 0.00370

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07782
Policy Update Magnitude: 0.53684
Value Function Update Magnitude: 0.63183

Collected Steps per Second: 22,221.63261
Overall Steps per Second: 10,703.55265

Timestep Collection Time: 2.25006
Timestep Consumption Time: 2.42129
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.67135

Cumulative Model Updates: 58,914
Cumulative Timesteps: 491,454,220

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.08407
Policy Entropy: 3.30198
Value Function Loss: 0.00363

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.06958
Policy Update Magnitude: 0.54476
Value Function Update Magnitude: 0.64189

Collected Steps per Second: 22,281.84863
Overall Steps per Second: 10,560.56686

Timestep Collection Time: 2.24416
Timestep Consumption Time: 2.49081
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.73497

Cumulative Model Updates: 58,920
Cumulative Timesteps: 491,504,224

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 491504224...
Checkpoint 491504224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 987.78284
Policy Entropy: 3.30552
Value Function Loss: 0.00357

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07414
Policy Update Magnitude: 0.54510
Value Function Update Magnitude: 0.63648

Collected Steps per Second: 20,994.82133
Overall Steps per Second: 10,398.53935

Timestep Collection Time: 2.38173
Timestep Consumption Time: 2.42702
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.80875

Cumulative Model Updates: 58,926
Cumulative Timesteps: 491,554,228

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415.22792
Policy Entropy: 3.30194
Value Function Loss: 0.00353

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07485
Policy Update Magnitude: 0.53867
Value Function Update Magnitude: 0.62109

Collected Steps per Second: 22,242.77109
Overall Steps per Second: 10,564.82965

Timestep Collection Time: 2.24819
Timestep Consumption Time: 2.48506
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.73325

Cumulative Model Updates: 58,932
Cumulative Timesteps: 491,604,234

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 491604234...
Checkpoint 491604234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.01394
Policy Entropy: 3.30373
Value Function Loss: 0.00340

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08248
Policy Update Magnitude: 0.53905
Value Function Update Magnitude: 0.61268

Collected Steps per Second: 22,196.56607
Overall Steps per Second: 10,665.85127

Timestep Collection Time: 2.25287
Timestep Consumption Time: 2.43555
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.68842

Cumulative Model Updates: 58,938
Cumulative Timesteps: 491,654,240

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.65018
Policy Entropy: 3.30048
Value Function Loss: 0.00360

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07272
Policy Update Magnitude: 0.53973
Value Function Update Magnitude: 0.61884

Collected Steps per Second: 22,534.43868
Overall Steps per Second: 10,619.48744

Timestep Collection Time: 2.21971
Timestep Consumption Time: 2.49049
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.71021

Cumulative Model Updates: 58,944
Cumulative Timesteps: 491,704,260

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 491704260...
Checkpoint 491704260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700.86897
Policy Entropy: 3.29924
Value Function Loss: 0.00360

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.07896
Policy Update Magnitude: 0.54612
Value Function Update Magnitude: 0.65301

Collected Steps per Second: 22,603.07568
Overall Steps per Second: 10,550.74648

Timestep Collection Time: 2.21227
Timestep Consumption Time: 2.52712
PPO Batch Consumption Time: 0.29610
Total Iteration Time: 4.73938

Cumulative Model Updates: 58,950
Cumulative Timesteps: 491,754,264

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 998.68850
Policy Entropy: 3.30540
Value Function Loss: 0.00345

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09326
Policy Update Magnitude: 0.54928
Value Function Update Magnitude: 0.66114

Collected Steps per Second: 23,300.73826
Overall Steps per Second: 10,763.94279

Timestep Collection Time: 2.14697
Timestep Consumption Time: 2.50058
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.64755

Cumulative Model Updates: 58,956
Cumulative Timesteps: 491,804,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 491804290...
Checkpoint 491804290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,634.62119
Policy Entropy: 3.30504
Value Function Loss: 0.00328

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09123
Policy Update Magnitude: 0.54263
Value Function Update Magnitude: 0.64176

Collected Steps per Second: 22,020.02325
Overall Steps per Second: 10,589.71592

Timestep Collection Time: 2.27157
Timestep Consumption Time: 2.45188
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.72345

Cumulative Model Updates: 58,962
Cumulative Timesteps: 491,854,310

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.04434
Policy Entropy: 3.31150
Value Function Loss: 0.00327

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08354
Policy Update Magnitude: 0.54053
Value Function Update Magnitude: 0.61712

Collected Steps per Second: 22,725.80210
Overall Steps per Second: 10,541.83742

Timestep Collection Time: 2.20067
Timestep Consumption Time: 2.54347
PPO Batch Consumption Time: 0.29698
Total Iteration Time: 4.74414

Cumulative Model Updates: 58,968
Cumulative Timesteps: 491,904,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 491904322...
Checkpoint 491904322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 922.35524
Policy Entropy: 3.30675
Value Function Loss: 0.00331

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09803
Policy Update Magnitude: 0.53896
Value Function Update Magnitude: 0.60607

Collected Steps per Second: 22,157.35585
Overall Steps per Second: 10,612.00873

Timestep Collection Time: 2.25794
Timestep Consumption Time: 2.45653
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.71447

Cumulative Model Updates: 58,974
Cumulative Timesteps: 491,954,352

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485.36764
Policy Entropy: 3.32538
Value Function Loss: 0.00347

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07791
Policy Update Magnitude: 0.54342
Value Function Update Magnitude: 0.60531

Collected Steps per Second: 22,852.33440
Overall Steps per Second: 10,616.62569

Timestep Collection Time: 2.18805
Timestep Consumption Time: 2.52173
PPO Batch Consumption Time: 0.29600
Total Iteration Time: 4.70978

Cumulative Model Updates: 58,980
Cumulative Timesteps: 492,004,354

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 492004354...
Checkpoint 492004354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617.37968
Policy Entropy: 3.32263
Value Function Loss: 0.00341

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08145
Policy Update Magnitude: 0.53857
Value Function Update Magnitude: 0.60101

Collected Steps per Second: 22,123.60118
Overall Steps per Second: 10,483.98456

Timestep Collection Time: 2.26057
Timestep Consumption Time: 2.50975
PPO Batch Consumption Time: 0.29644
Total Iteration Time: 4.77032

Cumulative Model Updates: 58,986
Cumulative Timesteps: 492,054,366

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.53518
Policy Entropy: 3.32489
Value Function Loss: 0.00353

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08445
Policy Update Magnitude: 0.53856
Value Function Update Magnitude: 0.60364

Collected Steps per Second: 22,369.25826
Overall Steps per Second: 10,470.96434

Timestep Collection Time: 2.23566
Timestep Consumption Time: 2.54041
PPO Batch Consumption Time: 0.29741
Total Iteration Time: 4.77606

Cumulative Model Updates: 58,992
Cumulative Timesteps: 492,104,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 492104376...
Checkpoint 492104376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 844.52455
Policy Entropy: 3.30946
Value Function Loss: 0.00362

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.54691
Value Function Update Magnitude: 0.63897

Collected Steps per Second: 22,375.99919
Overall Steps per Second: 10,628.31622

Timestep Collection Time: 2.23543
Timestep Consumption Time: 2.47086
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.70630

Cumulative Model Updates: 58,998
Cumulative Timesteps: 492,154,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 896.65507
Policy Entropy: 3.31020
Value Function Loss: 0.00361

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09326
Policy Update Magnitude: 0.55409
Value Function Update Magnitude: 0.66222

Collected Steps per Second: 22,283.63310
Overall Steps per Second: 10,527.34315

Timestep Collection Time: 2.24452
Timestep Consumption Time: 2.50654
PPO Batch Consumption Time: 0.29722
Total Iteration Time: 4.75106

Cumulative Model Updates: 59,004
Cumulative Timesteps: 492,204,412

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 492204412...
Checkpoint 492204412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,896.29357
Policy Entropy: 3.29629
Value Function Loss: 0.00360

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09214
Policy Update Magnitude: 0.55249
Value Function Update Magnitude: 0.69214

Collected Steps per Second: 22,009.27506
Overall Steps per Second: 10,567.18926

Timestep Collection Time: 2.27304
Timestep Consumption Time: 2.46124
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.73428

Cumulative Model Updates: 59,010
Cumulative Timesteps: 492,254,440

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 771.61660
Policy Entropy: 3.30178
Value Function Loss: 0.00343

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09063
Policy Update Magnitude: 0.55443
Value Function Update Magnitude: 0.69592

Collected Steps per Second: 22,425.11757
Overall Steps per Second: 10,535.50682

Timestep Collection Time: 2.22973
Timestep Consumption Time: 2.51631
PPO Batch Consumption Time: 0.29566
Total Iteration Time: 4.74605

Cumulative Model Updates: 59,016
Cumulative Timesteps: 492,304,442

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 492304442...
Checkpoint 492304442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 804.02917
Policy Entropy: 3.29473
Value Function Loss: 0.00348

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11607
Policy Update Magnitude: 0.55344
Value Function Update Magnitude: 0.68202

Collected Steps per Second: 22,963.65346
Overall Steps per Second: 10,622.67276

Timestep Collection Time: 2.17857
Timestep Consumption Time: 2.53098
PPO Batch Consumption Time: 0.29718
Total Iteration Time: 4.70955

Cumulative Model Updates: 59,022
Cumulative Timesteps: 492,354,470

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,109.86388
Policy Entropy: 3.29693
Value Function Loss: 0.00365

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12024
Policy Update Magnitude: 0.54701
Value Function Update Magnitude: 0.66912

Collected Steps per Second: 22,989.96249
Overall Steps per Second: 10,804.02202

Timestep Collection Time: 2.17617
Timestep Consumption Time: 2.45452
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.63068

Cumulative Model Updates: 59,028
Cumulative Timesteps: 492,404,500

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 492404500...
Checkpoint 492404500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.34593
Policy Entropy: 3.29488
Value Function Loss: 0.00359

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11271
Policy Update Magnitude: 0.55417
Value Function Update Magnitude: 0.68548

Collected Steps per Second: 22,493.75878
Overall Steps per Second: 10,668.67433

Timestep Collection Time: 2.22408
Timestep Consumption Time: 2.46516
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.68924

Cumulative Model Updates: 59,034
Cumulative Timesteps: 492,454,528

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467.77099
Policy Entropy: 3.30226
Value Function Loss: 0.00354

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.55379
Value Function Update Magnitude: 0.67179

Collected Steps per Second: 22,972.74273
Overall Steps per Second: 10,853.53068

Timestep Collection Time: 2.17693
Timestep Consumption Time: 2.43079
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.60772

Cumulative Model Updates: 59,040
Cumulative Timesteps: 492,504,538

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 492504538...
Checkpoint 492504538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 994.28536
Policy Entropy: 3.30979
Value Function Loss: 0.00346

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08472
Policy Update Magnitude: 0.54635
Value Function Update Magnitude: 0.65553

Collected Steps per Second: 22,240.38157
Overall Steps per Second: 10,715.57041

Timestep Collection Time: 2.24861
Timestep Consumption Time: 2.41843
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.66704

Cumulative Model Updates: 59,046
Cumulative Timesteps: 492,554,548

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714.24986
Policy Entropy: 3.29942
Value Function Loss: 0.00345

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10968
Policy Update Magnitude: 0.54423
Value Function Update Magnitude: 0.62852

Collected Steps per Second: 22,714.24817
Overall Steps per Second: 10,696.00029

Timestep Collection Time: 2.20126
Timestep Consumption Time: 2.47338
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.67464

Cumulative Model Updates: 59,052
Cumulative Timesteps: 492,604,548

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 492604548...
Checkpoint 492604548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.38532
Policy Entropy: 3.29279
Value Function Loss: 0.00350

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11143
Policy Update Magnitude: 0.54063
Value Function Update Magnitude: 0.62610

Collected Steps per Second: 22,091.28538
Overall Steps per Second: 10,503.66144

Timestep Collection Time: 2.26406
Timestep Consumption Time: 2.49771
PPO Batch Consumption Time: 0.29728
Total Iteration Time: 4.76177

Cumulative Model Updates: 59,058
Cumulative Timesteps: 492,654,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,946.68608
Policy Entropy: 3.30013
Value Function Loss: 0.00336

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09869
Policy Update Magnitude: 0.53114
Value Function Update Magnitude: 0.62410

Collected Steps per Second: 22,249.55737
Overall Steps per Second: 10,575.92421

Timestep Collection Time: 2.24822
Timestep Consumption Time: 2.48157
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.72980

Cumulative Model Updates: 59,064
Cumulative Timesteps: 492,704,586

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 492704586...
Checkpoint 492704586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.41059
Policy Entropy: 3.30851
Value Function Loss: 0.00342

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09032
Policy Update Magnitude: 0.53014
Value Function Update Magnitude: 0.61109

Collected Steps per Second: 22,463.02995
Overall Steps per Second: 10,649.90873

Timestep Collection Time: 2.22615
Timestep Consumption Time: 2.46929
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.69544

Cumulative Model Updates: 59,070
Cumulative Timesteps: 492,754,592

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.26138
Policy Entropy: 3.32402
Value Function Loss: 0.00334

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09794
Policy Update Magnitude: 0.53069
Value Function Update Magnitude: 0.60536

Collected Steps per Second: 22,388.41005
Overall Steps per Second: 10,732.19526

Timestep Collection Time: 2.23446
Timestep Consumption Time: 2.42684
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.66130

Cumulative Model Updates: 59,076
Cumulative Timesteps: 492,804,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 492804618...
Checkpoint 492804618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.16760
Policy Entropy: 3.32942
Value Function Loss: 0.00355

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08872
Policy Update Magnitude: 0.53013
Value Function Update Magnitude: 0.60328

Collected Steps per Second: 22,414.46216
Overall Steps per Second: 10,567.04861

Timestep Collection Time: 2.23088
Timestep Consumption Time: 2.50119
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.73207

Cumulative Model Updates: 59,082
Cumulative Timesteps: 492,854,622

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.77253
Policy Entropy: 3.33250
Value Function Loss: 0.00347

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08100
Policy Update Magnitude: 0.53627
Value Function Update Magnitude: 0.61596

Collected Steps per Second: 22,605.36322
Overall Steps per Second: 10,602.03855

Timestep Collection Time: 2.21319
Timestep Consumption Time: 2.50571
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.71890

Cumulative Model Updates: 59,088
Cumulative Timesteps: 492,904,652

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 492904652...
Checkpoint 492904652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 727.64032
Policy Entropy: 3.32017
Value Function Loss: 0.00346

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.53553
Value Function Update Magnitude: 0.62414

Collected Steps per Second: 22,967.24014
Overall Steps per Second: 10,750.62795

Timestep Collection Time: 2.17771
Timestep Consumption Time: 2.47467
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.65238

Cumulative Model Updates: 59,094
Cumulative Timesteps: 492,954,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.42540
Policy Entropy: 3.31566
Value Function Loss: 0.00345

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.53210
Value Function Update Magnitude: 0.61527

Collected Steps per Second: 23,262.45350
Overall Steps per Second: 10,736.64637

Timestep Collection Time: 2.14956
Timestep Consumption Time: 2.50776
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.65732

Cumulative Model Updates: 59,100
Cumulative Timesteps: 493,004,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 493004672...
Checkpoint 493004672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,427.46726
Policy Entropy: 3.31646
Value Function Loss: 0.00344

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11352
Policy Update Magnitude: 0.53017
Value Function Update Magnitude: 0.59703

Collected Steps per Second: 22,435.82668
Overall Steps per Second: 10,570.97917

Timestep Collection Time: 2.22867
Timestep Consumption Time: 2.50145
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.73012

Cumulative Model Updates: 59,106
Cumulative Timesteps: 493,054,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.12236
Policy Entropy: 3.34548
Value Function Loss: 0.00338

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.12522
Policy Update Magnitude: 0.52527
Value Function Update Magnitude: 0.60305

Collected Steps per Second: 22,962.61221
Overall Steps per Second: 10,850.31443

Timestep Collection Time: 2.17815
Timestep Consumption Time: 2.43149
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.60964

Cumulative Model Updates: 59,112
Cumulative Timesteps: 493,104,690

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 493104690...
Checkpoint 493104690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,966.56542
Policy Entropy: 3.33400
Value Function Loss: 0.00333

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11177
Policy Update Magnitude: 0.52213
Value Function Update Magnitude: 0.58467

Collected Steps per Second: 22,830.16462
Overall Steps per Second: 10,742.51666

Timestep Collection Time: 2.19131
Timestep Consumption Time: 2.46570
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.65701

Cumulative Model Updates: 59,118
Cumulative Timesteps: 493,154,718

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.74516
Policy Entropy: 3.34157
Value Function Loss: 0.00328

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.52390
Value Function Update Magnitude: 0.58754

Collected Steps per Second: 22,653.81549
Overall Steps per Second: 10,762.52151

Timestep Collection Time: 2.20784
Timestep Consumption Time: 2.43940
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.64724

Cumulative Model Updates: 59,124
Cumulative Timesteps: 493,204,734

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 493204734...
Checkpoint 493204734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.76599
Policy Entropy: 3.33652
Value Function Loss: 0.00329

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07802
Policy Update Magnitude: 0.52488
Value Function Update Magnitude: 0.57627

Collected Steps per Second: 22,417.34847
Overall Steps per Second: 10,749.45946

Timestep Collection Time: 2.23077
Timestep Consumption Time: 2.42137
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.65214

Cumulative Model Updates: 59,130
Cumulative Timesteps: 493,254,742

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 907.49781
Policy Entropy: 3.33106
Value Function Loss: 0.00320

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.52338
Value Function Update Magnitude: 0.58754

Collected Steps per Second: 22,517.92138
Overall Steps per Second: 10,628.04004

Timestep Collection Time: 2.22134
Timestep Consumption Time: 2.48508
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.70642

Cumulative Model Updates: 59,136
Cumulative Timesteps: 493,304,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 493304762...
Checkpoint 493304762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 789.36071
Policy Entropy: 3.30065
Value Function Loss: 0.00328

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08640
Policy Update Magnitude: 0.51749
Value Function Update Magnitude: 0.59729

Collected Steps per Second: 22,528.22389
Overall Steps per Second: 10,533.71001

Timestep Collection Time: 2.22050
Timestep Consumption Time: 2.52844
PPO Batch Consumption Time: 0.29681
Total Iteration Time: 4.74894

Cumulative Model Updates: 59,142
Cumulative Timesteps: 493,354,786

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.90897
Policy Entropy: 3.30219
Value Function Loss: 0.00354

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.07926
Policy Update Magnitude: 0.52756
Value Function Update Magnitude: 0.59869

Collected Steps per Second: 22,328.22083
Overall Steps per Second: 10,737.66381

Timestep Collection Time: 2.23995
Timestep Consumption Time: 2.41786
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.65781

Cumulative Model Updates: 59,148
Cumulative Timesteps: 493,404,800

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 493404800...
Checkpoint 493404800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 966.76534
Policy Entropy: 3.30516
Value Function Loss: 0.00354

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08022
Policy Update Magnitude: 0.54361
Value Function Update Magnitude: 0.62277

Collected Steps per Second: 22,043.37397
Overall Steps per Second: 10,630.15376

Timestep Collection Time: 2.26943
Timestep Consumption Time: 2.43661
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.70605

Cumulative Model Updates: 59,154
Cumulative Timesteps: 493,454,826

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.48893
Policy Entropy: 3.32042
Value Function Loss: 0.00340

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09126
Policy Update Magnitude: 0.53866
Value Function Update Magnitude: 0.62239

Collected Steps per Second: 22,766.75191
Overall Steps per Second: 10,596.70716

Timestep Collection Time: 2.19759
Timestep Consumption Time: 2.52388
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.72147

Cumulative Model Updates: 59,160
Cumulative Timesteps: 493,504,858

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 493504858...
Checkpoint 493504858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.93008
Policy Entropy: 3.31034
Value Function Loss: 0.00326

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08241
Policy Update Magnitude: 0.52887
Value Function Update Magnitude: 0.60355

Collected Steps per Second: 22,487.78316
Overall Steps per Second: 10,581.42798

Timestep Collection Time: 2.22467
Timestep Consumption Time: 2.50323
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.72791

Cumulative Model Updates: 59,166
Cumulative Timesteps: 493,554,886

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.76695
Policy Entropy: 3.32239
Value Function Loss: 0.00340

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.06629
Policy Update Magnitude: 0.52948
Value Function Update Magnitude: 0.58850

Collected Steps per Second: 22,709.80373
Overall Steps per Second: 10,659.62983

Timestep Collection Time: 2.20169
Timestep Consumption Time: 2.48890
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.69059

Cumulative Model Updates: 59,172
Cumulative Timesteps: 493,604,886

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 493604886...
Checkpoint 493604886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,852.70173
Policy Entropy: 3.31107
Value Function Loss: 0.00357

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07900
Policy Update Magnitude: 0.53455
Value Function Update Magnitude: 0.60129

Collected Steps per Second: 22,594.88841
Overall Steps per Second: 10,685.03416

Timestep Collection Time: 2.21298
Timestep Consumption Time: 2.46665
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.67963

Cumulative Model Updates: 59,178
Cumulative Timesteps: 493,654,888

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,935.95304
Policy Entropy: 3.31953
Value Function Loss: 0.00363

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08399
Policy Update Magnitude: 0.54107
Value Function Update Magnitude: 0.62423

Collected Steps per Second: 23,110.53008
Overall Steps per Second: 10,679.92194

Timestep Collection Time: 2.16473
Timestep Consumption Time: 2.51958
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.68430

Cumulative Model Updates: 59,184
Cumulative Timesteps: 493,704,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 493704916...
Checkpoint 493704916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672.63583
Policy Entropy: 3.31951
Value Function Loss: 0.00351

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08985
Policy Update Magnitude: 0.53795
Value Function Update Magnitude: 0.63449

Collected Steps per Second: 22,598.18597
Overall Steps per Second: 10,612.85695

Timestep Collection Time: 2.21336
Timestep Consumption Time: 2.49960
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.71296

Cumulative Model Updates: 59,190
Cumulative Timesteps: 493,754,934

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 931.00864
Policy Entropy: 3.32992
Value Function Loss: 0.00330

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.53778
Value Function Update Magnitude: 0.63426

Collected Steps per Second: 22,345.87264
Overall Steps per Second: 10,458.73275

Timestep Collection Time: 2.23880
Timestep Consumption Time: 2.54457
PPO Batch Consumption Time: 0.29738
Total Iteration Time: 4.78337

Cumulative Model Updates: 59,196
Cumulative Timesteps: 493,804,962

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 493804962...
Checkpoint 493804962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 906.32156
Policy Entropy: 3.32221
Value Function Loss: 0.00336

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08754
Policy Update Magnitude: 0.53302
Value Function Update Magnitude: 0.61771

Collected Steps per Second: 22,251.36183
Overall Steps per Second: 10,631.07028

Timestep Collection Time: 2.24795
Timestep Consumption Time: 2.45712
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.70508

Cumulative Model Updates: 59,202
Cumulative Timesteps: 493,854,982

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.09230
Policy Entropy: 3.32345
Value Function Loss: 0.00333

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08321
Policy Update Magnitude: 0.53739
Value Function Update Magnitude: 0.63476

Collected Steps per Second: 22,259.95125
Overall Steps per Second: 10,500.39920

Timestep Collection Time: 2.24655
Timestep Consumption Time: 2.51594
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.76249

Cumulative Model Updates: 59,208
Cumulative Timesteps: 493,904,990

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 493904990...
Checkpoint 493904990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,159.23440
Policy Entropy: 3.34014
Value Function Loss: 0.00327

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08047
Policy Update Magnitude: 0.53381
Value Function Update Magnitude: 0.62138

Collected Steps per Second: 22,398.12467
Overall Steps per Second: 10,657.74735

Timestep Collection Time: 2.23295
Timestep Consumption Time: 2.45978
PPO Batch Consumption Time: 0.28151
Total Iteration Time: 4.69274

Cumulative Model Updates: 59,214
Cumulative Timesteps: 493,955,004

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390.54677
Policy Entropy: 3.34073
Value Function Loss: 0.00330

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08768
Policy Update Magnitude: 0.52714
Value Function Update Magnitude: 0.60549

Collected Steps per Second: 22,658.17429
Overall Steps per Second: 10,518.78842

Timestep Collection Time: 2.20706
Timestep Consumption Time: 2.54710
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.75416

Cumulative Model Updates: 59,220
Cumulative Timesteps: 494,005,012

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 494005012...
Checkpoint 494005012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,610.75664
Policy Entropy: 3.32990
Value Function Loss: 0.00335

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.10774
Policy Update Magnitude: 0.52863
Value Function Update Magnitude: 0.61417

Collected Steps per Second: 21,863.68529
Overall Steps per Second: 10,503.04226

Timestep Collection Time: 2.28754
Timestep Consumption Time: 2.47432
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.76186

Cumulative Model Updates: 59,226
Cumulative Timesteps: 494,055,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.48117
Policy Entropy: 3.33941
Value Function Loss: 0.00346

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10052
Policy Update Magnitude: 0.52618
Value Function Update Magnitude: 0.62639

Collected Steps per Second: 22,332.71910
Overall Steps per Second: 10,466.16222

Timestep Collection Time: 2.23896
Timestep Consumption Time: 2.53853
PPO Batch Consumption Time: 0.29789
Total Iteration Time: 4.77749

Cumulative Model Updates: 59,232
Cumulative Timesteps: 494,105,028

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 494105028...
Checkpoint 494105028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.01184
Policy Entropy: 3.35093
Value Function Loss: 0.00344

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08262
Policy Update Magnitude: 0.52771
Value Function Update Magnitude: 0.63397

Collected Steps per Second: 22,296.44663
Overall Steps per Second: 10,651.10972

Timestep Collection Time: 2.24332
Timestep Consumption Time: 2.45272
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.69604

Cumulative Model Updates: 59,238
Cumulative Timesteps: 494,155,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.75592
Policy Entropy: 3.35765
Value Function Loss: 0.00313

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07443
Policy Update Magnitude: 0.52072
Value Function Update Magnitude: 0.64201

Collected Steps per Second: 22,488.48324
Overall Steps per Second: 10,612.70953

Timestep Collection Time: 2.22372
Timestep Consumption Time: 2.48837
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.71209

Cumulative Model Updates: 59,244
Cumulative Timesteps: 494,205,054

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 494205054...
Checkpoint 494205054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.91444
Policy Entropy: 3.34293
Value Function Loss: 0.00322

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07957
Policy Update Magnitude: 0.51644
Value Function Update Magnitude: 0.63998

Collected Steps per Second: 22,976.99247
Overall Steps per Second: 10,688.89079

Timestep Collection Time: 2.17740
Timestep Consumption Time: 2.50316
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.68056

Cumulative Model Updates: 59,250
Cumulative Timesteps: 494,255,084

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,627.09966
Policy Entropy: 3.33308
Value Function Loss: 0.00319

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08034
Policy Update Magnitude: 0.52288
Value Function Update Magnitude: 0.63942

Collected Steps per Second: 22,960.76830
Overall Steps per Second: 10,759.73826

Timestep Collection Time: 2.17798
Timestep Consumption Time: 2.46972
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.64770

Cumulative Model Updates: 59,256
Cumulative Timesteps: 494,305,092

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 494305092...
Checkpoint 494305092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.11909
Policy Entropy: 3.31424
Value Function Loss: 0.00327

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08278
Policy Update Magnitude: 0.52867
Value Function Update Magnitude: 0.65496

Collected Steps per Second: 22,857.85324
Overall Steps per Second: 10,626.61118

Timestep Collection Time: 2.18796
Timestep Consumption Time: 2.51834
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.70630

Cumulative Model Updates: 59,262
Cumulative Timesteps: 494,355,104

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.43925
Policy Entropy: 3.32344
Value Function Loss: 0.00317

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07468
Policy Update Magnitude: 0.54095
Value Function Update Magnitude: 0.66406

Collected Steps per Second: 22,515.60225
Overall Steps per Second: 10,528.39914

Timestep Collection Time: 2.22157
Timestep Consumption Time: 2.52939
PPO Batch Consumption Time: 0.29671
Total Iteration Time: 4.75096

Cumulative Model Updates: 59,268
Cumulative Timesteps: 494,405,124

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 494405124...
Checkpoint 494405124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706.21355
Policy Entropy: 3.30559
Value Function Loss: 0.00330

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08035
Policy Update Magnitude: 0.54341
Value Function Update Magnitude: 0.67375

Collected Steps per Second: 22,922.14554
Overall Steps per Second: 10,724.24179

Timestep Collection Time: 2.18217
Timestep Consumption Time: 2.48203
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.66420

Cumulative Model Updates: 59,274
Cumulative Timesteps: 494,455,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.84228
Policy Entropy: 3.31383
Value Function Loss: 0.00343

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.07745
Policy Update Magnitude: 0.54716
Value Function Update Magnitude: 0.70898

Collected Steps per Second: 22,529.24688
Overall Steps per Second: 10,786.90053

Timestep Collection Time: 2.22031
Timestep Consumption Time: 2.41698
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.63729

Cumulative Model Updates: 59,280
Cumulative Timesteps: 494,505,166

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 494505166...
Checkpoint 494505166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 807.21117
Policy Entropy: 3.29498
Value Function Loss: 0.00349

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07889
Policy Update Magnitude: 0.55166
Value Function Update Magnitude: 0.71789

Collected Steps per Second: 22,780.23673
Overall Steps per Second: 10,646.09209

Timestep Collection Time: 2.19497
Timestep Consumption Time: 2.50177
PPO Batch Consumption Time: 0.29696
Total Iteration Time: 4.69675

Cumulative Model Updates: 59,286
Cumulative Timesteps: 494,555,168

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647.62361
Policy Entropy: 3.30154
Value Function Loss: 0.00343

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08078
Policy Update Magnitude: 0.55603
Value Function Update Magnitude: 0.70391

Collected Steps per Second: 21,675.65320
Overall Steps per Second: 10,429.04373

Timestep Collection Time: 2.30812
Timestep Consumption Time: 2.48906
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.79718

Cumulative Model Updates: 59,292
Cumulative Timesteps: 494,605,198

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 494605198...
Checkpoint 494605198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.59273
Policy Entropy: 3.31052
Value Function Loss: 0.00330

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08399
Policy Update Magnitude: 0.55343
Value Function Update Magnitude: 0.67759

Collected Steps per Second: 22,119.94136
Overall Steps per Second: 10,585.50013

Timestep Collection Time: 2.26140
Timestep Consumption Time: 2.46412
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.72552

Cumulative Model Updates: 59,298
Cumulative Timesteps: 494,655,220

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 921.34292
Policy Entropy: 3.30253
Value Function Loss: 0.00341

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08496
Policy Update Magnitude: 0.54857
Value Function Update Magnitude: 0.64664

Collected Steps per Second: 22,171.00176
Overall Steps per Second: 10,472.95621

Timestep Collection Time: 2.25574
Timestep Consumption Time: 2.51961
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.77535

Cumulative Model Updates: 59,304
Cumulative Timesteps: 494,705,232

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 494705232...
Checkpoint 494705232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 993.08754
Policy Entropy: 3.30732
Value Function Loss: 0.00344

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11424
Policy Update Magnitude: 0.53618
Value Function Update Magnitude: 0.63753

Collected Steps per Second: 22,184.51852
Overall Steps per Second: 10,685.92127

Timestep Collection Time: 2.25418
Timestep Consumption Time: 2.42562
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.67980

Cumulative Model Updates: 59,310
Cumulative Timesteps: 494,755,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,312.95162
Policy Entropy: 3.30106
Value Function Loss: 0.00362

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09954
Policy Update Magnitude: 0.54123
Value Function Update Magnitude: 0.64444

Collected Steps per Second: 22,225.91687
Overall Steps per Second: 10,511.67375

Timestep Collection Time: 2.25071
Timestep Consumption Time: 2.50819
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 4.75890

Cumulative Model Updates: 59,316
Cumulative Timesteps: 494,805,264

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 494805264...
Checkpoint 494805264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 890.77643
Policy Entropy: 3.31406
Value Function Loss: 0.00374

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09731
Policy Update Magnitude: 0.55699
Value Function Update Magnitude: 0.67252

Collected Steps per Second: 22,746.18780
Overall Steps per Second: 10,588.28915

Timestep Collection Time: 2.19967
Timestep Consumption Time: 2.52574
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.72541

Cumulative Model Updates: 59,322
Cumulative Timesteps: 494,855,298

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 903.28077
Policy Entropy: 3.30037
Value Function Loss: 0.00363

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08052
Policy Update Magnitude: 0.56899
Value Function Update Magnitude: 0.67726

Collected Steps per Second: 22,738.25931
Overall Steps per Second: 10,730.93803

Timestep Collection Time: 2.19938
Timestep Consumption Time: 2.46098
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.66036

Cumulative Model Updates: 59,328
Cumulative Timesteps: 494,905,308

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 494905308...
Checkpoint 494905308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 856.70344
Policy Entropy: 3.30498
Value Function Loss: 0.00347

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07504
Policy Update Magnitude: 0.56809
Value Function Update Magnitude: 0.66804

Collected Steps per Second: 22,746.14638
Overall Steps per Second: 10,800.10170

Timestep Collection Time: 2.19835
Timestep Consumption Time: 2.43161
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.62996

Cumulative Model Updates: 59,334
Cumulative Timesteps: 494,955,312

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 811.48271
Policy Entropy: 3.29769
Value Function Loss: 0.00343

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08948
Policy Update Magnitude: 0.55637
Value Function Update Magnitude: 0.67280

Collected Steps per Second: 22,828.63423
Overall Steps per Second: 10,795.78069

Timestep Collection Time: 2.19049
Timestep Consumption Time: 2.44150
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.63199

Cumulative Model Updates: 59,340
Cumulative Timesteps: 495,005,318

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 495005318...
Checkpoint 495005318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.04298
Policy Entropy: 3.30569
Value Function Loss: 0.00340

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08568
Policy Update Magnitude: 0.56001
Value Function Update Magnitude: 0.66505

Collected Steps per Second: 22,615.04840
Overall Steps per Second: 10,766.75915

Timestep Collection Time: 2.21207
Timestep Consumption Time: 2.43427
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.64634

Cumulative Model Updates: 59,346
Cumulative Timesteps: 495,055,344

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.11558
Policy Entropy: 3.31709
Value Function Loss: 0.00335

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.07812
Policy Update Magnitude: 0.55020
Value Function Update Magnitude: 0.66268

Collected Steps per Second: 22,779.08582
Overall Steps per Second: 10,826.76134

Timestep Collection Time: 2.19526
Timestep Consumption Time: 2.42348
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.61874

Cumulative Model Updates: 59,352
Cumulative Timesteps: 495,105,350

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 495105350...
Checkpoint 495105350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 918.72299
Policy Entropy: 3.31848
Value Function Loss: 0.00340

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.54099
Value Function Update Magnitude: 0.66717

Collected Steps per Second: 22,351.73184
Overall Steps per Second: 10,734.58132

Timestep Collection Time: 2.23750
Timestep Consumption Time: 2.42146
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.65896

Cumulative Model Updates: 59,358
Cumulative Timesteps: 495,155,362

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782.72956
Policy Entropy: 3.31373
Value Function Loss: 0.00347

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09559
Policy Update Magnitude: 0.55145
Value Function Update Magnitude: 0.68023

Collected Steps per Second: 22,321.42558
Overall Steps per Second: 10,574.46153

Timestep Collection Time: 2.24090
Timestep Consumption Time: 2.48937
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.73026

Cumulative Model Updates: 59,364
Cumulative Timesteps: 495,205,382

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 495205382...
Checkpoint 495205382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 754.19488
Policy Entropy: 3.30723
Value Function Loss: 0.00333

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07599
Policy Update Magnitude: 0.55942
Value Function Update Magnitude: 0.67656

Collected Steps per Second: 22,241.07012
Overall Steps per Second: 10,528.02658

Timestep Collection Time: 2.24935
Timestep Consumption Time: 2.50254
PPO Batch Consumption Time: 0.29740
Total Iteration Time: 4.75189

Cumulative Model Updates: 59,370
Cumulative Timesteps: 495,255,410

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 899.50654
Policy Entropy: 3.29341
Value Function Loss: 0.00331

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08608
Policy Update Magnitude: 0.55097
Value Function Update Magnitude: 0.66098

Collected Steps per Second: 22,282.42962
Overall Steps per Second: 10,571.50832

Timestep Collection Time: 2.24428
Timestep Consumption Time: 2.48617
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.73045

Cumulative Model Updates: 59,376
Cumulative Timesteps: 495,305,418

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 495305418...
Checkpoint 495305418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,763.81952
Policy Entropy: 3.30388
Value Function Loss: 0.00327

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07372
Policy Update Magnitude: 0.55052
Value Function Update Magnitude: 0.66151

Collected Steps per Second: 22,203.16182
Overall Steps per Second: 10,538.29347

Timestep Collection Time: 2.25202
Timestep Consumption Time: 2.49277
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.74479

Cumulative Model Updates: 59,382
Cumulative Timesteps: 495,355,420

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.39243
Policy Entropy: 3.27873
Value Function Loss: 0.00352

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07792
Policy Update Magnitude: 0.55830
Value Function Update Magnitude: 0.68163

Collected Steps per Second: 22,685.95337
Overall Steps per Second: 10,697.82231

Timestep Collection Time: 2.20445
Timestep Consumption Time: 2.47034
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.67478

Cumulative Model Updates: 59,388
Cumulative Timesteps: 495,405,430

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 495405430...
Checkpoint 495405430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.29574
Policy Entropy: 3.28823
Value Function Loss: 0.00378

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08407
Policy Update Magnitude: 0.57204
Value Function Update Magnitude: 0.68701

Collected Steps per Second: 22,220.25226
Overall Steps per Second: 10,686.62563

Timestep Collection Time: 2.25047
Timestep Consumption Time: 2.42884
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.67931

Cumulative Model Updates: 59,394
Cumulative Timesteps: 495,455,436

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629.32269
Policy Entropy: 3.29467
Value Function Loss: 0.00350

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07952
Policy Update Magnitude: 0.57123
Value Function Update Magnitude: 0.68411

Collected Steps per Second: 22,661.52714
Overall Steps per Second: 10,623.40784

Timestep Collection Time: 2.20744
Timestep Consumption Time: 2.50141
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 4.70885

Cumulative Model Updates: 59,400
Cumulative Timesteps: 495,505,460

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 495505460...
Checkpoint 495505460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,005.32569
Policy Entropy: 3.31593
Value Function Loss: 0.00332

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08230
Policy Update Magnitude: 0.56179
Value Function Update Magnitude: 0.65726

Collected Steps per Second: 22,726.27770
Overall Steps per Second: 10,727.29840

Timestep Collection Time: 2.20186
Timestep Consumption Time: 2.46288
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.66473

Cumulative Model Updates: 59,406
Cumulative Timesteps: 495,555,500

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 795.95423
Policy Entropy: 3.31231
Value Function Loss: 0.00338

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09023
Policy Update Magnitude: 0.55366
Value Function Update Magnitude: 0.65696

Collected Steps per Second: 22,384.49484
Overall Steps per Second: 10,668.32362

Timestep Collection Time: 2.23387
Timestep Consumption Time: 2.45328
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.68715

Cumulative Model Updates: 59,412
Cumulative Timesteps: 495,605,504

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 495605504...
Checkpoint 495605504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.30281
Policy Entropy: 3.31584
Value Function Loss: 0.00332

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.54342
Value Function Update Magnitude: 0.65703

Collected Steps per Second: 22,846.95900
Overall Steps per Second: 10,663.42421

Timestep Collection Time: 2.18856
Timestep Consumption Time: 2.50055
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.68911

Cumulative Model Updates: 59,418
Cumulative Timesteps: 495,655,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726.23134
Policy Entropy: 3.31866
Value Function Loss: 0.00336

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.07990
Policy Update Magnitude: 0.55141
Value Function Update Magnitude: 0.64802

Collected Steps per Second: 22,296.58081
Overall Steps per Second: 10,555.80380

Timestep Collection Time: 2.24339
Timestep Consumption Time: 2.49523
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.73863

Cumulative Model Updates: 59,424
Cumulative Timesteps: 495,705,526

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 495705526...
Checkpoint 495705526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.61858
Policy Entropy: 3.31666
Value Function Loss: 0.00316

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07552
Policy Update Magnitude: 0.54942
Value Function Update Magnitude: 0.64600

Collected Steps per Second: 22,183.43967
Overall Steps per Second: 10,564.49586

Timestep Collection Time: 2.25456
Timestep Consumption Time: 2.47959
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.73416

Cumulative Model Updates: 59,430
Cumulative Timesteps: 495,755,540

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.52345
Policy Entropy: 3.30358
Value Function Loss: 0.00334

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08218
Policy Update Magnitude: 0.54726
Value Function Update Magnitude: 0.64227

Collected Steps per Second: 22,272.09864
Overall Steps per Second: 10,535.59145

Timestep Collection Time: 2.24622
Timestep Consumption Time: 2.50226
PPO Batch Consumption Time: 0.29572
Total Iteration Time: 4.74848

Cumulative Model Updates: 59,436
Cumulative Timesteps: 495,805,568

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 495805568...
Checkpoint 495805568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.50720
Policy Entropy: 3.30131
Value Function Loss: 0.00327

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09291
Policy Update Magnitude: 0.54588
Value Function Update Magnitude: 0.63890

Collected Steps per Second: 22,414.71772
Overall Steps per Second: 10,545.36760

Timestep Collection Time: 2.23130
Timestep Consumption Time: 2.51144
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.74275

Cumulative Model Updates: 59,442
Cumulative Timesteps: 495,855,582

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,341.16271
Policy Entropy: 3.31428
Value Function Loss: 0.00330

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09389
Policy Update Magnitude: 0.55493
Value Function Update Magnitude: 0.62873

Collected Steps per Second: 22,422.33395
Overall Steps per Second: 10,558.44165

Timestep Collection Time: 2.23028
Timestep Consumption Time: 2.50603
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.73630

Cumulative Model Updates: 59,448
Cumulative Timesteps: 495,905,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 495905590...
Checkpoint 495905590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.78739
Policy Entropy: 3.31772
Value Function Loss: 0.00332

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09796
Policy Update Magnitude: 0.55633
Value Function Update Magnitude: 0.63309

Collected Steps per Second: 21,434.75685
Overall Steps per Second: 10,522.20197

Timestep Collection Time: 2.33406
Timestep Consumption Time: 2.42065
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 4.75471

Cumulative Model Updates: 59,454
Cumulative Timesteps: 495,955,620

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 769.62296
Policy Entropy: 3.31748
Value Function Loss: 0.00343

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09328
Policy Update Magnitude: 0.55590
Value Function Update Magnitude: 0.63708

Collected Steps per Second: 22,364.79257
Overall Steps per Second: 10,473.24984

Timestep Collection Time: 2.23575
Timestep Consumption Time: 2.53851
PPO Batch Consumption Time: 0.29651
Total Iteration Time: 4.77426

Cumulative Model Updates: 59,460
Cumulative Timesteps: 496,005,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 496005622...
Checkpoint 496005622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 944.14089
Policy Entropy: 3.33220
Value Function Loss: 0.00338

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08146
Policy Update Magnitude: 0.56380
Value Function Update Magnitude: 0.63797

Collected Steps per Second: 22,813.82730
Overall Steps per Second: 10,656.07397

Timestep Collection Time: 2.19244
Timestep Consumption Time: 2.50141
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.69385

Cumulative Model Updates: 59,466
Cumulative Timesteps: 496,055,640

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,376.68950
Policy Entropy: 3.32222
Value Function Loss: 0.00337

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07784
Policy Update Magnitude: 0.56322
Value Function Update Magnitude: 0.62680

Collected Steps per Second: 22,839.55861
Overall Steps per Second: 10,801.48440

Timestep Collection Time: 2.18962
Timestep Consumption Time: 2.44030
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.62992

Cumulative Model Updates: 59,472
Cumulative Timesteps: 496,105,650

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 496105650...
Checkpoint 496105650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 770.56371
Policy Entropy: 3.31461
Value Function Loss: 0.00337

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08483
Policy Update Magnitude: 0.55662
Value Function Update Magnitude: 0.63026

Collected Steps per Second: 22,826.97610
Overall Steps per Second: 10,744.32513

Timestep Collection Time: 2.19057
Timestep Consumption Time: 2.46343
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.65399

Cumulative Model Updates: 59,478
Cumulative Timesteps: 496,155,654

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.02161
Policy Entropy: 3.29518
Value Function Loss: 0.00354

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10273
Policy Update Magnitude: 0.56298
Value Function Update Magnitude: 0.66838

Collected Steps per Second: 22,606.04464
Overall Steps per Second: 10,664.98945

Timestep Collection Time: 2.21277
Timestep Consumption Time: 2.47753
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.69030

Cumulative Model Updates: 59,484
Cumulative Timesteps: 496,205,676

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 496205676...
Checkpoint 496205676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.82806
Policy Entropy: 3.29965
Value Function Loss: 0.00369

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.10904
Policy Update Magnitude: 0.56997
Value Function Update Magnitude: 0.66736

Collected Steps per Second: 22,934.65970
Overall Steps per Second: 10,837.90314

Timestep Collection Time: 2.18072
Timestep Consumption Time: 2.43401
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.61473

Cumulative Model Updates: 59,490
Cumulative Timesteps: 496,255,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646.38660
Policy Entropy: 3.28822
Value Function Loss: 0.00371

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09899
Policy Update Magnitude: 0.57495
Value Function Update Magnitude: 0.66266

Collected Steps per Second: 22,569.04275
Overall Steps per Second: 10,613.28315

Timestep Collection Time: 2.21675
Timestep Consumption Time: 2.49715
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.71390

Cumulative Model Updates: 59,496
Cumulative Timesteps: 496,305,720

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 496305720...
Checkpoint 496305720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 799.67064
Policy Entropy: 3.29235
Value Function Loss: 0.00366

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.57406
Value Function Update Magnitude: 0.65464

Collected Steps per Second: 22,237.47614
Overall Steps per Second: 10,496.69632

Timestep Collection Time: 2.24846
Timestep Consumption Time: 2.51495
PPO Batch Consumption Time: 0.29740
Total Iteration Time: 4.76340

Cumulative Model Updates: 59,502
Cumulative Timesteps: 496,355,720

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.60641
Policy Entropy: 3.27897
Value Function Loss: 0.00353

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09738
Policy Update Magnitude: 0.56704
Value Function Update Magnitude: 0.63787

Collected Steps per Second: 22,382.73027
Overall Steps per Second: 10,595.21862

Timestep Collection Time: 2.23387
Timestep Consumption Time: 2.48524
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.71911

Cumulative Model Updates: 59,508
Cumulative Timesteps: 496,405,720

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 496405720...
Checkpoint 496405720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,272.34512
Policy Entropy: 3.29194
Value Function Loss: 0.00351

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09168
Policy Update Magnitude: 0.56249
Value Function Update Magnitude: 0.61968

Collected Steps per Second: 22,259.42118
Overall Steps per Second: 10,489.69131

Timestep Collection Time: 2.24624
Timestep Consumption Time: 2.52034
PPO Batch Consumption Time: 0.29803
Total Iteration Time: 4.76658

Cumulative Model Updates: 59,514
Cumulative Timesteps: 496,455,720

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719.35576
Policy Entropy: 3.28539
Value Function Loss: 0.00347

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10759
Policy Update Magnitude: 0.55903
Value Function Update Magnitude: 0.62213

Collected Steps per Second: 22,384.82305
Overall Steps per Second: 10,563.03543

Timestep Collection Time: 2.23375
Timestep Consumption Time: 2.49993
PPO Batch Consumption Time: 0.29614
Total Iteration Time: 4.73368

Cumulative Model Updates: 59,520
Cumulative Timesteps: 496,505,722

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 496505722...
Checkpoint 496505722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.49584
Policy Entropy: 3.30430
Value Function Loss: 0.00348

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11439
Policy Update Magnitude: 0.55709
Value Function Update Magnitude: 0.62647

Collected Steps per Second: 22,586.49805
Overall Steps per Second: 10,653.23985

Timestep Collection Time: 2.21495
Timestep Consumption Time: 2.48108
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.69604

Cumulative Model Updates: 59,526
Cumulative Timesteps: 496,555,750

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,567.63069
Policy Entropy: 3.31579
Value Function Loss: 0.00345

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.55101
Value Function Update Magnitude: 0.63012

Collected Steps per Second: 22,798.89852
Overall Steps per Second: 10,739.01809

Timestep Collection Time: 2.19344
Timestep Consumption Time: 2.46322
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.65666

Cumulative Model Updates: 59,532
Cumulative Timesteps: 496,605,758

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 496605758...
Checkpoint 496605758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.50956
Policy Entropy: 3.31942
Value Function Loss: 0.00342

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.55078
Value Function Update Magnitude: 0.63131

Collected Steps per Second: 22,829.90593
Overall Steps per Second: 10,693.94336

Timestep Collection Time: 2.19072
Timestep Consumption Time: 2.48613
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.67685

Cumulative Model Updates: 59,538
Cumulative Timesteps: 496,655,772

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,376.73103
Policy Entropy: 3.31927
Value Function Loss: 0.00357

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.55348
Value Function Update Magnitude: 0.65013

Collected Steps per Second: 22,787.38318
Overall Steps per Second: 10,706.17082

Timestep Collection Time: 2.19490
Timestep Consumption Time: 2.47680
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.67170

Cumulative Model Updates: 59,544
Cumulative Timesteps: 496,705,788

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 496705788...
Checkpoint 496705788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655.86263
Policy Entropy: 3.29580
Value Function Loss: 0.00379

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09791
Policy Update Magnitude: 0.55882
Value Function Update Magnitude: 0.65783

Collected Steps per Second: 22,842.57478
Overall Steps per Second: 10,823.11617

Timestep Collection Time: 2.18890
Timestep Consumption Time: 2.43085
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.61974

Cumulative Model Updates: 59,550
Cumulative Timesteps: 496,755,788

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 850.79605
Policy Entropy: 3.29843
Value Function Loss: 0.00375

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09170
Policy Update Magnitude: 0.57664
Value Function Update Magnitude: 0.67376

Collected Steps per Second: 22,540.89391
Overall Steps per Second: 10,635.18608

Timestep Collection Time: 2.21837
Timestep Consumption Time: 2.48338
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.70175

Cumulative Model Updates: 59,556
Cumulative Timesteps: 496,805,792

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 496805792...
Checkpoint 496805792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.73721
Policy Entropy: 3.31598
Value Function Loss: 0.00359

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12145
Policy Update Magnitude: 0.57008
Value Function Update Magnitude: 0.67749

Collected Steps per Second: 22,797.13042
Overall Steps per Second: 10,619.52464

Timestep Collection Time: 2.19414
Timestep Consumption Time: 2.51606
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.71019

Cumulative Model Updates: 59,562
Cumulative Timesteps: 496,855,812

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.61923
Policy Entropy: 3.33958
Value Function Loss: 0.00343

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11469
Policy Update Magnitude: 0.55602
Value Function Update Magnitude: 0.67268

Collected Steps per Second: 22,747.90984
Overall Steps per Second: 10,740.26814

Timestep Collection Time: 2.19827
Timestep Consumption Time: 2.45767
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.65594

Cumulative Model Updates: 59,568
Cumulative Timesteps: 496,905,818

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 496905818...
Checkpoint 496905818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.72560
Policy Entropy: 3.32648
Value Function Loss: 0.00340

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.54706
Value Function Update Magnitude: 0.65311

Collected Steps per Second: 22,088.57153
Overall Steps per Second: 10,663.94920

Timestep Collection Time: 2.26380
Timestep Consumption Time: 2.42527
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.68907

Cumulative Model Updates: 59,574
Cumulative Timesteps: 496,955,822

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.53509
Policy Entropy: 3.32567
Value Function Loss: 0.00334

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12032
Policy Update Magnitude: 0.54451
Value Function Update Magnitude: 0.64593

Collected Steps per Second: 22,148.90441
Overall Steps per Second: 10,510.34292

Timestep Collection Time: 2.25754
Timestep Consumption Time: 2.49987
PPO Batch Consumption Time: 0.29656
Total Iteration Time: 4.75741

Cumulative Model Updates: 59,580
Cumulative Timesteps: 497,005,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 497005824...
Checkpoint 497005824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480.49479
Policy Entropy: 3.32131
Value Function Loss: 0.00323

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.10993
Policy Update Magnitude: 0.54356
Value Function Update Magnitude: 0.64021

Collected Steps per Second: 22,332.62859
Overall Steps per Second: 10,590.48763

Timestep Collection Time: 2.24031
Timestep Consumption Time: 2.48393
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.72424

Cumulative Model Updates: 59,586
Cumulative Timesteps: 497,055,856

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741.28463
Policy Entropy: 3.32678
Value Function Loss: 0.00325

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08011
Policy Update Magnitude: 0.53839
Value Function Update Magnitude: 0.62001

Collected Steps per Second: 22,489.52606
Overall Steps per Second: 10,646.92035

Timestep Collection Time: 2.22424
Timestep Consumption Time: 2.47402
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.69826

Cumulative Model Updates: 59,592
Cumulative Timesteps: 497,105,878

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 497105878...
Checkpoint 497105878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.52264
Policy Entropy: 3.32699
Value Function Loss: 0.00326

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07156
Policy Update Magnitude: 0.54002
Value Function Update Magnitude: 0.60211

Collected Steps per Second: 22,117.09237
Overall Steps per Second: 10,533.34542

Timestep Collection Time: 2.26169
Timestep Consumption Time: 2.48723
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.74892

Cumulative Model Updates: 59,598
Cumulative Timesteps: 497,155,900

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 973.56643
Policy Entropy: 3.33226
Value Function Loss: 0.00336

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.54539
Value Function Update Magnitude: 0.60394

Collected Steps per Second: 22,921.54283
Overall Steps per Second: 10,733.85287

Timestep Collection Time: 2.18162
Timestep Consumption Time: 2.47710
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.65872

Cumulative Model Updates: 59,604
Cumulative Timesteps: 497,205,906

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 497205906...
Checkpoint 497205906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726.05628
Policy Entropy: 3.34650
Value Function Loss: 0.00339

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08188
Policy Update Magnitude: 0.54237
Value Function Update Magnitude: 0.60062

Collected Steps per Second: 22,698.89509
Overall Steps per Second: 10,687.24301

Timestep Collection Time: 2.20372
Timestep Consumption Time: 2.47681
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.68053

Cumulative Model Updates: 59,610
Cumulative Timesteps: 497,255,928

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.07331
Policy Entropy: 3.34818
Value Function Loss: 0.00340

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07101
Policy Update Magnitude: 0.54675
Value Function Update Magnitude: 0.62349

Collected Steps per Second: 22,821.64892
Overall Steps per Second: 10,826.32355

Timestep Collection Time: 2.19099
Timestep Consumption Time: 2.42757
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.61856

Cumulative Model Updates: 59,616
Cumulative Timesteps: 497,305,930

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 497305930...
Checkpoint 497305930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 665.04192
Policy Entropy: 3.34434
Value Function Loss: 0.00354

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.06940
Policy Update Magnitude: 0.55709
Value Function Update Magnitude: 0.64050

Collected Steps per Second: 22,894.41647
Overall Steps per Second: 10,761.48785

Timestep Collection Time: 2.18560
Timestep Consumption Time: 2.46413
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.64973

Cumulative Model Updates: 59,622
Cumulative Timesteps: 497,355,968

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788.49032
Policy Entropy: 3.33410
Value Function Loss: 0.00351

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09448
Policy Update Magnitude: 0.55517
Value Function Update Magnitude: 0.63358

Collected Steps per Second: 22,387.94814
Overall Steps per Second: 10,578.34288

Timestep Collection Time: 2.23424
Timestep Consumption Time: 2.49429
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.72853

Cumulative Model Updates: 59,628
Cumulative Timesteps: 497,405,988

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 497405988...
Checkpoint 497405988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 963.45412
Policy Entropy: 3.34757
Value Function Loss: 0.00358

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09964
Policy Update Magnitude: 0.54760
Value Function Update Magnitude: 0.62766

Collected Steps per Second: 22,847.47831
Overall Steps per Second: 10,633.94248

Timestep Collection Time: 2.18956
Timestep Consumption Time: 2.51481
PPO Batch Consumption Time: 0.29815
Total Iteration Time: 4.70437

Cumulative Model Updates: 59,634
Cumulative Timesteps: 497,456,014

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.40174
Policy Entropy: 3.36090
Value Function Loss: 0.00349

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09619
Policy Update Magnitude: 0.54899
Value Function Update Magnitude: 0.63307

Collected Steps per Second: 22,652.60553
Overall Steps per Second: 10,785.83714

Timestep Collection Time: 2.20822
Timestep Consumption Time: 2.42953
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.63775

Cumulative Model Updates: 59,640
Cumulative Timesteps: 497,506,036

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 497506036...
Checkpoint 497506036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,141.79477
Policy Entropy: 3.35844
Value Function Loss: 0.00354

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.53981
Value Function Update Magnitude: 0.63484

Collected Steps per Second: 22,230.28114
Overall Steps per Second: 10,670.55161

Timestep Collection Time: 2.24954
Timestep Consumption Time: 2.43700
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.68654

Cumulative Model Updates: 59,646
Cumulative Timesteps: 497,556,044

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,295.32534
Policy Entropy: 3.34766
Value Function Loss: 0.00346

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09070
Policy Update Magnitude: 0.53497
Value Function Update Magnitude: 0.64027

Collected Steps per Second: 21,863.23121
Overall Steps per Second: 10,526.44205

Timestep Collection Time: 2.28804
Timestep Consumption Time: 2.46418
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.75222

Cumulative Model Updates: 59,652
Cumulative Timesteps: 497,606,068

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 497606068...
Checkpoint 497606068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,173.20218
Policy Entropy: 3.33211
Value Function Loss: 0.00339

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07963
Policy Update Magnitude: 0.53834
Value Function Update Magnitude: 0.63135

Collected Steps per Second: 21,847.00735
Overall Steps per Second: 10,582.31733

Timestep Collection Time: 2.28928
Timestep Consumption Time: 2.43690
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.72619

Cumulative Model Updates: 59,658
Cumulative Timesteps: 497,656,082

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.15093
Policy Entropy: 3.35226
Value Function Loss: 0.00323

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07439
Policy Update Magnitude: 0.53899
Value Function Update Magnitude: 0.61225

Collected Steps per Second: 22,599.43473
Overall Steps per Second: 10,587.80928

Timestep Collection Time: 2.21315
Timestep Consumption Time: 2.51077
PPO Batch Consumption Time: 0.29688
Total Iteration Time: 4.72392

Cumulative Model Updates: 59,664
Cumulative Timesteps: 497,706,098

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 497706098...
Checkpoint 497706098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 944.14571
Policy Entropy: 3.36386
Value Function Loss: 0.00319

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07149
Policy Update Magnitude: 0.53624
Value Function Update Magnitude: 0.60972

Collected Steps per Second: 22,211.53945
Overall Steps per Second: 10,614.58579

Timestep Collection Time: 2.25243
Timestep Consumption Time: 2.46089
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.71333

Cumulative Model Updates: 59,670
Cumulative Timesteps: 497,756,128

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.55785
Policy Entropy: 3.37155
Value Function Loss: 0.00324

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.06648
Policy Update Magnitude: 0.53661
Value Function Update Magnitude: 0.61985

Collected Steps per Second: 22,756.99450
Overall Steps per Second: 10,766.67733

Timestep Collection Time: 2.19765
Timestep Consumption Time: 2.44742
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.64507

Cumulative Model Updates: 59,676
Cumulative Timesteps: 497,806,140

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 497806140...
Checkpoint 497806140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.12492
Policy Entropy: 3.36768
Value Function Loss: 0.00336

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.06782
Policy Update Magnitude: 0.54061
Value Function Update Magnitude: 0.62716

Collected Steps per Second: 21,822.10996
Overall Steps per Second: 10,428.94854

Timestep Collection Time: 2.29153
Timestep Consumption Time: 2.50339
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.79492

Cumulative Model Updates: 59,682
Cumulative Timesteps: 497,856,146

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,730.16412
Policy Entropy: 3.35861
Value Function Loss: 0.00336

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07216
Policy Update Magnitude: 0.54622
Value Function Update Magnitude: 0.64196

Collected Steps per Second: 22,730.17128
Overall Steps per Second: 10,780.79423

Timestep Collection Time: 2.20016
Timestep Consumption Time: 2.43865
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.63880

Cumulative Model Updates: 59,688
Cumulative Timesteps: 497,906,156

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 497906156...
Checkpoint 497906156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243.86816
Policy Entropy: 3.34505
Value Function Loss: 0.00345

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07603
Policy Update Magnitude: 0.55332
Value Function Update Magnitude: 0.65564

Collected Steps per Second: 22,610.40452
Overall Steps per Second: 10,603.18702

Timestep Collection Time: 2.21199
Timestep Consumption Time: 2.50489
PPO Batch Consumption Time: 0.29591
Total Iteration Time: 4.71688

Cumulative Model Updates: 59,694
Cumulative Timesteps: 497,956,170

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.12983
Policy Entropy: 3.33809
Value Function Loss: 0.00352

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.06949
Policy Update Magnitude: 0.55531
Value Function Update Magnitude: 0.66803

Collected Steps per Second: 22,691.12084
Overall Steps per Second: 10,772.44384

Timestep Collection Time: 2.20421
Timestep Consumption Time: 2.43875
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.64296

Cumulative Model Updates: 59,700
Cumulative Timesteps: 498,006,186

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 498006186...
Checkpoint 498006186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 946.31686
Policy Entropy: 3.33446
Value Function Loss: 0.00344

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08065
Policy Update Magnitude: 0.55169
Value Function Update Magnitude: 0.66985

Collected Steps per Second: 22,818.00802
Overall Steps per Second: 10,785.82847

Timestep Collection Time: 2.19151
Timestep Consumption Time: 2.44475
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.63627

Cumulative Model Updates: 59,706
Cumulative Timesteps: 498,056,192

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 903.37362
Policy Entropy: 3.34962
Value Function Loss: 0.00337

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10447
Policy Update Magnitude: 0.54780
Value Function Update Magnitude: 0.65565

Collected Steps per Second: 22,220.85967
Overall Steps per Second: 10,557.83771

Timestep Collection Time: 2.25068
Timestep Consumption Time: 2.48628
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.73695

Cumulative Model Updates: 59,712
Cumulative Timesteps: 498,106,204

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 498106204...
Checkpoint 498106204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 996.86782
Policy Entropy: 3.34686
Value Function Loss: 0.00332

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.53482
Value Function Update Magnitude: 0.65102

Collected Steps per Second: 22,244.49043
Overall Steps per Second: 10,532.02918

Timestep Collection Time: 2.24865
Timestep Consumption Time: 2.50068
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.74932

Cumulative Model Updates: 59,718
Cumulative Timesteps: 498,156,224

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.72548
Policy Entropy: 3.34659
Value Function Loss: 0.00338

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10149
Policy Update Magnitude: 0.52800
Value Function Update Magnitude: 0.64084

Collected Steps per Second: 22,521.71851
Overall Steps per Second: 10,611.12306

Timestep Collection Time: 2.22141
Timestep Consumption Time: 2.49345
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.71486

Cumulative Model Updates: 59,724
Cumulative Timesteps: 498,206,254

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 498206254...
Checkpoint 498206254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723.21114
Policy Entropy: 3.33980
Value Function Loss: 0.00345

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10015
Policy Update Magnitude: 0.53069
Value Function Update Magnitude: 0.61971

Collected Steps per Second: 21,770.12153
Overall Steps per Second: 10,484.47387

Timestep Collection Time: 2.29764
Timestep Consumption Time: 2.47322
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.77086

Cumulative Model Updates: 59,730
Cumulative Timesteps: 498,256,274

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.10162
Policy Entropy: 3.35450
Value Function Loss: 0.00369

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09168
Policy Update Magnitude: 0.53795
Value Function Update Magnitude: 0.63405

Collected Steps per Second: 22,738.36196
Overall Steps per Second: 10,806.90654

Timestep Collection Time: 2.19972
Timestep Consumption Time: 2.42862
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.62834

Cumulative Model Updates: 59,736
Cumulative Timesteps: 498,306,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 498306292...
Checkpoint 498306292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 772.50865
Policy Entropy: 3.35959
Value Function Loss: 0.00355

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09230
Policy Update Magnitude: 0.54300
Value Function Update Magnitude: 0.63945

Collected Steps per Second: 22,302.11025
Overall Steps per Second: 10,659.95502

Timestep Collection Time: 2.24239
Timestep Consumption Time: 2.44900
PPO Batch Consumption Time: 0.28183
Total Iteration Time: 4.69139

Cumulative Model Updates: 59,742
Cumulative Timesteps: 498,356,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 805.66683
Policy Entropy: 3.36786
Value Function Loss: 0.00340

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11028
Policy Update Magnitude: 0.54008
Value Function Update Magnitude: 0.63559

Collected Steps per Second: 22,646.92323
Overall Steps per Second: 10,588.67301

Timestep Collection Time: 2.20834
Timestep Consumption Time: 2.51483
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.72316

Cumulative Model Updates: 59,748
Cumulative Timesteps: 498,406,314

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 498406314...
Checkpoint 498406314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.63889
Policy Entropy: 3.35768
Value Function Loss: 0.00323

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10296
Policy Update Magnitude: 0.52348
Value Function Update Magnitude: 0.62389

Collected Steps per Second: 22,693.11301
Overall Steps per Second: 10,635.45923

Timestep Collection Time: 2.20375
Timestep Consumption Time: 2.49844
PPO Batch Consumption Time: 0.29800
Total Iteration Time: 4.70219

Cumulative Model Updates: 59,754
Cumulative Timesteps: 498,456,324

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.06595
Policy Entropy: 3.36606
Value Function Loss: 0.00322

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09285
Policy Update Magnitude: 0.52120
Value Function Update Magnitude: 0.61301

Collected Steps per Second: 22,728.62595
Overall Steps per Second: 10,796.82144

Timestep Collection Time: 2.20013
Timestep Consumption Time: 2.43142
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.63155

Cumulative Model Updates: 59,760
Cumulative Timesteps: 498,506,330

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 498506330...
Checkpoint 498506330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.16638
Policy Entropy: 3.37183
Value Function Loss: 0.00330

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07801
Policy Update Magnitude: 0.52874
Value Function Update Magnitude: 0.61583

Collected Steps per Second: 22,368.41929
Overall Steps per Second: 10,737.24964

Timestep Collection Time: 2.23610
Timestep Consumption Time: 2.42226
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.65836

Cumulative Model Updates: 59,766
Cumulative Timesteps: 498,556,348

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.36446
Policy Entropy: 3.36611
Value Function Loss: 0.00338

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07192
Policy Update Magnitude: 0.52896
Value Function Update Magnitude: 0.62179

Collected Steps per Second: 22,749.27059
Overall Steps per Second: 10,813.90072

Timestep Collection Time: 2.19866
Timestep Consumption Time: 2.42668
PPO Batch Consumption Time: 0.28211
Total Iteration Time: 4.62534

Cumulative Model Updates: 59,772
Cumulative Timesteps: 498,606,366

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 498606366...
Checkpoint 498606366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.38387
Policy Entropy: 3.35193
Value Function Loss: 0.00336

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07546
Policy Update Magnitude: 0.53234
Value Function Update Magnitude: 0.62722

Collected Steps per Second: 22,467.04651
Overall Steps per Second: 10,733.16138

Timestep Collection Time: 2.22566
Timestep Consumption Time: 2.43317
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.65883

Cumulative Model Updates: 59,778
Cumulative Timesteps: 498,656,370

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.96859
Policy Entropy: 3.34170
Value Function Loss: 0.00362

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08251
Policy Update Magnitude: 0.53843
Value Function Update Magnitude: 0.64358

Collected Steps per Second: 22,534.72350
Overall Steps per Second: 10,688.90558

Timestep Collection Time: 2.21995
Timestep Consumption Time: 2.46023
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.68018

Cumulative Model Updates: 59,784
Cumulative Timesteps: 498,706,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 498706396...
Checkpoint 498706396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.26537
Policy Entropy: 3.35016
Value Function Loss: 0.00360

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.53572
Value Function Update Magnitude: 0.65043

Collected Steps per Second: 22,397.70339
Overall Steps per Second: 10,726.16575

Timestep Collection Time: 2.23300
Timestep Consumption Time: 2.42981
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.66280

Cumulative Model Updates: 59,790
Cumulative Timesteps: 498,756,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.33596
Policy Entropy: 3.33807
Value Function Loss: 0.00344

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11288
Policy Update Magnitude: 0.53523
Value Function Update Magnitude: 0.62635

Collected Steps per Second: 22,616.91404
Overall Steps per Second: 10,588.37310

Timestep Collection Time: 2.21180
Timestep Consumption Time: 2.51263
PPO Batch Consumption Time: 0.29683
Total Iteration Time: 4.72443

Cumulative Model Updates: 59,796
Cumulative Timesteps: 498,806,434

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 498806434...
Checkpoint 498806434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.75022
Policy Entropy: 3.35821
Value Function Loss: 0.00341

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.53121
Value Function Update Magnitude: 0.60870

Collected Steps per Second: 21,976.07140
Overall Steps per Second: 10,636.43762

Timestep Collection Time: 2.27602
Timestep Consumption Time: 2.42649
PPO Batch Consumption Time: 0.28183
Total Iteration Time: 4.70251

Cumulative Model Updates: 59,802
Cumulative Timesteps: 498,856,452

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 993.30132
Policy Entropy: 3.34951
Value Function Loss: 0.00351

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08843
Policy Update Magnitude: 0.53458
Value Function Update Magnitude: 0.60715

Collected Steps per Second: 22,894.50505
Overall Steps per Second: 10,781.97906

Timestep Collection Time: 2.18507
Timestep Consumption Time: 2.45471
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.63978

Cumulative Model Updates: 59,808
Cumulative Timesteps: 498,906,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 498906478...
Checkpoint 498906478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.01879
Policy Entropy: 3.36477
Value Function Loss: 0.00340

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08652
Policy Update Magnitude: 0.53194
Value Function Update Magnitude: 0.63401

Collected Steps per Second: 22,288.34726
Overall Steps per Second: 10,717.02255

Timestep Collection Time: 2.24413
Timestep Consumption Time: 2.42302
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.66715

Cumulative Model Updates: 59,814
Cumulative Timesteps: 498,956,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.89850
Policy Entropy: 3.36633
Value Function Loss: 0.00319

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08080
Policy Update Magnitude: 0.52644
Value Function Update Magnitude: 0.64921

Collected Steps per Second: 22,852.50698
Overall Steps per Second: 10,815.56369

Timestep Collection Time: 2.18864
Timestep Consumption Time: 2.43580
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.62445

Cumulative Model Updates: 59,820
Cumulative Timesteps: 499,006,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 499006512...
Checkpoint 499006512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 762.84187
Policy Entropy: 3.37975
Value Function Loss: 0.00308

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09115
Policy Update Magnitude: 0.51481
Value Function Update Magnitude: 0.62196

Collected Steps per Second: 22,459.92307
Overall Steps per Second: 10,773.00490

Timestep Collection Time: 2.22619
Timestep Consumption Time: 2.41504
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.64123

Cumulative Model Updates: 59,826
Cumulative Timesteps: 499,056,512

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.75795
Policy Entropy: 3.38386
Value Function Loss: 0.00325

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08723
Policy Update Magnitude: 0.51576
Value Function Update Magnitude: 0.62055

Collected Steps per Second: 22,746.84837
Overall Steps per Second: 10,772.16231

Timestep Collection Time: 2.19916
Timestep Consumption Time: 2.44466
PPO Batch Consumption Time: 0.28421
Total Iteration Time: 4.64382

Cumulative Model Updates: 59,832
Cumulative Timesteps: 499,106,536

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 499106536...
Checkpoint 499106536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.23617
Policy Entropy: 3.38694
Value Function Loss: 0.00327

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.52010
Value Function Update Magnitude: 0.62571

Collected Steps per Second: 22,618.20615
Overall Steps per Second: 10,803.46925

Timestep Collection Time: 2.21114
Timestep Consumption Time: 2.41811
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.62925

Cumulative Model Updates: 59,838
Cumulative Timesteps: 499,156,548

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.92839
Policy Entropy: 3.40029
Value Function Loss: 0.00324

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09075
Policy Update Magnitude: 0.52407
Value Function Update Magnitude: 0.62363

Collected Steps per Second: 22,383.29773
Overall Steps per Second: 10,648.59315

Timestep Collection Time: 2.23506
Timestep Consumption Time: 2.46303
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.69809

Cumulative Model Updates: 59,844
Cumulative Timesteps: 499,206,576

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 499206576...
Checkpoint 499206576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 795.78248
Policy Entropy: 3.38551
Value Function Loss: 0.00349

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.52100
Value Function Update Magnitude: 0.62861

Collected Steps per Second: 22,541.32561
Overall Steps per Second: 10,615.61664

Timestep Collection Time: 2.21930
Timestep Consumption Time: 2.49319
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.71249

Cumulative Model Updates: 59,850
Cumulative Timesteps: 499,256,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481.19687
Policy Entropy: 3.38150
Value Function Loss: 0.00355

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06713
Policy Update Magnitude: 0.53085
Value Function Update Magnitude: 0.65200

Collected Steps per Second: 22,641.56853
Overall Steps per Second: 10,823.69533

Timestep Collection Time: 2.20921
Timestep Consumption Time: 2.41213
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.62134

Cumulative Model Updates: 59,856
Cumulative Timesteps: 499,306,622

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 499306622...
Checkpoint 499306622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.29765
Policy Entropy: 3.37589
Value Function Loss: 0.00344

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07455
Policy Update Magnitude: 0.53939
Value Function Update Magnitude: 0.67078

Collected Steps per Second: 22,463.51734
Overall Steps per Second: 10,548.57550

Timestep Collection Time: 2.22583
Timestep Consumption Time: 2.51415
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.73998

Cumulative Model Updates: 59,862
Cumulative Timesteps: 499,356,622

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.89034
Policy Entropy: 3.38927
Value Function Loss: 0.00321

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10058
Policy Update Magnitude: 0.53304
Value Function Update Magnitude: 0.65398

Collected Steps per Second: 22,826.29499
Overall Steps per Second: 10,568.26241

Timestep Collection Time: 2.19081
Timestep Consumption Time: 2.54110
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.73190

Cumulative Model Updates: 59,868
Cumulative Timesteps: 499,406,630

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 499406630...
Checkpoint 499406630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,644.65526
Policy Entropy: 3.39501
Value Function Loss: 0.00333

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.52677
Value Function Update Magnitude: 0.64788

Collected Steps per Second: 22,721.26106
Overall Steps per Second: 10,557.03729

Timestep Collection Time: 2.20102
Timestep Consumption Time: 2.53610
PPO Batch Consumption Time: 0.29667
Total Iteration Time: 4.73712

Cumulative Model Updates: 59,874
Cumulative Timesteps: 499,456,640

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.94348
Policy Entropy: 3.39229
Value Function Loss: 0.00339

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08591
Policy Update Magnitude: 0.53938
Value Function Update Magnitude: 0.63194

Collected Steps per Second: 23,110.26337
Overall Steps per Second: 10,797.55258

Timestep Collection Time: 2.16354
Timestep Consumption Time: 2.46714
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.63068

Cumulative Model Updates: 59,880
Cumulative Timesteps: 499,506,640

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 499506640...
Checkpoint 499506640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701.13160
Policy Entropy: 3.38223
Value Function Loss: 0.00326

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07775
Policy Update Magnitude: 0.53771
Value Function Update Magnitude: 0.61555

Collected Steps per Second: 22,189.78107
Overall Steps per Second: 10,712.28948

Timestep Collection Time: 2.25338
Timestep Consumption Time: 2.41434
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.66772

Cumulative Model Updates: 59,886
Cumulative Timesteps: 499,556,642

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.70682
Policy Entropy: 3.37268
Value Function Loss: 0.00320

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.52853
Value Function Update Magnitude: 0.60490

Collected Steps per Second: 22,687.52324
Overall Steps per Second: 10,633.99507

Timestep Collection Time: 2.20403
Timestep Consumption Time: 2.49825
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.70228

Cumulative Model Updates: 59,892
Cumulative Timesteps: 499,606,646

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 499606646...
Checkpoint 499606646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449.08684
Policy Entropy: 3.36892
Value Function Loss: 0.00297

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.51676
Value Function Update Magnitude: 0.57366

Collected Steps per Second: 22,847.12386
Overall Steps per Second: 10,835.61713

Timestep Collection Time: 2.18898
Timestep Consumption Time: 2.42653
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.61552

Cumulative Model Updates: 59,898
Cumulative Timesteps: 499,656,658

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.86738
Policy Entropy: 3.38657
Value Function Loss: 0.00310

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07735
Policy Update Magnitude: 0.51347
Value Function Update Magnitude: 0.56026

Collected Steps per Second: 22,194.12249
Overall Steps per Second: 10,531.73908

Timestep Collection Time: 2.25285
Timestep Consumption Time: 2.49471
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.74755

Cumulative Model Updates: 59,904
Cumulative Timesteps: 499,706,658

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 499706658...
Checkpoint 499706658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 877.97170
Policy Entropy: 3.38710
Value Function Loss: 0.00322

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07896
Policy Update Magnitude: 0.51249
Value Function Update Magnitude: 0.59044

Collected Steps per Second: 22,258.86093
Overall Steps per Second: 10,532.74051

Timestep Collection Time: 2.24693
Timestep Consumption Time: 2.50151
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.74843

Cumulative Model Updates: 59,910
Cumulative Timesteps: 499,756,672

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.75758
Policy Entropy: 3.37882
Value Function Loss: 0.00355

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08306
Policy Update Magnitude: 0.51844
Value Function Update Magnitude: 0.60365

Collected Steps per Second: 22,403.81170
Overall Steps per Second: 10,571.33269

Timestep Collection Time: 2.23203
Timestep Consumption Time: 2.49831
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.73034

Cumulative Model Updates: 59,916
Cumulative Timesteps: 499,806,678

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 499806678...
Checkpoint 499806678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 944.81897
Policy Entropy: 3.36772
Value Function Loss: 0.00346

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.52320
Value Function Update Magnitude: 0.60401

Collected Steps per Second: 22,385.56551
Overall Steps per Second: 10,598.05557

Timestep Collection Time: 2.23385
Timestep Consumption Time: 2.48456
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.71841

Cumulative Model Updates: 59,922
Cumulative Timesteps: 499,856,684

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654.88077
Policy Entropy: 3.35860
Value Function Loss: 0.00339

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09521
Policy Update Magnitude: 0.52434
Value Function Update Magnitude: 0.62964

Collected Steps per Second: 22,489.60635
Overall Steps per Second: 10,478.56177

Timestep Collection Time: 2.22405
Timestep Consumption Time: 2.54932
PPO Batch Consumption Time: 0.29728
Total Iteration Time: 4.77337

Cumulative Model Updates: 59,928
Cumulative Timesteps: 499,906,702

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 499906702...
Checkpoint 499906702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,890.09893
Policy Entropy: 3.36607
Value Function Loss: 0.00318

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08492
Policy Update Magnitude: 0.52158
Value Function Update Magnitude: 0.63541

Collected Steps per Second: 22,458.96223
Overall Steps per Second: 10,602.72464

Timestep Collection Time: 2.22691
Timestep Consumption Time: 2.49018
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.71709

Cumulative Model Updates: 59,934
Cumulative Timesteps: 499,956,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.48386
Policy Entropy: 3.36416
Value Function Loss: 0.00313

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07980
Policy Update Magnitude: 0.52381
Value Function Update Magnitude: 0.61947

Collected Steps per Second: 22,833.09582
Overall Steps per Second: 10,807.42628

Timestep Collection Time: 2.18980
Timestep Consumption Time: 2.43664
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.62645

Cumulative Model Updates: 59,940
Cumulative Timesteps: 500,006,716

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 500006716...
Checkpoint 500006716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.08256
Policy Entropy: 3.37832
Value Function Loss: 0.00321

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07240
Policy Update Magnitude: 0.52458
Value Function Update Magnitude: 0.61327

Collected Steps per Second: 22,586.22885
Overall Steps per Second: 10,722.30227

Timestep Collection Time: 2.21498
Timestep Consumption Time: 2.45081
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.66579

Cumulative Model Updates: 59,946
Cumulative Timesteps: 500,056,744

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783.68395
Policy Entropy: 3.37309
Value Function Loss: 0.00340

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09402
Policy Update Magnitude: 0.52861
Value Function Update Magnitude: 0.64129

Collected Steps per Second: 22,825.34920
Overall Steps per Second: 10,629.81539

Timestep Collection Time: 2.19099
Timestep Consumption Time: 2.51371
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.70469

Cumulative Model Updates: 59,952
Cumulative Timesteps: 500,106,754

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 500106754...
Checkpoint 500106754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,902.39879
Policy Entropy: 3.39256
Value Function Loss: 0.00331

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09791
Policy Update Magnitude: 0.53221
Value Function Update Magnitude: 0.65331

Collected Steps per Second: 22,260.29112
Overall Steps per Second: 10,503.45155

Timestep Collection Time: 2.24651
Timestep Consumption Time: 2.51459
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.76110

Cumulative Model Updates: 59,958
Cumulative Timesteps: 500,156,762

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 958.24205
Policy Entropy: 3.39984
Value Function Loss: 0.00317

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09525
Policy Update Magnitude: 0.53321
Value Function Update Magnitude: 0.63212

Collected Steps per Second: 22,670.38522
Overall Steps per Second: 10,585.55675

Timestep Collection Time: 2.20667
Timestep Consumption Time: 2.51921
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.72587

Cumulative Model Updates: 59,964
Cumulative Timesteps: 500,206,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 500206788...
Checkpoint 500206788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708.59512
Policy Entropy: 3.38992
Value Function Loss: 0.00323

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09406
Policy Update Magnitude: 0.52521
Value Function Update Magnitude: 0.61006

Collected Steps per Second: 22,561.82731
Overall Steps per Second: 10,646.51484

Timestep Collection Time: 2.21622
Timestep Consumption Time: 2.48034
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.69656

Cumulative Model Updates: 59,970
Cumulative Timesteps: 500,256,790

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.40140
Policy Entropy: 3.37961
Value Function Loss: 0.00333

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07536
Policy Update Magnitude: 0.52896
Value Function Update Magnitude: 0.59670

Collected Steps per Second: 22,722.88725
Overall Steps per Second: 10,783.90151

Timestep Collection Time: 2.20148
Timestep Consumption Time: 2.43729
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.63877

Cumulative Model Updates: 59,976
Cumulative Timesteps: 500,306,814

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 500306814...
Checkpoint 500306814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.73745
Policy Entropy: 3.37963
Value Function Loss: 0.00323

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07261
Policy Update Magnitude: 0.53342
Value Function Update Magnitude: 0.60285

Collected Steps per Second: 22,184.81689
Overall Steps per Second: 10,614.64047

Timestep Collection Time: 2.25506
Timestep Consumption Time: 2.45806
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.71311

Cumulative Model Updates: 59,982
Cumulative Timesteps: 500,356,842

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.97449
Policy Entropy: 3.37979
Value Function Loss: 0.00331

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.07909
Policy Update Magnitude: 0.53345
Value Function Update Magnitude: 0.59915

Collected Steps per Second: 22,568.43138
Overall Steps per Second: 10,663.97058

Timestep Collection Time: 2.21566
Timestep Consumption Time: 2.47340
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.68906

Cumulative Model Updates: 59,988
Cumulative Timesteps: 500,406,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 500406846...
Checkpoint 500406846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 853.31867
Policy Entropy: 3.37516
Value Function Loss: 0.00328

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.53213
Value Function Update Magnitude: 0.60578

Collected Steps per Second: 22,489.08988
Overall Steps per Second: 10,502.65882

Timestep Collection Time: 2.22472
Timestep Consumption Time: 2.53902
PPO Batch Consumption Time: 0.29644
Total Iteration Time: 4.76375

Cumulative Model Updates: 59,994
Cumulative Timesteps: 500,456,878

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243.42692
Policy Entropy: 3.36898
Value Function Loss: 0.00338

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.52645
Value Function Update Magnitude: 0.61194

Collected Steps per Second: 23,200.84901
Overall Steps per Second: 10,788.86374

Timestep Collection Time: 2.15630
Timestep Consumption Time: 2.48070
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.63700

Cumulative Model Updates: 60,000
Cumulative Timesteps: 500,506,906

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 500506906...
Checkpoint 500506906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 820.93284
Policy Entropy: 3.36856
Value Function Loss: 0.00348

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.52930
Value Function Update Magnitude: 0.63424

Collected Steps per Second: 22,464.03224
Overall Steps per Second: 10,645.24319

Timestep Collection Time: 2.22640
Timestep Consumption Time: 2.47185
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.69825

Cumulative Model Updates: 60,006
Cumulative Timesteps: 500,556,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.83466
Policy Entropy: 3.36975
Value Function Loss: 0.00353

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08970
Policy Update Magnitude: 0.53524
Value Function Update Magnitude: 0.65306

Collected Steps per Second: 23,057.05214
Overall Steps per Second: 10,846.66215

Timestep Collection Time: 2.16888
Timestep Consumption Time: 2.44157
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.61045

Cumulative Model Updates: 60,012
Cumulative Timesteps: 500,606,928

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 500606928...
Checkpoint 500606928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 951.82454
Policy Entropy: 3.36703
Value Function Loss: 0.00339

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.07820
Policy Update Magnitude: 0.54566
Value Function Update Magnitude: 0.65326

Collected Steps per Second: 22,595.77694
Overall Steps per Second: 10,768.90480

Timestep Collection Time: 2.21378
Timestep Consumption Time: 2.43126
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.64504

Cumulative Model Updates: 60,018
Cumulative Timesteps: 500,656,950

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694.11736
Policy Entropy: 3.35991
Value Function Loss: 0.00331

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08818
Policy Update Magnitude: 0.54290
Value Function Update Magnitude: 0.63720

Collected Steps per Second: 23,071.07435
Overall Steps per Second: 10,870.30570

Timestep Collection Time: 2.16826
Timestep Consumption Time: 2.43364
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.60189

Cumulative Model Updates: 60,024
Cumulative Timesteps: 500,706,974

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 500706974...
Checkpoint 500706974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.85785
Policy Entropy: 3.36731
Value Function Loss: 0.00347

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08431
Policy Update Magnitude: 0.53757
Value Function Update Magnitude: 0.62700

Collected Steps per Second: 22,184.48032
Overall Steps per Second: 10,720.06106

Timestep Collection Time: 2.25473
Timestep Consumption Time: 2.41129
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.66602

Cumulative Model Updates: 60,030
Cumulative Timesteps: 500,756,994

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.15636
Policy Entropy: 3.36850
Value Function Loss: 0.00342

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08735
Policy Update Magnitude: 0.54600
Value Function Update Magnitude: 0.62254

Collected Steps per Second: 22,411.06616
Overall Steps per Second: 10,623.82833

Timestep Collection Time: 2.23175
Timestep Consumption Time: 2.47615
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.70791

Cumulative Model Updates: 60,036
Cumulative Timesteps: 500,807,010

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 500807010...
Checkpoint 500807010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 782.95626
Policy Entropy: 3.37309
Value Function Loss: 0.00353

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10908
Policy Update Magnitude: 0.54157
Value Function Update Magnitude: 0.62392

Collected Steps per Second: 22,397.53114
Overall Steps per Second: 10,625.24765

Timestep Collection Time: 2.23248
Timestep Consumption Time: 2.47348
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.70596

Cumulative Model Updates: 60,042
Cumulative Timesteps: 500,857,012

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.46985
Policy Entropy: 3.38180
Value Function Loss: 0.00341

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10130
Policy Update Magnitude: 0.53657
Value Function Update Magnitude: 0.62882

Collected Steps per Second: 22,717.53053
Overall Steps per Second: 10,730.11009

Timestep Collection Time: 2.20130
Timestep Consumption Time: 2.45923
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.66053

Cumulative Model Updates: 60,048
Cumulative Timesteps: 500,907,020

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 500907020...
Checkpoint 500907020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.30784
Policy Entropy: 3.37230
Value Function Loss: 0.00336

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09110
Policy Update Magnitude: 0.53614
Value Function Update Magnitude: 0.63288

Collected Steps per Second: 22,241.30576
Overall Steps per Second: 10,615.17870

Timestep Collection Time: 2.24906
Timestep Consumption Time: 2.46325
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.71231

Cumulative Model Updates: 60,054
Cumulative Timesteps: 500,957,042

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.09887
Policy Entropy: 3.37253
Value Function Loss: 0.00345

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.54290
Value Function Update Magnitude: 0.62393

Collected Steps per Second: 22,423.27933
Overall Steps per Second: 10,573.31646

Timestep Collection Time: 2.23107
Timestep Consumption Time: 2.50046
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.73153

Cumulative Model Updates: 60,060
Cumulative Timesteps: 501,007,070

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 501007070...
Checkpoint 501007070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.63793
Policy Entropy: 3.36165
Value Function Loss: 0.00363

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10286
Policy Update Magnitude: 0.55248
Value Function Update Magnitude: 0.65305

Collected Steps per Second: 22,417.51175
Overall Steps per Second: 10,500.01961

Timestep Collection Time: 2.23102
Timestep Consumption Time: 2.53221
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.76323

Cumulative Model Updates: 60,066
Cumulative Timesteps: 501,057,084

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571.87885
Policy Entropy: 3.36173
Value Function Loss: 0.00367

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09126
Policy Update Magnitude: 0.55005
Value Function Update Magnitude: 0.68960

Collected Steps per Second: 23,366.66590
Overall Steps per Second: 10,922.48861

Timestep Collection Time: 2.14040
Timestep Consumption Time: 2.43859
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.57899

Cumulative Model Updates: 60,072
Cumulative Timesteps: 501,107,098

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 501107098...
Checkpoint 501107098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 897.51899
Policy Entropy: 3.35627
Value Function Loss: 0.00358

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07576
Policy Update Magnitude: 0.55015
Value Function Update Magnitude: 0.67864

Collected Steps per Second: 22,237.26733
Overall Steps per Second: 10,646.84103

Timestep Collection Time: 2.24983
Timestep Consumption Time: 2.44922
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.69905

Cumulative Model Updates: 60,078
Cumulative Timesteps: 501,157,128

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.80451
Policy Entropy: 3.36025
Value Function Loss: 0.00350

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08499
Policy Update Magnitude: 0.55239
Value Function Update Magnitude: 0.65584

Collected Steps per Second: 22,863.74117
Overall Steps per Second: 10,756.68913

Timestep Collection Time: 2.18792
Timestep Consumption Time: 2.46258
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.65050

Cumulative Model Updates: 60,084
Cumulative Timesteps: 501,207,152

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 501207152...
Checkpoint 501207152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 785.67644
Policy Entropy: 3.36572
Value Function Loss: 0.00357

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08444
Policy Update Magnitude: 0.55080
Value Function Update Magnitude: 0.64200

Collected Steps per Second: 22,554.18248
Overall Steps per Second: 10,729.30785

Timestep Collection Time: 2.21768
Timestep Consumption Time: 2.44413
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.66181

Cumulative Model Updates: 60,090
Cumulative Timesteps: 501,257,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 934.58788
Policy Entropy: 3.36633
Value Function Loss: 0.00358

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09633
Policy Update Magnitude: 0.55550
Value Function Update Magnitude: 0.66358

Collected Steps per Second: 22,857.25146
Overall Steps per Second: 10,610.46795

Timestep Collection Time: 2.18889
Timestep Consumption Time: 2.52645
PPO Batch Consumption Time: 0.29670
Total Iteration Time: 4.71534

Cumulative Model Updates: 60,096
Cumulative Timesteps: 501,307,202

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 501307202...
Checkpoint 501307202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408.25528
Policy Entropy: 3.36545
Value Function Loss: 0.00359

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10275
Policy Update Magnitude: 0.55783
Value Function Update Magnitude: 0.67798

Collected Steps per Second: 22,157.44525
Overall Steps per Second: 10,561.83297

Timestep Collection Time: 2.25766
Timestep Consumption Time: 2.47864
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.73630

Cumulative Model Updates: 60,102
Cumulative Timesteps: 501,357,226

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.88613
Policy Entropy: 3.35562
Value Function Loss: 0.00358

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.55055
Value Function Update Magnitude: 0.67363

Collected Steps per Second: 22,422.82231
Overall Steps per Second: 10,495.07337

Timestep Collection Time: 2.23067
Timestep Consumption Time: 2.53518
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.76586

Cumulative Model Updates: 60,108
Cumulative Timesteps: 501,407,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 501407244...
Checkpoint 501407244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 721.32852
Policy Entropy: 3.36144
Value Function Loss: 0.00371

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.55795
Value Function Update Magnitude: 0.67311

Collected Steps per Second: 22,437.28950
Overall Steps per Second: 10,531.65879

Timestep Collection Time: 2.22852
Timestep Consumption Time: 2.51926
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.74778

Cumulative Model Updates: 60,114
Cumulative Timesteps: 501,457,246

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 999.43709
Policy Entropy: 3.37001
Value Function Loss: 0.00354

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08589
Policy Update Magnitude: 0.55154
Value Function Update Magnitude: 0.64545

Collected Steps per Second: 22,113.06078
Overall Steps per Second: 10,495.73329

Timestep Collection Time: 2.26201
Timestep Consumption Time: 2.50373
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.76575

Cumulative Model Updates: 60,120
Cumulative Timesteps: 501,507,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 501507266...
Checkpoint 501507266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725.27787
Policy Entropy: 3.36539
Value Function Loss: 0.00361

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07260
Policy Update Magnitude: 0.54865
Value Function Update Magnitude: 0.61555

Collected Steps per Second: 22,018.60912
Overall Steps per Second: 10,645.89262

Timestep Collection Time: 2.27090
Timestep Consumption Time: 2.42594
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.69683

Cumulative Model Updates: 60,126
Cumulative Timesteps: 501,557,268

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 948.65669
Policy Entropy: 3.35114
Value Function Loss: 0.00350

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.54227
Value Function Update Magnitude: 0.61140

Collected Steps per Second: 22,663.91259
Overall Steps per Second: 10,674.17682

Timestep Collection Time: 2.20633
Timestep Consumption Time: 2.47825
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.68458

Cumulative Model Updates: 60,132
Cumulative Timesteps: 501,607,272

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 501607272...
Checkpoint 501607272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.73168
Policy Entropy: 3.33332
Value Function Loss: 0.00356

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08886
Policy Update Magnitude: 0.54475
Value Function Update Magnitude: 0.61849

Collected Steps per Second: 22,400.35810
Overall Steps per Second: 10,574.94403

Timestep Collection Time: 2.23309
Timestep Consumption Time: 2.49715
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.73024

Cumulative Model Updates: 60,138
Cumulative Timesteps: 501,657,294

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.45894
Policy Entropy: 3.33363
Value Function Loss: 0.00343

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08519
Policy Update Magnitude: 0.54424
Value Function Update Magnitude: 0.61280

Collected Steps per Second: 22,940.24119
Overall Steps per Second: 10,753.20011

Timestep Collection Time: 2.18080
Timestep Consumption Time: 2.47159
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.65238

Cumulative Model Updates: 60,144
Cumulative Timesteps: 501,707,322

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 501707322...
Checkpoint 501707322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,557.92984
Policy Entropy: 3.35037
Value Function Loss: 0.00339

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.53609
Value Function Update Magnitude: 0.59196

Collected Steps per Second: 22,316.00205
Overall Steps per Second: 10,646.54365

Timestep Collection Time: 2.24180
Timestep Consumption Time: 2.45719
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.69899

Cumulative Model Updates: 60,150
Cumulative Timesteps: 501,757,350

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 971.58296
Policy Entropy: 3.35499
Value Function Loss: 0.00346

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.53385
Value Function Update Magnitude: 0.58583

Collected Steps per Second: 22,746.38207
Overall Steps per Second: 10,777.78961

Timestep Collection Time: 2.19859
Timestep Consumption Time: 2.44151
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.64010

Cumulative Model Updates: 60,156
Cumulative Timesteps: 501,807,360

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 501807360...
Checkpoint 501807360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.95028
Policy Entropy: 3.36145
Value Function Loss: 0.00328

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08027
Policy Update Magnitude: 0.53403
Value Function Update Magnitude: 0.58898

Collected Steps per Second: 22,728.04639
Overall Steps per Second: 10,766.45638

Timestep Collection Time: 2.20028
Timestep Consumption Time: 2.44452
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.64480

Cumulative Model Updates: 60,162
Cumulative Timesteps: 501,857,368

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,041.74690
Policy Entropy: 3.36949
Value Function Loss: 0.00323

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09423
Policy Update Magnitude: 0.52630
Value Function Update Magnitude: 0.57923

Collected Steps per Second: 22,635.56750
Overall Steps per Second: 10,781.83574

Timestep Collection Time: 2.20918
Timestep Consumption Time: 2.42881
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.63799

Cumulative Model Updates: 60,168
Cumulative Timesteps: 501,907,374

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 501907374...
Checkpoint 501907374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.25173
Policy Entropy: 3.37182
Value Function Loss: 0.00325

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09714
Policy Update Magnitude: 0.52043
Value Function Update Magnitude: 0.56478

Collected Steps per Second: 21,983.76859
Overall Steps per Second: 10,667.89497

Timestep Collection Time: 2.27559
Timestep Consumption Time: 2.41381
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.68940

Cumulative Model Updates: 60,174
Cumulative Timesteps: 501,957,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,006.78951
Policy Entropy: 3.37575
Value Function Loss: 0.00345

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10722
Policy Update Magnitude: 0.52693
Value Function Update Magnitude: 0.56764

Collected Steps per Second: 22,327.74858
Overall Steps per Second: 10,534.85026

Timestep Collection Time: 2.24026
Timestep Consumption Time: 2.50779
PPO Batch Consumption Time: 0.29721
Total Iteration Time: 4.74805

Cumulative Model Updates: 60,180
Cumulative Timesteps: 502,007,420

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 502007420...
Checkpoint 502007420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.03817
Policy Entropy: 3.37536
Value Function Loss: 0.00342

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11228
Policy Update Magnitude: 0.53490
Value Function Update Magnitude: 0.57533

Collected Steps per Second: 22,700.26167
Overall Steps per Second: 10,626.67867

Timestep Collection Time: 2.20297
Timestep Consumption Time: 2.50292
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.70589

Cumulative Model Updates: 60,186
Cumulative Timesteps: 502,057,428

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.61256
Policy Entropy: 3.35775
Value Function Loss: 0.00338

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.10454
Policy Update Magnitude: 0.53967
Value Function Update Magnitude: 0.59072

Collected Steps per Second: 22,466.42690
Overall Steps per Second: 10,513.03082

Timestep Collection Time: 2.22661
Timestep Consumption Time: 2.53167
PPO Batch Consumption Time: 0.29640
Total Iteration Time: 4.75829

Cumulative Model Updates: 60,192
Cumulative Timesteps: 502,107,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 502107452...
Checkpoint 502107452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,779.96599
Policy Entropy: 3.35815
Value Function Loss: 0.00338

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10950
Policy Update Magnitude: 0.53488
Value Function Update Magnitude: 0.60158

Collected Steps per Second: 22,234.62667
Overall Steps per Second: 10,600.77720

Timestep Collection Time: 2.24901
Timestep Consumption Time: 2.46819
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.71720

Cumulative Model Updates: 60,198
Cumulative Timesteps: 502,157,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531.35186
Policy Entropy: 3.34793
Value Function Loss: 0.00338

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09027
Policy Update Magnitude: 0.53277
Value Function Update Magnitude: 0.60719

Collected Steps per Second: 22,815.34640
Overall Steps per Second: 10,639.26257

Timestep Collection Time: 2.19168
Timestep Consumption Time: 2.50827
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.69995

Cumulative Model Updates: 60,204
Cumulative Timesteps: 502,207,462

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 502207462...
Checkpoint 502207462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.48504
Policy Entropy: 3.35485
Value Function Loss: 0.00340

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08649
Policy Update Magnitude: 0.52801
Value Function Update Magnitude: 0.62605

Collected Steps per Second: 22,911.99948
Overall Steps per Second: 10,820.88337

Timestep Collection Time: 2.18244
Timestep Consumption Time: 2.43863
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.62106

Cumulative Model Updates: 60,210
Cumulative Timesteps: 502,257,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 899.82051
Policy Entropy: 3.34640
Value Function Loss: 0.00335

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07871
Policy Update Magnitude: 0.54332
Value Function Update Magnitude: 0.62393

Collected Steps per Second: 22,924.06693
Overall Steps per Second: 10,750.18175

Timestep Collection Time: 2.18120
Timestep Consumption Time: 2.47007
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.65127

Cumulative Model Updates: 60,216
Cumulative Timesteps: 502,307,468

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 502307468...
Checkpoint 502307468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 957.51173
Policy Entropy: 3.34854
Value Function Loss: 0.00343

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08137
Policy Update Magnitude: 0.55880
Value Function Update Magnitude: 0.62237

Collected Steps per Second: 22,343.97738
Overall Steps per Second: 10,649.71228

Timestep Collection Time: 2.23899
Timestep Consumption Time: 2.45860
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.69759

Cumulative Model Updates: 60,222
Cumulative Timesteps: 502,357,496

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,494.28043
Policy Entropy: 3.34405
Value Function Loss: 0.00356

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09502
Policy Update Magnitude: 0.55428
Value Function Update Magnitude: 0.62936

Collected Steps per Second: 22,719.73249
Overall Steps per Second: 10,669.07525

Timestep Collection Time: 2.20152
Timestep Consumption Time: 2.48661
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.68813

Cumulative Model Updates: 60,228
Cumulative Timesteps: 502,407,514

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 502407514...
Checkpoint 502407514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.25073
Policy Entropy: 3.33830
Value Function Loss: 0.00379

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08350
Policy Update Magnitude: 0.55714
Value Function Update Magnitude: 0.65876

Collected Steps per Second: 22,736.54044
Overall Steps per Second: 10,671.55111

Timestep Collection Time: 2.19972
Timestep Consumption Time: 2.48695
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.68667

Cumulative Model Updates: 60,234
Cumulative Timesteps: 502,457,528

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.80443
Policy Entropy: 3.33367
Value Function Loss: 0.00375

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08715
Policy Update Magnitude: 0.56370
Value Function Update Magnitude: 0.66556

Collected Steps per Second: 22,798.80630
Overall Steps per Second: 10,810.65257

Timestep Collection Time: 2.19319
Timestep Consumption Time: 2.43207
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.62525

Cumulative Model Updates: 60,240
Cumulative Timesteps: 502,507,530

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 502507530...
Checkpoint 502507530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.15863
Policy Entropy: 3.33476
Value Function Loss: 0.00363

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.56399
Value Function Update Magnitude: 0.65545

Collected Steps per Second: 22,010.59624
Overall Steps per Second: 10,623.53052

Timestep Collection Time: 2.27254
Timestep Consumption Time: 2.43587
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.70842

Cumulative Model Updates: 60,246
Cumulative Timesteps: 502,557,550

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.44560
Policy Entropy: 3.33309
Value Function Loss: 0.00341

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08417
Policy Update Magnitude: 0.55346
Value Function Update Magnitude: 0.63275

Collected Steps per Second: 22,588.02997
Overall Steps per Second: 10,595.63889

Timestep Collection Time: 2.21400
Timestep Consumption Time: 2.50586
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.71987

Cumulative Model Updates: 60,252
Cumulative Timesteps: 502,607,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 502607560...
Checkpoint 502607560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,601.13812
Policy Entropy: 3.32917
Value Function Loss: 0.00363

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08950
Policy Update Magnitude: 0.54905
Value Function Update Magnitude: 0.61392

Collected Steps per Second: 22,324.43440
Overall Steps per Second: 10,568.01450

Timestep Collection Time: 2.23970
Timestep Consumption Time: 2.49156
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.73126

Cumulative Model Updates: 60,258
Cumulative Timesteps: 502,657,560

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.17152
Policy Entropy: 3.33107
Value Function Loss: 0.00370

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07569
Policy Update Magnitude: 0.55946
Value Function Update Magnitude: 0.64521

Collected Steps per Second: 22,320.44865
Overall Steps per Second: 10,546.49900

Timestep Collection Time: 2.24144
Timestep Consumption Time: 2.50231
PPO Batch Consumption Time: 0.29547
Total Iteration Time: 4.74375

Cumulative Model Updates: 60,264
Cumulative Timesteps: 502,707,590

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 502707590...
Checkpoint 502707590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.43478
Policy Entropy: 3.33545
Value Function Loss: 0.00366

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.07929
Policy Update Magnitude: 0.56581
Value Function Update Magnitude: 0.65917

Collected Steps per Second: 22,466.97585
Overall Steps per Second: 10,560.16051

Timestep Collection Time: 2.22567
Timestep Consumption Time: 2.50949
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.73516

Cumulative Model Updates: 60,270
Cumulative Timesteps: 502,757,594

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,693.64425
Policy Entropy: 3.33894
Value Function Loss: 0.00358

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07845
Policy Update Magnitude: 0.56433
Value Function Update Magnitude: 0.65784

Collected Steps per Second: 22,868.59224
Overall Steps per Second: 10,823.58234

Timestep Collection Time: 2.18702
Timestep Consumption Time: 2.43382
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.62084

Cumulative Model Updates: 60,276
Cumulative Timesteps: 502,807,608

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 502807608...
Checkpoint 502807608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 739.67645
Policy Entropy: 3.34366
Value Function Loss: 0.00332

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07660
Policy Update Magnitude: 0.56046
Value Function Update Magnitude: 0.62986

Collected Steps per Second: 22,810.40690
Overall Steps per Second: 10,674.97438

Timestep Collection Time: 2.19216
Timestep Consumption Time: 2.49207
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.68423

Cumulative Model Updates: 60,282
Cumulative Timesteps: 502,857,612

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,733.87581
Policy Entropy: 3.33605
Value Function Loss: 0.00344

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.54811
Value Function Update Magnitude: 0.62640

Collected Steps per Second: 22,680.77163
Overall Steps per Second: 10,647.65629

Timestep Collection Time: 2.20557
Timestep Consumption Time: 2.49255
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.69812

Cumulative Model Updates: 60,288
Cumulative Timesteps: 502,907,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 502907636...
Checkpoint 502907636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 844.19167
Policy Entropy: 3.32795
Value Function Loss: 0.00340

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09248
Policy Update Magnitude: 0.54586
Value Function Update Magnitude: 0.64130

Collected Steps per Second: 22,902.96423
Overall Steps per Second: 10,864.24710

Timestep Collection Time: 2.18339
Timestep Consumption Time: 2.41942
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.60280

Cumulative Model Updates: 60,294
Cumulative Timesteps: 502,957,642

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499.34076
Policy Entropy: 3.32801
Value Function Loss: 0.00362

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11447
Policy Update Magnitude: 0.55898
Value Function Update Magnitude: 0.66133

Collected Steps per Second: 23,140.40014
Overall Steps per Second: 10,885.82350

Timestep Collection Time: 2.16185
Timestep Consumption Time: 2.43367
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.59552

Cumulative Model Updates: 60,300
Cumulative Timesteps: 503,007,668

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 503007668...
Checkpoint 503007668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 847.95973
Policy Entropy: 3.32111
Value Function Loss: 0.00370

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10806
Policy Update Magnitude: 0.56017
Value Function Update Magnitude: 0.66901

Collected Steps per Second: 22,460.17220
Overall Steps per Second: 10,735.28847

Timestep Collection Time: 2.22634
Timestep Consumption Time: 2.43157
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.65791

Cumulative Model Updates: 60,306
Cumulative Timesteps: 503,057,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,740.79738
Policy Entropy: 3.32188
Value Function Loss: 0.00361

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10242
Policy Update Magnitude: 0.57032
Value Function Update Magnitude: 0.67855

Collected Steps per Second: 22,368.38963
Overall Steps per Second: 10,540.09895

Timestep Collection Time: 2.23637
Timestep Consumption Time: 2.50970
PPO Batch Consumption Time: 0.29743
Total Iteration Time: 4.74607

Cumulative Model Updates: 60,312
Cumulative Timesteps: 503,107,696

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 503107696...
Checkpoint 503107696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.89423
Policy Entropy: 3.33287
Value Function Loss: 0.00350

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10451
Policy Update Magnitude: 0.56992
Value Function Update Magnitude: 0.66329

Collected Steps per Second: 22,486.23614
Overall Steps per Second: 10,577.28552

Timestep Collection Time: 2.22554
Timestep Consumption Time: 2.50573
PPO Batch Consumption Time: 0.29778
Total Iteration Time: 4.73127

Cumulative Model Updates: 60,318
Cumulative Timesteps: 503,157,740

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.76874
Policy Entropy: 3.33409
Value Function Loss: 0.00347

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09315
Policy Update Magnitude: 0.55457
Value Function Update Magnitude: 0.64189

Collected Steps per Second: 22,075.57753
Overall Steps per Second: 10,460.28846

Timestep Collection Time: 2.26522
Timestep Consumption Time: 2.51534
PPO Batch Consumption Time: 0.29716
Total Iteration Time: 4.78056

Cumulative Model Updates: 60,324
Cumulative Timesteps: 503,207,746

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 503207746...
Checkpoint 503207746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.10806
Policy Entropy: 3.33608
Value Function Loss: 0.00342

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08034
Policy Update Magnitude: 0.54654
Value Function Update Magnitude: 0.63891

Collected Steps per Second: 22,494.16884
Overall Steps per Second: 10,594.82925

Timestep Collection Time: 2.22289
Timestep Consumption Time: 2.49658
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.71947

Cumulative Model Updates: 60,330
Cumulative Timesteps: 503,257,748

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678.97891
Policy Entropy: 3.33651
Value Function Loss: 0.00352

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09124
Policy Update Magnitude: 0.54547
Value Function Update Magnitude: 0.67128

Collected Steps per Second: 22,315.22015
Overall Steps per Second: 10,547.94967

Timestep Collection Time: 2.24206
Timestep Consumption Time: 2.50123
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.74329

Cumulative Model Updates: 60,336
Cumulative Timesteps: 503,307,780

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 503307780...
Checkpoint 503307780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 908.87892
Policy Entropy: 3.33724
Value Function Loss: 0.00370

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07183
Policy Update Magnitude: 0.55633
Value Function Update Magnitude: 0.68707

Collected Steps per Second: 22,394.56820
Overall Steps per Second: 10,592.29146

Timestep Collection Time: 2.23313
Timestep Consumption Time: 2.48823
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.72136

Cumulative Model Updates: 60,342
Cumulative Timesteps: 503,357,790

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.50858
Policy Entropy: 3.33374
Value Function Loss: 0.00379

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.06979
Policy Update Magnitude: 0.56885
Value Function Update Magnitude: 0.68786

Collected Steps per Second: 22,592.88301
Overall Steps per Second: 10,730.78012

Timestep Collection Time: 2.21344
Timestep Consumption Time: 2.44680
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.66024

Cumulative Model Updates: 60,348
Cumulative Timesteps: 503,407,798

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 503407798...
Checkpoint 503407798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.16366
Policy Entropy: 3.34945
Value Function Loss: 0.00367

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07321
Policy Update Magnitude: 0.57077
Value Function Update Magnitude: 0.67896

Collected Steps per Second: 22,710.94981
Overall Steps per Second: 10,812.91264

Timestep Collection Time: 2.20229
Timestep Consumption Time: 2.42330
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.62558

Cumulative Model Updates: 60,354
Cumulative Timesteps: 503,457,814

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.66167
Policy Entropy: 3.32988
Value Function Loss: 0.00370

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08288
Policy Update Magnitude: 0.56387
Value Function Update Magnitude: 0.66563

Collected Steps per Second: 22,782.29896
Overall Steps per Second: 10,799.63503

Timestep Collection Time: 2.19556
Timestep Consumption Time: 2.43607
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.63164

Cumulative Model Updates: 60,360
Cumulative Timesteps: 503,507,834

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 503507834...
Checkpoint 503507834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 978.75283
Policy Entropy: 3.35058
Value Function Loss: 0.00358

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07812
Policy Update Magnitude: 0.56263
Value Function Update Magnitude: 0.65788

Collected Steps per Second: 22,680.75927
Overall Steps per Second: 10,757.37985

Timestep Collection Time: 2.20513
Timestep Consumption Time: 2.44414
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.64927

Cumulative Model Updates: 60,366
Cumulative Timesteps: 503,557,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.24076
Policy Entropy: 3.32951
Value Function Loss: 0.00355

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08437
Policy Update Magnitude: 0.55910
Value Function Update Magnitude: 0.65026

Collected Steps per Second: 21,914.31203
Overall Steps per Second: 10,422.34547

Timestep Collection Time: 2.28225
Timestep Consumption Time: 2.51648
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.79873

Cumulative Model Updates: 60,372
Cumulative Timesteps: 503,607,862

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 503607862...
Checkpoint 503607862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,487.30423
Policy Entropy: 3.34558
Value Function Loss: 0.00347

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.55222
Value Function Update Magnitude: 0.67010

Collected Steps per Second: 22,306.68178
Overall Steps per Second: 10,666.88867

Timestep Collection Time: 2.24247
Timestep Consumption Time: 2.44700
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.68946

Cumulative Model Updates: 60,378
Cumulative Timesteps: 503,657,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 907.62355
Policy Entropy: 3.34220
Value Function Loss: 0.00346

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.55816
Value Function Update Magnitude: 0.67567

Collected Steps per Second: 22,110.67008
Overall Steps per Second: 10,493.70130

Timestep Collection Time: 2.26162
Timestep Consumption Time: 2.50371
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 4.76533

Cumulative Model Updates: 60,384
Cumulative Timesteps: 503,707,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 503707890...
Checkpoint 503707890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,613.56005
Policy Entropy: 3.32860
Value Function Loss: 0.00361

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08696
Policy Update Magnitude: 0.56091
Value Function Update Magnitude: 0.69224

Collected Steps per Second: 22,541.31308
Overall Steps per Second: 10,596.72388

Timestep Collection Time: 2.21850
Timestep Consumption Time: 2.50069
PPO Batch Consumption Time: 0.29705
Total Iteration Time: 4.71919

Cumulative Model Updates: 60,390
Cumulative Timesteps: 503,757,898

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 879.66738
Policy Entropy: 3.33655
Value Function Loss: 0.00366

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09008
Policy Update Magnitude: 0.56949
Value Function Update Magnitude: 0.69948

Collected Steps per Second: 22,829.65264
Overall Steps per Second: 10,770.92929

Timestep Collection Time: 2.19066
Timestep Consumption Time: 2.45258
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.64324

Cumulative Model Updates: 60,396
Cumulative Timesteps: 503,807,910

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 503807910...
Checkpoint 503807910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 878.18285
Policy Entropy: 3.33627
Value Function Loss: 0.00363

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11100
Policy Update Magnitude: 0.57496
Value Function Update Magnitude: 0.69693

Collected Steps per Second: 22,583.21408
Overall Steps per Second: 10,740.09802

Timestep Collection Time: 2.21457
Timestep Consumption Time: 2.44200
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.65657

Cumulative Model Updates: 60,402
Cumulative Timesteps: 503,857,922

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.76640
Policy Entropy: 3.36734
Value Function Loss: 0.00376

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.10842
Policy Update Magnitude: 0.56896
Value Function Update Magnitude: 0.68862

Collected Steps per Second: 22,361.28958
Overall Steps per Second: 10,575.20241

Timestep Collection Time: 2.23645
Timestep Consumption Time: 2.49253
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.72899

Cumulative Model Updates: 60,408
Cumulative Timesteps: 503,907,932

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 503907932...
Checkpoint 503907932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.50066
Policy Entropy: 3.36102
Value Function Loss: 0.00390

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10138
Policy Update Magnitude: 0.56370
Value Function Update Magnitude: 0.72094

Collected Steps per Second: 22,615.73953
Overall Steps per Second: 10,584.80956

Timestep Collection Time: 2.21200
Timestep Consumption Time: 2.51421
PPO Batch Consumption Time: 0.29784
Total Iteration Time: 4.72621

Cumulative Model Updates: 60,414
Cumulative Timesteps: 503,957,958

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.91576
Policy Entropy: 3.35418
Value Function Loss: 0.00370

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.56057
Value Function Update Magnitude: 0.71102

Collected Steps per Second: 22,526.02161
Overall Steps per Second: 10,628.42180

Timestep Collection Time: 2.22001
Timestep Consumption Time: 2.48511
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.70512

Cumulative Model Updates: 60,420
Cumulative Timesteps: 504,007,966

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 504007966...
Checkpoint 504007966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 853.75794
Policy Entropy: 3.35472
Value Function Loss: 0.00375

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.55195
Value Function Update Magnitude: 0.71123

Collected Steps per Second: 22,991.45452
Overall Steps per Second: 10,844.59317

Timestep Collection Time: 2.17507
Timestep Consumption Time: 2.43626
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.61133

Cumulative Model Updates: 60,426
Cumulative Timesteps: 504,057,974

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680.67273
Policy Entropy: 3.35170
Value Function Loss: 0.00372

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08131
Policy Update Magnitude: 0.55524
Value Function Update Magnitude: 0.70270

Collected Steps per Second: 21,042.43742
Overall Steps per Second: 10,245.15619

Timestep Collection Time: 2.37701
Timestep Consumption Time: 2.50511
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.88211

Cumulative Model Updates: 60,432
Cumulative Timesteps: 504,107,992

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 504107992...
Checkpoint 504107992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.88303
Policy Entropy: 3.35002
Value Function Loss: 0.00373

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09189
Policy Update Magnitude: 0.55651
Value Function Update Magnitude: 0.68804

Collected Steps per Second: 22,225.39178
Overall Steps per Second: 10,544.59102

Timestep Collection Time: 2.25058
Timestep Consumption Time: 2.49309
PPO Batch Consumption Time: 0.29596
Total Iteration Time: 4.74366

Cumulative Model Updates: 60,438
Cumulative Timesteps: 504,158,012

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.59126
Policy Entropy: 3.34334
Value Function Loss: 0.00358

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08299
Policy Update Magnitude: 0.54945
Value Function Update Magnitude: 0.67445

Collected Steps per Second: 22,408.08278
Overall Steps per Second: 10,598.77148

Timestep Collection Time: 2.23250
Timestep Consumption Time: 2.48748
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.71998

Cumulative Model Updates: 60,444
Cumulative Timesteps: 504,208,038

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 504208038...
Checkpoint 504208038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529.98188
Policy Entropy: 3.35664
Value Function Loss: 0.00348

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.06930
Policy Update Magnitude: 0.54946
Value Function Update Magnitude: 0.65659

Collected Steps per Second: 22,321.48435
Overall Steps per Second: 10,537.18339

Timestep Collection Time: 2.24107
Timestep Consumption Time: 2.50631
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.74738

Cumulative Model Updates: 60,450
Cumulative Timesteps: 504,258,062

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.67425
Policy Entropy: 3.36462
Value Function Loss: 0.00343

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07626
Policy Update Magnitude: 0.54331
Value Function Update Magnitude: 0.64396

Collected Steps per Second: 22,556.51238
Overall Steps per Second: 10,686.68797

Timestep Collection Time: 2.21728
Timestep Consumption Time: 2.46275
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.68003

Cumulative Model Updates: 60,456
Cumulative Timesteps: 504,308,076

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 504308076...
Checkpoint 504308076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220.14428
Policy Entropy: 3.34864
Value Function Loss: 0.00349

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08105
Policy Update Magnitude: 0.53911
Value Function Update Magnitude: 0.63720

Collected Steps per Second: 22,772.31338
Overall Steps per Second: 10,702.66560

Timestep Collection Time: 2.19670
Timestep Consumption Time: 2.47727
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.67398

Cumulative Model Updates: 60,462
Cumulative Timesteps: 504,358,100

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.24911
Policy Entropy: 3.35177
Value Function Loss: 0.00350

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08032
Policy Update Magnitude: 0.53596
Value Function Update Magnitude: 0.65584

Collected Steps per Second: 22,643.41911
Overall Steps per Second: 10,625.19516

Timestep Collection Time: 2.20921
Timestep Consumption Time: 2.49885
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.70805

Cumulative Model Updates: 60,468
Cumulative Timesteps: 504,408,124

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 504408124...
Checkpoint 504408124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360.05725
Policy Entropy: 3.33946
Value Function Loss: 0.00351

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10081
Policy Update Magnitude: 0.54035
Value Function Update Magnitude: 0.67076

Collected Steps per Second: 22,915.05076
Overall Steps per Second: 10,746.86802

Timestep Collection Time: 2.18337
Timestep Consumption Time: 2.47213
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.65550

Cumulative Model Updates: 60,474
Cumulative Timesteps: 504,458,156

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,840.29027
Policy Entropy: 3.34304
Value Function Loss: 0.00332

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09007
Policy Update Magnitude: 0.52951
Value Function Update Magnitude: 0.66419

Collected Steps per Second: 22,769.00197
Overall Steps per Second: 10,706.09867

Timestep Collection Time: 2.19685
Timestep Consumption Time: 2.47526
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.67210

Cumulative Model Updates: 60,480
Cumulative Timesteps: 504,508,176

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 504508176...
Checkpoint 504508176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 875.16451
Policy Entropy: 3.33331
Value Function Loss: 0.00341

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08788
Policy Update Magnitude: 0.53660
Value Function Update Magnitude: 0.66654

Collected Steps per Second: 22,992.06685
Overall Steps per Second: 10,683.06337

Timestep Collection Time: 2.17484
Timestep Consumption Time: 2.50584
PPO Batch Consumption Time: 0.29825
Total Iteration Time: 4.68068

Cumulative Model Updates: 60,486
Cumulative Timesteps: 504,558,180

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.91731
Policy Entropy: 3.33909
Value Function Loss: 0.00353

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07665
Policy Update Magnitude: 0.55942
Value Function Update Magnitude: 0.67302

Collected Steps per Second: 22,423.98066
Overall Steps per Second: 10,755.50983

Timestep Collection Time: 2.23029
Timestep Consumption Time: 2.41960
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.64990

Cumulative Model Updates: 60,492
Cumulative Timesteps: 504,608,192

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 504608192...
Checkpoint 504608192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.54087
Policy Entropy: 3.36119
Value Function Loss: 0.00354

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08815
Policy Update Magnitude: 0.56461
Value Function Update Magnitude: 0.68949

Collected Steps per Second: 22,249.45217
Overall Steps per Second: 10,660.24342

Timestep Collection Time: 2.24850
Timestep Consumption Time: 2.44445
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.69295

Cumulative Model Updates: 60,498
Cumulative Timesteps: 504,658,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.63146
Policy Entropy: 3.36312
Value Function Loss: 0.00346

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08289
Policy Update Magnitude: 0.55715
Value Function Update Magnitude: 0.67993

Collected Steps per Second: 22,559.47535
Overall Steps per Second: 10,602.52805

Timestep Collection Time: 2.21734
Timestep Consumption Time: 2.50059
PPO Batch Consumption Time: 0.29647
Total Iteration Time: 4.71793

Cumulative Model Updates: 60,504
Cumulative Timesteps: 504,708,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 504708242...
Checkpoint 504708242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 908.47832
Policy Entropy: 3.36619
Value Function Loss: 0.00332

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08668
Policy Update Magnitude: 0.54663
Value Function Update Magnitude: 0.64624

Collected Steps per Second: 22,279.80214
Overall Steps per Second: 10,609.86254

Timestep Collection Time: 2.24419
Timestep Consumption Time: 2.46841
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.71260

Cumulative Model Updates: 60,510
Cumulative Timesteps: 504,758,242

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.79268
Policy Entropy: 3.35063
Value Function Loss: 0.00339

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08068
Policy Update Magnitude: 0.53293
Value Function Update Magnitude: 0.63961

Collected Steps per Second: 22,779.08479
Overall Steps per Second: 10,764.07242

Timestep Collection Time: 2.19526
Timestep Consumption Time: 2.45038
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.64564

Cumulative Model Updates: 60,516
Cumulative Timesteps: 504,808,248

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 504808248...
Checkpoint 504808248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 857.39836
Policy Entropy: 3.34784
Value Function Loss: 0.00344

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08086
Policy Update Magnitude: 0.52953
Value Function Update Magnitude: 0.64773

Collected Steps per Second: 22,786.25472
Overall Steps per Second: 10,772.65150

Timestep Collection Time: 2.19501
Timestep Consumption Time: 2.44786
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.64287

Cumulative Model Updates: 60,522
Cumulative Timesteps: 504,858,264

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.36665
Policy Entropy: 3.35361
Value Function Loss: 0.00349

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09451
Policy Update Magnitude: 0.53381
Value Function Update Magnitude: 0.63590

Collected Steps per Second: 22,544.62684
Overall Steps per Second: 10,548.11682

Timestep Collection Time: 2.21880
Timestep Consumption Time: 2.52347
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.74227

Cumulative Model Updates: 60,528
Cumulative Timesteps: 504,908,286

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 504908286...
Checkpoint 504908286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.69854
Policy Entropy: 3.35933
Value Function Loss: 0.00364

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.54066
Value Function Update Magnitude: 0.65645

Collected Steps per Second: 22,701.61774
Overall Steps per Second: 10,575.82058

Timestep Collection Time: 2.20390
Timestep Consumption Time: 2.52690
PPO Batch Consumption Time: 0.29831
Total Iteration Time: 4.73079

Cumulative Model Updates: 60,534
Cumulative Timesteps: 504,958,318

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 985.34127
Policy Entropy: 3.35177
Value Function Loss: 0.00368

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08329
Policy Update Magnitude: 0.54796
Value Function Update Magnitude: 0.67202

Collected Steps per Second: 22,746.18391
Overall Steps per Second: 10,808.35405

Timestep Collection Time: 2.19843
Timestep Consumption Time: 2.42817
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.62661

Cumulative Model Updates: 60,540
Cumulative Timesteps: 505,008,324

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 505008324...
Checkpoint 505008324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664.56335
Policy Entropy: 3.35787
Value Function Loss: 0.00353

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08074
Policy Update Magnitude: 0.55142
Value Function Update Magnitude: 0.68824

Collected Steps per Second: 22,901.51957
Overall Steps per Second: 10,658.43799

Timestep Collection Time: 2.18344
Timestep Consumption Time: 2.50806
PPO Batch Consumption Time: 0.29763
Total Iteration Time: 4.69149

Cumulative Model Updates: 60,546
Cumulative Timesteps: 505,058,328

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.88176
Policy Entropy: 3.36027
Value Function Loss: 0.00332

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08002
Policy Update Magnitude: 0.54648
Value Function Update Magnitude: 0.66719

Collected Steps per Second: 21,896.14944
Overall Steps per Second: 10,504.45434

Timestep Collection Time: 2.28369
Timestep Consumption Time: 2.47658
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.76027

Cumulative Model Updates: 60,552
Cumulative Timesteps: 505,108,332

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 505108332...
Checkpoint 505108332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.72409
Policy Entropy: 3.34380
Value Function Loss: 0.00352

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08862
Policy Update Magnitude: 0.53963
Value Function Update Magnitude: 0.68133

Collected Steps per Second: 22,314.13971
Overall Steps per Second: 10,609.17912

Timestep Collection Time: 2.24199
Timestep Consumption Time: 2.47355
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.71554

Cumulative Model Updates: 60,558
Cumulative Timesteps: 505,158,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 773.58703
Policy Entropy: 3.32967
Value Function Loss: 0.00365

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07642
Policy Update Magnitude: 0.55175
Value Function Update Magnitude: 0.72133

Collected Steps per Second: 22,174.74356
Overall Steps per Second: 10,511.27288

Timestep Collection Time: 2.25491
Timestep Consumption Time: 2.50208
PPO Batch Consumption Time: 0.29665
Total Iteration Time: 4.75699

Cumulative Model Updates: 60,564
Cumulative Timesteps: 505,208,362

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 505208362...
Checkpoint 505208362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 824.29514
Policy Entropy: 3.32105
Value Function Loss: 0.00349

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.55801
Value Function Update Magnitude: 0.72567

Collected Steps per Second: 22,349.48379
Overall Steps per Second: 10,596.32536

Timestep Collection Time: 2.23817
Timestep Consumption Time: 2.48252
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.72069

Cumulative Model Updates: 60,570
Cumulative Timesteps: 505,258,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.44561
Policy Entropy: 3.33443
Value Function Loss: 0.00346

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08174
Policy Update Magnitude: 0.54972
Value Function Update Magnitude: 0.68336

Collected Steps per Second: 22,449.42829
Overall Steps per Second: 10,498.85498

Timestep Collection Time: 2.22732
Timestep Consumption Time: 2.53530
PPO Batch Consumption Time: 0.29641
Total Iteration Time: 4.76261

Cumulative Model Updates: 60,576
Cumulative Timesteps: 505,308,386

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 505308386...
Checkpoint 505308386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 746.44901
Policy Entropy: 3.34661
Value Function Loss: 0.00373

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07636
Policy Update Magnitude: 0.55698
Value Function Update Magnitude: 0.66113

Collected Steps per Second: 22,751.41066
Overall Steps per Second: 10,675.08689

Timestep Collection Time: 2.19863
Timestep Consumption Time: 2.48723
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.68586

Cumulative Model Updates: 60,582
Cumulative Timesteps: 505,358,408

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.41137
Policy Entropy: 3.33831
Value Function Loss: 0.00380

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09442
Policy Update Magnitude: 0.56596
Value Function Update Magnitude: 0.67064

Collected Steps per Second: 22,637.78244
Overall Steps per Second: 10,754.68168

Timestep Collection Time: 2.20887
Timestep Consumption Time: 2.44064
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.64951

Cumulative Model Updates: 60,588
Cumulative Timesteps: 505,408,412

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 505408412...
Checkpoint 505408412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.64909
Policy Entropy: 3.34101
Value Function Loss: 0.00367

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08210
Policy Update Magnitude: 0.55982
Value Function Update Magnitude: 0.65721

Collected Steps per Second: 22,957.56336
Overall Steps per Second: 10,673.52591

Timestep Collection Time: 2.17802
Timestep Consumption Time: 2.50666
PPO Batch Consumption Time: 0.29651
Total Iteration Time: 4.68467

Cumulative Model Updates: 60,594
Cumulative Timesteps: 505,458,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,557.68356
Policy Entropy: 3.32309
Value Function Loss: 0.00365

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09807
Policy Update Magnitude: 0.54364
Value Function Update Magnitude: 0.64482

Collected Steps per Second: 21,830.64641
Overall Steps per Second: 10,439.47981

Timestep Collection Time: 2.29164
Timestep Consumption Time: 2.50055
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.79219

Cumulative Model Updates: 60,600
Cumulative Timesteps: 505,508,442

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 505508442...
Checkpoint 505508442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.22618
Policy Entropy: 3.33089
Value Function Loss: 0.00356

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11826
Policy Update Magnitude: 0.53330
Value Function Update Magnitude: 0.64386

Collected Steps per Second: 22,303.86638
Overall Steps per Second: 10,606.93107

Timestep Collection Time: 2.24203
Timestep Consumption Time: 2.47243
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.71446

Cumulative Model Updates: 60,606
Cumulative Timesteps: 505,558,448

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.86743
Policy Entropy: 3.34042
Value Function Loss: 0.00362

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11112
Policy Update Magnitude: 0.53850
Value Function Update Magnitude: 0.65303

Collected Steps per Second: 22,127.25093
Overall Steps per Second: 10,535.56882

Timestep Collection Time: 2.26174
Timestep Consumption Time: 2.48846
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.75019

Cumulative Model Updates: 60,612
Cumulative Timesteps: 505,608,494

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 505608494...
Checkpoint 505608494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.93484
Policy Entropy: 3.34491
Value Function Loss: 0.00357

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10472
Policy Update Magnitude: 0.55050
Value Function Update Magnitude: 0.66636

Collected Steps per Second: 22,328.24267
Overall Steps per Second: 10,621.03034

Timestep Collection Time: 2.23932
Timestep Consumption Time: 2.46832
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.70764

Cumulative Model Updates: 60,618
Cumulative Timesteps: 505,658,494

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.87112
Policy Entropy: 3.34254
Value Function Loss: 0.00366

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11487
Policy Update Magnitude: 0.55624
Value Function Update Magnitude: 0.66883

Collected Steps per Second: 22,774.73544
Overall Steps per Second: 10,655.63941

Timestep Collection Time: 2.19656
Timestep Consumption Time: 2.49823
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.69479

Cumulative Model Updates: 60,624
Cumulative Timesteps: 505,708,520

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 505708520...
Checkpoint 505708520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,508.67260
Policy Entropy: 3.34748
Value Function Loss: 0.00370

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.10919
Policy Update Magnitude: 0.55816
Value Function Update Magnitude: 0.66844

Collected Steps per Second: 22,884.75567
Overall Steps per Second: 10,805.91564

Timestep Collection Time: 2.18573
Timestep Consumption Time: 2.44321
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.62895

Cumulative Model Updates: 60,630
Cumulative Timesteps: 505,758,540

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 875.09855
Policy Entropy: 3.35338
Value Function Loss: 0.00366

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10140
Policy Update Magnitude: 0.55866
Value Function Update Magnitude: 0.64964

Collected Steps per Second: 22,904.33782
Overall Steps per Second: 10,710.19791

Timestep Collection Time: 2.18343
Timestep Consumption Time: 2.48595
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.66938

Cumulative Model Updates: 60,636
Cumulative Timesteps: 505,808,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 505808550...
Checkpoint 505808550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,423.51719
Policy Entropy: 3.35092
Value Function Loss: 0.00372

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09708
Policy Update Magnitude: 0.56074
Value Function Update Magnitude: 0.63979

Collected Steps per Second: 22,826.27596
Overall Steps per Second: 10,860.08126

Timestep Collection Time: 2.19116
Timestep Consumption Time: 2.41433
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.60549

Cumulative Model Updates: 60,642
Cumulative Timesteps: 505,858,566

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685.06891
Policy Entropy: 3.35493
Value Function Loss: 0.00348

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09708
Policy Update Magnitude: 0.55286
Value Function Update Magnitude: 0.63733

Collected Steps per Second: 22,629.53679
Overall Steps per Second: 10,528.81611

Timestep Collection Time: 2.20950
Timestep Consumption Time: 2.53937
PPO Batch Consumption Time: 0.29739
Total Iteration Time: 4.74887

Cumulative Model Updates: 60,648
Cumulative Timesteps: 505,908,566

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 505908566...
Checkpoint 505908566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.03026
Policy Entropy: 3.35139
Value Function Loss: 0.00340

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08372
Policy Update Magnitude: 0.54708
Value Function Update Magnitude: 0.62860

Collected Steps per Second: 22,456.35736
Overall Steps per Second: 10,636.26399

Timestep Collection Time: 2.22743
Timestep Consumption Time: 2.47535
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.70278

Cumulative Model Updates: 60,654
Cumulative Timesteps: 505,958,586

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.38245
Policy Entropy: 3.35879
Value Function Loss: 0.00321

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08056
Policy Update Magnitude: 0.53560
Value Function Update Magnitude: 0.62994

Collected Steps per Second: 21,822.20566
Overall Steps per Second: 10,470.35784

Timestep Collection Time: 2.29198
Timestep Consumption Time: 2.48494
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.77691

Cumulative Model Updates: 60,660
Cumulative Timesteps: 506,008,602

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 506008602...
Checkpoint 506008602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.21784
Policy Entropy: 3.34810
Value Function Loss: 0.00334

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07647
Policy Update Magnitude: 0.53118
Value Function Update Magnitude: 0.62398

Collected Steps per Second: 22,221.00673
Overall Steps per Second: 10,639.01937

Timestep Collection Time: 2.25057
Timestep Consumption Time: 2.45005
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.70062

Cumulative Model Updates: 60,666
Cumulative Timesteps: 506,058,612

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 968.89883
Policy Entropy: 3.33508
Value Function Loss: 0.00339

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07834
Policy Update Magnitude: 0.53362
Value Function Update Magnitude: 0.62176

Collected Steps per Second: 22,378.66350
Overall Steps per Second: 10,477.15433

Timestep Collection Time: 2.23534
Timestep Consumption Time: 2.53924
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.77458

Cumulative Model Updates: 60,672
Cumulative Timesteps: 506,108,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 506108636...
Checkpoint 506108636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 953.06373
Policy Entropy: 3.34012
Value Function Loss: 0.00341

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.53293
Value Function Update Magnitude: 0.62641

Collected Steps per Second: 22,315.43301
Overall Steps per Second: 10,579.26030

Timestep Collection Time: 2.24087
Timestep Consumption Time: 2.48592
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.72680

Cumulative Model Updates: 60,678
Cumulative Timesteps: 506,158,642

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,441.31378
Policy Entropy: 3.33499
Value Function Loss: 0.00344

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09977
Policy Update Magnitude: 0.52610
Value Function Update Magnitude: 0.61487

Collected Steps per Second: 22,840.88704
Overall Steps per Second: 10,593.90982

Timestep Collection Time: 2.18984
Timestep Consumption Time: 2.53155
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.72139

Cumulative Model Updates: 60,684
Cumulative Timesteps: 506,208,660

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 506208660...
Checkpoint 506208660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,625.13140
Policy Entropy: 3.35230
Value Function Loss: 0.00345

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.52452
Value Function Update Magnitude: 0.63227

Collected Steps per Second: 22,675.91998
Overall Steps per Second: 10,632.54614

Timestep Collection Time: 2.20542
Timestep Consumption Time: 2.49806
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.70348

Cumulative Model Updates: 60,690
Cumulative Timesteps: 506,258,670

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,824.96070
Policy Entropy: 3.34032
Value Function Loss: 0.00362

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09965
Policy Update Magnitude: 0.52487
Value Function Update Magnitude: 0.65381

Collected Steps per Second: 22,847.13461
Overall Steps per Second: 10,742.70756

Timestep Collection Time: 2.18951
Timestep Consumption Time: 2.46705
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.65655

Cumulative Model Updates: 60,696
Cumulative Timesteps: 506,308,694

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 506308694...
Checkpoint 506308694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605.87648
Policy Entropy: 3.36022
Value Function Loss: 0.00348

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08423
Policy Update Magnitude: 0.53498
Value Function Update Magnitude: 0.65262

Collected Steps per Second: 22,632.91545
Overall Steps per Second: 10,706.10105

Timestep Collection Time: 2.21041
Timestep Consumption Time: 2.46244
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.67285

Cumulative Model Updates: 60,702
Cumulative Timesteps: 506,358,722

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,500.98266
Policy Entropy: 3.35581
Value Function Loss: 0.00350

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08941
Policy Update Magnitude: 0.53514
Value Function Update Magnitude: 0.63897

Collected Steps per Second: 22,979.88527
Overall Steps per Second: 10,841.28878

Timestep Collection Time: 2.17712
Timestep Consumption Time: 2.43764
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.61477

Cumulative Model Updates: 60,708
Cumulative Timesteps: 506,408,752

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 506408752...
Checkpoint 506408752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.48718
Policy Entropy: 3.36083
Value Function Loss: 0.00345

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.53643
Value Function Update Magnitude: 0.63590

Collected Steps per Second: 22,603.56983
Overall Steps per Second: 10,718.81338

Timestep Collection Time: 2.21239
Timestep Consumption Time: 2.45305
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.66544

Cumulative Model Updates: 60,714
Cumulative Timesteps: 506,458,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 889.30553
Policy Entropy: 3.34169
Value Function Loss: 0.00344

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.52869
Value Function Update Magnitude: 0.63048

Collected Steps per Second: 22,413.75879
Overall Steps per Second: 10,603.22109

Timestep Collection Time: 2.23122
Timestep Consumption Time: 2.48527
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.71649

Cumulative Model Updates: 60,720
Cumulative Timesteps: 506,508,770

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 506508770...
Checkpoint 506508770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 936.41582
Policy Entropy: 3.34850
Value Function Loss: 0.00337

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.52367
Value Function Update Magnitude: 0.62008

Collected Steps per Second: 22,101.70239
Overall Steps per Second: 10,478.94121

Timestep Collection Time: 2.26299
Timestep Consumption Time: 2.51001
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.77300

Cumulative Model Updates: 60,726
Cumulative Timesteps: 506,558,786

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,594.35722
Policy Entropy: 3.33588
Value Function Loss: 0.00337

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09899
Policy Update Magnitude: 0.51753
Value Function Update Magnitude: 0.60773

Collected Steps per Second: 22,459.78325
Overall Steps per Second: 10,508.71931

Timestep Collection Time: 2.22665
Timestep Consumption Time: 2.53226
PPO Batch Consumption Time: 0.29735
Total Iteration Time: 4.75891

Cumulative Model Updates: 60,732
Cumulative Timesteps: 506,608,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 506608796...
Checkpoint 506608796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 712.99846
Policy Entropy: 3.35079
Value Function Loss: 0.00339

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08896
Policy Update Magnitude: 0.52254
Value Function Update Magnitude: 0.62889

Collected Steps per Second: 22,461.50561
Overall Steps per Second: 10,572.15411

Timestep Collection Time: 2.22656
Timestep Consumption Time: 2.50398
PPO Batch Consumption Time: 0.29670
Total Iteration Time: 4.73054

Cumulative Model Updates: 60,738
Cumulative Timesteps: 506,658,808

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 861.18689
Policy Entropy: 3.34642
Value Function Loss: 0.00343

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.53361
Value Function Update Magnitude: 0.65012

Collected Steps per Second: 22,810.88821
Overall Steps per Second: 10,642.95263

Timestep Collection Time: 2.19229
Timestep Consumption Time: 2.50641
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.69870

Cumulative Model Updates: 60,744
Cumulative Timesteps: 506,708,816

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 506708816...
Checkpoint 506708816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464.07080
Policy Entropy: 3.36159
Value Function Loss: 0.00330

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09007
Policy Update Magnitude: 0.52962
Value Function Update Magnitude: 0.64553

Collected Steps per Second: 22,933.48130
Overall Steps per Second: 10,792.28569

Timestep Collection Time: 2.18031
Timestep Consumption Time: 2.45282
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.63312

Cumulative Model Updates: 60,750
Cumulative Timesteps: 506,758,818

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.03402
Policy Entropy: 3.34772
Value Function Loss: 0.00339

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07799
Policy Update Magnitude: 0.53227
Value Function Update Magnitude: 0.61949

Collected Steps per Second: 22,500.27921
Overall Steps per Second: 10,602.94522

Timestep Collection Time: 2.22326
Timestep Consumption Time: 2.49467
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.71793

Cumulative Model Updates: 60,756
Cumulative Timesteps: 506,808,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 506808842...
Checkpoint 506808842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 985.51644
Policy Entropy: 3.35674
Value Function Loss: 0.00339

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07290
Policy Update Magnitude: 0.53798
Value Function Update Magnitude: 0.61200

Collected Steps per Second: 22,456.65742
Overall Steps per Second: 10,614.24152

Timestep Collection Time: 2.22794
Timestep Consumption Time: 2.48573
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.71367

Cumulative Model Updates: 60,762
Cumulative Timesteps: 506,858,874

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.29076
Policy Entropy: 3.34861
Value Function Loss: 0.00349

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.06812
Policy Update Magnitude: 0.54790
Value Function Update Magnitude: 0.64191

Collected Steps per Second: 23,055.88843
Overall Steps per Second: 10,873.22865

Timestep Collection Time: 2.16942
Timestep Consumption Time: 2.43068
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.60011

Cumulative Model Updates: 60,768
Cumulative Timesteps: 506,908,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 506908892...
Checkpoint 506908892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 834.89966
Policy Entropy: 3.35945
Value Function Loss: 0.00350

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07656
Policy Update Magnitude: 0.55310
Value Function Update Magnitude: 0.67563

Collected Steps per Second: 22,581.19678
Overall Steps per Second: 10,672.11102

Timestep Collection Time: 2.21459
Timestep Consumption Time: 2.47127
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.68586

Cumulative Model Updates: 60,774
Cumulative Timesteps: 506,958,900

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.19567
Policy Entropy: 3.36445
Value Function Loss: 0.00334

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08903
Policy Update Magnitude: 0.54725
Value Function Update Magnitude: 0.65786

Collected Steps per Second: 22,407.30269
Overall Steps per Second: 10,564.28569

Timestep Collection Time: 2.23159
Timestep Consumption Time: 2.50171
PPO Batch Consumption Time: 0.29650
Total Iteration Time: 4.73331

Cumulative Model Updates: 60,780
Cumulative Timesteps: 507,008,904

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 507008904...
Checkpoint 507008904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.12242
Policy Entropy: 3.37143
Value Function Loss: 0.00323

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08428
Policy Update Magnitude: 0.53840
Value Function Update Magnitude: 0.62283

Collected Steps per Second: 22,048.93926
Overall Steps per Second: 10,576.74434

Timestep Collection Time: 2.26786
Timestep Consumption Time: 2.45987
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.72773

Cumulative Model Updates: 60,786
Cumulative Timesteps: 507,058,908

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.97846
Policy Entropy: 3.35300
Value Function Loss: 0.00349

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09268
Policy Update Magnitude: 0.53993
Value Function Update Magnitude: 0.62742

Collected Steps per Second: 22,215.69884
Overall Steps per Second: 10,530.83518

Timestep Collection Time: 2.25309
Timestep Consumption Time: 2.50000
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.75309

Cumulative Model Updates: 60,792
Cumulative Timesteps: 507,108,962

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 507108962...
Checkpoint 507108962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.01429
Policy Entropy: 3.35833
Value Function Loss: 0.00337

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08964
Policy Update Magnitude: 0.54462
Value Function Update Magnitude: 0.63539

Collected Steps per Second: 22,254.40841
Overall Steps per Second: 10,542.05540

Timestep Collection Time: 2.24782
Timestep Consumption Time: 2.49736
PPO Batch Consumption Time: 0.29673
Total Iteration Time: 4.74518

Cumulative Model Updates: 60,798
Cumulative Timesteps: 507,158,986

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.12684
Policy Entropy: 3.35694
Value Function Loss: 0.00338

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08857
Policy Update Magnitude: 0.54468
Value Function Update Magnitude: 0.65002

Collected Steps per Second: 22,543.78119
Overall Steps per Second: 10,606.57853

Timestep Collection Time: 2.21817
Timestep Consumption Time: 2.49645
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.71462

Cumulative Model Updates: 60,804
Cumulative Timesteps: 507,208,992

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 507208992...
Checkpoint 507208992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.44719
Policy Entropy: 3.37870
Value Function Loss: 0.00312

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08455
Policy Update Magnitude: 0.52882
Value Function Update Magnitude: 0.61469

Collected Steps per Second: 22,341.32513
Overall Steps per Second: 10,582.57691

Timestep Collection Time: 2.23836
Timestep Consumption Time: 2.48714
PPO Batch Consumption Time: 0.29581
Total Iteration Time: 4.72550

Cumulative Model Updates: 60,810
Cumulative Timesteps: 507,259,000

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,538.30768
Policy Entropy: 3.37041
Value Function Loss: 0.00324

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09604
Policy Update Magnitude: 0.51916
Value Function Update Magnitude: 0.61605

Collected Steps per Second: 22,894.75993
Overall Steps per Second: 10,681.35884

Timestep Collection Time: 2.18399
Timestep Consumption Time: 2.49725
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.68124

Cumulative Model Updates: 60,816
Cumulative Timesteps: 507,309,002

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 507309002...
Checkpoint 507309002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.55942
Policy Entropy: 3.37025
Value Function Loss: 0.00342

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08315
Policy Update Magnitude: 0.53568
Value Function Update Magnitude: 0.65110

Collected Steps per Second: 22,790.81833
Overall Steps per Second: 10,753.02760

Timestep Collection Time: 2.19413
Timestep Consumption Time: 2.45628
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.65041

Cumulative Model Updates: 60,822
Cumulative Timesteps: 507,359,008

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783.59468
Policy Entropy: 3.35789
Value Function Loss: 0.00340

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07990
Policy Update Magnitude: 0.55770
Value Function Update Magnitude: 0.66691

Collected Steps per Second: 22,489.61677
Overall Steps per Second: 10,584.28133

Timestep Collection Time: 2.22325
Timestep Consumption Time: 2.50074
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.72399

Cumulative Model Updates: 60,828
Cumulative Timesteps: 507,409,008

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 507409008...
Checkpoint 507409008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.52121
Policy Entropy: 3.34976
Value Function Loss: 0.00343

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08148
Policy Update Magnitude: 0.55578
Value Function Update Magnitude: 0.65451

Collected Steps per Second: 22,152.63219
Overall Steps per Second: 10,517.23429

Timestep Collection Time: 2.25824
Timestep Consumption Time: 2.49833
PPO Batch Consumption Time: 0.29716
Total Iteration Time: 4.75657

Cumulative Model Updates: 60,834
Cumulative Timesteps: 507,459,034

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.04281
Policy Entropy: 3.35445
Value Function Loss: 0.00351

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07717
Policy Update Magnitude: 0.55332
Value Function Update Magnitude: 0.64307

Collected Steps per Second: 22,360.79820
Overall Steps per Second: 10,607.76478

Timestep Collection Time: 2.23704
Timestep Consumption Time: 2.47856
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.71560

Cumulative Model Updates: 60,840
Cumulative Timesteps: 507,509,056

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 507509056...
Checkpoint 507509056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.26010
Policy Entropy: 3.36518
Value Function Loss: 0.00355

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07557
Policy Update Magnitude: 0.54978
Value Function Update Magnitude: 0.63786

Collected Steps per Second: 22,363.56379
Overall Steps per Second: 10,586.89484

Timestep Collection Time: 2.23632
Timestep Consumption Time: 2.48764
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.72395

Cumulative Model Updates: 60,846
Cumulative Timesteps: 507,559,068

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 787.89319
Policy Entropy: 3.36806
Value Function Loss: 0.00354

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.54697
Value Function Update Magnitude: 0.62691

Collected Steps per Second: 23,019.03709
Overall Steps per Second: 10,820.47371

Timestep Collection Time: 2.17316
Timestep Consumption Time: 2.44993
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.62309

Cumulative Model Updates: 60,852
Cumulative Timesteps: 507,609,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 507609092...
Checkpoint 507609092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,314.86291
Policy Entropy: 3.36493
Value Function Loss: 0.00356

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08140
Policy Update Magnitude: 0.54672
Value Function Update Magnitude: 0.64060

Collected Steps per Second: 22,450.86769
Overall Steps per Second: 10,578.09498

Timestep Collection Time: 2.22771
Timestep Consumption Time: 2.50036
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.72807

Cumulative Model Updates: 60,858
Cumulative Timesteps: 507,659,106

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757.87415
Policy Entropy: 3.35754
Value Function Loss: 0.00350

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07784
Policy Update Magnitude: 0.55071
Value Function Update Magnitude: 0.63776

Collected Steps per Second: 23,020.55380
Overall Steps per Second: 10,848.27593

Timestep Collection Time: 2.17310
Timestep Consumption Time: 2.43832
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.61142

Cumulative Model Updates: 60,864
Cumulative Timesteps: 507,709,132

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 507709132...
Checkpoint 507709132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.02141
Policy Entropy: 3.36599
Value Function Loss: 0.00352

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07317
Policy Update Magnitude: 0.55109
Value Function Update Magnitude: 0.63879

Collected Steps per Second: 22,887.69553
Overall Steps per Second: 10,732.08685

Timestep Collection Time: 2.18467
Timestep Consumption Time: 2.47445
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.65911

Cumulative Model Updates: 60,870
Cumulative Timesteps: 507,759,134

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,296.22151
Policy Entropy: 3.36128
Value Function Loss: 0.00345

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08253
Policy Update Magnitude: 0.54891
Value Function Update Magnitude: 0.65489

Collected Steps per Second: 22,681.42223
Overall Steps per Second: 10,761.77597

Timestep Collection Time: 2.20445
Timestep Consumption Time: 2.44163
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.64607

Cumulative Model Updates: 60,876
Cumulative Timesteps: 507,809,134

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 507809134...
Checkpoint 507809134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.83283
Policy Entropy: 3.35329
Value Function Loss: 0.00360

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10392
Policy Update Magnitude: 0.55439
Value Function Update Magnitude: 0.66456

Collected Steps per Second: 22,227.35440
Overall Steps per Second: 10,665.81848

Timestep Collection Time: 2.25029
Timestep Consumption Time: 2.43927
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.68956

Cumulative Model Updates: 60,882
Cumulative Timesteps: 507,859,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.70338
Policy Entropy: 3.32537
Value Function Loss: 0.00362

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10750
Policy Update Magnitude: 0.55315
Value Function Update Magnitude: 0.70377

Collected Steps per Second: 22,147.74198
Overall Steps per Second: 10,576.93577

Timestep Collection Time: 2.25811
Timestep Consumption Time: 2.47029
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.72840

Cumulative Model Updates: 60,888
Cumulative Timesteps: 507,909,164

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 507909164...
Checkpoint 507909164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.05054
Policy Entropy: 3.33339
Value Function Loss: 0.00371

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.55678
Value Function Update Magnitude: 0.71724

Collected Steps per Second: 22,099.72776
Overall Steps per Second: 10,608.18613

Timestep Collection Time: 2.26320
Timestep Consumption Time: 2.45165
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.71485

Cumulative Model Updates: 60,894
Cumulative Timesteps: 507,959,180

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.41166
Policy Entropy: 3.33913
Value Function Loss: 0.00369

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08093
Policy Update Magnitude: 0.56738
Value Function Update Magnitude: 0.71057

Collected Steps per Second: 22,286.84165
Overall Steps per Second: 10,556.16123

Timestep Collection Time: 2.24473
Timestep Consumption Time: 2.49449
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.73922

Cumulative Model Updates: 60,900
Cumulative Timesteps: 508,009,208

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 508009208...
Checkpoint 508009208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.71320
Policy Entropy: 3.34055
Value Function Loss: 0.00357

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07475
Policy Update Magnitude: 0.55973
Value Function Update Magnitude: 0.69894

Collected Steps per Second: 21,962.08245
Overall Steps per Second: 10,507.66493

Timestep Collection Time: 2.27729
Timestep Consumption Time: 2.48247
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.75976

Cumulative Model Updates: 60,906
Cumulative Timesteps: 508,059,222

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.93247
Policy Entropy: 3.34060
Value Function Loss: 0.00350

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.07951
Policy Update Magnitude: 0.55971
Value Function Update Magnitude: 0.68055

Collected Steps per Second: 23,129.30582
Overall Steps per Second: 10,832.88135

Timestep Collection Time: 2.16219
Timestep Consumption Time: 2.45431
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.61650

Cumulative Model Updates: 60,912
Cumulative Timesteps: 508,109,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 508109232...
Checkpoint 508109232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.57301
Policy Entropy: 3.34420
Value Function Loss: 0.00342

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08003
Policy Update Magnitude: 0.55052
Value Function Update Magnitude: 0.67500

Collected Steps per Second: 22,404.09669
Overall Steps per Second: 10,694.96709

Timestep Collection Time: 2.23173
Timestep Consumption Time: 2.44336
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.67510

Cumulative Model Updates: 60,918
Cumulative Timesteps: 508,159,232

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 922.62419
Policy Entropy: 3.33224
Value Function Loss: 0.00347

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08346
Policy Update Magnitude: 0.54600
Value Function Update Magnitude: 0.68025

Collected Steps per Second: 22,817.32108
Overall Steps per Second: 10,722.37931

Timestep Collection Time: 2.19228
Timestep Consumption Time: 2.47291
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.66520

Cumulative Model Updates: 60,924
Cumulative Timesteps: 508,209,254

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 508209254...
Checkpoint 508209254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 665.70676
Policy Entropy: 3.33501
Value Function Loss: 0.00347

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07318
Policy Update Magnitude: 0.54917
Value Function Update Magnitude: 0.69258

Collected Steps per Second: 22,612.94097
Overall Steps per Second: 10,797.39733

Timestep Collection Time: 2.21236
Timestep Consumption Time: 2.42098
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.63334

Cumulative Model Updates: 60,930
Cumulative Timesteps: 508,259,282

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 963.00584
Policy Entropy: 3.32560
Value Function Loss: 0.00373

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08548
Policy Update Magnitude: 0.56946
Value Function Update Magnitude: 0.69308

Collected Steps per Second: 22,889.27221
Overall Steps per Second: 10,616.49637

Timestep Collection Time: 2.18495
Timestep Consumption Time: 2.52583
PPO Batch Consumption Time: 0.29757
Total Iteration Time: 4.71078

Cumulative Model Updates: 60,936
Cumulative Timesteps: 508,309,294

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 508309294...
Checkpoint 508309294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.61611
Policy Entropy: 3.34687
Value Function Loss: 0.00375

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.57280
Value Function Update Magnitude: 0.68999

Collected Steps per Second: 22,826.64976
Overall Steps per Second: 10,594.71746

Timestep Collection Time: 2.19051
Timestep Consumption Time: 2.52901
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.71952

Cumulative Model Updates: 60,942
Cumulative Timesteps: 508,359,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,508.07211
Policy Entropy: 3.35719
Value Function Loss: 0.00357

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.56385
Value Function Update Magnitude: 0.69511

Collected Steps per Second: 22,367.14094
Overall Steps per Second: 10,486.68311

Timestep Collection Time: 2.23623
Timestep Consumption Time: 2.53344
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.76967

Cumulative Model Updates: 60,948
Cumulative Timesteps: 508,409,314

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 508409314...
Checkpoint 508409314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,674.49793
Policy Entropy: 3.36815
Value Function Loss: 0.00358

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07577
Policy Update Magnitude: 0.55896
Value Function Update Magnitude: 0.67981

Collected Steps per Second: 22,446.95104
Overall Steps per Second: 10,537.86537

Timestep Collection Time: 2.22819
Timestep Consumption Time: 2.51813
PPO Batch Consumption Time: 0.29853
Total Iteration Time: 4.74631

Cumulative Model Updates: 60,954
Cumulative Timesteps: 508,459,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457.48911
Policy Entropy: 3.37505
Value Function Loss: 0.00355

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08641
Policy Update Magnitude: 0.56583
Value Function Update Magnitude: 0.68652

Collected Steps per Second: 22,377.87072
Overall Steps per Second: 10,542.55227

Timestep Collection Time: 2.23471
Timestep Consumption Time: 2.50874
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.74344

Cumulative Model Updates: 60,960
Cumulative Timesteps: 508,509,338

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 508509338...
Checkpoint 508509338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449.46628
Policy Entropy: 3.37618
Value Function Loss: 0.00359

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.56178
Value Function Update Magnitude: 0.70309

Collected Steps per Second: 22,222.19458
Overall Steps per Second: 10,584.62589

Timestep Collection Time: 2.25081
Timestep Consumption Time: 2.47472
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.72553

Cumulative Model Updates: 60,966
Cumulative Timesteps: 508,559,356

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 841.91051
Policy Entropy: 3.36653
Value Function Loss: 0.00337

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09676
Policy Update Magnitude: 0.54870
Value Function Update Magnitude: 0.68818

Collected Steps per Second: 22,998.27731
Overall Steps per Second: 10,836.12982

Timestep Collection Time: 2.17521
Timestep Consumption Time: 2.44139
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.61659

Cumulative Model Updates: 60,972
Cumulative Timesteps: 508,609,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 508609382...
Checkpoint 508609382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.75290
Policy Entropy: 3.35551
Value Function Loss: 0.00357

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09934
Policy Update Magnitude: 0.54736
Value Function Update Magnitude: 0.67238

Collected Steps per Second: 22,516.28080
Overall Steps per Second: 10,682.57658

Timestep Collection Time: 2.22168
Timestep Consumption Time: 2.46108
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.68277

Cumulative Model Updates: 60,978
Cumulative Timesteps: 508,659,406

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.79280
Policy Entropy: 3.34991
Value Function Loss: 0.00364

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09491
Policy Update Magnitude: 0.54925
Value Function Update Magnitude: 0.66810

Collected Steps per Second: 22,825.38172
Overall Steps per Second: 10,659.23961

Timestep Collection Time: 2.19107
Timestep Consumption Time: 2.50082
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.69189

Cumulative Model Updates: 60,984
Cumulative Timesteps: 508,709,418

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 508709418...
Checkpoint 508709418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.65275
Policy Entropy: 3.35482
Value Function Loss: 0.00360

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08960
Policy Update Magnitude: 0.56366
Value Function Update Magnitude: 0.66680

Collected Steps per Second: 22,653.97320
Overall Steps per Second: 10,619.90703

Timestep Collection Time: 2.20800
Timestep Consumption Time: 2.50202
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.71002

Cumulative Model Updates: 60,990
Cumulative Timesteps: 508,759,438

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.25093
Policy Entropy: 3.35908
Value Function Loss: 0.00353

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07940
Policy Update Magnitude: 0.56185
Value Function Update Magnitude: 0.66584

Collected Steps per Second: 22,946.78392
Overall Steps per Second: 10,766.16564

Timestep Collection Time: 2.17913
Timestep Consumption Time: 2.46542
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.64455

Cumulative Model Updates: 60,996
Cumulative Timesteps: 508,809,442

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 508809442...
Checkpoint 508809442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.82881
Policy Entropy: 3.37160
Value Function Loss: 0.00341

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09411
Policy Update Magnitude: 0.54735
Value Function Update Magnitude: 0.65674

Collected Steps per Second: 22,239.57775
Overall Steps per Second: 10,626.05319

Timestep Collection Time: 2.24968
Timestep Consumption Time: 2.45874
PPO Batch Consumption Time: 0.28165
Total Iteration Time: 4.70843

Cumulative Model Updates: 61,002
Cumulative Timesteps: 508,859,474

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 808.55156
Policy Entropy: 3.38253
Value Function Loss: 0.00339

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09704
Policy Update Magnitude: 0.54124
Value Function Update Magnitude: 0.65554

Collected Steps per Second: 22,510.17326
Overall Steps per Second: 10,621.37801

Timestep Collection Time: 2.22193
Timestep Consumption Time: 2.48706
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.70899

Cumulative Model Updates: 61,008
Cumulative Timesteps: 508,909,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 508909490...
Checkpoint 508909490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.27908
Policy Entropy: 3.39181
Value Function Loss: 0.00357

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10379
Policy Update Magnitude: 0.54441
Value Function Update Magnitude: 0.66772

Collected Steps per Second: 22,468.97194
Overall Steps per Second: 10,513.12846

Timestep Collection Time: 2.22565
Timestep Consumption Time: 2.53107
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 4.75672

Cumulative Model Updates: 61,014
Cumulative Timesteps: 508,959,498

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 778.24429
Policy Entropy: 3.39275
Value Function Loss: 0.00366

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08719
Policy Update Magnitude: 0.55302
Value Function Update Magnitude: 0.66727

Collected Steps per Second: 22,639.07135
Overall Steps per Second: 10,781.55379

Timestep Collection Time: 2.20928
Timestep Consumption Time: 2.42976
PPO Batch Consumption Time: 0.28204
Total Iteration Time: 4.63903

Cumulative Model Updates: 61,020
Cumulative Timesteps: 509,009,514

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 509009514...
Checkpoint 509009514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,376.96485
Policy Entropy: 3.39841
Value Function Loss: 0.00347

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08360
Policy Update Magnitude: 0.55670
Value Function Update Magnitude: 0.65597

Collected Steps per Second: 22,297.62758
Overall Steps per Second: 10,676.08510

Timestep Collection Time: 2.24293
Timestep Consumption Time: 2.44156
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.68449

Cumulative Model Updates: 61,026
Cumulative Timesteps: 509,059,526

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,005.48189
Policy Entropy: 3.39084
Value Function Loss: 0.00343

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.53987
Value Function Update Magnitude: 0.64585

Collected Steps per Second: 22,789.39518
Overall Steps per Second: 10,685.54356

Timestep Collection Time: 2.19497
Timestep Consumption Time: 2.48631
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.68128

Cumulative Model Updates: 61,032
Cumulative Timesteps: 509,109,548

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 509109548...
Checkpoint 509109548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.06628
Policy Entropy: 3.38223
Value Function Loss: 0.00353

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09968
Policy Update Magnitude: 0.53789
Value Function Update Magnitude: 0.62998

Collected Steps per Second: 22,608.34052
Overall Steps per Second: 10,545.28798

Timestep Collection Time: 2.21157
Timestep Consumption Time: 2.52988
PPO Batch Consumption Time: 0.29572
Total Iteration Time: 4.74145

Cumulative Model Updates: 61,038
Cumulative Timesteps: 509,159,548

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.05432
Policy Entropy: 3.37719
Value Function Loss: 0.00356

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12204
Policy Update Magnitude: 0.53798
Value Function Update Magnitude: 0.63180

Collected Steps per Second: 23,249.18199
Overall Steps per Second: 10,808.76731

Timestep Collection Time: 2.15061
Timestep Consumption Time: 2.47526
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.62587

Cumulative Model Updates: 61,044
Cumulative Timesteps: 509,209,548

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 509209548...
Checkpoint 509209548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 966.05099
Policy Entropy: 3.38615
Value Function Loss: 0.00357

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.10959
Policy Update Magnitude: 0.53594
Value Function Update Magnitude: 0.61543

Collected Steps per Second: 22,530.02303
Overall Steps per Second: 10,641.61926

Timestep Collection Time: 2.21997
Timestep Consumption Time: 2.48007
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.70004

Cumulative Model Updates: 61,050
Cumulative Timesteps: 509,259,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.62781
Policy Entropy: 3.39008
Value Function Loss: 0.00352

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11133
Policy Update Magnitude: 0.53738
Value Function Update Magnitude: 0.62753

Collected Steps per Second: 21,733.80559
Overall Steps per Second: 10,439.74041

Timestep Collection Time: 2.30176
Timestep Consumption Time: 2.49012
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.79188

Cumulative Model Updates: 61,056
Cumulative Timesteps: 509,309,590

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 509309590...
Checkpoint 509309590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 927.77647
Policy Entropy: 3.38526
Value Function Loss: 0.00346

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08215
Policy Update Magnitude: 0.53934
Value Function Update Magnitude: 0.62603

Collected Steps per Second: 22,383.20307
Overall Steps per Second: 10,634.04375

Timestep Collection Time: 2.23498
Timestep Consumption Time: 2.46935
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.70433

Cumulative Model Updates: 61,062
Cumulative Timesteps: 509,359,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480.34486
Policy Entropy: 3.36550
Value Function Loss: 0.00351

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07432
Policy Update Magnitude: 0.54940
Value Function Update Magnitude: 0.62726

Collected Steps per Second: 22,789.72272
Overall Steps per Second: 10,677.89198

Timestep Collection Time: 2.19441
Timestep Consumption Time: 2.48910
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.68351

Cumulative Model Updates: 61,068
Cumulative Timesteps: 509,409,626

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 509409626...
Checkpoint 509409626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 917.53494
Policy Entropy: 3.36694
Value Function Loss: 0.00341

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08599
Policy Update Magnitude: 0.54916
Value Function Update Magnitude: 0.62119

Collected Steps per Second: 21,805.12922
Overall Steps per Second: 10,436.20726

Timestep Collection Time: 2.29405
Timestep Consumption Time: 2.49907
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.79312

Cumulative Model Updates: 61,074
Cumulative Timesteps: 509,459,648

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,183.81657
Policy Entropy: 3.37289
Value Function Loss: 0.00336

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08092
Policy Update Magnitude: 0.53397
Value Function Update Magnitude: 0.61054

Collected Steps per Second: 22,583.22608
Overall Steps per Second: 10,645.60321

Timestep Collection Time: 2.21439
Timestep Consumption Time: 2.48314
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.69753

Cumulative Model Updates: 61,080
Cumulative Timesteps: 509,509,656

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 509509656...
Checkpoint 509509656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 928.68642
Policy Entropy: 3.36758
Value Function Loss: 0.00338

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.52830
Value Function Update Magnitude: 0.58836

Collected Steps per Second: 22,584.77530
Overall Steps per Second: 10,543.15233

Timestep Collection Time: 2.21503
Timestep Consumption Time: 2.52985
PPO Batch Consumption Time: 0.29507
Total Iteration Time: 4.74488

Cumulative Model Updates: 61,086
Cumulative Timesteps: 509,559,682

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,921.54573
Policy Entropy: 3.37262
Value Function Loss: 0.00336

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07145
Policy Update Magnitude: 0.52508
Value Function Update Magnitude: 0.59308

Collected Steps per Second: 23,140.09508
Overall Steps per Second: 10,827.13878

Timestep Collection Time: 2.16188
Timestep Consumption Time: 2.45855
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.62043

Cumulative Model Updates: 61,092
Cumulative Timesteps: 509,609,708

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 509609708...
Checkpoint 509609708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,590.66703
Policy Entropy: 3.36415
Value Function Loss: 0.00332

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.52584
Value Function Update Magnitude: 0.58912

Collected Steps per Second: 22,502.34643
Overall Steps per Second: 10,622.88136

Timestep Collection Time: 2.22199
Timestep Consumption Time: 2.48483
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.70682

Cumulative Model Updates: 61,098
Cumulative Timesteps: 509,659,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629.15811
Policy Entropy: 3.36296
Value Function Loss: 0.00329

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10297
Policy Update Magnitude: 0.52233
Value Function Update Magnitude: 0.60694

Collected Steps per Second: 22,820.59131
Overall Steps per Second: 10,841.30735

Timestep Collection Time: 2.19100
Timestep Consumption Time: 2.42099
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.61199

Cumulative Model Updates: 61,104
Cumulative Timesteps: 509,709,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 509709708...
Checkpoint 509709708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.48667
Policy Entropy: 3.37454
Value Function Loss: 0.00341

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09888
Policy Update Magnitude: 0.52658
Value Function Update Magnitude: 0.61185

Collected Steps per Second: 22,606.54228
Overall Steps per Second: 10,696.66717

Timestep Collection Time: 2.21299
Timestep Consumption Time: 2.46398
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.67697

Cumulative Model Updates: 61,110
Cumulative Timesteps: 509,759,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480.03431
Policy Entropy: 3.36040
Value Function Loss: 0.00345

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08082
Policy Update Magnitude: 0.53452
Value Function Update Magnitude: 0.61880

Collected Steps per Second: 23,169.40168
Overall Steps per Second: 10,895.58138

Timestep Collection Time: 2.15923
Timestep Consumption Time: 2.43236
PPO Batch Consumption Time: 0.28390
Total Iteration Time: 4.59159

Cumulative Model Updates: 61,116
Cumulative Timesteps: 509,809,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 509809764...
Checkpoint 509809764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 816.85017
Policy Entropy: 3.34280
Value Function Loss: 0.00346

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08182
Policy Update Magnitude: 0.54058
Value Function Update Magnitude: 0.61781

Collected Steps per Second: 22,431.95563
Overall Steps per Second: 10,666.67235

Timestep Collection Time: 2.23012
Timestep Consumption Time: 2.45981
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.68993

Cumulative Model Updates: 61,122
Cumulative Timesteps: 509,859,790

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.04563
Policy Entropy: 3.32789
Value Function Loss: 0.00336

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08464
Policy Update Magnitude: 0.54025
Value Function Update Magnitude: 0.61694

Collected Steps per Second: 22,432.36664
Overall Steps per Second: 10,582.17587

Timestep Collection Time: 2.22892
Timestep Consumption Time: 2.49600
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.72493

Cumulative Model Updates: 61,128
Cumulative Timesteps: 509,909,790

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 509909790...
Checkpoint 509909790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 878.41222
Policy Entropy: 3.32515
Value Function Loss: 0.00346

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08943
Policy Update Magnitude: 0.54361
Value Function Update Magnitude: 0.62906

Collected Steps per Second: 22,432.50106
Overall Steps per Second: 10,591.60631

Timestep Collection Time: 2.22900
Timestep Consumption Time: 2.49191
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.72091

Cumulative Model Updates: 61,134
Cumulative Timesteps: 509,959,792

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.97639
Policy Entropy: 3.33229
Value Function Loss: 0.00341

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07891
Policy Update Magnitude: 0.54618
Value Function Update Magnitude: 0.62761

Collected Steps per Second: 22,523.93230
Overall Steps per Second: 10,748.49569

Timestep Collection Time: 2.22066
Timestep Consumption Time: 2.43283
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.65349

Cumulative Model Updates: 61,140
Cumulative Timesteps: 510,009,810

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 510009810...
Checkpoint 510009810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,660.23691
Policy Entropy: 3.33286
Value Function Loss: 0.00329

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07142
Policy Update Magnitude: 0.54619
Value Function Update Magnitude: 0.61296

Collected Steps per Second: 21,932.75543
Overall Steps per Second: 10,645.37127

Timestep Collection Time: 2.27988
Timestep Consumption Time: 2.41738
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.69725

Cumulative Model Updates: 61,146
Cumulative Timesteps: 510,059,814

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,736.13158
Policy Entropy: 3.34700
Value Function Loss: 0.00323

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08719
Policy Update Magnitude: 0.53628
Value Function Update Magnitude: 0.59685

Collected Steps per Second: 22,538.35408
Overall Steps per Second: 10,510.33600

Timestep Collection Time: 2.21959
Timestep Consumption Time: 2.54010
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.75970

Cumulative Model Updates: 61,152
Cumulative Timesteps: 510,109,840

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 510109840...
Checkpoint 510109840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.69202
Policy Entropy: 3.35732
Value Function Loss: 0.00331

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07228
Policy Update Magnitude: 0.53081
Value Function Update Magnitude: 0.59122

Collected Steps per Second: 22,534.99497
Overall Steps per Second: 10,682.72157

Timestep Collection Time: 2.21913
Timestep Consumption Time: 2.46208
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.68120

Cumulative Model Updates: 61,158
Cumulative Timesteps: 510,159,848

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 784.37929
Policy Entropy: 3.35242
Value Function Loss: 0.00338

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08441
Policy Update Magnitude: 0.53536
Value Function Update Magnitude: 0.58080

Collected Steps per Second: 22,851.73081
Overall Steps per Second: 10,612.76553

Timestep Collection Time: 2.18898
Timestep Consumption Time: 2.52440
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.71338

Cumulative Model Updates: 61,164
Cumulative Timesteps: 510,209,870

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 510209870...
Checkpoint 510209870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.22580
Policy Entropy: 3.35162
Value Function Loss: 0.00339

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08376
Policy Update Magnitude: 0.53476
Value Function Update Magnitude: 0.59647

Collected Steps per Second: 22,478.19720
Overall Steps per Second: 10,512.91104

Timestep Collection Time: 2.22500
Timestep Consumption Time: 2.53239
PPO Batch Consumption Time: 0.29814
Total Iteration Time: 4.75739

Cumulative Model Updates: 61,170
Cumulative Timesteps: 510,259,884

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 917.68558
Policy Entropy: 3.32464
Value Function Loss: 0.00349

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08675
Policy Update Magnitude: 0.53249
Value Function Update Magnitude: 0.60679

Collected Steps per Second: 22,645.24502
Overall Steps per Second: 10,765.01669

Timestep Collection Time: 2.20823
Timestep Consumption Time: 2.43700
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.64523

Cumulative Model Updates: 61,176
Cumulative Timesteps: 510,309,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 510309890...
Checkpoint 510309890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544.98465
Policy Entropy: 3.32705
Value Function Loss: 0.00356

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10029
Policy Update Magnitude: 0.54140
Value Function Update Magnitude: 0.62768

Collected Steps per Second: 22,462.74182
Overall Steps per Second: 10,743.30392

Timestep Collection Time: 2.22653
Timestep Consumption Time: 2.42883
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.65536

Cumulative Model Updates: 61,182
Cumulative Timesteps: 510,359,904

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.76879
Policy Entropy: 3.32612
Value Function Loss: 0.00352

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10920
Policy Update Magnitude: 0.54174
Value Function Update Magnitude: 0.62768

Collected Steps per Second: 22,775.20034
Overall Steps per Second: 10,792.92189

Timestep Collection Time: 2.19555
Timestep Consumption Time: 2.43749
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.63304

Cumulative Model Updates: 61,188
Cumulative Timesteps: 510,409,908

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 510409908...
Checkpoint 510409908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 779.55972
Policy Entropy: 3.34199
Value Function Loss: 0.00349

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10043
Policy Update Magnitude: 0.53710
Value Function Update Magnitude: 0.63135

Collected Steps per Second: 22,405.71447
Overall Steps per Second: 10,759.63232

Timestep Collection Time: 2.23220
Timestep Consumption Time: 2.41610
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 4.64830

Cumulative Model Updates: 61,194
Cumulative Timesteps: 510,459,922

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.55480
Policy Entropy: 3.35237
Value Function Loss: 0.00338

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07956
Policy Update Magnitude: 0.53737
Value Function Update Magnitude: 0.62655

Collected Steps per Second: 22,545.94499
Overall Steps per Second: 10,592.04965

Timestep Collection Time: 2.21778
Timestep Consumption Time: 2.50293
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.72071

Cumulative Model Updates: 61,200
Cumulative Timesteps: 510,509,924

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 510509924...
Checkpoint 510509924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714.58492
Policy Entropy: 3.33944
Value Function Loss: 0.00355

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07308
Policy Update Magnitude: 0.54774
Value Function Update Magnitude: 0.63716

Collected Steps per Second: 22,337.94009
Overall Steps per Second: 10,569.43535

Timestep Collection Time: 2.23951
Timestep Consumption Time: 2.49357
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.73308

Cumulative Model Updates: 61,206
Cumulative Timesteps: 510,559,950

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.31343
Policy Entropy: 3.33278
Value Function Loss: 0.00356

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08375
Policy Update Magnitude: 0.55182
Value Function Update Magnitude: 0.66007

Collected Steps per Second: 22,363.45548
Overall Steps per Second: 10,579.62712

Timestep Collection Time: 2.23624
Timestep Consumption Time: 2.49077
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.72701

Cumulative Model Updates: 61,212
Cumulative Timesteps: 510,609,960

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 510609960...
Checkpoint 510609960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,737.84228
Policy Entropy: 3.33068
Value Function Loss: 0.00345

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07625
Policy Update Magnitude: 0.54946
Value Function Update Magnitude: 0.66175

Collected Steps per Second: 22,409.57164
Overall Steps per Second: 10,626.64936

Timestep Collection Time: 2.23333
Timestep Consumption Time: 2.47634
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.70967

Cumulative Model Updates: 61,218
Cumulative Timesteps: 510,660,008

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 964.69810
Policy Entropy: 3.34328
Value Function Loss: 0.00337

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07235
Policy Update Magnitude: 0.54298
Value Function Update Magnitude: 0.65485

Collected Steps per Second: 22,198.88518
Overall Steps per Second: 10,485.68299

Timestep Collection Time: 2.25336
Timestep Consumption Time: 2.51715
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.77050

Cumulative Model Updates: 61,224
Cumulative Timesteps: 510,710,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 510710030...
Checkpoint 510710030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 821.37186
Policy Entropy: 3.33968
Value Function Loss: 0.00339

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07035
Policy Update Magnitude: 0.54338
Value Function Update Magnitude: 0.66439

Collected Steps per Second: 23,040.12687
Overall Steps per Second: 10,796.21783

Timestep Collection Time: 2.17117
Timestep Consumption Time: 2.46231
PPO Batch Consumption Time: 0.28383
Total Iteration Time: 4.63347

Cumulative Model Updates: 61,230
Cumulative Timesteps: 510,760,054

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.89219
Policy Entropy: 3.33720
Value Function Loss: 0.00331

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07214
Policy Update Magnitude: 0.54458
Value Function Update Magnitude: 0.65638

Collected Steps per Second: 22,595.58259
Overall Steps per Second: 10,640.21424

Timestep Collection Time: 2.21282
Timestep Consumption Time: 2.48633
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.69915

Cumulative Model Updates: 61,236
Cumulative Timesteps: 510,810,054

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 510810054...
Checkpoint 510810054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.92579
Policy Entropy: 3.33996
Value Function Loss: 0.00358

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08421
Policy Update Magnitude: 0.54257
Value Function Update Magnitude: 0.65164

Collected Steps per Second: 22,430.74390
Overall Steps per Second: 10,554.84920

Timestep Collection Time: 2.23042
Timestep Consumption Time: 2.50958
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.74000

Cumulative Model Updates: 61,242
Cumulative Timesteps: 510,860,084

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 921.82567
Policy Entropy: 3.33907
Value Function Loss: 0.00355

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10363
Policy Update Magnitude: 0.54354
Value Function Update Magnitude: 0.66477

Collected Steps per Second: 22,705.41631
Overall Steps per Second: 10,809.80896

Timestep Collection Time: 2.20291
Timestep Consumption Time: 2.42418
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.62709

Cumulative Model Updates: 61,248
Cumulative Timesteps: 510,910,102

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 510910102...
Checkpoint 510910102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 936.49859
Policy Entropy: 3.32877
Value Function Loss: 0.00371

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.11758
Policy Update Magnitude: 0.54231
Value Function Update Magnitude: 0.70378

Collected Steps per Second: 22,647.82804
Overall Steps per Second: 10,732.85730

Timestep Collection Time: 2.20851
Timestep Consumption Time: 2.45176
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.66027

Cumulative Model Updates: 61,254
Cumulative Timesteps: 510,960,120

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 939.25029
Policy Entropy: 3.33609
Value Function Loss: 0.00352

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.10952
Policy Update Magnitude: 0.54736
Value Function Update Magnitude: 0.68904

Collected Steps per Second: 22,377.59710
Overall Steps per Second: 10,574.21165

Timestep Collection Time: 2.23554
Timestep Consumption Time: 2.49540
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.73094

Cumulative Model Updates: 61,260
Cumulative Timesteps: 511,010,146

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 511010146...
Checkpoint 511010146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,514.61977
Policy Entropy: 3.32747
Value Function Loss: 0.00356

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11430
Policy Update Magnitude: 0.54300
Value Function Update Magnitude: 0.67613

Collected Steps per Second: 22,476.80293
Overall Steps per Second: 10,591.88780

Timestep Collection Time: 2.22523
Timestep Consumption Time: 2.49688
PPO Batch Consumption Time: 0.29673
Total Iteration Time: 4.72210

Cumulative Model Updates: 61,266
Cumulative Timesteps: 511,060,162

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 971.90950
Policy Entropy: 3.33819
Value Function Loss: 0.00365

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09416
Policy Update Magnitude: 0.54531
Value Function Update Magnitude: 0.69522

Collected Steps per Second: 22,301.14349
Overall Steps per Second: 10,582.22491

Timestep Collection Time: 2.24204
Timestep Consumption Time: 2.48287
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.72490

Cumulative Model Updates: 61,272
Cumulative Timesteps: 511,110,162

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 511110162...
Checkpoint 511110162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 798.27433
Policy Entropy: 3.31154
Value Function Loss: 0.00378

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08346
Policy Update Magnitude: 0.54949
Value Function Update Magnitude: 0.69715

Collected Steps per Second: 22,216.80578
Overall Steps per Second: 10,569.28280

Timestep Collection Time: 2.25199
Timestep Consumption Time: 2.48173
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.73372

Cumulative Model Updates: 61,278
Cumulative Timesteps: 511,160,194

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 907.54528
Policy Entropy: 3.31189
Value Function Loss: 0.00364

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09373
Policy Update Magnitude: 0.54423
Value Function Update Magnitude: 0.66435

Collected Steps per Second: 21,895.42857
Overall Steps per Second: 10,342.59729

Timestep Collection Time: 2.28358
Timestep Consumption Time: 2.55079
PPO Batch Consumption Time: 0.29711
Total Iteration Time: 4.83438

Cumulative Model Updates: 61,284
Cumulative Timesteps: 511,210,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 511210194...
Checkpoint 511210194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 881.11860
Policy Entropy: 3.31151
Value Function Loss: 0.00360

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.07910
Policy Update Magnitude: 0.53469
Value Function Update Magnitude: 0.66156

Collected Steps per Second: 22,403.78112
Overall Steps per Second: 10,631.00507

Timestep Collection Time: 2.23248
Timestep Consumption Time: 2.47225
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.70473

Cumulative Model Updates: 61,290
Cumulative Timesteps: 511,260,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613.48063
Policy Entropy: 3.31444
Value Function Loss: 0.00352

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09721
Policy Update Magnitude: 0.53083
Value Function Update Magnitude: 0.65510

Collected Steps per Second: 22,715.19301
Overall Steps per Second: 10,636.91483

Timestep Collection Time: 2.20223
Timestep Consumption Time: 2.50064
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.70287

Cumulative Model Updates: 61,296
Cumulative Timesteps: 511,310,234

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 511310234...
Checkpoint 511310234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.40668
Policy Entropy: 3.31114
Value Function Loss: 0.00371

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09143
Policy Update Magnitude: 0.53549
Value Function Update Magnitude: 0.64220

Collected Steps per Second: 22,783.17435
Overall Steps per Second: 10,620.40114

Timestep Collection Time: 2.19460
Timestep Consumption Time: 2.51332
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.70792

Cumulative Model Updates: 61,302
Cumulative Timesteps: 511,360,234

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525.90347
Policy Entropy: 3.31102
Value Function Loss: 0.00372

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09307
Policy Update Magnitude: 0.53998
Value Function Update Magnitude: 0.63473

Collected Steps per Second: 22,358.45597
Overall Steps per Second: 10,713.90356

Timestep Collection Time: 2.23736
Timestep Consumption Time: 2.43171
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.66907

Cumulative Model Updates: 61,308
Cumulative Timesteps: 511,410,258

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 511410258...
Checkpoint 511410258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 951.82511
Policy Entropy: 3.31572
Value Function Loss: 0.00363

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08876
Policy Update Magnitude: 0.54537
Value Function Update Magnitude: 0.64648

Collected Steps per Second: 22,624.37709
Overall Steps per Second: 10,660.57666

Timestep Collection Time: 2.21124
Timestep Consumption Time: 2.48156
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.69280

Cumulative Model Updates: 61,314
Cumulative Timesteps: 511,460,286

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 798.93615
Policy Entropy: 3.30549
Value Function Loss: 0.00355

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08696
Policy Update Magnitude: 0.54098
Value Function Update Magnitude: 0.64747

Collected Steps per Second: 22,519.25864
Overall Steps per Second: 10,613.88390

Timestep Collection Time: 2.22059
Timestep Consumption Time: 2.49079
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.71138

Cumulative Model Updates: 61,320
Cumulative Timesteps: 511,510,292

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 511510292...
Checkpoint 511510292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.78952
Policy Entropy: 3.31038
Value Function Loss: 0.00356

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07126
Policy Update Magnitude: 0.54357
Value Function Update Magnitude: 0.65222

Collected Steps per Second: 22,790.50639
Overall Steps per Second: 10,810.83371

Timestep Collection Time: 2.19442
Timestep Consumption Time: 2.43168
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.62610

Cumulative Model Updates: 61,326
Cumulative Timesteps: 511,560,304

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.53381
Policy Entropy: 3.31568
Value Function Loss: 0.00334

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.07879
Policy Update Magnitude: 0.53988
Value Function Update Magnitude: 0.64378

Collected Steps per Second: 22,517.51874
Overall Steps per Second: 10,575.63057

Timestep Collection Time: 2.22129
Timestep Consumption Time: 2.50826
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 4.72955

Cumulative Model Updates: 61,332
Cumulative Timesteps: 511,610,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 511610322...
Checkpoint 511610322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499.35908
Policy Entropy: 3.33671
Value Function Loss: 0.00347

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07675
Policy Update Magnitude: 0.53913
Value Function Update Magnitude: 0.63632

Collected Steps per Second: 22,298.43439
Overall Steps per Second: 10,662.73261

Timestep Collection Time: 2.24339
Timestep Consumption Time: 2.44809
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.69148

Cumulative Model Updates: 61,338
Cumulative Timesteps: 511,660,346

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.68390
Policy Entropy: 3.34878
Value Function Loss: 0.00353

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09316
Policy Update Magnitude: 0.54657
Value Function Update Magnitude: 0.64180

Collected Steps per Second: 21,461.58059
Overall Steps per Second: 10,439.55438

Timestep Collection Time: 2.33002
Timestep Consumption Time: 2.46003
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.79005

Cumulative Model Updates: 61,344
Cumulative Timesteps: 511,710,352

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 511710352...
Checkpoint 511710352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.42179
Policy Entropy: 3.34413
Value Function Loss: 0.00355

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10520
Policy Update Magnitude: 0.55044
Value Function Update Magnitude: 0.66244

Collected Steps per Second: 21,750.74920
Overall Steps per Second: 10,709.20753

Timestep Collection Time: 2.29969
Timestep Consumption Time: 2.37106
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.67075

Cumulative Model Updates: 61,350
Cumulative Timesteps: 511,760,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.94813
Policy Entropy: 3.32896
Value Function Loss: 0.00375

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.55246
Value Function Update Magnitude: 0.67351

Collected Steps per Second: 21,611.42477
Overall Steps per Second: 10,528.52900

Timestep Collection Time: 2.31359
Timestep Consumption Time: 2.43541
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.74900

Cumulative Model Updates: 61,356
Cumulative Timesteps: 511,810,372

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 511810372...
Checkpoint 511810372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 771.85313
Policy Entropy: 3.31823
Value Function Loss: 0.00379

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09957
Policy Update Magnitude: 0.55397
Value Function Update Magnitude: 0.66728

Collected Steps per Second: 22,080.90541
Overall Steps per Second: 10,632.38740

Timestep Collection Time: 2.26440
Timestep Consumption Time: 2.43821
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.70261

Cumulative Model Updates: 61,362
Cumulative Timesteps: 511,860,372

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 888.86359
Policy Entropy: 3.31143
Value Function Loss: 0.00392

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08304
Policy Update Magnitude: 0.55790
Value Function Update Magnitude: 0.65339

Collected Steps per Second: 22,001.43637
Overall Steps per Second: 10,677.34244

Timestep Collection Time: 2.27267
Timestep Consumption Time: 2.41033
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.68300

Cumulative Model Updates: 61,368
Cumulative Timesteps: 511,910,374

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 511910374...
Checkpoint 511910374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.62531
Policy Entropy: 3.31639
Value Function Loss: 0.00383

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11126
Policy Update Magnitude: 0.55876
Value Function Update Magnitude: 0.64161

Collected Steps per Second: 22,207.83344
Overall Steps per Second: 10,765.76098

Timestep Collection Time: 2.25191
Timestep Consumption Time: 2.39337
PPO Batch Consumption Time: 0.28196
Total Iteration Time: 4.64528

Cumulative Model Updates: 61,374
Cumulative Timesteps: 511,960,384

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.48302
Policy Entropy: 3.30841
Value Function Loss: 0.00373

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.55644
Value Function Update Magnitude: 0.63273

Collected Steps per Second: 21,814.52332
Overall Steps per Second: 10,555.09453

Timestep Collection Time: 2.29205
Timestep Consumption Time: 2.44500
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.73705

Cumulative Model Updates: 61,380
Cumulative Timesteps: 512,010,384

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 512010384...
Checkpoint 512010384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,502.45079
Policy Entropy: 3.32345
Value Function Loss: 0.00371

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09937
Policy Update Magnitude: 0.54908
Value Function Update Magnitude: 0.63970

Collected Steps per Second: 22,168.88093
Overall Steps per Second: 10,677.61386

Timestep Collection Time: 2.25596
Timestep Consumption Time: 2.42786
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.68382

Cumulative Model Updates: 61,386
Cumulative Timesteps: 512,060,396

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 973.11640
Policy Entropy: 3.33025
Value Function Loss: 0.00357

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08490
Policy Update Magnitude: 0.54990
Value Function Update Magnitude: 0.63766

Collected Steps per Second: 22,408.92693
Overall Steps per Second: 10,745.76757

Timestep Collection Time: 2.23152
Timestep Consumption Time: 2.42203
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.65355

Cumulative Model Updates: 61,392
Cumulative Timesteps: 512,110,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 512110402...
Checkpoint 512110402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.54939
Policy Entropy: 3.32839
Value Function Loss: 0.00342

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08609
Policy Update Magnitude: 0.54308
Value Function Update Magnitude: 0.64870

Collected Steps per Second: 22,115.97954
Overall Steps per Second: 10,627.38920

Timestep Collection Time: 2.26207
Timestep Consumption Time: 2.44538
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.70746

Cumulative Model Updates: 61,398
Cumulative Timesteps: 512,160,430

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.81805
Policy Entropy: 3.32244
Value Function Loss: 0.00327

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09157
Policy Update Magnitude: 0.52938
Value Function Update Magnitude: 0.63280

Collected Steps per Second: 21,745.46164
Overall Steps per Second: 10,523.94842

Timestep Collection Time: 2.29951
Timestep Consumption Time: 2.45193
PPO Batch Consumption Time: 0.29623
Total Iteration Time: 4.75145

Cumulative Model Updates: 61,404
Cumulative Timesteps: 512,210,434

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 512210434...
Checkpoint 512210434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.12300
Policy Entropy: 3.32501
Value Function Loss: 0.00321

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09724
Policy Update Magnitude: 0.51489
Value Function Update Magnitude: 0.61077

Collected Steps per Second: 21,443.93233
Overall Steps per Second: 10,627.94151

Timestep Collection Time: 2.33166
Timestep Consumption Time: 2.37292
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.70458

Cumulative Model Updates: 61,410
Cumulative Timesteps: 512,260,434

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 921.76569
Policy Entropy: 3.33137
Value Function Loss: 0.00333

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09577
Policy Update Magnitude: 0.50933
Value Function Update Magnitude: 0.61556

Collected Steps per Second: 21,664.40037
Overall Steps per Second: 10,511.31350

Timestep Collection Time: 2.30840
Timestep Consumption Time: 2.44934
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.75773

Cumulative Model Updates: 61,416
Cumulative Timesteps: 512,310,444

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 512310444...
Checkpoint 512310444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.70676
Policy Entropy: 3.31767
Value Function Loss: 0.00340

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10748
Policy Update Magnitude: 0.51680
Value Function Update Magnitude: 0.62507

Collected Steps per Second: 22,174.48880
Overall Steps per Second: 10,603.30795

Timestep Collection Time: 2.25502
Timestep Consumption Time: 2.46086
PPO Batch Consumption Time: 0.29714
Total Iteration Time: 4.71589

Cumulative Model Updates: 61,422
Cumulative Timesteps: 512,360,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.87314
Policy Entropy: 3.28913
Value Function Loss: 0.00350

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10772
Policy Update Magnitude: 0.51733
Value Function Update Magnitude: 0.63210

Collected Steps per Second: 21,551.45847
Overall Steps per Second: 10,473.72765

Timestep Collection Time: 2.32012
Timestep Consumption Time: 2.45392
PPO Batch Consumption Time: 0.29680
Total Iteration Time: 4.77404

Cumulative Model Updates: 61,428
Cumulative Timesteps: 512,410,450

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 512410450...
Checkpoint 512410450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 797.48728
Policy Entropy: 3.29278
Value Function Loss: 0.00345

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11184
Policy Update Magnitude: 0.52227
Value Function Update Magnitude: 0.63771

Collected Steps per Second: 21,858.33518
Overall Steps per Second: 10,539.78402

Timestep Collection Time: 2.28837
Timestep Consumption Time: 2.45746
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.74583

Cumulative Model Updates: 61,434
Cumulative Timesteps: 512,460,470

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.39798
Policy Entropy: 3.30900
Value Function Loss: 0.00350

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09110
Policy Update Magnitude: 0.52683
Value Function Update Magnitude: 0.63118

Collected Steps per Second: 22,472.32092
Overall Steps per Second: 10,494.52557

Timestep Collection Time: 2.22638
Timestep Consumption Time: 2.54105
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.76744

Cumulative Model Updates: 61,440
Cumulative Timesteps: 512,510,502

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 512510502...
Checkpoint 512510502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.43105
Policy Entropy: 3.29932
Value Function Loss: 0.00344

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07716
Policy Update Magnitude: 0.52086
Value Function Update Magnitude: 0.62587

Collected Steps per Second: 22,071.88174
Overall Steps per Second: 10,631.28250

Timestep Collection Time: 2.26632
Timestep Consumption Time: 2.43885
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.70517

Cumulative Model Updates: 61,446
Cumulative Timesteps: 512,560,524

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 907.31053
Policy Entropy: 3.30893
Value Function Loss: 0.00358

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09054
Policy Update Magnitude: 0.52984
Value Function Update Magnitude: 0.62762

Collected Steps per Second: 22,531.73166
Overall Steps per Second: 10,536.62539

Timestep Collection Time: 2.21945
Timestep Consumption Time: 2.52666
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.74611

Cumulative Model Updates: 61,452
Cumulative Timesteps: 512,610,532

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 512610532...
Checkpoint 512610532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 844.73815
Policy Entropy: 3.31304
Value Function Loss: 0.00353

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09744
Policy Update Magnitude: 0.52595
Value Function Update Magnitude: 0.63356

Collected Steps per Second: 22,027.18812
Overall Steps per Second: 10,579.52078

Timestep Collection Time: 2.27137
Timestep Consumption Time: 2.45776
PPO Batch Consumption Time: 0.29735
Total Iteration Time: 4.72914

Cumulative Model Updates: 61,458
Cumulative Timesteps: 512,660,564

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,037.17330
Policy Entropy: 3.31143
Value Function Loss: 0.00360

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08407
Policy Update Magnitude: 0.52471
Value Function Update Magnitude: 0.62776

Collected Steps per Second: 22,329.67265
Overall Steps per Second: 10,805.83833

Timestep Collection Time: 2.24079
Timestep Consumption Time: 2.38967
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.63046

Cumulative Model Updates: 61,464
Cumulative Timesteps: 512,710,600

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 512710600...
Checkpoint 512710600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.17461
Policy Entropy: 3.30886
Value Function Loss: 0.00352

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08118
Policy Update Magnitude: 0.53345
Value Function Update Magnitude: 0.62844

Collected Steps per Second: 22,005.33199
Overall Steps per Second: 10,696.96633

Timestep Collection Time: 2.27345
Timestep Consumption Time: 2.40339
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.67684

Cumulative Model Updates: 61,470
Cumulative Timesteps: 512,760,628

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.11083
Policy Entropy: 3.30911
Value Function Loss: 0.00338

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07248
Policy Update Magnitude: 0.53169
Value Function Update Magnitude: 0.61041

Collected Steps per Second: 22,070.98610
Overall Steps per Second: 10,657.34133

Timestep Collection Time: 2.26551
Timestep Consumption Time: 2.42628
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.69179

Cumulative Model Updates: 61,476
Cumulative Timesteps: 512,810,630

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 512810630...
Checkpoint 512810630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.11605
Policy Entropy: 3.31958
Value Function Loss: 0.00327

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07308
Policy Update Magnitude: 0.52283
Value Function Update Magnitude: 0.61271

Collected Steps per Second: 22,284.28391
Overall Steps per Second: 10,841.02948

Timestep Collection Time: 2.24436
Timestep Consumption Time: 2.36904
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.61340

Cumulative Model Updates: 61,482
Cumulative Timesteps: 512,860,644

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.78697
Policy Entropy: 3.32229
Value Function Loss: 0.00310

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06363
Policy Update Magnitude: 0.51770
Value Function Update Magnitude: 0.61318

Collected Steps per Second: 21,466.16388
Overall Steps per Second: 10,520.87613

Timestep Collection Time: 2.33018
Timestep Consumption Time: 2.42418
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.75436

Cumulative Model Updates: 61,488
Cumulative Timesteps: 512,910,664

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 512910664...
Checkpoint 512910664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.62417
Policy Entropy: 3.30201
Value Function Loss: 0.00312

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07351
Policy Update Magnitude: 0.51866
Value Function Update Magnitude: 0.62350

Collected Steps per Second: 21,810.77313
Overall Steps per Second: 10,604.80452

Timestep Collection Time: 2.29245
Timestep Consumption Time: 2.42240
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.71484

Cumulative Model Updates: 61,494
Cumulative Timesteps: 512,960,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,513.37987
Policy Entropy: 3.30213
Value Function Loss: 0.00326

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.11634
Policy Update Magnitude: 0.52309
Value Function Update Magnitude: 0.61030

Collected Steps per Second: 21,732.73688
Overall Steps per Second: 10,520.28634

Timestep Collection Time: 2.30123
Timestep Consumption Time: 2.45263
PPO Batch Consumption Time: 0.29692
Total Iteration Time: 4.75386

Cumulative Model Updates: 61,500
Cumulative Timesteps: 513,010,676

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 513010676...
Checkpoint 513010676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,678.41412
Policy Entropy: 3.29650
Value Function Loss: 0.00327

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.12120
Policy Update Magnitude: 0.51712
Value Function Update Magnitude: 0.60533

Collected Steps per Second: 21,843.78171
Overall Steps per Second: 10,593.95246

Timestep Collection Time: 2.28907
Timestep Consumption Time: 2.43079
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.71986

Cumulative Model Updates: 61,506
Cumulative Timesteps: 513,060,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,835.03638
Policy Entropy: 3.30136
Value Function Loss: 0.00332

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10741
Policy Update Magnitude: 0.50927
Value Function Update Magnitude: 0.61888

Collected Steps per Second: 21,748.34874
Overall Steps per Second: 10,450.51574

Timestep Collection Time: 2.29930
Timestep Consumption Time: 2.48573
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.78503

Cumulative Model Updates: 61,512
Cumulative Timesteps: 513,110,684

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 513110684...
Checkpoint 513110684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,250.54122
Policy Entropy: 3.30851
Value Function Loss: 0.00323

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08456
Policy Update Magnitude: 0.51440
Value Function Update Magnitude: 0.61424

Collected Steps per Second: 21,976.22832
Overall Steps per Second: 10,613.33570

Timestep Collection Time: 2.27664
Timestep Consumption Time: 2.43743
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.71407

Cumulative Model Updates: 61,518
Cumulative Timesteps: 513,160,716

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.88045
Policy Entropy: 3.30412
Value Function Loss: 0.00336

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10081
Policy Update Magnitude: 0.51584
Value Function Update Magnitude: 0.60845

Collected Steps per Second: 21,858.47175
Overall Steps per Second: 10,560.63966

Timestep Collection Time: 2.28845
Timestep Consumption Time: 2.44820
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.73664

Cumulative Model Updates: 61,524
Cumulative Timesteps: 513,210,738

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 513210738...
Checkpoint 513210738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,535.24747
Policy Entropy: 3.30994
Value Function Loss: 0.00339

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10312
Policy Update Magnitude: 0.52026
Value Function Update Magnitude: 0.61804

Collected Steps per Second: 21,831.06664
Overall Steps per Second: 10,572.41100

Timestep Collection Time: 2.29169
Timestep Consumption Time: 2.44044
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.73213

Cumulative Model Updates: 61,530
Cumulative Timesteps: 513,260,768

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.48147
Policy Entropy: 3.31184
Value Function Loss: 0.00340

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08678
Policy Update Magnitude: 0.52473
Value Function Update Magnitude: 0.60990

Collected Steps per Second: 21,904.86308
Overall Steps per Second: 10,597.85917

Timestep Collection Time: 2.28369
Timestep Consumption Time: 2.43650
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.72020

Cumulative Model Updates: 61,536
Cumulative Timesteps: 513,310,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 513310792...
Checkpoint 513310792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.31503
Policy Entropy: 3.32157
Value Function Loss: 0.00321

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09024
Policy Update Magnitude: 0.52375
Value Function Update Magnitude: 0.59212

Collected Steps per Second: 22,131.25381
Overall Steps per Second: 10,688.92989

Timestep Collection Time: 2.25988
Timestep Consumption Time: 2.41917
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.67905

Cumulative Model Updates: 61,542
Cumulative Timesteps: 513,360,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.90336
Policy Entropy: 3.31077
Value Function Loss: 0.00330

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10086
Policy Update Magnitude: 0.52038
Value Function Update Magnitude: 0.58107

Collected Steps per Second: 21,513.49701
Overall Steps per Second: 10,622.56103

Timestep Collection Time: 2.32515
Timestep Consumption Time: 2.38389
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.70903

Cumulative Model Updates: 61,548
Cumulative Timesteps: 513,410,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 513410828...
Checkpoint 513410828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.26706
Policy Entropy: 3.30177
Value Function Loss: 0.00338

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 0.52637
Value Function Update Magnitude: 0.58728

Collected Steps per Second: 21,518.79393
Overall Steps per Second: 10,655.83281

Timestep Collection Time: 2.32467
Timestep Consumption Time: 2.36985
PPO Batch Consumption Time: 0.28172
Total Iteration Time: 4.69452

Cumulative Model Updates: 61,554
Cumulative Timesteps: 513,460,852

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 844.66759
Policy Entropy: 3.29962
Value Function Loss: 0.00337

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08637
Policy Update Magnitude: 0.53525
Value Function Update Magnitude: 0.58692

Collected Steps per Second: 21,803.79133
Overall Steps per Second: 10,525.60737

Timestep Collection Time: 2.29465
Timestep Consumption Time: 2.45871
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.75336

Cumulative Model Updates: 61,560
Cumulative Timesteps: 513,510,884

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 513510884...
Checkpoint 513510884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.71314
Policy Entropy: 3.30552
Value Function Loss: 0.00349

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07388
Policy Update Magnitude: 0.53967
Value Function Update Magnitude: 0.57349

Collected Steps per Second: 21,740.19352
Overall Steps per Second: 10,635.87018

Timestep Collection Time: 2.30053
Timestep Consumption Time: 2.40186
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.70239

Cumulative Model Updates: 61,566
Cumulative Timesteps: 513,560,898

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.72504
Policy Entropy: 3.31464
Value Function Loss: 0.00337

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07808
Policy Update Magnitude: 0.53903
Value Function Update Magnitude: 0.57045

Collected Steps per Second: 22,008.76461
Overall Steps per Second: 10,509.71553

Timestep Collection Time: 2.27282
Timestep Consumption Time: 2.48677
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.75960

Cumulative Model Updates: 61,572
Cumulative Timesteps: 513,610,920

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 513610920...
Checkpoint 513610920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.91465
Policy Entropy: 3.31483
Value Function Loss: 0.00354

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.07860
Policy Update Magnitude: 0.54314
Value Function Update Magnitude: 0.57226

Collected Steps per Second: 23,070.09736
Overall Steps per Second: 10,652.16566

Timestep Collection Time: 2.16748
Timestep Consumption Time: 2.52678
PPO Batch Consumption Time: 0.29660
Total Iteration Time: 4.69426

Cumulative Model Updates: 61,578
Cumulative Timesteps: 513,660,924

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,411.93611
Policy Entropy: 3.31041
Value Function Loss: 0.00369

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08011
Policy Update Magnitude: 0.54879
Value Function Update Magnitude: 0.59817

Collected Steps per Second: 23,244.43431
Overall Steps per Second: 10,879.71558

Timestep Collection Time: 2.15174
Timestep Consumption Time: 2.44544
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.59718

Cumulative Model Updates: 61,584
Cumulative Timesteps: 513,710,940

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 513710940...
Checkpoint 513710940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478.86006
Policy Entropy: 3.31654
Value Function Loss: 0.00384

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08669
Policy Update Magnitude: 0.55202
Value Function Update Magnitude: 0.60484

Collected Steps per Second: 22,847.34357
Overall Steps per Second: 10,568.36909

Timestep Collection Time: 2.18931
Timestep Consumption Time: 2.54368
PPO Batch Consumption Time: 0.29823
Total Iteration Time: 4.73299

Cumulative Model Updates: 61,590
Cumulative Timesteps: 513,760,960

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.39216
Policy Entropy: 3.31430
Value Function Loss: 0.00382

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.56307
Value Function Update Magnitude: 0.61322

Collected Steps per Second: 22,876.37328
Overall Steps per Second: 10,679.49561

Timestep Collection Time: 2.18654
Timestep Consumption Time: 2.49721
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.68374

Cumulative Model Updates: 61,596
Cumulative Timesteps: 513,810,980

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 513810980...
Checkpoint 513810980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481.66411
Policy Entropy: 3.31444
Value Function Loss: 0.00362

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09531
Policy Update Magnitude: 0.55226
Value Function Update Magnitude: 0.62336

Collected Steps per Second: 22,965.73529
Overall Steps per Second: 10,821.19012

Timestep Collection Time: 2.17846
Timestep Consumption Time: 2.44487
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.62334

Cumulative Model Updates: 61,602
Cumulative Timesteps: 513,861,010

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,487.21393
Policy Entropy: 3.30370
Value Function Loss: 0.00348

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10514
Policy Update Magnitude: 0.54062
Value Function Update Magnitude: 0.61451

Collected Steps per Second: 22,340.16164
Overall Steps per Second: 10,530.95247

Timestep Collection Time: 2.23857
Timestep Consumption Time: 2.51029
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.74886

Cumulative Model Updates: 61,608
Cumulative Timesteps: 513,911,020

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 513911020...
Checkpoint 513911020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 856.22764
Policy Entropy: 3.30768
Value Function Loss: 0.00346

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09842
Policy Update Magnitude: 0.53319
Value Function Update Magnitude: 0.63575

Collected Steps per Second: 21,441.47503
Overall Steps per Second: 10,345.09348

Timestep Collection Time: 2.33324
Timestep Consumption Time: 2.50268
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.83592

Cumulative Model Updates: 61,614
Cumulative Timesteps: 513,961,048

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 946.18795
Policy Entropy: 3.31809
Value Function Loss: 0.00337

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08222
Policy Update Magnitude: 0.53080
Value Function Update Magnitude: 0.63799

Collected Steps per Second: 22,282.62458
Overall Steps per Second: 10,512.84482

Timestep Collection Time: 2.24480
Timestep Consumption Time: 2.51319
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.75799

Cumulative Model Updates: 61,620
Cumulative Timesteps: 514,011,068

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 514011068...
Checkpoint 514011068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,479.57460
Policy Entropy: 3.31529
Value Function Loss: 0.00332

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.52964
Value Function Update Magnitude: 0.61709

Collected Steps per Second: 22,694.96727
Overall Steps per Second: 10,641.81696

Timestep Collection Time: 2.20481
Timestep Consumption Time: 2.49721
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.70202

Cumulative Model Updates: 61,626
Cumulative Timesteps: 514,061,106

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.88368
Policy Entropy: 3.31415
Value Function Loss: 0.00337

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11724
Policy Update Magnitude: 0.52720
Value Function Update Magnitude: 0.61145

Collected Steps per Second: 22,638.64302
Overall Steps per Second: 10,648.08781

Timestep Collection Time: 2.20932
Timestep Consumption Time: 2.48786
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.69718

Cumulative Model Updates: 61,632
Cumulative Timesteps: 514,111,122

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 514111122...
Checkpoint 514111122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.09203
Policy Entropy: 3.32010
Value Function Loss: 0.00340

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.12272
Policy Update Magnitude: 0.52993
Value Function Update Magnitude: 0.62043

Collected Steps per Second: 22,785.02815
Overall Steps per Second: 10,619.37859

Timestep Collection Time: 2.19460
Timestep Consumption Time: 2.51415
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.70875

Cumulative Model Updates: 61,638
Cumulative Timesteps: 514,161,126

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,636.82216
Policy Entropy: 3.32968
Value Function Loss: 0.00335

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.53396
Value Function Update Magnitude: 0.63518

Collected Steps per Second: 22,636.62476
Overall Steps per Second: 10,531.58686

Timestep Collection Time: 2.21022
Timestep Consumption Time: 2.54044
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.75066

Cumulative Model Updates: 61,644
Cumulative Timesteps: 514,211,158

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 514211158...
Checkpoint 514211158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.67737
Policy Entropy: 3.32149
Value Function Loss: 0.00345

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.53864
Value Function Update Magnitude: 0.63850

Collected Steps per Second: 22,787.80850
Overall Steps per Second: 10,651.00062

Timestep Collection Time: 2.19495
Timestep Consumption Time: 2.50114
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.69608

Cumulative Model Updates: 61,650
Cumulative Timesteps: 514,261,176

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.35026
Policy Entropy: 3.32404
Value Function Loss: 0.00350

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08681
Policy Update Magnitude: 0.53127
Value Function Update Magnitude: 0.63668

Collected Steps per Second: 22,948.31752
Overall Steps per Second: 10,814.35056

Timestep Collection Time: 2.18003
Timestep Consumption Time: 2.44605
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.62608

Cumulative Model Updates: 61,656
Cumulative Timesteps: 514,311,204

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 514311204...
Checkpoint 514311204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,142.03359
Policy Entropy: 3.32543
Value Function Loss: 0.00345

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07376
Policy Update Magnitude: 0.53499
Value Function Update Magnitude: 0.64081

Collected Steps per Second: 21,823.57381
Overall Steps per Second: 10,697.93847

Timestep Collection Time: 2.29202
Timestep Consumption Time: 2.38365
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.67567

Cumulative Model Updates: 61,662
Cumulative Timesteps: 514,361,224

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,454.28310
Policy Entropy: 3.32967
Value Function Loss: 0.00325

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07664
Policy Update Magnitude: 0.53271
Value Function Update Magnitude: 0.61722

Collected Steps per Second: 22,899.54660
Overall Steps per Second: 10,686.89948

Timestep Collection Time: 2.18450
Timestep Consumption Time: 2.49637
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.68087

Cumulative Model Updates: 61,668
Cumulative Timesteps: 514,411,248

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 514411248...
Checkpoint 514411248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066.20514
Policy Entropy: 3.33601
Value Function Loss: 0.00327

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07562
Policy Update Magnitude: 0.52139
Value Function Update Magnitude: 0.60814

Collected Steps per Second: 21,822.86403
Overall Steps per Second: 10,599.53445

Timestep Collection Time: 2.29200
Timestep Consumption Time: 2.42689
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.71889

Cumulative Model Updates: 61,674
Cumulative Timesteps: 514,461,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.53910
Policy Entropy: 3.33978
Value Function Loss: 0.00340

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07032
Policy Update Magnitude: 0.52628
Value Function Update Magnitude: 0.61073

Collected Steps per Second: 22,151.72287
Overall Steps per Second: 10,794.95735

Timestep Collection Time: 2.25833
Timestep Consumption Time: 2.37587
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.63420

Cumulative Model Updates: 61,680
Cumulative Timesteps: 514,511,292

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 514511292...
Checkpoint 514511292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.87244
Policy Entropy: 3.34360
Value Function Loss: 0.00339

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07539
Policy Update Magnitude: 0.53311
Value Function Update Magnitude: 0.60610

Collected Steps per Second: 21,565.53596
Overall Steps per Second: 10,602.92181

Timestep Collection Time: 2.31889
Timestep Consumption Time: 2.39755
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.71644

Cumulative Model Updates: 61,686
Cumulative Timesteps: 514,561,300

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 902.03494
Policy Entropy: 3.34288
Value Function Loss: 0.00349

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07632
Policy Update Magnitude: 0.53448
Value Function Update Magnitude: 0.61914

Collected Steps per Second: 21,904.06430
Overall Steps per Second: 10,588.64744

Timestep Collection Time: 2.28277
Timestep Consumption Time: 2.43945
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.72223

Cumulative Model Updates: 61,692
Cumulative Timesteps: 514,611,302

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 514611302...
Checkpoint 514611302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,895.12758
Policy Entropy: 3.34375
Value Function Loss: 0.00342

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07905
Policy Update Magnitude: 0.54639
Value Function Update Magnitude: 0.63282

Collected Steps per Second: 22,721.25067
Overall Steps per Second: 10,571.77363

Timestep Collection Time: 2.20138
Timestep Consumption Time: 2.52990
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.73128

Cumulative Model Updates: 61,698
Cumulative Timesteps: 514,661,320

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,010.77552
Policy Entropy: 3.33499
Value Function Loss: 0.00342

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08601
Policy Update Magnitude: 0.54136
Value Function Update Magnitude: 0.61722

Collected Steps per Second: 23,046.88056
Overall Steps per Second: 10,741.44309

Timestep Collection Time: 2.16992
Timestep Consumption Time: 2.48587
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.65580

Cumulative Model Updates: 61,704
Cumulative Timesteps: 514,711,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 514711330...
Checkpoint 514711330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.53071
Policy Entropy: 3.32976
Value Function Loss: 0.00335

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.53455
Value Function Update Magnitude: 0.60815

Collected Steps per Second: 22,883.07015
Overall Steps per Second: 10,710.62879

Timestep Collection Time: 2.18616
Timestep Consumption Time: 2.48453
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.67069

Cumulative Model Updates: 61,710
Cumulative Timesteps: 514,761,356

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 937.72207
Policy Entropy: 3.32923
Value Function Loss: 0.00322

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08760
Policy Update Magnitude: 0.52222
Value Function Update Magnitude: 0.60457

Collected Steps per Second: 23,041.35149
Overall Steps per Second: 10,830.67842

Timestep Collection Time: 2.17019
Timestep Consumption Time: 2.44670
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.61689

Cumulative Model Updates: 61,716
Cumulative Timesteps: 514,811,360

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 514811360...
Checkpoint 514811360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.13283
Policy Entropy: 3.33738
Value Function Loss: 0.00325

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07263
Policy Update Magnitude: 0.51792
Value Function Update Magnitude: 0.59841

Collected Steps per Second: 21,917.30967
Overall Steps per Second: 10,769.79459

Timestep Collection Time: 2.28167
Timestep Consumption Time: 2.36169
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.64336

Cumulative Model Updates: 61,722
Cumulative Timesteps: 514,861,368

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.62753
Policy Entropy: 3.32915
Value Function Loss: 0.00333

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07913
Policy Update Magnitude: 0.52414
Value Function Update Magnitude: 0.58778

Collected Steps per Second: 22,229.82345
Overall Steps per Second: 10,800.79022

Timestep Collection Time: 2.25022
Timestep Consumption Time: 2.38111
PPO Batch Consumption Time: 0.28389
Total Iteration Time: 4.63133

Cumulative Model Updates: 61,728
Cumulative Timesteps: 514,911,390

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 514911390...
Checkpoint 514911390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.71884
Policy Entropy: 3.34041
Value Function Loss: 0.00346

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07792
Policy Update Magnitude: 0.52895
Value Function Update Magnitude: 0.59439

Collected Steps per Second: 21,650.71490
Overall Steps per Second: 10,629.86440

Timestep Collection Time: 2.31078
Timestep Consumption Time: 2.39577
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.70655

Cumulative Model Updates: 61,734
Cumulative Timesteps: 514,961,420

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.56803
Policy Entropy: 3.33263
Value Function Loss: 0.00350

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07909
Policy Update Magnitude: 0.53257
Value Function Update Magnitude: 0.60389

Collected Steps per Second: 21,802.86619
Overall Steps per Second: 10,500.76899

Timestep Collection Time: 2.29337
Timestep Consumption Time: 2.46838
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.76175

Cumulative Model Updates: 61,740
Cumulative Timesteps: 515,011,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 515011422...
Checkpoint 515011422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 944.90783
Policy Entropy: 3.34208
Value Function Loss: 0.00333

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09497
Policy Update Magnitude: 0.52922
Value Function Update Magnitude: 0.62095

Collected Steps per Second: 21,284.56779
Overall Steps per Second: 10,591.42000

Timestep Collection Time: 2.34997
Timestep Consumption Time: 2.37254
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.72250

Cumulative Model Updates: 61,746
Cumulative Timesteps: 515,061,440

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.51141
Policy Entropy: 3.33373
Value Function Loss: 0.00327

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08294
Policy Update Magnitude: 0.52412
Value Function Update Magnitude: 0.62540

Collected Steps per Second: 21,864.38383
Overall Steps per Second: 10,526.56075

Timestep Collection Time: 2.28820
Timestep Consumption Time: 2.46454
PPO Batch Consumption Time: 0.29656
Total Iteration Time: 4.75274

Cumulative Model Updates: 61,752
Cumulative Timesteps: 515,111,470

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 515111470...
Checkpoint 515111470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,699.82883
Policy Entropy: 3.33434
Value Function Loss: 0.00315

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08019
Policy Update Magnitude: 0.52687
Value Function Update Magnitude: 0.63999

Collected Steps per Second: 21,215.69352
Overall Steps per Second: 10,549.33170

Timestep Collection Time: 2.35693
Timestep Consumption Time: 2.38308
PPO Batch Consumption Time: 0.28228
Total Iteration Time: 4.74002

Cumulative Model Updates: 61,758
Cumulative Timesteps: 515,161,474

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,934.74562
Policy Entropy: 3.32842
Value Function Loss: 0.00319

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07277
Policy Update Magnitude: 0.52907
Value Function Update Magnitude: 0.64780

Collected Steps per Second: 21,817.72362
Overall Steps per Second: 10,528.81004

Timestep Collection Time: 2.29199
Timestep Consumption Time: 2.45745
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.74944

Cumulative Model Updates: 61,764
Cumulative Timesteps: 515,211,480

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 515211480...
Checkpoint 515211480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.27321
Policy Entropy: 3.33152
Value Function Loss: 0.00318

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08386
Policy Update Magnitude: 0.52621
Value Function Update Magnitude: 0.65371

Collected Steps per Second: 21,754.49100
Overall Steps per Second: 10,676.20863

Timestep Collection Time: 2.29838
Timestep Consumption Time: 2.38493
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.68331

Cumulative Model Updates: 61,770
Cumulative Timesteps: 515,261,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.59833
Policy Entropy: 3.33201
Value Function Loss: 0.00334

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08113
Policy Update Magnitude: 0.53370
Value Function Update Magnitude: 0.65398

Collected Steps per Second: 22,372.99503
Overall Steps per Second: 10,745.26117

Timestep Collection Time: 2.23663
Timestep Consumption Time: 2.42031
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.65694

Cumulative Model Updates: 61,776
Cumulative Timesteps: 515,311,520

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 515311520...
Checkpoint 515311520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 938.20186
Policy Entropy: 3.33619
Value Function Loss: 0.00340

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08191
Policy Update Magnitude: 0.54346
Value Function Update Magnitude: 0.64424

Collected Steps per Second: 22,615.75961
Overall Steps per Second: 10,700.14201

Timestep Collection Time: 2.21164
Timestep Consumption Time: 2.46287
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.67452

Cumulative Model Updates: 61,782
Cumulative Timesteps: 515,361,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.41449
Policy Entropy: 3.35409
Value Function Loss: 0.00317

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08710
Policy Update Magnitude: 0.52998
Value Function Update Magnitude: 0.63161

Collected Steps per Second: 22,081.32901
Overall Steps per Second: 10,643.69822

Timestep Collection Time: 2.26562
Timestep Consumption Time: 2.43462
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.70025

Cumulative Model Updates: 61,788
Cumulative Timesteps: 515,411,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 515411566...
Checkpoint 515411566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,714.38590
Policy Entropy: 3.37037
Value Function Loss: 0.00320

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09588
Policy Update Magnitude: 0.52477
Value Function Update Magnitude: 0.62328

Collected Steps per Second: 22,597.19321
Overall Steps per Second: 10,555.81275

Timestep Collection Time: 2.21293
Timestep Consumption Time: 2.52437
PPO Batch Consumption Time: 0.29681
Total Iteration Time: 4.73730

Cumulative Model Updates: 61,794
Cumulative Timesteps: 515,461,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 918.74718
Policy Entropy: 3.35540
Value Function Loss: 0.00328

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09344
Policy Update Magnitude: 0.52840
Value Function Update Magnitude: 0.64029

Collected Steps per Second: 23,137.60784
Overall Steps per Second: 10,810.04208

Timestep Collection Time: 2.16168
Timestep Consumption Time: 2.46513
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.62681

Cumulative Model Updates: 61,800
Cumulative Timesteps: 515,511,588

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 515511588...
Checkpoint 515511588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,432.52487
Policy Entropy: 3.34052
Value Function Loss: 0.00351

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08334
Policy Update Magnitude: 0.54487
Value Function Update Magnitude: 0.65097

Collected Steps per Second: 22,531.16376
Overall Steps per Second: 10,725.70633

Timestep Collection Time: 2.22039
Timestep Consumption Time: 2.44392
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.66431

Cumulative Model Updates: 61,806
Cumulative Timesteps: 515,561,616

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.95601
Policy Entropy: 3.32264
Value Function Loss: 0.00371

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08498
Policy Update Magnitude: 0.55721
Value Function Update Magnitude: 0.64241

Collected Steps per Second: 22,739.37379
Overall Steps per Second: 10,633.67255

Timestep Collection Time: 2.19909
Timestep Consumption Time: 2.50352
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.70261

Cumulative Model Updates: 61,812
Cumulative Timesteps: 515,611,622

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 515611622...
Checkpoint 515611622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 972.60873
Policy Entropy: 3.32870
Value Function Loss: 0.00392

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.56659
Value Function Update Magnitude: 0.64640

Collected Steps per Second: 22,196.05041
Overall Steps per Second: 10,478.40673

Timestep Collection Time: 2.25382
Timestep Consumption Time: 2.52037
PPO Batch Consumption Time: 0.29603
Total Iteration Time: 4.77420

Cumulative Model Updates: 61,818
Cumulative Timesteps: 515,661,648

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.93969
Policy Entropy: 3.32669
Value Function Loss: 0.00380

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10283
Policy Update Magnitude: 0.56799
Value Function Update Magnitude: 0.66068

Collected Steps per Second: 22,464.67844
Overall Steps per Second: 10,541.55511

Timestep Collection Time: 2.22678
Timestep Consumption Time: 2.51863
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.74541

Cumulative Model Updates: 61,824
Cumulative Timesteps: 515,711,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 515711672...
Checkpoint 515711672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.78882
Policy Entropy: 3.31890
Value Function Loss: 0.00358

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10418
Policy Update Magnitude: 0.56205
Value Function Update Magnitude: 0.66025

Collected Steps per Second: 22,206.30913
Overall Steps per Second: 10,547.43018

Timestep Collection Time: 2.25251
Timestep Consumption Time: 2.48987
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.74239

Cumulative Model Updates: 61,830
Cumulative Timesteps: 515,761,692

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.02005
Policy Entropy: 3.33445
Value Function Loss: 0.00343

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07747
Policy Update Magnitude: 0.55053
Value Function Update Magnitude: 0.62273

Collected Steps per Second: 22,340.71321
Overall Steps per Second: 10,498.00212

Timestep Collection Time: 2.23878
Timestep Consumption Time: 2.52555
PPO Batch Consumption Time: 0.29681
Total Iteration Time: 4.76434

Cumulative Model Updates: 61,836
Cumulative Timesteps: 515,811,708

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 515811708...
Checkpoint 515811708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544.20157
Policy Entropy: 3.34553
Value Function Loss: 0.00340

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07719
Policy Update Magnitude: 0.54907
Value Function Update Magnitude: 0.57822

Collected Steps per Second: 22,679.34556
Overall Steps per Second: 10,598.41105

Timestep Collection Time: 2.20562
Timestep Consumption Time: 2.51414
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.71976

Cumulative Model Updates: 61,842
Cumulative Timesteps: 515,861,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.63563
Policy Entropy: 3.33957
Value Function Loss: 0.00350

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09325
Policy Update Magnitude: 0.54441
Value Function Update Magnitude: 0.57780

Collected Steps per Second: 22,878.11144
Overall Steps per Second: 10,731.10336

Timestep Collection Time: 2.18558
Timestep Consumption Time: 2.47396
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.65954

Cumulative Model Updates: 61,848
Cumulative Timesteps: 515,911,732

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 515911732...
Checkpoint 515911732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.41634
Policy Entropy: 3.32034
Value Function Loss: 0.00348

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11229
Policy Update Magnitude: 0.54225
Value Function Update Magnitude: 0.60312

Collected Steps per Second: 22,549.39060
Overall Steps per Second: 10,705.49966

Timestep Collection Time: 2.21771
Timestep Consumption Time: 2.45353
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.67124

Cumulative Model Updates: 61,854
Cumulative Timesteps: 515,961,740

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750.08538
Policy Entropy: 3.31838
Value Function Loss: 0.00342

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09779
Policy Update Magnitude: 0.54224
Value Function Update Magnitude: 0.61329

Collected Steps per Second: 22,803.23799
Overall Steps per Second: 10,606.17069

Timestep Collection Time: 2.19320
Timestep Consumption Time: 2.52217
PPO Batch Consumption Time: 0.29522
Total Iteration Time: 4.71537

Cumulative Model Updates: 61,860
Cumulative Timesteps: 516,011,752

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 516011752...
Checkpoint 516011752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.55299
Policy Entropy: 3.31944
Value Function Loss: 0.00340

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.54116
Value Function Update Magnitude: 0.59414

Collected Steps per Second: 22,768.83680
Overall Steps per Second: 10,587.36279

Timestep Collection Time: 2.19634
Timestep Consumption Time: 2.52703
PPO Batch Consumption Time: 0.29809
Total Iteration Time: 4.72337

Cumulative Model Updates: 61,866
Cumulative Timesteps: 516,061,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.89858
Policy Entropy: 3.31133
Value Function Loss: 0.00351

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07747
Policy Update Magnitude: 0.54231
Value Function Update Magnitude: 0.58738

Collected Steps per Second: 23,124.58856
Overall Steps per Second: 10,815.72612

Timestep Collection Time: 2.16315
Timestep Consumption Time: 2.46178
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.62493

Cumulative Model Updates: 61,872
Cumulative Timesteps: 516,111,782

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 516111782...
Checkpoint 516111782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 870.88840
Policy Entropy: 3.30330
Value Function Loss: 0.00371

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08219
Policy Update Magnitude: 0.55283
Value Function Update Magnitude: 0.62627

Collected Steps per Second: 22,394.99017
Overall Steps per Second: 10,682.82187

Timestep Collection Time: 2.23273
Timestep Consumption Time: 2.44787
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.68060

Cumulative Model Updates: 61,878
Cumulative Timesteps: 516,161,784

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.78876
Policy Entropy: 3.30929
Value Function Loss: 0.00373

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08230
Policy Update Magnitude: 0.56414
Value Function Update Magnitude: 0.65185

Collected Steps per Second: 22,777.07696
Overall Steps per Second: 10,612.62313

Timestep Collection Time: 2.19528
Timestep Consumption Time: 2.51628
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.71156

Cumulative Model Updates: 61,884
Cumulative Timesteps: 516,211,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 516211786...
Checkpoint 516211786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.02530
Policy Entropy: 3.30821
Value Function Loss: 0.00380

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.56702
Value Function Update Magnitude: 0.64397

Collected Steps per Second: 22,427.39135
Overall Steps per Second: 10,549.71094

Timestep Collection Time: 2.23004
Timestep Consumption Time: 2.51075
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.74079

Cumulative Model Updates: 61,890
Cumulative Timesteps: 516,261,800

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.60744
Policy Entropy: 3.31190
Value Function Loss: 0.00367

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09649
Policy Update Magnitude: 0.56864
Value Function Update Magnitude: 0.63059

Collected Steps per Second: 22,447.00956
Overall Steps per Second: 10,500.14341

Timestep Collection Time: 2.22756
Timestep Consumption Time: 2.53447
PPO Batch Consumption Time: 0.29624
Total Iteration Time: 4.76203

Cumulative Model Updates: 61,896
Cumulative Timesteps: 516,311,802

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 516311802...
Checkpoint 516311802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.32959
Policy Entropy: 3.29771
Value Function Loss: 0.00361

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11770
Policy Update Magnitude: 0.56430
Value Function Update Magnitude: 0.62655

Collected Steps per Second: 22,352.96568
Overall Steps per Second: 10,535.98239

Timestep Collection Time: 2.23702
Timestep Consumption Time: 2.50900
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.74602

Cumulative Model Updates: 61,902
Cumulative Timesteps: 516,361,806

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.87163
Policy Entropy: 3.30811
Value Function Loss: 0.00361

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11503
Policy Update Magnitude: 0.54786
Value Function Update Magnitude: 0.62406

Collected Steps per Second: 22,585.48064
Overall Steps per Second: 10,511.36622

Timestep Collection Time: 2.21408
Timestep Consumption Time: 2.54325
PPO Batch Consumption Time: 0.29695
Total Iteration Time: 4.75733

Cumulative Model Updates: 61,908
Cumulative Timesteps: 516,411,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 516411812...
Checkpoint 516411812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.67588
Policy Entropy: 3.29860
Value Function Loss: 0.00361

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12526
Policy Update Magnitude: 0.54609
Value Function Update Magnitude: 0.62792

Collected Steps per Second: 22,882.48406
Overall Steps per Second: 10,625.54109

Timestep Collection Time: 2.18639
Timestep Consumption Time: 2.52208
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.70847

Cumulative Model Updates: 61,914
Cumulative Timesteps: 516,461,842

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 808.84247
Policy Entropy: 3.33395
Value Function Loss: 0.00358

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08331
Policy Update Magnitude: 0.54149
Value Function Update Magnitude: 0.64265

Collected Steps per Second: 22,772.91337
Overall Steps per Second: 10,581.72674

Timestep Collection Time: 2.19656
Timestep Consumption Time: 2.53065
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.72721

Cumulative Model Updates: 61,920
Cumulative Timesteps: 516,511,864

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 516511864...
Checkpoint 516511864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.74960
Policy Entropy: 3.34471
Value Function Loss: 0.00336

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07884
Policy Update Magnitude: 0.54445
Value Function Update Magnitude: 0.62786

Collected Steps per Second: 22,318.86898
Overall Steps per Second: 10,512.09626

Timestep Collection Time: 2.24035
Timestep Consumption Time: 2.51627
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.75662

Cumulative Model Updates: 61,926
Cumulative Timesteps: 516,561,866

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.23500
Policy Entropy: 3.35562
Value Function Loss: 0.00352

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07607
Policy Update Magnitude: 0.54560
Value Function Update Magnitude: 0.62427

Collected Steps per Second: 22,855.76538
Overall Steps per Second: 10,685.89775

Timestep Collection Time: 2.18868
Timestep Consumption Time: 2.49263
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.68131

Cumulative Model Updates: 61,932
Cumulative Timesteps: 516,611,890

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 516611890...
Checkpoint 516611890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617.05990
Policy Entropy: 3.35008
Value Function Loss: 0.00334

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07851
Policy Update Magnitude: 0.54731
Value Function Update Magnitude: 0.61893

Collected Steps per Second: 22,689.18069
Overall Steps per Second: 10,746.02887

Timestep Collection Time: 2.20369
Timestep Consumption Time: 2.44919
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.65288

Cumulative Model Updates: 61,938
Cumulative Timesteps: 516,661,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.66195
Policy Entropy: 3.34095
Value Function Loss: 0.00355

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08347
Policy Update Magnitude: 0.55548
Value Function Update Magnitude: 0.62327

Collected Steps per Second: 23,204.12029
Overall Steps per Second: 10,717.37246

Timestep Collection Time: 2.15608
Timestep Consumption Time: 2.51204
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.66812

Cumulative Model Updates: 61,944
Cumulative Timesteps: 516,711,920

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 516711920...
Checkpoint 516711920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.59436
Policy Entropy: 3.33426
Value Function Loss: 0.00367

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10667
Policy Update Magnitude: 0.56063
Value Function Update Magnitude: 0.63333

Collected Steps per Second: 22,366.21813
Overall Steps per Second: 10,454.36709

Timestep Collection Time: 2.23560
Timestep Consumption Time: 2.54728
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.78288

Cumulative Model Updates: 61,950
Cumulative Timesteps: 516,761,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 961.47453
Policy Entropy: 3.31959
Value Function Loss: 0.00368

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10697
Policy Update Magnitude: 0.55962
Value Function Update Magnitude: 0.63440

Collected Steps per Second: 21,183.65257
Overall Steps per Second: 10,214.63890

Timestep Collection Time: 2.36173
Timestep Consumption Time: 2.53615
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.89787

Cumulative Model Updates: 61,956
Cumulative Timesteps: 516,811,952

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 516811952...
Checkpoint 516811952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,563.55765
Policy Entropy: 3.33161
Value Function Loss: 0.00364

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11666
Policy Update Magnitude: 0.54825
Value Function Update Magnitude: 0.64544

Collected Steps per Second: 22,328.00420
Overall Steps per Second: 10,489.75303

Timestep Collection Time: 2.24042
Timestep Consumption Time: 2.52843
PPO Batch Consumption Time: 0.29715
Total Iteration Time: 4.76884

Cumulative Model Updates: 61,962
Cumulative Timesteps: 516,861,976

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,584.55052
Policy Entropy: 3.34466
Value Function Loss: 0.00356

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09568
Policy Update Magnitude: 0.54750
Value Function Update Magnitude: 0.66602

Collected Steps per Second: 22,562.24369
Overall Steps per Second: 10,423.34212

Timestep Collection Time: 2.21618
Timestep Consumption Time: 2.58094
PPO Batch Consumption Time: 0.29648
Total Iteration Time: 4.79712

Cumulative Model Updates: 61,968
Cumulative Timesteps: 516,911,978

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 516911978...
Checkpoint 516911978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 917.34467
Policy Entropy: 3.36533
Value Function Loss: 0.00352

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08526
Policy Update Magnitude: 0.54408
Value Function Update Magnitude: 0.66972

Collected Steps per Second: 22,173.26063
Overall Steps per Second: 10,565.25330

Timestep Collection Time: 2.25551
Timestep Consumption Time: 2.47812
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.73363

Cumulative Model Updates: 61,974
Cumulative Timesteps: 516,961,990

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 944.21219
Policy Entropy: 3.37295
Value Function Loss: 0.00358

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09695
Policy Update Magnitude: 0.54228
Value Function Update Magnitude: 0.65134

Collected Steps per Second: 22,899.71682
Overall Steps per Second: 10,593.83093

Timestep Collection Time: 2.18387
Timestep Consumption Time: 2.53680
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.72067

Cumulative Model Updates: 61,980
Cumulative Timesteps: 517,012,000

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 517012000...
Checkpoint 517012000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.73580
Policy Entropy: 3.36013
Value Function Loss: 0.00339

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.54304
Value Function Update Magnitude: 0.64089

Collected Steps per Second: 22,743.74474
Overall Steps per Second: 10,553.46689

Timestep Collection Time: 2.19849
Timestep Consumption Time: 2.53947
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.73797

Cumulative Model Updates: 61,986
Cumulative Timesteps: 517,062,002

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.89791
Policy Entropy: 3.34250
Value Function Loss: 0.00347

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07771
Policy Update Magnitude: 0.54733
Value Function Update Magnitude: 0.64752

Collected Steps per Second: 22,814.68072
Overall Steps per Second: 10,625.94716

Timestep Collection Time: 2.19210
Timestep Consumption Time: 2.51449
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.70659

Cumulative Model Updates: 61,992
Cumulative Timesteps: 517,112,014

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 517112014...
Checkpoint 517112014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 799.26077
Policy Entropy: 3.33691
Value Function Loss: 0.00347

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08612
Policy Update Magnitude: 0.55218
Value Function Update Magnitude: 0.63411

Collected Steps per Second: 22,623.26265
Overall Steps per Second: 10,555.38825

Timestep Collection Time: 2.21082
Timestep Consumption Time: 2.52761
PPO Batch Consumption Time: 0.29875
Total Iteration Time: 4.73843

Cumulative Model Updates: 61,998
Cumulative Timesteps: 517,162,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.57856
Policy Entropy: 3.35268
Value Function Loss: 0.00346

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09562
Policy Update Magnitude: 0.54751
Value Function Update Magnitude: 0.62416

Collected Steps per Second: 22,871.51861
Overall Steps per Second: 10,793.20592

Timestep Collection Time: 2.18717
Timestep Consumption Time: 2.44759
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.63477

Cumulative Model Updates: 62,004
Cumulative Timesteps: 517,212,054

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 517212054...
Checkpoint 517212054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.95848
Policy Entropy: 3.36334
Value Function Loss: 0.00345

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09222
Policy Update Magnitude: 0.54672
Value Function Update Magnitude: 0.63550

Collected Steps per Second: 22,629.04873
Overall Steps per Second: 10,767.21916

Timestep Collection Time: 2.20981
Timestep Consumption Time: 2.43447
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.64428

Cumulative Model Updates: 62,010
Cumulative Timesteps: 517,262,060

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.62663
Policy Entropy: 3.36683
Value Function Loss: 0.00331

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08251
Policy Update Magnitude: 0.54751
Value Function Update Magnitude: 0.63747

Collected Steps per Second: 22,947.34907
Overall Steps per Second: 10,751.74244

Timestep Collection Time: 2.17934
Timestep Consumption Time: 2.47200
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.65134

Cumulative Model Updates: 62,016
Cumulative Timesteps: 517,312,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 517312070...
Checkpoint 517312070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 894.26111
Policy Entropy: 3.35604
Value Function Loss: 0.00346

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07296
Policy Update Magnitude: 0.55043
Value Function Update Magnitude: 0.60413

Collected Steps per Second: 22,106.03408
Overall Steps per Second: 10,629.97311

Timestep Collection Time: 2.26210
Timestep Consumption Time: 2.44215
PPO Batch Consumption Time: 0.28191
Total Iteration Time: 4.70425

Cumulative Model Updates: 62,022
Cumulative Timesteps: 517,362,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.91097
Policy Entropy: 3.35880
Value Function Loss: 0.00356

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.54665
Value Function Update Magnitude: 0.58344

Collected Steps per Second: 22,321.34987
Overall Steps per Second: 10,547.68938

Timestep Collection Time: 2.24055
Timestep Consumption Time: 2.50097
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.74151

Cumulative Model Updates: 62,028
Cumulative Timesteps: 517,412,088

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 517412088...
Checkpoint 517412088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 840.47916
Policy Entropy: 3.34542
Value Function Loss: 0.00370

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.54468
Value Function Update Magnitude: 0.58561

Collected Steps per Second: 22,085.98470
Overall Steps per Second: 10,626.03566

Timestep Collection Time: 2.26497
Timestep Consumption Time: 2.44272
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.70768

Cumulative Model Updates: 62,034
Cumulative Timesteps: 517,462,112

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.23243
Policy Entropy: 3.33613
Value Function Loss: 0.00355

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.11076
Policy Update Magnitude: 0.54368
Value Function Update Magnitude: 0.58295

Collected Steps per Second: 22,145.10177
Overall Steps per Second: 10,456.08898

Timestep Collection Time: 2.25892
Timestep Consumption Time: 2.52528
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.78420

Cumulative Model Updates: 62,040
Cumulative Timesteps: 517,512,136

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 517512136...
Checkpoint 517512136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.16232
Policy Entropy: 3.34130
Value Function Loss: 0.00332

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08654
Policy Update Magnitude: 0.53332
Value Function Update Magnitude: 0.58143

Collected Steps per Second: 22,419.64234
Overall Steps per Second: 10,658.44693

Timestep Collection Time: 2.23224
Timestep Consumption Time: 2.46319
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.69543

Cumulative Model Updates: 62,046
Cumulative Timesteps: 517,562,182

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 891.08435
Policy Entropy: 3.35229
Value Function Loss: 0.00342

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08954
Policy Update Magnitude: 0.52870
Value Function Update Magnitude: 0.57731

Collected Steps per Second: 22,833.71892
Overall Steps per Second: 10,547.87401

Timestep Collection Time: 2.19097
Timestep Consumption Time: 2.55198
PPO Batch Consumption Time: 0.29615
Total Iteration Time: 4.74295

Cumulative Model Updates: 62,052
Cumulative Timesteps: 517,612,210

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 517612210...
Checkpoint 517612210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,566.68756
Policy Entropy: 3.34900
Value Function Loss: 0.00355

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08494
Policy Update Magnitude: 0.53835
Value Function Update Magnitude: 0.58920

Collected Steps per Second: 23,027.77263
Overall Steps per Second: 10,630.81189

Timestep Collection Time: 2.17146
Timestep Consumption Time: 2.53222
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.70369

Cumulative Model Updates: 62,058
Cumulative Timesteps: 517,662,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,620.81507
Policy Entropy: 3.34716
Value Function Loss: 0.00374

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09422
Policy Update Magnitude: 0.54776
Value Function Update Magnitude: 0.61231

Collected Steps per Second: 22,653.21438
Overall Steps per Second: 10,712.47050

Timestep Collection Time: 2.20852
Timestep Consumption Time: 2.46174
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.67026

Cumulative Model Updates: 62,064
Cumulative Timesteps: 517,712,244

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 517712244...
Checkpoint 517712244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,776.95300
Policy Entropy: 3.33798
Value Function Loss: 0.00360

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.55048
Value Function Update Magnitude: 0.62926

Collected Steps per Second: 22,548.86203
Overall Steps per Second: 10,685.01549

Timestep Collection Time: 2.21741
Timestep Consumption Time: 2.46204
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.67945

Cumulative Model Updates: 62,070
Cumulative Timesteps: 517,762,244

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 985.28144
Policy Entropy: 3.34648
Value Function Loss: 0.00358

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10718
Policy Update Magnitude: 0.54882
Value Function Update Magnitude: 0.63922

Collected Steps per Second: 23,011.08703
Overall Steps per Second: 10,696.40517

Timestep Collection Time: 2.17391
Timestep Consumption Time: 2.50280
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.67671

Cumulative Model Updates: 62,076
Cumulative Timesteps: 517,812,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 517812268...
Checkpoint 517812268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,452.24642
Policy Entropy: 3.34791
Value Function Loss: 0.00369

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10622
Policy Update Magnitude: 0.55186
Value Function Update Magnitude: 0.63522

Collected Steps per Second: 23,050.94884
Overall Steps per Second: 10,847.73959

Timestep Collection Time: 2.16937
Timestep Consumption Time: 2.44044
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.60981

Cumulative Model Updates: 62,082
Cumulative Timesteps: 517,862,274

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.60266
Policy Entropy: 3.35247
Value Function Loss: 0.00374

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.55435
Value Function Update Magnitude: 0.62779

Collected Steps per Second: 22,623.15613
Overall Steps per Second: 10,563.94599

Timestep Collection Time: 2.21066
Timestep Consumption Time: 2.52356
PPO Batch Consumption Time: 0.29663
Total Iteration Time: 4.73422

Cumulative Model Updates: 62,088
Cumulative Timesteps: 517,912,286

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 517912286...
Checkpoint 517912286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.74554
Policy Entropy: 3.34418
Value Function Loss: 0.00374

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07987
Policy Update Magnitude: 0.56012
Value Function Update Magnitude: 0.63100

Collected Steps per Second: 22,141.08310
Overall Steps per Second: 10,643.35217

Timestep Collection Time: 2.25933
Timestep Consumption Time: 2.44069
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.70002

Cumulative Model Updates: 62,094
Cumulative Timesteps: 517,962,310

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 763.67624
Policy Entropy: 3.33782
Value Function Loss: 0.00354

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08816
Policy Update Magnitude: 0.56475
Value Function Update Magnitude: 0.60858

Collected Steps per Second: 22,558.94825
Overall Steps per Second: 10,552.53196

Timestep Collection Time: 2.21659
Timestep Consumption Time: 2.52199
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.73858

Cumulative Model Updates: 62,100
Cumulative Timesteps: 518,012,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 518012314...
Checkpoint 518012314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629.66691
Policy Entropy: 3.34430
Value Function Loss: 0.00356

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08676
Policy Update Magnitude: 0.55794
Value Function Update Magnitude: 0.60393

Collected Steps per Second: 22,903.78514
Overall Steps per Second: 10,671.74223

Timestep Collection Time: 2.18313
Timestep Consumption Time: 2.50233
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.68546

Cumulative Model Updates: 62,106
Cumulative Timesteps: 518,062,316

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.63380
Policy Entropy: 3.34245
Value Function Loss: 0.00355

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.54907
Value Function Update Magnitude: 0.61783

Collected Steps per Second: 22,688.26953
Overall Steps per Second: 10,679.60613

Timestep Collection Time: 2.20378
Timestep Consumption Time: 2.47804
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.68182

Cumulative Model Updates: 62,112
Cumulative Timesteps: 518,112,316

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 518112316...
Checkpoint 518112316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.64685
Policy Entropy: 3.34432
Value Function Loss: 0.00345

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08019
Policy Update Magnitude: 0.54881
Value Function Update Magnitude: 0.64508

Collected Steps per Second: 22,838.05611
Overall Steps per Second: 10,663.80741

Timestep Collection Time: 2.18994
Timestep Consumption Time: 2.50013
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.69007

Cumulative Model Updates: 62,118
Cumulative Timesteps: 518,162,330

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.14483
Policy Entropy: 3.34940
Value Function Loss: 0.00352

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08117
Policy Update Magnitude: 0.54771
Value Function Update Magnitude: 0.65115

Collected Steps per Second: 22,715.06957
Overall Steps per Second: 10,608.07074

Timestep Collection Time: 2.20118
Timestep Consumption Time: 2.51221
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.71339

Cumulative Model Updates: 62,124
Cumulative Timesteps: 518,212,330

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 518212330...
Checkpoint 518212330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 931.25747
Policy Entropy: 3.33462
Value Function Loss: 0.00364

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08214
Policy Update Magnitude: 0.55640
Value Function Update Magnitude: 0.65229

Collected Steps per Second: 22,931.21461
Overall Steps per Second: 10,833.20193

Timestep Collection Time: 2.18043
Timestep Consumption Time: 2.43501
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.61544

Cumulative Model Updates: 62,130
Cumulative Timesteps: 518,262,330

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767.31188
Policy Entropy: 3.33121
Value Function Loss: 0.00362

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08138
Policy Update Magnitude: 0.55859
Value Function Update Magnitude: 0.65991

Collected Steps per Second: 22,673.85000
Overall Steps per Second: 10,574.40991

Timestep Collection Time: 2.20633
Timestep Consumption Time: 2.52452
PPO Batch Consumption Time: 0.29586
Total Iteration Time: 4.73085

Cumulative Model Updates: 62,136
Cumulative Timesteps: 518,312,356

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 518312356...
Checkpoint 518312356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,534.57734
Policy Entropy: 3.32589
Value Function Loss: 0.00359

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08606
Policy Update Magnitude: 0.55249
Value Function Update Magnitude: 0.66774

Collected Steps per Second: 22,656.56258
Overall Steps per Second: 10,621.68088

Timestep Collection Time: 2.20793
Timestep Consumption Time: 2.50169
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.70961

Cumulative Model Updates: 62,142
Cumulative Timesteps: 518,362,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 972.21719
Policy Entropy: 3.32676
Value Function Loss: 0.00362

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08938
Policy Update Magnitude: 0.55115
Value Function Update Magnitude: 0.66812

Collected Steps per Second: 22,148.16565
Overall Steps per Second: 10,456.05812

Timestep Collection Time: 2.25752
Timestep Consumption Time: 2.52439
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.78192

Cumulative Model Updates: 62,148
Cumulative Timesteps: 518,412,380

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 518412380...
Checkpoint 518412380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.31139
Policy Entropy: 3.34067
Value Function Loss: 0.00361

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09704
Policy Update Magnitude: 0.55306
Value Function Update Magnitude: 0.65970

Collected Steps per Second: 22,376.26005
Overall Steps per Second: 10,709.53564

Timestep Collection Time: 2.23558
Timestep Consumption Time: 2.43539
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.67098

Cumulative Model Updates: 62,154
Cumulative Timesteps: 518,462,404

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.64332
Policy Entropy: 3.32788
Value Function Loss: 0.00357

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08363
Policy Update Magnitude: 0.55827
Value Function Update Magnitude: 0.66342

Collected Steps per Second: 22,603.89288
Overall Steps per Second: 10,573.42912

Timestep Collection Time: 2.21227
Timestep Consumption Time: 2.51713
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.72940

Cumulative Model Updates: 62,160
Cumulative Timesteps: 518,512,410

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 518512410...
Checkpoint 518512410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.18556
Policy Entropy: 3.33820
Value Function Loss: 0.00333

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07589
Policy Update Magnitude: 0.54499
Value Function Update Magnitude: 0.63957

Collected Steps per Second: 22,834.37007
Overall Steps per Second: 10,643.21096

Timestep Collection Time: 2.18968
Timestep Consumption Time: 2.50815
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.69783

Cumulative Model Updates: 62,166
Cumulative Timesteps: 518,562,410

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.00691
Policy Entropy: 3.33998
Value Function Loss: 0.00334

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07093
Policy Update Magnitude: 0.53671
Value Function Update Magnitude: 0.60979

Collected Steps per Second: 22,842.02637
Overall Steps per Second: 10,713.46740

Timestep Collection Time: 2.18947
Timestep Consumption Time: 2.47867
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.66814

Cumulative Model Updates: 62,172
Cumulative Timesteps: 518,612,422

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 518612422...
Checkpoint 518612422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 900.92978
Policy Entropy: 3.33134
Value Function Loss: 0.00350

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07193
Policy Update Magnitude: 0.54131
Value Function Update Magnitude: 0.59664

Collected Steps per Second: 22,896.51544
Overall Steps per Second: 10,610.58280

Timestep Collection Time: 2.18374
Timestep Consumption Time: 2.52854
PPO Batch Consumption Time: 0.29785
Total Iteration Time: 4.71228

Cumulative Model Updates: 62,178
Cumulative Timesteps: 518,662,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.62452
Policy Entropy: 3.33131
Value Function Loss: 0.00347

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08724
Policy Update Magnitude: 0.54783
Value Function Update Magnitude: 0.60695

Collected Steps per Second: 22,561.68979
Overall Steps per Second: 10,538.39223

Timestep Collection Time: 2.21641
Timestep Consumption Time: 2.52871
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.74513

Cumulative Model Updates: 62,184
Cumulative Timesteps: 518,712,428

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 518712428...
Checkpoint 518712428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.90774
Policy Entropy: 3.32893
Value Function Loss: 0.00365

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09373
Policy Update Magnitude: 0.54181
Value Function Update Magnitude: 0.61880

Collected Steps per Second: 23,056.18576
Overall Steps per Second: 10,674.74151

Timestep Collection Time: 2.16896
Timestep Consumption Time: 2.51574
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 4.68470

Cumulative Model Updates: 62,190
Cumulative Timesteps: 518,762,436

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 818.02506
Policy Entropy: 3.33405
Value Function Loss: 0.00357

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08775
Policy Update Magnitude: 0.53509
Value Function Update Magnitude: 0.61985

Collected Steps per Second: 22,588.93416
Overall Steps per Second: 10,689.67333

Timestep Collection Time: 2.21374
Timestep Consumption Time: 2.46423
PPO Batch Consumption Time: 0.28197
Total Iteration Time: 4.67797

Cumulative Model Updates: 62,196
Cumulative Timesteps: 518,812,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 518812442...
Checkpoint 518812442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,786.00602
Policy Entropy: 3.34388
Value Function Loss: 0.00337

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.53081
Value Function Update Magnitude: 0.61227

Collected Steps per Second: 22,283.90707
Overall Steps per Second: 10,767.61552

Timestep Collection Time: 2.24395
Timestep Consumption Time: 2.39997
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.64393

Cumulative Model Updates: 62,202
Cumulative Timesteps: 518,862,446

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.46529
Policy Entropy: 3.34626
Value Function Loss: 0.00324

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.52445
Value Function Update Magnitude: 0.59466

Collected Steps per Second: 21,577.41208
Overall Steps per Second: 10,503.17507

Timestep Collection Time: 2.31844
Timestep Consumption Time: 2.44450
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.76294

Cumulative Model Updates: 62,208
Cumulative Timesteps: 518,912,472

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 518912472...
Checkpoint 518912472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 922.41513
Policy Entropy: 3.33881
Value Function Loss: 0.00349

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.52910
Value Function Update Magnitude: 0.59619

Collected Steps per Second: 22,083.12602
Overall Steps per Second: 10,569.03537

Timestep Collection Time: 2.26472
Timestep Consumption Time: 2.46722
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.73194

Cumulative Model Updates: 62,214
Cumulative Timesteps: 518,962,484

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,828.83619
Policy Entropy: 3.33920
Value Function Loss: 0.00347

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08304
Policy Update Magnitude: 0.54557
Value Function Update Magnitude: 0.60833

Collected Steps per Second: 22,499.13356
Overall Steps per Second: 10,526.22321

Timestep Collection Time: 2.22346
Timestep Consumption Time: 2.52905
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.75251

Cumulative Model Updates: 62,220
Cumulative Timesteps: 519,012,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 519012510...
Checkpoint 519012510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,442.05692
Policy Entropy: 3.32416
Value Function Loss: 0.00359

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.07999
Policy Update Magnitude: 0.54136
Value Function Update Magnitude: 0.60976

Collected Steps per Second: 22,464.41988
Overall Steps per Second: 10,598.52939

Timestep Collection Time: 2.22672
Timestep Consumption Time: 2.49299
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.71971

Cumulative Model Updates: 62,226
Cumulative Timesteps: 519,062,532

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 993.61457
Policy Entropy: 3.34195
Value Function Loss: 0.00361

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08336
Policy Update Magnitude: 0.53604
Value Function Update Magnitude: 0.61493

Collected Steps per Second: 22,931.45438
Overall Steps per Second: 10,631.71299

Timestep Collection Time: 2.18093
Timestep Consumption Time: 2.52311
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.70404

Cumulative Model Updates: 62,232
Cumulative Timesteps: 519,112,544

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 519112544...
Checkpoint 519112544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703.80783
Policy Entropy: 3.33804
Value Function Loss: 0.00336

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08992
Policy Update Magnitude: 0.53420
Value Function Update Magnitude: 0.61797

Collected Steps per Second: 22,243.63965
Overall Steps per Second: 10,741.20063

Timestep Collection Time: 2.24801
Timestep Consumption Time: 2.40733
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.65535

Cumulative Model Updates: 62,238
Cumulative Timesteps: 519,162,548

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.71334
Policy Entropy: 3.34872
Value Function Loss: 0.00323

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.51832
Value Function Update Magnitude: 0.60599

Collected Steps per Second: 21,945.05555
Overall Steps per Second: 10,589.74067

Timestep Collection Time: 2.27851
Timestep Consumption Time: 2.44323
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.72174

Cumulative Model Updates: 62,244
Cumulative Timesteps: 519,212,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 519212550...
Checkpoint 519212550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.62014
Policy Entropy: 3.33296
Value Function Loss: 0.00310

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07403
Policy Update Magnitude: 0.51358
Value Function Update Magnitude: 0.57955

Collected Steps per Second: 22,133.64771
Overall Steps per Second: 10,634.77179

Timestep Collection Time: 2.25982
Timestep Consumption Time: 2.44343
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.70325

Cumulative Model Updates: 62,250
Cumulative Timesteps: 519,262,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,648.79541
Policy Entropy: 3.35166
Value Function Loss: 0.00307

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08820
Policy Update Magnitude: 0.51162
Value Function Update Magnitude: 0.58154

Collected Steps per Second: 21,475.25517
Overall Steps per Second: 10,463.31662

Timestep Collection Time: 2.32966
Timestep Consumption Time: 2.45181
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.78147

Cumulative Model Updates: 62,256
Cumulative Timesteps: 519,312,598

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 519312598...
Checkpoint 519312598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 956.08705
Policy Entropy: 3.35846
Value Function Loss: 0.00324

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.51656
Value Function Update Magnitude: 0.58204

Collected Steps per Second: 21,763.52830
Overall Steps per Second: 10,631.48264

Timestep Collection Time: 2.29742
Timestep Consumption Time: 2.40559
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.70301

Cumulative Model Updates: 62,262
Cumulative Timesteps: 519,362,598

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,573.92842
Policy Entropy: 3.36679
Value Function Loss: 0.00323

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08342
Policy Update Magnitude: 0.52047
Value Function Update Magnitude: 0.59817

Collected Steps per Second: 21,930.97470
Overall Steps per Second: 10,639.77305

Timestep Collection Time: 2.28043
Timestep Consumption Time: 2.42005
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.70048

Cumulative Model Updates: 62,268
Cumulative Timesteps: 519,412,610

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 519412610...
Checkpoint 519412610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 804.70579
Policy Entropy: 3.36667
Value Function Loss: 0.00353

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07823
Policy Update Magnitude: 0.52797
Value Function Update Magnitude: 0.60015

Collected Steps per Second: 21,831.78280
Overall Steps per Second: 10,589.51274

Timestep Collection Time: 2.29042
Timestep Consumption Time: 2.43161
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.72203

Cumulative Model Updates: 62,274
Cumulative Timesteps: 519,462,614

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.44187
Policy Entropy: 3.35858
Value Function Loss: 0.00348

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.53794
Value Function Update Magnitude: 0.60764

Collected Steps per Second: 21,873.22609
Overall Steps per Second: 10,730.58509

Timestep Collection Time: 2.28627
Timestep Consumption Time: 2.37406
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.66032

Cumulative Model Updates: 62,280
Cumulative Timesteps: 519,512,622

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 519512622...
Checkpoint 519512622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.08838
Policy Entropy: 3.37402
Value Function Loss: 0.00348

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08201
Policy Update Magnitude: 0.54295
Value Function Update Magnitude: 0.62414

Collected Steps per Second: 21,513.37833
Overall Steps per Second: 10,624.38733

Timestep Collection Time: 2.32469
Timestep Consumption Time: 2.38259
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.70728

Cumulative Model Updates: 62,286
Cumulative Timesteps: 519,562,634

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,808.45232
Policy Entropy: 3.36660
Value Function Loss: 0.00341

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09410
Policy Update Magnitude: 0.54112
Value Function Update Magnitude: 0.64001

Collected Steps per Second: 22,117.01860
Overall Steps per Second: 10,583.44605

Timestep Collection Time: 2.26188
Timestep Consumption Time: 2.46494
PPO Batch Consumption Time: 0.29692
Total Iteration Time: 4.72682

Cumulative Model Updates: 62,292
Cumulative Timesteps: 519,612,660

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 519612660...
Checkpoint 519612660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 972.25256
Policy Entropy: 3.37172
Value Function Loss: 0.00323

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09712
Policy Update Magnitude: 0.53246
Value Function Update Magnitude: 0.63162

Collected Steps per Second: 21,933.95312
Overall Steps per Second: 10,568.57073

Timestep Collection Time: 2.28139
Timestep Consumption Time: 2.45340
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.73479

Cumulative Model Updates: 62,298
Cumulative Timesteps: 519,662,700

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.10252
Policy Entropy: 3.35253
Value Function Loss: 0.00316

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09156
Policy Update Magnitude: 0.52547
Value Function Update Magnitude: 0.60119

Collected Steps per Second: 22,029.25751
Overall Steps per Second: 10,583.73398

Timestep Collection Time: 2.27062
Timestep Consumption Time: 2.45550
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.72612

Cumulative Model Updates: 62,304
Cumulative Timesteps: 519,712,720

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 519712720...
Checkpoint 519712720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,052.38603
Policy Entropy: 3.36206
Value Function Loss: 0.00317

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08125
Policy Update Magnitude: 0.52076
Value Function Update Magnitude: 0.60220

Collected Steps per Second: 22,151.53553
Overall Steps per Second: 10,654.65287

Timestep Collection Time: 2.25835
Timestep Consumption Time: 2.43687
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.69523

Cumulative Model Updates: 62,310
Cumulative Timesteps: 519,762,746

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.10507
Policy Entropy: 3.35180
Value Function Loss: 0.00339

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.52066
Value Function Update Magnitude: 0.61227

Collected Steps per Second: 21,964.24939
Overall Steps per Second: 10,719.16082

Timestep Collection Time: 2.27670
Timestep Consumption Time: 2.38840
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.66510

Cumulative Model Updates: 62,316
Cumulative Timesteps: 519,812,752

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 519812752...
Checkpoint 519812752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.27165
Policy Entropy: 3.34348
Value Function Loss: 0.00351

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.53456
Value Function Update Magnitude: 0.62755

Collected Steps per Second: 22,268.37728
Overall Steps per Second: 10,677.01139

Timestep Collection Time: 2.24543
Timestep Consumption Time: 2.43772
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.68315

Cumulative Model Updates: 62,322
Cumulative Timesteps: 519,862,754

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.19532
Policy Entropy: 3.34849
Value Function Loss: 0.00351

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09731
Policy Update Magnitude: 0.53386
Value Function Update Magnitude: 0.61841

Collected Steps per Second: 22,252.67970
Overall Steps per Second: 10,420.89861

Timestep Collection Time: 2.24809
Timestep Consumption Time: 2.55246
PPO Batch Consumption Time: 0.29759
Total Iteration Time: 4.80055

Cumulative Model Updates: 62,328
Cumulative Timesteps: 519,912,780

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 519912780...
Checkpoint 519912780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.88257
Policy Entropy: 3.35991
Value Function Loss: 0.00340

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09454
Policy Update Magnitude: 0.53128
Value Function Update Magnitude: 0.60820

Collected Steps per Second: 22,722.75679
Overall Steps per Second: 10,635.35982

Timestep Collection Time: 2.20079
Timestep Consumption Time: 2.50126
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.70205

Cumulative Model Updates: 62,334
Cumulative Timesteps: 519,962,788

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.38427
Policy Entropy: 3.38177
Value Function Loss: 0.00345

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08841
Policy Update Magnitude: 0.52647
Value Function Update Magnitude: 0.60953

Collected Steps per Second: 23,001.46174
Overall Steps per Second: 10,712.41547

Timestep Collection Time: 2.17447
Timestep Consumption Time: 2.49450
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.66897

Cumulative Model Updates: 62,340
Cumulative Timesteps: 520,012,804

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 520012804...
Checkpoint 520012804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.40853
Policy Entropy: 3.36250
Value Function Loss: 0.00367

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08165
Policy Update Magnitude: 0.53574
Value Function Update Magnitude: 0.62524

Collected Steps per Second: 22,398.22004
Overall Steps per Second: 10,569.19395

Timestep Collection Time: 2.23286
Timestep Consumption Time: 2.49901
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.73187

Cumulative Model Updates: 62,346
Cumulative Timesteps: 520,062,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 828.09557
Policy Entropy: 3.35771
Value Function Loss: 0.00377

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08389
Policy Update Magnitude: 0.54781
Value Function Update Magnitude: 0.64146

Collected Steps per Second: 22,483.06893
Overall Steps per Second: 10,675.40811

Timestep Collection Time: 2.22487
Timestep Consumption Time: 2.46085
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.68572

Cumulative Model Updates: 62,352
Cumulative Timesteps: 520,112,838

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 520112838...
Checkpoint 520112838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 988.51626
Policy Entropy: 3.33591
Value Function Loss: 0.00395

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08196
Policy Update Magnitude: 0.55352
Value Function Update Magnitude: 0.63619

Collected Steps per Second: 22,093.45440
Overall Steps per Second: 10,616.10011

Timestep Collection Time: 2.26411
Timestep Consumption Time: 2.44779
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.71190

Cumulative Model Updates: 62,358
Cumulative Timesteps: 520,162,860

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 908.02413
Policy Entropy: 3.34939
Value Function Loss: 0.00382

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.55471
Value Function Update Magnitude: 0.65090

Collected Steps per Second: 22,430.13112
Overall Steps per Second: 10,582.78616

Timestep Collection Time: 2.23057
Timestep Consumption Time: 2.49711
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.72768

Cumulative Model Updates: 62,364
Cumulative Timesteps: 520,212,892

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 520212892...
Checkpoint 520212892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 915.76836
Policy Entropy: 3.34309
Value Function Loss: 0.00360

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08368
Policy Update Magnitude: 0.55156
Value Function Update Magnitude: 0.64529

Collected Steps per Second: 22,460.05957
Overall Steps per Second: 10,670.58756

Timestep Collection Time: 2.22680
Timestep Consumption Time: 2.46029
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.68709

Cumulative Model Updates: 62,370
Cumulative Timesteps: 520,262,906

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.22973
Policy Entropy: 3.35187
Value Function Loss: 0.00333

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08563
Policy Update Magnitude: 0.53595
Value Function Update Magnitude: 0.63386

Collected Steps per Second: 22,591.18151
Overall Steps per Second: 10,498.19579

Timestep Collection Time: 2.21387
Timestep Consumption Time: 2.55018
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.76406

Cumulative Model Updates: 62,376
Cumulative Timesteps: 520,312,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 520312920...
Checkpoint 520312920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 933.18942
Policy Entropy: 3.34128
Value Function Loss: 0.00343

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08858
Policy Update Magnitude: 0.53425
Value Function Update Magnitude: 0.61034

Collected Steps per Second: 23,062.65491
Overall Steps per Second: 10,699.33038

Timestep Collection Time: 2.16879
Timestep Consumption Time: 2.50608
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.67487

Cumulative Model Updates: 62,382
Cumulative Timesteps: 520,362,938

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.95277
Policy Entropy: 3.33961
Value Function Loss: 0.00353

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10192
Policy Update Magnitude: 0.54595
Value Function Update Magnitude: 0.60000

Collected Steps per Second: 23,041.48739
Overall Steps per Second: 10,774.37387

Timestep Collection Time: 2.17069
Timestep Consumption Time: 2.47143
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.64213

Cumulative Model Updates: 62,388
Cumulative Timesteps: 520,412,954

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 520412954...
Checkpoint 520412954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 989.00847
Policy Entropy: 3.34380
Value Function Loss: 0.00365

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10007
Policy Update Magnitude: 0.55279
Value Function Update Magnitude: 0.62842

Collected Steps per Second: 23,038.42392
Overall Steps per Second: 10,629.35080

Timestep Collection Time: 2.17142
Timestep Consumption Time: 2.53499
PPO Batch Consumption Time: 0.29723
Total Iteration Time: 4.70640

Cumulative Model Updates: 62,394
Cumulative Timesteps: 520,462,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220.70482
Policy Entropy: 3.36255
Value Function Loss: 0.00348

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09975
Policy Update Magnitude: 0.55114
Value Function Update Magnitude: 0.64247

Collected Steps per Second: 22,789.27641
Overall Steps per Second: 10,652.52168

Timestep Collection Time: 2.19507
Timestep Consumption Time: 2.50091
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.69598

Cumulative Model Updates: 62,400
Cumulative Timesteps: 520,513,004

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 520513004...
Checkpoint 520513004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 727.56384
Policy Entropy: 3.37562
Value Function Loss: 0.00341

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.53394
Value Function Update Magnitude: 0.62869

Collected Steps per Second: 22,156.20282
Overall Steps per Second: 10,783.32478

Timestep Collection Time: 2.25779
Timestep Consumption Time: 2.38123
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.63901

Cumulative Model Updates: 62,406
Cumulative Timesteps: 520,563,028

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,924.29233
Policy Entropy: 3.35590
Value Function Loss: 0.00329

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09212
Policy Update Magnitude: 0.52208
Value Function Update Magnitude: 0.62210

Collected Steps per Second: 21,764.09922
Overall Steps per Second: 10,649.92889

Timestep Collection Time: 2.29957
Timestep Consumption Time: 2.39981
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.69937

Cumulative Model Updates: 62,412
Cumulative Timesteps: 520,613,076

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 520613076...
Checkpoint 520613076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.57593
Policy Entropy: 3.33745
Value Function Loss: 0.00348

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07573
Policy Update Magnitude: 0.52625
Value Function Update Magnitude: 0.64092

Collected Steps per Second: 21,645.03383
Overall Steps per Second: 10,566.08089

Timestep Collection Time: 2.31018
Timestep Consumption Time: 2.42232
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.73250

Cumulative Model Updates: 62,418
Cumulative Timesteps: 520,663,080

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564.60137
Policy Entropy: 3.34430
Value Function Loss: 0.00348

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07648
Policy Update Magnitude: 0.54384
Value Function Update Magnitude: 0.66625

Collected Steps per Second: 21,473.77298
Overall Steps per Second: 10,498.81016

Timestep Collection Time: 2.32982
Timestep Consumption Time: 2.43548
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.76530

Cumulative Model Updates: 62,424
Cumulative Timesteps: 520,713,110

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 520713110...
Checkpoint 520713110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 990.35081
Policy Entropy: 3.36994
Value Function Loss: 0.00345

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08394
Policy Update Magnitude: 0.55112
Value Function Update Magnitude: 0.65247

Collected Steps per Second: 22,175.69728
Overall Steps per Second: 10,645.23547

Timestep Collection Time: 2.25499
Timestep Consumption Time: 2.44251
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.69750

Cumulative Model Updates: 62,430
Cumulative Timesteps: 520,763,116

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 851.28395
Policy Entropy: 3.37459
Value Function Loss: 0.00348

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08907
Policy Update Magnitude: 0.54676
Value Function Update Magnitude: 0.63762

Collected Steps per Second: 21,953.28589
Overall Steps per Second: 10,434.14457

Timestep Collection Time: 2.27829
Timestep Consumption Time: 2.51520
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.79349

Cumulative Model Updates: 62,436
Cumulative Timesteps: 520,813,132

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 520813132...
Checkpoint 520813132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.54451
Policy Entropy: 3.35559
Value Function Loss: 0.00348

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.55033
Value Function Update Magnitude: 0.63196

Collected Steps per Second: 22,484.44786
Overall Steps per Second: 10,630.65000

Timestep Collection Time: 2.22412
Timestep Consumption Time: 2.48002
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.70413

Cumulative Model Updates: 62,442
Cumulative Timesteps: 520,863,140

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 749.22549
Policy Entropy: 3.33853
Value Function Loss: 0.00352

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.07625
Policy Update Magnitude: 0.55155
Value Function Update Magnitude: 0.64362

Collected Steps per Second: 22,492.59898
Overall Steps per Second: 10,447.77145

Timestep Collection Time: 2.22331
Timestep Consumption Time: 2.56317
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.78648

Cumulative Model Updates: 62,448
Cumulative Timesteps: 520,913,148

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 520913148...
Checkpoint 520913148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.56253
Policy Entropy: 3.35448
Value Function Loss: 0.00342

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08258
Policy Update Magnitude: 0.55429
Value Function Update Magnitude: 0.63699

Collected Steps per Second: 22,689.86468
Overall Steps per Second: 10,662.84929

Timestep Collection Time: 2.20486
Timestep Consumption Time: 2.48694
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.69180

Cumulative Model Updates: 62,454
Cumulative Timesteps: 520,963,176

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.30861
Policy Entropy: 3.36586
Value Function Loss: 0.00332

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07163
Policy Update Magnitude: 0.54378
Value Function Update Magnitude: 0.64491

Collected Steps per Second: 23,030.54417
Overall Steps per Second: 10,815.29781

Timestep Collection Time: 2.17103
Timestep Consumption Time: 2.45205
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.62308

Cumulative Model Updates: 62,460
Cumulative Timesteps: 521,013,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 521013176...
Checkpoint 521013176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.69991
Policy Entropy: 3.36018
Value Function Loss: 0.00342

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08570
Policy Update Magnitude: 0.53830
Value Function Update Magnitude: 0.62688

Collected Steps per Second: 22,345.07886
Overall Steps per Second: 10,656.62140

Timestep Collection Time: 2.23835
Timestep Consumption Time: 2.45507
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.69342

Cumulative Model Updates: 62,466
Cumulative Timesteps: 521,063,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.95358
Policy Entropy: 3.35404
Value Function Loss: 0.00351

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09463
Policy Update Magnitude: 0.54088
Value Function Update Magnitude: 0.62799

Collected Steps per Second: 22,941.35568
Overall Steps per Second: 10,679.83431

Timestep Collection Time: 2.18052
Timestep Consumption Time: 2.50345
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.68397

Cumulative Model Updates: 62,472
Cumulative Timesteps: 521,113,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 521113216...
Checkpoint 521113216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 832.33978
Policy Entropy: 3.35961
Value Function Loss: 0.00367

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09127
Policy Update Magnitude: 0.54356
Value Function Update Magnitude: 0.63253

Collected Steps per Second: 22,907.55422
Overall Steps per Second: 10,710.48686

Timestep Collection Time: 2.18277
Timestep Consumption Time: 2.48574
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.66851

Cumulative Model Updates: 62,478
Cumulative Timesteps: 521,163,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.24705
Policy Entropy: 3.36740
Value Function Loss: 0.00373

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07329
Policy Update Magnitude: 0.54621
Value Function Update Magnitude: 0.63823

Collected Steps per Second: 22,922.44869
Overall Steps per Second: 10,649.92868

Timestep Collection Time: 2.18327
Timestep Consumption Time: 2.51591
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.69919

Cumulative Model Updates: 62,484
Cumulative Timesteps: 521,213,264

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 521213264...
Checkpoint 521213264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,724.21903
Policy Entropy: 3.36209
Value Function Loss: 0.00368

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08629
Policy Update Magnitude: 0.54685
Value Function Update Magnitude: 0.66389

Collected Steps per Second: 22,190.13974
Overall Steps per Second: 10,612.18454

Timestep Collection Time: 2.25461
Timestep Consumption Time: 2.45979
PPO Batch Consumption Time: 0.28334
Total Iteration Time: 4.71439

Cumulative Model Updates: 62,490
Cumulative Timesteps: 521,263,294

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706.04590
Policy Entropy: 3.35698
Value Function Loss: 0.00354

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08132
Policy Update Magnitude: 0.54034
Value Function Update Magnitude: 0.67188

Collected Steps per Second: 22,532.82101
Overall Steps per Second: 10,505.48420

Timestep Collection Time: 2.21934
Timestep Consumption Time: 2.54084
PPO Batch Consumption Time: 0.29779
Total Iteration Time: 4.76018

Cumulative Model Updates: 62,496
Cumulative Timesteps: 521,313,302

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 521313302...
Checkpoint 521313302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 972.72007
Policy Entropy: 3.35738
Value Function Loss: 0.00344

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08835
Policy Update Magnitude: 0.53574
Value Function Update Magnitude: 0.64551

Collected Steps per Second: 22,487.84827
Overall Steps per Second: 10,680.37335

Timestep Collection Time: 2.22405
Timestep Consumption Time: 2.45875
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.68280

Cumulative Model Updates: 62,502
Cumulative Timesteps: 521,363,316

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 936.38712
Policy Entropy: 3.35693
Value Function Loss: 0.00353

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07571
Policy Update Magnitude: 0.54029
Value Function Update Magnitude: 0.64617

Collected Steps per Second: 22,681.29037
Overall Steps per Second: 10,612.71971

Timestep Collection Time: 2.20534
Timestep Consumption Time: 2.50787
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.71321

Cumulative Model Updates: 62,508
Cumulative Timesteps: 521,413,336

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 521413336...
Checkpoint 521413336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,376.94434
Policy Entropy: 3.36140
Value Function Loss: 0.00358

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08884
Policy Update Magnitude: 0.54181
Value Function Update Magnitude: 0.65800

Collected Steps per Second: 22,203.92796
Overall Steps per Second: 10,490.05765

Timestep Collection Time: 2.25402
Timestep Consumption Time: 2.51698
PPO Batch Consumption Time: 0.29653
Total Iteration Time: 4.77099

Cumulative Model Updates: 62,514
Cumulative Timesteps: 521,463,384

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.27274
Policy Entropy: 3.35638
Value Function Loss: 0.00370

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09018
Policy Update Magnitude: 0.53638
Value Function Update Magnitude: 0.63677

Collected Steps per Second: 22,747.27739
Overall Steps per Second: 10,575.01624

Timestep Collection Time: 2.19903
Timestep Consumption Time: 2.53117
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.73021

Cumulative Model Updates: 62,520
Cumulative Timesteps: 521,513,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 521513406...
Checkpoint 521513406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 951.33012
Policy Entropy: 3.36059
Value Function Loss: 0.00363

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08533
Policy Update Magnitude: 0.53610
Value Function Update Magnitude: 0.62203

Collected Steps per Second: 22,902.66345
Overall Steps per Second: 10,694.65584

Timestep Collection Time: 2.18350
Timestep Consumption Time: 2.49248
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.67598

Cumulative Model Updates: 62,526
Cumulative Timesteps: 521,563,414

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605.31366
Policy Entropy: 3.35058
Value Function Loss: 0.00366

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08555
Policy Update Magnitude: 0.52906
Value Function Update Magnitude: 0.64066

Collected Steps per Second: 23,051.57653
Overall Steps per Second: 10,718.26612

Timestep Collection Time: 2.16983
Timestep Consumption Time: 2.49678
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.66661

Cumulative Model Updates: 62,532
Cumulative Timesteps: 521,613,432

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 521613432...
Checkpoint 521613432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 787.14223
Policy Entropy: 3.34397
Value Function Loss: 0.00374

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08751
Policy Update Magnitude: 0.53021
Value Function Update Magnitude: 0.65832

Collected Steps per Second: 22,812.01090
Overall Steps per Second: 10,587.72433

Timestep Collection Time: 2.19253
Timestep Consumption Time: 2.53143
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.72396

Cumulative Model Updates: 62,538
Cumulative Timesteps: 521,663,448

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.97634
Policy Entropy: 3.33089
Value Function Loss: 0.00374

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.12411
Policy Update Magnitude: 0.54040
Value Function Update Magnitude: 0.66301

Collected Steps per Second: 22,673.49304
Overall Steps per Second: 10,602.16135

Timestep Collection Time: 2.20601
Timestep Consumption Time: 2.51171
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.71772

Cumulative Model Updates: 62,544
Cumulative Timesteps: 521,713,466

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 521713466...
Checkpoint 521713466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.30789
Policy Entropy: 3.31963
Value Function Loss: 0.00395

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11732
Policy Update Magnitude: 0.54618
Value Function Update Magnitude: 0.68552

Collected Steps per Second: 22,702.27311
Overall Steps per Second: 10,619.30925

Timestep Collection Time: 2.20322
Timestep Consumption Time: 2.50688
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 4.71010

Cumulative Model Updates: 62,550
Cumulative Timesteps: 521,763,484

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,466.89072
Policy Entropy: 3.31865
Value Function Loss: 0.00379

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10512
Policy Update Magnitude: 0.55071
Value Function Update Magnitude: 0.69341

Collected Steps per Second: 23,005.76570
Overall Steps per Second: 10,788.39365

Timestep Collection Time: 2.17432
Timestep Consumption Time: 2.46232
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.63665

Cumulative Model Updates: 62,556
Cumulative Timesteps: 521,813,506

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 521813506...
Checkpoint 521813506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.19214
Policy Entropy: 3.30282
Value Function Loss: 0.00367

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11104
Policy Update Magnitude: 0.56391
Value Function Update Magnitude: 0.67608

Collected Steps per Second: 21,960.20711
Overall Steps per Second: 10,561.69297

Timestep Collection Time: 2.27739
Timestep Consumption Time: 2.45783
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.73523

Cumulative Model Updates: 62,562
Cumulative Timesteps: 521,863,518

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,801.37802
Policy Entropy: 3.33678
Value Function Loss: 0.00344

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10341
Policy Update Magnitude: 0.55564
Value Function Update Magnitude: 0.63853

Collected Steps per Second: 22,370.38958
Overall Steps per Second: 10,578.77452

Timestep Collection Time: 2.23697
Timestep Consumption Time: 2.49344
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.73042

Cumulative Model Updates: 62,568
Cumulative Timesteps: 521,913,560

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 521913560...
Checkpoint 521913560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,647.36343
Policy Entropy: 3.35071
Value Function Loss: 0.00328

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.53170
Value Function Update Magnitude: 0.61475

Collected Steps per Second: 22,274.76294
Overall Steps per Second: 10,686.51086

Timestep Collection Time: 2.24469
Timestep Consumption Time: 2.43410
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.67880

Cumulative Model Updates: 62,574
Cumulative Timesteps: 521,963,560

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.95501
Policy Entropy: 3.34304
Value Function Loss: 0.00331

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.51849
Value Function Update Magnitude: 0.59620

Collected Steps per Second: 22,476.95182
Overall Steps per Second: 10,541.96405

Timestep Collection Time: 2.22548
Timestep Consumption Time: 2.51956
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.74504

Cumulative Model Updates: 62,580
Cumulative Timesteps: 522,013,582

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 522013582...
Checkpoint 522013582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.19883
Policy Entropy: 3.34099
Value Function Loss: 0.00325

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.52200
Value Function Update Magnitude: 0.60317

Collected Steps per Second: 22,561.26173
Overall Steps per Second: 10,551.14521

Timestep Collection Time: 2.21654
Timestep Consumption Time: 2.52304
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.73958

Cumulative Model Updates: 62,586
Cumulative Timesteps: 522,063,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.54301
Policy Entropy: 3.34558
Value Function Loss: 0.00332

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11473
Policy Update Magnitude: 0.51721
Value Function Update Magnitude: 0.62571

Collected Steps per Second: 23,093.78694
Overall Steps per Second: 10,771.69301

Timestep Collection Time: 2.16526
Timestep Consumption Time: 2.47691
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.64217

Cumulative Model Updates: 62,592
Cumulative Timesteps: 522,113,594

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 522113594...
Checkpoint 522113594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 993.07327
Policy Entropy: 3.36180
Value Function Loss: 0.00314

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11562
Policy Update Magnitude: 0.52250
Value Function Update Magnitude: 0.64297

Collected Steps per Second: 22,775.08591
Overall Steps per Second: 10,647.25765

Timestep Collection Time: 2.19538
Timestep Consumption Time: 2.50066
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.69604

Cumulative Model Updates: 62,598
Cumulative Timesteps: 522,163,594

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.11323
Policy Entropy: 3.35399
Value Function Loss: 0.00344

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10209
Policy Update Magnitude: 0.52318
Value Function Update Magnitude: 0.63340

Collected Steps per Second: 22,960.98460
Overall Steps per Second: 10,664.55127

Timestep Collection Time: 2.17830
Timestep Consumption Time: 2.51163
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.68993

Cumulative Model Updates: 62,604
Cumulative Timesteps: 522,213,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 522213610...
Checkpoint 522213610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.14493
Policy Entropy: 3.34722
Value Function Loss: 0.00342

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.52922
Value Function Update Magnitude: 0.61002

Collected Steps per Second: 22,845.87176
Overall Steps per Second: 10,683.38644

Timestep Collection Time: 2.18937
Timestep Consumption Time: 2.49248
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.68185

Cumulative Model Updates: 62,610
Cumulative Timesteps: 522,263,628

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 937.54189
Policy Entropy: 3.34570
Value Function Loss: 0.00366

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08409
Policy Update Magnitude: 0.54284
Value Function Update Magnitude: 0.61026

Collected Steps per Second: 22,970.65377
Overall Steps per Second: 10,676.24906

Timestep Collection Time: 2.17678
Timestep Consumption Time: 2.50670
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.68348

Cumulative Model Updates: 62,616
Cumulative Timesteps: 522,313,630

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 522313630...
Checkpoint 522313630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.52340
Policy Entropy: 3.35716
Value Function Loss: 0.00351

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.55015
Value Function Update Magnitude: 0.62394

Collected Steps per Second: 22,766.75486
Overall Steps per Second: 10,624.96446

Timestep Collection Time: 2.19645
Timestep Consumption Time: 2.51001
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.70646

Cumulative Model Updates: 62,622
Cumulative Timesteps: 522,363,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.44729
Policy Entropy: 3.34369
Value Function Loss: 0.00357

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09649
Policy Update Magnitude: 0.54746
Value Function Update Magnitude: 0.63574

Collected Steps per Second: 21,625.01426
Overall Steps per Second: 10,402.44733

Timestep Collection Time: 2.31343
Timestep Consumption Time: 2.49582
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.80925

Cumulative Model Updates: 62,628
Cumulative Timesteps: 522,413,664

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 522413664...
Checkpoint 522413664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.01544
Policy Entropy: 3.33954
Value Function Loss: 0.00354

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11406
Policy Update Magnitude: 0.54264
Value Function Update Magnitude: 0.65821

Collected Steps per Second: 21,830.53672
Overall Steps per Second: 10,438.08034

Timestep Collection Time: 2.29156
Timestep Consumption Time: 2.50108
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.79264

Cumulative Model Updates: 62,634
Cumulative Timesteps: 522,463,690

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.72149
Policy Entropy: 3.33088
Value Function Loss: 0.00367

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10546
Policy Update Magnitude: 0.54239
Value Function Update Magnitude: 0.66272

Collected Steps per Second: 22,374.61297
Overall Steps per Second: 10,642.04017

Timestep Collection Time: 2.23485
Timestep Consumption Time: 2.46387
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.69872

Cumulative Model Updates: 62,640
Cumulative Timesteps: 522,513,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 522513694...
Checkpoint 522513694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726.10622
Policy Entropy: 3.35214
Value Function Loss: 0.00371

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10910
Policy Update Magnitude: 0.55168
Value Function Update Magnitude: 0.67790

Collected Steps per Second: 22,003.60260
Overall Steps per Second: 10,526.84256

Timestep Collection Time: 2.27335
Timestep Consumption Time: 2.47850
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.75185

Cumulative Model Updates: 62,646
Cumulative Timesteps: 522,563,716

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.97451
Policy Entropy: 3.36404
Value Function Loss: 0.00365

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11342
Policy Update Magnitude: 0.54698
Value Function Update Magnitude: 0.66978

Collected Steps per Second: 22,640.72276
Overall Steps per Second: 10,643.15028

Timestep Collection Time: 2.20850
Timestep Consumption Time: 2.48955
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.69805

Cumulative Model Updates: 62,652
Cumulative Timesteps: 522,613,718

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 522613718...
Checkpoint 522613718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,284.20042
Policy Entropy: 3.35858
Value Function Loss: 0.00365

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.54525
Value Function Update Magnitude: 0.67145

Collected Steps per Second: 22,282.56136
Overall Steps per Second: 10,635.03338

Timestep Collection Time: 2.24454
Timestep Consumption Time: 2.45822
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.70276

Cumulative Model Updates: 62,658
Cumulative Timesteps: 522,663,732

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.43218
Policy Entropy: 3.37168
Value Function Loss: 0.00363

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09566
Policy Update Magnitude: 0.55222
Value Function Update Magnitude: 0.67465

Collected Steps per Second: 22,926.54391
Overall Steps per Second: 10,537.79467

Timestep Collection Time: 2.18210
Timestep Consumption Time: 2.56538
PPO Batch Consumption Time: 0.29671
Total Iteration Time: 4.74748

Cumulative Model Updates: 62,664
Cumulative Timesteps: 522,713,760

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 522713760...
Checkpoint 522713760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.80547
Policy Entropy: 3.37441
Value Function Loss: 0.00361

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.54853
Value Function Update Magnitude: 0.66614

Collected Steps per Second: 22,716.02506
Overall Steps per Second: 10,535.55174

Timestep Collection Time: 2.20127
Timestep Consumption Time: 2.54495
PPO Batch Consumption Time: 0.29550
Total Iteration Time: 4.74622

Cumulative Model Updates: 62,670
Cumulative Timesteps: 522,763,764

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.67292
Policy Entropy: 3.38547
Value Function Loss: 0.00368

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09029
Policy Update Magnitude: 0.54626
Value Function Update Magnitude: 0.68610

Collected Steps per Second: 22,743.53107
Overall Steps per Second: 10,625.71701

Timestep Collection Time: 2.19957
Timestep Consumption Time: 2.50844
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.70801

Cumulative Model Updates: 62,676
Cumulative Timesteps: 522,813,790

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 522813790...
Checkpoint 522813790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935.40567
Policy Entropy: 3.36371
Value Function Loss: 0.00372

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10464
Policy Update Magnitude: 0.54911
Value Function Update Magnitude: 0.71845

Collected Steps per Second: 22,750.67120
Overall Steps per Second: 10,574.11975

Timestep Collection Time: 2.19906
Timestep Consumption Time: 2.53231
PPO Batch Consumption Time: 0.29719
Total Iteration Time: 4.73136

Cumulative Model Updates: 62,682
Cumulative Timesteps: 522,863,820

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 957.60925
Policy Entropy: 3.35533
Value Function Loss: 0.00374

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10725
Policy Update Magnitude: 0.55218
Value Function Update Magnitude: 0.72205

Collected Steps per Second: 23,098.61291
Overall Steps per Second: 10,761.27695

Timestep Collection Time: 2.16489
Timestep Consumption Time: 2.48195
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.64685

Cumulative Model Updates: 62,688
Cumulative Timesteps: 522,913,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 522913826...
Checkpoint 522913826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 814.54173
Policy Entropy: 3.35348
Value Function Loss: 0.00368

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.54838
Value Function Update Magnitude: 0.71457

Collected Steps per Second: 22,181.45729
Overall Steps per Second: 10,594.93858

Timestep Collection Time: 2.25423
Timestep Consumption Time: 2.46520
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.71942

Cumulative Model Updates: 62,694
Cumulative Timesteps: 522,963,828

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.95832
Policy Entropy: 3.36355
Value Function Loss: 0.00359

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10218
Policy Update Magnitude: 0.54356
Value Function Update Magnitude: 0.70311

Collected Steps per Second: 22,924.22302
Overall Steps per Second: 10,572.01384

Timestep Collection Time: 2.18188
Timestep Consumption Time: 2.54929
PPO Batch Consumption Time: 0.29863
Total Iteration Time: 4.73117

Cumulative Model Updates: 62,700
Cumulative Timesteps: 523,013,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 523013846...
Checkpoint 523013846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,336.72499
Policy Entropy: 3.36679
Value Function Loss: 0.00335

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08036
Policy Update Magnitude: 0.53622
Value Function Update Magnitude: 0.69165

Collected Steps per Second: 21,987.67046
Overall Steps per Second: 10,565.63849

Timestep Collection Time: 2.27491
Timestep Consumption Time: 2.45930
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.73421

Cumulative Model Updates: 62,706
Cumulative Timesteps: 523,063,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.84513
Policy Entropy: 3.36883
Value Function Loss: 0.00329

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07363
Policy Update Magnitude: 0.53549
Value Function Update Magnitude: 0.70125

Collected Steps per Second: 22,428.51276
Overall Steps per Second: 10,493.89586

Timestep Collection Time: 2.22993
Timestep Consumption Time: 2.53608
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.76601

Cumulative Model Updates: 62,712
Cumulative Timesteps: 523,113,880

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 523113880...
Checkpoint 523113880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,732.83221
Policy Entropy: 3.36832
Value Function Loss: 0.00338

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.53308
Value Function Update Magnitude: 0.68147

Collected Steps per Second: 21,460.72802
Overall Steps per Second: 10,636.30471

Timestep Collection Time: 2.33105
Timestep Consumption Time: 2.37228
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.70333

Cumulative Model Updates: 62,718
Cumulative Timesteps: 523,163,906

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.52093
Policy Entropy: 3.35560
Value Function Loss: 0.00358

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.53464
Value Function Update Magnitude: 0.67739

Collected Steps per Second: 22,378.02353
Overall Steps per Second: 10,472.37517

Timestep Collection Time: 2.23550
Timestep Consumption Time: 2.54145
PPO Batch Consumption Time: 0.29665
Total Iteration Time: 4.77695

Cumulative Model Updates: 62,724
Cumulative Timesteps: 523,213,932

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 523213932...
Checkpoint 523213932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679.85414
Policy Entropy: 3.35563
Value Function Loss: 0.00355

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.11866
Policy Update Magnitude: 0.53492
Value Function Update Magnitude: 0.67100

Collected Steps per Second: 21,706.36771
Overall Steps per Second: 10,669.83452

Timestep Collection Time: 2.30412
Timestep Consumption Time: 2.38330
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.68742

Cumulative Model Updates: 62,730
Cumulative Timesteps: 523,263,946

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 952.02207
Policy Entropy: 3.35870
Value Function Loss: 0.00333

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12023
Policy Update Magnitude: 0.53095
Value Function Update Magnitude: 0.64312

Collected Steps per Second: 21,889.07075
Overall Steps per Second: 10,519.54416

Timestep Collection Time: 2.28479
Timestep Consumption Time: 2.46941
PPO Batch Consumption Time: 0.29588
Total Iteration Time: 4.75420

Cumulative Model Updates: 62,736
Cumulative Timesteps: 523,313,958

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 523313958...
Checkpoint 523313958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.26205
Policy Entropy: 3.38904
Value Function Loss: 0.00313

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.12278
Policy Update Magnitude: 0.52072
Value Function Update Magnitude: 0.61467

Collected Steps per Second: 22,098.57170
Overall Steps per Second: 10,574.01972

Timestep Collection Time: 2.26340
Timestep Consumption Time: 2.46687
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.73027

Cumulative Model Updates: 62,742
Cumulative Timesteps: 523,363,976

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,429.06480
Policy Entropy: 3.38927
Value Function Loss: 0.00309

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10446
Policy Update Magnitude: 0.50587
Value Function Update Magnitude: 0.59168

Collected Steps per Second: 22,044.85835
Overall Steps per Second: 10,640.86063

Timestep Collection Time: 2.26819
Timestep Consumption Time: 2.43086
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.69906

Cumulative Model Updates: 62,748
Cumulative Timesteps: 523,413,978

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 523413978...
Checkpoint 523413978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 835.11044
Policy Entropy: 3.39575
Value Function Loss: 0.00342

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09136
Policy Update Magnitude: 0.51617
Value Function Update Magnitude: 0.59486

Collected Steps per Second: 21,824.94963
Overall Steps per Second: 10,565.87759

Timestep Collection Time: 2.29160
Timestep Consumption Time: 2.44194
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.73354

Cumulative Model Updates: 62,754
Cumulative Timesteps: 523,463,992

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.26678
Policy Entropy: 3.39269
Value Function Loss: 0.00346

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08565
Policy Update Magnitude: 0.52208
Value Function Update Magnitude: 0.59933

Collected Steps per Second: 22,505.29591
Overall Steps per Second: 10,790.95835

Timestep Collection Time: 2.22223
Timestep Consumption Time: 2.41239
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.63462

Cumulative Model Updates: 62,760
Cumulative Timesteps: 523,514,004

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 523514004...
Checkpoint 523514004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.28981
Policy Entropy: 3.39752
Value Function Loss: 0.00352

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08001
Policy Update Magnitude: 0.53166
Value Function Update Magnitude: 0.59856

Collected Steps per Second: 21,959.84623
Overall Steps per Second: 10,632.30310

Timestep Collection Time: 2.27716
Timestep Consumption Time: 2.42606
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.70321

Cumulative Model Updates: 62,766
Cumulative Timesteps: 523,564,010

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 751.59045
Policy Entropy: 3.38589
Value Function Loss: 0.00339

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07413
Policy Update Magnitude: 0.53242
Value Function Update Magnitude: 0.60479

Collected Steps per Second: 22,344.41079
Overall Steps per Second: 10,671.10746

Timestep Collection Time: 2.23814
Timestep Consumption Time: 2.44834
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.68649

Cumulative Model Updates: 62,772
Cumulative Timesteps: 523,614,020

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 523614020...
Checkpoint 523614020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.03666
Policy Entropy: 3.39129
Value Function Loss: 0.00339

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07426
Policy Update Magnitude: 0.52618
Value Function Update Magnitude: 0.59806

Collected Steps per Second: 21,482.13132
Overall Steps per Second: 10,484.88780

Timestep Collection Time: 2.32798
Timestep Consumption Time: 2.44174
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.76972

Cumulative Model Updates: 62,778
Cumulative Timesteps: 523,664,030

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 856.39903
Policy Entropy: 3.38978
Value Function Loss: 0.00349

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08122
Policy Update Magnitude: 0.52663
Value Function Update Magnitude: 0.60951

Collected Steps per Second: 22,509.11409
Overall Steps per Second: 10,588.50237

Timestep Collection Time: 2.22194
Timestep Consumption Time: 2.50148
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.72343

Cumulative Model Updates: 62,784
Cumulative Timesteps: 523,714,044

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 523714044...
Checkpoint 523714044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 894.95571
Policy Entropy: 3.38568
Value Function Loss: 0.00349

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07961
Policy Update Magnitude: 0.52987
Value Function Update Magnitude: 0.62065

Collected Steps per Second: 22,494.75290
Overall Steps per Second: 10,546.46171

Timestep Collection Time: 2.22390
Timestep Consumption Time: 2.51950
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.74339

Cumulative Model Updates: 62,790
Cumulative Timesteps: 523,764,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.69123
Policy Entropy: 3.37423
Value Function Loss: 0.00351

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07450
Policy Update Magnitude: 0.53404
Value Function Update Magnitude: 0.61794

Collected Steps per Second: 22,061.54510
Overall Steps per Second: 10,706.13447

Timestep Collection Time: 2.26648
Timestep Consumption Time: 2.40393
PPO Batch Consumption Time: 0.28470
Total Iteration Time: 4.67041

Cumulative Model Updates: 62,796
Cumulative Timesteps: 523,814,072

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 523814072...
Checkpoint 523814072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.14229
Policy Entropy: 3.38583
Value Function Loss: 0.00335

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07025
Policy Update Magnitude: 0.53907
Value Function Update Magnitude: 0.64230

Collected Steps per Second: 22,812.11456
Overall Steps per Second: 10,663.86301

Timestep Collection Time: 2.19199
Timestep Consumption Time: 2.49711
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.68911

Cumulative Model Updates: 62,802
Cumulative Timesteps: 523,864,076

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 911.20190
Policy Entropy: 3.38062
Value Function Loss: 0.00337

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.06841
Policy Update Magnitude: 0.54082
Value Function Update Magnitude: 0.64554

Collected Steps per Second: 21,896.39979
Overall Steps per Second: 10,415.94514

Timestep Collection Time: 2.28485
Timestep Consumption Time: 2.51836
PPO Batch Consumption Time: 0.29904
Total Iteration Time: 4.80321

Cumulative Model Updates: 62,808
Cumulative Timesteps: 523,914,106

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 523914106...
Checkpoint 523914106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 884.70177
Policy Entropy: 3.37576
Value Function Loss: 0.00337

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07249
Policy Update Magnitude: 0.53731
Value Function Update Magnitude: 0.61703

Collected Steps per Second: 20,115.79288
Overall Steps per Second: 10,211.96899

Timestep Collection Time: 2.48680
Timestep Consumption Time: 2.41176
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.89857

Cumulative Model Updates: 62,814
Cumulative Timesteps: 523,964,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.65494
Policy Entropy: 3.36968
Value Function Loss: 0.00339

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07216
Policy Update Magnitude: 0.53566
Value Function Update Magnitude: 0.62649

Collected Steps per Second: 20,906.34449
Overall Steps per Second: 10,247.07807

Timestep Collection Time: 2.39267
Timestep Consumption Time: 2.48892
PPO Batch Consumption Time: 0.29588
Total Iteration Time: 4.88159

Cumulative Model Updates: 62,820
Cumulative Timesteps: 524,014,152

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 524014152...
Checkpoint 524014152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.41287
Policy Entropy: 3.38262
Value Function Loss: 0.00341

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08147
Policy Update Magnitude: 0.53361
Value Function Update Magnitude: 0.62638

Collected Steps per Second: 22,069.23451
Overall Steps per Second: 10,600.51096

Timestep Collection Time: 2.26641
Timestep Consumption Time: 2.45204
PPO Batch Consumption Time: 0.29713
Total Iteration Time: 4.71845

Cumulative Model Updates: 62,826
Cumulative Timesteps: 524,064,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700.81991
Policy Entropy: 3.39102
Value Function Loss: 0.00337

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07214
Policy Update Magnitude: 0.53314
Value Function Update Magnitude: 0.62885

Collected Steps per Second: 22,433.96401
Overall Steps per Second: 10,872.29427

Timestep Collection Time: 2.22983
Timestep Consumption Time: 2.37122
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.60105

Cumulative Model Updates: 62,832
Cumulative Timesteps: 524,114,194

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 524114194...
Checkpoint 524114194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,401.70964
Policy Entropy: 3.38155
Value Function Loss: 0.00346

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08258
Policy Update Magnitude: 0.53905
Value Function Update Magnitude: 0.62233

Collected Steps per Second: 21,911.92306
Overall Steps per Second: 10,623.63607

Timestep Collection Time: 2.28259
Timestep Consumption Time: 2.42540
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.70799

Cumulative Model Updates: 62,838
Cumulative Timesteps: 524,164,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360.53574
Policy Entropy: 3.38630
Value Function Loss: 0.00346

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08587
Policy Update Magnitude: 0.53773
Value Function Update Magnitude: 0.62451

Collected Steps per Second: 22,110.92658
Overall Steps per Second: 10,640.24613

Timestep Collection Time: 2.26268
Timestep Consumption Time: 2.43928
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.70196

Cumulative Model Updates: 62,844
Cumulative Timesteps: 524,214,240

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 524214240...
Checkpoint 524214240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,869.30032
Policy Entropy: 3.37132
Value Function Loss: 0.00349

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.53695
Value Function Update Magnitude: 0.63029

Collected Steps per Second: 21,722.90985
Overall Steps per Second: 10,575.10367

Timestep Collection Time: 2.30236
Timestep Consumption Time: 2.42705
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.72941

Cumulative Model Updates: 62,850
Cumulative Timesteps: 524,264,254

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 884.22108
Policy Entropy: 3.36947
Value Function Loss: 0.00349

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09284
Policy Update Magnitude: 0.53658
Value Function Update Magnitude: 0.63667

Collected Steps per Second: 21,994.63736
Overall Steps per Second: 10,740.09985

Timestep Collection Time: 2.27328
Timestep Consumption Time: 2.38217
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.65545

Cumulative Model Updates: 62,856
Cumulative Timesteps: 524,314,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 524314254...
Checkpoint 524314254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485.57636
Policy Entropy: 3.34842
Value Function Loss: 0.00359

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09690
Policy Update Magnitude: 0.54366
Value Function Update Magnitude: 0.63761

Collected Steps per Second: 22,302.00407
Overall Steps per Second: 10,653.25679

Timestep Collection Time: 2.24312
Timestep Consumption Time: 2.45272
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.69584

Cumulative Model Updates: 62,862
Cumulative Timesteps: 524,364,280

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.72867
Policy Entropy: 3.35482
Value Function Loss: 0.00357

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.11036
Policy Update Magnitude: 0.53937
Value Function Update Magnitude: 0.64116

Collected Steps per Second: 22,325.32482
Overall Steps per Second: 10,484.23733

Timestep Collection Time: 2.24059
Timestep Consumption Time: 2.53057
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.77116

Cumulative Model Updates: 62,868
Cumulative Timesteps: 524,414,302

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 524414302...
Checkpoint 524414302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 786.33421
Policy Entropy: 3.35622
Value Function Loss: 0.00350

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.53359
Value Function Update Magnitude: 0.62626

Collected Steps per Second: 22,524.01022
Overall Steps per Second: 10,680.23721

Timestep Collection Time: 2.22092
Timestep Consumption Time: 2.46287
PPO Batch Consumption Time: 0.28142
Total Iteration Time: 4.68379

Cumulative Model Updates: 62,874
Cumulative Timesteps: 524,464,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,521.35836
Policy Entropy: 3.36476
Value Function Loss: 0.00337

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08091
Policy Update Magnitude: 0.53713
Value Function Update Magnitude: 0.59586

Collected Steps per Second: 21,889.07275
Overall Steps per Second: 10,532.96269

Timestep Collection Time: 2.28507
Timestep Consumption Time: 2.46364
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.74871

Cumulative Model Updates: 62,880
Cumulative Timesteps: 524,514,344

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 524514344...
Checkpoint 524514344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,501.18002
Policy Entropy: 3.37187
Value Function Loss: 0.00329

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.53001
Value Function Update Magnitude: 0.58782

Collected Steps per Second: 22,728.32401
Overall Steps per Second: 10,604.59326

Timestep Collection Time: 2.20078
Timestep Consumption Time: 2.51605
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.71682

Cumulative Model Updates: 62,886
Cumulative Timesteps: 524,564,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.99237
Policy Entropy: 3.36248
Value Function Loss: 0.00356

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07549
Policy Update Magnitude: 0.52815
Value Function Update Magnitude: 0.59647

Collected Steps per Second: 21,995.38205
Overall Steps per Second: 10,746.32804

Timestep Collection Time: 2.27439
Timestep Consumption Time: 2.38079
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.65517

Cumulative Model Updates: 62,892
Cumulative Timesteps: 524,614,390

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 524614390...
Checkpoint 524614390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.55508
Policy Entropy: 3.34801
Value Function Loss: 0.00366

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08780
Policy Update Magnitude: 0.53646
Value Function Update Magnitude: 0.60885

Collected Steps per Second: 22,433.32699
Overall Steps per Second: 10,651.90752

Timestep Collection Time: 2.22936
Timestep Consumption Time: 2.46576
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.69512

Cumulative Model Updates: 62,898
Cumulative Timesteps: 524,664,402

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 826.16239
Policy Entropy: 3.33843
Value Function Loss: 0.00381

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09306
Policy Update Magnitude: 0.54616
Value Function Update Magnitude: 0.63254

Collected Steps per Second: 22,995.88275
Overall Steps per Second: 10,634.56875

Timestep Collection Time: 2.17482
Timestep Consumption Time: 2.52795
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.70278

Cumulative Model Updates: 62,904
Cumulative Timesteps: 524,714,414

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 524714414...
Checkpoint 524714414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.88009
Policy Entropy: 3.33532
Value Function Loss: 0.00359

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08531
Policy Update Magnitude: 0.54794
Value Function Update Magnitude: 0.63838

Collected Steps per Second: 21,931.81454
Overall Steps per Second: 10,574.52897

Timestep Collection Time: 2.28007
Timestep Consumption Time: 2.44884
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 4.72891

Cumulative Model Updates: 62,910
Cumulative Timesteps: 524,764,420

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 884.84539
Policy Entropy: 3.34095
Value Function Loss: 0.00367

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.54688
Value Function Update Magnitude: 0.63816

Collected Steps per Second: 22,267.36785
Overall Steps per Second: 10,498.06439

Timestep Collection Time: 2.24661
Timestep Consumption Time: 2.51865
PPO Batch Consumption Time: 0.29600
Total Iteration Time: 4.76526

Cumulative Model Updates: 62,916
Cumulative Timesteps: 524,814,446

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 524814446...
Checkpoint 524814446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 793.12991
Policy Entropy: 3.34494
Value Function Loss: 0.00354

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09909
Policy Update Magnitude: 0.54534
Value Function Update Magnitude: 0.63270

Collected Steps per Second: 21,890.06304
Overall Steps per Second: 10,589.31008

Timestep Collection Time: 2.28423
Timestep Consumption Time: 2.43770
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.72193

Cumulative Model Updates: 62,922
Cumulative Timesteps: 524,864,448

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.70147
Policy Entropy: 3.34303
Value Function Loss: 0.00342

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08450
Policy Update Magnitude: 0.54472
Value Function Update Magnitude: 0.62926

Collected Steps per Second: 22,497.16964
Overall Steps per Second: 10,542.97257

Timestep Collection Time: 2.22312
Timestep Consumption Time: 2.52070
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.74382

Cumulative Model Updates: 62,928
Cumulative Timesteps: 524,914,462

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 524914462...
Checkpoint 524914462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 987.55716
Policy Entropy: 3.32929
Value Function Loss: 0.00352

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10049
Policy Update Magnitude: 0.54119
Value Function Update Magnitude: 0.61886

Collected Steps per Second: 22,600.63186
Overall Steps per Second: 10,546.56884

Timestep Collection Time: 2.21268
Timestep Consumption Time: 2.52896
PPO Batch Consumption Time: 0.29766
Total Iteration Time: 4.74164

Cumulative Model Updates: 62,934
Cumulative Timesteps: 524,964,470

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 913.34780
Policy Entropy: 3.32183
Value Function Loss: 0.00349

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09798
Policy Update Magnitude: 0.53836
Value Function Update Magnitude: 0.62010

Collected Steps per Second: 22,492.25216
Overall Steps per Second: 10,460.20598

Timestep Collection Time: 2.22388
Timestep Consumption Time: 2.55806
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.78193

Cumulative Model Updates: 62,940
Cumulative Timesteps: 525,014,490

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 525014490...
Checkpoint 525014490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.75072
Policy Entropy: 3.31453
Value Function Loss: 0.00372

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08229
Policy Update Magnitude: 0.54571
Value Function Update Magnitude: 0.60114

Collected Steps per Second: 22,786.91421
Overall Steps per Second: 10,718.17606

Timestep Collection Time: 2.19573
Timestep Consumption Time: 2.47241
PPO Batch Consumption Time: 0.28183
Total Iteration Time: 4.66814

Cumulative Model Updates: 62,946
Cumulative Timesteps: 525,064,524

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 924.43244
Policy Entropy: 3.29602
Value Function Loss: 0.00377

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09841
Policy Update Magnitude: 0.55251
Value Function Update Magnitude: 0.63985

Collected Steps per Second: 22,594.93711
Overall Steps per Second: 10,508.97744

Timestep Collection Time: 2.21395
Timestep Consumption Time: 2.54617
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.76012

Cumulative Model Updates: 62,952
Cumulative Timesteps: 525,114,548

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 525114548...
Checkpoint 525114548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 802.43853
Policy Entropy: 3.29248
Value Function Loss: 0.00360

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09802
Policy Update Magnitude: 0.55359
Value Function Update Magnitude: 0.66560

Collected Steps per Second: 23,091.46908
Overall Steps per Second: 10,761.76982

Timestep Collection Time: 2.16660
Timestep Consumption Time: 2.48226
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.64886

Cumulative Model Updates: 62,958
Cumulative Timesteps: 525,164,578

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.76381
Policy Entropy: 3.29145
Value Function Loss: 0.00362

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09177
Policy Update Magnitude: 0.54803
Value Function Update Magnitude: 0.64543

Collected Steps per Second: 23,050.97252
Overall Steps per Second: 10,702.37246

Timestep Collection Time: 2.16954
Timestep Consumption Time: 2.50326
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.67280

Cumulative Model Updates: 62,964
Cumulative Timesteps: 525,214,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 525214588...
Checkpoint 525214588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.61934
Policy Entropy: 3.31189
Value Function Loss: 0.00361

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10009
Policy Update Magnitude: 0.55067
Value Function Update Magnitude: 0.63444

Collected Steps per Second: 22,776.52225
Overall Steps per Second: 10,655.29761

Timestep Collection Time: 2.19656
Timestep Consumption Time: 2.49876
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.69532

Cumulative Model Updates: 62,970
Cumulative Timesteps: 525,264,618

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.77240
Policy Entropy: 3.31456
Value Function Loss: 0.00370

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10635
Policy Update Magnitude: 0.56015
Value Function Update Magnitude: 0.64872

Collected Steps per Second: 23,058.08949
Overall Steps per Second: 10,815.07806

Timestep Collection Time: 2.16896
Timestep Consumption Time: 2.45533
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.62428

Cumulative Model Updates: 62,976
Cumulative Timesteps: 525,314,630

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 525314630...
Checkpoint 525314630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 785.48248
Policy Entropy: 3.31813
Value Function Loss: 0.00360

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10965
Policy Update Magnitude: 0.55573
Value Function Update Magnitude: 0.65524

Collected Steps per Second: 22,588.43264
Overall Steps per Second: 10,779.46885

Timestep Collection Time: 2.21476
Timestep Consumption Time: 2.42628
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.64105

Cumulative Model Updates: 62,982
Cumulative Timesteps: 525,364,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 852.04882
Policy Entropy: 3.33057
Value Function Loss: 0.00364

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11409
Policy Update Magnitude: 0.54550
Value Function Update Magnitude: 0.65429

Collected Steps per Second: 22,232.82184
Overall Steps per Second: 10,461.86432

Timestep Collection Time: 2.24893
Timestep Consumption Time: 2.53034
PPO Batch Consumption Time: 0.29733
Total Iteration Time: 4.77926

Cumulative Model Updates: 62,988
Cumulative Timesteps: 525,414,658

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 525414658...
Checkpoint 525414658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.68995
Policy Entropy: 3.35316
Value Function Loss: 0.00347

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09647
Policy Update Magnitude: 0.54118
Value Function Update Magnitude: 0.64808

Collected Steps per Second: 22,268.54267
Overall Steps per Second: 10,558.01452

Timestep Collection Time: 2.24595
Timestep Consumption Time: 2.49112
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.73706

Cumulative Model Updates: 62,994
Cumulative Timesteps: 525,464,672

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,670.32670
Policy Entropy: 3.34477
Value Function Loss: 0.00345

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08928
Policy Update Magnitude: 0.54202
Value Function Update Magnitude: 0.64406

Collected Steps per Second: 22,386.62287
Overall Steps per Second: 10,511.62684

Timestep Collection Time: 2.23491
Timestep Consumption Time: 2.52478
PPO Batch Consumption Time: 0.29681
Total Iteration Time: 4.75968

Cumulative Model Updates: 63,000
Cumulative Timesteps: 525,514,704

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 525514704...
Checkpoint 525514704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723.97888
Policy Entropy: 3.34726
Value Function Loss: 0.00341

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08254
Policy Update Magnitude: 0.54381
Value Function Update Magnitude: 0.65109

Collected Steps per Second: 22,459.75586
Overall Steps per Second: 10,615.70292

Timestep Collection Time: 2.22736
Timestep Consumption Time: 2.48509
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.71245

Cumulative Model Updates: 63,006
Cumulative Timesteps: 525,564,730

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 999.69618
Policy Entropy: 3.32508
Value Function Loss: 0.00352

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.54358
Value Function Update Magnitude: 0.65279

Collected Steps per Second: 22,405.84685
Overall Steps per Second: 10,510.52781

Timestep Collection Time: 2.23174
Timestep Consumption Time: 2.52578
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.75752

Cumulative Model Updates: 63,012
Cumulative Timesteps: 525,614,734

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 525614734...
Checkpoint 525614734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.93465
Policy Entropy: 3.34590
Value Function Loss: 0.00358

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09207
Policy Update Magnitude: 0.54774
Value Function Update Magnitude: 0.68457

Collected Steps per Second: 21,948.92387
Overall Steps per Second: 10,559.69307

Timestep Collection Time: 2.27929
Timestep Consumption Time: 2.45835
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.73764

Cumulative Model Updates: 63,018
Cumulative Timesteps: 525,664,762

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696.44302
Policy Entropy: 3.32580
Value Function Loss: 0.00377

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.07993
Policy Update Magnitude: 0.56611
Value Function Update Magnitude: 0.69803

Collected Steps per Second: 22,699.06121
Overall Steps per Second: 10,617.76715

Timestep Collection Time: 2.20397
Timestep Consumption Time: 2.50776
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.71173

Cumulative Model Updates: 63,024
Cumulative Timesteps: 525,714,790

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 525714790...
Checkpoint 525714790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.49852
Policy Entropy: 3.33255
Value Function Loss: 0.00371

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.57130
Value Function Update Magnitude: 0.69614

Collected Steps per Second: 22,884.28566
Overall Steps per Second: 10,711.02112

Timestep Collection Time: 2.18560
Timestep Consumption Time: 2.48398
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.66958

Cumulative Model Updates: 63,030
Cumulative Timesteps: 525,764,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 912.93275
Policy Entropy: 3.32544
Value Function Loss: 0.00360

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08849
Policy Update Magnitude: 0.57135
Value Function Update Magnitude: 0.67615

Collected Steps per Second: 22,973.98360
Overall Steps per Second: 10,695.86001

Timestep Collection Time: 2.17646
Timestep Consumption Time: 2.49843
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.67489

Cumulative Model Updates: 63,036
Cumulative Timesteps: 525,814,808

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 525814808...
Checkpoint 525814808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.52369
Policy Entropy: 3.33481
Value Function Loss: 0.00345

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10174
Policy Update Magnitude: 0.55817
Value Function Update Magnitude: 0.65408

Collected Steps per Second: 22,216.15102
Overall Steps per Second: 10,616.43352

Timestep Collection Time: 2.25107
Timestep Consumption Time: 2.45956
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 4.71062

Cumulative Model Updates: 63,042
Cumulative Timesteps: 525,864,818

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.82674
Policy Entropy: 3.32682
Value Function Loss: 0.00349

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11055
Policy Update Magnitude: 0.54881
Value Function Update Magnitude: 0.63151

Collected Steps per Second: 22,800.85569
Overall Steps per Second: 10,658.60836

Timestep Collection Time: 2.19369
Timestep Consumption Time: 2.49904
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.69273

Cumulative Model Updates: 63,048
Cumulative Timesteps: 525,914,836

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 525914836...
Checkpoint 525914836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,664.51570
Policy Entropy: 3.31961
Value Function Loss: 0.00343

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.54048
Value Function Update Magnitude: 0.62439

Collected Steps per Second: 21,525.81107
Overall Steps per Second: 10,544.15588

Timestep Collection Time: 2.32400
Timestep Consumption Time: 2.42043
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.74443

Cumulative Model Updates: 63,054
Cumulative Timesteps: 525,964,862

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,506.02490
Policy Entropy: 3.31543
Value Function Loss: 0.00341

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.11051
Policy Update Magnitude: 0.53351
Value Function Update Magnitude: 0.61333

Collected Steps per Second: 21,434.22083
Overall Steps per Second: 10,450.37580

Timestep Collection Time: 2.33337
Timestep Consumption Time: 2.45249
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.78586

Cumulative Model Updates: 63,060
Cumulative Timesteps: 526,014,876

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 526014876...
Checkpoint 526014876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 760.88597
Policy Entropy: 3.32232
Value Function Loss: 0.00351

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11714
Policy Update Magnitude: 0.53333
Value Function Update Magnitude: 0.59913

Collected Steps per Second: 21,715.15421
Overall Steps per Second: 10,542.55747

Timestep Collection Time: 2.30337
Timestep Consumption Time: 2.44102
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.74439

Cumulative Model Updates: 63,066
Cumulative Timesteps: 526,064,894

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 984.96673
Policy Entropy: 3.30672
Value Function Loss: 0.00364

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.54237
Value Function Update Magnitude: 0.62236

Collected Steps per Second: 21,814.54514
Overall Steps per Second: 10,567.21600

Timestep Collection Time: 2.29260
Timestep Consumption Time: 2.44015
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.73275

Cumulative Model Updates: 63,072
Cumulative Timesteps: 526,114,906

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 526114906...
Checkpoint 526114906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.07387
Policy Entropy: 3.28914
Value Function Loss: 0.00367

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.13128
Policy Update Magnitude: 0.54759
Value Function Update Magnitude: 0.63020

Collected Steps per Second: 21,930.37448
Overall Steps per Second: 10,571.50587

Timestep Collection Time: 2.28104
Timestep Consumption Time: 2.45093
PPO Batch Consumption Time: 0.29668
Total Iteration Time: 4.73197

Cumulative Model Updates: 63,078
Cumulative Timesteps: 526,164,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694.41992
Policy Entropy: 3.31099
Value Function Loss: 0.00371

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.12180
Policy Update Magnitude: 0.55152
Value Function Update Magnitude: 0.62399

Collected Steps per Second: 23,033.12651
Overall Steps per Second: 10,762.32458

Timestep Collection Time: 2.17218
Timestep Consumption Time: 2.47663
PPO Batch Consumption Time: 0.28191
Total Iteration Time: 4.64881

Cumulative Model Updates: 63,084
Cumulative Timesteps: 526,214,962

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 526214962...
Checkpoint 526214962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.19949
Policy Entropy: 3.32450
Value Function Loss: 0.00366

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11347
Policy Update Magnitude: 0.54846
Value Function Update Magnitude: 0.62323

Collected Steps per Second: 22,914.07748
Overall Steps per Second: 10,714.58954

Timestep Collection Time: 2.18215
Timestep Consumption Time: 2.48457
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.66672

Cumulative Model Updates: 63,090
Cumulative Timesteps: 526,264,964

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 854.06790
Policy Entropy: 3.32313
Value Function Loss: 0.00357

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09890
Policy Update Magnitude: 0.54297
Value Function Update Magnitude: 0.60013

Collected Steps per Second: 22,150.05020
Overall Steps per Second: 10,703.70985

Timestep Collection Time: 2.25769
Timestep Consumption Time: 2.41433
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.67202

Cumulative Model Updates: 63,096
Cumulative Timesteps: 526,314,972

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 526314972...
Checkpoint 526314972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.77427
Policy Entropy: 3.30046
Value Function Loss: 0.00368

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.54018
Value Function Update Magnitude: 0.57776

Collected Steps per Second: 22,231.04054
Overall Steps per Second: 10,770.29829

Timestep Collection Time: 2.25037
Timestep Consumption Time: 2.39463
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.64500

Cumulative Model Updates: 63,102
Cumulative Timesteps: 526,365,000

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 949.22905
Policy Entropy: 3.29849
Value Function Loss: 0.00372

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08936
Policy Update Magnitude: 0.54425
Value Function Update Magnitude: 0.57396

Collected Steps per Second: 21,808.69924
Overall Steps per Second: 10,466.29303

Timestep Collection Time: 2.29266
Timestep Consumption Time: 2.48458
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.77724

Cumulative Model Updates: 63,108
Cumulative Timesteps: 526,415,000

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 526415000...
Checkpoint 526415000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220.20753
Policy Entropy: 3.32670
Value Function Loss: 0.00357

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09102
Policy Update Magnitude: 0.53910
Value Function Update Magnitude: 0.59595

Collected Steps per Second: 21,903.03333
Overall Steps per Second: 10,747.50246

Timestep Collection Time: 2.28407
Timestep Consumption Time: 2.37078
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.65485

Cumulative Model Updates: 63,114
Cumulative Timesteps: 526,465,028

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.39424
Policy Entropy: 3.30324
Value Function Loss: 0.00363

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07633
Policy Update Magnitude: 0.54286
Value Function Update Magnitude: 0.58379

Collected Steps per Second: 22,510.52987
Overall Steps per Second: 10,576.68365

Timestep Collection Time: 2.22189
Timestep Consumption Time: 2.50700
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.72889

Cumulative Model Updates: 63,120
Cumulative Timesteps: 526,515,044

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 526515044...
Checkpoint 526515044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.30910
Policy Entropy: 3.31775
Value Function Loss: 0.00350

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07863
Policy Update Magnitude: 0.54022
Value Function Update Magnitude: 0.58030

Collected Steps per Second: 21,798.15133
Overall Steps per Second: 10,576.28844

Timestep Collection Time: 2.29414
Timestep Consumption Time: 2.43417
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.72831

Cumulative Model Updates: 63,126
Cumulative Timesteps: 526,565,052

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 787.60082
Policy Entropy: 3.30892
Value Function Loss: 0.00368

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08887
Policy Update Magnitude: 0.53761
Value Function Update Magnitude: 0.59235

Collected Steps per Second: 22,432.78373
Overall Steps per Second: 10,575.61153

Timestep Collection Time: 2.22959
Timestep Consumption Time: 2.49978
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.72937

Cumulative Model Updates: 63,132
Cumulative Timesteps: 526,615,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 526615068...
Checkpoint 526615068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 793.31992
Policy Entropy: 3.32938
Value Function Loss: 0.00354

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08799
Policy Update Magnitude: 0.54275
Value Function Update Magnitude: 0.60416

Collected Steps per Second: 22,714.14203
Overall Steps per Second: 10,578.83225

Timestep Collection Time: 2.20268
Timestep Consumption Time: 2.52676
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.72944

Cumulative Model Updates: 63,138
Cumulative Timesteps: 526,665,100

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 803.20424
Policy Entropy: 3.33013
Value Function Loss: 0.00356

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.09964
Policy Update Magnitude: 0.54049
Value Function Update Magnitude: 0.59614

Collected Steps per Second: 22,202.36962
Overall Steps per Second: 10,684.98352

Timestep Collection Time: 2.25327
Timestep Consumption Time: 2.42881
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.68208

Cumulative Model Updates: 63,144
Cumulative Timesteps: 526,715,128

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 526715128...
Checkpoint 526715128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.66932
Policy Entropy: 3.34131
Value Function Loss: 0.00366

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09126
Policy Update Magnitude: 0.53821
Value Function Update Magnitude: 0.61014

Collected Steps per Second: 22,748.01207
Overall Steps per Second: 10,688.19276

Timestep Collection Time: 2.19861
Timestep Consumption Time: 2.48076
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.67937

Cumulative Model Updates: 63,150
Cumulative Timesteps: 526,765,142

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.02377
Policy Entropy: 3.33514
Value Function Loss: 0.00365

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08658
Policy Update Magnitude: 0.53422
Value Function Update Magnitude: 0.62790

Collected Steps per Second: 22,177.74494
Overall Steps per Second: 10,697.26898

Timestep Collection Time: 2.25523
Timestep Consumption Time: 2.42035
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.67559

Cumulative Model Updates: 63,156
Cumulative Timesteps: 526,815,158

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 526815158...
Checkpoint 526815158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.93489
Policy Entropy: 3.34094
Value Function Loss: 0.00365

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08577
Policy Update Magnitude: 0.53126
Value Function Update Magnitude: 0.62098

Collected Steps per Second: 22,226.74192
Overall Steps per Second: 10,783.79572

Timestep Collection Time: 2.24990
Timestep Consumption Time: 2.38743
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.63733

Cumulative Model Updates: 63,162
Cumulative Timesteps: 526,865,166

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,394.04883
Policy Entropy: 3.34191
Value Function Loss: 0.00362

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08891
Policy Update Magnitude: 0.52566
Value Function Update Magnitude: 0.60086

Collected Steps per Second: 22,272.23669
Overall Steps per Second: 10,689.15372

Timestep Collection Time: 2.24522
Timestep Consumption Time: 2.43298
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.67820

Cumulative Model Updates: 63,168
Cumulative Timesteps: 526,915,172

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 526915172...
Checkpoint 526915172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.03869
Policy Entropy: 3.35566
Value Function Loss: 0.00355

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08643
Policy Update Magnitude: 0.52804
Value Function Update Magnitude: 0.59824

Collected Steps per Second: 21,984.72231
Overall Steps per Second: 10,618.74591

Timestep Collection Time: 2.27576
Timestep Consumption Time: 2.43591
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.71167

Cumulative Model Updates: 63,174
Cumulative Timesteps: 526,965,204

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.64162
Policy Entropy: 3.35469
Value Function Loss: 0.00354

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07505
Policy Update Magnitude: 0.54107
Value Function Update Magnitude: 0.60652

Collected Steps per Second: 21,708.18076
Overall Steps per Second: 10,668.40422

Timestep Collection Time: 2.30374
Timestep Consumption Time: 2.38393
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.68767

Cumulative Model Updates: 63,180
Cumulative Timesteps: 527,015,214

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 527015214...
Checkpoint 527015214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,506.41429
Policy Entropy: 3.34292
Value Function Loss: 0.00365

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07514
Policy Update Magnitude: 0.54259
Value Function Update Magnitude: 0.61752

Collected Steps per Second: 21,208.36810
Overall Steps per Second: 10,426.79104

Timestep Collection Time: 2.35813
Timestep Consumption Time: 2.43836
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.79649

Cumulative Model Updates: 63,186
Cumulative Timesteps: 527,065,226

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.60096
Policy Entropy: 3.34467
Value Function Loss: 0.00360

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07667
Policy Update Magnitude: 0.55063
Value Function Update Magnitude: 0.62635

Collected Steps per Second: 22,490.06630
Overall Steps per Second: 10,698.45784

Timestep Collection Time: 2.22427
Timestep Consumption Time: 2.45154
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.67581

Cumulative Model Updates: 63,192
Cumulative Timesteps: 527,115,250

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 527115250...
Checkpoint 527115250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 979.83186
Policy Entropy: 3.34036
Value Function Loss: 0.00369

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08753
Policy Update Magnitude: 0.55386
Value Function Update Magnitude: 0.61683

Collected Steps per Second: 22,488.21770
Overall Steps per Second: 10,728.10814

Timestep Collection Time: 2.22410
Timestep Consumption Time: 2.43805
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.66215

Cumulative Model Updates: 63,198
Cumulative Timesteps: 527,165,266

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450.14995
Policy Entropy: 3.34562
Value Function Loss: 0.00351

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07818
Policy Update Magnitude: 0.54952
Value Function Update Magnitude: 0.61823

Collected Steps per Second: 22,723.06718
Overall Steps per Second: 10,594.05169

Timestep Collection Time: 2.20164
Timestep Consumption Time: 2.52063
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.72227

Cumulative Model Updates: 63,204
Cumulative Timesteps: 527,215,294

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 527215294...
Checkpoint 527215294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671.73387
Policy Entropy: 3.33077
Value Function Loss: 0.00337

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07376
Policy Update Magnitude: 0.54575
Value Function Update Magnitude: 0.61781

Collected Steps per Second: 23,046.85398
Overall Steps per Second: 10,817.46313

Timestep Collection Time: 2.17080
Timestep Consumption Time: 2.45413
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.62493

Cumulative Model Updates: 63,210
Cumulative Timesteps: 527,265,324

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 856.44751
Policy Entropy: 3.34427
Value Function Loss: 0.00358

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07806
Policy Update Magnitude: 0.54219
Value Function Update Magnitude: 0.62454

Collected Steps per Second: 22,414.31920
Overall Steps per Second: 10,610.32836

Timestep Collection Time: 2.23081
Timestep Consumption Time: 2.48177
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.71258

Cumulative Model Updates: 63,216
Cumulative Timesteps: 527,315,326

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 527315326...
Checkpoint 527315326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,489.26764
Policy Entropy: 3.34241
Value Function Loss: 0.00358

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07431
Policy Update Magnitude: 0.54805
Value Function Update Magnitude: 0.62228

Collected Steps per Second: 22,941.98176
Overall Steps per Second: 10,668.50423

Timestep Collection Time: 2.18081
Timestep Consumption Time: 2.50889
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.68969

Cumulative Model Updates: 63,222
Cumulative Timesteps: 527,365,358

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 814.53855
Policy Entropy: 3.34108
Value Function Loss: 0.00368

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08220
Policy Update Magnitude: 0.55692
Value Function Update Magnitude: 0.62932

Collected Steps per Second: 22,552.55861
Overall Steps per Second: 10,639.38184

Timestep Collection Time: 2.21775
Timestep Consumption Time: 2.48327
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.70103

Cumulative Model Updates: 63,228
Cumulative Timesteps: 527,415,374

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 527415374...
Checkpoint 527415374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.77399
Policy Entropy: 3.33203
Value Function Loss: 0.00353

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09177
Policy Update Magnitude: 0.54949
Value Function Update Magnitude: 0.62198

Collected Steps per Second: 23,009.81972
Overall Steps per Second: 10,803.61315

Timestep Collection Time: 2.17299
Timestep Consumption Time: 2.45510
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.62808

Cumulative Model Updates: 63,234
Cumulative Timesteps: 527,465,374

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,433.15543
Policy Entropy: 3.33300
Value Function Loss: 0.00362

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09598
Policy Update Magnitude: 0.54510
Value Function Update Magnitude: 0.60243

Collected Steps per Second: 22,087.44841
Overall Steps per Second: 10,502.92207

Timestep Collection Time: 2.26518
Timestep Consumption Time: 2.49845
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.76363

Cumulative Model Updates: 63,240
Cumulative Timesteps: 527,515,406

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 527515406...
Checkpoint 527515406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,394.06216
Policy Entropy: 3.32563
Value Function Loss: 0.00369

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09784
Policy Update Magnitude: 0.54571
Value Function Update Magnitude: 0.60849

Collected Steps per Second: 22,294.87988
Overall Steps per Second: 10,688.13859

Timestep Collection Time: 2.24285
Timestep Consumption Time: 2.43561
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.67846

Cumulative Model Updates: 63,246
Cumulative Timesteps: 527,565,410

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.43775
Policy Entropy: 3.33507
Value Function Loss: 0.00360

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10315
Policy Update Magnitude: 0.55448
Value Function Update Magnitude: 0.61967

Collected Steps per Second: 22,515.18278
Overall Steps per Second: 10,547.46935

Timestep Collection Time: 2.22072
Timestep Consumption Time: 2.51975
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.74047

Cumulative Model Updates: 63,252
Cumulative Timesteps: 527,615,410

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 527615410...
Checkpoint 527615410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 868.00620
Policy Entropy: 3.33050
Value Function Loss: 0.00340

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10473
Policy Update Magnitude: 0.54891
Value Function Update Magnitude: 0.60980

Collected Steps per Second: 22,623.38725
Overall Steps per Second: 10,564.77896

Timestep Collection Time: 2.21028
Timestep Consumption Time: 2.52281
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.73309

Cumulative Model Updates: 63,258
Cumulative Timesteps: 527,665,414

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 765.08712
Policy Entropy: 3.33937
Value Function Loss: 0.00327

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08244
Policy Update Magnitude: 0.53737
Value Function Update Magnitude: 0.59778

Collected Steps per Second: 22,907.16809
Overall Steps per Second: 10,712.13606

Timestep Collection Time: 2.18386
Timestep Consumption Time: 2.48617
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.67003

Cumulative Model Updates: 63,264
Cumulative Timesteps: 527,715,440

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 527715440...
Checkpoint 527715440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,157.73696
Policy Entropy: 3.33219
Value Function Loss: 0.00351

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.07850
Policy Update Magnitude: 0.53453
Value Function Update Magnitude: 0.59707

Collected Steps per Second: 22,647.78237
Overall Steps per Second: 10,794.39340

Timestep Collection Time: 2.20799
Timestep Consumption Time: 2.42460
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.63259

Cumulative Model Updates: 63,270
Cumulative Timesteps: 527,765,446

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 984.13720
Policy Entropy: 3.32730
Value Function Loss: 0.00371

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.54174
Value Function Update Magnitude: 0.61046

Collected Steps per Second: 22,927.13235
Overall Steps per Second: 10,773.80755

Timestep Collection Time: 2.18100
Timestep Consumption Time: 2.46026
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.64126

Cumulative Model Updates: 63,276
Cumulative Timesteps: 527,815,450

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 527815450...
Checkpoint 527815450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 864.92383
Policy Entropy: 3.33365
Value Function Loss: 0.00379

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.07759
Policy Update Magnitude: 0.55022
Value Function Update Magnitude: 0.62694

Collected Steps per Second: 21,147.25418
Overall Steps per Second: 10,067.85134

Timestep Collection Time: 2.36570
Timestep Consumption Time: 2.60339
PPO Batch Consumption Time: 0.29715
Total Iteration Time: 4.96908

Cumulative Model Updates: 63,282
Cumulative Timesteps: 527,865,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 807.57651
Policy Entropy: 3.33362
Value Function Loss: 0.00385

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08289
Policy Update Magnitude: 0.55836
Value Function Update Magnitude: 0.63292

Collected Steps per Second: 22,824.28713
Overall Steps per Second: 10,732.19122

Timestep Collection Time: 2.19091
Timestep Consumption Time: 2.46853
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.65944

Cumulative Model Updates: 63,288
Cumulative Timesteps: 527,915,484

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 527915484...
Checkpoint 527915484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,358.96757
Policy Entropy: 3.33188
Value Function Loss: 0.00393

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09574
Policy Update Magnitude: 0.56465
Value Function Update Magnitude: 0.63834

Collected Steps per Second: 22,594.91033
Overall Steps per Second: 10,586.79953

Timestep Collection Time: 2.21324
Timestep Consumption Time: 2.51038
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.72362

Cumulative Model Updates: 63,294
Cumulative Timesteps: 527,965,492

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.79975
Policy Entropy: 3.31807
Value Function Loss: 0.00393

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09899
Policy Update Magnitude: 0.56371
Value Function Update Magnitude: 0.63928

Collected Steps per Second: 22,609.53724
Overall Steps per Second: 10,571.38302

Timestep Collection Time: 2.21154
Timestep Consumption Time: 2.51839
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.72994

Cumulative Model Updates: 63,300
Cumulative Timesteps: 528,015,494

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 528015494...
Checkpoint 528015494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,129.15766
Policy Entropy: 3.31867
Value Function Loss: 0.00374

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10609
Policy Update Magnitude: 0.55727
Value Function Update Magnitude: 0.64296

Collected Steps per Second: 22,463.50690
Overall Steps per Second: 10,561.35810

Timestep Collection Time: 2.22708
Timestep Consumption Time: 2.50981
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.73689

Cumulative Model Updates: 63,306
Cumulative Timesteps: 528,065,522

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.24921
Policy Entropy: 3.32209
Value Function Loss: 0.00382

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.55174
Value Function Update Magnitude: 0.64858

Collected Steps per Second: 22,230.17703
Overall Steps per Second: 10,469.93847

Timestep Collection Time: 2.24937
Timestep Consumption Time: 2.52658
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 4.77596

Cumulative Model Updates: 63,312
Cumulative Timesteps: 528,115,526

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 528115526...
Checkpoint 528115526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 903.95212
Policy Entropy: 3.32942
Value Function Loss: 0.00388

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09368
Policy Update Magnitude: 0.54837
Value Function Update Magnitude: 0.64280

Collected Steps per Second: 22,101.10893
Overall Steps per Second: 10,649.18048

Timestep Collection Time: 2.26260
Timestep Consumption Time: 2.43316
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.69576

Cumulative Model Updates: 63,318
Cumulative Timesteps: 528,165,532

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178.37018
Policy Entropy: 3.34426
Value Function Loss: 0.00397

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08471
Policy Update Magnitude: 0.55725
Value Function Update Magnitude: 0.65296

Collected Steps per Second: 22,623.52773
Overall Steps per Second: 10,588.59533

Timestep Collection Time: 2.21088
Timestep Consumption Time: 2.51288
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.72376

Cumulative Model Updates: 63,324
Cumulative Timesteps: 528,215,550

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 528215550...
Checkpoint 528215550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 926.30895
Policy Entropy: 3.33577
Value Function Loss: 0.00368

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10517
Policy Update Magnitude: 0.55763
Value Function Update Magnitude: 0.64139

Collected Steps per Second: 22,184.23578
Overall Steps per Second: 10,479.41951

Timestep Collection Time: 2.25466
Timestep Consumption Time: 2.51831
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.77297

Cumulative Model Updates: 63,330
Cumulative Timesteps: 528,265,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 890.13583
Policy Entropy: 3.31486
Value Function Loss: 0.00372

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10723
Policy Update Magnitude: 0.55035
Value Function Update Magnitude: 0.61742

Collected Steps per Second: 22,844.54570
Overall Steps per Second: 10,614.42676

Timestep Collection Time: 2.18879
Timestep Consumption Time: 2.52196
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.71076

Cumulative Model Updates: 63,336
Cumulative Timesteps: 528,315,570

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 528315570...
Checkpoint 528315570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,444.44893
Policy Entropy: 3.30246
Value Function Loss: 0.00369

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.54954
Value Function Update Magnitude: 0.62701

Collected Steps per Second: 22,555.81905
Overall Steps per Second: 10,577.50035

Timestep Collection Time: 2.21779
Timestep Consumption Time: 2.51150
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.72928

Cumulative Model Updates: 63,342
Cumulative Timesteps: 528,365,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.09295
Policy Entropy: 3.31784
Value Function Loss: 0.00372

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10099
Policy Update Magnitude: 0.54829
Value Function Update Magnitude: 0.63456

Collected Steps per Second: 22,969.84560
Overall Steps per Second: 10,753.72337

Timestep Collection Time: 2.17712
Timestep Consumption Time: 2.47318
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.65030

Cumulative Model Updates: 63,348
Cumulative Timesteps: 528,415,602

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 528415602...
Checkpoint 528415602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 955.96136
Policy Entropy: 3.34579
Value Function Loss: 0.00358

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08312
Policy Update Magnitude: 0.54100
Value Function Update Magnitude: 0.64496

Collected Steps per Second: 22,954.63839
Overall Steps per Second: 10,639.07454

Timestep Collection Time: 2.17943
Timestep Consumption Time: 2.52286
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.70229

Cumulative Model Updates: 63,354
Cumulative Timesteps: 528,465,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.30222
Policy Entropy: 3.36018
Value Function Loss: 0.00351

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08159
Policy Update Magnitude: 0.54065
Value Function Update Magnitude: 0.65727

Collected Steps per Second: 22,515.33309
Overall Steps per Second: 10,530.26349

Timestep Collection Time: 2.22204
Timestep Consumption Time: 2.52903
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.75107

Cumulative Model Updates: 63,360
Cumulative Timesteps: 528,515,660

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 528515660...
Checkpoint 528515660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.07373
Policy Entropy: 3.36700
Value Function Loss: 0.00345

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08757
Policy Update Magnitude: 0.53701
Value Function Update Magnitude: 0.64961

Collected Steps per Second: 21,740.90156
Overall Steps per Second: 10,515.99693

Timestep Collection Time: 2.30018
Timestep Consumption Time: 2.45524
PPO Batch Consumption Time: 0.28383
Total Iteration Time: 4.75542

Cumulative Model Updates: 63,366
Cumulative Timesteps: 528,565,668

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646.57473
Policy Entropy: 3.35138
Value Function Loss: 0.00340

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07277
Policy Update Magnitude: 0.53706
Value Function Update Magnitude: 0.65060

Collected Steps per Second: 22,855.60708
Overall Steps per Second: 10,627.86621

Timestep Collection Time: 2.18782
Timestep Consumption Time: 2.51717
PPO Batch Consumption Time: 0.29776
Total Iteration Time: 4.70499

Cumulative Model Updates: 63,372
Cumulative Timesteps: 528,615,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 528615672...
Checkpoint 528615672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.83952
Policy Entropy: 3.34249
Value Function Loss: 0.00352

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08705
Policy Update Magnitude: 0.54400
Value Function Update Magnitude: 0.64276

Collected Steps per Second: 22,374.36436
Overall Steps per Second: 10,575.24281

Timestep Collection Time: 2.23586
Timestep Consumption Time: 2.49462
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.73048

Cumulative Model Updates: 63,378
Cumulative Timesteps: 528,665,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,206.78433
Policy Entropy: 3.34673
Value Function Loss: 0.00347

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08320
Policy Update Magnitude: 0.53837
Value Function Update Magnitude: 0.64390

Collected Steps per Second: 20,945.10854
Overall Steps per Second: 10,240.68518

Timestep Collection Time: 2.38729
Timestep Consumption Time: 2.49539
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.88268

Cumulative Model Updates: 63,384
Cumulative Timesteps: 528,715,700

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 528715700...
Checkpoint 528715700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.93469
Policy Entropy: 3.35409
Value Function Loss: 0.00346

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10142
Policy Update Magnitude: 0.53671
Value Function Update Magnitude: 0.64019

Collected Steps per Second: 22,079.76058
Overall Steps per Second: 10,648.97604

Timestep Collection Time: 2.26597
Timestep Consumption Time: 2.43233
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.69829

Cumulative Model Updates: 63,390
Cumulative Timesteps: 528,765,732

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,589.81664
Policy Entropy: 3.35769
Value Function Loss: 0.00346

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10805
Policy Update Magnitude: 0.53846
Value Function Update Magnitude: 0.64883

Collected Steps per Second: 22,411.02893
Overall Steps per Second: 10,665.69045

Timestep Collection Time: 2.23238
Timestep Consumption Time: 2.45836
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 4.69074

Cumulative Model Updates: 63,396
Cumulative Timesteps: 528,815,762

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 528815762...
Checkpoint 528815762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 905.87504
Policy Entropy: 3.35842
Value Function Loss: 0.00360

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.54008
Value Function Update Magnitude: 0.64361

Collected Steps per Second: 21,376.85830
Overall Steps per Second: 10,632.72903

Timestep Collection Time: 2.33907
Timestep Consumption Time: 2.36358
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.70265

Cumulative Model Updates: 63,402
Cumulative Timesteps: 528,865,764

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,548.23075
Policy Entropy: 3.34462
Value Function Loss: 0.00377

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08628
Policy Update Magnitude: 0.55483
Value Function Update Magnitude: 0.65162

Collected Steps per Second: 22,297.54483
Overall Steps per Second: 10,830.82899

Timestep Collection Time: 2.24348
Timestep Consumption Time: 2.37519
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.61867

Cumulative Model Updates: 63,408
Cumulative Timesteps: 528,915,788

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 528915788...
Checkpoint 528915788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.26274
Policy Entropy: 3.33596
Value Function Loss: 0.00378

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09354
Policy Update Magnitude: 0.56588
Value Function Update Magnitude: 0.66166

Collected Steps per Second: 22,847.48693
Overall Steps per Second: 10,725.04310

Timestep Collection Time: 2.18939
Timestep Consumption Time: 2.47465
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.66404

Cumulative Model Updates: 63,414
Cumulative Timesteps: 528,965,810

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 929.03593
Policy Entropy: 3.34582
Value Function Loss: 0.00353

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10489
Policy Update Magnitude: 0.55689
Value Function Update Magnitude: 0.63793

Collected Steps per Second: 22,694.72442
Overall Steps per Second: 10,633.12670

Timestep Collection Time: 2.20351
Timestep Consumption Time: 2.49953
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.70304

Cumulative Model Updates: 63,420
Cumulative Timesteps: 529,015,818

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 529015818...
Checkpoint 529015818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 842.42266
Policy Entropy: 3.34921
Value Function Loss: 0.00353

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10253
Policy Update Magnitude: 0.54407
Value Function Update Magnitude: 0.59976

Collected Steps per Second: 22,874.25585
Overall Steps per Second: 10,651.42673

Timestep Collection Time: 2.18648
Timestep Consumption Time: 2.50905
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.69552

Cumulative Model Updates: 63,426
Cumulative Timesteps: 529,065,832

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 761.29445
Policy Entropy: 3.34701
Value Function Loss: 0.00347

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10865
Policy Update Magnitude: 0.53760
Value Function Update Magnitude: 0.60000

Collected Steps per Second: 21,848.45457
Overall Steps per Second: 10,724.21883

Timestep Collection Time: 2.28922
Timestep Consumption Time: 2.37461
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.66384

Cumulative Model Updates: 63,432
Cumulative Timesteps: 529,115,848

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 529115848...
Checkpoint 529115848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.28945
Policy Entropy: 3.34302
Value Function Loss: 0.00351

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10621
Policy Update Magnitude: 0.53554
Value Function Update Magnitude: 0.60378

Collected Steps per Second: 22,348.96765
Overall Steps per Second: 10,598.49839

Timestep Collection Time: 2.23813
Timestep Consumption Time: 2.48140
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.71954

Cumulative Model Updates: 63,438
Cumulative Timesteps: 529,165,868

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783.48370
Policy Entropy: 3.33929
Value Function Loss: 0.00343

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.53554
Value Function Update Magnitude: 0.59053

Collected Steps per Second: 22,515.44638
Overall Steps per Second: 10,540.76929

Timestep Collection Time: 2.22070
Timestep Consumption Time: 2.52279
PPO Batch Consumption Time: 0.29682
Total Iteration Time: 4.74349

Cumulative Model Updates: 63,444
Cumulative Timesteps: 529,215,868

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 529215868...
Checkpoint 529215868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 824.73658
Policy Entropy: 3.35073
Value Function Loss: 0.00345

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09134
Policy Update Magnitude: 0.53758
Value Function Update Magnitude: 0.61189

Collected Steps per Second: 22,294.48815
Overall Steps per Second: 10,553.79990

Timestep Collection Time: 2.24280
Timestep Consumption Time: 2.49502
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.73782

Cumulative Model Updates: 63,450
Cumulative Timesteps: 529,265,870

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.58559
Policy Entropy: 3.36034
Value Function Loss: 0.00347

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08668
Policy Update Magnitude: 0.54703
Value Function Update Magnitude: 0.62370

Collected Steps per Second: 22,251.18960
Overall Steps per Second: 10,456.02242

Timestep Collection Time: 2.24797
Timestep Consumption Time: 2.53588
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.78385

Cumulative Model Updates: 63,456
Cumulative Timesteps: 529,315,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 529315890...
Checkpoint 529315890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 845.11356
Policy Entropy: 3.34937
Value Function Loss: 0.00372

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08071
Policy Update Magnitude: 0.55106
Value Function Update Magnitude: 0.60389

Collected Steps per Second: 22,355.06757
Overall Steps per Second: 10,630.23330

Timestep Collection Time: 2.23699
Timestep Consumption Time: 2.46733
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.70432

Cumulative Model Updates: 63,462
Cumulative Timesteps: 529,365,898

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.12898
Policy Entropy: 3.34535
Value Function Loss: 0.00366

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07630
Policy Update Magnitude: 0.56213
Value Function Update Magnitude: 0.61725

Collected Steps per Second: 22,910.43301
Overall Steps per Second: 10,650.33524

Timestep Collection Time: 2.18311
Timestep Consumption Time: 2.51308
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.69619

Cumulative Model Updates: 63,468
Cumulative Timesteps: 529,415,914

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 529415914...
Checkpoint 529415914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747.22241
Policy Entropy: 3.33361
Value Function Loss: 0.00382

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08653
Policy Update Magnitude: 0.56461
Value Function Update Magnitude: 0.62615

Collected Steps per Second: 23,114.81145
Overall Steps per Second: 10,851.50148

Timestep Collection Time: 2.16312
Timestep Consumption Time: 2.44454
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.60766

Cumulative Model Updates: 63,474
Cumulative Timesteps: 529,465,914

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 804.74365
Policy Entropy: 3.34855
Value Function Loss: 0.00369

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08978
Policy Update Magnitude: 0.57538
Value Function Update Magnitude: 0.62162

Collected Steps per Second: 22,552.28713
Overall Steps per Second: 10,531.29459

Timestep Collection Time: 2.21725
Timestep Consumption Time: 2.53089
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.74813

Cumulative Model Updates: 63,480
Cumulative Timesteps: 529,515,918

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 529515918...
Checkpoint 529515918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.07533
Policy Entropy: 3.35332
Value Function Loss: 0.00360

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07726
Policy Update Magnitude: 0.55993
Value Function Update Magnitude: 0.61061

Collected Steps per Second: 23,124.85545
Overall Steps per Second: 10,719.64042

Timestep Collection Time: 2.16269
Timestep Consumption Time: 2.50276
PPO Batch Consumption Time: 0.29605
Total Iteration Time: 4.66545

Cumulative Model Updates: 63,486
Cumulative Timesteps: 529,565,930

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.96004
Policy Entropy: 3.35266
Value Function Loss: 0.00361

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.55399
Value Function Update Magnitude: 0.61131

Collected Steps per Second: 22,862.97602
Overall Steps per Second: 10,775.59909

Timestep Collection Time: 2.18808
Timestep Consumption Time: 2.45445
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.64253

Cumulative Model Updates: 63,492
Cumulative Timesteps: 529,615,956

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 529615956...
Checkpoint 529615956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.69555
Policy Entropy: 3.35091
Value Function Loss: 0.00359

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07912
Policy Update Magnitude: 0.54943
Value Function Update Magnitude: 0.61445

Collected Steps per Second: 22,566.90817
Overall Steps per Second: 10,732.89233

Timestep Collection Time: 2.21563
Timestep Consumption Time: 2.44294
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.65858

Cumulative Model Updates: 63,498
Cumulative Timesteps: 529,665,956

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,730.05895
Policy Entropy: 3.33733
Value Function Loss: 0.00357

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08324
Policy Update Magnitude: 0.55631
Value Function Update Magnitude: 0.63167

Collected Steps per Second: 22,415.12257
Overall Steps per Second: 10,577.76141

Timestep Collection Time: 2.23126
Timestep Consumption Time: 2.49696
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.72822

Cumulative Model Updates: 63,504
Cumulative Timesteps: 529,715,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 529715970...
Checkpoint 529715970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 735.80255
Policy Entropy: 3.33046
Value Function Loss: 0.00363

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09858
Policy Update Magnitude: 0.55347
Value Function Update Magnitude: 0.62869

Collected Steps per Second: 22,168.47125
Overall Steps per Second: 10,470.51292

Timestep Collection Time: 2.25654
Timestep Consumption Time: 2.52107
PPO Batch Consumption Time: 0.29513
Total Iteration Time: 4.77761

Cumulative Model Updates: 63,510
Cumulative Timesteps: 529,765,994

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 930.69397
Policy Entropy: 3.32071
Value Function Loss: 0.00373

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11008
Policy Update Magnitude: 0.55941
Value Function Update Magnitude: 0.64294

Collected Steps per Second: 22,654.07849
Overall Steps per Second: 10,547.99304

Timestep Collection Time: 2.20764
Timestep Consumption Time: 2.53374
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.74138

Cumulative Model Updates: 63,516
Cumulative Timesteps: 529,816,006

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 529816006...
Checkpoint 529816006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 918.90437
Policy Entropy: 3.33456
Value Function Loss: 0.00375

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09749
Policy Update Magnitude: 0.56447
Value Function Update Magnitude: 0.66627

Collected Steps per Second: 22,250.08759
Overall Steps per Second: 10,545.26432

Timestep Collection Time: 2.24835
Timestep Consumption Time: 2.49558
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.74393

Cumulative Model Updates: 63,522
Cumulative Timesteps: 529,866,032

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.41434
Policy Entropy: 3.34084
Value Function Loss: 0.00381

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10722
Policy Update Magnitude: 0.56034
Value Function Update Magnitude: 0.67501

Collected Steps per Second: 22,718.85882
Overall Steps per Second: 10,559.71071

Timestep Collection Time: 2.20090
Timestep Consumption Time: 2.53426
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.73517

Cumulative Model Updates: 63,528
Cumulative Timesteps: 529,916,034

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 529916034...
Checkpoint 529916034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.17420
Policy Entropy: 3.34925
Value Function Loss: 0.00373

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09520
Policy Update Magnitude: 0.55413
Value Function Update Magnitude: 0.67273

Collected Steps per Second: 22,657.38675
Overall Steps per Second: 10,560.43798

Timestep Collection Time: 2.20687
Timestep Consumption Time: 2.52797
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 4.73484

Cumulative Model Updates: 63,534
Cumulative Timesteps: 529,966,036

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 879.86394
Policy Entropy: 3.35107
Value Function Loss: 0.00386

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.55380
Value Function Update Magnitude: 0.66564

Collected Steps per Second: 22,843.04191
Overall Steps per Second: 10,748.82391

Timestep Collection Time: 2.18911
Timestep Consumption Time: 2.46312
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.65223

Cumulative Model Updates: 63,540
Cumulative Timesteps: 530,016,042

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 530016042...
Checkpoint 530016042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300.30897
Policy Entropy: 3.35355
Value Function Loss: 0.00379

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.55973
Value Function Update Magnitude: 0.66535

Collected Steps per Second: 22,417.96450
Overall Steps per Second: 10,672.93122

Timestep Collection Time: 2.23071
Timestep Consumption Time: 2.45479
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.68550

Cumulative Model Updates: 63,546
Cumulative Timesteps: 530,066,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.79147
Policy Entropy: 3.33664
Value Function Loss: 0.00388

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.55898
Value Function Update Magnitude: 0.66560

Collected Steps per Second: 22,925.66939
Overall Steps per Second: 10,648.32655

Timestep Collection Time: 2.18210
Timestep Consumption Time: 2.51592
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.69802

Cumulative Model Updates: 63,552
Cumulative Timesteps: 530,116,076

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 530116076...
Checkpoint 530116076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 926.29070
Policy Entropy: 3.32517
Value Function Loss: 0.00368

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08401
Policy Update Magnitude: 0.55592
Value Function Update Magnitude: 0.66033

Collected Steps per Second: 22,509.99037
Overall Steps per Second: 10,527.86136

Timestep Collection Time: 2.22239
Timestep Consumption Time: 2.52938
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.75177

Cumulative Model Updates: 63,558
Cumulative Timesteps: 530,166,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.10182
Policy Entropy: 3.31072
Value Function Loss: 0.00387

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.55711
Value Function Update Magnitude: 0.66838

Collected Steps per Second: 22,619.56813
Overall Steps per Second: 10,519.06638

Timestep Collection Time: 2.21118
Timestep Consumption Time: 2.54361
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 4.75479

Cumulative Model Updates: 63,564
Cumulative Timesteps: 530,216,118

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 530216118...
Checkpoint 530216118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 924.73378
Policy Entropy: 3.31988
Value Function Loss: 0.00381

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.12741
Policy Update Magnitude: 0.56086
Value Function Update Magnitude: 0.67115

Collected Steps per Second: 22,518.20336
Overall Steps per Second: 10,577.89630

Timestep Collection Time: 2.22140
Timestep Consumption Time: 2.50751
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.72892

Cumulative Model Updates: 63,570
Cumulative Timesteps: 530,266,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649.17395
Policy Entropy: 3.31990
Value Function Loss: 0.00392

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10392
Policy Update Magnitude: 0.56196
Value Function Update Magnitude: 0.66972

Collected Steps per Second: 22,374.84313
Overall Steps per Second: 10,609.06241

Timestep Collection Time: 2.23555
Timestep Consumption Time: 2.47929
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.71484

Cumulative Model Updates: 63,576
Cumulative Timesteps: 530,316,160

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 530316160...
Checkpoint 530316160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.87573
Policy Entropy: 3.32984
Value Function Loss: 0.00358

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09871
Policy Update Magnitude: 0.56029
Value Function Update Magnitude: 0.64912

Collected Steps per Second: 22,092.64179
Overall Steps per Second: 10,459.01636

Timestep Collection Time: 2.26329
Timestep Consumption Time: 2.51747
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.78076

Cumulative Model Updates: 63,582
Cumulative Timesteps: 530,366,162

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.98120
Policy Entropy: 3.32177
Value Function Loss: 0.00341

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07031
Policy Update Magnitude: 0.54618
Value Function Update Magnitude: 0.62674

Collected Steps per Second: 22,671.12710
Overall Steps per Second: 10,580.75428

Timestep Collection Time: 2.20615
Timestep Consumption Time: 2.52092
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.72707

Cumulative Model Updates: 63,588
Cumulative Timesteps: 530,416,178

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 530416178...
Checkpoint 530416178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 911.00185
Policy Entropy: 3.31438
Value Function Loss: 0.00344

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07549
Policy Update Magnitude: 0.55120
Value Function Update Magnitude: 0.61961

Collected Steps per Second: 22,010.72865
Overall Steps per Second: 10,579.45845

Timestep Collection Time: 2.27235
Timestep Consumption Time: 2.45531
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.72765

Cumulative Model Updates: 63,594
Cumulative Timesteps: 530,466,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475.59775
Policy Entropy: 3.32400
Value Function Loss: 0.00353

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08108
Policy Update Magnitude: 0.54744
Value Function Update Magnitude: 0.60700

Collected Steps per Second: 22,376.10772
Overall Steps per Second: 10,576.30414

Timestep Collection Time: 2.23569
Timestep Consumption Time: 2.49432
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.73001

Cumulative Model Updates: 63,600
Cumulative Timesteps: 530,516,220

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 530516220...
Checkpoint 530516220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 860.31622
Policy Entropy: 3.33803
Value Function Loss: 0.00362

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08175
Policy Update Magnitude: 0.54346
Value Function Update Magnitude: 0.60987

Collected Steps per Second: 22,745.43007
Overall Steps per Second: 10,650.27053

Timestep Collection Time: 2.19921
Timestep Consumption Time: 2.49757
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.69678

Cumulative Model Updates: 63,606
Cumulative Timesteps: 530,566,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599.46493
Policy Entropy: 3.33331
Value Function Loss: 0.00358

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08441
Policy Update Magnitude: 0.54211
Value Function Update Magnitude: 0.61109

Collected Steps per Second: 22,835.06798
Overall Steps per Second: 10,655.31917

Timestep Collection Time: 2.19005
Timestep Consumption Time: 2.50338
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.69343

Cumulative Model Updates: 63,612
Cumulative Timesteps: 530,616,252

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 530616252...
Checkpoint 530616252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.00632
Policy Entropy: 3.33746
Value Function Loss: 0.00362

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09401
Policy Update Magnitude: 0.54058
Value Function Update Magnitude: 0.62756

Collected Steps per Second: 22,860.72627
Overall Steps per Second: 10,694.47870

Timestep Collection Time: 2.18786
Timestep Consumption Time: 2.48895
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.67681

Cumulative Model Updates: 63,618
Cumulative Timesteps: 530,666,268

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457.63964
Policy Entropy: 3.34207
Value Function Loss: 0.00349

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08492
Policy Update Magnitude: 0.53859
Value Function Update Magnitude: 0.64662

Collected Steps per Second: 22,707.16553
Overall Steps per Second: 10,676.23098

Timestep Collection Time: 2.20195
Timestep Consumption Time: 2.48135
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.68330

Cumulative Model Updates: 63,624
Cumulative Timesteps: 530,716,268

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 530716268...
Checkpoint 530716268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 789.26100
Policy Entropy: 3.35523
Value Function Loss: 0.00352

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08812
Policy Update Magnitude: 0.54281
Value Function Update Magnitude: 0.64796

Collected Steps per Second: 22,988.32298
Overall Steps per Second: 10,844.96528

Timestep Collection Time: 2.17597
Timestep Consumption Time: 2.43649
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.61246

Cumulative Model Updates: 63,630
Cumulative Timesteps: 530,766,290

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.44708
Policy Entropy: 3.34631
Value Function Loss: 0.00343

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08944
Policy Update Magnitude: 0.54222
Value Function Update Magnitude: 0.64217

Collected Steps per Second: 22,814.12496
Overall Steps per Second: 10,738.62257

Timestep Collection Time: 2.19215
Timestep Consumption Time: 2.46506
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.65721

Cumulative Model Updates: 63,636
Cumulative Timesteps: 530,816,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 530816302...
Checkpoint 530816302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.83253
Policy Entropy: 3.34025
Value Function Loss: 0.00368

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07911
Policy Update Magnitude: 0.54607
Value Function Update Magnitude: 0.63604

Collected Steps per Second: 22,916.72997
Overall Steps per Second: 10,878.73810

Timestep Collection Time: 2.18199
Timestep Consumption Time: 2.41450
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.59649

Cumulative Model Updates: 63,642
Cumulative Timesteps: 530,866,306

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.11435
Policy Entropy: 3.33735
Value Function Loss: 0.00357

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07700
Policy Update Magnitude: 0.54809
Value Function Update Magnitude: 0.63650

Collected Steps per Second: 22,600.27630
Overall Steps per Second: 10,794.68334

Timestep Collection Time: 2.21289
Timestep Consumption Time: 2.42013
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.63302

Cumulative Model Updates: 63,648
Cumulative Timesteps: 530,916,318

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 530916318...
Checkpoint 530916318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 821.97213
Policy Entropy: 3.33157
Value Function Loss: 0.00366

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08490
Policy Update Magnitude: 0.54513
Value Function Update Magnitude: 0.63029

Collected Steps per Second: 22,281.96864
Overall Steps per Second: 10,698.15994

Timestep Collection Time: 2.24504
Timestep Consumption Time: 2.43090
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.67594

Cumulative Model Updates: 63,654
Cumulative Timesteps: 530,966,342

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,470.94121
Policy Entropy: 3.33697
Value Function Loss: 0.00347

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09126
Policy Update Magnitude: 0.54113
Value Function Update Magnitude: 0.60782

Collected Steps per Second: 22,428.11162
Overall Steps per Second: 10,583.01233

Timestep Collection Time: 2.23059
Timestep Consumption Time: 2.49660
PPO Batch Consumption Time: 0.29616
Total Iteration Time: 4.72720

Cumulative Model Updates: 63,660
Cumulative Timesteps: 531,016,370

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 531016370...
Checkpoint 531016370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.26829
Policy Entropy: 3.34855
Value Function Loss: 0.00345

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09769
Policy Update Magnitude: 0.53465
Value Function Update Magnitude: 0.60827

Collected Steps per Second: 22,555.95399
Overall Steps per Second: 10,623.35158

Timestep Collection Time: 2.21786
Timestep Consumption Time: 2.49120
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.70906

Cumulative Model Updates: 63,666
Cumulative Timesteps: 531,066,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.45036
Policy Entropy: 3.35769
Value Function Loss: 0.00343

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07774
Policy Update Magnitude: 0.53023
Value Function Update Magnitude: 0.60330

Collected Steps per Second: 22,389.66184
Overall Steps per Second: 10,421.63500

Timestep Collection Time: 2.23442
Timestep Consumption Time: 2.56597
PPO Batch Consumption Time: 0.29730
Total Iteration Time: 4.80040

Cumulative Model Updates: 63,672
Cumulative Timesteps: 531,116,424

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 531116424...
Checkpoint 531116424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629.42856
Policy Entropy: 3.36693
Value Function Loss: 0.00351

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08139
Policy Update Magnitude: 0.53153
Value Function Update Magnitude: 0.63636

Collected Steps per Second: 22,897.69706
Overall Steps per Second: 10,579.78777

Timestep Collection Time: 2.18380
Timestep Consumption Time: 2.54257
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 4.72637

Cumulative Model Updates: 63,678
Cumulative Timesteps: 531,166,428

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.85078
Policy Entropy: 3.36054
Value Function Loss: 0.00351

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.53351
Value Function Update Magnitude: 0.65755

Collected Steps per Second: 22,751.51919
Overall Steps per Second: 10,601.60629

Timestep Collection Time: 2.19845
Timestep Consumption Time: 2.51952
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.71796

Cumulative Model Updates: 63,684
Cumulative Timesteps: 531,216,446

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 531216446...
Checkpoint 531216446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.15649
Policy Entropy: 3.35264
Value Function Loss: 0.00356

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09011
Policy Update Magnitude: 0.53712
Value Function Update Magnitude: 0.64152

Collected Steps per Second: 22,849.14543
Overall Steps per Second: 10,632.24323

Timestep Collection Time: 2.18870
Timestep Consumption Time: 2.51491
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.70362

Cumulative Model Updates: 63,690
Cumulative Timesteps: 531,266,456

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.23067
Policy Entropy: 3.35227
Value Function Loss: 0.00356

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08617
Policy Update Magnitude: 0.55010
Value Function Update Magnitude: 0.62990

Collected Steps per Second: 22,799.99019
Overall Steps per Second: 10,759.28303

Timestep Collection Time: 2.19298
Timestep Consumption Time: 2.45417
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.64715

Cumulative Model Updates: 63,696
Cumulative Timesteps: 531,316,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 531316456...
Checkpoint 531316456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.83725
Policy Entropy: 3.34217
Value Function Loss: 0.00353

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08550
Policy Update Magnitude: 0.55102
Value Function Update Magnitude: 0.62011

Collected Steps per Second: 22,677.67523
Overall Steps per Second: 10,674.89568

Timestep Collection Time: 2.20525
Timestep Consumption Time: 2.47957
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.68482

Cumulative Model Updates: 63,702
Cumulative Timesteps: 531,366,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,591.71103
Policy Entropy: 3.34310
Value Function Loss: 0.00360

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08328
Policy Update Magnitude: 0.54866
Value Function Update Magnitude: 0.62399

Collected Steps per Second: 22,492.68981
Overall Steps per Second: 10,639.61192

Timestep Collection Time: 2.22419
Timestep Consumption Time: 2.47786
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.70205

Cumulative Model Updates: 63,708
Cumulative Timesteps: 531,416,494

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 531416494...
Checkpoint 531416494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,790.94988
Policy Entropy: 3.33474
Value Function Loss: 0.00367

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09808
Policy Update Magnitude: 0.54828
Value Function Update Magnitude: 0.63070

Collected Steps per Second: 22,933.72250
Overall Steps per Second: 10,874.40667

Timestep Collection Time: 2.18063
Timestep Consumption Time: 2.41824
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.59887

Cumulative Model Updates: 63,714
Cumulative Timesteps: 531,466,504

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.04948
Policy Entropy: 3.32990
Value Function Loss: 0.00355

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10939
Policy Update Magnitude: 0.54222
Value Function Update Magnitude: 0.62598

Collected Steps per Second: 22,316.52230
Overall Steps per Second: 10,529.77635

Timestep Collection Time: 2.24112
Timestep Consumption Time: 2.50865
PPO Batch Consumption Time: 0.29688
Total Iteration Time: 4.74977

Cumulative Model Updates: 63,720
Cumulative Timesteps: 531,516,518

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 531516518...
Checkpoint 531516518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 946.47255
Policy Entropy: 3.33208
Value Function Loss: 0.00341

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11538
Policy Update Magnitude: 0.53360
Value Function Update Magnitude: 0.60719

Collected Steps per Second: 21,942.52299
Overall Steps per Second: 10,653.56799

Timestep Collection Time: 2.27977
Timestep Consumption Time: 2.41574
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.69552

Cumulative Model Updates: 63,726
Cumulative Timesteps: 531,566,542

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,484.61647
Policy Entropy: 3.33586
Value Function Loss: 0.00340

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10437
Policy Update Magnitude: 0.52447
Value Function Update Magnitude: 0.60533

Collected Steps per Second: 22,363.45548
Overall Steps per Second: 10,589.39995

Timestep Collection Time: 2.23624
Timestep Consumption Time: 2.48641
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.72265

Cumulative Model Updates: 63,732
Cumulative Timesteps: 531,616,552

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 531616552...
Checkpoint 531616552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,572.47329
Policy Entropy: 3.34371
Value Function Loss: 0.00345

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.53022
Value Function Update Magnitude: 0.61136

Collected Steps per Second: 22,703.25897
Overall Steps per Second: 10,842.50391

Timestep Collection Time: 2.20347
Timestep Consumption Time: 2.41041
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.61388

Cumulative Model Updates: 63,738
Cumulative Timesteps: 531,666,578

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 793.28188
Policy Entropy: 3.34092
Value Function Loss: 0.00353

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10117
Policy Update Magnitude: 0.53600
Value Function Update Magnitude: 0.64299

Collected Steps per Second: 22,508.84657
Overall Steps per Second: 10,542.07670

Timestep Collection Time: 2.22179
Timestep Consumption Time: 2.52205
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.74385

Cumulative Model Updates: 63,744
Cumulative Timesteps: 531,716,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 531716588...
Checkpoint 531716588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.58131
Policy Entropy: 3.33370
Value Function Loss: 0.00361

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10136
Policy Update Magnitude: 0.54212
Value Function Update Magnitude: 0.63634

Collected Steps per Second: 22,670.54528
Overall Steps per Second: 10,643.99352

Timestep Collection Time: 2.20656
Timestep Consumption Time: 2.49318
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.69974

Cumulative Model Updates: 63,750
Cumulative Timesteps: 531,766,612

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.03777
Policy Entropy: 3.33760
Value Function Loss: 0.00350

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09166
Policy Update Magnitude: 0.53754
Value Function Update Magnitude: 0.62875

Collected Steps per Second: 22,902.52108
Overall Steps per Second: 10,803.29696

Timestep Collection Time: 2.18360
Timestep Consumption Time: 2.44554
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.62914

Cumulative Model Updates: 63,756
Cumulative Timesteps: 531,816,622

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 531816622...
Checkpoint 531816622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.95638
Policy Entropy: 3.33304
Value Function Loss: 0.00347

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08545
Policy Update Magnitude: 0.53033
Value Function Update Magnitude: 0.60469

Collected Steps per Second: 22,766.54894
Overall Steps per Second: 10,757.80157

Timestep Collection Time: 2.19726
Timestep Consumption Time: 2.45276
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.65002

Cumulative Model Updates: 63,762
Cumulative Timesteps: 531,866,646

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.18078
Policy Entropy: 3.34046
Value Function Loss: 0.00345

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07743
Policy Update Magnitude: 0.53108
Value Function Update Magnitude: 0.63969

Collected Steps per Second: 22,583.25618
Overall Steps per Second: 10,707.36364

Timestep Collection Time: 2.21518
Timestep Consumption Time: 2.45693
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.67211

Cumulative Model Updates: 63,768
Cumulative Timesteps: 531,916,672

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 531916672...
Checkpoint 531916672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.14739
Policy Entropy: 3.32359
Value Function Loss: 0.00357

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08528
Policy Update Magnitude: 0.53955
Value Function Update Magnitude: 0.68716

Collected Steps per Second: 22,738.12351
Overall Steps per Second: 10,823.10087

Timestep Collection Time: 2.20009
Timestep Consumption Time: 2.42206
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.62215

Cumulative Model Updates: 63,774
Cumulative Timesteps: 531,966,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.47841
Policy Entropy: 3.32965
Value Function Loss: 0.00357

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09424
Policy Update Magnitude: 0.54510
Value Function Update Magnitude: 0.68109

Collected Steps per Second: 22,207.56988
Overall Steps per Second: 10,545.07805

Timestep Collection Time: 2.25266
Timestep Consumption Time: 2.49136
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.74401

Cumulative Model Updates: 63,780
Cumulative Timesteps: 532,016,724

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 532016724...
Checkpoint 532016724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 965.22292
Policy Entropy: 3.32289
Value Function Loss: 0.00382

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09776
Policy Update Magnitude: 0.54370
Value Function Update Magnitude: 0.67345

Collected Steps per Second: 22,068.47793
Overall Steps per Second: 10,572.88739

Timestep Collection Time: 2.26649
Timestep Consumption Time: 2.46429
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.73078

Cumulative Model Updates: 63,786
Cumulative Timesteps: 532,066,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.07131
Policy Entropy: 3.32736
Value Function Loss: 0.00405

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.55405
Value Function Update Magnitude: 0.67932

Collected Steps per Second: 22,538.80385
Overall Steps per Second: 10,640.19446

Timestep Collection Time: 2.21928
Timestep Consumption Time: 2.48176
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.70104

Cumulative Model Updates: 63,792
Cumulative Timesteps: 532,116,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 532116762...
Checkpoint 532116762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.73751
Policy Entropy: 3.33070
Value Function Loss: 0.00391

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10360
Policy Update Magnitude: 0.55577
Value Function Update Magnitude: 0.66219

Collected Steps per Second: 22,546.11941
Overall Steps per Second: 10,635.07615

Timestep Collection Time: 2.21847
Timestep Consumption Time: 2.48464
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.70312

Cumulative Model Updates: 63,798
Cumulative Timesteps: 532,166,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.94547
Policy Entropy: 3.32784
Value Function Loss: 0.00373

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09978
Policy Update Magnitude: 0.54217
Value Function Update Magnitude: 0.63363

Collected Steps per Second: 22,757.89279
Overall Steps per Second: 10,737.33723

Timestep Collection Time: 2.19783
Timestep Consumption Time: 2.46049
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.65832

Cumulative Model Updates: 63,804
Cumulative Timesteps: 532,216,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 532216798...
Checkpoint 532216798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392.04153
Policy Entropy: 3.33598
Value Function Loss: 0.00345

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09058
Policy Update Magnitude: 0.52773
Value Function Update Magnitude: 0.60970

Collected Steps per Second: 22,765.70195
Overall Steps per Second: 10,635.65459

Timestep Collection Time: 2.19743
Timestep Consumption Time: 2.50618
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.70361

Cumulative Model Updates: 63,810
Cumulative Timesteps: 532,266,824

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,518.83544
Policy Entropy: 3.32725
Value Function Loss: 0.00356

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09000
Policy Update Magnitude: 0.53180
Value Function Update Magnitude: 0.60807

Collected Steps per Second: 22,741.78516
Overall Steps per Second: 10,556.00207

Timestep Collection Time: 2.19921
Timestep Consumption Time: 2.53876
PPO Batch Consumption Time: 0.29553
Total Iteration Time: 4.73797

Cumulative Model Updates: 63,816
Cumulative Timesteps: 532,316,838

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 532316838...
Checkpoint 532316838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475.07942
Policy Entropy: 3.33530
Value Function Loss: 0.00369

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10173
Policy Update Magnitude: 0.53586
Value Function Update Magnitude: 0.60646

Collected Steps per Second: 22,779.42296
Overall Steps per Second: 10,611.18607

Timestep Collection Time: 2.19584
Timestep Consumption Time: 2.51805
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.71389

Cumulative Model Updates: 63,822
Cumulative Timesteps: 532,366,858

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 830.46768
Policy Entropy: 3.33377
Value Function Loss: 0.00377

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10360
Policy Update Magnitude: 0.54019
Value Function Update Magnitude: 0.61742

Collected Steps per Second: 22,318.73279
Overall Steps per Second: 10,697.91206

Timestep Collection Time: 2.24144
Timestep Consumption Time: 2.43480
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.67624

Cumulative Model Updates: 63,828
Cumulative Timesteps: 532,416,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 532416884...
Checkpoint 532416884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.83685
Policy Entropy: 3.34865
Value Function Loss: 0.00358

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09693
Policy Update Magnitude: 0.53742
Value Function Update Magnitude: 0.62916

Collected Steps per Second: 22,794.16351
Overall Steps per Second: 10,763.21036

Timestep Collection Time: 2.19486
Timestep Consumption Time: 2.45338
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.64824

Cumulative Model Updates: 63,834
Cumulative Timesteps: 532,466,914

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744.02801
Policy Entropy: 3.34812
Value Function Loss: 0.00363

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07963
Policy Update Magnitude: 0.54253
Value Function Update Magnitude: 0.63148

Collected Steps per Second: 22,427.51678
Overall Steps per Second: 10,625.28850

Timestep Collection Time: 2.22976
Timestep Consumption Time: 2.47675
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.70651

Cumulative Model Updates: 63,840
Cumulative Timesteps: 532,516,922

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 532516922...
Checkpoint 532516922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610.69909
Policy Entropy: 3.34706
Value Function Loss: 0.00380

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08062
Policy Update Magnitude: 0.55391
Value Function Update Magnitude: 0.65277

Collected Steps per Second: 22,718.26508
Overall Steps per Second: 10,805.50552

Timestep Collection Time: 2.20166
Timestep Consumption Time: 2.42727
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.62894

Cumulative Model Updates: 63,846
Cumulative Timesteps: 532,566,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 886.32254
Policy Entropy: 3.34376
Value Function Loss: 0.00378

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07197
Policy Update Magnitude: 0.56051
Value Function Update Magnitude: 0.65891

Collected Steps per Second: 22,087.76510
Overall Steps per Second: 10,527.06102

Timestep Collection Time: 2.26397
Timestep Consumption Time: 2.48627
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.75023

Cumulative Model Updates: 63,852
Cumulative Timesteps: 532,616,946

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 532616946...
Checkpoint 532616946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,470.89030
Policy Entropy: 3.35468
Value Function Loss: 0.00379

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.55754
Value Function Update Magnitude: 0.65556

Collected Steps per Second: 22,357.97630
Overall Steps per Second: 10,663.37994

Timestep Collection Time: 2.23741
Timestep Consumption Time: 2.45378
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.69120

Cumulative Model Updates: 63,858
Cumulative Timesteps: 532,666,970

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.64388
Policy Entropy: 3.35379
Value Function Loss: 0.00361

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08106
Policy Update Magnitude: 0.54565
Value Function Update Magnitude: 0.64273

Collected Steps per Second: 22,231.75610
Overall Steps per Second: 10,500.52414

Timestep Collection Time: 2.24975
Timestep Consumption Time: 2.51344
PPO Batch Consumption Time: 0.29756
Total Iteration Time: 4.76319

Cumulative Model Updates: 63,864
Cumulative Timesteps: 532,716,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 532716986...
Checkpoint 532716986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 905.32411
Policy Entropy: 3.35856
Value Function Loss: 0.00357

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.54483
Value Function Update Magnitude: 0.63522

Collected Steps per Second: 22,424.58265
Overall Steps per Second: 10,611.08991

Timestep Collection Time: 2.22970
Timestep Consumption Time: 2.48236
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.71205

Cumulative Model Updates: 63,870
Cumulative Timesteps: 532,766,986

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 746.48703
Policy Entropy: 3.34112
Value Function Loss: 0.00355

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.10904
Policy Update Magnitude: 0.54649
Value Function Update Magnitude: 0.64878

Collected Steps per Second: 22,771.64164
Overall Steps per Second: 10,608.74031

Timestep Collection Time: 2.19677
Timestep Consumption Time: 2.51859
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.71536

Cumulative Model Updates: 63,876
Cumulative Timesteps: 532,817,010

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 532817010...
Checkpoint 532817010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 912.68814
Policy Entropy: 3.33806
Value Function Loss: 0.00377

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11672
Policy Update Magnitude: 0.55730
Value Function Update Magnitude: 0.65698

Collected Steps per Second: 23,168.22675
Overall Steps per Second: 10,916.62141

Timestep Collection Time: 2.15865
Timestep Consumption Time: 2.42262
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.58127

Cumulative Model Updates: 63,882
Cumulative Timesteps: 532,867,022

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.54564
Policy Entropy: 3.33392
Value Function Loss: 0.00382

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.12841
Policy Update Magnitude: 0.55891
Value Function Update Magnitude: 0.66801

Collected Steps per Second: 22,522.88754
Overall Steps per Second: 10,644.74064

Timestep Collection Time: 2.22130
Timestep Consumption Time: 2.47868
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.69997

Cumulative Model Updates: 63,888
Cumulative Timesteps: 532,917,052

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 532917052...
Checkpoint 532917052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649.83782
Policy Entropy: 3.35270
Value Function Loss: 0.00359

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.12262
Policy Update Magnitude: 0.55041
Value Function Update Magnitude: 0.65990

Collected Steps per Second: 22,839.08506
Overall Steps per Second: 10,807.60235

Timestep Collection Time: 2.18967
Timestep Consumption Time: 2.43763
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.62730

Cumulative Model Updates: 63,894
Cumulative Timesteps: 532,967,062

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 803.74662
Policy Entropy: 3.35473
Value Function Loss: 0.00364

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11545
Policy Update Magnitude: 0.54055
Value Function Update Magnitude: 0.63040

Collected Steps per Second: 22,745.44539
Overall Steps per Second: 10,623.50641

Timestep Collection Time: 2.19886
Timestep Consumption Time: 2.50900
PPO Batch Consumption Time: 0.29639
Total Iteration Time: 4.70786

Cumulative Model Updates: 63,900
Cumulative Timesteps: 533,017,076

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 533017076...
Checkpoint 533017076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 803.03010
Policy Entropy: 3.35383
Value Function Loss: 0.00359

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.54089
Value Function Update Magnitude: 0.62308

Collected Steps per Second: 22,948.67170
Overall Steps per Second: 10,718.51900

Timestep Collection Time: 2.17956
Timestep Consumption Time: 2.48694
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.66650

Cumulative Model Updates: 63,906
Cumulative Timesteps: 533,067,094

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.64714
Policy Entropy: 3.36021
Value Function Loss: 0.00360

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10016
Policy Update Magnitude: 0.54203
Value Function Update Magnitude: 0.63915

Collected Steps per Second: 22,298.90691
Overall Steps per Second: 10,715.29064

Timestep Collection Time: 2.24298
Timestep Consumption Time: 2.42474
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.66772

Cumulative Model Updates: 63,912
Cumulative Timesteps: 533,117,110

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 533117110...
Checkpoint 533117110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.40496
Policy Entropy: 3.36382
Value Function Loss: 0.00350

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07837
Policy Update Magnitude: 0.53928
Value Function Update Magnitude: 0.63403

Collected Steps per Second: 21,953.36762
Overall Steps per Second: 10,615.74844

Timestep Collection Time: 2.27755
Timestep Consumption Time: 2.43243
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.70998

Cumulative Model Updates: 63,918
Cumulative Timesteps: 533,167,110

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317.97733
Policy Entropy: 3.36983
Value Function Loss: 0.00359

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08071
Policy Update Magnitude: 0.54159
Value Function Update Magnitude: 0.61550

Collected Steps per Second: 22,527.44104
Overall Steps per Second: 10,555.30085

Timestep Collection Time: 2.21996
Timestep Consumption Time: 2.51794
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 4.73790

Cumulative Model Updates: 63,924
Cumulative Timesteps: 533,217,120

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 533217120...
Checkpoint 533217120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 720.37677
Policy Entropy: 3.38780
Value Function Loss: 0.00366

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.10339
Policy Update Magnitude: 0.57193
Value Function Update Magnitude: 0.63597

Collected Steps per Second: 22,366.90317
Overall Steps per Second: 10,607.94288

Timestep Collection Time: 2.23589
Timestep Consumption Time: 2.47850
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.71439

Cumulative Model Updates: 63,930
Cumulative Timesteps: 533,267,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.32808
Policy Entropy: 3.38668
Value Function Loss: 0.00373

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.12216
Policy Update Magnitude: 0.55734
Value Function Update Magnitude: 0.64038

Collected Steps per Second: 22,303.89605
Overall Steps per Second: 10,514.01916

Timestep Collection Time: 2.24239
Timestep Consumption Time: 2.51450
PPO Batch Consumption Time: 0.29746
Total Iteration Time: 4.75689

Cumulative Model Updates: 63,936
Cumulative Timesteps: 533,317,144

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 533317144...
Checkpoint 533317144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631.37415
Policy Entropy: 3.37672
Value Function Loss: 0.00379

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.12176
Policy Update Magnitude: 0.55764
Value Function Update Magnitude: 0.64686

Collected Steps per Second: 22,441.01247
Overall Steps per Second: 10,656.39693

Timestep Collection Time: 2.22860
Timestep Consumption Time: 2.46455
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.69314

Cumulative Model Updates: 63,942
Cumulative Timesteps: 533,367,156

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.63914
Policy Entropy: 3.38348
Value Function Loss: 0.00395

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10842
Policy Update Magnitude: 0.56069
Value Function Update Magnitude: 0.64173

Collected Steps per Second: 22,144.66207
Overall Steps per Second: 10,740.10616

Timestep Collection Time: 2.25806
Timestep Consumption Time: 2.39776
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.65582

Cumulative Model Updates: 63,948
Cumulative Timesteps: 533,417,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 533417160...
Checkpoint 533417160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 758.76680
Policy Entropy: 3.36811
Value Function Loss: 0.00402

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08654
Policy Update Magnitude: 0.56944
Value Function Update Magnitude: 0.65089

Collected Steps per Second: 22,047.01745
Overall Steps per Second: 10,741.17269

Timestep Collection Time: 2.26933
Timestep Consumption Time: 2.38863
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.65796

Cumulative Model Updates: 63,954
Cumulative Timesteps: 533,467,192

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.94933
Policy Entropy: 3.36112
Value Function Loss: 0.00391

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07941
Policy Update Magnitude: 0.57826
Value Function Update Magnitude: 0.66402

Collected Steps per Second: 22,157.21288
Overall Steps per Second: 10,787.51258

Timestep Collection Time: 2.25687
Timestep Consumption Time: 2.37867
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.63555

Cumulative Model Updates: 63,960
Cumulative Timesteps: 533,517,198

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 533517198...
Checkpoint 533517198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 804.37347
Policy Entropy: 3.33582
Value Function Loss: 0.00388

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07675
Policy Update Magnitude: 0.57224
Value Function Update Magnitude: 0.65409

Collected Steps per Second: 22,230.75481
Overall Steps per Second: 10,745.34058

Timestep Collection Time: 2.24968
Timestep Consumption Time: 2.40462
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.65430

Cumulative Model Updates: 63,966
Cumulative Timesteps: 533,567,210

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.64769
Policy Entropy: 3.34851
Value Function Loss: 0.00372

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07263
Policy Update Magnitude: 0.57127
Value Function Update Magnitude: 0.63186

Collected Steps per Second: 22,172.37972
Overall Steps per Second: 10,787.98854

Timestep Collection Time: 2.25515
Timestep Consumption Time: 2.37982
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.63497

Cumulative Model Updates: 63,972
Cumulative Timesteps: 533,617,212

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 533617212...
Checkpoint 533617212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.46176
Policy Entropy: 3.35385
Value Function Loss: 0.00378

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08064
Policy Update Magnitude: 0.56368
Value Function Update Magnitude: 0.62114

Collected Steps per Second: 21,770.39908
Overall Steps per Second: 10,685.43721

Timestep Collection Time: 2.29706
Timestep Consumption Time: 2.38295
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.68001

Cumulative Model Updates: 63,978
Cumulative Timesteps: 533,667,220

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 912.52543
Policy Entropy: 3.34686
Value Function Loss: 0.00381

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08634
Policy Update Magnitude: 0.55833
Value Function Update Magnitude: 0.60809

Collected Steps per Second: 21,444.29882
Overall Steps per Second: 10,554.15229

Timestep Collection Time: 2.33255
Timestep Consumption Time: 2.40681
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.73937

Cumulative Model Updates: 63,984
Cumulative Timesteps: 533,717,240

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 533717240...
Checkpoint 533717240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 853.16881
Policy Entropy: 3.35368
Value Function Loss: 0.00383

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08650
Policy Update Magnitude: 0.56266
Value Function Update Magnitude: 0.60678

Collected Steps per Second: 21,746.11777
Overall Steps per Second: 10,606.15832

Timestep Collection Time: 2.29981
Timestep Consumption Time: 2.41556
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.71537

Cumulative Model Updates: 63,990
Cumulative Timesteps: 533,767,252

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.63397
Policy Entropy: 3.36238
Value Function Loss: 0.00375

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09209
Policy Update Magnitude: 0.55693
Value Function Update Magnitude: 0.64540

Collected Steps per Second: 21,939.18945
Overall Steps per Second: 10,627.12260

Timestep Collection Time: 2.28012
Timestep Consumption Time: 2.42708
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.70720

Cumulative Model Updates: 63,996
Cumulative Timesteps: 533,817,276

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 533817276...
Checkpoint 533817276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 776.98743
Policy Entropy: 3.36706
Value Function Loss: 0.00370

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08803
Policy Update Magnitude: 0.55038
Value Function Update Magnitude: 0.64885

Collected Steps per Second: 22,549.30942
Overall Steps per Second: 10,546.24251

Timestep Collection Time: 2.21745
Timestep Consumption Time: 2.52376
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.74121

Cumulative Model Updates: 64,002
Cumulative Timesteps: 533,867,278

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.95205
Policy Entropy: 3.37093
Value Function Loss: 0.00365

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09232
Policy Update Magnitude: 0.54874
Value Function Update Magnitude: 0.64513

Collected Steps per Second: 23,172.83292
Overall Steps per Second: 10,751.37070

Timestep Collection Time: 2.15804
Timestep Consumption Time: 2.49327
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.65131

Cumulative Model Updates: 64,008
Cumulative Timesteps: 533,917,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 533917286...
Checkpoint 533917286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 961.74484
Policy Entropy: 3.36732
Value Function Loss: 0.00360

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10007
Policy Update Magnitude: 0.54368
Value Function Update Magnitude: 0.64900

Collected Steps per Second: 22,621.93816
Overall Steps per Second: 10,764.24134

Timestep Collection Time: 2.21148
Timestep Consumption Time: 2.43613
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.64761

Cumulative Model Updates: 64,014
Cumulative Timesteps: 533,967,314

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.91283
Policy Entropy: 3.36293
Value Function Loss: 0.00359

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.53583
Value Function Update Magnitude: 0.65079

Collected Steps per Second: 22,777.57166
Overall Steps per Second: 10,730.31769

Timestep Collection Time: 2.19646
Timestep Consumption Time: 2.46603
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.66249

Cumulative Model Updates: 64,020
Cumulative Timesteps: 534,017,344

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 534017344...
Checkpoint 534017344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.78616
Policy Entropy: 3.37284
Value Function Loss: 0.00351

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08614
Policy Update Magnitude: 0.54596
Value Function Update Magnitude: 0.65155

Collected Steps per Second: 22,849.92616
Overall Steps per Second: 10,811.89189

Timestep Collection Time: 2.18889
Timestep Consumption Time: 2.43713
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.62602

Cumulative Model Updates: 64,026
Cumulative Timesteps: 534,067,360

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066.12761
Policy Entropy: 3.36918
Value Function Loss: 0.00352

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07576
Policy Update Magnitude: 0.55073
Value Function Update Magnitude: 0.68645

Collected Steps per Second: 22,555.23528
Overall Steps per Second: 10,611.86331

Timestep Collection Time: 2.21784
Timestep Consumption Time: 2.49613
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.71397

Cumulative Model Updates: 64,032
Cumulative Timesteps: 534,117,384

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 534117384...
Checkpoint 534117384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,364.81565
Policy Entropy: 3.36732
Value Function Loss: 0.00354

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07931
Policy Update Magnitude: 0.54917
Value Function Update Magnitude: 0.70561

Collected Steps per Second: 23,102.56807
Overall Steps per Second: 10,853.01357

Timestep Collection Time: 2.16443
Timestep Consumption Time: 2.44295
PPO Batch Consumption Time: 0.28390
Total Iteration Time: 4.60738

Cumulative Model Updates: 64,038
Cumulative Timesteps: 534,167,388

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,454.89951
Policy Entropy: 3.36128
Value Function Loss: 0.00361

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08663
Policy Update Magnitude: 0.54315
Value Function Update Magnitude: 0.71417

Collected Steps per Second: 21,752.95293
Overall Steps per Second: 10,511.81509

Timestep Collection Time: 2.29918
Timestep Consumption Time: 2.45870
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.75788

Cumulative Model Updates: 64,044
Cumulative Timesteps: 534,217,402

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 534217402...
Checkpoint 534217402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 804.91600
Policy Entropy: 3.35170
Value Function Loss: 0.00383

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.55176
Value Function Update Magnitude: 0.70129

Collected Steps per Second: 22,411.03963
Overall Steps per Second: 10,605.07358

Timestep Collection Time: 2.23167
Timestep Consumption Time: 2.48438
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.71604

Cumulative Model Updates: 64,050
Cumulative Timesteps: 534,267,416

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 918.90369
Policy Entropy: 3.35611
Value Function Loss: 0.00363

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09007
Policy Update Magnitude: 0.55655
Value Function Update Magnitude: 0.68113

Collected Steps per Second: 22,112.52438
Overall Steps per Second: 10,482.26357

Timestep Collection Time: 2.26134
Timestep Consumption Time: 2.50900
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.77034

Cumulative Model Updates: 64,056
Cumulative Timesteps: 534,317,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 534317420...
Checkpoint 534317420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.56192
Policy Entropy: 3.35090
Value Function Loss: 0.00385

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07857
Policy Update Magnitude: 0.55628
Value Function Update Magnitude: 0.68888

Collected Steps per Second: 22,485.49539
Overall Steps per Second: 10,614.00805

Timestep Collection Time: 2.22366
Timestep Consumption Time: 2.48710
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.71076

Cumulative Model Updates: 64,062
Cumulative Timesteps: 534,367,420

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.32567
Policy Entropy: 3.36377
Value Function Loss: 0.00358

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08137
Policy Update Magnitude: 0.56187
Value Function Update Magnitude: 0.73511

Collected Steps per Second: 22,395.71650
Overall Steps per Second: 10,524.62953

Timestep Collection Time: 2.23302
Timestep Consumption Time: 2.51869
PPO Batch Consumption Time: 0.29667
Total Iteration Time: 4.75171

Cumulative Model Updates: 64,068
Cumulative Timesteps: 534,417,430

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 534417430...
Checkpoint 534417430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.14388
Policy Entropy: 3.34717
Value Function Loss: 0.00377

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07418
Policy Update Magnitude: 0.56300
Value Function Update Magnitude: 0.72461

Collected Steps per Second: 22,433.15748
Overall Steps per Second: 10,580.15414

Timestep Collection Time: 2.22947
Timestep Consumption Time: 2.49768
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.72715

Cumulative Model Updates: 64,074
Cumulative Timesteps: 534,467,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384.97204
Policy Entropy: 3.34752
Value Function Loss: 0.00359

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07167
Policy Update Magnitude: 0.56390
Value Function Update Magnitude: 0.70824

Collected Steps per Second: 22,830.60943
Overall Steps per Second: 10,595.45100

Timestep Collection Time: 2.19092
Timestep Consumption Time: 2.52998
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.72089

Cumulative Model Updates: 64,080
Cumulative Timesteps: 534,517,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 534517464...
Checkpoint 534517464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 814.59865
Policy Entropy: 3.34478
Value Function Loss: 0.00377

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.06898
Policy Update Magnitude: 0.55998
Value Function Update Magnitude: 0.68257

Collected Steps per Second: 22,939.58228
Overall Steps per Second: 10,658.32450

Timestep Collection Time: 2.17990
Timestep Consumption Time: 2.51183
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.69173

Cumulative Model Updates: 64,086
Cumulative Timesteps: 534,567,470

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.93333
Policy Entropy: 3.35342
Value Function Loss: 0.00361

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08766
Policy Update Magnitude: 0.56273
Value Function Update Magnitude: 0.67976

Collected Steps per Second: 21,953.57886
Overall Steps per Second: 10,706.14750

Timestep Collection Time: 2.27854
Timestep Consumption Time: 2.39373
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.67227

Cumulative Model Updates: 64,092
Cumulative Timesteps: 534,617,492

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 534617492...
Checkpoint 534617492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.82487
Policy Entropy: 3.33246
Value Function Loss: 0.00353

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.56173
Value Function Update Magnitude: 0.67393

Collected Steps per Second: 22,855.76286
Overall Steps per Second: 10,681.14666

Timestep Collection Time: 2.18964
Timestep Consumption Time: 2.49581
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.68545

Cumulative Model Updates: 64,098
Cumulative Timesteps: 534,667,538

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,609.41934
Policy Entropy: 3.31654
Value Function Loss: 0.00363

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08942
Policy Update Magnitude: 0.55624
Value Function Update Magnitude: 0.66910

Collected Steps per Second: 22,716.75284
Overall Steps per Second: 10,658.46010

Timestep Collection Time: 2.20146
Timestep Consumption Time: 2.49059
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.69205

Cumulative Model Updates: 64,104
Cumulative Timesteps: 534,717,548

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 534717548...
Checkpoint 534717548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 924.62182
Policy Entropy: 3.29942
Value Function Loss: 0.00366

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.56149
Value Function Update Magnitude: 0.66627

Collected Steps per Second: 22,347.38597
Overall Steps per Second: 10,825.86968

Timestep Collection Time: 2.23847
Timestep Consumption Time: 2.38231
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.62078

Cumulative Model Updates: 64,110
Cumulative Timesteps: 534,767,572

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.59083
Policy Entropy: 3.30851
Value Function Loss: 0.00375

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09936
Policy Update Magnitude: 0.56082
Value Function Update Magnitude: 0.67690

Collected Steps per Second: 22,075.81508
Overall Steps per Second: 10,657.54055

Timestep Collection Time: 2.26592
Timestep Consumption Time: 2.42766
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.69358

Cumulative Model Updates: 64,116
Cumulative Timesteps: 534,817,594

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 534817594...
Checkpoint 534817594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 820.34970
Policy Entropy: 3.30245
Value Function Loss: 0.00371

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09604
Policy Update Magnitude: 0.56633
Value Function Update Magnitude: 0.69472

Collected Steps per Second: 22,853.74517
Overall Steps per Second: 10,693.33043

Timestep Collection Time: 2.18905
Timestep Consumption Time: 2.48938
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.67843

Cumulative Model Updates: 64,122
Cumulative Timesteps: 534,867,622

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.66363
Policy Entropy: 3.31211
Value Function Loss: 0.00352

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.55803
Value Function Update Magnitude: 0.72298

Collected Steps per Second: 22,622.19264
Overall Steps per Second: 10,729.17996

Timestep Collection Time: 2.21022
Timestep Consumption Time: 2.44997
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.66019

Cumulative Model Updates: 64,128
Cumulative Timesteps: 534,917,622

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 534917622...
Checkpoint 534917622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 976.78432
Policy Entropy: 3.31332
Value Function Loss: 0.00342

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.55016
Value Function Update Magnitude: 0.70509

Collected Steps per Second: 22,412.32887
Overall Steps per Second: 10,612.04049

Timestep Collection Time: 2.23172
Timestep Consumption Time: 2.48161
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.71333

Cumulative Model Updates: 64,134
Cumulative Timesteps: 534,967,640

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627.76346
Policy Entropy: 3.30450
Value Function Loss: 0.00363

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09646
Policy Update Magnitude: 0.55262
Value Function Update Magnitude: 0.69837

Collected Steps per Second: 22,791.98593
Overall Steps per Second: 10,642.11097

Timestep Collection Time: 2.19489
Timestep Consumption Time: 2.50586
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.70076

Cumulative Model Updates: 64,140
Cumulative Timesteps: 535,017,666

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 535017666...
Checkpoint 535017666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.57060
Policy Entropy: 3.29934
Value Function Loss: 0.00379

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09227
Policy Update Magnitude: 0.56160
Value Function Update Magnitude: 0.70159

Collected Steps per Second: 22,453.46931
Overall Steps per Second: 10,504.77414

Timestep Collection Time: 2.22772
Timestep Consumption Time: 2.53393
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.76164

Cumulative Model Updates: 64,146
Cumulative Timesteps: 535,067,686

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.77853
Policy Entropy: 3.30718
Value Function Loss: 0.00373

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08337
Policy Update Magnitude: 0.56396
Value Function Update Magnitude: 0.69072

Collected Steps per Second: 22,868.23822
Overall Steps per Second: 10,751.05371

Timestep Collection Time: 2.18696
Timestep Consumption Time: 2.46486
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.65182

Cumulative Model Updates: 64,152
Cumulative Timesteps: 535,117,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 535117698...
Checkpoint 535117698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,465.81389
Policy Entropy: 3.33030
Value Function Loss: 0.00364

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07680
Policy Update Magnitude: 0.56119
Value Function Update Magnitude: 0.68542

Collected Steps per Second: 22,748.63320
Overall Steps per Second: 10,780.31260

Timestep Collection Time: 2.19820
Timestep Consumption Time: 2.44044
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.63864

Cumulative Model Updates: 64,158
Cumulative Timesteps: 535,167,704

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 796.59253
Policy Entropy: 3.33289
Value Function Loss: 0.00351

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09038
Policy Update Magnitude: 0.55454
Value Function Update Magnitude: 0.67600

Collected Steps per Second: 22,855.89174
Overall Steps per Second: 10,759.35369

Timestep Collection Time: 2.18867
Timestep Consumption Time: 2.46068
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.64935

Cumulative Model Updates: 64,164
Cumulative Timesteps: 535,217,728

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 535217728...
Checkpoint 535217728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.76366
Policy Entropy: 3.32718
Value Function Loss: 0.00352

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09266
Policy Update Magnitude: 0.55700
Value Function Update Magnitude: 0.66701

Collected Steps per Second: 22,526.91065
Overall Steps per Second: 10,701.22689

Timestep Collection Time: 2.22037
Timestep Consumption Time: 2.45368
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.67404

Cumulative Model Updates: 64,170
Cumulative Timesteps: 535,267,746

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 831.42264
Policy Entropy: 3.33241
Value Function Loss: 0.00358

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08278
Policy Update Magnitude: 0.56344
Value Function Update Magnitude: 0.65285

Collected Steps per Second: 22,648.30716
Overall Steps per Second: 10,571.59791

Timestep Collection Time: 2.20873
Timestep Consumption Time: 2.52319
PPO Batch Consumption Time: 0.29603
Total Iteration Time: 4.73192

Cumulative Model Updates: 64,176
Cumulative Timesteps: 535,317,770

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 535317770...
Checkpoint 535317770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.46153
Policy Entropy: 3.33495
Value Function Loss: 0.00376

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.56490
Value Function Update Magnitude: 0.65225

Collected Steps per Second: 23,062.82996
Overall Steps per Second: 10,717.09135

Timestep Collection Time: 2.16860
Timestep Consumption Time: 2.49815
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.66675

Cumulative Model Updates: 64,182
Cumulative Timesteps: 535,367,784

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.74478
Policy Entropy: 3.34338
Value Function Loss: 0.00373

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10447
Policy Update Magnitude: 0.56235
Value Function Update Magnitude: 0.65949

Collected Steps per Second: 22,323.17345
Overall Steps per Second: 10,662.97049

Timestep Collection Time: 2.24126
Timestep Consumption Time: 2.45087
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.69213

Cumulative Model Updates: 64,188
Cumulative Timesteps: 535,417,816

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 535417816...
Checkpoint 535417816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.42576
Policy Entropy: 3.33352
Value Function Loss: 0.00358

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10428
Policy Update Magnitude: 0.55463
Value Function Update Magnitude: 0.65076

Collected Steps per Second: 22,379.62263
Overall Steps per Second: 10,655.53660

Timestep Collection Time: 2.23525
Timestep Consumption Time: 2.45940
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.69465

Cumulative Model Updates: 64,194
Cumulative Timesteps: 535,467,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.22317
Policy Entropy: 3.33425
Value Function Loss: 0.00347

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09763
Policy Update Magnitude: 0.55188
Value Function Update Magnitude: 0.64413

Collected Steps per Second: 22,312.17699
Overall Steps per Second: 10,524.89991

Timestep Collection Time: 2.24093
Timestep Consumption Time: 2.50971
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.75064

Cumulative Model Updates: 64,200
Cumulative Timesteps: 535,517,840

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 535517840...
Checkpoint 535517840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.23435
Policy Entropy: 3.34656
Value Function Loss: 0.00342

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08681
Policy Update Magnitude: 0.54297
Value Function Update Magnitude: 0.63443

Collected Steps per Second: 22,175.88621
Overall Steps per Second: 10,664.72067

Timestep Collection Time: 2.25488
Timestep Consumption Time: 2.43385
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.68873

Cumulative Model Updates: 64,206
Cumulative Timesteps: 535,567,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.47220
Policy Entropy: 3.35545
Value Function Loss: 0.00347

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08136
Policy Update Magnitude: 0.54368
Value Function Update Magnitude: 0.62550

Collected Steps per Second: 22,941.27528
Overall Steps per Second: 10,775.13910

Timestep Collection Time: 2.18070
Timestep Consumption Time: 2.46221
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.64291

Cumulative Model Updates: 64,212
Cumulative Timesteps: 535,617,872

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 535617872...
Checkpoint 535617872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 759.44796
Policy Entropy: 3.35379
Value Function Loss: 0.00346

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07093
Policy Update Magnitude: 0.54908
Value Function Update Magnitude: 0.62032

Collected Steps per Second: 22,647.42472
Overall Steps per Second: 10,642.29072

Timestep Collection Time: 2.20829
Timestep Consumption Time: 2.49108
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.69936

Cumulative Model Updates: 64,218
Cumulative Timesteps: 535,667,884

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 820.42136
Policy Entropy: 3.36015
Value Function Loss: 0.00355

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07350
Policy Update Magnitude: 0.55394
Value Function Update Magnitude: 0.63111

Collected Steps per Second: 23,033.99515
Overall Steps per Second: 10,679.14595

Timestep Collection Time: 2.17183
Timestep Consumption Time: 2.51262
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.68446

Cumulative Model Updates: 64,224
Cumulative Timesteps: 535,717,910

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 535717910...
Checkpoint 535717910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,661.34521
Policy Entropy: 3.33457
Value Function Loss: 0.00377

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08005
Policy Update Magnitude: 0.56037
Value Function Update Magnitude: 0.66216

Collected Steps per Second: 22,776.11427
Overall Steps per Second: 10,661.83346

Timestep Collection Time: 2.19546
Timestep Consumption Time: 2.49454
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.69000

Cumulative Model Updates: 64,230
Cumulative Timesteps: 535,767,914

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 867.12338
Policy Entropy: 3.32403
Value Function Loss: 0.00391

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09702
Policy Update Magnitude: 0.56581
Value Function Update Magnitude: 0.67745

Collected Steps per Second: 23,269.25117
Overall Steps per Second: 10,724.52436

Timestep Collection Time: 2.14970
Timestep Consumption Time: 2.51456
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.66426

Cumulative Model Updates: 64,236
Cumulative Timesteps: 535,817,936

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 535817936...
Checkpoint 535817936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.46863
Policy Entropy: 3.30178
Value Function Loss: 0.00390

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11093
Policy Update Magnitude: 0.56802
Value Function Update Magnitude: 0.66780

Collected Steps per Second: 22,575.05753
Overall Steps per Second: 10,605.91078

Timestep Collection Time: 2.21590
Timestep Consumption Time: 2.50072
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.71662

Cumulative Model Updates: 64,242
Cumulative Timesteps: 535,867,960

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.15659
Policy Entropy: 3.33207
Value Function Loss: 0.00390

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11640
Policy Update Magnitude: 0.56223
Value Function Update Magnitude: 0.66218

Collected Steps per Second: 22,254.29412
Overall Steps per Second: 10,511.88242

Timestep Collection Time: 2.24676
Timestep Consumption Time: 2.50976
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.75652

Cumulative Model Updates: 64,248
Cumulative Timesteps: 535,917,960

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 535917960...
Checkpoint 535917960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 901.74605
Policy Entropy: 3.34884
Value Function Loss: 0.00367

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11123
Policy Update Magnitude: 0.55506
Value Function Update Magnitude: 0.66141

Collected Steps per Second: 21,663.65653
Overall Steps per Second: 10,543.48009

Timestep Collection Time: 2.30820
Timestep Consumption Time: 2.43445
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.74265

Cumulative Model Updates: 64,254
Cumulative Timesteps: 535,967,964

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.64287
Policy Entropy: 3.37539
Value Function Loss: 0.00357

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08665
Policy Update Magnitude: 0.54525
Value Function Update Magnitude: 0.64811

Collected Steps per Second: 22,241.44630
Overall Steps per Second: 10,570.50906

Timestep Collection Time: 2.24868
Timestep Consumption Time: 2.48278
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.73147

Cumulative Model Updates: 64,260
Cumulative Timesteps: 536,017,978

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 536017978...
Checkpoint 536017978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.71751
Policy Entropy: 3.37410
Value Function Loss: 0.00336

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.54381
Value Function Update Magnitude: 0.63957

Collected Steps per Second: 22,444.81523
Overall Steps per Second: 10,659.36512

Timestep Collection Time: 2.22804
Timestep Consumption Time: 2.46342
PPO Batch Consumption Time: 0.28220
Total Iteration Time: 4.69146

Cumulative Model Updates: 64,266
Cumulative Timesteps: 536,067,986

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 951.65377
Policy Entropy: 3.37359
Value Function Loss: 0.00338

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08274
Policy Update Magnitude: 0.53634
Value Function Update Magnitude: 0.63078

Collected Steps per Second: 22,589.14174
Overall Steps per Second: 10,526.93137

Timestep Collection Time: 2.21452
Timestep Consumption Time: 2.53749
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.75200

Cumulative Model Updates: 64,272
Cumulative Timesteps: 536,118,010

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 536118010...
Checkpoint 536118010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.12235
Policy Entropy: 3.35887
Value Function Loss: 0.00341

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08452
Policy Update Magnitude: 0.54502
Value Function Update Magnitude: 0.62722

Collected Steps per Second: 22,744.72064
Overall Steps per Second: 10,552.11243

Timestep Collection Time: 2.19875
Timestep Consumption Time: 2.54058
PPO Batch Consumption Time: 0.29653
Total Iteration Time: 4.73934

Cumulative Model Updates: 64,278
Cumulative Timesteps: 536,168,020

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.34969
Policy Entropy: 3.35328
Value Function Loss: 0.00356

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09424
Policy Update Magnitude: 0.54903
Value Function Update Magnitude: 0.62520

Collected Steps per Second: 22,928.96855
Overall Steps per Second: 10,768.51121

Timestep Collection Time: 2.18169
Timestep Consumption Time: 2.46370
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.64540

Cumulative Model Updates: 64,284
Cumulative Timesteps: 536,218,044

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 536218044...
Checkpoint 536218044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581.10048
Policy Entropy: 3.34620
Value Function Loss: 0.00365

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09532
Policy Update Magnitude: 0.55134
Value Function Update Magnitude: 0.62670

Collected Steps per Second: 22,642.60668
Overall Steps per Second: 10,734.25846

Timestep Collection Time: 2.20999
Timestep Consumption Time: 2.45172
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.66171

Cumulative Model Updates: 64,290
Cumulative Timesteps: 536,268,084

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 805.59620
Policy Entropy: 3.34738
Value Function Loss: 0.00349

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11515
Policy Update Magnitude: 0.54380
Value Function Update Magnitude: 0.62226

Collected Steps per Second: 22,859.38731
Overall Steps per Second: 10,645.51126

Timestep Collection Time: 2.18851
Timestep Consumption Time: 2.51094
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.69945

Cumulative Model Updates: 64,296
Cumulative Timesteps: 536,318,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 536318112...
Checkpoint 536318112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.43582
Policy Entropy: 3.34399
Value Function Loss: 0.00356

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08817
Policy Update Magnitude: 0.54428
Value Function Update Magnitude: 0.61163

Collected Steps per Second: 22,954.81083
Overall Steps per Second: 10,802.33031

Timestep Collection Time: 2.17933
Timestep Consumption Time: 2.45171
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.63104

Cumulative Model Updates: 64,302
Cumulative Timesteps: 536,368,138

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,704.96548
Policy Entropy: 3.34714
Value Function Loss: 0.00363

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08138
Policy Update Magnitude: 0.55782
Value Function Update Magnitude: 0.62020

Collected Steps per Second: 22,807.78009
Overall Steps per Second: 10,602.72163

Timestep Collection Time: 2.19302
Timestep Consumption Time: 2.52444
PPO Batch Consumption Time: 0.29818
Total Iteration Time: 4.71747

Cumulative Model Updates: 64,308
Cumulative Timesteps: 536,418,156

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 536418156...
Checkpoint 536418156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 909.62425
Policy Entropy: 3.34117
Value Function Loss: 0.00353

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07465
Policy Update Magnitude: 0.56206
Value Function Update Magnitude: 0.62364

Collected Steps per Second: 22,147.30946
Overall Steps per Second: 10,644.89952

Timestep Collection Time: 2.25815
Timestep Consumption Time: 2.44006
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.69821

Cumulative Model Updates: 64,314
Cumulative Timesteps: 536,468,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.16139
Policy Entropy: 3.34480
Value Function Loss: 0.00363

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.06768
Policy Update Magnitude: 0.56095
Value Function Update Magnitude: 0.61120

Collected Steps per Second: 22,851.62971
Overall Steps per Second: 10,790.72352

Timestep Collection Time: 2.18864
Timestep Consumption Time: 2.44627
PPO Batch Consumption Time: 0.28243
Total Iteration Time: 4.63491

Cumulative Model Updates: 64,320
Cumulative Timesteps: 536,518,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 536518182...
Checkpoint 536518182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 729.96519
Policy Entropy: 3.34903
Value Function Loss: 0.00365

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07581
Policy Update Magnitude: 0.56448
Value Function Update Magnitude: 0.63707

Collected Steps per Second: 22,491.44688
Overall Steps per Second: 10,702.78650

Timestep Collection Time: 2.22387
Timestep Consumption Time: 2.44949
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.67336

Cumulative Model Updates: 64,326
Cumulative Timesteps: 536,568,200

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 866.86126
Policy Entropy: 3.34482
Value Function Loss: 0.00370

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07922
Policy Update Magnitude: 0.56634
Value Function Update Magnitude: 0.66475

Collected Steps per Second: 22,469.24607
Overall Steps per Second: 10,526.00943

Timestep Collection Time: 2.22606
Timestep Consumption Time: 2.52578
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.75185

Cumulative Model Updates: 64,332
Cumulative Timesteps: 536,618,218

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 536618218...
Checkpoint 536618218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723.45720
Policy Entropy: 3.33956
Value Function Loss: 0.00366

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.56236
Value Function Update Magnitude: 0.65922

Collected Steps per Second: 22,272.19204
Overall Steps per Second: 10,598.86108

Timestep Collection Time: 2.24531
Timestep Consumption Time: 2.47293
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.71824

Cumulative Model Updates: 64,338
Cumulative Timesteps: 536,668,226

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469.30068
Policy Entropy: 3.34865
Value Function Loss: 0.00352

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07813
Policy Update Magnitude: 0.55605
Value Function Update Magnitude: 0.64306

Collected Steps per Second: 22,819.05383
Overall Steps per Second: 10,584.02722

Timestep Collection Time: 2.19168
Timestep Consumption Time: 2.53356
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.72523

Cumulative Model Updates: 64,344
Cumulative Timesteps: 536,718,238

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 536718238...
Checkpoint 536718238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 743.50780
Policy Entropy: 3.34378
Value Function Loss: 0.00336

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07325
Policy Update Magnitude: 0.54401
Value Function Update Magnitude: 0.62545

Collected Steps per Second: 22,777.33143
Overall Steps per Second: 10,619.23406

Timestep Collection Time: 2.19560
Timestep Consumption Time: 2.51378
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.70938

Cumulative Model Updates: 64,350
Cumulative Timesteps: 536,768,248

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 946.74936
Policy Entropy: 3.34283
Value Function Loss: 0.00337

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07249
Policy Update Magnitude: 0.54324
Value Function Update Magnitude: 0.60179

Collected Steps per Second: 23,260.34015
Overall Steps per Second: 10,764.74117

Timestep Collection Time: 2.15079
Timestep Consumption Time: 2.49661
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.64739

Cumulative Model Updates: 64,356
Cumulative Timesteps: 536,818,276

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 536818276...
Checkpoint 536818276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 922.52190
Policy Entropy: 3.34105
Value Function Loss: 0.00341

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08799
Policy Update Magnitude: 0.54031
Value Function Update Magnitude: 0.61354

Collected Steps per Second: 22,338.59250
Overall Steps per Second: 10,671.41187

Timestep Collection Time: 2.23917
Timestep Consumption Time: 2.44812
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.68729

Cumulative Model Updates: 64,362
Cumulative Timesteps: 536,868,296

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.14129
Policy Entropy: 3.35126
Value Function Loss: 0.00355

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08710
Policy Update Magnitude: 0.54176
Value Function Update Magnitude: 0.62427

Collected Steps per Second: 22,957.53297
Overall Steps per Second: 10,838.60721

Timestep Collection Time: 2.17811
Timestep Consumption Time: 2.43540
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.61351

Cumulative Model Updates: 64,368
Cumulative Timesteps: 536,918,300

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 536918300...
Checkpoint 536918300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725.12520
Policy Entropy: 3.36266
Value Function Loss: 0.00371

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.54892
Value Function Update Magnitude: 0.64837

Collected Steps per Second: 22,550.99662
Overall Steps per Second: 10,732.51001

Timestep Collection Time: 2.21800
Timestep Consumption Time: 2.44242
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.66042

Cumulative Model Updates: 64,374
Cumulative Timesteps: 536,968,318

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,470.56263
Policy Entropy: 3.36274
Value Function Loss: 0.00375

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.55656
Value Function Update Magnitude: 0.66045

Collected Steps per Second: 22,604.53570
Overall Steps per Second: 10,784.85491

Timestep Collection Time: 2.21256
Timestep Consumption Time: 2.42486
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.63743

Cumulative Model Updates: 64,380
Cumulative Timesteps: 537,018,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 537018332...
Checkpoint 537018332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 881.91211
Policy Entropy: 3.35644
Value Function Loss: 0.00369

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09029
Policy Update Magnitude: 0.56174
Value Function Update Magnitude: 0.66933

Collected Steps per Second: 22,201.68434
Overall Steps per Second: 10,656.81671

Timestep Collection Time: 2.25307
Timestep Consumption Time: 2.44082
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.69390

Cumulative Model Updates: 64,386
Cumulative Timesteps: 537,068,354

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,446.08993
Policy Entropy: 3.36252
Value Function Loss: 0.00361

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08592
Policy Update Magnitude: 0.55666
Value Function Update Magnitude: 0.66415

Collected Steps per Second: 22,253.08603
Overall Steps per Second: 10,543.41264

Timestep Collection Time: 2.24751
Timestep Consumption Time: 2.49612
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.74363

Cumulative Model Updates: 64,392
Cumulative Timesteps: 537,118,368

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 537118368...
Checkpoint 537118368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 882.40873
Policy Entropy: 3.36055
Value Function Loss: 0.00355

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.07861
Policy Update Magnitude: 0.55039
Value Function Update Magnitude: 0.64019

Collected Steps per Second: 22,372.12732
Overall Steps per Second: 10,623.83131

Timestep Collection Time: 2.23519
Timestep Consumption Time: 2.47177
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.70696

Cumulative Model Updates: 64,398
Cumulative Timesteps: 537,168,374

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 864.19667
Policy Entropy: 3.35205
Value Function Loss: 0.00351

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08348
Policy Update Magnitude: 0.54680
Value Function Update Magnitude: 0.61333

Collected Steps per Second: 22,588.79246
Overall Steps per Second: 10,617.61129

Timestep Collection Time: 2.21490
Timestep Consumption Time: 2.49727
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.71217

Cumulative Model Updates: 64,404
Cumulative Timesteps: 537,218,406

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 537218406...
Checkpoint 537218406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.91040
Policy Entropy: 3.34546
Value Function Loss: 0.00332

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08383
Policy Update Magnitude: 0.53273
Value Function Update Magnitude: 0.60368

Collected Steps per Second: 22,824.99669
Overall Steps per Second: 10,824.91833

Timestep Collection Time: 2.19163
Timestep Consumption Time: 2.42956
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.62119

Cumulative Model Updates: 64,410
Cumulative Timesteps: 537,268,430

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.96207
Policy Entropy: 3.33941
Value Function Loss: 0.00357

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07458
Policy Update Magnitude: 0.53112
Value Function Update Magnitude: 0.61928

Collected Steps per Second: 22,800.94917
Overall Steps per Second: 10,686.53752

Timestep Collection Time: 2.19421
Timestep Consumption Time: 2.48738
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.68159

Cumulative Model Updates: 64,416
Cumulative Timesteps: 537,318,460

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 537318460...
Checkpoint 537318460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.63839
Policy Entropy: 3.33092
Value Function Loss: 0.00368

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08444
Policy Update Magnitude: 0.54689
Value Function Update Magnitude: 0.65293

Collected Steps per Second: 22,656.03926
Overall Steps per Second: 10,689.34753

Timestep Collection Time: 2.20798
Timestep Consumption Time: 2.47182
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.67980

Cumulative Model Updates: 64,422
Cumulative Timesteps: 537,368,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.85250
Policy Entropy: 3.32593
Value Function Loss: 0.00382

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09468
Policy Update Magnitude: 0.55491
Value Function Update Magnitude: 0.68344

Collected Steps per Second: 23,308.12947
Overall Steps per Second: 10,740.45935

Timestep Collection Time: 2.14535
Timestep Consumption Time: 2.51032
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.65567

Cumulative Model Updates: 64,428
Cumulative Timesteps: 537,418,488

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 537418488...
Checkpoint 537418488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,379.77844
Policy Entropy: 3.34100
Value Function Loss: 0.00366

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09114
Policy Update Magnitude: 0.54824
Value Function Update Magnitude: 0.68629

Collected Steps per Second: 22,525.29027
Overall Steps per Second: 10,617.34385

Timestep Collection Time: 2.21990
Timestep Consumption Time: 2.48975
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.70965

Cumulative Model Updates: 64,434
Cumulative Timesteps: 537,468,492

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 968.63494
Policy Entropy: 3.34192
Value Function Loss: 0.00359

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08247
Policy Update Magnitude: 0.54662
Value Function Update Magnitude: 0.67222

Collected Steps per Second: 22,131.40832
Overall Steps per Second: 10,480.76898

Timestep Collection Time: 2.26023
Timestep Consumption Time: 2.51251
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 4.77274

Cumulative Model Updates: 64,440
Cumulative Timesteps: 537,518,514

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 537518514...
Checkpoint 537518514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.96946
Policy Entropy: 3.34413
Value Function Loss: 0.00372

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.55282
Value Function Update Magnitude: 0.66326

Collected Steps per Second: 21,889.68518
Overall Steps per Second: 10,585.40709

Timestep Collection Time: 2.28464
Timestep Consumption Time: 2.43979
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.72443

Cumulative Model Updates: 64,446
Cumulative Timesteps: 537,568,524

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.07824
Policy Entropy: 3.35031
Value Function Loss: 0.00367

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08431
Policy Update Magnitude: 0.56138
Value Function Update Magnitude: 0.69175

Collected Steps per Second: 22,523.56952
Overall Steps per Second: 10,591.72118

Timestep Collection Time: 2.21999
Timestep Consumption Time: 2.50087
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.72086

Cumulative Model Updates: 64,452
Cumulative Timesteps: 537,618,526

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 537618526...
Checkpoint 537618526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 729.11574
Policy Entropy: 3.35129
Value Function Loss: 0.00374

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08005
Policy Update Magnitude: 0.56157
Value Function Update Magnitude: 0.70609

Collected Steps per Second: 22,078.75982
Overall Steps per Second: 10,524.19252

Timestep Collection Time: 2.26553
Timestep Consumption Time: 2.48733
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.75286

Cumulative Model Updates: 64,458
Cumulative Timesteps: 537,668,546

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.51104
Policy Entropy: 3.35749
Value Function Loss: 0.00352

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.07990
Policy Update Magnitude: 0.55577
Value Function Update Magnitude: 0.71953

Collected Steps per Second: 22,886.87196
Overall Steps per Second: 10,605.64053

Timestep Collection Time: 2.18483
Timestep Consumption Time: 2.53002
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.71485

Cumulative Model Updates: 64,464
Cumulative Timesteps: 537,718,550

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 537718550...
Checkpoint 537718550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.22444
Policy Entropy: 3.35275
Value Function Loss: 0.00359

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07463
Policy Update Magnitude: 0.55240
Value Function Update Magnitude: 0.72438

Collected Steps per Second: 22,900.04672
Overall Steps per Second: 10,821.69243

Timestep Collection Time: 2.18471
Timestep Consumption Time: 2.43841
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.62312

Cumulative Model Updates: 64,470
Cumulative Timesteps: 537,768,580

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 895.47091
Policy Entropy: 3.35179
Value Function Loss: 0.00356

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07330
Policy Update Magnitude: 0.55810
Value Function Update Magnitude: 0.71038

Collected Steps per Second: 22,779.52045
Overall Steps per Second: 10,662.94179

Timestep Collection Time: 2.19592
Timestep Consumption Time: 2.49528
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.69120

Cumulative Model Updates: 64,476
Cumulative Timesteps: 537,818,602

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 537818602...
Checkpoint 537818602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.41720
Policy Entropy: 3.35467
Value Function Loss: 0.00360

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08538
Policy Update Magnitude: 0.55074
Value Function Update Magnitude: 0.70090

Collected Steps per Second: 21,290.09405
Overall Steps per Second: 10,445.31019

Timestep Collection Time: 2.34907
Timestep Consumption Time: 2.43891
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.78799

Cumulative Model Updates: 64,482
Cumulative Timesteps: 537,868,614

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.92321
Policy Entropy: 3.37428
Value Function Loss: 0.00366

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09261
Policy Update Magnitude: 0.55230
Value Function Update Magnitude: 0.70414

Collected Steps per Second: 22,906.37425
Overall Steps per Second: 10,743.53318

Timestep Collection Time: 2.18332
Timestep Consumption Time: 2.47176
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.65508

Cumulative Model Updates: 64,488
Cumulative Timesteps: 537,918,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 537918626...
Checkpoint 537918626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 960.46476
Policy Entropy: 3.37437
Value Function Loss: 0.00362

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.07874
Policy Update Magnitude: 0.54379
Value Function Update Magnitude: 0.70462

Collected Steps per Second: 22,774.08161
Overall Steps per Second: 10,831.64566

Timestep Collection Time: 2.19680
Timestep Consumption Time: 2.42208
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.61887

Cumulative Model Updates: 64,494
Cumulative Timesteps: 537,968,656

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416.03862
Policy Entropy: 3.36561
Value Function Loss: 0.00351

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.07834
Policy Update Magnitude: 0.54311
Value Function Update Magnitude: 0.68113

Collected Steps per Second: 22,350.38649
Overall Steps per Second: 10,536.50000

Timestep Collection Time: 2.23755
Timestep Consumption Time: 2.50881
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.74636

Cumulative Model Updates: 64,500
Cumulative Timesteps: 538,018,666

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 538018666...
Checkpoint 538018666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,506.04903
Policy Entropy: 3.35087
Value Function Loss: 0.00369

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07760
Policy Update Magnitude: 0.54134
Value Function Update Magnitude: 0.67978

Collected Steps per Second: 22,073.71923
Overall Steps per Second: 10,685.49778

Timestep Collection Time: 2.26541
Timestep Consumption Time: 2.41439
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.67980

Cumulative Model Updates: 64,506
Cumulative Timesteps: 538,068,672

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,405.02185
Policy Entropy: 3.35876
Value Function Loss: 0.00357

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07878
Policy Update Magnitude: 0.54635
Value Function Update Magnitude: 0.68328

Collected Steps per Second: 22,369.41412
Overall Steps per Second: 10,616.59319

Timestep Collection Time: 2.23537
Timestep Consumption Time: 2.47461
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.70999

Cumulative Model Updates: 64,512
Cumulative Timesteps: 538,118,676

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 538118676...
Checkpoint 538118676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.51315
Policy Entropy: 3.35184
Value Function Loss: 0.00360

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07814
Policy Update Magnitude: 0.54899
Value Function Update Magnitude: 0.67392

Collected Steps per Second: 22,551.28104
Overall Steps per Second: 10,789.61115

Timestep Collection Time: 2.21814
Timestep Consumption Time: 2.41798
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.63613

Cumulative Model Updates: 64,518
Cumulative Timesteps: 538,168,698

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.78023
Policy Entropy: 3.35845
Value Function Loss: 0.00355

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08219
Policy Update Magnitude: 0.54986
Value Function Update Magnitude: 0.66786

Collected Steps per Second: 22,789.48614
Overall Steps per Second: 10,653.71538

Timestep Collection Time: 2.19461
Timestep Consumption Time: 2.49990
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.69451

Cumulative Model Updates: 64,524
Cumulative Timesteps: 538,218,712

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 538218712...
Checkpoint 538218712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 746.42570
Policy Entropy: 3.34646
Value Function Loss: 0.00368

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08362
Policy Update Magnitude: 0.55423
Value Function Update Magnitude: 0.67115

Collected Steps per Second: 22,703.33169
Overall Steps per Second: 10,677.23427

Timestep Collection Time: 2.20276
Timestep Consumption Time: 2.48104
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.68380

Cumulative Model Updates: 64,530
Cumulative Timesteps: 538,268,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 977.18403
Policy Entropy: 3.34492
Value Function Loss: 0.00354

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07836
Policy Update Magnitude: 0.55450
Value Function Update Magnitude: 0.66051

Collected Steps per Second: 22,914.07588
Overall Steps per Second: 10,775.75038

Timestep Collection Time: 2.18241
Timestep Consumption Time: 2.45838
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.64079

Cumulative Model Updates: 64,536
Cumulative Timesteps: 538,318,730

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 538318730...
Checkpoint 538318730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300.01001
Policy Entropy: 3.34572
Value Function Loss: 0.00344

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07897
Policy Update Magnitude: 0.54379
Value Function Update Magnitude: 0.63623

Collected Steps per Second: 22,990.37661
Overall Steps per Second: 10,687.63708

Timestep Collection Time: 2.17491
Timestep Consumption Time: 2.50358
PPO Batch Consumption Time: 0.29716
Total Iteration Time: 4.67849

Cumulative Model Updates: 64,542
Cumulative Timesteps: 538,368,732

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.95710
Policy Entropy: 3.33015
Value Function Loss: 0.00345

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.07794
Policy Update Magnitude: 0.53983
Value Function Update Magnitude: 0.61369

Collected Steps per Second: 22,949.62644
Overall Steps per Second: 10,845.71102

Timestep Collection Time: 2.17868
Timestep Consumption Time: 2.43143
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.61012

Cumulative Model Updates: 64,548
Cumulative Timesteps: 538,418,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 538418732...
Checkpoint 538418732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 998.15029
Policy Entropy: 3.32826
Value Function Loss: 0.00346

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08084
Policy Update Magnitude: 0.54428
Value Function Update Magnitude: 0.60404

Collected Steps per Second: 22,399.35427
Overall Steps per Second: 10,626.81013

Timestep Collection Time: 2.23301
Timestep Consumption Time: 2.47376
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.70677

Cumulative Model Updates: 64,554
Cumulative Timesteps: 538,468,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.70015
Policy Entropy: 3.32887
Value Function Loss: 0.00340

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.54401
Value Function Update Magnitude: 0.61802

Collected Steps per Second: 22,461.95634
Overall Steps per Second: 10,645.07820

Timestep Collection Time: 2.22670
Timestep Consumption Time: 2.47181
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.69851

Cumulative Model Updates: 64,560
Cumulative Timesteps: 538,518,766

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 538518766...
Checkpoint 538518766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.84121
Policy Entropy: 3.33107
Value Function Loss: 0.00354

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10117
Policy Update Magnitude: 0.53970
Value Function Update Magnitude: 0.64111

Collected Steps per Second: 22,169.51830
Overall Steps per Second: 10,509.84916

Timestep Collection Time: 2.25562
Timestep Consumption Time: 2.50239
PPO Batch Consumption Time: 0.29670
Total Iteration Time: 4.75801

Cumulative Model Updates: 64,566
Cumulative Timesteps: 538,568,772

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.41222
Policy Entropy: 3.33918
Value Function Loss: 0.00351

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09630
Policy Update Magnitude: 0.54291
Value Function Update Magnitude: 0.64965

Collected Steps per Second: 22,285.78925
Overall Steps per Second: 10,607.82223

Timestep Collection Time: 2.24421
Timestep Consumption Time: 2.47061
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.71482

Cumulative Model Updates: 64,572
Cumulative Timesteps: 538,618,786

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 538618786...
Checkpoint 538618786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.25255
Policy Entropy: 3.33674
Value Function Loss: 0.00370

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10118
Policy Update Magnitude: 0.54567
Value Function Update Magnitude: 0.63152

Collected Steps per Second: 22,146.16281
Overall Steps per Second: 10,571.68621

Timestep Collection Time: 2.25809
Timestep Consumption Time: 2.47228
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.73037

Cumulative Model Updates: 64,578
Cumulative Timesteps: 538,668,794

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 997.84501
Policy Entropy: 3.34451
Value Function Loss: 0.00360

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09300
Policy Update Magnitude: 0.53990
Value Function Update Magnitude: 0.64712

Collected Steps per Second: 22,312.76055
Overall Steps per Second: 10,664.54951

Timestep Collection Time: 2.24141
Timestep Consumption Time: 2.44815
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.68956

Cumulative Model Updates: 64,584
Cumulative Timesteps: 538,718,806

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 538718806...
Checkpoint 538718806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 796.10740
Policy Entropy: 3.33358
Value Function Loss: 0.00348

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08529
Policy Update Magnitude: 0.53870
Value Function Update Magnitude: 0.63691

Collected Steps per Second: 22,680.13716
Overall Steps per Second: 10,761.20418

Timestep Collection Time: 2.20563
Timestep Consumption Time: 2.44292
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.64855

Cumulative Model Updates: 64,590
Cumulative Timesteps: 538,768,830

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 759.26834
Policy Entropy: 3.33779
Value Function Loss: 0.00342

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08023
Policy Update Magnitude: 0.53774
Value Function Update Magnitude: 0.64241

Collected Steps per Second: 22,763.36245
Overall Steps per Second: 10,765.68584

Timestep Collection Time: 2.19774
Timestep Consumption Time: 2.44924
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.64699

Cumulative Model Updates: 64,596
Cumulative Timesteps: 538,818,858

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 538818858...
Checkpoint 538818858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 867.75425
Policy Entropy: 3.33869
Value Function Loss: 0.00344

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08225
Policy Update Magnitude: 0.54385
Value Function Update Magnitude: 0.65375

Collected Steps per Second: 22,219.62468
Overall Steps per Second: 10,668.88893

Timestep Collection Time: 2.25170
Timestep Consumption Time: 2.43782
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.68952

Cumulative Model Updates: 64,602
Cumulative Timesteps: 538,868,890

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542.96770
Policy Entropy: 3.34584
Value Function Loss: 0.00338

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07663
Policy Update Magnitude: 0.55002
Value Function Update Magnitude: 0.66208

Collected Steps per Second: 22,719.32978
Overall Steps per Second: 10,643.06796

Timestep Collection Time: 2.20121
Timestep Consumption Time: 2.49762
PPO Batch Consumption Time: 0.29556
Total Iteration Time: 4.69883

Cumulative Model Updates: 64,608
Cumulative Timesteps: 538,918,900

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 538918900...
Checkpoint 538918900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,628.07958
Policy Entropy: 3.33607
Value Function Loss: 0.00354

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07130
Policy Update Magnitude: 0.55020
Value Function Update Magnitude: 0.67064

Collected Steps per Second: 22,673.33039
Overall Steps per Second: 10,630.29576

Timestep Collection Time: 2.20673
Timestep Consumption Time: 2.50000
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 4.70674

Cumulative Model Updates: 64,614
Cumulative Timesteps: 538,968,934

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.18353
Policy Entropy: 3.35194
Value Function Loss: 0.00361

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07706
Policy Update Magnitude: 0.54983
Value Function Update Magnitude: 0.66749

Collected Steps per Second: 22,779.83575
Overall Steps per Second: 10,808.89285

Timestep Collection Time: 2.19607
Timestep Consumption Time: 2.43216
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.62823

Cumulative Model Updates: 64,620
Cumulative Timesteps: 539,018,960

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 539018960...
Checkpoint 539018960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,860.35478
Policy Entropy: 3.35005
Value Function Loss: 0.00376

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07376
Policy Update Magnitude: 0.55473
Value Function Update Magnitude: 0.69480

Collected Steps per Second: 21,896.56617
Overall Steps per Second: 10,611.24374

Timestep Collection Time: 2.28474
Timestep Consumption Time: 2.42988
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.71462

Cumulative Model Updates: 64,626
Cumulative Timesteps: 539,068,988

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 776.01346
Policy Entropy: 3.34610
Value Function Loss: 0.00353

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07457
Policy Update Magnitude: 0.55977
Value Function Update Magnitude: 0.68937

Collected Steps per Second: 22,313.90740
Overall Steps per Second: 10,548.29160

Timestep Collection Time: 2.24129
Timestep Consumption Time: 2.49995
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.74124

Cumulative Model Updates: 64,632
Cumulative Timesteps: 539,119,000

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 539119000...
Checkpoint 539119000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 996.14020
Policy Entropy: 3.34146
Value Function Loss: 0.00357

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08378
Policy Update Magnitude: 0.55344
Value Function Update Magnitude: 0.69408

Collected Steps per Second: 22,232.68332
Overall Steps per Second: 10,686.69460

Timestep Collection Time: 2.24939
Timestep Consumption Time: 2.43026
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.67965

Cumulative Model Updates: 64,638
Cumulative Timesteps: 539,169,010

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.53441
Policy Entropy: 3.32879
Value Function Loss: 0.00350

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07824
Policy Update Magnitude: 0.54878
Value Function Update Magnitude: 0.68180

Collected Steps per Second: 22,418.72707
Overall Steps per Second: 10,740.64691

Timestep Collection Time: 2.23046
Timestep Consumption Time: 2.42513
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.65559

Cumulative Model Updates: 64,644
Cumulative Timesteps: 539,219,014

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 539219014...
Checkpoint 539219014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.25808
Policy Entropy: 3.33585
Value Function Loss: 0.00365

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08024
Policy Update Magnitude: 0.55456
Value Function Update Magnitude: 0.66187

Collected Steps per Second: 22,241.58111
Overall Steps per Second: 10,721.11029

Timestep Collection Time: 2.24921
Timestep Consumption Time: 2.41691
PPO Batch Consumption Time: 0.28168
Total Iteration Time: 4.66612

Cumulative Model Updates: 64,650
Cumulative Timesteps: 539,269,040

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,928.78558
Policy Entropy: 3.32756
Value Function Loss: 0.00361

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08015
Policy Update Magnitude: 0.55601
Value Function Update Magnitude: 0.64884

Collected Steps per Second: 22,666.02270
Overall Steps per Second: 10,521.43158

Timestep Collection Time: 2.20612
Timestep Consumption Time: 2.54646
PPO Batch Consumption Time: 0.29728
Total Iteration Time: 4.75259

Cumulative Model Updates: 64,656
Cumulative Timesteps: 539,319,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 539319044...
Checkpoint 539319044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 973.61564
Policy Entropy: 3.33474
Value Function Loss: 0.00361

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08415
Policy Update Magnitude: 0.55469
Value Function Update Magnitude: 0.64510

Collected Steps per Second: 22,677.68212
Overall Steps per Second: 10,631.72192

Timestep Collection Time: 2.20560
Timestep Consumption Time: 2.49900
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.70460

Cumulative Model Updates: 64,662
Cumulative Timesteps: 539,369,062

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.13578
Policy Entropy: 3.32094
Value Function Loss: 0.00350

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09325
Policy Update Magnitude: 0.54707
Value Function Update Magnitude: 0.64993

Collected Steps per Second: 22,817.53290
Overall Steps per Second: 10,805.22258

Timestep Collection Time: 2.19235
Timestep Consumption Time: 2.43726
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.62961

Cumulative Model Updates: 64,668
Cumulative Timesteps: 539,419,086

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 539419086...
Checkpoint 539419086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.37717
Policy Entropy: 3.33119
Value Function Loss: 0.00340

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09809
Policy Update Magnitude: 0.53916
Value Function Update Magnitude: 0.64038

Collected Steps per Second: 22,746.07076
Overall Steps per Second: 10,683.36362

Timestep Collection Time: 2.19897
Timestep Consumption Time: 2.48289
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.68186

Cumulative Model Updates: 64,674
Cumulative Timesteps: 539,469,104

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,762.56171
Policy Entropy: 3.33299
Value Function Loss: 0.00337

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11181
Policy Update Magnitude: 0.53696
Value Function Update Magnitude: 0.63015

Collected Steps per Second: 22,938.65839
Overall Steps per Second: 10,864.06308

Timestep Collection Time: 2.18077
Timestep Consumption Time: 2.42377
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.60454

Cumulative Model Updates: 64,680
Cumulative Timesteps: 539,519,128

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 539519128...
Checkpoint 539519128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.25259
Policy Entropy: 3.32378
Value Function Loss: 0.00348

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10161
Policy Update Magnitude: 0.53603
Value Function Update Magnitude: 0.62361

Collected Steps per Second: 22,635.27198
Overall Steps per Second: 10,701.20635

Timestep Collection Time: 2.20930
Timestep Consumption Time: 2.46382
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.67312

Cumulative Model Updates: 64,686
Cumulative Timesteps: 539,569,136

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678.17368
Policy Entropy: 3.33308
Value Function Loss: 0.00364

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10357
Policy Update Magnitude: 0.54324
Value Function Update Magnitude: 0.64059

Collected Steps per Second: 22,293.03891
Overall Steps per Second: 10,605.47450

Timestep Collection Time: 2.24357
Timestep Consumption Time: 2.47248
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.71605

Cumulative Model Updates: 64,692
Cumulative Timesteps: 539,619,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 539619152...
Checkpoint 539619152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,814.49557
Policy Entropy: 3.32333
Value Function Loss: 0.00350

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10486
Policy Update Magnitude: 0.54868
Value Function Update Magnitude: 0.65229

Collected Steps per Second: 22,239.11131
Overall Steps per Second: 10,531.24614

Timestep Collection Time: 2.24892
Timestep Consumption Time: 2.50018
PPO Batch Consumption Time: 0.29749
Total Iteration Time: 4.74911

Cumulative Model Updates: 64,698
Cumulative Timesteps: 539,669,166

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.89372
Policy Entropy: 3.32501
Value Function Loss: 0.00335

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09844
Policy Update Magnitude: 0.54262
Value Function Update Magnitude: 0.65001

Collected Steps per Second: 22,492.42826
Overall Steps per Second: 10,781.99200

Timestep Collection Time: 2.22297
Timestep Consumption Time: 2.41439
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.63736

Cumulative Model Updates: 64,704
Cumulative Timesteps: 539,719,166

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 539719166...
Checkpoint 539719166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.36483
Policy Entropy: 3.31262
Value Function Loss: 0.00329

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08150
Policy Update Magnitude: 0.53368
Value Function Update Magnitude: 0.63420

Collected Steps per Second: 22,232.91784
Overall Steps per Second: 10,588.84908

Timestep Collection Time: 2.24973
Timestep Consumption Time: 2.47392
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.72365

Cumulative Model Updates: 64,710
Cumulative Timesteps: 539,769,184

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 826.08407
Policy Entropy: 3.30680
Value Function Loss: 0.00343

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07696
Policy Update Magnitude: 0.53204
Value Function Update Magnitude: 0.61416

Collected Steps per Second: 22,911.16903
Overall Steps per Second: 10,680.40543

Timestep Collection Time: 2.18260
Timestep Consumption Time: 2.49943
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.68203

Cumulative Model Updates: 64,716
Cumulative Timesteps: 539,819,190

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 539819190...
Checkpoint 539819190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.24427
Policy Entropy: 3.30162
Value Function Loss: 0.00355

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.53486
Value Function Update Magnitude: 0.62076

Collected Steps per Second: 22,495.84090
Overall Steps per Second: 10,613.19659

Timestep Collection Time: 2.22308
Timestep Consumption Time: 2.48898
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.71206

Cumulative Model Updates: 64,722
Cumulative Timesteps: 539,869,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,539.84947
Policy Entropy: 3.29387
Value Function Loss: 0.00348

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09039
Policy Update Magnitude: 0.54037
Value Function Update Magnitude: 0.64049

Collected Steps per Second: 22,921.81466
Overall Steps per Second: 10,838.17698

Timestep Collection Time: 2.18220
Timestep Consumption Time: 2.43297
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.61517

Cumulative Model Updates: 64,728
Cumulative Timesteps: 539,919,220

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 539919220...
Checkpoint 539919220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 776.05076
Policy Entropy: 3.31005
Value Function Loss: 0.00339

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10166
Policy Update Magnitude: 0.53521
Value Function Update Magnitude: 0.62179

Collected Steps per Second: 22,957.84861
Overall Steps per Second: 10,709.15423

Timestep Collection Time: 2.17886
Timestep Consumption Time: 2.49209
PPO Batch Consumption Time: 0.29524
Total Iteration Time: 4.67096

Cumulative Model Updates: 64,734
Cumulative Timesteps: 539,969,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.79859
Policy Entropy: 3.32283
Value Function Loss: 0.00334

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08810
Policy Update Magnitude: 0.53762
Value Function Update Magnitude: 0.60745

Collected Steps per Second: 22,271.76053
Overall Steps per Second: 10,573.07330

Timestep Collection Time: 2.24607
Timestep Consumption Time: 2.48519
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.73126

Cumulative Model Updates: 64,740
Cumulative Timesteps: 540,019,266

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 540019266...
Checkpoint 540019266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 738.23019
Policy Entropy: 3.32894
Value Function Loss: 0.00341

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09931
Policy Update Magnitude: 0.53163
Value Function Update Magnitude: 0.61344

Collected Steps per Second: 22,403.43551
Overall Steps per Second: 10,605.78031

Timestep Collection Time: 2.23296
Timestep Consumption Time: 2.48390
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.71686

Cumulative Model Updates: 64,746
Cumulative Timesteps: 540,069,292

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,520.81264
Policy Entropy: 3.30607
Value Function Loss: 0.00344

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09313
Policy Update Magnitude: 0.54828
Value Function Update Magnitude: 0.61515

Collected Steps per Second: 22,620.42924
Overall Steps per Second: 10,764.84318

Timestep Collection Time: 2.21039
Timestep Consumption Time: 2.43436
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.64475

Cumulative Model Updates: 64,752
Cumulative Timesteps: 540,119,292

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 540119292...
Checkpoint 540119292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 904.46153
Policy Entropy: 3.31000
Value Function Loss: 0.00355

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10458
Policy Update Magnitude: 0.55928
Value Function Update Magnitude: 0.63137

Collected Steps per Second: 22,616.40973
Overall Steps per Second: 10,595.86518

Timestep Collection Time: 2.21123
Timestep Consumption Time: 2.50854
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.71977

Cumulative Model Updates: 64,758
Cumulative Timesteps: 540,169,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517.01313
Policy Entropy: 3.31544
Value Function Loss: 0.00344

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.56041
Value Function Update Magnitude: 0.63578

Collected Steps per Second: 22,876.21912
Overall Steps per Second: 10,832.84873

Timestep Collection Time: 2.18611
Timestep Consumption Time: 2.43040
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.61651

Cumulative Model Updates: 64,764
Cumulative Timesteps: 540,219,312

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 540219312...
Checkpoint 540219312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660.18091
Policy Entropy: 3.33036
Value Function Loss: 0.00355

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08043
Policy Update Magnitude: 0.56368
Value Function Update Magnitude: 0.63900

Collected Steps per Second: 22,729.60571
Overall Steps per Second: 10,731.16844

Timestep Collection Time: 2.20065
Timestep Consumption Time: 2.46053
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.66119

Cumulative Model Updates: 64,770
Cumulative Timesteps: 540,269,332

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.89574
Policy Entropy: 3.33292
Value Function Loss: 0.00356

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.55477
Value Function Update Magnitude: 0.61980

Collected Steps per Second: 22,591.72121
Overall Steps per Second: 10,772.08997

Timestep Collection Time: 2.21347
Timestep Consumption Time: 2.42872
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.64218

Cumulative Model Updates: 64,776
Cumulative Timesteps: 540,319,338

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 540319338...
Checkpoint 540319338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.35465
Policy Entropy: 3.33652
Value Function Loss: 0.00359

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09660
Policy Update Magnitude: 0.54410
Value Function Update Magnitude: 0.59728

Collected Steps per Second: 22,598.27064
Overall Steps per Second: 10,807.61720

Timestep Collection Time: 2.21309
Timestep Consumption Time: 2.41439
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.62748

Cumulative Model Updates: 64,782
Cumulative Timesteps: 540,369,350

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 746.33350
Policy Entropy: 3.33137
Value Function Loss: 0.00370

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08786
Policy Update Magnitude: 0.54241
Value Function Update Magnitude: 0.59520

Collected Steps per Second: 23,068.43593
Overall Steps per Second: 10,895.31580

Timestep Collection Time: 2.16798
Timestep Consumption Time: 2.42225
PPO Batch Consumption Time: 0.28179
Total Iteration Time: 4.59023

Cumulative Model Updates: 64,788
Cumulative Timesteps: 540,419,362

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 540419362...
Checkpoint 540419362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 847.23344
Policy Entropy: 3.32127
Value Function Loss: 0.00368

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09283
Policy Update Magnitude: 0.55468
Value Function Update Magnitude: 0.59873

Collected Steps per Second: 22,438.49340
Overall Steps per Second: 10,703.29786

Timestep Collection Time: 2.22831
Timestep Consumption Time: 2.44314
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.67146

Cumulative Model Updates: 64,794
Cumulative Timesteps: 540,469,362

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599.19643
Policy Entropy: 3.31228
Value Function Loss: 0.00382

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.56127
Value Function Update Magnitude: 0.61020

Collected Steps per Second: 22,374.37661
Overall Steps per Second: 10,612.64643

Timestep Collection Time: 2.23568
Timestep Consumption Time: 2.47775
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.71343

Cumulative Model Updates: 64,800
Cumulative Timesteps: 540,519,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 540519384...
Checkpoint 540519384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.94194
Policy Entropy: 3.30974
Value Function Loss: 0.00398

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.12498
Policy Update Magnitude: 0.57397
Value Function Update Magnitude: 0.63025

Collected Steps per Second: 22,225.49198
Overall Steps per Second: 10,835.86734

Timestep Collection Time: 2.25093
Timestep Consumption Time: 2.36596
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.61689

Cumulative Model Updates: 64,806
Cumulative Timesteps: 540,569,412

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 834.92154
Policy Entropy: 3.33540
Value Function Loss: 0.00419

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.11856
Policy Update Magnitude: 0.58958
Value Function Update Magnitude: 0.64063

Collected Steps per Second: 21,763.58690
Overall Steps per Second: 10,496.35713

Timestep Collection Time: 2.29778
Timestep Consumption Time: 2.46654
PPO Batch Consumption Time: 0.29581
Total Iteration Time: 4.76432

Cumulative Model Updates: 64,812
Cumulative Timesteps: 540,619,420

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 540619420...
Checkpoint 540619420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 945.49437
Policy Entropy: 3.36651
Value Function Loss: 0.00398

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10266
Policy Update Magnitude: 0.58245
Value Function Update Magnitude: 0.64760

Collected Steps per Second: 21,945.32145
Overall Steps per Second: 10,640.61942

Timestep Collection Time: 2.27875
Timestep Consumption Time: 2.42097
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.69973

Cumulative Model Updates: 64,818
Cumulative Timesteps: 540,669,428

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.67720
Policy Entropy: 3.37458
Value Function Loss: 0.00362

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08716
Policy Update Magnitude: 0.57065
Value Function Update Magnitude: 0.65884

Collected Steps per Second: 22,051.03946
Overall Steps per Second: 10,577.69692

Timestep Collection Time: 2.26783
Timestep Consumption Time: 2.45985
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.72768

Cumulative Model Updates: 64,824
Cumulative Timesteps: 540,719,436

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 540719436...
Checkpoint 540719436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.40628
Policy Entropy: 3.39003
Value Function Loss: 0.00348

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08725
Policy Update Magnitude: 0.56686
Value Function Update Magnitude: 0.63893

Collected Steps per Second: 22,280.01460
Overall Steps per Second: 10,676.95289

Timestep Collection Time: 2.24443
Timestep Consumption Time: 2.43911
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.68355

Cumulative Model Updates: 64,830
Cumulative Timesteps: 540,769,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.63055
Policy Entropy: 3.37527
Value Function Loss: 0.00367

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08914
Policy Update Magnitude: 0.56150
Value Function Update Magnitude: 0.62049

Collected Steps per Second: 22,059.48440
Overall Steps per Second: 10,782.93531

Timestep Collection Time: 2.26751
Timestep Consumption Time: 2.37131
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.63881

Cumulative Model Updates: 64,836
Cumulative Timesteps: 540,819,462

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 540819462...
Checkpoint 540819462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,943.59498
Policy Entropy: 3.37538
Value Function Loss: 0.00364

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09230
Policy Update Magnitude: 0.56028
Value Function Update Magnitude: 0.60485

Collected Steps per Second: 22,102.53062
Overall Steps per Second: 10,584.00019

Timestep Collection Time: 2.26291
Timestep Consumption Time: 2.46272
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.72562

Cumulative Model Updates: 64,842
Cumulative Timesteps: 540,869,478

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.97399
Policy Entropy: 3.36681
Value Function Loss: 0.00361

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.55964
Value Function Update Magnitude: 0.60423

Collected Steps per Second: 22,240.30092
Overall Steps per Second: 10,819.55500

Timestep Collection Time: 2.24844
Timestep Consumption Time: 2.37338
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.62182

Cumulative Model Updates: 64,848
Cumulative Timesteps: 540,919,484

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 540919484...
Checkpoint 540919484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 972.70399
Policy Entropy: 3.38684
Value Function Loss: 0.00354

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09193
Policy Update Magnitude: 0.55361
Value Function Update Magnitude: 0.59926

Collected Steps per Second: 22,131.90248
Overall Steps per Second: 10,806.67025

Timestep Collection Time: 2.26000
Timestep Consumption Time: 2.36844
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.62844

Cumulative Model Updates: 64,854
Cumulative Timesteps: 540,969,502

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,615.54299
Policy Entropy: 3.39035
Value Function Loss: 0.00369

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08693
Policy Update Magnitude: 0.55583
Value Function Update Magnitude: 0.60331

Collected Steps per Second: 21,985.21855
Overall Steps per Second: 10,615.86312

Timestep Collection Time: 2.27489
Timestep Consumption Time: 2.43636
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.71125

Cumulative Model Updates: 64,860
Cumulative Timesteps: 541,019,516

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 541019516...
Checkpoint 541019516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 808.80057
Policy Entropy: 3.39831
Value Function Loss: 0.00366

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.56514
Value Function Update Magnitude: 0.62708

Collected Steps per Second: 21,689.24604
Overall Steps per Second: 10,580.56649

Timestep Collection Time: 2.30603
Timestep Consumption Time: 2.42113
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.72716

Cumulative Model Updates: 64,866
Cumulative Timesteps: 541,069,532

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,436.69749
Policy Entropy: 3.40473
Value Function Loss: 0.00371

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08702
Policy Update Magnitude: 0.56835
Value Function Update Magnitude: 0.64059

Collected Steps per Second: 21,849.90853
Overall Steps per Second: 10,707.04085

Timestep Collection Time: 2.28889
Timestep Consumption Time: 2.38206
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.67095

Cumulative Model Updates: 64,872
Cumulative Timesteps: 541,119,544

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 541119544...
Checkpoint 541119544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 862.52746
Policy Entropy: 3.40551
Value Function Loss: 0.00355

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07696
Policy Update Magnitude: 0.56769
Value Function Update Magnitude: 0.66751

Collected Steps per Second: 21,609.23485
Overall Steps per Second: 10,654.93516

Timestep Collection Time: 2.31494
Timestep Consumption Time: 2.37998
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.69491

Cumulative Model Updates: 64,878
Cumulative Timesteps: 541,169,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,686.21950
Policy Entropy: 3.39250
Value Function Loss: 0.00354

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08038
Policy Update Magnitude: 0.56392
Value Function Update Magnitude: 0.66179

Collected Steps per Second: 21,439.18823
Overall Steps per Second: 10,486.23962

Timestep Collection Time: 2.33330
Timestep Consumption Time: 2.43714
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.77044

Cumulative Model Updates: 64,884
Cumulative Timesteps: 541,219,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 541219592...
Checkpoint 541219592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.97019
Policy Entropy: 3.38278
Value Function Loss: 0.00353

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08889
Policy Update Magnitude: 0.55632
Value Function Update Magnitude: 0.66388

Collected Steps per Second: 21,768.60493
Overall Steps per Second: 10,649.82567

Timestep Collection Time: 2.29771
Timestep Consumption Time: 2.39889
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.69660

Cumulative Model Updates: 64,890
Cumulative Timesteps: 541,269,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.33397
Policy Entropy: 3.37468
Value Function Loss: 0.00346

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10051
Policy Update Magnitude: 0.55264
Value Function Update Magnitude: 0.64269

Collected Steps per Second: 22,017.10113
Overall Steps per Second: 10,566.30459

Timestep Collection Time: 2.27214
Timestep Consumption Time: 2.46234
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 4.73448

Cumulative Model Updates: 64,896
Cumulative Timesteps: 541,319,636

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 541319636...
Checkpoint 541319636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 940.00398
Policy Entropy: 3.36999
Value Function Loss: 0.00345

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.54971
Value Function Update Magnitude: 0.62247

Collected Steps per Second: 22,207.57389
Overall Steps per Second: 10,664.77624

Timestep Collection Time: 2.25175
Timestep Consumption Time: 2.43714
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.68889

Cumulative Model Updates: 64,902
Cumulative Timesteps: 541,369,642

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.14223
Policy Entropy: 3.36770
Value Function Loss: 0.00360

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09371
Policy Update Magnitude: 0.54815
Value Function Update Magnitude: 0.61331

Collected Steps per Second: 22,178.52417
Overall Steps per Second: 10,781.05352

Timestep Collection Time: 2.25461
Timestep Consumption Time: 2.38352
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.63814

Cumulative Model Updates: 64,908
Cumulative Timesteps: 541,419,646

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 541419646...
Checkpoint 541419646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688.24702
Policy Entropy: 3.36762
Value Function Loss: 0.00375

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09119
Policy Update Magnitude: 0.55170
Value Function Update Magnitude: 0.62985

Collected Steps per Second: 22,806.91853
Overall Steps per Second: 10,617.82972

Timestep Collection Time: 2.19363
Timestep Consumption Time: 2.51825
PPO Batch Consumption Time: 0.29610
Total Iteration Time: 4.71189

Cumulative Model Updates: 64,914
Cumulative Timesteps: 541,469,676

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348.36877
Policy Entropy: 3.36241
Value Function Loss: 0.00402

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10453
Policy Update Magnitude: 0.56305
Value Function Update Magnitude: 0.62836

Collected Steps per Second: 23,065.04283
Overall Steps per Second: 10,816.76197

Timestep Collection Time: 2.16882
Timestep Consumption Time: 2.45585
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.62467

Cumulative Model Updates: 64,920
Cumulative Timesteps: 541,519,700

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 541519700...
Checkpoint 541519700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700.26906
Policy Entropy: 3.35132
Value Function Loss: 0.00395

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.10950
Policy Update Magnitude: 0.57297
Value Function Update Magnitude: 0.66298

Collected Steps per Second: 22,871.20080
Overall Steps per Second: 10,722.11333

Timestep Collection Time: 2.18703
Timestep Consumption Time: 2.47810
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.66513

Cumulative Model Updates: 64,926
Cumulative Timesteps: 541,569,720

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 895.70166
Policy Entropy: 3.36516
Value Function Loss: 0.00379

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10805
Policy Update Magnitude: 0.57694
Value Function Update Magnitude: 0.67318

Collected Steps per Second: 22,234.98883
Overall Steps per Second: 10,460.79173

Timestep Collection Time: 2.24997
Timestep Consumption Time: 2.53246
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.78243

Cumulative Model Updates: 64,932
Cumulative Timesteps: 541,619,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 541619748...
Checkpoint 541619748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 824.03110
Policy Entropy: 3.37059
Value Function Loss: 0.00369

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10531
Policy Update Magnitude: 0.56420
Value Function Update Magnitude: 0.67860

Collected Steps per Second: 21,880.16275
Overall Steps per Second: 10,574.29354

Timestep Collection Time: 2.28572
Timestep Consumption Time: 2.44386
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.72958

Cumulative Model Updates: 64,938
Cumulative Timesteps: 541,669,760

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 938.43172
Policy Entropy: 3.37468
Value Function Loss: 0.00362

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09279
Policy Update Magnitude: 0.55874
Value Function Update Magnitude: 0.67055

Collected Steps per Second: 22,160.84302
Overall Steps per Second: 10,502.23917

Timestep Collection Time: 2.25704
Timestep Consumption Time: 2.50556
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.76260

Cumulative Model Updates: 64,944
Cumulative Timesteps: 541,719,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 541719778...
Checkpoint 541719778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.16823
Policy Entropy: 3.35697
Value Function Loss: 0.00372

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08757
Policy Update Magnitude: 0.55468
Value Function Update Magnitude: 0.67026

Collected Steps per Second: 22,360.53285
Overall Steps per Second: 10,661.00763

Timestep Collection Time: 2.23635
Timestep Consumption Time: 2.45420
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.69055

Cumulative Model Updates: 64,950
Cumulative Timesteps: 541,769,784

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641.00871
Policy Entropy: 3.34881
Value Function Loss: 0.00378

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07650
Policy Update Magnitude: 0.55918
Value Function Update Magnitude: 0.68694

Collected Steps per Second: 22,773.62659
Overall Steps per Second: 10,560.66147

Timestep Collection Time: 2.19561
Timestep Consumption Time: 2.53913
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.73474

Cumulative Model Updates: 64,956
Cumulative Timesteps: 541,819,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 541819786...
Checkpoint 541819786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 940.73015
Policy Entropy: 3.35559
Value Function Loss: 0.00387

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07629
Policy Update Magnitude: 0.57151
Value Function Update Magnitude: 0.70502

Collected Steps per Second: 23,069.60932
Overall Steps per Second: 10,687.79332

Timestep Collection Time: 2.16831
Timestep Consumption Time: 2.51199
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.68029

Cumulative Model Updates: 64,962
Cumulative Timesteps: 541,869,808

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,721.81009
Policy Entropy: 3.36317
Value Function Loss: 0.00391

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07486
Policy Update Magnitude: 0.57342
Value Function Update Magnitude: 0.69984

Collected Steps per Second: 22,854.95627
Overall Steps per Second: 10,796.56748

Timestep Collection Time: 2.18788
Timestep Consumption Time: 2.44359
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.63147

Cumulative Model Updates: 64,968
Cumulative Timesteps: 541,919,812

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 541919812...
Checkpoint 541919812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680.93537
Policy Entropy: 3.36642
Value Function Loss: 0.00397

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08447
Policy Update Magnitude: 0.56484
Value Function Update Magnitude: 0.69202

Collected Steps per Second: 22,691.19249
Overall Steps per Second: 10,508.46831

Timestep Collection Time: 2.20367
Timestep Consumption Time: 2.55477
PPO Batch Consumption Time: 0.29862
Total Iteration Time: 4.75845

Cumulative Model Updates: 64,974
Cumulative Timesteps: 541,969,816

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.50841
Policy Entropy: 3.36320
Value Function Loss: 0.00370

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09376
Policy Update Magnitude: 0.56358
Value Function Update Magnitude: 0.68720

Collected Steps per Second: 22,533.43862
Overall Steps per Second: 10,593.90218

Timestep Collection Time: 2.21901
Timestep Consumption Time: 2.50087
PPO Batch Consumption Time: 0.29691
Total Iteration Time: 4.71988

Cumulative Model Updates: 64,980
Cumulative Timesteps: 542,019,818

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 542019818...
Checkpoint 542019818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.99524
Policy Entropy: 3.35118
Value Function Loss: 0.00372

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08428
Policy Update Magnitude: 0.56167
Value Function Update Magnitude: 0.68693

Collected Steps per Second: 22,647.17745
Overall Steps per Second: 10,623.88030

Timestep Collection Time: 2.20902
Timestep Consumption Time: 2.50000
PPO Batch Consumption Time: 0.29803
Total Iteration Time: 4.70901

Cumulative Model Updates: 64,986
Cumulative Timesteps: 542,069,846

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750.87520
Policy Entropy: 3.34833
Value Function Loss: 0.00359

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09039
Policy Update Magnitude: 0.55692
Value Function Update Magnitude: 0.68023

Collected Steps per Second: 23,108.27125
Overall Steps per Second: 10,837.41798

Timestep Collection Time: 2.16511
Timestep Consumption Time: 2.45149
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.61660

Cumulative Model Updates: 64,992
Cumulative Timesteps: 542,119,878

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 542119878...
Checkpoint 542119878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.30286
Policy Entropy: 3.33849
Value Function Loss: 0.00366

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08915
Policy Update Magnitude: 0.55704
Value Function Update Magnitude: 0.66198

Collected Steps per Second: 22,252.91771
Overall Steps per Second: 10,665.08015

Timestep Collection Time: 2.24753
Timestep Consumption Time: 2.44198
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.68951

Cumulative Model Updates: 64,998
Cumulative Timesteps: 542,169,892

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,418.55206
Policy Entropy: 3.34505
Value Function Loss: 0.00363

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09780
Policy Update Magnitude: 0.55070
Value Function Update Magnitude: 0.64718

Collected Steps per Second: 22,295.41297
Overall Steps per Second: 10,541.64198

Timestep Collection Time: 2.24333
Timestep Consumption Time: 2.50128
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.74461

Cumulative Model Updates: 65,004
Cumulative Timesteps: 542,219,908

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 542219908...
Checkpoint 542219908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,576.72274
Policy Entropy: 3.34515
Value Function Loss: 0.00377

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.54856
Value Function Update Magnitude: 0.63081

Collected Steps per Second: 22,411.30133
Overall Steps per Second: 10,587.91801

Timestep Collection Time: 2.23155
Timestep Consumption Time: 2.49194
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.72350

Cumulative Model Updates: 65,010
Cumulative Timesteps: 542,269,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.04510
Policy Entropy: 3.35550
Value Function Loss: 0.00371

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08559
Policy Update Magnitude: 0.54249
Value Function Update Magnitude: 0.61575

Collected Steps per Second: 21,642.62092
Overall Steps per Second: 10,395.52184

Timestep Collection Time: 2.31081
Timestep Consumption Time: 2.50011
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.81092

Cumulative Model Updates: 65,016
Cumulative Timesteps: 542,319,932

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 542319932...
Checkpoint 542319932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.06109
Policy Entropy: 3.34160
Value Function Loss: 0.00353

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08399
Policy Update Magnitude: 0.53803
Value Function Update Magnitude: 0.61509

Collected Steps per Second: 22,684.29562
Overall Steps per Second: 10,675.03075

Timestep Collection Time: 2.20540
Timestep Consumption Time: 2.48105
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.68645

Cumulative Model Updates: 65,022
Cumulative Timesteps: 542,369,960

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.15258
Policy Entropy: 3.34430
Value Function Loss: 0.00363

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08662
Policy Update Magnitude: 0.54279
Value Function Update Magnitude: 0.62766

Collected Steps per Second: 22,645.25463
Overall Steps per Second: 10,584.08534

Timestep Collection Time: 2.20982
Timestep Consumption Time: 2.51822
PPO Batch Consumption Time: 0.29547
Total Iteration Time: 4.72804

Cumulative Model Updates: 65,028
Cumulative Timesteps: 542,420,002

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 542420002...
Checkpoint 542420002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.93811
Policy Entropy: 3.33778
Value Function Loss: 0.00328

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09086
Policy Update Magnitude: 0.53915
Value Function Update Magnitude: 0.61931

Collected Steps per Second: 23,039.16021
Overall Steps per Second: 10,844.00974

Timestep Collection Time: 2.17030
Timestep Consumption Time: 2.44072
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.61103

Cumulative Model Updates: 65,034
Cumulative Timesteps: 542,470,004

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 983.66524
Policy Entropy: 3.36187
Value Function Loss: 0.00333

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.53399
Value Function Update Magnitude: 0.59258

Collected Steps per Second: 22,531.08734
Overall Steps per Second: 10,596.59544

Timestep Collection Time: 2.21996
Timestep Consumption Time: 2.50024
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.72020

Cumulative Model Updates: 65,040
Cumulative Timesteps: 542,520,022

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 542520022...
Checkpoint 542520022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 932.09557
Policy Entropy: 3.36653
Value Function Loss: 0.00333

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08836
Policy Update Magnitude: 0.53429
Value Function Update Magnitude: 0.57968

Collected Steps per Second: 22,918.17173
Overall Steps per Second: 10,721.96156

Timestep Collection Time: 2.18194
Timestep Consumption Time: 2.48195
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.66389

Cumulative Model Updates: 65,046
Cumulative Timesteps: 542,570,028

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 967.00935
Policy Entropy: 3.37117
Value Function Loss: 0.00342

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09761
Policy Update Magnitude: 0.53694
Value Function Update Magnitude: 0.60665

Collected Steps per Second: 22,694.85342
Overall Steps per Second: 10,768.67495

Timestep Collection Time: 2.20358
Timestep Consumption Time: 2.44044
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.64403

Cumulative Model Updates: 65,052
Cumulative Timesteps: 542,620,038

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 542620038...
Checkpoint 542620038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,381.71505
Policy Entropy: 3.36541
Value Function Loss: 0.00343

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08653
Policy Update Magnitude: 0.53346
Value Function Update Magnitude: 0.64434

Collected Steps per Second: 22,558.59736
Overall Steps per Second: 10,658.20113

Timestep Collection Time: 2.21743
Timestep Consumption Time: 2.47586
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.69329

Cumulative Model Updates: 65,058
Cumulative Timesteps: 542,670,060

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.27790
Policy Entropy: 3.35787
Value Function Loss: 0.00331

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08159
Policy Update Magnitude: 0.53118
Value Function Update Magnitude: 0.63072

Collected Steps per Second: 22,599.64385
Overall Steps per Second: 10,651.69964

Timestep Collection Time: 2.21375
Timestep Consumption Time: 2.48315
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.69690

Cumulative Model Updates: 65,064
Cumulative Timesteps: 542,720,090

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 542720090...
Checkpoint 542720090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 928.82303
Policy Entropy: 3.37038
Value Function Loss: 0.00335

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07933
Policy Update Magnitude: 0.53537
Value Function Update Magnitude: 0.61154

Collected Steps per Second: 22,295.02282
Overall Steps per Second: 10,609.56792

Timestep Collection Time: 2.24400
Timestep Consumption Time: 2.47156
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.71555

Cumulative Model Updates: 65,070
Cumulative Timesteps: 542,770,120

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066.97289
Policy Entropy: 3.37956
Value Function Loss: 0.00341

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08641
Policy Update Magnitude: 0.53310
Value Function Update Magnitude: 0.61006

Collected Steps per Second: 22,496.27600
Overall Steps per Second: 10,721.57936

Timestep Collection Time: 2.22295
Timestep Consumption Time: 2.44129
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.66424

Cumulative Model Updates: 65,076
Cumulative Timesteps: 542,820,128

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 542820128...
Checkpoint 542820128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.22451
Policy Entropy: 3.38300
Value Function Loss: 0.00361

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07557
Policy Update Magnitude: 0.53362
Value Function Update Magnitude: 0.64117

Collected Steps per Second: 22,382.60578
Overall Steps per Second: 10,746.08077

Timestep Collection Time: 2.23432
Timestep Consumption Time: 2.41947
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.65379

Cumulative Model Updates: 65,082
Cumulative Timesteps: 542,870,138

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682.33232
Policy Entropy: 3.37405
Value Function Loss: 0.00361

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08027
Policy Update Magnitude: 0.53927
Value Function Update Magnitude: 0.65148

Collected Steps per Second: 22,830.22475
Overall Steps per Second: 10,783.24781

Timestep Collection Time: 2.19052
Timestep Consumption Time: 2.44723
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 4.63775

Cumulative Model Updates: 65,088
Cumulative Timesteps: 542,920,148

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 542920148...
Checkpoint 542920148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.43051
Policy Entropy: 3.36189
Value Function Loss: 0.00366

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08544
Policy Update Magnitude: 0.54083
Value Function Update Magnitude: 0.64599

Collected Steps per Second: 22,906.41418
Overall Steps per Second: 10,686.51743

Timestep Collection Time: 2.18410
Timestep Consumption Time: 2.49750
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.68160

Cumulative Model Updates: 65,094
Cumulative Timesteps: 542,970,178

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.91962
Policy Entropy: 3.35027
Value Function Loss: 0.00365

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11091
Policy Update Magnitude: 0.53788
Value Function Update Magnitude: 0.65370

Collected Steps per Second: 22,299.81847
Overall Steps per Second: 10,552.07312

Timestep Collection Time: 2.24298
Timestep Consumption Time: 2.49713
PPO Batch Consumption Time: 0.29585
Total Iteration Time: 4.74011

Cumulative Model Updates: 65,100
Cumulative Timesteps: 543,020,196

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 543020196...
Checkpoint 543020196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,717.93846
Policy Entropy: 3.35197
Value Function Loss: 0.00388

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11398
Policy Update Magnitude: 0.53900
Value Function Update Magnitude: 0.65396

Collected Steps per Second: 22,957.60763
Overall Steps per Second: 10,767.46355

Timestep Collection Time: 2.17801
Timestep Consumption Time: 2.46579
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.64380

Cumulative Model Updates: 65,106
Cumulative Timesteps: 543,070,198

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.83369
Policy Entropy: 3.35155
Value Function Loss: 0.00405

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.12805
Policy Update Magnitude: 0.54090
Value Function Update Magnitude: 0.65637

Collected Steps per Second: 22,858.29765
Overall Steps per Second: 10,681.05698

Timestep Collection Time: 2.18914
Timestep Consumption Time: 2.49579
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.68493

Cumulative Model Updates: 65,112
Cumulative Timesteps: 543,120,238

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 543120238...
Checkpoint 543120238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 953.15126
Policy Entropy: 3.35929
Value Function Loss: 0.00386

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11538
Policy Update Magnitude: 0.54644
Value Function Update Magnitude: 0.65951

Collected Steps per Second: 22,834.05764
Overall Steps per Second: 10,656.20296

Timestep Collection Time: 2.19094
Timestep Consumption Time: 2.50379
PPO Batch Consumption Time: 0.29742
Total Iteration Time: 4.69473

Cumulative Model Updates: 65,118
Cumulative Timesteps: 543,170,266

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345.26473
Policy Entropy: 3.35543
Value Function Loss: 0.00366

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.13444
Policy Update Magnitude: 0.54192
Value Function Update Magnitude: 0.64527

Collected Steps per Second: 21,998.81232
Overall Steps per Second: 10,478.29967

Timestep Collection Time: 2.27367
Timestep Consumption Time: 2.49982
PPO Batch Consumption Time: 0.29695
Total Iteration Time: 4.77348

Cumulative Model Updates: 65,124
Cumulative Timesteps: 543,220,284

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 543220284...
Checkpoint 543220284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.90356
Policy Entropy: 3.34800
Value Function Loss: 0.00335

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.14327
Policy Update Magnitude: 0.53033
Value Function Update Magnitude: 0.62368

Collected Steps per Second: 22,217.47672
Overall Steps per Second: 10,619.75300

Timestep Collection Time: 2.25102
Timestep Consumption Time: 2.45832
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.70934

Cumulative Model Updates: 65,130
Cumulative Timesteps: 543,270,296

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 892.03885
Policy Entropy: 3.35153
Value Function Loss: 0.00325

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.12976
Policy Update Magnitude: 0.52581
Value Function Update Magnitude: 0.61919

Collected Steps per Second: 22,508.21494
Overall Steps per Second: 10,626.27811

Timestep Collection Time: 2.22257
Timestep Consumption Time: 2.48520
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.70776

Cumulative Model Updates: 65,136
Cumulative Timesteps: 543,320,322

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 543320322...
Checkpoint 543320322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.60108
Policy Entropy: 3.37236
Value Function Loss: 0.00316

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11198
Policy Update Magnitude: 0.51891
Value Function Update Magnitude: 0.60608

Collected Steps per Second: 22,557.09669
Overall Steps per Second: 10,655.56708

Timestep Collection Time: 2.21713
Timestep Consumption Time: 2.47638
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.69351

Cumulative Model Updates: 65,142
Cumulative Timesteps: 543,370,334

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.82938
Policy Entropy: 3.36985
Value Function Loss: 0.00326

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08084
Policy Update Magnitude: 0.52388
Value Function Update Magnitude: 0.58758

Collected Steps per Second: 22,779.00594
Overall Steps per Second: 10,697.62845

Timestep Collection Time: 2.19588
Timestep Consumption Time: 2.47992
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.67580

Cumulative Model Updates: 65,148
Cumulative Timesteps: 543,420,354

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 543420354...
Checkpoint 543420354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.89892
Policy Entropy: 3.35355
Value Function Loss: 0.00353

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08448
Policy Update Magnitude: 0.53514
Value Function Update Magnitude: 0.59058

Collected Steps per Second: 22,825.52176
Overall Steps per Second: 10,668.99341

Timestep Collection Time: 2.19123
Timestep Consumption Time: 2.49675
PPO Batch Consumption Time: 0.29772
Total Iteration Time: 4.68798

Cumulative Model Updates: 65,154
Cumulative Timesteps: 543,470,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.22284
Policy Entropy: 3.34628
Value Function Loss: 0.00366

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08956
Policy Update Magnitude: 0.53729
Value Function Update Magnitude: 0.63879

Collected Steps per Second: 23,040.32633
Overall Steps per Second: 10,893.99325

Timestep Collection Time: 2.17106
Timestep Consumption Time: 2.42064
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.59170

Cumulative Model Updates: 65,160
Cumulative Timesteps: 543,520,392

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 543520392...
Checkpoint 543520392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 833.81517
Policy Entropy: 3.33247
Value Function Loss: 0.00373

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11015
Policy Update Magnitude: 0.54493
Value Function Update Magnitude: 0.66225

Collected Steps per Second: 22,807.86711
Overall Steps per Second: 10,638.91011

Timestep Collection Time: 2.19328
Timestep Consumption Time: 2.50871
PPO Batch Consumption Time: 0.29742
Total Iteration Time: 4.70199

Cumulative Model Updates: 65,166
Cumulative Timesteps: 543,570,416

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 986.41157
Policy Entropy: 3.34826
Value Function Loss: 0.00352

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09783
Policy Update Magnitude: 0.54053
Value Function Update Magnitude: 0.64639

Collected Steps per Second: 22,325.72507
Overall Steps per Second: 10,587.52732

Timestep Collection Time: 2.24020
Timestep Consumption Time: 2.48366
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.72386

Cumulative Model Updates: 65,172
Cumulative Timesteps: 543,620,430

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 543620430...
Checkpoint 543620430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719.95564
Policy Entropy: 3.35083
Value Function Loss: 0.00356

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08898
Policy Update Magnitude: 0.54098
Value Function Update Magnitude: 0.64878

Collected Steps per Second: 22,475.49581
Overall Steps per Second: 10,623.62718

Timestep Collection Time: 2.22545
Timestep Consumption Time: 2.48274
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.70818

Cumulative Model Updates: 65,178
Cumulative Timesteps: 543,670,448

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 735.04222
Policy Entropy: 3.33996
Value Function Loss: 0.00402

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09826
Policy Update Magnitude: 0.55321
Value Function Update Magnitude: 0.65831

Collected Steps per Second: 22,256.38188
Overall Steps per Second: 10,709.46009

Timestep Collection Time: 2.24736
Timestep Consumption Time: 2.42309
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.67045

Cumulative Model Updates: 65,184
Cumulative Timesteps: 543,720,466

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 543720466...
Checkpoint 543720466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 997.90404
Policy Entropy: 3.32499
Value Function Loss: 0.00400

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09030
Policy Update Magnitude: 0.56562
Value Function Update Magnitude: 0.68721

Collected Steps per Second: 22,318.33800
Overall Steps per Second: 10,681.73736

Timestep Collection Time: 2.24112
Timestep Consumption Time: 2.44145
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.68257

Cumulative Model Updates: 65,190
Cumulative Timesteps: 543,770,484

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.86181
Policy Entropy: 3.31389
Value Function Loss: 0.00383

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08887
Policy Update Magnitude: 0.57098
Value Function Update Magnitude: 0.68679

Collected Steps per Second: 22,833.27071
Overall Steps per Second: 10,850.42311

Timestep Collection Time: 2.19110
Timestep Consumption Time: 2.41978
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.61088

Cumulative Model Updates: 65,196
Cumulative Timesteps: 543,820,514

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 543820514...
Checkpoint 543820514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643.36328
Policy Entropy: 3.32104
Value Function Loss: 0.00359

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.11923
Policy Update Magnitude: 0.55992
Value Function Update Magnitude: 0.66347

Collected Steps per Second: 21,982.43954
Overall Steps per Second: 10,649.29898

Timestep Collection Time: 2.27563
Timestep Consumption Time: 2.42176
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.69740

Cumulative Model Updates: 65,202
Cumulative Timesteps: 543,870,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 947.96274
Policy Entropy: 3.32299
Value Function Loss: 0.00380

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.10843
Policy Update Magnitude: 0.55468
Value Function Update Magnitude: 0.65376

Collected Steps per Second: 22,616.71341
Overall Steps per Second: 10,601.44798

Timestep Collection Time: 2.21146
Timestep Consumption Time: 2.50638
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.71785

Cumulative Model Updates: 65,208
Cumulative Timesteps: 543,920,554

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 543920554...
Checkpoint 543920554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.55913
Policy Entropy: 3.35117
Value Function Loss: 0.00358

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08134
Policy Update Magnitude: 0.54601
Value Function Update Magnitude: 0.64050

Collected Steps per Second: 22,462.03125
Overall Steps per Second: 10,587.96537

Timestep Collection Time: 2.22607
Timestep Consumption Time: 2.49646
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.72253

Cumulative Model Updates: 65,214
Cumulative Timesteps: 543,970,556

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,804.24820
Policy Entropy: 3.36265
Value Function Loss: 0.00346

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08494
Policy Update Magnitude: 0.53163
Value Function Update Magnitude: 0.60870

Collected Steps per Second: 22,533.76393
Overall Steps per Second: 10,616.52992

Timestep Collection Time: 2.21951
Timestep Consumption Time: 2.49144
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.71096

Cumulative Model Updates: 65,220
Cumulative Timesteps: 544,020,570

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 544020570...
Checkpoint 544020570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 950.12330
Policy Entropy: 3.38992
Value Function Loss: 0.00343

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08046
Policy Update Magnitude: 0.52523
Value Function Update Magnitude: 0.60032

Collected Steps per Second: 22,743.17363
Overall Steps per Second: 10,849.04375

Timestep Collection Time: 2.19899
Timestep Consumption Time: 2.41082
PPO Batch Consumption Time: 0.28230
Total Iteration Time: 4.60981

Cumulative Model Updates: 65,226
Cumulative Timesteps: 544,070,582

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,506.19146
Policy Entropy: 3.38230
Value Function Loss: 0.00361

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.06962
Policy Update Magnitude: 0.53021
Value Function Update Magnitude: 0.61803

Collected Steps per Second: 22,858.29389
Overall Steps per Second: 10,726.70062

Timestep Collection Time: 2.18835
Timestep Consumption Time: 2.47496
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.66332

Cumulative Model Updates: 65,232
Cumulative Timesteps: 544,120,604

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 544120604...
Checkpoint 544120604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.20472
Policy Entropy: 3.37682
Value Function Loss: 0.00350

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07340
Policy Update Magnitude: 0.53128
Value Function Update Magnitude: 0.61857

Collected Steps per Second: 23,129.24484
Overall Steps per Second: 10,916.38215

Timestep Collection Time: 2.16220
Timestep Consumption Time: 2.41899
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.58119

Cumulative Model Updates: 65,238
Cumulative Timesteps: 544,170,614

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.62574
Policy Entropy: 3.35737
Value Function Loss: 0.00366

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07940
Policy Update Magnitude: 0.52990
Value Function Update Magnitude: 0.62015

Collected Steps per Second: 22,891.31946
Overall Steps per Second: 10,857.54222

Timestep Collection Time: 2.18502
Timestep Consumption Time: 2.42173
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.60675

Cumulative Model Updates: 65,244
Cumulative Timesteps: 544,220,632

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 544220632...
Checkpoint 544220632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 799.83092
Policy Entropy: 3.34952
Value Function Loss: 0.00373

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08034
Policy Update Magnitude: 0.53586
Value Function Update Magnitude: 0.63303

Collected Steps per Second: 22,632.52852
Overall Steps per Second: 10,672.57727

Timestep Collection Time: 2.20930
Timestep Consumption Time: 2.47579
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.68509

Cumulative Model Updates: 65,250
Cumulative Timesteps: 544,270,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 885.91943
Policy Entropy: 3.35660
Value Function Loss: 0.00374

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08615
Policy Update Magnitude: 0.54017
Value Function Update Magnitude: 0.63570

Collected Steps per Second: 22,144.20883
Overall Steps per Second: 10,496.40246

Timestep Collection Time: 2.25802
Timestep Consumption Time: 2.50571
PPO Batch Consumption Time: 0.29586
Total Iteration Time: 4.76373

Cumulative Model Updates: 65,256
Cumulative Timesteps: 544,320,636

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 544320636...
Checkpoint 544320636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,716.30994
Policy Entropy: 3.37153
Value Function Loss: 0.00369

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08726
Policy Update Magnitude: 0.53409
Value Function Update Magnitude: 0.62704

Collected Steps per Second: 22,408.72105
Overall Steps per Second: 10,580.42772

Timestep Collection Time: 2.23136
Timestep Consumption Time: 2.49453
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.72590

Cumulative Model Updates: 65,262
Cumulative Timesteps: 544,370,638

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.57445
Policy Entropy: 3.38031
Value Function Loss: 0.00360

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07963
Policy Update Magnitude: 0.53124
Value Function Update Magnitude: 0.61699

Collected Steps per Second: 22,584.82679
Overall Steps per Second: 10,656.27217

Timestep Collection Time: 2.21414
Timestep Consumption Time: 2.47849
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.69264

Cumulative Model Updates: 65,268
Cumulative Timesteps: 544,420,644

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 544420644...
Checkpoint 544420644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.44458
Policy Entropy: 3.36394
Value Function Loss: 0.00371

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.52773
Value Function Update Magnitude: 0.60154

Collected Steps per Second: 22,523.29826
Overall Steps per Second: 10,586.39387

Timestep Collection Time: 2.22108
Timestep Consumption Time: 2.50442
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.72550

Cumulative Model Updates: 65,274
Cumulative Timesteps: 544,470,670

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767.64176
Policy Entropy: 3.35556
Value Function Loss: 0.00378

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08193
Policy Update Magnitude: 0.53228
Value Function Update Magnitude: 0.61288

Collected Steps per Second: 22,571.64052
Overall Steps per Second: 10,656.67520

Timestep Collection Time: 2.21552
Timestep Consumption Time: 2.47712
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.69265

Cumulative Model Updates: 65,280
Cumulative Timesteps: 544,520,678

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 544520678...
Checkpoint 544520678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,054.12569
Policy Entropy: 3.34701
Value Function Loss: 0.00365

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.53864
Value Function Update Magnitude: 0.62789

Collected Steps per Second: 22,601.38466
Overall Steps per Second: 10,708.62268

Timestep Collection Time: 2.21261
Timestep Consumption Time: 2.45727
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.66988

Cumulative Model Updates: 65,286
Cumulative Timesteps: 544,570,686

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,557.33591
Policy Entropy: 3.34709
Value Function Loss: 0.00358

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08222
Policy Update Magnitude: 0.53001
Value Function Update Magnitude: 0.63296

Collected Steps per Second: 22,627.09312
Overall Steps per Second: 10,527.09074

Timestep Collection Time: 2.20992
Timestep Consumption Time: 2.54011
PPO Batch Consumption Time: 0.29694
Total Iteration Time: 4.75003

Cumulative Model Updates: 65,292
Cumulative Timesteps: 544,620,690

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 544620690...
Checkpoint 544620690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.98705
Policy Entropy: 3.33718
Value Function Loss: 0.00359

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08224
Policy Update Magnitude: 0.53129
Value Function Update Magnitude: 0.63863

Collected Steps per Second: 22,854.87384
Overall Steps per Second: 10,701.84990

Timestep Collection Time: 2.18798
Timestep Consumption Time: 2.48467
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.67265

Cumulative Model Updates: 65,298
Cumulative Timesteps: 544,670,696

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,306.63313
Policy Entropy: 3.34032
Value Function Loss: 0.00356

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.53879
Value Function Update Magnitude: 0.65059

Collected Steps per Second: 22,725.04562
Overall Steps per Second: 10,807.11395

Timestep Collection Time: 2.20118
Timestep Consumption Time: 2.42743
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.62862

Cumulative Model Updates: 65,304
Cumulative Timesteps: 544,720,718

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 544720718...
Checkpoint 544720718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.50052
Policy Entropy: 3.32982
Value Function Loss: 0.00365

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08721
Policy Update Magnitude: 0.54415
Value Function Update Magnitude: 0.64362

Collected Steps per Second: 22,655.68694
Overall Steps per Second: 10,601.38273

Timestep Collection Time: 2.20695
Timestep Consumption Time: 2.50941
PPO Batch Consumption Time: 0.29799
Total Iteration Time: 4.71637

Cumulative Model Updates: 65,310
Cumulative Timesteps: 544,770,718

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.11574
Policy Entropy: 3.35250
Value Function Loss: 0.00357

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08654
Policy Update Magnitude: 0.54197
Value Function Update Magnitude: 0.62933

Collected Steps per Second: 22,673.15541
Overall Steps per Second: 10,854.19742

Timestep Collection Time: 2.20560
Timestep Consumption Time: 2.40165
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.60725

Cumulative Model Updates: 65,316
Cumulative Timesteps: 544,820,726

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 544820726...
Checkpoint 544820726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.61136
Policy Entropy: 3.35791
Value Function Loss: 0.00359

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08187
Policy Update Magnitude: 0.53679
Value Function Update Magnitude: 0.61925

Collected Steps per Second: 22,326.56884
Overall Steps per Second: 10,730.70735

Timestep Collection Time: 2.23984
Timestep Consumption Time: 2.42043
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.66027

Cumulative Model Updates: 65,322
Cumulative Timesteps: 544,870,734

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,612.30942
Policy Entropy: 3.36781
Value Function Loss: 0.00352

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09819
Policy Update Magnitude: 0.52886
Value Function Update Magnitude: 0.61724

Collected Steps per Second: 22,263.55261
Overall Steps per Second: 10,456.92509

Timestep Collection Time: 2.24591
Timestep Consumption Time: 2.53580
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.78171

Cumulative Model Updates: 65,328
Cumulative Timesteps: 544,920,736

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 544920736...
Checkpoint 544920736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.10998
Policy Entropy: 3.38133
Value Function Loss: 0.00343

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08635
Policy Update Magnitude: 0.52473
Value Function Update Magnitude: 0.60955

Collected Steps per Second: 22,205.55147
Overall Steps per Second: 10,592.23779

Timestep Collection Time: 2.25358
Timestep Consumption Time: 2.47082
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.72440

Cumulative Model Updates: 65,334
Cumulative Timesteps: 544,970,778

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,677.98244
Policy Entropy: 3.37076
Value Function Loss: 0.00342

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09074
Policy Update Magnitude: 0.51664
Value Function Update Magnitude: 0.59905

Collected Steps per Second: 22,337.80575
Overall Steps per Second: 10,484.96099

Timestep Collection Time: 2.23934
Timestep Consumption Time: 2.53149
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.77083

Cumulative Model Updates: 65,340
Cumulative Timesteps: 545,020,800

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 545020800...
Checkpoint 545020800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.83521
Policy Entropy: 3.37265
Value Function Loss: 0.00351

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.50832
Value Function Update Magnitude: 0.60715

Collected Steps per Second: 22,507.69383
Overall Steps per Second: 10,612.35409

Timestep Collection Time: 2.22253
Timestep Consumption Time: 2.49122
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.71375

Cumulative Model Updates: 65,346
Cumulative Timesteps: 545,070,824

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,487.36486
Policy Entropy: 3.34811
Value Function Loss: 0.00362

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10618
Policy Update Magnitude: 0.51809
Value Function Update Magnitude: 0.61148

Collected Steps per Second: 22,534.11947
Overall Steps per Second: 10,445.32603

Timestep Collection Time: 2.21886
Timestep Consumption Time: 2.56797
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.78683

Cumulative Model Updates: 65,352
Cumulative Timesteps: 545,120,824

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 545120824...
Checkpoint 545120824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,934.59922
Policy Entropy: 3.34787
Value Function Loss: 0.00359

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09894
Policy Update Magnitude: 0.52342
Value Function Update Magnitude: 0.61527

Collected Steps per Second: 22,495.32491
Overall Steps per Second: 10,633.53225

Timestep Collection Time: 2.22322
Timestep Consumption Time: 2.48002
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.70323

Cumulative Model Updates: 65,358
Cumulative Timesteps: 545,170,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,504.28211
Policy Entropy: 3.35110
Value Function Loss: 0.00348

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.52196
Value Function Update Magnitude: 0.62359

Collected Steps per Second: 22,602.64404
Overall Steps per Second: 10,639.31785

Timestep Collection Time: 2.21319
Timestep Consumption Time: 2.48861
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.70181

Cumulative Model Updates: 65,364
Cumulative Timesteps: 545,220,860

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 545220860...
Checkpoint 545220860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 798.20995
Policy Entropy: 3.36250
Value Function Loss: 0.00339

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.51681
Value Function Update Magnitude: 0.60281

Collected Steps per Second: 22,871.65467
Overall Steps per Second: 10,843.56457

Timestep Collection Time: 2.18620
Timestep Consumption Time: 2.42501
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.61121

Cumulative Model Updates: 65,370
Cumulative Timesteps: 545,270,862

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.02537
Policy Entropy: 3.36796
Value Function Loss: 0.00334

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.51904
Value Function Update Magnitude: 0.58961

Collected Steps per Second: 22,923.27536
Overall Steps per Second: 10,710.85741

Timestep Collection Time: 2.18197
Timestep Consumption Time: 2.48787
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.66984

Cumulative Model Updates: 65,376
Cumulative Timesteps: 545,320,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 545320880...
Checkpoint 545320880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.83290
Policy Entropy: 3.36120
Value Function Loss: 0.00327

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08754
Policy Update Magnitude: 0.51517
Value Function Update Magnitude: 0.58448

Collected Steps per Second: 22,694.74327
Overall Steps per Second: 10,663.24224

Timestep Collection Time: 2.20395
Timestep Consumption Time: 2.48675
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.69069

Cumulative Model Updates: 65,382
Cumulative Timesteps: 545,370,898

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.40879
Policy Entropy: 3.35078
Value Function Loss: 0.00344

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08338
Policy Update Magnitude: 0.52505
Value Function Update Magnitude: 0.58495

Collected Steps per Second: 22,662.77963
Overall Steps per Second: 10,741.01791

Timestep Collection Time: 2.20679
Timestep Consumption Time: 2.44938
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.65617

Cumulative Model Updates: 65,388
Cumulative Timesteps: 545,420,910

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 545420910...
Checkpoint 545420910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,519.26339
Policy Entropy: 3.34102
Value Function Loss: 0.00325

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.52717
Value Function Update Magnitude: 0.59086

Collected Steps per Second: 22,406.24949
Overall Steps per Second: 10,630.26522

Timestep Collection Time: 2.23215
Timestep Consumption Time: 2.47272
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.70487

Cumulative Model Updates: 65,394
Cumulative Timesteps: 545,470,924

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 877.98405
Policy Entropy: 3.34962
Value Function Loss: 0.00356

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09959
Policy Update Magnitude: 0.52056
Value Function Update Magnitude: 0.57476

Collected Steps per Second: 21,311.37112
Overall Steps per Second: 10,486.81455

Timestep Collection Time: 2.34692
Timestep Consumption Time: 2.42250
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.76942

Cumulative Model Updates: 65,400
Cumulative Timesteps: 545,520,940

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 545520940...
Checkpoint 545520940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 863.16532
Policy Entropy: 3.34039
Value Function Loss: 0.00346

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10563
Policy Update Magnitude: 0.51563
Value Function Update Magnitude: 0.57823

Collected Steps per Second: 22,076.53399
Overall Steps per Second: 10,565.32627

Timestep Collection Time: 2.26603
Timestep Consumption Time: 2.46890
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.73492

Cumulative Model Updates: 65,406
Cumulative Timesteps: 545,570,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.13538
Policy Entropy: 3.34034
Value Function Loss: 0.00379

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10133
Policy Update Magnitude: 0.52674
Value Function Update Magnitude: 0.59388

Collected Steps per Second: 22,749.71220
Overall Steps per Second: 10,545.40062

Timestep Collection Time: 2.19915
Timestep Consumption Time: 2.54510
PPO Batch Consumption Time: 0.29723
Total Iteration Time: 4.74425

Cumulative Model Updates: 65,412
Cumulative Timesteps: 545,620,996

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 545620996...
Checkpoint 545620996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.48391
Policy Entropy: 3.35073
Value Function Loss: 0.00357

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10355
Policy Update Magnitude: 0.53606
Value Function Update Magnitude: 0.63630

Collected Steps per Second: 22,235.31618
Overall Steps per Second: 10,636.99459

Timestep Collection Time: 2.24921
Timestep Consumption Time: 2.45249
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.70170

Cumulative Model Updates: 65,418
Cumulative Timesteps: 545,671,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 814.45021
Policy Entropy: 3.35481
Value Function Loss: 0.00348

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08599
Policy Update Magnitude: 0.53690
Value Function Update Magnitude: 0.63207

Collected Steps per Second: 22,902.15664
Overall Steps per Second: 10,809.08980

Timestep Collection Time: 2.18442
Timestep Consumption Time: 2.44390
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.62833

Cumulative Model Updates: 65,424
Cumulative Timesteps: 545,721,036

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 545721036...
Checkpoint 545721036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 902.08738
Policy Entropy: 3.35520
Value Function Loss: 0.00350

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07298
Policy Update Magnitude: 0.52885
Value Function Update Magnitude: 0.62607

Collected Steps per Second: 22,268.86601
Overall Steps per Second: 10,736.09778

Timestep Collection Time: 2.24601
Timestep Consumption Time: 2.41267
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.65868

Cumulative Model Updates: 65,430
Cumulative Timesteps: 545,771,052

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,942.61819
Policy Entropy: 3.34433
Value Function Loss: 0.00371

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07231
Policy Update Magnitude: 0.53266
Value Function Update Magnitude: 0.64356

Collected Steps per Second: 22,965.53040
Overall Steps per Second: 10,846.13162

Timestep Collection Time: 2.17805
Timestep Consumption Time: 2.43374
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.61178

Cumulative Model Updates: 65,436
Cumulative Timesteps: 545,821,072

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 545821072...
Checkpoint 545821072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,506.28282
Policy Entropy: 3.34025
Value Function Loss: 0.00378

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07547
Policy Update Magnitude: 0.54192
Value Function Update Magnitude: 0.67362

Collected Steps per Second: 22,759.99983
Overall Steps per Second: 10,678.08782

Timestep Collection Time: 2.19807
Timestep Consumption Time: 2.48704
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.68511

Cumulative Model Updates: 65,442
Cumulative Timesteps: 545,871,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.30126
Policy Entropy: 3.34721
Value Function Loss: 0.00369

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07107
Policy Update Magnitude: 0.54911
Value Function Update Magnitude: 0.67954

Collected Steps per Second: 22,746.72350
Overall Steps per Second: 10,790.45022

Timestep Collection Time: 2.19821
Timestep Consumption Time: 2.43571
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.63391

Cumulative Model Updates: 65,448
Cumulative Timesteps: 545,921,102

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 545921102...
Checkpoint 545921102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.66061
Policy Entropy: 3.34913
Value Function Loss: 0.00346

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07488
Policy Update Magnitude: 0.54807
Value Function Update Magnitude: 0.67723

Collected Steps per Second: 22,212.70175
Overall Steps per Second: 10,671.81876

Timestep Collection Time: 2.25105
Timestep Consumption Time: 2.43437
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.68542

Cumulative Model Updates: 65,454
Cumulative Timesteps: 545,971,104

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.58966
Policy Entropy: 3.36584
Value Function Loss: 0.00337

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10639
Policy Update Magnitude: 0.53307
Value Function Update Magnitude: 0.65553

Collected Steps per Second: 22,524.17452
Overall Steps per Second: 10,617.27154

Timestep Collection Time: 2.22090
Timestep Consumption Time: 2.49067
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.71157

Cumulative Model Updates: 65,460
Cumulative Timesteps: 546,021,128

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 546021128...
Checkpoint 546021128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 889.26222
Policy Entropy: 3.37807
Value Function Loss: 0.00332

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10068
Policy Update Magnitude: 0.52342
Value Function Update Magnitude: 0.63056

Collected Steps per Second: 22,449.52515
Overall Steps per Second: 10,562.94111

Timestep Collection Time: 2.22802
Timestep Consumption Time: 2.50721
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.73523

Cumulative Model Updates: 65,466
Cumulative Timesteps: 546,071,146

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475.33140
Policy Entropy: 3.38660
Value Function Loss: 0.00340

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10351
Policy Update Magnitude: 0.52893
Value Function Update Magnitude: 0.63353

Collected Steps per Second: 22,868.59022
Overall Steps per Second: 10,856.19746

Timestep Collection Time: 2.18641
Timestep Consumption Time: 2.41926
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.60566

Cumulative Model Updates: 65,472
Cumulative Timesteps: 546,121,146

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 546121146...
Checkpoint 546121146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 994.79993
Policy Entropy: 3.38795
Value Function Loss: 0.00341

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10026
Policy Update Magnitude: 0.52558
Value Function Update Magnitude: 0.63419

Collected Steps per Second: 22,222.33474
Overall Steps per Second: 10,644.67358

Timestep Collection Time: 2.25143
Timestep Consumption Time: 2.44876
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.70019

Cumulative Model Updates: 65,478
Cumulative Timesteps: 546,171,178

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 756.01151
Policy Entropy: 3.37093
Value Function Loss: 0.00350

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10331
Policy Update Magnitude: 0.52754
Value Function Update Magnitude: 0.63453

Collected Steps per Second: 22,985.00702
Overall Steps per Second: 10,835.61219

Timestep Collection Time: 2.17551
Timestep Consumption Time: 2.43928
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.61478

Cumulative Model Updates: 65,484
Cumulative Timesteps: 546,221,182

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 546221182...
Checkpoint 546221182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.02856
Policy Entropy: 3.36738
Value Function Loss: 0.00358

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09493
Policy Update Magnitude: 0.54226
Value Function Update Magnitude: 0.62003

Collected Steps per Second: 22,563.41347
Overall Steps per Second: 10,730.27029

Timestep Collection Time: 2.21651
Timestep Consumption Time: 2.44432
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.66083

Cumulative Model Updates: 65,490
Cumulative Timesteps: 546,271,194

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.67489
Policy Entropy: 3.35033
Value Function Loss: 0.00364

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.54478
Value Function Update Magnitude: 0.61427

Collected Steps per Second: 22,955.22080
Overall Steps per Second: 10,842.55026

Timestep Collection Time: 2.17902
Timestep Consumption Time: 2.43428
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.61331

Cumulative Model Updates: 65,496
Cumulative Timesteps: 546,321,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 546321214...
Checkpoint 546321214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 787.17203
Policy Entropy: 3.34123
Value Function Loss: 0.00371

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.54453
Value Function Update Magnitude: 0.63389

Collected Steps per Second: 22,172.86250
Overall Steps per Second: 10,694.06569

Timestep Collection Time: 2.25564
Timestep Consumption Time: 2.42116
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.67680

Cumulative Model Updates: 65,502
Cumulative Timesteps: 546,371,228

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.81219
Policy Entropy: 3.34598
Value Function Loss: 0.00372

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09352
Policy Update Magnitude: 0.54795
Value Function Update Magnitude: 0.65287

Collected Steps per Second: 22,618.56891
Overall Steps per Second: 10,642.83625

Timestep Collection Time: 2.21057
Timestep Consumption Time: 2.48742
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.69800

Cumulative Model Updates: 65,508
Cumulative Timesteps: 546,421,228

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 546421228...
Checkpoint 546421228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.12069
Policy Entropy: 3.35758
Value Function Loss: 0.00359

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09132
Policy Update Magnitude: 0.55122
Value Function Update Magnitude: 0.66041

Collected Steps per Second: 22,646.73271
Overall Steps per Second: 10,808.59067

Timestep Collection Time: 2.20782
Timestep Consumption Time: 2.41813
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.62595

Cumulative Model Updates: 65,514
Cumulative Timesteps: 546,471,228

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 875.09609
Policy Entropy: 3.36697
Value Function Loss: 0.00342

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.54130
Value Function Update Magnitude: 0.64920

Collected Steps per Second: 22,316.33951
Overall Steps per Second: 10,564.08783

Timestep Collection Time: 2.24177
Timestep Consumption Time: 2.49390
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.73567

Cumulative Model Updates: 65,520
Cumulative Timesteps: 546,521,256

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 546521256...
Checkpoint 546521256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415.32468
Policy Entropy: 3.37389
Value Function Loss: 0.00327

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08845
Policy Update Magnitude: 0.53567
Value Function Update Magnitude: 0.62924

Collected Steps per Second: 22,034.41200
Overall Steps per Second: 10,635.07548

Timestep Collection Time: 2.26936
Timestep Consumption Time: 2.43244
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.70180

Cumulative Model Updates: 65,526
Cumulative Timesteps: 546,571,260

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.89515
Policy Entropy: 3.36117
Value Function Loss: 0.00354

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09796
Policy Update Magnitude: 0.53408
Value Function Update Magnitude: 0.63043

Collected Steps per Second: 22,385.32411
Overall Steps per Second: 10,620.63356

Timestep Collection Time: 2.23450
Timestep Consumption Time: 2.47520
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.70970

Cumulative Model Updates: 65,532
Cumulative Timesteps: 546,621,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 546621280...
Checkpoint 546621280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.28554
Policy Entropy: 3.36125
Value Function Loss: 0.00347

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09570
Policy Update Magnitude: 0.53729
Value Function Update Magnitude: 0.65097

Collected Steps per Second: 22,590.54684
Overall Steps per Second: 10,694.18425

Timestep Collection Time: 2.21367
Timestep Consumption Time: 2.46252
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.67619

Cumulative Model Updates: 65,538
Cumulative Timesteps: 546,671,288

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.08808
Policy Entropy: 3.36004
Value Function Loss: 0.00347

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08845
Policy Update Magnitude: 0.54889
Value Function Update Magnitude: 0.65768

Collected Steps per Second: 22,810.77757
Overall Steps per Second: 10,662.69723

Timestep Collection Time: 2.19203
Timestep Consumption Time: 2.49740
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.68943

Cumulative Model Updates: 65,544
Cumulative Timesteps: 546,721,290

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 546721290...
Checkpoint 546721290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 875.14647
Policy Entropy: 3.36893
Value Function Loss: 0.00341

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07714
Policy Update Magnitude: 0.55944
Value Function Update Magnitude: 0.66544

Collected Steps per Second: 22,548.86271
Overall Steps per Second: 10,619.81137

Timestep Collection Time: 2.21820
Timestep Consumption Time: 2.49167
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.70988

Cumulative Model Updates: 65,550
Cumulative Timesteps: 546,771,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.58111
Policy Entropy: 3.37328
Value Function Loss: 0.00329

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07852
Policy Update Magnitude: 0.56420
Value Function Update Magnitude: 0.66453

Collected Steps per Second: 23,004.00321
Overall Steps per Second: 10,652.58410

Timestep Collection Time: 2.17388
Timestep Consumption Time: 2.52057
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.69445

Cumulative Model Updates: 65,556
Cumulative Timesteps: 546,821,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 546821316...
Checkpoint 546821316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,925.63360
Policy Entropy: 3.37099
Value Function Loss: 0.00322

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07515
Policy Update Magnitude: 0.56271
Value Function Update Magnitude: 0.66102

Collected Steps per Second: 22,855.53317
Overall Steps per Second: 10,876.08481

Timestep Collection Time: 2.18818
Timestep Consumption Time: 2.41017
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.59835

Cumulative Model Updates: 65,562
Cumulative Timesteps: 546,871,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.95995
Policy Entropy: 3.35440
Value Function Loss: 0.00323

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08037
Policy Update Magnitude: 0.55008
Value Function Update Magnitude: 0.64955

Collected Steps per Second: 23,079.18765
Overall Steps per Second: 10,858.95054

Timestep Collection Time: 2.16784
Timestep Consumption Time: 2.43960
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.60744

Cumulative Model Updates: 65,568
Cumulative Timesteps: 546,921,360

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 546921360...
Checkpoint 546921360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 989.36338
Policy Entropy: 3.35524
Value Function Loss: 0.00333

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10289
Policy Update Magnitude: 0.53883
Value Function Update Magnitude: 0.65075

Collected Steps per Second: 22,265.99931
Overall Steps per Second: 10,720.32043

Timestep Collection Time: 2.24603
Timestep Consumption Time: 2.41895
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.66497

Cumulative Model Updates: 65,574
Cumulative Timesteps: 546,971,370

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.72888
Policy Entropy: 3.34815
Value Function Loss: 0.00346

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10356
Policy Update Magnitude: 0.54604
Value Function Update Magnitude: 0.67092

Collected Steps per Second: 22,893.07753
Overall Steps per Second: 10,835.68410

Timestep Collection Time: 2.18415
Timestep Consumption Time: 2.43041
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.61457

Cumulative Model Updates: 65,580
Cumulative Timesteps: 547,021,372

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 547021372...
Checkpoint 547021372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.36664
Policy Entropy: 3.35123
Value Function Loss: 0.00358

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.55459
Value Function Update Magnitude: 0.67068

Collected Steps per Second: 21,781.18961
Overall Steps per Second: 10,604.89855

Timestep Collection Time: 2.29666
Timestep Consumption Time: 2.42040
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.71707

Cumulative Model Updates: 65,586
Cumulative Timesteps: 547,071,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 727.36477
Policy Entropy: 3.33949
Value Function Loss: 0.00387

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.56527
Value Function Update Magnitude: 0.67664

Collected Steps per Second: 22,122.89875
Overall Steps per Second: 10,576.79677

Timestep Collection Time: 2.26119
Timestep Consumption Time: 2.46841
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.72960

Cumulative Model Updates: 65,592
Cumulative Timesteps: 547,121,420

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 547121420...
Checkpoint 547121420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.03502
Policy Entropy: 3.35426
Value Function Loss: 0.00384

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09346
Policy Update Magnitude: 0.57251
Value Function Update Magnitude: 0.69233

Collected Steps per Second: 22,246.00773
Overall Steps per Second: 10,651.74496

Timestep Collection Time: 2.24777
Timestep Consumption Time: 2.44667
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.69444

Cumulative Model Updates: 65,598
Cumulative Timesteps: 547,171,424

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.23819
Policy Entropy: 3.34989
Value Function Loss: 0.00371

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.56623
Value Function Update Magnitude: 0.67573

Collected Steps per Second: 22,516.67684
Overall Steps per Second: 10,675.19350

Timestep Collection Time: 2.22155
Timestep Consumption Time: 2.46426
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.68582

Cumulative Model Updates: 65,604
Cumulative Timesteps: 547,221,446

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 547221446...
Checkpoint 547221446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.49813
Policy Entropy: 3.35672
Value Function Loss: 0.00346

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09088
Policy Update Magnitude: 0.55284
Value Function Update Magnitude: 0.66065

Collected Steps per Second: 22,401.83687
Overall Steps per Second: 10,632.82306

Timestep Collection Time: 2.23250
Timestep Consumption Time: 2.47105
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.70355

Cumulative Model Updates: 65,610
Cumulative Timesteps: 547,271,458

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.97458
Policy Entropy: 3.36837
Value Function Loss: 0.00336

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.54758
Value Function Update Magnitude: 0.65357

Collected Steps per Second: 23,013.40529
Overall Steps per Second: 10,704.65339

Timestep Collection Time: 2.17352
Timestep Consumption Time: 2.49922
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.67273

Cumulative Model Updates: 65,616
Cumulative Timesteps: 547,321,478

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 547321478...
Checkpoint 547321478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.15609
Policy Entropy: 3.39311
Value Function Loss: 0.00344

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08972
Policy Update Magnitude: 0.53988
Value Function Update Magnitude: 0.64137

Collected Steps per Second: 22,520.35092
Overall Steps per Second: 10,613.75035

Timestep Collection Time: 2.22155
Timestep Consumption Time: 2.49215
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.71370

Cumulative Model Updates: 65,622
Cumulative Timesteps: 547,371,508

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.51222
Policy Entropy: 3.39039
Value Function Loss: 0.00339

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08337
Policy Update Magnitude: 0.53138
Value Function Update Magnitude: 0.61908

Collected Steps per Second: 22,128.94950
Overall Steps per Second: 10,470.82064

Timestep Collection Time: 2.26066
Timestep Consumption Time: 2.51700
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.77766

Cumulative Model Updates: 65,628
Cumulative Timesteps: 547,421,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 547421534...
Checkpoint 547421534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 840.07233
Policy Entropy: 3.37931
Value Function Loss: 0.00342

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.53273
Value Function Update Magnitude: 0.60201

Collected Steps per Second: 22,581.57719
Overall Steps per Second: 10,666.11145

Timestep Collection Time: 2.21508
Timestep Consumption Time: 2.47454
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.68962

Cumulative Model Updates: 65,634
Cumulative Timesteps: 547,471,554

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 743.97582
Policy Entropy: 3.36341
Value Function Loss: 0.00343

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09617
Policy Update Magnitude: 0.53040
Value Function Update Magnitude: 0.60901

Collected Steps per Second: 23,084.25773
Overall Steps per Second: 10,800.57747

Timestep Collection Time: 2.16632
Timestep Consumption Time: 2.46380
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.63012

Cumulative Model Updates: 65,640
Cumulative Timesteps: 547,521,562

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 547521562...
Checkpoint 547521562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 872.79786
Policy Entropy: 3.34691
Value Function Loss: 0.00345

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09681
Policy Update Magnitude: 0.53673
Value Function Update Magnitude: 0.62123

Collected Steps per Second: 22,410.53496
Overall Steps per Second: 10,767.27953

Timestep Collection Time: 2.23181
Timestep Consumption Time: 2.41338
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.64518

Cumulative Model Updates: 65,646
Cumulative Timesteps: 547,571,578

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.51823
Policy Entropy: 3.33415
Value Function Loss: 0.00347

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09641
Policy Update Magnitude: 0.54316
Value Function Update Magnitude: 0.63537

Collected Steps per Second: 22,764.83764
Overall Steps per Second: 10,811.78044

Timestep Collection Time: 2.19698
Timestep Consumption Time: 2.42890
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.62588

Cumulative Model Updates: 65,652
Cumulative Timesteps: 547,621,592

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 547621592...
Checkpoint 547621592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.46051
Policy Entropy: 3.32055
Value Function Loss: 0.00339

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.54028
Value Function Update Magnitude: 0.64624

Collected Steps per Second: 22,330.76563
Overall Steps per Second: 10,733.73299

Timestep Collection Time: 2.24050
Timestep Consumption Time: 2.42070
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.66119

Cumulative Model Updates: 65,658
Cumulative Timesteps: 547,671,624

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 735.27424
Policy Entropy: 3.31934
Value Function Loss: 0.00328

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10594
Policy Update Magnitude: 0.54309
Value Function Update Magnitude: 0.62702

Collected Steps per Second: 22,655.49086
Overall Steps per Second: 10,780.35055

Timestep Collection Time: 2.20697
Timestep Consumption Time: 2.43110
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.63807

Cumulative Model Updates: 65,664
Cumulative Timesteps: 547,721,624

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 547721624...
Checkpoint 547721624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529.63462
Policy Entropy: 3.31684
Value Function Loss: 0.00340

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.54388
Value Function Update Magnitude: 0.62174

Collected Steps per Second: 22,386.79355
Overall Steps per Second: 10,639.87142

Timestep Collection Time: 2.23382
Timestep Consumption Time: 2.46624
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.70006

Cumulative Model Updates: 65,670
Cumulative Timesteps: 547,771,632

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 737.24982
Policy Entropy: 3.33427
Value Function Loss: 0.00325

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08490
Policy Update Magnitude: 0.54655
Value Function Update Magnitude: 0.61525

Collected Steps per Second: 22,848.69414
Overall Steps per Second: 10,722.72017

Timestep Collection Time: 2.18840
Timestep Consumption Time: 2.47479
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.66318

Cumulative Model Updates: 65,676
Cumulative Timesteps: 547,821,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 547821634...
Checkpoint 547821634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.46408
Policy Entropy: 3.32131
Value Function Loss: 0.00346

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10020
Policy Update Magnitude: 0.54777
Value Function Update Magnitude: 0.61662

Collected Steps per Second: 22,712.51697
Overall Steps per Second: 10,807.29808

Timestep Collection Time: 2.20161
Timestep Consumption Time: 2.42527
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.62687

Cumulative Model Updates: 65,682
Cumulative Timesteps: 547,871,638

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.15748
Policy Entropy: 3.32283
Value Function Loss: 0.00353

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11238
Policy Update Magnitude: 0.55576
Value Function Update Magnitude: 0.62568

Collected Steps per Second: 22,839.59866
Overall Steps per Second: 10,731.82179

Timestep Collection Time: 2.19058
Timestep Consumption Time: 2.47144
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.66202

Cumulative Model Updates: 65,688
Cumulative Timesteps: 547,921,670

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 547921670...
Checkpoint 547921670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 971.91381
Policy Entropy: 3.31553
Value Function Loss: 0.00369

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.12022
Policy Update Magnitude: 0.55750
Value Function Update Magnitude: 0.64159

Collected Steps per Second: 22,672.85320
Overall Steps per Second: 10,811.92228

Timestep Collection Time: 2.20643
Timestep Consumption Time: 2.42050
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.62693

Cumulative Model Updates: 65,694
Cumulative Timesteps: 547,971,696

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 746.47271
Policy Entropy: 3.31561
Value Function Loss: 0.00348

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10148
Policy Update Magnitude: 0.55979
Value Function Update Magnitude: 0.64182

Collected Steps per Second: 22,907.08979
Overall Steps per Second: 10,719.04972

Timestep Collection Time: 2.18325
Timestep Consumption Time: 2.48246
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.66571

Cumulative Model Updates: 65,700
Cumulative Timesteps: 548,021,708

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 548021708...
Checkpoint 548021708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.76185
Policy Entropy: 3.32357
Value Function Loss: 0.00345

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08846
Policy Update Magnitude: 0.55496
Value Function Update Magnitude: 0.62165

Collected Steps per Second: 22,396.94120
Overall Steps per Second: 10,584.67827

Timestep Collection Time: 2.23272
Timestep Consumption Time: 2.49166
PPO Batch Consumption Time: 0.29582
Total Iteration Time: 4.72438

Cumulative Model Updates: 65,706
Cumulative Timesteps: 548,071,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.13835
Policy Entropy: 3.32664
Value Function Loss: 0.00344

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08849
Policy Update Magnitude: 0.54716
Value Function Update Magnitude: 0.60805

Collected Steps per Second: 22,571.55901
Overall Steps per Second: 10,751.65271

Timestep Collection Time: 2.21553
Timestep Consumption Time: 2.43566
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.65119

Cumulative Model Updates: 65,712
Cumulative Timesteps: 548,121,722

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 548121722...
Checkpoint 548121722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.21815
Policy Entropy: 3.33301
Value Function Loss: 0.00345

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.55408
Value Function Update Magnitude: 0.61648

Collected Steps per Second: 21,794.26907
Overall Steps per Second: 10,599.73796

Timestep Collection Time: 2.29556
Timestep Consumption Time: 2.42437
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.71993

Cumulative Model Updates: 65,718
Cumulative Timesteps: 548,171,752

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 926.03360
Policy Entropy: 3.33941
Value Function Loss: 0.00340

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.55395
Value Function Update Magnitude: 0.62806

Collected Steps per Second: 21,826.27325
Overall Steps per Second: 10,595.52554

Timestep Collection Time: 2.29082
Timestep Consumption Time: 2.42816
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.71897

Cumulative Model Updates: 65,724
Cumulative Timesteps: 548,221,752

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 548221752...
Checkpoint 548221752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 798.53532
Policy Entropy: 3.31604
Value Function Loss: 0.00342

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08247
Policy Update Magnitude: 0.55854
Value Function Update Magnitude: 0.62443

Collected Steps per Second: 22,355.97024
Overall Steps per Second: 10,601.45223

Timestep Collection Time: 2.23708
Timestep Consumption Time: 2.48039
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.71747

Cumulative Model Updates: 65,730
Cumulative Timesteps: 548,271,764

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 905.52479
Policy Entropy: 3.31617
Value Function Loss: 0.00360

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08166
Policy Update Magnitude: 0.55720
Value Function Update Magnitude: 0.63885

Collected Steps per Second: 22,806.66246
Overall Steps per Second: 10,885.46255

Timestep Collection Time: 2.19269
Timestep Consumption Time: 2.40132
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.59402

Cumulative Model Updates: 65,736
Cumulative Timesteps: 548,321,772

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 548321772...
Checkpoint 548321772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.31709
Policy Entropy: 3.32688
Value Function Loss: 0.00369

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.11844
Policy Update Magnitude: 0.55652
Value Function Update Magnitude: 0.64102

Collected Steps per Second: 21,936.92763
Overall Steps per Second: 10,667.75450

Timestep Collection Time: 2.27972
Timestep Consumption Time: 2.40824
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.68796

Cumulative Model Updates: 65,742
Cumulative Timesteps: 548,371,782

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760.94784
Policy Entropy: 3.34638
Value Function Loss: 0.00392

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.11687
Policy Update Magnitude: 0.54941
Value Function Update Magnitude: 0.66767

Collected Steps per Second: 22,140.14918
Overall Steps per Second: 10,811.31713

Timestep Collection Time: 2.25834
Timestep Consumption Time: 2.36644
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.62478

Cumulative Model Updates: 65,748
Cumulative Timesteps: 548,421,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 548421782...
Checkpoint 548421782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.64325
Policy Entropy: 3.36316
Value Function Loss: 0.00368

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11545
Policy Update Magnitude: 0.54424
Value Function Update Magnitude: 0.67040

Collected Steps per Second: 21,873.56610
Overall Steps per Second: 10,734.14873

Timestep Collection Time: 2.28660
Timestep Consumption Time: 2.37293
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.65952

Cumulative Model Updates: 65,754
Cumulative Timesteps: 548,471,798

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.71637
Policy Entropy: 3.35224
Value Function Loss: 0.00363

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09050
Policy Update Magnitude: 0.54495
Value Function Update Magnitude: 0.65397

Collected Steps per Second: 22,475.58641
Overall Steps per Second: 10,841.07139

Timestep Collection Time: 2.22561
Timestep Consumption Time: 2.38850
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.61412

Cumulative Model Updates: 65,760
Cumulative Timesteps: 548,521,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 548521820...
Checkpoint 548521820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,527.16315
Policy Entropy: 3.36456
Value Function Loss: 0.00359

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08598
Policy Update Magnitude: 0.55545
Value Function Update Magnitude: 0.63885

Collected Steps per Second: 21,951.22754
Overall Steps per Second: 10,660.84018

Timestep Collection Time: 2.27905
Timestep Consumption Time: 2.41364
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.69269

Cumulative Model Updates: 65,766
Cumulative Timesteps: 548,571,848

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 952.81456
Policy Entropy: 3.36024
Value Function Loss: 0.00355

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08160
Policy Update Magnitude: 0.56336
Value Function Update Magnitude: 0.64319

Collected Steps per Second: 22,501.12562
Overall Steps per Second: 10,848.00894

Timestep Collection Time: 2.22300
Timestep Consumption Time: 2.38798
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.61098

Cumulative Model Updates: 65,772
Cumulative Timesteps: 548,621,868

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 548621868...
Checkpoint 548621868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 816.83625
Policy Entropy: 3.36276
Value Function Loss: 0.00356

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08079
Policy Update Magnitude: 0.55274
Value Function Update Magnitude: 0.64447

Collected Steps per Second: 21,436.96686
Overall Steps per Second: 10,629.25852

Timestep Collection Time: 2.33307
Timestep Consumption Time: 2.37224
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.70531

Cumulative Model Updates: 65,778
Cumulative Timesteps: 548,671,882

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.48121
Policy Entropy: 3.35835
Value Function Loss: 0.00359

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07041
Policy Update Magnitude: 0.55537
Value Function Update Magnitude: 0.65252

Collected Steps per Second: 21,661.94432
Overall Steps per Second: 10,538.54587

Timestep Collection Time: 2.30856
Timestep Consumption Time: 2.43668
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.74525

Cumulative Model Updates: 65,784
Cumulative Timesteps: 548,721,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 548721890...
Checkpoint 548721890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545.11846
Policy Entropy: 3.34750
Value Function Loss: 0.00345

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08108
Policy Update Magnitude: 0.55996
Value Function Update Magnitude: 0.64868

Collected Steps per Second: 21,473.14183
Overall Steps per Second: 10,637.89565

Timestep Collection Time: 2.32970
Timestep Consumption Time: 2.37292
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.70262

Cumulative Model Updates: 65,790
Cumulative Timesteps: 548,771,916

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.30376
Policy Entropy: 3.33531
Value Function Loss: 0.00341

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08097
Policy Update Magnitude: 0.55034
Value Function Update Magnitude: 0.61781

Collected Steps per Second: 21,899.45218
Overall Steps per Second: 10,565.59631

Timestep Collection Time: 2.28408
Timestep Consumption Time: 2.45016
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.73423

Cumulative Model Updates: 65,796
Cumulative Timesteps: 548,821,936

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 548821936...
Checkpoint 548821936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.47822
Policy Entropy: 3.31979
Value Function Loss: 0.00357

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08596
Policy Update Magnitude: 0.55145
Value Function Update Magnitude: 0.60122

Collected Steps per Second: 22,833.37624
Overall Steps per Second: 10,592.75332

Timestep Collection Time: 2.19083
Timestep Consumption Time: 2.53165
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.72247

Cumulative Model Updates: 65,802
Cumulative Timesteps: 548,871,960

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 830.59134
Policy Entropy: 3.32411
Value Function Loss: 0.00356

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09409
Policy Update Magnitude: 0.55155
Value Function Update Magnitude: 0.60003

Collected Steps per Second: 23,004.49292
Overall Steps per Second: 10,770.58773

Timestep Collection Time: 2.17444
Timestep Consumption Time: 2.46987
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.64431

Cumulative Model Updates: 65,808
Cumulative Timesteps: 548,921,982

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 548921982...
Checkpoint 548921982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.24732
Policy Entropy: 3.32724
Value Function Loss: 0.00380

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08683
Policy Update Magnitude: 0.56207
Value Function Update Magnitude: 0.63332

Collected Steps per Second: 22,589.60690
Overall Steps per Second: 10,740.55460

Timestep Collection Time: 2.21350
Timestep Consumption Time: 2.44194
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.65544

Cumulative Model Updates: 65,814
Cumulative Timesteps: 548,971,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.64441
Policy Entropy: 3.34202
Value Function Loss: 0.00359

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.55958
Value Function Update Magnitude: 0.64050

Collected Steps per Second: 23,144.25251
Overall Steps per Second: 10,859.85516

Timestep Collection Time: 2.16054
Timestep Consumption Time: 2.44394
PPO Batch Consumption Time: 0.28172
Total Iteration Time: 4.60448

Cumulative Model Updates: 65,820
Cumulative Timesteps: 549,021,988

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 549021988...
Checkpoint 549021988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.65113
Policy Entropy: 3.32472
Value Function Loss: 0.00353

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10039
Policy Update Magnitude: 0.55079
Value Function Update Magnitude: 0.62198

Collected Steps per Second: 22,638.91412
Overall Steps per Second: 10,659.40234

Timestep Collection Time: 2.20920
Timestep Consumption Time: 2.48280
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.69201

Cumulative Model Updates: 65,826
Cumulative Timesteps: 549,072,002

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 858.15783
Policy Entropy: 3.34014
Value Function Loss: 0.00356

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10602
Policy Update Magnitude: 0.53783
Value Function Update Magnitude: 0.62263

Collected Steps per Second: 22,313.91317
Overall Steps per Second: 10,813.13574

Timestep Collection Time: 2.24093
Timestep Consumption Time: 2.38344
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.62438

Cumulative Model Updates: 65,832
Cumulative Timesteps: 549,122,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 549122006...
Checkpoint 549122006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 955.53083
Policy Entropy: 3.34158
Value Function Loss: 0.00346

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09965
Policy Update Magnitude: 0.53795
Value Function Update Magnitude: 0.62753

Collected Steps per Second: 22,369.43382
Overall Steps per Second: 10,680.36454

Timestep Collection Time: 2.23618
Timestep Consumption Time: 2.44737
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.68355

Cumulative Model Updates: 65,838
Cumulative Timesteps: 549,172,028

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684.44184
Policy Entropy: 3.33263
Value Function Loss: 0.00357

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09103
Policy Update Magnitude: 0.54794
Value Function Update Magnitude: 0.61918

Collected Steps per Second: 22,771.20770
Overall Steps per Second: 10,628.90848

Timestep Collection Time: 2.19576
Timestep Consumption Time: 2.50840
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.70415

Cumulative Model Updates: 65,844
Cumulative Timesteps: 549,222,028

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 549222028...
Checkpoint 549222028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 992.94931
Policy Entropy: 3.33990
Value Function Loss: 0.00331

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10492
Policy Update Magnitude: 0.54830
Value Function Update Magnitude: 0.61220

Collected Steps per Second: 22,326.74129
Overall Steps per Second: 10,528.89085

Timestep Collection Time: 2.23983
Timestep Consumption Time: 2.50977
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.74960

Cumulative Model Updates: 65,850
Cumulative Timesteps: 549,272,036

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 904.37435
Policy Entropy: 3.33113
Value Function Loss: 0.00347

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09493
Policy Update Magnitude: 0.55027
Value Function Update Magnitude: 0.60237

Collected Steps per Second: 22,912.20084
Overall Steps per Second: 10,727.51300

Timestep Collection Time: 2.18259
Timestep Consumption Time: 2.47907
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.66166

Cumulative Model Updates: 65,856
Cumulative Timesteps: 549,322,044

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 549322044...
Checkpoint 549322044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328.73488
Policy Entropy: 3.34881
Value Function Loss: 0.00332

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10222
Policy Update Magnitude: 0.54437
Value Function Update Magnitude: 0.60685

Collected Steps per Second: 22,051.48559
Overall Steps per Second: 10,529.67086

Timestep Collection Time: 2.26833
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.75039

Cumulative Model Updates: 65,862
Cumulative Timesteps: 549,372,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 953.63291
Policy Entropy: 3.33305
Value Function Loss: 0.00356

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09797
Policy Update Magnitude: 0.54050
Value Function Update Magnitude: 0.60498

Collected Steps per Second: 22,932.02458
Overall Steps per Second: 10,744.90739

Timestep Collection Time: 2.18228
Timestep Consumption Time: 2.47519
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.65746

Cumulative Model Updates: 65,868
Cumulative Timesteps: 549,422,108

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 549422108...
Checkpoint 549422108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 996.79094
Policy Entropy: 3.34575
Value Function Loss: 0.00356

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.07994
Policy Update Magnitude: 0.54778
Value Function Update Magnitude: 0.63046

Collected Steps per Second: 22,904.92014
Overall Steps per Second: 10,633.01911

Timestep Collection Time: 2.18442
Timestep Consumption Time: 2.52111
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.70553

Cumulative Model Updates: 65,874
Cumulative Timesteps: 549,472,142

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.70043
Policy Entropy: 3.31768
Value Function Loss: 0.00372

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.55565
Value Function Update Magnitude: 0.65026

Collected Steps per Second: 22,962.44988
Overall Steps per Second: 10,765.11415

Timestep Collection Time: 2.17799
Timestep Consumption Time: 2.46776
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.64575

Cumulative Model Updates: 65,880
Cumulative Timesteps: 549,522,154

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 549522154...
Checkpoint 549522154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 947.51745
Policy Entropy: 3.33712
Value Function Loss: 0.00363

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10411
Policy Update Magnitude: 0.54718
Value Function Update Magnitude: 0.65498

Collected Steps per Second: 22,698.24091
Overall Steps per Second: 10,774.99786

Timestep Collection Time: 2.20370
Timestep Consumption Time: 2.43853
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.64223

Cumulative Model Updates: 65,886
Cumulative Timesteps: 549,572,174

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 969.43644
Policy Entropy: 3.34011
Value Function Loss: 0.00350

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09450
Policy Update Magnitude: 0.54592
Value Function Update Magnitude: 0.66330

Collected Steps per Second: 22,841.06339
Overall Steps per Second: 10,687.82760

Timestep Collection Time: 2.18913
Timestep Consumption Time: 2.48928
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.67841

Cumulative Model Updates: 65,892
Cumulative Timesteps: 549,622,176

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 549622176...
Checkpoint 549622176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 893.79180
Policy Entropy: 3.36613
Value Function Loss: 0.00332

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07236
Policy Update Magnitude: 0.53564
Value Function Update Magnitude: 0.64568

Collected Steps per Second: 22,947.86529
Overall Steps per Second: 10,788.47927

Timestep Collection Time: 2.17981
Timestep Consumption Time: 2.45680
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.63661

Cumulative Model Updates: 65,898
Cumulative Timesteps: 549,672,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.69581
Policy Entropy: 3.36681
Value Function Loss: 0.00325

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07015
Policy Update Magnitude: 0.53152
Value Function Update Magnitude: 0.64097

Collected Steps per Second: 22,887.97746
Overall Steps per Second: 10,700.36330

Timestep Collection Time: 2.18508
Timestep Consumption Time: 2.48878
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.67386

Cumulative Model Updates: 65,904
Cumulative Timesteps: 549,722,210

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 549722210...
Checkpoint 549722210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 822.06961
Policy Entropy: 3.37168
Value Function Loss: 0.00327

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.06699
Policy Update Magnitude: 0.52873
Value Function Update Magnitude: 0.63445

Collected Steps per Second: 21,600.63215
Overall Steps per Second: 10,501.92256

Timestep Collection Time: 2.31540
Timestep Consumption Time: 2.44697
PPO Batch Consumption Time: 0.29680
Total Iteration Time: 4.76237

Cumulative Model Updates: 65,910
Cumulative Timesteps: 549,772,224

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 990.94316
Policy Entropy: 3.37370
Value Function Loss: 0.00338

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07362
Policy Update Magnitude: 0.52725
Value Function Update Magnitude: 0.64925

Collected Steps per Second: 22,072.43768
Overall Steps per Second: 10,767.14718

Timestep Collection Time: 2.26527
Timestep Consumption Time: 2.37849
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.64376

Cumulative Model Updates: 65,916
Cumulative Timesteps: 549,822,224

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 549822224...
Checkpoint 549822224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,401.56480
Policy Entropy: 3.37288
Value Function Loss: 0.00332

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06457
Policy Update Magnitude: 0.52946
Value Function Update Magnitude: 0.66123

Collected Steps per Second: 22,392.35950
Overall Steps per Second: 10,688.46823

Timestep Collection Time: 2.23353
Timestep Consumption Time: 2.44572
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.67925

Cumulative Model Updates: 65,922
Cumulative Timesteps: 549,872,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672.63788
Policy Entropy: 3.38555
Value Function Loss: 0.00329

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07101
Policy Update Magnitude: 0.52492
Value Function Update Magnitude: 0.65101

Collected Steps per Second: 22,835.43797
Overall Steps per Second: 10,533.07714

Timestep Collection Time: 2.18958
Timestep Consumption Time: 2.55737
PPO Batch Consumption Time: 0.29717
Total Iteration Time: 4.74695

Cumulative Model Updates: 65,928
Cumulative Timesteps: 549,922,238

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 549922238...
Checkpoint 549922238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.99285
Policy Entropy: 3.37228
Value Function Loss: 0.00332

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08270
Policy Update Magnitude: 0.51778
Value Function Update Magnitude: 0.64295

Collected Steps per Second: 22,378.71544
Overall Steps per Second: 10,593.22842

Timestep Collection Time: 2.23507
Timestep Consumption Time: 2.48663
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.72170

Cumulative Model Updates: 65,934
Cumulative Timesteps: 549,972,256

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 845.11642
Policy Entropy: 3.37129
Value Function Loss: 0.00343

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08482
Policy Update Magnitude: 0.52061
Value Function Update Magnitude: 0.64222

Collected Steps per Second: 23,053.09648
Overall Steps per Second: 10,803.88921

Timestep Collection Time: 2.16917
Timestep Consumption Time: 2.45935
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.62852

Cumulative Model Updates: 65,940
Cumulative Timesteps: 550,022,262

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 550022262...
Checkpoint 550022262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 848.33192
Policy Entropy: 3.35716
Value Function Loss: 0.00342

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08556
Policy Update Magnitude: 0.52571
Value Function Update Magnitude: 0.61129

Collected Steps per Second: 21,977.00790
Overall Steps per Second: 10,766.05177

Timestep Collection Time: 2.27565
Timestep Consumption Time: 2.36969
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.64534

Cumulative Model Updates: 65,946
Cumulative Timesteps: 550,072,274

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.71843
Policy Entropy: 3.35532
Value Function Loss: 0.00341

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08015
Policy Update Magnitude: 0.52937
Value Function Update Magnitude: 0.60412

Collected Steps per Second: 21,840.77988
Overall Steps per Second: 10,581.06038

Timestep Collection Time: 2.28975
Timestep Consumption Time: 2.43662
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.72637

Cumulative Model Updates: 65,952
Cumulative Timesteps: 550,122,284

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 550122284...
Checkpoint 550122284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.08794
Policy Entropy: 3.33720
Value Function Loss: 0.00351

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08627
Policy Update Magnitude: 0.53441
Value Function Update Magnitude: 0.61622

Collected Steps per Second: 22,213.95337
Overall Steps per Second: 10,675.55925

Timestep Collection Time: 2.25129
Timestep Consumption Time: 2.43324
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.68453

Cumulative Model Updates: 65,958
Cumulative Timesteps: 550,172,294

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,908.66761
Policy Entropy: 3.34369
Value Function Loss: 0.00347

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.07904
Policy Update Magnitude: 0.53998
Value Function Update Magnitude: 0.64866

Collected Steps per Second: 22,262.80947
Overall Steps per Second: 10,740.24635

Timestep Collection Time: 2.24707
Timestep Consumption Time: 2.41074
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.65781

Cumulative Model Updates: 65,964
Cumulative Timesteps: 550,222,320

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 550222320...
Checkpoint 550222320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 952.24603
Policy Entropy: 3.34741
Value Function Loss: 0.00346

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08490
Policy Update Magnitude: 0.54418
Value Function Update Magnitude: 0.65593

Collected Steps per Second: 22,623.57773
Overall Steps per Second: 10,626.07061

Timestep Collection Time: 2.21053
Timestep Consumption Time: 2.49582
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.70635

Cumulative Model Updates: 65,970
Cumulative Timesteps: 550,272,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 848.06148
Policy Entropy: 3.36755
Value Function Loss: 0.00341

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07730
Policy Update Magnitude: 0.54074
Value Function Update Magnitude: 0.65807

Collected Steps per Second: 22,155.93749
Overall Steps per Second: 10,429.68509

Timestep Collection Time: 2.25763
Timestep Consumption Time: 2.53829
PPO Batch Consumption Time: 0.29578
Total Iteration Time: 4.79593

Cumulative Model Updates: 65,976
Cumulative Timesteps: 550,322,350

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 550322350...
Checkpoint 550322350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.33573
Policy Entropy: 3.35809
Value Function Loss: 0.00354

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08703
Policy Update Magnitude: 0.54550
Value Function Update Magnitude: 0.67263

Collected Steps per Second: 22,271.77938
Overall Steps per Second: 10,639.38696

Timestep Collection Time: 2.24589
Timestep Consumption Time: 2.45551
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.70140

Cumulative Model Updates: 65,982
Cumulative Timesteps: 550,372,370

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 991.53285
Policy Entropy: 3.34487
Value Function Loss: 0.00361

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09716
Policy Update Magnitude: 0.55316
Value Function Update Magnitude: 0.69948

Collected Steps per Second: 22,889.79707
Overall Steps per Second: 10,609.13659

Timestep Collection Time: 2.18560
Timestep Consumption Time: 2.52996
PPO Batch Consumption Time: 0.29660
Total Iteration Time: 4.71556

Cumulative Model Updates: 65,988
Cumulative Timesteps: 550,422,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 550422398...
Checkpoint 550422398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 930.11250
Policy Entropy: 3.35266
Value Function Loss: 0.00354

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09081
Policy Update Magnitude: 0.55811
Value Function Update Magnitude: 0.69297

Collected Steps per Second: 22,882.98640
Overall Steps per Second: 10,602.52206

Timestep Collection Time: 2.18608
Timestep Consumption Time: 2.53204
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.71812

Cumulative Model Updates: 65,994
Cumulative Timesteps: 550,472,422

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 831.48259
Policy Entropy: 3.35970
Value Function Loss: 0.00349

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10424
Policy Update Magnitude: 0.54979
Value Function Update Magnitude: 0.68185

Collected Steps per Second: 23,074.24441
Overall Steps per Second: 10,776.64418

Timestep Collection Time: 2.16726
Timestep Consumption Time: 2.47314
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.64041

Cumulative Model Updates: 66,000
Cumulative Timesteps: 550,522,430

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 550522430...
Checkpoint 550522430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.65527
Policy Entropy: 3.36883
Value Function Loss: 0.00337

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09650
Policy Update Magnitude: 0.53954
Value Function Update Magnitude: 0.68535

Collected Steps per Second: 22,834.17690
Overall Steps per Second: 10,687.65429

Timestep Collection Time: 2.18988
Timestep Consumption Time: 2.48879
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.67867

Cumulative Model Updates: 66,006
Cumulative Timesteps: 550,572,434

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,339.17956
Policy Entropy: 3.36635
Value Function Loss: 0.00345

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10098
Policy Update Magnitude: 0.54200
Value Function Update Magnitude: 0.71381

Collected Steps per Second: 22,666.09051
Overall Steps per Second: 10,658.42154

Timestep Collection Time: 2.20682
Timestep Consumption Time: 2.48618
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.69300

Cumulative Model Updates: 66,012
Cumulative Timesteps: 550,622,454

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 550622454...
Checkpoint 550622454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.44708
Policy Entropy: 3.37592
Value Function Loss: 0.00344

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.11712
Policy Update Magnitude: 0.53485
Value Function Update Magnitude: 0.69602

Collected Steps per Second: 23,138.60950
Overall Steps per Second: 10,856.38534

Timestep Collection Time: 2.16201
Timestep Consumption Time: 2.44597
PPO Batch Consumption Time: 0.28286
Total Iteration Time: 4.60798

Cumulative Model Updates: 66,018
Cumulative Timesteps: 550,672,480

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 999.69452
Policy Entropy: 3.37100
Value Function Loss: 0.00366

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10879
Policy Update Magnitude: 0.53859
Value Function Update Magnitude: 0.68814

Collected Steps per Second: 22,800.39024
Overall Steps per Second: 10,665.21064

Timestep Collection Time: 2.19382
Timestep Consumption Time: 2.49619
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.69002

Cumulative Model Updates: 66,024
Cumulative Timesteps: 550,722,500

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 550722500...
Checkpoint 550722500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.63604
Policy Entropy: 3.35753
Value Function Loss: 0.00359

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11288
Policy Update Magnitude: 0.55062
Value Function Update Magnitude: 0.68903

Collected Steps per Second: 22,756.20942
Overall Steps per Second: 10,636.30134

Timestep Collection Time: 2.19861
Timestep Consumption Time: 2.50528
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.70389

Cumulative Model Updates: 66,030
Cumulative Timesteps: 550,772,532

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 900.29827
Policy Entropy: 3.35873
Value Function Loss: 0.00361

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09440
Policy Update Magnitude: 0.55081
Value Function Update Magnitude: 0.67948

Collected Steps per Second: 22,157.45145
Overall Steps per Second: 10,525.32830

Timestep Collection Time: 2.25685
Timestep Consumption Time: 2.49417
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.75102

Cumulative Model Updates: 66,036
Cumulative Timesteps: 550,822,538

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 550822538...
Checkpoint 550822538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.74192
Policy Entropy: 3.35373
Value Function Loss: 0.00364

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08041
Policy Update Magnitude: 0.55522
Value Function Update Magnitude: 0.67615

Collected Steps per Second: 22,489.20235
Overall Steps per Second: 10,580.87148

Timestep Collection Time: 2.22338
Timestep Consumption Time: 2.50232
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.72570

Cumulative Model Updates: 66,042
Cumulative Timesteps: 550,872,540

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,838.63750
Policy Entropy: 3.36206
Value Function Loss: 0.00363

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08409
Policy Update Magnitude: 0.56496
Value Function Update Magnitude: 0.68742

Collected Steps per Second: 22,476.39653
Overall Steps per Second: 10,680.26680

Timestep Collection Time: 2.22545
Timestep Consumption Time: 2.45796
PPO Batch Consumption Time: 0.28383
Total Iteration Time: 4.68340

Cumulative Model Updates: 66,048
Cumulative Timesteps: 550,922,560

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 550922560...
Checkpoint 550922560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.07321
Policy Entropy: 3.36613
Value Function Loss: 0.00365

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.55865
Value Function Update Magnitude: 0.68253

Collected Steps per Second: 22,133.39975
Overall Steps per Second: 10,620.59213

Timestep Collection Time: 2.26011
Timestep Consumption Time: 2.44998
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.71010

Cumulative Model Updates: 66,054
Cumulative Timesteps: 550,972,584

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.83145
Policy Entropy: 3.36724
Value Function Loss: 0.00351

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08927
Policy Update Magnitude: 0.55243
Value Function Update Magnitude: 0.69435

Collected Steps per Second: 22,580.97807
Overall Steps per Second: 10,545.80030

Timestep Collection Time: 2.21505
Timestep Consumption Time: 2.52788
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.74293

Cumulative Model Updates: 66,060
Cumulative Timesteps: 551,022,602

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 551022602...
Checkpoint 551022602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.12108
Policy Entropy: 3.37253
Value Function Loss: 0.00339

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07402
Policy Update Magnitude: 0.54900
Value Function Update Magnitude: 0.66656

Collected Steps per Second: 22,137.56816
Overall Steps per Second: 10,679.41840

Timestep Collection Time: 2.25860
Timestep Consumption Time: 2.42330
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.68190

Cumulative Model Updates: 66,066
Cumulative Timesteps: 551,072,602

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.33272
Policy Entropy: 3.37621
Value Function Loss: 0.00343

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07327
Policy Update Magnitude: 0.53780
Value Function Update Magnitude: 0.65296

Collected Steps per Second: 22,055.47545
Overall Steps per Second: 10,715.51688

Timestep Collection Time: 2.26864
Timestep Consumption Time: 2.40085
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.66949

Cumulative Model Updates: 66,072
Cumulative Timesteps: 551,122,638

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 551122638...
Checkpoint 551122638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 894.18254
Policy Entropy: 3.38148
Value Function Loss: 0.00349

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07207
Policy Update Magnitude: 0.53924
Value Function Update Magnitude: 0.64451

Collected Steps per Second: 22,936.15321
Overall Steps per Second: 10,812.72734

Timestep Collection Time: 2.18057
Timestep Consumption Time: 2.44490
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.62547

Cumulative Model Updates: 66,078
Cumulative Timesteps: 551,172,652

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.38091
Policy Entropy: 3.38238
Value Function Loss: 0.00337

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07194
Policy Update Magnitude: 0.55064
Value Function Update Magnitude: 0.64509

Collected Steps per Second: 22,984.94625
Overall Steps per Second: 10,772.18101

Timestep Collection Time: 2.17647
Timestep Consumption Time: 2.46753
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.64400

Cumulative Model Updates: 66,084
Cumulative Timesteps: 551,222,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 551222678...
Checkpoint 551222678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 920.41422
Policy Entropy: 3.37433
Value Function Loss: 0.00337

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07616
Policy Update Magnitude: 0.54440
Value Function Update Magnitude: 0.64242

Collected Steps per Second: 22,418.57406
Overall Steps per Second: 10,639.42588

Timestep Collection Time: 2.23029
Timestep Consumption Time: 2.46921
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.69950

Cumulative Model Updates: 66,090
Cumulative Timesteps: 551,272,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.63271
Policy Entropy: 3.35400
Value Function Loss: 0.00332

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07447
Policy Update Magnitude: 0.53818
Value Function Update Magnitude: 0.64416

Collected Steps per Second: 22,292.75335
Overall Steps per Second: 10,587.91726

Timestep Collection Time: 2.24396
Timestep Consumption Time: 2.48067
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.72463

Cumulative Model Updates: 66,096
Cumulative Timesteps: 551,322,702

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 551322702...
Checkpoint 551322702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.58101
Policy Entropy: 3.35533
Value Function Loss: 0.00336

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08069
Policy Update Magnitude: 0.53545
Value Function Update Magnitude: 0.63784

Collected Steps per Second: 22,414.23600
Overall Steps per Second: 10,610.39194

Timestep Collection Time: 2.23180
Timestep Consumption Time: 2.48283
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.71462

Cumulative Model Updates: 66,102
Cumulative Timesteps: 551,372,726

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.93277
Policy Entropy: 3.34277
Value Function Loss: 0.00349

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.07746
Policy Update Magnitude: 0.54032
Value Function Update Magnitude: 0.63672

Collected Steps per Second: 21,990.89225
Overall Steps per Second: 10,603.95757

Timestep Collection Time: 2.27494
Timestep Consumption Time: 2.44292
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.71786

Cumulative Model Updates: 66,108
Cumulative Timesteps: 551,422,754

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 551422754...
Checkpoint 551422754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384.80739
Policy Entropy: 3.35376
Value Function Loss: 0.00342

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07482
Policy Update Magnitude: 0.54667
Value Function Update Magnitude: 0.62812

Collected Steps per Second: 21,708.13036
Overall Steps per Second: 10,500.17422

Timestep Collection Time: 2.30448
Timestep Consumption Time: 2.45982
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.76430

Cumulative Model Updates: 66,114
Cumulative Timesteps: 551,472,780

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.48101
Policy Entropy: 3.35542
Value Function Loss: 0.00342

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09411
Policy Update Magnitude: 0.54807
Value Function Update Magnitude: 0.61155

Collected Steps per Second: 22,114.36734
Overall Steps per Second: 10,625.30511

Timestep Collection Time: 2.26152
Timestep Consumption Time: 2.44536
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.70688

Cumulative Model Updates: 66,120
Cumulative Timesteps: 551,522,792

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 551522792...
Checkpoint 551522792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 994.21733
Policy Entropy: 3.35723
Value Function Loss: 0.00341

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08223
Policy Update Magnitude: 0.54434
Value Function Update Magnitude: 0.61760

Collected Steps per Second: 23,086.02523
Overall Steps per Second: 10,833.37825

Timestep Collection Time: 2.16711
Timestep Consumption Time: 2.45102
PPO Batch Consumption Time: 0.28231
Total Iteration Time: 4.61813

Cumulative Model Updates: 66,126
Cumulative Timesteps: 551,572,822

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 921.74138
Policy Entropy: 3.33579
Value Function Loss: 0.00346

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08121
Policy Update Magnitude: 0.54894
Value Function Update Magnitude: 0.62797

Collected Steps per Second: 22,938.71964
Overall Steps per Second: 10,579.06043

Timestep Collection Time: 2.17981
Timestep Consumption Time: 2.54670
PPO Batch Consumption Time: 0.29737
Total Iteration Time: 4.72651

Cumulative Model Updates: 66,132
Cumulative Timesteps: 551,622,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 551622824...
Checkpoint 551622824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.21442
Policy Entropy: 3.33525
Value Function Loss: 0.00355

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08004
Policy Update Magnitude: 0.55425
Value Function Update Magnitude: 0.64358

Collected Steps per Second: 21,874.62454
Overall Steps per Second: 10,633.26839

Timestep Collection Time: 2.28722
Timestep Consumption Time: 2.41802
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.70523

Cumulative Model Updates: 66,138
Cumulative Timesteps: 551,672,856

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,015.11737
Policy Entropy: 3.31883
Value Function Loss: 0.00360

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09459
Policy Update Magnitude: 0.55301
Value Function Update Magnitude: 0.66493

Collected Steps per Second: 21,808.17913
Overall Steps per Second: 10,574.90844

Timestep Collection Time: 2.29400
Timestep Consumption Time: 2.43682
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.73082

Cumulative Model Updates: 66,144
Cumulative Timesteps: 551,722,884

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 551722884...
Checkpoint 551722884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.92988
Policy Entropy: 3.34748
Value Function Loss: 0.00361

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09220
Policy Update Magnitude: 0.55457
Value Function Update Magnitude: 0.66574

Collected Steps per Second: 22,316.22080
Overall Steps per Second: 10,699.69562

Timestep Collection Time: 2.24124
Timestep Consumption Time: 2.43329
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.67453

Cumulative Model Updates: 66,150
Cumulative Timesteps: 551,772,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.74813
Policy Entropy: 3.35189
Value Function Loss: 0.00375

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10854
Policy Update Magnitude: 0.55433
Value Function Update Magnitude: 0.65649

Collected Steps per Second: 21,318.31614
Overall Steps per Second: 10,446.78671

Timestep Collection Time: 2.34540
Timestep Consumption Time: 2.44076
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.78616

Cumulative Model Updates: 66,156
Cumulative Timesteps: 551,822,900

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 551822900...
Checkpoint 551822900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.81945
Policy Entropy: 3.36660
Value Function Loss: 0.00378

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.10881
Policy Update Magnitude: 0.55343
Value Function Update Magnitude: 0.65848

Collected Steps per Second: 21,887.38702
Overall Steps per Second: 10,628.76114

Timestep Collection Time: 2.28561
Timestep Consumption Time: 2.42105
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.70666

Cumulative Model Updates: 66,162
Cumulative Timesteps: 551,872,926

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 887.71906
Policy Entropy: 3.35065
Value Function Loss: 0.00375

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09945
Policy Update Magnitude: 0.55174
Value Function Update Magnitude: 0.67835

Collected Steps per Second: 21,132.17838
Overall Steps per Second: 10,396.53077

Timestep Collection Time: 2.36738
Timestep Consumption Time: 2.44460
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.81199

Cumulative Model Updates: 66,168
Cumulative Timesteps: 551,922,954

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 551922954...
Checkpoint 551922954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 895.34767
Policy Entropy: 3.36990
Value Function Loss: 0.00374

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09206
Policy Update Magnitude: 0.55823
Value Function Update Magnitude: 0.70456

Collected Steps per Second: 21,858.41255
Overall Steps per Second: 10,547.14373

Timestep Collection Time: 2.28836
Timestep Consumption Time: 2.45415
PPO Batch Consumption Time: 0.29735
Total Iteration Time: 4.74252

Cumulative Model Updates: 66,174
Cumulative Timesteps: 551,972,974

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,428.87271
Policy Entropy: 3.36518
Value Function Loss: 0.00351

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08429
Policy Update Magnitude: 0.55863
Value Function Update Magnitude: 0.70072

Collected Steps per Second: 21,769.85035
Overall Steps per Second: 10,571.26295

Timestep Collection Time: 2.29712
Timestep Consumption Time: 2.43344
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.73056

Cumulative Model Updates: 66,180
Cumulative Timesteps: 552,022,982

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 552022982...
Checkpoint 552022982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.55984
Policy Entropy: 3.37362
Value Function Loss: 0.00347

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08775
Policy Update Magnitude: 0.55445
Value Function Update Magnitude: 0.67450

Collected Steps per Second: 22,276.32791
Overall Steps per Second: 10,607.51149

Timestep Collection Time: 2.24552
Timestep Consumption Time: 2.47019
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.71571

Cumulative Model Updates: 66,186
Cumulative Timesteps: 552,073,004

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.52783
Policy Entropy: 3.36343
Value Function Loss: 0.00336

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07065
Policy Update Magnitude: 0.55047
Value Function Update Magnitude: 0.64625

Collected Steps per Second: 22,091.97690
Overall Steps per Second: 10,715.93658

Timestep Collection Time: 2.26390
Timestep Consumption Time: 2.40336
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.66725

Cumulative Model Updates: 66,192
Cumulative Timesteps: 552,123,018

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 552123018...
Checkpoint 552123018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.95335
Policy Entropy: 3.36243
Value Function Loss: 0.00338

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.06849
Policy Update Magnitude: 0.54478
Value Function Update Magnitude: 0.63259

Collected Steps per Second: 22,244.97553
Overall Steps per Second: 10,719.81394

Timestep Collection Time: 2.24788
Timestep Consumption Time: 2.41675
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.66463

Cumulative Model Updates: 66,198
Cumulative Timesteps: 552,173,022

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391.20455
Policy Entropy: 3.36711
Value Function Loss: 0.00341

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.06991
Policy Update Magnitude: 0.53874
Value Function Update Magnitude: 0.62138

Collected Steps per Second: 22,237.63575
Overall Steps per Second: 10,801.67658

Timestep Collection Time: 2.24853
Timestep Consumption Time: 2.38057
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.62910

Cumulative Model Updates: 66,204
Cumulative Timesteps: 552,223,024

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 552223024...
Checkpoint 552223024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.99354
Policy Entropy: 3.36217
Value Function Loss: 0.00344

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.06710
Policy Update Magnitude: 0.54196
Value Function Update Magnitude: 0.62086

Collected Steps per Second: 22,049.56771
Overall Steps per Second: 10,692.88140

Timestep Collection Time: 2.26853
Timestep Consumption Time: 2.40935
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.67788

Cumulative Model Updates: 66,210
Cumulative Timesteps: 552,273,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 804.07574
Policy Entropy: 3.35764
Value Function Loss: 0.00350

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.07790
Policy Update Magnitude: 0.54609
Value Function Update Magnitude: 0.62824

Collected Steps per Second: 21,868.78215
Overall Steps per Second: 10,540.10382

Timestep Collection Time: 2.28691
Timestep Consumption Time: 2.45801
PPO Batch Consumption Time: 0.29710
Total Iteration Time: 4.74492

Cumulative Model Updates: 66,216
Cumulative Timesteps: 552,323,056

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 552323056...
Checkpoint 552323056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.87168
Policy Entropy: 3.35959
Value Function Loss: 0.00358

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08084
Policy Update Magnitude: 0.54191
Value Function Update Magnitude: 0.62528

Collected Steps per Second: 22,131.98602
Overall Steps per Second: 10,617.31454

Timestep Collection Time: 2.25935
Timestep Consumption Time: 2.45031
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.70967

Cumulative Model Updates: 66,222
Cumulative Timesteps: 552,373,060

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.51738
Policy Entropy: 3.36968
Value Function Loss: 0.00358

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07475
Policy Update Magnitude: 0.54528
Value Function Update Magnitude: 0.65254

Collected Steps per Second: 21,737.34084
Overall Steps per Second: 10,531.17448

Timestep Collection Time: 2.30074
Timestep Consumption Time: 2.44821
PPO Batch Consumption Time: 0.29492
Total Iteration Time: 4.74895

Cumulative Model Updates: 66,228
Cumulative Timesteps: 552,423,072

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 552423072...
Checkpoint 552423072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 663.78385
Policy Entropy: 3.37106
Value Function Loss: 0.00356

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08417
Policy Update Magnitude: 0.55110
Value Function Update Magnitude: 0.66142

Collected Steps per Second: 22,610.63050
Overall Steps per Second: 10,583.68523

Timestep Collection Time: 2.21215
Timestep Consumption Time: 2.51381
PPO Batch Consumption Time: 0.29713
Total Iteration Time: 4.72595

Cumulative Model Updates: 66,234
Cumulative Timesteps: 552,473,090

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 779.01041
Policy Entropy: 3.36566
Value Function Loss: 0.00349

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07950
Policy Update Magnitude: 0.55449
Value Function Update Magnitude: 0.65567

Collected Steps per Second: 22,333.34553
Overall Steps per Second: 10,546.12106

Timestep Collection Time: 2.23889
Timestep Consumption Time: 2.50238
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.74127

Cumulative Model Updates: 66,240
Cumulative Timesteps: 552,523,092

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 552523092...
Checkpoint 552523092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.34371
Policy Entropy: 3.35137
Value Function Loss: 0.00342

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07729
Policy Update Magnitude: 0.54725
Value Function Update Magnitude: 0.63302

Collected Steps per Second: 22,227.29161
Overall Steps per Second: 10,464.48007

Timestep Collection Time: 2.24967
Timestep Consumption Time: 2.52878
PPO Batch Consumption Time: 0.29714
Total Iteration Time: 4.77845

Cumulative Model Updates: 66,246
Cumulative Timesteps: 552,573,096

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 826.54438
Policy Entropy: 3.35509
Value Function Loss: 0.00341

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08369
Policy Update Magnitude: 0.54075
Value Function Update Magnitude: 0.61165

Collected Steps per Second: 22,609.74508
Overall Steps per Second: 10,589.74011

Timestep Collection Time: 2.21188
Timestep Consumption Time: 2.51062
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.72250

Cumulative Model Updates: 66,252
Cumulative Timesteps: 552,623,106

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 552623106...
Checkpoint 552623106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.53697
Policy Entropy: 3.35577
Value Function Loss: 0.00361

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09342
Policy Update Magnitude: 0.54047
Value Function Update Magnitude: 0.61131

Collected Steps per Second: 22,820.58613
Overall Steps per Second: 10,542.69619

Timestep Collection Time: 2.19232
Timestep Consumption Time: 2.55315
PPO Batch Consumption Time: 0.29644
Total Iteration Time: 4.74547

Cumulative Model Updates: 66,258
Cumulative Timesteps: 552,673,136

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 879.25079
Policy Entropy: 3.35539
Value Function Loss: 0.00352

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09828
Policy Update Magnitude: 0.54011
Value Function Update Magnitude: 0.62358

Collected Steps per Second: 22,828.57428
Overall Steps per Second: 10,765.19147

Timestep Collection Time: 2.19094
Timestep Consumption Time: 2.45515
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.64609

Cumulative Model Updates: 66,264
Cumulative Timesteps: 552,723,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 552723152...
Checkpoint 552723152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565.64589
Policy Entropy: 3.34644
Value Function Loss: 0.00387

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.10720
Policy Update Magnitude: 0.54926
Value Function Update Magnitude: 0.63052

Collected Steps per Second: 22,596.75226
Overall Steps per Second: 10,768.86440

Timestep Collection Time: 2.21315
Timestep Consumption Time: 2.43079
PPO Batch Consumption Time: 0.28171
Total Iteration Time: 4.64394

Cumulative Model Updates: 66,270
Cumulative Timesteps: 552,773,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 958.10391
Policy Entropy: 3.34659
Value Function Loss: 0.00374

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11299
Policy Update Magnitude: 0.54787
Value Function Update Magnitude: 0.64684

Collected Steps per Second: 22,910.24843
Overall Steps per Second: 10,798.99148

Timestep Collection Time: 2.18278
Timestep Consumption Time: 2.44802
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.63080

Cumulative Model Updates: 66,276
Cumulative Timesteps: 552,823,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 552823170...
Checkpoint 552823170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.10183
Policy Entropy: 3.35117
Value Function Loss: 0.00377

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11263
Policy Update Magnitude: 0.54534
Value Function Update Magnitude: 0.64873

Collected Steps per Second: 22,804.46899
Overall Steps per Second: 10,748.97126

Timestep Collection Time: 2.19264
Timestep Consumption Time: 2.45915
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.65179

Cumulative Model Updates: 66,282
Cumulative Timesteps: 552,873,172

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.86411
Policy Entropy: 3.36340
Value Function Loss: 0.00382

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10208
Policy Update Magnitude: 0.55512
Value Function Update Magnitude: 0.66448

Collected Steps per Second: 22,708.21496
Overall Steps per Second: 10,641.15818

Timestep Collection Time: 2.20299
Timestep Consumption Time: 2.49819
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.70118

Cumulative Model Updates: 66,288
Cumulative Timesteps: 552,923,198

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 552923198...
Checkpoint 552923198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,262.04353
Policy Entropy: 3.36905
Value Function Loss: 0.00386

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.55802
Value Function Update Magnitude: 0.68897

Collected Steps per Second: 23,002.02553
Overall Steps per Second: 10,823.51897

Timestep Collection Time: 2.17459
Timestep Consumption Time: 2.44683
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.62142

Cumulative Model Updates: 66,294
Cumulative Timesteps: 552,973,218

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.03830
Policy Entropy: 3.37272
Value Function Loss: 0.00384

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10973
Policy Update Magnitude: 0.56103
Value Function Update Magnitude: 0.69059

Collected Steps per Second: 22,367.90130
Overall Steps per Second: 10,553.45045

Timestep Collection Time: 2.23561
Timestep Consumption Time: 2.50274
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.73836

Cumulative Model Updates: 66,300
Cumulative Timesteps: 553,023,224

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 553023224...
Checkpoint 553023224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 765.50317
Policy Entropy: 3.38071
Value Function Loss: 0.00367

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.10772
Policy Update Magnitude: 0.55931
Value Function Update Magnitude: 0.67990

Collected Steps per Second: 22,609.86657
Overall Steps per Second: 10,636.66410

Timestep Collection Time: 2.21231
Timestep Consumption Time: 2.49029
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.70260

Cumulative Model Updates: 66,306
Cumulative Timesteps: 553,073,244

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,396.68651
Policy Entropy: 3.37422
Value Function Loss: 0.00369

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.55845
Value Function Update Magnitude: 0.65632

Collected Steps per Second: 22,311.92713
Overall Steps per Second: 10,508.30567

Timestep Collection Time: 2.24167
Timestep Consumption Time: 2.51799
PPO Batch Consumption Time: 0.29578
Total Iteration Time: 4.75966

Cumulative Model Updates: 66,312
Cumulative Timesteps: 553,123,260

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 553123260...
Checkpoint 553123260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 897.57421
Policy Entropy: 3.35170
Value Function Loss: 0.00374

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.55378
Value Function Update Magnitude: 0.65071

Collected Steps per Second: 22,147.18863
Overall Steps per Second: 10,555.60224

Timestep Collection Time: 2.25780
Timestep Consumption Time: 2.47940
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.73720

Cumulative Model Updates: 66,318
Cumulative Timesteps: 553,173,264

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.65778
Policy Entropy: 3.35301
Value Function Loss: 0.00360

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08872
Policy Update Magnitude: 0.54737
Value Function Update Magnitude: 0.64135

Collected Steps per Second: 22,700.45568
Overall Steps per Second: 10,579.36590

Timestep Collection Time: 2.20357
Timestep Consumption Time: 2.52469
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 4.72826

Cumulative Model Updates: 66,324
Cumulative Timesteps: 553,223,286

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 553223286...
Checkpoint 553223286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.30271
Policy Entropy: 3.35697
Value Function Loss: 0.00349

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08395
Policy Update Magnitude: 0.54607
Value Function Update Magnitude: 0.64629

Collected Steps per Second: 22,836.91666
Overall Steps per Second: 10,526.08896

Timestep Collection Time: 2.19031
Timestep Consumption Time: 2.56169
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.75200

Cumulative Model Updates: 66,330
Cumulative Timesteps: 553,273,306

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,796.67890
Policy Entropy: 3.37327
Value Function Loss: 0.00354

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08003
Policy Update Magnitude: 0.54350
Value Function Update Magnitude: 0.64101

Collected Steps per Second: 22,759.79408
Overall Steps per Second: 10,641.16067

Timestep Collection Time: 2.19765
Timestep Consumption Time: 2.50278
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.70043

Cumulative Model Updates: 66,336
Cumulative Timesteps: 553,323,324

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 553323324...
Checkpoint 553323324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,805.32298
Policy Entropy: 3.38624
Value Function Loss: 0.00325

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08256
Policy Update Magnitude: 0.54074
Value Function Update Magnitude: 0.62658

Collected Steps per Second: 22,968.51365
Overall Steps per Second: 10,823.59239

Timestep Collection Time: 2.17707
Timestep Consumption Time: 2.44284
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.61991

Cumulative Model Updates: 66,342
Cumulative Timesteps: 553,373,328

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 815.00225
Policy Entropy: 3.38550
Value Function Loss: 0.00338

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08512
Policy Update Magnitude: 0.53320
Value Function Update Magnitude: 0.61787

Collected Steps per Second: 22,818.89911
Overall Steps per Second: 10,608.93569

Timestep Collection Time: 2.19196
Timestep Consumption Time: 2.52275
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.71470

Cumulative Model Updates: 66,348
Cumulative Timesteps: 553,423,346

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 553423346...
Checkpoint 553423346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.89834
Policy Entropy: 3.39301
Value Function Loss: 0.00334

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08546
Policy Update Magnitude: 0.52789
Value Function Update Magnitude: 0.62149

Collected Steps per Second: 22,959.44944
Overall Steps per Second: 10,694.01041

Timestep Collection Time: 2.17889
Timestep Consumption Time: 2.49906
PPO Batch Consumption Time: 0.29642
Total Iteration Time: 4.67795

Cumulative Model Updates: 66,354
Cumulative Timesteps: 553,473,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.88273
Policy Entropy: 3.37983
Value Function Loss: 0.00350

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10017
Policy Update Magnitude: 0.52643
Value Function Update Magnitude: 0.64524

Collected Steps per Second: 22,150.06151
Overall Steps per Second: 10,764.44472

Timestep Collection Time: 2.25832
Timestep Consumption Time: 2.38864
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.64697

Cumulative Model Updates: 66,360
Cumulative Timesteps: 553,523,394

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 553523394...
Checkpoint 553523394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 889.05063
Policy Entropy: 3.37855
Value Function Loss: 0.00348

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09289
Policy Update Magnitude: 0.52827
Value Function Update Magnitude: 0.65543

Collected Steps per Second: 22,856.01792
Overall Steps per Second: 10,648.49065

Timestep Collection Time: 2.18831
Timestep Consumption Time: 2.50870
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.69700

Cumulative Model Updates: 66,366
Cumulative Timesteps: 553,573,410

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 902.65456
Policy Entropy: 3.36946
Value Function Loss: 0.00367

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09226
Policy Update Magnitude: 0.52874
Value Function Update Magnitude: 0.64937

Collected Steps per Second: 22,474.76510
Overall Steps per Second: 10,549.88863

Timestep Collection Time: 2.22516
Timestep Consumption Time: 2.51517
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.74033

Cumulative Model Updates: 66,372
Cumulative Timesteps: 553,623,420

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 553623420...
Checkpoint 553623420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 854.19427
Policy Entropy: 3.35954
Value Function Loss: 0.00377

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08232
Policy Update Magnitude: 0.53749
Value Function Update Magnitude: 0.65680

Collected Steps per Second: 22,510.64306
Overall Steps per Second: 10,585.34758

Timestep Collection Time: 2.22126
Timestep Consumption Time: 2.50244
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.72370

Cumulative Model Updates: 66,378
Cumulative Timesteps: 553,673,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,528.62272
Policy Entropy: 3.36361
Value Function Loss: 0.00359

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.07971
Policy Update Magnitude: 0.54138
Value Function Update Magnitude: 0.65971

Collected Steps per Second: 22,294.36684
Overall Steps per Second: 10,496.73142

Timestep Collection Time: 2.24380
Timestep Consumption Time: 2.52188
PPO Batch Consumption Time: 0.29582
Total Iteration Time: 4.76567

Cumulative Model Updates: 66,384
Cumulative Timesteps: 553,723,446

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 553723446...
Checkpoint 553723446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.50272
Policy Entropy: 3.37215
Value Function Loss: 0.00345

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.53619
Value Function Update Magnitude: 0.66381

Collected Steps per Second: 22,631.37434
Overall Steps per Second: 10,574.23757

Timestep Collection Time: 2.20932
Timestep Consumption Time: 2.51915
PPO Batch Consumption Time: 0.29585
Total Iteration Time: 4.72847

Cumulative Model Updates: 66,390
Cumulative Timesteps: 553,773,446

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.80195
Policy Entropy: 3.36663
Value Function Loss: 0.00343

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10111
Policy Update Magnitude: 0.52907
Value Function Update Magnitude: 0.63057

Collected Steps per Second: 22,772.40415
Overall Steps per Second: 10,550.07764

Timestep Collection Time: 2.19757
Timestep Consumption Time: 2.54590
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.74347

Cumulative Model Updates: 66,396
Cumulative Timesteps: 553,823,490

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 553823490...
Checkpoint 553823490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 916.98570
Policy Entropy: 3.36733
Value Function Loss: 0.00355

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10361
Policy Update Magnitude: 0.53725
Value Function Update Magnitude: 0.63911

Collected Steps per Second: 22,772.34909
Overall Steps per Second: 10,567.53888

Timestep Collection Time: 2.19617
Timestep Consumption Time: 2.53643
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.73261

Cumulative Model Updates: 66,402
Cumulative Timesteps: 553,873,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.85646
Policy Entropy: 3.37649
Value Function Loss: 0.00360

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09740
Policy Update Magnitude: 0.54361
Value Function Update Magnitude: 0.63569

Collected Steps per Second: 23,266.25529
Overall Steps per Second: 10,841.14890

Timestep Collection Time: 2.14955
Timestep Consumption Time: 2.46361
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.61316

Cumulative Model Updates: 66,408
Cumulative Timesteps: 553,923,514

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 553923514...
Checkpoint 553923514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.34049
Policy Entropy: 3.39099
Value Function Loss: 0.00349

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.07662
Policy Update Magnitude: 0.54336
Value Function Update Magnitude: 0.62518

Collected Steps per Second: 22,825.93368
Overall Steps per Second: 10,718.77926

Timestep Collection Time: 2.19049
Timestep Consumption Time: 2.47422
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.66471

Cumulative Model Updates: 66,414
Cumulative Timesteps: 553,973,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 797.85809
Policy Entropy: 3.37907
Value Function Loss: 0.00351

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08243
Policy Update Magnitude: 0.53440
Value Function Update Magnitude: 0.62978

Collected Steps per Second: 22,864.97507
Overall Steps per Second: 10,795.03609

Timestep Collection Time: 2.18789
Timestep Consumption Time: 2.44628
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.63417

Cumulative Model Updates: 66,420
Cumulative Timesteps: 554,023,540

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 554023540...
Checkpoint 554023540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.51357
Policy Entropy: 3.38314
Value Function Loss: 0.00359

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07417
Policy Update Magnitude: 0.53440
Value Function Update Magnitude: 0.62456

Collected Steps per Second: 22,623.85809
Overall Steps per Second: 10,759.30288

Timestep Collection Time: 2.21023
Timestep Consumption Time: 2.43728
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.64751

Cumulative Model Updates: 66,426
Cumulative Timesteps: 554,073,544

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.13246
Policy Entropy: 3.36313
Value Function Loss: 0.00364

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08444
Policy Update Magnitude: 0.53844
Value Function Update Magnitude: 0.63030

Collected Steps per Second: 22,596.67661
Overall Steps per Second: 10,625.57341

Timestep Collection Time: 2.21307
Timestep Consumption Time: 2.49331
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.70638

Cumulative Model Updates: 66,432
Cumulative Timesteps: 554,123,552

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 554123552...
Checkpoint 554123552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.75426
Policy Entropy: 3.36916
Value Function Loss: 0.00356

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08930
Policy Update Magnitude: 0.53914
Value Function Update Magnitude: 0.63777

Collected Steps per Second: 22,616.78766
Overall Steps per Second: 10,616.02230

Timestep Collection Time: 2.21075
Timestep Consumption Time: 2.49911
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.70986

Cumulative Model Updates: 66,438
Cumulative Timesteps: 554,173,552

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.23300
Policy Entropy: 3.34691
Value Function Loss: 0.00354

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.07937
Policy Update Magnitude: 0.54121
Value Function Update Magnitude: 0.64011

Collected Steps per Second: 22,630.68758
Overall Steps per Second: 10,786.63765

Timestep Collection Time: 2.21027
Timestep Consumption Time: 2.42695
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.63722

Cumulative Model Updates: 66,444
Cumulative Timesteps: 554,223,572

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 554223572...
Checkpoint 554223572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078.74129
Policy Entropy: 3.35054
Value Function Loss: 0.00354

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09823
Policy Update Magnitude: 0.54130
Value Function Update Magnitude: 0.62861

Collected Steps per Second: 22,462.97624
Overall Steps per Second: 10,571.72071

Timestep Collection Time: 2.22660
Timestep Consumption Time: 2.50452
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.73111

Cumulative Model Updates: 66,450
Cumulative Timesteps: 554,273,588

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.39127
Policy Entropy: 3.34926
Value Function Loss: 0.00371

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10745
Policy Update Magnitude: 0.53822
Value Function Update Magnitude: 0.63777

Collected Steps per Second: 22,494.64315
Overall Steps per Second: 10,581.84983

Timestep Collection Time: 2.22346
Timestep Consumption Time: 2.50312
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.72658

Cumulative Model Updates: 66,456
Cumulative Timesteps: 554,323,604

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 554323604...
Checkpoint 554323604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.74723
Policy Entropy: 3.34715
Value Function Loss: 0.00356

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10265
Policy Update Magnitude: 0.53507
Value Function Update Magnitude: 0.62986

Collected Steps per Second: 22,933.82055
Overall Steps per Second: 10,545.11782

Timestep Collection Time: 2.18088
Timestep Consumption Time: 2.56216
PPO Batch Consumption Time: 0.29695
Total Iteration Time: 4.74305

Cumulative Model Updates: 66,462
Cumulative Timesteps: 554,373,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 923.46164
Policy Entropy: 3.36848
Value Function Loss: 0.00361

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09900
Policy Update Magnitude: 0.54005
Value Function Update Magnitude: 0.62546

Collected Steps per Second: 22,866.19140
Overall Steps per Second: 10,747.00519

Timestep Collection Time: 2.18681
Timestep Consumption Time: 2.46602
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.65283

Cumulative Model Updates: 66,468
Cumulative Timesteps: 554,423,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 554423624...
Checkpoint 554423624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.55565
Policy Entropy: 3.35864
Value Function Loss: 0.00344

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10409
Policy Update Magnitude: 0.53668
Value Function Update Magnitude: 0.62308

Collected Steps per Second: 22,196.66094
Overall Steps per Second: 10,638.85990

Timestep Collection Time: 2.25358
Timestep Consumption Time: 2.44824
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.70182

Cumulative Model Updates: 66,474
Cumulative Timesteps: 554,473,646

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.53486
Policy Entropy: 3.37769
Value Function Loss: 0.00339

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.52859
Value Function Update Magnitude: 0.60714

Collected Steps per Second: 23,214.22171
Overall Steps per Second: 10,759.10193

Timestep Collection Time: 2.15402
Timestep Consumption Time: 2.49358
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.64760

Cumulative Model Updates: 66,480
Cumulative Timesteps: 554,523,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 554523650...
Checkpoint 554523650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,922.38460
Policy Entropy: 3.36866
Value Function Loss: 0.00337

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09366
Policy Update Magnitude: 0.52422
Value Function Update Magnitude: 0.58935

Collected Steps per Second: 22,815.61779
Overall Steps per Second: 10,710.04356

Timestep Collection Time: 2.19280
Timestep Consumption Time: 2.47852
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.67132

Cumulative Model Updates: 66,486
Cumulative Timesteps: 554,573,680

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.39762
Policy Entropy: 3.36790
Value Function Loss: 0.00364

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09244
Policy Update Magnitude: 0.53647
Value Function Update Magnitude: 0.61600

Collected Steps per Second: 23,335.42574
Overall Steps per Second: 10,750.36609

Timestep Collection Time: 2.14267
Timestep Consumption Time: 2.50834
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.65100

Cumulative Model Updates: 66,492
Cumulative Timesteps: 554,623,680

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 554623680...
Checkpoint 554623680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,193.70898
Policy Entropy: 3.35184
Value Function Loss: 0.00368

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08579
Policy Update Magnitude: 0.55254
Value Function Update Magnitude: 0.63857

Collected Steps per Second: 22,597.66844
Overall Steps per Second: 10,530.27254

Timestep Collection Time: 2.21359
Timestep Consumption Time: 2.53671
PPO Batch Consumption Time: 0.29662
Total Iteration Time: 4.75030

Cumulative Model Updates: 66,498
Cumulative Timesteps: 554,673,702

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 930.45107
Policy Entropy: 3.34423
Value Function Loss: 0.00370

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09208
Policy Update Magnitude: 0.55282
Value Function Update Magnitude: 0.65930

Collected Steps per Second: 22,637.69681
Overall Steps per Second: 10,628.79695

Timestep Collection Time: 2.20915
Timestep Consumption Time: 2.49600
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.70514

Cumulative Model Updates: 66,504
Cumulative Timesteps: 554,723,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 554723712...
Checkpoint 554723712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.37610
Policy Entropy: 3.35446
Value Function Loss: 0.00370

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09418
Policy Update Magnitude: 0.54435
Value Function Update Magnitude: 0.65870

Collected Steps per Second: 22,676.82974
Overall Steps per Second: 10,638.50241

Timestep Collection Time: 2.20578
Timestep Consumption Time: 2.49601
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.70179

Cumulative Model Updates: 66,510
Cumulative Timesteps: 554,773,732

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 739.98239
Policy Entropy: 3.36501
Value Function Loss: 0.00363

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09873
Policy Update Magnitude: 0.53862
Value Function Update Magnitude: 0.66672

Collected Steps per Second: 21,798.21646
Overall Steps per Second: 10,725.90779

Timestep Collection Time: 2.29477
Timestep Consumption Time: 2.36889
PPO Batch Consumption Time: 0.28204
Total Iteration Time: 4.66366

Cumulative Model Updates: 66,516
Cumulative Timesteps: 554,823,754

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 554823754...
Checkpoint 554823754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.45967
Policy Entropy: 3.37695
Value Function Loss: 0.00371

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09498
Policy Update Magnitude: 0.53915
Value Function Update Magnitude: 0.64815

Collected Steps per Second: 21,698.95634
Overall Steps per Second: 10,699.52688

Timestep Collection Time: 2.30453
Timestep Consumption Time: 2.36913
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.67366

Cumulative Model Updates: 66,522
Cumulative Timesteps: 554,873,760

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.85649
Policy Entropy: 3.35736
Value Function Loss: 0.00386

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.11859
Policy Update Magnitude: 0.54221
Value Function Update Magnitude: 0.65106

Collected Steps per Second: 23,016.19635
Overall Steps per Second: 10,669.91826

Timestep Collection Time: 2.17377
Timestep Consumption Time: 2.51530
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.68907

Cumulative Model Updates: 66,528
Cumulative Timesteps: 554,923,792

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 554923792...
Checkpoint 554923792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.02135
Policy Entropy: 3.35437
Value Function Loss: 0.00378

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11389
Policy Update Magnitude: 0.54288
Value Function Update Magnitude: 0.66025

Collected Steps per Second: 22,497.71600
Overall Steps per Second: 10,623.55381

Timestep Collection Time: 2.22351
Timestep Consumption Time: 2.48527
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.70878

Cumulative Model Updates: 66,534
Cumulative Timesteps: 554,973,816

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 978.04780
Policy Entropy: 3.33830
Value Function Loss: 0.00385

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10713
Policy Update Magnitude: 0.54690
Value Function Update Magnitude: 0.65913

Collected Steps per Second: 23,335.85828
Overall Steps per Second: 10,717.76558

Timestep Collection Time: 2.14288
Timestep Consumption Time: 2.52283
PPO Batch Consumption Time: 0.29660
Total Iteration Time: 4.66571

Cumulative Model Updates: 66,540
Cumulative Timesteps: 555,023,822

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 555023822...
Checkpoint 555023822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 721.17748
Policy Entropy: 3.34567
Value Function Loss: 0.00393

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11311
Policy Update Magnitude: 0.55458
Value Function Update Magnitude: 0.66096

Collected Steps per Second: 21,715.06071
Overall Steps per Second: 10,536.13125

Timestep Collection Time: 2.30255
Timestep Consumption Time: 2.44303
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.74557

Cumulative Model Updates: 66,546
Cumulative Timesteps: 555,073,822

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.39420
Policy Entropy: 3.33380
Value Function Loss: 0.00383

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10789
Policy Update Magnitude: 0.55256
Value Function Update Magnitude: 0.66484

Collected Steps per Second: 22,497.91360
Overall Steps per Second: 10,530.30102

Timestep Collection Time: 2.22261
Timestep Consumption Time: 2.52598
PPO Batch Consumption Time: 0.29677
Total Iteration Time: 4.74858

Cumulative Model Updates: 66,552
Cumulative Timesteps: 555,123,826

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 555123826...
Checkpoint 555123826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,603.69657
Policy Entropy: 3.32693
Value Function Loss: 0.00369

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10888
Policy Update Magnitude: 0.54819
Value Function Update Magnitude: 0.65528

Collected Steps per Second: 21,686.68066
Overall Steps per Second: 10,547.87154

Timestep Collection Time: 2.30676
Timestep Consumption Time: 2.43600
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.74276

Cumulative Model Updates: 66,558
Cumulative Timesteps: 555,173,852

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,423.52177
Policy Entropy: 3.30649
Value Function Loss: 0.00360

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08707
Policy Update Magnitude: 0.54261
Value Function Update Magnitude: 0.64715

Collected Steps per Second: 22,665.46462
Overall Steps per Second: 10,543.23242

Timestep Collection Time: 2.20635
Timestep Consumption Time: 2.53679
PPO Batch Consumption Time: 0.29659
Total Iteration Time: 4.74314

Cumulative Model Updates: 66,564
Cumulative Timesteps: 555,223,860

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 555223860...
Checkpoint 555223860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.53471
Policy Entropy: 3.30884
Value Function Loss: 0.00380

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.53918
Value Function Update Magnitude: 0.64015

Collected Steps per Second: 22,760.69102
Overall Steps per Second: 10,589.29207

Timestep Collection Time: 2.19695
Timestep Consumption Time: 2.52518
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.72213

Cumulative Model Updates: 66,570
Cumulative Timesteps: 555,273,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.26162
Policy Entropy: 3.30633
Value Function Loss: 0.00392

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.54462
Value Function Update Magnitude: 0.65535

Collected Steps per Second: 22,738.90652
Overall Steps per Second: 10,609.43154

Timestep Collection Time: 2.19931
Timestep Consumption Time: 2.51442
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.71373

Cumulative Model Updates: 66,576
Cumulative Timesteps: 555,323,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 555323874...
Checkpoint 555323874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.48460
Policy Entropy: 3.29970
Value Function Loss: 0.00379

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08226
Policy Update Magnitude: 0.55172
Value Function Update Magnitude: 0.66364

Collected Steps per Second: 23,204.23228
Overall Steps per Second: 10,888.10828

Timestep Collection Time: 2.15504
Timestep Consumption Time: 2.43768
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.59272

Cumulative Model Updates: 66,582
Cumulative Timesteps: 555,373,880

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.66625
Policy Entropy: 3.28909
Value Function Loss: 0.00375

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08348
Policy Update Magnitude: 0.55805
Value Function Update Magnitude: 0.65140

Collected Steps per Second: 22,761.77025
Overall Steps per Second: 10,607.85669

Timestep Collection Time: 2.19798
Timestep Consumption Time: 2.51833
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.71632

Cumulative Model Updates: 66,588
Cumulative Timesteps: 555,423,910

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 555423910...
Checkpoint 555423910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,663.39297
Policy Entropy: 3.28350
Value Function Loss: 0.00355

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11710
Policy Update Magnitude: 0.55606
Value Function Update Magnitude: 0.64407

Collected Steps per Second: 22,760.26759
Overall Steps per Second: 10,587.18947

Timestep Collection Time: 2.19690
Timestep Consumption Time: 2.52598
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.72288

Cumulative Model Updates: 66,594
Cumulative Timesteps: 555,473,912

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,002.90246
Policy Entropy: 3.30080
Value Function Loss: 0.00369

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10657
Policy Update Magnitude: 0.55300
Value Function Update Magnitude: 0.63968

Collected Steps per Second: 23,159.64388
Overall Steps per Second: 10,846.16832

Timestep Collection Time: 2.15962
Timestep Consumption Time: 2.45178
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.61140

Cumulative Model Updates: 66,600
Cumulative Timesteps: 555,523,928

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 555523928...
Checkpoint 555523928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.70109
Policy Entropy: 3.30384
Value Function Loss: 0.00372

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09998
Policy Update Magnitude: 0.55689
Value Function Update Magnitude: 0.65265

Collected Steps per Second: 22,652.91624
Overall Steps per Second: 10,696.38662

Timestep Collection Time: 2.20749
Timestep Consumption Time: 2.46755
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.67504

Cumulative Model Updates: 66,606
Cumulative Timesteps: 555,573,934

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760.21791
Policy Entropy: 3.30643
Value Function Loss: 0.00372

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10375
Policy Update Magnitude: 0.55414
Value Function Update Magnitude: 0.64452

Collected Steps per Second: 22,825.58404
Overall Steps per Second: 10,673.33794

Timestep Collection Time: 2.19114
Timestep Consumption Time: 2.49474
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.68588

Cumulative Model Updates: 66,612
Cumulative Timesteps: 555,623,948

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 555623948...
Checkpoint 555623948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 858.74401
Policy Entropy: 3.31292
Value Function Loss: 0.00367

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10054
Policy Update Magnitude: 0.53995
Value Function Update Magnitude: 0.64222

Collected Steps per Second: 22,109.36906
Overall Steps per Second: 10,494.85354

Timestep Collection Time: 2.26239
Timestep Consumption Time: 2.50376
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.76615

Cumulative Model Updates: 66,618
Cumulative Timesteps: 555,673,968

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 899.72577
Policy Entropy: 3.28946
Value Function Loss: 0.00352

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08831
Policy Update Magnitude: 0.53246
Value Function Update Magnitude: 0.63948

Collected Steps per Second: 22,519.92139
Overall Steps per Second: 10,613.17797

Timestep Collection Time: 2.22097
Timestep Consumption Time: 2.49166
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.71263

Cumulative Model Updates: 66,624
Cumulative Timesteps: 555,723,984

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 555723984...
Checkpoint 555723984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.04731
Policy Entropy: 3.31715
Value Function Loss: 0.00344

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08042
Policy Update Magnitude: 0.53518
Value Function Update Magnitude: 0.63488

Collected Steps per Second: 22,347.87171
Overall Steps per Second: 10,477.73690

Timestep Collection Time: 2.23762
Timestep Consumption Time: 2.53498
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.77260

Cumulative Model Updates: 66,630
Cumulative Timesteps: 555,773,990

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 768.14618
Policy Entropy: 3.31646
Value Function Loss: 0.00348

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08129
Policy Update Magnitude: 0.53489
Value Function Update Magnitude: 0.63935

Collected Steps per Second: 22,591.37696
Overall Steps per Second: 10,694.90557

Timestep Collection Time: 2.21341
Timestep Consumption Time: 2.46209
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.67550

Cumulative Model Updates: 66,636
Cumulative Timesteps: 555,823,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 555823994...
Checkpoint 555823994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.69060
Policy Entropy: 3.33053
Value Function Loss: 0.00372

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.53528
Value Function Update Magnitude: 0.63342

Collected Steps per Second: 22,855.33353
Overall Steps per Second: 10,767.08830

Timestep Collection Time: 2.18802
Timestep Consumption Time: 2.45650
PPO Batch Consumption Time: 0.28177
Total Iteration Time: 4.64452

Cumulative Model Updates: 66,642
Cumulative Timesteps: 555,874,002

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 786.97504
Policy Entropy: 3.34486
Value Function Loss: 0.00359

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09017
Policy Update Magnitude: 0.53999
Value Function Update Magnitude: 0.64652

Collected Steps per Second: 22,750.40793
Overall Steps per Second: 10,648.60939

Timestep Collection Time: 2.19785
Timestep Consumption Time: 2.49779
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.69564

Cumulative Model Updates: 66,648
Cumulative Timesteps: 555,924,004

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 555924004...
Checkpoint 555924004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,623.61808
Policy Entropy: 3.33358
Value Function Loss: 0.00347

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08611
Policy Update Magnitude: 0.53770
Value Function Update Magnitude: 0.64800

Collected Steps per Second: 22,382.40290
Overall Steps per Second: 10,836.35774

Timestep Collection Time: 2.23506
Timestep Consumption Time: 2.38144
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.61650

Cumulative Model Updates: 66,654
Cumulative Timesteps: 555,974,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 747.35525
Policy Entropy: 3.35236
Value Function Loss: 0.00334

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07669
Policy Update Magnitude: 0.52628
Value Function Update Magnitude: 0.62467

Collected Steps per Second: 22,289.60537
Overall Steps per Second: 10,727.33842

Timestep Collection Time: 2.24454
Timestep Consumption Time: 2.41924
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.66378

Cumulative Model Updates: 66,660
Cumulative Timesteps: 556,024,060

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 556024060...
Checkpoint 556024060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 869.89730
Policy Entropy: 3.33502
Value Function Loss: 0.00353

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07265
Policy Update Magnitude: 0.52925
Value Function Update Magnitude: 0.63794

Collected Steps per Second: 22,456.77374
Overall Steps per Second: 10,550.06802

Timestep Collection Time: 2.22694
Timestep Consumption Time: 2.51331
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.74025

Cumulative Model Updates: 66,666
Cumulative Timesteps: 556,074,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,575.91455
Policy Entropy: 3.34781
Value Function Loss: 0.00359

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07319
Policy Update Magnitude: 0.54237
Value Function Update Magnitude: 0.66756

Collected Steps per Second: 23,133.45699
Overall Steps per Second: 10,807.29836

Timestep Collection Time: 2.16258
Timestep Consumption Time: 2.46651
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.62909

Cumulative Model Updates: 66,672
Cumulative Timesteps: 556,124,098

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 556124098...
Checkpoint 556124098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467.45874
Policy Entropy: 3.34415
Value Function Loss: 0.00356

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08080
Policy Update Magnitude: 0.54351
Value Function Update Magnitude: 0.69940

Collected Steps per Second: 22,298.89830
Overall Steps per Second: 10,696.82697

Timestep Collection Time: 2.24361
Timestep Consumption Time: 2.43348
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.67709

Cumulative Model Updates: 66,678
Cumulative Timesteps: 556,174,128

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 768.22050
Policy Entropy: 3.32016
Value Function Loss: 0.00366

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08740
Policy Update Magnitude: 0.53699
Value Function Update Magnitude: 0.71199

Collected Steps per Second: 22,912.67245
Overall Steps per Second: 10,793.79112

Timestep Collection Time: 2.18237
Timestep Consumption Time: 2.45029
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.63266

Cumulative Model Updates: 66,684
Cumulative Timesteps: 556,224,132

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 556224132...
Checkpoint 556224132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.26651
Policy Entropy: 3.32265
Value Function Loss: 0.00373

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.54345
Value Function Update Magnitude: 0.69158

Collected Steps per Second: 22,127.96251
Overall Steps per Second: 10,632.80183

Timestep Collection Time: 2.25986
Timestep Consumption Time: 2.44314
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.70299

Cumulative Model Updates: 66,690
Cumulative Timesteps: 556,274,138

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717.00225
Policy Entropy: 3.32290
Value Function Loss: 0.00393

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08253
Policy Update Magnitude: 0.55042
Value Function Update Magnitude: 0.66936

Collected Steps per Second: 22,957.27302
Overall Steps per Second: 10,637.52123

Timestep Collection Time: 2.17831
Timestep Consumption Time: 2.52279
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.70110

Cumulative Model Updates: 66,696
Cumulative Timesteps: 556,324,146

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 556324146...
Checkpoint 556324146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 958.94301
Policy Entropy: 3.33610
Value Function Loss: 0.00399

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.55416
Value Function Update Magnitude: 0.68158

Collected Steps per Second: 22,407.56186
Overall Steps per Second: 10,513.09929

Timestep Collection Time: 2.23175
Timestep Consumption Time: 2.52499
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.75673

Cumulative Model Updates: 66,702
Cumulative Timesteps: 556,374,154

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728.37603
Policy Entropy: 3.34126
Value Function Loss: 0.00388

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11531
Policy Update Magnitude: 0.55080
Value Function Update Magnitude: 0.68575

Collected Steps per Second: 22,854.26046
Overall Steps per Second: 10,653.66088

Timestep Collection Time: 2.18865
Timestep Consumption Time: 2.50645
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.69510

Cumulative Model Updates: 66,708
Cumulative Timesteps: 556,424,174

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 556424174...
Checkpoint 556424174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589.16843
Policy Entropy: 3.34168
Value Function Loss: 0.00366

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.53550
Value Function Update Magnitude: 0.68668

Collected Steps per Second: 23,046.93133
Overall Steps per Second: 10,823.25749

Timestep Collection Time: 2.17001
Timestep Consumption Time: 2.45078
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.62079

Cumulative Model Updates: 66,714
Cumulative Timesteps: 556,474,186

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.81002
Policy Entropy: 3.34149
Value Function Loss: 0.00345

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09856
Policy Update Magnitude: 0.52270
Value Function Update Magnitude: 0.67367

Collected Steps per Second: 23,193.98828
Overall Steps per Second: 10,894.32106

Timestep Collection Time: 2.15685
Timestep Consumption Time: 2.43508
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.59193

Cumulative Model Updates: 66,720
Cumulative Timesteps: 556,524,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 556524212...
Checkpoint 556524212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.90175
Policy Entropy: 3.33141
Value Function Loss: 0.00373

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10170
Policy Update Magnitude: 0.53236
Value Function Update Magnitude: 0.65698

Collected Steps per Second: 22,622.63737
Overall Steps per Second: 10,755.88073

Timestep Collection Time: 2.21079
Timestep Consumption Time: 2.43913
PPO Batch Consumption Time: 0.28192
Total Iteration Time: 4.64992

Cumulative Model Updates: 66,726
Cumulative Timesteps: 556,574,226

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 977.76421
Policy Entropy: 3.32521
Value Function Loss: 0.00389

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11011
Policy Update Magnitude: 0.54409
Value Function Update Magnitude: 0.67433

Collected Steps per Second: 23,224.05209
Overall Steps per Second: 10,883.14596

Timestep Collection Time: 2.15440
Timestep Consumption Time: 2.44298
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 4.59738

Cumulative Model Updates: 66,732
Cumulative Timesteps: 556,624,260

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 556624260...
Checkpoint 556624260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.19996
Policy Entropy: 3.31977
Value Function Loss: 0.00373

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09249
Policy Update Magnitude: 0.54491
Value Function Update Magnitude: 0.68196

Collected Steps per Second: 22,082.83974
Overall Steps per Second: 10,580.36793

Timestep Collection Time: 2.26520
Timestep Consumption Time: 2.46262
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.72781

Cumulative Model Updates: 66,738
Cumulative Timesteps: 556,674,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.65851
Policy Entropy: 3.30661
Value Function Loss: 0.00367

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10150
Policy Update Magnitude: 0.54241
Value Function Update Magnitude: 0.68198

Collected Steps per Second: 22,119.02311
Overall Steps per Second: 10,504.01243

Timestep Collection Time: 2.26158
Timestep Consumption Time: 2.50079
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.76237

Cumulative Model Updates: 66,744
Cumulative Timesteps: 556,724,306

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 556724306...
Checkpoint 556724306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 861.41122
Policy Entropy: 3.31035
Value Function Loss: 0.00372

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10215
Policy Update Magnitude: 0.54575
Value Function Update Magnitude: 0.67573

Collected Steps per Second: 22,202.56532
Overall Steps per Second: 10,660.22470

Timestep Collection Time: 2.25298
Timestep Consumption Time: 2.43941
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.69240

Cumulative Model Updates: 66,750
Cumulative Timesteps: 556,774,328

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.35121
Policy Entropy: 3.29218
Value Function Loss: 0.00395

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.07800
Policy Update Magnitude: 0.55343
Value Function Update Magnitude: 0.69255

Collected Steps per Second: 22,950.03204
Overall Steps per Second: 10,824.39489

Timestep Collection Time: 2.17960
Timestep Consumption Time: 2.44162
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.62123

Cumulative Model Updates: 66,756
Cumulative Timesteps: 556,824,350

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 556824350...
Checkpoint 556824350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 758.94562
Policy Entropy: 3.31788
Value Function Loss: 0.00403

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07847
Policy Update Magnitude: 0.55940
Value Function Update Magnitude: 0.70158

Collected Steps per Second: 22,283.98657
Overall Steps per Second: 10,670.48731

Timestep Collection Time: 2.24484
Timestep Consumption Time: 2.44323
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.68807

Cumulative Model Updates: 66,762
Cumulative Timesteps: 556,874,374

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.54374
Policy Entropy: 3.32167
Value Function Loss: 0.00390

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09530
Policy Update Magnitude: 0.55081
Value Function Update Magnitude: 0.70829

Collected Steps per Second: 23,000.54226
Overall Steps per Second: 10,626.65899

Timestep Collection Time: 2.17404
Timestep Consumption Time: 2.53149
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.70552

Cumulative Model Updates: 66,768
Cumulative Timesteps: 556,924,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 556924378...
Checkpoint 556924378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 951.00296
Policy Entropy: 3.32139
Value Function Loss: 0.00400

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08954
Policy Update Magnitude: 0.54435
Value Function Update Magnitude: 0.68433

Collected Steps per Second: 21,931.68172
Overall Steps per Second: 10,468.54089

Timestep Collection Time: 2.28017
Timestep Consumption Time: 2.49681
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.77698

Cumulative Model Updates: 66,774
Cumulative Timesteps: 556,974,386

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.94755
Policy Entropy: 3.32589
Value Function Loss: 0.00386

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11077
Policy Update Magnitude: 0.54407
Value Function Update Magnitude: 0.66477

Collected Steps per Second: 22,770.10483
Overall Steps per Second: 10,560.04370

Timestep Collection Time: 2.19700
Timestep Consumption Time: 2.54029
PPO Batch Consumption Time: 0.29671
Total Iteration Time: 4.73729

Cumulative Model Updates: 66,780
Cumulative Timesteps: 557,024,412

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 557024412...
Checkpoint 557024412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.68665
Policy Entropy: 3.33598
Value Function Loss: 0.00380

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.14368
Policy Update Magnitude: 0.54257
Value Function Update Magnitude: 0.65949

Collected Steps per Second: 22,970.10537
Overall Steps per Second: 10,626.66461

Timestep Collection Time: 2.17674
Timestep Consumption Time: 2.52840
PPO Batch Consumption Time: 0.29659
Total Iteration Time: 4.70515

Cumulative Model Updates: 66,786
Cumulative Timesteps: 557,074,412

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.20658
Policy Entropy: 3.33662
Value Function Loss: 0.00377

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.12487
Policy Update Magnitude: 0.53643
Value Function Update Magnitude: 0.65110

Collected Steps per Second: 22,715.88687
Overall Steps per Second: 10,754.73384

Timestep Collection Time: 2.20190
Timestep Consumption Time: 2.44889
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.65079

Cumulative Model Updates: 66,792
Cumulative Timesteps: 557,124,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 557124430...
Checkpoint 557124430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 894.98344
Policy Entropy: 3.31029
Value Function Loss: 0.00373

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.13367
Policy Update Magnitude: 0.53432
Value Function Update Magnitude: 0.66549

Collected Steps per Second: 22,729.93064
Overall Steps per Second: 10,780.90489

Timestep Collection Time: 2.20097
Timestep Consumption Time: 2.43945
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.64043

Cumulative Model Updates: 66,798
Cumulative Timesteps: 557,174,458

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 822.25266
Policy Entropy: 3.31226
Value Function Loss: 0.00367

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.12280
Policy Update Magnitude: 0.53797
Value Function Update Magnitude: 0.66921

Collected Steps per Second: 23,011.97327
Overall Steps per Second: 10,835.26715

Timestep Collection Time: 2.17322
Timestep Consumption Time: 2.44227
PPO Batch Consumption Time: 0.28193
Total Iteration Time: 4.61548

Cumulative Model Updates: 66,804
Cumulative Timesteps: 557,224,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 557224468...
Checkpoint 557224468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.72581
Policy Entropy: 3.31513
Value Function Loss: 0.00361

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.13068
Policy Update Magnitude: 0.53808
Value Function Update Magnitude: 0.65792

Collected Steps per Second: 22,100.86743
Overall Steps per Second: 10,609.64180

Timestep Collection Time: 2.26299
Timestep Consumption Time: 2.45103
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.71401

Cumulative Model Updates: 66,810
Cumulative Timesteps: 557,274,482

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 991.14285
Policy Entropy: 3.32641
Value Function Loss: 0.00377

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11613
Policy Update Magnitude: 0.53976
Value Function Update Magnitude: 0.66290

Collected Steps per Second: 22,789.12068
Overall Steps per Second: 10,638.35828

Timestep Collection Time: 2.19508
Timestep Consumption Time: 2.50715
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.70223

Cumulative Model Updates: 66,816
Cumulative Timesteps: 557,324,506

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 557324506...
Checkpoint 557324506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 743.66957
Policy Entropy: 3.31543
Value Function Loss: 0.00381

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11126
Policy Update Magnitude: 0.54362
Value Function Update Magnitude: 0.66619

Collected Steps per Second: 22,472.87934
Overall Steps per Second: 10,531.31894

Timestep Collection Time: 2.22579
Timestep Consumption Time: 2.52385
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.74964

Cumulative Model Updates: 66,822
Cumulative Timesteps: 557,374,526

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 762.03327
Policy Entropy: 3.32984
Value Function Loss: 0.00396

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.55020
Value Function Update Magnitude: 0.64588

Collected Steps per Second: 22,557.67999
Overall Steps per Second: 10,599.92681

Timestep Collection Time: 2.21654
Timestep Consumption Time: 2.50047
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.71701

Cumulative Model Updates: 66,828
Cumulative Timesteps: 557,424,526

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 557424526...
Checkpoint 557424526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 811.96418
Policy Entropy: 3.34033
Value Function Loss: 0.00368

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.54983
Value Function Update Magnitude: 0.64562

Collected Steps per Second: 22,343.71093
Overall Steps per Second: 10,500.96606

Timestep Collection Time: 2.23902
Timestep Consumption Time: 2.52511
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.76413

Cumulative Model Updates: 66,834
Cumulative Timesteps: 557,474,554

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.91666
Policy Entropy: 3.36485
Value Function Loss: 0.00357

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07837
Policy Update Magnitude: 0.53206
Value Function Update Magnitude: 0.63791

Collected Steps per Second: 22,997.11364
Overall Steps per Second: 10,755.37596

Timestep Collection Time: 2.17523
Timestep Consumption Time: 2.47584
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.65107

Cumulative Model Updates: 66,840
Cumulative Timesteps: 557,524,578

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 557524578...
Checkpoint 557524578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 852.98860
Policy Entropy: 3.34887
Value Function Loss: 0.00349

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07320
Policy Update Magnitude: 0.52626
Value Function Update Magnitude: 0.62751

Collected Steps per Second: 22,721.47898
Overall Steps per Second: 10,709.32520

Timestep Collection Time: 2.20065
Timestep Consumption Time: 2.46837
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.66901

Cumulative Model Updates: 66,846
Cumulative Timesteps: 557,574,580

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583.40445
Policy Entropy: 3.33831
Value Function Loss: 0.00361

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08157
Policy Update Magnitude: 0.52799
Value Function Update Magnitude: 0.63558

Collected Steps per Second: 22,670.76747
Overall Steps per Second: 10,565.58882

Timestep Collection Time: 2.20575
Timestep Consumption Time: 2.52716
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.73291

Cumulative Model Updates: 66,852
Cumulative Timesteps: 557,624,586

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 557624586...
Checkpoint 557624586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.45456
Policy Entropy: 3.33819
Value Function Loss: 0.00370

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07769
Policy Update Magnitude: 0.52668
Value Function Update Magnitude: 0.64628

Collected Steps per Second: 22,734.83566
Overall Steps per Second: 10,564.19750

Timestep Collection Time: 2.20032
Timestep Consumption Time: 2.53492
PPO Batch Consumption Time: 0.29791
Total Iteration Time: 4.73524

Cumulative Model Updates: 66,858
Cumulative Timesteps: 557,674,610

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.59468
Policy Entropy: 3.34358
Value Function Loss: 0.00379

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07179
Policy Update Magnitude: 0.54051
Value Function Update Magnitude: 0.67289

Collected Steps per Second: 23,069.90184
Overall Steps per Second: 10,842.78155

Timestep Collection Time: 2.16837
Timestep Consumption Time: 2.44521
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.61358

Cumulative Model Updates: 66,864
Cumulative Timesteps: 557,724,634

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 557724634...
Checkpoint 557724634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 771.94591
Policy Entropy: 3.35854
Value Function Loss: 0.00364

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07511
Policy Update Magnitude: 0.54484
Value Function Update Magnitude: 0.67849

Collected Steps per Second: 22,291.80587
Overall Steps per Second: 10,666.93647

Timestep Collection Time: 2.24369
Timestep Consumption Time: 2.44519
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.68888

Cumulative Model Updates: 66,870
Cumulative Timesteps: 557,774,650

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 968.23523
Policy Entropy: 3.35538
Value Function Loss: 0.00350

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07407
Policy Update Magnitude: 0.53937
Value Function Update Magnitude: 0.65051

Collected Steps per Second: 22,361.78914
Overall Steps per Second: 10,544.01469

Timestep Collection Time: 2.23631
Timestep Consumption Time: 2.50647
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.74279

Cumulative Model Updates: 66,876
Cumulative Timesteps: 557,824,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 557824658...
Checkpoint 557824658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,754.69499
Policy Entropy: 3.34749
Value Function Loss: 0.00332

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.07994
Policy Update Magnitude: 0.52441
Value Function Update Magnitude: 0.62485

Collected Steps per Second: 22,101.97313
Overall Steps per Second: 10,583.64466

Timestep Collection Time: 2.26278
Timestep Consumption Time: 2.46262
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.72540

Cumulative Model Updates: 66,882
Cumulative Timesteps: 557,874,670

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.29184
Policy Entropy: 3.34703
Value Function Loss: 0.00332

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09007
Policy Update Magnitude: 0.51229
Value Function Update Magnitude: 0.61040

Collected Steps per Second: 22,326.27100
Overall Steps per Second: 10,489.07345

Timestep Collection Time: 2.23978
Timestep Consumption Time: 2.52765
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.76744

Cumulative Model Updates: 66,888
Cumulative Timesteps: 557,924,676

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 557924676...
Checkpoint 557924676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.59785
Policy Entropy: 3.35308
Value Function Loss: 0.00345

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07410
Policy Update Magnitude: 0.52299
Value Function Update Magnitude: 0.61442

Collected Steps per Second: 22,175.98519
Overall Steps per Second: 10,610.49500

Timestep Collection Time: 2.25586
Timestep Consumption Time: 2.45890
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.71477

Cumulative Model Updates: 66,894
Cumulative Timesteps: 557,974,702

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.54383
Policy Entropy: 3.36935
Value Function Loss: 0.00359

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07528
Policy Update Magnitude: 0.52980
Value Function Update Magnitude: 0.64277

Collected Steps per Second: 22,767.70578
Overall Steps per Second: 10,543.25010

Timestep Collection Time: 2.19723
Timestep Consumption Time: 2.54760
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.74484

Cumulative Model Updates: 66,900
Cumulative Timesteps: 558,024,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 558024728...
Checkpoint 558024728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.49855
Policy Entropy: 3.37398
Value Function Loss: 0.00384

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08026
Policy Update Magnitude: 0.53143
Value Function Update Magnitude: 0.66798

Collected Steps per Second: 22,708.74549
Overall Steps per Second: 10,569.47574

Timestep Collection Time: 2.20179
Timestep Consumption Time: 2.52881
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 4.73060

Cumulative Model Updates: 66,906
Cumulative Timesteps: 558,074,728

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.22307
Policy Entropy: 3.38134
Value Function Loss: 0.00377

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07521
Policy Update Magnitude: 0.53839
Value Function Update Magnitude: 0.68215

Collected Steps per Second: 22,849.71500
Overall Steps per Second: 10,634.20416

Timestep Collection Time: 2.18821
Timestep Consumption Time: 2.51360
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.70181

Cumulative Model Updates: 66,912
Cumulative Timesteps: 558,124,728

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 558124728...
Checkpoint 558124728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534.27355
Policy Entropy: 3.39594
Value Function Loss: 0.00363

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07990
Policy Update Magnitude: 0.53510
Value Function Update Magnitude: 0.68704

Collected Steps per Second: 23,169.85717
Overall Steps per Second: 10,817.91829

Timestep Collection Time: 2.15849
Timestep Consumption Time: 2.46458
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.62307

Cumulative Model Updates: 66,918
Cumulative Timesteps: 558,174,740

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.15377
Policy Entropy: 3.37656
Value Function Loss: 0.00390

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07177
Policy Update Magnitude: 0.53436
Value Function Update Magnitude: 0.67504

Collected Steps per Second: 22,695.81391
Overall Steps per Second: 10,520.69553

Timestep Collection Time: 2.20331
Timestep Consumption Time: 2.54979
PPO Batch Consumption Time: 0.29767
Total Iteration Time: 4.75311

Cumulative Model Updates: 66,924
Cumulative Timesteps: 558,224,746

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 558224746...
Checkpoint 558224746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.07505
Policy Entropy: 3.36350
Value Function Loss: 0.00398

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08483
Policy Update Magnitude: 0.54474
Value Function Update Magnitude: 0.67201

Collected Steps per Second: 22,826.71419
Overall Steps per Second: 10,632.21024

Timestep Collection Time: 2.19094
Timestep Consumption Time: 2.51288
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.70382

Cumulative Model Updates: 66,930
Cumulative Timesteps: 558,274,758

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.52818
Policy Entropy: 3.34337
Value Function Loss: 0.00410

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09036
Policy Update Magnitude: 0.54813
Value Function Update Magnitude: 0.67637

Collected Steps per Second: 21,817.30073
Overall Steps per Second: 10,547.37343

Timestep Collection Time: 2.29304
Timestep Consumption Time: 2.45013
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.74317

Cumulative Model Updates: 66,936
Cumulative Timesteps: 558,324,786

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 558324786...
Checkpoint 558324786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 886.17073
Policy Entropy: 3.32556
Value Function Loss: 0.00396

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11394
Policy Update Magnitude: 0.54364
Value Function Update Magnitude: 0.67282

Collected Steps per Second: 22,415.43421
Overall Steps per Second: 10,589.93253

Timestep Collection Time: 2.23168
Timestep Consumption Time: 2.49206
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.72373

Cumulative Model Updates: 66,942
Cumulative Timesteps: 558,374,810

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.20763
Policy Entropy: 3.32374
Value Function Loss: 0.00393

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11915
Policy Update Magnitude: 0.53218
Value Function Update Magnitude: 0.67116

Collected Steps per Second: 22,464.67166
Overall Steps per Second: 10,516.07714

Timestep Collection Time: 2.22625
Timestep Consumption Time: 2.52951
PPO Batch Consumption Time: 0.29668
Total Iteration Time: 4.75577

Cumulative Model Updates: 66,948
Cumulative Timesteps: 558,424,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 558424822...
Checkpoint 558424822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 848.65963
Policy Entropy: 3.32530
Value Function Loss: 0.00374

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.53273
Value Function Update Magnitude: 0.64537

Collected Steps per Second: 22,306.35271
Overall Steps per Second: 10,566.20033

Timestep Collection Time: 2.24223
Timestep Consumption Time: 2.49135
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.73358

Cumulative Model Updates: 66,954
Cumulative Timesteps: 558,474,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.14471
Policy Entropy: 3.33838
Value Function Loss: 0.00375

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10764
Policy Update Magnitude: 0.53228
Value Function Update Magnitude: 0.64639

Collected Steps per Second: 22,891.05673
Overall Steps per Second: 10,691.12355

Timestep Collection Time: 2.18557
Timestep Consumption Time: 2.49401
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.67958

Cumulative Model Updates: 66,960
Cumulative Timesteps: 558,524,868

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 558524868...
Checkpoint 558524868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328.94932
Policy Entropy: 3.33165
Value Function Loss: 0.00366

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09980
Policy Update Magnitude: 0.53230
Value Function Update Magnitude: 0.63899

Collected Steps per Second: 22,562.24973
Overall Steps per Second: 10,766.12934

Timestep Collection Time: 2.21698
Timestep Consumption Time: 2.42907
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.64605

Cumulative Model Updates: 66,966
Cumulative Timesteps: 558,574,888

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.03777
Policy Entropy: 3.33020
Value Function Loss: 0.00371

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09051
Policy Update Magnitude: 0.53453
Value Function Update Magnitude: 0.63045

Collected Steps per Second: 22,296.05796
Overall Steps per Second: 10,586.31420

Timestep Collection Time: 2.24309
Timestep Consumption Time: 2.48113
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.72421

Cumulative Model Updates: 66,972
Cumulative Timesteps: 558,624,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 558624900...
Checkpoint 558624900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 795.85515
Policy Entropy: 3.35368
Value Function Loss: 0.00367

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09619
Policy Update Magnitude: 0.53105
Value Function Update Magnitude: 0.63337

Collected Steps per Second: 22,742.13926
Overall Steps per Second: 10,611.04524

Timestep Collection Time: 2.19927
Timestep Consumption Time: 2.51431
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.71358

Cumulative Model Updates: 66,978
Cumulative Timesteps: 558,674,916

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.40817
Policy Entropy: 3.36046
Value Function Loss: 0.00359

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.52600
Value Function Update Magnitude: 0.63684

Collected Steps per Second: 22,959.55747
Overall Steps per Second: 10,773.75490

Timestep Collection Time: 2.17844
Timestep Consumption Time: 2.46395
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.64239

Cumulative Model Updates: 66,984
Cumulative Timesteps: 558,724,932

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 558724932...
Checkpoint 558724932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 986.36536
Policy Entropy: 3.37683
Value Function Loss: 0.00353

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09474
Policy Update Magnitude: 0.52095
Value Function Update Magnitude: 0.63533

Collected Steps per Second: 22,831.81095
Overall Steps per Second: 10,764.09796

Timestep Collection Time: 2.19089
Timestep Consumption Time: 2.45622
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.64711

Cumulative Model Updates: 66,990
Cumulative Timesteps: 558,774,954

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.23893
Policy Entropy: 3.36003
Value Function Loss: 0.00355

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08389
Policy Update Magnitude: 0.52106
Value Function Update Magnitude: 0.63665

Collected Steps per Second: 22,677.93679
Overall Steps per Second: 10,596.09329

Timestep Collection Time: 2.20487
Timestep Consumption Time: 2.51403
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.71891

Cumulative Model Updates: 66,996
Cumulative Timesteps: 558,824,956

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 558824956...
Checkpoint 558824956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.29436
Policy Entropy: 3.36208
Value Function Loss: 0.00358

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08596
Policy Update Magnitude: 0.53103
Value Function Update Magnitude: 0.64900

Collected Steps per Second: 22,629.22736
Overall Steps per Second: 10,496.58293

Timestep Collection Time: 2.21148
Timestep Consumption Time: 2.55617
PPO Batch Consumption Time: 0.29641
Total Iteration Time: 4.76765

Cumulative Model Updates: 67,002
Cumulative Timesteps: 558,875,000

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 853.14253
Policy Entropy: 3.36068
Value Function Loss: 0.00360

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.53475
Value Function Update Magnitude: 0.65454

Collected Steps per Second: 22,577.87276
Overall Steps per Second: 10,606.72597

Timestep Collection Time: 2.21562
Timestep Consumption Time: 2.50063
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.71625

Cumulative Model Updates: 67,008
Cumulative Timesteps: 558,925,024

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 558925024...
Checkpoint 558925024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.27722
Policy Entropy: 3.35844
Value Function Loss: 0.00362

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.54072
Value Function Update Magnitude: 0.66416

Collected Steps per Second: 22,267.97044
Overall Steps per Second: 10,494.40940

Timestep Collection Time: 2.24592
Timestep Consumption Time: 2.51967
PPO Batch Consumption Time: 0.29861
Total Iteration Time: 4.76559

Cumulative Model Updates: 67,014
Cumulative Timesteps: 558,975,036

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.01840
Policy Entropy: 3.36698
Value Function Loss: 0.00347

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08293
Policy Update Magnitude: 0.54026
Value Function Update Magnitude: 0.64353

Collected Steps per Second: 22,396.29620
Overall Steps per Second: 10,488.77358

Timestep Collection Time: 2.23278
Timestep Consumption Time: 2.53479
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 4.76757

Cumulative Model Updates: 67,020
Cumulative Timesteps: 559,025,042

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 559025042...
Checkpoint 559025042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.57393
Policy Entropy: 3.36515
Value Function Loss: 0.00379

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07946
Policy Update Magnitude: 0.53600
Value Function Update Magnitude: 0.63753

Collected Steps per Second: 22,299.65928
Overall Steps per Second: 10,650.05278

Timestep Collection Time: 2.24237
Timestep Consumption Time: 2.45282
PPO Batch Consumption Time: 0.28151
Total Iteration Time: 4.69519

Cumulative Model Updates: 67,026
Cumulative Timesteps: 559,075,046

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672.63295
Policy Entropy: 3.35692
Value Function Loss: 0.00376

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07351
Policy Update Magnitude: 0.54893
Value Function Update Magnitude: 0.66879

Collected Steps per Second: 22,563.23920
Overall Steps per Second: 10,572.79512

Timestep Collection Time: 2.21626
Timestep Consumption Time: 2.51343
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.72969

Cumulative Model Updates: 67,032
Cumulative Timesteps: 559,125,052

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 559125052...
Checkpoint 559125052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 962.35329
Policy Entropy: 3.36070
Value Function Loss: 0.00371

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08287
Policy Update Magnitude: 0.55075
Value Function Update Magnitude: 0.67393

Collected Steps per Second: 22,735.59719
Overall Steps per Second: 10,862.07540

Timestep Collection Time: 2.20025
Timestep Consumption Time: 2.40513
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.60538

Cumulative Model Updates: 67,038
Cumulative Timesteps: 559,175,076

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 959.24237
Policy Entropy: 3.35776
Value Function Loss: 0.00365

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.07989
Policy Update Magnitude: 0.54580
Value Function Update Magnitude: 0.68613

Collected Steps per Second: 22,632.65939
Overall Steps per Second: 10,497.89900

Timestep Collection Time: 2.20990
Timestep Consumption Time: 2.55448
PPO Batch Consumption Time: 0.29660
Total Iteration Time: 4.76438

Cumulative Model Updates: 67,044
Cumulative Timesteps: 559,225,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 559225092...
Checkpoint 559225092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,293.99855
Policy Entropy: 3.35782
Value Function Loss: 0.00369

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07675
Policy Update Magnitude: 0.54387
Value Function Update Magnitude: 0.68089

Collected Steps per Second: 22,783.47866
Overall Steps per Second: 10,612.44401

Timestep Collection Time: 2.19554
Timestep Consumption Time: 2.51798
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.71352

Cumulative Model Updates: 67,050
Cumulative Timesteps: 559,275,114

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 958.50295
Policy Entropy: 3.36001
Value Function Loss: 0.00357

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08992
Policy Update Magnitude: 0.54398
Value Function Update Magnitude: 0.67947

Collected Steps per Second: 22,723.74388
Overall Steps per Second: 10,813.92706

Timestep Collection Time: 2.20069
Timestep Consumption Time: 2.42371
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.62441

Cumulative Model Updates: 67,056
Cumulative Timesteps: 559,325,122

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 559325122...
Checkpoint 559325122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424.83225
Policy Entropy: 3.36484
Value Function Loss: 0.00348

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10254
Policy Update Magnitude: 0.53501
Value Function Update Magnitude: 0.66009

Collected Steps per Second: 22,724.80615
Overall Steps per Second: 10,776.85099

Timestep Collection Time: 2.20033
Timestep Consumption Time: 2.43943
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.63976

Cumulative Model Updates: 67,062
Cumulative Timesteps: 559,375,124

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.69206
Policy Entropy: 3.36495
Value Function Loss: 0.00362

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10954
Policy Update Magnitude: 0.52940
Value Function Update Magnitude: 0.61525

Collected Steps per Second: 22,755.04005
Overall Steps per Second: 10,800.79142

Timestep Collection Time: 2.19855
Timestep Consumption Time: 2.43334
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.63188

Cumulative Model Updates: 67,068
Cumulative Timesteps: 559,425,152

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 559425152...
Checkpoint 559425152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.20814
Policy Entropy: 3.36418
Value Function Loss: 0.00374

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10123
Policy Update Magnitude: 0.54009
Value Function Update Magnitude: 0.62954

Collected Steps per Second: 22,983.05095
Overall Steps per Second: 10,725.17060

Timestep Collection Time: 2.17630
Timestep Consumption Time: 2.48731
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.66361

Cumulative Model Updates: 67,074
Cumulative Timesteps: 559,475,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.88823
Policy Entropy: 3.35214
Value Function Loss: 0.00391

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10485
Policy Update Magnitude: 0.54772
Value Function Update Magnitude: 0.66023

Collected Steps per Second: 22,482.34489
Overall Steps per Second: 10,667.19975

Timestep Collection Time: 2.22441
Timestep Consumption Time: 2.46379
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.68820

Cumulative Model Updates: 67,080
Cumulative Timesteps: 559,525,180

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 559525180...
Checkpoint 559525180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,707.75705
Policy Entropy: 3.34685
Value Function Loss: 0.00372

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08996
Policy Update Magnitude: 0.54921
Value Function Update Magnitude: 0.67028

Collected Steps per Second: 22,179.38847
Overall Steps per Second: 10,525.84961

Timestep Collection Time: 2.25570
Timestep Consumption Time: 2.49736
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 4.75306

Cumulative Model Updates: 67,086
Cumulative Timesteps: 559,575,210

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 863.47980
Policy Entropy: 3.35653
Value Function Loss: 0.00359

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08140
Policy Update Magnitude: 0.54208
Value Function Update Magnitude: 0.65570

Collected Steps per Second: 22,676.98518
Overall Steps per Second: 10,760.99297

Timestep Collection Time: 2.20541
Timestep Consumption Time: 2.44212
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.64753

Cumulative Model Updates: 67,092
Cumulative Timesteps: 559,625,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 559625222...
Checkpoint 559625222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.93453
Policy Entropy: 3.34601
Value Function Loss: 0.00350

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08168
Policy Update Magnitude: 0.53115
Value Function Update Magnitude: 0.64010

Collected Steps per Second: 22,250.46746
Overall Steps per Second: 10,653.92196

Timestep Collection Time: 2.24714
Timestep Consumption Time: 2.44596
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.69311

Cumulative Model Updates: 67,098
Cumulative Timesteps: 559,675,222

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 753.94561
Policy Entropy: 3.33715
Value Function Loss: 0.00375

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08934
Policy Update Magnitude: 0.54060
Value Function Update Magnitude: 0.63714

Collected Steps per Second: 23,035.87308
Overall Steps per Second: 10,856.72762

Timestep Collection Time: 2.17105
Timestep Consumption Time: 2.43550
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.60654

Cumulative Model Updates: 67,104
Cumulative Timesteps: 559,725,234

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 559725234...
Checkpoint 559725234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 745.63337
Policy Entropy: 3.32130
Value Function Loss: 0.00384

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08525
Policy Update Magnitude: 0.54739
Value Function Update Magnitude: 0.64384

Collected Steps per Second: 22,787.37781
Overall Steps per Second: 10,768.19779

Timestep Collection Time: 2.19604
Timestep Consumption Time: 2.45116
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.64720

Cumulative Model Updates: 67,110
Cumulative Timesteps: 559,775,276

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 804.38483
Policy Entropy: 3.32257
Value Function Loss: 0.00377

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07954
Policy Update Magnitude: 0.54591
Value Function Update Magnitude: 0.63935

Collected Steps per Second: 22,705.66159
Overall Steps per Second: 10,768.47541

Timestep Collection Time: 2.20236
Timestep Consumption Time: 2.44138
PPO Batch Consumption Time: 0.28383
Total Iteration Time: 4.64374

Cumulative Model Updates: 67,116
Cumulative Timesteps: 559,825,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 559825282...
Checkpoint 559825282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711.00731
Policy Entropy: 3.33006
Value Function Loss: 0.00374

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08495
Policy Update Magnitude: 0.54598
Value Function Update Magnitude: 0.62979

Collected Steps per Second: 22,443.79705
Overall Steps per Second: 10,749.80237

Timestep Collection Time: 2.22832
Timestep Consumption Time: 2.42404
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.65236

Cumulative Model Updates: 67,122
Cumulative Timesteps: 559,875,294

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.63576
Policy Entropy: 3.33184
Value Function Loss: 0.00374

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07812
Policy Update Magnitude: 0.54357
Value Function Update Magnitude: 0.62062

Collected Steps per Second: 22,467.74541
Overall Steps per Second: 10,649.68419

Timestep Collection Time: 2.22577
Timestep Consumption Time: 2.46996
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.69573

Cumulative Model Updates: 67,128
Cumulative Timesteps: 559,925,302

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 559925302...
Checkpoint 559925302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 771.26116
Policy Entropy: 3.34147
Value Function Loss: 0.00377

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08308
Policy Update Magnitude: 0.54619
Value Function Update Magnitude: 0.63134

Collected Steps per Second: 23,196.65978
Overall Steps per Second: 10,898.09605

Timestep Collection Time: 2.15660
Timestep Consumption Time: 2.43374
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.59034

Cumulative Model Updates: 67,134
Cumulative Timesteps: 559,975,328

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 766.34259
Policy Entropy: 3.33628
Value Function Loss: 0.00371

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08138
Policy Update Magnitude: 0.54771
Value Function Update Magnitude: 0.64057

Collected Steps per Second: 21,771.49948
Overall Steps per Second: 10,572.57487

Timestep Collection Time: 2.29695
Timestep Consumption Time: 2.43303
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.72997

Cumulative Model Updates: 67,140
Cumulative Timesteps: 560,025,336

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 560025336...
Checkpoint 560025336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.38799
Policy Entropy: 3.35326
Value Function Loss: 0.00358

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07910
Policy Update Magnitude: 0.54833
Value Function Update Magnitude: 0.63040

Collected Steps per Second: 22,025.86326
Overall Steps per Second: 10,607.79177

Timestep Collection Time: 2.27060
Timestep Consumption Time: 2.44404
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.71465

Cumulative Model Updates: 67,146
Cumulative Timesteps: 560,075,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 951.22412
Policy Entropy: 3.35235
Value Function Loss: 0.00373

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.54027
Value Function Update Magnitude: 0.62887

Collected Steps per Second: 21,894.66199
Overall Steps per Second: 10,761.16138

Timestep Collection Time: 2.28375
Timestep Consumption Time: 2.36277
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.64652

Cumulative Model Updates: 67,152
Cumulative Timesteps: 560,125,350

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 560125350...
Checkpoint 560125350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.30568
Policy Entropy: 3.36284
Value Function Loss: 0.00384

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10605
Policy Update Magnitude: 0.53946
Value Function Update Magnitude: 0.63894

Collected Steps per Second: 21,540.96466
Overall Steps per Second: 10,627.46366

Timestep Collection Time: 2.32153
Timestep Consumption Time: 2.38401
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.70554

Cumulative Model Updates: 67,158
Cumulative Timesteps: 560,175,358

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,466.72737
Policy Entropy: 3.33770
Value Function Loss: 0.00410

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10796
Policy Update Magnitude: 0.54692
Value Function Update Magnitude: 0.66249

Collected Steps per Second: 21,679.19463
Overall Steps per Second: 10,504.02061

Timestep Collection Time: 2.30765
Timestep Consumption Time: 2.45510
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.76275

Cumulative Model Updates: 67,164
Cumulative Timesteps: 560,225,386

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 560225386...
Checkpoint 560225386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 872.51755
Policy Entropy: 3.33901
Value Function Loss: 0.00384

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10118
Policy Update Magnitude: 0.55344
Value Function Update Magnitude: 0.68481

Collected Steps per Second: 22,161.08324
Overall Steps per Second: 10,629.28198

Timestep Collection Time: 2.25621
Timestep Consumption Time: 2.44778
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.70399

Cumulative Model Updates: 67,170
Cumulative Timesteps: 560,275,386

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.73478
Policy Entropy: 3.32946
Value Function Loss: 0.00395

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10612
Policy Update Magnitude: 0.55697
Value Function Update Magnitude: 0.67435

Collected Steps per Second: 22,425.76175
Overall Steps per Second: 10,850.86862

Timestep Collection Time: 2.22994
Timestep Consumption Time: 2.37873
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.60866

Cumulative Model Updates: 67,176
Cumulative Timesteps: 560,325,394

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 560325394...
Checkpoint 560325394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 905.50675
Policy Entropy: 3.34159
Value Function Loss: 0.00378

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10004
Policy Update Magnitude: 0.55694
Value Function Update Magnitude: 0.66563

Collected Steps per Second: 22,867.96148
Overall Steps per Second: 10,740.84057

Timestep Collection Time: 2.18734
Timestep Consumption Time: 2.46965
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.65699

Cumulative Model Updates: 67,182
Cumulative Timesteps: 560,375,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.51847
Policy Entropy: 3.34748
Value Function Loss: 0.00365

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09049
Policy Update Magnitude: 0.54614
Value Function Update Magnitude: 0.65451

Collected Steps per Second: 21,977.62590
Overall Steps per Second: 10,654.33219

Timestep Collection Time: 2.27504
Timestep Consumption Time: 2.41789
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.69293

Cumulative Model Updates: 67,188
Cumulative Timesteps: 560,425,414

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 560425414...
Checkpoint 560425414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.14384
Policy Entropy: 3.36313
Value Function Loss: 0.00365

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08193
Policy Update Magnitude: 0.54795
Value Function Update Magnitude: 0.62997

Collected Steps per Second: 23,143.99872
Overall Steps per Second: 10,884.30909

Timestep Collection Time: 2.16117
Timestep Consumption Time: 2.43426
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.59542

Cumulative Model Updates: 67,194
Cumulative Timesteps: 560,475,432

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.25516
Policy Entropy: 3.35457
Value Function Loss: 0.00378

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06990
Policy Update Magnitude: 0.55632
Value Function Update Magnitude: 0.64740

Collected Steps per Second: 22,846.43256
Overall Steps per Second: 10,798.16509

Timestep Collection Time: 2.18940
Timestep Consumption Time: 2.44287
PPO Batch Consumption Time: 0.28230
Total Iteration Time: 4.63227

Cumulative Model Updates: 67,200
Cumulative Timesteps: 560,525,452

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 560525452...
Checkpoint 560525452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.52387
Policy Entropy: 3.34158
Value Function Loss: 0.00382

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07953
Policy Update Magnitude: 0.55797
Value Function Update Magnitude: 0.65715

Collected Steps per Second: 22,447.60468
Overall Steps per Second: 10,684.18463

Timestep Collection Time: 2.22857
Timestep Consumption Time: 2.45368
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.68225

Cumulative Model Updates: 67,206
Cumulative Timesteps: 560,575,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 797.39974
Policy Entropy: 3.34830
Value Function Loss: 0.00368

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08367
Policy Update Magnitude: 0.55324
Value Function Update Magnitude: 0.66854

Collected Steps per Second: 22,332.03858
Overall Steps per Second: 10,491.60363

Timestep Collection Time: 2.23929
Timestep Consumption Time: 2.52718
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.76648

Cumulative Model Updates: 67,212
Cumulative Timesteps: 560,625,486

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 560625486...
Checkpoint 560625486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 953.55569
Policy Entropy: 3.34454
Value Function Loss: 0.00379

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09836
Policy Update Magnitude: 0.54577
Value Function Update Magnitude: 0.67556

Collected Steps per Second: 22,534.31820
Overall Steps per Second: 10,631.52717

Timestep Collection Time: 2.21928
Timestep Consumption Time: 2.48465
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.70393

Cumulative Model Updates: 67,218
Cumulative Timesteps: 560,675,496

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.88132
Policy Entropy: 3.34800
Value Function Loss: 0.00377

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08861
Policy Update Magnitude: 0.55132
Value Function Update Magnitude: 0.69141

Collected Steps per Second: 22,078.64204
Overall Steps per Second: 10,492.38041

Timestep Collection Time: 2.26545
Timestep Consumption Time: 2.50163
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.76708

Cumulative Model Updates: 67,224
Cumulative Timesteps: 560,725,514

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 560725514...
Checkpoint 560725514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.76384
Policy Entropy: 3.33952
Value Function Loss: 0.00380

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09699
Policy Update Magnitude: 0.55044
Value Function Update Magnitude: 0.69275

Collected Steps per Second: 22,576.95026
Overall Steps per Second: 10,600.48482

Timestep Collection Time: 2.21465
Timestep Consumption Time: 2.50212
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.71677

Cumulative Model Updates: 67,230
Cumulative Timesteps: 560,775,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.07254
Policy Entropy: 3.33334
Value Function Loss: 0.00378

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09742
Policy Update Magnitude: 0.54767
Value Function Update Magnitude: 0.69759

Collected Steps per Second: 23,047.24326
Overall Steps per Second: 10,636.54866

Timestep Collection Time: 2.17050
Timestep Consumption Time: 2.53253
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.70303

Cumulative Model Updates: 67,236
Cumulative Timesteps: 560,825,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 560825538...
Checkpoint 560825538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.38961
Policy Entropy: 3.33195
Value Function Loss: 0.00376

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10999
Policy Update Magnitude: 0.54813
Value Function Update Magnitude: 0.68984

Collected Steps per Second: 22,551.89566
Overall Steps per Second: 10,542.85637

Timestep Collection Time: 2.21835
Timestep Consumption Time: 2.52685
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.74520

Cumulative Model Updates: 67,242
Cumulative Timesteps: 560,875,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.58207
Policy Entropy: 3.31430
Value Function Loss: 0.00381

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10561
Policy Update Magnitude: 0.55145
Value Function Update Magnitude: 0.70476

Collected Steps per Second: 23,225.28447
Overall Steps per Second: 10,866.43299

Timestep Collection Time: 2.15308
Timestep Consumption Time: 2.44879
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.60188

Cumulative Model Updates: 67,248
Cumulative Timesteps: 560,925,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 560925572...
Checkpoint 560925572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,433.97386
Policy Entropy: 3.31957
Value Function Loss: 0.00367

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09783
Policy Update Magnitude: 0.55254
Value Function Update Magnitude: 0.68959

Collected Steps per Second: 21,856.26916
Overall Steps per Second: 10,525.02307

Timestep Collection Time: 2.28841
Timestep Consumption Time: 2.46370
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.75210

Cumulative Model Updates: 67,254
Cumulative Timesteps: 560,975,588

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.55269
Policy Entropy: 3.31778
Value Function Loss: 0.00369

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.55638
Value Function Update Magnitude: 0.67440

Collected Steps per Second: 22,589.63064
Overall Steps per Second: 10,508.98467

Timestep Collection Time: 2.21429
Timestep Consumption Time: 2.54545
PPO Batch Consumption Time: 0.29805
Total Iteration Time: 4.75974

Cumulative Model Updates: 67,260
Cumulative Timesteps: 561,025,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 561025608...
Checkpoint 561025608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.02544
Policy Entropy: 3.33623
Value Function Loss: 0.00372

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08468
Policy Update Magnitude: 0.55931
Value Function Update Magnitude: 0.65216

Collected Steps per Second: 22,896.63707
Overall Steps per Second: 10,663.52278

Timestep Collection Time: 2.18373
Timestep Consumption Time: 2.50516
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.68888

Cumulative Model Updates: 67,266
Cumulative Timesteps: 561,075,608

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 791.17181
Policy Entropy: 3.33956
Value Function Loss: 0.00379

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08182
Policy Update Magnitude: 0.55246
Value Function Update Magnitude: 0.64298

Collected Steps per Second: 22,795.53473
Overall Steps per Second: 10,631.91887

Timestep Collection Time: 2.19455
Timestep Consumption Time: 2.51071
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.70527

Cumulative Model Updates: 67,272
Cumulative Timesteps: 561,125,634

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 561125634...
Checkpoint 561125634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,730.83931
Policy Entropy: 3.33995
Value Function Loss: 0.00390

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08982
Policy Update Magnitude: 0.54931
Value Function Update Magnitude: 0.63505

Collected Steps per Second: 22,550.45360
Overall Steps per Second: 10,560.10550

Timestep Collection Time: 2.21814
Timestep Consumption Time: 2.51856
PPO Batch Consumption Time: 0.29684
Total Iteration Time: 4.73670

Cumulative Model Updates: 67,278
Cumulative Timesteps: 561,175,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 747.92931
Policy Entropy: 3.33572
Value Function Loss: 0.00385

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10024
Policy Update Magnitude: 0.54863
Value Function Update Magnitude: 0.62256

Collected Steps per Second: 22,436.01048
Overall Steps per Second: 10,619.06584

Timestep Collection Time: 2.22856
Timestep Consumption Time: 2.47995
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.70851

Cumulative Model Updates: 67,284
Cumulative Timesteps: 561,225,654

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 561225654...
Checkpoint 561225654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.58833
Policy Entropy: 3.33077
Value Function Loss: 0.00377

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09157
Policy Update Magnitude: 0.54545
Value Function Update Magnitude: 0.60614

Collected Steps per Second: 22,389.23583
Overall Steps per Second: 10,508.02053

Timestep Collection Time: 2.23348
Timestep Consumption Time: 2.52536
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.75884

Cumulative Model Updates: 67,290
Cumulative Timesteps: 561,275,660

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 835.36451
Policy Entropy: 3.32561
Value Function Loss: 0.00370

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.07852
Policy Update Magnitude: 0.53967
Value Function Update Magnitude: 0.58793

Collected Steps per Second: 22,372.78281
Overall Steps per Second: 10,580.03581

Timestep Collection Time: 2.23531
Timestep Consumption Time: 2.49152
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.72683

Cumulative Model Updates: 67,296
Cumulative Timesteps: 561,325,670

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 561325670...
Checkpoint 561325670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.72809
Policy Entropy: 3.33610
Value Function Loss: 0.00367

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07596
Policy Update Magnitude: 0.54226
Value Function Update Magnitude: 0.59172

Collected Steps per Second: 22,456.42816
Overall Steps per Second: 10,572.17077

Timestep Collection Time: 2.22760
Timestep Consumption Time: 2.50407
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.73167

Cumulative Model Updates: 67,302
Cumulative Timesteps: 561,375,694

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.27508
Policy Entropy: 3.34951
Value Function Loss: 0.00367

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08891
Policy Update Magnitude: 0.54551
Value Function Update Magnitude: 0.60196

Collected Steps per Second: 22,934.98044
Overall Steps per Second: 10,718.94037

Timestep Collection Time: 2.18060
Timestep Consumption Time: 2.48516
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.66576

Cumulative Model Updates: 67,308
Cumulative Timesteps: 561,425,706

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 561425706...
Checkpoint 561425706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.86123
Policy Entropy: 3.34330
Value Function Loss: 0.00366

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08358
Policy Update Magnitude: 0.53906
Value Function Update Magnitude: 0.58634

Collected Steps per Second: 22,565.96666
Overall Steps per Second: 10,574.71875

Timestep Collection Time: 2.21590
Timestep Consumption Time: 2.51273
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.72864

Cumulative Model Updates: 67,314
Cumulative Timesteps: 561,475,710

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,759.75552
Policy Entropy: 3.31499
Value Function Loss: 0.00375

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.54077
Value Function Update Magnitude: 0.60413

Collected Steps per Second: 22,975.17856
Overall Steps per Second: 10,687.30745

Timestep Collection Time: 2.17635
Timestep Consumption Time: 2.50229
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.67863

Cumulative Model Updates: 67,320
Cumulative Timesteps: 561,525,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 561525712...
Checkpoint 561525712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 993.85933
Policy Entropy: 3.31369
Value Function Loss: 0.00377

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10837
Policy Update Magnitude: 0.53923
Value Function Update Magnitude: 0.61849

Collected Steps per Second: 22,718.06409
Overall Steps per Second: 10,676.17041

Timestep Collection Time: 2.20124
Timestep Consumption Time: 2.48283
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.68408

Cumulative Model Updates: 67,326
Cumulative Timesteps: 561,575,720

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 898.06261
Policy Entropy: 3.31960
Value Function Loss: 0.00389

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.54235
Value Function Update Magnitude: 0.61720

Collected Steps per Second: 23,054.82305
Overall Steps per Second: 10,694.96192

Timestep Collection Time: 2.16961
Timestep Consumption Time: 2.50736
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.67697

Cumulative Model Updates: 67,332
Cumulative Timesteps: 561,625,740

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 561625740...
Checkpoint 561625740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714.33893
Policy Entropy: 3.32931
Value Function Loss: 0.00381

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.54620
Value Function Update Magnitude: 0.64205

Collected Steps per Second: 23,017.69514
Overall Steps per Second: 10,657.87596

Timestep Collection Time: 2.17242
Timestep Consumption Time: 2.51933
PPO Batch Consumption Time: 0.29697
Total Iteration Time: 4.69174

Cumulative Model Updates: 67,338
Cumulative Timesteps: 561,675,744

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.89454
Policy Entropy: 3.31797
Value Function Loss: 0.00378

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08170
Policy Update Magnitude: 0.55463
Value Function Update Magnitude: 0.66607

Collected Steps per Second: 22,780.62724
Overall Steps per Second: 10,689.25685

Timestep Collection Time: 2.19599
Timestep Consumption Time: 2.48404
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.68003

Cumulative Model Updates: 67,344
Cumulative Timesteps: 561,725,770

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 561725770...
Checkpoint 561725770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 923.23745
Policy Entropy: 3.31956
Value Function Loss: 0.00397

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09461
Policy Update Magnitude: 0.56103
Value Function Update Magnitude: 0.66953

Collected Steps per Second: 22,571.42852
Overall Steps per Second: 10,760.56195

Timestep Collection Time: 2.21661
Timestep Consumption Time: 2.43296
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.64957

Cumulative Model Updates: 67,350
Cumulative Timesteps: 561,775,802

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565.23642
Policy Entropy: 3.31708
Value Function Loss: 0.00394

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09011
Policy Update Magnitude: 0.56411
Value Function Update Magnitude: 0.67079

Collected Steps per Second: 22,055.32684
Overall Steps per Second: 10,520.59732

Timestep Collection Time: 2.26811
Timestep Consumption Time: 2.48675
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.75486

Cumulative Model Updates: 67,356
Cumulative Timesteps: 561,825,826

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 561825826...
Checkpoint 561825826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,145.42977
Policy Entropy: 3.32336
Value Function Loss: 0.00370

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08269
Policy Update Magnitude: 0.56242
Value Function Update Magnitude: 0.65496

Collected Steps per Second: 22,375.87170
Overall Steps per Second: 10,626.26657

Timestep Collection Time: 2.23562
Timestep Consumption Time: 2.47196
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.70758

Cumulative Model Updates: 67,362
Cumulative Timesteps: 561,875,850

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 854.31657
Policy Entropy: 3.31596
Value Function Loss: 0.00379

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.55926
Value Function Update Magnitude: 0.64797

Collected Steps per Second: 22,705.96600
Overall Steps per Second: 10,640.86868

Timestep Collection Time: 2.20321
Timestep Consumption Time: 2.49810
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.70131

Cumulative Model Updates: 67,368
Cumulative Timesteps: 561,925,876

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 561925876...
Checkpoint 561925876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 861.89237
Policy Entropy: 3.31864
Value Function Loss: 0.00372

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08610
Policy Update Magnitude: 0.56054
Value Function Update Magnitude: 0.64355

Collected Steps per Second: 22,247.77744
Overall Steps per Second: 10,481.31835

Timestep Collection Time: 2.24760
Timestep Consumption Time: 2.52318
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.77077

Cumulative Model Updates: 67,374
Cumulative Timesteps: 561,975,880

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 821.02007
Policy Entropy: 3.31109
Value Function Loss: 0.00390

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07409
Policy Update Magnitude: 0.56832
Value Function Update Magnitude: 0.65702

Collected Steps per Second: 22,853.89890
Overall Steps per Second: 10,526.11774

Timestep Collection Time: 2.18851
Timestep Consumption Time: 2.56310
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.75161

Cumulative Model Updates: 67,380
Cumulative Timesteps: 562,025,896

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 562025896...
Checkpoint 562025896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 952.17461
Policy Entropy: 3.31530
Value Function Loss: 0.00380

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07660
Policy Update Magnitude: 0.56131
Value Function Update Magnitude: 0.66263

Collected Steps per Second: 22,641.55519
Overall Steps per Second: 10,525.40188

Timestep Collection Time: 2.21027
Timestep Consumption Time: 2.54432
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.75459

Cumulative Model Updates: 67,386
Cumulative Timesteps: 562,075,940

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 768.94841
Policy Entropy: 3.31068
Value Function Loss: 0.00405

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09119
Policy Update Magnitude: 0.55406
Value Function Update Magnitude: 0.65567

Collected Steps per Second: 22,868.43288
Overall Steps per Second: 10,598.61172

Timestep Collection Time: 2.18651
Timestep Consumption Time: 2.53128
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.71779

Cumulative Model Updates: 67,392
Cumulative Timesteps: 562,125,942

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 562125942...
Checkpoint 562125942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 743.24613
Policy Entropy: 3.31795
Value Function Loss: 0.00404

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08627
Policy Update Magnitude: 0.55814
Value Function Update Magnitude: 0.66572

Collected Steps per Second: 22,518.20390
Overall Steps per Second: 10,559.22892

Timestep Collection Time: 2.22220
Timestep Consumption Time: 2.51678
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.73898

Cumulative Model Updates: 67,398
Cumulative Timesteps: 562,175,982

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641.57046
Policy Entropy: 3.32040
Value Function Loss: 0.00411

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08475
Policy Update Magnitude: 0.56595
Value Function Update Magnitude: 0.68426

Collected Steps per Second: 22,534.01958
Overall Steps per Second: 10,540.39785

Timestep Collection Time: 2.21913
Timestep Consumption Time: 2.52509
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.74422

Cumulative Model Updates: 67,404
Cumulative Timesteps: 562,225,988

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 562225988...
Checkpoint 562225988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.94728
Policy Entropy: 3.31237
Value Function Loss: 0.00409

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10072
Policy Update Magnitude: 0.56313
Value Function Update Magnitude: 0.69704

Collected Steps per Second: 23,101.64423
Overall Steps per Second: 10,910.56515

Timestep Collection Time: 2.16504
Timestep Consumption Time: 2.41914
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.58418

Cumulative Model Updates: 67,410
Cumulative Timesteps: 562,276,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.79607
Policy Entropy: 3.29989
Value Function Loss: 0.00396

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10336
Policy Update Magnitude: 0.54992
Value Function Update Magnitude: 0.69374

Collected Steps per Second: 22,812.15864
Overall Steps per Second: 10,730.47535

Timestep Collection Time: 2.19252
Timestep Consumption Time: 2.46860
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.66112

Cumulative Model Updates: 67,416
Cumulative Timesteps: 562,326,020

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 562326020...
Checkpoint 562326020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.86743
Policy Entropy: 3.29511
Value Function Loss: 0.00375

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11502
Policy Update Magnitude: 0.54640
Value Function Update Magnitude: 0.67615

Collected Steps per Second: 22,358.32480
Overall Steps per Second: 10,599.51852

Timestep Collection Time: 2.23630
Timestep Consumption Time: 2.48089
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.71720

Cumulative Model Updates: 67,422
Cumulative Timesteps: 562,376,020

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.90085
Policy Entropy: 3.30021
Value Function Loss: 0.00375

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.11934
Policy Update Magnitude: 0.54783
Value Function Update Magnitude: 0.64968

Collected Steps per Second: 22,632.04667
Overall Steps per Second: 10,810.31617

Timestep Collection Time: 2.21005
Timestep Consumption Time: 2.41682
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.62688

Cumulative Model Updates: 67,428
Cumulative Timesteps: 562,426,038

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 562426038...
Checkpoint 562426038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578.60897
Policy Entropy: 3.29163
Value Function Loss: 0.00375

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11380
Policy Update Magnitude: 0.54493
Value Function Update Magnitude: 0.64008

Collected Steps per Second: 22,285.29960
Overall Steps per Second: 10,577.07482

Timestep Collection Time: 2.24444
Timestep Consumption Time: 2.48447
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.72891

Cumulative Model Updates: 67,434
Cumulative Timesteps: 562,476,056

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 852.26728
Policy Entropy: 3.29473
Value Function Loss: 0.00392

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.55034
Value Function Update Magnitude: 0.66388

Collected Steps per Second: 22,775.41787
Overall Steps per Second: 10,815.26545

Timestep Collection Time: 2.19596
Timestep Consumption Time: 2.42843
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.62439

Cumulative Model Updates: 67,440
Cumulative Timesteps: 562,526,070

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 562526070...
Checkpoint 562526070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,364.41115
Policy Entropy: 3.29897
Value Function Loss: 0.00388

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10451
Policy Update Magnitude: 0.55316
Value Function Update Magnitude: 0.65666

Collected Steps per Second: 22,090.14652
Overall Steps per Second: 10,661.96523

Timestep Collection Time: 2.26436
Timestep Consumption Time: 2.42708
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.69144

Cumulative Model Updates: 67,446
Cumulative Timesteps: 562,576,090

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 961.18182
Policy Entropy: 3.30267
Value Function Loss: 0.00391

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09340
Policy Update Magnitude: 0.55731
Value Function Update Magnitude: 0.65095

Collected Steps per Second: 22,799.91115
Overall Steps per Second: 10,646.82042

Timestep Collection Time: 2.19343
Timestep Consumption Time: 2.50375
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.69718

Cumulative Model Updates: 67,452
Cumulative Timesteps: 562,626,100

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 562626100...
Checkpoint 562626100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 873.96755
Policy Entropy: 3.31078
Value Function Loss: 0.00396

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08114
Policy Update Magnitude: 0.55613
Value Function Update Magnitude: 0.63832

Collected Steps per Second: 22,693.22275
Overall Steps per Second: 10,645.82101

Timestep Collection Time: 2.20445
Timestep Consumption Time: 2.49467
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.69912

Cumulative Model Updates: 67,458
Cumulative Timesteps: 562,676,126

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.22083
Policy Entropy: 3.30344
Value Function Loss: 0.00392

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10022
Policy Update Magnitude: 0.55353
Value Function Update Magnitude: 0.64187

Collected Steps per Second: 23,051.06053
Overall Steps per Second: 10,764.77575

Timestep Collection Time: 2.17005
Timestep Consumption Time: 2.47677
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.64682

Cumulative Model Updates: 67,464
Cumulative Timesteps: 562,726,148

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 562726148...
Checkpoint 562726148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564.03619
Policy Entropy: 3.30535
Value Function Loss: 0.00383

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09256
Policy Update Magnitude: 0.55040
Value Function Update Magnitude: 0.63400

Collected Steps per Second: 22,383.26634
Overall Steps per Second: 10,663.87233

Timestep Collection Time: 2.23381
Timestep Consumption Time: 2.45492
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.68873

Cumulative Model Updates: 67,470
Cumulative Timesteps: 562,776,148

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.91161
Policy Entropy: 3.31637
Value Function Loss: 0.00390

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09393
Policy Update Magnitude: 0.55030
Value Function Update Magnitude: 0.64283

Collected Steps per Second: 22,417.25334
Overall Steps per Second: 10,589.07522

Timestep Collection Time: 2.23096
Timestep Consumption Time: 2.49202
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.72298

Cumulative Model Updates: 67,476
Cumulative Timesteps: 562,826,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 562826160...
Checkpoint 562826160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 786.35118
Policy Entropy: 3.33025
Value Function Loss: 0.00364

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.54622
Value Function Update Magnitude: 0.64511

Collected Steps per Second: 22,385.97839
Overall Steps per Second: 10,534.98826

Timestep Collection Time: 2.23381
Timestep Consumption Time: 2.51285
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.74666

Cumulative Model Updates: 67,482
Cumulative Timesteps: 562,876,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.92096
Policy Entropy: 3.33088
Value Function Loss: 0.00370

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09777
Policy Update Magnitude: 0.53488
Value Function Update Magnitude: 0.64381

Collected Steps per Second: 22,379.98970
Overall Steps per Second: 10,566.34396

Timestep Collection Time: 2.23557
Timestep Consumption Time: 2.49947
PPO Batch Consumption Time: 0.29604
Total Iteration Time: 4.73503

Cumulative Model Updates: 67,488
Cumulative Timesteps: 562,926,198

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 562926198...
Checkpoint 562926198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,620.16885
Policy Entropy: 3.33367
Value Function Loss: 0.00353

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09725
Policy Update Magnitude: 0.52816
Value Function Update Magnitude: 0.64869

Collected Steps per Second: 22,126.51794
Overall Steps per Second: 10,567.34534

Timestep Collection Time: 2.26118
Timestep Consumption Time: 2.47341
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.73459

Cumulative Model Updates: 67,494
Cumulative Timesteps: 562,976,230

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,393.52136
Policy Entropy: 3.32776
Value Function Loss: 0.00376

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08245
Policy Update Magnitude: 0.53948
Value Function Update Magnitude: 0.64581

Collected Steps per Second: 22,536.23031
Overall Steps per Second: 10,547.29380

Timestep Collection Time: 2.22025
Timestep Consumption Time: 2.52372
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.74397

Cumulative Model Updates: 67,500
Cumulative Timesteps: 563,026,266

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 563026266...
Checkpoint 563026266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.95349
Policy Entropy: 3.33277
Value Function Loss: 0.00380

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09530
Policy Update Magnitude: 0.55426
Value Function Update Magnitude: 0.65041

Collected Steps per Second: 22,659.21731
Overall Steps per Second: 10,622.64290

Timestep Collection Time: 2.20723
Timestep Consumption Time: 2.50102
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.70824

Cumulative Model Updates: 67,506
Cumulative Timesteps: 563,076,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,659.62414
Policy Entropy: 3.32415
Value Function Loss: 0.00389

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09456
Policy Update Magnitude: 0.54603
Value Function Update Magnitude: 0.65234

Collected Steps per Second: 22,494.88247
Overall Steps per Second: 10,760.03652

Timestep Collection Time: 2.22397
Timestep Consumption Time: 2.42545
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.64943

Cumulative Model Updates: 67,512
Cumulative Timesteps: 563,126,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 563126308...
Checkpoint 563126308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.08434
Policy Entropy: 3.32602
Value Function Loss: 0.00369

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08947
Policy Update Magnitude: 0.53565
Value Function Update Magnitude: 0.64096

Collected Steps per Second: 22,160.95527
Overall Steps per Second: 10,676.60943

Timestep Collection Time: 2.25839
Timestep Consumption Time: 2.42924
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.68763

Cumulative Model Updates: 67,518
Cumulative Timesteps: 563,176,356

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.11663
Policy Entropy: 3.34328
Value Function Loss: 0.00357

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08521
Policy Update Magnitude: 0.53097
Value Function Update Magnitude: 0.62853

Collected Steps per Second: 22,993.78787
Overall Steps per Second: 10,846.68307

Timestep Collection Time: 2.17563
Timestep Consumption Time: 2.43647
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.61210

Cumulative Model Updates: 67,524
Cumulative Timesteps: 563,226,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 563226382...
Checkpoint 563226382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.33502
Policy Entropy: 3.36691
Value Function Loss: 0.00340

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.52238
Value Function Update Magnitude: 0.61271

Collected Steps per Second: 22,490.56325
Overall Steps per Second: 10,791.32795

Timestep Collection Time: 2.22404
Timestep Consumption Time: 2.41116
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.63520

Cumulative Model Updates: 67,530
Cumulative Timesteps: 563,276,402

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 924.85912
Policy Entropy: 3.35355
Value Function Loss: 0.00351

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09366
Policy Update Magnitude: 0.51155
Value Function Update Magnitude: 0.60584

Collected Steps per Second: 22,488.13464
Overall Steps per Second: 10,750.62306

Timestep Collection Time: 2.22357
Timestep Consumption Time: 2.42769
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.65127

Cumulative Model Updates: 67,536
Cumulative Timesteps: 563,326,406

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 563326406...
Checkpoint 563326406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,668.10434
Policy Entropy: 3.34527
Value Function Loss: 0.00354

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.52211
Value Function Update Magnitude: 0.62185

Collected Steps per Second: 21,756.78209
Overall Steps per Second: 10,487.40457

Timestep Collection Time: 2.29933
Timestep Consumption Time: 2.47077
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.77010

Cumulative Model Updates: 67,542
Cumulative Timesteps: 563,376,432

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.91129
Policy Entropy: 3.33193
Value Function Loss: 0.00354

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.52692
Value Function Update Magnitude: 0.61865

Collected Steps per Second: 22,325.03503
Overall Steps per Second: 10,702.42365

Timestep Collection Time: 2.23991
Timestep Consumption Time: 2.43249
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.67240

Cumulative Model Updates: 67,548
Cumulative Timesteps: 563,426,438

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 563426438...
Checkpoint 563426438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.13009
Policy Entropy: 3.34364
Value Function Loss: 0.00340

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.52385
Value Function Update Magnitude: 0.60656

Collected Steps per Second: 22,446.87047
Overall Steps per Second: 10,631.46158

Timestep Collection Time: 2.22784
Timestep Consumption Time: 2.47594
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.70377

Cumulative Model Updates: 67,554
Cumulative Timesteps: 563,476,446

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.91596
Policy Entropy: 3.33608
Value Function Loss: 0.00346

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10280
Policy Update Magnitude: 0.51075
Value Function Update Magnitude: 0.60870

Collected Steps per Second: 22,219.66085
Overall Steps per Second: 10,512.21120

Timestep Collection Time: 2.25053
Timestep Consumption Time: 2.50641
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.75694

Cumulative Model Updates: 67,560
Cumulative Timesteps: 563,526,452

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 563526452...
Checkpoint 563526452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445.03485
Policy Entropy: 3.32927
Value Function Loss: 0.00343

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.51809
Value Function Update Magnitude: 0.61549

Collected Steps per Second: 22,479.90833
Overall Steps per Second: 10,585.72952

Timestep Collection Time: 2.22465
Timestep Consumption Time: 2.49963
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.72428

Cumulative Model Updates: 67,566
Cumulative Timesteps: 563,576,462

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,422.94939
Policy Entropy: 3.32351
Value Function Loss: 0.00361

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09166
Policy Update Magnitude: 0.52263
Value Function Update Magnitude: 0.60820

Collected Steps per Second: 22,859.87082
Overall Steps per Second: 10,839.17978

Timestep Collection Time: 2.18855
Timestep Consumption Time: 2.42711
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.61566

Cumulative Model Updates: 67,572
Cumulative Timesteps: 563,626,492

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 563626492...
Checkpoint 563626492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.64032
Policy Entropy: 3.32487
Value Function Loss: 0.00343

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.06938
Policy Update Magnitude: 0.52237
Value Function Update Magnitude: 0.60945

Collected Steps per Second: 22,741.08109
Overall Steps per Second: 10,693.30947

Timestep Collection Time: 2.20025
Timestep Consumption Time: 2.47894
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.67919

Cumulative Model Updates: 67,578
Cumulative Timesteps: 563,676,528

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801.60686
Policy Entropy: 3.32387
Value Function Loss: 0.00340

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07761
Policy Update Magnitude: 0.51879
Value Function Update Magnitude: 0.58848

Collected Steps per Second: 23,085.28789
Overall Steps per Second: 10,890.92809

Timestep Collection Time: 2.16640
Timestep Consumption Time: 2.42568
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.59208

Cumulative Model Updates: 67,584
Cumulative Timesteps: 563,726,540

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 563726540...
Checkpoint 563726540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 896.41427
Policy Entropy: 3.30887
Value Function Loss: 0.00331

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09420
Policy Update Magnitude: 0.50922
Value Function Update Magnitude: 0.59174

Collected Steps per Second: 22,445.20249
Overall Steps per Second: 10,690.80118

Timestep Collection Time: 2.22863
Timestep Consumption Time: 2.45035
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.67898

Cumulative Model Updates: 67,590
Cumulative Timesteps: 563,776,562

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,569.45933
Policy Entropy: 3.32111
Value Function Loss: 0.00338

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.50856
Value Function Update Magnitude: 0.60922

Collected Steps per Second: 22,929.55996
Overall Steps per Second: 10,835.27307

Timestep Collection Time: 2.18190
Timestep Consumption Time: 2.43543
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.61733

Cumulative Model Updates: 67,596
Cumulative Timesteps: 563,826,592

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 563826592...
Checkpoint 563826592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.94594
Policy Entropy: 3.31712
Value Function Loss: 0.00343

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07986
Policy Update Magnitude: 0.51520
Value Function Update Magnitude: 0.60935

Collected Steps per Second: 22,126.91314
Overall Steps per Second: 10,675.68520

Timestep Collection Time: 2.26051
Timestep Consumption Time: 2.42472
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.68523

Cumulative Model Updates: 67,602
Cumulative Timesteps: 563,876,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 971.66543
Policy Entropy: 3.31450
Value Function Loss: 0.00341

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07575
Policy Update Magnitude: 0.51959
Value Function Update Magnitude: 0.62301

Collected Steps per Second: 22,171.09182
Overall Steps per Second: 10,519.13339

Timestep Collection Time: 2.25528
Timestep Consumption Time: 2.49815
PPO Batch Consumption Time: 0.29724
Total Iteration Time: 4.75343

Cumulative Model Updates: 67,608
Cumulative Timesteps: 563,926,612

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 563926612...
Checkpoint 563926612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288.11305
Policy Entropy: 3.31259
Value Function Loss: 0.00364

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08003
Policy Update Magnitude: 0.52471
Value Function Update Magnitude: 0.66768

Collected Steps per Second: 22,087.73630
Overall Steps per Second: 10,630.63509

Timestep Collection Time: 2.26406
Timestep Consumption Time: 2.44008
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.70414

Cumulative Model Updates: 67,614
Cumulative Timesteps: 563,976,620

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,830.29592
Policy Entropy: 3.32136
Value Function Loss: 0.00372

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08143
Policy Update Magnitude: 0.53649
Value Function Update Magnitude: 0.68504

Collected Steps per Second: 22,537.85207
Overall Steps per Second: 10,757.70973

Timestep Collection Time: 2.21955
Timestep Consumption Time: 2.43051
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.65006

Cumulative Model Updates: 67,620
Cumulative Timesteps: 564,026,644

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 564026644...
Checkpoint 564026644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650.50988
Policy Entropy: 3.32666
Value Function Loss: 0.00390

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07218
Policy Update Magnitude: 0.54187
Value Function Update Magnitude: 0.67246

Collected Steps per Second: 22,281.75268
Overall Steps per Second: 10,713.73955

Timestep Collection Time: 2.24498
Timestep Consumption Time: 2.42398
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.66896

Cumulative Model Updates: 67,626
Cumulative Timesteps: 564,076,666

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.54588
Policy Entropy: 3.33708
Value Function Loss: 0.00363

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07818
Policy Update Magnitude: 0.54452
Value Function Update Magnitude: 0.69837

Collected Steps per Second: 22,682.52996
Overall Steps per Second: 10,561.75038

Timestep Collection Time: 2.20549
Timestep Consumption Time: 2.53104
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.73653

Cumulative Model Updates: 67,632
Cumulative Timesteps: 564,126,692

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 564126692...
Checkpoint 564126692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.20326
Policy Entropy: 3.33842
Value Function Loss: 0.00358

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09895
Policy Update Magnitude: 0.53475
Value Function Update Magnitude: 0.67919

Collected Steps per Second: 22,495.28327
Overall Steps per Second: 10,577.60831

Timestep Collection Time: 2.22304
Timestep Consumption Time: 2.50468
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.72772

Cumulative Model Updates: 67,638
Cumulative Timesteps: 564,176,700

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.33007
Policy Entropy: 3.34045
Value Function Loss: 0.00364

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09234
Policy Update Magnitude: 0.52833
Value Function Update Magnitude: 0.64068

Collected Steps per Second: 23,011.15932
Overall Steps per Second: 10,849.64628

Timestep Collection Time: 2.17408
Timestep Consumption Time: 2.43695
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.61103

Cumulative Model Updates: 67,644
Cumulative Timesteps: 564,226,728

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 564226728...
Checkpoint 564226728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.99485
Policy Entropy: 3.33770
Value Function Loss: 0.00371

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08138
Policy Update Magnitude: 0.53189
Value Function Update Magnitude: 0.63527

Collected Steps per Second: 22,625.58889
Overall Steps per Second: 10,672.79427

Timestep Collection Time: 2.21051
Timestep Consumption Time: 2.47561
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.68612

Cumulative Model Updates: 67,650
Cumulative Timesteps: 564,276,742

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.52915
Policy Entropy: 3.31879
Value Function Loss: 0.00364

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07909
Policy Update Magnitude: 0.53716
Value Function Update Magnitude: 0.64588

Collected Steps per Second: 23,050.17392
Overall Steps per Second: 10,866.30836

Timestep Collection Time: 2.16979
Timestep Consumption Time: 2.43288
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.60267

Cumulative Model Updates: 67,656
Cumulative Timesteps: 564,326,756

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 564326756...
Checkpoint 564326756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.27691
Policy Entropy: 3.31017
Value Function Loss: 0.00355

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08145
Policy Update Magnitude: 0.53736
Value Function Update Magnitude: 0.64951

Collected Steps per Second: 22,272.53902
Overall Steps per Second: 10,743.09554

Timestep Collection Time: 2.24581
Timestep Consumption Time: 2.41020
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.65601

Cumulative Model Updates: 67,662
Cumulative Timesteps: 564,376,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 908.82134
Policy Entropy: 3.30861
Value Function Loss: 0.00368

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.53666
Value Function Update Magnitude: 0.66538

Collected Steps per Second: 23,074.38535
Overall Steps per Second: 10,860.50261

Timestep Collection Time: 2.16821
Timestep Consumption Time: 2.43840
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.60660

Cumulative Model Updates: 67,668
Cumulative Timesteps: 564,426,806

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 564426806...
Checkpoint 564426806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.01280
Policy Entropy: 3.30131
Value Function Loss: 0.00372

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11456
Policy Update Magnitude: 0.53773
Value Function Update Magnitude: 0.66653

Collected Steps per Second: 22,119.72631
Overall Steps per Second: 10,699.12167

Timestep Collection Time: 2.26097
Timestep Consumption Time: 2.41343
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.67440

Cumulative Model Updates: 67,674
Cumulative Timesteps: 564,476,818

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 794.58518
Policy Entropy: 3.31123
Value Function Loss: 0.00392

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.11888
Policy Update Magnitude: 0.54692
Value Function Update Magnitude: 0.68227

Collected Steps per Second: 22,364.45674
Overall Steps per Second: 10,609.13637

Timestep Collection Time: 2.23587
Timestep Consumption Time: 2.47743
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.71330

Cumulative Model Updates: 67,680
Cumulative Timesteps: 564,526,822

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 564526822...
Checkpoint 564526822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.18684
Policy Entropy: 3.32128
Value Function Loss: 0.00392

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10751
Policy Update Magnitude: 0.55041
Value Function Update Magnitude: 0.69038

Collected Steps per Second: 22,318.43037
Overall Steps per Second: 10,615.34444

Timestep Collection Time: 2.24093
Timestep Consumption Time: 2.47055
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.71148

Cumulative Model Updates: 67,686
Cumulative Timesteps: 564,576,836

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.46942
Policy Entropy: 3.31018
Value Function Loss: 0.00388

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.55308
Value Function Update Magnitude: 0.70085

Collected Steps per Second: 22,632.90384
Overall Steps per Second: 10,784.76708

Timestep Collection Time: 2.21023
Timestep Consumption Time: 2.42816
PPO Batch Consumption Time: 0.28168
Total Iteration Time: 4.63839

Cumulative Model Updates: 67,692
Cumulative Timesteps: 564,626,860

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 564626860...
Checkpoint 564626860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.55930
Policy Entropy: 3.31198
Value Function Loss: 0.00365

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08450
Policy Update Magnitude: 0.54746
Value Function Update Magnitude: 0.69985

Collected Steps per Second: 22,274.74559
Overall Steps per Second: 10,577.13469

Timestep Collection Time: 2.24505
Timestep Consumption Time: 2.48288
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.72793

Cumulative Model Updates: 67,698
Cumulative Timesteps: 564,676,868

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,377.17684
Policy Entropy: 3.30395
Value Function Loss: 0.00357

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08076
Policy Update Magnitude: 0.54931
Value Function Update Magnitude: 0.66369

Collected Steps per Second: 22,955.91610
Overall Steps per Second: 10,869.32383

Timestep Collection Time: 2.17896
Timestep Consumption Time: 2.42298
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.60194

Cumulative Model Updates: 67,704
Cumulative Timesteps: 564,726,888

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 564726888...
Checkpoint 564726888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.80938
Policy Entropy: 3.31536
Value Function Loss: 0.00347

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08487
Policy Update Magnitude: 0.54197
Value Function Update Magnitude: 0.63818

Collected Steps per Second: 21,733.65618
Overall Steps per Second: 10,380.50343

Timestep Collection Time: 2.30168
Timestep Consumption Time: 2.51735
PPO Batch Consumption Time: 0.29632
Total Iteration Time: 4.81903

Cumulative Model Updates: 67,710
Cumulative Timesteps: 564,776,912

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.66775
Policy Entropy: 3.30901
Value Function Loss: 0.00351

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.53203
Value Function Update Magnitude: 0.63059

Collected Steps per Second: 22,516.59951
Overall Steps per Second: 10,719.76695

Timestep Collection Time: 2.22183
Timestep Consumption Time: 2.44506
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.66689

Cumulative Model Updates: 67,716
Cumulative Timesteps: 564,826,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 564826940...
Checkpoint 564826940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.23503
Policy Entropy: 3.32088
Value Function Loss: 0.00348

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09020
Policy Update Magnitude: 0.52575
Value Function Update Magnitude: 0.61581

Collected Steps per Second: 22,102.52586
Overall Steps per Second: 10,645.43806

Timestep Collection Time: 2.26282
Timestep Consumption Time: 2.43534
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.69816

Cumulative Model Updates: 67,722
Cumulative Timesteps: 564,876,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,578.03377
Policy Entropy: 3.32375
Value Function Loss: 0.00369

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10295
Policy Update Magnitude: 0.52670
Value Function Update Magnitude: 0.60441

Collected Steps per Second: 23,045.35807
Overall Steps per Second: 10,746.26681

Timestep Collection Time: 2.16981
Timestep Consumption Time: 2.48334
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.65315

Cumulative Model Updates: 67,728
Cumulative Timesteps: 564,926,958

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 564926958...
Checkpoint 564926958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 779.62078
Policy Entropy: 3.33074
Value Function Loss: 0.00379

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.53473
Value Function Update Magnitude: 0.62414

Collected Steps per Second: 22,808.44260
Overall Steps per Second: 10,851.64781

Timestep Collection Time: 2.19296
Timestep Consumption Time: 2.41629
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.60925

Cumulative Model Updates: 67,734
Cumulative Timesteps: 564,976,976

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.91693
Policy Entropy: 3.32797
Value Function Loss: 0.00392

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08450
Policy Update Magnitude: 0.55505
Value Function Update Magnitude: 0.64059

Collected Steps per Second: 23,005.74274
Overall Steps per Second: 10,865.77018

Timestep Collection Time: 2.17415
Timestep Consumption Time: 2.42911
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.60326

Cumulative Model Updates: 67,740
Cumulative Timesteps: 565,026,994

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 565026994...
Checkpoint 565026994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.88134
Policy Entropy: 3.32810
Value Function Loss: 0.00394

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07617
Policy Update Magnitude: 0.55735
Value Function Update Magnitude: 0.63627

Collected Steps per Second: 22,082.27101
Overall Steps per Second: 10,664.73667

Timestep Collection Time: 2.26507
Timestep Consumption Time: 2.42496
PPO Batch Consumption Time: 0.28190
Total Iteration Time: 4.69004

Cumulative Model Updates: 67,746
Cumulative Timesteps: 565,077,012

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 970.04926
Policy Entropy: 3.33057
Value Function Loss: 0.00407

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07274
Policy Update Magnitude: 0.55536
Value Function Update Magnitude: 0.63036

Collected Steps per Second: 22,912.49976
Overall Steps per Second: 10,642.14689

Timestep Collection Time: 2.18352
Timestep Consumption Time: 2.51759
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.70112

Cumulative Model Updates: 67,752
Cumulative Timesteps: 565,127,042

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 565127042...
Checkpoint 565127042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.52392
Policy Entropy: 3.32434
Value Function Loss: 0.00391

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08334
Policy Update Magnitude: 0.56131
Value Function Update Magnitude: 0.62628

Collected Steps per Second: 22,291.89566
Overall Steps per Second: 10,493.47375

Timestep Collection Time: 2.24386
Timestep Consumption Time: 2.52291
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.76677

Cumulative Model Updates: 67,758
Cumulative Timesteps: 565,177,062

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.34449
Policy Entropy: 3.32510
Value Function Loss: 0.00386

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08227
Policy Update Magnitude: 0.56826
Value Function Update Magnitude: 0.64440

Collected Steps per Second: 22,311.80692
Overall Steps per Second: 10,552.66090

Timestep Collection Time: 2.24150
Timestep Consumption Time: 2.49777
PPO Batch Consumption Time: 0.29593
Total Iteration Time: 4.73928

Cumulative Model Updates: 67,764
Cumulative Timesteps: 565,227,074

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 565227074...
Checkpoint 565227074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 908.64080
Policy Entropy: 3.33006
Value Function Loss: 0.00367

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09201
Policy Update Magnitude: 0.56718
Value Function Update Magnitude: 0.65209

Collected Steps per Second: 22,393.64318
Overall Steps per Second: 10,585.60529

Timestep Collection Time: 2.23287
Timestep Consumption Time: 2.49072
PPO Batch Consumption Time: 0.29753
Total Iteration Time: 4.72358

Cumulative Model Updates: 67,770
Cumulative Timesteps: 565,277,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.06947
Policy Entropy: 3.31214
Value Function Loss: 0.00389

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08413
Policy Update Magnitude: 0.56183
Value Function Update Magnitude: 0.66577

Collected Steps per Second: 22,555.08273
Overall Steps per Second: 10,803.07042

Timestep Collection Time: 2.21786
Timestep Consumption Time: 2.41268
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.63054

Cumulative Model Updates: 67,776
Cumulative Timesteps: 565,327,100

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 565327100...
Checkpoint 565327100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 858.82012
Policy Entropy: 3.30478
Value Function Loss: 0.00387

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.56842
Value Function Update Magnitude: 0.69548

Collected Steps per Second: 22,266.99231
Overall Steps per Second: 10,716.01063

Timestep Collection Time: 2.24575
Timestep Consumption Time: 2.42073
PPO Batch Consumption Time: 0.28151
Total Iteration Time: 4.66648

Cumulative Model Updates: 67,782
Cumulative Timesteps: 565,377,106

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.68807
Policy Entropy: 3.28918
Value Function Loss: 0.00394

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09973
Policy Update Magnitude: 0.56295
Value Function Update Magnitude: 0.70183

Collected Steps per Second: 22,862.97916
Overall Steps per Second: 10,807.87587

Timestep Collection Time: 2.18808
Timestep Consumption Time: 2.44058
PPO Batch Consumption Time: 0.28193
Total Iteration Time: 4.62866

Cumulative Model Updates: 67,788
Cumulative Timesteps: 565,427,132

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 565427132...
Checkpoint 565427132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.51727
Policy Entropy: 3.29927
Value Function Loss: 0.00388

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12468
Policy Update Magnitude: 0.55336
Value Function Update Magnitude: 0.68889

Collected Steps per Second: 22,617.44429
Overall Steps per Second: 10,734.18397

Timestep Collection Time: 2.21095
Timestep Consumption Time: 2.44763
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.65857

Cumulative Model Updates: 67,794
Cumulative Timesteps: 565,477,138

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.27425
Policy Entropy: 3.31996
Value Function Loss: 0.00372

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10417
Policy Update Magnitude: 0.53766
Value Function Update Magnitude: 0.68373

Collected Steps per Second: 22,675.55188
Overall Steps per Second: 10,627.12671

Timestep Collection Time: 2.20537
Timestep Consumption Time: 2.50032
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.70569

Cumulative Model Updates: 67,800
Cumulative Timesteps: 565,527,146

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 565527146...
Checkpoint 565527146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472.84801
Policy Entropy: 3.33108
Value Function Loss: 0.00359

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10063
Policy Update Magnitude: 0.53096
Value Function Update Magnitude: 0.67421

Collected Steps per Second: 22,637.58404
Overall Steps per Second: 10,812.27374

Timestep Collection Time: 2.20951
Timestep Consumption Time: 2.41653
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.62604

Cumulative Model Updates: 67,806
Cumulative Timesteps: 565,577,164

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 785.17200
Policy Entropy: 3.36192
Value Function Loss: 0.00345

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.52357
Value Function Update Magnitude: 0.65532

Collected Steps per Second: 22,833.75785
Overall Steps per Second: 10,738.93573

Timestep Collection Time: 2.18983
Timestep Consumption Time: 2.46631
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.65614

Cumulative Model Updates: 67,812
Cumulative Timesteps: 565,627,166

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 565627166...
Checkpoint 565627166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 732.05295
Policy Entropy: 3.34591
Value Function Loss: 0.00351

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09393
Policy Update Magnitude: 0.52289
Value Function Update Magnitude: 0.65188

Collected Steps per Second: 22,556.29911
Overall Steps per Second: 10,679.87125

Timestep Collection Time: 2.21801
Timestep Consumption Time: 2.46651
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.68451

Cumulative Model Updates: 67,818
Cumulative Timesteps: 565,677,196

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.51857
Policy Entropy: 3.33367
Value Function Loss: 0.00362

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08465
Policy Update Magnitude: 0.53723
Value Function Update Magnitude: 0.67346

Collected Steps per Second: 22,370.99650
Overall Steps per Second: 10,677.33891

Timestep Collection Time: 2.23620
Timestep Consumption Time: 2.44905
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.68525

Cumulative Model Updates: 67,824
Cumulative Timesteps: 565,727,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 565727222...
Checkpoint 565727222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,476.29599
Policy Entropy: 3.33196
Value Function Loss: 0.00358

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07854
Policy Update Magnitude: 0.55068
Value Function Update Magnitude: 0.68562

Collected Steps per Second: 22,170.22511
Overall Steps per Second: 10,661.11922

Timestep Collection Time: 2.25564
Timestep Consumption Time: 2.43505
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.69069

Cumulative Model Updates: 67,830
Cumulative Timesteps: 565,777,230

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.96888
Policy Entropy: 3.34053
Value Function Loss: 0.00372

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08289
Policy Update Magnitude: 0.54544
Value Function Update Magnitude: 0.67881

Collected Steps per Second: 22,508.02194
Overall Steps per Second: 10,774.54663

Timestep Collection Time: 2.22187
Timestep Consumption Time: 2.41962
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.64149

Cumulative Model Updates: 67,836
Cumulative Timesteps: 565,827,240

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 565827240...
Checkpoint 565827240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.05285
Policy Entropy: 3.32747
Value Function Loss: 0.00371

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07590
Policy Update Magnitude: 0.54172
Value Function Update Magnitude: 0.68034

Collected Steps per Second: 22,447.34998
Overall Steps per Second: 10,747.50768

Timestep Collection Time: 2.22815
Timestep Consumption Time: 2.42558
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.65373

Cumulative Model Updates: 67,842
Cumulative Timesteps: 565,877,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.56739
Policy Entropy: 3.32061
Value Function Loss: 0.00378

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.54367
Value Function Update Magnitude: 0.67753

Collected Steps per Second: 22,929.74492
Overall Steps per Second: 10,696.44367

Timestep Collection Time: 2.18188
Timestep Consumption Time: 2.49537
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.67726

Cumulative Model Updates: 67,848
Cumulative Timesteps: 565,927,286

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 565927286...
Checkpoint 565927286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.37670
Policy Entropy: 3.32803
Value Function Loss: 0.00367

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07335
Policy Update Magnitude: 0.54607
Value Function Update Magnitude: 0.67185

Collected Steps per Second: 22,812.50335
Overall Steps per Second: 10,792.88226

Timestep Collection Time: 2.19178
Timestep Consumption Time: 2.44090
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.63268

Cumulative Model Updates: 67,854
Cumulative Timesteps: 565,977,286

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724.98847
Policy Entropy: 3.33631
Value Function Loss: 0.00362

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07590
Policy Update Magnitude: 0.54252
Value Function Update Magnitude: 0.66750

Collected Steps per Second: 22,943.28721
Overall Steps per Second: 10,877.44191

Timestep Collection Time: 2.17981
Timestep Consumption Time: 2.41796
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.59777

Cumulative Model Updates: 67,860
Cumulative Timesteps: 566,027,298

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 566027298...
Checkpoint 566027298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564.09622
Policy Entropy: 3.34011
Value Function Loss: 0.00370

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08053
Policy Update Magnitude: 0.53707
Value Function Update Magnitude: 0.65895

Collected Steps per Second: 23,017.69912
Overall Steps per Second: 10,689.32081

Timestep Collection Time: 2.17346
Timestep Consumption Time: 2.50673
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.68019

Cumulative Model Updates: 67,866
Cumulative Timesteps: 566,077,326

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 897.58377
Policy Entropy: 3.32638
Value Function Loss: 0.00375

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09386
Policy Update Magnitude: 0.53883
Value Function Update Magnitude: 0.67093

Collected Steps per Second: 23,084.31888
Overall Steps per Second: 10,885.95690

Timestep Collection Time: 2.16641
Timestep Consumption Time: 2.42759
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.59399

Cumulative Model Updates: 67,872
Cumulative Timesteps: 566,127,336

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 566127336...
Checkpoint 566127336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.54808
Policy Entropy: 3.33478
Value Function Loss: 0.00394

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.55134
Value Function Update Magnitude: 0.68350

Collected Steps per Second: 22,457.87487
Overall Steps per Second: 10,658.41584

Timestep Collection Time: 2.22746
Timestep Consumption Time: 2.46592
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.69338

Cumulative Model Updates: 67,878
Cumulative Timesteps: 566,177,360

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 917.46668
Policy Entropy: 3.34606
Value Function Loss: 0.00380

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09433
Policy Update Magnitude: 0.55879
Value Function Update Magnitude: 0.67931

Collected Steps per Second: 22,558.98196
Overall Steps per Second: 10,633.91356

Timestep Collection Time: 2.21677
Timestep Consumption Time: 2.48592
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.70269

Cumulative Model Updates: 67,884
Cumulative Timesteps: 566,227,368

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 566227368...
Checkpoint 566227368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.05361
Policy Entropy: 3.34697
Value Function Loss: 0.00390

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08688
Policy Update Magnitude: 0.55579
Value Function Update Magnitude: 0.66251

Collected Steps per Second: 22,493.24220
Overall Steps per Second: 10,669.23683

Timestep Collection Time: 2.22369
Timestep Consumption Time: 2.46437
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.68806

Cumulative Model Updates: 67,890
Cumulative Timesteps: 566,277,386

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.64992
Policy Entropy: 3.34920
Value Function Loss: 0.00405

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08676
Policy Update Magnitude: 0.55562
Value Function Update Magnitude: 0.67799

Collected Steps per Second: 22,356.84769
Overall Steps per Second: 10,699.06651

Timestep Collection Time: 2.23699
Timestep Consumption Time: 2.43744
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.67443

Cumulative Model Updates: 67,896
Cumulative Timesteps: 566,327,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 566327398...
Checkpoint 566327398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.37787
Policy Entropy: 3.34976
Value Function Loss: 0.00415

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07238
Policy Update Magnitude: 0.57290
Value Function Update Magnitude: 0.73664

Collected Steps per Second: 22,225.12572
Overall Steps per Second: 10,717.82304

Timestep Collection Time: 2.25016
Timestep Consumption Time: 2.41590
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.66606

Cumulative Model Updates: 67,902
Cumulative Timesteps: 566,377,408

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,563.71153
Policy Entropy: 3.34444
Value Function Loss: 0.00402

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08200
Policy Update Magnitude: 0.57867
Value Function Update Magnitude: 0.75148

Collected Steps per Second: 22,927.90503
Overall Steps per Second: 10,826.78355

Timestep Collection Time: 2.18092
Timestep Consumption Time: 2.43762
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.61855

Cumulative Model Updates: 67,908
Cumulative Timesteps: 566,427,412

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 566427412...
Checkpoint 566427412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.97754
Policy Entropy: 3.34298
Value Function Loss: 0.00387

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07614
Policy Update Magnitude: 0.57606
Value Function Update Magnitude: 0.72934

Collected Steps per Second: 22,901.90170
Overall Steps per Second: 10,652.26806

Timestep Collection Time: 2.18410
Timestep Consumption Time: 2.51162
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.69571

Cumulative Model Updates: 67,914
Cumulative Timesteps: 566,477,432

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 778.77242
Policy Entropy: 3.34130
Value Function Loss: 0.00396

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.56285
Value Function Update Magnitude: 0.69835

Collected Steps per Second: 21,888.81376
Overall Steps per Second: 10,486.82462

Timestep Collection Time: 2.28427
Timestep Consumption Time: 2.48362
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.76789

Cumulative Model Updates: 67,920
Cumulative Timesteps: 566,527,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 566527432...
Checkpoint 566527432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.45576
Policy Entropy: 3.34053
Value Function Loss: 0.00387

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08588
Policy Update Magnitude: 0.56516
Value Function Update Magnitude: 0.68130

Collected Steps per Second: 22,684.54700
Overall Steps per Second: 10,622.47797

Timestep Collection Time: 2.20476
Timestep Consumption Time: 2.50356
PPO Batch Consumption Time: 0.29704
Total Iteration Time: 4.70832

Cumulative Model Updates: 67,926
Cumulative Timesteps: 566,577,446

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,013.24249
Policy Entropy: 3.33516
Value Function Loss: 0.00395

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.56777
Value Function Update Magnitude: 0.67365

Collected Steps per Second: 23,157.24479
Overall Steps per Second: 10,906.20362

Timestep Collection Time: 2.16019
Timestep Consumption Time: 2.42656
PPO Batch Consumption Time: 0.28134
Total Iteration Time: 4.58675

Cumulative Model Updates: 67,932
Cumulative Timesteps: 566,627,470

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 566627470...
Checkpoint 566627470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 788.04192
Policy Entropy: 3.32637
Value Function Loss: 0.00369

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09262
Policy Update Magnitude: 0.56776
Value Function Update Magnitude: 0.67764

Collected Steps per Second: 22,402.91581
Overall Steps per Second: 10,631.65699

Timestep Collection Time: 2.23301
Timestep Consumption Time: 2.47237
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.70538

Cumulative Model Updates: 67,938
Cumulative Timesteps: 566,677,496

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744.87183
Policy Entropy: 3.33454
Value Function Loss: 0.00369

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08435
Policy Update Magnitude: 0.56175
Value Function Update Magnitude: 0.63894

Collected Steps per Second: 22,324.40912
Overall Steps per Second: 10,572.46630

Timestep Collection Time: 2.23997
Timestep Consumption Time: 2.48986
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.72983

Cumulative Model Updates: 67,944
Cumulative Timesteps: 566,727,502

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 566727502...
Checkpoint 566727502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.81519
Policy Entropy: 3.32409
Value Function Loss: 0.00369

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09343
Policy Update Magnitude: 0.55878
Value Function Update Magnitude: 0.62160

Collected Steps per Second: 22,445.65764
Overall Steps per Second: 10,585.22935

Timestep Collection Time: 2.22840
Timestep Consumption Time: 2.49686
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.72526

Cumulative Model Updates: 67,950
Cumulative Timesteps: 566,777,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.57418
Policy Entropy: 3.32141
Value Function Loss: 0.00367

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10824
Policy Update Magnitude: 0.54692
Value Function Update Magnitude: 0.61106

Collected Steps per Second: 22,665.50776
Overall Steps per Second: 10,779.31996

Timestep Collection Time: 2.20679
Timestep Consumption Time: 2.43339
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.64018

Cumulative Model Updates: 67,956
Cumulative Timesteps: 566,827,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 566827538...
Checkpoint 566827538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,296.09590
Policy Entropy: 3.31049
Value Function Loss: 0.00366

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.12635
Policy Update Magnitude: 0.54014
Value Function Update Magnitude: 0.59444

Collected Steps per Second: 22,444.74441
Overall Steps per Second: 10,700.35887

Timestep Collection Time: 2.22885
Timestep Consumption Time: 2.44632
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.67517

Cumulative Model Updates: 67,962
Cumulative Timesteps: 566,877,564

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.92281
Policy Entropy: 3.31455
Value Function Loss: 0.00375

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.53466
Value Function Update Magnitude: 0.59323

Collected Steps per Second: 22,229.31683
Overall Steps per Second: 10,497.32792

Timestep Collection Time: 2.24928
Timestep Consumption Time: 2.51383
PPO Batch Consumption Time: 0.29851
Total Iteration Time: 4.76312

Cumulative Model Updates: 67,968
Cumulative Timesteps: 566,927,564

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 566927564...
Checkpoint 566927564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 793.70256
Policy Entropy: 3.32644
Value Function Loss: 0.00366

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09430
Policy Update Magnitude: 0.53894
Value Function Update Magnitude: 0.61208

Collected Steps per Second: 22,652.15844
Overall Steps per Second: 10,610.83315

Timestep Collection Time: 2.20809
Timestep Consumption Time: 2.50577
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.71386

Cumulative Model Updates: 67,974
Cumulative Timesteps: 566,977,582

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.34244
Policy Entropy: 3.31266
Value Function Loss: 0.00371

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11328
Policy Update Magnitude: 0.54063
Value Function Update Magnitude: 0.61478

Collected Steps per Second: 22,682.60401
Overall Steps per Second: 10,756.35199

Timestep Collection Time: 2.20548
Timestep Consumption Time: 2.44535
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.65083

Cumulative Model Updates: 67,980
Cumulative Timesteps: 567,027,608

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 567027608...
Checkpoint 567027608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,312.48932
Policy Entropy: 3.30604
Value Function Loss: 0.00378

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10045
Policy Update Magnitude: 0.54304
Value Function Update Magnitude: 0.61847

Collected Steps per Second: 23,008.00863
Overall Steps per Second: 10,817.39474

Timestep Collection Time: 2.17333
Timestep Consumption Time: 2.44922
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.62255

Cumulative Model Updates: 67,986
Cumulative Timesteps: 567,077,612

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.65111
Policy Entropy: 3.28737
Value Function Loss: 0.00392

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09167
Policy Update Magnitude: 0.55446
Value Function Update Magnitude: 0.63795

Collected Steps per Second: 22,292.81639
Overall Steps per Second: 10,614.11986

Timestep Collection Time: 2.24422
Timestep Consumption Time: 2.46931
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.71353

Cumulative Model Updates: 67,992
Cumulative Timesteps: 567,127,642

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 567127642...
Checkpoint 567127642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 971.51318
Policy Entropy: 3.30223
Value Function Loss: 0.00397

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08358
Policy Update Magnitude: 0.56284
Value Function Update Magnitude: 0.64891

Collected Steps per Second: 22,774.47361
Overall Steps per Second: 10,837.10529

Timestep Collection Time: 2.19632
Timestep Consumption Time: 2.41931
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.61562

Cumulative Model Updates: 67,998
Cumulative Timesteps: 567,177,662

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.47968
Policy Entropy: 3.29855
Value Function Loss: 0.00386

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08456
Policy Update Magnitude: 0.57199
Value Function Update Magnitude: 0.64428

Collected Steps per Second: 22,674.03306
Overall Steps per Second: 10,679.68340

Timestep Collection Time: 2.20649
Timestep Consumption Time: 2.47811
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.68460

Cumulative Model Updates: 68,004
Cumulative Timesteps: 567,227,692

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 567227692...
Checkpoint 567227692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,684.41961
Policy Entropy: 3.28568
Value Function Loss: 0.00399

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08692
Policy Update Magnitude: 0.57484
Value Function Update Magnitude: 0.64833

Collected Steps per Second: 22,294.97034
Overall Steps per Second: 10,479.69568

Timestep Collection Time: 2.24284
Timestep Consumption Time: 2.52867
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.77151

Cumulative Model Updates: 68,010
Cumulative Timesteps: 567,277,696

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 934.76558
Policy Entropy: 3.27620
Value Function Loss: 0.00391

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09316
Policy Update Magnitude: 0.57686
Value Function Update Magnitude: 0.66178

Collected Steps per Second: 22,367.86426
Overall Steps per Second: 10,566.71141

Timestep Collection Time: 2.23624
Timestep Consumption Time: 2.49749
PPO Batch Consumption Time: 0.29621
Total Iteration Time: 4.73373

Cumulative Model Updates: 68,016
Cumulative Timesteps: 567,327,716

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 567327716...
Checkpoint 567327716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,683.54945
Policy Entropy: 3.28371
Value Function Loss: 0.00376

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.57175
Value Function Update Magnitude: 0.67569

Collected Steps per Second: 22,276.40561
Overall Steps per Second: 10,716.88866

Timestep Collection Time: 2.24489
Timestep Consumption Time: 2.42139
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.66628

Cumulative Model Updates: 68,022
Cumulative Timesteps: 567,377,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.76621
Policy Entropy: 3.29863
Value Function Loss: 0.00364

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10561
Policy Update Magnitude: 0.55926
Value Function Update Magnitude: 0.65169

Collected Steps per Second: 22,251.41267
Overall Steps per Second: 10,496.03767

Timestep Collection Time: 2.24777
Timestep Consumption Time: 2.51746
PPO Batch Consumption Time: 0.29738
Total Iteration Time: 4.76523

Cumulative Model Updates: 68,028
Cumulative Timesteps: 567,427,740

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 567427740...
Checkpoint 567427740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,642.92429
Policy Entropy: 3.31676
Value Function Loss: 0.00355

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08611
Policy Update Magnitude: 0.55241
Value Function Update Magnitude: 0.63069

Collected Steps per Second: 22,214.90323
Overall Steps per Second: 10,674.71138

Timestep Collection Time: 2.25137
Timestep Consumption Time: 2.43391
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.68528

Cumulative Model Updates: 68,034
Cumulative Timesteps: 567,477,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.85508
Policy Entropy: 3.31049
Value Function Loss: 0.00373

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09688
Policy Update Magnitude: 0.54545
Value Function Update Magnitude: 0.62619

Collected Steps per Second: 22,032.08002
Overall Steps per Second: 10,432.37548

Timestep Collection Time: 2.26960
Timestep Consumption Time: 2.52356
PPO Batch Consumption Time: 0.29785
Total Iteration Time: 4.79316

Cumulative Model Updates: 68,040
Cumulative Timesteps: 567,527,758

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 567527758...
Checkpoint 567527758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669.70177
Policy Entropy: 3.30686
Value Function Loss: 0.00389

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09478
Policy Update Magnitude: 0.55387
Value Function Update Magnitude: 0.64123

Collected Steps per Second: 23,047.60870
Overall Steps per Second: 10,652.39293

Timestep Collection Time: 2.17003
Timestep Consumption Time: 2.52507
PPO Batch Consumption Time: 0.29742
Total Iteration Time: 4.69510

Cumulative Model Updates: 68,046
Cumulative Timesteps: 567,577,772

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 828.00130
Policy Entropy: 3.30761
Value Function Loss: 0.00385

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09193
Policy Update Magnitude: 0.55943
Value Function Update Magnitude: 0.66440

Collected Steps per Second: 22,642.86884
Overall Steps per Second: 10,764.46900

Timestep Collection Time: 2.20961
Timestep Consumption Time: 2.43827
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.64788

Cumulative Model Updates: 68,052
Cumulative Timesteps: 567,627,804

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 567627804...
Checkpoint 567627804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.69937
Policy Entropy: 3.30704
Value Function Loss: 0.00367

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10089
Policy Update Magnitude: 0.55944
Value Function Update Magnitude: 0.67463

Collected Steps per Second: 22,888.53180
Overall Steps per Second: 10,767.97518

Timestep Collection Time: 2.18494
Timestep Consumption Time: 2.45939
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.64433

Cumulative Model Updates: 68,058
Cumulative Timesteps: 567,677,814

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,378.10509
Policy Entropy: 3.31679
Value Function Loss: 0.00366

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09626
Policy Update Magnitude: 0.55068
Value Function Update Magnitude: 0.66500

Collected Steps per Second: 22,768.54054
Overall Steps per Second: 10,827.18840

Timestep Collection Time: 2.19663
Timestep Consumption Time: 2.42267
PPO Batch Consumption Time: 0.28177
Total Iteration Time: 4.61930

Cumulative Model Updates: 68,064
Cumulative Timesteps: 567,727,828

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 567727828...
Checkpoint 567727828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 889.44750
Policy Entropy: 3.31263
Value Function Loss: 0.00352

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.53887
Value Function Update Magnitude: 0.62767

Collected Steps per Second: 22,800.14374
Overall Steps per Second: 10,711.16018

Timestep Collection Time: 2.19376
Timestep Consumption Time: 2.47595
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.66971

Cumulative Model Updates: 68,070
Cumulative Timesteps: 567,777,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 821.15488
Policy Entropy: 3.31608
Value Function Loss: 0.00362

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08720
Policy Update Magnitude: 0.54225
Value Function Update Magnitude: 0.63094

Collected Steps per Second: 22,439.68639
Overall Steps per Second: 10,629.70774

Timestep Collection Time: 2.22873
Timestep Consumption Time: 2.47620
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.70493

Cumulative Model Updates: 68,076
Cumulative Timesteps: 567,827,858

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 567827858...
Checkpoint 567827858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.66880
Policy Entropy: 3.33447
Value Function Loss: 0.00352

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.54600
Value Function Update Magnitude: 0.62360

Collected Steps per Second: 22,363.59704
Overall Steps per Second: 10,581.89999

Timestep Collection Time: 2.23667
Timestep Consumption Time: 2.49027
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.72694

Cumulative Model Updates: 68,082
Cumulative Timesteps: 567,877,878

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653.98840
Policy Entropy: 3.32060
Value Function Loss: 0.00374

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08786
Policy Update Magnitude: 0.54392
Value Function Update Magnitude: 0.61902

Collected Steps per Second: 22,606.40913
Overall Steps per Second: 10,755.33484

Timestep Collection Time: 2.21220
Timestep Consumption Time: 2.43758
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.64979

Cumulative Model Updates: 68,088
Cumulative Timesteps: 567,927,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 567927888...
Checkpoint 567927888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.05533
Policy Entropy: 3.32610
Value Function Loss: 0.00397

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09475
Policy Update Magnitude: 0.54679
Value Function Update Magnitude: 0.63739

Collected Steps per Second: 22,167.82288
Overall Steps per Second: 10,722.34628

Timestep Collection Time: 2.25660
Timestep Consumption Time: 2.40879
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.66540

Cumulative Model Updates: 68,094
Cumulative Timesteps: 567,977,912

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.95816
Policy Entropy: 3.32989
Value Function Loss: 0.00378

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.55350
Value Function Update Magnitude: 0.64116

Collected Steps per Second: 22,695.73289
Overall Steps per Second: 10,770.52538

Timestep Collection Time: 2.20385
Timestep Consumption Time: 2.44012
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.64397

Cumulative Model Updates: 68,100
Cumulative Timesteps: 568,027,930

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 568027930...
Checkpoint 568027930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300.08014
Policy Entropy: 3.32982
Value Function Loss: 0.00378

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.10995
Policy Update Magnitude: 0.54770
Value Function Update Magnitude: 0.63480

Collected Steps per Second: 22,263.72189
Overall Steps per Second: 10,706.16054

Timestep Collection Time: 2.24778
Timestep Consumption Time: 2.42654
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.67432

Cumulative Model Updates: 68,106
Cumulative Timesteps: 568,077,974

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 804.66653
Policy Entropy: 3.32952
Value Function Loss: 0.00382

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.53626
Value Function Update Magnitude: 0.63333

Collected Steps per Second: 22,508.05233
Overall Steps per Second: 10,513.68485

Timestep Collection Time: 2.22249
Timestep Consumption Time: 2.53550
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 4.75799

Cumulative Model Updates: 68,112
Cumulative Timesteps: 568,127,998

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 568127998...
Checkpoint 568127998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 889.39949
Policy Entropy: 3.31421
Value Function Loss: 0.00390

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.13398
Policy Update Magnitude: 0.54183
Value Function Update Magnitude: 0.63451

Collected Steps per Second: 22,793.55636
Overall Steps per Second: 10,667.66423

Timestep Collection Time: 2.19439
Timestep Consumption Time: 2.49436
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 4.68875

Cumulative Model Updates: 68,118
Cumulative Timesteps: 568,178,016

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.05480
Policy Entropy: 3.32913
Value Function Loss: 0.00389

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.54475
Value Function Update Magnitude: 0.62855

Collected Steps per Second: 22,883.10460
Overall Steps per Second: 10,789.35512

Timestep Collection Time: 2.18519
Timestep Consumption Time: 2.44937
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.63457

Cumulative Model Updates: 68,124
Cumulative Timesteps: 568,228,020

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 568228020...
Checkpoint 568228020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 897.49445
Policy Entropy: 3.33280
Value Function Loss: 0.00397

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10838
Policy Update Magnitude: 0.55119
Value Function Update Magnitude: 0.63830

Collected Steps per Second: 22,746.86620
Overall Steps per Second: 10,653.88864

Timestep Collection Time: 2.19925
Timestep Consumption Time: 2.49631
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.69556

Cumulative Model Updates: 68,130
Cumulative Timesteps: 568,278,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,396.50314
Policy Entropy: 3.34684
Value Function Loss: 0.00393

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08441
Policy Update Magnitude: 0.54972
Value Function Update Magnitude: 0.64341

Collected Steps per Second: 22,604.67668
Overall Steps per Second: 10,677.42604

Timestep Collection Time: 2.21255
Timestep Consumption Time: 2.47154
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.68409

Cumulative Model Updates: 68,136
Cumulative Timesteps: 568,328,060

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 568328060...
Checkpoint 568328060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.73069
Policy Entropy: 3.34538
Value Function Loss: 0.00375

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07763
Policy Update Magnitude: 0.54585
Value Function Update Magnitude: 0.63479

Collected Steps per Second: 22,936.56031
Overall Steps per Second: 10,860.73260

Timestep Collection Time: 2.18045
Timestep Consumption Time: 2.42440
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.60485

Cumulative Model Updates: 68,142
Cumulative Timesteps: 568,378,072

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.99561
Policy Entropy: 3.34717
Value Function Loss: 0.00371

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08882
Policy Update Magnitude: 0.53527
Value Function Update Magnitude: 0.63099

Collected Steps per Second: 22,025.81657
Overall Steps per Second: 10,472.58651

Timestep Collection Time: 2.27015
Timestep Consumption Time: 2.50441
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.77456

Cumulative Model Updates: 68,148
Cumulative Timesteps: 568,428,074

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 568428074...
Checkpoint 568428074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.98321
Policy Entropy: 3.33287
Value Function Loss: 0.00376

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08132
Policy Update Magnitude: 0.53929
Value Function Update Magnitude: 0.64217

Collected Steps per Second: 22,151.96407
Overall Steps per Second: 10,645.22180

Timestep Collection Time: 2.25714
Timestep Consumption Time: 2.43981
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.69694

Cumulative Model Updates: 68,154
Cumulative Timesteps: 568,478,074

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 988.70048
Policy Entropy: 3.35473
Value Function Loss: 0.00372

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08054
Policy Update Magnitude: 0.54608
Value Function Update Magnitude: 0.64955

Collected Steps per Second: 22,564.58181
Overall Steps per Second: 10,621.37553

Timestep Collection Time: 2.21631
Timestep Consumption Time: 2.49212
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.70843

Cumulative Model Updates: 68,160
Cumulative Timesteps: 568,528,084

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 568528084...
Checkpoint 568528084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605.07663
Policy Entropy: 3.37363
Value Function Loss: 0.00366

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07575
Policy Update Magnitude: 0.53982
Value Function Update Magnitude: 0.63592

Collected Steps per Second: 22,471.51845
Overall Steps per Second: 10,634.70724

Timestep Collection Time: 2.22620
Timestep Consumption Time: 2.47784
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.70403

Cumulative Model Updates: 68,166
Cumulative Timesteps: 568,578,110

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 965.43235
Policy Entropy: 3.38061
Value Function Loss: 0.00346

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07029
Policy Update Magnitude: 0.53543
Value Function Update Magnitude: 0.63069

Collected Steps per Second: 22,939.78748
Overall Steps per Second: 10,754.97790

Timestep Collection Time: 2.17988
Timestep Consumption Time: 2.46969
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.64957

Cumulative Model Updates: 68,172
Cumulative Timesteps: 568,628,116

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 568628116...
Checkpoint 568628116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.99638
Policy Entropy: 3.38033
Value Function Loss: 0.00340

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06621
Policy Update Magnitude: 0.53029
Value Function Update Magnitude: 0.61346

Collected Steps per Second: 22,653.17139
Overall Steps per Second: 10,635.48490

Timestep Collection Time: 2.20773
Timestep Consumption Time: 2.49465
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.70237

Cumulative Model Updates: 68,178
Cumulative Timesteps: 568,678,128

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.84536
Policy Entropy: 3.37055
Value Function Loss: 0.00327

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06344
Policy Update Magnitude: 0.52858
Value Function Update Magnitude: 0.61276

Collected Steps per Second: 22,488.98611
Overall Steps per Second: 10,626.66796

Timestep Collection Time: 2.22456
Timestep Consumption Time: 2.48322
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.70778

Cumulative Model Updates: 68,184
Cumulative Timesteps: 568,728,156

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 568728156...
Checkpoint 568728156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,338.80374
Policy Entropy: 3.36708
Value Function Loss: 0.00343

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.06989
Policy Update Magnitude: 0.52833
Value Function Update Magnitude: 0.60702

Collected Steps per Second: 22,804.85590
Overall Steps per Second: 10,838.18200

Timestep Collection Time: 2.19269
Timestep Consumption Time: 2.42100
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.61369

Cumulative Model Updates: 68,190
Cumulative Timesteps: 568,778,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 978.45187
Policy Entropy: 3.33751
Value Function Loss: 0.00386

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07783
Policy Update Magnitude: 0.55180
Value Function Update Magnitude: 0.64806

Collected Steps per Second: 22,914.03052
Overall Steps per Second: 10,733.04864

Timestep Collection Time: 2.18303
Timestep Consumption Time: 2.47753
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.66056

Cumulative Model Updates: 68,196
Cumulative Timesteps: 568,828,182

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 568828182...
Checkpoint 568828182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,312.67116
Policy Entropy: 3.34108
Value Function Loss: 0.00389

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08326
Policy Update Magnitude: 0.57087
Value Function Update Magnitude: 0.70443

Collected Steps per Second: 22,948.72850
Overall Steps per Second: 10,851.52177

Timestep Collection Time: 2.17903
Timestep Consumption Time: 2.42917
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.60820

Cumulative Model Updates: 68,202
Cumulative Timesteps: 568,878,188

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.25602
Policy Entropy: 3.32466
Value Function Loss: 0.00390

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08118
Policy Update Magnitude: 0.57106
Value Function Update Magnitude: 0.70319

Collected Steps per Second: 21,889.08024
Overall Steps per Second: 10,552.79190

Timestep Collection Time: 2.28452
Timestep Consumption Time: 2.45413
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.73865

Cumulative Model Updates: 68,208
Cumulative Timesteps: 568,928,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 568928194...
Checkpoint 568928194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 778.27854
Policy Entropy: 3.33283
Value Function Loss: 0.00367

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07588
Policy Update Magnitude: 0.55506
Value Function Update Magnitude: 0.68134

Collected Steps per Second: 22,415.05256
Overall Steps per Second: 10,603.52410

Timestep Collection Time: 2.23207
Timestep Consumption Time: 2.48636
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.71843

Cumulative Model Updates: 68,214
Cumulative Timesteps: 568,978,226

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629.50847
Policy Entropy: 3.32575
Value Function Loss: 0.00353

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.54168
Value Function Update Magnitude: 0.65029

Collected Steps per Second: 22,449.83234
Overall Steps per Second: 10,627.79687

Timestep Collection Time: 2.22737
Timestep Consumption Time: 2.47765
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.70502

Cumulative Model Updates: 68,220
Cumulative Timesteps: 569,028,230

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 569028230...
Checkpoint 569028230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.32024
Policy Entropy: 3.33820
Value Function Loss: 0.00349

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10344
Policy Update Magnitude: 0.52911
Value Function Update Magnitude: 0.63384

Collected Steps per Second: 22,476.68836
Overall Steps per Second: 10,634.97364

Timestep Collection Time: 2.22497
Timestep Consumption Time: 2.47744
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.70241

Cumulative Model Updates: 68,226
Cumulative Timesteps: 569,078,240

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,743.57267
Policy Entropy: 3.36083
Value Function Loss: 0.00333

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09596
Policy Update Magnitude: 0.51869
Value Function Update Magnitude: 0.60853

Collected Steps per Second: 22,622.23566
Overall Steps per Second: 10,722.93512

Timestep Collection Time: 2.21128
Timestep Consumption Time: 2.45386
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.66514

Cumulative Model Updates: 68,232
Cumulative Timesteps: 569,128,264

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 569128264...
Checkpoint 569128264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.50134
Policy Entropy: 3.35462
Value Function Loss: 0.00348

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08504
Policy Update Magnitude: 0.51085
Value Function Update Magnitude: 0.59261

Collected Steps per Second: 22,526.77318
Overall Steps per Second: 10,658.63943

Timestep Collection Time: 2.22011
Timestep Consumption Time: 2.47204
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.69216

Cumulative Model Updates: 68,238
Cumulative Timesteps: 569,178,276

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 983.84780
Policy Entropy: 3.34597
Value Function Loss: 0.00349

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08503
Policy Update Magnitude: 0.51315
Value Function Update Magnitude: 0.57769

Collected Steps per Second: 22,805.43731
Overall Steps per Second: 10,801.31677

Timestep Collection Time: 2.19255
Timestep Consumption Time: 2.43670
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.62925

Cumulative Model Updates: 68,244
Cumulative Timesteps: 569,228,278

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 569228278...
Checkpoint 569228278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 766.00479
Policy Entropy: 3.32466
Value Function Loss: 0.00388

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08825
Policy Update Magnitude: 0.52001
Value Function Update Magnitude: 0.57234

Collected Steps per Second: 22,816.66750
Overall Steps per Second: 10,735.22163

Timestep Collection Time: 2.19156
Timestep Consumption Time: 2.46638
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.65794

Cumulative Model Updates: 68,250
Cumulative Timesteps: 569,278,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.97434
Policy Entropy: 3.33509
Value Function Loss: 0.00386

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08754
Policy Update Magnitude: 0.53193
Value Function Update Magnitude: 0.59613

Collected Steps per Second: 22,835.56344
Overall Steps per Second: 10,802.84741

Timestep Collection Time: 2.18992
Timestep Consumption Time: 2.43923
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.62915

Cumulative Model Updates: 68,256
Cumulative Timesteps: 569,328,290

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 569328290...
Checkpoint 569328290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.19952
Policy Entropy: 3.33445
Value Function Loss: 0.00386

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08399
Policy Update Magnitude: 0.54218
Value Function Update Magnitude: 0.60157

Collected Steps per Second: 22,624.02807
Overall Steps per Second: 10,762.43938

Timestep Collection Time: 2.21057
Timestep Consumption Time: 2.43633
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.64690

Cumulative Model Updates: 68,262
Cumulative Timesteps: 569,378,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 796.17847
Policy Entropy: 3.34952
Value Function Loss: 0.00361

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.07718
Policy Update Magnitude: 0.54529
Value Function Update Magnitude: 0.62894

Collected Steps per Second: 22,767.89405
Overall Steps per Second: 10,803.59254

Timestep Collection Time: 2.19634
Timestep Consumption Time: 2.43231
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.62865

Cumulative Model Updates: 68,268
Cumulative Timesteps: 569,428,308

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 569428308...
Checkpoint 569428308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.03375
Policy Entropy: 3.34964
Value Function Loss: 0.00353

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.06807
Policy Update Magnitude: 0.53765
Value Function Update Magnitude: 0.63012

Collected Steps per Second: 22,483.58633
Overall Steps per Second: 10,676.81058

Timestep Collection Time: 2.22482
Timestep Consumption Time: 2.46028
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.68511

Cumulative Model Updates: 68,274
Cumulative Timesteps: 569,478,330

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 939.44517
Policy Entropy: 3.32579
Value Function Loss: 0.00363

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.07607
Policy Update Magnitude: 0.53787
Value Function Update Magnitude: 0.64038

Collected Steps per Second: 22,107.38314
Overall Steps per Second: 10,690.10092

Timestep Collection Time: 2.26268
Timestep Consumption Time: 2.41660
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.67928

Cumulative Model Updates: 68,280
Cumulative Timesteps: 569,528,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 569528352...
Checkpoint 569528352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,536.30865
Policy Entropy: 3.32863
Value Function Loss: 0.00362

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.07948
Policy Update Magnitude: 0.54617
Value Function Update Magnitude: 0.64049

Collected Steps per Second: 21,922.87809
Overall Steps per Second: 10,652.66087

Timestep Collection Time: 2.28154
Timestep Consumption Time: 2.41381
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.69535

Cumulative Model Updates: 68,286
Cumulative Timesteps: 569,578,370

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,226.18975
Policy Entropy: 3.33870
Value Function Loss: 0.00335

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.54735
Value Function Update Magnitude: 0.63130

Collected Steps per Second: 21,929.27734
Overall Steps per Second: 10,689.76292

Timestep Collection Time: 2.28024
Timestep Consumption Time: 2.39751
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.67775

Cumulative Model Updates: 68,292
Cumulative Timesteps: 569,628,374

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 569628374...
Checkpoint 569628374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.96648
Policy Entropy: 3.36209
Value Function Loss: 0.00346

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07827
Policy Update Magnitude: 0.54125
Value Function Update Magnitude: 0.61665

Collected Steps per Second: 21,955.84492
Overall Steps per Second: 10,619.16300

Timestep Collection Time: 2.27866
Timestep Consumption Time: 2.43263
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.71129

Cumulative Model Updates: 68,298
Cumulative Timesteps: 569,678,404

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 793.94301
Policy Entropy: 3.35856
Value Function Loss: 0.00346

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07650
Policy Update Magnitude: 0.54231
Value Function Update Magnitude: 0.62393

Collected Steps per Second: 22,095.60941
Overall Steps per Second: 10,627.82745

Timestep Collection Time: 2.26344
Timestep Consumption Time: 2.44232
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.70576

Cumulative Model Updates: 68,304
Cumulative Timesteps: 569,728,416

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 569728416...
Checkpoint 569728416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,468.95841
Policy Entropy: 3.34260
Value Function Loss: 0.00346

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08268
Policy Update Magnitude: 0.54274
Value Function Update Magnitude: 0.62522

Collected Steps per Second: 22,189.24409
Overall Steps per Second: 10,813.68585

Timestep Collection Time: 2.25361
Timestep Consumption Time: 2.37071
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.62433

Cumulative Model Updates: 68,310
Cumulative Timesteps: 569,778,422

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.75721
Policy Entropy: 3.33758
Value Function Loss: 0.00367

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08242
Policy Update Magnitude: 0.54308
Value Function Update Magnitude: 0.62257

Collected Steps per Second: 22,241.75099
Overall Steps per Second: 10,654.78606

Timestep Collection Time: 2.24910
Timestep Consumption Time: 2.44588
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.69498

Cumulative Model Updates: 68,316
Cumulative Timesteps: 569,828,446

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 569828446...
Checkpoint 569828446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,129.93907
Policy Entropy: 3.34467
Value Function Loss: 0.00360

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07748
Policy Update Magnitude: 0.54868
Value Function Update Magnitude: 0.62536

Collected Steps per Second: 22,298.53956
Overall Steps per Second: 10,736.34668

Timestep Collection Time: 2.24248
Timestep Consumption Time: 2.41497
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.65745

Cumulative Model Updates: 68,322
Cumulative Timesteps: 569,878,450

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 953.12423
Policy Entropy: 3.34713
Value Function Loss: 0.00346

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08248
Policy Update Magnitude: 0.55155
Value Function Update Magnitude: 0.62413

Collected Steps per Second: 23,029.69955
Overall Steps per Second: 10,715.30626

Timestep Collection Time: 2.17146
Timestep Consumption Time: 2.49551
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.66697

Cumulative Model Updates: 68,328
Cumulative Timesteps: 569,928,458

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 569928458...
Checkpoint 569928458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,539.18319
Policy Entropy: 3.34354
Value Function Loss: 0.00339

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08123
Policy Update Magnitude: 0.54193
Value Function Update Magnitude: 0.59427

Collected Steps per Second: 22,953.53264
Overall Steps per Second: 10,663.95602

Timestep Collection Time: 2.17849
Timestep Consumption Time: 2.51058
PPO Batch Consumption Time: 0.29711
Total Iteration Time: 4.68907

Cumulative Model Updates: 68,334
Cumulative Timesteps: 569,978,462

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.65208
Policy Entropy: 3.35001
Value Function Loss: 0.00333

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07104
Policy Update Magnitude: 0.53482
Value Function Update Magnitude: 0.58961

Collected Steps per Second: 21,583.36773
Overall Steps per Second: 10,494.89126

Timestep Collection Time: 2.31743
Timestep Consumption Time: 2.44851
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.76594

Cumulative Model Updates: 68,340
Cumulative Timesteps: 570,028,480

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 570028480...
Checkpoint 570028480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 971.35052
Policy Entropy: 3.34486
Value Function Loss: 0.00346

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07247
Policy Update Magnitude: 0.54084
Value Function Update Magnitude: 0.59406

Collected Steps per Second: 22,013.97413
Overall Steps per Second: 10,592.24380

Timestep Collection Time: 2.27256
Timestep Consumption Time: 2.45052
PPO Batch Consumption Time: 0.29703
Total Iteration Time: 4.72308

Cumulative Model Updates: 68,346
Cumulative Timesteps: 570,078,508

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 957.51735
Policy Entropy: 3.35914
Value Function Loss: 0.00349

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07690
Policy Update Magnitude: 0.54711
Value Function Update Magnitude: 0.59963

Collected Steps per Second: 21,502.40729
Overall Steps per Second: 10,473.97381

Timestep Collection Time: 2.32579
Timestep Consumption Time: 2.44891
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.77469

Cumulative Model Updates: 68,352
Cumulative Timesteps: 570,128,518

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 570128518...
Checkpoint 570128518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 793.50537
Policy Entropy: 3.34676
Value Function Loss: 0.00361

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.55420
Value Function Update Magnitude: 0.61326

Collected Steps per Second: 22,048.68875
Overall Steps per Second: 10,597.34558

Timestep Collection Time: 2.26825
Timestep Consumption Time: 2.45104
PPO Batch Consumption Time: 0.29722
Total Iteration Time: 4.71929

Cumulative Model Updates: 68,358
Cumulative Timesteps: 570,178,530

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,787.39739
Policy Entropy: 3.34158
Value Function Loss: 0.00362

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08572
Policy Update Magnitude: 0.56311
Value Function Update Magnitude: 0.62804

Collected Steps per Second: 23,091.62116
Overall Steps per Second: 10,674.86605

Timestep Collection Time: 2.16711
Timestep Consumption Time: 2.52073
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.68783

Cumulative Model Updates: 68,364
Cumulative Timesteps: 570,228,572

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 570228572...
Checkpoint 570228572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.79296
Policy Entropy: 3.32636
Value Function Loss: 0.00368

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.55070
Value Function Update Magnitude: 0.62214

Collected Steps per Second: 23,105.96582
Overall Steps per Second: 10,820.04657

Timestep Collection Time: 2.16559
Timestep Consumption Time: 2.45898
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.62456

Cumulative Model Updates: 68,370
Cumulative Timesteps: 570,278,610

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.64629
Policy Entropy: 3.32445
Value Function Loss: 0.00382

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11079
Policy Update Magnitude: 0.55002
Value Function Update Magnitude: 0.62993

Collected Steps per Second: 23,061.48924
Overall Steps per Second: 10,666.38255

Timestep Collection Time: 2.16881
Timestep Consumption Time: 2.52031
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.68912

Cumulative Model Updates: 68,376
Cumulative Timesteps: 570,328,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 570328626...
Checkpoint 570328626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 811.31024
Policy Entropy: 3.30008
Value Function Loss: 0.00411

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11365
Policy Update Magnitude: 0.56304
Value Function Update Magnitude: 0.68375

Collected Steps per Second: 22,861.05144
Overall Steps per Second: 10,731.13382

Timestep Collection Time: 2.18713
Timestep Consumption Time: 2.47221
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.65934

Cumulative Model Updates: 68,382
Cumulative Timesteps: 570,378,626

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705.83717
Policy Entropy: 3.27987
Value Function Loss: 0.00405

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.13055
Policy Update Magnitude: 0.57542
Value Function Update Magnitude: 0.70989

Collected Steps per Second: 22,772.76794
Overall Steps per Second: 10,679.90119

Timestep Collection Time: 2.19683
Timestep Consumption Time: 2.48748
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.68431

Cumulative Model Updates: 68,388
Cumulative Timesteps: 570,428,654

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 570428654...
Checkpoint 570428654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.91079
Policy Entropy: 3.28267
Value Function Loss: 0.00404

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.12283
Policy Update Magnitude: 0.56767
Value Function Update Magnitude: 0.67596

Collected Steps per Second: 22,084.57646
Overall Steps per Second: 10,613.50269

Timestep Collection Time: 2.26448
Timestep Consumption Time: 2.44745
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 4.71192

Cumulative Model Updates: 68,394
Cumulative Timesteps: 570,478,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 955.92885
Policy Entropy: 3.27979
Value Function Loss: 0.00400

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11124
Policy Update Magnitude: 0.56082
Value Function Update Magnitude: 0.65229

Collected Steps per Second: 22,305.41491
Overall Steps per Second: 10,461.95426

Timestep Collection Time: 2.24250
Timestep Consumption Time: 2.53863
PPO Batch Consumption Time: 0.29667
Total Iteration Time: 4.78113

Cumulative Model Updates: 68,400
Cumulative Timesteps: 570,528,684

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 570528684...
Checkpoint 570528684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 845.82159
Policy Entropy: 3.27526
Value Function Loss: 0.00409

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.11574
Policy Update Magnitude: 0.55505
Value Function Update Magnitude: 0.64984

Collected Steps per Second: 22,813.01913
Overall Steps per Second: 10,639.63374

Timestep Collection Time: 2.19243
Timestep Consumption Time: 2.50848
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.70091

Cumulative Model Updates: 68,406
Cumulative Timesteps: 570,578,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 786.03240
Policy Entropy: 3.25324
Value Function Loss: 0.00416

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.10730
Policy Update Magnitude: 0.56487
Value Function Update Magnitude: 0.66283

Collected Steps per Second: 22,386.44678
Overall Steps per Second: 10,521.88911

Timestep Collection Time: 2.23474
Timestep Consumption Time: 2.51991
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.75466

Cumulative Model Updates: 68,412
Cumulative Timesteps: 570,628,728

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 570628728...
Checkpoint 570628728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.18788
Policy Entropy: 3.26218
Value Function Loss: 0.00404

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.57361
Value Function Update Magnitude: 0.66044

Collected Steps per Second: 22,822.34717
Overall Steps per Second: 10,601.03363

Timestep Collection Time: 2.19154
Timestep Consumption Time: 2.52649
PPO Batch Consumption Time: 0.29737
Total Iteration Time: 4.71803

Cumulative Model Updates: 68,418
Cumulative Timesteps: 570,678,744

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.55761
Policy Entropy: 3.26959
Value Function Loss: 0.00389

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11565
Policy Update Magnitude: 0.56941
Value Function Update Magnitude: 0.64752

Collected Steps per Second: 22,572.71255
Overall Steps per Second: 10,500.40350

Timestep Collection Time: 2.21613
Timestep Consumption Time: 2.54788
PPO Batch Consumption Time: 0.29513
Total Iteration Time: 4.76401

Cumulative Model Updates: 68,424
Cumulative Timesteps: 570,728,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 570728768...
Checkpoint 570728768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526.29843
Policy Entropy: 3.28270
Value Function Loss: 0.00380

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11640
Policy Update Magnitude: 0.55506
Value Function Update Magnitude: 0.64250

Collected Steps per Second: 22,715.12348
Overall Steps per Second: 10,578.32640

Timestep Collection Time: 2.20197
Timestep Consumption Time: 2.52638
PPO Batch Consumption Time: 0.29644
Total Iteration Time: 4.72835

Cumulative Model Updates: 68,430
Cumulative Timesteps: 570,778,786

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721.82509
Policy Entropy: 3.27293
Value Function Loss: 0.00379

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.10968
Policy Update Magnitude: 0.55606
Value Function Update Magnitude: 0.64664

Collected Steps per Second: 23,180.43995
Overall Steps per Second: 10,835.14639

Timestep Collection Time: 2.15820
Timestep Consumption Time: 2.45900
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.61720

Cumulative Model Updates: 68,436
Cumulative Timesteps: 570,828,814

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 570828814...
Checkpoint 570828814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.47359
Policy Entropy: 3.27428
Value Function Loss: 0.00372

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10653
Policy Update Magnitude: 0.55847
Value Function Update Magnitude: 0.67520

Collected Steps per Second: 22,552.79501
Overall Steps per Second: 10,731.43553

Timestep Collection Time: 2.21844
Timestep Consumption Time: 2.44375
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.66219

Cumulative Model Updates: 68,442
Cumulative Timesteps: 570,878,846

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.52000
Policy Entropy: 3.26895
Value Function Loss: 0.00379

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09502
Policy Update Magnitude: 0.55789
Value Function Update Magnitude: 0.70349

Collected Steps per Second: 22,840.50206
Overall Steps per Second: 10,673.01079

Timestep Collection Time: 2.18918
Timestep Consumption Time: 2.49572
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.68490

Cumulative Model Updates: 68,448
Cumulative Timesteps: 570,928,848

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 570928848...
Checkpoint 570928848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 717.52605
Policy Entropy: 3.26016
Value Function Loss: 0.00403

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08363
Policy Update Magnitude: 0.56861
Value Function Update Magnitude: 0.70288

Collected Steps per Second: 22,652.23641
Overall Steps per Second: 10,668.26354

Timestep Collection Time: 2.20808
Timestep Consumption Time: 2.48040
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.68849

Cumulative Model Updates: 68,454
Cumulative Timesteps: 570,978,866

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.31646
Policy Entropy: 3.28208
Value Function Loss: 0.00424

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08455
Policy Update Magnitude: 0.57574
Value Function Update Magnitude: 0.68738

Collected Steps per Second: 23,011.98233
Overall Steps per Second: 10,644.07008

Timestep Collection Time: 2.17365
Timestep Consumption Time: 2.52568
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.69933

Cumulative Model Updates: 68,460
Cumulative Timesteps: 571,028,886

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 571028886...
Checkpoint 571028886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.07947
Policy Entropy: 3.28020
Value Function Loss: 0.00409

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.56942
Value Function Update Magnitude: 0.67347

Collected Steps per Second: 22,370.16100
Overall Steps per Second: 10,688.02591

Timestep Collection Time: 2.23592
Timestep Consumption Time: 2.44389
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.67982

Cumulative Model Updates: 68,466
Cumulative Timesteps: 571,078,904

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 895.23201
Policy Entropy: 3.28040
Value Function Loss: 0.00400

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.55973
Value Function Update Magnitude: 0.65835

Collected Steps per Second: 22,022.88827
Overall Steps per Second: 10,395.88404

Timestep Collection Time: 2.27136
Timestep Consumption Time: 2.54035
PPO Batch Consumption Time: 0.29550
Total Iteration Time: 4.81171

Cumulative Model Updates: 68,472
Cumulative Timesteps: 571,128,926

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 571128926...
Checkpoint 571128926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.16390
Policy Entropy: 3.27230
Value Function Loss: 0.00386

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09615
Policy Update Magnitude: 0.54986
Value Function Update Magnitude: 0.66215

Collected Steps per Second: 22,706.49156
Overall Steps per Second: 10,647.36766

Timestep Collection Time: 2.20228
Timestep Consumption Time: 2.49428
PPO Batch Consumption Time: 0.29516
Total Iteration Time: 4.69656

Cumulative Model Updates: 68,478
Cumulative Timesteps: 571,178,932

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714.69356
Policy Entropy: 3.27972
Value Function Loss: 0.00403

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09912
Policy Update Magnitude: 0.55718
Value Function Update Magnitude: 0.67491

Collected Steps per Second: 22,399.39800
Overall Steps per Second: 10,634.37283

Timestep Collection Time: 2.23256
Timestep Consumption Time: 2.46993
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.70249

Cumulative Model Updates: 68,484
Cumulative Timesteps: 571,228,940

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 571228940...
Checkpoint 571228940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 960.86061
Policy Entropy: 3.27788
Value Function Loss: 0.00414

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10315
Policy Update Magnitude: 0.56830
Value Function Update Magnitude: 0.67981

Collected Steps per Second: 22,459.81491
Overall Steps per Second: 10,647.02925

Timestep Collection Time: 2.22709
Timestep Consumption Time: 2.47094
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.69802

Cumulative Model Updates: 68,490
Cumulative Timesteps: 571,278,960

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 967.41433
Policy Entropy: 3.29991
Value Function Loss: 0.00421

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10596
Policy Update Magnitude: 0.57449
Value Function Update Magnitude: 0.69103

Collected Steps per Second: 22,873.79117
Overall Steps per Second: 10,751.57861

Timestep Collection Time: 2.18600
Timestep Consumption Time: 2.46467
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.65067

Cumulative Model Updates: 68,496
Cumulative Timesteps: 571,328,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 571328962...
Checkpoint 571328962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,145.41233
Policy Entropy: 3.30255
Value Function Loss: 0.00406

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11483
Policy Update Magnitude: 0.57044
Value Function Update Magnitude: 0.69470

Collected Steps per Second: 22,522.10165
Overall Steps per Second: 10,592.21691

Timestep Collection Time: 2.22084
Timestep Consumption Time: 2.50131
PPO Batch Consumption Time: 0.29639
Total Iteration Time: 4.72215

Cumulative Model Updates: 68,502
Cumulative Timesteps: 571,378,980

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654.85275
Policy Entropy: 3.31128
Value Function Loss: 0.00397

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10208
Policy Update Magnitude: 0.56378
Value Function Update Magnitude: 0.68953

Collected Steps per Second: 23,186.42387
Overall Steps per Second: 10,846.91170

Timestep Collection Time: 2.15747
Timestep Consumption Time: 2.45435
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.61182

Cumulative Model Updates: 68,508
Cumulative Timesteps: 571,429,004

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 571429004...
Checkpoint 571429004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487.58695
Policy Entropy: 3.31638
Value Function Loss: 0.00387

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08206
Policy Update Magnitude: 0.55760
Value Function Update Magnitude: 0.68146

Collected Steps per Second: 22,571.19499
Overall Steps per Second: 10,712.51181

Timestep Collection Time: 2.21628
Timestep Consumption Time: 2.45340
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.66968

Cumulative Model Updates: 68,514
Cumulative Timesteps: 571,479,028

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.20676
Policy Entropy: 3.31290
Value Function Loss: 0.00387

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08723
Policy Update Magnitude: 0.55796
Value Function Update Magnitude: 0.67105

Collected Steps per Second: 22,692.81853
Overall Steps per Second: 10,800.49638

Timestep Collection Time: 2.20431
Timestep Consumption Time: 2.42714
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.63145

Cumulative Model Updates: 68,520
Cumulative Timesteps: 571,529,050

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 571529050...
Checkpoint 571529050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.86426
Policy Entropy: 3.30240
Value Function Loss: 0.00383

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08847
Policy Update Magnitude: 0.55798
Value Function Update Magnitude: 0.65696

Collected Steps per Second: 22,645.15458
Overall Steps per Second: 10,804.82273

Timestep Collection Time: 2.20815
Timestep Consumption Time: 2.41978
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.62793

Cumulative Model Updates: 68,526
Cumulative Timesteps: 571,579,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425.77220
Policy Entropy: 3.29271
Value Function Loss: 0.00392

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.55586
Value Function Update Magnitude: 0.64867

Collected Steps per Second: 22,478.81457
Overall Steps per Second: 10,759.41147

Timestep Collection Time: 2.22556
Timestep Consumption Time: 2.42413
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.64970

Cumulative Model Updates: 68,532
Cumulative Timesteps: 571,629,082

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 571629082...
Checkpoint 571629082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.78722
Policy Entropy: 3.28458
Value Function Loss: 0.00390

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09771
Policy Update Magnitude: 0.56116
Value Function Update Magnitude: 0.63835

Collected Steps per Second: 22,080.21102
Overall Steps per Second: 10,659.17833

Timestep Collection Time: 2.26538
Timestep Consumption Time: 2.42729
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.69267

Cumulative Model Updates: 68,538
Cumulative Timesteps: 571,679,102

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.06990
Policy Entropy: 3.28747
Value Function Loss: 0.00383

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09137
Policy Update Magnitude: 0.56108
Value Function Update Magnitude: 0.65140

Collected Steps per Second: 22,287.51103
Overall Steps per Second: 10,545.82676

Timestep Collection Time: 2.24422
Timestep Consumption Time: 2.49870
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.74292

Cumulative Model Updates: 68,544
Cumulative Timesteps: 571,729,120

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 571729120...
Checkpoint 571729120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.76039
Policy Entropy: 3.27503
Value Function Loss: 0.00367

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09474
Policy Update Magnitude: 0.55514
Value Function Update Magnitude: 0.64811

Collected Steps per Second: 22,372.33004
Overall Steps per Second: 10,646.99714

Timestep Collection Time: 2.23624
Timestep Consumption Time: 2.46273
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.69898

Cumulative Model Updates: 68,550
Cumulative Timesteps: 571,779,150

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.90421
Policy Entropy: 3.28049
Value Function Loss: 0.00385

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.55611
Value Function Update Magnitude: 0.65603

Collected Steps per Second: 22,537.38828
Overall Steps per Second: 10,656.11305

Timestep Collection Time: 2.21987
Timestep Consumption Time: 2.47509
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.69496

Cumulative Model Updates: 68,556
Cumulative Timesteps: 571,829,180

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 571829180...
Checkpoint 571829180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 876.67453
Policy Entropy: 3.28850
Value Function Loss: 0.00377

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08943
Policy Update Magnitude: 0.55854
Value Function Update Magnitude: 0.64683

Collected Steps per Second: 22,248.88391
Overall Steps per Second: 10,459.01940

Timestep Collection Time: 2.24775
Timestep Consumption Time: 2.53377
PPO Batch Consumption Time: 0.29665
Total Iteration Time: 4.78152

Cumulative Model Updates: 68,562
Cumulative Timesteps: 571,879,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 823.30906
Policy Entropy: 3.30227
Value Function Loss: 0.00371

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09385
Policy Update Magnitude: 0.54865
Value Function Update Magnitude: 0.61325

Collected Steps per Second: 23,054.75611
Overall Steps per Second: 10,847.53925

Timestep Collection Time: 2.16979
Timestep Consumption Time: 2.44176
PPO Batch Consumption Time: 0.28132
Total Iteration Time: 4.61155

Cumulative Model Updates: 68,568
Cumulative Timesteps: 571,929,214

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 571929214...
Checkpoint 571929214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674.10877
Policy Entropy: 3.29623
Value Function Loss: 0.00351

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09315
Policy Update Magnitude: 0.53558
Value Function Update Magnitude: 0.60309

Collected Steps per Second: 22,680.22721
Overall Steps per Second: 10,701.49606

Timestep Collection Time: 2.20483
Timestep Consumption Time: 2.46798
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.67280

Cumulative Model Updates: 68,574
Cumulative Timesteps: 571,979,220

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.11361
Policy Entropy: 3.30114
Value Function Loss: 0.00355

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09316
Policy Update Magnitude: 0.52705
Value Function Update Magnitude: 0.59371

Collected Steps per Second: 23,056.51076
Overall Steps per Second: 10,895.10844

Timestep Collection Time: 2.16928
Timestep Consumption Time: 2.42141
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.59068

Cumulative Model Updates: 68,580
Cumulative Timesteps: 572,029,236

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 572029236...
Checkpoint 572029236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 928.63704
Policy Entropy: 3.29240
Value Function Loss: 0.00359

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11060
Policy Update Magnitude: 0.52666
Value Function Update Magnitude: 0.59374

Collected Steps per Second: 21,965.89635
Overall Steps per Second: 10,607.12642

Timestep Collection Time: 2.27744
Timestep Consumption Time: 2.43882
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.71626

Cumulative Model Updates: 68,586
Cumulative Timesteps: 572,079,262

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.44760
Policy Entropy: 3.28235
Value Function Loss: 0.00384

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.53317
Value Function Update Magnitude: 0.62222

Collected Steps per Second: 22,878.53749
Overall Steps per Second: 10,988.06992

Timestep Collection Time: 2.18554
Timestep Consumption Time: 2.36503
PPO Batch Consumption Time: 0.28192
Total Iteration Time: 4.55057

Cumulative Model Updates: 68,592
Cumulative Timesteps: 572,129,264

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 572129264...
Checkpoint 572129264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.30470
Policy Entropy: 3.28138
Value Function Loss: 0.00391

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10119
Policy Update Magnitude: 0.53909
Value Function Update Magnitude: 0.63973

Collected Steps per Second: 21,665.37032
Overall Steps per Second: 10,656.46754

Timestep Collection Time: 2.30931
Timestep Consumption Time: 2.38568
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.69499

Cumulative Model Updates: 68,598
Cumulative Timesteps: 572,179,296

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.98014
Policy Entropy: 3.29387
Value Function Loss: 0.00411

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08599
Policy Update Magnitude: 0.54600
Value Function Update Magnitude: 0.64080

Collected Steps per Second: 21,894.47826
Overall Steps per Second: 10,612.25375

Timestep Collection Time: 2.28423
Timestep Consumption Time: 2.42844
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.71267

Cumulative Model Updates: 68,604
Cumulative Timesteps: 572,229,308

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 572229308...
Checkpoint 572229308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468.29867
Policy Entropy: 3.28747
Value Function Loss: 0.00429

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09897
Policy Update Magnitude: 0.55468
Value Function Update Magnitude: 0.66481

Collected Steps per Second: 21,689.42066
Overall Steps per Second: 10,556.89521

Timestep Collection Time: 2.30656
Timestep Consumption Time: 2.43233
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.73889

Cumulative Model Updates: 68,610
Cumulative Timesteps: 572,279,336

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.85912
Policy Entropy: 3.29391
Value Function Loss: 0.00419

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11616
Policy Update Magnitude: 0.56128
Value Function Update Magnitude: 0.67311

Collected Steps per Second: 21,792.28519
Overall Steps per Second: 10,580.79646

Timestep Collection Time: 2.29531
Timestep Consumption Time: 2.43212
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.72743

Cumulative Model Updates: 68,616
Cumulative Timesteps: 572,329,356

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 572329356...
Checkpoint 572329356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 872.94373
Policy Entropy: 3.29261
Value Function Loss: 0.00415

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10637
Policy Update Magnitude: 0.55817
Value Function Update Magnitude: 0.67469

Collected Steps per Second: 22,456.56548
Overall Steps per Second: 10,808.57696

Timestep Collection Time: 2.22777
Timestep Consumption Time: 2.40078
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.62855

Cumulative Model Updates: 68,622
Cumulative Timesteps: 572,379,384

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.09502
Policy Entropy: 3.30631
Value Function Loss: 0.00405

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09453
Policy Update Magnitude: 0.55553
Value Function Update Magnitude: 0.67114

Collected Steps per Second: 22,151.52329
Overall Steps per Second: 10,684.87707

Timestep Collection Time: 2.25727
Timestep Consumption Time: 2.42243
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.67970

Cumulative Model Updates: 68,628
Cumulative Timesteps: 572,429,386

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 572429386...
Checkpoint 572429386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.36647
Policy Entropy: 3.29680
Value Function Loss: 0.00401

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08905
Policy Update Magnitude: 0.55787
Value Function Update Magnitude: 0.66135

Collected Steps per Second: 22,734.12673
Overall Steps per Second: 10,670.74953

Timestep Collection Time: 2.19978
Timestep Consumption Time: 2.48687
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.68664

Cumulative Model Updates: 68,634
Cumulative Timesteps: 572,479,396

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.26904
Policy Entropy: 3.27782
Value Function Loss: 0.00404

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09286
Policy Update Magnitude: 0.55417
Value Function Update Magnitude: 0.64791

Collected Steps per Second: 22,856.22032
Overall Steps per Second: 10,709.88063

Timestep Collection Time: 2.18776
Timestep Consumption Time: 2.48120
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.66896

Cumulative Model Updates: 68,640
Cumulative Timesteps: 572,529,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 572529400...
Checkpoint 572529400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.59241
Policy Entropy: 3.27753
Value Function Loss: 0.00384

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08762
Policy Update Magnitude: 0.55115
Value Function Update Magnitude: 0.63598

Collected Steps per Second: 22,904.28096
Overall Steps per Second: 10,658.06931

Timestep Collection Time: 2.18422
Timestep Consumption Time: 2.50969
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.69391

Cumulative Model Updates: 68,646
Cumulative Timesteps: 572,579,428

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,159.11054
Policy Entropy: 3.28646
Value Function Loss: 0.00368

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09215
Policy Update Magnitude: 0.54124
Value Function Update Magnitude: 0.63136

Collected Steps per Second: 23,331.48473
Overall Steps per Second: 10,899.92515

Timestep Collection Time: 2.14414
Timestep Consumption Time: 2.44543
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.58957

Cumulative Model Updates: 68,652
Cumulative Timesteps: 572,629,454

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 572629454...
Checkpoint 572629454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.85995
Policy Entropy: 3.30380
Value Function Loss: 0.00360

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10767
Policy Update Magnitude: 0.52646
Value Function Update Magnitude: 0.62796

Collected Steps per Second: 21,895.12463
Overall Steps per Second: 10,531.64391

Timestep Collection Time: 2.28361
Timestep Consumption Time: 2.46398
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.74760

Cumulative Model Updates: 68,658
Cumulative Timesteps: 572,679,454

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673.12743
Policy Entropy: 3.28715
Value Function Loss: 0.00367

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09987
Policy Update Magnitude: 0.52724
Value Function Update Magnitude: 0.61872

Collected Steps per Second: 22,575.76977
Overall Steps per Second: 10,530.43681

Timestep Collection Time: 2.21574
Timestep Consumption Time: 2.53449
PPO Batch Consumption Time: 0.29644
Total Iteration Time: 4.75023

Cumulative Model Updates: 68,664
Cumulative Timesteps: 572,729,476

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 572729476...
Checkpoint 572729476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 720.94531
Policy Entropy: 3.27562
Value Function Loss: 0.00378

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.53913
Value Function Update Magnitude: 0.62859

Collected Steps per Second: 22,226.79443
Overall Steps per Second: 10,695.60629

Timestep Collection Time: 2.25080
Timestep Consumption Time: 2.42664
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.67743

Cumulative Model Updates: 68,670
Cumulative Timesteps: 572,779,504

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.95978
Policy Entropy: 3.27873
Value Function Loss: 0.00402

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.54895
Value Function Update Magnitude: 0.64375

Collected Steps per Second: 22,237.63155
Overall Steps per Second: 10,390.84894

Timestep Collection Time: 2.24871
Timestep Consumption Time: 2.56379
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.81250

Cumulative Model Updates: 68,676
Cumulative Timesteps: 572,829,510

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 572829510...
Checkpoint 572829510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 899.81186
Policy Entropy: 3.29562
Value Function Loss: 0.00401

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.55324
Value Function Update Magnitude: 0.65750

Collected Steps per Second: 22,574.68503
Overall Steps per Second: 10,645.03914

Timestep Collection Time: 2.21531
Timestep Consumption Time: 2.48265
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.69796

Cumulative Model Updates: 68,682
Cumulative Timesteps: 572,879,520

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 770.87970
Policy Entropy: 3.30379
Value Function Loss: 0.00409

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.54914
Value Function Update Magnitude: 0.65063

Collected Steps per Second: 22,850.03387
Overall Steps per Second: 10,645.94987

Timestep Collection Time: 2.18862
Timestep Consumption Time: 2.50894
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.69756

Cumulative Model Updates: 68,688
Cumulative Timesteps: 572,929,530

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 572929530...
Checkpoint 572929530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545.93030
Policy Entropy: 3.31731
Value Function Loss: 0.00371

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.54000
Value Function Update Magnitude: 0.62695

Collected Steps per Second: 22,949.30072
Overall Steps per Second: 10,825.45032

Timestep Collection Time: 2.18011
Timestep Consumption Time: 2.44159
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.62170

Cumulative Model Updates: 68,694
Cumulative Timesteps: 572,979,562

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.27675
Policy Entropy: 3.31892
Value Function Loss: 0.00367

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09887
Policy Update Magnitude: 0.52957
Value Function Update Magnitude: 0.61114

Collected Steps per Second: 22,963.53697
Overall Steps per Second: 10,651.33681

Timestep Collection Time: 2.17780
Timestep Consumption Time: 2.51738
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.69519

Cumulative Model Updates: 68,700
Cumulative Timesteps: 573,029,572

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 573029572...
Checkpoint 573029572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.73066
Policy Entropy: 3.32768
Value Function Loss: 0.00356

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08220
Policy Update Magnitude: 0.52247
Value Function Update Magnitude: 0.60494

Collected Steps per Second: 22,567.69089
Overall Steps per Second: 10,563.44410

Timestep Collection Time: 2.21573
Timestep Consumption Time: 2.51795
PPO Batch Consumption Time: 0.29646
Total Iteration Time: 4.73368

Cumulative Model Updates: 68,706
Cumulative Timesteps: 573,079,576

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,312.01571
Policy Entropy: 3.30617
Value Function Loss: 0.00359

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.07820
Policy Update Magnitude: 0.52946
Value Function Update Magnitude: 0.60091

Collected Steps per Second: 22,830.90122
Overall Steps per Second: 10,809.00878

Timestep Collection Time: 2.19098
Timestep Consumption Time: 2.43683
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.62781

Cumulative Model Updates: 68,712
Cumulative Timesteps: 573,129,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 573129598...
Checkpoint 573129598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.73838
Policy Entropy: 3.29629
Value Function Loss: 0.00383

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09029
Policy Update Magnitude: 0.53494
Value Function Update Magnitude: 0.59818

Collected Steps per Second: 22,318.03739
Overall Steps per Second: 10,666.68964

Timestep Collection Time: 2.24124
Timestep Consumption Time: 2.44813
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.68936

Cumulative Model Updates: 68,718
Cumulative Timesteps: 573,179,618

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.98695
Policy Entropy: 3.29814
Value Function Loss: 0.00376

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10593
Policy Update Magnitude: 0.53598
Value Function Update Magnitude: 0.60464

Collected Steps per Second: 22,860.28964
Overall Steps per Second: 10,637.96638

Timestep Collection Time: 2.18781
Timestep Consumption Time: 2.51365
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.70146

Cumulative Model Updates: 68,724
Cumulative Timesteps: 573,229,632

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 573229632...
Checkpoint 573229632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668.64187
Policy Entropy: 3.31227
Value Function Loss: 0.00357

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.52836
Value Function Update Magnitude: 0.58873

Collected Steps per Second: 22,169.34980
Overall Steps per Second: 10,454.72623

Timestep Collection Time: 2.25537
Timestep Consumption Time: 2.52716
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.78253

Cumulative Model Updates: 68,730
Cumulative Timesteps: 573,279,632

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.13105
Policy Entropy: 3.32700
Value Function Loss: 0.00339

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09745
Policy Update Magnitude: 0.51657
Value Function Update Magnitude: 0.56585

Collected Steps per Second: 22,561.85191
Overall Steps per Second: 10,586.97871

Timestep Collection Time: 2.21684
Timestep Consumption Time: 2.50745
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.72429

Cumulative Model Updates: 68,736
Cumulative Timesteps: 573,329,648

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 573329648...
Checkpoint 573329648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.86356
Policy Entropy: 3.32314
Value Function Loss: 0.00369

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.52094
Value Function Update Magnitude: 0.56471

Collected Steps per Second: 21,719.96710
Overall Steps per Second: 10,574.50035

Timestep Collection Time: 2.30286
Timestep Consumption Time: 2.42720
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.73006

Cumulative Model Updates: 68,742
Cumulative Timesteps: 573,379,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 776.44484
Policy Entropy: 3.31982
Value Function Loss: 0.00367

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08410
Policy Update Magnitude: 0.53444
Value Function Update Magnitude: 0.57796

Collected Steps per Second: 22,715.18186
Overall Steps per Second: 10,607.47476

Timestep Collection Time: 2.20170
Timestep Consumption Time: 2.51309
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.71479

Cumulative Model Updates: 68,748
Cumulative Timesteps: 573,429,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 573429678...
Checkpoint 573429678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.68130
Policy Entropy: 3.30454
Value Function Loss: 0.00375

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.53853
Value Function Update Magnitude: 0.57466

Collected Steps per Second: 22,881.67135
Overall Steps per Second: 10,586.42714

Timestep Collection Time: 2.18568
Timestep Consumption Time: 2.53848
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.72416

Cumulative Model Updates: 68,754
Cumulative Timesteps: 573,479,690

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,056.35040
Policy Entropy: 3.29307
Value Function Loss: 0.00368

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09064
Policy Update Magnitude: 0.53101
Value Function Update Magnitude: 0.57243

Collected Steps per Second: 23,037.91733
Overall Steps per Second: 10,769.95787

Timestep Collection Time: 2.17051
Timestep Consumption Time: 2.47241
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.64292

Cumulative Model Updates: 68,760
Cumulative Timesteps: 573,529,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 573529694...
Checkpoint 573529694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 878.13949
Policy Entropy: 3.29575
Value Function Loss: 0.00377

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09395
Policy Update Magnitude: 0.53282
Value Function Update Magnitude: 0.56775

Collected Steps per Second: 22,929.41287
Overall Steps per Second: 10,638.33973

Timestep Collection Time: 2.18156
Timestep Consumption Time: 2.52048
PPO Batch Consumption Time: 0.29648
Total Iteration Time: 4.70205

Cumulative Model Updates: 68,766
Cumulative Timesteps: 573,579,716

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 943.78878
Policy Entropy: 3.29088
Value Function Loss: 0.00387

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.10873
Policy Update Magnitude: 0.53689
Value Function Update Magnitude: 0.58848

Collected Steps per Second: 22,882.89309
Overall Steps per Second: 10,819.50069

Timestep Collection Time: 2.18530
Timestep Consumption Time: 2.43654
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.62184

Cumulative Model Updates: 68,772
Cumulative Timesteps: 573,629,722

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 573629722...
Checkpoint 573629722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 721.16251
Policy Entropy: 3.31446
Value Function Loss: 0.00386

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10399
Policy Update Magnitude: 0.54818
Value Function Update Magnitude: 0.59594

Collected Steps per Second: 22,127.42928
Overall Steps per Second: 10,585.19153

Timestep Collection Time: 2.26090
Timestep Consumption Time: 2.46532
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.72623

Cumulative Model Updates: 68,778
Cumulative Timesteps: 573,679,750

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.94934
Policy Entropy: 3.31063
Value Function Loss: 0.00388

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09309
Policy Update Magnitude: 0.54851
Value Function Update Magnitude: 0.59263

Collected Steps per Second: 22,978.45328
Overall Steps per Second: 10,663.21438

Timestep Collection Time: 2.17708
Timestep Consumption Time: 2.51437
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.69146

Cumulative Model Updates: 68,784
Cumulative Timesteps: 573,729,776

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 573729776...
Checkpoint 573729776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 965.69757
Policy Entropy: 3.30614
Value Function Loss: 0.00380

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08382
Policy Update Magnitude: 0.53738
Value Function Update Magnitude: 0.59905

Collected Steps per Second: 22,223.19673
Overall Steps per Second: 10,582.07931

Timestep Collection Time: 2.25071
Timestep Consumption Time: 2.47596
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.72667

Cumulative Model Updates: 68,790
Cumulative Timesteps: 573,779,794

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,059.59171
Policy Entropy: 3.28494
Value Function Loss: 0.00372

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08232
Policy Update Magnitude: 0.53114
Value Function Update Magnitude: 0.59558

Collected Steps per Second: 22,762.38888
Overall Steps per Second: 10,641.47246

Timestep Collection Time: 2.19784
Timestep Consumption Time: 2.50339
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.70123

Cumulative Model Updates: 68,796
Cumulative Timesteps: 573,829,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 573829822...
Checkpoint 573829822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 972.33895
Policy Entropy: 3.29273
Value Function Loss: 0.00361

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08051
Policy Update Magnitude: 0.53016
Value Function Update Magnitude: 0.58449

Collected Steps per Second: 22,275.42168
Overall Steps per Second: 10,637.71751

Timestep Collection Time: 2.24534
Timestep Consumption Time: 2.45642
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.70176

Cumulative Model Updates: 68,802
Cumulative Timesteps: 573,879,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.61440
Policy Entropy: 3.29192
Value Function Loss: 0.00348

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09024
Policy Update Magnitude: 0.51990
Value Function Update Magnitude: 0.57067

Collected Steps per Second: 22,617.03861
Overall Steps per Second: 10,726.43322

Timestep Collection Time: 2.21081
Timestep Consumption Time: 2.45076
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.66157

Cumulative Model Updates: 68,808
Cumulative Timesteps: 573,929,840

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 573929840...
Checkpoint 573929840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 955.95733
Policy Entropy: 3.32018
Value Function Loss: 0.00343

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08840
Policy Update Magnitude: 0.51212
Value Function Update Magnitude: 0.57893

Collected Steps per Second: 22,194.26429
Overall Steps per Second: 10,619.31788

Timestep Collection Time: 2.25347
Timestep Consumption Time: 2.45625
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.70972

Cumulative Model Updates: 68,814
Cumulative Timesteps: 573,979,854

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674.68380
Policy Entropy: 3.30787
Value Function Loss: 0.00362

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08505
Policy Update Magnitude: 0.51645
Value Function Update Magnitude: 0.59252

Collected Steps per Second: 23,094.61571
Overall Steps per Second: 10,785.31386

Timestep Collection Time: 2.16570
Timestep Consumption Time: 2.47172
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.63742

Cumulative Model Updates: 68,820
Cumulative Timesteps: 574,029,870

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 574029870...
Checkpoint 574029870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 880.22231
Policy Entropy: 3.30604
Value Function Loss: 0.00360

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08049
Policy Update Magnitude: 0.52589
Value Function Update Magnitude: 0.59256

Collected Steps per Second: 22,723.60065
Overall Steps per Second: 10,717.45143

Timestep Collection Time: 2.20088
Timestep Consumption Time: 2.46552
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.66641

Cumulative Model Updates: 68,826
Cumulative Timesteps: 574,079,882

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714.19109
Policy Entropy: 3.29110
Value Function Loss: 0.00363

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07850
Policy Update Magnitude: 0.53017
Value Function Update Magnitude: 0.59786

Collected Steps per Second: 22,903.68710
Overall Steps per Second: 10,860.90099

Timestep Collection Time: 2.18375
Timestep Consumption Time: 2.42139
PPO Batch Consumption Time: 0.28220
Total Iteration Time: 4.60514

Cumulative Model Updates: 68,832
Cumulative Timesteps: 574,129,898

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 574129898...
Checkpoint 574129898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707.30216
Policy Entropy: 3.29798
Value Function Loss: 0.00360

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07766
Policy Update Magnitude: 0.52768
Value Function Update Magnitude: 0.62094

Collected Steps per Second: 21,789.43941
Overall Steps per Second: 10,502.07040

Timestep Collection Time: 2.29542
Timestep Consumption Time: 2.46707
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.76249

Cumulative Model Updates: 68,838
Cumulative Timesteps: 574,179,914

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760.08610
Policy Entropy: 3.29626
Value Function Loss: 0.00369

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07877
Policy Update Magnitude: 0.53433
Value Function Update Magnitude: 0.61822

Collected Steps per Second: 22,367.17961
Overall Steps per Second: 10,737.29290

Timestep Collection Time: 2.23551
Timestep Consumption Time: 2.42135
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.65685

Cumulative Model Updates: 68,844
Cumulative Timesteps: 574,229,916

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 574229916...
Checkpoint 574229916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,413.92587
Policy Entropy: 3.29713
Value Function Loss: 0.00372

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08171
Policy Update Magnitude: 0.53560
Value Function Update Magnitude: 0.60265

Collected Steps per Second: 21,868.24798
Overall Steps per Second: 10,624.19604

Timestep Collection Time: 2.28816
Timestep Consumption Time: 2.42166
PPO Batch Consumption Time: 0.28171
Total Iteration Time: 4.70982

Cumulative Model Updates: 68,850
Cumulative Timesteps: 574,279,954

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782.79851
Policy Entropy: 3.27982
Value Function Loss: 0.00365

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08595
Policy Update Magnitude: 0.53399
Value Function Update Magnitude: 0.57308

Collected Steps per Second: 22,486.55277
Overall Steps per Second: 10,920.92796

Timestep Collection Time: 2.22453
Timestep Consumption Time: 2.35585
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.58038

Cumulative Model Updates: 68,856
Cumulative Timesteps: 574,329,976

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 574329976...
Checkpoint 574329976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 900.68174
Policy Entropy: 3.29460
Value Function Loss: 0.00351

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08651
Policy Update Magnitude: 0.52223
Value Function Update Magnitude: 0.56684

Collected Steps per Second: 21,953.22044
Overall Steps per Second: 10,612.39561

Timestep Collection Time: 2.27857
Timestep Consumption Time: 2.43497
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.71354

Cumulative Model Updates: 68,862
Cumulative Timesteps: 574,379,998

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.43562
Policy Entropy: 3.31003
Value Function Loss: 0.00345

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07940
Policy Update Magnitude: 0.51700
Value Function Update Magnitude: 0.55329

Collected Steps per Second: 22,409.26320
Overall Steps per Second: 10,823.53868

Timestep Collection Time: 2.23256
Timestep Consumption Time: 2.38977
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.62233

Cumulative Model Updates: 68,868
Cumulative Timesteps: 574,430,028

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 574430028...
Checkpoint 574430028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.44288
Policy Entropy: 3.32075
Value Function Loss: 0.00353

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07774
Policy Update Magnitude: 0.51363
Value Function Update Magnitude: 0.55983

Collected Steps per Second: 21,802.94956
Overall Steps per Second: 10,697.10990

Timestep Collection Time: 2.29327
Timestep Consumption Time: 2.38089
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.67416

Cumulative Model Updates: 68,874
Cumulative Timesteps: 574,480,028

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.88588
Policy Entropy: 3.31045
Value Function Loss: 0.00368

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.06785
Policy Update Magnitude: 0.51985
Value Function Update Magnitude: 0.55783

Collected Steps per Second: 22,401.71402
Overall Steps per Second: 10,843.35484

Timestep Collection Time: 2.23269
Timestep Consumption Time: 2.37991
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.61259

Cumulative Model Updates: 68,880
Cumulative Timesteps: 574,530,044

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 574530044...
Checkpoint 574530044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 852.59820
Policy Entropy: 3.30844
Value Function Loss: 0.00371

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08014
Policy Update Magnitude: 0.53172
Value Function Update Magnitude: 0.57519

Collected Steps per Second: 22,050.02052
Overall Steps per Second: 10,728.46537

Timestep Collection Time: 2.26803
Timestep Consumption Time: 2.39341
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.66143

Cumulative Model Updates: 68,886
Cumulative Timesteps: 574,580,054

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 900.17967
Policy Entropy: 3.30672
Value Function Loss: 0.00369

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10569
Policy Update Magnitude: 0.53388
Value Function Update Magnitude: 0.58576

Collected Steps per Second: 22,909.07717
Overall Steps per Second: 10,786.94507

Timestep Collection Time: 2.18298
Timestep Consumption Time: 2.45318
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.63616

Cumulative Model Updates: 68,892
Cumulative Timesteps: 574,630,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 574630064...
Checkpoint 574630064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 936.75678
Policy Entropy: 3.31918
Value Function Loss: 0.00372

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10145
Policy Update Magnitude: 0.53615
Value Function Update Magnitude: 0.60222

Collected Steps per Second: 22,158.38146
Overall Steps per Second: 10,646.55915

Timestep Collection Time: 2.25648
Timestep Consumption Time: 2.43987
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.69635

Cumulative Model Updates: 68,898
Cumulative Timesteps: 574,680,064

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.05517
Policy Entropy: 3.32222
Value Function Loss: 0.00364

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.52549
Value Function Update Magnitude: 0.60218

Collected Steps per Second: 22,385.95075
Overall Steps per Second: 10,582.56885

Timestep Collection Time: 2.23390
Timestep Consumption Time: 2.49161
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.72551

Cumulative Model Updates: 68,904
Cumulative Timesteps: 574,730,072

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 574730072...
Checkpoint 574730072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 890.05094
Policy Entropy: 3.32407
Value Function Loss: 0.00374

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.52755
Value Function Update Magnitude: 0.61557

Collected Steps per Second: 22,412.18101
Overall Steps per Second: 10,622.75887

Timestep Collection Time: 2.23120
Timestep Consumption Time: 2.47624
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.70744

Cumulative Model Updates: 68,910
Cumulative Timesteps: 574,780,078

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,477.65349
Policy Entropy: 3.32486
Value Function Loss: 0.00372

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10145
Policy Update Magnitude: 0.53730
Value Function Update Magnitude: 0.62608

Collected Steps per Second: 22,528.88413
Overall Steps per Second: 10,582.36449

Timestep Collection Time: 2.22053
Timestep Consumption Time: 2.50677
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.72730

Cumulative Model Updates: 68,916
Cumulative Timesteps: 574,830,104

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 574830104...
Checkpoint 574830104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178.49749
Policy Entropy: 3.32548
Value Function Loss: 0.00372

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11362
Policy Update Magnitude: 0.53478
Value Function Update Magnitude: 0.61766

Collected Steps per Second: 22,488.16729
Overall Steps per Second: 10,499.61516

Timestep Collection Time: 2.22339
Timestep Consumption Time: 2.53869
PPO Batch Consumption Time: 0.29710
Total Iteration Time: 4.76208

Cumulative Model Updates: 68,922
Cumulative Timesteps: 574,880,104

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.39686
Policy Entropy: 3.32586
Value Function Loss: 0.00369

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10363
Policy Update Magnitude: 0.53002
Value Function Update Magnitude: 0.60513

Collected Steps per Second: 23,179.32062
Overall Steps per Second: 10,832.15664

Timestep Collection Time: 2.15787
Timestep Consumption Time: 2.45968
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.61755

Cumulative Model Updates: 68,928
Cumulative Timesteps: 574,930,122

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 574930122...
Checkpoint 574930122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 919.25321
Policy Entropy: 3.33246
Value Function Loss: 0.00369

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09370
Policy Update Magnitude: 0.53450
Value Function Update Magnitude: 0.58084

Collected Steps per Second: 22,536.67438
Overall Steps per Second: 10,691.07327

Timestep Collection Time: 2.21869
Timestep Consumption Time: 2.45829
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.67699

Cumulative Model Updates: 68,934
Cumulative Timesteps: 574,980,124

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 921.50219
Policy Entropy: 3.32149
Value Function Loss: 0.00385

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09849
Policy Update Magnitude: 0.54156
Value Function Update Magnitude: 0.60898

Collected Steps per Second: 23,307.26990
Overall Steps per Second: 10,841.90775

Timestep Collection Time: 2.14525
Timestep Consumption Time: 2.46648
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.61173

Cumulative Model Updates: 68,940
Cumulative Timesteps: 575,030,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 575030124...
Checkpoint 575030124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.38151
Policy Entropy: 3.33317
Value Function Loss: 0.00402

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09930
Policy Update Magnitude: 0.54509
Value Function Update Magnitude: 0.63519

Collected Steps per Second: 22,315.41835
Overall Steps per Second: 10,681.54016

Timestep Collection Time: 2.24060
Timestep Consumption Time: 2.44037
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.68097

Cumulative Model Updates: 68,946
Cumulative Timesteps: 575,080,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.69634
Policy Entropy: 3.33310
Value Function Loss: 0.00401

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09256
Policy Update Magnitude: 0.54097
Value Function Update Magnitude: 0.62416

Collected Steps per Second: 23,005.42454
Overall Steps per Second: 10,739.70185

Timestep Collection Time: 2.17401
Timestep Consumption Time: 2.48292
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.65693

Cumulative Model Updates: 68,952
Cumulative Timesteps: 575,130,138

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 575130138...
Checkpoint 575130138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,410.39136
Policy Entropy: 3.33023
Value Function Loss: 0.00383

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09165
Policy Update Magnitude: 0.53312
Value Function Update Magnitude: 0.60949

Collected Steps per Second: 22,665.27005
Overall Steps per Second: 10,776.69066

Timestep Collection Time: 2.20628
Timestep Consumption Time: 2.43392
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.64020

Cumulative Model Updates: 68,958
Cumulative Timesteps: 575,180,144

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 960.84104
Policy Entropy: 3.32864
Value Function Loss: 0.00367

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.53299
Value Function Update Magnitude: 0.59893

Collected Steps per Second: 22,241.84293
Overall Steps per Second: 10,499.24350

Timestep Collection Time: 2.24864
Timestep Consumption Time: 2.51494
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.76358

Cumulative Model Updates: 68,964
Cumulative Timesteps: 575,230,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 575230158...
Checkpoint 575230158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.41954
Policy Entropy: 3.32477
Value Function Loss: 0.00372

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09423
Policy Update Magnitude: 0.53681
Value Function Update Magnitude: 0.59577

Collected Steps per Second: 22,230.32204
Overall Steps per Second: 10,698.44166

Timestep Collection Time: 2.25053
Timestep Consumption Time: 2.42585
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.67638

Cumulative Model Updates: 68,970
Cumulative Timesteps: 575,280,188

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707.41366
Policy Entropy: 3.31869
Value Function Loss: 0.00376

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09678
Policy Update Magnitude: 0.54011
Value Function Update Magnitude: 0.59766

Collected Steps per Second: 22,448.15271
Overall Steps per Second: 10,774.20540

Timestep Collection Time: 2.22842
Timestep Consumption Time: 2.41452
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.64294

Cumulative Model Updates: 68,976
Cumulative Timesteps: 575,330,212

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 575330212...
Checkpoint 575330212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 823.45377
Policy Entropy: 3.31507
Value Function Loss: 0.00377

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10545
Policy Update Magnitude: 0.54071
Value Function Update Magnitude: 0.61124

Collected Steps per Second: 22,519.39554
Overall Steps per Second: 10,717.97555

Timestep Collection Time: 2.22057
Timestep Consumption Time: 2.44505
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.66562

Cumulative Model Updates: 68,982
Cumulative Timesteps: 575,380,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 855.70082
Policy Entropy: 3.30339
Value Function Loss: 0.00402

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08719
Policy Update Magnitude: 0.55509
Value Function Update Magnitude: 0.63514

Collected Steps per Second: 22,885.27291
Overall Steps per Second: 10,824.62476

Timestep Collection Time: 2.18569
Timestep Consumption Time: 2.43526
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.62095

Cumulative Model Updates: 68,988
Cumulative Timesteps: 575,430,238

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 575430238...
Checkpoint 575430238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485.03109
Policy Entropy: 3.30630
Value Function Loss: 0.00419

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08740
Policy Update Magnitude: 0.56960
Value Function Update Magnitude: 0.66689

Collected Steps per Second: 22,362.87653
Overall Steps per Second: 10,739.99612

Timestep Collection Time: 2.23737
Timestep Consumption Time: 2.42129
PPO Batch Consumption Time: 0.28230
Total Iteration Time: 4.65866

Cumulative Model Updates: 68,994
Cumulative Timesteps: 575,480,272

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.28656
Policy Entropy: 3.29813
Value Function Loss: 0.00426

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09351
Policy Update Magnitude: 0.58032
Value Function Update Magnitude: 0.67993

Collected Steps per Second: 23,081.81873
Overall Steps per Second: 10,929.36699

Timestep Collection Time: 2.16707
Timestep Consumption Time: 2.40959
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 4.57666

Cumulative Model Updates: 69,000
Cumulative Timesteps: 575,530,292

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 575530292...
Checkpoint 575530292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 939.86417
Policy Entropy: 3.29639
Value Function Loss: 0.00429

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08858
Policy Update Magnitude: 0.57884
Value Function Update Magnitude: 0.69314

Collected Steps per Second: 22,665.62746
Overall Steps per Second: 10,635.80026

Timestep Collection Time: 2.20757
Timestep Consumption Time: 2.49692
PPO Batch Consumption Time: 0.29718
Total Iteration Time: 4.70449

Cumulative Model Updates: 69,006
Cumulative Timesteps: 575,580,328

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.78431
Policy Entropy: 3.29387
Value Function Loss: 0.00407

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09514
Policy Update Magnitude: 0.57213
Value Function Update Magnitude: 0.69233

Collected Steps per Second: 23,179.75790
Overall Steps per Second: 10,892.78704

Timestep Collection Time: 2.15731
Timestep Consumption Time: 2.43343
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.59074

Cumulative Model Updates: 69,012
Cumulative Timesteps: 575,630,334

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 575630334...
Checkpoint 575630334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.07956
Policy Entropy: 3.29236
Value Function Loss: 0.00388

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09707
Policy Update Magnitude: 0.56204
Value Function Update Magnitude: 0.65330

Collected Steps per Second: 22,213.74493
Overall Steps per Second: 10,646.37019

Timestep Collection Time: 2.25203
Timestep Consumption Time: 2.44685
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.69888

Cumulative Model Updates: 69,018
Cumulative Timesteps: 575,680,360

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 755.63282
Policy Entropy: 3.27862
Value Function Loss: 0.00371

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08755
Policy Update Magnitude: 0.54266
Value Function Update Magnitude: 0.62613

Collected Steps per Second: 22,492.53203
Overall Steps per Second: 10,884.45597

Timestep Collection Time: 2.22323
Timestep Consumption Time: 2.37103
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.59426

Cumulative Model Updates: 69,024
Cumulative Timesteps: 575,730,366

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 575730366...
Checkpoint 575730366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672.88208
Policy Entropy: 3.27191
Value Function Loss: 0.00382

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09092
Policy Update Magnitude: 0.54953
Value Function Update Magnitude: 0.61182

Collected Steps per Second: 21,887.31003
Overall Steps per Second: 10,706.02341

Timestep Collection Time: 2.28498
Timestep Consumption Time: 2.38641
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.67139

Cumulative Model Updates: 69,030
Cumulative Timesteps: 575,780,378

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677.25326
Policy Entropy: 3.26989
Value Function Loss: 0.00385

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09719
Policy Update Magnitude: 0.54923
Value Function Update Magnitude: 0.62484

Collected Steps per Second: 21,553.04931
Overall Steps per Second: 10,501.08702

Timestep Collection Time: 2.32079
Timestep Consumption Time: 2.44253
PPO Batch Consumption Time: 0.29632
Total Iteration Time: 4.76332

Cumulative Model Updates: 69,036
Cumulative Timesteps: 575,830,398

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 575830398...
Checkpoint 575830398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 989.73470
Policy Entropy: 3.27113
Value Function Loss: 0.00413

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09967
Policy Update Magnitude: 0.55183
Value Function Update Magnitude: 0.63295

Collected Steps per Second: 21,961.38262
Overall Steps per Second: 10,600.46577

Timestep Collection Time: 2.27727
Timestep Consumption Time: 2.44064
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 4.71791

Cumulative Model Updates: 69,042
Cumulative Timesteps: 575,880,410

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.61906
Policy Entropy: 3.27030
Value Function Loss: 0.00396

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08473
Policy Update Magnitude: 0.55195
Value Function Update Magnitude: 0.64750

Collected Steps per Second: 21,863.01361
Overall Steps per Second: 10,586.93406

Timestep Collection Time: 2.28752
Timestep Consumption Time: 2.43642
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.72394

Cumulative Model Updates: 69,048
Cumulative Timesteps: 575,930,422

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 575930422...
Checkpoint 575930422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 887.35733
Policy Entropy: 3.28782
Value Function Loss: 0.00396

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08073
Policy Update Magnitude: 0.55536
Value Function Update Magnitude: 0.64281

Collected Steps per Second: 22,311.39026
Overall Steps per Second: 10,845.89549

Timestep Collection Time: 2.24164
Timestep Consumption Time: 2.36969
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.61133

Cumulative Model Updates: 69,054
Cumulative Timesteps: 575,980,436

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 759.80270
Policy Entropy: 3.30152
Value Function Loss: 0.00377

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08029
Policy Update Magnitude: 0.54816
Value Function Update Magnitude: 0.62693

Collected Steps per Second: 22,180.53093
Overall Steps per Second: 10,681.52909

Timestep Collection Time: 2.25504
Timestep Consumption Time: 2.42762
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.68266

Cumulative Model Updates: 69,060
Cumulative Timesteps: 576,030,454

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 576030454...
Checkpoint 576030454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.18995
Policy Entropy: 3.30982
Value Function Loss: 0.00371

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08407
Policy Update Magnitude: 0.54607
Value Function Update Magnitude: 0.62560

Collected Steps per Second: 22,525.67409
Overall Steps per Second: 10,425.42426

Timestep Collection Time: 2.22040
Timestep Consumption Time: 2.57710
PPO Batch Consumption Time: 0.29683
Total Iteration Time: 4.79750

Cumulative Model Updates: 69,066
Cumulative Timesteps: 576,080,470

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.40246
Policy Entropy: 3.29898
Value Function Loss: 0.00366

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08096
Policy Update Magnitude: 0.54007
Value Function Update Magnitude: 0.62075

Collected Steps per Second: 22,950.63264
Overall Steps per Second: 10,675.15499

Timestep Collection Time: 2.17902
Timestep Consumption Time: 2.50568
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.68471

Cumulative Model Updates: 69,072
Cumulative Timesteps: 576,130,480

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 576130480...
Checkpoint 576130480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 755.66335
Policy Entropy: 3.29497
Value Function Loss: 0.00352

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09144
Policy Update Magnitude: 0.53516
Value Function Update Magnitude: 0.61037

Collected Steps per Second: 22,171.11425
Overall Steps per Second: 10,646.46002

Timestep Collection Time: 2.25627
Timestep Consumption Time: 2.44238
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.69865

Cumulative Model Updates: 69,078
Cumulative Timesteps: 576,180,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 861.91708
Policy Entropy: 3.29320
Value Function Loss: 0.00351

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09877
Policy Update Magnitude: 0.53156
Value Function Update Magnitude: 0.59420

Collected Steps per Second: 23,165.85868
Overall Steps per Second: 10,832.02047

Timestep Collection Time: 2.15947
Timestep Consumption Time: 2.45887
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.61834

Cumulative Model Updates: 69,084
Cumulative Timesteps: 576,230,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 576230530...
Checkpoint 576230530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 937.39721
Policy Entropy: 3.28058
Value Function Loss: 0.00353

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09441
Policy Update Magnitude: 0.53663
Value Function Update Magnitude: 0.57550

Collected Steps per Second: 22,155.76320
Overall Steps per Second: 10,652.37537

Timestep Collection Time: 2.25783
Timestep Consumption Time: 2.43821
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.69604

Cumulative Model Updates: 69,090
Cumulative Timesteps: 576,280,554

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.47353
Policy Entropy: 3.28418
Value Function Loss: 0.00356

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08835
Policy Update Magnitude: 0.53788
Value Function Update Magnitude: 0.57950

Collected Steps per Second: 22,376.66955
Overall Steps per Second: 10,546.32623

Timestep Collection Time: 2.23465
Timestep Consumption Time: 2.50672
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.74137

Cumulative Model Updates: 69,096
Cumulative Timesteps: 576,330,558

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 576330558...
Checkpoint 576330558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,964.14852
Policy Entropy: 3.28561
Value Function Loss: 0.00344

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08729
Policy Update Magnitude: 0.53458
Value Function Update Magnitude: 0.59410

Collected Steps per Second: 22,379.57191
Overall Steps per Second: 10,646.71856

Timestep Collection Time: 2.23543
Timestep Consumption Time: 2.46348
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.69891

Cumulative Model Updates: 69,102
Cumulative Timesteps: 576,380,586

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624.67390
Policy Entropy: 3.28999
Value Function Loss: 0.00357

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08418
Policy Update Magnitude: 0.53683
Value Function Update Magnitude: 0.59227

Collected Steps per Second: 22,544.04074
Overall Steps per Second: 10,577.94232

Timestep Collection Time: 2.21895
Timestep Consumption Time: 2.51014
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.72909

Cumulative Model Updates: 69,108
Cumulative Timesteps: 576,430,610

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 576430610...
Checkpoint 576430610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 886.00862
Policy Entropy: 3.26807
Value Function Loss: 0.00362

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.53620
Value Function Update Magnitude: 0.59544

Collected Steps per Second: 22,740.47043
Overall Steps per Second: 10,615.14926

Timestep Collection Time: 2.19908
Timestep Consumption Time: 2.51193
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.71100

Cumulative Model Updates: 69,114
Cumulative Timesteps: 576,480,618

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.49550
Policy Entropy: 3.25578
Value Function Loss: 0.00374

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09339
Policy Update Magnitude: 0.53610
Value Function Update Magnitude: 0.60887

Collected Steps per Second: 22,913.49932
Overall Steps per Second: 10,724.77704

Timestep Collection Time: 2.18256
Timestep Consumption Time: 2.48048
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.66303

Cumulative Model Updates: 69,120
Cumulative Timesteps: 576,530,628

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 576530628...
Checkpoint 576530628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.38162
Policy Entropy: 3.25440
Value Function Loss: 0.00368

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08125
Policy Update Magnitude: 0.54445
Value Function Update Magnitude: 0.62150

Collected Steps per Second: 22,802.96064
Overall Steps per Second: 10,666.24677

Timestep Collection Time: 2.19349
Timestep Consumption Time: 2.49589
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.68937

Cumulative Model Updates: 69,126
Cumulative Timesteps: 576,580,646

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.77253
Policy Entropy: 3.26307
Value Function Loss: 0.00360

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08506
Policy Update Magnitude: 0.53645
Value Function Update Magnitude: 0.61679

Collected Steps per Second: 22,949.91630
Overall Steps per Second: 10,724.43289

Timestep Collection Time: 2.17944
Timestep Consumption Time: 2.48449
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.66393

Cumulative Model Updates: 69,132
Cumulative Timesteps: 576,630,664

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 576630664...
Checkpoint 576630664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430.43098
Policy Entropy: 3.27281
Value Function Loss: 0.00347

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.52536
Value Function Update Magnitude: 0.61405

Collected Steps per Second: 22,802.70377
Overall Steps per Second: 10,759.38253

Timestep Collection Time: 2.19342
Timestep Consumption Time: 2.45517
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.64859

Cumulative Model Updates: 69,138
Cumulative Timesteps: 576,680,680

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.03695
Policy Entropy: 3.27745
Value Function Loss: 0.00348

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09387
Policy Update Magnitude: 0.52059
Value Function Update Magnitude: 0.60668

Collected Steps per Second: 23,001.36559
Overall Steps per Second: 10,743.96919

Timestep Collection Time: 2.17518
Timestep Consumption Time: 2.48158
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.65675

Cumulative Model Updates: 69,144
Cumulative Timesteps: 576,730,712

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 576730712...
Checkpoint 576730712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.58534
Policy Entropy: 3.28483
Value Function Loss: 0.00348

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.52140
Value Function Update Magnitude: 0.60795

Collected Steps per Second: 22,892.23202
Overall Steps per Second: 10,807.64125

Timestep Collection Time: 2.18467
Timestep Consumption Time: 2.44280
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.62747

Cumulative Model Updates: 69,150
Cumulative Timesteps: 576,780,724

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 802.52480
Policy Entropy: 3.28857
Value Function Loss: 0.00348

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09150
Policy Update Magnitude: 0.52103
Value Function Update Magnitude: 0.60419

Collected Steps per Second: 22,289.53051
Overall Steps per Second: 10,524.07698

Timestep Collection Time: 2.24347
Timestep Consumption Time: 2.50811
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.75158

Cumulative Model Updates: 69,156
Cumulative Timesteps: 576,830,730

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 576830730...
Checkpoint 576830730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.58277
Policy Entropy: 3.28538
Value Function Loss: 0.00357

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08141
Policy Update Magnitude: 0.52440
Value Function Update Magnitude: 0.60459

Collected Steps per Second: 22,468.98542
Overall Steps per Second: 10,727.50289

Timestep Collection Time: 2.22591
Timestep Consumption Time: 2.43631
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.66222

Cumulative Model Updates: 69,162
Cumulative Timesteps: 576,880,744

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 877.09458
Policy Entropy: 3.27543
Value Function Loss: 0.00363

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.52572
Value Function Update Magnitude: 0.61776

Collected Steps per Second: 22,713.46928
Overall Steps per Second: 10,747.25879

Timestep Collection Time: 2.20169
Timestep Consumption Time: 2.45140
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.65309

Cumulative Model Updates: 69,168
Cumulative Timesteps: 576,930,752

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 576930752...
Checkpoint 576930752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.93656
Policy Entropy: 3.26870
Value Function Loss: 0.00359

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08657
Policy Update Magnitude: 0.53373
Value Function Update Magnitude: 0.63188

Collected Steps per Second: 22,260.23609
Overall Steps per Second: 10,628.44253

Timestep Collection Time: 2.24661
Timestep Consumption Time: 2.45869
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.70530

Cumulative Model Updates: 69,174
Cumulative Timesteps: 576,980,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 749.59487
Policy Entropy: 3.28589
Value Function Loss: 0.00367

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08245
Policy Update Magnitude: 0.53498
Value Function Update Magnitude: 0.63439

Collected Steps per Second: 22,817.94348
Overall Steps per Second: 10,604.58743

Timestep Collection Time: 2.19187
Timestep Consumption Time: 2.52439
PPO Batch Consumption Time: 0.29703
Total Iteration Time: 4.71626

Cumulative Model Updates: 69,180
Cumulative Timesteps: 577,030,776

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 577030776...
Checkpoint 577030776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.25409
Policy Entropy: 3.28945
Value Function Loss: 0.00362

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08270
Policy Update Magnitude: 0.53986
Value Function Update Magnitude: 0.62983

Collected Steps per Second: 22,951.69564
Overall Steps per Second: 10,606.74614

Timestep Collection Time: 2.17875
Timestep Consumption Time: 2.53580
PPO Batch Consumption Time: 0.29722
Total Iteration Time: 4.71455

Cumulative Model Updates: 69,186
Cumulative Timesteps: 577,080,782

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 921.40949
Policy Entropy: 3.28958
Value Function Loss: 0.00376

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08557
Policy Update Magnitude: 0.53801
Value Function Update Magnitude: 0.64117

Collected Steps per Second: 23,106.12892
Overall Steps per Second: 10,828.96999

Timestep Collection Time: 2.16479
Timestep Consumption Time: 2.45430
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.61909

Cumulative Model Updates: 69,192
Cumulative Timesteps: 577,130,802

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 577130802...
Checkpoint 577130802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622.69544
Policy Entropy: 3.28227
Value Function Loss: 0.00377

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08938
Policy Update Magnitude: 0.54017
Value Function Update Magnitude: 0.64853

Collected Steps per Second: 23,032.71616
Overall Steps per Second: 10,706.59572

Timestep Collection Time: 2.17195
Timestep Consumption Time: 2.50049
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.67245

Cumulative Model Updates: 69,198
Cumulative Timesteps: 577,180,828

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.49882
Policy Entropy: 3.26958
Value Function Loss: 0.00391

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09367
Policy Update Magnitude: 0.54527
Value Function Update Magnitude: 0.64270

Collected Steps per Second: 22,513.70717
Overall Steps per Second: 10,561.96740

Timestep Collection Time: 2.22176
Timestep Consumption Time: 2.51410
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.73586

Cumulative Model Updates: 69,204
Cumulative Timesteps: 577,230,848

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 577230848...
Checkpoint 577230848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.74787
Policy Entropy: 3.26958
Value Function Loss: 0.00379

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10178
Policy Update Magnitude: 0.54893
Value Function Update Magnitude: 0.64064

Collected Steps per Second: 23,035.62233
Overall Steps per Second: 10,719.29055

Timestep Collection Time: 2.17055
Timestep Consumption Time: 2.49394
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.66449

Cumulative Model Updates: 69,210
Cumulative Timesteps: 577,280,848

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.93848
Policy Entropy: 3.26522
Value Function Loss: 0.00363

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.54432
Value Function Update Magnitude: 0.61178

Collected Steps per Second: 22,551.23785
Overall Steps per Second: 10,670.98758

Timestep Collection Time: 2.21779
Timestep Consumption Time: 2.46912
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.68691

Cumulative Model Updates: 69,216
Cumulative Timesteps: 577,330,862

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 577330862...
Checkpoint 577330862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 916.67514
Policy Entropy: 3.27707
Value Function Loss: 0.00360

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09151
Policy Update Magnitude: 0.53527
Value Function Update Magnitude: 0.58240

Collected Steps per Second: 22,305.72719
Overall Steps per Second: 10,715.68469

Timestep Collection Time: 2.24176
Timestep Consumption Time: 2.42467
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.66643

Cumulative Model Updates: 69,222
Cumulative Timesteps: 577,380,866

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.76194
Policy Entropy: 3.29961
Value Function Loss: 0.00354

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08463
Policy Update Magnitude: 0.53362
Value Function Update Magnitude: 0.58108

Collected Steps per Second: 22,347.73229
Overall Steps per Second: 10,515.38922

Timestep Collection Time: 2.23862
Timestep Consumption Time: 2.51898
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.75760

Cumulative Model Updates: 69,228
Cumulative Timesteps: 577,430,894

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 577430894...
Checkpoint 577430894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.02368
Policy Entropy: 3.31908
Value Function Loss: 0.00351

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.53084
Value Function Update Magnitude: 0.58975

Collected Steps per Second: 22,642.48854
Overall Steps per Second: 10,571.86643

Timestep Collection Time: 2.20841
Timestep Consumption Time: 2.52150
PPO Batch Consumption Time: 0.29588
Total Iteration Time: 4.72991

Cumulative Model Updates: 69,234
Cumulative Timesteps: 577,480,898

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.02051
Policy Entropy: 3.31034
Value Function Loss: 0.00356

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.53318
Value Function Update Magnitude: 0.59489

Collected Steps per Second: 22,747.68840
Overall Steps per Second: 10,631.46922

Timestep Collection Time: 2.19829
Timestep Consumption Time: 2.50529
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.70358

Cumulative Model Updates: 69,240
Cumulative Timesteps: 577,530,904

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 577530904...
Checkpoint 577530904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,378.83024
Policy Entropy: 3.31671
Value Function Loss: 0.00360

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07782
Policy Update Magnitude: 0.53496
Value Function Update Magnitude: 0.59512

Collected Steps per Second: 23,100.91732
Overall Steps per Second: 10,872.86577

Timestep Collection Time: 2.16632
Timestep Consumption Time: 2.43633
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.60265

Cumulative Model Updates: 69,246
Cumulative Timesteps: 577,580,948

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581.46048
Policy Entropy: 3.32066
Value Function Loss: 0.00367

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08760
Policy Update Magnitude: 0.53257
Value Function Update Magnitude: 0.60901

Collected Steps per Second: 22,570.53518
Overall Steps per Second: 10,494.21437

Timestep Collection Time: 2.21563
Timestep Consumption Time: 2.54966
PPO Batch Consumption Time: 0.29703
Total Iteration Time: 4.76529

Cumulative Model Updates: 69,252
Cumulative Timesteps: 577,630,956

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 577630956...
Checkpoint 577630956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.17038
Policy Entropy: 3.33610
Value Function Loss: 0.00375

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09673
Policy Update Magnitude: 0.52892
Value Function Update Magnitude: 0.62387

Collected Steps per Second: 22,980.71221
Overall Steps per Second: 10,650.32104

Timestep Collection Time: 2.17687
Timestep Consumption Time: 2.52027
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.69714

Cumulative Model Updates: 69,258
Cumulative Timesteps: 577,680,982

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.02555
Policy Entropy: 3.34324
Value Function Loss: 0.00376

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10408
Policy Update Magnitude: 0.52823
Value Function Update Magnitude: 0.63240

Collected Steps per Second: 22,888.37044
Overall Steps per Second: 10,788.52254

Timestep Collection Time: 2.18452
Timestep Consumption Time: 2.45004
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.63455

Cumulative Model Updates: 69,264
Cumulative Timesteps: 577,730,982

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 577730982...
Checkpoint 577730982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.58807
Policy Entropy: 3.33050
Value Function Loss: 0.00369

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09905
Policy Update Magnitude: 0.52998
Value Function Update Magnitude: 0.61593

Collected Steps per Second: 22,781.46366
Overall Steps per Second: 10,711.93229

Timestep Collection Time: 2.19661
Timestep Consumption Time: 2.47500
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.67161

Cumulative Model Updates: 69,270
Cumulative Timesteps: 577,781,024

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.68577
Policy Entropy: 3.31740
Value Function Loss: 0.00387

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11478
Policy Update Magnitude: 0.52510
Value Function Update Magnitude: 0.63318

Collected Steps per Second: 21,885.54295
Overall Steps per Second: 10,466.57985

Timestep Collection Time: 2.28571
Timestep Consumption Time: 2.49369
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.77940

Cumulative Model Updates: 69,276
Cumulative Timesteps: 577,831,048

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 577831048...
Checkpoint 577831048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 874.01543
Policy Entropy: 3.29480
Value Function Loss: 0.00379

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09424
Policy Update Magnitude: 0.53464
Value Function Update Magnitude: 0.62875

Collected Steps per Second: 22,346.04224
Overall Steps per Second: 10,619.42371

Timestep Collection Time: 2.23825
Timestep Consumption Time: 2.47161
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.70986

Cumulative Model Updates: 69,282
Cumulative Timesteps: 577,881,064

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.07590
Policy Entropy: 3.29642
Value Function Loss: 0.00360

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07753
Policy Update Magnitude: 0.54068
Value Function Update Magnitude: 0.61185

Collected Steps per Second: 22,518.92181
Overall Steps per Second: 10,536.10086

Timestep Collection Time: 2.22115
Timestep Consumption Time: 2.52614
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 4.74730

Cumulative Model Updates: 69,288
Cumulative Timesteps: 577,931,082

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 577931082...
Checkpoint 577931082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.00191
Policy Entropy: 3.30390
Value Function Loss: 0.00358

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08002
Policy Update Magnitude: 0.52986
Value Function Update Magnitude: 0.59149

Collected Steps per Second: 22,659.07570
Overall Steps per Second: 10,580.74333

Timestep Collection Time: 2.20697
Timestep Consumption Time: 2.51935
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.72632

Cumulative Model Updates: 69,294
Cumulative Timesteps: 577,981,090

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 976.32231
Policy Entropy: 3.32448
Value Function Loss: 0.00367

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08903
Policy Update Magnitude: 0.52432
Value Function Update Magnitude: 0.59736

Collected Steps per Second: 22,897.91547
Overall Steps per Second: 10,620.74370

Timestep Collection Time: 2.18483
Timestep Consumption Time: 2.52558
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.71040

Cumulative Model Updates: 69,300
Cumulative Timesteps: 578,031,118

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 578031118...
Checkpoint 578031118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.87991
Policy Entropy: 3.31501
Value Function Loss: 0.00354

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08086
Policy Update Magnitude: 0.52223
Value Function Update Magnitude: 0.58715

Collected Steps per Second: 22,796.04508
Overall Steps per Second: 10,675.87085

Timestep Collection Time: 2.19433
Timestep Consumption Time: 2.49119
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.68552

Cumulative Model Updates: 69,306
Cumulative Timesteps: 578,081,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.39843
Policy Entropy: 3.30283
Value Function Loss: 0.00385

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08356
Policy Update Magnitude: 0.53034
Value Function Update Magnitude: 0.59915

Collected Steps per Second: 22,921.86737
Overall Steps per Second: 10,660.56511

Timestep Collection Time: 2.18272
Timestep Consumption Time: 2.51047
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.69318

Cumulative Model Updates: 69,312
Cumulative Timesteps: 578,131,172

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 578131172...
Checkpoint 578131172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.05717
Policy Entropy: 3.30432
Value Function Loss: 0.00381

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08467
Policy Update Magnitude: 0.53967
Value Function Update Magnitude: 0.62812

Collected Steps per Second: 22,740.83857
Overall Steps per Second: 10,674.75040

Timestep Collection Time: 2.19904
Timestep Consumption Time: 2.48566
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.68470

Cumulative Model Updates: 69,318
Cumulative Timesteps: 578,181,180

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,411.35929
Policy Entropy: 3.31351
Value Function Loss: 0.00397

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09003
Policy Update Magnitude: 0.53816
Value Function Update Magnitude: 0.62679

Collected Steps per Second: 22,685.18758
Overall Steps per Second: 10,608.31764

Timestep Collection Time: 2.20408
Timestep Consumption Time: 2.50920
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.71328

Cumulative Model Updates: 69,324
Cumulative Timesteps: 578,231,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 578231180...
Checkpoint 578231180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.23311
Policy Entropy: 3.31305
Value Function Loss: 0.00363

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10267
Policy Update Magnitude: 0.53805
Value Function Update Magnitude: 0.59299

Collected Steps per Second: 23,115.09595
Overall Steps per Second: 10,833.48503

Timestep Collection Time: 2.16318
Timestep Consumption Time: 2.45233
PPO Batch Consumption Time: 0.28383
Total Iteration Time: 4.61550

Cumulative Model Updates: 69,330
Cumulative Timesteps: 578,281,182

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 781.18292
Policy Entropy: 3.29257
Value Function Loss: 0.00380

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10673
Policy Update Magnitude: 0.53279
Value Function Update Magnitude: 0.58253

Collected Steps per Second: 22,283.01334
Overall Steps per Second: 10,571.33227

Timestep Collection Time: 2.24404
Timestep Consumption Time: 2.48611
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.73015

Cumulative Model Updates: 69,336
Cumulative Timesteps: 578,331,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 578331186...
Checkpoint 578331186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.10088
Policy Entropy: 3.27221
Value Function Loss: 0.00382

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10384
Policy Update Magnitude: 0.53649
Value Function Update Magnitude: 0.59639

Collected Steps per Second: 21,930.61131
Overall Steps per Second: 10,573.43481

Timestep Collection Time: 2.28010
Timestep Consumption Time: 2.44911
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.72921

Cumulative Model Updates: 69,342
Cumulative Timesteps: 578,381,190

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.57470
Policy Entropy: 3.26733
Value Function Loss: 0.00385

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12073
Policy Update Magnitude: 0.53899
Value Function Update Magnitude: 0.59932

Collected Steps per Second: 22,353.86273
Overall Steps per Second: 10,504.71428

Timestep Collection Time: 2.23702
Timestep Consumption Time: 2.52332
PPO Batch Consumption Time: 0.29556
Total Iteration Time: 4.76034

Cumulative Model Updates: 69,348
Cumulative Timesteps: 578,431,196

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 578431196...
Checkpoint 578431196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 986.74408
Policy Entropy: 3.27068
Value Function Loss: 0.00367

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11289
Policy Update Magnitude: 0.53285
Value Function Update Magnitude: 0.59892

Collected Steps per Second: 22,154.18235
Overall Steps per Second: 10,631.04029

Timestep Collection Time: 2.25727
Timestep Consumption Time: 2.44669
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.70396

Cumulative Model Updates: 69,354
Cumulative Timesteps: 578,481,204

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,444.15406
Policy Entropy: 3.26524
Value Function Loss: 0.00363

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.53724
Value Function Update Magnitude: 0.61580

Collected Steps per Second: 22,566.65279
Overall Steps per Second: 10,568.84646

Timestep Collection Time: 2.21575
Timestep Consumption Time: 2.51533
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.73107

Cumulative Model Updates: 69,360
Cumulative Timesteps: 578,531,206

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 578531206...
Checkpoint 578531206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,341.29107
Policy Entropy: 3.27380
Value Function Loss: 0.00368

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.54242
Value Function Update Magnitude: 0.61905

Collected Steps per Second: 21,933.33385
Overall Steps per Second: 10,501.56453

Timestep Collection Time: 2.28091
Timestep Consumption Time: 2.48295
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.76386

Cumulative Model Updates: 69,366
Cumulative Timesteps: 578,581,234

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659.08530
Policy Entropy: 3.28073
Value Function Loss: 0.00378

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08483
Policy Update Magnitude: 0.55085
Value Function Update Magnitude: 0.61637

Collected Steps per Second: 22,633.44946
Overall Steps per Second: 10,513.74889

Timestep Collection Time: 2.20947
Timestep Consumption Time: 2.54697
PPO Batch Consumption Time: 0.29578
Total Iteration Time: 4.75644

Cumulative Model Updates: 69,372
Cumulative Timesteps: 578,631,242

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 578631242...
Checkpoint 578631242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.68678
Policy Entropy: 3.29638
Value Function Loss: 0.00391

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09788
Policy Update Magnitude: 0.55343
Value Function Update Magnitude: 0.61848

Collected Steps per Second: 22,660.44660
Overall Steps per Second: 10,563.72494

Timestep Collection Time: 2.20746
Timestep Consumption Time: 2.52780
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.73526

Cumulative Model Updates: 69,378
Cumulative Timesteps: 578,681,264

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 919.85091
Policy Entropy: 3.29105
Value Function Loss: 0.00390

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.55449
Value Function Update Magnitude: 0.61340

Collected Steps per Second: 23,011.95373
Overall Steps per Second: 10,725.42569

Timestep Collection Time: 2.17287
Timestep Consumption Time: 2.48914
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.66201

Cumulative Model Updates: 69,384
Cumulative Timesteps: 578,731,266

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 578731266...
Checkpoint 578731266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078.71203
Policy Entropy: 3.29823
Value Function Loss: 0.00381

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08282
Policy Update Magnitude: 0.54669
Value Function Update Magnitude: 0.62026

Collected Steps per Second: 22,782.04303
Overall Steps per Second: 10,753.13459

Timestep Collection Time: 2.19533
Timestep Consumption Time: 2.45578
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.65111

Cumulative Model Updates: 69,390
Cumulative Timesteps: 578,781,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.74963
Policy Entropy: 3.30231
Value Function Loss: 0.00372

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07370
Policy Update Magnitude: 0.54209
Value Function Update Magnitude: 0.59938

Collected Steps per Second: 22,771.56240
Overall Steps per Second: 10,545.49723

Timestep Collection Time: 2.19634
Timestep Consumption Time: 2.54635
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.74269

Cumulative Model Updates: 69,396
Cumulative Timesteps: 578,831,294

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 578831294...
Checkpoint 578831294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.11283
Policy Entropy: 3.30941
Value Function Loss: 0.00364

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07203
Policy Update Magnitude: 0.54470
Value Function Update Magnitude: 0.58011

Collected Steps per Second: 22,955.73356
Overall Steps per Second: 10,638.94447

Timestep Collection Time: 2.17924
Timestep Consumption Time: 2.52292
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.70216

Cumulative Model Updates: 69,402
Cumulative Timesteps: 578,881,320

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.34811
Policy Entropy: 3.29580
Value Function Loss: 0.00365

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07999
Policy Update Magnitude: 0.54758
Value Function Update Magnitude: 0.57962

Collected Steps per Second: 22,820.59652
Overall Steps per Second: 10,700.82667

Timestep Collection Time: 2.19100
Timestep Consumption Time: 2.48153
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.67254

Cumulative Model Updates: 69,408
Cumulative Timesteps: 578,931,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 578931320...
Checkpoint 578931320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 862.68768
Policy Entropy: 3.29398
Value Function Loss: 0.00378

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.54526
Value Function Update Magnitude: 0.58021

Collected Steps per Second: 22,289.59763
Overall Steps per Second: 10,543.90706

Timestep Collection Time: 2.24365
Timestep Consumption Time: 2.49938
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.74302

Cumulative Model Updates: 69,414
Cumulative Timesteps: 578,981,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.48132
Policy Entropy: 3.29630
Value Function Loss: 0.00369

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08977
Policy Update Magnitude: 0.54775
Value Function Update Magnitude: 0.57981

Collected Steps per Second: 22,714.70006
Overall Steps per Second: 10,774.34915

Timestep Collection Time: 2.20175
Timestep Consumption Time: 2.44002
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.64177

Cumulative Model Updates: 69,420
Cumulative Timesteps: 579,031,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 579031342...
Checkpoint 579031342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 898.20273
Policy Entropy: 3.30239
Value Function Loss: 0.00380

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07430
Policy Update Magnitude: 0.54859
Value Function Update Magnitude: 0.59944

Collected Steps per Second: 22,267.03650
Overall Steps per Second: 10,582.28241

Timestep Collection Time: 2.24601
Timestep Consumption Time: 2.48000
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.72601

Cumulative Model Updates: 69,426
Cumulative Timesteps: 579,081,354

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.40843
Policy Entropy: 3.29691
Value Function Loss: 0.00390

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08448
Policy Update Magnitude: 0.55687
Value Function Update Magnitude: 0.62571

Collected Steps per Second: 22,419.22033
Overall Steps per Second: 10,593.96207

Timestep Collection Time: 2.23112
Timestep Consumption Time: 2.49044
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.72156

Cumulative Model Updates: 69,432
Cumulative Timesteps: 579,131,374

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 579131374...
Checkpoint 579131374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.77062
Policy Entropy: 3.29331
Value Function Loss: 0.00392

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08476
Policy Update Magnitude: 0.56275
Value Function Update Magnitude: 0.63842

Collected Steps per Second: 22,491.13567
Overall Steps per Second: 10,598.17851

Timestep Collection Time: 2.22363
Timestep Consumption Time: 2.49529
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.71892

Cumulative Model Updates: 69,438
Cumulative Timesteps: 579,181,386

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.53442
Policy Entropy: 3.28852
Value Function Loss: 0.00392

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09058
Policy Update Magnitude: 0.56202
Value Function Update Magnitude: 0.63182

Collected Steps per Second: 22,794.96039
Overall Steps per Second: 10,755.53459

Timestep Collection Time: 2.19417
Timestep Consumption Time: 2.45609
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.65026

Cumulative Model Updates: 69,444
Cumulative Timesteps: 579,231,402

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 579231402...
Checkpoint 579231402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.72106
Policy Entropy: 3.28548
Value Function Loss: 0.00375

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08023
Policy Update Magnitude: 0.56182
Value Function Update Magnitude: 0.63480

Collected Steps per Second: 22,675.14788
Overall Steps per Second: 10,676.26499

Timestep Collection Time: 2.20567
Timestep Consumption Time: 2.47892
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.68460

Cumulative Model Updates: 69,450
Cumulative Timesteps: 579,281,416

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 785.06933
Policy Entropy: 3.28323
Value Function Loss: 0.00370

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.55556
Value Function Update Magnitude: 0.63285

Collected Steps per Second: 22,688.19397
Overall Steps per Second: 10,715.33529

Timestep Collection Time: 2.20441
Timestep Consumption Time: 2.46311
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.66752

Cumulative Model Updates: 69,456
Cumulative Timesteps: 579,331,430

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 579331430...
Checkpoint 579331430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.85349
Policy Entropy: 3.28856
Value Function Loss: 0.00355

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09760
Policy Update Magnitude: 0.54360
Value Function Update Magnitude: 0.62298

Collected Steps per Second: 23,186.82936
Overall Steps per Second: 10,862.21032

Timestep Collection Time: 2.15640
Timestep Consumption Time: 2.44672
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.60311

Cumulative Model Updates: 69,462
Cumulative Timesteps: 579,381,430

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.46547
Policy Entropy: 3.30002
Value Function Loss: 0.00363

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09763
Policy Update Magnitude: 0.53605
Value Function Update Magnitude: 0.59090

Collected Steps per Second: 22,796.47691
Overall Steps per Second: 10,818.53461

Timestep Collection Time: 2.19420
Timestep Consumption Time: 2.42935
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.62355

Cumulative Model Updates: 69,468
Cumulative Timesteps: 579,431,450

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 579431450...
Checkpoint 579431450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 909.30683
Policy Entropy: 3.30280
Value Function Loss: 0.00360

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08854
Policy Update Magnitude: 0.53384
Value Function Update Magnitude: 0.57355

Collected Steps per Second: 22,777.11531
Overall Steps per Second: 10,721.74893

Timestep Collection Time: 2.19642
Timestep Consumption Time: 2.46961
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.66603

Cumulative Model Updates: 69,474
Cumulative Timesteps: 579,481,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430.71001
Policy Entropy: 3.30507
Value Function Loss: 0.00366

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08964
Policy Update Magnitude: 0.53629
Value Function Update Magnitude: 0.57689

Collected Steps per Second: 22,310.94950
Overall Steps per Second: 10,586.37622

Timestep Collection Time: 2.24150
Timestep Consumption Time: 2.48250
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.72400

Cumulative Model Updates: 69,480
Cumulative Timesteps: 579,531,488

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 579531488...
Checkpoint 579531488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 833.08142
Policy Entropy: 3.29493
Value Function Loss: 0.00358

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09340
Policy Update Magnitude: 0.53971
Value Function Update Magnitude: 0.58204

Collected Steps per Second: 22,667.98998
Overall Steps per Second: 10,695.55118

Timestep Collection Time: 2.20699
Timestep Consumption Time: 2.47047
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.67746

Cumulative Model Updates: 69,486
Cumulative Timesteps: 579,581,516

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.11449
Policy Entropy: 3.30251
Value Function Loss: 0.00363

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09336
Policy Update Magnitude: 0.54616
Value Function Update Magnitude: 0.58906

Collected Steps per Second: 22,479.65804
Overall Steps per Second: 10,681.36438

Timestep Collection Time: 2.22459
Timestep Consumption Time: 2.45721
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.68180

Cumulative Model Updates: 69,492
Cumulative Timesteps: 579,631,524

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 579631524...
Checkpoint 579631524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300.93620
Policy Entropy: 3.30398
Value Function Loss: 0.00352

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09495
Policy Update Magnitude: 0.53951
Value Function Update Magnitude: 0.59141

Collected Steps per Second: 22,166.42213
Overall Steps per Second: 10,704.34088

Timestep Collection Time: 2.25675
Timestep Consumption Time: 2.41650
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.67324

Cumulative Model Updates: 69,498
Cumulative Timesteps: 579,681,548

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.45050
Policy Entropy: 3.30934
Value Function Loss: 0.00351

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10190
Policy Update Magnitude: 0.53816
Value Function Update Magnitude: 0.58921

Collected Steps per Second: 22,863.71818
Overall Steps per Second: 10,785.70906

Timestep Collection Time: 2.18792
Timestep Consumption Time: 2.45007
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.63799

Cumulative Model Updates: 69,504
Cumulative Timesteps: 579,731,572

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 579731572...
Checkpoint 579731572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.85511
Policy Entropy: 3.31116
Value Function Loss: 0.00345

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.54207
Value Function Update Magnitude: 0.58702

Collected Steps per Second: 22,656.76590
Overall Steps per Second: 10,730.64328

Timestep Collection Time: 2.20685
Timestep Consumption Time: 2.45271
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.65955

Cumulative Model Updates: 69,510
Cumulative Timesteps: 579,781,572

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.24771
Policy Entropy: 3.32165
Value Function Loss: 0.00368

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09719
Policy Update Magnitude: 0.53727
Value Function Update Magnitude: 0.59786

Collected Steps per Second: 22,271.62964
Overall Steps per Second: 10,557.51363

Timestep Collection Time: 2.24600
Timestep Consumption Time: 2.49205
PPO Batch Consumption Time: 0.29585
Total Iteration Time: 4.73805

Cumulative Model Updates: 69,516
Cumulative Timesteps: 579,831,594

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 579831594...
Checkpoint 579831594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 946.94899
Policy Entropy: 3.31815
Value Function Loss: 0.00356

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10155
Policy Update Magnitude: 0.52813
Value Function Update Magnitude: 0.58472

Collected Steps per Second: 22,941.54529
Overall Steps per Second: 10,870.87198

Timestep Collection Time: 2.18041
Timestep Consumption Time: 2.42106
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.60147

Cumulative Model Updates: 69,522
Cumulative Timesteps: 579,881,616

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.89403
Policy Entropy: 3.33140
Value Function Loss: 0.00351

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09722
Policy Update Magnitude: 0.52364
Value Function Update Magnitude: 0.56736

Collected Steps per Second: 22,679.50672
Overall Steps per Second: 10,643.43787

Timestep Collection Time: 2.20516
Timestep Consumption Time: 2.49370
PPO Batch Consumption Time: 0.29658
Total Iteration Time: 4.69886

Cumulative Model Updates: 69,528
Cumulative Timesteps: 579,931,628

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 579931628...
Checkpoint 579931628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 911.56925
Policy Entropy: 3.34248
Value Function Loss: 0.00355

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08676
Policy Update Magnitude: 0.51801
Value Function Update Magnitude: 0.55515

Collected Steps per Second: 22,703.26043
Overall Steps per Second: 10,657.88862

Timestep Collection Time: 2.20294
Timestep Consumption Time: 2.48973
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 4.69267

Cumulative Model Updates: 69,534
Cumulative Timesteps: 579,981,642

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.12260
Policy Entropy: 3.33754
Value Function Loss: 0.00369

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09128
Policy Update Magnitude: 0.52653
Value Function Update Magnitude: 0.57166

Collected Steps per Second: 22,418.28146
Overall Steps per Second: 10,751.55553

Timestep Collection Time: 2.23095
Timestep Consumption Time: 2.42084
PPO Batch Consumption Time: 0.28201
Total Iteration Time: 4.65179

Cumulative Model Updates: 69,540
Cumulative Timesteps: 580,031,656

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 580031656...
Checkpoint 580031656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.44323
Policy Entropy: 3.33694
Value Function Loss: 0.00363

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09937
Policy Update Magnitude: 0.53281
Value Function Update Magnitude: 0.60417

Collected Steps per Second: 22,417.73190
Overall Steps per Second: 10,734.14078

Timestep Collection Time: 2.23047
Timestep Consumption Time: 2.42775
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.65822

Cumulative Model Updates: 69,546
Cumulative Timesteps: 580,081,658

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 895.18018
Policy Entropy: 3.33932
Value Function Loss: 0.00361

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08747
Policy Update Magnitude: 0.53563
Value Function Update Magnitude: 0.61016

Collected Steps per Second: 22,509.85870
Overall Steps per Second: 10,684.51690

Timestep Collection Time: 2.22169
Timestep Consumption Time: 2.45891
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.68060

Cumulative Model Updates: 69,552
Cumulative Timesteps: 580,131,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 580131668...
Checkpoint 580131668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 809.44133
Policy Entropy: 3.33256
Value Function Loss: 0.00383

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09266
Policy Update Magnitude: 0.53762
Value Function Update Magnitude: 0.60378

Collected Steps per Second: 22,595.44597
Overall Steps per Second: 10,749.28453

Timestep Collection Time: 2.21363
Timestep Consumption Time: 2.43952
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.65315

Cumulative Model Updates: 69,558
Cumulative Timesteps: 580,181,686

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.53584
Policy Entropy: 3.32868
Value Function Loss: 0.00383

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08060
Policy Update Magnitude: 0.53854
Value Function Update Magnitude: 0.59500

Collected Steps per Second: 22,671.43814
Overall Steps per Second: 10,546.27873

Timestep Collection Time: 2.20701
Timestep Consumption Time: 2.53742
PPO Batch Consumption Time: 0.29733
Total Iteration Time: 4.74442

Cumulative Model Updates: 69,564
Cumulative Timesteps: 580,231,722

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 580231722...
Checkpoint 580231722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 778.28613
Policy Entropy: 3.31743
Value Function Loss: 0.00393

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.07989
Policy Update Magnitude: 0.54691
Value Function Update Magnitude: 0.60447

Collected Steps per Second: 22,906.85802
Overall Steps per Second: 10,654.10051

Timestep Collection Time: 2.18336
Timestep Consumption Time: 2.51098
PPO Batch Consumption Time: 0.29750
Total Iteration Time: 4.69434

Cumulative Model Updates: 69,570
Cumulative Timesteps: 580,281,736

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.42980
Policy Entropy: 3.33293
Value Function Loss: 0.00382

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10819
Policy Update Magnitude: 0.53875
Value Function Update Magnitude: 0.64124

Collected Steps per Second: 22,990.61932
Overall Steps per Second: 10,853.23572

Timestep Collection Time: 2.17532
Timestep Consumption Time: 2.43270
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.60803

Cumulative Model Updates: 69,576
Cumulative Timesteps: 580,331,748

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 580331748...
Checkpoint 580331748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 940.40981
Policy Entropy: 3.33369
Value Function Loss: 0.00363

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09047
Policy Update Magnitude: 0.53408
Value Function Update Magnitude: 0.66772

Collected Steps per Second: 22,609.27469
Overall Steps per Second: 10,641.83439

Timestep Collection Time: 2.21175
Timestep Consumption Time: 2.48725
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.69900

Cumulative Model Updates: 69,582
Cumulative Timesteps: 580,381,754

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.50148
Policy Entropy: 3.33468
Value Function Loss: 0.00382

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.11993
Policy Update Magnitude: 0.54244
Value Function Update Magnitude: 0.66484

Collected Steps per Second: 22,797.54824
Overall Steps per Second: 10,687.72907

Timestep Collection Time: 2.19322
Timestep Consumption Time: 2.48504
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.67826

Cumulative Model Updates: 69,588
Cumulative Timesteps: 580,431,754

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 580431754...
Checkpoint 580431754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 804.48788
Policy Entropy: 3.32705
Value Function Loss: 0.00387

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11124
Policy Update Magnitude: 0.54153
Value Function Update Magnitude: 0.65409

Collected Steps per Second: 22,893.02453
Overall Steps per Second: 10,858.70402

Timestep Collection Time: 2.18547
Timestep Consumption Time: 2.42208
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.60755

Cumulative Model Updates: 69,594
Cumulative Timesteps: 580,481,786

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801.40955
Policy Entropy: 3.32367
Value Function Loss: 0.00378

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11128
Policy Update Magnitude: 0.54373
Value Function Update Magnitude: 0.66511

Collected Steps per Second: 22,706.45122
Overall Steps per Second: 10,723.85392

Timestep Collection Time: 2.20325
Timestep Consumption Time: 2.46186
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.66511

Cumulative Model Updates: 69,600
Cumulative Timesteps: 580,531,814

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 580531814...
Checkpoint 580531814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481.61354
Policy Entropy: 3.34097
Value Function Loss: 0.00354

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.10930
Policy Update Magnitude: 0.54177
Value Function Update Magnitude: 0.64992

Collected Steps per Second: 22,657.08743
Overall Steps per Second: 10,811.35353

Timestep Collection Time: 2.20708
Timestep Consumption Time: 2.41824
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.62532

Cumulative Model Updates: 69,606
Cumulative Timesteps: 580,581,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760.51521
Policy Entropy: 3.32841
Value Function Loss: 0.00378

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.11778
Policy Update Magnitude: 0.53983
Value Function Update Magnitude: 0.63318

Collected Steps per Second: 22,112.15268
Overall Steps per Second: 10,495.05825

Timestep Collection Time: 2.26192
Timestep Consumption Time: 2.50375
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.76567

Cumulative Model Updates: 69,612
Cumulative Timesteps: 580,631,836

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 580631836...
Checkpoint 580631836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 665.49105
Policy Entropy: 3.31797
Value Function Loss: 0.00387

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10660
Policy Update Magnitude: 0.54535
Value Function Update Magnitude: 0.64476

Collected Steps per Second: 22,329.89352
Overall Steps per Second: 10,658.84183

Timestep Collection Time: 2.24112
Timestep Consumption Time: 2.45395
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.69507

Cumulative Model Updates: 69,618
Cumulative Timesteps: 580,681,880

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.08293
Policy Entropy: 3.30455
Value Function Loss: 0.00392

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.55226
Value Function Update Magnitude: 0.64379

Collected Steps per Second: 22,141.82405
Overall Steps per Second: 10,523.73193

Timestep Collection Time: 2.25826
Timestep Consumption Time: 2.49310
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.75136

Cumulative Model Updates: 69,624
Cumulative Timesteps: 580,731,882

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 580731882...
Checkpoint 580731882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 961.52523
Policy Entropy: 3.30495
Value Function Loss: 0.00396

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.55599
Value Function Update Magnitude: 0.65720

Collected Steps per Second: 22,217.22976
Overall Steps per Second: 10,542.60734

Timestep Collection Time: 2.25051
Timestep Consumption Time: 2.49215
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.74266

Cumulative Model Updates: 69,630
Cumulative Timesteps: 580,781,882

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 958.40553
Policy Entropy: 3.31141
Value Function Loss: 0.00399

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11056
Policy Update Magnitude: 0.55835
Value Function Update Magnitude: 0.66311

Collected Steps per Second: 22,815.50710
Overall Steps per Second: 10,627.23188

Timestep Collection Time: 2.19246
Timestep Consumption Time: 2.51451
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.70696

Cumulative Model Updates: 69,636
Cumulative Timesteps: 580,831,904

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 580831904...
Checkpoint 580831904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 802.52545
Policy Entropy: 3.32480
Value Function Loss: 0.00384

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.10875
Policy Update Magnitude: 0.55636
Value Function Update Magnitude: 0.65075

Collected Steps per Second: 22,865.37561
Overall Steps per Second: 10,811.04425

Timestep Collection Time: 2.18750
Timestep Consumption Time: 2.43907
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.62657

Cumulative Model Updates: 69,642
Cumulative Timesteps: 580,881,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.28616
Policy Entropy: 3.33273
Value Function Loss: 0.00390

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.10975
Policy Update Magnitude: 0.54723
Value Function Update Magnitude: 0.64174

Collected Steps per Second: 22,832.72298
Overall Steps per Second: 10,729.11061

Timestep Collection Time: 2.19063
Timestep Consumption Time: 2.47127
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.66190

Cumulative Model Updates: 69,648
Cumulative Timesteps: 580,931,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 580931940...
Checkpoint 580931940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,145.52903
Policy Entropy: 3.34637
Value Function Loss: 0.00382

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09056
Policy Update Magnitude: 0.54290
Value Function Update Magnitude: 0.64425

Collected Steps per Second: 22,723.62764
Overall Steps per Second: 10,692.22528

Timestep Collection Time: 2.20097
Timestep Consumption Time: 2.47664
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.67760

Cumulative Model Updates: 69,654
Cumulative Timesteps: 580,981,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.07015
Policy Entropy: 3.33795
Value Function Loss: 0.00390

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08588
Policy Update Magnitude: 0.54349
Value Function Update Magnitude: 0.64974

Collected Steps per Second: 22,786.19694
Overall Steps per Second: 10,673.69951

Timestep Collection Time: 2.19554
Timestep Consumption Time: 2.49150
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.68703

Cumulative Model Updates: 69,660
Cumulative Timesteps: 581,031,982

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 581031982...
Checkpoint 581031982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 915.43210
Policy Entropy: 3.33238
Value Function Loss: 0.00378

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08936
Policy Update Magnitude: 0.54529
Value Function Update Magnitude: 0.65294

Collected Steps per Second: 22,847.72040
Overall Steps per Second: 10,676.99936

Timestep Collection Time: 2.18954
Timestep Consumption Time: 2.49586
PPO Batch Consumption Time: 0.29709
Total Iteration Time: 4.68540

Cumulative Model Updates: 69,666
Cumulative Timesteps: 581,082,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,727.64116
Policy Entropy: 3.30003
Value Function Loss: 0.00380

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.54704
Value Function Update Magnitude: 0.65555

Collected Steps per Second: 22,539.98542
Overall Steps per Second: 10,779.19767

Timestep Collection Time: 2.21899
Timestep Consumption Time: 2.42106
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.64005

Cumulative Model Updates: 69,672
Cumulative Timesteps: 581,132,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 581132024...
Checkpoint 581132024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,354.83010
Policy Entropy: 3.28801
Value Function Loss: 0.00387

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.55132
Value Function Update Magnitude: 0.67254

Collected Steps per Second: 22,608.34363
Overall Steps per Second: 10,755.43930

Timestep Collection Time: 2.21228
Timestep Consumption Time: 2.43802
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.65030

Cumulative Model Updates: 69,678
Cumulative Timesteps: 581,182,040

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669.21148
Policy Entropy: 3.30001
Value Function Loss: 0.00392

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.56282
Value Function Update Magnitude: 0.69378

Collected Steps per Second: 22,308.14779
Overall Steps per Second: 10,553.13479

Timestep Collection Time: 2.24142
Timestep Consumption Time: 2.49669
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.73812

Cumulative Model Updates: 69,684
Cumulative Timesteps: 581,232,042

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 581232042...
Checkpoint 581232042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,515.41334
Policy Entropy: 3.31421
Value Function Loss: 0.00370

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.56197
Value Function Update Magnitude: 0.70030

Collected Steps per Second: 22,785.38926
Overall Steps per Second: 10,687.19027

Timestep Collection Time: 2.19535
Timestep Consumption Time: 2.48520
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.68056

Cumulative Model Updates: 69,690
Cumulative Timesteps: 581,282,064

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,616.45901
Policy Entropy: 3.31480
Value Function Loss: 0.00357

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08974
Policy Update Magnitude: 0.54493
Value Function Update Magnitude: 0.69423

Collected Steps per Second: 23,107.17078
Overall Steps per Second: 10,771.54577

Timestep Collection Time: 2.16487
Timestep Consumption Time: 2.47922
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.64409

Cumulative Model Updates: 69,696
Cumulative Timesteps: 581,332,088

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 581332088...
Checkpoint 581332088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.08624
Policy Entropy: 3.31292
Value Function Loss: 0.00350

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08392
Policy Update Magnitude: 0.53788
Value Function Update Magnitude: 0.67993

Collected Steps per Second: 22,372.48942
Overall Steps per Second: 10,606.45215

Timestep Collection Time: 2.23560
Timestep Consumption Time: 2.48002
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.71562

Cumulative Model Updates: 69,702
Cumulative Timesteps: 581,382,104

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 810.21340
Policy Entropy: 3.30912
Value Function Loss: 0.00363

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09334
Policy Update Magnitude: 0.54163
Value Function Update Magnitude: 0.68437

Collected Steps per Second: 23,001.00795
Overall Steps per Second: 10,872.48260

Timestep Collection Time: 2.17451
Timestep Consumption Time: 2.42572
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.60024

Cumulative Model Updates: 69,708
Cumulative Timesteps: 581,432,120

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 581432120...
Checkpoint 581432120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,990.93323
Policy Entropy: 3.29300
Value Function Loss: 0.00374

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09469
Policy Update Magnitude: 0.54452
Value Function Update Magnitude: 0.68751

Collected Steps per Second: 22,500.67970
Overall Steps per Second: 10,689.26851

Timestep Collection Time: 2.22340
Timestep Consumption Time: 2.45681
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.68021

Cumulative Model Updates: 69,714
Cumulative Timesteps: 581,482,148

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 999.84746
Policy Entropy: 3.30045
Value Function Loss: 0.00388

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09327
Policy Update Magnitude: 0.55143
Value Function Update Magnitude: 0.69328

Collected Steps per Second: 22,982.81515
Overall Steps per Second: 10,872.05580

Timestep Collection Time: 2.17580
Timestep Consumption Time: 2.42370
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.59950

Cumulative Model Updates: 69,720
Cumulative Timesteps: 581,532,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 581532154...
Checkpoint 581532154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 937.93640
Policy Entropy: 3.28819
Value Function Loss: 0.00392

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08863
Policy Update Magnitude: 0.56238
Value Function Update Magnitude: 0.72387

Collected Steps per Second: 22,255.51933
Overall Steps per Second: 10,744.21762

Timestep Collection Time: 2.24744
Timestep Consumption Time: 2.40790
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.65534

Cumulative Model Updates: 69,726
Cumulative Timesteps: 581,582,172

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.05487
Policy Entropy: 3.30109
Value Function Loss: 0.00382

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08787
Policy Update Magnitude: 0.56643
Value Function Update Magnitude: 0.70178

Collected Steps per Second: 22,692.07060
Overall Steps per Second: 10,784.84947

Timestep Collection Time: 2.20473
Timestep Consumption Time: 2.43418
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.63891

Cumulative Model Updates: 69,732
Cumulative Timesteps: 581,632,202

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 581632202...
Checkpoint 581632202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,872.32009
Policy Entropy: 3.31787
Value Function Loss: 0.00374

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08773
Policy Update Magnitude: 0.55476
Value Function Update Magnitude: 0.65881

Collected Steps per Second: 22,198.92054
Overall Steps per Second: 10,721.60155

Timestep Collection Time: 2.25353
Timestep Consumption Time: 2.41237
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.66591

Cumulative Model Updates: 69,738
Cumulative Timesteps: 581,682,228

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.26153
Policy Entropy: 3.32464
Value Function Loss: 0.00365

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07533
Policy Update Magnitude: 0.54205
Value Function Update Magnitude: 0.63008

Collected Steps per Second: 22,537.82223
Overall Steps per Second: 10,670.25443

Timestep Collection Time: 2.21903
Timestep Consumption Time: 2.46802
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.68705

Cumulative Model Updates: 69,744
Cumulative Timesteps: 581,732,240

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 581732240...
Checkpoint 581732240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.30141
Policy Entropy: 3.31342
Value Function Loss: 0.00381

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08125
Policy Update Magnitude: 0.54406
Value Function Update Magnitude: 0.62456

Collected Steps per Second: 22,463.36363
Overall Steps per Second: 10,749.07443

Timestep Collection Time: 2.22629
Timestep Consumption Time: 2.42620
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.65249

Cumulative Model Updates: 69,750
Cumulative Timesteps: 581,782,250

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.71890
Policy Entropy: 3.30441
Value Function Loss: 0.00403

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09595
Policy Update Magnitude: 0.54563
Value Function Update Magnitude: 0.63381

Collected Steps per Second: 22,073.70959
Overall Steps per Second: 10,552.88575

Timestep Collection Time: 2.26559
Timestep Consumption Time: 2.47340
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.73899

Cumulative Model Updates: 69,756
Cumulative Timesteps: 581,832,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 581832260...
Checkpoint 581832260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.66145
Policy Entropy: 3.31494
Value Function Loss: 0.00409

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.54993
Value Function Update Magnitude: 0.64154

Collected Steps per Second: 22,027.01873
Overall Steps per Second: 10,650.08975

Timestep Collection Time: 2.27012
Timestep Consumption Time: 2.42505
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.69517

Cumulative Model Updates: 69,762
Cumulative Timesteps: 581,882,264

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 777.45462
Policy Entropy: 3.31720
Value Function Loss: 0.00391

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10327
Policy Update Magnitude: 0.55346
Value Function Update Magnitude: 0.65076

Collected Steps per Second: 22,577.15381
Overall Steps per Second: 10,695.40237

Timestep Collection Time: 2.21543
Timestep Consumption Time: 2.46116
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.67659

Cumulative Model Updates: 69,768
Cumulative Timesteps: 581,932,282

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 581932282...
Checkpoint 581932282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.18763
Policy Entropy: 3.30899
Value Function Loss: 0.00362

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.55570
Value Function Update Magnitude: 0.66631

Collected Steps per Second: 22,621.09178
Overall Steps per Second: 10,767.89455

Timestep Collection Time: 2.21059
Timestep Consumption Time: 2.43340
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.64399

Cumulative Model Updates: 69,774
Cumulative Timesteps: 581,982,288

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,495.42273
Policy Entropy: 3.29593
Value Function Loss: 0.00367

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09190
Policy Update Magnitude: 0.55795
Value Function Update Magnitude: 0.67623

Collected Steps per Second: 23,009.60266
Overall Steps per Second: 10,858.70161

Timestep Collection Time: 2.17344
Timestep Consumption Time: 2.43208
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.60552

Cumulative Model Updates: 69,780
Cumulative Timesteps: 582,032,298

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 582032298...
Checkpoint 582032298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.66932
Policy Entropy: 3.30527
Value Function Loss: 0.00358

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08396
Policy Update Magnitude: 0.55915
Value Function Update Magnitude: 0.64922

Collected Steps per Second: 22,210.21585
Overall Steps per Second: 10,673.07546

Timestep Collection Time: 2.25140
Timestep Consumption Time: 2.43366
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.68506

Cumulative Model Updates: 69,786
Cumulative Timesteps: 582,082,302

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 969.58457
Policy Entropy: 3.30748
Value Function Loss: 0.00355

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08944
Policy Update Magnitude: 0.55214
Value Function Update Magnitude: 0.62995

Collected Steps per Second: 22,906.10608
Overall Steps per Second: 10,733.77238

Timestep Collection Time: 2.18361
Timestep Consumption Time: 2.47626
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.65987

Cumulative Model Updates: 69,792
Cumulative Timesteps: 582,132,320

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 582132320...
Checkpoint 582132320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 978.68482
Policy Entropy: 3.30508
Value Function Loss: 0.00369

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08170
Policy Update Magnitude: 0.54258
Value Function Update Magnitude: 0.63555

Collected Steps per Second: 22,742.65713
Overall Steps per Second: 10,871.57228

Timestep Collection Time: 2.19895
Timestep Consumption Time: 2.40112
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.60007

Cumulative Model Updates: 69,798
Cumulative Timesteps: 582,182,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.69011
Policy Entropy: 3.29783
Value Function Loss: 0.00369

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.54937
Value Function Update Magnitude: 0.62819

Collected Steps per Second: 22,893.26745
Overall Steps per Second: 10,815.70694

Timestep Collection Time: 2.18501
Timestep Consumption Time: 2.43993
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.62494

Cumulative Model Updates: 69,804
Cumulative Timesteps: 582,232,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 582232352...
Checkpoint 582232352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 739.92530
Policy Entropy: 3.29808
Value Function Loss: 0.00389

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09299
Policy Update Magnitude: 0.55480
Value Function Update Magnitude: 0.62660

Collected Steps per Second: 22,322.03919
Overall Steps per Second: 10,730.91635

Timestep Collection Time: 2.24083
Timestep Consumption Time: 2.42046
PPO Batch Consumption Time: 0.28228
Total Iteration Time: 4.66130

Cumulative Model Updates: 69,810
Cumulative Timesteps: 582,282,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 862.65861
Policy Entropy: 3.31843
Value Function Loss: 0.00388

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08684
Policy Update Magnitude: 0.55792
Value Function Update Magnitude: 0.66399

Collected Steps per Second: 22,489.87174
Overall Steps per Second: 10,620.91755

Timestep Collection Time: 2.22447
Timestep Consumption Time: 2.48586
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.71033

Cumulative Model Updates: 69,816
Cumulative Timesteps: 582,332,400

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 582332400...
Checkpoint 582332400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.16304
Policy Entropy: 3.31494
Value Function Loss: 0.00387

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10854
Policy Update Magnitude: 0.56561
Value Function Update Magnitude: 0.68509

Collected Steps per Second: 22,168.53271
Overall Steps per Second: 10,512.79982

Timestep Collection Time: 2.25581
Timestep Consumption Time: 2.50106
PPO Batch Consumption Time: 0.29679
Total Iteration Time: 4.75687

Cumulative Model Updates: 69,822
Cumulative Timesteps: 582,382,408

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.73339
Policy Entropy: 3.27868
Value Function Loss: 0.00401

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.56409
Value Function Update Magnitude: 0.68755

Collected Steps per Second: 22,510.98348
Overall Steps per Second: 10,601.24668

Timestep Collection Time: 2.22140
Timestep Consumption Time: 2.49559
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.71699

Cumulative Model Updates: 69,828
Cumulative Timesteps: 582,432,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 582432414...
Checkpoint 582432414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.29204
Policy Entropy: 3.26637
Value Function Loss: 0.00396

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.12059
Policy Update Magnitude: 0.56528
Value Function Update Magnitude: 0.68496

Collected Steps per Second: 22,483.17651
Overall Steps per Second: 10,645.49054

Timestep Collection Time: 2.22397
Timestep Consumption Time: 2.47304
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.69701

Cumulative Model Updates: 69,834
Cumulative Timesteps: 582,482,416

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 820.78398
Policy Entropy: 3.26792
Value Function Loss: 0.00390

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.12294
Policy Update Magnitude: 0.56984
Value Function Update Magnitude: 0.66895

Collected Steps per Second: 22,887.33603
Overall Steps per Second: 10,817.90188

Timestep Collection Time: 2.18479
Timestep Consumption Time: 2.43755
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.62234

Cumulative Model Updates: 69,840
Cumulative Timesteps: 582,532,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 582532420...
Checkpoint 582532420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.31957
Policy Entropy: 3.28834
Value Function Loss: 0.00377

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10849
Policy Update Magnitude: 0.56665
Value Function Update Magnitude: 0.64955

Collected Steps per Second: 22,525.85745
Overall Steps per Second: 10,585.90352

Timestep Collection Time: 2.22056
Timestep Consumption Time: 2.50459
PPO Batch Consumption Time: 0.29775
Total Iteration Time: 4.72515

Cumulative Model Updates: 69,846
Cumulative Timesteps: 582,582,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 935.17133
Policy Entropy: 3.29258
Value Function Loss: 0.00376

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.10727
Policy Update Magnitude: 0.55834
Value Function Update Magnitude: 0.63569

Collected Steps per Second: 22,755.64768
Overall Steps per Second: 10,810.40042

Timestep Collection Time: 2.19752
Timestep Consumption Time: 2.42821
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.62573

Cumulative Model Updates: 69,852
Cumulative Timesteps: 582,632,446

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 582632446...
Checkpoint 582632446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 925.48510
Policy Entropy: 3.27573
Value Function Loss: 0.00404

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11685
Policy Update Magnitude: 0.55482
Value Function Update Magnitude: 0.62535

Collected Steps per Second: 22,795.68255
Overall Steps per Second: 10,710.23220

Timestep Collection Time: 2.19559
Timestep Consumption Time: 2.47751
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.67310

Cumulative Model Updates: 69,858
Cumulative Timesteps: 582,682,496

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 982.59234
Policy Entropy: 3.27333
Value Function Loss: 0.00419

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.12580
Policy Update Magnitude: 0.55783
Value Function Update Magnitude: 0.65695

Collected Steps per Second: 23,127.86150
Overall Steps per Second: 10,900.37812

Timestep Collection Time: 2.16207
Timestep Consumption Time: 2.42530
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.58736

Cumulative Model Updates: 69,864
Cumulative Timesteps: 582,732,500

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 582732500...
Checkpoint 582732500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.67527
Policy Entropy: 3.26507
Value Function Loss: 0.00434

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.57071
Value Function Update Magnitude: 0.68870

Collected Steps per Second: 22,702.56099
Overall Steps per Second: 10,620.74991

Timestep Collection Time: 2.20239
Timestep Consumption Time: 2.50537
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.70777

Cumulative Model Updates: 69,870
Cumulative Timesteps: 582,782,500

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.84722
Policy Entropy: 3.25482
Value Function Loss: 0.00410

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11420
Policy Update Magnitude: 0.57703
Value Function Update Magnitude: 0.68993

Collected Steps per Second: 22,556.94422
Overall Steps per Second: 10,623.89910

Timestep Collection Time: 2.21661
Timestep Consumption Time: 2.48976
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.70637

Cumulative Model Updates: 69,876
Cumulative Timesteps: 582,832,500

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 582832500...
Checkpoint 582832500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.63653
Policy Entropy: 3.25355
Value Function Loss: 0.00396

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11197
Policy Update Magnitude: 0.57575
Value Function Update Magnitude: 0.67606

Collected Steps per Second: 22,101.35907
Overall Steps per Second: 10,494.90407

Timestep Collection Time: 2.26249
Timestep Consumption Time: 2.50211
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.76460

Cumulative Model Updates: 69,882
Cumulative Timesteps: 582,882,504

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.61580
Policy Entropy: 3.24540
Value Function Loss: 0.00400

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10685
Policy Update Magnitude: 0.56740
Value Function Update Magnitude: 0.66783

Collected Steps per Second: 22,704.29793
Overall Steps per Second: 10,666.95793

Timestep Collection Time: 2.20231
Timestep Consumption Time: 2.48525
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.68756

Cumulative Model Updates: 69,888
Cumulative Timesteps: 582,932,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 582932506...
Checkpoint 582932506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,932.59721
Policy Entropy: 3.24139
Value Function Loss: 0.00397

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11757
Policy Update Magnitude: 0.56007
Value Function Update Magnitude: 0.66556

Collected Steps per Second: 22,325.11373
Overall Steps per Second: 10,592.44641

Timestep Collection Time: 2.24053
Timestep Consumption Time: 2.48171
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.72223

Cumulative Model Updates: 69,894
Cumulative Timesteps: 582,982,526

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.39836
Policy Entropy: 3.23962
Value Function Loss: 0.00398

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09058
Policy Update Magnitude: 0.55554
Value Function Update Magnitude: 0.65941

Collected Steps per Second: 22,536.26783
Overall Steps per Second: 10,676.16540

Timestep Collection Time: 2.21927
Timestep Consumption Time: 2.46537
PPO Batch Consumption Time: 0.28204
Total Iteration Time: 4.68464

Cumulative Model Updates: 69,900
Cumulative Timesteps: 583,032,540

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 583032540...
Checkpoint 583032540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 966.66281
Policy Entropy: 3.24981
Value Function Loss: 0.00375

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08066
Policy Update Magnitude: 0.55723
Value Function Update Magnitude: 0.66046

Collected Steps per Second: 21,974.73187
Overall Steps per Second: 10,436.62540

Timestep Collection Time: 2.27589
Timestep Consumption Time: 2.51608
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.79197

Cumulative Model Updates: 69,906
Cumulative Timesteps: 583,082,552

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 990.67850
Policy Entropy: 3.27454
Value Function Loss: 0.00359

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09618
Policy Update Magnitude: 0.55375
Value Function Update Magnitude: 0.66488

Collected Steps per Second: 22,755.02137
Overall Steps per Second: 10,662.51783

Timestep Collection Time: 2.19741
Timestep Consumption Time: 2.49211
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.68951

Cumulative Model Updates: 69,912
Cumulative Timesteps: 583,132,554

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 583132554...
Checkpoint 583132554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 718.90562
Policy Entropy: 3.27190
Value Function Loss: 0.00363

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08396
Policy Update Magnitude: 0.55304
Value Function Update Magnitude: 0.66283

Collected Steps per Second: 22,585.44542
Overall Steps per Second: 10,608.38440

Timestep Collection Time: 2.21399
Timestep Consumption Time: 2.49964
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.71363

Cumulative Model Updates: 69,918
Cumulative Timesteps: 583,182,558

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 879.08162
Policy Entropy: 3.27710
Value Function Loss: 0.00379

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08605
Policy Update Magnitude: 0.55832
Value Function Update Magnitude: 0.66608

Collected Steps per Second: 23,257.15779
Overall Steps per Second: 10,933.62009

Timestep Collection Time: 2.15108
Timestep Consumption Time: 2.42453
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.57561

Cumulative Model Updates: 69,924
Cumulative Timesteps: 583,232,586

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 583232586...
Checkpoint 583232586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.82050
Policy Entropy: 3.27544
Value Function Loss: 0.00390

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10905
Policy Update Magnitude: 0.55944
Value Function Update Magnitude: 0.66299

Collected Steps per Second: 22,725.93113
Overall Steps per Second: 10,697.66052

Timestep Collection Time: 2.20057
Timestep Consumption Time: 2.47428
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.67485

Cumulative Model Updates: 69,930
Cumulative Timesteps: 583,282,596

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392.35315
Policy Entropy: 3.27888
Value Function Loss: 0.00406

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10427
Policy Update Magnitude: 0.55863
Value Function Update Magnitude: 0.63798

Collected Steps per Second: 23,107.71031
Overall Steps per Second: 10,878.96481

Timestep Collection Time: 2.16456
Timestep Consumption Time: 2.43312
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.59768

Cumulative Model Updates: 69,936
Cumulative Timesteps: 583,332,614

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 583332614...
Checkpoint 583332614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 820.86935
Policy Entropy: 3.28435
Value Function Loss: 0.00401

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10206
Policy Update Magnitude: 0.56554
Value Function Update Magnitude: 0.63105

Collected Steps per Second: 22,419.75521
Overall Steps per Second: 10,690.55261

Timestep Collection Time: 2.23018
Timestep Consumption Time: 2.44685
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.67703

Cumulative Model Updates: 69,942
Cumulative Timesteps: 583,382,614

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451.75980
Policy Entropy: 3.28857
Value Function Loss: 0.00395

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10387
Policy Update Magnitude: 0.56451
Value Function Update Magnitude: 0.65892

Collected Steps per Second: 22,343.22307
Overall Steps per Second: 10,592.91431

Timestep Collection Time: 2.23844
Timestep Consumption Time: 2.48302
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.72146

Cumulative Model Updates: 69,948
Cumulative Timesteps: 583,432,628

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 583432628...
Checkpoint 583432628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.54369
Policy Entropy: 3.31326
Value Function Loss: 0.00380

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11026
Policy Update Magnitude: 0.55776
Value Function Update Magnitude: 0.65699

Collected Steps per Second: 22,200.27728
Overall Steps per Second: 10,574.35878

Timestep Collection Time: 2.25322
Timestep Consumption Time: 2.47728
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.73050

Cumulative Model Updates: 69,954
Cumulative Timesteps: 583,482,650

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.47870
Policy Entropy: 3.33887
Value Function Loss: 0.00374

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10532
Policy Update Magnitude: 0.54645
Value Function Update Magnitude: 0.64218

Collected Steps per Second: 22,567.34537
Overall Steps per Second: 10,759.76897

Timestep Collection Time: 2.21568
Timestep Consumption Time: 2.43145
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.64713

Cumulative Model Updates: 69,960
Cumulative Timesteps: 583,532,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 583532652...
Checkpoint 583532652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.80244
Policy Entropy: 3.33383
Value Function Loss: 0.00363

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09755
Policy Update Magnitude: 0.54057
Value Function Update Magnitude: 0.64283

Collected Steps per Second: 22,116.47432
Overall Steps per Second: 10,570.95235

Timestep Collection Time: 2.26085
Timestep Consumption Time: 2.46928
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.73013

Cumulative Model Updates: 69,966
Cumulative Timesteps: 583,582,654

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,145.94649
Policy Entropy: 3.32108
Value Function Loss: 0.00372

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.53768
Value Function Update Magnitude: 0.63423

Collected Steps per Second: 22,243.64466
Overall Steps per Second: 10,583.79175

Timestep Collection Time: 2.24873
Timestep Consumption Time: 2.47736
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.72609

Cumulative Model Updates: 69,972
Cumulative Timesteps: 583,632,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 583632674...
Checkpoint 583632674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 936.20039
Policy Entropy: 3.30089
Value Function Loss: 0.00384

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.53982
Value Function Update Magnitude: 0.64793

Collected Steps per Second: 22,848.90905
Overall Steps per Second: 10,664.51369

Timestep Collection Time: 2.18916
Timestep Consumption Time: 2.50116
PPO Batch Consumption Time: 0.29753
Total Iteration Time: 4.69032

Cumulative Model Updates: 69,978
Cumulative Timesteps: 583,682,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,930.15190
Policy Entropy: 3.30214
Value Function Loss: 0.00384

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.54278
Value Function Update Magnitude: 0.63540

Collected Steps per Second: 22,094.84075
Overall Steps per Second: 10,431.68027

Timestep Collection Time: 2.26379
Timestep Consumption Time: 2.53103
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 4.79482

Cumulative Model Updates: 69,984
Cumulative Timesteps: 583,732,712

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 583732712...
Checkpoint 583732712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 994.51635
Policy Entropy: 3.30299
Value Function Loss: 0.00382

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08058
Policy Update Magnitude: 0.54172
Value Function Update Magnitude: 0.62428

Collected Steps per Second: 22,497.07147
Overall Steps per Second: 10,627.54876

Timestep Collection Time: 2.22304
Timestep Consumption Time: 2.48284
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.70588

Cumulative Model Updates: 69,990
Cumulative Timesteps: 583,782,724

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.30300
Policy Entropy: 3.31113
Value Function Loss: 0.00399

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07236
Policy Update Magnitude: 0.54206
Value Function Update Magnitude: 0.62837

Collected Steps per Second: 23,045.29691
Overall Steps per Second: 10,881.13886

Timestep Collection Time: 2.17077
Timestep Consumption Time: 2.42673
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.59750

Cumulative Model Updates: 69,996
Cumulative Timesteps: 583,832,750

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 583832750...
Checkpoint 583832750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.50545
Policy Entropy: 3.32313
Value Function Loss: 0.00383

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.06880
Policy Update Magnitude: 0.54562
Value Function Update Magnitude: 0.64662

Collected Steps per Second: 22,715.04676
Overall Steps per Second: 10,673.08497

Timestep Collection Time: 2.20154
Timestep Consumption Time: 2.48389
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.68543

Cumulative Model Updates: 70,002
Cumulative Timesteps: 583,882,758

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.85367
Policy Entropy: 3.33033
Value Function Loss: 0.00366

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.06994
Policy Update Magnitude: 0.54614
Value Function Update Magnitude: 0.63818

Collected Steps per Second: 22,719.94199
Overall Steps per Second: 10,799.72623

Timestep Collection Time: 2.20150
Timestep Consumption Time: 2.42991
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.63141

Cumulative Model Updates: 70,008
Cumulative Timesteps: 583,932,776

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 583932776...
Checkpoint 583932776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.73579
Policy Entropy: 3.34216
Value Function Loss: 0.00337

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07664
Policy Update Magnitude: 0.53476
Value Function Update Magnitude: 0.62639

Collected Steps per Second: 22,225.89558
Overall Steps per Second: 10,705.35164

Timestep Collection Time: 2.25044
Timestep Consumption Time: 2.42180
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.67224

Cumulative Model Updates: 70,014
Cumulative Timesteps: 583,982,794

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,632.25741
Policy Entropy: 3.33116
Value Function Loss: 0.00337

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07108
Policy Update Magnitude: 0.52768
Value Function Update Magnitude: 0.60057

Collected Steps per Second: 22,609.53110
Overall Steps per Second: 10,647.13652

Timestep Collection Time: 2.21261
Timestep Consumption Time: 2.48593
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.69854

Cumulative Model Updates: 70,020
Cumulative Timesteps: 584,032,820

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 584032820...
Checkpoint 584032820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 903.41569
Policy Entropy: 3.34711
Value Function Loss: 0.00342

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07269
Policy Update Magnitude: 0.53009
Value Function Update Magnitude: 0.58941

Collected Steps per Second: 22,534.38528
Overall Steps per Second: 10,651.97775

Timestep Collection Time: 2.21945
Timestep Consumption Time: 2.47583
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.69528

Cumulative Model Updates: 70,026
Cumulative Timesteps: 584,082,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.06700
Policy Entropy: 3.34079
Value Function Loss: 0.00345

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.53399
Value Function Update Magnitude: 0.59943

Collected Steps per Second: 22,601.38753
Overall Steps per Second: 10,749.50061

Timestep Collection Time: 2.21278
Timestep Consumption Time: 2.43971
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.65250

Cumulative Model Updates: 70,032
Cumulative Timesteps: 584,132,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 584132846...
Checkpoint 584132846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,597.86641
Policy Entropy: 3.34846
Value Function Loss: 0.00350

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07954
Policy Update Magnitude: 0.53296
Value Function Update Magnitude: 0.60442

Collected Steps per Second: 22,472.93108
Overall Steps per Second: 10,630.20777

Timestep Collection Time: 2.22525
Timestep Consumption Time: 2.47907
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.70433

Cumulative Model Updates: 70,038
Cumulative Timesteps: 584,182,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.07931
Policy Entropy: 3.34159
Value Function Loss: 0.00354

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08513
Policy Update Magnitude: 0.53459
Value Function Update Magnitude: 0.60616

Collected Steps per Second: 22,816.20481
Overall Steps per Second: 10,780.52478

Timestep Collection Time: 2.19169
Timestep Consumption Time: 2.44686
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.63855

Cumulative Model Updates: 70,044
Cumulative Timesteps: 584,232,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 584232860...
Checkpoint 584232860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,566.61966
Policy Entropy: 3.32745
Value Function Loss: 0.00379

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08393
Policy Update Magnitude: 0.54536
Value Function Update Magnitude: 0.61437

Collected Steps per Second: 22,907.12384
Overall Steps per Second: 10,755.31733

Timestep Collection Time: 2.18369
Timestep Consumption Time: 2.46722
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.65091

Cumulative Model Updates: 70,050
Cumulative Timesteps: 584,282,882

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.97692
Policy Entropy: 3.31652
Value Function Loss: 0.00392

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09581
Policy Update Magnitude: 0.55228
Value Function Update Magnitude: 0.63238

Collected Steps per Second: 22,759.50072
Overall Steps per Second: 10,821.26293

Timestep Collection Time: 2.19741
Timestep Consumption Time: 2.42423
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.62164

Cumulative Model Updates: 70,056
Cumulative Timesteps: 584,332,894

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 584332894...
Checkpoint 584332894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708.90641
Policy Entropy: 3.30973
Value Function Loss: 0.00392

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09210
Policy Update Magnitude: 0.56097
Value Function Update Magnitude: 0.65044

Collected Steps per Second: 22,473.98639
Overall Steps per Second: 10,767.12295

Timestep Collection Time: 2.22524
Timestep Consumption Time: 2.41946
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.64469

Cumulative Model Updates: 70,062
Cumulative Timesteps: 584,382,904

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.14978
Policy Entropy: 3.32845
Value Function Loss: 0.00392

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.56275
Value Function Update Magnitude: 0.65800

Collected Steps per Second: 22,912.22024
Overall Steps per Second: 10,834.30565

Timestep Collection Time: 2.18303
Timestep Consumption Time: 2.43360
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.61663

Cumulative Model Updates: 70,068
Cumulative Timesteps: 584,432,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 584432922...
Checkpoint 584432922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 936.39511
Policy Entropy: 3.34813
Value Function Loss: 0.00375

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08568
Policy Update Magnitude: 0.55712
Value Function Update Magnitude: 0.67455

Collected Steps per Second: 22,286.41929
Overall Steps per Second: 10,725.02461

Timestep Collection Time: 2.24469
Timestep Consumption Time: 2.41973
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.66442

Cumulative Model Updates: 70,074
Cumulative Timesteps: 584,482,948

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.49022
Policy Entropy: 3.34649
Value Function Loss: 0.00370

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08826
Policy Update Magnitude: 0.55871
Value Function Update Magnitude: 0.69208

Collected Steps per Second: 22,625.56535
Overall Steps per Second: 10,798.17360

Timestep Collection Time: 2.21051
Timestep Consumption Time: 2.42120
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.63171

Cumulative Model Updates: 70,080
Cumulative Timesteps: 584,532,962

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 584532962...
Checkpoint 584532962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,374.93718
Policy Entropy: 3.33471
Value Function Loss: 0.00365

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09747
Policy Update Magnitude: 0.55590
Value Function Update Magnitude: 0.70497

Collected Steps per Second: 21,804.62322
Overall Steps per Second: 10,534.13136

Timestep Collection Time: 2.29318
Timestep Consumption Time: 2.45348
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.74667

Cumulative Model Updates: 70,086
Cumulative Timesteps: 584,582,964

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.62392
Policy Entropy: 3.31866
Value Function Loss: 0.00363

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.54593
Value Function Update Magnitude: 0.70076

Collected Steps per Second: 22,492.14495
Overall Steps per Second: 10,675.77393

Timestep Collection Time: 2.22389
Timestep Consumption Time: 2.46149
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.68537

Cumulative Model Updates: 70,092
Cumulative Timesteps: 584,632,984

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 584632984...
Checkpoint 584632984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,306.08289
Policy Entropy: 3.30706
Value Function Loss: 0.00362

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.12132
Policy Update Magnitude: 0.54158
Value Function Update Magnitude: 0.66987

Collected Steps per Second: 22,383.67174
Overall Steps per Second: 10,631.22342

Timestep Collection Time: 2.23458
Timestep Consumption Time: 2.47025
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.70482

Cumulative Model Updates: 70,098
Cumulative Timesteps: 584,683,002

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541.75329
Policy Entropy: 3.32194
Value Function Loss: 0.00355

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09268
Policy Update Magnitude: 0.53612
Value Function Update Magnitude: 0.63267

Collected Steps per Second: 22,736.33900
Overall Steps per Second: 10,596.55475

Timestep Collection Time: 2.19921
Timestep Consumption Time: 2.51949
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.71870

Cumulative Model Updates: 70,104
Cumulative Timesteps: 584,733,004

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 584733004...
Checkpoint 584733004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,828.67803
Policy Entropy: 3.31831
Value Function Loss: 0.00348

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08807
Policy Update Magnitude: 0.53742
Value Function Update Magnitude: 0.62087

Collected Steps per Second: 22,644.43216
Overall Steps per Second: 10,653.27824

Timestep Collection Time: 2.20884
Timestep Consumption Time: 2.48624
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.69508

Cumulative Model Updates: 70,110
Cumulative Timesteps: 584,783,022

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659.46441
Policy Entropy: 3.32718
Value Function Loss: 0.00366

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08615
Policy Update Magnitude: 0.54458
Value Function Update Magnitude: 0.63982

Collected Steps per Second: 23,137.79895
Overall Steps per Second: 10,746.11978

Timestep Collection Time: 2.16200
Timestep Consumption Time: 2.49307
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.65508

Cumulative Model Updates: 70,116
Cumulative Timesteps: 584,833,046

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 584833046...
Checkpoint 584833046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 884.73424
Policy Entropy: 3.32051
Value Function Loss: 0.00388

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.55261
Value Function Update Magnitude: 0.67077

Collected Steps per Second: 22,690.34399
Overall Steps per Second: 10,621.68049

Timestep Collection Time: 2.20578
Timestep Consumption Time: 2.50628
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 4.71206

Cumulative Model Updates: 70,122
Cumulative Timesteps: 584,883,096

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.36309
Policy Entropy: 3.33470
Value Function Loss: 0.00410

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10231
Policy Update Magnitude: 0.56295
Value Function Update Magnitude: 0.69222

Collected Steps per Second: 23,085.60551
Overall Steps per Second: 10,890.91612

Timestep Collection Time: 2.16715
Timestep Consumption Time: 2.42659
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.59374

Cumulative Model Updates: 70,128
Cumulative Timesteps: 584,933,126

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 584933126...
Checkpoint 584933126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 886.66675
Policy Entropy: 3.31197
Value Function Loss: 0.00433

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.56794
Value Function Update Magnitude: 0.72173

Collected Steps per Second: 22,432.33817
Overall Steps per Second: 10,673.68666

Timestep Collection Time: 2.22919
Timestep Consumption Time: 2.45579
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.68498

Cumulative Model Updates: 70,134
Cumulative Timesteps: 584,983,132

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.09584
Policy Entropy: 3.30629
Value Function Loss: 0.00406

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09059
Policy Update Magnitude: 0.57315
Value Function Update Magnitude: 0.72319

Collected Steps per Second: 22,953.87310
Overall Steps per Second: 10,855.09972

Timestep Collection Time: 2.17933
Timestep Consumption Time: 2.42901
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.60834

Cumulative Model Updates: 70,140
Cumulative Timesteps: 585,033,156

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 585033156...
Checkpoint 585033156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,339.34401
Policy Entropy: 3.30316
Value Function Loss: 0.00380

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.07967
Policy Update Magnitude: 0.56711
Value Function Update Magnitude: 0.69129

Collected Steps per Second: 22,139.41706
Overall Steps per Second: 10,652.10399

Timestep Collection Time: 2.25896
Timestep Consumption Time: 2.43608
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.69503

Cumulative Model Updates: 70,146
Cumulative Timesteps: 585,083,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,670.85569
Policy Entropy: 3.32486
Value Function Loss: 0.00374

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07801
Policy Update Magnitude: 0.55899
Value Function Update Magnitude: 0.65899

Collected Steps per Second: 22,739.13208
Overall Steps per Second: 10,686.76697

Timestep Collection Time: 2.19964
Timestep Consumption Time: 2.48072
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.68037

Cumulative Model Updates: 70,152
Cumulative Timesteps: 585,133,186

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 585133186...
Checkpoint 585133186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 851.69289
Policy Entropy: 3.31025
Value Function Loss: 0.00365

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08023
Policy Update Magnitude: 0.55487
Value Function Update Magnitude: 0.64630

Collected Steps per Second: 22,186.78555
Overall Steps per Second: 10,567.39320

Timestep Collection Time: 2.25422
Timestep Consumption Time: 2.47864
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.73286

Cumulative Model Updates: 70,158
Cumulative Timesteps: 585,183,200

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707.06285
Policy Entropy: 3.30234
Value Function Loss: 0.00368

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07794
Policy Update Magnitude: 0.54906
Value Function Update Magnitude: 0.65031

Collected Steps per Second: 22,463.82911
Overall Steps per Second: 10,742.59556

Timestep Collection Time: 2.22633
Timestep Consumption Time: 2.42915
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.65549

Cumulative Model Updates: 70,164
Cumulative Timesteps: 585,233,212

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 585233212...
Checkpoint 585233212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 762.09480
Policy Entropy: 3.29645
Value Function Loss: 0.00373

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07721
Policy Update Magnitude: 0.55306
Value Function Update Magnitude: 0.65060

Collected Steps per Second: 22,605.46210
Overall Steps per Second: 10,693.84280

Timestep Collection Time: 2.21256
Timestep Consumption Time: 2.46452
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.67708

Cumulative Model Updates: 70,170
Cumulative Timesteps: 585,283,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.14424
Policy Entropy: 3.29537
Value Function Loss: 0.00370

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08669
Policy Update Magnitude: 0.55257
Value Function Update Magnitude: 0.65620

Collected Steps per Second: 22,732.60428
Overall Steps per Second: 10,760.69223

Timestep Collection Time: 2.20045
Timestep Consumption Time: 2.44813
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.64859

Cumulative Model Updates: 70,176
Cumulative Timesteps: 585,333,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 585333250...
Checkpoint 585333250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.73076
Policy Entropy: 3.30694
Value Function Loss: 0.00374

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09025
Policy Update Magnitude: 0.55603
Value Function Update Magnitude: 0.67066

Collected Steps per Second: 22,447.52239
Overall Steps per Second: 10,728.50607

Timestep Collection Time: 2.22777
Timestep Consumption Time: 2.43345
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.66123

Cumulative Model Updates: 70,182
Cumulative Timesteps: 585,383,258

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744.99805
Policy Entropy: 3.29212
Value Function Loss: 0.00389

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08867
Policy Update Magnitude: 0.55506
Value Function Update Magnitude: 0.65426

Collected Steps per Second: 22,782.53888
Overall Steps per Second: 10,706.44807

Timestep Collection Time: 2.19475
Timestep Consumption Time: 2.47552
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.67027

Cumulative Model Updates: 70,188
Cumulative Timesteps: 585,433,260

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 585433260...
Checkpoint 585433260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178.68324
Policy Entropy: 3.28903
Value Function Loss: 0.00415

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11561
Policy Update Magnitude: 0.55960
Value Function Update Magnitude: 0.63660

Collected Steps per Second: 22,942.44940
Overall Steps per Second: 10,786.60300

Timestep Collection Time: 2.18024
Timestep Consumption Time: 2.45700
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.63723

Cumulative Model Updates: 70,194
Cumulative Timesteps: 585,483,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 911.24468
Policy Entropy: 3.27092
Value Function Loss: 0.00418

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12016
Policy Update Magnitude: 0.56225
Value Function Update Magnitude: 0.63002

Collected Steps per Second: 22,842.86139
Overall Steps per Second: 10,694.77773

Timestep Collection Time: 2.18913
Timestep Consumption Time: 2.48661
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.67574

Cumulative Model Updates: 70,200
Cumulative Timesteps: 585,533,286

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 585533286...
Checkpoint 585533286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.00669
Policy Entropy: 3.25598
Value Function Loss: 0.00406

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.55907
Value Function Update Magnitude: 0.61490

Collected Steps per Second: 22,699.20616
Overall Steps per Second: 10,699.57744

Timestep Collection Time: 2.20369
Timestep Consumption Time: 2.47145
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.67514

Cumulative Model Updates: 70,206
Cumulative Timesteps: 585,583,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782.51953
Policy Entropy: 3.26954
Value Function Loss: 0.00375

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11504
Policy Update Magnitude: 0.55333
Value Function Update Magnitude: 0.61173

Collected Steps per Second: 22,677.46387
Overall Steps per Second: 10,690.94615

Timestep Collection Time: 2.20598
Timestep Consumption Time: 2.47331
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.67929

Cumulative Model Updates: 70,212
Cumulative Timesteps: 585,633,334

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 585633334...
Checkpoint 585633334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 736.83838
Policy Entropy: 3.26064
Value Function Loss: 0.00386

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09412
Policy Update Magnitude: 0.54611
Value Function Update Magnitude: 0.60408

Collected Steps per Second: 22,018.12596
Overall Steps per Second: 10,624.54797

Timestep Collection Time: 2.27113
Timestep Consumption Time: 2.43552
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.70665

Cumulative Model Updates: 70,218
Cumulative Timesteps: 585,683,340

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.98900
Policy Entropy: 3.27263
Value Function Loss: 0.00402

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09239
Policy Update Magnitude: 0.55158
Value Function Update Magnitude: 0.58366

Collected Steps per Second: 22,934.68936
Overall Steps per Second: 10,864.81367

Timestep Collection Time: 2.18115
Timestep Consumption Time: 2.42307
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.60422

Cumulative Model Updates: 70,224
Cumulative Timesteps: 585,733,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 585733364...
Checkpoint 585733364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 806.15835
Policy Entropy: 3.28107
Value Function Loss: 0.00406

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09836
Policy Update Magnitude: 0.55539
Value Function Update Magnitude: 0.59768

Collected Steps per Second: 22,264.22239
Overall Steps per Second: 10,727.45848

Timestep Collection Time: 2.24782
Timestep Consumption Time: 2.41740
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.66522

Cumulative Model Updates: 70,230
Cumulative Timesteps: 585,783,410

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 891.02996
Policy Entropy: 3.28575
Value Function Loss: 0.00409

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08947
Policy Update Magnitude: 0.55395
Value Function Update Magnitude: 0.59633

Collected Steps per Second: 22,722.94556
Overall Steps per Second: 10,590.96442

Timestep Collection Time: 2.20068
Timestep Consumption Time: 2.52089
PPO Batch Consumption Time: 0.29524
Total Iteration Time: 4.72157

Cumulative Model Updates: 70,236
Cumulative Timesteps: 585,833,416

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 585833416...
Checkpoint 585833416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.77910
Policy Entropy: 3.29255
Value Function Loss: 0.00406

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09137
Policy Update Magnitude: 0.55678
Value Function Update Magnitude: 0.61297

Collected Steps per Second: 22,863.70773
Overall Steps per Second: 10,756.29882

Timestep Collection Time: 2.18827
Timestep Consumption Time: 2.46314
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.65141

Cumulative Model Updates: 70,242
Cumulative Timesteps: 585,883,448

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.42352
Policy Entropy: 3.27276
Value Function Loss: 0.00401

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08415
Policy Update Magnitude: 0.55775
Value Function Update Magnitude: 0.62397

Collected Steps per Second: 22,832.21051
Overall Steps per Second: 10,688.97205

Timestep Collection Time: 2.19006
Timestep Consumption Time: 2.48803
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.67809

Cumulative Model Updates: 70,248
Cumulative Timesteps: 585,933,452

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 585933452...
Checkpoint 585933452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.72860
Policy Entropy: 3.26049
Value Function Loss: 0.00400

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08854
Policy Update Magnitude: 0.55713
Value Function Update Magnitude: 0.61531

Collected Steps per Second: 22,708.99242
Overall Steps per Second: 10,633.70787

Timestep Collection Time: 2.20195
Timestep Consumption Time: 2.50046
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.70240

Cumulative Model Updates: 70,254
Cumulative Timesteps: 585,983,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801.71617
Policy Entropy: 3.26977
Value Function Loss: 0.00389

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11559
Policy Update Magnitude: 0.54394
Value Function Update Magnitude: 0.60891

Collected Steps per Second: 22,791.97034
Overall Steps per Second: 10,802.02941

Timestep Collection Time: 2.19437
Timestep Consumption Time: 2.43569
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.63006

Cumulative Model Updates: 70,260
Cumulative Timesteps: 586,033,470

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 586033470...
Checkpoint 586033470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430.80040
Policy Entropy: 3.27879
Value Function Loss: 0.00377

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11607
Policy Update Magnitude: 0.54137
Value Function Update Magnitude: 0.61516

Collected Steps per Second: 22,983.27189
Overall Steps per Second: 10,743.33895

Timestep Collection Time: 2.17593
Timestep Consumption Time: 2.47905
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.65498

Cumulative Model Updates: 70,266
Cumulative Timesteps: 586,083,480

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.31996
Policy Entropy: 3.27424
Value Function Loss: 0.00385

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10865
Policy Update Magnitude: 0.54383
Value Function Update Magnitude: 0.62471

Collected Steps per Second: 22,726.86389
Overall Steps per Second: 10,815.92455

Timestep Collection Time: 2.20136
Timestep Consumption Time: 2.42423
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.62559

Cumulative Model Updates: 70,272
Cumulative Timesteps: 586,133,510

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 586133510...
Checkpoint 586133510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.30657
Policy Entropy: 3.25656
Value Function Loss: 0.00395

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.55233
Value Function Update Magnitude: 0.62556

Collected Steps per Second: 21,955.11883
Overall Steps per Second: 10,619.44370

Timestep Collection Time: 2.27801
Timestep Consumption Time: 2.43165
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.70966

Cumulative Model Updates: 70,278
Cumulative Timesteps: 586,183,524

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.90979
Policy Entropy: 3.26284
Value Function Loss: 0.00425

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.56185
Value Function Update Magnitude: 0.63902

Collected Steps per Second: 22,564.82244
Overall Steps per Second: 10,578.03269

Timestep Collection Time: 2.21690
Timestep Consumption Time: 2.51214
PPO Batch Consumption Time: 0.29695
Total Iteration Time: 4.72905

Cumulative Model Updates: 70,284
Cumulative Timesteps: 586,233,548

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 586233548...
Checkpoint 586233548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 880.16548
Policy Entropy: 3.27784
Value Function Loss: 0.00404

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.10980
Policy Update Magnitude: 0.56736
Value Function Update Magnitude: 0.66650

Collected Steps per Second: 22,283.94778
Overall Steps per Second: 10,638.77341

Timestep Collection Time: 2.24395
Timestep Consumption Time: 2.45622
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.70017

Cumulative Model Updates: 70,290
Cumulative Timesteps: 586,283,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.44751
Policy Entropy: 3.29280
Value Function Loss: 0.00382

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.56509
Value Function Update Magnitude: 0.67571

Collected Steps per Second: 22,687.05608
Overall Steps per Second: 10,661.18983

Timestep Collection Time: 2.20505
Timestep Consumption Time: 2.48730
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.69235

Cumulative Model Updates: 70,296
Cumulative Timesteps: 586,333,578

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 586333578...
Checkpoint 586333578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.99502
Policy Entropy: 3.27742
Value Function Loss: 0.00374

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08710
Policy Update Magnitude: 0.55673
Value Function Update Magnitude: 0.66996

Collected Steps per Second: 22,219.56572
Overall Steps per Second: 10,579.59348

Timestep Collection Time: 2.25108
Timestep Consumption Time: 2.47670
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.72778

Cumulative Model Updates: 70,302
Cumulative Timesteps: 586,383,596

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.49094
Policy Entropy: 3.28240
Value Function Loss: 0.00377

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08686
Policy Update Magnitude: 0.55510
Value Function Update Magnitude: 0.65722

Collected Steps per Second: 22,968.48549
Overall Steps per Second: 10,697.38374

Timestep Collection Time: 2.17768
Timestep Consumption Time: 2.49804
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.67572

Cumulative Model Updates: 70,308
Cumulative Timesteps: 586,433,614

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 586433614...
Checkpoint 586433614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698.08928
Policy Entropy: 3.27739
Value Function Loss: 0.00400

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09469
Policy Update Magnitude: 0.55825
Value Function Update Magnitude: 0.65935

Collected Steps per Second: 22,727.30785
Overall Steps per Second: 10,754.93062

Timestep Collection Time: 2.20035
Timestep Consumption Time: 2.44943
PPO Batch Consumption Time: 0.29550
Total Iteration Time: 4.64977

Cumulative Model Updates: 70,314
Cumulative Timesteps: 586,483,622

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.85619
Policy Entropy: 3.27291
Value Function Loss: 0.00387

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10540
Policy Update Magnitude: 0.55883
Value Function Update Magnitude: 0.66050

Collected Steps per Second: 22,317.32626
Overall Steps per Second: 10,817.11813

Timestep Collection Time: 2.24068
Timestep Consumption Time: 2.38218
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.62286

Cumulative Model Updates: 70,320
Cumulative Timesteps: 586,533,628

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 586533628...
Checkpoint 586533628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,628.32780
Policy Entropy: 3.29307
Value Function Loss: 0.00380

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10122
Policy Update Magnitude: 0.55279
Value Function Update Magnitude: 0.64105

Collected Steps per Second: 22,317.62162
Overall Steps per Second: 10,647.96260

Timestep Collection Time: 2.24038
Timestep Consumption Time: 2.45535
PPO Batch Consumption Time: 0.29713
Total Iteration Time: 4.69573

Cumulative Model Updates: 70,326
Cumulative Timesteps: 586,583,628

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.65799
Policy Entropy: 3.30399
Value Function Loss: 0.00374

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10273
Policy Update Magnitude: 0.55250
Value Function Update Magnitude: 0.62604

Collected Steps per Second: 22,093.79992
Overall Steps per Second: 10,698.35047

Timestep Collection Time: 2.26371
Timestep Consumption Time: 2.41121
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.67493

Cumulative Model Updates: 70,332
Cumulative Timesteps: 586,633,642

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 586633642...
Checkpoint 586633642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,612.40948
Policy Entropy: 3.31558
Value Function Loss: 0.00365

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11118
Policy Update Magnitude: 0.54620
Value Function Update Magnitude: 0.60400

Collected Steps per Second: 22,367.48924
Overall Steps per Second: 10,876.45435

Timestep Collection Time: 2.23574
Timestep Consumption Time: 2.36208
PPO Batch Consumption Time: 0.28154
Total Iteration Time: 4.59782

Cumulative Model Updates: 70,338
Cumulative Timesteps: 586,683,650

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.29637
Policy Entropy: 3.30965
Value Function Loss: 0.00388

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11329
Policy Update Magnitude: 0.54726
Value Function Update Magnitude: 0.59249

Collected Steps per Second: 21,673.75962
Overall Steps per Second: 10,560.31678

Timestep Collection Time: 2.30814
Timestep Consumption Time: 2.42903
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.73717

Cumulative Model Updates: 70,344
Cumulative Timesteps: 586,733,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 586733676...
Checkpoint 586733676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.25049
Policy Entropy: 3.30371
Value Function Loss: 0.00389

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10117
Policy Update Magnitude: 0.55358
Value Function Update Magnitude: 0.60222

Collected Steps per Second: 21,533.68379
Overall Steps per Second: 10,514.45242

Timestep Collection Time: 2.32334
Timestep Consumption Time: 2.43488
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.75821

Cumulative Model Updates: 70,350
Cumulative Timesteps: 586,783,706

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.91626
Policy Entropy: 3.30013
Value Function Loss: 0.00396

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10668
Policy Update Magnitude: 0.55695
Value Function Update Magnitude: 0.61483

Collected Steps per Second: 22,618.22506
Overall Steps per Second: 10,632.96387

Timestep Collection Time: 2.21131
Timestep Consumption Time: 2.49255
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.70386

Cumulative Model Updates: 70,356
Cumulative Timesteps: 586,833,722

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 586833722...
Checkpoint 586833722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.27068
Policy Entropy: 3.30028
Value Function Loss: 0.00375

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10015
Policy Update Magnitude: 0.55658
Value Function Update Magnitude: 0.62231

Collected Steps per Second: 22,161.82118
Overall Steps per Second: 10,466.04321

Timestep Collection Time: 2.25658
Timestep Consumption Time: 2.52173
PPO Batch Consumption Time: 0.29564
Total Iteration Time: 4.77831

Cumulative Model Updates: 70,362
Cumulative Timesteps: 586,883,732

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 818.31050
Policy Entropy: 3.28546
Value Function Loss: 0.00394

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09867
Policy Update Magnitude: 0.55185
Value Function Update Magnitude: 0.62777

Collected Steps per Second: 21,917.03026
Overall Steps per Second: 10,610.90769

Timestep Collection Time: 2.28206
Timestep Consumption Time: 2.43158
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.71364

Cumulative Model Updates: 70,368
Cumulative Timesteps: 586,933,748

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 586933748...
Checkpoint 586933748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 739.75183
Policy Entropy: 3.28363
Value Function Loss: 0.00390

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09923
Policy Update Magnitude: 0.56233
Value Function Update Magnitude: 0.62063

Collected Steps per Second: 22,792.45279
Overall Steps per Second: 10,572.58576

Timestep Collection Time: 2.19441
Timestep Consumption Time: 2.53631
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.73073

Cumulative Model Updates: 70,374
Cumulative Timesteps: 586,983,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.15475
Policy Entropy: 3.30296
Value Function Loss: 0.00394

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08504
Policy Update Magnitude: 0.56047
Value Function Update Magnitude: 0.62525

Collected Steps per Second: 23,198.66262
Overall Steps per Second: 10,792.05750

Timestep Collection Time: 2.15633
Timestep Consumption Time: 2.47893
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.63526

Cumulative Model Updates: 70,380
Cumulative Timesteps: 587,033,788

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 587033788...
Checkpoint 587033788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.90340
Policy Entropy: 3.31958
Value Function Loss: 0.00377

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07858
Policy Update Magnitude: 0.55981
Value Function Update Magnitude: 0.64382

Collected Steps per Second: 22,771.34848
Overall Steps per Second: 10,662.98844

Timestep Collection Time: 2.19715
Timestep Consumption Time: 2.49497
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.69212

Cumulative Model Updates: 70,386
Cumulative Timesteps: 587,083,820

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 895.20450
Policy Entropy: 3.31562
Value Function Loss: 0.00373

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07549
Policy Update Magnitude: 0.56036
Value Function Update Magnitude: 0.65690

Collected Steps per Second: 22,680.12670
Overall Steps per Second: 10,586.62059

Timestep Collection Time: 2.20572
Timestep Consumption Time: 2.51968
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.72540

Cumulative Model Updates: 70,392
Cumulative Timesteps: 587,133,846

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 587133846...
Checkpoint 587133846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545.19686
Policy Entropy: 3.31482
Value Function Loss: 0.00361

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.07770
Policy Update Magnitude: 0.55417
Value Function Update Magnitude: 0.64604

Collected Steps per Second: 23,144.63322
Overall Steps per Second: 10,864.00986

Timestep Collection Time: 2.16076
Timestep Consumption Time: 2.44251
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.60327

Cumulative Model Updates: 70,398
Cumulative Timesteps: 587,183,856

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 961.52797
Policy Entropy: 3.32901
Value Function Loss: 0.00384

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08533
Policy Update Magnitude: 0.54657
Value Function Update Magnitude: 0.61419

Collected Steps per Second: 22,882.83036
Overall Steps per Second: 10,627.42768

Timestep Collection Time: 2.18574
Timestep Consumption Time: 2.52057
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.70631

Cumulative Model Updates: 70,404
Cumulative Timesteps: 587,233,872

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 587233872...
Checkpoint 587233872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 905.19482
Policy Entropy: 3.34310
Value Function Loss: 0.00384

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10291
Policy Update Magnitude: 0.54447
Value Function Update Magnitude: 0.62385

Collected Steps per Second: 22,774.66650
Overall Steps per Second: 10,613.82721

Timestep Collection Time: 2.19683
Timestep Consumption Time: 2.51702
PPO Batch Consumption Time: 0.29634
Total Iteration Time: 4.71385

Cumulative Model Updates: 70,410
Cumulative Timesteps: 587,283,904

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,337.32215
Policy Entropy: 3.34000
Value Function Loss: 0.00389

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08947
Policy Update Magnitude: 0.54236
Value Function Update Magnitude: 0.63689

Collected Steps per Second: 22,353.17253
Overall Steps per Second: 10,593.21563

Timestep Collection Time: 2.23700
Timestep Consumption Time: 2.48338
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.72038

Cumulative Model Updates: 70,416
Cumulative Timesteps: 587,333,908

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 587333908...
Checkpoint 587333908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 936.24169
Policy Entropy: 3.32807
Value Function Loss: 0.00388

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08747
Policy Update Magnitude: 0.54867
Value Function Update Magnitude: 0.64762

Collected Steps per Second: 22,624.83461
Overall Steps per Second: 10,606.79149

Timestep Collection Time: 2.21031
Timestep Consumption Time: 2.50440
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.71472

Cumulative Model Updates: 70,422
Cumulative Timesteps: 587,383,916

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,678.79798
Policy Entropy: 3.31976
Value Function Loss: 0.00376

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09019
Policy Update Magnitude: 0.54782
Value Function Update Magnitude: 0.64149

Collected Steps per Second: 22,513.70673
Overall Steps per Second: 10,703.49781

Timestep Collection Time: 2.22114
Timestep Consumption Time: 2.45079
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.67193

Cumulative Model Updates: 70,428
Cumulative Timesteps: 587,433,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 587433922...
Checkpoint 587433922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,406.70920
Policy Entropy: 3.32187
Value Function Loss: 0.00382

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08641
Policy Update Magnitude: 0.55420
Value Function Update Magnitude: 0.63516

Collected Steps per Second: 22,405.07143
Overall Steps per Second: 10,723.71894

Timestep Collection Time: 2.23217
Timestep Consumption Time: 2.43151
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.66368

Cumulative Model Updates: 70,434
Cumulative Timesteps: 587,483,934

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 950.34349
Policy Entropy: 3.32028
Value Function Loss: 0.00375

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.07946
Policy Update Magnitude: 0.56129
Value Function Update Magnitude: 0.65315

Collected Steps per Second: 22,483.70518
Overall Steps per Second: 10,586.45508

Timestep Collection Time: 2.22508
Timestep Consumption Time: 2.50058
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.72566

Cumulative Model Updates: 70,440
Cumulative Timesteps: 587,533,962

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 587533962...
Checkpoint 587533962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.90818
Policy Entropy: 3.31047
Value Function Loss: 0.00377

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08101
Policy Update Magnitude: 0.56887
Value Function Update Magnitude: 0.66053

Collected Steps per Second: 22,672.02059
Overall Steps per Second: 10,545.61199

Timestep Collection Time: 2.20633
Timestep Consumption Time: 2.53706
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.74339

Cumulative Model Updates: 70,446
Cumulative Timesteps: 587,583,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.05788
Policy Entropy: 3.31365
Value Function Loss: 0.00370

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08119
Policy Update Magnitude: 0.56480
Value Function Update Magnitude: 0.64505

Collected Steps per Second: 22,426.17647
Overall Steps per Second: 10,526.19259

Timestep Collection Time: 2.22972
Timestep Consumption Time: 2.52072
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.75044

Cumulative Model Updates: 70,452
Cumulative Timesteps: 587,633,988

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 587633988...
Checkpoint 587633988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621.40140
Policy Entropy: 3.31427
Value Function Loss: 0.00378

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09228
Policy Update Magnitude: 0.55665
Value Function Update Magnitude: 0.62864

Collected Steps per Second: 23,296.98886
Overall Steps per Second: 10,910.41010

Timestep Collection Time: 2.14654
Timestep Consumption Time: 2.43697
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.58351

Cumulative Model Updates: 70,458
Cumulative Timesteps: 587,683,996

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.50306
Policy Entropy: 3.32072
Value Function Loss: 0.00394

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08495
Policy Update Magnitude: 0.56178
Value Function Update Magnitude: 0.62725

Collected Steps per Second: 22,686.85223
Overall Steps per Second: 10,590.27902

Timestep Collection Time: 2.20489
Timestep Consumption Time: 2.51850
PPO Batch Consumption Time: 0.29709
Total Iteration Time: 4.72339

Cumulative Model Updates: 70,464
Cumulative Timesteps: 587,734,018

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 587734018...
Checkpoint 587734018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425.16242
Policy Entropy: 3.30957
Value Function Loss: 0.00381

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08716
Policy Update Magnitude: 0.56265
Value Function Update Magnitude: 0.62750

Collected Steps per Second: 23,053.04367
Overall Steps per Second: 10,705.91988

Timestep Collection Time: 2.16891
Timestep Consumption Time: 2.50140
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.67031

Cumulative Model Updates: 70,470
Cumulative Timesteps: 587,784,018

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 985.25654
Policy Entropy: 3.31176
Value Function Loss: 0.00388

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08437
Policy Update Magnitude: 0.56612
Value Function Update Magnitude: 0.61936

Collected Steps per Second: 22,799.82613
Overall Steps per Second: 10,812.27047

Timestep Collection Time: 2.19309
Timestep Consumption Time: 2.43147
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.62456

Cumulative Model Updates: 70,476
Cumulative Timesteps: 587,834,020

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 587834020...
Checkpoint 587834020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601.07887
Policy Entropy: 3.30551
Value Function Loss: 0.00377

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08378
Policy Update Magnitude: 0.57480
Value Function Update Magnitude: 0.60346

Collected Steps per Second: 22,994.61389
Overall Steps per Second: 10,663.07193

Timestep Collection Time: 2.17573
Timestep Consumption Time: 2.51617
PPO Batch Consumption Time: 0.29673
Total Iteration Time: 4.69189

Cumulative Model Updates: 70,482
Cumulative Timesteps: 587,884,050

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 971.27105
Policy Entropy: 3.31920
Value Function Loss: 0.00379

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.56534
Value Function Update Magnitude: 0.58893

Collected Steps per Second: 22,162.37117
Overall Steps per Second: 10,509.15942

Timestep Collection Time: 2.25653
Timestep Consumption Time: 2.50218
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.75871

Cumulative Model Updates: 70,488
Cumulative Timesteps: 587,934,060

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 587934060...
Checkpoint 587934060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 996.55290
Policy Entropy: 3.31013
Value Function Loss: 0.00375

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08324
Policy Update Magnitude: 0.56563
Value Function Update Magnitude: 0.58004

Collected Steps per Second: 22,386.86146
Overall Steps per Second: 10,541.36502

Timestep Collection Time: 2.23399
Timestep Consumption Time: 2.51037
PPO Batch Consumption Time: 0.29614
Total Iteration Time: 4.74436

Cumulative Model Updates: 70,494
Cumulative Timesteps: 587,984,072

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.95979
Policy Entropy: 3.31072
Value Function Loss: 0.00383

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08857
Policy Update Magnitude: 0.56374
Value Function Update Magnitude: 0.58277

Collected Steps per Second: 22,579.26783
Overall Steps per Second: 10,576.81539

Timestep Collection Time: 2.21513
Timestep Consumption Time: 2.51370
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.72883

Cumulative Model Updates: 70,500
Cumulative Timesteps: 588,034,088

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 588034088...
Checkpoint 588034088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 779.01286
Policy Entropy: 3.30454
Value Function Loss: 0.00381

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10141
Policy Update Magnitude: 0.55459
Value Function Update Magnitude: 0.57946

Collected Steps per Second: 22,154.08729
Overall Steps per Second: 10,512.37069

Timestep Collection Time: 2.25800
Timestep Consumption Time: 2.50058
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.75858

Cumulative Model Updates: 70,506
Cumulative Timesteps: 588,084,112

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.75068
Policy Entropy: 3.29714
Value Function Loss: 0.00401

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09235
Policy Update Magnitude: 0.55452
Value Function Update Magnitude: 0.59326

Collected Steps per Second: 22,550.86910
Overall Steps per Second: 10,587.67391

Timestep Collection Time: 2.21756
Timestep Consumption Time: 2.50566
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.72323

Cumulative Model Updates: 70,512
Cumulative Timesteps: 588,134,120

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 588134120...
Checkpoint 588134120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.66980
Policy Entropy: 3.30676
Value Function Loss: 0.00392

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08360
Policy Update Magnitude: 0.55790
Value Function Update Magnitude: 0.59554

Collected Steps per Second: 22,638.52656
Overall Steps per Second: 10,485.87950

Timestep Collection Time: 2.20960
Timestep Consumption Time: 2.56082
PPO Batch Consumption Time: 0.29644
Total Iteration Time: 4.77042

Cumulative Model Updates: 70,518
Cumulative Timesteps: 588,184,142

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.73665
Policy Entropy: 3.29840
Value Function Loss: 0.00388

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.07867
Policy Update Magnitude: 0.55554
Value Function Update Magnitude: 0.61035

Collected Steps per Second: 22,905.11936
Overall Steps per Second: 10,664.74842

Timestep Collection Time: 2.18388
Timestep Consumption Time: 2.50653
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.69041

Cumulative Model Updates: 70,524
Cumulative Timesteps: 588,234,164

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 588234164...
Checkpoint 588234164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.50948
Policy Entropy: 3.30007
Value Function Loss: 0.00401

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08734
Policy Update Magnitude: 0.56208
Value Function Update Magnitude: 0.62607

Collected Steps per Second: 23,068.47750
Overall Steps per Second: 10,838.87974

Timestep Collection Time: 2.16763
Timestep Consumption Time: 2.44576
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.61339

Cumulative Model Updates: 70,530
Cumulative Timesteps: 588,284,168

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.27925
Policy Entropy: 3.31571
Value Function Loss: 0.00395

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07722
Policy Update Magnitude: 0.55842
Value Function Update Magnitude: 0.62438

Collected Steps per Second: 22,842.99795
Overall Steps per Second: 10,581.74801

Timestep Collection Time: 2.18991
Timestep Consumption Time: 2.53748
PPO Batch Consumption Time: 0.29588
Total Iteration Time: 4.72739

Cumulative Model Updates: 70,536
Cumulative Timesteps: 588,334,192

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 588334192...
Checkpoint 588334192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.16553
Policy Entropy: 3.30309
Value Function Loss: 0.00401

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.55177
Value Function Update Magnitude: 0.60769

Collected Steps per Second: 22,800.69129
Overall Steps per Second: 10,607.59539

Timestep Collection Time: 2.19467
Timestep Consumption Time: 2.52270
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.71737

Cumulative Model Updates: 70,542
Cumulative Timesteps: 588,384,232

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.71247
Policy Entropy: 3.31493
Value Function Loss: 0.00369

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09277
Policy Update Magnitude: 0.54256
Value Function Update Magnitude: 0.60571

Collected Steps per Second: 22,617.83718
Overall Steps per Second: 10,629.57009

Timestep Collection Time: 2.21162
Timestep Consumption Time: 2.49431
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.70593

Cumulative Model Updates: 70,548
Cumulative Timesteps: 588,434,254

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 588434254...
Checkpoint 588434254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 993.31424
Policy Entropy: 3.29717
Value Function Loss: 0.00376

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08217
Policy Update Magnitude: 0.53963
Value Function Update Magnitude: 0.61008

Collected Steps per Second: 23,002.07156
Overall Steps per Second: 10,807.37122

Timestep Collection Time: 2.17450
Timestep Consumption Time: 2.45364
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.62814

Cumulative Model Updates: 70,554
Cumulative Timesteps: 588,484,272

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 870.47522
Policy Entropy: 3.29334
Value Function Loss: 0.00377

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08414
Policy Update Magnitude: 0.53823
Value Function Update Magnitude: 0.60765

Collected Steps per Second: 22,384.28590
Overall Steps per Second: 10,519.85073

Timestep Collection Time: 2.23398
Timestep Consumption Time: 2.51951
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.75349

Cumulative Model Updates: 70,560
Cumulative Timesteps: 588,534,278

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 588534278...
Checkpoint 588534278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 966.53695
Policy Entropy: 3.29458
Value Function Loss: 0.00376

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08064
Policy Update Magnitude: 0.55030
Value Function Update Magnitude: 0.60738

Collected Steps per Second: 22,510.17131
Overall Steps per Second: 10,622.50550

Timestep Collection Time: 2.22140
Timestep Consumption Time: 2.48597
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.70736

Cumulative Model Updates: 70,566
Cumulative Timesteps: 588,584,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.63837
Policy Entropy: 3.28537
Value Function Loss: 0.00387

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08772
Policy Update Magnitude: 0.55660
Value Function Update Magnitude: 0.61618

Collected Steps per Second: 22,316.40202
Overall Steps per Second: 10,557.21948

Timestep Collection Time: 2.24167
Timestep Consumption Time: 2.49689
PPO Batch Consumption Time: 0.29603
Total Iteration Time: 4.73856

Cumulative Model Updates: 70,572
Cumulative Timesteps: 588,634,308

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 588634308...
Checkpoint 588634308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,881.14582
Policy Entropy: 3.28433
Value Function Loss: 0.00391

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08526
Policy Update Magnitude: 0.56378
Value Function Update Magnitude: 0.61866

Collected Steps per Second: 22,385.00025
Overall Steps per Second: 10,543.74589

Timestep Collection Time: 2.23409
Timestep Consumption Time: 2.50901
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.74310

Cumulative Model Updates: 70,578
Cumulative Timesteps: 588,684,318

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.71122
Policy Entropy: 3.28346
Value Function Loss: 0.00382

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08757
Policy Update Magnitude: 0.56052
Value Function Update Magnitude: 0.62430

Collected Steps per Second: 22,310.10348
Overall Steps per Second: 10,433.24656

Timestep Collection Time: 2.24159
Timestep Consumption Time: 2.55175
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.79333

Cumulative Model Updates: 70,584
Cumulative Timesteps: 588,734,328

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 588734328...
Checkpoint 588734328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.55855
Policy Entropy: 3.29405
Value Function Loss: 0.00367

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07496
Policy Update Magnitude: 0.55465
Value Function Update Magnitude: 0.60528

Collected Steps per Second: 22,899.90281
Overall Steps per Second: 10,657.75335

Timestep Collection Time: 2.18394
Timestep Consumption Time: 2.50861
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.69255

Cumulative Model Updates: 70,590
Cumulative Timesteps: 588,784,340

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.52417
Policy Entropy: 3.31216
Value Function Loss: 0.00355

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08857
Policy Update Magnitude: 0.54661
Value Function Update Magnitude: 0.60664

Collected Steps per Second: 22,902.67239
Overall Steps per Second: 10,805.08374

Timestep Collection Time: 2.18368
Timestep Consumption Time: 2.44489
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.62856

Cumulative Model Updates: 70,596
Cumulative Timesteps: 588,834,352

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 588834352...
Checkpoint 588834352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.32085
Policy Entropy: 3.31416
Value Function Loss: 0.00350

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08885
Policy Update Magnitude: 0.53327
Value Function Update Magnitude: 0.60571

Collected Steps per Second: 22,634.59663
Overall Steps per Second: 10,733.20213

Timestep Collection Time: 2.20963
Timestep Consumption Time: 2.45012
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.65975

Cumulative Model Updates: 70,602
Cumulative Timesteps: 588,884,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 808.96100
Policy Entropy: 3.30742
Value Function Loss: 0.00373

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09562
Policy Update Magnitude: 0.53873
Value Function Update Magnitude: 0.60975

Collected Steps per Second: 22,446.36774
Overall Steps per Second: 10,532.93554

Timestep Collection Time: 2.22807
Timestep Consumption Time: 2.52009
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.74815

Cumulative Model Updates: 70,608
Cumulative Timesteps: 588,934,378

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 588934378...
Checkpoint 588934378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 736.08443
Policy Entropy: 3.28286
Value Function Loss: 0.00377

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10347
Policy Update Magnitude: 0.55325
Value Function Update Magnitude: 0.63295

Collected Steps per Second: 23,108.54033
Overall Steps per Second: 10,928.79126

Timestep Collection Time: 2.16457
Timestep Consumption Time: 2.41233
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.57690

Cumulative Model Updates: 70,614
Cumulative Timesteps: 588,984,398

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631.75961
Policy Entropy: 3.26410
Value Function Loss: 0.00395

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10656
Policy Update Magnitude: 0.55709
Value Function Update Magnitude: 0.65130

Collected Steps per Second: 22,765.37423
Overall Steps per Second: 10,664.82545

Timestep Collection Time: 2.19641
Timestep Consumption Time: 2.49209
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.68850

Cumulative Model Updates: 70,620
Cumulative Timesteps: 589,034,400

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 589034400...
Checkpoint 589034400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.98358
Policy Entropy: 3.26368
Value Function Loss: 0.00403

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09135
Policy Update Magnitude: 0.56789
Value Function Update Magnitude: 0.67036

Collected Steps per Second: 22,866.85256
Overall Steps per Second: 10,763.62548

Timestep Collection Time: 2.18762
Timestep Consumption Time: 2.45988
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.64750

Cumulative Model Updates: 70,626
Cumulative Timesteps: 589,084,424

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.21110
Policy Entropy: 3.26977
Value Function Loss: 0.00401

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09472
Policy Update Magnitude: 0.57265
Value Function Update Magnitude: 0.66683

Collected Steps per Second: 22,381.57220
Overall Steps per Second: 10,689.80353

Timestep Collection Time: 2.23461
Timestep Consumption Time: 2.44406
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.67866

Cumulative Model Updates: 70,632
Cumulative Timesteps: 589,134,438

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 589134438...
Checkpoint 589134438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.55354
Policy Entropy: 3.28086
Value Function Loss: 0.00400

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08876
Policy Update Magnitude: 0.57550
Value Function Update Magnitude: 0.65850

Collected Steps per Second: 22,319.33182
Overall Steps per Second: 10,613.01560

Timestep Collection Time: 2.24093
Timestep Consumption Time: 2.47178
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.71270

Cumulative Model Updates: 70,638
Cumulative Timesteps: 589,184,454

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585.79483
Policy Entropy: 3.27737
Value Function Loss: 0.00409

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.57479
Value Function Update Magnitude: 0.67118

Collected Steps per Second: 22,697.49465
Overall Steps per Second: 10,684.31750

Timestep Collection Time: 2.20289
Timestep Consumption Time: 2.47687
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.67976

Cumulative Model Updates: 70,644
Cumulative Timesteps: 589,234,454

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 589234454...
Checkpoint 589234454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.67988
Policy Entropy: 3.26542
Value Function Loss: 0.00398

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10825
Policy Update Magnitude: 0.57957
Value Function Update Magnitude: 0.67014

Collected Steps per Second: 22,540.51754
Overall Steps per Second: 10,779.87437

Timestep Collection Time: 2.21858
Timestep Consumption Time: 2.42043
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.63902

Cumulative Model Updates: 70,650
Cumulative Timesteps: 589,284,462

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.30701
Policy Entropy: 3.24763
Value Function Loss: 0.00413

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.11110
Policy Update Magnitude: 0.57826
Value Function Update Magnitude: 0.65239

Collected Steps per Second: 22,619.60120
Overall Steps per Second: 10,539.21249

Timestep Collection Time: 2.21180
Timestep Consumption Time: 2.53524
PPO Batch Consumption Time: 0.29624
Total Iteration Time: 4.74703

Cumulative Model Updates: 70,656
Cumulative Timesteps: 589,334,492

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 589334492...
Checkpoint 589334492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.23437
Policy Entropy: 3.26069
Value Function Loss: 0.00414

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10854
Policy Update Magnitude: 0.57543
Value Function Update Magnitude: 0.64385

Collected Steps per Second: 22,530.14258
Overall Steps per Second: 10,637.27718

Timestep Collection Time: 2.22031
Timestep Consumption Time: 2.48239
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.70271

Cumulative Model Updates: 70,662
Cumulative Timesteps: 589,384,516

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.87621
Policy Entropy: 3.28005
Value Function Loss: 0.00387

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.56668
Value Function Update Magnitude: 0.64921

Collected Steps per Second: 22,962.60477
Overall Steps per Second: 10,829.24191

Timestep Collection Time: 2.17841
Timestep Consumption Time: 2.44075
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.61916

Cumulative Model Updates: 70,668
Cumulative Timesteps: 589,434,538

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 589434538...
Checkpoint 589434538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.02064
Policy Entropy: 3.29138
Value Function Loss: 0.00391

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10002
Policy Update Magnitude: 0.56032
Value Function Update Magnitude: 0.63619

Collected Steps per Second: 21,890.13856
Overall Steps per Second: 10,613.17293

Timestep Collection Time: 2.28560
Timestep Consumption Time: 2.42855
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.71414

Cumulative Model Updates: 70,674
Cumulative Timesteps: 589,484,570

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726.03384
Policy Entropy: 3.30026
Value Function Loss: 0.00379

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08816
Policy Update Magnitude: 0.55893
Value Function Update Magnitude: 0.62381

Collected Steps per Second: 22,441.56571
Overall Steps per Second: 10,576.47565

Timestep Collection Time: 2.22872
Timestep Consumption Time: 2.50026
PPO Batch Consumption Time: 0.29680
Total Iteration Time: 4.72899

Cumulative Model Updates: 70,680
Cumulative Timesteps: 589,534,586

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 589534586...
Checkpoint 589534586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 966.19603
Policy Entropy: 3.29822
Value Function Loss: 0.00403

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09595
Policy Update Magnitude: 0.56021
Value Function Update Magnitude: 0.64455

Collected Steps per Second: 22,615.93413
Overall Steps per Second: 10,625.21699

Timestep Collection Time: 2.21154
Timestep Consumption Time: 2.49575
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.70729

Cumulative Model Updates: 70,686
Cumulative Timesteps: 589,584,602

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 892.37841
Policy Entropy: 3.30719
Value Function Loss: 0.00400

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08930
Policy Update Magnitude: 0.56225
Value Function Update Magnitude: 0.66887

Collected Steps per Second: 22,229.84648
Overall Steps per Second: 10,549.50521

Timestep Collection Time: 2.25013
Timestep Consumption Time: 2.49133
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.74145

Cumulative Model Updates: 70,692
Cumulative Timesteps: 589,634,622

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 589634622...
Checkpoint 589634622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.30841
Policy Entropy: 3.30278
Value Function Loss: 0.00398

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.07855
Policy Update Magnitude: 0.56146
Value Function Update Magnitude: 0.68500

Collected Steps per Second: 22,941.47516
Overall Steps per Second: 10,645.88844

Timestep Collection Time: 2.18068
Timestep Consumption Time: 2.51860
PPO Batch Consumption Time: 0.29599
Total Iteration Time: 4.69928

Cumulative Model Updates: 70,698
Cumulative Timesteps: 589,684,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 727.87489
Policy Entropy: 3.28480
Value Function Loss: 0.00386

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.55984
Value Function Update Magnitude: 0.66020

Collected Steps per Second: 22,834.76233
Overall Steps per Second: 10,847.74126

Timestep Collection Time: 2.19017
Timestep Consumption Time: 2.42019
PPO Batch Consumption Time: 0.28183
Total Iteration Time: 4.61036

Cumulative Model Updates: 70,704
Cumulative Timesteps: 589,734,662

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 589734662...
Checkpoint 589734662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.28506
Policy Entropy: 3.30024
Value Function Loss: 0.00398

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09319
Policy Update Magnitude: 0.55248
Value Function Update Magnitude: 0.62023

Collected Steps per Second: 22,784.71893
Overall Steps per Second: 10,678.41282

Timestep Collection Time: 2.19577
Timestep Consumption Time: 2.48938
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.68515

Cumulative Model Updates: 70,710
Cumulative Timesteps: 589,784,692

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.48520
Policy Entropy: 3.29207
Value Function Loss: 0.00394

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08387
Policy Update Magnitude: 0.55033
Value Function Update Magnitude: 0.60706

Collected Steps per Second: 23,175.22662
Overall Steps per Second: 10,874.95412

Timestep Collection Time: 2.15799
Timestep Consumption Time: 2.44083
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.59882

Cumulative Model Updates: 70,716
Cumulative Timesteps: 589,834,704

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 589834704...
Checkpoint 589834704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 810.58163
Policy Entropy: 3.30049
Value Function Loss: 0.00392

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07610
Policy Update Magnitude: 0.54848
Value Function Update Magnitude: 0.59086

Collected Steps per Second: 22,821.93724
Overall Steps per Second: 10,690.80974

Timestep Collection Time: 2.19166
Timestep Consumption Time: 2.48693
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.67860

Cumulative Model Updates: 70,722
Cumulative Timesteps: 589,884,722

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.48090
Policy Entropy: 3.28043
Value Function Loss: 0.00386

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.06910
Policy Update Magnitude: 0.54833
Value Function Update Magnitude: 0.57882

Collected Steps per Second: 22,604.04144
Overall Steps per Second: 10,779.39147

Timestep Collection Time: 2.21252
Timestep Consumption Time: 2.42707
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.63959

Cumulative Model Updates: 70,728
Cumulative Timesteps: 589,934,734

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 589934734...
Checkpoint 589934734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170.88161
Policy Entropy: 3.28743
Value Function Loss: 0.00387

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08187
Policy Update Magnitude: 0.55072
Value Function Update Magnitude: 0.56691

Collected Steps per Second: 22,378.70767
Overall Steps per Second: 10,712.44757

Timestep Collection Time: 2.23561
Timestep Consumption Time: 2.43466
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.67027

Cumulative Model Updates: 70,734
Cumulative Timesteps: 589,984,764

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.08722
Policy Entropy: 3.27443
Value Function Loss: 0.00391

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08136
Policy Update Magnitude: 0.54565
Value Function Update Magnitude: 0.58718

Collected Steps per Second: 22,340.57389
Overall Steps per Second: 10,590.36164

Timestep Collection Time: 2.23933
Timestep Consumption Time: 2.48458
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.72392

Cumulative Model Updates: 70,740
Cumulative Timesteps: 590,034,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 590034792...
Checkpoint 590034792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.68147
Policy Entropy: 3.29438
Value Function Loss: 0.00400

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09332
Policy Update Magnitude: 0.54254
Value Function Update Magnitude: 0.59673

Collected Steps per Second: 22,668.51381
Overall Steps per Second: 10,670.25601

Timestep Collection Time: 2.20694
Timestep Consumption Time: 2.48161
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.68855

Cumulative Model Updates: 70,746
Cumulative Timesteps: 590,084,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704.01334
Policy Entropy: 3.29453
Value Function Loss: 0.00405

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08489
Policy Update Magnitude: 0.54448
Value Function Update Magnitude: 0.60112

Collected Steps per Second: 22,426.63126
Overall Steps per Second: 10,750.62866

Timestep Collection Time: 2.23047
Timestep Consumption Time: 2.42246
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.65294

Cumulative Model Updates: 70,752
Cumulative Timesteps: 590,134,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 590134842...
Checkpoint 590134842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 856.10274
Policy Entropy: 3.29852
Value Function Loss: 0.00406

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09348
Policy Update Magnitude: 0.55127
Value Function Update Magnitude: 0.63333

Collected Steps per Second: 22,906.52299
Overall Steps per Second: 10,607.75828

Timestep Collection Time: 2.18313
Timestep Consumption Time: 2.53115
PPO Batch Consumption Time: 0.29668
Total Iteration Time: 4.71429

Cumulative Model Updates: 70,758
Cumulative Timesteps: 590,184,850

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,393.44051
Policy Entropy: 3.29620
Value Function Loss: 0.00395

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.55161
Value Function Update Magnitude: 0.65170

Collected Steps per Second: 22,978.27436
Overall Steps per Second: 10,829.19794

Timestep Collection Time: 2.17788
Timestep Consumption Time: 2.44333
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.62121

Cumulative Model Updates: 70,764
Cumulative Timesteps: 590,234,894

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 590234894...
Checkpoint 590234894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.54606
Policy Entropy: 3.28632
Value Function Loss: 0.00399

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09424
Policy Update Magnitude: 0.54941
Value Function Update Magnitude: 0.63973

Collected Steps per Second: 22,601.93256
Overall Steps per Second: 10,703.60112

Timestep Collection Time: 2.21229
Timestep Consumption Time: 2.45922
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.67151

Cumulative Model Updates: 70,770
Cumulative Timesteps: 590,284,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.09161
Policy Entropy: 3.28340
Value Function Loss: 0.00383

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09466
Policy Update Magnitude: 0.54627
Value Function Update Magnitude: 0.62557

Collected Steps per Second: 22,383.69877
Overall Steps per Second: 10,568.33574

Timestep Collection Time: 2.23439
Timestep Consumption Time: 2.49804
PPO Batch Consumption Time: 0.29585
Total Iteration Time: 4.73244

Cumulative Model Updates: 70,776
Cumulative Timesteps: 590,334,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 590334910...
Checkpoint 590334910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 964.40775
Policy Entropy: 3.28267
Value Function Loss: 0.00379

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09039
Policy Update Magnitude: 0.54590
Value Function Update Magnitude: 0.62298

Collected Steps per Second: 22,838.94978
Overall Steps per Second: 10,719.46959

Timestep Collection Time: 2.18959
Timestep Consumption Time: 2.47556
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.66516

Cumulative Model Updates: 70,782
Cumulative Timesteps: 590,384,918

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.02550
Policy Entropy: 3.29415
Value Function Loss: 0.00357

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08261
Policy Update Magnitude: 0.54410
Value Function Update Magnitude: 0.62119

Collected Steps per Second: 23,076.99760
Overall Steps per Second: 10,737.51616

Timestep Collection Time: 2.16761
Timestep Consumption Time: 2.49101
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.65862

Cumulative Model Updates: 70,788
Cumulative Timesteps: 590,434,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 590434940...
Checkpoint 590434940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.93994
Policy Entropy: 3.29635
Value Function Loss: 0.00364

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09200
Policy Update Magnitude: 0.54338
Value Function Update Magnitude: 0.61280

Collected Steps per Second: 22,436.38019
Overall Steps per Second: 10,672.83716

Timestep Collection Time: 2.22879
Timestep Consumption Time: 2.45656
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.68535

Cumulative Model Updates: 70,794
Cumulative Timesteps: 590,484,946

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,584.82304
Policy Entropy: 3.30636
Value Function Loss: 0.00362

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.54740
Value Function Update Magnitude: 0.62999

Collected Steps per Second: 22,148.91900
Overall Steps per Second: 10,495.51026

Timestep Collection Time: 2.25808
Timestep Consumption Time: 2.50720
PPO Batch Consumption Time: 0.29610
Total Iteration Time: 4.76528

Cumulative Model Updates: 70,800
Cumulative Timesteps: 590,534,960

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 590534960...
Checkpoint 590534960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,433.67551
Policy Entropy: 3.31379
Value Function Loss: 0.00365

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08863
Policy Update Magnitude: 0.55323
Value Function Update Magnitude: 0.62719

Collected Steps per Second: 22,124.52207
Overall Steps per Second: 10,572.89991

Timestep Collection Time: 2.26075
Timestep Consumption Time: 2.47002
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.73077

Cumulative Model Updates: 70,806
Cumulative Timesteps: 590,584,978

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,337.10977
Policy Entropy: 3.32655
Value Function Loss: 0.00375

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09158
Policy Update Magnitude: 0.54981
Value Function Update Magnitude: 0.63113

Collected Steps per Second: 22,531.97594
Overall Steps per Second: 10,632.10625

Timestep Collection Time: 2.21951
Timestep Consumption Time: 2.48417
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.70368

Cumulative Model Updates: 70,812
Cumulative Timesteps: 590,634,988

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 590634988...
Checkpoint 590634988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 951.76478
Policy Entropy: 3.32491
Value Function Loss: 0.00376

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10043
Policy Update Magnitude: 0.54564
Value Function Update Magnitude: 0.64346

Collected Steps per Second: 22,513.81110
Overall Steps per Second: 10,613.34297

Timestep Collection Time: 2.22086
Timestep Consumption Time: 2.49019
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.71105

Cumulative Model Updates: 70,818
Cumulative Timesteps: 590,684,988

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.36849
Policy Entropy: 3.32032
Value Function Loss: 0.00381

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10174
Policy Update Magnitude: 0.54612
Value Function Update Magnitude: 0.62181

Collected Steps per Second: 22,286.75690
Overall Steps per Second: 10,676.76918

Timestep Collection Time: 2.24420
Timestep Consumption Time: 2.44036
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.68456

Cumulative Model Updates: 70,824
Cumulative Timesteps: 590,735,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 590735004...
Checkpoint 590735004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 843.71759
Policy Entropy: 3.31290
Value Function Loss: 0.00367

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.54179
Value Function Update Magnitude: 0.58788

Collected Steps per Second: 22,811.41056
Overall Steps per Second: 10,805.67351

Timestep Collection Time: 2.19224
Timestep Consumption Time: 2.43570
PPO Batch Consumption Time: 0.29553
Total Iteration Time: 4.62794

Cumulative Model Updates: 70,830
Cumulative Timesteps: 590,785,012

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.00897
Policy Entropy: 3.30489
Value Function Loss: 0.00358

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07785
Policy Update Magnitude: 0.53959
Value Function Update Magnitude: 0.57626

Collected Steps per Second: 22,482.80247
Overall Steps per Second: 10,761.91945

Timestep Collection Time: 2.22401
Timestep Consumption Time: 2.42219
PPO Batch Consumption Time: 0.28179
Total Iteration Time: 4.64620

Cumulative Model Updates: 70,836
Cumulative Timesteps: 590,835,014

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 590835014...
Checkpoint 590835014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 871.27784
Policy Entropy: 3.29216
Value Function Loss: 0.00375

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08404
Policy Update Magnitude: 0.54704
Value Function Update Magnitude: 0.59185

Collected Steps per Second: 22,589.62997
Overall Steps per Second: 10,678.63352

Timestep Collection Time: 2.21535
Timestep Consumption Time: 2.47101
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.68637

Cumulative Model Updates: 70,842
Cumulative Timesteps: 590,885,058

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 763.10761
Policy Entropy: 3.28467
Value Function Loss: 0.00388

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10192
Policy Update Magnitude: 0.55056
Value Function Update Magnitude: 0.61018

Collected Steps per Second: 23,076.97595
Overall Steps per Second: 10,936.37508

Timestep Collection Time: 2.16770
Timestep Consumption Time: 2.40639
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.57409

Cumulative Model Updates: 70,848
Cumulative Timesteps: 590,935,082

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 590935082...
Checkpoint 590935082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 946.22000
Policy Entropy: 3.27060
Value Function Loss: 0.00412

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11499
Policy Update Magnitude: 0.55529
Value Function Update Magnitude: 0.62412

Collected Steps per Second: 22,515.42298
Overall Steps per Second: 10,753.31082

Timestep Collection Time: 2.22194
Timestep Consumption Time: 2.43039
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.65233

Cumulative Model Updates: 70,854
Cumulative Timesteps: 590,985,110

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.28878
Policy Entropy: 3.28551
Value Function Loss: 0.00379

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.56230
Value Function Update Magnitude: 0.62317

Collected Steps per Second: 22,404.85666
Overall Steps per Second: 10,812.32641

Timestep Collection Time: 2.23166
Timestep Consumption Time: 2.39269
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.62435

Cumulative Model Updates: 70,860
Cumulative Timesteps: 591,035,110

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 591035110...
Checkpoint 591035110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 934.48826
Policy Entropy: 3.29925
Value Function Loss: 0.00359

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09007
Policy Update Magnitude: 0.55371
Value Function Update Magnitude: 0.61893

Collected Steps per Second: 21,624.70504
Overall Steps per Second: 10,708.36945

Timestep Collection Time: 2.31263
Timestep Consumption Time: 2.35755
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.67018

Cumulative Model Updates: 70,866
Cumulative Timesteps: 591,085,120

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.38187
Policy Entropy: 3.29305
Value Function Loss: 0.00358

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.55019
Value Function Update Magnitude: 0.60635

Collected Steps per Second: 21,843.36708
Overall Steps per Second: 10,695.31340

Timestep Collection Time: 2.28994
Timestep Consumption Time: 2.38687
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.67681

Cumulative Model Updates: 70,872
Cumulative Timesteps: 591,135,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 591135140...
Checkpoint 591135140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 834.74400
Policy Entropy: 3.28175
Value Function Loss: 0.00372

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09068
Policy Update Magnitude: 0.54621
Value Function Update Magnitude: 0.59885

Collected Steps per Second: 21,793.65521
Overall Steps per Second: 10,707.80487

Timestep Collection Time: 2.29489
Timestep Consumption Time: 2.37591
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.67080

Cumulative Model Updates: 70,878
Cumulative Timesteps: 591,185,154

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,413.97351
Policy Entropy: 3.28013
Value Function Loss: 0.00386

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09126
Policy Update Magnitude: 0.54749
Value Function Update Magnitude: 0.60924

Collected Steps per Second: 21,763.71196
Overall Steps per Second: 10,500.72252

Timestep Collection Time: 2.29768
Timestep Consumption Time: 2.46447
PPO Batch Consumption Time: 0.29746
Total Iteration Time: 4.76215

Cumulative Model Updates: 70,884
Cumulative Timesteps: 591,235,160

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 591235160...
Checkpoint 591235160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.59233
Policy Entropy: 3.28407
Value Function Loss: 0.00369

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08255
Policy Update Magnitude: 0.54684
Value Function Update Magnitude: 0.65810

Collected Steps per Second: 22,122.37197
Overall Steps per Second: 10,634.20859

Timestep Collection Time: 2.26061
Timestep Consumption Time: 2.44214
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.70275

Cumulative Model Updates: 70,890
Cumulative Timesteps: 591,285,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,785.76606
Policy Entropy: 3.28325
Value Function Loss: 0.00370

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09355
Policy Update Magnitude: 0.54111
Value Function Update Magnitude: 0.65717

Collected Steps per Second: 22,170.38908
Overall Steps per Second: 10,653.35449

Timestep Collection Time: 2.25634
Timestep Consumption Time: 2.43927
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.69561

Cumulative Model Updates: 70,896
Cumulative Timesteps: 591,335,194

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 591335194...
Checkpoint 591335194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682.22399
Policy Entropy: 3.28824
Value Function Loss: 0.00375

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08862
Policy Update Magnitude: 0.54507
Value Function Update Magnitude: 0.65783

Collected Steps per Second: 21,548.04855
Overall Steps per Second: 10,401.08119

Timestep Collection Time: 2.32077
Timestep Consumption Time: 2.48719
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.80796

Cumulative Model Updates: 70,902
Cumulative Timesteps: 591,385,202

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698.05006
Policy Entropy: 3.28297
Value Function Loss: 0.00392

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08728
Policy Update Magnitude: 0.55080
Value Function Update Magnitude: 0.66281

Collected Steps per Second: 22,102.31166
Overall Steps per Second: 10,638.85243

Timestep Collection Time: 2.26230
Timestep Consumption Time: 2.43765
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.69994

Cumulative Model Updates: 70,908
Cumulative Timesteps: 591,435,204

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 591435204...
Checkpoint 591435204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.09236
Policy Entropy: 3.27211
Value Function Loss: 0.00408

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10426
Policy Update Magnitude: 0.56353
Value Function Update Magnitude: 0.67832

Collected Steps per Second: 22,880.59426
Overall Steps per Second: 10,712.24293

Timestep Collection Time: 2.18587
Timestep Consumption Time: 2.48299
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.66886

Cumulative Model Updates: 70,914
Cumulative Timesteps: 591,485,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.53930
Policy Entropy: 3.27596
Value Function Loss: 0.00414

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10387
Policy Update Magnitude: 0.57687
Value Function Update Magnitude: 0.69533

Collected Steps per Second: 23,361.77132
Overall Steps per Second: 10,754.66726

Timestep Collection Time: 2.14051
Timestep Consumption Time: 2.50920
PPO Batch Consumption Time: 0.29620
Total Iteration Time: 4.64970

Cumulative Model Updates: 70,920
Cumulative Timesteps: 591,535,224

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 591535224...
Checkpoint 591535224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.94446
Policy Entropy: 3.27720
Value Function Loss: 0.00404

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.12974
Policy Update Magnitude: 0.56868
Value Function Update Magnitude: 0.69050

Collected Steps per Second: 23,087.12331
Overall Steps per Second: 10,746.42996

Timestep Collection Time: 2.16632
Timestep Consumption Time: 2.48769
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.65401

Cumulative Model Updates: 70,926
Cumulative Timesteps: 591,585,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.62030
Policy Entropy: 3.28139
Value Function Loss: 0.00396

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11459
Policy Update Magnitude: 0.55663
Value Function Update Magnitude: 0.66196

Collected Steps per Second: 21,910.15662
Overall Steps per Second: 10,747.54497

Timestep Collection Time: 2.28241
Timestep Consumption Time: 2.37056
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.65297

Cumulative Model Updates: 70,932
Cumulative Timesteps: 591,635,246

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 591635246...
Checkpoint 591635246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 886.46727
Policy Entropy: 3.27768
Value Function Loss: 0.00411

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09900
Policy Update Magnitude: 0.55245
Value Function Update Magnitude: 0.65313

Collected Steps per Second: 22,077.71502
Overall Steps per Second: 10,608.77916

Timestep Collection Time: 2.26491
Timestep Consumption Time: 2.44855
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.71345

Cumulative Model Updates: 70,938
Cumulative Timesteps: 591,685,250

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.05288
Policy Entropy: 3.29255
Value Function Loss: 0.00401

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07446
Policy Update Magnitude: 0.55893
Value Function Update Magnitude: 0.64041

Collected Steps per Second: 22,053.22288
Overall Steps per Second: 10,642.11416

Timestep Collection Time: 2.26733
Timestep Consumption Time: 2.43117
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.69850

Cumulative Model Updates: 70,944
Cumulative Timesteps: 591,735,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 591735252...
Checkpoint 591735252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.51895
Policy Entropy: 3.29740
Value Function Loss: 0.00393

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08722
Policy Update Magnitude: 0.56294
Value Function Update Magnitude: 0.64693

Collected Steps per Second: 22,901.30134
Overall Steps per Second: 10,660.52879

Timestep Collection Time: 2.18372
Timestep Consumption Time: 2.50742
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.69114

Cumulative Model Updates: 70,950
Cumulative Timesteps: 591,785,262

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.08027
Policy Entropy: 3.30626
Value Function Loss: 0.00393

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08480
Policy Update Magnitude: 0.55440
Value Function Update Magnitude: 0.64615

Collected Steps per Second: 22,950.82343
Overall Steps per Second: 10,708.69866

Timestep Collection Time: 2.17883
Timestep Consumption Time: 2.49083
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.66966

Cumulative Model Updates: 70,956
Cumulative Timesteps: 591,835,268

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 591835268...
Checkpoint 591835268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 856.91793
Policy Entropy: 3.28500
Value Function Loss: 0.00378

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.07811
Policy Update Magnitude: 0.55353
Value Function Update Magnitude: 0.63887

Collected Steps per Second: 23,022.19243
Overall Steps per Second: 10,645.25314

Timestep Collection Time: 2.17208
Timestep Consumption Time: 2.52541
PPO Batch Consumption Time: 0.29852
Total Iteration Time: 4.69749

Cumulative Model Updates: 70,962
Cumulative Timesteps: 591,885,274

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 770.19100
Policy Entropy: 3.27845
Value Function Loss: 0.00384

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09167
Policy Update Magnitude: 0.55804
Value Function Update Magnitude: 0.63701

Collected Steps per Second: 23,145.37277
Overall Steps per Second: 10,847.75352

Timestep Collection Time: 2.16104
Timestep Consumption Time: 2.44987
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.61091

Cumulative Model Updates: 70,968
Cumulative Timesteps: 591,935,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 591935292...
Checkpoint 591935292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.47514
Policy Entropy: 3.26990
Value Function Loss: 0.00401

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.56726
Value Function Update Magnitude: 0.63950

Collected Steps per Second: 22,409.41844
Overall Steps per Second: 10,688.65779

Timestep Collection Time: 2.23174
Timestep Consumption Time: 2.44724
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.67898

Cumulative Model Updates: 70,974
Cumulative Timesteps: 591,985,304

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.14943
Policy Entropy: 3.27500
Value Function Loss: 0.00404

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11182
Policy Update Magnitude: 0.56778
Value Function Update Magnitude: 0.63588

Collected Steps per Second: 22,909.72888
Overall Steps per Second: 10,832.19041

Timestep Collection Time: 2.18300
Timestep Consumption Time: 2.43398
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.61698

Cumulative Model Updates: 70,980
Cumulative Timesteps: 592,035,316

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 592035316...
Checkpoint 592035316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 844.12568
Policy Entropy: 3.27423
Value Function Loss: 0.00409

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11247
Policy Update Magnitude: 0.55757
Value Function Update Magnitude: 0.62324

Collected Steps per Second: 22,568.27248
Overall Steps per Second: 10,770.12024

Timestep Collection Time: 2.21568
Timestep Consumption Time: 2.42717
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.64285

Cumulative Model Updates: 70,986
Cumulative Timesteps: 592,085,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.26957
Policy Entropy: 3.27097
Value Function Loss: 0.00406

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11715
Policy Update Magnitude: 0.56401
Value Function Update Magnitude: 0.64351

Collected Steps per Second: 22,567.33597
Overall Steps per Second: 10,716.86113

Timestep Collection Time: 2.21559
Timestep Consumption Time: 2.44995
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.66555

Cumulative Model Updates: 70,992
Cumulative Timesteps: 592,135,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 592135320...
Checkpoint 592135320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.82076
Policy Entropy: 3.27359
Value Function Loss: 0.00383

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.12003
Policy Update Magnitude: 0.56730
Value Function Update Magnitude: 0.65629

Collected Steps per Second: 22,116.52480
Overall Steps per Second: 10,506.99387

Timestep Collection Time: 2.26102
Timestep Consumption Time: 2.49828
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.75931

Cumulative Model Updates: 70,998
Cumulative Timesteps: 592,185,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 812.51379
Policy Entropy: 3.27088
Value Function Loss: 0.00373

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11053
Policy Update Magnitude: 0.55859
Value Function Update Magnitude: 0.63880

Collected Steps per Second: 23,036.83743
Overall Steps per Second: 10,716.89307

Timestep Collection Time: 2.17087
Timestep Consumption Time: 2.49559
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.66646

Cumulative Model Updates: 71,004
Cumulative Timesteps: 592,235,336

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 592235336...
Checkpoint 592235336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,514.69043
Policy Entropy: 3.28592
Value Function Loss: 0.00379

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08664
Policy Update Magnitude: 0.55088
Value Function Update Magnitude: 0.62494

Collected Steps per Second: 21,896.52916
Overall Steps per Second: 10,569.46159

Timestep Collection Time: 2.28484
Timestep Consumption Time: 2.44861
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.73345

Cumulative Model Updates: 71,010
Cumulative Timesteps: 592,285,366

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.82814
Policy Entropy: 3.28719
Value Function Loss: 0.00397

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.55194
Value Function Update Magnitude: 0.63749

Collected Steps per Second: 22,613.43451
Overall Steps per Second: 10,507.07464

Timestep Collection Time: 2.21187
Timestep Consumption Time: 2.54854
PPO Batch Consumption Time: 0.29815
Total Iteration Time: 4.76041

Cumulative Model Updates: 71,016
Cumulative Timesteps: 592,335,384

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 592335384...
Checkpoint 592335384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.80882
Policy Entropy: 3.29066
Value Function Loss: 0.00402

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08200
Policy Update Magnitude: 0.55737
Value Function Update Magnitude: 0.62883

Collected Steps per Second: 22,299.98375
Overall Steps per Second: 10,612.27544

Timestep Collection Time: 2.24215
Timestep Consumption Time: 2.46937
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.71152

Cumulative Model Updates: 71,022
Cumulative Timesteps: 592,385,384

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 922.54370
Policy Entropy: 3.29402
Value Function Loss: 0.00387

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08083
Policy Update Magnitude: 0.55902
Value Function Update Magnitude: 0.61697

Collected Steps per Second: 22,823.85473
Overall Steps per Second: 10,638.61984

Timestep Collection Time: 2.19157
Timestep Consumption Time: 2.51017
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.70174

Cumulative Model Updates: 71,028
Cumulative Timesteps: 592,435,404

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 592435404...
Checkpoint 592435404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328.33934
Policy Entropy: 3.28444
Value Function Loss: 0.00375

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08408
Policy Update Magnitude: 0.54996
Value Function Update Magnitude: 0.60921

Collected Steps per Second: 22,744.25441
Overall Steps per Second: 10,662.71913

Timestep Collection Time: 2.19836
Timestep Consumption Time: 2.49088
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.68924

Cumulative Model Updates: 71,034
Cumulative Timesteps: 592,485,404

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,097.28842
Policy Entropy: 3.28168
Value Function Loss: 0.00373

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09839
Policy Update Magnitude: 0.55422
Value Function Update Magnitude: 0.61408

Collected Steps per Second: 23,091.31559
Overall Steps per Second: 10,761.06627

Timestep Collection Time: 2.16592
Timestep Consumption Time: 2.48176
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.64768

Cumulative Model Updates: 71,040
Cumulative Timesteps: 592,535,418

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 592535418...
Checkpoint 592535418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.38185
Policy Entropy: 3.28218
Value Function Loss: 0.00394

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09578
Policy Update Magnitude: 0.57087
Value Function Update Magnitude: 0.64288

Collected Steps per Second: 22,862.36248
Overall Steps per Second: 10,644.65135

Timestep Collection Time: 2.18779
Timestep Consumption Time: 2.51110
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.69889

Cumulative Model Updates: 71,046
Cumulative Timesteps: 592,585,436

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723.65341
Policy Entropy: 3.29812
Value Function Loss: 0.00400

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09310
Policy Update Magnitude: 0.58113
Value Function Update Magnitude: 0.66731

Collected Steps per Second: 22,959.90896
Overall Steps per Second: 10,854.87312

Timestep Collection Time: 2.17893
Timestep Consumption Time: 2.42988
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.60881

Cumulative Model Updates: 71,052
Cumulative Timesteps: 592,635,464

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 592635464...
Checkpoint 592635464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.00234
Policy Entropy: 3.31137
Value Function Loss: 0.00392

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09437
Policy Update Magnitude: 0.57993
Value Function Update Magnitude: 0.67364

Collected Steps per Second: 22,420.77492
Overall Steps per Second: 10,667.55840

Timestep Collection Time: 2.23097
Timestep Consumption Time: 2.45802
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.68898

Cumulative Model Updates: 71,058
Cumulative Timesteps: 592,685,484

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 962.61499
Policy Entropy: 3.30603
Value Function Loss: 0.00417

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08347
Policy Update Magnitude: 0.58284
Value Function Update Magnitude: 0.66161

Collected Steps per Second: 22,835.81616
Overall Steps per Second: 10,659.18741

Timestep Collection Time: 2.19068
Timestep Consumption Time: 2.50255
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.69323

Cumulative Model Updates: 71,064
Cumulative Timesteps: 592,735,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 592735510...
Checkpoint 592735510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.79303
Policy Entropy: 3.29466
Value Function Loss: 0.00421

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08801
Policy Update Magnitude: 0.58628
Value Function Update Magnitude: 0.65075

Collected Steps per Second: 22,456.94398
Overall Steps per Second: 10,545.05421

Timestep Collection Time: 2.22675
Timestep Consumption Time: 2.51538
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.74213

Cumulative Model Updates: 71,070
Cumulative Timesteps: 592,785,516

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 951.46170
Policy Entropy: 3.27791
Value Function Loss: 0.00443

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08938
Policy Update Magnitude: 0.57912
Value Function Update Magnitude: 0.65679

Collected Steps per Second: 22,780.54327
Overall Steps per Second: 10,759.32546

Timestep Collection Time: 2.19591
Timestep Consumption Time: 2.45345
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.64936

Cumulative Model Updates: 71,076
Cumulative Timesteps: 592,835,540

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 592835540...
Checkpoint 592835540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 892.72043
Policy Entropy: 3.28817
Value Function Loss: 0.00435

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08863
Policy Update Magnitude: 0.57451
Value Function Update Magnitude: 0.67218

Collected Steps per Second: 22,220.64450
Overall Steps per Second: 10,655.43404

Timestep Collection Time: 2.25079
Timestep Consumption Time: 2.44297
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.69376

Cumulative Model Updates: 71,082
Cumulative Timesteps: 592,885,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.26211
Policy Entropy: 3.28020
Value Function Loss: 0.00466

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09849
Policy Update Magnitude: 0.58853
Value Function Update Magnitude: 0.68658

Collected Steps per Second: 22,139.03395
Overall Steps per Second: 10,497.03289

Timestep Collection Time: 2.25854
Timestep Consumption Time: 2.50490
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.76344

Cumulative Model Updates: 71,088
Cumulative Timesteps: 592,935,556

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 592935556...
Checkpoint 592935556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 864.20431
Policy Entropy: 3.29083
Value Function Loss: 0.00435

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10652
Policy Update Magnitude: 0.59388
Value Function Update Magnitude: 0.71306

Collected Steps per Second: 22,518.07391
Overall Steps per Second: 10,704.59083

Timestep Collection Time: 2.22106
Timestep Consumption Time: 2.45114
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.67220

Cumulative Model Updates: 71,094
Cumulative Timesteps: 592,985,570

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.07042
Policy Entropy: 3.30420
Value Function Loss: 0.00400

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09460
Policy Update Magnitude: 0.58452
Value Function Update Magnitude: 0.69372

Collected Steps per Second: 22,997.84719
Overall Steps per Second: 10,800.78928

Timestep Collection Time: 2.17446
Timestep Consumption Time: 2.45557
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.63003

Cumulative Model Updates: 71,100
Cumulative Timesteps: 593,035,578

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 593035578...
Checkpoint 593035578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.10257
Policy Entropy: 3.30898
Value Function Loss: 0.00368

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 0.57169
Value Function Update Magnitude: 0.65414

Collected Steps per Second: 22,872.80408
Overall Steps per Second: 10,729.02974

Timestep Collection Time: 2.18731
Timestep Consumption Time: 2.47574
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.66305

Cumulative Model Updates: 71,106
Cumulative Timesteps: 593,085,608

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.59958
Policy Entropy: 3.31786
Value Function Loss: 0.00366

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10172
Policy Update Magnitude: 0.55886
Value Function Update Magnitude: 0.62497

Collected Steps per Second: 22,248.15884
Overall Steps per Second: 10,487.88539

Timestep Collection Time: 2.24882
Timestep Consumption Time: 2.52164
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.77046

Cumulative Model Updates: 71,112
Cumulative Timesteps: 593,135,640

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 593135640...
Checkpoint 593135640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 893.11313
Policy Entropy: 3.29182
Value Function Loss: 0.00394

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09491
Policy Update Magnitude: 0.55865
Value Function Update Magnitude: 0.63277

Collected Steps per Second: 22,739.02899
Overall Steps per Second: 10,564.78726

Timestep Collection Time: 2.19921
Timestep Consumption Time: 2.53425
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.73346

Cumulative Model Updates: 71,118
Cumulative Timesteps: 593,185,648

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,989.60943
Policy Entropy: 3.30451
Value Function Loss: 0.00386

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09156
Policy Update Magnitude: 0.56437
Value Function Update Magnitude: 0.65022

Collected Steps per Second: 22,879.54083
Overall Steps per Second: 10,593.91018

Timestep Collection Time: 2.18571
Timestep Consumption Time: 2.53474
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.72045

Cumulative Model Updates: 71,124
Cumulative Timesteps: 593,235,656

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 593235656...
Checkpoint 593235656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 733.27879
Policy Entropy: 3.29811
Value Function Loss: 0.00373

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.56556
Value Function Update Magnitude: 0.66086

Collected Steps per Second: 22,342.01172
Overall Steps per Second: 10,549.23892

Timestep Collection Time: 2.23874
Timestep Consumption Time: 2.50264
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.74138

Cumulative Model Updates: 71,130
Cumulative Timesteps: 593,285,674

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.60959
Policy Entropy: 3.30863
Value Function Loss: 0.00367

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10656
Policy Update Magnitude: 0.56032
Value Function Update Magnitude: 0.66846

Collected Steps per Second: 22,531.83575
Overall Steps per Second: 10,560.66921

Timestep Collection Time: 2.21979
Timestep Consumption Time: 2.51627
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.73606

Cumulative Model Updates: 71,136
Cumulative Timesteps: 593,335,690

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 593335690...
Checkpoint 593335690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.50129
Policy Entropy: 3.31950
Value Function Loss: 0.00375

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11772
Policy Update Magnitude: 0.55557
Value Function Update Magnitude: 0.64893

Collected Steps per Second: 22,445.60145
Overall Steps per Second: 10,541.11899

Timestep Collection Time: 2.22886
Timestep Consumption Time: 2.51713
PPO Batch Consumption Time: 0.29550
Total Iteration Time: 4.74599

Cumulative Model Updates: 71,142
Cumulative Timesteps: 593,385,718

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.75511
Policy Entropy: 3.32971
Value Function Loss: 0.00374

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11005
Policy Update Magnitude: 0.54756
Value Function Update Magnitude: 0.65254

Collected Steps per Second: 22,740.80474
Overall Steps per Second: 10,638.15241

Timestep Collection Time: 2.19983
Timestep Consumption Time: 2.50267
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.70251

Cumulative Model Updates: 71,148
Cumulative Timesteps: 593,435,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 593435744...
Checkpoint 593435744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,435.02527
Policy Entropy: 3.32884
Value Function Loss: 0.00373

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.55279
Value Function Update Magnitude: 0.64322

Collected Steps per Second: 22,808.19377
Overall Steps per Second: 10,652.92833

Timestep Collection Time: 2.19316
Timestep Consumption Time: 2.50245
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.69561

Cumulative Model Updates: 71,154
Cumulative Timesteps: 593,485,766

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 891.99536
Policy Entropy: 3.31356
Value Function Loss: 0.00387

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.56294
Value Function Update Magnitude: 0.62853

Collected Steps per Second: 23,091.87263
Overall Steps per Second: 10,636.49253

Timestep Collection Time: 2.16544
Timestep Consumption Time: 2.53574
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.70117

Cumulative Model Updates: 71,160
Cumulative Timesteps: 593,535,770

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 593535770...
Checkpoint 593535770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 740.34210
Policy Entropy: 3.31564
Value Function Loss: 0.00405

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.57236
Value Function Update Magnitude: 0.66760

Collected Steps per Second: 22,927.51377
Overall Steps per Second: 10,704.34926

Timestep Collection Time: 2.18175
Timestep Consumption Time: 2.49131
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.67305

Cumulative Model Updates: 71,166
Cumulative Timesteps: 593,585,792

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.61806
Policy Entropy: 3.32952
Value Function Loss: 0.00415

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07474
Policy Update Magnitude: 0.57793
Value Function Update Magnitude: 0.69211

Collected Steps per Second: 23,105.59573
Overall Steps per Second: 10,822.06513

Timestep Collection Time: 2.16432
Timestep Consumption Time: 2.45661
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.62093

Cumulative Model Updates: 71,172
Cumulative Timesteps: 593,635,800

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 593635800...
Checkpoint 593635800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 856.97343
Policy Entropy: 3.32808
Value Function Loss: 0.00402

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07619
Policy Update Magnitude: 0.57616
Value Function Update Magnitude: 0.68889

Collected Steps per Second: 22,523.58977
Overall Steps per Second: 10,751.06801

Timestep Collection Time: 2.22007
Timestep Consumption Time: 2.43100
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.65107

Cumulative Model Updates: 71,178
Cumulative Timesteps: 593,685,804

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.91085
Policy Entropy: 3.33050
Value Function Loss: 0.00396

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07467
Policy Update Magnitude: 0.57209
Value Function Update Magnitude: 0.67062

Collected Steps per Second: 22,835.72999
Overall Steps per Second: 10,779.30006

Timestep Collection Time: 2.18955
Timestep Consumption Time: 2.44897
PPO Batch Consumption Time: 0.28230
Total Iteration Time: 4.63852

Cumulative Model Updates: 71,184
Cumulative Timesteps: 593,735,804

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 593735804...
Checkpoint 593735804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,590.97832
Policy Entropy: 3.32025
Value Function Loss: 0.00374

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.55716
Value Function Update Magnitude: 0.65802

Collected Steps per Second: 22,265.33787
Overall Steps per Second: 10,650.86595

Timestep Collection Time: 2.24636
Timestep Consumption Time: 2.44959
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.69596

Cumulative Model Updates: 71,190
Cumulative Timesteps: 593,785,820

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764.62156
Policy Entropy: 3.30729
Value Function Loss: 0.00388

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08504
Policy Update Magnitude: 0.55098
Value Function Update Magnitude: 0.64642

Collected Steps per Second: 22,554.88065
Overall Steps per Second: 10,577.26212

Timestep Collection Time: 2.21682
Timestep Consumption Time: 2.51031
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.72712

Cumulative Model Updates: 71,196
Cumulative Timesteps: 593,835,820

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 593835820...
Checkpoint 593835820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.71441
Policy Entropy: 3.30212
Value Function Loss: 0.00385

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08083
Policy Update Magnitude: 0.56015
Value Function Update Magnitude: 0.63731

Collected Steps per Second: 22,129.39240
Overall Steps per Second: 10,593.98044

Timestep Collection Time: 2.26043
Timestep Consumption Time: 2.46131
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.72174

Cumulative Model Updates: 71,202
Cumulative Timesteps: 593,885,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.34824
Policy Entropy: 3.29822
Value Function Loss: 0.00403

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08387
Policy Update Magnitude: 0.56932
Value Function Update Magnitude: 0.63535

Collected Steps per Second: 22,718.84610
Overall Steps per Second: 10,579.58276

Timestep Collection Time: 2.20082
Timestep Consumption Time: 2.52527
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.72608

Cumulative Model Updates: 71,208
Cumulative Timesteps: 593,935,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 593935842...
Checkpoint 593935842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610.63509
Policy Entropy: 3.31157
Value Function Loss: 0.00408

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07888
Policy Update Magnitude: 0.57208
Value Function Update Magnitude: 0.62747

Collected Steps per Second: 22,448.57656
Overall Steps per Second: 10,613.14650

Timestep Collection Time: 2.22749
Timestep Consumption Time: 2.48402
PPO Batch Consumption Time: 0.29550
Total Iteration Time: 4.71152

Cumulative Model Updates: 71,214
Cumulative Timesteps: 593,985,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 797.11727
Policy Entropy: 3.30863
Value Function Loss: 0.00397

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07861
Policy Update Magnitude: 0.57301
Value Function Update Magnitude: 0.63899

Collected Steps per Second: 22,806.50180
Overall Steps per Second: 10,597.09428

Timestep Collection Time: 2.19341
Timestep Consumption Time: 2.52713
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.72054

Cumulative Model Updates: 71,220
Cumulative Timesteps: 594,035,870

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 594035870...
Checkpoint 594035870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,528.99609
Policy Entropy: 3.30912
Value Function Loss: 0.00369

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.06965
Policy Update Magnitude: 0.55968
Value Function Update Magnitude: 0.63922

Collected Steps per Second: 22,658.24185
Overall Steps per Second: 10,802.57603

Timestep Collection Time: 2.20794
Timestep Consumption Time: 2.42318
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.63112

Cumulative Model Updates: 71,226
Cumulative Timesteps: 594,085,898

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.53048
Policy Entropy: 3.29145
Value Function Loss: 0.00354

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07849
Policy Update Magnitude: 0.54111
Value Function Update Magnitude: 0.61657

Collected Steps per Second: 22,768.58094
Overall Steps per Second: 10,703.36984

Timestep Collection Time: 2.19618
Timestep Consumption Time: 2.47562
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.67180

Cumulative Model Updates: 71,232
Cumulative Timesteps: 594,135,902

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 594135902...
Checkpoint 594135902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.05834
Policy Entropy: 3.27711
Value Function Loss: 0.00378

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07928
Policy Update Magnitude: 0.55013
Value Function Update Magnitude: 0.61919

Collected Steps per Second: 22,632.35823
Overall Steps per Second: 10,784.94703

Timestep Collection Time: 2.20967
Timestep Consumption Time: 2.42735
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.63702

Cumulative Model Updates: 71,238
Cumulative Timesteps: 594,185,912

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 780.19485
Policy Entropy: 3.27763
Value Function Loss: 0.00397

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.07960
Policy Update Magnitude: 0.56508
Value Function Update Magnitude: 0.63431

Collected Steps per Second: 22,743.33508
Overall Steps per Second: 10,668.65124

Timestep Collection Time: 2.19853
Timestep Consumption Time: 2.48828
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 4.68682

Cumulative Model Updates: 71,244
Cumulative Timesteps: 594,235,914

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 594235914...
Checkpoint 594235914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 653.25595
Policy Entropy: 3.30012
Value Function Loss: 0.00393

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08693
Policy Update Magnitude: 0.57347
Value Function Update Magnitude: 0.66146

Collected Steps per Second: 22,715.97508
Overall Steps per Second: 10,675.51122

Timestep Collection Time: 2.20118
Timestep Consumption Time: 2.48262
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.68380

Cumulative Model Updates: 71,250
Cumulative Timesteps: 594,285,916

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 800.37930
Policy Entropy: 3.29825
Value Function Loss: 0.00387

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10892
Policy Update Magnitude: 0.56653
Value Function Update Magnitude: 0.66552

Collected Steps per Second: 23,053.54237
Overall Steps per Second: 10,791.69891

Timestep Collection Time: 2.16921
Timestep Consumption Time: 2.46472
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.63393

Cumulative Model Updates: 71,256
Cumulative Timesteps: 594,335,924

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 594335924...
Checkpoint 594335924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.96244
Policy Entropy: 3.30169
Value Function Loss: 0.00365

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10418
Policy Update Magnitude: 0.55797
Value Function Update Magnitude: 0.69015

Collected Steps per Second: 22,054.91586
Overall Steps per Second: 10,591.19042

Timestep Collection Time: 2.26798
Timestep Consumption Time: 2.45482
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.72279

Cumulative Model Updates: 71,262
Cumulative Timesteps: 594,385,944

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700.88265
Policy Entropy: 3.28869
Value Function Loss: 0.00376

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10122
Policy Update Magnitude: 0.55675
Value Function Update Magnitude: 0.69873

Collected Steps per Second: 21,830.27585
Overall Steps per Second: 10,572.17200

Timestep Collection Time: 2.29168
Timestep Consumption Time: 2.44037
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.73205

Cumulative Model Updates: 71,268
Cumulative Timesteps: 594,435,972

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 594435972...
Checkpoint 594435972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.03987
Policy Entropy: 3.30394
Value Function Loss: 0.00371

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10165
Policy Update Magnitude: 0.55432
Value Function Update Magnitude: 0.65573

Collected Steps per Second: 21,513.21976
Overall Steps per Second: 10,572.47632

Timestep Collection Time: 2.32480
Timestep Consumption Time: 2.40578
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.73059

Cumulative Model Updates: 71,274
Cumulative Timesteps: 594,485,986

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.33580
Policy Entropy: 3.31362
Value Function Loss: 0.00373

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10806
Policy Update Magnitude: 0.55252
Value Function Update Magnitude: 0.65410

Collected Steps per Second: 21,956.56417
Overall Steps per Second: 10,610.55169

Timestep Collection Time: 2.27741
Timestep Consumption Time: 2.43526
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.71267

Cumulative Model Updates: 71,280
Cumulative Timesteps: 594,535,990

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 594535990...
Checkpoint 594535990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.69159
Policy Entropy: 3.31815
Value Function Loss: 0.00362

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09696
Policy Update Magnitude: 0.55285
Value Function Update Magnitude: 0.68366

Collected Steps per Second: 21,958.52812
Overall Steps per Second: 10,649.57943

Timestep Collection Time: 2.27820
Timestep Consumption Time: 2.41926
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.69746

Cumulative Model Updates: 71,286
Cumulative Timesteps: 594,586,016

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 761.67254
Policy Entropy: 3.31968
Value Function Loss: 0.00358

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.11005
Policy Update Magnitude: 0.54686
Value Function Update Magnitude: 0.66392

Collected Steps per Second: 22,264.86878
Overall Steps per Second: 10,760.60067

Timestep Collection Time: 2.24632
Timestep Consumption Time: 2.40156
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.64788

Cumulative Model Updates: 71,292
Cumulative Timesteps: 594,636,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 594636030...
Checkpoint 594636030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667.52587
Policy Entropy: 3.31520
Value Function Loss: 0.00376

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12348
Policy Update Magnitude: 0.54703
Value Function Update Magnitude: 0.65667

Collected Steps per Second: 21,989.43457
Overall Steps per Second: 10,555.42412

Timestep Collection Time: 2.27491
Timestep Consumption Time: 2.46426
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.73917

Cumulative Model Updates: 71,298
Cumulative Timesteps: 594,686,054

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757.12656
Policy Entropy: 3.31407
Value Function Loss: 0.00402

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11729
Policy Update Magnitude: 0.55676
Value Function Update Magnitude: 0.64782

Collected Steps per Second: 22,305.36938
Overall Steps per Second: 10,696.22299

Timestep Collection Time: 2.24296
Timestep Consumption Time: 2.43439
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.67735

Cumulative Model Updates: 71,304
Cumulative Timesteps: 594,736,084

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 594736084...
Checkpoint 594736084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 894.48508
Policy Entropy: 3.30780
Value Function Loss: 0.00397

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10175
Policy Update Magnitude: 0.56294
Value Function Update Magnitude: 0.65125

Collected Steps per Second: 22,420.18729
Overall Steps per Second: 10,851.40849

Timestep Collection Time: 2.23147
Timestep Consumption Time: 2.37899
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.61046

Cumulative Model Updates: 71,310
Cumulative Timesteps: 594,786,114

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.07569
Policy Entropy: 3.30956
Value Function Loss: 0.00408

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09854
Policy Update Magnitude: 0.55594
Value Function Update Magnitude: 0.64675

Collected Steps per Second: 22,152.06108
Overall Steps per Second: 10,525.99027

Timestep Collection Time: 2.25722
Timestep Consumption Time: 2.49312
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.75034

Cumulative Model Updates: 71,316
Cumulative Timesteps: 594,836,116

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 594836116...
Checkpoint 594836116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.12835
Policy Entropy: 3.30286
Value Function Loss: 0.00386

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08704
Policy Update Magnitude: 0.55151
Value Function Update Magnitude: 0.64039

Collected Steps per Second: 22,757.03489
Overall Steps per Second: 10,638.97385

Timestep Collection Time: 2.19765
Timestep Consumption Time: 2.50318
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.70083

Cumulative Model Updates: 71,322
Cumulative Timesteps: 594,886,128

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.73959
Policy Entropy: 3.30375
Value Function Loss: 0.00386

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08587
Policy Update Magnitude: 0.55366
Value Function Update Magnitude: 0.64906

Collected Steps per Second: 22,719.90100
Overall Steps per Second: 10,657.01388

Timestep Collection Time: 2.20098
Timestep Consumption Time: 2.49133
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.69231

Cumulative Model Updates: 71,328
Cumulative Timesteps: 594,936,134

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 594936134...
Checkpoint 594936134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.41860
Policy Entropy: 3.31124
Value Function Loss: 0.00357

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11237
Policy Update Magnitude: 0.54483
Value Function Update Magnitude: 0.64345

Collected Steps per Second: 22,535.17117
Overall Steps per Second: 10,665.79224

Timestep Collection Time: 2.21991
Timestep Consumption Time: 2.47041
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.69032

Cumulative Model Updates: 71,334
Cumulative Timesteps: 594,986,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.55089
Policy Entropy: 3.30812
Value Function Loss: 0.00385

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10790
Policy Update Magnitude: 0.54737
Value Function Update Magnitude: 0.63006

Collected Steps per Second: 22,918.15529
Overall Steps per Second: 10,653.19418

Timestep Collection Time: 2.18211
Timestep Consumption Time: 2.51225
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.69437

Cumulative Model Updates: 71,340
Cumulative Timesteps: 595,036,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 595036170...
Checkpoint 595036170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.79608
Policy Entropy: 3.28713
Value Function Loss: 0.00369

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08785
Policy Update Magnitude: 0.55898
Value Function Update Magnitude: 0.62572

Collected Steps per Second: 22,017.51133
Overall Steps per Second: 10,592.76908

Timestep Collection Time: 2.27119
Timestep Consumption Time: 2.44958
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.72077

Cumulative Model Updates: 71,346
Cumulative Timesteps: 595,086,176

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 748.27439
Policy Entropy: 3.27251
Value Function Loss: 0.00382

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07748
Policy Update Magnitude: 0.55995
Value Function Update Magnitude: 0.61038

Collected Steps per Second: 22,902.87823
Overall Steps per Second: 10,652.65564

Timestep Collection Time: 2.18409
Timestep Consumption Time: 2.51164
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.69573

Cumulative Model Updates: 71,352
Cumulative Timesteps: 595,136,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 595136198...
Checkpoint 595136198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 751.12628
Policy Entropy: 3.27585
Value Function Loss: 0.00384

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07714
Policy Update Magnitude: 0.55569
Value Function Update Magnitude: 0.60528

Collected Steps per Second: 22,949.75927
Overall Steps per Second: 10,574.52190

Timestep Collection Time: 2.17981
Timestep Consumption Time: 2.55100
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.73080

Cumulative Model Updates: 71,358
Cumulative Timesteps: 595,186,224

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 973.62797
Policy Entropy: 3.27022
Value Function Loss: 0.00399

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07286
Policy Update Magnitude: 0.55130
Value Function Update Magnitude: 0.61327

Collected Steps per Second: 22,802.75444
Overall Steps per Second: 10,736.72090

Timestep Collection Time: 2.19316
Timestep Consumption Time: 2.46469
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.65785

Cumulative Model Updates: 71,364
Cumulative Timesteps: 595,236,234

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 595236234...
Checkpoint 595236234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 904.33270
Policy Entropy: 3.27102
Value Function Loss: 0.00397

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08355
Policy Update Magnitude: 0.54822
Value Function Update Magnitude: 0.61003

Collected Steps per Second: 22,667.40391
Overall Steps per Second: 10,726.50187

Timestep Collection Time: 2.20660
Timestep Consumption Time: 2.45643
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.66303

Cumulative Model Updates: 71,370
Cumulative Timesteps: 595,286,252

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690.28254
Policy Entropy: 3.27107
Value Function Loss: 0.00394

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08660
Policy Update Magnitude: 0.55232
Value Function Update Magnitude: 0.60369

Collected Steps per Second: 22,857.65479
Overall Steps per Second: 10,772.17296

Timestep Collection Time: 2.18780
Timestep Consumption Time: 2.45453
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.64233

Cumulative Model Updates: 71,376
Cumulative Timesteps: 595,336,260

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 595336260...
Checkpoint 595336260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 841.84374
Policy Entropy: 3.28262
Value Function Loss: 0.00397

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11318
Policy Update Magnitude: 0.55879
Value Function Update Magnitude: 0.62216

Collected Steps per Second: 22,923.00912
Overall Steps per Second: 10,772.72130

Timestep Collection Time: 2.18156
Timestep Consumption Time: 2.46053
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.64210

Cumulative Model Updates: 71,382
Cumulative Timesteps: 595,386,268

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.53349
Policy Entropy: 3.28680
Value Function Loss: 0.00392

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10620
Policy Update Magnitude: 0.55980
Value Function Update Magnitude: 0.65123

Collected Steps per Second: 22,820.80521
Overall Steps per Second: 10,660.86945

Timestep Collection Time: 2.19151
Timestep Consumption Time: 2.49967
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.69117

Cumulative Model Updates: 71,388
Cumulative Timesteps: 595,436,280

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 595436280...
Checkpoint 595436280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615.95885
Policy Entropy: 3.29727
Value Function Loss: 0.00374

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08839
Policy Update Magnitude: 0.56395
Value Function Update Magnitude: 0.65683

Collected Steps per Second: 22,774.03878
Overall Steps per Second: 10,799.40334

Timestep Collection Time: 2.19575
Timestep Consumption Time: 2.43470
PPO Batch Consumption Time: 0.28197
Total Iteration Time: 4.63044

Cumulative Model Updates: 71,394
Cumulative Timesteps: 595,486,286

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.12100
Policy Entropy: 3.29501
Value Function Loss: 0.00364

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10548
Policy Update Magnitude: 0.55522
Value Function Update Magnitude: 0.64635

Collected Steps per Second: 22,654.98085
Overall Steps per Second: 10,564.83394

Timestep Collection Time: 2.20879
Timestep Consumption Time: 2.52768
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.73647

Cumulative Model Updates: 71,400
Cumulative Timesteps: 595,536,326

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 595536326...
Checkpoint 595536326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.67308
Policy Entropy: 3.29773
Value Function Loss: 0.00372

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09228
Policy Update Magnitude: 0.54881
Value Function Update Magnitude: 0.63353

Collected Steps per Second: 22,252.29206
Overall Steps per Second: 10,629.68558

Timestep Collection Time: 2.24714
Timestep Consumption Time: 2.45705
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.70418

Cumulative Model Updates: 71,406
Cumulative Timesteps: 595,586,330

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.49167
Policy Entropy: 3.29872
Value Function Loss: 0.00366

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.54655
Value Function Update Magnitude: 0.61616

Collected Steps per Second: 22,663.12977
Overall Steps per Second: 10,641.97189

Timestep Collection Time: 2.20729
Timestep Consumption Time: 2.49335
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.70063

Cumulative Model Updates: 71,412
Cumulative Timesteps: 595,636,354

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 595636354...
Checkpoint 595636354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,468.10147
Policy Entropy: 3.30716
Value Function Loss: 0.00351

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10030
Policy Update Magnitude: 0.54525
Value Function Update Magnitude: 0.60751

Collected Steps per Second: 22,297.56909
Overall Steps per Second: 10,515.93507

Timestep Collection Time: 2.24258
Timestep Consumption Time: 2.51249
PPO Batch Consumption Time: 0.29647
Total Iteration Time: 4.75507

Cumulative Model Updates: 71,418
Cumulative Timesteps: 595,686,358

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.67629
Policy Entropy: 3.32292
Value Function Loss: 0.00352

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10384
Policy Update Magnitude: 0.53791
Value Function Update Magnitude: 0.59074

Collected Steps per Second: 22,383.84654
Overall Steps per Second: 10,486.69296

Timestep Collection Time: 2.23447
Timestep Consumption Time: 2.53500
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.76947

Cumulative Model Updates: 71,424
Cumulative Timesteps: 595,736,374

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 595736374...
Checkpoint 595736374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.11665
Policy Entropy: 3.31969
Value Function Loss: 0.00377

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08625
Policy Update Magnitude: 0.53920
Value Function Update Magnitude: 0.58699

Collected Steps per Second: 22,429.10067
Overall Steps per Second: 10,553.96385

Timestep Collection Time: 2.22943
Timestep Consumption Time: 2.50851
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.73794

Cumulative Model Updates: 71,430
Cumulative Timesteps: 595,786,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.07096
Policy Entropy: 3.31532
Value Function Loss: 0.00379

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08015
Policy Update Magnitude: 0.55259
Value Function Update Magnitude: 0.58223

Collected Steps per Second: 22,527.32575
Overall Steps per Second: 10,539.50545

Timestep Collection Time: 2.21979
Timestep Consumption Time: 2.52483
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.74462

Cumulative Model Updates: 71,436
Cumulative Timesteps: 595,836,384

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 595836384...
Checkpoint 595836384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935.43137
Policy Entropy: 3.30856
Value Function Loss: 0.00380

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.55374
Value Function Update Magnitude: 0.59158

Collected Steps per Second: 22,692.86211
Overall Steps per Second: 10,601.86022

Timestep Collection Time: 2.20413
Timestep Consumption Time: 2.51372
PPO Batch Consumption Time: 0.29695
Total Iteration Time: 4.71785

Cumulative Model Updates: 71,442
Cumulative Timesteps: 595,886,402

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.26184
Policy Entropy: 3.31346
Value Function Loss: 0.00379

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07415
Policy Update Magnitude: 0.54912
Value Function Update Magnitude: 0.59386

Collected Steps per Second: 22,876.08395
Overall Steps per Second: 10,774.71669

Timestep Collection Time: 2.18639
Timestep Consumption Time: 2.45559
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.64198

Cumulative Model Updates: 71,448
Cumulative Timesteps: 595,936,418

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 595936418...
Checkpoint 595936418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.78349
Policy Entropy: 3.31509
Value Function Loss: 0.00395

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07458
Policy Update Magnitude: 0.55721
Value Function Update Magnitude: 0.60527

Collected Steps per Second: 22,649.45554
Overall Steps per Second: 10,696.87691

Timestep Collection Time: 2.20818
Timestep Consumption Time: 2.46739
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.67557

Cumulative Model Updates: 71,454
Cumulative Timesteps: 595,986,432

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 886.04165
Policy Entropy: 3.31146
Value Function Loss: 0.00395

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.56322
Value Function Update Magnitude: 0.62899

Collected Steps per Second: 22,645.42225
Overall Steps per Second: 10,620.60852

Timestep Collection Time: 2.20813
Timestep Consumption Time: 2.50008
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.70820

Cumulative Model Updates: 71,460
Cumulative Timesteps: 596,036,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 596036436...
Checkpoint 596036436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 929.38656
Policy Entropy: 3.31634
Value Function Loss: 0.00395

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09715
Policy Update Magnitude: 0.55570
Value Function Update Magnitude: 0.64733

Collected Steps per Second: 22,740.36080
Overall Steps per Second: 10,615.21915

Timestep Collection Time: 2.19926
Timestep Consumption Time: 2.51209
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.71135

Cumulative Model Updates: 71,466
Cumulative Timesteps: 596,086,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 785.80808
Policy Entropy: 3.32821
Value Function Loss: 0.00387

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07469
Policy Update Magnitude: 0.55634
Value Function Update Magnitude: 0.63516

Collected Steps per Second: 22,554.04083
Overall Steps per Second: 10,795.83772

Timestep Collection Time: 2.21743
Timestep Consumption Time: 2.41510
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.63253

Cumulative Model Updates: 71,472
Cumulative Timesteps: 596,136,460

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 596136460...
Checkpoint 596136460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,358.52845
Policy Entropy: 3.33297
Value Function Loss: 0.00385

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08164
Policy Update Magnitude: 0.56021
Value Function Update Magnitude: 0.61651

Collected Steps per Second: 22,495.11562
Overall Steps per Second: 10,581.63648

Timestep Collection Time: 2.22342
Timestep Consumption Time: 2.50326
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.72668

Cumulative Model Updates: 71,478
Cumulative Timesteps: 596,186,476

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.30766
Policy Entropy: 3.31043
Value Function Loss: 0.00396

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10413
Policy Update Magnitude: 0.56852
Value Function Update Magnitude: 0.61989

Collected Steps per Second: 22,705.27159
Overall Steps per Second: 10,677.93758

Timestep Collection Time: 2.20257
Timestep Consumption Time: 2.48092
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.68349

Cumulative Model Updates: 71,484
Cumulative Timesteps: 596,236,486

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 596236486...
Checkpoint 596236486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 931.14604
Policy Entropy: 3.29811
Value Function Loss: 0.00398

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09874
Policy Update Magnitude: 0.57377
Value Function Update Magnitude: 0.63402

Collected Steps per Second: 22,433.12512
Overall Steps per Second: 10,612.13262

Timestep Collection Time: 2.22911
Timestep Consumption Time: 2.48304
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.71215

Cumulative Model Updates: 71,490
Cumulative Timesteps: 596,286,492

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 722.77114
Policy Entropy: 3.27798
Value Function Loss: 0.00389

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.57200
Value Function Update Magnitude: 0.61431

Collected Steps per Second: 22,521.51620
Overall Steps per Second: 10,745.65710

Timestep Collection Time: 2.22019
Timestep Consumption Time: 2.43304
PPO Batch Consumption Time: 0.28174
Total Iteration Time: 4.65323

Cumulative Model Updates: 71,496
Cumulative Timesteps: 596,336,494

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 596336494...
Checkpoint 596336494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.90605
Policy Entropy: 3.29840
Value Function Loss: 0.00369

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08829
Policy Update Magnitude: 0.56337
Value Function Update Magnitude: 0.58290

Collected Steps per Second: 22,942.67858
Overall Steps per Second: 10,671.59050

Timestep Collection Time: 2.17995
Timestep Consumption Time: 2.50669
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.68665

Cumulative Model Updates: 71,502
Cumulative Timesteps: 596,386,508

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788.74503
Policy Entropy: 3.30260
Value Function Loss: 0.00391

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07858
Policy Update Magnitude: 0.57083
Value Function Update Magnitude: 0.59437

Collected Steps per Second: 22,297.19303
Overall Steps per Second: 10,587.36196

Timestep Collection Time: 2.24342
Timestep Consumption Time: 2.48127
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.72469

Cumulative Model Updates: 71,508
Cumulative Timesteps: 596,436,530

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 596436530...
Checkpoint 596436530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.39914
Policy Entropy: 3.30694
Value Function Loss: 0.00387

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09519
Policy Update Magnitude: 0.58009
Value Function Update Magnitude: 0.61278

Collected Steps per Second: 22,984.13453
Overall Steps per Second: 10,836.94709

Timestep Collection Time: 2.17567
Timestep Consumption Time: 2.43872
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.61440

Cumulative Model Updates: 71,514
Cumulative Timesteps: 596,486,536

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.91453
Policy Entropy: 3.29639
Value Function Loss: 0.00408

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10736
Policy Update Magnitude: 0.58275
Value Function Update Magnitude: 0.63350

Collected Steps per Second: 22,725.77422
Overall Steps per Second: 10,660.37270

Timestep Collection Time: 2.20067
Timestep Consumption Time: 2.49072
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.69139

Cumulative Model Updates: 71,520
Cumulative Timesteps: 596,536,548

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 596536548...
Checkpoint 596536548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 905.97783
Policy Entropy: 3.30054
Value Function Loss: 0.00420

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08818
Policy Update Magnitude: 0.58352
Value Function Update Magnitude: 0.66930

Collected Steps per Second: 23,129.57547
Overall Steps per Second: 10,890.05967

Timestep Collection Time: 2.16243
Timestep Consumption Time: 2.43039
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.59281

Cumulative Model Updates: 71,526
Cumulative Timesteps: 596,586,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.79726
Policy Entropy: 3.29941
Value Function Loss: 0.00413

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08611
Policy Update Magnitude: 0.58706
Value Function Update Magnitude: 0.66153

Collected Steps per Second: 22,622.56529
Overall Steps per Second: 10,926.08335

Timestep Collection Time: 2.21027
Timestep Consumption Time: 2.36612
PPO Batch Consumption Time: 0.28153
Total Iteration Time: 4.57639

Cumulative Model Updates: 71,532
Cumulative Timesteps: 596,636,566

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 596636566...
Checkpoint 596636566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 879.17000
Policy Entropy: 3.30886
Value Function Loss: 0.00398

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08735
Policy Update Magnitude: 0.58685
Value Function Update Magnitude: 0.65417

Collected Steps per Second: 21,750.09006
Overall Steps per Second: 10,733.79192

Timestep Collection Time: 2.29994
Timestep Consumption Time: 2.36048
PPO Batch Consumption Time: 0.28150
Total Iteration Time: 4.66042

Cumulative Model Updates: 71,538
Cumulative Timesteps: 596,686,590

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,714.86128
Policy Entropy: 3.30971
Value Function Loss: 0.00394

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.58110
Value Function Update Magnitude: 0.64371

Collected Steps per Second: 21,427.80838
Overall Steps per Second: 10,455.15757

Timestep Collection Time: 2.33463
Timestep Consumption Time: 2.45019
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.78482

Cumulative Model Updates: 71,544
Cumulative Timesteps: 596,736,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 596736616...
Checkpoint 596736616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 899.04237
Policy Entropy: 3.31448
Value Function Loss: 0.00383

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08348
Policy Update Magnitude: 0.57776
Value Function Update Magnitude: 0.63058

Collected Steps per Second: 22,044.33547
Overall Steps per Second: 10,590.33952

Timestep Collection Time: 2.26825
Timestep Consumption Time: 2.45323
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.72147

Cumulative Model Updates: 71,550
Cumulative Timesteps: 596,786,618

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635.60035
Policy Entropy: 3.30918
Value Function Loss: 0.00402

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.57574
Value Function Update Magnitude: 0.62223

Collected Steps per Second: 22,522.81459
Overall Steps per Second: 10,648.57167

Timestep Collection Time: 2.22086
Timestep Consumption Time: 2.47648
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.69734

Cumulative Model Updates: 71,556
Cumulative Timesteps: 596,836,638

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 596836638...
Checkpoint 596836638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574.11576
Policy Entropy: 3.32457
Value Function Loss: 0.00382

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07465
Policy Update Magnitude: 0.56741
Value Function Update Magnitude: 0.61729

Collected Steps per Second: 22,428.57942
Overall Steps per Second: 10,639.85409

Timestep Collection Time: 2.22983
Timestep Consumption Time: 2.47061
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.70044

Cumulative Model Updates: 71,562
Cumulative Timesteps: 596,886,650

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674.67275
Policy Entropy: 3.31347
Value Function Loss: 0.00407

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08614
Policy Update Magnitude: 0.57347
Value Function Update Magnitude: 0.62522

Collected Steps per Second: 23,120.88390
Overall Steps per Second: 10,892.50916

Timestep Collection Time: 2.16341
Timestep Consumption Time: 2.42873
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.59215

Cumulative Model Updates: 71,568
Cumulative Timesteps: 596,936,670

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 596936670...
Checkpoint 596936670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 780.98045
Policy Entropy: 3.31854
Value Function Loss: 0.00419

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09200
Policy Update Magnitude: 0.58242
Value Function Update Magnitude: 0.63112

Collected Steps per Second: 22,576.05523
Overall Steps per Second: 10,929.24197

Timestep Collection Time: 2.21474
Timestep Consumption Time: 2.36015
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.57488

Cumulative Model Updates: 71,574
Cumulative Timesteps: 596,986,670

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 860.58948
Policy Entropy: 3.29953
Value Function Loss: 0.00439

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.58220
Value Function Update Magnitude: 0.64442

Collected Steps per Second: 21,878.61517
Overall Steps per Second: 10,594.43780

Timestep Collection Time: 2.28534
Timestep Consumption Time: 2.43412
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.71946

Cumulative Model Updates: 71,580
Cumulative Timesteps: 597,036,670

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 597036670...
Checkpoint 597036670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 699.28871
Policy Entropy: 3.29799
Value Function Loss: 0.00406

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09251
Policy Update Magnitude: 0.57597
Value Function Update Magnitude: 0.66545

Collected Steps per Second: 22,156.95582
Overall Steps per Second: 10,736.02572

Timestep Collection Time: 2.25789
Timestep Consumption Time: 2.40193
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.65982

Cumulative Model Updates: 71,586
Cumulative Timesteps: 597,086,698

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.75687
Policy Entropy: 3.28294
Value Function Loss: 0.00397

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10123
Policy Update Magnitude: 0.57038
Value Function Update Magnitude: 0.64829

Collected Steps per Second: 21,336.55887
Overall Steps per Second: 10,575.00411

Timestep Collection Time: 2.34396
Timestep Consumption Time: 2.38531
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.72927

Cumulative Model Updates: 71,592
Cumulative Timesteps: 597,136,710

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 597136710...
Checkpoint 597136710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659.70982
Policy Entropy: 3.29800
Value Function Loss: 0.00408

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10430
Policy Update Magnitude: 0.57132
Value Function Update Magnitude: 0.62404

Collected Steps per Second: 22,516.60806
Overall Steps per Second: 10,716.48532

Timestep Collection Time: 2.22085
Timestep Consumption Time: 2.44542
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.66627

Cumulative Model Updates: 71,598
Cumulative Timesteps: 597,186,716

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.01118
Policy Entropy: 3.29540
Value Function Loss: 0.00412

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11078
Policy Update Magnitude: 0.57580
Value Function Update Magnitude: 0.64166

Collected Steps per Second: 21,721.41874
Overall Steps per Second: 10,564.43112

Timestep Collection Time: 2.30307
Timestep Consumption Time: 2.43225
PPO Batch Consumption Time: 0.29531
Total Iteration Time: 4.73532

Cumulative Model Updates: 71,604
Cumulative Timesteps: 597,236,742

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 597236742...
Checkpoint 597236742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.25704
Policy Entropy: 3.30621
Value Function Loss: 0.00417

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10341
Policy Update Magnitude: 0.56905
Value Function Update Magnitude: 0.66141

Collected Steps per Second: 21,481.89503
Overall Steps per Second: 10,528.87919

Timestep Collection Time: 2.32763
Timestep Consumption Time: 2.42140
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.74903

Cumulative Model Updates: 71,610
Cumulative Timesteps: 597,286,744

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 930.73245
Policy Entropy: 3.30174
Value Function Loss: 0.00405

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.56174
Value Function Update Magnitude: 0.66264

Collected Steps per Second: 22,233.45456
Overall Steps per Second: 10,626.74705

Timestep Collection Time: 2.24886
Timestep Consumption Time: 2.45625
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.70511

Cumulative Model Updates: 71,616
Cumulative Timesteps: 597,336,744

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 597336744...
Checkpoint 597336744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.23328
Policy Entropy: 3.30022
Value Function Loss: 0.00396

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09832
Policy Update Magnitude: 0.55773
Value Function Update Magnitude: 0.67949

Collected Steps per Second: 22,787.38830
Overall Steps per Second: 10,647.78248

Timestep Collection Time: 2.19437
Timestep Consumption Time: 2.50182
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.69619

Cumulative Model Updates: 71,622
Cumulative Timesteps: 597,386,748

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 906.29545
Policy Entropy: 3.27347
Value Function Loss: 0.00405

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08886
Policy Update Magnitude: 0.56066
Value Function Update Magnitude: 0.68899

Collected Steps per Second: 23,125.15073
Overall Steps per Second: 10,733.68459

Timestep Collection Time: 2.16319
Timestep Consumption Time: 2.49728
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.66047

Cumulative Model Updates: 71,628
Cumulative Timesteps: 597,436,772

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 597436772...
Checkpoint 597436772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 820.64242
Policy Entropy: 3.28060
Value Function Loss: 0.00414

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11384
Policy Update Magnitude: 0.55846
Value Function Update Magnitude: 0.69457

Collected Steps per Second: 21,892.19586
Overall Steps per Second: 10,645.97204

Timestep Collection Time: 2.28520
Timestep Consumption Time: 2.41404
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.69924

Cumulative Model Updates: 71,634
Cumulative Timesteps: 597,486,800

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.99509
Policy Entropy: 3.29651
Value Function Loss: 0.00413

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11047
Policy Update Magnitude: 0.56533
Value Function Update Magnitude: 0.69321

Collected Steps per Second: 22,328.84434
Overall Steps per Second: 10,796.00408

Timestep Collection Time: 2.23944
Timestep Consumption Time: 2.39228
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.63171

Cumulative Model Updates: 71,640
Cumulative Timesteps: 597,536,804

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 597536804...
Checkpoint 597536804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357.66272
Policy Entropy: 3.32671
Value Function Loss: 0.00385

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.13015
Policy Update Magnitude: 0.56219
Value Function Update Magnitude: 0.67168

Collected Steps per Second: 22,188.68091
Overall Steps per Second: 10,736.65738

Timestep Collection Time: 2.25367
Timestep Consumption Time: 2.40383
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.65750

Cumulative Model Updates: 71,646
Cumulative Timesteps: 597,586,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 902.90276
Policy Entropy: 3.32148
Value Function Loss: 0.00360

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12832
Policy Update Magnitude: 0.54634
Value Function Update Magnitude: 0.64660

Collected Steps per Second: 21,657.26919
Overall Steps per Second: 10,519.00253

Timestep Collection Time: 2.30897
Timestep Consumption Time: 2.44490
PPO Batch Consumption Time: 0.29734
Total Iteration Time: 4.75387

Cumulative Model Updates: 71,652
Cumulative Timesteps: 597,636,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 597636816...
Checkpoint 597636816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.54904
Policy Entropy: 3.31596
Value Function Loss: 0.00356

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10843
Policy Update Magnitude: 0.53918
Value Function Update Magnitude: 0.61808

Collected Steps per Second: 22,011.73416
Overall Steps per Second: 10,596.58480

Timestep Collection Time: 2.27270
Timestep Consumption Time: 2.44826
PPO Batch Consumption Time: 0.29680
Total Iteration Time: 4.72096

Cumulative Model Updates: 71,658
Cumulative Timesteps: 597,686,842

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,468.44001
Policy Entropy: 3.31145
Value Function Loss: 0.00367

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10273
Policy Update Magnitude: 0.53538
Value Function Update Magnitude: 0.61298

Collected Steps per Second: 21,965.13158
Overall Steps per Second: 10,636.40278

Timestep Collection Time: 2.27634
Timestep Consumption Time: 2.42450
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.70084

Cumulative Model Updates: 71,664
Cumulative Timesteps: 597,736,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 597736842...
Checkpoint 597736842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600.09708
Policy Entropy: 3.30776
Value Function Loss: 0.00399

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08503
Policy Update Magnitude: 0.54177
Value Function Update Magnitude: 0.64864

Collected Steps per Second: 23,113.61873
Overall Steps per Second: 10,766.63286

Timestep Collection Time: 2.16435
Timestep Consumption Time: 2.48204
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.64639

Cumulative Model Updates: 71,670
Cumulative Timesteps: 597,786,868

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738.86954
Policy Entropy: 3.30279
Value Function Loss: 0.00402

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.54889
Value Function Update Magnitude: 0.67141

Collected Steps per Second: 22,471.67689
Overall Steps per Second: 10,580.60885

Timestep Collection Time: 2.22582
Timestep Consumption Time: 2.50150
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.72733

Cumulative Model Updates: 71,676
Cumulative Timesteps: 597,836,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 597836886...
Checkpoint 597836886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673.86552
Policy Entropy: 3.29645
Value Function Loss: 0.00407

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09446
Policy Update Magnitude: 0.56268
Value Function Update Magnitude: 0.66162

Collected Steps per Second: 22,707.66169
Overall Steps per Second: 10,614.19625

Timestep Collection Time: 2.20296
Timestep Consumption Time: 2.50998
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.71293

Cumulative Model Updates: 71,682
Cumulative Timesteps: 597,886,910

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.67237
Policy Entropy: 3.29417
Value Function Loss: 0.00403

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09397
Policy Update Magnitude: 0.55858
Value Function Update Magnitude: 0.63536

Collected Steps per Second: 23,073.25817
Overall Steps per Second: 10,827.44756

Timestep Collection Time: 2.16796
Timestep Consumption Time: 2.45196
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.61993

Cumulative Model Updates: 71,688
Cumulative Timesteps: 597,936,932

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 597936932...
Checkpoint 597936932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 784.55308
Policy Entropy: 3.28620
Value Function Loss: 0.00393

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08522
Policy Update Magnitude: 0.55308
Value Function Update Magnitude: 0.61078

Collected Steps per Second: 22,740.25999
Overall Steps per Second: 10,709.34908

Timestep Collection Time: 2.19918
Timestep Consumption Time: 2.47057
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.66975

Cumulative Model Updates: 71,694
Cumulative Timesteps: 597,986,942

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 753.35045
Policy Entropy: 3.28792
Value Function Loss: 0.00406

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11498
Policy Update Magnitude: 0.54852
Value Function Update Magnitude: 0.59890

Collected Steps per Second: 22,668.30282
Overall Steps per Second: 10,605.56230

Timestep Collection Time: 2.20713
Timestep Consumption Time: 2.51039
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.71752

Cumulative Model Updates: 71,700
Cumulative Timesteps: 598,036,974

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 598036974...
Checkpoint 598036974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.40423
Policy Entropy: 3.28463
Value Function Loss: 0.00408

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.12296
Policy Update Magnitude: 0.54718
Value Function Update Magnitude: 0.61836

Collected Steps per Second: 22,859.36713
Overall Steps per Second: 10,698.42864

Timestep Collection Time: 2.18781
Timestep Consumption Time: 2.48689
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.67471

Cumulative Model Updates: 71,706
Cumulative Timesteps: 598,086,986

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 807.21447
Policy Entropy: 3.28746
Value Function Loss: 0.00402

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11864
Policy Update Magnitude: 0.54220
Value Function Update Magnitude: 0.61391

Collected Steps per Second: 22,592.03878
Overall Steps per Second: 10,694.62237

Timestep Collection Time: 2.21414
Timestep Consumption Time: 2.46316
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.67730

Cumulative Model Updates: 71,712
Cumulative Timesteps: 598,137,008

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 598137008...
Checkpoint 598137008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.96805
Policy Entropy: 3.28890
Value Function Loss: 0.00399

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11704
Policy Update Magnitude: 0.54382
Value Function Update Magnitude: 0.59351

Collected Steps per Second: 22,445.72528
Overall Steps per Second: 10,629.33183

Timestep Collection Time: 2.22875
Timestep Consumption Time: 2.47766
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.70641

Cumulative Model Updates: 71,718
Cumulative Timesteps: 598,187,034

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 934.35354
Policy Entropy: 3.30651
Value Function Loss: 0.00403

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09074
Policy Update Magnitude: 0.54833
Value Function Update Magnitude: 0.59841

Collected Steps per Second: 22,440.44104
Overall Steps per Second: 10,529.49940

Timestep Collection Time: 2.22848
Timestep Consumption Time: 2.52085
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.74932

Cumulative Model Updates: 71,724
Cumulative Timesteps: 598,237,042

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 598237042...
Checkpoint 598237042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360.49702
Policy Entropy: 3.28548
Value Function Loss: 0.00390

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09110
Policy Update Magnitude: 0.54637
Value Function Update Magnitude: 0.60407

Collected Steps per Second: 22,520.15277
Overall Steps per Second: 10,604.84687

Timestep Collection Time: 2.22112
Timestep Consumption Time: 2.49559
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.71671

Cumulative Model Updates: 71,730
Cumulative Timesteps: 598,287,062

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.80621
Policy Entropy: 3.27484
Value Function Loss: 0.00392

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09905
Policy Update Magnitude: 0.54210
Value Function Update Magnitude: 0.61994

Collected Steps per Second: 22,805.77949
Overall Steps per Second: 10,581.48659

Timestep Collection Time: 2.19260
Timestep Consumption Time: 2.53301
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.72561

Cumulative Model Updates: 71,736
Cumulative Timesteps: 598,337,066

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 598337066...
Checkpoint 598337066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.21719
Policy Entropy: 3.27124
Value Function Loss: 0.00385

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09189
Policy Update Magnitude: 0.54424
Value Function Update Magnitude: 0.62761

Collected Steps per Second: 23,196.35495
Overall Steps per Second: 10,823.44165

Timestep Collection Time: 2.15646
Timestep Consumption Time: 2.46518
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.62164

Cumulative Model Updates: 71,742
Cumulative Timesteps: 598,387,088

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 837.35189
Policy Entropy: 3.28989
Value Function Loss: 0.00378

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08545
Policy Update Magnitude: 0.54656
Value Function Update Magnitude: 0.64245

Collected Steps per Second: 22,505.20776
Overall Steps per Second: 10,631.65434

Timestep Collection Time: 2.22197
Timestep Consumption Time: 2.48153
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.70350

Cumulative Model Updates: 71,748
Cumulative Timesteps: 598,437,094

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 598437094...
Checkpoint 598437094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.86379
Policy Entropy: 3.30291
Value Function Loss: 0.00372

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08034
Policy Update Magnitude: 0.54385
Value Function Update Magnitude: 0.62506

Collected Steps per Second: 22,666.77171
Overall Steps per Second: 10,564.61736

Timestep Collection Time: 2.20605
Timestep Consumption Time: 2.52711
PPO Batch Consumption Time: 0.29770
Total Iteration Time: 4.73316

Cumulative Model Updates: 71,754
Cumulative Timesteps: 598,487,098

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 876.60584
Policy Entropy: 3.30123
Value Function Loss: 0.00369

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.53653
Value Function Update Magnitude: 0.62314

Collected Steps per Second: 22,773.42162
Overall Steps per Second: 10,639.62583

Timestep Collection Time: 2.19660
Timestep Consumption Time: 2.50507
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.70167

Cumulative Model Updates: 71,760
Cumulative Timesteps: 598,537,122

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 598537122...
Checkpoint 598537122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 865.78438
Policy Entropy: 3.28928
Value Function Loss: 0.00376

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10273
Policy Update Magnitude: 0.53056
Value Function Update Magnitude: 0.62538

Collected Steps per Second: 23,039.13751
Overall Steps per Second: 10,824.67834

Timestep Collection Time: 2.17091
Timestep Consumption Time: 2.44964
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.62055

Cumulative Model Updates: 71,766
Cumulative Timesteps: 598,587,138

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.56234
Policy Entropy: 3.28199
Value Function Loss: 0.00377

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09773
Policy Update Magnitude: 0.53237
Value Function Update Magnitude: 0.62521

Collected Steps per Second: 22,260.01065
Overall Steps per Second: 10,582.35294

Timestep Collection Time: 2.24672
Timestep Consumption Time: 2.47926
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.72598

Cumulative Model Updates: 71,772
Cumulative Timesteps: 598,637,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 598637150...
Checkpoint 598637150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.37110
Policy Entropy: 3.29532
Value Function Loss: 0.00380

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10662
Policy Update Magnitude: 0.52902
Value Function Update Magnitude: 0.62623

Collected Steps per Second: 21,820.75210
Overall Steps per Second: 10,564.52167

Timestep Collection Time: 2.29250
Timestep Consumption Time: 2.44260
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.73509

Cumulative Model Updates: 71,778
Cumulative Timesteps: 598,687,174

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 890.58000
Policy Entropy: 3.30129
Value Function Loss: 0.00375

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.52649
Value Function Update Magnitude: 0.62970

Collected Steps per Second: 22,470.91028
Overall Steps per Second: 10,501.21611

Timestep Collection Time: 2.22510
Timestep Consumption Time: 2.53625
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 4.76135

Cumulative Model Updates: 71,784
Cumulative Timesteps: 598,737,174

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 598737174...
Checkpoint 598737174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.20929
Policy Entropy: 3.31096
Value Function Loss: 0.00354

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08998
Policy Update Magnitude: 0.52095
Value Function Update Magnitude: 0.63641

Collected Steps per Second: 22,342.30195
Overall Steps per Second: 10,690.27262

Timestep Collection Time: 2.23916
Timestep Consumption Time: 2.44061
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.67977

Cumulative Model Updates: 71,790
Cumulative Timesteps: 598,787,202

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.73849
Policy Entropy: 3.30110
Value Function Loss: 0.00357

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07982
Policy Update Magnitude: 0.51639
Value Function Update Magnitude: 0.62561

Collected Steps per Second: 22,552.56342
Overall Steps per Second: 10,483.60008

Timestep Collection Time: 2.21740
Timestep Consumption Time: 2.55272
PPO Batch Consumption Time: 0.29653
Total Iteration Time: 4.77012

Cumulative Model Updates: 71,796
Cumulative Timesteps: 598,837,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 598837210...
Checkpoint 598837210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,514.44950
Policy Entropy: 3.31278
Value Function Loss: 0.00328

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.50473
Value Function Update Magnitude: 0.60420

Collected Steps per Second: 21,639.35252
Overall Steps per Second: 10,474.77960

Timestep Collection Time: 2.31107
Timestep Consumption Time: 2.46326
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.77432

Cumulative Model Updates: 71,802
Cumulative Timesteps: 598,887,220

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 739.87660
Policy Entropy: 3.30606
Value Function Loss: 0.00331

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07802
Policy Update Magnitude: 0.50092
Value Function Update Magnitude: 0.59042

Collected Steps per Second: 21,641.94399
Overall Steps per Second: 10,504.79931

Timestep Collection Time: 2.31033
Timestep Consumption Time: 2.44940
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.75973

Cumulative Model Updates: 71,808
Cumulative Timesteps: 598,937,220

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 598937220...
Checkpoint 598937220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570.73950
Policy Entropy: 3.30186
Value Function Loss: 0.00356

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08319
Policy Update Magnitude: 0.50648
Value Function Update Magnitude: 0.58279

Collected Steps per Second: 22,347.84551
Overall Steps per Second: 10,699.02080

Timestep Collection Time: 2.23798
Timestep Consumption Time: 2.43665
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.67463

Cumulative Model Updates: 71,814
Cumulative Timesteps: 598,987,234

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 965.06900
Policy Entropy: 3.29318
Value Function Loss: 0.00384

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08999
Policy Update Magnitude: 0.51960
Value Function Update Magnitude: 0.60723

Collected Steps per Second: 22,115.02991
Overall Steps per Second: 10,530.76185

Timestep Collection Time: 2.26109
Timestep Consumption Time: 2.48729
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.74837

Cumulative Model Updates: 71,820
Cumulative Timesteps: 599,037,238

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 599037238...
Checkpoint 599037238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,339.29765
Policy Entropy: 3.30587
Value Function Loss: 0.00395

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09573
Policy Update Magnitude: 0.53480
Value Function Update Magnitude: 0.61699

Collected Steps per Second: 22,038.36355
Overall Steps per Second: 10,545.42640

Timestep Collection Time: 2.26932
Timestep Consumption Time: 2.47321
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.74253

Cumulative Model Updates: 71,826
Cumulative Timesteps: 599,087,250

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.93052
Policy Entropy: 3.29194
Value Function Loss: 0.00404

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08215
Policy Update Magnitude: 0.55350
Value Function Update Magnitude: 0.62803

Collected Steps per Second: 22,693.69208
Overall Steps per Second: 10,804.37645

Timestep Collection Time: 2.20467
Timestep Consumption Time: 2.42605
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.63072

Cumulative Model Updates: 71,832
Cumulative Timesteps: 599,137,282

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 599137282...
Checkpoint 599137282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.72232
Policy Entropy: 3.28490
Value Function Loss: 0.00405

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08362
Policy Update Magnitude: 0.56450
Value Function Update Magnitude: 0.64562

Collected Steps per Second: 22,219.42062
Overall Steps per Second: 10,649.44065

Timestep Collection Time: 2.25109
Timestep Consumption Time: 2.44568
PPO Batch Consumption Time: 0.28228
Total Iteration Time: 4.69677

Cumulative Model Updates: 71,838
Cumulative Timesteps: 599,187,300

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692.70369
Policy Entropy: 3.27223
Value Function Loss: 0.00403

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09055
Policy Update Magnitude: 0.56397
Value Function Update Magnitude: 0.65046

Collected Steps per Second: 22,764.29114
Overall Steps per Second: 10,623.99961

Timestep Collection Time: 2.19713
Timestep Consumption Time: 2.51071
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 4.70783

Cumulative Model Updates: 71,844
Cumulative Timesteps: 599,237,316

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 599237316...
Checkpoint 599237316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.71843
Policy Entropy: 3.28411
Value Function Loss: 0.00403

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07862
Policy Update Magnitude: 0.55782
Value Function Update Magnitude: 0.62642

Collected Steps per Second: 22,479.90801
Overall Steps per Second: 10,594.48599

Timestep Collection Time: 2.22474
Timestep Consumption Time: 2.49583
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 4.72057

Cumulative Model Updates: 71,850
Cumulative Timesteps: 599,287,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,263.04261
Policy Entropy: 3.27168
Value Function Loss: 0.00410

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08440
Policy Update Magnitude: 0.55625
Value Function Update Magnitude: 0.60939

Collected Steps per Second: 22,946.14606
Overall Steps per Second: 10,817.68183

Timestep Collection Time: 2.17980
Timestep Consumption Time: 2.44393
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.62373

Cumulative Model Updates: 71,856
Cumulative Timesteps: 599,337,346

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 599337346...
Checkpoint 599337346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 781.33451
Policy Entropy: 3.27339
Value Function Loss: 0.00407

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08924
Policy Update Magnitude: 0.55659
Value Function Update Magnitude: 0.61707

Collected Steps per Second: 22,730.54513
Overall Steps per Second: 10,676.69885

Timestep Collection Time: 2.20092
Timestep Consumption Time: 2.48480
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.68572

Cumulative Model Updates: 71,862
Cumulative Timesteps: 599,387,374

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.97897
Policy Entropy: 3.26924
Value Function Loss: 0.00394

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.54766
Value Function Update Magnitude: 0.61924

Collected Steps per Second: 22,694.29135
Overall Steps per Second: 10,670.76234

Timestep Collection Time: 2.20434
Timestep Consumption Time: 2.48379
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.68814

Cumulative Model Updates: 71,868
Cumulative Timesteps: 599,437,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 599437400...
Checkpoint 599437400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.97310
Policy Entropy: 3.27085
Value Function Loss: 0.00398

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.54602
Value Function Update Magnitude: 0.62526

Collected Steps per Second: 22,721.26034
Overall Steps per Second: 10,809.36726

Timestep Collection Time: 2.20076
Timestep Consumption Time: 2.42523
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.62599

Cumulative Model Updates: 71,874
Cumulative Timesteps: 599,487,404

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657.26014
Policy Entropy: 3.25762
Value Function Loss: 0.00390

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08906
Policy Update Magnitude: 0.55133
Value Function Update Magnitude: 0.62895

Collected Steps per Second: 22,189.09876
Overall Steps per Second: 10,570.25378

Timestep Collection Time: 2.25426
Timestep Consumption Time: 2.47789
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.73215

Cumulative Model Updates: 71,880
Cumulative Timesteps: 599,537,424

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 599537424...
Checkpoint 599537424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,623.27511
Policy Entropy: 3.24872
Value Function Loss: 0.00390

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08704
Policy Update Magnitude: 0.55134
Value Function Update Magnitude: 0.63304

Collected Steps per Second: 22,339.24840
Overall Steps per Second: 10,620.50179

Timestep Collection Time: 2.23830
Timestep Consumption Time: 2.46976
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.70806

Cumulative Model Updates: 71,886
Cumulative Timesteps: 599,587,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.06358
Policy Entropy: 3.25609
Value Function Loss: 0.00395

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08662
Policy Update Magnitude: 0.55072
Value Function Update Magnitude: 0.65109

Collected Steps per Second: 22,409.18945
Overall Steps per Second: 10,653.12943

Timestep Collection Time: 2.23230
Timestep Consumption Time: 2.46341
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.69571

Cumulative Model Updates: 71,892
Cumulative Timesteps: 599,637,450

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 599637450...
Checkpoint 599637450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714.84343
Policy Entropy: 3.26348
Value Function Loss: 0.00395

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.54953
Value Function Update Magnitude: 0.64272

Collected Steps per Second: 22,611.74518
Overall Steps per Second: 10,792.11272

Timestep Collection Time: 2.21195
Timestep Consumption Time: 2.42255
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.63450

Cumulative Model Updates: 71,898
Cumulative Timesteps: 599,687,466

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627.26374
Policy Entropy: 3.27336
Value Function Loss: 0.00408

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08690
Policy Update Magnitude: 0.55229
Value Function Update Magnitude: 0.66757

Collected Steps per Second: 22,754.10694
Overall Steps per Second: 10,683.48222

Timestep Collection Time: 2.19767
Timestep Consumption Time: 2.48301
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.68068

Cumulative Model Updates: 71,904
Cumulative Timesteps: 599,737,472

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 599737472...
Checkpoint 599737472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,147.83560
Policy Entropy: 3.27401
Value Function Loss: 0.00399

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09258
Policy Update Magnitude: 0.56457
Value Function Update Magnitude: 0.68108

Collected Steps per Second: 22,708.61560
Overall Steps per Second: 10,590.70844

Timestep Collection Time: 2.20242
Timestep Consumption Time: 2.52002
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.72244

Cumulative Model Updates: 71,910
Cumulative Timesteps: 599,787,486

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 987.79271
Policy Entropy: 3.27715
Value Function Loss: 0.00398

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.55616
Value Function Update Magnitude: 0.66469

Collected Steps per Second: 23,019.04467
Overall Steps per Second: 10,842.98144

Timestep Collection Time: 2.17307
Timestep Consumption Time: 2.44024
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.61331

Cumulative Model Updates: 71,916
Cumulative Timesteps: 599,837,508

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 599837508...
Checkpoint 599837508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.24100
Policy Entropy: 3.26902
Value Function Loss: 0.00392

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.54665
Value Function Update Magnitude: 0.63497

Collected Steps per Second: 22,436.47447
Overall Steps per Second: 10,657.74641

Timestep Collection Time: 2.22958
Timestep Consumption Time: 2.46409
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.69368

Cumulative Model Updates: 71,922
Cumulative Timesteps: 599,887,532

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685.77383
Policy Entropy: 3.26813
Value Function Loss: 0.00401

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09001
Policy Update Magnitude: 0.54385
Value Function Update Magnitude: 0.64929

Collected Steps per Second: 22,871.74194
Overall Steps per Second: 10,789.49920

Timestep Collection Time: 2.18707
Timestep Consumption Time: 2.44911
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.63617

Cumulative Model Updates: 71,928
Cumulative Timesteps: 599,937,554

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 599937554...
Checkpoint 599937554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 780.56488
Policy Entropy: 3.26107
Value Function Loss: 0.00385

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09673
Policy Update Magnitude: 0.55055
Value Function Update Magnitude: 0.67245

Collected Steps per Second: 22,527.02452
Overall Steps per Second: 10,655.36005

Timestep Collection Time: 2.21973
Timestep Consumption Time: 2.47312
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.69285

Cumulative Model Updates: 71,934
Cumulative Timesteps: 599,987,558

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.43216
Policy Entropy: 3.25811
Value Function Loss: 0.00389

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08843
Policy Update Magnitude: 0.55266
Value Function Update Magnitude: 0.66115

Collected Steps per Second: 22,532.60355
Overall Steps per Second: 10,597.82012

Timestep Collection Time: 2.21963
Timestep Consumption Time: 2.49964
PPO Batch Consumption Time: 0.29627
Total Iteration Time: 4.71927

Cumulative Model Updates: 71,940
Cumulative Timesteps: 600,037,572

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 600037572...
Checkpoint 600037572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522.01819
Policy Entropy: 3.26129
Value Function Loss: 0.00393

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08828
Policy Update Magnitude: 0.55690
Value Function Update Magnitude: 0.66690

Collected Steps per Second: 22,970.05367
Overall Steps per Second: 10,746.00855

Timestep Collection Time: 2.17675
Timestep Consumption Time: 2.47614
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.65289

Cumulative Model Updates: 71,946
Cumulative Timesteps: 600,087,572

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.84104
Policy Entropy: 3.25075
Value Function Loss: 0.00403

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08286
Policy Update Magnitude: 0.56358
Value Function Update Magnitude: 0.67106

Collected Steps per Second: 22,161.62091
Overall Steps per Second: 10,681.98559

Timestep Collection Time: 2.25642
Timestep Consumption Time: 2.42492
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.68134

Cumulative Model Updates: 71,952
Cumulative Timesteps: 600,137,578

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 600137578...
Checkpoint 600137578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.50167
Policy Entropy: 3.26170
Value Function Loss: 0.00401

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.56219
Value Function Update Magnitude: 0.67185

Collected Steps per Second: 22,124.34991
Overall Steps per Second: 10,654.46585

Timestep Collection Time: 2.26041
Timestep Consumption Time: 2.43340
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.69381

Cumulative Model Updates: 71,958
Cumulative Timesteps: 600,187,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.49510
Policy Entropy: 3.24891
Value Function Loss: 0.00403

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09580
Policy Update Magnitude: 0.55974
Value Function Update Magnitude: 0.67329

Collected Steps per Second: 22,376.56517
Overall Steps per Second: 10,565.19282

Timestep Collection Time: 2.23520
Timestep Consumption Time: 2.49884
PPO Batch Consumption Time: 0.29610
Total Iteration Time: 4.73404

Cumulative Model Updates: 71,964
Cumulative Timesteps: 600,237,604

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 600237604...
Checkpoint 600237604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450.13892
Policy Entropy: 3.24901
Value Function Loss: 0.00384

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.11136
Policy Update Magnitude: 0.55361
Value Function Update Magnitude: 0.64888

Collected Steps per Second: 22,385.92472
Overall Steps per Second: 10,571.65989

Timestep Collection Time: 2.23498
Timestep Consumption Time: 2.49768
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.73265

Cumulative Model Updates: 71,970
Cumulative Timesteps: 600,287,636

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 715.78600
Policy Entropy: 3.24377
Value Function Loss: 0.00412

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10176
Policy Update Magnitude: 0.54527
Value Function Update Magnitude: 0.64162

Collected Steps per Second: 23,187.39405
Overall Steps per Second: 10,891.94268

Timestep Collection Time: 2.15669
Timestep Consumption Time: 2.43459
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.59128

Cumulative Model Updates: 71,976
Cumulative Timesteps: 600,337,644

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 600337644...
Checkpoint 600337644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 908.62664
Policy Entropy: 3.24698
Value Function Loss: 0.00439

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09995
Policy Update Magnitude: 0.55625
Value Function Update Magnitude: 0.64604

Collected Steps per Second: 21,847.20279
Overall Steps per Second: 10,590.66400

Timestep Collection Time: 2.28963
Timestep Consumption Time: 2.43359
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.72322

Cumulative Model Updates: 71,982
Cumulative Timesteps: 600,387,666

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,769.42903
Policy Entropy: 3.24147
Value Function Loss: 0.00457

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10711
Policy Update Magnitude: 0.57532
Value Function Update Magnitude: 0.68580

Collected Steps per Second: 22,371.01840
Overall Steps per Second: 10,754.95389

Timestep Collection Time: 2.23548
Timestep Consumption Time: 2.41447
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.64995

Cumulative Model Updates: 71,988
Cumulative Timesteps: 600,437,676

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 600437676...
Checkpoint 600437676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.34913
Policy Entropy: 3.24116
Value Function Loss: 0.00429

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.11016
Policy Update Magnitude: 0.58364
Value Function Update Magnitude: 0.68376

Collected Steps per Second: 22,057.33522
Overall Steps per Second: 10,796.34346

Timestep Collection Time: 2.26718
Timestep Consumption Time: 2.36476
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.63194

Cumulative Model Updates: 71,994
Cumulative Timesteps: 600,487,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.33317
Policy Entropy: 3.23668
Value Function Loss: 0.00420

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11728
Policy Update Magnitude: 0.57480
Value Function Update Magnitude: 0.68119

Collected Steps per Second: 22,020.55357
Overall Steps per Second: 10,602.02673

Timestep Collection Time: 2.27079
Timestep Consumption Time: 2.44567
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.71646

Cumulative Model Updates: 72,000
Cumulative Timesteps: 600,537,688

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 600537688...
Checkpoint 600537688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.26100
Policy Entropy: 3.25131
Value Function Loss: 0.00393

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10473
Policy Update Magnitude: 0.56502
Value Function Update Magnitude: 0.66406

Collected Steps per Second: 21,818.46164
Overall Steps per Second: 10,560.89376

Timestep Collection Time: 2.29237
Timestep Consumption Time: 2.44359
PPO Batch Consumption Time: 0.29718
Total Iteration Time: 4.73596

Cumulative Model Updates: 72,006
Cumulative Timesteps: 600,587,704

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.80486
Policy Entropy: 3.24294
Value Function Loss: 0.00391

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09018
Policy Update Magnitude: 0.56079
Value Function Update Magnitude: 0.65359

Collected Steps per Second: 22,233.67267
Overall Steps per Second: 10,813.86732

Timestep Collection Time: 2.24911
Timestep Consumption Time: 2.37514
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.62425

Cumulative Model Updates: 72,012
Cumulative Timesteps: 600,637,710

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 600637710...
Checkpoint 600637710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 783.44967
Policy Entropy: 3.24866
Value Function Loss: 0.00399

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09301
Policy Update Magnitude: 0.56189
Value Function Update Magnitude: 0.64512

Collected Steps per Second: 22,606.29408
Overall Steps per Second: 10,777.18376

Timestep Collection Time: 2.21239
Timestep Consumption Time: 2.42834
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.64073

Cumulative Model Updates: 72,018
Cumulative Timesteps: 600,687,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.29791
Policy Entropy: 3.25653
Value Function Loss: 0.00416

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.07950
Policy Update Magnitude: 0.56938
Value Function Update Magnitude: 0.64288

Collected Steps per Second: 22,930.95210
Overall Steps per Second: 10,816.68993

Timestep Collection Time: 2.18159
Timestep Consumption Time: 2.44330
PPO Batch Consumption Time: 0.28204
Total Iteration Time: 4.62489

Cumulative Model Updates: 72,024
Cumulative Timesteps: 600,737,750

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 600737750...
Checkpoint 600737750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 933.26351
Policy Entropy: 3.25721
Value Function Loss: 0.00410

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09463
Policy Update Magnitude: 0.56869
Value Function Update Magnitude: 0.64366

Collected Steps per Second: 21,939.82724
Overall Steps per Second: 10,571.45052

Timestep Collection Time: 2.27987
Timestep Consumption Time: 2.45174
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.73161

Cumulative Model Updates: 72,030
Cumulative Timesteps: 600,787,770

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.79251
Policy Entropy: 3.26976
Value Function Loss: 0.00405

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08583
Policy Update Magnitude: 0.56257
Value Function Update Magnitude: 0.63746

Collected Steps per Second: 22,781.72369
Overall Steps per Second: 10,648.54532

Timestep Collection Time: 2.19597
Timestep Consumption Time: 2.50214
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.69811

Cumulative Model Updates: 72,036
Cumulative Timesteps: 600,837,798

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 600837798...
Checkpoint 600837798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.84286
Policy Entropy: 3.25474
Value Function Loss: 0.00384

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10215
Policy Update Magnitude: 0.55426
Value Function Update Magnitude: 0.63722

Collected Steps per Second: 22,672.36467
Overall Steps per Second: 10,544.41322

Timestep Collection Time: 2.20753
Timestep Consumption Time: 2.53906
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.74659

Cumulative Model Updates: 72,042
Cumulative Timesteps: 600,887,848

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.43317
Policy Entropy: 3.25211
Value Function Loss: 0.00407

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.55791
Value Function Update Magnitude: 0.64073

Collected Steps per Second: 22,259.26414
Overall Steps per Second: 10,433.25803

Timestep Collection Time: 2.24724
Timestep Consumption Time: 2.54723
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 4.79448

Cumulative Model Updates: 72,048
Cumulative Timesteps: 600,937,870

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 600937870...
Checkpoint 600937870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.42951
Policy Entropy: 3.24677
Value Function Loss: 0.00414

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.56620
Value Function Update Magnitude: 0.64689

Collected Steps per Second: 22,113.93829
Overall Steps per Second: 10,559.25146

Timestep Collection Time: 2.26183
Timestep Consumption Time: 2.47506
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.73689

Cumulative Model Updates: 72,054
Cumulative Timesteps: 600,987,888

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 906.75000
Policy Entropy: 3.24922
Value Function Loss: 0.00423

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11604
Policy Update Magnitude: 0.57581
Value Function Update Magnitude: 0.67016

Collected Steps per Second: 22,988.49623
Overall Steps per Second: 10,648.04854

Timestep Collection Time: 2.17500
Timestep Consumption Time: 2.52070
PPO Batch Consumption Time: 0.29639
Total Iteration Time: 4.69570

Cumulative Model Updates: 72,060
Cumulative Timesteps: 601,037,888

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 601037888...
Checkpoint 601037888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.28050
Policy Entropy: 3.24084
Value Function Loss: 0.00421

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11421
Policy Update Magnitude: 0.57225
Value Function Update Magnitude: 0.68939

Collected Steps per Second: 22,211.65638
Overall Steps per Second: 10,600.19356

Timestep Collection Time: 2.25107
Timestep Consumption Time: 2.46582
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.71689

Cumulative Model Updates: 72,066
Cumulative Timesteps: 601,087,888

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638.47810
Policy Entropy: 3.24195
Value Function Loss: 0.00435

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.11934
Policy Update Magnitude: 0.57381
Value Function Update Magnitude: 0.69418

Collected Steps per Second: 23,219.08439
Overall Steps per Second: 10,810.62642

Timestep Collection Time: 2.15383
Timestep Consumption Time: 2.47217
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.62600

Cumulative Model Updates: 72,072
Cumulative Timesteps: 601,137,898

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 601137898...
Checkpoint 601137898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 805.25341
Policy Entropy: 3.22896
Value Function Loss: 0.00449

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.11938
Policy Update Magnitude: 0.58349
Value Function Update Magnitude: 0.69694

Collected Steps per Second: 22,490.04968
Overall Steps per Second: 10,711.47277

Timestep Collection Time: 2.22445
Timestep Consumption Time: 2.44606
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.67051

Cumulative Model Updates: 72,078
Cumulative Timesteps: 601,187,926

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.05213
Policy Entropy: 3.22902
Value Function Loss: 0.00449

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.12921
Policy Update Magnitude: 0.58526
Value Function Update Magnitude: 0.70568

Collected Steps per Second: 22,191.69200
Overall Steps per Second: 10,491.05992

Timestep Collection Time: 2.25409
Timestep Consumption Time: 2.51397
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.76806

Cumulative Model Updates: 72,084
Cumulative Timesteps: 601,237,948

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 601237948...
Checkpoint 601237948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.58066
Policy Entropy: 3.22156
Value Function Loss: 0.00447

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.58286
Value Function Update Magnitude: 0.68023

Collected Steps per Second: 22,133.88416
Overall Steps per Second: 10,593.17838

Timestep Collection Time: 2.25970
Timestep Consumption Time: 2.46183
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.72153

Cumulative Model Updates: 72,090
Cumulative Timesteps: 601,287,964

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.01107
Policy Entropy: 3.21849
Value Function Loss: 0.00438

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11351
Policy Update Magnitude: 0.57551
Value Function Update Magnitude: 0.66112

Collected Steps per Second: 22,664.69830
Overall Steps per Second: 10,570.89087

Timestep Collection Time: 2.20704
Timestep Consumption Time: 2.52501
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.73205

Cumulative Model Updates: 72,096
Cumulative Timesteps: 601,337,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 601337986...
Checkpoint 601337986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.55306
Policy Entropy: 3.22006
Value Function Loss: 0.00438

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10841
Policy Update Magnitude: 0.57399
Value Function Update Magnitude: 0.64588

Collected Steps per Second: 22,187.14480
Overall Steps per Second: 10,535.41007

Timestep Collection Time: 2.25419
Timestep Consumption Time: 2.49304
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.74723

Cumulative Model Updates: 72,102
Cumulative Timesteps: 601,388,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 800.13762
Policy Entropy: 3.23388
Value Function Loss: 0.00432

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10145
Policy Update Magnitude: 0.58080
Value Function Update Magnitude: 0.63887

Collected Steps per Second: 23,037.47325
Overall Steps per Second: 10,694.08371

Timestep Collection Time: 2.17090
Timestep Consumption Time: 2.50571
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.67660

Cumulative Model Updates: 72,108
Cumulative Timesteps: 601,438,012

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 601438012...
Checkpoint 601438012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.27389
Policy Entropy: 3.23208
Value Function Loss: 0.00445

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09934
Policy Update Magnitude: 0.57740
Value Function Update Magnitude: 0.63270

Collected Steps per Second: 22,758.88079
Overall Steps per Second: 10,814.57789

Timestep Collection Time: 2.19730
Timestep Consumption Time: 2.42683
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.62413

Cumulative Model Updates: 72,114
Cumulative Timesteps: 601,488,020

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.74809
Policy Entropy: 3.24478
Value Function Loss: 0.00430

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10433
Policy Update Magnitude: 0.57779
Value Function Update Magnitude: 0.62233

Collected Steps per Second: 22,854.80366
Overall Steps per Second: 10,661.01945

Timestep Collection Time: 2.18781
Timestep Consumption Time: 2.50236
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.69017

Cumulative Model Updates: 72,120
Cumulative Timesteps: 601,538,022

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 601538022...
Checkpoint 601538022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 983.37384
Policy Entropy: 3.25648
Value Function Loss: 0.00418

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.57054
Value Function Update Magnitude: 0.62415

Collected Steps per Second: 22,540.92975
Overall Steps per Second: 10,698.10631

Timestep Collection Time: 2.21845
Timestep Consumption Time: 2.45583
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.67429

Cumulative Model Updates: 72,126
Cumulative Timesteps: 601,588,028

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 789.02429
Policy Entropy: 3.26741
Value Function Loss: 0.00407

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09452
Policy Update Magnitude: 0.56426
Value Function Update Magnitude: 0.63895

Collected Steps per Second: 23,106.65263
Overall Steps per Second: 10,723.80220

Timestep Collection Time: 2.16500
Timestep Consumption Time: 2.49995
PPO Batch Consumption Time: 0.29646
Total Iteration Time: 4.66495

Cumulative Model Updates: 72,132
Cumulative Timesteps: 601,638,054

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 601638054...
Checkpoint 601638054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.27871
Policy Entropy: 3.25752
Value Function Loss: 0.00413

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12370
Policy Update Magnitude: 0.56349
Value Function Update Magnitude: 0.65092

Collected Steps per Second: 22,516.94850
Overall Steps per Second: 10,835.89724

Timestep Collection Time: 2.22073
Timestep Consumption Time: 2.39393
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.61466

Cumulative Model Updates: 72,138
Cumulative Timesteps: 601,688,058

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 981.15094
Policy Entropy: 3.25671
Value Function Loss: 0.00411

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12292
Policy Update Magnitude: 0.56043
Value Function Update Magnitude: 0.65264

Collected Steps per Second: 21,820.99636
Overall Steps per Second: 10,655.38570

Timestep Collection Time: 2.29174
Timestep Consumption Time: 2.40148
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.69321

Cumulative Model Updates: 72,144
Cumulative Timesteps: 601,738,066

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 601738066...
Checkpoint 601738066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 809.33028
Policy Entropy: 3.24050
Value Function Loss: 0.00407

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.12426
Policy Update Magnitude: 0.55298
Value Function Update Magnitude: 0.65143

Collected Steps per Second: 21,501.43136
Overall Steps per Second: 10,629.88091

Timestep Collection Time: 2.32608
Timestep Consumption Time: 2.37896
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.70504

Cumulative Model Updates: 72,150
Cumulative Timesteps: 601,788,080

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.48470
Policy Entropy: 3.25635
Value Function Loss: 0.00390

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12466
Policy Update Magnitude: 0.54805
Value Function Update Magnitude: 0.65851

Collected Steps per Second: 21,214.12608
Overall Steps per Second: 10,457.12972

Timestep Collection Time: 2.35730
Timestep Consumption Time: 2.42489
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.78219

Cumulative Model Updates: 72,156
Cumulative Timesteps: 601,838,088

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 601838088...
Checkpoint 601838088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.14134
Policy Entropy: 3.26893
Value Function Loss: 0.00393

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10632
Policy Update Magnitude: 0.54662
Value Function Update Magnitude: 0.64761

Collected Steps per Second: 21,623.71409
Overall Steps per Second: 10,683.31785

Timestep Collection Time: 2.31357
Timestep Consumption Time: 2.36924
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.68281

Cumulative Model Updates: 72,162
Cumulative Timesteps: 601,888,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514.26193
Policy Entropy: 3.29031
Value Function Loss: 0.00393

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07857
Policy Update Magnitude: 0.55037
Value Function Update Magnitude: 0.63829

Collected Steps per Second: 22,167.60681
Overall Steps per Second: 10,426.18007

Timestep Collection Time: 2.25581
Timestep Consumption Time: 2.54038
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.79620

Cumulative Model Updates: 72,168
Cumulative Timesteps: 601,938,122

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 601938122...
Checkpoint 601938122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.33174
Policy Entropy: 3.27145
Value Function Loss: 0.00399

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08286
Policy Update Magnitude: 0.54891
Value Function Update Magnitude: 0.64667

Collected Steps per Second: 22,556.95505
Overall Steps per Second: 10,658.59420

Timestep Collection Time: 2.21670
Timestep Consumption Time: 2.47454
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.69124

Cumulative Model Updates: 72,174
Cumulative Timesteps: 601,988,124

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 990.83930
Policy Entropy: 3.27249
Value Function Loss: 0.00403

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08544
Policy Update Magnitude: 0.55595
Value Function Update Magnitude: 0.64975

Collected Steps per Second: 22,935.92075
Overall Steps per Second: 10,762.16140

Timestep Collection Time: 2.18068
Timestep Consumption Time: 2.46671
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.64739

Cumulative Model Updates: 72,180
Cumulative Timesteps: 602,038,140

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 602038140...
Checkpoint 602038140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 911.09183
Policy Entropy: 3.26760
Value Function Loss: 0.00406

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08678
Policy Update Magnitude: 0.55842
Value Function Update Magnitude: 0.64776

Collected Steps per Second: 22,799.31059
Overall Steps per Second: 10,796.19033

Timestep Collection Time: 2.19358
Timestep Consumption Time: 2.43880
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.63237

Cumulative Model Updates: 72,186
Cumulative Timesteps: 602,088,152

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617.28524
Policy Entropy: 3.28125
Value Function Loss: 0.00416

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.55798
Value Function Update Magnitude: 0.63457

Collected Steps per Second: 23,302.57983
Overall Steps per Second: 10,841.62679

Timestep Collection Time: 2.14672
Timestep Consumption Time: 2.46735
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.61407

Cumulative Model Updates: 72,192
Cumulative Timesteps: 602,138,176

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 602138176...
Checkpoint 602138176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 963.10218
Policy Entropy: 3.29847
Value Function Loss: 0.00391

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09464
Policy Update Magnitude: 0.55215
Value Function Update Magnitude: 0.63951

Collected Steps per Second: 22,536.16448
Overall Steps per Second: 10,656.95837

Timestep Collection Time: 2.21874
Timestep Consumption Time: 2.47321
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.69196

Cumulative Model Updates: 72,198
Cumulative Timesteps: 602,188,178

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706.19632
Policy Entropy: 3.30288
Value Function Loss: 0.00394

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08074
Policy Update Magnitude: 0.54259
Value Function Update Magnitude: 0.61805

Collected Steps per Second: 22,799.97000
Overall Steps per Second: 10,639.56383

Timestep Collection Time: 2.19325
Timestep Consumption Time: 2.50676
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.70000

Cumulative Model Updates: 72,204
Cumulative Timesteps: 602,238,184

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 602238184...
Checkpoint 602238184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 987.77421
Policy Entropy: 3.30393
Value Function Loss: 0.00376

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07272
Policy Update Magnitude: 0.54377
Value Function Update Magnitude: 0.61075

Collected Steps per Second: 22,823.23353
Overall Steps per Second: 10,713.23886

Timestep Collection Time: 2.19119
Timestep Consumption Time: 2.47687
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.66806

Cumulative Model Updates: 72,210
Cumulative Timesteps: 602,288,194

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.30926
Policy Entropy: 3.28462
Value Function Loss: 0.00400

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 0.55096
Value Function Update Magnitude: 0.63535

Collected Steps per Second: 22,590.09996
Overall Steps per Second: 10,699.67847

Timestep Collection Time: 2.21451
Timestep Consumption Time: 2.46096
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.67547

Cumulative Model Updates: 72,216
Cumulative Timesteps: 602,338,220

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 602338220...
Checkpoint 602338220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,444.66951
Policy Entropy: 3.28876
Value Function Loss: 0.00398

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.10081
Policy Update Magnitude: 0.56005
Value Function Update Magnitude: 0.64911

Collected Steps per Second: 22,336.12048
Overall Steps per Second: 10,568.89244

Timestep Collection Time: 2.23960
Timestep Consumption Time: 2.49353
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.73314

Cumulative Model Updates: 72,222
Cumulative Timesteps: 602,388,244

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.16404
Policy Entropy: 3.30228
Value Function Loss: 0.00391

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10172
Policy Update Magnitude: 0.55504
Value Function Update Magnitude: 0.64567

Collected Steps per Second: 22,573.24321
Overall Steps per Second: 10,536.22412

Timestep Collection Time: 2.21554
Timestep Consumption Time: 2.53113
PPO Batch Consumption Time: 0.29640
Total Iteration Time: 4.74667

Cumulative Model Updates: 72,228
Cumulative Timesteps: 602,438,256

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 602438256...
Checkpoint 602438256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,293.53286
Policy Entropy: 3.30775
Value Function Loss: 0.00379

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10126
Policy Update Magnitude: 0.54800
Value Function Update Magnitude: 0.62364

Collected Steps per Second: 22,247.92160
Overall Steps per Second: 10,609.41752

Timestep Collection Time: 2.24839
Timestep Consumption Time: 2.46648
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.71487

Cumulative Model Updates: 72,234
Cumulative Timesteps: 602,488,278

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.47705
Policy Entropy: 3.29391
Value Function Loss: 0.00375

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09392
Policy Update Magnitude: 0.54504
Value Function Update Magnitude: 0.60921

Collected Steps per Second: 22,771.23726
Overall Steps per Second: 10,636.40904

Timestep Collection Time: 2.19619
Timestep Consumption Time: 2.50558
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.70177

Cumulative Model Updates: 72,240
Cumulative Timesteps: 602,538,288

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 602538288...
Checkpoint 602538288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 835.41182
Policy Entropy: 3.28925
Value Function Loss: 0.00373

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09884
Policy Update Magnitude: 0.53776
Value Function Update Magnitude: 0.60101

Collected Steps per Second: 22,360.55542
Overall Steps per Second: 10,550.89341

Timestep Collection Time: 2.23626
Timestep Consumption Time: 2.50305
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.73931

Cumulative Model Updates: 72,246
Cumulative Timesteps: 602,588,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760.39358
Policy Entropy: 3.29227
Value Function Loss: 0.00388

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08745
Policy Update Magnitude: 0.53815
Value Function Update Magnitude: 0.59389

Collected Steps per Second: 23,094.24143
Overall Steps per Second: 10,813.64028

Timestep Collection Time: 2.16582
Timestep Consumption Time: 2.45963
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.62545

Cumulative Model Updates: 72,252
Cumulative Timesteps: 602,638,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 602638310...
Checkpoint 602638310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 980.74096
Policy Entropy: 3.30723
Value Function Loss: 0.00375

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07586
Policy Update Magnitude: 0.54261
Value Function Update Magnitude: 0.59759

Collected Steps per Second: 22,560.45664
Overall Steps per Second: 10,635.09405

Timestep Collection Time: 2.21662
Timestep Consumption Time: 2.48555
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.70217

Cumulative Model Updates: 72,258
Cumulative Timesteps: 602,688,318

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,661.31181
Policy Entropy: 3.30169
Value Function Loss: 0.00353

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08095
Policy Update Magnitude: 0.53769
Value Function Update Magnitude: 0.59757

Collected Steps per Second: 22,988.48990
Overall Steps per Second: 10,841.17447

Timestep Collection Time: 2.17561
Timestep Consumption Time: 2.43773
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.61334

Cumulative Model Updates: 72,264
Cumulative Timesteps: 602,738,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 602738332...
Checkpoint 602738332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,483.91326
Policy Entropy: 3.28541
Value Function Loss: 0.00364

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08664
Policy Update Magnitude: 0.53530
Value Function Update Magnitude: 0.60431

Collected Steps per Second: 22,307.75332
Overall Steps per Second: 10,738.59861

Timestep Collection Time: 2.24173
Timestep Consumption Time: 2.41511
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.65685

Cumulative Model Updates: 72,270
Cumulative Timesteps: 602,788,340

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.38237
Policy Entropy: 3.27098
Value Function Loss: 0.00381

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08494
Policy Update Magnitude: 0.55230
Value Function Update Magnitude: 0.62317

Collected Steps per Second: 22,203.20204
Overall Steps per Second: 10,505.82889

Timestep Collection Time: 2.25328
Timestep Consumption Time: 2.50884
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.76212

Cumulative Model Updates: 72,276
Cumulative Timesteps: 602,838,370

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 602838370...
Checkpoint 602838370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935.12877
Policy Entropy: 3.27775
Value Function Loss: 0.00410

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.57311
Value Function Update Magnitude: 0.64835

Collected Steps per Second: 21,970.22279
Overall Steps per Second: 10,548.83856

Timestep Collection Time: 2.27581
Timestep Consumption Time: 2.46405
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.73986

Cumulative Model Updates: 72,282
Cumulative Timesteps: 602,888,370

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.67840
Policy Entropy: 3.29331
Value Function Loss: 0.00396

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07698
Policy Update Magnitude: 0.57332
Value Function Update Magnitude: 0.64923

Collected Steps per Second: 22,431.16450
Overall Steps per Second: 10,578.60515

Timestep Collection Time: 2.22940
Timestep Consumption Time: 2.49788
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.72728

Cumulative Model Updates: 72,288
Cumulative Timesteps: 602,938,378

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 602938378...
Checkpoint 602938378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,337.34155
Policy Entropy: 3.30647
Value Function Loss: 0.00391

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08404
Policy Update Magnitude: 0.56595
Value Function Update Magnitude: 0.65214

Collected Steps per Second: 22,502.24719
Overall Steps per Second: 10,609.57830

Timestep Collection Time: 2.22244
Timestep Consumption Time: 2.49122
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 4.71367

Cumulative Model Updates: 72,294
Cumulative Timesteps: 602,988,388

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 895.84256
Policy Entropy: 3.29878
Value Function Loss: 0.00379

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08746
Policy Update Magnitude: 0.56438
Value Function Update Magnitude: 0.65329

Collected Steps per Second: 22,640.13625
Overall Steps per Second: 10,780.91340

Timestep Collection Time: 2.20944
Timestep Consumption Time: 2.43043
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.63987

Cumulative Model Updates: 72,300
Cumulative Timesteps: 603,038,410

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 603038410...
Checkpoint 603038410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.64480
Policy Entropy: 3.30253
Value Function Loss: 0.00389

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09074
Policy Update Magnitude: 0.56850
Value Function Update Magnitude: 0.65882

Collected Steps per Second: 22,279.44878
Overall Steps per Second: 10,671.40500

Timestep Collection Time: 2.24449
Timestep Consumption Time: 2.44149
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.68598

Cumulative Model Updates: 72,306
Cumulative Timesteps: 603,088,416

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,508.58994
Policy Entropy: 3.30720
Value Function Loss: 0.00384

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10706
Policy Update Magnitude: 0.56628
Value Function Update Magnitude: 0.67653

Collected Steps per Second: 22,863.22787
Overall Steps per Second: 10,559.90652

Timestep Collection Time: 2.18692
Timestep Consumption Time: 2.54797
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.73489

Cumulative Model Updates: 72,312
Cumulative Timesteps: 603,138,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 603138416...
Checkpoint 603138416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.45305
Policy Entropy: 3.29868
Value Function Loss: 0.00383

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.11057
Policy Update Magnitude: 0.56067
Value Function Update Magnitude: 0.66165

Collected Steps per Second: 22,762.94640
Overall Steps per Second: 10,674.43424

Timestep Collection Time: 2.19655
Timestep Consumption Time: 2.48754
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.68409

Cumulative Model Updates: 72,318
Cumulative Timesteps: 603,188,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.22322
Policy Entropy: 3.30435
Value Function Loss: 0.00384

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08503
Policy Update Magnitude: 0.55482
Value Function Update Magnitude: 0.65297

Collected Steps per Second: 22,724.13652
Overall Steps per Second: 10,764.19175

Timestep Collection Time: 2.20083
Timestep Consumption Time: 2.44531
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.64615

Cumulative Model Updates: 72,324
Cumulative Timesteps: 603,238,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 603238428...
Checkpoint 603238428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.17834
Policy Entropy: 3.30665
Value Function Loss: 0.00379

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09820
Policy Update Magnitude: 0.55622
Value Function Update Magnitude: 0.62631

Collected Steps per Second: 22,823.48103
Overall Steps per Second: 10,689.57548

Timestep Collection Time: 2.19195
Timestep Consumption Time: 2.48812
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.68007

Cumulative Model Updates: 72,330
Cumulative Timesteps: 603,288,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.64704
Policy Entropy: 3.30532
Value Function Loss: 0.00384

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09054
Policy Update Magnitude: 0.55098
Value Function Update Magnitude: 0.61697

Collected Steps per Second: 23,177.15895
Overall Steps per Second: 10,868.36847

Timestep Collection Time: 2.15764
Timestep Consumption Time: 2.44360
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.60124

Cumulative Model Updates: 72,336
Cumulative Timesteps: 603,338,464

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 603338464...
Checkpoint 603338464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,622.09453
Policy Entropy: 3.30606
Value Function Loss: 0.00380

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09697
Policy Update Magnitude: 0.54745
Value Function Update Magnitude: 0.61911

Collected Steps per Second: 22,523.91939
Overall Steps per Second: 10,641.40693

Timestep Collection Time: 2.22022
Timestep Consumption Time: 2.47916
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.69938

Cumulative Model Updates: 72,342
Cumulative Timesteps: 603,388,472

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 969.16466
Policy Entropy: 3.29999
Value Function Loss: 0.00401

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09291
Policy Update Magnitude: 0.55030
Value Function Update Magnitude: 0.62613

Collected Steps per Second: 22,477.95190
Overall Steps per Second: 10,644.74649

Timestep Collection Time: 2.22458
Timestep Consumption Time: 2.47295
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.69753

Cumulative Model Updates: 72,348
Cumulative Timesteps: 603,438,476

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 603438476...
Checkpoint 603438476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 735.38794
Policy Entropy: 3.30027
Value Function Loss: 0.00397

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08408
Policy Update Magnitude: 0.55761
Value Function Update Magnitude: 0.65142

Collected Steps per Second: 22,535.19299
Overall Steps per Second: 10,763.04552

Timestep Collection Time: 2.21928
Timestep Consumption Time: 2.42736
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.64664

Cumulative Model Updates: 72,354
Cumulative Timesteps: 603,488,488

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 886.63844
Policy Entropy: 3.29836
Value Function Loss: 0.00396

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08581
Policy Update Magnitude: 0.55750
Value Function Update Magnitude: 0.66938

Collected Steps per Second: 22,449.10374
Overall Steps per Second: 10,514.66424

Timestep Collection Time: 2.22735
Timestep Consumption Time: 2.52810
PPO Batch Consumption Time: 0.29785
Total Iteration Time: 4.75545

Cumulative Model Updates: 72,360
Cumulative Timesteps: 603,538,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 603538490...
Checkpoint 603538490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 829.42445
Policy Entropy: 3.30078
Value Function Loss: 0.00398

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07905
Policy Update Magnitude: 0.55965
Value Function Update Magnitude: 0.66533

Collected Steps per Second: 22,248.47617
Overall Steps per Second: 10,689.76632

Timestep Collection Time: 2.24770
Timestep Consumption Time: 2.43041
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.67812

Cumulative Model Updates: 72,366
Cumulative Timesteps: 603,588,498

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 919.49028
Policy Entropy: 3.31379
Value Function Loss: 0.00402

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08350
Policy Update Magnitude: 0.55836
Value Function Update Magnitude: 0.62707

Collected Steps per Second: 22,819.91490
Overall Steps per Second: 10,796.71658

Timestep Collection Time: 2.19221
Timestep Consumption Time: 2.44124
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.63345

Cumulative Model Updates: 72,372
Cumulative Timesteps: 603,638,524

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 603638524...
Checkpoint 603638524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.87065
Policy Entropy: 3.30234
Value Function Loss: 0.00406

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08325
Policy Update Magnitude: 0.55097
Value Function Update Magnitude: 0.61558

Collected Steps per Second: 22,879.97580
Overall Steps per Second: 10,761.89863

Timestep Collection Time: 2.18672
Timestep Consumption Time: 2.46228
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.64899

Cumulative Model Updates: 72,378
Cumulative Timesteps: 603,688,556

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.83461
Policy Entropy: 3.30246
Value Function Loss: 0.00385

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08341
Policy Update Magnitude: 0.54101
Value Function Update Magnitude: 0.61501

Collected Steps per Second: 22,623.95746
Overall Steps per Second: 10,779.43817

Timestep Collection Time: 2.21058
Timestep Consumption Time: 2.42900
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.63957

Cumulative Model Updates: 72,384
Cumulative Timesteps: 603,738,568

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 603738568...
Checkpoint 603738568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507.36693
Policy Entropy: 3.28296
Value Function Loss: 0.00383

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.07993
Policy Update Magnitude: 0.53479
Value Function Update Magnitude: 0.60399

Collected Steps per Second: 22,451.74067
Overall Steps per Second: 10,734.77844

Timestep Collection Time: 2.22798
Timestep Consumption Time: 2.43183
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.65981

Cumulative Model Updates: 72,390
Cumulative Timesteps: 603,788,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710.66073
Policy Entropy: 3.28586
Value Function Loss: 0.00386

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07452
Policy Update Magnitude: 0.53582
Value Function Update Magnitude: 0.58171

Collected Steps per Second: 23,010.12152
Overall Steps per Second: 10,858.87723

Timestep Collection Time: 2.17391
Timestep Consumption Time: 2.43264
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.60655

Cumulative Model Updates: 72,396
Cumulative Timesteps: 603,838,612

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 603838612...
Checkpoint 603838612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.10255
Policy Entropy: 3.27236
Value Function Loss: 0.00386

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07511
Policy Update Magnitude: 0.54021
Value Function Update Magnitude: 0.58496

Collected Steps per Second: 22,670.42525
Overall Steps per Second: 10,747.49521

Timestep Collection Time: 2.20622
Timestep Consumption Time: 2.44751
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.65374

Cumulative Model Updates: 72,402
Cumulative Timesteps: 603,888,628

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.67278
Policy Entropy: 3.27287
Value Function Loss: 0.00383

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07597
Policy Update Magnitude: 0.54420
Value Function Update Magnitude: 0.57687

Collected Steps per Second: 22,423.46736
Overall Steps per Second: 10,632.71069

Timestep Collection Time: 2.23097
Timestep Consumption Time: 2.47395
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.70492

Cumulative Model Updates: 72,408
Cumulative Timesteps: 603,938,654

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 603938654...
Checkpoint 603938654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 919.62166
Policy Entropy: 3.28446
Value Function Loss: 0.00394

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07869
Policy Update Magnitude: 0.54709
Value Function Update Magnitude: 0.58374

Collected Steps per Second: 22,103.13763
Overall Steps per Second: 10,525.89838

Timestep Collection Time: 2.26257
Timestep Consumption Time: 2.48856
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.75114

Cumulative Model Updates: 72,414
Cumulative Timesteps: 603,988,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 859.78252
Policy Entropy: 3.28119
Value Function Loss: 0.00391

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07745
Policy Update Magnitude: 0.54742
Value Function Update Magnitude: 0.60050

Collected Steps per Second: 22,192.11798
Overall Steps per Second: 10,555.83712

Timestep Collection Time: 2.25350
Timestep Consumption Time: 2.48416
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.73766

Cumulative Model Updates: 72,420
Cumulative Timesteps: 604,038,674

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 604038674...
Checkpoint 604038674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.17920
Policy Entropy: 3.29945
Value Function Loss: 0.00391

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08780
Policy Update Magnitude: 0.54029
Value Function Update Magnitude: 0.59627

Collected Steps per Second: 22,274.01637
Overall Steps per Second: 10,597.73915

Timestep Collection Time: 2.24513
Timestep Consumption Time: 2.47362
PPO Batch Consumption Time: 0.29508
Total Iteration Time: 4.71874

Cumulative Model Updates: 72,426
Cumulative Timesteps: 604,088,682

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.29340
Policy Entropy: 3.29180
Value Function Loss: 0.00387

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08901
Policy Update Magnitude: 0.53459
Value Function Update Magnitude: 0.60401

Collected Steps per Second: 22,431.61083
Overall Steps per Second: 10,671.22336

Timestep Collection Time: 2.23033
Timestep Consumption Time: 2.45797
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.68831

Cumulative Model Updates: 72,432
Cumulative Timesteps: 604,138,712

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 604138712...
Checkpoint 604138712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707.55392
Policy Entropy: 3.28991
Value Function Loss: 0.00397

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09882
Policy Update Magnitude: 0.54094
Value Function Update Magnitude: 0.61318

Collected Steps per Second: 22,654.76678
Overall Steps per Second: 10,665.36907

Timestep Collection Time: 2.20819
Timestep Consumption Time: 2.48232
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.69051

Cumulative Model Updates: 72,438
Cumulative Timesteps: 604,188,738

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 851.35582
Policy Entropy: 3.27263
Value Function Loss: 0.00387

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10129
Policy Update Magnitude: 0.54808
Value Function Update Magnitude: 0.61240

Collected Steps per Second: 22,574.99272
Overall Steps per Second: 10,617.75113

Timestep Collection Time: 2.21537
Timestep Consumption Time: 2.49485
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.71023

Cumulative Model Updates: 72,444
Cumulative Timesteps: 604,238,750

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 604238750...
Checkpoint 604238750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.09309
Policy Entropy: 3.26827
Value Function Loss: 0.00398

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09472
Policy Update Magnitude: 0.54453
Value Function Update Magnitude: 0.61913

Collected Steps per Second: 22,624.27473
Overall Steps per Second: 10,636.37413

Timestep Collection Time: 2.21063
Timestep Consumption Time: 2.49153
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.70217

Cumulative Model Updates: 72,450
Cumulative Timesteps: 604,288,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 910.87926
Policy Entropy: 3.27896
Value Function Loss: 0.00378

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09212
Policy Update Magnitude: 0.54494
Value Function Update Magnitude: 0.61185

Collected Steps per Second: 22,612.62411
Overall Steps per Second: 10,777.30533

Timestep Collection Time: 2.21124
Timestep Consumption Time: 2.42832
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.63956

Cumulative Model Updates: 72,456
Cumulative Timesteps: 604,338,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 604338766...
Checkpoint 604338766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 953.76487
Policy Entropy: 3.30332
Value Function Loss: 0.00387

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10175
Policy Update Magnitude: 0.53979
Value Function Update Magnitude: 0.60554

Collected Steps per Second: 22,485.33768
Overall Steps per Second: 10,685.56724

Timestep Collection Time: 2.22501
Timestep Consumption Time: 2.45701
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.68202

Cumulative Model Updates: 72,462
Cumulative Timesteps: 604,388,796

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,632.50798
Policy Entropy: 3.31792
Value Function Loss: 0.00381

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08885
Policy Update Magnitude: 0.53166
Value Function Update Magnitude: 0.59766

Collected Steps per Second: 22,909.72576
Overall Steps per Second: 10,842.01402

Timestep Collection Time: 2.18274
Timestep Consumption Time: 2.42950
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.61224

Cumulative Model Updates: 72,468
Cumulative Timesteps: 604,438,802

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 604438802...
Checkpoint 604438802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761.91857
Policy Entropy: 3.31439
Value Function Loss: 0.00371

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.07826
Policy Update Magnitude: 0.52954
Value Function Update Magnitude: 0.58961

Collected Steps per Second: 22,357.01946
Overall Steps per Second: 10,749.81750

Timestep Collection Time: 2.23742
Timestep Consumption Time: 2.41587
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.65329

Cumulative Model Updates: 72,474
Cumulative Timesteps: 604,488,824

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 876.77728
Policy Entropy: 3.30598
Value Function Loss: 0.00379

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07284
Policy Update Magnitude: 0.52703
Value Function Update Magnitude: 0.59766

Collected Steps per Second: 21,934.79413
Overall Steps per Second: 10,638.05050

Timestep Collection Time: 2.27967
Timestep Consumption Time: 2.42082
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.70049

Cumulative Model Updates: 72,480
Cumulative Timesteps: 604,538,828

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 604538828...
Checkpoint 604538828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.69077
Policy Entropy: 3.30309
Value Function Loss: 0.00384

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07718
Policy Update Magnitude: 0.53892
Value Function Update Magnitude: 0.61397

Collected Steps per Second: 21,677.85130
Overall Steps per Second: 10,597.30391

Timestep Collection Time: 2.30687
Timestep Consumption Time: 2.41207
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.71894

Cumulative Model Updates: 72,486
Cumulative Timesteps: 604,588,836

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.83416
Policy Entropy: 3.31714
Value Function Loss: 0.00398

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10004
Policy Update Magnitude: 0.54020
Value Function Update Magnitude: 0.62112

Collected Steps per Second: 22,014.92252
Overall Steps per Second: 10,751.24369

Timestep Collection Time: 2.27246
Timestep Consumption Time: 2.38077
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.65323

Cumulative Model Updates: 72,492
Cumulative Timesteps: 604,638,864

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 604638864...
Checkpoint 604638864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655.69306
Policy Entropy: 3.31041
Value Function Loss: 0.00390

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.53808
Value Function Update Magnitude: 0.63817

Collected Steps per Second: 22,378.99088
Overall Steps per Second: 10,618.03348

Timestep Collection Time: 2.23531
Timestep Consumption Time: 2.47592
PPO Batch Consumption Time: 0.29716
Total Iteration Time: 4.71123

Cumulative Model Updates: 72,498
Cumulative Timesteps: 604,688,888

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.31218
Policy Entropy: 3.30908
Value Function Loss: 0.00391

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09239
Policy Update Magnitude: 0.53851
Value Function Update Magnitude: 0.64713

Collected Steps per Second: 21,872.71622
Overall Steps per Second: 10,517.65517

Timestep Collection Time: 2.28705
Timestep Consumption Time: 2.46914
PPO Batch Consumption Time: 0.29604
Total Iteration Time: 4.75619

Cumulative Model Updates: 72,504
Cumulative Timesteps: 604,738,912

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 604738912...
Checkpoint 604738912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.55692
Policy Entropy: 3.30862
Value Function Loss: 0.00363

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08485
Policy Update Magnitude: 0.53962
Value Function Update Magnitude: 0.64892

Collected Steps per Second: 23,056.40089
Overall Steps per Second: 10,710.43716

Timestep Collection Time: 2.16981
Timestep Consumption Time: 2.50115
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.67096

Cumulative Model Updates: 72,510
Cumulative Timesteps: 604,788,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.82445
Policy Entropy: 3.33089
Value Function Loss: 0.00356

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.52753
Value Function Update Magnitude: 0.62325

Collected Steps per Second: 22,740.77607
Overall Steps per Second: 10,758.27415

Timestep Collection Time: 2.19878
Timestep Consumption Time: 2.44899
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.64777

Cumulative Model Updates: 72,516
Cumulative Timesteps: 604,838,942

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 604838942...
Checkpoint 604838942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.28370
Policy Entropy: 3.33491
Value Function Loss: 0.00349

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07622
Policy Update Magnitude: 0.51869
Value Function Update Magnitude: 0.59931

Collected Steps per Second: 21,839.30184
Overall Steps per Second: 10,677.68274

Timestep Collection Time: 2.29018
Timestep Consumption Time: 2.39398
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.68416

Cumulative Model Updates: 72,522
Cumulative Timesteps: 604,888,958

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.69418
Policy Entropy: 3.31919
Value Function Loss: 0.00377

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07616
Policy Update Magnitude: 0.52103
Value Function Update Magnitude: 0.60353

Collected Steps per Second: 22,202.67097
Overall Steps per Second: 10,474.50513

Timestep Collection Time: 2.25288
Timestep Consumption Time: 2.52252
PPO Batch Consumption Time: 0.29698
Total Iteration Time: 4.77540

Cumulative Model Updates: 72,528
Cumulative Timesteps: 604,938,978

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 604938978...
Checkpoint 604938978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,759.03305
Policy Entropy: 3.31153
Value Function Loss: 0.00372

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.07760
Policy Update Magnitude: 0.52766
Value Function Update Magnitude: 0.59812

Collected Steps per Second: 22,401.00112
Overall Steps per Second: 10,614.56376

Timestep Collection Time: 2.23303
Timestep Consumption Time: 2.47956
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.71258

Cumulative Model Updates: 72,534
Cumulative Timesteps: 604,989,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.44755
Policy Entropy: 3.29161
Value Function Loss: 0.00383

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07683
Policy Update Magnitude: 0.53610
Value Function Update Magnitude: 0.60785

Collected Steps per Second: 22,607.65993
Overall Steps per Second: 10,619.36870

Timestep Collection Time: 2.21261
Timestep Consumption Time: 2.49784
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.71045

Cumulative Model Updates: 72,540
Cumulative Timesteps: 605,039,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 605039022...
Checkpoint 605039022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 966.34976
Policy Entropy: 3.28726
Value Function Loss: 0.00366

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07777
Policy Update Magnitude: 0.54057
Value Function Update Magnitude: 0.61811

Collected Steps per Second: 22,470.69480
Overall Steps per Second: 10,567.11724

Timestep Collection Time: 2.22628
Timestep Consumption Time: 2.50784
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.73412

Cumulative Model Updates: 72,546
Cumulative Timesteps: 605,089,048

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 913.03249
Policy Entropy: 3.27659
Value Function Loss: 0.00376

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09446
Policy Update Magnitude: 0.53604
Value Function Update Magnitude: 0.60488

Collected Steps per Second: 22,656.39864
Overall Steps per Second: 10,545.49501

Timestep Collection Time: 2.20750
Timestep Consumption Time: 2.53519
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.74269

Cumulative Model Updates: 72,552
Cumulative Timesteps: 605,139,062

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 605139062...
Checkpoint 605139062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,729.70568
Policy Entropy: 3.27252
Value Function Loss: 0.00376

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09875
Policy Update Magnitude: 0.53470
Value Function Update Magnitude: 0.59158

Collected Steps per Second: 23,037.24628
Overall Steps per Second: 10,677.01942

Timestep Collection Time: 2.17153
Timestep Consumption Time: 2.51386
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.68539

Cumulative Model Updates: 72,558
Cumulative Timesteps: 605,189,088

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.55801
Policy Entropy: 3.26944
Value Function Loss: 0.00379

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11211
Policy Update Magnitude: 0.53529
Value Function Update Magnitude: 0.59795

Collected Steps per Second: 23,002.06312
Overall Steps per Second: 10,682.79311

Timestep Collection Time: 2.17433
Timestep Consumption Time: 2.50741
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.68173

Cumulative Model Updates: 72,564
Cumulative Timesteps: 605,239,102

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 605239102...
Checkpoint 605239102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711.20844
Policy Entropy: 3.27677
Value Function Loss: 0.00369

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.54085
Value Function Update Magnitude: 0.60642

Collected Steps per Second: 22,801.44579
Overall Steps per Second: 10,640.67415

Timestep Collection Time: 2.19346
Timestep Consumption Time: 2.50681
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.70027

Cumulative Model Updates: 72,570
Cumulative Timesteps: 605,289,116

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.54952
Policy Entropy: 3.28850
Value Function Loss: 0.00364

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09459
Policy Update Magnitude: 0.53670
Value Function Update Magnitude: 0.62165

Collected Steps per Second: 22,659.27833
Overall Steps per Second: 10,571.33046

Timestep Collection Time: 2.20687
Timestep Consumption Time: 2.52347
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.73034

Cumulative Model Updates: 72,576
Cumulative Timesteps: 605,339,122

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 605339122...
Checkpoint 605339122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725.47598
Policy Entropy: 3.28096
Value Function Loss: 0.00363

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09226
Policy Update Magnitude: 0.53293
Value Function Update Magnitude: 0.61865

Collected Steps per Second: 22,838.88615
Overall Steps per Second: 10,656.39339

Timestep Collection Time: 2.18960
Timestep Consumption Time: 2.50317
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.69277

Cumulative Model Updates: 72,582
Cumulative Timesteps: 605,389,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 867.15184
Policy Entropy: 3.28771
Value Function Loss: 0.00378

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10613
Policy Update Magnitude: 0.53501
Value Function Update Magnitude: 0.63121

Collected Steps per Second: 23,023.21127
Overall Steps per Second: 10,807.33964

Timestep Collection Time: 2.17276
Timestep Consumption Time: 2.45594
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.62871

Cumulative Model Updates: 72,588
Cumulative Timesteps: 605,439,154

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 605439154...
Checkpoint 605439154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.47668
Policy Entropy: 3.30144
Value Function Loss: 0.00372

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09268
Policy Update Magnitude: 0.53850
Value Function Update Magnitude: 0.65955

Collected Steps per Second: 22,407.85540
Overall Steps per Second: 10,632.28989

Timestep Collection Time: 2.23243
Timestep Consumption Time: 2.47248
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.70491

Cumulative Model Updates: 72,594
Cumulative Timesteps: 605,489,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 945.87943
Policy Entropy: 3.29946
Value Function Loss: 0.00363

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08939
Policy Update Magnitude: 0.53915
Value Function Update Magnitude: 0.64639

Collected Steps per Second: 22,547.78419
Overall Steps per Second: 10,603.83755

Timestep Collection Time: 2.21796
Timestep Consumption Time: 2.49826
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.71622

Cumulative Model Updates: 72,600
Cumulative Timesteps: 605,539,188

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 605539188...
Checkpoint 605539188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.52953
Policy Entropy: 3.28794
Value Function Loss: 0.00378

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08282
Policy Update Magnitude: 0.54280
Value Function Update Magnitude: 0.63448

Collected Steps per Second: 22,497.18279
Overall Steps per Second: 10,560.03040

Timestep Collection Time: 2.22321
Timestep Consumption Time: 2.51314
PPO Batch Consumption Time: 0.29678
Total Iteration Time: 4.73635

Cumulative Model Updates: 72,606
Cumulative Timesteps: 605,589,204

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 874.35740
Policy Entropy: 3.27498
Value Function Loss: 0.00386

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.54597
Value Function Update Magnitude: 0.62178

Collected Steps per Second: 22,385.78498
Overall Steps per Second: 10,548.48738

Timestep Collection Time: 2.23383
Timestep Consumption Time: 2.50676
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.74058

Cumulative Model Updates: 72,612
Cumulative Timesteps: 605,639,210

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 605639210...
Checkpoint 605639210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,693.65637
Policy Entropy: 3.27746
Value Function Loss: 0.00407

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09666
Policy Update Magnitude: 0.54941
Value Function Update Magnitude: 0.61920

Collected Steps per Second: 22,657.12174
Overall Steps per Second: 10,661.39041

Timestep Collection Time: 2.20822
Timestep Consumption Time: 2.48460
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.69282

Cumulative Model Updates: 72,618
Cumulative Timesteps: 605,689,242

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 913.17959
Policy Entropy: 3.30273
Value Function Loss: 0.00385

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11181
Policy Update Magnitude: 0.55260
Value Function Update Magnitude: 0.62568

Collected Steps per Second: 22,823.78137
Overall Steps per Second: 10,650.88934

Timestep Collection Time: 2.19175
Timestep Consumption Time: 2.50495
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.69670

Cumulative Model Updates: 72,624
Cumulative Timesteps: 605,739,266

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 605739266...
Checkpoint 605739266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.36090
Policy Entropy: 3.29063
Value Function Loss: 0.00410

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.10931
Policy Update Magnitude: 0.55462
Value Function Update Magnitude: 0.64225

Collected Steps per Second: 22,730.20927
Overall Steps per Second: 10,670.28433

Timestep Collection Time: 2.20033
Timestep Consumption Time: 2.48689
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.68722

Cumulative Model Updates: 72,630
Cumulative Timesteps: 605,789,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 836.70524
Policy Entropy: 3.29287
Value Function Loss: 0.00422

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.56010
Value Function Update Magnitude: 0.66435

Collected Steps per Second: 22,780.18687
Overall Steps per Second: 10,643.04021

Timestep Collection Time: 2.19507
Timestep Consumption Time: 2.50322
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.69828

Cumulative Model Updates: 72,636
Cumulative Timesteps: 605,839,284

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 605839284...
Checkpoint 605839284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,010.27030
Policy Entropy: 3.27305
Value Function Loss: 0.00430

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.13444
Policy Update Magnitude: 0.57040
Value Function Update Magnitude: 0.68229

Collected Steps per Second: 22,900.49765
Overall Steps per Second: 10,715.63591

Timestep Collection Time: 2.18345
Timestep Consumption Time: 2.48282
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.66627

Cumulative Model Updates: 72,642
Cumulative Timesteps: 605,889,286

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719.24611
Policy Entropy: 3.28371
Value Function Loss: 0.00407

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.56896
Value Function Update Magnitude: 0.67895

Collected Steps per Second: 22,714.28640
Overall Steps per Second: 10,684.00961

Timestep Collection Time: 2.20249
Timestep Consumption Time: 2.48002
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.68251

Cumulative Model Updates: 72,648
Cumulative Timesteps: 605,939,314

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 605939314...
Checkpoint 605939314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 869.49597
Policy Entropy: 3.29496
Value Function Loss: 0.00378

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.12626
Policy Update Magnitude: 0.55187
Value Function Update Magnitude: 0.64793

Collected Steps per Second: 22,810.27517
Overall Steps per Second: 10,620.86429

Timestep Collection Time: 2.19199
Timestep Consumption Time: 2.51572
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.70771

Cumulative Model Updates: 72,654
Cumulative Timesteps: 605,989,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.43240
Policy Entropy: 3.30898
Value Function Loss: 0.00374

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10706
Policy Update Magnitude: 0.53851
Value Function Update Magnitude: 0.62628

Collected Steps per Second: 22,720.86053
Overall Steps per Second: 10,648.62067

Timestep Collection Time: 2.20106
Timestep Consumption Time: 2.49532
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.69638

Cumulative Model Updates: 72,660
Cumulative Timesteps: 606,039,324

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 606039324...
Checkpoint 606039324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532.26588
Policy Entropy: 3.31176
Value Function Loss: 0.00371

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.54253
Value Function Update Magnitude: 0.62953

Collected Steps per Second: 22,471.76174
Overall Steps per Second: 10,563.74710

Timestep Collection Time: 2.22644
Timestep Consumption Time: 2.50976
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.73620

Cumulative Model Updates: 72,666
Cumulative Timesteps: 606,089,356

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783.21277
Policy Entropy: 3.32379
Value Function Loss: 0.00361

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08597
Policy Update Magnitude: 0.53819
Value Function Update Magnitude: 0.63695

Collected Steps per Second: 22,320.35895
Overall Steps per Second: 10,544.43280

Timestep Collection Time: 2.24127
Timestep Consumption Time: 2.50303
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.74430

Cumulative Model Updates: 72,672
Cumulative Timesteps: 606,139,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 606139382...
Checkpoint 606139382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 827.70785
Policy Entropy: 3.32330
Value Function Loss: 0.00373

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08847
Policy Update Magnitude: 0.52959
Value Function Update Magnitude: 0.62748

Collected Steps per Second: 22,263.93984
Overall Steps per Second: 10,472.38485

Timestep Collection Time: 2.24605
Timestep Consumption Time: 2.52898
PPO Batch Consumption Time: 0.29639
Total Iteration Time: 4.77503

Cumulative Model Updates: 72,678
Cumulative Timesteps: 606,189,388

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469.85416
Policy Entropy: 3.32212
Value Function Loss: 0.00384

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07569
Policy Update Magnitude: 0.53493
Value Function Update Magnitude: 0.65931

Collected Steps per Second: 22,678.43283
Overall Steps per Second: 10,601.86281

Timestep Collection Time: 2.20544
Timestep Consumption Time: 2.51222
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.71766

Cumulative Model Updates: 72,684
Cumulative Timesteps: 606,239,404

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 606239404...
Checkpoint 606239404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.75914
Policy Entropy: 3.31129
Value Function Loss: 0.00405

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07810
Policy Update Magnitude: 0.54630
Value Function Update Magnitude: 0.69182

Collected Steps per Second: 22,402.76009
Overall Steps per Second: 10,478.90134

Timestep Collection Time: 2.23205
Timestep Consumption Time: 2.53983
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.77187

Cumulative Model Updates: 72,690
Cumulative Timesteps: 606,289,408

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 965.41989
Policy Entropy: 3.31372
Value Function Loss: 0.00390

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08677
Policy Update Magnitude: 0.54955
Value Function Update Magnitude: 0.69989

Collected Steps per Second: 22,369.23425
Overall Steps per Second: 10,459.36940

Timestep Collection Time: 2.23566
Timestep Consumption Time: 2.54570
PPO Batch Consumption Time: 0.29783
Total Iteration Time: 4.78136

Cumulative Model Updates: 72,696
Cumulative Timesteps: 606,339,418

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 606339418...
Checkpoint 606339418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.76793
Policy Entropy: 3.31965
Value Function Loss: 0.00402

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.07877
Policy Update Magnitude: 0.54843
Value Function Update Magnitude: 0.68934

Collected Steps per Second: 22,755.15885
Overall Steps per Second: 10,581.87041

Timestep Collection Time: 2.19766
Timestep Consumption Time: 2.52816
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.72582

Cumulative Model Updates: 72,702
Cumulative Timesteps: 606,389,426

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 885.25144
Policy Entropy: 3.30903
Value Function Loss: 0.00394

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08212
Policy Update Magnitude: 0.54219
Value Function Update Magnitude: 0.68043

Collected Steps per Second: 22,820.03833
Overall Steps per Second: 10,813.73555

Timestep Collection Time: 2.19211
Timestep Consumption Time: 2.43386
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.62597

Cumulative Model Updates: 72,708
Cumulative Timesteps: 606,439,450

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 606439450...
Checkpoint 606439450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 908.26832
Policy Entropy: 3.29249
Value Function Loss: 0.00393

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09709
Policy Update Magnitude: 0.54306
Value Function Update Magnitude: 0.66745

Collected Steps per Second: 23,030.06787
Overall Steps per Second: 10,735.78912

Timestep Collection Time: 2.17107
Timestep Consumption Time: 2.48624
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.65732

Cumulative Model Updates: 72,714
Cumulative Timesteps: 606,489,450

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691.41966
Policy Entropy: 3.28583
Value Function Loss: 0.00409

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10733
Policy Update Magnitude: 0.54848
Value Function Update Magnitude: 0.67262

Collected Steps per Second: 22,816.62920
Overall Steps per Second: 10,828.71733

Timestep Collection Time: 2.19191
Timestep Consumption Time: 2.42655
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.61846

Cumulative Model Updates: 72,720
Cumulative Timesteps: 606,539,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 606539462...
Checkpoint 606539462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 735.10001
Policy Entropy: 3.27171
Value Function Loss: 0.00392

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11215
Policy Update Magnitude: 0.55333
Value Function Update Magnitude: 0.67681

Collected Steps per Second: 22,816.13076
Overall Steps per Second: 10,722.29337

Timestep Collection Time: 2.19275
Timestep Consumption Time: 2.47323
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.66598

Cumulative Model Updates: 72,726
Cumulative Timesteps: 606,589,492

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.84151
Policy Entropy: 3.28591
Value Function Loss: 0.00392

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10902
Policy Update Magnitude: 0.55132
Value Function Update Magnitude: 0.66745

Collected Steps per Second: 22,417.48993
Overall Steps per Second: 10,613.74990

Timestep Collection Time: 2.23174
Timestep Consumption Time: 2.48196
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.71370

Cumulative Model Updates: 72,732
Cumulative Timesteps: 606,639,522

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 606639522...
Checkpoint 606639522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 829.84906
Policy Entropy: 3.27235
Value Function Loss: 0.00388

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09427
Policy Update Magnitude: 0.53918
Value Function Update Magnitude: 0.66809

Collected Steps per Second: 22,448.98619
Overall Steps per Second: 10,643.66894

Timestep Collection Time: 2.22798
Timestep Consumption Time: 2.47115
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.69913

Cumulative Model Updates: 72,738
Cumulative Timesteps: 606,689,538

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.88506
Policy Entropy: 3.28294
Value Function Loss: 0.00394

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08194
Policy Update Magnitude: 0.53909
Value Function Update Magnitude: 0.66775

Collected Steps per Second: 22,561.71934
Overall Steps per Second: 10,767.00305

Timestep Collection Time: 2.21738
Timestep Consumption Time: 2.42903
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.64642

Cumulative Model Updates: 72,744
Cumulative Timesteps: 606,739,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 606739566...
Checkpoint 606739566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.05748
Policy Entropy: 3.26695
Value Function Loss: 0.00397

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10308
Policy Update Magnitude: 0.54823
Value Function Update Magnitude: 0.68067

Collected Steps per Second: 22,556.79631
Overall Steps per Second: 10,634.64445

Timestep Collection Time: 2.21672
Timestep Consumption Time: 2.48509
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.70180

Cumulative Model Updates: 72,750
Cumulative Timesteps: 606,789,568

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.11708
Policy Entropy: 3.26833
Value Function Loss: 0.00388

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.55334
Value Function Update Magnitude: 0.68271

Collected Steps per Second: 22,842.74304
Overall Steps per Second: 10,796.42860

Timestep Collection Time: 2.19098
Timestep Consumption Time: 2.44463
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.63561

Cumulative Model Updates: 72,756
Cumulative Timesteps: 606,839,616

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 606839616...
Checkpoint 606839616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698.40053
Policy Entropy: 3.28126
Value Function Loss: 0.00370

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11869
Policy Update Magnitude: 0.54465
Value Function Update Magnitude: 0.66486

Collected Steps per Second: 22,720.67780
Overall Steps per Second: 10,758.55910

Timestep Collection Time: 2.20073
Timestep Consumption Time: 2.44692
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.64765

Cumulative Model Updates: 72,762
Cumulative Timesteps: 606,889,618

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.71354
Policy Entropy: 3.30358
Value Function Loss: 0.00387

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09331
Policy Update Magnitude: 0.54182
Value Function Update Magnitude: 0.65960

Collected Steps per Second: 22,498.84720
Overall Steps per Second: 10,640.42032

Timestep Collection Time: 2.22349
Timestep Consumption Time: 2.47801
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.70151

Cumulative Model Updates: 72,768
Cumulative Timesteps: 606,939,644

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 606939644...
Checkpoint 606939644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706.76957
Policy Entropy: 3.29466
Value Function Loss: 0.00389

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08183
Policy Update Magnitude: 0.55251
Value Function Update Magnitude: 0.66878

Collected Steps per Second: 22,664.04015
Overall Steps per Second: 10,802.54593

Timestep Collection Time: 2.20693
Timestep Consumption Time: 2.42327
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.63020

Cumulative Model Updates: 72,774
Cumulative Timesteps: 606,989,662

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,607.81962
Policy Entropy: 3.28374
Value Function Loss: 0.00391

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09291
Policy Update Magnitude: 0.55990
Value Function Update Magnitude: 0.65844

Collected Steps per Second: 22,108.13716
Overall Steps per Second: 10,532.18199

Timestep Collection Time: 2.26242
Timestep Consumption Time: 2.48664
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.74906

Cumulative Model Updates: 72,780
Cumulative Timesteps: 607,039,680

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 607039680...
Checkpoint 607039680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.65461
Policy Entropy: 3.28831
Value Function Loss: 0.00395

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08009
Policy Update Magnitude: 0.55213
Value Function Update Magnitude: 0.63917

Collected Steps per Second: 22,936.38658
Overall Steps per Second: 10,670.02879

Timestep Collection Time: 2.18108
Timestep Consumption Time: 2.50738
PPO Batch Consumption Time: 0.29833
Total Iteration Time: 4.68846

Cumulative Model Updates: 72,786
Cumulative Timesteps: 607,089,706

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.56003
Policy Entropy: 3.29223
Value Function Loss: 0.00395

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07255
Policy Update Magnitude: 0.54791
Value Function Update Magnitude: 0.62795

Collected Steps per Second: 22,397.73649
Overall Steps per Second: 10,608.61403

Timestep Collection Time: 2.23299
Timestep Consumption Time: 2.48148
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.71447

Cumulative Model Updates: 72,792
Cumulative Timesteps: 607,139,720

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 607139720...
Checkpoint 607139720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532.88574
Policy Entropy: 3.28297
Value Function Loss: 0.00411

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08542
Policy Update Magnitude: 0.55174
Value Function Update Magnitude: 0.63003

Collected Steps per Second: 22,550.64033
Overall Steps per Second: 10,650.05644

Timestep Collection Time: 2.21838
Timestep Consumption Time: 2.47887
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.69725

Cumulative Model Updates: 72,798
Cumulative Timesteps: 607,189,746

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 919.80774
Policy Entropy: 3.28662
Value Function Loss: 0.00390

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.55149
Value Function Update Magnitude: 0.63285

Collected Steps per Second: 22,719.36009
Overall Steps per Second: 10,752.90286

Timestep Collection Time: 2.20217
Timestep Consumption Time: 2.45071
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.65288

Cumulative Model Updates: 72,804
Cumulative Timesteps: 607,239,778

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 607239778...
Checkpoint 607239778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.48542
Policy Entropy: 3.28899
Value Function Loss: 0.00383

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07763
Policy Update Magnitude: 0.54440
Value Function Update Magnitude: 0.64627

Collected Steps per Second: 22,333.98294
Overall Steps per Second: 10,604.24185

Timestep Collection Time: 2.23937
Timestep Consumption Time: 2.47705
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.71641

Cumulative Model Updates: 72,810
Cumulative Timesteps: 607,289,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.22321
Policy Entropy: 3.28288
Value Function Loss: 0.00368

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08039
Policy Update Magnitude: 0.54218
Value Function Update Magnitude: 0.65754

Collected Steps per Second: 22,433.16281
Overall Steps per Second: 10,611.64499

Timestep Collection Time: 2.23018
Timestep Consumption Time: 2.48445
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.71463

Cumulative Model Updates: 72,816
Cumulative Timesteps: 607,339,822

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 607339822...
Checkpoint 607339822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.18597
Policy Entropy: 3.27689
Value Function Loss: 0.00390

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08655
Policy Update Magnitude: 0.54668
Value Function Update Magnitude: 0.64763

Collected Steps per Second: 22,534.60295
Overall Steps per Second: 10,583.22793

Timestep Collection Time: 2.22085
Timestep Consumption Time: 2.50795
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.72880

Cumulative Model Updates: 72,822
Cumulative Timesteps: 607,389,868

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 937.99223
Policy Entropy: 3.28077
Value Function Loss: 0.00390

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10768
Policy Update Magnitude: 0.54911
Value Function Update Magnitude: 0.63672

Collected Steps per Second: 22,813.88354
Overall Steps per Second: 10,741.03935

Timestep Collection Time: 2.19191
Timestep Consumption Time: 2.46369
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.65560

Cumulative Model Updates: 72,828
Cumulative Timesteps: 607,439,874

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 607439874...
Checkpoint 607439874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 881.96923
Policy Entropy: 3.30471
Value Function Loss: 0.00387

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11081
Policy Update Magnitude: 0.54053
Value Function Update Magnitude: 0.63753

Collected Steps per Second: 22,644.09882
Overall Steps per Second: 10,711.19825

Timestep Collection Time: 2.20843
Timestep Consumption Time: 2.46032
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.66876

Cumulative Model Updates: 72,834
Cumulative Timesteps: 607,489,882

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.39155
Policy Entropy: 3.31379
Value Function Loss: 0.00403

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11598
Policy Update Magnitude: 0.53326
Value Function Update Magnitude: 0.62984

Collected Steps per Second: 22,755.01078
Overall Steps per Second: 10,794.44299

Timestep Collection Time: 2.19767
Timestep Consumption Time: 2.43508
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.63275

Cumulative Model Updates: 72,840
Cumulative Timesteps: 607,539,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 607539890...
Checkpoint 607539890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.45191
Policy Entropy: 3.31929
Value Function Loss: 0.00398

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09069
Policy Update Magnitude: 0.53769
Value Function Update Magnitude: 0.63800

Collected Steps per Second: 22,780.86657
Overall Steps per Second: 10,756.33170

Timestep Collection Time: 2.19509
Timestep Consumption Time: 2.45390
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.64898

Cumulative Model Updates: 72,846
Cumulative Timesteps: 607,589,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684.84643
Policy Entropy: 3.32596
Value Function Loss: 0.00389

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09692
Policy Update Magnitude: 0.53736
Value Function Update Magnitude: 0.63407

Collected Steps per Second: 22,696.59763
Overall Steps per Second: 10,684.00904

Timestep Collection Time: 2.20315
Timestep Consumption Time: 2.47712
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.68027

Cumulative Model Updates: 72,852
Cumulative Timesteps: 607,639,900

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 607639900...
Checkpoint 607639900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 776.41309
Policy Entropy: 3.32355
Value Function Loss: 0.00383

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08762
Policy Update Magnitude: 0.52686
Value Function Update Magnitude: 0.62074

Collected Steps per Second: 23,047.05967
Overall Steps per Second: 10,851.49962

Timestep Collection Time: 2.16965
Timestep Consumption Time: 2.43838
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.60803

Cumulative Model Updates: 72,858
Cumulative Timesteps: 607,689,904

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.63934
Policy Entropy: 3.32655
Value Function Loss: 0.00377

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09762
Policy Update Magnitude: 0.52318
Value Function Update Magnitude: 0.61597

Collected Steps per Second: 22,029.21095
Overall Steps per Second: 10,482.29694

Timestep Collection Time: 2.27062
Timestep Consumption Time: 2.50123
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.77185

Cumulative Model Updates: 72,864
Cumulative Timesteps: 607,739,924

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 607739924...
Checkpoint 607739924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,690.14900
Policy Entropy: 3.31509
Value Function Loss: 0.00384

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09965
Policy Update Magnitude: 0.51887
Value Function Update Magnitude: 0.62526

Collected Steps per Second: 22,354.81701
Overall Steps per Second: 10,614.51958

Timestep Collection Time: 2.23800
Timestep Consumption Time: 2.47536
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.71336

Cumulative Model Updates: 72,870
Cumulative Timesteps: 607,789,954

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 810.12349
Policy Entropy: 3.32540
Value Function Loss: 0.00388

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09899
Policy Update Magnitude: 0.52639
Value Function Update Magnitude: 0.62006

Collected Steps per Second: 22,345.95335
Overall Steps per Second: 10,600.95718

Timestep Collection Time: 2.23808
Timestep Consumption Time: 2.47961
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.71769

Cumulative Model Updates: 72,876
Cumulative Timesteps: 607,839,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 607839966...
Checkpoint 607839966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 888.46644
Policy Entropy: 3.33445
Value Function Loss: 0.00396

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09372
Policy Update Magnitude: 0.53103
Value Function Update Magnitude: 0.64309

Collected Steps per Second: 22,308.99379
Overall Steps per Second: 10,525.71310

Timestep Collection Time: 2.24223
Timestep Consumption Time: 2.51013
PPO Batch Consumption Time: 0.29764
Total Iteration Time: 4.75236

Cumulative Model Updates: 72,882
Cumulative Timesteps: 607,889,988

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.20469
Policy Entropy: 3.33907
Value Function Loss: 0.00380

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10431
Policy Update Magnitude: 0.52680
Value Function Update Magnitude: 0.66228

Collected Steps per Second: 22,953.13896
Overall Steps per Second: 10,746.24821

Timestep Collection Time: 2.17887
Timestep Consumption Time: 2.47503
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.65390

Cumulative Model Updates: 72,888
Cumulative Timesteps: 607,940,000

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 607940000...
Checkpoint 607940000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.07564
Policy Entropy: 3.33215
Value Function Loss: 0.00362

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10749
Policy Update Magnitude: 0.52088
Value Function Update Magnitude: 0.65125

Collected Steps per Second: 22,456.23248
Overall Steps per Second: 10,712.88563

Timestep Collection Time: 2.22718
Timestep Consumption Time: 2.44141
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.66858

Cumulative Model Updates: 72,894
Cumulative Timesteps: 607,990,014

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,426.70130
Policy Entropy: 3.34162
Value Function Loss: 0.00376

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09254
Policy Update Magnitude: 0.51571
Value Function Update Magnitude: 0.64462

Collected Steps per Second: 22,895.80751
Overall Steps per Second: 10,835.76437

Timestep Collection Time: 2.18494
Timestep Consumption Time: 2.43181
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.61675

Cumulative Model Updates: 72,900
Cumulative Timesteps: 608,040,040

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 608040040...
Checkpoint 608040040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.54235
Policy Entropy: 3.33535
Value Function Loss: 0.00382

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08269
Policy Update Magnitude: 0.52368
Value Function Update Magnitude: 0.64880

Collected Steps per Second: 22,559.21388
Overall Steps per Second: 10,795.13873

Timestep Collection Time: 2.21736
Timestep Consumption Time: 2.41639
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.63375

Cumulative Model Updates: 72,906
Cumulative Timesteps: 608,090,062

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.42001
Policy Entropy: 3.32574
Value Function Loss: 0.00388

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09171
Policy Update Magnitude: 0.52967
Value Function Update Magnitude: 0.63362

Collected Steps per Second: 22,637.41808
Overall Steps per Second: 10,771.68573

Timestep Collection Time: 2.20935
Timestep Consumption Time: 2.43375
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.64310

Cumulative Model Updates: 72,912
Cumulative Timesteps: 608,140,076

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 608140076...
Checkpoint 608140076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,894.28471
Policy Entropy: 3.32382
Value Function Loss: 0.00374

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09383
Policy Update Magnitude: 0.52215
Value Function Update Magnitude: 0.62594

Collected Steps per Second: 22,692.91908
Overall Steps per Second: 10,715.88029

Timestep Collection Time: 2.20368
Timestep Consumption Time: 2.46304
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.66672

Cumulative Model Updates: 72,918
Cumulative Timesteps: 608,190,084

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 831.64888
Policy Entropy: 3.32095
Value Function Loss: 0.00375

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08068
Policy Update Magnitude: 0.52549
Value Function Update Magnitude: 0.63551

Collected Steps per Second: 22,093.60561
Overall Steps per Second: 10,483.96457

Timestep Collection Time: 2.26446
Timestep Consumption Time: 2.50759
PPO Batch Consumption Time: 0.29700
Total Iteration Time: 4.77205

Cumulative Model Updates: 72,924
Cumulative Timesteps: 608,240,114

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 608240114...
Checkpoint 608240114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.71100
Policy Entropy: 3.32295
Value Function Loss: 0.00369

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07342
Policy Update Magnitude: 0.52880
Value Function Update Magnitude: 0.63454

Collected Steps per Second: 22,261.48742
Overall Steps per Second: 10,623.03932

Timestep Collection Time: 2.24666
Timestep Consumption Time: 2.46141
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.70807

Cumulative Model Updates: 72,930
Cumulative Timesteps: 608,290,128

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.51626
Policy Entropy: 3.31663
Value Function Loss: 0.00367

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07927
Policy Update Magnitude: 0.52284
Value Function Update Magnitude: 0.63502

Collected Steps per Second: 22,434.75953
Overall Steps per Second: 10,631.01550

Timestep Collection Time: 2.22913
Timestep Consumption Time: 2.47503
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.70416

Cumulative Model Updates: 72,936
Cumulative Timesteps: 608,340,138

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 608340138...
Checkpoint 608340138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680.43653
Policy Entropy: 3.30341
Value Function Loss: 0.00386

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09080
Policy Update Magnitude: 0.52481
Value Function Update Magnitude: 0.62401

Collected Steps per Second: 22,217.31229
Overall Steps per Second: 10,514.65887

Timestep Collection Time: 2.25122
Timestep Consumption Time: 2.50557
PPO Batch Consumption Time: 0.29495
Total Iteration Time: 4.75679

Cumulative Model Updates: 72,942
Cumulative Timesteps: 608,390,154

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.13092
Policy Entropy: 3.30198
Value Function Loss: 0.00381

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08707
Policy Update Magnitude: 0.53300
Value Function Update Magnitude: 0.62196

Collected Steps per Second: 22,586.23039
Overall Steps per Second: 10,765.02386

Timestep Collection Time: 2.21471
Timestep Consumption Time: 2.43200
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.64672

Cumulative Model Updates: 72,948
Cumulative Timesteps: 608,440,176

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 608440176...
Checkpoint 608440176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 812.22992
Policy Entropy: 3.28514
Value Function Loss: 0.00383

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.53352
Value Function Update Magnitude: 0.63965

Collected Steps per Second: 22,815.55919
Overall Steps per Second: 10,777.26561

Timestep Collection Time: 2.19157
Timestep Consumption Time: 2.44801
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.63958

Cumulative Model Updates: 72,954
Cumulative Timesteps: 608,490,178

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.01789
Policy Entropy: 3.30192
Value Function Loss: 0.00365

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09236
Policy Update Magnitude: 0.53264
Value Function Update Magnitude: 0.63591

Collected Steps per Second: 22,899.84884
Overall Steps per Second: 10,785.63414

Timestep Collection Time: 2.18360
Timestep Consumption Time: 2.45257
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.63617

Cumulative Model Updates: 72,960
Cumulative Timesteps: 608,540,182

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 608540182...
Checkpoint 608540182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 766.29576
Policy Entropy: 3.30078
Value Function Loss: 0.00366

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.52806
Value Function Update Magnitude: 0.63312

Collected Steps per Second: 21,859.66169
Overall Steps per Second: 10,420.44936

Timestep Collection Time: 2.28741
Timestep Consumption Time: 2.51104
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.79845

Cumulative Model Updates: 72,966
Cumulative Timesteps: 608,590,184

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.27847
Policy Entropy: 3.31166
Value Function Loss: 0.00352

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07805
Policy Update Magnitude: 0.52354
Value Function Update Magnitude: 0.64983

Collected Steps per Second: 22,345.80663
Overall Steps per Second: 10,685.04910

Timestep Collection Time: 2.23827
Timestep Consumption Time: 2.44266
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.68093

Cumulative Model Updates: 72,972
Cumulative Timesteps: 608,640,200

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 608640200...
Checkpoint 608640200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750.68997
Policy Entropy: 3.31433
Value Function Loss: 0.00354

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09403
Policy Update Magnitude: 0.52314
Value Function Update Magnitude: 0.62534

Collected Steps per Second: 22,244.62998
Overall Steps per Second: 10,706.81121

Timestep Collection Time: 2.24773
Timestep Consumption Time: 2.42219
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.66992

Cumulative Model Updates: 72,978
Cumulative Timesteps: 608,690,200

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.21775
Policy Entropy: 3.31048
Value Function Loss: 0.00366

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09453
Policy Update Magnitude: 0.52997
Value Function Update Magnitude: 0.61333

Collected Steps per Second: 22,168.26860
Overall Steps per Second: 10,455.86505

Timestep Collection Time: 2.25548
Timestep Consumption Time: 2.52653
PPO Batch Consumption Time: 0.29805
Total Iteration Time: 4.78201

Cumulative Model Updates: 72,984
Cumulative Timesteps: 608,740,200

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 608740200...
Checkpoint 608740200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631.96603
Policy Entropy: 3.30886
Value Function Loss: 0.00382

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07498
Policy Update Magnitude: 0.52947
Value Function Update Magnitude: 0.61556

Collected Steps per Second: 22,723.90344
Overall Steps per Second: 10,724.95125

Timestep Collection Time: 2.20103
Timestep Consumption Time: 2.46249
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.66352

Cumulative Model Updates: 72,990
Cumulative Timesteps: 608,790,216

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 947.53887
Policy Entropy: 3.30130
Value Function Loss: 0.00403

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08551
Policy Update Magnitude: 0.53740
Value Function Update Magnitude: 0.60756

Collected Steps per Second: 22,325.41250
Overall Steps per Second: 10,814.52376

Timestep Collection Time: 2.24059
Timestep Consumption Time: 2.38486
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.62545

Cumulative Model Updates: 72,996
Cumulative Timesteps: 608,840,238

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 608840238...
Checkpoint 608840238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696.00963
Policy Entropy: 3.30022
Value Function Loss: 0.00399

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10428
Policy Update Magnitude: 0.54216
Value Function Update Magnitude: 0.61345

Collected Steps per Second: 21,865.27310
Overall Steps per Second: 10,618.44883

Timestep Collection Time: 2.28673
Timestep Consumption Time: 2.42205
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.70879

Cumulative Model Updates: 73,002
Cumulative Timesteps: 608,890,238

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 813.03862
Policy Entropy: 3.32321
Value Function Loss: 0.00383

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10575
Policy Update Magnitude: 0.53845
Value Function Update Magnitude: 0.62851

Collected Steps per Second: 22,168.23684
Overall Steps per Second: 10,680.99294

Timestep Collection Time: 2.25674
Timestep Consumption Time: 2.42709
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.68383

Cumulative Model Updates: 73,008
Cumulative Timesteps: 608,940,266

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 608940266...
Checkpoint 608940266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.09699
Policy Entropy: 3.32451
Value Function Loss: 0.00372

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09316
Policy Update Magnitude: 0.53912
Value Function Update Magnitude: 0.61463

Collected Steps per Second: 22,281.78999
Overall Steps per Second: 10,812.30161

Timestep Collection Time: 2.24506
Timestep Consumption Time: 2.38152
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.62658

Cumulative Model Updates: 73,014
Cumulative Timesteps: 608,990,290

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.32509
Policy Entropy: 3.34339
Value Function Loss: 0.00375

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09862
Policy Update Magnitude: 0.53379
Value Function Update Magnitude: 0.60223

Collected Steps per Second: 22,151.82920
Overall Steps per Second: 10,644.38822

Timestep Collection Time: 2.25742
Timestep Consumption Time: 2.44045
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.69787

Cumulative Model Updates: 73,020
Cumulative Timesteps: 609,040,296

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 609040296...
Checkpoint 609040296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 717.49072
Policy Entropy: 3.32514
Value Function Loss: 0.00385

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10489
Policy Update Magnitude: 0.53703
Value Function Update Magnitude: 0.60794

Collected Steps per Second: 22,445.61144
Overall Steps per Second: 10,510.24990

Timestep Collection Time: 2.22868
Timestep Consumption Time: 2.53087
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.75954

Cumulative Model Updates: 73,026
Cumulative Timesteps: 609,090,320

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 872.03945
Policy Entropy: 3.33298
Value Function Loss: 0.00373

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10952
Policy Update Magnitude: 0.54304
Value Function Update Magnitude: 0.60236

Collected Steps per Second: 22,874.91889
Overall Steps per Second: 10,647.90704

Timestep Collection Time: 2.18580
Timestep Consumption Time: 2.50996
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.69576

Cumulative Model Updates: 73,032
Cumulative Timesteps: 609,140,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 609140320...
Checkpoint 609140320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.17793
Policy Entropy: 3.31738
Value Function Loss: 0.00372

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10724
Policy Update Magnitude: 0.53077
Value Function Update Magnitude: 0.60031

Collected Steps per Second: 22,329.99799
Overall Steps per Second: 10,529.34431

Timestep Collection Time: 2.23959
Timestep Consumption Time: 2.51000
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.74958

Cumulative Model Updates: 73,038
Cumulative Timesteps: 609,190,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 916.85890
Policy Entropy: 3.32441
Value Function Loss: 0.00368

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11259
Policy Update Magnitude: 0.52817
Value Function Update Magnitude: 0.60765

Collected Steps per Second: 22,580.62710
Overall Steps per Second: 10,588.13887

Timestep Collection Time: 2.21455
Timestep Consumption Time: 2.50828
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.72283

Cumulative Model Updates: 73,044
Cumulative Timesteps: 609,240,336

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 609240336...
Checkpoint 609240336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667.62021
Policy Entropy: 3.32434
Value Function Loss: 0.00381

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.52923
Value Function Update Magnitude: 0.62647

Collected Steps per Second: 22,678.88323
Overall Steps per Second: 10,558.55998

Timestep Collection Time: 2.20540
Timestep Consumption Time: 2.53161
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.73701

Cumulative Model Updates: 73,050
Cumulative Timesteps: 609,290,352

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 814.74372
Policy Entropy: 3.32587
Value Function Loss: 0.00396

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09391
Policy Update Magnitude: 0.54722
Value Function Update Magnitude: 0.62878

Collected Steps per Second: 23,172.31965
Overall Steps per Second: 10,710.01848

Timestep Collection Time: 2.15896
Timestep Consumption Time: 2.51219
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.67114

Cumulative Model Updates: 73,056
Cumulative Timesteps: 609,340,380

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 609340380...
Checkpoint 609340380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 871.53287
Policy Entropy: 3.32365
Value Function Loss: 0.00419

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08965
Policy Update Magnitude: 0.55450
Value Function Update Magnitude: 0.62108

Collected Steps per Second: 22,775.69218
Overall Steps per Second: 10,704.95257

Timestep Collection Time: 2.19559
Timestep Consumption Time: 2.47571
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.67130

Cumulative Model Updates: 73,062
Cumulative Timesteps: 609,390,386

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710.84389
Policy Entropy: 3.32426
Value Function Loss: 0.00421

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09206
Policy Update Magnitude: 0.56192
Value Function Update Magnitude: 0.63504

Collected Steps per Second: 22,868.49145
Overall Steps per Second: 10,682.13811

Timestep Collection Time: 2.18650
Timestep Consumption Time: 2.49440
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.68090

Cumulative Model Updates: 73,068
Cumulative Timesteps: 609,440,388

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 609440388...
Checkpoint 609440388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 833.51614
Policy Entropy: 3.32057
Value Function Loss: 0.00397

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08443
Policy Update Magnitude: 0.55602
Value Function Update Magnitude: 0.63714

Collected Steps per Second: 22,817.41584
Overall Steps per Second: 10,773.26553

Timestep Collection Time: 2.19245
Timestep Consumption Time: 2.45108
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.64353

Cumulative Model Updates: 73,074
Cumulative Timesteps: 609,490,414

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 883.02642
Policy Entropy: 3.32498
Value Function Loss: 0.00412

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08989
Policy Update Magnitude: 0.54948
Value Function Update Magnitude: 0.60376

Collected Steps per Second: 22,901.95984
Overall Steps per Second: 10,640.99069

Timestep Collection Time: 2.18453
Timestep Consumption Time: 2.51710
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.70163

Cumulative Model Updates: 73,080
Cumulative Timesteps: 609,540,444

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 609540444...
Checkpoint 609540444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605.17425
Policy Entropy: 3.31943
Value Function Loss: 0.00412

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09103
Policy Update Magnitude: 0.54495
Value Function Update Magnitude: 0.58751

Collected Steps per Second: 22,534.16716
Overall Steps per Second: 10,553.23736

Timestep Collection Time: 2.21983
Timestep Consumption Time: 2.52014
PPO Batch Consumption Time: 0.29495
Total Iteration Time: 4.73997

Cumulative Model Updates: 73,086
Cumulative Timesteps: 609,590,466

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783.04936
Policy Entropy: 3.31356
Value Function Loss: 0.00415

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07541
Policy Update Magnitude: 0.54222
Value Function Update Magnitude: 0.58908

Collected Steps per Second: 22,538.77481
Overall Steps per Second: 10,564.80794

Timestep Collection Time: 2.21840
Timestep Consumption Time: 2.51429
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.73269

Cumulative Model Updates: 73,092
Cumulative Timesteps: 609,640,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 609640466...
Checkpoint 609640466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 834.62704
Policy Entropy: 3.32278
Value Function Loss: 0.00397

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08448
Policy Update Magnitude: 0.54561
Value Function Update Magnitude: 0.58326

Collected Steps per Second: 21,871.96785
Overall Steps per Second: 10,549.56432

Timestep Collection Time: 2.28612
Timestep Consumption Time: 2.45360
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.73972

Cumulative Model Updates: 73,098
Cumulative Timesteps: 609,690,468

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.91690
Policy Entropy: 3.31800
Value Function Loss: 0.00406

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08511
Policy Update Magnitude: 0.54571
Value Function Update Magnitude: 0.57965

Collected Steps per Second: 22,705.79528
Overall Steps per Second: 10,794.36326

Timestep Collection Time: 2.20252
Timestep Consumption Time: 2.43045
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.63297

Cumulative Model Updates: 73,104
Cumulative Timesteps: 609,740,478

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 609740478...
Checkpoint 609740478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.72464
Policy Entropy: 3.30062
Value Function Loss: 0.00413

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07986
Policy Update Magnitude: 0.55419
Value Function Update Magnitude: 0.58573

Collected Steps per Second: 22,271.88054
Overall Steps per Second: 10,702.50671

Timestep Collection Time: 2.24570
Timestep Consumption Time: 2.42760
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.67330

Cumulative Model Updates: 73,110
Cumulative Timesteps: 609,790,494

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.76669
Policy Entropy: 3.28531
Value Function Loss: 0.00434

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.56969
Value Function Update Magnitude: 0.60741

Collected Steps per Second: 23,000.23088
Overall Steps per Second: 10,672.98244

Timestep Collection Time: 2.17433
Timestep Consumption Time: 2.51134
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.68566

Cumulative Model Updates: 73,116
Cumulative Timesteps: 609,840,504

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 609840504...
Checkpoint 609840504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 953.29757
Policy Entropy: 3.29228
Value Function Loss: 0.00429

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11297
Policy Update Magnitude: 0.57443
Value Function Update Magnitude: 0.62278

Collected Steps per Second: 22,671.33245
Overall Steps per Second: 10,709.89397

Timestep Collection Time: 2.20605
Timestep Consumption Time: 2.46384
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.66989

Cumulative Model Updates: 73,122
Cumulative Timesteps: 609,890,518

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 941.83707
Policy Entropy: 3.29467
Value Function Loss: 0.00413

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.55646
Value Function Update Magnitude: 0.61923

Collected Steps per Second: 23,207.07867
Overall Steps per Second: 10,655.72448

Timestep Collection Time: 2.15469
Timestep Consumption Time: 2.53800
PPO Batch Consumption Time: 0.29710
Total Iteration Time: 4.69269

Cumulative Model Updates: 73,128
Cumulative Timesteps: 609,940,522

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 609940522...
Checkpoint 609940522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 721.39933
Policy Entropy: 3.31771
Value Function Loss: 0.00403

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08727
Policy Update Magnitude: 0.53924
Value Function Update Magnitude: 0.60696

Collected Steps per Second: 22,903.13518
Overall Steps per Second: 10,634.21050

Timestep Collection Time: 2.18372
Timestep Consumption Time: 2.51940
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.70312

Cumulative Model Updates: 73,134
Cumulative Timesteps: 609,990,536

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 913.70776
Policy Entropy: 3.31745
Value Function Loss: 0.00396

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08710
Policy Update Magnitude: 0.53799
Value Function Update Magnitude: 0.60009

Collected Steps per Second: 23,026.68146
Overall Steps per Second: 10,851.05362

Timestep Collection Time: 2.17157
Timestep Consumption Time: 2.43665
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.60822

Cumulative Model Updates: 73,140
Cumulative Timesteps: 610,040,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 610040540...
Checkpoint 610040540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 980.62967
Policy Entropy: 3.30763
Value Function Loss: 0.00396

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08348
Policy Update Magnitude: 0.53522
Value Function Update Magnitude: 0.59788

Collected Steps per Second: 22,827.61175
Overall Steps per Second: 10,685.18692

Timestep Collection Time: 2.19182
Timestep Consumption Time: 2.49074
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.68256

Cumulative Model Updates: 73,146
Cumulative Timesteps: 610,090,574

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.16161
Policy Entropy: 3.31566
Value Function Loss: 0.00393

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07088
Policy Update Magnitude: 0.54073
Value Function Update Magnitude: 0.65290

Collected Steps per Second: 23,020.09830
Overall Steps per Second: 10,862.20423

Timestep Collection Time: 2.17314
Timestep Consumption Time: 2.43237
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.60551

Cumulative Model Updates: 73,152
Cumulative Timesteps: 610,140,600

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 610140600...
Checkpoint 610140600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648.60784
Policy Entropy: 3.30350
Value Function Loss: 0.00382

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07282
Policy Update Magnitude: 0.54858
Value Function Update Magnitude: 0.67350

Collected Steps per Second: 21,761.58839
Overall Steps per Second: 10,565.79025

Timestep Collection Time: 2.29763
Timestep Consumption Time: 2.43463
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.73225

Cumulative Model Updates: 73,158
Cumulative Timesteps: 610,190,600

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.63585
Policy Entropy: 3.31025
Value Function Loss: 0.00367

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.07951
Policy Update Magnitude: 0.54311
Value Function Update Magnitude: 0.65042

Collected Steps per Second: 22,804.14266
Overall Steps per Second: 10,689.20107

Timestep Collection Time: 2.19329
Timestep Consumption Time: 2.48583
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.67911

Cumulative Model Updates: 73,164
Cumulative Timesteps: 610,240,616

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 610240616...
Checkpoint 610240616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 983.79486
Policy Entropy: 3.30384
Value Function Loss: 0.00362

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09947
Policy Update Magnitude: 0.53104
Value Function Update Magnitude: 0.61303

Collected Steps per Second: 22,281.04728
Overall Steps per Second: 10,525.73090

Timestep Collection Time: 2.24451
Timestep Consumption Time: 2.50671
PPO Batch Consumption Time: 0.29598
Total Iteration Time: 4.75121

Cumulative Model Updates: 73,170
Cumulative Timesteps: 610,290,626

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.00716
Policy Entropy: 3.29540
Value Function Loss: 0.00369

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09732
Policy Update Magnitude: 0.53057
Value Function Update Magnitude: 0.59116

Collected Steps per Second: 22,454.10367
Overall Steps per Second: 10,589.72578

Timestep Collection Time: 2.22694
Timestep Consumption Time: 2.49499
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.72194

Cumulative Model Updates: 73,176
Cumulative Timesteps: 610,340,630

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 610340630...
Checkpoint 610340630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 841.88384
Policy Entropy: 3.29152
Value Function Loss: 0.00382

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10109
Policy Update Magnitude: 0.53263
Value Function Update Magnitude: 0.60127

Collected Steps per Second: 22,484.16073
Overall Steps per Second: 10,602.71283

Timestep Collection Time: 2.22397
Timestep Consumption Time: 2.49219
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.71615

Cumulative Model Updates: 73,182
Cumulative Timesteps: 610,390,634

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 824.44089
Policy Entropy: 3.28105
Value Function Loss: 0.00391

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09568
Policy Update Magnitude: 0.53209
Value Function Update Magnitude: 0.60642

Collected Steps per Second: 22,867.01562
Overall Steps per Second: 10,731.73557

Timestep Collection Time: 2.18761
Timestep Consumption Time: 2.47371
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.66131

Cumulative Model Updates: 73,188
Cumulative Timesteps: 610,440,658

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 610440658...
Checkpoint 610440658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,306.52178
Policy Entropy: 3.29250
Value Function Loss: 0.00394

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10286
Policy Update Magnitude: 0.53325
Value Function Update Magnitude: 0.62550

Collected Steps per Second: 21,115.01659
Overall Steps per Second: 10,232.92634

Timestep Collection Time: 2.36855
Timestep Consumption Time: 2.51881
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.88736

Cumulative Model Updates: 73,194
Cumulative Timesteps: 610,490,670

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 867.67964
Policy Entropy: 3.29781
Value Function Loss: 0.00407

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09877
Policy Update Magnitude: 0.53683
Value Function Update Magnitude: 0.64100

Collected Steps per Second: 22,525.66864
Overall Steps per Second: 10,589.18549

Timestep Collection Time: 2.21996
Timestep Consumption Time: 2.50241
PPO Batch Consumption Time: 0.29556
Total Iteration Time: 4.72237

Cumulative Model Updates: 73,200
Cumulative Timesteps: 610,540,676

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 610540676...
Checkpoint 610540676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464.05485
Policy Entropy: 3.29622
Value Function Loss: 0.00403

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10552
Policy Update Magnitude: 0.53623
Value Function Update Magnitude: 0.63017

Collected Steps per Second: 22,995.74539
Overall Steps per Second: 10,731.30942

Timestep Collection Time: 2.17449
Timestep Consumption Time: 2.48515
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.65964

Cumulative Model Updates: 73,206
Cumulative Timesteps: 610,590,680

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687.96957
Policy Entropy: 3.29696
Value Function Loss: 0.00405

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11436
Policy Update Magnitude: 0.54086
Value Function Update Magnitude: 0.60797

Collected Steps per Second: 22,666.31079
Overall Steps per Second: 10,730.33291

Timestep Collection Time: 2.20715
Timestep Consumption Time: 2.45514
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.66230

Cumulative Model Updates: 73,212
Cumulative Timesteps: 610,640,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 610640708...
Checkpoint 610640708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 774.25588
Policy Entropy: 3.27696
Value Function Loss: 0.00411

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10865
Policy Update Magnitude: 0.54078
Value Function Update Magnitude: 0.60993

Collected Steps per Second: 22,512.53766
Overall Steps per Second: 10,722.71884

Timestep Collection Time: 2.22161
Timestep Consumption Time: 2.44270
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 4.66430

Cumulative Model Updates: 73,218
Cumulative Timesteps: 610,690,722

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,379.61063
Policy Entropy: 3.26444
Value Function Loss: 0.00418

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08990
Policy Update Magnitude: 0.54730
Value Function Update Magnitude: 0.61335

Collected Steps per Second: 22,310.06430
Overall Steps per Second: 10,858.18463

Timestep Collection Time: 2.24132
Timestep Consumption Time: 2.36387
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.60519

Cumulative Model Updates: 73,224
Cumulative Timesteps: 610,740,726

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 610740726...
Checkpoint 610740726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 778.04032
Policy Entropy: 3.26333
Value Function Loss: 0.00406

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08940
Policy Update Magnitude: 0.54670
Value Function Update Magnitude: 0.61157

Collected Steps per Second: 21,732.69850
Overall Steps per Second: 10,637.72502

Timestep Collection Time: 2.30068
Timestep Consumption Time: 2.39957
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.70025

Cumulative Model Updates: 73,230
Cumulative Timesteps: 610,790,726

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.84369
Policy Entropy: 3.25769
Value Function Loss: 0.00410

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09557
Policy Update Magnitude: 0.54649
Value Function Update Magnitude: 0.61222

Collected Steps per Second: 21,350.01512
Overall Steps per Second: 10,475.46680

Timestep Collection Time: 2.34239
Timestep Consumption Time: 2.43162
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.77401

Cumulative Model Updates: 73,236
Cumulative Timesteps: 610,840,736

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 610840736...
Checkpoint 610840736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 900.78588
Policy Entropy: 3.27827
Value Function Loss: 0.00396

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08989
Policy Update Magnitude: 0.54857
Value Function Update Magnitude: 0.61347

Collected Steps per Second: 22,091.05642
Overall Steps per Second: 10,617.64923

Timestep Collection Time: 2.26417
Timestep Consumption Time: 2.44666
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.71084

Cumulative Model Updates: 73,242
Cumulative Timesteps: 610,890,754

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 956.44799
Policy Entropy: 3.26838
Value Function Loss: 0.00411

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09724
Policy Update Magnitude: 0.55296
Value Function Update Magnitude: 0.62064

Collected Steps per Second: 22,643.95088
Overall Steps per Second: 10,565.42806

Timestep Collection Time: 2.20871
Timestep Consumption Time: 2.52503
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.73374

Cumulative Model Updates: 73,248
Cumulative Timesteps: 610,940,768

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 610940768...
Checkpoint 610940768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 779.18739
Policy Entropy: 3.27250
Value Function Loss: 0.00399

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09374
Policy Update Magnitude: 0.55298
Value Function Update Magnitude: 0.62937

Collected Steps per Second: 22,179.08244
Overall Steps per Second: 10,567.82504

Timestep Collection Time: 2.25618
Timestep Consumption Time: 2.47895
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.73513

Cumulative Model Updates: 73,254
Cumulative Timesteps: 610,990,808

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744.97306
Policy Entropy: 3.25771
Value Function Loss: 0.00412

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.55079
Value Function Update Magnitude: 0.64320

Collected Steps per Second: 23,215.10008
Overall Steps per Second: 10,797.35733

Timestep Collection Time: 2.15394
Timestep Consumption Time: 2.47719
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.63113

Cumulative Model Updates: 73,260
Cumulative Timesteps: 611,040,812

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 611040812...
Checkpoint 611040812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.83141
Policy Entropy: 3.26501
Value Function Loss: 0.00425

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08870
Policy Update Magnitude: 0.55375
Value Function Update Magnitude: 0.66504

Collected Steps per Second: 22,453.08078
Overall Steps per Second: 10,684.37073

Timestep Collection Time: 2.22758
Timestep Consumption Time: 2.45365
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.68123

Cumulative Model Updates: 73,266
Cumulative Timesteps: 611,090,828

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,664.48322
Policy Entropy: 3.26520
Value Function Loss: 0.00411

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08632
Policy Update Magnitude: 0.55550
Value Function Update Magnitude: 0.66312

Collected Steps per Second: 22,738.31292
Overall Steps per Second: 10,581.24435

Timestep Collection Time: 2.19920
Timestep Consumption Time: 2.52671
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.72591

Cumulative Model Updates: 73,272
Cumulative Timesteps: 611,140,834

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 611140834...
Checkpoint 611140834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692.48619
Policy Entropy: 3.26758
Value Function Loss: 0.00405

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07832
Policy Update Magnitude: 0.55722
Value Function Update Magnitude: 0.65062

Collected Steps per Second: 22,852.31146
Overall Steps per Second: 10,629.86339

Timestep Collection Time: 2.18901
Timestep Consumption Time: 2.51697
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 4.70599

Cumulative Model Updates: 73,278
Cumulative Timesteps: 611,190,858

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.93293
Policy Entropy: 3.25715
Value Function Loss: 0.00407

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09915
Policy Update Magnitude: 0.55835
Value Function Update Magnitude: 0.64541

Collected Steps per Second: 22,704.68802
Overall Steps per Second: 10,775.56266

Timestep Collection Time: 2.20342
Timestep Consumption Time: 2.43931
PPO Batch Consumption Time: 0.28178
Total Iteration Time: 4.64273

Cumulative Model Updates: 73,284
Cumulative Timesteps: 611,240,886

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 611240886...
Checkpoint 611240886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.36558
Policy Entropy: 3.27944
Value Function Loss: 0.00410

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11329
Policy Update Magnitude: 0.55412
Value Function Update Magnitude: 0.64896

Collected Steps per Second: 22,369.59110
Overall Steps per Second: 10,651.67456

Timestep Collection Time: 2.23518
Timestep Consumption Time: 2.45892
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.69410

Cumulative Model Updates: 73,290
Cumulative Timesteps: 611,290,886

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644.69350
Policy Entropy: 3.26771
Value Function Loss: 0.00416

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10049
Policy Update Magnitude: 0.55782
Value Function Update Magnitude: 0.63942

Collected Steps per Second: 22,672.26708
Overall Steps per Second: 10,605.23607

Timestep Collection Time: 2.20622
Timestep Consumption Time: 2.51032
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.71654

Cumulative Model Updates: 73,296
Cumulative Timesteps: 611,340,906

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 611340906...
Checkpoint 611340906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635.16950
Policy Entropy: 3.26828
Value Function Loss: 0.00419

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09822
Policy Update Magnitude: 0.56646
Value Function Update Magnitude: 0.63487

Collected Steps per Second: 22,348.90145
Overall Steps per Second: 10,523.73036

Timestep Collection Time: 2.23751
Timestep Consumption Time: 2.51422
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.75174

Cumulative Model Updates: 73,302
Cumulative Timesteps: 611,390,912

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.47876
Policy Entropy: 3.27143
Value Function Loss: 0.00408

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08858
Policy Update Magnitude: 0.56209
Value Function Update Magnitude: 0.65412

Collected Steps per Second: 22,427.63881
Overall Steps per Second: 10,477.53540

Timestep Collection Time: 2.23073
Timestep Consumption Time: 2.54425
PPO Batch Consumption Time: 0.29745
Total Iteration Time: 4.77498

Cumulative Model Updates: 73,308
Cumulative Timesteps: 611,440,942

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 611440942...
Checkpoint 611440942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687.10270
Policy Entropy: 3.28517
Value Function Loss: 0.00405

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08428
Policy Update Magnitude: 0.56092
Value Function Update Magnitude: 0.68467

Collected Steps per Second: 22,191.81158
Overall Steps per Second: 10,634.77982

Timestep Collection Time: 2.25425
Timestep Consumption Time: 2.44974
PPO Batch Consumption Time: 0.28183
Total Iteration Time: 4.70400

Cumulative Model Updates: 73,314
Cumulative Timesteps: 611,490,968

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.31929
Policy Entropy: 3.27185
Value Function Loss: 0.00416

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09566
Policy Update Magnitude: 0.56282
Value Function Update Magnitude: 0.70302

Collected Steps per Second: 22,604.71495
Overall Steps per Second: 10,627.18248

Timestep Collection Time: 2.21237
Timestep Consumption Time: 2.49349
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.70586

Cumulative Model Updates: 73,320
Cumulative Timesteps: 611,540,978

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 611540978...
Checkpoint 611540978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 953.33449
Policy Entropy: 3.27996
Value Function Loss: 0.00423

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08571
Policy Update Magnitude: 0.56433
Value Function Update Magnitude: 0.68918

Collected Steps per Second: 22,383.42474
Overall Steps per Second: 10,608.01458

Timestep Collection Time: 2.23415
Timestep Consumption Time: 2.48002
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.71417

Cumulative Model Updates: 73,326
Cumulative Timesteps: 611,590,986

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 725.21723
Policy Entropy: 3.26942
Value Function Loss: 0.00434

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09127
Policy Update Magnitude: 0.56031
Value Function Update Magnitude: 0.66123

Collected Steps per Second: 22,799.79869
Overall Steps per Second: 10,751.88450

Timestep Collection Time: 2.19379
Timestep Consumption Time: 2.45823
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.65202

Cumulative Model Updates: 73,332
Cumulative Timesteps: 611,641,004

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 611641004...
Checkpoint 611641004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 984.24225
Policy Entropy: 3.28451
Value Function Loss: 0.00426

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08119
Policy Update Magnitude: 0.56134
Value Function Update Magnitude: 0.65378

Collected Steps per Second: 22,738.31810
Overall Steps per Second: 10,634.13164

Timestep Collection Time: 2.19981
Timestep Consumption Time: 2.50391
PPO Batch Consumption Time: 0.29816
Total Iteration Time: 4.70372

Cumulative Model Updates: 73,338
Cumulative Timesteps: 611,691,024

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.81709
Policy Entropy: 3.27836
Value Function Loss: 0.00424

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08595
Policy Update Magnitude: 0.54963
Value Function Update Magnitude: 0.65787

Collected Steps per Second: 22,930.89075
Overall Steps per Second: 10,802.73065

Timestep Collection Time: 2.18142
Timestep Consumption Time: 2.44907
PPO Batch Consumption Time: 0.28453
Total Iteration Time: 4.63050

Cumulative Model Updates: 73,344
Cumulative Timesteps: 611,741,046

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 611741046...
Checkpoint 611741046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 849.39140
Policy Entropy: 3.27742
Value Function Loss: 0.00403

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09328
Policy Update Magnitude: 0.54147
Value Function Update Magnitude: 0.66049

Collected Steps per Second: 22,617.54989
Overall Steps per Second: 10,800.63420

Timestep Collection Time: 2.21200
Timestep Consumption Time: 2.42014
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.63214

Cumulative Model Updates: 73,350
Cumulative Timesteps: 611,791,076

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.70841
Policy Entropy: 3.27135
Value Function Loss: 0.00392

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08485
Policy Update Magnitude: 0.54137
Value Function Update Magnitude: 0.66659

Collected Steps per Second: 22,650.38804
Overall Steps per Second: 10,804.88389

Timestep Collection Time: 2.20747
Timestep Consumption Time: 2.42007
PPO Batch Consumption Time: 0.28178
Total Iteration Time: 4.62754

Cumulative Model Updates: 73,356
Cumulative Timesteps: 611,841,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 611841076...
Checkpoint 611841076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.99935
Policy Entropy: 3.27233
Value Function Loss: 0.00386

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.54310
Value Function Update Magnitude: 0.65311

Collected Steps per Second: 22,645.35904
Overall Steps per Second: 10,684.35051

Timestep Collection Time: 2.20831
Timestep Consumption Time: 2.47218
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.68049

Cumulative Model Updates: 73,362
Cumulative Timesteps: 611,891,084

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.65006
Policy Entropy: 3.26638
Value Function Loss: 0.00389

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10323
Policy Update Magnitude: 0.54326
Value Function Update Magnitude: 0.65323

Collected Steps per Second: 22,471.45079
Overall Steps per Second: 10,643.73398

Timestep Collection Time: 2.22602
Timestep Consumption Time: 2.47364
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.69967

Cumulative Model Updates: 73,368
Cumulative Timesteps: 611,941,106

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 611941106...
Checkpoint 611941106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,309.85176
Policy Entropy: 3.27980
Value Function Loss: 0.00408

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.11793
Policy Update Magnitude: 0.54760
Value Function Update Magnitude: 0.68508

Collected Steps per Second: 22,391.25577
Overall Steps per Second: 10,610.82428

Timestep Collection Time: 2.23409
Timestep Consumption Time: 2.48034
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.71443

Cumulative Model Updates: 73,374
Cumulative Timesteps: 611,991,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.59960
Policy Entropy: 3.28162
Value Function Loss: 0.00412

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.12474
Policy Update Magnitude: 0.55000
Value Function Update Magnitude: 0.72234

Collected Steps per Second: 22,721.23020
Overall Steps per Second: 10,748.87018

Timestep Collection Time: 2.20182
Timestep Consumption Time: 2.45244
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.65426

Cumulative Model Updates: 73,380
Cumulative Timesteps: 612,041,158

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 612041158...
Checkpoint 612041158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645.64835
Policy Entropy: 3.29515
Value Function Loss: 0.00408

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10383
Policy Update Magnitude: 0.54927
Value Function Update Magnitude: 0.72280

Collected Steps per Second: 21,662.78038
Overall Steps per Second: 10,552.85985

Timestep Collection Time: 2.30884
Timestep Consumption Time: 2.43072
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.73957

Cumulative Model Updates: 73,386
Cumulative Timesteps: 612,091,174

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.01947
Policy Entropy: 3.28311
Value Function Loss: 0.00414

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09001
Policy Update Magnitude: 0.55674
Value Function Update Magnitude: 0.69657

Collected Steps per Second: 22,842.77207
Overall Steps per Second: 10,614.46894

Timestep Collection Time: 2.18984
Timestep Consumption Time: 2.52278
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 4.71262

Cumulative Model Updates: 73,392
Cumulative Timesteps: 612,141,196

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 612141196...
Checkpoint 612141196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 807.93759
Policy Entropy: 3.28389
Value Function Loss: 0.00401

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07809
Policy Update Magnitude: 0.56223
Value Function Update Magnitude: 0.70523

Collected Steps per Second: 22,819.26412
Overall Steps per Second: 10,668.32968

Timestep Collection Time: 2.19262
Timestep Consumption Time: 2.49734
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 4.68996

Cumulative Model Updates: 73,398
Cumulative Timesteps: 612,191,230

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.01519
Policy Entropy: 3.28712
Value Function Loss: 0.00390

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08330
Policy Update Magnitude: 0.55631
Value Function Update Magnitude: 0.69601

Collected Steps per Second: 22,619.05828
Overall Steps per Second: 10,778.93217

Timestep Collection Time: 2.21106
Timestep Consumption Time: 2.42874
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.63979

Cumulative Model Updates: 73,404
Cumulative Timesteps: 612,241,242

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 612241242...
Checkpoint 612241242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.10437
Policy Entropy: 3.28808
Value Function Loss: 0.00375

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09126
Policy Update Magnitude: 0.54616
Value Function Update Magnitude: 0.66936

Collected Steps per Second: 22,726.80315
Overall Steps per Second: 10,668.74835

Timestep Collection Time: 2.20216
Timestep Consumption Time: 2.48893
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.69108

Cumulative Model Updates: 73,410
Cumulative Timesteps: 612,291,290

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,640.38329
Policy Entropy: 3.28954
Value Function Loss: 0.00387

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08497
Policy Update Magnitude: 0.53789
Value Function Update Magnitude: 0.65051

Collected Steps per Second: 22,917.14615
Overall Steps per Second: 10,681.90632

Timestep Collection Time: 2.18247
Timestep Consumption Time: 2.49984
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.68231

Cumulative Model Updates: 73,416
Cumulative Timesteps: 612,341,306

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 612341306...
Checkpoint 612341306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 923.94734
Policy Entropy: 3.29547
Value Function Loss: 0.00416

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08022
Policy Update Magnitude: 0.54890
Value Function Update Magnitude: 0.63943

Collected Steps per Second: 22,062.12720
Overall Steps per Second: 10,380.32724

Timestep Collection Time: 2.26642
Timestep Consumption Time: 2.55058
PPO Batch Consumption Time: 0.29658
Total Iteration Time: 4.81700

Cumulative Model Updates: 73,422
Cumulative Timesteps: 612,391,308

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.80455
Policy Entropy: 3.29914
Value Function Loss: 0.00419

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07650
Policy Update Magnitude: 0.54936
Value Function Update Magnitude: 0.63846

Collected Steps per Second: 22,191.43086
Overall Steps per Second: 10,520.15157

Timestep Collection Time: 2.25366
Timestep Consumption Time: 2.50026
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.75392

Cumulative Model Updates: 73,428
Cumulative Timesteps: 612,441,320

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 612441320...
Checkpoint 612441320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.92624
Policy Entropy: 3.30303
Value Function Loss: 0.00392

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07095
Policy Update Magnitude: 0.54508
Value Function Update Magnitude: 0.64195

Collected Steps per Second: 22,333.80842
Overall Steps per Second: 10,607.83879

Timestep Collection Time: 2.23974
Timestep Consumption Time: 2.47583
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.71557

Cumulative Model Updates: 73,434
Cumulative Timesteps: 612,491,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 909.58676
Policy Entropy: 3.29695
Value Function Loss: 0.00364

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06953
Policy Update Magnitude: 0.53284
Value Function Update Magnitude: 0.62944

Collected Steps per Second: 22,415.05773
Overall Steps per Second: 10,630.38398

Timestep Collection Time: 2.23073
Timestep Consumption Time: 2.47295
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.70369

Cumulative Model Updates: 73,440
Cumulative Timesteps: 612,541,344

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 612541344...
Checkpoint 612541344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.32785
Policy Entropy: 3.29290
Value Function Loss: 0.00352

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08424
Policy Update Magnitude: 0.52150
Value Function Update Magnitude: 0.60638

Collected Steps per Second: 22,357.50111
Overall Steps per Second: 10,577.70753

Timestep Collection Time: 2.23656
Timestep Consumption Time: 2.49074
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.72730

Cumulative Model Updates: 73,446
Cumulative Timesteps: 612,591,348

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 881.57779
Policy Entropy: 3.29148
Value Function Loss: 0.00386

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.11798
Policy Update Magnitude: 0.52219
Value Function Update Magnitude: 0.58846

Collected Steps per Second: 22,560.53043
Overall Steps per Second: 10,733.58575

Timestep Collection Time: 2.21670
Timestep Consumption Time: 2.44250
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.65921

Cumulative Model Updates: 73,452
Cumulative Timesteps: 612,641,358

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 612641358...
Checkpoint 612641358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 735.81769
Policy Entropy: 3.28518
Value Function Loss: 0.00398

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.11315
Policy Update Magnitude: 0.52999
Value Function Update Magnitude: 0.58918

Collected Steps per Second: 22,352.99034
Overall Steps per Second: 10,660.74357

Timestep Collection Time: 2.23746
Timestep Consumption Time: 2.45395
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.69142

Cumulative Model Updates: 73,458
Cumulative Timesteps: 612,691,372

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 862.70723
Policy Entropy: 3.28713
Value Function Loss: 0.00430

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.54433
Value Function Update Magnitude: 0.60957

Collected Steps per Second: 22,692.44267
Overall Steps per Second: 10,671.31399

Timestep Collection Time: 2.20382
Timestep Consumption Time: 2.48258
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.68640

Cumulative Model Updates: 73,464
Cumulative Timesteps: 612,741,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 612741382...
Checkpoint 612741382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372.76598
Policy Entropy: 3.29480
Value Function Loss: 0.00416

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08073
Policy Update Magnitude: 0.55063
Value Function Update Magnitude: 0.64145

Collected Steps per Second: 22,997.15410
Overall Steps per Second: 10,908.95787

Timestep Collection Time: 2.17436
Timestep Consumption Time: 2.40940
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.58376

Cumulative Model Updates: 73,470
Cumulative Timesteps: 612,791,386

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 867.95005
Policy Entropy: 3.28610
Value Function Loss: 0.00422

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08489
Policy Update Magnitude: 0.55670
Value Function Update Magnitude: 0.65006

Collected Steps per Second: 22,514.21017
Overall Steps per Second: 10,593.40055

Timestep Collection Time: 2.22100
Timestep Consumption Time: 2.49930
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.72030

Cumulative Model Updates: 73,476
Cumulative Timesteps: 612,841,390

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 612841390...
Checkpoint 612841390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631.60587
Policy Entropy: 3.27313
Value Function Loss: 0.00440

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08163
Policy Update Magnitude: 0.56071
Value Function Update Magnitude: 0.64926

Collected Steps per Second: 22,928.30151
Overall Steps per Second: 10,978.31571

Timestep Collection Time: 2.18184
Timestep Consumption Time: 2.37496
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.55680

Cumulative Model Updates: 73,482
Cumulative Timesteps: 612,891,416

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658.62327
Policy Entropy: 3.27399
Value Function Loss: 0.00441

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09039
Policy Update Magnitude: 0.57197
Value Function Update Magnitude: 0.65282

Collected Steps per Second: 22,071.78669
Overall Steps per Second: 10,636.22180

Timestep Collection Time: 2.26660
Timestep Consumption Time: 2.43695
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.70355

Cumulative Model Updates: 73,488
Cumulative Timesteps: 612,941,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 612941444...
Checkpoint 612941444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.08090
Policy Entropy: 3.26655
Value Function Loss: 0.00446

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10381
Policy Update Magnitude: 0.57338
Value Function Update Magnitude: 0.64311

Collected Steps per Second: 22,410.97990
Overall Steps per Second: 10,852.92195

Timestep Collection Time: 2.23221
Timestep Consumption Time: 2.37724
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.60945

Cumulative Model Updates: 73,494
Cumulative Timesteps: 612,991,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 996.68499
Policy Entropy: 3.27888
Value Function Loss: 0.00443

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11631
Policy Update Magnitude: 0.56517
Value Function Update Magnitude: 0.65766

Collected Steps per Second: 21,590.54772
Overall Steps per Second: 10,570.22567

Timestep Collection Time: 2.31601
Timestep Consumption Time: 2.41463
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.73065

Cumulative Model Updates: 73,500
Cumulative Timesteps: 613,041,474

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 613041474...
Checkpoint 613041474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 875.44233
Policy Entropy: 3.29918
Value Function Loss: 0.00436

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.13316
Policy Update Magnitude: 0.55996
Value Function Update Magnitude: 0.66535

Collected Steps per Second: 21,603.12557
Overall Steps per Second: 10,612.22141

Timestep Collection Time: 2.31494
Timestep Consumption Time: 2.39755
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.71249

Cumulative Model Updates: 73,506
Cumulative Timesteps: 613,091,484

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 871.47093
Policy Entropy: 3.31607
Value Function Loss: 0.00423

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.11785
Policy Update Magnitude: 0.55391
Value Function Update Magnitude: 0.66239

Collected Steps per Second: 22,016.06809
Overall Steps per Second: 10,643.52942

Timestep Collection Time: 2.27180
Timestep Consumption Time: 2.42740
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.69919

Cumulative Model Updates: 73,512
Cumulative Timesteps: 613,141,500

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 613141500...
Checkpoint 613141500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.16160
Policy Entropy: 3.31699
Value Function Loss: 0.00415

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11477
Policy Update Magnitude: 0.54708
Value Function Update Magnitude: 0.65684

Collected Steps per Second: 21,838.20289
Overall Steps per Second: 10,537.91694

Timestep Collection Time: 2.29002
Timestep Consumption Time: 2.45570
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.74572

Cumulative Model Updates: 73,518
Cumulative Timesteps: 613,191,510

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596.61787
Policy Entropy: 3.31831
Value Function Loss: 0.00398

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.54587
Value Function Update Magnitude: 0.66643

Collected Steps per Second: 22,739.99731
Overall Steps per Second: 10,553.63038

Timestep Collection Time: 2.19886
Timestep Consumption Time: 2.53904
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.73790

Cumulative Model Updates: 73,524
Cumulative Timesteps: 613,241,512

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 613241512...
Checkpoint 613241512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 908.26609
Policy Entropy: 3.31692
Value Function Loss: 0.00401

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09302
Policy Update Magnitude: 0.54268
Value Function Update Magnitude: 0.67142

Collected Steps per Second: 22,889.95129
Overall Steps per Second: 10,635.25822

Timestep Collection Time: 2.18550
Timestep Consumption Time: 2.51829
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.70379

Cumulative Model Updates: 73,530
Cumulative Timesteps: 613,291,538

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.15304
Policy Entropy: 3.32311
Value Function Loss: 0.00382

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.54735
Value Function Update Magnitude: 0.65939

Collected Steps per Second: 23,260.59106
Overall Steps per Second: 10,700.43602

Timestep Collection Time: 2.15076
Timestep Consumption Time: 2.52456
PPO Batch Consumption Time: 0.29596
Total Iteration Time: 4.67532

Cumulative Model Updates: 73,536
Cumulative Timesteps: 613,341,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 613341566...
Checkpoint 613341566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.43101
Policy Entropy: 3.31587
Value Function Loss: 0.00401

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10381
Policy Update Magnitude: 0.54804
Value Function Update Magnitude: 0.64162

Collected Steps per Second: 22,829.31721
Overall Steps per Second: 10,637.84308

Timestep Collection Time: 2.19087
Timestep Consumption Time: 2.51084
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.70170

Cumulative Model Updates: 73,542
Cumulative Timesteps: 613,391,582

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 954.82565
Policy Entropy: 3.31900
Value Function Loss: 0.00380

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10131
Policy Update Magnitude: 0.53974
Value Function Update Magnitude: 0.63560

Collected Steps per Second: 22,748.93262
Overall Steps per Second: 10,613.19771

Timestep Collection Time: 2.19834
Timestep Consumption Time: 2.51371
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.71206

Cumulative Model Updates: 73,548
Cumulative Timesteps: 613,441,592

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 613441592...
Checkpoint 613441592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.46833
Policy Entropy: 3.30669
Value Function Loss: 0.00391

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08393
Policy Update Magnitude: 0.54779
Value Function Update Magnitude: 0.62907

Collected Steps per Second: 23,074.31192
Overall Steps per Second: 10,741.59057

Timestep Collection Time: 2.16821
Timestep Consumption Time: 2.48938
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.65760

Cumulative Model Updates: 73,554
Cumulative Timesteps: 613,491,622

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.09023
Policy Entropy: 3.29988
Value Function Loss: 0.00388

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08654
Policy Update Magnitude: 0.55286
Value Function Update Magnitude: 0.64536

Collected Steps per Second: 22,965.60801
Overall Steps per Second: 10,686.68864

Timestep Collection Time: 2.17830
Timestep Consumption Time: 2.50285
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.68115

Cumulative Model Updates: 73,560
Cumulative Timesteps: 613,541,648

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 613541648...
Checkpoint 613541648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.73948
Policy Entropy: 3.30464
Value Function Loss: 0.00390

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09401
Policy Update Magnitude: 0.55535
Value Function Update Magnitude: 0.65147

Collected Steps per Second: 23,076.66688
Overall Steps per Second: 10,656.07747

Timestep Collection Time: 2.16782
Timestep Consumption Time: 2.52678
PPO Batch Consumption Time: 0.29746
Total Iteration Time: 4.69460

Cumulative Model Updates: 73,566
Cumulative Timesteps: 613,591,674

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 699.20896
Policy Entropy: 3.30811
Value Function Loss: 0.00401

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08062
Policy Update Magnitude: 0.56176
Value Function Update Magnitude: 0.64439

Collected Steps per Second: 22,000.81192
Overall Steps per Second: 10,474.62407

Timestep Collection Time: 2.27264
Timestep Consumption Time: 2.50080
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.77344

Cumulative Model Updates: 73,572
Cumulative Timesteps: 613,641,674

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 613641674...
Checkpoint 613641674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668.06718
Policy Entropy: 3.30810
Value Function Loss: 0.00413

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08719
Policy Update Magnitude: 0.56133
Value Function Update Magnitude: 0.64540

Collected Steps per Second: 22,232.74574
Overall Steps per Second: 10,640.70902

Timestep Collection Time: 2.24956
Timestep Consumption Time: 2.45069
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.70025

Cumulative Model Updates: 73,578
Cumulative Timesteps: 613,691,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.11256
Policy Entropy: 3.29077
Value Function Loss: 0.00418

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10802
Policy Update Magnitude: 0.57041
Value Function Update Magnitude: 0.64227

Collected Steps per Second: 22,525.09322
Overall Steps per Second: 10,598.45069

Timestep Collection Time: 2.22010
Timestep Consumption Time: 2.49832
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.71843

Cumulative Model Updates: 73,584
Cumulative Timesteps: 613,741,696

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 613741696...
Checkpoint 613741696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673.02204
Policy Entropy: 3.30125
Value Function Loss: 0.00422

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09381
Policy Update Magnitude: 0.56237
Value Function Update Magnitude: 0.64906

Collected Steps per Second: 22,451.86809
Overall Steps per Second: 10,537.24793

Timestep Collection Time: 2.22734
Timestep Consumption Time: 2.51849
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.74583

Cumulative Model Updates: 73,590
Cumulative Timesteps: 613,791,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 773.56118
Policy Entropy: 3.29225
Value Function Loss: 0.00421

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.56210
Value Function Update Magnitude: 0.64876

Collected Steps per Second: 22,459.40198
Overall Steps per Second: 10,547.60964

Timestep Collection Time: 2.22651
Timestep Consumption Time: 2.51447
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.74098

Cumulative Model Updates: 73,596
Cumulative Timesteps: 613,841,710

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 613841710...
Checkpoint 613841710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 843.08673
Policy Entropy: 3.29548
Value Function Loss: 0.00417

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10268
Policy Update Magnitude: 0.56278
Value Function Update Magnitude: 0.63492

Collected Steps per Second: 22,944.36258
Overall Steps per Second: 10,595.37790

Timestep Collection Time: 2.17953
Timestep Consumption Time: 2.54026
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.71979

Cumulative Model Updates: 73,602
Cumulative Timesteps: 613,891,718

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.35793
Policy Entropy: 3.28370
Value Function Loss: 0.00414

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.55886
Value Function Update Magnitude: 0.62750

Collected Steps per Second: 22,877.28636
Overall Steps per Second: 10,728.79500

Timestep Collection Time: 2.18671
Timestep Consumption Time: 2.47607
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.66278

Cumulative Model Updates: 73,608
Cumulative Timesteps: 613,941,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 613941744...
Checkpoint 613941744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 956.10519
Policy Entropy: 3.27507
Value Function Loss: 0.00400

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10085
Policy Update Magnitude: 0.55642
Value Function Update Magnitude: 0.64164

Collected Steps per Second: 22,892.31860
Overall Steps per Second: 10,746.45957

Timestep Collection Time: 2.18501
Timestep Consumption Time: 2.46954
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.65456

Cumulative Model Updates: 73,614
Cumulative Timesteps: 613,991,764

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 936.13586
Policy Entropy: 3.28109
Value Function Loss: 0.00394

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10489
Policy Update Magnitude: 0.55287
Value Function Update Magnitude: 0.65118

Collected Steps per Second: 22,221.12207
Overall Steps per Second: 10,444.36270

Timestep Collection Time: 2.25020
Timestep Consumption Time: 2.53726
PPO Batch Consumption Time: 0.29632
Total Iteration Time: 4.78746

Cumulative Model Updates: 73,620
Cumulative Timesteps: 614,041,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 614041766...
Checkpoint 614041766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 944.48368
Policy Entropy: 3.29210
Value Function Loss: 0.00409

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.55692
Value Function Update Magnitude: 0.66000

Collected Steps per Second: 22,842.67251
Overall Steps per Second: 10,657.13632

Timestep Collection Time: 2.18994
Timestep Consumption Time: 2.50401
PPO Batch Consumption Time: 0.29817
Total Iteration Time: 4.69394

Cumulative Model Updates: 73,626
Cumulative Timesteps: 614,091,790

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 933.38204
Policy Entropy: 3.29189
Value Function Loss: 0.00419

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.55881
Value Function Update Magnitude: 0.66184

Collected Steps per Second: 22,673.56396
Overall Steps per Second: 10,787.74896

Timestep Collection Time: 2.20601
Timestep Consumption Time: 2.43055
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.63656

Cumulative Model Updates: 73,632
Cumulative Timesteps: 614,141,808

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 614141808...
Checkpoint 614141808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 947.87553
Policy Entropy: 3.29056
Value Function Loss: 0.00435

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10111
Policy Update Magnitude: 0.56199
Value Function Update Magnitude: 0.64776

Collected Steps per Second: 22,680.25662
Overall Steps per Second: 10,715.89813

Timestep Collection Time: 2.20553
Timestep Consumption Time: 2.46249
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.66802

Cumulative Model Updates: 73,638
Cumulative Timesteps: 614,191,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.66824
Policy Entropy: 3.28408
Value Function Loss: 0.00433

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10433
Policy Update Magnitude: 0.56570
Value Function Update Magnitude: 0.66232

Collected Steps per Second: 22,522.09861
Overall Steps per Second: 10,669.95536

Timestep Collection Time: 2.22084
Timestep Consumption Time: 2.46690
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.68774

Cumulative Model Updates: 73,644
Cumulative Timesteps: 614,241,848

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 614241848...
Checkpoint 614241848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692.64121
Policy Entropy: 3.28687
Value Function Loss: 0.00434

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10291
Policy Update Magnitude: 0.56985
Value Function Update Magnitude: 0.69395

Collected Steps per Second: 21,941.28819
Overall Steps per Second: 10,422.91959

Timestep Collection Time: 2.27990
Timestep Consumption Time: 2.51952
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.79942

Cumulative Model Updates: 73,650
Cumulative Timesteps: 614,291,872

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.20049
Policy Entropy: 3.27474
Value Function Loss: 0.00427

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10472
Policy Update Magnitude: 0.57263
Value Function Update Magnitude: 0.68026

Collected Steps per Second: 22,274.01177
Overall Steps per Second: 10,479.81783

Timestep Collection Time: 2.24477
Timestep Consumption Time: 2.52631
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.77108

Cumulative Model Updates: 73,656
Cumulative Timesteps: 614,341,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 614341872...
Checkpoint 614341872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.24880
Policy Entropy: 3.27964
Value Function Loss: 0.00408

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.56249
Value Function Update Magnitude: 0.67180

Collected Steps per Second: 22,341.52153
Overall Steps per Second: 10,611.63643

Timestep Collection Time: 2.23870
Timestep Consumption Time: 2.47461
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.71332

Cumulative Model Updates: 73,662
Cumulative Timesteps: 614,391,888

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.77285
Policy Entropy: 3.26011
Value Function Loss: 0.00392

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.55414
Value Function Update Magnitude: 0.68971

Collected Steps per Second: 22,269.22920
Overall Steps per Second: 10,536.53848

Timestep Collection Time: 2.24534
Timestep Consumption Time: 2.50024
PPO Batch Consumption Time: 0.29680
Total Iteration Time: 4.74558

Cumulative Model Updates: 73,668
Cumulative Timesteps: 614,441,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 614441890...
Checkpoint 614441890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.11475
Policy Entropy: 3.27943
Value Function Loss: 0.00387

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.55341
Value Function Update Magnitude: 0.67834

Collected Steps per Second: 22,408.35450
Overall Steps per Second: 10,579.77492

Timestep Collection Time: 2.23140
Timestep Consumption Time: 2.49479
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.72619

Cumulative Model Updates: 73,674
Cumulative Timesteps: 614,491,892

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.18974
Policy Entropy: 3.29582
Value Function Loss: 0.00406

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10402
Policy Update Magnitude: 0.54763
Value Function Update Magnitude: 0.65855

Collected Steps per Second: 22,846.40401
Overall Steps per Second: 10,849.72134

Timestep Collection Time: 2.18975
Timestep Consumption Time: 2.42124
PPO Batch Consumption Time: 0.28514
Total Iteration Time: 4.61099

Cumulative Model Updates: 73,680
Cumulative Timesteps: 614,541,920

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 614541920...
Checkpoint 614541920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678.32475
Policy Entropy: 3.30620
Value Function Loss: 0.00414

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10154
Policy Update Magnitude: 0.54889
Value Function Update Magnitude: 0.65581

Collected Steps per Second: 22,202.73052
Overall Steps per Second: 10,676.94263

Timestep Collection Time: 2.25270
Timestep Consumption Time: 2.43179
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.68449

Cumulative Model Updates: 73,686
Cumulative Timesteps: 614,591,936

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.22612
Policy Entropy: 3.30284
Value Function Loss: 0.00420

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.12227
Policy Update Magnitude: 0.54910
Value Function Update Magnitude: 0.65902

Collected Steps per Second: 22,080.08593
Overall Steps per Second: 10,633.07722

Timestep Collection Time: 2.26467
Timestep Consumption Time: 2.43802
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.70268

Cumulative Model Updates: 73,692
Cumulative Timesteps: 614,641,940

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 614641940...
Checkpoint 614641940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 988.21462
Policy Entropy: 3.30111
Value Function Loss: 0.00409

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.12742
Policy Update Magnitude: 0.54828
Value Function Update Magnitude: 0.65011

Collected Steps per Second: 21,852.44176
Overall Steps per Second: 10,558.20738

Timestep Collection Time: 2.28917
Timestep Consumption Time: 2.44875
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.73793

Cumulative Model Updates: 73,698
Cumulative Timesteps: 614,691,964

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692.23072
Policy Entropy: 3.30436
Value Function Loss: 0.00422

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12201
Policy Update Magnitude: 0.55109
Value Function Update Magnitude: 0.63156

Collected Steps per Second: 21,869.56584
Overall Steps per Second: 10,720.07002

Timestep Collection Time: 2.28692
Timestep Consumption Time: 2.37853
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.66545

Cumulative Model Updates: 73,704
Cumulative Timesteps: 614,741,978

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 614741978...
Checkpoint 614741978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 987.56015
Policy Entropy: 3.28860
Value Function Loss: 0.00439

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11691
Policy Update Magnitude: 0.55707
Value Function Update Magnitude: 0.62117

Collected Steps per Second: 21,512.79062
Overall Steps per Second: 10,615.28889

Timestep Collection Time: 2.32420
Timestep Consumption Time: 2.38599
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.71019

Cumulative Model Updates: 73,710
Cumulative Timesteps: 614,791,978

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.12586
Policy Entropy: 3.25607
Value Function Loss: 0.00443

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.56000
Value Function Update Magnitude: 0.62202

Collected Steps per Second: 22,215.43079
Overall Steps per Second: 10,573.90076

Timestep Collection Time: 2.25186
Timestep Consumption Time: 2.47922
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.73108

Cumulative Model Updates: 73,716
Cumulative Timesteps: 614,842,004

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 614842004...
Checkpoint 614842004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681.82426
Policy Entropy: 3.25722
Value Function Loss: 0.00417

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09856
Policy Update Magnitude: 0.56491
Value Function Update Magnitude: 0.61192

Collected Steps per Second: 22,205.47049
Overall Steps per Second: 10,644.37866

Timestep Collection Time: 2.25224
Timestep Consumption Time: 2.44620
PPO Batch Consumption Time: 0.28181
Total Iteration Time: 4.69844

Cumulative Model Updates: 73,722
Cumulative Timesteps: 614,892,016

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.20976
Policy Entropy: 3.26466
Value Function Loss: 0.00418

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08514
Policy Update Magnitude: 0.56363
Value Function Update Magnitude: 0.59954

Collected Steps per Second: 22,732.99191
Overall Steps per Second: 10,560.71834

Timestep Collection Time: 2.19953
Timestep Consumption Time: 2.53518
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.73472

Cumulative Model Updates: 73,728
Cumulative Timesteps: 614,942,018

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 614942018...
Checkpoint 614942018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 829.84334
Policy Entropy: 3.29129
Value Function Loss: 0.00394

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07986
Policy Update Magnitude: 0.55249
Value Function Update Magnitude: 0.59698

Collected Steps per Second: 22,472.86726
Overall Steps per Second: 10,514.07760

Timestep Collection Time: 2.22571
Timestep Consumption Time: 2.53153
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.75724

Cumulative Model Updates: 73,734
Cumulative Timesteps: 614,992,036

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 780.90370
Policy Entropy: 3.29734
Value Function Loss: 0.00393

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09008
Policy Update Magnitude: 0.54230
Value Function Update Magnitude: 0.56997

Collected Steps per Second: 22,837.87493
Overall Steps per Second: 10,610.83482

Timestep Collection Time: 2.18987
Timestep Consumption Time: 2.52342
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.71330

Cumulative Model Updates: 73,740
Cumulative Timesteps: 615,042,048

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 615042048...
Checkpoint 615042048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 837.34670
Policy Entropy: 3.29474
Value Function Loss: 0.00375

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08321
Policy Update Magnitude: 0.53739
Value Function Update Magnitude: 0.55286

Collected Steps per Second: 22,489.83817
Overall Steps per Second: 10,536.28325

Timestep Collection Time: 2.22349
Timestep Consumption Time: 2.52258
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.74608

Cumulative Model Updates: 73,746
Cumulative Timesteps: 615,092,054

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.98811
Policy Entropy: 3.28214
Value Function Loss: 0.00395

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08260
Policy Update Magnitude: 0.54074
Value Function Update Magnitude: 0.56201

Collected Steps per Second: 23,078.15190
Overall Steps per Second: 10,829.20829

Timestep Collection Time: 2.16655
Timestep Consumption Time: 2.45059
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.61714

Cumulative Model Updates: 73,752
Cumulative Timesteps: 615,142,054

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 615142054...
Checkpoint 615142054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.99193
Policy Entropy: 3.28611
Value Function Loss: 0.00403

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.55273
Value Function Update Magnitude: 0.57075

Collected Steps per Second: 22,954.92210
Overall Steps per Second: 10,649.27308

Timestep Collection Time: 2.17888
Timestep Consumption Time: 2.51778
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.69666

Cumulative Model Updates: 73,758
Cumulative Timesteps: 615,192,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 880.60528
Policy Entropy: 3.28944
Value Function Loss: 0.00423

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09700
Policy Update Magnitude: 0.55621
Value Function Update Magnitude: 0.57650

Collected Steps per Second: 22,655.62900
Overall Steps per Second: 10,601.74508

Timestep Collection Time: 2.20713
Timestep Consumption Time: 2.50945
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.71658

Cumulative Model Updates: 73,764
Cumulative Timesteps: 615,242,074

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 615242074...
Checkpoint 615242074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.58081
Policy Entropy: 3.27946
Value Function Loss: 0.00443

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09955
Policy Update Magnitude: 0.56304
Value Function Update Magnitude: 0.59901

Collected Steps per Second: 22,870.47406
Overall Steps per Second: 10,651.39799

Timestep Collection Time: 2.18675
Timestep Consumption Time: 2.50860
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.69535

Cumulative Model Updates: 73,770
Cumulative Timesteps: 615,292,086

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.81662
Policy Entropy: 3.28184
Value Function Loss: 0.00422

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08831
Policy Update Magnitude: 0.56531
Value Function Update Magnitude: 0.61688

Collected Steps per Second: 22,540.09833
Overall Steps per Second: 10,672.21304

Timestep Collection Time: 2.21845
Timestep Consumption Time: 2.46699
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.68544

Cumulative Model Updates: 73,776
Cumulative Timesteps: 615,342,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 615342090...
Checkpoint 615342090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.05710
Policy Entropy: 3.28616
Value Function Loss: 0.00383

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.55141
Value Function Update Magnitude: 0.60230

Collected Steps per Second: 22,436.93251
Overall Steps per Second: 10,649.64177

Timestep Collection Time: 2.22981
Timestep Consumption Time: 2.46800
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.69781

Cumulative Model Updates: 73,782
Cumulative Timesteps: 615,392,120

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 965.19554
Policy Entropy: 3.31132
Value Function Loss: 0.00364

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.53610
Value Function Update Magnitude: 0.58582

Collected Steps per Second: 22,354.65952
Overall Steps per Second: 10,524.20235

Timestep Collection Time: 2.23765
Timestep Consumption Time: 2.51539
PPO Batch Consumption Time: 0.29564
Total Iteration Time: 4.75304

Cumulative Model Updates: 73,788
Cumulative Timesteps: 615,442,142

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 615442142...
Checkpoint 615442142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.86740
Policy Entropy: 3.32060
Value Function Loss: 0.00349

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08988
Policy Update Magnitude: 0.52345
Value Function Update Magnitude: 0.59048

Collected Steps per Second: 22,082.10494
Overall Steps per Second: 10,597.78648

Timestep Collection Time: 2.26645
Timestep Consumption Time: 2.45604
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.72250

Cumulative Model Updates: 73,794
Cumulative Timesteps: 615,492,190

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 879.76335
Policy Entropy: 3.32843
Value Function Loss: 0.00362

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08989
Policy Update Magnitude: 0.52099
Value Function Update Magnitude: 0.58771

Collected Steps per Second: 22,821.54403
Overall Steps per Second: 10,602.68876

Timestep Collection Time: 2.19275
Timestep Consumption Time: 2.52699
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.71975

Cumulative Model Updates: 73,800
Cumulative Timesteps: 615,542,232

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 615542232...
Checkpoint 615542232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.17527
Policy Entropy: 3.32267
Value Function Loss: 0.00382

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08342
Policy Update Magnitude: 0.52497
Value Function Update Magnitude: 0.59309

Collected Steps per Second: 22,690.65012
Overall Steps per Second: 10,577.16217

Timestep Collection Time: 2.20399
Timestep Consumption Time: 2.52412
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.72811

Cumulative Model Updates: 73,806
Cumulative Timesteps: 615,592,242

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.16748
Policy Entropy: 3.31511
Value Function Loss: 0.00383

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08936
Policy Update Magnitude: 0.52495
Value Function Update Magnitude: 0.58825

Collected Steps per Second: 22,833.41594
Overall Steps per Second: 10,633.37046

Timestep Collection Time: 2.19074
Timestep Consumption Time: 2.51351
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.70425

Cumulative Model Updates: 73,812
Cumulative Timesteps: 615,642,264

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 615642264...
Checkpoint 615642264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.55166
Policy Entropy: 3.30601
Value Function Loss: 0.00389

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08351
Policy Update Magnitude: 0.53264
Value Function Update Magnitude: 0.61462

Collected Steps per Second: 22,862.76586
Overall Steps per Second: 10,805.17126

Timestep Collection Time: 2.18775
Timestep Consumption Time: 2.44133
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.62908

Cumulative Model Updates: 73,818
Cumulative Timesteps: 615,692,282

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.36860
Policy Entropy: 3.30358
Value Function Loss: 0.00380

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08555
Policy Update Magnitude: 0.53937
Value Function Update Magnitude: 0.63213

Collected Steps per Second: 22,505.49145
Overall Steps per Second: 10,549.10937

Timestep Collection Time: 2.22355
Timestep Consumption Time: 2.52017
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.74372

Cumulative Model Updates: 73,824
Cumulative Timesteps: 615,742,324

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 615742324...
Checkpoint 615742324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,497.86716
Policy Entropy: 3.28940
Value Function Loss: 0.00397

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08745
Policy Update Magnitude: 0.54586
Value Function Update Magnitude: 0.63076

Collected Steps per Second: 22,840.18197
Overall Steps per Second: 10,614.03547

Timestep Collection Time: 2.18991
Timestep Consumption Time: 2.52253
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.71244

Cumulative Model Updates: 73,830
Cumulative Timesteps: 615,792,342

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 917.82464
Policy Entropy: 3.29847
Value Function Loss: 0.00411

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09873
Policy Update Magnitude: 0.55373
Value Function Update Magnitude: 0.64083

Collected Steps per Second: 22,756.85574
Overall Steps per Second: 10,660.53053

Timestep Collection Time: 2.19828
Timestep Consumption Time: 2.49435
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.69264

Cumulative Model Updates: 73,836
Cumulative Timesteps: 615,842,368

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 615842368...
Checkpoint 615842368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585.21071
Policy Entropy: 3.29511
Value Function Loss: 0.00420

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10134
Policy Update Magnitude: 0.56662
Value Function Update Magnitude: 0.65149

Collected Steps per Second: 22,952.35386
Overall Steps per Second: 10,800.56256

Timestep Collection Time: 2.17982
Timestep Consumption Time: 2.45253
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.63235

Cumulative Model Updates: 73,842
Cumulative Timesteps: 615,892,400

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.56444
Policy Entropy: 3.29759
Value Function Loss: 0.00393

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.56700
Value Function Update Magnitude: 0.64652

Collected Steps per Second: 22,003.16637
Overall Steps per Second: 10,604.03293

Timestep Collection Time: 2.27276
Timestep Consumption Time: 2.44318
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.71594

Cumulative Model Updates: 73,848
Cumulative Timesteps: 615,942,408

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 615942408...
Checkpoint 615942408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,630.85276
Policy Entropy: 3.30924
Value Function Loss: 0.00394

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.55406
Value Function Update Magnitude: 0.64392

Collected Steps per Second: 22,153.63009
Overall Steps per Second: 10,591.79315

Timestep Collection Time: 2.25805
Timestep Consumption Time: 2.46485
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.72290

Cumulative Model Updates: 73,854
Cumulative Timesteps: 615,992,432

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 994.61993
Policy Entropy: 3.30881
Value Function Loss: 0.00386

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08496
Policy Update Magnitude: 0.54050
Value Function Update Magnitude: 0.62351

Collected Steps per Second: 22,646.20564
Overall Steps per Second: 10,564.69680

Timestep Collection Time: 2.20796
Timestep Consumption Time: 2.52497
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.73293

Cumulative Model Updates: 73,860
Cumulative Timesteps: 616,042,434

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 616042434...
Checkpoint 616042434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,374.29508
Policy Entropy: 3.31961
Value Function Loss: 0.00394

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07864
Policy Update Magnitude: 0.53767
Value Function Update Magnitude: 0.60392

Collected Steps per Second: 22,073.61188
Overall Steps per Second: 10,534.48612

Timestep Collection Time: 2.26515
Timestep Consumption Time: 2.48117
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.74632

Cumulative Model Updates: 73,866
Cumulative Timesteps: 616,092,434

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.49545
Policy Entropy: 3.30826
Value Function Loss: 0.00399

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08889
Policy Update Magnitude: 0.54484
Value Function Update Magnitude: 0.59278

Collected Steps per Second: 22,824.72876
Overall Steps per Second: 10,665.32938

Timestep Collection Time: 2.19192
Timestep Consumption Time: 2.49898
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.69090

Cumulative Model Updates: 73,872
Cumulative Timesteps: 616,142,464

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 616142464...
Checkpoint 616142464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.81805
Policy Entropy: 3.30914
Value Function Loss: 0.00392

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08992
Policy Update Magnitude: 0.54777
Value Function Update Magnitude: 0.59541

Collected Steps per Second: 22,477.69349
Overall Steps per Second: 10,538.12785

Timestep Collection Time: 2.22567
Timestep Consumption Time: 2.52166
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.74733

Cumulative Model Updates: 73,878
Cumulative Timesteps: 616,192,492

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 777.82122
Policy Entropy: 3.28288
Value Function Loss: 0.00411

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09248
Policy Update Magnitude: 0.55340
Value Function Update Magnitude: 0.61230

Collected Steps per Second: 22,968.12713
Overall Steps per Second: 10,816.17602

Timestep Collection Time: 2.17763
Timestep Consumption Time: 2.44656
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.62419

Cumulative Model Updates: 73,884
Cumulative Timesteps: 616,242,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 616242508...
Checkpoint 616242508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 763.17888
Policy Entropy: 3.29902
Value Function Loss: 0.00389

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08576
Policy Update Magnitude: 0.55036
Value Function Update Magnitude: 0.61138

Collected Steps per Second: 22,537.29630
Overall Steps per Second: 10,611.13861

Timestep Collection Time: 2.21890
Timestep Consumption Time: 2.49388
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.71278

Cumulative Model Updates: 73,890
Cumulative Timesteps: 616,292,516

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 875.84874
Policy Entropy: 3.30502
Value Function Loss: 0.00390

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07964
Policy Update Magnitude: 0.54586
Value Function Update Magnitude: 0.60229

Collected Steps per Second: 22,966.71657
Overall Steps per Second: 10,838.86030

Timestep Collection Time: 2.17898
Timestep Consumption Time: 2.43811
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.61709

Cumulative Model Updates: 73,896
Cumulative Timesteps: 616,342,560

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 616342560...
Checkpoint 616342560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 831.98138
Policy Entropy: 3.32166
Value Function Loss: 0.00375

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07809
Policy Update Magnitude: 0.54424
Value Function Update Magnitude: 0.59139

Collected Steps per Second: 22,569.88013
Overall Steps per Second: 10,700.80908

Timestep Collection Time: 2.21632
Timestep Consumption Time: 2.45828
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.67460

Cumulative Model Updates: 73,902
Cumulative Timesteps: 616,392,582

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 900.61260
Policy Entropy: 3.32133
Value Function Loss: 0.00386

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08387
Policy Update Magnitude: 0.54529
Value Function Update Magnitude: 0.59877

Collected Steps per Second: 22,122.41165
Overall Steps per Second: 10,509.47289

Timestep Collection Time: 2.26142
Timestep Consumption Time: 2.49886
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.76028

Cumulative Model Updates: 73,908
Cumulative Timesteps: 616,442,610

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 616442610...
Checkpoint 616442610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 783.40913
Policy Entropy: 3.31398
Value Function Loss: 0.00389

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08769
Policy Update Magnitude: 0.54756
Value Function Update Magnitude: 0.62477

Collected Steps per Second: 21,945.38727
Overall Steps per Second: 10,642.35882

Timestep Collection Time: 2.27884
Timestep Consumption Time: 2.42031
PPO Batch Consumption Time: 0.28220
Total Iteration Time: 4.69915

Cumulative Model Updates: 73,914
Cumulative Timesteps: 616,492,620

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 996.97443
Policy Entropy: 3.31680
Value Function Loss: 0.00386

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07461
Policy Update Magnitude: 0.54958
Value Function Update Magnitude: 0.62735

Collected Steps per Second: 22,679.21647
Overall Steps per Second: 10,793.92105

Timestep Collection Time: 2.20598
Timestep Consumption Time: 2.42903
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.63502

Cumulative Model Updates: 73,920
Cumulative Timesteps: 616,542,650

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 616542650...
Checkpoint 616542650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.87503
Policy Entropy: 3.32007
Value Function Loss: 0.00401

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07863
Policy Update Magnitude: 0.55119
Value Function Update Magnitude: 0.63253

Collected Steps per Second: 22,051.74747
Overall Steps per Second: 10,596.58058

Timestep Collection Time: 2.26748
Timestep Consumption Time: 2.45121
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.71869

Cumulative Model Updates: 73,926
Cumulative Timesteps: 616,592,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.04463
Policy Entropy: 3.32305
Value Function Loss: 0.00401

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.55453
Value Function Update Magnitude: 0.63346

Collected Steps per Second: 23,137.71827
Overall Steps per Second: 10,769.45845

Timestep Collection Time: 2.16192
Timestep Consumption Time: 2.48288
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.64480

Cumulative Model Updates: 73,932
Cumulative Timesteps: 616,642,674

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 616642674...
Checkpoint 616642674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.91079
Policy Entropy: 3.32661
Value Function Loss: 0.00381

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.55012
Value Function Update Magnitude: 0.61537

Collected Steps per Second: 22,681.02833
Overall Steps per Second: 10,804.14104

Timestep Collection Time: 2.20528
Timestep Consumption Time: 2.42424
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.62952

Cumulative Model Updates: 73,938
Cumulative Timesteps: 616,692,692

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,401.68265
Policy Entropy: 3.30479
Value Function Loss: 0.00391

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09198
Policy Update Magnitude: 0.54279
Value Function Update Magnitude: 0.61042

Collected Steps per Second: 23,049.18117
Overall Steps per Second: 10,727.16993

Timestep Collection Time: 2.16945
Timestep Consumption Time: 2.49199
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.66143

Cumulative Model Updates: 73,944
Cumulative Timesteps: 616,742,696

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 616742696...
Checkpoint 616742696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.39050
Policy Entropy: 3.30023
Value Function Loss: 0.00398

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09499
Policy Update Magnitude: 0.55122
Value Function Update Magnitude: 0.62648

Collected Steps per Second: 22,201.14815
Overall Steps per Second: 10,546.83563

Timestep Collection Time: 2.25322
Timestep Consumption Time: 2.48982
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.74303

Cumulative Model Updates: 73,950
Cumulative Timesteps: 616,792,720

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 789.60277
Policy Entropy: 3.29426
Value Function Loss: 0.00394

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10829
Policy Update Magnitude: 0.55334
Value Function Update Magnitude: 0.63860

Collected Steps per Second: 22,860.11351
Overall Steps per Second: 10,844.91383

Timestep Collection Time: 2.18827
Timestep Consumption Time: 2.42440
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.61267

Cumulative Model Updates: 73,956
Cumulative Timesteps: 616,842,744

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 616842744...
Checkpoint 616842744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 928.85435
Policy Entropy: 3.30988
Value Function Loss: 0.00371

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.54936
Value Function Update Magnitude: 0.63009

Collected Steps per Second: 22,569.18886
Overall Steps per Second: 10,614.20007

Timestep Collection Time: 2.21647
Timestep Consumption Time: 2.49646
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 4.71293

Cumulative Model Updates: 73,962
Cumulative Timesteps: 616,892,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.37441
Policy Entropy: 3.31959
Value Function Loss: 0.00352

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09242
Policy Update Magnitude: 0.54005
Value Function Update Magnitude: 0.63362

Collected Steps per Second: 22,104.06518
Overall Steps per Second: 10,483.63589

Timestep Collection Time: 2.26275
Timestep Consumption Time: 2.50811
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.77086

Cumulative Model Updates: 73,968
Cumulative Timesteps: 616,942,784

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 616942784...
Checkpoint 616942784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.80536
Policy Entropy: 3.31731
Value Function Loss: 0.00350

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07650
Policy Update Magnitude: 0.53710
Value Function Update Magnitude: 0.62116

Collected Steps per Second: 22,503.95512
Overall Steps per Second: 10,615.87227

Timestep Collection Time: 2.22370
Timestep Consumption Time: 2.49019
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.71388

Cumulative Model Updates: 73,974
Cumulative Timesteps: 616,992,826

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 860.07726
Policy Entropy: 3.30357
Value Function Loss: 0.00386

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08198
Policy Update Magnitude: 0.53844
Value Function Update Magnitude: 0.62379

Collected Steps per Second: 22,403.75628
Overall Steps per Second: 10,616.00725

Timestep Collection Time: 2.23302
Timestep Consumption Time: 2.47949
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.71251

Cumulative Model Updates: 73,980
Cumulative Timesteps: 617,042,854

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 617042854...
Checkpoint 617042854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.65701
Policy Entropy: 3.31119
Value Function Loss: 0.00383

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07967
Policy Update Magnitude: 0.54391
Value Function Update Magnitude: 0.64116

Collected Steps per Second: 22,211.47900
Overall Steps per Second: 10,529.13514

Timestep Collection Time: 2.25217
Timestep Consumption Time: 2.49884
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.75101

Cumulative Model Updates: 73,986
Cumulative Timesteps: 617,092,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.72104
Policy Entropy: 3.29973
Value Function Loss: 0.00391

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08667
Policy Update Magnitude: 0.54773
Value Function Update Magnitude: 0.63047

Collected Steps per Second: 22,731.19777
Overall Steps per Second: 10,811.68575

Timestep Collection Time: 2.20032
Timestep Consumption Time: 2.42578
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.62611

Cumulative Model Updates: 73,992
Cumulative Timesteps: 617,142,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 617142894...
Checkpoint 617142894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 987.38293
Policy Entropy: 3.31655
Value Function Loss: 0.00389

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.54600
Value Function Update Magnitude: 0.62076

Collected Steps per Second: 22,429.78819
Overall Steps per Second: 10,647.37441

Timestep Collection Time: 2.23007
Timestep Consumption Time: 2.46780
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.69787

Cumulative Model Updates: 73,998
Cumulative Timesteps: 617,192,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 971.11742
Policy Entropy: 3.29608
Value Function Loss: 0.00407

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10296
Policy Update Magnitude: 0.54964
Value Function Update Magnitude: 0.63479

Collected Steps per Second: 22,774.31657
Overall Steps per Second: 10,675.35001

Timestep Collection Time: 2.19660
Timestep Consumption Time: 2.48953
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.68612

Cumulative Model Updates: 74,004
Cumulative Timesteps: 617,242,940

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 617242940...
Checkpoint 617242940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 942.47941
Policy Entropy: 3.31530
Value Function Loss: 0.00391

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09615
Policy Update Magnitude: 0.55431
Value Function Update Magnitude: 0.64579

Collected Steps per Second: 21,822.83195
Overall Steps per Second: 10,434.59683

Timestep Collection Time: 2.29264
Timestep Consumption Time: 2.50217
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.79482

Cumulative Model Updates: 74,010
Cumulative Timesteps: 617,292,972

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.26575
Policy Entropy: 3.30051
Value Function Loss: 0.00386

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.55364
Value Function Update Magnitude: 0.64450

Collected Steps per Second: 22,792.16304
Overall Steps per Second: 10,803.84505

Timestep Collection Time: 2.19391
Timestep Consumption Time: 2.43444
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.62835

Cumulative Model Updates: 74,016
Cumulative Timesteps: 617,342,976

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 617342976...
Checkpoint 617342976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 880.90719
Policy Entropy: 3.30437
Value Function Loss: 0.00383

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09110
Policy Update Magnitude: 0.55180
Value Function Update Magnitude: 0.64424

Collected Steps per Second: 22,514.07163
Overall Steps per Second: 10,778.91985

Timestep Collection Time: 2.22137
Timestep Consumption Time: 2.41843
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.63980

Cumulative Model Updates: 74,022
Cumulative Timesteps: 617,392,988

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 944.71275
Policy Entropy: 3.29061
Value Function Loss: 0.00398

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08783
Policy Update Magnitude: 0.55183
Value Function Update Magnitude: 0.64981

Collected Steps per Second: 22,833.51838
Overall Steps per Second: 10,817.59928

Timestep Collection Time: 2.19046
Timestep Consumption Time: 2.43311
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 4.62358

Cumulative Model Updates: 74,028
Cumulative Timesteps: 617,443,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 617443004...
Checkpoint 617443004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 921.34830
Policy Entropy: 3.30514
Value Function Loss: 0.00392

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.55598
Value Function Update Magnitude: 0.64281

Collected Steps per Second: 22,467.07291
Overall Steps per Second: 10,787.05703

Timestep Collection Time: 2.22619
Timestep Consumption Time: 2.41048
PPO Batch Consumption Time: 0.28203
Total Iteration Time: 4.63667

Cumulative Model Updates: 74,034
Cumulative Timesteps: 617,493,020

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.99695
Policy Entropy: 3.29209
Value Function Loss: 0.00386

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09728
Policy Update Magnitude: 0.55648
Value Function Update Magnitude: 0.63523

Collected Steps per Second: 22,248.70150
Overall Steps per Second: 10,525.52478

Timestep Collection Time: 2.24813
Timestep Consumption Time: 2.50394
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.75207

Cumulative Model Updates: 74,040
Cumulative Timesteps: 617,543,038

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 617543038...
Checkpoint 617543038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,429.76482
Policy Entropy: 3.29366
Value Function Loss: 0.00400

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09499
Policy Update Magnitude: 0.55468
Value Function Update Magnitude: 0.63618

Collected Steps per Second: 22,357.65344
Overall Steps per Second: 10,537.84868

Timestep Collection Time: 2.23727
Timestep Consumption Time: 2.50943
PPO Batch Consumption Time: 0.29749
Total Iteration Time: 4.74670

Cumulative Model Updates: 74,046
Cumulative Timesteps: 617,593,058

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.34611
Policy Entropy: 3.26653
Value Function Loss: 0.00408

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11518
Policy Update Magnitude: 0.55540
Value Function Update Magnitude: 0.63163

Collected Steps per Second: 22,181.37585
Overall Steps per Second: 10,531.91364

Timestep Collection Time: 2.25523
Timestep Consumption Time: 2.49453
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.74975

Cumulative Model Updates: 74,052
Cumulative Timesteps: 617,643,082

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 617643082...
Checkpoint 617643082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.10249
Policy Entropy: 3.27849
Value Function Loss: 0.00408

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11064
Policy Update Magnitude: 0.55195
Value Function Update Magnitude: 0.62341

Collected Steps per Second: 22,220.42767
Overall Steps per Second: 10,556.81278

Timestep Collection Time: 2.25126
Timestep Consumption Time: 2.48729
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.73855

Cumulative Model Updates: 74,058
Cumulative Timesteps: 617,693,106

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.54844
Policy Entropy: 3.29834
Value Function Loss: 0.00382

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09190
Policy Update Magnitude: 0.54112
Value Function Update Magnitude: 0.62596

Collected Steps per Second: 23,179.86847
Overall Steps per Second: 10,795.27867

Timestep Collection Time: 2.15782
Timestep Consumption Time: 2.47550
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.63332

Cumulative Model Updates: 74,064
Cumulative Timesteps: 617,743,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 617743124...
Checkpoint 617743124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 896.75982
Policy Entropy: 3.31317
Value Function Loss: 0.00366

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08560
Policy Update Magnitude: 0.53120
Value Function Update Magnitude: 0.60187

Collected Steps per Second: 22,075.29480
Overall Steps per Second: 10,499.49341

Timestep Collection Time: 2.26633
Timestep Consumption Time: 2.49866
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.76499

Cumulative Model Updates: 74,070
Cumulative Timesteps: 617,793,154

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.24478
Policy Entropy: 3.31301
Value Function Loss: 0.00374

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08821
Policy Update Magnitude: 0.52959
Value Function Update Magnitude: 0.58430

Collected Steps per Second: 23,270.12028
Overall Steps per Second: 10,719.94100

Timestep Collection Time: 2.14997
Timestep Consumption Time: 2.51704
PPO Batch Consumption Time: 0.29718
Total Iteration Time: 4.66700

Cumulative Model Updates: 74,076
Cumulative Timesteps: 617,843,184

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 617843184...
Checkpoint 617843184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.95981
Policy Entropy: 3.30074
Value Function Loss: 0.00392

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10325
Policy Update Magnitude: 0.53361
Value Function Update Magnitude: 0.59434

Collected Steps per Second: 22,544.80971
Overall Steps per Second: 10,658.75257

Timestep Collection Time: 2.21949
Timestep Consumption Time: 2.47505
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.69455

Cumulative Model Updates: 74,082
Cumulative Timesteps: 617,893,222

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.49714
Policy Entropy: 3.29471
Value Function Loss: 0.00393

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09081
Policy Update Magnitude: 0.54672
Value Function Update Magnitude: 0.60537

Collected Steps per Second: 22,956.26366
Overall Steps per Second: 10,808.43639

Timestep Collection Time: 2.17927
Timestep Consumption Time: 2.44933
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.62861

Cumulative Model Updates: 74,088
Cumulative Timesteps: 617,943,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 617943250...
Checkpoint 617943250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.62820
Policy Entropy: 3.30105
Value Function Loss: 0.00395

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08286
Policy Update Magnitude: 0.55213
Value Function Update Magnitude: 0.62060

Collected Steps per Second: 22,541.70504
Overall Steps per Second: 10,699.01043

Timestep Collection Time: 2.21838
Timestep Consumption Time: 2.45551
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.67389

Cumulative Model Updates: 74,094
Cumulative Timesteps: 617,993,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 879.78117
Policy Entropy: 3.31597
Value Function Loss: 0.00381

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08311
Policy Update Magnitude: 0.54786
Value Function Update Magnitude: 0.61385

Collected Steps per Second: 22,882.11985
Overall Steps per Second: 10,842.01193

Timestep Collection Time: 2.18642
Timestep Consumption Time: 2.42803
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.61446

Cumulative Model Updates: 74,100
Cumulative Timesteps: 618,043,286

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 618043286...
Checkpoint 618043286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,339.17309
Policy Entropy: 3.32593
Value Function Loss: 0.00372

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07916
Policy Update Magnitude: 0.53914
Value Function Update Magnitude: 0.59310

Collected Steps per Second: 22,470.41551
Overall Steps per Second: 10,754.47242

Timestep Collection Time: 2.22524
Timestep Consumption Time: 2.42418
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.64941

Cumulative Model Updates: 74,106
Cumulative Timesteps: 618,093,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,406.54458
Policy Entropy: 3.32801
Value Function Loss: 0.00380

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08154
Policy Update Magnitude: 0.54085
Value Function Update Magnitude: 0.58589

Collected Steps per Second: 22,383.91867
Overall Steps per Second: 10,607.21873

Timestep Collection Time: 2.23428
Timestep Consumption Time: 2.48062
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.71490

Cumulative Model Updates: 74,112
Cumulative Timesteps: 618,143,300

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 618143300...
Checkpoint 618143300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.71085
Policy Entropy: 3.30724
Value Function Loss: 0.00375

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08328
Policy Update Magnitude: 0.54130
Value Function Update Magnitude: 0.58799

Collected Steps per Second: 21,858.53376
Overall Steps per Second: 10,461.50419

Timestep Collection Time: 2.28872
Timestep Consumption Time: 2.49339
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.78210

Cumulative Model Updates: 74,118
Cumulative Timesteps: 618,193,328

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.60051
Policy Entropy: 3.30968
Value Function Loss: 0.00360

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07235
Policy Update Magnitude: 0.54553
Value Function Update Magnitude: 0.59243

Collected Steps per Second: 22,504.79037
Overall Steps per Second: 10,632.17506

Timestep Collection Time: 2.22264
Timestep Consumption Time: 2.48195
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.70459

Cumulative Model Updates: 74,124
Cumulative Timesteps: 618,243,348

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 618243348...
Checkpoint 618243348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.98379
Policy Entropy: 3.32635
Value Function Loss: 0.00344

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07200
Policy Update Magnitude: 0.53235
Value Function Update Magnitude: 0.58189

Collected Steps per Second: 22,336.68250
Overall Steps per Second: 10,581.37712

Timestep Collection Time: 2.23874
Timestep Consumption Time: 2.48711
PPO Batch Consumption Time: 0.29624
Total Iteration Time: 4.72585

Cumulative Model Updates: 74,130
Cumulative Timesteps: 618,293,354

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.82023
Policy Entropy: 3.33043
Value Function Loss: 0.00369

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.06951
Policy Update Magnitude: 0.53580
Value Function Update Magnitude: 0.56902

Collected Steps per Second: 23,079.59427
Overall Steps per Second: 10,739.90745

Timestep Collection Time: 2.16642
Timestep Consumption Time: 2.48912
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.65553

Cumulative Model Updates: 74,136
Cumulative Timesteps: 618,343,354

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 618343354...
Checkpoint 618343354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408.59253
Policy Entropy: 3.32379
Value Function Loss: 0.00365

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07563
Policy Update Magnitude: 0.54490
Value Function Update Magnitude: 0.57556

Collected Steps per Second: 21,940.45713
Overall Steps per Second: 10,530.66117

Timestep Collection Time: 2.27908
Timestep Consumption Time: 2.46934
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.74842

Cumulative Model Updates: 74,142
Cumulative Timesteps: 618,393,358

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,435.62162
Policy Entropy: 3.30737
Value Function Loss: 0.00363

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.54652
Value Function Update Magnitude: 0.56977

Collected Steps per Second: 22,810.37938
Overall Steps per Second: 10,657.77986

Timestep Collection Time: 2.19277
Timestep Consumption Time: 2.50032
PPO Batch Consumption Time: 0.29640
Total Iteration Time: 4.69310

Cumulative Model Updates: 74,148
Cumulative Timesteps: 618,443,376

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 618443376...
Checkpoint 618443376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 910.58223
Policy Entropy: 3.30187
Value Function Loss: 0.00376

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08865
Policy Update Magnitude: 0.54737
Value Function Update Magnitude: 0.56936

Collected Steps per Second: 22,176.07588
Overall Steps per Second: 10,616.21682

Timestep Collection Time: 2.25567
Timestep Consumption Time: 2.45617
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.71185

Cumulative Model Updates: 74,154
Cumulative Timesteps: 618,493,398

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.17457
Policy Entropy: 3.29393
Value Function Loss: 0.00387

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.55618
Value Function Update Magnitude: 0.58176

Collected Steps per Second: 23,176.50669
Overall Steps per Second: 10,893.02413

Timestep Collection Time: 2.15805
Timestep Consumption Time: 2.43352
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.59156

Cumulative Model Updates: 74,160
Cumulative Timesteps: 618,543,414

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 618543414...
Checkpoint 618543414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 807.58022
Policy Entropy: 3.29394
Value Function Loss: 0.00406

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08781
Policy Update Magnitude: 0.56120
Value Function Update Magnitude: 0.59970

Collected Steps per Second: 22,496.87818
Overall Steps per Second: 10,621.66089

Timestep Collection Time: 2.22306
Timestep Consumption Time: 2.48543
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.70849

Cumulative Model Updates: 74,166
Cumulative Timesteps: 618,593,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,536.27217
Policy Entropy: 3.29458
Value Function Loss: 0.00384

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10585
Policy Update Magnitude: 0.56125
Value Function Update Magnitude: 0.61663

Collected Steps per Second: 22,422.16894
Overall Steps per Second: 10,598.48400

Timestep Collection Time: 2.23074
Timestep Consumption Time: 2.48862
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.71935

Cumulative Model Updates: 74,172
Cumulative Timesteps: 618,643,444

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 618643444...
Checkpoint 618643444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 910.47062
Policy Entropy: 3.30189
Value Function Loss: 0.00364

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11056
Policy Update Magnitude: 0.55519
Value Function Update Magnitude: 0.61772

Collected Steps per Second: 22,623.45173
Overall Steps per Second: 10,668.45700

Timestep Collection Time: 2.21027
Timestep Consumption Time: 2.47682
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.68709

Cumulative Model Updates: 74,178
Cumulative Timesteps: 618,693,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.46496
Policy Entropy: 3.31304
Value Function Loss: 0.00380

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10587
Policy Update Magnitude: 0.54941
Value Function Update Magnitude: 0.60184

Collected Steps per Second: 22,834.52177
Overall Steps per Second: 10,738.98719

Timestep Collection Time: 2.19002
Timestep Consumption Time: 2.46666
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.65668

Cumulative Model Updates: 74,184
Cumulative Timesteps: 618,743,456

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 618743456...
Checkpoint 618743456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 773.53387
Policy Entropy: 3.29146
Value Function Loss: 0.00400

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09566
Policy Update Magnitude: 0.55812
Value Function Update Magnitude: 0.62204

Collected Steps per Second: 22,103.60982
Overall Steps per Second: 10,602.07336

Timestep Collection Time: 2.26235
Timestep Consumption Time: 2.45428
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.71662

Cumulative Model Updates: 74,190
Cumulative Timesteps: 618,793,462

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.27263
Policy Entropy: 3.28244
Value Function Loss: 0.00416

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.57517
Value Function Update Magnitude: 0.62781

Collected Steps per Second: 22,900.43069
Overall Steps per Second: 10,852.07699

Timestep Collection Time: 2.18450
Timestep Consumption Time: 2.42531
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.60981

Cumulative Model Updates: 74,196
Cumulative Timesteps: 618,843,488

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 618843488...
Checkpoint 618843488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.13855
Policy Entropy: 3.28511
Value Function Loss: 0.00414

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08760
Policy Update Magnitude: 0.57779
Value Function Update Magnitude: 0.63675

Collected Steps per Second: 22,533.77836
Overall Steps per Second: 10,722.10564

Timestep Collection Time: 2.21907
Timestep Consumption Time: 2.44457
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.66364

Cumulative Model Updates: 74,202
Cumulative Timesteps: 618,893,492

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 967.58599
Policy Entropy: 3.29209
Value Function Loss: 0.00420

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09701
Policy Update Magnitude: 0.57159
Value Function Update Magnitude: 0.64796

Collected Steps per Second: 22,958.83686
Overall Steps per Second: 10,835.51733

Timestep Collection Time: 2.17798
Timestep Consumption Time: 2.43684
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.61482

Cumulative Model Updates: 74,208
Cumulative Timesteps: 618,943,496

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 618943496...
Checkpoint 618943496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,010.73089
Policy Entropy: 3.30180
Value Function Loss: 0.00416

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.56708
Value Function Update Magnitude: 0.65733

Collected Steps per Second: 22,593.18208
Overall Steps per Second: 10,700.26480

Timestep Collection Time: 2.21341
Timestep Consumption Time: 2.46012
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.67353

Cumulative Model Updates: 74,214
Cumulative Timesteps: 618,993,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.47471
Policy Entropy: 3.28653
Value Function Loss: 0.00424

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.56964
Value Function Update Magnitude: 0.66352

Collected Steps per Second: 23,048.96446
Overall Steps per Second: 10,930.36869

Timestep Collection Time: 2.17008
Timestep Consumption Time: 2.40598
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.57606

Cumulative Model Updates: 74,220
Cumulative Timesteps: 619,043,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 619043522...
Checkpoint 619043522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.22502
Policy Entropy: 3.29332
Value Function Loss: 0.00407

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08480
Policy Update Magnitude: 0.56010
Value Function Update Magnitude: 0.65428

Collected Steps per Second: 22,037.54175
Overall Steps per Second: 10,652.08144

Timestep Collection Time: 2.26886
Timestep Consumption Time: 2.42506
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.69392

Cumulative Model Updates: 74,226
Cumulative Timesteps: 619,093,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.39245
Policy Entropy: 3.28736
Value Function Loss: 0.00395

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08761
Policy Update Magnitude: 0.54964
Value Function Update Magnitude: 0.63022

Collected Steps per Second: 21,322.20710
Overall Steps per Second: 10,431.70646

Timestep Collection Time: 2.34516
Timestep Consumption Time: 2.44830
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.79346

Cumulative Model Updates: 74,232
Cumulative Timesteps: 619,143,526

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 619143526...
Checkpoint 619143526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 799.37252
Policy Entropy: 3.30860
Value Function Loss: 0.00395

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09367
Policy Update Magnitude: 0.55083
Value Function Update Magnitude: 0.60645

Collected Steps per Second: 21,738.07042
Overall Steps per Second: 10,628.73877

Timestep Collection Time: 2.30103
Timestep Consumption Time: 2.40508
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.70611

Cumulative Model Updates: 74,238
Cumulative Timesteps: 619,193,546

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.17524
Policy Entropy: 3.30759
Value Function Loss: 0.00410

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.55429
Value Function Update Magnitude: 0.60314

Collected Steps per Second: 21,744.48147
Overall Steps per Second: 10,526.78606

Timestep Collection Time: 2.29943
Timestep Consumption Time: 2.45035
PPO Batch Consumption Time: 0.29616
Total Iteration Time: 4.74979

Cumulative Model Updates: 74,244
Cumulative Timesteps: 619,243,546

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 619243546...
Checkpoint 619243546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 782.84009
Policy Entropy: 3.31381
Value Function Loss: 0.00393

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.55564
Value Function Update Magnitude: 0.61132

Collected Steps per Second: 22,114.91737
Overall Steps per Second: 10,600.91505

Timestep Collection Time: 2.26182
Timestep Consumption Time: 2.45664
PPO Batch Consumption Time: 0.29763
Total Iteration Time: 4.71846

Cumulative Model Updates: 74,250
Cumulative Timesteps: 619,293,566

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.04960
Policy Entropy: 3.30972
Value Function Loss: 0.00377

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09869
Policy Update Magnitude: 0.54628
Value Function Update Magnitude: 0.59657

Collected Steps per Second: 21,677.93248
Overall Steps per Second: 10,491.92829

Timestep Collection Time: 2.30723
Timestep Consumption Time: 2.45986
PPO Batch Consumption Time: 0.29686
Total Iteration Time: 4.76709

Cumulative Model Updates: 74,256
Cumulative Timesteps: 619,343,582

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 619343582...
Checkpoint 619343582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 954.42862
Policy Entropy: 3.30395
Value Function Loss: 0.00355

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08972
Policy Update Magnitude: 0.53821
Value Function Update Magnitude: 0.58063

Collected Steps per Second: 21,989.67266
Overall Steps per Second: 10,586.45403

Timestep Collection Time: 2.27389
Timestep Consumption Time: 2.44932
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.72321

Cumulative Model Updates: 74,262
Cumulative Timesteps: 619,393,584

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.54026
Policy Entropy: 3.30076
Value Function Loss: 0.00374

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.53434
Value Function Update Magnitude: 0.57713

Collected Steps per Second: 22,234.70030
Overall Steps per Second: 10,794.90013

Timestep Collection Time: 2.24946
Timestep Consumption Time: 2.38384
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.63330

Cumulative Model Updates: 74,268
Cumulative Timesteps: 619,443,600

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 619443600...
Checkpoint 619443600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 718.30965
Policy Entropy: 3.30341
Value Function Loss: 0.00372

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09830
Policy Update Magnitude: 0.53655
Value Function Update Magnitude: 0.59167

Collected Steps per Second: 22,103.61597
Overall Steps per Second: 10,736.05709

Timestep Collection Time: 2.26325
Timestep Consumption Time: 2.39638
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.65963

Cumulative Model Updates: 74,274
Cumulative Timesteps: 619,493,626

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 975.22346
Policy Entropy: 3.30153
Value Function Loss: 0.00366

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08734
Policy Update Magnitude: 0.53514
Value Function Update Magnitude: 0.57766

Collected Steps per Second: 22,921.76074
Overall Steps per Second: 10,784.54260

Timestep Collection Time: 2.18264
Timestep Consumption Time: 2.45640
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.63905

Cumulative Model Updates: 74,280
Cumulative Timesteps: 619,543,656

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 619543656...
Checkpoint 619543656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.37267
Policy Entropy: 3.29749
Value Function Loss: 0.00385

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08529
Policy Update Magnitude: 0.54200
Value Function Update Magnitude: 0.57620

Collected Steps per Second: 22,842.76852
Overall Steps per Second: 10,789.06337

Timestep Collection Time: 2.18914
Timestep Consumption Time: 2.44574
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.63488

Cumulative Model Updates: 74,286
Cumulative Timesteps: 619,593,662

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.33969
Policy Entropy: 3.29869
Value Function Loss: 0.00395

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.55794
Value Function Update Magnitude: 0.59928

Collected Steps per Second: 22,914.31489
Overall Steps per Second: 10,778.21715

Timestep Collection Time: 2.18257
Timestep Consumption Time: 2.45753
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.64010

Cumulative Model Updates: 74,292
Cumulative Timesteps: 619,643,674

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 619643674...
Checkpoint 619643674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 691.47171
Policy Entropy: 3.29036
Value Function Loss: 0.00424

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10531
Policy Update Magnitude: 0.56783
Value Function Update Magnitude: 0.62749

Collected Steps per Second: 22,277.16445
Overall Steps per Second: 10,685.09944

Timestep Collection Time: 2.24535
Timestep Consumption Time: 2.43594
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.68129

Cumulative Model Updates: 74,298
Cumulative Timesteps: 619,693,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 853.97964
Policy Entropy: 3.30129
Value Function Loss: 0.00416

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10310
Policy Update Magnitude: 0.56911
Value Function Update Magnitude: 0.62581

Collected Steps per Second: 22,228.78265
Overall Steps per Second: 10,531.68208

Timestep Collection Time: 2.24952
Timestep Consumption Time: 2.49844
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.74796

Cumulative Model Updates: 74,304
Cumulative Timesteps: 619,743,698

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 619743698...
Checkpoint 619743698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,501.46074
Policy Entropy: 3.28855
Value Function Loss: 0.00417

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09854
Policy Update Magnitude: 0.56423
Value Function Update Magnitude: 0.62791

Collected Steps per Second: 22,173.49664
Overall Steps per Second: 10,661.47222

Timestep Collection Time: 2.25521
Timestep Consumption Time: 2.43513
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.69035

Cumulative Model Updates: 74,310
Cumulative Timesteps: 619,793,704

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.15182
Policy Entropy: 3.28815
Value Function Loss: 0.00392

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08440
Policy Update Magnitude: 0.55414
Value Function Update Magnitude: 0.62188

Collected Steps per Second: 22,523.52780
Overall Steps per Second: 10,516.15394

Timestep Collection Time: 2.22026
Timestep Consumption Time: 2.53509
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.75535

Cumulative Model Updates: 74,316
Cumulative Timesteps: 619,843,712

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 619843712...
Checkpoint 619843712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.43456
Policy Entropy: 3.28215
Value Function Loss: 0.00371

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08697
Policy Update Magnitude: 0.54446
Value Function Update Magnitude: 0.60931

Collected Steps per Second: 23,076.28016
Overall Steps per Second: 10,624.51097

Timestep Collection Time: 2.16681
Timestep Consumption Time: 2.53947
PPO Batch Consumption Time: 0.29704
Total Iteration Time: 4.70629

Cumulative Model Updates: 74,322
Cumulative Timesteps: 619,893,714

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 947.88665
Policy Entropy: 3.26933
Value Function Loss: 0.00389

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09179
Policy Update Magnitude: 0.54674
Value Function Update Magnitude: 0.59677

Collected Steps per Second: 22,673.77166
Overall Steps per Second: 10,678.56905

Timestep Collection Time: 2.20607
Timestep Consumption Time: 2.47807
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.68415

Cumulative Model Updates: 74,328
Cumulative Timesteps: 619,943,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 619943734...
Checkpoint 619943734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.60658
Policy Entropy: 3.27086
Value Function Loss: 0.00398

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10545
Policy Update Magnitude: 0.55375
Value Function Update Magnitude: 0.60587

Collected Steps per Second: 22,636.06072
Overall Steps per Second: 10,692.44281

Timestep Collection Time: 2.20886
Timestep Consumption Time: 2.46734
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.67620

Cumulative Model Updates: 74,334
Cumulative Timesteps: 619,993,734

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,610.86397
Policy Entropy: 3.26135
Value Function Loss: 0.00406

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09904
Policy Update Magnitude: 0.55482
Value Function Update Magnitude: 0.61252

Collected Steps per Second: 22,774.91225
Overall Steps per Second: 10,626.49520

Timestep Collection Time: 2.19628
Timestep Consumption Time: 2.51083
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.70710

Cumulative Model Updates: 74,340
Cumulative Timesteps: 620,043,754

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 620043754...
Checkpoint 620043754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 931.70160
Policy Entropy: 3.26918
Value Function Loss: 0.00387

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.54847
Value Function Update Magnitude: 0.60845

Collected Steps per Second: 21,941.60716
Overall Steps per Second: 10,573.01290

Timestep Collection Time: 2.27923
Timestep Consumption Time: 2.45074
PPO Batch Consumption Time: 0.29714
Total Iteration Time: 4.72997

Cumulative Model Updates: 74,346
Cumulative Timesteps: 620,093,764

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,676.76934
Policy Entropy: 3.27017
Value Function Loss: 0.00376

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09160
Policy Update Magnitude: 0.53958
Value Function Update Magnitude: 0.59780

Collected Steps per Second: 22,778.14808
Overall Steps per Second: 10,767.40237

Timestep Collection Time: 2.19596
Timestep Consumption Time: 2.44954
PPO Batch Consumption Time: 0.28412
Total Iteration Time: 4.64550

Cumulative Model Updates: 74,352
Cumulative Timesteps: 620,143,784

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 620143784...
Checkpoint 620143784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.63815
Policy Entropy: 3.27838
Value Function Loss: 0.00377

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08933
Policy Update Magnitude: 0.53718
Value Function Update Magnitude: 0.59695

Collected Steps per Second: 22,052.72174
Overall Steps per Second: 10,776.86504

Timestep Collection Time: 2.26766
Timestep Consumption Time: 2.37265
PPO Batch Consumption Time: 0.28174
Total Iteration Time: 4.64031

Cumulative Model Updates: 74,358
Cumulative Timesteps: 620,193,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.88278
Policy Entropy: 3.26954
Value Function Loss: 0.00394

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08053
Policy Update Magnitude: 0.54345
Value Function Update Magnitude: 0.61043

Collected Steps per Second: 22,157.37969
Overall Steps per Second: 10,800.57059

Timestep Collection Time: 2.25713
Timestep Consumption Time: 2.37337
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.63050

Cumulative Model Updates: 74,364
Cumulative Timesteps: 620,243,804

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 620243804...
Checkpoint 620243804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450.85961
Policy Entropy: 3.26867
Value Function Loss: 0.00385

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07981
Policy Update Magnitude: 0.54859
Value Function Update Magnitude: 0.60622

Collected Steps per Second: 22,058.52486
Overall Steps per Second: 10,493.58451

Timestep Collection Time: 2.26742
Timestep Consumption Time: 2.49892
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.76634

Cumulative Model Updates: 74,370
Cumulative Timesteps: 620,293,820

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.36893
Policy Entropy: 3.25907
Value Function Loss: 0.00384

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.54904
Value Function Update Magnitude: 0.60997

Collected Steps per Second: 22,574.36221
Overall Steps per Second: 10,700.91141

Timestep Collection Time: 2.21490
Timestep Consumption Time: 2.45760
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.67250

Cumulative Model Updates: 74,376
Cumulative Timesteps: 620,343,820

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 620343820...
Checkpoint 620343820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.77802
Policy Entropy: 3.27032
Value Function Loss: 0.00369

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08808
Policy Update Magnitude: 0.55088
Value Function Update Magnitude: 0.60238

Collected Steps per Second: 22,470.44455
Overall Steps per Second: 10,623.66507

Timestep Collection Time: 2.22639
Timestep Consumption Time: 2.48272
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.70911

Cumulative Model Updates: 74,382
Cumulative Timesteps: 620,393,848

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.42196
Policy Entropy: 3.28707
Value Function Loss: 0.00381

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08728
Policy Update Magnitude: 0.54509
Value Function Update Magnitude: 0.60328

Collected Steps per Second: 22,970.93903
Overall Steps per Second: 10,602.54678

Timestep Collection Time: 2.17771
Timestep Consumption Time: 2.54040
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.71811

Cumulative Model Updates: 74,388
Cumulative Timesteps: 620,443,872

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 620443872...
Checkpoint 620443872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,534.38465
Policy Entropy: 3.29873
Value Function Loss: 0.00402

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09119
Policy Update Magnitude: 0.53878
Value Function Update Magnitude: 0.60167

Collected Steps per Second: 23,033.03402
Overall Steps per Second: 10,695.82503

Timestep Collection Time: 2.17158
Timestep Consumption Time: 2.50483
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.67640

Cumulative Model Updates: 74,394
Cumulative Timesteps: 620,493,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.85508
Policy Entropy: 3.29391
Value Function Loss: 0.00399

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09821
Policy Update Magnitude: 0.53567
Value Function Update Magnitude: 0.60130

Collected Steps per Second: 22,051.45156
Overall Steps per Second: 10,717.65821

Timestep Collection Time: 2.26833
Timestep Consumption Time: 2.39873
PPO Batch Consumption Time: 0.28518
Total Iteration Time: 4.66706

Cumulative Model Updates: 74,400
Cumulative Timesteps: 620,543,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 620543910...
Checkpoint 620543910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.55107
Policy Entropy: 3.26223
Value Function Loss: 0.00405

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.53946
Value Function Update Magnitude: 0.59005

Collected Steps per Second: 23,104.13864
Overall Steps per Second: 10,663.78366

Timestep Collection Time: 2.16567
Timestep Consumption Time: 2.52647
PPO Batch Consumption Time: 0.29673
Total Iteration Time: 4.69214

Cumulative Model Updates: 74,406
Cumulative Timesteps: 620,593,946

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653.96678
Policy Entropy: 3.27532
Value Function Loss: 0.00407

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12236
Policy Update Magnitude: 0.54609
Value Function Update Magnitude: 0.59583

Collected Steps per Second: 22,864.24772
Overall Steps per Second: 10,800.03576

Timestep Collection Time: 2.18796
Timestep Consumption Time: 2.44406
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.63202

Cumulative Model Updates: 74,412
Cumulative Timesteps: 620,643,972

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 620643972...
Checkpoint 620643972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.05941
Policy Entropy: 3.28460
Value Function Loss: 0.00393

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.11998
Policy Update Magnitude: 0.54119
Value Function Update Magnitude: 0.61055

Collected Steps per Second: 21,858.90934
Overall Steps per Second: 10,746.32099

Timestep Collection Time: 2.28813
Timestep Consumption Time: 2.36612
PPO Batch Consumption Time: 0.28193
Total Iteration Time: 4.65424

Cumulative Model Updates: 74,418
Cumulative Timesteps: 620,693,988

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.33127
Policy Entropy: 3.29458
Value Function Loss: 0.00390

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09182
Policy Update Magnitude: 0.53762
Value Function Update Magnitude: 0.61486

Collected Steps per Second: 21,861.75159
Overall Steps per Second: 10,583.58976

Timestep Collection Time: 2.28737
Timestep Consumption Time: 2.43749
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.72486

Cumulative Model Updates: 74,424
Cumulative Timesteps: 620,743,994

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 620743994...
Checkpoint 620743994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,379.43694
Policy Entropy: 3.29964
Value Function Loss: 0.00376

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09127
Policy Update Magnitude: 0.53487
Value Function Update Magnitude: 0.62716

Collected Steps per Second: 21,797.52899
Overall Steps per Second: 10,562.88822

Timestep Collection Time: 2.29421
Timestep Consumption Time: 2.44011
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.73431

Cumulative Model Updates: 74,430
Cumulative Timesteps: 620,794,002

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.31326
Policy Entropy: 3.30564
Value Function Loss: 0.00379

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07471
Policy Update Magnitude: 0.53810
Value Function Update Magnitude: 0.63216

Collected Steps per Second: 21,772.13325
Overall Steps per Second: 10,593.58670

Timestep Collection Time: 2.29743
Timestep Consumption Time: 2.42429
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.72172

Cumulative Model Updates: 74,436
Cumulative Timesteps: 620,844,022

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 620844022...
Checkpoint 620844022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.75015
Policy Entropy: 3.31890
Value Function Loss: 0.00373

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09494
Policy Update Magnitude: 0.53824
Value Function Update Magnitude: 0.64855

Collected Steps per Second: 21,998.91875
Overall Steps per Second: 10,792.51399

Timestep Collection Time: 2.27366
Timestep Consumption Time: 2.36085
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.63451

Cumulative Model Updates: 74,442
Cumulative Timesteps: 620,894,040

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 993.06741
Policy Entropy: 3.31351
Value Function Loss: 0.00365

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09795
Policy Update Magnitude: 0.53109
Value Function Update Magnitude: 0.67790

Collected Steps per Second: 22,192.42544
Overall Steps per Second: 10,526.68757

Timestep Collection Time: 2.25356
Timestep Consumption Time: 2.49741
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.75097

Cumulative Model Updates: 74,448
Cumulative Timesteps: 620,944,052

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 620944052...
Checkpoint 620944052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.43084
Policy Entropy: 3.30836
Value Function Loss: 0.00372

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.52695
Value Function Update Magnitude: 0.67832

Collected Steps per Second: 22,412.88835
Overall Steps per Second: 10,645.45281

Timestep Collection Time: 2.23247
Timestep Consumption Time: 2.46776
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.70022

Cumulative Model Updates: 74,454
Cumulative Timesteps: 620,994,088

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.58376
Policy Entropy: 3.30369
Value Function Loss: 0.00370

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08702
Policy Update Magnitude: 0.53368
Value Function Update Magnitude: 0.64943

Collected Steps per Second: 22,023.73303
Overall Steps per Second: 10,520.83739

Timestep Collection Time: 2.27146
Timestep Consumption Time: 2.48349
PPO Batch Consumption Time: 0.29646
Total Iteration Time: 4.75494

Cumulative Model Updates: 74,460
Cumulative Timesteps: 621,044,114

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 621044114...
Checkpoint 621044114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.97813
Policy Entropy: 3.29984
Value Function Loss: 0.00371

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08166
Policy Update Magnitude: 0.53661
Value Function Update Magnitude: 0.62265

Collected Steps per Second: 22,159.84590
Overall Steps per Second: 10,597.19670

Timestep Collection Time: 2.25687
Timestep Consumption Time: 2.46249
PPO Batch Consumption Time: 0.29743
Total Iteration Time: 4.71936

Cumulative Model Updates: 74,466
Cumulative Timesteps: 621,094,126

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,508.27447
Policy Entropy: 3.30290
Value Function Loss: 0.00366

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08629
Policy Update Magnitude: 0.53389
Value Function Update Magnitude: 0.61534

Collected Steps per Second: 22,002.48294
Overall Steps per Second: 10,602.92021

Timestep Collection Time: 2.27247
Timestep Consumption Time: 2.44321
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.71568

Cumulative Model Updates: 74,472
Cumulative Timesteps: 621,144,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 621144126...
Checkpoint 621144126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,839.68642
Policy Entropy: 3.30081
Value Function Loss: 0.00367

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09991
Policy Update Magnitude: 0.53440
Value Function Update Magnitude: 0.63503

Collected Steps per Second: 22,242.16159
Overall Steps per Second: 10,673.53150

Timestep Collection Time: 2.24915
Timestep Consumption Time: 2.43777
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.68692

Cumulative Model Updates: 74,478
Cumulative Timesteps: 621,194,152

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.02395
Policy Entropy: 3.29861
Value Function Loss: 0.00347

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09126
Policy Update Magnitude: 0.52619
Value Function Update Magnitude: 0.62037

Collected Steps per Second: 22,188.03432
Overall Steps per Second: 10,800.60557

Timestep Collection Time: 2.25473
Timestep Consumption Time: 2.37723
PPO Batch Consumption Time: 0.28139
Total Iteration Time: 4.63196

Cumulative Model Updates: 74,484
Cumulative Timesteps: 621,244,180

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 621244180...
Checkpoint 621244180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 996.90290
Policy Entropy: 3.29441
Value Function Loss: 0.00352

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08180
Policy Update Magnitude: 0.52273
Value Function Update Magnitude: 0.60028

Collected Steps per Second: 22,125.84950
Overall Steps per Second: 10,579.51163

Timestep Collection Time: 2.26025
Timestep Consumption Time: 2.46681
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.72706

Cumulative Model Updates: 74,490
Cumulative Timesteps: 621,294,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178.39386
Policy Entropy: 3.29323
Value Function Loss: 0.00369

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08726
Policy Update Magnitude: 0.52602
Value Function Update Magnitude: 0.57812

Collected Steps per Second: 22,709.20436
Overall Steps per Second: 10,560.00701

Timestep Collection Time: 2.20237
Timestep Consumption Time: 2.53380
PPO Batch Consumption Time: 0.29517
Total Iteration Time: 4.73617

Cumulative Model Updates: 74,496
Cumulative Timesteps: 621,344,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 621344204...
Checkpoint 621344204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,471.50423
Policy Entropy: 3.29308
Value Function Loss: 0.00384

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08481
Policy Update Magnitude: 0.53568
Value Function Update Magnitude: 0.58910

Collected Steps per Second: 21,821.74967
Overall Steps per Second: 10,527.72472

Timestep Collection Time: 2.29239
Timestep Consumption Time: 2.45925
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.75164

Cumulative Model Updates: 74,502
Cumulative Timesteps: 621,394,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.69194
Policy Entropy: 3.30123
Value Function Loss: 0.00396

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09762
Policy Update Magnitude: 0.53939
Value Function Update Magnitude: 0.61767

Collected Steps per Second: 21,779.06401
Overall Steps per Second: 10,515.34108

Timestep Collection Time: 2.29615
Timestep Consumption Time: 2.45957
PPO Batch Consumption Time: 0.29641
Total Iteration Time: 4.75572

Cumulative Model Updates: 74,508
Cumulative Timesteps: 621,444,236

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 621444236...
Checkpoint 621444236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631.78392
Policy Entropy: 3.30540
Value Function Loss: 0.00407

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10517
Policy Update Magnitude: 0.54854
Value Function Update Magnitude: 0.64142

Collected Steps per Second: 22,486.21873
Overall Steps per Second: 10,607.46949

Timestep Collection Time: 2.22385
Timestep Consumption Time: 2.49037
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.71423

Cumulative Model Updates: 74,514
Cumulative Timesteps: 621,494,242

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.38649
Policy Entropy: 3.31741
Value Function Loss: 0.00429

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10831
Policy Update Magnitude: 0.55437
Value Function Update Magnitude: 0.64823

Collected Steps per Second: 22,314.93268
Overall Steps per Second: 10,454.97996

Timestep Collection Time: 2.24146
Timestep Consumption Time: 2.54267
PPO Batch Consumption Time: 0.29731
Total Iteration Time: 4.78413

Cumulative Model Updates: 74,520
Cumulative Timesteps: 621,544,260

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 621544260...
Checkpoint 621544260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 830.62496
Policy Entropy: 3.32431
Value Function Loss: 0.00405

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.55213
Value Function Update Magnitude: 0.64877

Collected Steps per Second: 22,880.37409
Overall Steps per Second: 10,628.02741

Timestep Collection Time: 2.18563
Timestep Consumption Time: 2.51967
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.70529

Cumulative Model Updates: 74,526
Cumulative Timesteps: 621,594,268

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 916.13082
Policy Entropy: 3.31712
Value Function Loss: 0.00404

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09486
Policy Update Magnitude: 0.54479
Value Function Update Magnitude: 0.63697

Collected Steps per Second: 22,959.99503
Overall Steps per Second: 10,634.93157

Timestep Collection Time: 2.17857
Timestep Consumption Time: 2.52480
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.70337

Cumulative Model Updates: 74,532
Cumulative Timesteps: 621,644,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 621644288...
Checkpoint 621644288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706.60700
Policy Entropy: 3.32211
Value Function Loss: 0.00397

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09039
Policy Update Magnitude: 0.54416
Value Function Update Magnitude: 0.62342

Collected Steps per Second: 23,115.40052
Overall Steps per Second: 10,823.51078

Timestep Collection Time: 2.16393
Timestep Consumption Time: 2.45750
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.62142

Cumulative Model Updates: 74,538
Cumulative Timesteps: 621,694,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 725.10429
Policy Entropy: 3.30677
Value Function Loss: 0.00406

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.54407
Value Function Update Magnitude: 0.61659

Collected Steps per Second: 22,429.51403
Overall Steps per Second: 10,553.06520

Timestep Collection Time: 2.23054
Timestep Consumption Time: 2.51026
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.74080

Cumulative Model Updates: 74,544
Cumulative Timesteps: 621,744,338

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 621744338...
Checkpoint 621744338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679.56171
Policy Entropy: 3.31121
Value Function Loss: 0.00381

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.07933
Policy Update Magnitude: 0.54132
Value Function Update Magnitude: 0.61001

Collected Steps per Second: 22,914.86523
Overall Steps per Second: 10,602.79721

Timestep Collection Time: 2.18286
Timestep Consumption Time: 2.53476
PPO Batch Consumption Time: 0.29848
Total Iteration Time: 4.71762

Cumulative Model Updates: 74,550
Cumulative Timesteps: 621,794,358

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.22148
Policy Entropy: 3.31385
Value Function Loss: 0.00394

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07492
Policy Update Magnitude: 0.54564
Value Function Update Magnitude: 0.61696

Collected Steps per Second: 22,726.18553
Overall Steps per Second: 10,663.49009

Timestep Collection Time: 2.20125
Timestep Consumption Time: 2.49009
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.69133

Cumulative Model Updates: 74,556
Cumulative Timesteps: 621,844,384

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 621844384...
Checkpoint 621844384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602.72949
Policy Entropy: 3.30796
Value Function Loss: 0.00408

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.55682
Value Function Update Magnitude: 0.63353

Collected Steps per Second: 22,983.58150
Overall Steps per Second: 10,798.23249

Timestep Collection Time: 2.17642
Timestep Consumption Time: 2.45600
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.63242

Cumulative Model Updates: 74,562
Cumulative Timesteps: 621,894,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.41825
Policy Entropy: 3.30395
Value Function Loss: 0.00411

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07698
Policy Update Magnitude: 0.55892
Value Function Update Magnitude: 0.65169

Collected Steps per Second: 21,411.61813
Overall Steps per Second: 10,448.45997

Timestep Collection Time: 2.33621
Timestep Consumption Time: 2.45129
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.78750

Cumulative Model Updates: 74,568
Cumulative Timesteps: 621,944,428

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 621944428...
Checkpoint 621944428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,058.36784
Policy Entropy: 3.31449
Value Function Loss: 0.00386

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07845
Policy Update Magnitude: 0.55615
Value Function Update Magnitude: 0.65383

Collected Steps per Second: 22,116.63747
Overall Steps per Second: 10,522.46055

Timestep Collection Time: 2.26137
Timestep Consumption Time: 2.49170
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.75307

Cumulative Model Updates: 74,574
Cumulative Timesteps: 621,994,442

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,950.53574
Policy Entropy: 3.31385
Value Function Loss: 0.00362

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.53621
Value Function Update Magnitude: 0.63784

Collected Steps per Second: 22,647.59526
Overall Steps per Second: 10,718.35317

Timestep Collection Time: 2.20853
Timestep Consumption Time: 2.45804
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.66658

Cumulative Model Updates: 74,580
Cumulative Timesteps: 622,044,460

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 622044460...
Checkpoint 622044460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.31277
Policy Entropy: 3.31983
Value Function Loss: 0.00353

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08845
Policy Update Magnitude: 0.51975
Value Function Update Magnitude: 0.63328

Collected Steps per Second: 22,303.58386
Overall Steps per Second: 10,659.73225

Timestep Collection Time: 2.24206
Timestep Consumption Time: 2.44905
PPO Batch Consumption Time: 0.28168
Total Iteration Time: 4.69111

Cumulative Model Updates: 74,586
Cumulative Timesteps: 622,094,466

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.10132
Policy Entropy: 3.30054
Value Function Loss: 0.00345

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08411
Policy Update Magnitude: 0.51870
Value Function Update Magnitude: 0.64481

Collected Steps per Second: 22,560.24966
Overall Steps per Second: 10,490.91268

Timestep Collection Time: 2.21744
Timestep Consumption Time: 2.55107
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.76851

Cumulative Model Updates: 74,592
Cumulative Timesteps: 622,144,492

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 622144492...
Checkpoint 622144492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 749.88934
Policy Entropy: 3.29146
Value Function Loss: 0.00365

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08240
Policy Update Magnitude: 0.52726
Value Function Update Magnitude: 0.63958

Collected Steps per Second: 22,794.95727
Overall Steps per Second: 10,569.06522

Timestep Collection Time: 2.19417
Timestep Consumption Time: 2.53813
PPO Batch Consumption Time: 0.29743
Total Iteration Time: 4.73230

Cumulative Model Updates: 74,598
Cumulative Timesteps: 622,194,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.08777
Policy Entropy: 3.29034
Value Function Loss: 0.00385

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07176
Policy Update Magnitude: 0.53757
Value Function Update Magnitude: 0.64372

Collected Steps per Second: 22,771.47903
Overall Steps per Second: 10,670.25559

Timestep Collection Time: 2.19652
Timestep Consumption Time: 2.49109
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.68761

Cumulative Model Updates: 74,604
Cumulative Timesteps: 622,244,526

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 622244526...
Checkpoint 622244526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.97293
Policy Entropy: 3.26936
Value Function Loss: 0.00395

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.54616
Value Function Update Magnitude: 0.66017

Collected Steps per Second: 22,851.10310
Overall Steps per Second: 10,771.68226

Timestep Collection Time: 2.18930
Timestep Consumption Time: 2.45510
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.64440

Cumulative Model Updates: 74,610
Cumulative Timesteps: 622,294,554

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.51438
Policy Entropy: 3.27685
Value Function Loss: 0.00381

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08358
Policy Update Magnitude: 0.54256
Value Function Update Magnitude: 0.66629

Collected Steps per Second: 22,553.25446
Overall Steps per Second: 10,572.89915

Timestep Collection Time: 2.21715
Timestep Consumption Time: 2.51230
PPO Batch Consumption Time: 0.29748
Total Iteration Time: 4.72945

Cumulative Model Updates: 74,616
Cumulative Timesteps: 622,344,558

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 622344558...
Checkpoint 622344558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.79687
Policy Entropy: 3.28495
Value Function Loss: 0.00367

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08508
Policy Update Magnitude: 0.54374
Value Function Update Magnitude: 0.64792

Collected Steps per Second: 22,808.63207
Overall Steps per Second: 10,642.13851

Timestep Collection Time: 2.19347
Timestep Consumption Time: 2.50765
PPO Batch Consumption Time: 0.29763
Total Iteration Time: 4.70112

Cumulative Model Updates: 74,622
Cumulative Timesteps: 622,394,588

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.26250
Policy Entropy: 3.28517
Value Function Loss: 0.00376

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.54823
Value Function Update Magnitude: 0.63910

Collected Steps per Second: 22,815.08820
Overall Steps per Second: 10,792.29371

Timestep Collection Time: 2.19285
Timestep Consumption Time: 2.44287
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.63572

Cumulative Model Updates: 74,628
Cumulative Timesteps: 622,444,618

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 622444618...
Checkpoint 622444618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686.32344
Policy Entropy: 3.27924
Value Function Loss: 0.00404

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10360
Policy Update Magnitude: 0.55036
Value Function Update Magnitude: 0.64193

Collected Steps per Second: 22,394.41144
Overall Steps per Second: 10,755.53978

Timestep Collection Time: 2.23279
Timestep Consumption Time: 2.41616
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.64895

Cumulative Model Updates: 74,634
Cumulative Timesteps: 622,494,620

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 947.88531
Policy Entropy: 3.27596
Value Function Loss: 0.00410

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08677
Policy Update Magnitude: 0.55215
Value Function Update Magnitude: 0.65875

Collected Steps per Second: 22,458.65549
Overall Steps per Second: 10,611.94968

Timestep Collection Time: 2.22640
Timestep Consumption Time: 2.48546
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.71186

Cumulative Model Updates: 74,640
Cumulative Timesteps: 622,544,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 622544622...
Checkpoint 622544622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 944.52383
Policy Entropy: 3.28339
Value Function Loss: 0.00399

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09719
Policy Update Magnitude: 0.54823
Value Function Update Magnitude: 0.66522

Collected Steps per Second: 22,242.68552
Overall Steps per Second: 10,567.65744

Timestep Collection Time: 2.24847
Timestep Consumption Time: 2.48408
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.73255

Cumulative Model Updates: 74,646
Cumulative Timesteps: 622,594,634

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 924.05215
Policy Entropy: 3.28592
Value Function Loss: 0.00401

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09176
Policy Update Magnitude: 0.54433
Value Function Update Magnitude: 0.66845

Collected Steps per Second: 22,406.44302
Overall Steps per Second: 10,717.56693

Timestep Collection Time: 2.23195
Timestep Consumption Time: 2.43422
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.66617

Cumulative Model Updates: 74,652
Cumulative Timesteps: 622,644,644

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 622644644...
Checkpoint 622644644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.36853
Policy Entropy: 3.27907
Value Function Loss: 0.00400

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10697
Policy Update Magnitude: 0.55497
Value Function Update Magnitude: 0.67156

Collected Steps per Second: 22,732.90594
Overall Steps per Second: 10,701.31615

Timestep Collection Time: 2.20042
Timestep Consumption Time: 2.47396
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.67438

Cumulative Model Updates: 74,658
Cumulative Timesteps: 622,694,666

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 968.86936
Policy Entropy: 3.28106
Value Function Loss: 0.00423

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10091
Policy Update Magnitude: 0.56143
Value Function Update Magnitude: 0.68424

Collected Steps per Second: 22,624.41494
Overall Steps per Second: 10,649.37868

Timestep Collection Time: 2.21018
Timestep Consumption Time: 2.48531
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.69549

Cumulative Model Updates: 74,664
Cumulative Timesteps: 622,744,670

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 622744670...
Checkpoint 622744670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.17706
Policy Entropy: 3.30053
Value Function Loss: 0.00407

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11373
Policy Update Magnitude: 0.56181
Value Function Update Magnitude: 0.67728

Collected Steps per Second: 23,209.91974
Overall Steps per Second: 10,907.10455

Timestep Collection Time: 2.15485
Timestep Consumption Time: 2.43060
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.58545

Cumulative Model Updates: 74,670
Cumulative Timesteps: 622,794,684

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.97853
Policy Entropy: 3.30681
Value Function Loss: 0.00394

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10348
Policy Update Magnitude: 0.55634
Value Function Update Magnitude: 0.65626

Collected Steps per Second: 22,672.75565
Overall Steps per Second: 10,809.98451

Timestep Collection Time: 2.20573
Timestep Consumption Time: 2.42055
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.62628

Cumulative Model Updates: 74,676
Cumulative Timesteps: 622,844,694

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 622844694...
Checkpoint 622844694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.04584
Policy Entropy: 3.31332
Value Function Loss: 0.00377

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.54455
Value Function Update Magnitude: 0.62422

Collected Steps per Second: 22,742.27523
Overall Steps per Second: 10,732.03907

Timestep Collection Time: 2.19872
Timestep Consumption Time: 2.46060
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.65932

Cumulative Model Updates: 74,682
Cumulative Timesteps: 622,894,698

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752.97984
Policy Entropy: 3.31650
Value Function Loss: 0.00388

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09256
Policy Update Magnitude: 0.53918
Value Function Update Magnitude: 0.60562

Collected Steps per Second: 21,924.46162
Overall Steps per Second: 10,441.57999

Timestep Collection Time: 2.28092
Timestep Consumption Time: 2.50839
PPO Batch Consumption Time: 0.29644
Total Iteration Time: 4.78931

Cumulative Model Updates: 74,688
Cumulative Timesteps: 622,944,706

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 622944706...
Checkpoint 622944706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 986.84897
Policy Entropy: 3.32530
Value Function Loss: 0.00377

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09662
Policy Update Magnitude: 0.53619
Value Function Update Magnitude: 0.62005

Collected Steps per Second: 22,310.23530
Overall Steps per Second: 10,625.46358

Timestep Collection Time: 2.24166
Timestep Consumption Time: 2.46514
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.70681

Cumulative Model Updates: 74,694
Cumulative Timesteps: 622,994,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.90737
Policy Entropy: 3.32359
Value Function Loss: 0.00378

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10547
Policy Update Magnitude: 0.53164
Value Function Update Magnitude: 0.62098

Collected Steps per Second: 22,590.26079
Overall Steps per Second: 10,629.14266

Timestep Collection Time: 2.21441
Timestep Consumption Time: 2.49190
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.70631

Cumulative Model Updates: 74,700
Cumulative Timesteps: 623,044,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 623044742...
Checkpoint 623044742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 779.26933
Policy Entropy: 3.31812
Value Function Loss: 0.00403

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11241
Policy Update Magnitude: 0.53299
Value Function Update Magnitude: 0.63975

Collected Steps per Second: 22,263.98414
Overall Steps per Second: 10,535.81345

Timestep Collection Time: 2.24596
Timestep Consumption Time: 2.50014
PPO Batch Consumption Time: 0.29671
Total Iteration Time: 4.74610

Cumulative Model Updates: 74,706
Cumulative Timesteps: 623,094,746

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.64493
Policy Entropy: 3.31770
Value Function Loss: 0.00412

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11028
Policy Update Magnitude: 0.54290
Value Function Update Magnitude: 0.62754

Collected Steps per Second: 22,447.28747
Overall Steps per Second: 10,563.86855

Timestep Collection Time: 2.22833
Timestep Consumption Time: 2.50668
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.73501

Cumulative Model Updates: 74,712
Cumulative Timesteps: 623,144,766

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 623144766...
Checkpoint 623144766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.28642
Policy Entropy: 3.30773
Value Function Loss: 0.00417

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10448
Policy Update Magnitude: 0.55077
Value Function Update Magnitude: 0.62329

Collected Steps per Second: 22,379.19067
Overall Steps per Second: 10,565.96621

Timestep Collection Time: 2.23484
Timestep Consumption Time: 2.49866
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.73350

Cumulative Model Updates: 74,718
Cumulative Timesteps: 623,194,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827.20586
Policy Entropy: 3.31573
Value Function Loss: 0.00415

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11734
Policy Update Magnitude: 0.55304
Value Function Update Magnitude: 0.62303

Collected Steps per Second: 22,430.66381
Overall Steps per Second: 10,707.04026

Timestep Collection Time: 2.23034
Timestep Consumption Time: 2.44210
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.67244

Cumulative Model Updates: 74,724
Cumulative Timesteps: 623,244,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 623244808...
Checkpoint 623244808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.92399
Policy Entropy: 3.30392
Value Function Loss: 0.00412

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10202
Policy Update Magnitude: 0.56320
Value Function Update Magnitude: 0.63218

Collected Steps per Second: 22,582.30091
Overall Steps per Second: 10,728.88206

Timestep Collection Time: 2.21554
Timestep Consumption Time: 2.44776
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.66330

Cumulative Model Updates: 74,730
Cumulative Timesteps: 623,294,840

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.33746
Policy Entropy: 3.28519
Value Function Loss: 0.00414

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.56050
Value Function Update Magnitude: 0.64261

Collected Steps per Second: 22,783.00514
Overall Steps per Second: 10,686.65384

Timestep Collection Time: 2.19462
Timestep Consumption Time: 2.48411
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.67873

Cumulative Model Updates: 74,736
Cumulative Timesteps: 623,344,840

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 623344840...
Checkpoint 623344840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.97495
Policy Entropy: 3.28129
Value Function Loss: 0.00412

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08935
Policy Update Magnitude: 0.55916
Value Function Update Magnitude: 0.61915

Collected Steps per Second: 22,868.44752
Overall Steps per Second: 10,864.10221

Timestep Collection Time: 2.18651
Timestep Consumption Time: 2.41599
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.60250

Cumulative Model Updates: 74,742
Cumulative Timesteps: 623,394,842

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 947.51801
Policy Entropy: 3.28969
Value Function Loss: 0.00402

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.56182
Value Function Update Magnitude: 0.60065

Collected Steps per Second: 22,147.47942
Overall Steps per Second: 10,673.83593

Timestep Collection Time: 2.25886
Timestep Consumption Time: 2.42812
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.68697

Cumulative Model Updates: 74,748
Cumulative Timesteps: 623,444,870

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 623444870...
Checkpoint 623444870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.51134
Policy Entropy: 3.29158
Value Function Loss: 0.00393

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.10853
Policy Update Magnitude: 0.56284
Value Function Update Magnitude: 0.60598

Collected Steps per Second: 22,096.07244
Overall Steps per Second: 10,782.64882

Timestep Collection Time: 2.26294
Timestep Consumption Time: 2.37433
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.63726

Cumulative Model Updates: 74,754
Cumulative Timesteps: 623,494,872

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.19484
Policy Entropy: 3.28595
Value Function Loss: 0.00401

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.11778
Policy Update Magnitude: 0.55250
Value Function Update Magnitude: 0.63256

Collected Steps per Second: 21,985.61093
Overall Steps per Second: 10,604.65241

Timestep Collection Time: 2.27485
Timestep Consumption Time: 2.44138
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 4.71623

Cumulative Model Updates: 74,760
Cumulative Timesteps: 623,544,886

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 623544886...
Checkpoint 623544886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.56949
Policy Entropy: 3.28172
Value Function Loss: 0.00404

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.12660
Policy Update Magnitude: 0.55040
Value Function Update Magnitude: 0.64882

Collected Steps per Second: 21,524.62894
Overall Steps per Second: 10,591.13910

Timestep Collection Time: 2.32339
Timestep Consumption Time: 2.39849
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.72187

Cumulative Model Updates: 74,766
Cumulative Timesteps: 623,594,896

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 944.36754
Policy Entropy: 3.27259
Value Function Loss: 0.00397

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10324
Policy Update Magnitude: 0.55602
Value Function Update Magnitude: 0.64588

Collected Steps per Second: 22,107.30337
Overall Steps per Second: 10,668.34246

Timestep Collection Time: 2.26287
Timestep Consumption Time: 2.42633
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.68920

Cumulative Model Updates: 74,772
Cumulative Timesteps: 623,644,922

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 623644922...
Checkpoint 623644922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,689.75178
Policy Entropy: 3.28614
Value Function Loss: 0.00382

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08352
Policy Update Magnitude: 0.55419
Value Function Update Magnitude: 0.63508

Collected Steps per Second: 21,641.04694
Overall Steps per Second: 10,533.76711

Timestep Collection Time: 2.31061
Timestep Consumption Time: 2.43641
PPO Batch Consumption Time: 0.29648
Total Iteration Time: 4.74702

Cumulative Model Updates: 74,778
Cumulative Timesteps: 623,694,926

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,010.98643
Policy Entropy: 3.29240
Value Function Loss: 0.00389

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08130
Policy Update Magnitude: 0.55360
Value Function Update Magnitude: 0.60573

Collected Steps per Second: 22,116.86646
Overall Steps per Second: 10,740.40865

Timestep Collection Time: 2.26108
Timestep Consumption Time: 2.39498
PPO Batch Consumption Time: 0.28457
Total Iteration Time: 4.65606

Cumulative Model Updates: 74,784
Cumulative Timesteps: 623,744,934

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 623744934...
Checkpoint 623744934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 881.81346
Policy Entropy: 3.29468
Value Function Loss: 0.00413

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.55488
Value Function Update Magnitude: 0.60132

Collected Steps per Second: 22,563.54870
Overall Steps per Second: 10,641.29474

Timestep Collection Time: 2.21623
Timestep Consumption Time: 2.48301
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.69924

Cumulative Model Updates: 74,790
Cumulative Timesteps: 623,794,940

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.87031
Policy Entropy: 3.28567
Value Function Loss: 0.00415

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09403
Policy Update Magnitude: 0.56273
Value Function Update Magnitude: 0.63445

Collected Steps per Second: 21,897.30031
Overall Steps per Second: 10,483.02791

Timestep Collection Time: 2.28467
Timestep Consumption Time: 2.48762
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.77229

Cumulative Model Updates: 74,796
Cumulative Timesteps: 623,844,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 623844968...
Checkpoint 623844968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.05327
Policy Entropy: 3.29052
Value Function Loss: 0.00386

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.56470
Value Function Update Magnitude: 0.62648

Collected Steps per Second: 22,838.00327
Overall Steps per Second: 10,673.11374

Timestep Collection Time: 2.18951
Timestep Consumption Time: 2.49553
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.68504

Cumulative Model Updates: 74,802
Cumulative Timesteps: 623,894,972

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.28351
Policy Entropy: 3.28589
Value Function Loss: 0.00394

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08976
Policy Update Magnitude: 0.56068
Value Function Update Magnitude: 0.60714

Collected Steps per Second: 22,498.59164
Overall Steps per Second: 10,545.74694

Timestep Collection Time: 2.22281
Timestep Consumption Time: 2.51939
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.74220

Cumulative Model Updates: 74,808
Cumulative Timesteps: 623,944,982

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 623944982...
Checkpoint 623944982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 900.12766
Policy Entropy: 3.29885
Value Function Loss: 0.00370

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09247
Policy Update Magnitude: 0.54801
Value Function Update Magnitude: 0.59644

Collected Steps per Second: 22,530.91275
Overall Steps per Second: 10,491.56772

Timestep Collection Time: 2.21917
Timestep Consumption Time: 2.54656
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.76573

Cumulative Model Updates: 74,814
Cumulative Timesteps: 623,994,982

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.16125
Policy Entropy: 3.28381
Value Function Loss: 0.00390

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08933
Policy Update Magnitude: 0.54460
Value Function Update Magnitude: 0.58532

Collected Steps per Second: 22,836.60507
Overall Steps per Second: 10,628.65675

Timestep Collection Time: 2.19069
Timestep Consumption Time: 2.51620
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.70690

Cumulative Model Updates: 74,820
Cumulative Timesteps: 624,045,010

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 624045010...
Checkpoint 624045010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 833.49654
Policy Entropy: 3.30383
Value Function Loss: 0.00392

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.55471
Value Function Update Magnitude: 0.60478

Collected Steps per Second: 22,563.58152
Overall Steps per Second: 10,536.52960

Timestep Collection Time: 2.21605
Timestep Consumption Time: 2.52954
PPO Batch Consumption Time: 0.29847
Total Iteration Time: 4.74559

Cumulative Model Updates: 74,826
Cumulative Timesteps: 624,095,012

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 959.86152
Policy Entropy: 3.30939
Value Function Loss: 0.00411

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09787
Policy Update Magnitude: 0.56024
Value Function Update Magnitude: 0.61163

Collected Steps per Second: 22,393.29217
Overall Steps per Second: 10,558.86826

Timestep Collection Time: 2.23290
Timestep Consumption Time: 2.50264
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.73555

Cumulative Model Updates: 74,832
Cumulative Timesteps: 624,145,014

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 624145014...
Checkpoint 624145014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680.21907
Policy Entropy: 3.31268
Value Function Loss: 0.00429

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.56205
Value Function Update Magnitude: 0.61920

Collected Steps per Second: 22,340.13968
Overall Steps per Second: 10,478.20438

Timestep Collection Time: 2.23929
Timestep Consumption Time: 2.53500
PPO Batch Consumption Time: 0.29652
Total Iteration Time: 4.77429

Cumulative Model Updates: 74,838
Cumulative Timesteps: 624,195,040

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.67191
Policy Entropy: 3.33873
Value Function Loss: 0.00401

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10281
Policy Update Magnitude: 0.56414
Value Function Update Magnitude: 0.62946

Collected Steps per Second: 22,622.20733
Overall Steps per Second: 10,535.39896

Timestep Collection Time: 2.21057
Timestep Consumption Time: 2.53609
PPO Batch Consumption Time: 0.29700
Total Iteration Time: 4.74666

Cumulative Model Updates: 74,844
Cumulative Timesteps: 624,245,048

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 624245048...
Checkpoint 624245048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,090.93069
Policy Entropy: 3.33072
Value Function Loss: 0.00386

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10652
Policy Update Magnitude: 0.54880
Value Function Update Magnitude: 0.60608

Collected Steps per Second: 22,337.69654
Overall Steps per Second: 10,614.54866

Timestep Collection Time: 2.23846
Timestep Consumption Time: 2.47225
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.71070

Cumulative Model Updates: 74,850
Cumulative Timesteps: 624,295,050

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.80241
Policy Entropy: 3.33892
Value Function Loss: 0.00380

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09068
Policy Update Magnitude: 0.53886
Value Function Update Magnitude: 0.59320

Collected Steps per Second: 22,955.52499
Overall Steps per Second: 10,788.22094

Timestep Collection Time: 2.17926
Timestep Consumption Time: 2.45784
PPO Batch Consumption Time: 0.28171
Total Iteration Time: 4.63709

Cumulative Model Updates: 74,856
Cumulative Timesteps: 624,345,076

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 624345076...
Checkpoint 624345076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 853.93303
Policy Entropy: 3.31905
Value Function Loss: 0.00397

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08336
Policy Update Magnitude: 0.54545
Value Function Update Magnitude: 0.60605

Collected Steps per Second: 22,765.29998
Overall Steps per Second: 10,779.12129

Timestep Collection Time: 2.19747
Timestep Consumption Time: 2.44354
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.64101

Cumulative Model Updates: 74,862
Cumulative Timesteps: 624,395,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 808.63187
Policy Entropy: 3.31279
Value Function Loss: 0.00393

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.07684
Policy Update Magnitude: 0.54985
Value Function Update Magnitude: 0.60747

Collected Steps per Second: 23,113.56912
Overall Steps per Second: 10,819.40604

Timestep Collection Time: 2.16392
Timestep Consumption Time: 2.45888
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.62280

Cumulative Model Updates: 74,868
Cumulative Timesteps: 624,445,118

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 624445118...
Checkpoint 624445118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,708.44461
Policy Entropy: 3.31102
Value Function Loss: 0.00384

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07531
Policy Update Magnitude: 0.55015
Value Function Update Magnitude: 0.61312

Collected Steps per Second: 22,643.71431
Overall Steps per Second: 10,724.43544

Timestep Collection Time: 2.20882
Timestep Consumption Time: 2.45492
PPO Batch Consumption Time: 0.28231
Total Iteration Time: 4.66374

Cumulative Model Updates: 74,874
Cumulative Timesteps: 624,495,134

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.80088
Policy Entropy: 3.31476
Value Function Loss: 0.00378

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.55004
Value Function Update Magnitude: 0.61080

Collected Steps per Second: 22,656.10233
Overall Steps per Second: 10,606.31547

Timestep Collection Time: 2.20779
Timestep Consumption Time: 2.50826
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.71606

Cumulative Model Updates: 74,880
Cumulative Timesteps: 624,545,154

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 624545154...
Checkpoint 624545154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 920.84478
Policy Entropy: 3.30536
Value Function Loss: 0.00380

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09442
Policy Update Magnitude: 0.54707
Value Function Update Magnitude: 0.60193

Collected Steps per Second: 23,067.98478
Overall Steps per Second: 10,838.16070

Timestep Collection Time: 2.16803
Timestep Consumption Time: 2.44641
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.61444

Cumulative Model Updates: 74,886
Cumulative Timesteps: 624,595,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.64025
Policy Entropy: 3.30254
Value Function Loss: 0.00406

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.55128
Value Function Update Magnitude: 0.60581

Collected Steps per Second: 22,432.80909
Overall Steps per Second: 10,599.09889

Timestep Collection Time: 2.22995
Timestep Consumption Time: 2.48970
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.71965

Cumulative Model Updates: 74,892
Cumulative Timesteps: 624,645,190

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 624645190...
Checkpoint 624645190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 751.75741
Policy Entropy: 3.30140
Value Function Loss: 0.00393

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10176
Policy Update Magnitude: 0.55012
Value Function Update Magnitude: 0.58340

Collected Steps per Second: 22,237.51782
Overall Steps per Second: 10,579.03717

Timestep Collection Time: 2.24872
Timestep Consumption Time: 2.47817
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.72690

Cumulative Model Updates: 74,898
Cumulative Timesteps: 624,695,196

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.12774
Policy Entropy: 3.30251
Value Function Loss: 0.00379

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.55152
Value Function Update Magnitude: 0.57260

Collected Steps per Second: 22,813.27449
Overall Steps per Second: 10,670.12734

Timestep Collection Time: 2.19285
Timestep Consumption Time: 2.49557
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.68842

Cumulative Model Updates: 74,904
Cumulative Timesteps: 624,745,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 624745222...
Checkpoint 624745222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660.94251
Policy Entropy: 3.30116
Value Function Loss: 0.00384

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09936
Policy Update Magnitude: 0.55032
Value Function Update Magnitude: 0.55487

Collected Steps per Second: 22,403.25948
Overall Steps per Second: 10,517.54549

Timestep Collection Time: 2.23182
Timestep Consumption Time: 2.52214
PPO Batch Consumption Time: 0.29711
Total Iteration Time: 4.75396

Cumulative Model Updates: 74,910
Cumulative Timesteps: 624,795,222

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 821.19113
Policy Entropy: 3.27983
Value Function Loss: 0.00411

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10256
Policy Update Magnitude: 0.55474
Value Function Update Magnitude: 0.56214

Collected Steps per Second: 22,595.94658
Overall Steps per Second: 10,620.08892

Timestep Collection Time: 2.21314
Timestep Consumption Time: 2.49567
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.70881

Cumulative Model Updates: 74,916
Cumulative Timesteps: 624,845,230

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 624845230...
Checkpoint 624845230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.52012
Policy Entropy: 3.28977
Value Function Loss: 0.00424

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10931
Policy Update Magnitude: 0.55997
Value Function Update Magnitude: 0.58443

Collected Steps per Second: 22,068.84670
Overall Steps per Second: 10,411.99395

Timestep Collection Time: 2.26600
Timestep Consumption Time: 2.53692
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.80292

Cumulative Model Updates: 74,922
Cumulative Timesteps: 624,895,238

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.24318
Policy Entropy: 3.30431
Value Function Loss: 0.00417

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10327
Policy Update Magnitude: 0.55815
Value Function Update Magnitude: 0.60997

Collected Steps per Second: 22,659.24577
Overall Steps per Second: 10,592.45411

Timestep Collection Time: 2.20705
Timestep Consumption Time: 2.51424
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.72129

Cumulative Model Updates: 74,928
Cumulative Timesteps: 624,945,248

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 624945248...
Checkpoint 624945248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 897.79262
Policy Entropy: 3.29932
Value Function Loss: 0.00404

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08822
Policy Update Magnitude: 0.55046
Value Function Update Magnitude: 0.61190

Collected Steps per Second: 22,949.54188
Overall Steps per Second: 10,721.87124

Timestep Collection Time: 2.17974
Timestep Consumption Time: 2.48586
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.66560

Cumulative Model Updates: 74,934
Cumulative Timesteps: 624,995,272

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.94516
Policy Entropy: 3.28523
Value Function Loss: 0.00386

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08127
Policy Update Magnitude: 0.55231
Value Function Update Magnitude: 0.61215

Collected Steps per Second: 23,052.88225
Overall Steps per Second: 10,711.35773

Timestep Collection Time: 2.17031
Timestep Consumption Time: 2.50062
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.67093

Cumulative Model Updates: 74,940
Cumulative Timesteps: 625,045,304

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 625045304...
Checkpoint 625045304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 805.45359
Policy Entropy: 3.26729
Value Function Loss: 0.00400

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09806
Policy Update Magnitude: 0.55807
Value Function Update Magnitude: 0.59885

Collected Steps per Second: 22,672.77289
Overall Steps per Second: 10,585.54046

Timestep Collection Time: 2.20555
Timestep Consumption Time: 2.51844
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.72399

Cumulative Model Updates: 74,946
Cumulative Timesteps: 625,095,310

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 806.49222
Policy Entropy: 3.27221
Value Function Loss: 0.00401

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08753
Policy Update Magnitude: 0.56385
Value Function Update Magnitude: 0.58946

Collected Steps per Second: 22,759.70731
Overall Steps per Second: 10,646.88690

Timestep Collection Time: 2.19827
Timestep Consumption Time: 2.50094
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.69921

Cumulative Model Updates: 74,952
Cumulative Timesteps: 625,145,342

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 625145342...
Checkpoint 625145342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595.80780
Policy Entropy: 3.27620
Value Function Loss: 0.00413

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09255
Policy Update Magnitude: 0.56063
Value Function Update Magnitude: 0.59363

Collected Steps per Second: 22,865.98991
Overall Steps per Second: 10,682.58547

Timestep Collection Time: 2.18727
Timestep Consumption Time: 2.49456
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.68183

Cumulative Model Updates: 74,958
Cumulative Timesteps: 625,195,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.50700
Policy Entropy: 3.27241
Value Function Loss: 0.00408

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.56069
Value Function Update Magnitude: 0.60175

Collected Steps per Second: 22,419.11898
Overall Steps per Second: 10,684.44076

Timestep Collection Time: 2.23033
Timestep Consumption Time: 2.44956
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.67989

Cumulative Model Updates: 74,964
Cumulative Timesteps: 625,245,358

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 625245358...
Checkpoint 625245358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 781.35068
Policy Entropy: 3.25144
Value Function Loss: 0.00425

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11058
Policy Update Magnitude: 0.56854
Value Function Update Magnitude: 0.59740

Collected Steps per Second: 22,110.14973
Overall Steps per Second: 10,612.98281

Timestep Collection Time: 2.26276
Timestep Consumption Time: 2.45128
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.71404

Cumulative Model Updates: 74,970
Cumulative Timesteps: 625,295,388

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.62685
Policy Entropy: 3.24381
Value Function Loss: 0.00449

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.14618
Policy Update Magnitude: 0.57248
Value Function Update Magnitude: 0.59446

Collected Steps per Second: 22,571.37807
Overall Steps per Second: 10,529.27267

Timestep Collection Time: 2.21599
Timestep Consumption Time: 2.53438
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.75038

Cumulative Model Updates: 74,976
Cumulative Timesteps: 625,345,406

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 625345406...
Checkpoint 625345406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.02470
Policy Entropy: 3.24258
Value Function Loss: 0.00421

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.14157
Policy Update Magnitude: 0.56449
Value Function Update Magnitude: 0.56562

Collected Steps per Second: 22,246.08298
Overall Steps per Second: 10,665.84262

Timestep Collection Time: 2.24786
Timestep Consumption Time: 2.44057
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.68842

Cumulative Model Updates: 74,982
Cumulative Timesteps: 625,395,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.44510
Policy Entropy: 3.24106
Value Function Loss: 0.00437

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11364
Policy Update Magnitude: 0.55357
Value Function Update Magnitude: 0.55053

Collected Steps per Second: 23,038.65537
Overall Steps per Second: 10,627.73692

Timestep Collection Time: 2.17070
Timestep Consumption Time: 2.53491
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.70561

Cumulative Model Updates: 74,988
Cumulative Timesteps: 625,445,422

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 625445422...
Checkpoint 625445422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 863.55925
Policy Entropy: 3.23544
Value Function Loss: 0.00432

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10609
Policy Update Magnitude: 0.56172
Value Function Update Magnitude: 0.56665

Collected Steps per Second: 22,671.81983
Overall Steps per Second: 10,749.94242

Timestep Collection Time: 2.20556
Timestep Consumption Time: 2.44600
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.65156

Cumulative Model Updates: 74,994
Cumulative Timesteps: 625,495,426

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714.83784
Policy Entropy: 3.22966
Value Function Loss: 0.00423

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11596
Policy Update Magnitude: 0.56743
Value Function Update Magnitude: 0.57894

Collected Steps per Second: 22,928.80209
Overall Steps per Second: 10,608.78912

Timestep Collection Time: 2.18093
Timestep Consumption Time: 2.53271
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 4.71364

Cumulative Model Updates: 75,000
Cumulative Timesteps: 625,545,432

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 625545432...
Checkpoint 625545432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.30470
Policy Entropy: 3.23882
Value Function Loss: 0.00406

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11756
Policy Update Magnitude: 0.56210
Value Function Update Magnitude: 0.57979

Collected Steps per Second: 22,903.26044
Overall Steps per Second: 10,744.53581

Timestep Collection Time: 2.18423
Timestep Consumption Time: 2.47172
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.65595

Cumulative Model Updates: 75,006
Cumulative Timesteps: 625,595,458

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648.25140
Policy Entropy: 3.25777
Value Function Loss: 0.00383

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11576
Policy Update Magnitude: 0.55239
Value Function Update Magnitude: 0.59206

Collected Steps per Second: 23,046.97509
Overall Steps per Second: 10,769.55525

Timestep Collection Time: 2.16992
Timestep Consumption Time: 2.47373
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.64365

Cumulative Model Updates: 75,012
Cumulative Timesteps: 625,645,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 625645468...
Checkpoint 625645468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 888.19448
Policy Entropy: 3.26734
Value Function Loss: 0.00394

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13082
Policy Update Magnitude: 0.54842
Value Function Update Magnitude: 0.60389

Collected Steps per Second: 22,526.54354
Overall Steps per Second: 10,620.19262

Timestep Collection Time: 2.22031
Timestep Consumption Time: 2.48921
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.70952

Cumulative Model Updates: 75,018
Cumulative Timesteps: 625,695,484

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678.14563
Policy Entropy: 3.26537
Value Function Loss: 0.00404

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11192
Policy Update Magnitude: 0.55239
Value Function Update Magnitude: 0.59858

Collected Steps per Second: 21,434.73593
Overall Steps per Second: 10,513.06472

Timestep Collection Time: 2.33294
Timestep Consumption Time: 2.42362
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.75656

Cumulative Model Updates: 75,024
Cumulative Timesteps: 625,745,490

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 625745490...
Checkpoint 625745490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624.88321
Policy Entropy: 3.25490
Value Function Loss: 0.00425

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11304
Policy Update Magnitude: 0.56664
Value Function Update Magnitude: 0.60802

Collected Steps per Second: 22,141.02656
Overall Steps per Second: 10,609.30373

Timestep Collection Time: 2.25943
Timestep Consumption Time: 2.45587
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.71530

Cumulative Model Updates: 75,030
Cumulative Timesteps: 625,795,516

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.95206
Policy Entropy: 3.25822
Value Function Loss: 0.00426

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.57563
Value Function Update Magnitude: 0.63944

Collected Steps per Second: 22,519.42114
Overall Steps per Second: 10,870.41081

Timestep Collection Time: 2.22075
Timestep Consumption Time: 2.37981
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.60056

Cumulative Model Updates: 75,036
Cumulative Timesteps: 625,845,526

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 625845526...
Checkpoint 625845526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 860.26388
Policy Entropy: 3.25367
Value Function Loss: 0.00414

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09024
Policy Update Magnitude: 0.57298
Value Function Update Magnitude: 0.65033

Collected Steps per Second: 21,607.20156
Overall Steps per Second: 10,627.90807

Timestep Collection Time: 2.31404
Timestep Consumption Time: 2.39055
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.70459

Cumulative Model Updates: 75,042
Cumulative Timesteps: 625,895,526

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663.35398
Policy Entropy: 3.26794
Value Function Loss: 0.00413

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09852
Policy Update Magnitude: 0.56872
Value Function Update Magnitude: 0.64683

Collected Steps per Second: 22,473.10320
Overall Steps per Second: 10,865.89159

Timestep Collection Time: 2.22631
Timestep Consumption Time: 2.37819
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.60450

Cumulative Model Updates: 75,048
Cumulative Timesteps: 625,945,558

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 625945558...
Checkpoint 625945558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668.86879
Policy Entropy: 3.24864
Value Function Loss: 0.00425

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09869
Policy Update Magnitude: 0.57078
Value Function Update Magnitude: 0.64722

Collected Steps per Second: 22,103.33208
Overall Steps per Second: 10,792.23860

Timestep Collection Time: 2.26310
Timestep Consumption Time: 2.37190
PPO Batch Consumption Time: 0.28121
Total Iteration Time: 4.63500

Cumulative Model Updates: 75,054
Cumulative Timesteps: 625,995,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 892.58479
Policy Entropy: 3.25999
Value Function Loss: 0.00426

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09612
Policy Update Magnitude: 0.57142
Value Function Update Magnitude: 0.67184

Collected Steps per Second: 23,289.86906
Overall Steps per Second: 10,900.64914

Timestep Collection Time: 2.14789
Timestep Consumption Time: 2.44120
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.58908

Cumulative Model Updates: 75,060
Cumulative Timesteps: 626,045,604

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 626045604...
Checkpoint 626045604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.98206
Policy Entropy: 3.28679
Value Function Loss: 0.00399

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08930
Policy Update Magnitude: 0.56604
Value Function Update Magnitude: 0.68376

Collected Steps per Second: 22,472.47645
Overall Steps per Second: 10,627.47683

Timestep Collection Time: 2.22601
Timestep Consumption Time: 2.48103
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.70704

Cumulative Model Updates: 75,066
Cumulative Timesteps: 626,095,628

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 858.62661
Policy Entropy: 3.30079
Value Function Loss: 0.00404

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08873
Policy Update Magnitude: 0.55446
Value Function Update Magnitude: 0.67636

Collected Steps per Second: 22,948.18749
Overall Steps per Second: 10,777.98636

Timestep Collection Time: 2.17995
Timestep Consumption Time: 2.46154
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.64150

Cumulative Model Updates: 75,072
Cumulative Timesteps: 626,145,654

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 626145654...
Checkpoint 626145654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,411.16288
Policy Entropy: 3.30448
Value Function Loss: 0.00386

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10034
Policy Update Magnitude: 0.54559
Value Function Update Magnitude: 0.66181

Collected Steps per Second: 22,847.69262
Overall Steps per Second: 10,798.36278

Timestep Collection Time: 2.18867
Timestep Consumption Time: 2.44222
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.63089

Cumulative Model Updates: 75,078
Cumulative Timesteps: 626,195,660

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,776.32463
Policy Entropy: 3.29265
Value Function Loss: 0.00386

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08505
Policy Update Magnitude: 0.54707
Value Function Update Magnitude: 0.65259

Collected Steps per Second: 22,553.09210
Overall Steps per Second: 10,534.28854

Timestep Collection Time: 2.21743
Timestep Consumption Time: 2.52992
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.74735

Cumulative Model Updates: 75,084
Cumulative Timesteps: 626,245,670

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 626245670...
Checkpoint 626245670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.11750
Policy Entropy: 3.29554
Value Function Loss: 0.00383

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.54192
Value Function Update Magnitude: 0.63571

Collected Steps per Second: 22,404.96096
Overall Steps per Second: 10,534.98875

Timestep Collection Time: 2.23299
Timestep Consumption Time: 2.51595
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.74894

Cumulative Model Updates: 75,090
Cumulative Timesteps: 626,295,700

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.07080
Policy Entropy: 3.29813
Value Function Loss: 0.00395

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07677
Policy Update Magnitude: 0.54598
Value Function Update Magnitude: 0.63948

Collected Steps per Second: 22,361.98513
Overall Steps per Second: 10,563.91531

Timestep Collection Time: 2.23630
Timestep Consumption Time: 2.49756
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.73385

Cumulative Model Updates: 75,096
Cumulative Timesteps: 626,345,708

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 626345708...
Checkpoint 626345708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710.35110
Policy Entropy: 3.30788
Value Function Loss: 0.00382

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07706
Policy Update Magnitude: 0.54887
Value Function Update Magnitude: 0.63128

Collected Steps per Second: 22,484.71118
Overall Steps per Second: 10,536.80734

Timestep Collection Time: 2.22453
Timestep Consumption Time: 2.52244
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.74698

Cumulative Model Updates: 75,102
Cumulative Timesteps: 626,395,726

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.41584
Policy Entropy: 3.30265
Value Function Loss: 0.00385

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.07859
Policy Update Magnitude: 0.54384
Value Function Update Magnitude: 0.61696

Collected Steps per Second: 22,525.43491
Overall Steps per Second: 10,510.90320

Timestep Collection Time: 2.22025
Timestep Consumption Time: 2.53786
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.75811

Cumulative Model Updates: 75,108
Cumulative Timesteps: 626,445,738

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 626445738...
Checkpoint 626445738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 978.16198
Policy Entropy: 3.29701
Value Function Loss: 0.00366

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08101
Policy Update Magnitude: 0.54382
Value Function Update Magnitude: 0.62719

Collected Steps per Second: 22,581.62513
Overall Steps per Second: 10,576.86182

Timestep Collection Time: 2.21534
Timestep Consumption Time: 2.51442
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.72976

Cumulative Model Updates: 75,114
Cumulative Timesteps: 626,495,764

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 774.11893
Policy Entropy: 3.27450
Value Function Loss: 0.00382

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08579
Policy Update Magnitude: 0.54950
Value Function Update Magnitude: 0.64501

Collected Steps per Second: 23,134.06506
Overall Steps per Second: 10,784.27196

Timestep Collection Time: 2.16227
Timestep Consumption Time: 2.47616
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.63842

Cumulative Model Updates: 75,120
Cumulative Timesteps: 626,545,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 626545786...
Checkpoint 626545786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.15020
Policy Entropy: 3.27594
Value Function Loss: 0.00365

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.54212
Value Function Update Magnitude: 0.65346

Collected Steps per Second: 22,691.64341
Overall Steps per Second: 10,784.52329

Timestep Collection Time: 2.20407
Timestep Consumption Time: 2.43350
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.63757

Cumulative Model Updates: 75,126
Cumulative Timesteps: 626,595,800

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.24053
Policy Entropy: 3.28535
Value Function Loss: 0.00389

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08714
Policy Update Magnitude: 0.54125
Value Function Update Magnitude: 0.62666

Collected Steps per Second: 22,513.53281
Overall Steps per Second: 10,840.03721

Timestep Collection Time: 2.22151
Timestep Consumption Time: 2.39231
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.61382

Cumulative Model Updates: 75,132
Cumulative Timesteps: 626,645,814

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 626645814...
Checkpoint 626645814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.15523
Policy Entropy: 3.27842
Value Function Loss: 0.00392

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10409
Policy Update Magnitude: 0.54175
Value Function Update Magnitude: 0.61084

Collected Steps per Second: 22,722.96655
Overall Steps per Second: 10,696.16941

Timestep Collection Time: 2.20139
Timestep Consumption Time: 2.47524
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.67663

Cumulative Model Updates: 75,138
Cumulative Timesteps: 626,695,836

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.91032
Policy Entropy: 3.29040
Value Function Loss: 0.00391

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10919
Policy Update Magnitude: 0.53636
Value Function Update Magnitude: 0.60561

Collected Steps per Second: 22,978.47566
Overall Steps per Second: 10,772.67430

Timestep Collection Time: 2.17621
Timestep Consumption Time: 2.46572
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.64193

Cumulative Model Updates: 75,144
Cumulative Timesteps: 626,745,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 626745842...
Checkpoint 626745842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.15787
Policy Entropy: 3.28935
Value Function Loss: 0.00385

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10559
Policy Update Magnitude: 0.53553
Value Function Update Magnitude: 0.60885

Collected Steps per Second: 22,479.66418
Overall Steps per Second: 10,763.36290

Timestep Collection Time: 2.22486
Timestep Consumption Time: 2.42183
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.64669

Cumulative Model Updates: 75,150
Cumulative Timesteps: 626,795,856

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.94751
Policy Entropy: 3.29226
Value Function Loss: 0.00384

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.53777
Value Function Update Magnitude: 0.61727

Collected Steps per Second: 22,311.05186
Overall Steps per Second: 10,491.17775

Timestep Collection Time: 2.24167
Timestep Consumption Time: 2.52557
PPO Batch Consumption Time: 0.29634
Total Iteration Time: 4.76724

Cumulative Model Updates: 75,156
Cumulative Timesteps: 626,845,870

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 626845870...
Checkpoint 626845870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 805.48191
Policy Entropy: 3.29762
Value Function Loss: 0.00387

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.53634
Value Function Update Magnitude: 0.62295

Collected Steps per Second: 22,585.76065
Overall Steps per Second: 10,586.96713

Timestep Collection Time: 2.21396
Timestep Consumption Time: 2.50920
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.72317

Cumulative Model Updates: 75,162
Cumulative Timesteps: 626,895,874

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 695.96789
Policy Entropy: 3.29352
Value Function Loss: 0.00423

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.54254
Value Function Update Magnitude: 0.61350

Collected Steps per Second: 22,566.66775
Overall Steps per Second: 10,600.19948

Timestep Collection Time: 2.21699
Timestep Consumption Time: 2.50274
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.71972

Cumulative Model Updates: 75,168
Cumulative Timesteps: 626,945,904

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 626945904...
Checkpoint 626945904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.74176
Policy Entropy: 3.28000
Value Function Loss: 0.00415

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10708
Policy Update Magnitude: 0.55557
Value Function Update Magnitude: 0.62530

Collected Steps per Second: 22,730.56387
Overall Steps per Second: 10,484.18530

Timestep Collection Time: 2.20012
Timestep Consumption Time: 2.56992
PPO Batch Consumption Time: 0.29650
Total Iteration Time: 4.77004

Cumulative Model Updates: 75,174
Cumulative Timesteps: 626,995,914

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.83269
Policy Entropy: 3.27337
Value Function Loss: 0.00414

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11578
Policy Update Magnitude: 0.56072
Value Function Update Magnitude: 0.65457

Collected Steps per Second: 22,890.61395
Overall Steps per Second: 10,684.81083

Timestep Collection Time: 2.18491
Timestep Consumption Time: 2.49594
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.68085

Cumulative Model Updates: 75,180
Cumulative Timesteps: 627,045,928

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 627045928...
Checkpoint 627045928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,579.58232
Policy Entropy: 3.27800
Value Function Loss: 0.00394

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.12233
Policy Update Magnitude: 0.55883
Value Function Update Magnitude: 0.67064

Collected Steps per Second: 22,780.91690
Overall Steps per Second: 10,773.33460

Timestep Collection Time: 2.19570
Timestep Consumption Time: 2.44725
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.64295

Cumulative Model Updates: 75,186
Cumulative Timesteps: 627,095,948

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178.84012
Policy Entropy: 3.27131
Value Function Loss: 0.00400

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10305
Policy Update Magnitude: 0.55441
Value Function Update Magnitude: 0.65967

Collected Steps per Second: 22,897.88114
Overall Steps per Second: 10,595.96665

Timestep Collection Time: 2.18370
Timestep Consumption Time: 2.53527
PPO Batch Consumption Time: 0.29747
Total Iteration Time: 4.71897

Cumulative Model Updates: 75,192
Cumulative Timesteps: 627,145,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 627145950...
Checkpoint 627145950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 782.84917
Policy Entropy: 3.27631
Value Function Loss: 0.00401

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09262
Policy Update Magnitude: 0.55104
Value Function Update Magnitude: 0.65000

Collected Steps per Second: 22,819.80588
Overall Steps per Second: 10,632.52717

Timestep Collection Time: 2.19187
Timestep Consumption Time: 2.51238
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 4.70424

Cumulative Model Updates: 75,198
Cumulative Timesteps: 627,195,968

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.96996
Policy Entropy: 3.24604
Value Function Loss: 0.00401

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10032
Policy Update Magnitude: 0.54309
Value Function Update Magnitude: 0.64251

Collected Steps per Second: 23,007.28187
Overall Steps per Second: 10,760.47393

Timestep Collection Time: 2.17444
Timestep Consumption Time: 2.47480
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.64924

Cumulative Model Updates: 75,204
Cumulative Timesteps: 627,245,996

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 627245996...
Checkpoint 627245996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,672.14559
Policy Entropy: 3.26222
Value Function Loss: 0.00378

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10781
Policy Update Magnitude: 0.53693
Value Function Update Magnitude: 0.63433

Collected Steps per Second: 22,524.70852
Overall Steps per Second: 10,710.60467

Timestep Collection Time: 2.22032
Timestep Consumption Time: 2.44907
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.66939

Cumulative Model Updates: 75,210
Cumulative Timesteps: 627,296,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714.31340
Policy Entropy: 3.26139
Value Function Loss: 0.00377

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09695
Policy Update Magnitude: 0.53926
Value Function Update Magnitude: 0.65082

Collected Steps per Second: 22,632.94718
Overall Steps per Second: 10,515.87403

Timestep Collection Time: 2.20935
Timestep Consumption Time: 2.54575
PPO Batch Consumption Time: 0.29742
Total Iteration Time: 4.75510

Cumulative Model Updates: 75,216
Cumulative Timesteps: 627,346,012

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 627346012...
Checkpoint 627346012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 752.75610
Policy Entropy: 3.27443
Value Function Loss: 0.00371

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09617
Policy Update Magnitude: 0.53587
Value Function Update Magnitude: 0.65407

Collected Steps per Second: 22,375.75500
Overall Steps per Second: 10,623.88470

Timestep Collection Time: 2.23492
Timestep Consumption Time: 2.47221
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.70713

Cumulative Model Updates: 75,222
Cumulative Timesteps: 627,396,020

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719.89189
Policy Entropy: 3.26900
Value Function Loss: 0.00384

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08318
Policy Update Magnitude: 0.54001
Value Function Update Magnitude: 0.63753

Collected Steps per Second: 22,425.61429
Overall Steps per Second: 10,500.07036

Timestep Collection Time: 2.23084
Timestep Consumption Time: 2.53370
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 4.76454

Cumulative Model Updates: 75,228
Cumulative Timesteps: 627,446,048

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 627446048...
Checkpoint 627446048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649.27624
Policy Entropy: 3.26133
Value Function Loss: 0.00407

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08794
Policy Update Magnitude: 0.54784
Value Function Update Magnitude: 0.63782

Collected Steps per Second: 22,533.73370
Overall Steps per Second: 10,588.35520

Timestep Collection Time: 2.21987
Timestep Consumption Time: 2.50437
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.72425

Cumulative Model Updates: 75,234
Cumulative Timesteps: 627,496,070

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 777.08821
Policy Entropy: 3.25907
Value Function Loss: 0.00432

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08279
Policy Update Magnitude: 0.55867
Value Function Update Magnitude: 0.64401

Collected Steps per Second: 22,690.46172
Overall Steps per Second: 10,595.30598

Timestep Collection Time: 2.20401
Timestep Consumption Time: 2.51600
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.72001

Cumulative Model Updates: 75,240
Cumulative Timesteps: 627,546,080

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 627546080...
Checkpoint 627546080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.85265
Policy Entropy: 3.26010
Value Function Loss: 0.00444

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08640
Policy Update Magnitude: 0.56595
Value Function Update Magnitude: 0.64969

Collected Steps per Second: 23,018.33431
Overall Steps per Second: 10,614.85715

Timestep Collection Time: 2.17288
Timestep Consumption Time: 2.53901
PPO Batch Consumption Time: 0.29658
Total Iteration Time: 4.71189

Cumulative Model Updates: 75,246
Cumulative Timesteps: 627,596,096

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.80428
Policy Entropy: 3.25384
Value Function Loss: 0.00452

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09128
Policy Update Magnitude: 0.56455
Value Function Update Magnitude: 0.64076

Collected Steps per Second: 22,803.41280
Overall Steps per Second: 10,641.47549

Timestep Collection Time: 2.19336
Timestep Consumption Time: 2.50674
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.70010

Cumulative Model Updates: 75,252
Cumulative Timesteps: 627,646,112

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 627646112...
Checkpoint 627646112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.71496
Policy Entropy: 3.26683
Value Function Loss: 0.00437

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07690
Policy Update Magnitude: 0.56204
Value Function Update Magnitude: 0.63415

Collected Steps per Second: 22,582.27772
Overall Steps per Second: 10,702.00321

Timestep Collection Time: 2.21421
Timestep Consumption Time: 2.45800
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.67221

Cumulative Model Updates: 75,258
Cumulative Timesteps: 627,696,114

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 960.89849
Policy Entropy: 3.27309
Value Function Loss: 0.00413

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08249
Policy Update Magnitude: 0.55691
Value Function Update Magnitude: 0.61764

Collected Steps per Second: 22,761.10049
Overall Steps per Second: 10,593.06765

Timestep Collection Time: 2.19884
Timestep Consumption Time: 2.52576
PPO Batch Consumption Time: 0.29703
Total Iteration Time: 4.72460

Cumulative Model Updates: 75,264
Cumulative Timesteps: 627,746,162

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 627746162...
Checkpoint 627746162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 807.65386
Policy Entropy: 3.27628
Value Function Loss: 0.00393

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08852
Policy Update Magnitude: 0.54312
Value Function Update Magnitude: 0.60190

Collected Steps per Second: 22,639.74339
Overall Steps per Second: 10,633.30493

Timestep Collection Time: 2.20939
Timestep Consumption Time: 2.49470
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.70409

Cumulative Model Updates: 75,270
Cumulative Timesteps: 627,796,182

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.03569
Policy Entropy: 3.26247
Value Function Loss: 0.00394

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09314
Policy Update Magnitude: 0.53901
Value Function Update Magnitude: 0.59379

Collected Steps per Second: 22,742.53424
Overall Steps per Second: 10,604.66032

Timestep Collection Time: 2.19879
Timestep Consumption Time: 2.51669
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.71547

Cumulative Model Updates: 75,276
Cumulative Timesteps: 627,846,188

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 627846188...
Checkpoint 627846188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 892.73656
Policy Entropy: 3.26656
Value Function Loss: 0.00403

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10853
Policy Update Magnitude: 0.54180
Value Function Update Magnitude: 0.61327

Collected Steps per Second: 22,870.58062
Overall Steps per Second: 10,802.01391

Timestep Collection Time: 2.18744
Timestep Consumption Time: 2.44392
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.63136

Cumulative Model Updates: 75,282
Cumulative Timesteps: 627,896,216

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.71353
Policy Entropy: 3.26866
Value Function Loss: 0.00395

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11086
Policy Update Magnitude: 0.53805
Value Function Update Magnitude: 0.61299

Collected Steps per Second: 22,023.32798
Overall Steps per Second: 10,587.78306

Timestep Collection Time: 2.27096
Timestep Consumption Time: 2.45279
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.72375

Cumulative Model Updates: 75,288
Cumulative Timesteps: 627,946,230

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 627946230...
Checkpoint 627946230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.86327
Policy Entropy: 3.26255
Value Function Loss: 0.00438

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10861
Policy Update Magnitude: 0.55475
Value Function Update Magnitude: 0.64164

Collected Steps per Second: 22,123.34875
Overall Steps per Second: 10,618.56078

Timestep Collection Time: 2.26087
Timestep Consumption Time: 2.44956
PPO Batch Consumption Time: 0.28181
Total Iteration Time: 4.71043

Cumulative Model Updates: 75,294
Cumulative Timesteps: 627,996,248

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683.24421
Policy Entropy: 3.26448
Value Function Loss: 0.00441

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10414
Policy Update Magnitude: 0.57209
Value Function Update Magnitude: 0.65036

Collected Steps per Second: 21,953.88815
Overall Steps per Second: 10,454.09380

Timestep Collection Time: 2.27878
Timestep Consumption Time: 2.50672
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.78549

Cumulative Model Updates: 75,300
Cumulative Timesteps: 628,046,276

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 628046276...
Checkpoint 628046276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.67328
Policy Entropy: 3.27195
Value Function Loss: 0.00415

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09011
Policy Update Magnitude: 0.56784
Value Function Update Magnitude: 0.63246

Collected Steps per Second: 22,175.22908
Overall Steps per Second: 10,605.59450

Timestep Collection Time: 2.25612
Timestep Consumption Time: 2.46120
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.71732

Cumulative Model Updates: 75,306
Cumulative Timesteps: 628,096,306

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.13309
Policy Entropy: 3.27047
Value Function Loss: 0.00388

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08615
Policy Update Magnitude: 0.55087
Value Function Update Magnitude: 0.61332

Collected Steps per Second: 22,279.91601
Overall Steps per Second: 10,470.67330

Timestep Collection Time: 2.24507
Timestep Consumption Time: 2.53208
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.77715

Cumulative Model Updates: 75,312
Cumulative Timesteps: 628,146,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 628146326...
Checkpoint 628146326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 804.93811
Policy Entropy: 3.25610
Value Function Loss: 0.00417

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10196
Policy Update Magnitude: 0.55059
Value Function Update Magnitude: 0.62259

Collected Steps per Second: 22,675.47996
Overall Steps per Second: 10,711.59715

Timestep Collection Time: 2.20582
Timestep Consumption Time: 2.46370
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.66952

Cumulative Model Updates: 75,318
Cumulative Timesteps: 628,196,344

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 927.43590
Policy Entropy: 3.26135
Value Function Loss: 0.00434

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11526
Policy Update Magnitude: 0.56071
Value Function Update Magnitude: 0.63855

Collected Steps per Second: 22,940.10530
Overall Steps per Second: 10,748.00515

Timestep Collection Time: 2.17985
Timestep Consumption Time: 2.47273
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.65258

Cumulative Model Updates: 75,324
Cumulative Timesteps: 628,246,350

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 628246350...
Checkpoint 628246350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.19807
Policy Entropy: 3.26649
Value Function Loss: 0.00422

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11163
Policy Update Magnitude: 0.55937
Value Function Update Magnitude: 0.61879

Collected Steps per Second: 22,341.49894
Overall Steps per Second: 10,621.47406

Timestep Collection Time: 2.23933
Timestep Consumption Time: 2.47094
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.71027

Cumulative Model Updates: 75,330
Cumulative Timesteps: 628,296,380

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 807.22960
Policy Entropy: 3.27688
Value Function Loss: 0.00399

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10633
Policy Update Magnitude: 0.54546
Value Function Update Magnitude: 0.58670

Collected Steps per Second: 22,859.80732
Overall Steps per Second: 10,698.58263

Timestep Collection Time: 2.18838
Timestep Consumption Time: 2.48756
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.67595

Cumulative Model Updates: 75,336
Cumulative Timesteps: 628,346,406

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 628346406...
Checkpoint 628346406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.60379
Policy Entropy: 3.27874
Value Function Loss: 0.00388

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09319
Policy Update Magnitude: 0.53485
Value Function Update Magnitude: 0.58581

Collected Steps per Second: 22,931.54379
Overall Steps per Second: 10,611.85088

Timestep Collection Time: 2.18040
Timestep Consumption Time: 2.53131
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.71171

Cumulative Model Updates: 75,342
Cumulative Timesteps: 628,396,406

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.71136
Policy Entropy: 3.27745
Value Function Loss: 0.00396

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09473
Policy Update Magnitude: 0.53960
Value Function Update Magnitude: 0.58493

Collected Steps per Second: 22,814.11986
Overall Steps per Second: 10,720.07655

Timestep Collection Time: 2.19163
Timestep Consumption Time: 2.47252
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.66415

Cumulative Model Updates: 75,348
Cumulative Timesteps: 628,446,406

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 628446406...
Checkpoint 628446406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.99156
Policy Entropy: 3.27508
Value Function Loss: 0.00393

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11515
Policy Update Magnitude: 0.53753
Value Function Update Magnitude: 0.58387

Collected Steps per Second: 22,699.81550
Overall Steps per Second: 10,722.09291

Timestep Collection Time: 2.20301
Timestep Consumption Time: 2.46100
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.66401

Cumulative Model Updates: 75,354
Cumulative Timesteps: 628,496,414

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.75470
Policy Entropy: 3.28246
Value Function Loss: 0.00398

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.54806
Value Function Update Magnitude: 0.58048

Collected Steps per Second: 22,438.94995
Overall Steps per Second: 10,597.89034

Timestep Collection Time: 2.22925
Timestep Consumption Time: 2.49075
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.72000

Cumulative Model Updates: 75,360
Cumulative Timesteps: 628,546,436

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 628546436...
Checkpoint 628546436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 854.76569
Policy Entropy: 3.28904
Value Function Loss: 0.00387

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.54164
Value Function Update Magnitude: 0.59173

Collected Steps per Second: 22,742.93036
Overall Steps per Second: 10,714.19001

Timestep Collection Time: 2.19919
Timestep Consumption Time: 2.46901
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.66820

Cumulative Model Updates: 75,366
Cumulative Timesteps: 628,596,452

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.32671
Policy Entropy: 3.28730
Value Function Loss: 0.00384

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.53425
Value Function Update Magnitude: 0.60389

Collected Steps per Second: 22,561.95755
Overall Steps per Second: 10,715.73570

Timestep Collection Time: 2.21718
Timestep Consumption Time: 2.45109
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.66827

Cumulative Model Updates: 75,372
Cumulative Timesteps: 628,646,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 628646476...
Checkpoint 628646476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.03398
Policy Entropy: 3.27975
Value Function Loss: 0.00375

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08838
Policy Update Magnitude: 0.52511
Value Function Update Magnitude: 0.60765

Collected Steps per Second: 22,269.65510
Overall Steps per Second: 10,592.33165

Timestep Collection Time: 2.24575
Timestep Consumption Time: 2.47578
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.72153

Cumulative Model Updates: 75,378
Cumulative Timesteps: 628,696,488

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.05837
Policy Entropy: 3.28616
Value Function Loss: 0.00383

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09047
Policy Update Magnitude: 0.53067
Value Function Update Magnitude: 0.60723

Collected Steps per Second: 22,868.53100
Overall Steps per Second: 10,822.68132

Timestep Collection Time: 2.18694
Timestep Consumption Time: 2.43410
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.62104

Cumulative Model Updates: 75,384
Cumulative Timesteps: 628,746,500

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 628746500...
Checkpoint 628746500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 874.79195
Policy Entropy: 3.29057
Value Function Loss: 0.00392

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08386
Policy Update Magnitude: 0.53589
Value Function Update Magnitude: 0.61510

Collected Steps per Second: 22,732.22299
Overall Steps per Second: 10,798.69831

Timestep Collection Time: 2.19961
Timestep Consumption Time: 2.43076
PPO Batch Consumption Time: 0.28177
Total Iteration Time: 4.63037

Cumulative Model Updates: 75,390
Cumulative Timesteps: 628,796,502

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,010.00632
Policy Entropy: 3.28536
Value Function Loss: 0.00384

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08732
Policy Update Magnitude: 0.54009
Value Function Update Magnitude: 0.61632

Collected Steps per Second: 22,780.70421
Overall Steps per Second: 10,803.40999

Timestep Collection Time: 2.19572
Timestep Consumption Time: 2.43430
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.63002

Cumulative Model Updates: 75,396
Cumulative Timesteps: 628,846,522

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 628846522...
Checkpoint 628846522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,886.39718
Policy Entropy: 3.27735
Value Function Loss: 0.00386

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09946
Policy Update Magnitude: 0.53881
Value Function Update Magnitude: 0.62372

Collected Steps per Second: 22,466.99397
Overall Steps per Second: 10,769.47656

Timestep Collection Time: 2.22656
Timestep Consumption Time: 2.41842
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.64498

Cumulative Model Updates: 75,402
Cumulative Timesteps: 628,896,546

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,596.41601
Policy Entropy: 3.28024
Value Function Loss: 0.00378

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08821
Policy Update Magnitude: 0.53849
Value Function Update Magnitude: 0.62885

Collected Steps per Second: 22,909.56620
Overall Steps per Second: 10,831.87046

Timestep Collection Time: 2.18372
Timestep Consumption Time: 2.43488
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.61859

Cumulative Model Updates: 75,408
Cumulative Timesteps: 628,946,574

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 628946574...
Checkpoint 628946574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 964.04386
Policy Entropy: 3.29447
Value Function Loss: 0.00401

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08983
Policy Update Magnitude: 0.53667
Value Function Update Magnitude: 0.62880

Collected Steps per Second: 22,710.62617
Overall Steps per Second: 10,732.48088

Timestep Collection Time: 2.20302
Timestep Consumption Time: 2.45872
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.66174

Cumulative Model Updates: 75,414
Cumulative Timesteps: 628,996,606

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 826.21176
Policy Entropy: 3.30023
Value Function Loss: 0.00409

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.54368
Value Function Update Magnitude: 0.65117

Collected Steps per Second: 22,104.73308
Overall Steps per Second: 10,499.31077

Timestep Collection Time: 2.26323
Timestep Consumption Time: 2.50166
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.76488

Cumulative Model Updates: 75,420
Cumulative Timesteps: 629,046,634

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 629046634...
Checkpoint 629046634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.54938
Policy Entropy: 3.30941
Value Function Loss: 0.00413

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09289
Policy Update Magnitude: 0.54698
Value Function Update Magnitude: 0.66397

Collected Steps per Second: 21,844.20855
Overall Steps per Second: 10,546.71127

Timestep Collection Time: 2.28939
Timestep Consumption Time: 2.45237
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.74176

Cumulative Model Updates: 75,426
Cumulative Timesteps: 629,096,644

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,699.71354
Policy Entropy: 3.31292
Value Function Loss: 0.00388

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08583
Policy Update Magnitude: 0.54221
Value Function Update Magnitude: 0.66514

Collected Steps per Second: 22,287.68767
Overall Steps per Second: 10,520.02513

Timestep Collection Time: 2.24366
Timestep Consumption Time: 2.50975
PPO Batch Consumption Time: 0.29668
Total Iteration Time: 4.75341

Cumulative Model Updates: 75,432
Cumulative Timesteps: 629,146,650

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 629146650...
Checkpoint 629146650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 738.75706
Policy Entropy: 3.30838
Value Function Loss: 0.00384

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08711
Policy Update Magnitude: 0.53567
Value Function Update Magnitude: 0.64438

Collected Steps per Second: 22,416.12283
Overall Steps per Second: 10,597.07797

Timestep Collection Time: 2.23143
Timestep Consumption Time: 2.48874
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.72017

Cumulative Model Updates: 75,438
Cumulative Timesteps: 629,196,670

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 870.12891
Policy Entropy: 3.28930
Value Function Loss: 0.00389

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08005
Policy Update Magnitude: 0.53387
Value Function Update Magnitude: 0.64054

Collected Steps per Second: 22,356.00821
Overall Steps per Second: 10,506.48563

Timestep Collection Time: 2.23707
Timestep Consumption Time: 2.52304
PPO Batch Consumption Time: 0.29650
Total Iteration Time: 4.76011

Cumulative Model Updates: 75,444
Cumulative Timesteps: 629,246,682

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 629246682...
Checkpoint 629246682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,309.44427
Policy Entropy: 3.28375
Value Function Loss: 0.00413

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07610
Policy Update Magnitude: 0.54307
Value Function Update Magnitude: 0.64992

Collected Steps per Second: 22,715.00936
Overall Steps per Second: 10,606.08762

Timestep Collection Time: 2.20242
Timestep Consumption Time: 2.51449
PPO Batch Consumption Time: 0.29634
Total Iteration Time: 4.71691

Cumulative Model Updates: 75,450
Cumulative Timesteps: 629,296,710

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.06036
Policy Entropy: 3.29800
Value Function Loss: 0.00408

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07220
Policy Update Magnitude: 0.54570
Value Function Update Magnitude: 0.65915

Collected Steps per Second: 22,947.11377
Overall Steps per Second: 10,864.18735

Timestep Collection Time: 2.18128
Timestep Consumption Time: 2.42597
PPO Batch Consumption Time: 0.28220
Total Iteration Time: 4.60725

Cumulative Model Updates: 75,456
Cumulative Timesteps: 629,346,764

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 629346764...
Checkpoint 629346764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.52690
Policy Entropy: 3.31675
Value Function Loss: 0.00400

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07780
Policy Update Magnitude: 0.54175
Value Function Update Magnitude: 0.64154

Collected Steps per Second: 22,886.01049
Overall Steps per Second: 10,659.41637

Timestep Collection Time: 2.18527
Timestep Consumption Time: 2.50655
PPO Batch Consumption Time: 0.29660
Total Iteration Time: 4.69181

Cumulative Model Updates: 75,462
Cumulative Timesteps: 629,396,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,834.91844
Policy Entropy: 3.31391
Value Function Loss: 0.00388

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07375
Policy Update Magnitude: 0.53519
Value Function Update Magnitude: 0.62480

Collected Steps per Second: 22,685.34261
Overall Steps per Second: 10,666.07371

Timestep Collection Time: 2.20415
Timestep Consumption Time: 2.48379
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.68795

Cumulative Model Updates: 75,468
Cumulative Timesteps: 629,446,778

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 629446778...
Checkpoint 629446778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 785.82786
Policy Entropy: 3.31293
Value Function Loss: 0.00379

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08512
Policy Update Magnitude: 0.53929
Value Function Update Magnitude: 0.61458

Collected Steps per Second: 22,835.68574
Overall Steps per Second: 10,835.30106

Timestep Collection Time: 2.19026
Timestep Consumption Time: 2.42577
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.61602

Cumulative Model Updates: 75,474
Cumulative Timesteps: 629,496,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.47633
Policy Entropy: 3.30996
Value Function Loss: 0.00370

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08435
Policy Update Magnitude: 0.53734
Value Function Update Magnitude: 0.62237

Collected Steps per Second: 22,681.22345
Overall Steps per Second: 10,611.90609

Timestep Collection Time: 2.20579
Timestep Consumption Time: 2.50873
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 4.71452

Cumulative Model Updates: 75,480
Cumulative Timesteps: 629,546,824

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 629546824...
Checkpoint 629546824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 984.05851
Policy Entropy: 3.31957
Value Function Loss: 0.00368

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08466
Policy Update Magnitude: 0.53212
Value Function Update Magnitude: 0.61125

Collected Steps per Second: 22,532.81385
Overall Steps per Second: 10,633.96775

Timestep Collection Time: 2.22023
Timestep Consumption Time: 2.48432
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.70455

Cumulative Model Updates: 75,486
Cumulative Timesteps: 629,596,852

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.00838
Policy Entropy: 3.31781
Value Function Loss: 0.00360

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08070
Policy Update Magnitude: 0.52673
Value Function Update Magnitude: 0.59536

Collected Steps per Second: 22,390.32171
Overall Steps per Second: 10,706.76071

Timestep Collection Time: 2.23418
Timestep Consumption Time: 2.43801
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.67219

Cumulative Model Updates: 75,492
Cumulative Timesteps: 629,646,876

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 629646876...
Checkpoint 629646876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 779.32563
Policy Entropy: 3.31870
Value Function Loss: 0.00349

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08905
Policy Update Magnitude: 0.51782
Value Function Update Magnitude: 0.57237

Collected Steps per Second: 22,546.79668
Overall Steps per Second: 10,742.77799

Timestep Collection Time: 2.21921
Timestep Consumption Time: 2.43843
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.65764

Cumulative Model Updates: 75,498
Cumulative Timesteps: 629,696,912

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 824.42685
Policy Entropy: 3.31802
Value Function Loss: 0.00351

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08577
Policy Update Magnitude: 0.50741
Value Function Update Magnitude: 0.55162

Collected Steps per Second: 22,915.07963
Overall Steps per Second: 10,831.89522

Timestep Collection Time: 2.18398
Timestep Consumption Time: 2.43627
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.62024

Cumulative Model Updates: 75,504
Cumulative Timesteps: 629,746,958

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 629746958...
Checkpoint 629746958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.70823
Policy Entropy: 3.31352
Value Function Loss: 0.00357

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08475
Policy Update Magnitude: 0.51445
Value Function Update Magnitude: 0.56101

Collected Steps per Second: 22,944.23727
Overall Steps per Second: 10,701.37357

Timestep Collection Time: 2.17928
Timestep Consumption Time: 2.49320
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.67248

Cumulative Model Updates: 75,510
Cumulative Timesteps: 629,796,960

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.01119
Policy Entropy: 3.31379
Value Function Loss: 0.00377

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07807
Policy Update Magnitude: 0.52612
Value Function Update Magnitude: 0.57554

Collected Steps per Second: 22,470.66639
Overall Steps per Second: 10,637.28276

Timestep Collection Time: 2.22601
Timestep Consumption Time: 2.47632
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.70233

Cumulative Model Updates: 75,516
Cumulative Timesteps: 629,846,980

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 629846980...
Checkpoint 629846980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,312.29090
Policy Entropy: 3.31697
Value Function Loss: 0.00382

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08540
Policy Update Magnitude: 0.53402
Value Function Update Magnitude: 0.60447

Collected Steps per Second: 22,596.47509
Overall Steps per Second: 10,642.70894

Timestep Collection Time: 2.21273
Timestep Consumption Time: 2.48532
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.69805

Cumulative Model Updates: 75,522
Cumulative Timesteps: 629,896,980

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.83620
Policy Entropy: 3.31105
Value Function Loss: 0.00397

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.54151
Value Function Update Magnitude: 0.62561

Collected Steps per Second: 22,839.61771
Overall Steps per Second: 10,808.79653

Timestep Collection Time: 2.18944
Timestep Consumption Time: 2.43698
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.62642

Cumulative Model Updates: 75,528
Cumulative Timesteps: 629,946,986

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 629946986...
Checkpoint 629946986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 796.58851
Policy Entropy: 3.30071
Value Function Loss: 0.00402

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08506
Policy Update Magnitude: 0.55722
Value Function Update Magnitude: 0.64365

Collected Steps per Second: 22,720.20422
Overall Steps per Second: 10,608.71629

Timestep Collection Time: 2.20183
Timestep Consumption Time: 2.51373
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.71556

Cumulative Model Updates: 75,534
Cumulative Timesteps: 629,997,012

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 755.16901
Policy Entropy: 3.30697
Value Function Loss: 0.00407

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08384
Policy Update Magnitude: 0.56066
Value Function Update Magnitude: 0.63243

Collected Steps per Second: 22,101.56786
Overall Steps per Second: 10,469.23921

Timestep Collection Time: 2.26274
Timestep Consumption Time: 2.51412
PPO Batch Consumption Time: 0.29684
Total Iteration Time: 4.77685

Cumulative Model Updates: 75,540
Cumulative Timesteps: 630,047,022

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 630047022...
Checkpoint 630047022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 862.79071
Policy Entropy: 3.30687
Value Function Loss: 0.00403

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08000
Policy Update Magnitude: 0.54845
Value Function Update Magnitude: 0.61985

Collected Steps per Second: 22,327.66337
Overall Steps per Second: 10,625.77548

Timestep Collection Time: 2.23973
Timestep Consumption Time: 2.46656
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.70629

Cumulative Model Updates: 75,546
Cumulative Timesteps: 630,097,030

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.83412
Policy Entropy: 3.29732
Value Function Loss: 0.00396

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08418
Policy Update Magnitude: 0.54337
Value Function Update Magnitude: 0.62755

Collected Steps per Second: 22,695.05811
Overall Steps per Second: 10,679.48113

Timestep Collection Time: 2.20453
Timestep Consumption Time: 2.48034
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.68487

Cumulative Model Updates: 75,552
Cumulative Timesteps: 630,147,062

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 630147062...
Checkpoint 630147062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 975.56764
Policy Entropy: 3.29140
Value Function Loss: 0.00363

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.07858
Policy Update Magnitude: 0.53888
Value Function Update Magnitude: 0.63214

Collected Steps per Second: 22,772.52564
Overall Steps per Second: 10,803.01023

Timestep Collection Time: 2.19695
Timestep Consumption Time: 2.43417
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.63112

Cumulative Model Updates: 75,558
Cumulative Timesteps: 630,197,092

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,358.07231
Policy Entropy: 3.28690
Value Function Loss: 0.00368

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08651
Policy Update Magnitude: 0.53591
Value Function Update Magnitude: 0.62827

Collected Steps per Second: 22,418.05106
Overall Steps per Second: 10,479.03941

Timestep Collection Time: 2.23079
Timestep Consumption Time: 2.54159
PPO Batch Consumption Time: 0.29735
Total Iteration Time: 4.77238

Cumulative Model Updates: 75,564
Cumulative Timesteps: 630,247,102

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 630247102...
Checkpoint 630247102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 826.77001
Policy Entropy: 3.29765
Value Function Loss: 0.00379

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10327
Policy Update Magnitude: 0.53962
Value Function Update Magnitude: 0.62362

Collected Steps per Second: 22,941.96227
Overall Steps per Second: 10,695.20957

Timestep Collection Time: 2.18063
Timestep Consumption Time: 2.49698
PPO Batch Consumption Time: 0.29786
Total Iteration Time: 4.67761

Cumulative Model Updates: 75,570
Cumulative Timesteps: 630,297,130

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.32026
Policy Entropy: 3.29473
Value Function Loss: 0.00388

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10654
Policy Update Magnitude: 0.53994
Value Function Update Magnitude: 0.61709

Collected Steps per Second: 22,794.09590
Overall Steps per Second: 10,806.19415

Timestep Collection Time: 2.19443
Timestep Consumption Time: 2.43440
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.62883

Cumulative Model Updates: 75,576
Cumulative Timesteps: 630,347,150

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 630347150...
Checkpoint 630347150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 994.67073
Policy Entropy: 3.30865
Value Function Loss: 0.00386

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08031
Policy Update Magnitude: 0.53325
Value Function Update Magnitude: 0.60279

Collected Steps per Second: 22,641.98523
Overall Steps per Second: 10,728.11293

Timestep Collection Time: 2.20961
Timestep Consumption Time: 2.45384
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.66345

Cumulative Model Updates: 75,582
Cumulative Timesteps: 630,397,180

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 930.50447
Policy Entropy: 3.30101
Value Function Loss: 0.00397

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.07823
Policy Update Magnitude: 0.53297
Value Function Update Magnitude: 0.60435

Collected Steps per Second: 22,452.95251
Overall Steps per Second: 10,637.00858

Timestep Collection Time: 2.22697
Timestep Consumption Time: 2.47379
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.70076

Cumulative Model Updates: 75,588
Cumulative Timesteps: 630,447,182

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 630447182...
Checkpoint 630447182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,033.12834
Policy Entropy: 3.30568
Value Function Loss: 0.00391

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.53216
Value Function Update Magnitude: 0.60348

Collected Steps per Second: 22,848.45852
Overall Steps per Second: 10,827.83732

Timestep Collection Time: 2.18929
Timestep Consumption Time: 2.43046
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.61976

Cumulative Model Updates: 75,594
Cumulative Timesteps: 630,497,204

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,471.17930
Policy Entropy: 3.31027
Value Function Loss: 0.00394

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10431
Policy Update Magnitude: 0.52767
Value Function Update Magnitude: 0.60345

Collected Steps per Second: 22,177.08395
Overall Steps per Second: 10,547.88337

Timestep Collection Time: 2.25593
Timestep Consumption Time: 2.48720
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.74313

Cumulative Model Updates: 75,600
Cumulative Timesteps: 630,547,234

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 630547234...
Checkpoint 630547234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 844.91071
Policy Entropy: 3.29281
Value Function Loss: 0.00392

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.53356
Value Function Update Magnitude: 0.60878

Collected Steps per Second: 22,182.26034
Overall Steps per Second: 10,698.14255

Timestep Collection Time: 2.25532
Timestep Consumption Time: 2.42101
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.67633

Cumulative Model Updates: 75,606
Cumulative Timesteps: 630,597,262

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,059.73844
Policy Entropy: 3.29897
Value Function Loss: 0.00396

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.10995
Policy Update Magnitude: 0.53929
Value Function Update Magnitude: 0.61744

Collected Steps per Second: 22,154.96446
Overall Steps per Second: 10,494.81465

Timestep Collection Time: 2.25791
Timestep Consumption Time: 2.50863
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.76654

Cumulative Model Updates: 75,612
Cumulative Timesteps: 630,647,286

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 630647286...
Checkpoint 630647286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.52995
Policy Entropy: 3.29584
Value Function Loss: 0.00393

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11687
Policy Update Magnitude: 0.53912
Value Function Update Magnitude: 0.61974

Collected Steps per Second: 22,185.27977
Overall Steps per Second: 10,546.54560

Timestep Collection Time: 2.25474
Timestep Consumption Time: 2.48824
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.74297

Cumulative Model Updates: 75,618
Cumulative Timesteps: 630,697,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.55855
Policy Entropy: 3.30209
Value Function Loss: 0.00381

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10373
Policy Update Magnitude: 0.53788
Value Function Update Magnitude: 0.60596

Collected Steps per Second: 22,567.46362
Overall Steps per Second: 10,668.24764

Timestep Collection Time: 2.21762
Timestep Consumption Time: 2.47350
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.69112

Cumulative Model Updates: 75,624
Cumulative Timesteps: 630,747,354

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 630747354...
Checkpoint 630747354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.37245
Policy Entropy: 3.30285
Value Function Loss: 0.00398

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09127
Policy Update Magnitude: 0.53159
Value Function Update Magnitude: 0.60297

Collected Steps per Second: 22,802.98966
Overall Steps per Second: 10,797.53281

Timestep Collection Time: 2.19340
Timestep Consumption Time: 2.43877
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.63217

Cumulative Model Updates: 75,630
Cumulative Timesteps: 630,797,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694.92100
Policy Entropy: 3.31037
Value Function Loss: 0.00388

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07883
Policy Update Magnitude: 0.53359
Value Function Update Magnitude: 0.61165

Collected Steps per Second: 22,262.01095
Overall Steps per Second: 10,489.01219

Timestep Collection Time: 2.24715
Timestep Consumption Time: 2.52223
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.76937

Cumulative Model Updates: 75,636
Cumulative Timesteps: 630,847,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 630847396...
Checkpoint 630847396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,823.63860
Policy Entropy: 3.29929
Value Function Loss: 0.00400

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.53129
Value Function Update Magnitude: 0.62003

Collected Steps per Second: 22,727.96780
Overall Steps per Second: 10,673.05983

Timestep Collection Time: 2.20055
Timestep Consumption Time: 2.48546
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.68600

Cumulative Model Updates: 75,642
Cumulative Timesteps: 630,897,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 931.44675
Policy Entropy: 3.30192
Value Function Loss: 0.00392

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.07980
Policy Update Magnitude: 0.53161
Value Function Update Magnitude: 0.61812

Collected Steps per Second: 22,618.68545
Overall Steps per Second: 10,685.11506

Timestep Collection Time: 2.21092
Timestep Consumption Time: 2.46924
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.68016

Cumulative Model Updates: 75,648
Cumulative Timesteps: 630,947,418

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 630947418...
Checkpoint 630947418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.77189
Policy Entropy: 3.30536
Value Function Loss: 0.00406

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08289
Policy Update Magnitude: 0.53539
Value Function Update Magnitude: 0.61993

Collected Steps per Second: 22,734.05869
Overall Steps per Second: 10,806.04932

Timestep Collection Time: 2.20040
Timestep Consumption Time: 2.42886
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.62926

Cumulative Model Updates: 75,654
Cumulative Timesteps: 630,997,442

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698.79372
Policy Entropy: 3.32429
Value Function Loss: 0.00399

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07759
Policy Update Magnitude: 0.53745
Value Function Update Magnitude: 0.63503

Collected Steps per Second: 22,811.45166
Overall Steps per Second: 10,723.25554

Timestep Collection Time: 2.19206
Timestep Consumption Time: 2.47108
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.66314

Cumulative Model Updates: 75,660
Cumulative Timesteps: 631,047,446

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 631047446...
Checkpoint 631047446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.62866
Policy Entropy: 3.33199
Value Function Loss: 0.00393

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08869
Policy Update Magnitude: 0.53056
Value Function Update Magnitude: 0.63524

Collected Steps per Second: 22,871.43639
Overall Steps per Second: 10,839.19653

Timestep Collection Time: 2.18648
Timestep Consumption Time: 2.42714
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.61363

Cumulative Model Updates: 75,666
Cumulative Timesteps: 631,097,454

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.56470
Policy Entropy: 3.30827
Value Function Loss: 0.00419

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10250
Policy Update Magnitude: 0.52929
Value Function Update Magnitude: 0.63819

Collected Steps per Second: 22,349.30411
Overall Steps per Second: 10,552.34757

Timestep Collection Time: 2.23739
Timestep Consumption Time: 2.50128
PPO Batch Consumption Time: 0.29639
Total Iteration Time: 4.73866

Cumulative Model Updates: 75,672
Cumulative Timesteps: 631,147,458

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 631147458...
Checkpoint 631147458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 934.64488
Policy Entropy: 3.30318
Value Function Loss: 0.00408

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.53708
Value Function Update Magnitude: 0.65356

Collected Steps per Second: 22,640.16975
Overall Steps per Second: 10,587.95411

Timestep Collection Time: 2.20891
Timestep Consumption Time: 2.51439
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 4.72329

Cumulative Model Updates: 75,678
Cumulative Timesteps: 631,197,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 955.27043
Policy Entropy: 3.29553
Value Function Loss: 0.00396

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09881
Policy Update Magnitude: 0.52920
Value Function Update Magnitude: 0.65248

Collected Steps per Second: 22,660.49534
Overall Steps per Second: 10,655.91777

Timestep Collection Time: 2.20648
Timestep Consumption Time: 2.48575
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.69223

Cumulative Model Updates: 75,684
Cumulative Timesteps: 631,247,468

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 631247468...
Checkpoint 631247468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.93959
Policy Entropy: 3.31433
Value Function Loss: 0.00380

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08704
Policy Update Magnitude: 0.52662
Value Function Update Magnitude: 0.67186

Collected Steps per Second: 22,276.97928
Overall Steps per Second: 10,619.46467

Timestep Collection Time: 2.24564
Timestep Consumption Time: 2.46515
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.71078

Cumulative Model Updates: 75,690
Cumulative Timesteps: 631,297,494

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,621.72674
Policy Entropy: 3.29772
Value Function Loss: 0.00366

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.07866
Policy Update Magnitude: 0.52775
Value Function Update Magnitude: 0.64792

Collected Steps per Second: 22,826.55443
Overall Steps per Second: 10,748.31743

Timestep Collection Time: 2.19078
Timestep Consumption Time: 2.46185
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.65264

Cumulative Model Updates: 75,696
Cumulative Timesteps: 631,347,502

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 631347502...
Checkpoint 631347502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,059.53433
Policy Entropy: 3.30142
Value Function Loss: 0.00374

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08854
Policy Update Magnitude: 0.52432
Value Function Update Magnitude: 0.62671

Collected Steps per Second: 22,406.90466
Overall Steps per Second: 10,618.74208

Timestep Collection Time: 2.23172
Timestep Consumption Time: 2.47750
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.70922

Cumulative Model Updates: 75,702
Cumulative Timesteps: 631,397,508

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,504.17926
Policy Entropy: 3.29172
Value Function Loss: 0.00372

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08907
Policy Update Magnitude: 0.52104
Value Function Update Magnitude: 0.63190

Collected Steps per Second: 22,897.03231
Overall Steps per Second: 10,816.73510

Timestep Collection Time: 2.18386
Timestep Consumption Time: 2.43897
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.62284

Cumulative Model Updates: 75,708
Cumulative Timesteps: 631,447,512

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 631447512...
Checkpoint 631447512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 811.96038
Policy Entropy: 3.30146
Value Function Loss: 0.00412

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.53088
Value Function Update Magnitude: 0.65492

Collected Steps per Second: 22,832.28930
Overall Steps per Second: 10,717.96870

Timestep Collection Time: 2.19084
Timestep Consumption Time: 2.47627
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.66712

Cumulative Model Updates: 75,714
Cumulative Timesteps: 631,497,534

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 958.12202
Policy Entropy: 3.31288
Value Function Loss: 0.00411

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08789
Policy Update Magnitude: 0.53680
Value Function Update Magnitude: 0.66806

Collected Steps per Second: 22,777.60819
Overall Steps per Second: 10,800.32553

Timestep Collection Time: 2.19681
Timestep Consumption Time: 2.43620
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.63301

Cumulative Model Updates: 75,720
Cumulative Timesteps: 631,547,572

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 631547572...
Checkpoint 631547572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.88328
Policy Entropy: 3.30824
Value Function Loss: 0.00416

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08626
Policy Update Magnitude: 0.53620
Value Function Update Magnitude: 0.67501

Collected Steps per Second: 22,807.98741
Overall Steps per Second: 10,742.21599

Timestep Collection Time: 2.19274
Timestep Consumption Time: 2.46291
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.65565

Cumulative Model Updates: 75,726
Cumulative Timesteps: 631,597,584

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 903.27654
Policy Entropy: 3.28483
Value Function Loss: 0.00406

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10421
Policy Update Magnitude: 0.53113
Value Function Update Magnitude: 0.68455

Collected Steps per Second: 22,296.43671
Overall Steps per Second: 10,497.59401

Timestep Collection Time: 2.24359
Timestep Consumption Time: 2.52170
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.76528

Cumulative Model Updates: 75,732
Cumulative Timesteps: 631,647,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 631647608...
Checkpoint 631647608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 958.37439
Policy Entropy: 3.26842
Value Function Loss: 0.00403

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10724
Policy Update Magnitude: 0.53749
Value Function Update Magnitude: 0.68878

Collected Steps per Second: 22,205.08872
Overall Steps per Second: 10,615.69210

Timestep Collection Time: 2.25264
Timestep Consumption Time: 2.45926
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.71189

Cumulative Model Updates: 75,738
Cumulative Timesteps: 631,697,628

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 938.23589
Policy Entropy: 3.24665
Value Function Loss: 0.00388

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10291
Policy Update Magnitude: 0.53738
Value Function Update Magnitude: 0.67971

Collected Steps per Second: 22,029.29239
Overall Steps per Second: 10,478.52958

Timestep Collection Time: 2.26989
Timestep Consumption Time: 2.50216
PPO Batch Consumption Time: 0.29767
Total Iteration Time: 4.77204

Cumulative Model Updates: 75,744
Cumulative Timesteps: 631,747,632

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 631747632...
Checkpoint 631747632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.76778
Policy Entropy: 3.25479
Value Function Loss: 0.00383

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09054
Policy Update Magnitude: 0.53405
Value Function Update Magnitude: 0.66107

Collected Steps per Second: 22,284.27791
Overall Steps per Second: 10,609.62346

Timestep Collection Time: 2.24490
Timestep Consumption Time: 2.47025
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.71515

Cumulative Model Updates: 75,750
Cumulative Timesteps: 631,797,658

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.66397
Policy Entropy: 3.27139
Value Function Loss: 0.00367

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10534
Policy Update Magnitude: 0.52721
Value Function Update Magnitude: 0.65402

Collected Steps per Second: 22,623.23064
Overall Steps per Second: 10,630.05526

Timestep Collection Time: 2.21029
Timestep Consumption Time: 2.49373
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.70402

Cumulative Model Updates: 75,756
Cumulative Timesteps: 631,847,662

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 631847662...
Checkpoint 631847662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.52851
Policy Entropy: 3.26766
Value Function Loss: 0.00357

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08991
Policy Update Magnitude: 0.51444
Value Function Update Magnitude: 0.66199

Collected Steps per Second: 22,533.77791
Overall Steps per Second: 10,653.48724

Timestep Collection Time: 2.21916
Timestep Consumption Time: 2.47470
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.69386

Cumulative Model Updates: 75,762
Cumulative Timesteps: 631,897,668

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 871.71593
Policy Entropy: 3.27827
Value Function Loss: 0.00353

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07938
Policy Update Magnitude: 0.51627
Value Function Update Magnitude: 0.65979

Collected Steps per Second: 23,199.44479
Overall Steps per Second: 10,693.10261

Timestep Collection Time: 2.15531
Timestep Consumption Time: 2.52079
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.67610

Cumulative Model Updates: 75,768
Cumulative Timesteps: 631,947,670

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 631947670...
Checkpoint 631947670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.24471
Policy Entropy: 3.26500
Value Function Loss: 0.00370

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08406
Policy Update Magnitude: 0.52700
Value Function Update Magnitude: 0.64944

Collected Steps per Second: 22,459.67217
Overall Steps per Second: 10,629.78626

Timestep Collection Time: 2.22737
Timestep Consumption Time: 2.47884
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.70621

Cumulative Model Updates: 75,774
Cumulative Timesteps: 631,997,696

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.62981
Policy Entropy: 3.27229
Value Function Loss: 0.00380

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10036
Policy Update Magnitude: 0.53124
Value Function Update Magnitude: 0.64582

Collected Steps per Second: 22,770.50178
Overall Steps per Second: 10,698.74165

Timestep Collection Time: 2.19697
Timestep Consumption Time: 2.47891
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.67588

Cumulative Model Updates: 75,780
Cumulative Timesteps: 632,047,722

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 632047722...
Checkpoint 632047722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 889.22954
Policy Entropy: 3.26968
Value Function Loss: 0.00396

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.53099
Value Function Update Magnitude: 0.65205

Collected Steps per Second: 22,894.83926
Overall Steps per Second: 10,827.66884

Timestep Collection Time: 2.18425
Timestep Consumption Time: 2.43429
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.61854

Cumulative Model Updates: 75,786
Cumulative Timesteps: 632,097,730

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.06988
Policy Entropy: 3.26567
Value Function Loss: 0.00380

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.53346
Value Function Update Magnitude: 0.63413

Collected Steps per Second: 22,898.72108
Overall Steps per Second: 10,734.74340

Timestep Collection Time: 2.18362
Timestep Consumption Time: 2.47434
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.65796

Cumulative Model Updates: 75,792
Cumulative Timesteps: 632,147,732

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 632147732...
Checkpoint 632147732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.38443
Policy Entropy: 3.24977
Value Function Loss: 0.00403

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08393
Policy Update Magnitude: 0.53182
Value Function Update Magnitude: 0.63204

Collected Steps per Second: 22,756.41955
Overall Steps per Second: 10,799.17967

Timestep Collection Time: 2.19789
Timestep Consumption Time: 2.43358
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.63146

Cumulative Model Updates: 75,798
Cumulative Timesteps: 632,197,748

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719.95961
Policy Entropy: 3.25513
Value Function Loss: 0.00395

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09418
Policy Update Magnitude: 0.54071
Value Function Update Magnitude: 0.65011

Collected Steps per Second: 22,164.48040
Overall Steps per Second: 10,482.95140

Timestep Collection Time: 2.25667
Timestep Consumption Time: 2.51469
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.77137

Cumulative Model Updates: 75,804
Cumulative Timesteps: 632,247,766

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 632247766...
Checkpoint 632247766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 985.43279
Policy Entropy: 3.26111
Value Function Loss: 0.00392

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09471
Policy Update Magnitude: 0.53993
Value Function Update Magnitude: 0.63678

Collected Steps per Second: 21,975.97051
Overall Steps per Second: 10,593.23268

Timestep Collection Time: 2.27658
Timestep Consumption Time: 2.44625
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.72283

Cumulative Model Updates: 75,810
Cumulative Timesteps: 632,297,796

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.99181
Policy Entropy: 3.28455
Value Function Loss: 0.00374

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08299
Policy Update Magnitude: 0.53772
Value Function Update Magnitude: 0.61403

Collected Steps per Second: 22,669.47920
Overall Steps per Second: 10,647.20560

Timestep Collection Time: 2.20570
Timestep Consumption Time: 2.49056
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.69626

Cumulative Model Updates: 75,816
Cumulative Timesteps: 632,347,798

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 632347798...
Checkpoint 632347798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.76851
Policy Entropy: 3.28597
Value Function Loss: 0.00361

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08007
Policy Update Magnitude: 0.53775
Value Function Update Magnitude: 0.58994

Collected Steps per Second: 22,011.81646
Overall Steps per Second: 10,507.14863

Timestep Collection Time: 2.27178
Timestep Consumption Time: 2.48746
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.75924

Cumulative Model Updates: 75,822
Cumulative Timesteps: 632,397,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.50739
Policy Entropy: 3.27998
Value Function Loss: 0.00382

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.07898
Policy Update Magnitude: 0.53556
Value Function Update Magnitude: 0.58173

Collected Steps per Second: 23,145.29065
Overall Steps per Second: 10,795.45036

Timestep Collection Time: 2.16130
Timestep Consumption Time: 2.47250
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.63380

Cumulative Model Updates: 75,828
Cumulative Timesteps: 632,447,828

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 632447828...
Checkpoint 632447828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.14569
Policy Entropy: 3.27780
Value Function Loss: 0.00381

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.07843
Policy Update Magnitude: 0.54305
Value Function Update Magnitude: 0.59910

Collected Steps per Second: 22,446.64982
Overall Steps per Second: 10,753.33969

Timestep Collection Time: 2.22804
Timestep Consumption Time: 2.42280
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.65083

Cumulative Model Updates: 75,834
Cumulative Timesteps: 632,497,840

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.27765
Policy Entropy: 3.27708
Value Function Loss: 0.00405

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.54691
Value Function Update Magnitude: 0.61703

Collected Steps per Second: 22,775.25638
Overall Steps per Second: 10,806.06976

Timestep Collection Time: 2.19616
Timestep Consumption Time: 2.43254
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.62869

Cumulative Model Updates: 75,840
Cumulative Timesteps: 632,547,858

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 632547858...
Checkpoint 632547858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.01999
Policy Entropy: 3.29272
Value Function Loss: 0.00409

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08183
Policy Update Magnitude: 0.54779
Value Function Update Magnitude: 0.61582

Collected Steps per Second: 22,275.67553
Overall Steps per Second: 10,702.79864

Timestep Collection Time: 2.24595
Timestep Consumption Time: 2.42853
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.67448

Cumulative Model Updates: 75,846
Cumulative Timesteps: 632,597,888

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 867.06290
Policy Entropy: 3.28484
Value Function Loss: 0.00407

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08418
Policy Update Magnitude: 0.54817
Value Function Update Magnitude: 0.61006

Collected Steps per Second: 22,838.77196
Overall Steps per Second: 10,688.79905

Timestep Collection Time: 2.19005
Timestep Consumption Time: 2.48943
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.67948

Cumulative Model Updates: 75,852
Cumulative Timesteps: 632,647,906

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 632647906...
Checkpoint 632647906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.36018
Policy Entropy: 3.28382
Value Function Loss: 0.00396

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09361
Policy Update Magnitude: 0.53691
Value Function Update Magnitude: 0.60766

Collected Steps per Second: 23,079.68104
Overall Steps per Second: 10,876.94505

Timestep Collection Time: 2.16771
Timestep Consumption Time: 2.43193
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.59964

Cumulative Model Updates: 75,858
Cumulative Timesteps: 632,697,936

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 830.35206
Policy Entropy: 3.28961
Value Function Loss: 0.00409

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08984
Policy Update Magnitude: 0.53301
Value Function Update Magnitude: 0.61778

Collected Steps per Second: 22,531.57677
Overall Steps per Second: 10,646.96700

Timestep Collection Time: 2.21911
Timestep Consumption Time: 2.47707
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.69617

Cumulative Model Updates: 75,864
Cumulative Timesteps: 632,747,936

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 632747936...
Checkpoint 632747936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.19169
Policy Entropy: 3.27502
Value Function Loss: 0.00427

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09863
Policy Update Magnitude: 0.53955
Value Function Update Magnitude: 0.64323

Collected Steps per Second: 22,456.55996
Overall Steps per Second: 10,631.22658

Timestep Collection Time: 2.22697
Timestep Consumption Time: 2.47710
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.70407

Cumulative Model Updates: 75,870
Cumulative Timesteps: 632,797,946

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 933.37164
Policy Entropy: 3.28808
Value Function Loss: 0.00424

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09312
Policy Update Magnitude: 0.54683
Value Function Update Magnitude: 0.67872

Collected Steps per Second: 22,537.11924
Overall Steps per Second: 10,781.41419

Timestep Collection Time: 2.21989
Timestep Consumption Time: 2.42050
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.64039

Cumulative Model Updates: 75,876
Cumulative Timesteps: 632,847,976

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 632847976...
Checkpoint 632847976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621.21420
Policy Entropy: 3.26344
Value Function Loss: 0.00410

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09900
Policy Update Magnitude: 0.54646
Value Function Update Magnitude: 0.68461

Collected Steps per Second: 22,030.93111
Overall Steps per Second: 10,582.68699

Timestep Collection Time: 2.27099
Timestep Consumption Time: 2.45673
PPO Batch Consumption Time: 0.29878
Total Iteration Time: 4.72772

Cumulative Model Updates: 75,882
Cumulative Timesteps: 632,898,008

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 978.74281
Policy Entropy: 3.27050
Value Function Loss: 0.00391

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.54911
Value Function Update Magnitude: 0.68587

Collected Steps per Second: 22,008.11853
Overall Steps per Second: 10,633.32443

Timestep Collection Time: 2.27334
Timestep Consumption Time: 2.43186
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.70521

Cumulative Model Updates: 75,888
Cumulative Timesteps: 632,948,040

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 632948040...
Checkpoint 632948040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 801.53870
Policy Entropy: 3.25812
Value Function Loss: 0.00397

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.13121
Policy Update Magnitude: 0.54407
Value Function Update Magnitude: 0.66162

Collected Steps per Second: 21,787.25080
Overall Steps per Second: 10,489.46069

Timestep Collection Time: 2.29520
Timestep Consumption Time: 2.47207
PPO Batch Consumption Time: 0.29658
Total Iteration Time: 4.76726

Cumulative Model Updates: 75,894
Cumulative Timesteps: 632,998,046

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 936.92050
Policy Entropy: 3.26631
Value Function Loss: 0.00425

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.11917
Policy Update Magnitude: 0.53832
Value Function Update Magnitude: 0.64964

Collected Steps per Second: 22,558.95838
Overall Steps per Second: 10,861.17090

Timestep Collection Time: 2.21721
Timestep Consumption Time: 2.38800
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.60521

Cumulative Model Updates: 75,900
Cumulative Timesteps: 633,048,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 633048064...
Checkpoint 633048064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 932.16440
Policy Entropy: 3.26917
Value Function Loss: 0.00435

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10116
Policy Update Magnitude: 0.54570
Value Function Update Magnitude: 0.65382

Collected Steps per Second: 22,130.90001
Overall Steps per Second: 10,711.46659

Timestep Collection Time: 2.26001
Timestep Consumption Time: 2.40938
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.66939

Cumulative Model Updates: 75,906
Cumulative Timesteps: 633,098,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729.31797
Policy Entropy: 3.27817
Value Function Loss: 0.00415

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10270
Policy Update Magnitude: 0.54598
Value Function Update Magnitude: 0.63644

Collected Steps per Second: 22,231.29031
Overall Steps per Second: 10,782.57855

Timestep Collection Time: 2.24989
Timestep Consumption Time: 2.38889
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.63878

Cumulative Model Updates: 75,912
Cumulative Timesteps: 633,148,098

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 633148098...
Checkpoint 633148098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.80048
Policy Entropy: 3.27638
Value Function Loss: 0.00420

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10996
Policy Update Magnitude: 0.54785
Value Function Update Magnitude: 0.62064

Collected Steps per Second: 21,968.91396
Overall Steps per Second: 10,751.02631

Timestep Collection Time: 2.27694
Timestep Consumption Time: 2.37582
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.65277

Cumulative Model Updates: 75,918
Cumulative Timesteps: 633,198,120

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.06900
Policy Entropy: 3.27119
Value Function Loss: 0.00432

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.54792
Value Function Update Magnitude: 0.61469

Collected Steps per Second: 22,090.94265
Overall Steps per Second: 10,666.29982

Timestep Collection Time: 2.26455
Timestep Consumption Time: 2.42555
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.69010

Cumulative Model Updates: 75,924
Cumulative Timesteps: 633,248,146

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 633248146...
Checkpoint 633248146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 994.08757
Policy Entropy: 3.26600
Value Function Loss: 0.00428

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11424
Policy Update Magnitude: 0.54576
Value Function Update Magnitude: 0.62554

Collected Steps per Second: 22,478.55154
Overall Steps per Second: 10,568.12013

Timestep Collection Time: 2.22505
Timestep Consumption Time: 2.50767
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.73272

Cumulative Model Updates: 75,930
Cumulative Timesteps: 633,298,162

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 974.45182
Policy Entropy: 3.28716
Value Function Loss: 0.00413

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09080
Policy Update Magnitude: 0.54262
Value Function Update Magnitude: 0.64261

Collected Steps per Second: 21,908.66675
Overall Steps per Second: 10,724.84742

Timestep Collection Time: 2.28266
Timestep Consumption Time: 2.38035
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.66300

Cumulative Model Updates: 75,936
Cumulative Timesteps: 633,348,172

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 633348172...
Checkpoint 633348172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,756.65612
Policy Entropy: 3.29864
Value Function Loss: 0.00416

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08594
Policy Update Magnitude: 0.53643
Value Function Update Magnitude: 0.65070

Collected Steps per Second: 20,722.41349
Overall Steps per Second: 10,280.89726

Timestep Collection Time: 2.41381
Timestep Consumption Time: 2.45152
PPO Batch Consumption Time: 0.29740
Total Iteration Time: 4.86533

Cumulative Model Updates: 75,942
Cumulative Timesteps: 633,398,192

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 910.07624
Policy Entropy: 3.30067
Value Function Loss: 0.00402

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08258
Policy Update Magnitude: 0.53709
Value Function Update Magnitude: 0.65163

Collected Steps per Second: 22,399.90329
Overall Steps per Second: 10,563.48021

Timestep Collection Time: 2.23340
Timestep Consumption Time: 2.50254
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.73594

Cumulative Model Updates: 75,948
Cumulative Timesteps: 633,448,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 633448220...
Checkpoint 633448220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.52874
Policy Entropy: 3.27933
Value Function Loss: 0.00412

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.54175
Value Function Update Magnitude: 0.64339

Collected Steps per Second: 22,394.40639
Overall Steps per Second: 10,524.42304

Timestep Collection Time: 2.23386
Timestep Consumption Time: 2.51946
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.75332

Cumulative Model Updates: 75,954
Cumulative Timesteps: 633,498,246

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.20500
Policy Entropy: 3.28209
Value Function Loss: 0.00394

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10509
Policy Update Magnitude: 0.54898
Value Function Update Magnitude: 0.62979

Collected Steps per Second: 23,130.02013
Overall Steps per Second: 10,676.03499

Timestep Collection Time: 2.16273
Timestep Consumption Time: 2.52290
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.68563

Cumulative Model Updates: 75,960
Cumulative Timesteps: 633,548,270

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 633548270...
Checkpoint 633548270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 876.22869
Policy Entropy: 3.27955
Value Function Loss: 0.00401

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10698
Policy Update Magnitude: 0.54404
Value Function Update Magnitude: 0.63240

Collected Steps per Second: 22,773.59241
Overall Steps per Second: 10,714.15848

Timestep Collection Time: 2.19605
Timestep Consumption Time: 2.47179
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.66784

Cumulative Model Updates: 75,966
Cumulative Timesteps: 633,598,282

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 936.72443
Policy Entropy: 3.28830
Value Function Loss: 0.00368

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08768
Policy Update Magnitude: 0.53396
Value Function Update Magnitude: 0.62837

Collected Steps per Second: 22,668.69010
Overall Steps per Second: 10,581.46122

Timestep Collection Time: 2.20648
Timestep Consumption Time: 2.52047
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.72695

Cumulative Model Updates: 75,972
Cumulative Timesteps: 633,648,300

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 633648300...
Checkpoint 633648300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 941.94966
Policy Entropy: 3.28995
Value Function Loss: 0.00387

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07426
Policy Update Magnitude: 0.52827
Value Function Update Magnitude: 0.62334

Collected Steps per Second: 22,503.47263
Overall Steps per Second: 10,674.41386

Timestep Collection Time: 2.22223
Timestep Consumption Time: 2.46261
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.68485

Cumulative Model Updates: 75,978
Cumulative Timesteps: 633,698,308

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.94487
Policy Entropy: 3.29131
Value Function Loss: 0.00386

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.53256
Value Function Update Magnitude: 0.65382

Collected Steps per Second: 23,025.98014
Overall Steps per Second: 10,799.30064

Timestep Collection Time: 2.17276
Timestep Consumption Time: 2.45994
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.63271

Cumulative Model Updates: 75,984
Cumulative Timesteps: 633,748,338

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 633748338...
Checkpoint 633748338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499.13143
Policy Entropy: 3.28488
Value Function Loss: 0.00411

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08454
Policy Update Magnitude: 0.53950
Value Function Update Magnitude: 0.66758

Collected Steps per Second: 22,710.58209
Overall Steps per Second: 10,740.24211

Timestep Collection Time: 2.20197
Timestep Consumption Time: 2.45416
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.65613

Cumulative Model Updates: 75,990
Cumulative Timesteps: 633,798,346

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 753.51649
Policy Entropy: 3.27464
Value Function Loss: 0.00414

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08687
Policy Update Magnitude: 0.55525
Value Function Update Magnitude: 0.67099

Collected Steps per Second: 22,878.27071
Overall Steps per Second: 10,684.38924

Timestep Collection Time: 2.18609
Timestep Consumption Time: 2.49494
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.68103

Cumulative Model Updates: 75,996
Cumulative Timesteps: 633,848,360

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 633848360...
Checkpoint 633848360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 812.51593
Policy Entropy: 3.26700
Value Function Loss: 0.00429

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11337
Policy Update Magnitude: 0.56311
Value Function Update Magnitude: 0.65980

Collected Steps per Second: 22,712.50651
Overall Steps per Second: 10,738.01722

Timestep Collection Time: 2.20205
Timestep Consumption Time: 2.45561
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.65766

Cumulative Model Updates: 76,002
Cumulative Timesteps: 633,898,374

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.86889
Policy Entropy: 3.26864
Value Function Loss: 0.00426

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.10859
Policy Update Magnitude: 0.56143
Value Function Update Magnitude: 0.64915

Collected Steps per Second: 22,562.38800
Overall Steps per Second: 10,596.07183

Timestep Collection Time: 2.21714
Timestep Consumption Time: 2.50385
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.72099

Cumulative Model Updates: 76,008
Cumulative Timesteps: 633,948,398

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 633948398...
Checkpoint 633948398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696.55010
Policy Entropy: 3.28153
Value Function Loss: 0.00417

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.55637
Value Function Update Magnitude: 0.64427

Collected Steps per Second: 21,861.90627
Overall Steps per Second: 10,557.22654

Timestep Collection Time: 2.28800
Timestep Consumption Time: 2.44999
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.73799

Cumulative Model Updates: 76,014
Cumulative Timesteps: 633,998,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602.94238
Policy Entropy: 3.27923
Value Function Loss: 0.00421

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.13096
Policy Update Magnitude: 0.55359
Value Function Update Magnitude: 0.66027

Collected Steps per Second: 22,473.23395
Overall Steps per Second: 10,527.36606

Timestep Collection Time: 2.22540
Timestep Consumption Time: 2.52526
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.75067

Cumulative Model Updates: 76,020
Cumulative Timesteps: 634,048,430

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 634048430...
Checkpoint 634048430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 771.14569
Policy Entropy: 3.28702
Value Function Loss: 0.00403

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.14082
Policy Update Magnitude: 0.54799
Value Function Update Magnitude: 0.67615

Collected Steps per Second: 22,060.19103
Overall Steps per Second: 10,562.61814

Timestep Collection Time: 2.26852
Timestep Consumption Time: 2.46932
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.73784

Cumulative Model Updates: 76,026
Cumulative Timesteps: 634,098,474

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721.23319
Policy Entropy: 3.27654
Value Function Loss: 0.00397

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.14047
Policy Update Magnitude: 0.54814
Value Function Update Magnitude: 0.66900

Collected Steps per Second: 23,028.59244
Overall Steps per Second: 10,627.58843

Timestep Collection Time: 2.17121
Timestep Consumption Time: 2.53352
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 4.70474

Cumulative Model Updates: 76,032
Cumulative Timesteps: 634,148,474

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 634148474...
Checkpoint 634148474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 753.86475
Policy Entropy: 3.28149
Value Function Loss: 0.00399

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.13653
Policy Update Magnitude: 0.54769
Value Function Update Magnitude: 0.66707

Collected Steps per Second: 22,020.96962
Overall Steps per Second: 10,488.83789

Timestep Collection Time: 2.27156
Timestep Consumption Time: 2.49751
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.76907

Cumulative Model Updates: 76,038
Cumulative Timesteps: 634,198,496

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 825.93179
Policy Entropy: 3.29578
Value Function Loss: 0.00406

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12511
Policy Update Magnitude: 0.54566
Value Function Update Magnitude: 0.67884

Collected Steps per Second: 22,977.00792
Overall Steps per Second: 10,576.23521

Timestep Collection Time: 2.17652
Timestep Consumption Time: 2.55200
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.72853

Cumulative Model Updates: 76,044
Cumulative Timesteps: 634,248,506

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 634248506...
Checkpoint 634248506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 942.26766
Policy Entropy: 3.31101
Value Function Loss: 0.00397

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10257
Policy Update Magnitude: 0.53525
Value Function Update Magnitude: 0.68340

Collected Steps per Second: 22,407.85695
Overall Steps per Second: 10,568.19993

Timestep Collection Time: 2.23252
Timestep Consumption Time: 2.50111
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.73363

Cumulative Model Updates: 76,050
Cumulative Timesteps: 634,298,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.87745
Policy Entropy: 3.31280
Value Function Loss: 0.00395

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08305
Policy Update Magnitude: 0.53432
Value Function Update Magnitude: 0.65218

Collected Steps per Second: 22,862.89241
Overall Steps per Second: 10,800.34234

Timestep Collection Time: 2.18730
Timestep Consumption Time: 2.44292
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.63022

Cumulative Model Updates: 76,056
Cumulative Timesteps: 634,348,540

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 634348540...
Checkpoint 634348540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,474.01559
Policy Entropy: 3.29408
Value Function Loss: 0.00424

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09964
Policy Update Magnitude: 0.54857
Value Function Update Magnitude: 0.66048

Collected Steps per Second: 22,418.75967
Overall Steps per Second: 10,691.36527

Timestep Collection Time: 2.23161
Timestep Consumption Time: 2.44786
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.67948

Cumulative Model Updates: 76,062
Cumulative Timesteps: 634,398,570

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.35266
Policy Entropy: 3.29266
Value Function Loss: 0.00409

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09286
Policy Update Magnitude: 0.55398
Value Function Update Magnitude: 0.67831

Collected Steps per Second: 22,977.97095
Overall Steps per Second: 10,685.99832

Timestep Collection Time: 2.17669
Timestep Consumption Time: 2.50382
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.68052

Cumulative Model Updates: 76,068
Cumulative Timesteps: 634,448,586

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 634448586...
Checkpoint 634448586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481.19910
Policy Entropy: 3.29992
Value Function Loss: 0.00413

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09898
Policy Update Magnitude: 0.55182
Value Function Update Magnitude: 0.68237

Collected Steps per Second: 22,428.46895
Overall Steps per Second: 10,648.56914

Timestep Collection Time: 2.23011
Timestep Consumption Time: 2.46704
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.69716

Cumulative Model Updates: 76,074
Cumulative Timesteps: 634,498,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 981.99693
Policy Entropy: 3.31781
Value Function Loss: 0.00395

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.54525
Value Function Update Magnitude: 0.68766

Collected Steps per Second: 22,536.33615
Overall Steps per Second: 10,739.12182

Timestep Collection Time: 2.21970
Timestep Consumption Time: 2.43840
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.65811

Cumulative Model Updates: 76,080
Cumulative Timesteps: 634,548,628

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 634548628...
Checkpoint 634548628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,971.86727
Policy Entropy: 3.32257
Value Function Loss: 0.00396

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11250
Policy Update Magnitude: 0.53756
Value Function Update Magnitude: 0.67693

Collected Steps per Second: 22,203.76694
Overall Steps per Second: 10,610.31552

Timestep Collection Time: 2.25205
Timestep Consumption Time: 2.46072
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.71277

Cumulative Model Updates: 76,086
Cumulative Timesteps: 634,598,632

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328.99766
Policy Entropy: 3.32144
Value Function Loss: 0.00396

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11130
Policy Update Magnitude: 0.53293
Value Function Update Magnitude: 0.67111

Collected Steps per Second: 22,030.53032
Overall Steps per Second: 10,471.73633

Timestep Collection Time: 2.27003
Timestep Consumption Time: 2.50568
PPO Batch Consumption Time: 0.29668
Total Iteration Time: 4.77571

Cumulative Model Updates: 76,092
Cumulative Timesteps: 634,648,642

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 634648642...
Checkpoint 634648642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 809.75360
Policy Entropy: 3.32666
Value Function Loss: 0.00397

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09207
Policy Update Magnitude: 0.53748
Value Function Update Magnitude: 0.66100

Collected Steps per Second: 22,208.03940
Overall Steps per Second: 10,585.40490

Timestep Collection Time: 2.25171
Timestep Consumption Time: 2.47234
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.72405

Cumulative Model Updates: 76,098
Cumulative Timesteps: 634,698,648

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 890.76593
Policy Entropy: 3.31634
Value Function Loss: 0.00403

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09074
Policy Update Magnitude: 0.54140
Value Function Update Magnitude: 0.65352

Collected Steps per Second: 23,121.08696
Overall Steps per Second: 10,855.89697

Timestep Collection Time: 2.16339
Timestep Consumption Time: 2.44424
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.60763

Cumulative Model Updates: 76,104
Cumulative Timesteps: 634,748,668

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 634748668...
Checkpoint 634748668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 787.86525
Policy Entropy: 3.31237
Value Function Loss: 0.00399

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09806
Policy Update Magnitude: 0.53582
Value Function Update Magnitude: 0.66174

Collected Steps per Second: 22,561.62426
Overall Steps per Second: 10,719.41212

Timestep Collection Time: 2.21615
Timestep Consumption Time: 2.44828
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.66443

Cumulative Model Updates: 76,110
Cumulative Timesteps: 634,798,668

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.11660
Policy Entropy: 3.32103
Value Function Loss: 0.00392

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09199
Policy Update Magnitude: 0.52959
Value Function Update Magnitude: 0.65690

Collected Steps per Second: 22,808.49287
Overall Steps per Second: 10,798.95564

Timestep Collection Time: 2.19339
Timestep Consumption Time: 2.43928
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.63267

Cumulative Model Updates: 76,116
Cumulative Timesteps: 634,848,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 634848696...
Checkpoint 634848696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619.50934
Policy Entropy: 3.33297
Value Function Loss: 0.00393

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07772
Policy Update Magnitude: 0.52704
Value Function Update Magnitude: 0.64684

Collected Steps per Second: 22,625.27665
Overall Steps per Second: 10,743.12469

Timestep Collection Time: 2.21071
Timestep Consumption Time: 2.44510
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.65581

Cumulative Model Updates: 76,122
Cumulative Timesteps: 634,898,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.32642
Policy Entropy: 3.31946
Value Function Loss: 0.00385

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08416
Policy Update Magnitude: 0.52570
Value Function Update Magnitude: 0.66124

Collected Steps per Second: 22,679.85077
Overall Steps per Second: 10,789.18750

Timestep Collection Time: 2.20539
Timestep Consumption Time: 2.43054
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.63594

Cumulative Model Updates: 76,128
Cumulative Timesteps: 634,948,732

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 634948732...
Checkpoint 634948732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.18868
Policy Entropy: 3.29795
Value Function Loss: 0.00406

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08165
Policy Update Magnitude: 0.53313
Value Function Update Magnitude: 0.66265

Collected Steps per Second: 22,733.75753
Overall Steps per Second: 10,764.25014

Timestep Collection Time: 2.19990
Timestep Consumption Time: 2.44622
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.64612

Cumulative Model Updates: 76,134
Cumulative Timesteps: 634,998,744

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.13877
Policy Entropy: 3.29589
Value Function Loss: 0.00408

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09507
Policy Update Magnitude: 0.54453
Value Function Update Magnitude: 0.67326

Collected Steps per Second: 22,591.15773
Overall Steps per Second: 10,653.81131

Timestep Collection Time: 2.21379
Timestep Consumption Time: 2.48050
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.69428

Cumulative Model Updates: 76,140
Cumulative Timesteps: 635,048,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 635048756...
Checkpoint 635048756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 941.68227
Policy Entropy: 3.29188
Value Function Loss: 0.00418

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09704
Policy Update Magnitude: 0.54699
Value Function Update Magnitude: 0.65681

Collected Steps per Second: 22,427.05377
Overall Steps per Second: 10,609.13205

Timestep Collection Time: 2.22954
Timestep Consumption Time: 2.48357
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.71311

Cumulative Model Updates: 76,146
Cumulative Timesteps: 635,098,758

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 813.79533
Policy Entropy: 3.29871
Value Function Loss: 0.00421

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11340
Policy Update Magnitude: 0.54333
Value Function Update Magnitude: 0.65129

Collected Steps per Second: 22,540.63902
Overall Steps per Second: 10,792.73260

Timestep Collection Time: 2.21875
Timestep Consumption Time: 2.41511
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.63386

Cumulative Model Updates: 76,152
Cumulative Timesteps: 635,148,770

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 635148770...
Checkpoint 635148770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.12814
Policy Entropy: 3.28886
Value Function Loss: 0.00438

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11579
Policy Update Magnitude: 0.53557
Value Function Update Magnitude: 0.64843

Collected Steps per Second: 22,288.60112
Overall Steps per Second: 10,692.09105

Timestep Collection Time: 2.24456
Timestep Consumption Time: 2.43442
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.67897

Cumulative Model Updates: 76,158
Cumulative Timesteps: 635,198,798

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 952.17616
Policy Entropy: 3.29931
Value Function Loss: 0.00424

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.54194
Value Function Update Magnitude: 0.63745

Collected Steps per Second: 21,935.19708
Overall Steps per Second: 10,710.40970

Timestep Collection Time: 2.27972
Timestep Consumption Time: 2.38920
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.66892

Cumulative Model Updates: 76,164
Cumulative Timesteps: 635,248,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 635248804...
Checkpoint 635248804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.96575
Policy Entropy: 3.29065
Value Function Loss: 0.00425

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08544
Policy Update Magnitude: 0.54430
Value Function Update Magnitude: 0.63830

Collected Steps per Second: 21,248.51376
Overall Steps per Second: 10,398.38744

Timestep Collection Time: 2.35367
Timestep Consumption Time: 2.45592
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.80959

Cumulative Model Updates: 76,170
Cumulative Timesteps: 635,298,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 822.96521
Policy Entropy: 3.29911
Value Function Loss: 0.00396

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08250
Policy Update Magnitude: 0.53974
Value Function Update Magnitude: 0.63058

Collected Steps per Second: 22,269.36673
Overall Steps per Second: 10,760.68138

Timestep Collection Time: 2.24596
Timestep Consumption Time: 2.40208
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.64803

Cumulative Model Updates: 76,176
Cumulative Timesteps: 635,348,832

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 635348832...
Checkpoint 635348832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 798.12769
Policy Entropy: 3.29798
Value Function Loss: 0.00434

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07801
Policy Update Magnitude: 0.54267
Value Function Update Magnitude: 0.64385

Collected Steps per Second: 22,726.86682
Overall Steps per Second: 10,641.74103

Timestep Collection Time: 2.20048
Timestep Consumption Time: 2.49894
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.69942

Cumulative Model Updates: 76,182
Cumulative Timesteps: 635,398,842

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.38772
Policy Entropy: 3.30989
Value Function Loss: 0.00411

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08587
Policy Update Magnitude: 0.54938
Value Function Update Magnitude: 0.66087

Collected Steps per Second: 22,822.98988
Overall Steps per Second: 10,753.88002

Timestep Collection Time: 2.19095
Timestep Consumption Time: 2.45891
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.64986

Cumulative Model Updates: 76,188
Cumulative Timesteps: 635,448,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 635448846...
Checkpoint 635448846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.80326
Policy Entropy: 3.31206
Value Function Loss: 0.00423

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08664
Policy Update Magnitude: 0.54886
Value Function Update Magnitude: 0.67602

Collected Steps per Second: 22,620.62869
Overall Steps per Second: 10,743.82514

Timestep Collection Time: 2.21090
Timestep Consumption Time: 2.44405
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.65495

Cumulative Model Updates: 76,194
Cumulative Timesteps: 635,498,858

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693.96903
Policy Entropy: 3.31063
Value Function Loss: 0.00393

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09104
Policy Update Magnitude: 0.54406
Value Function Update Magnitude: 0.68462

Collected Steps per Second: 22,641.99732
Overall Steps per Second: 10,575.52633

Timestep Collection Time: 2.20899
Timestep Consumption Time: 2.52042
PPO Batch Consumption Time: 0.29816
Total Iteration Time: 4.72941

Cumulative Model Updates: 76,200
Cumulative Timesteps: 635,548,874

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 635548874...
Checkpoint 635548874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.04751
Policy Entropy: 3.29989
Value Function Loss: 0.00388

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09332
Policy Update Magnitude: 0.53515
Value Function Update Magnitude: 0.67562

Collected Steps per Second: 22,700.93554
Overall Steps per Second: 10,604.97094

Timestep Collection Time: 2.20264
Timestep Consumption Time: 2.51232
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 4.71496

Cumulative Model Updates: 76,206
Cumulative Timesteps: 635,598,876

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 742.44239
Policy Entropy: 3.30490
Value Function Loss: 0.00403

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08301
Policy Update Magnitude: 0.53629
Value Function Update Magnitude: 0.67533

Collected Steps per Second: 22,709.01214
Overall Steps per Second: 10,683.04200

Timestep Collection Time: 2.20221
Timestep Consumption Time: 2.47904
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.68125

Cumulative Model Updates: 76,212
Cumulative Timesteps: 635,648,886

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 635648886...
Checkpoint 635648886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.38440
Policy Entropy: 3.30028
Value Function Loss: 0.00418

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08659
Policy Update Magnitude: 0.54025
Value Function Update Magnitude: 0.67255

Collected Steps per Second: 22,861.64880
Overall Steps per Second: 10,771.70501

Timestep Collection Time: 2.18733
Timestep Consumption Time: 2.45502
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.64235

Cumulative Model Updates: 76,218
Cumulative Timesteps: 635,698,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.61065
Policy Entropy: 3.30491
Value Function Loss: 0.00401

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08537
Policy Update Magnitude: 0.53593
Value Function Update Magnitude: 0.64466

Collected Steps per Second: 21,531.77133
Overall Steps per Second: 10,557.11863

Timestep Collection Time: 2.32261
Timestep Consumption Time: 2.41447
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.73709

Cumulative Model Updates: 76,224
Cumulative Timesteps: 635,748,902

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 635748902...
Checkpoint 635748902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,417.93180
Policy Entropy: 3.30225
Value Function Loss: 0.00394

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07956
Policy Update Magnitude: 0.52878
Value Function Update Magnitude: 0.63082

Collected Steps per Second: 21,548.55641
Overall Steps per Second: 10,648.73130

Timestep Collection Time: 2.32136
Timestep Consumption Time: 2.37610
PPO Batch Consumption Time: 0.28193
Total Iteration Time: 4.69746

Cumulative Model Updates: 76,230
Cumulative Timesteps: 635,798,924

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 952.36868
Policy Entropy: 3.31075
Value Function Loss: 0.00381

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07536
Policy Update Magnitude: 0.52691
Value Function Update Magnitude: 0.61933

Collected Steps per Second: 22,156.84784
Overall Steps per Second: 10,574.79620

Timestep Collection Time: 2.25817
Timestep Consumption Time: 2.47327
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.73144

Cumulative Model Updates: 76,236
Cumulative Timesteps: 635,848,958

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 635848958...
Checkpoint 635848958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 997.46395
Policy Entropy: 3.31154
Value Function Loss: 0.00371

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07700
Policy Update Magnitude: 0.52850
Value Function Update Magnitude: 0.62803

Collected Steps per Second: 22,942.05415
Overall Steps per Second: 10,689.65256

Timestep Collection Time: 2.17940
Timestep Consumption Time: 2.49802
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.67742

Cumulative Model Updates: 76,242
Cumulative Timesteps: 635,898,958

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.09531
Policy Entropy: 3.29878
Value Function Loss: 0.00374

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.07976
Policy Update Magnitude: 0.52102
Value Function Update Magnitude: 0.63185

Collected Steps per Second: 23,081.60892
Overall Steps per Second: 10,703.93068

Timestep Collection Time: 2.16692
Timestep Consumption Time: 2.50576
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.67268

Cumulative Model Updates: 76,248
Cumulative Timesteps: 635,948,974

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 635948974...
Checkpoint 635948974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.00392
Policy Entropy: 3.29433
Value Function Loss: 0.00380

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09337
Policy Update Magnitude: 0.52745
Value Function Update Magnitude: 0.62289

Collected Steps per Second: 22,811.69170
Overall Steps per Second: 10,678.83449

Timestep Collection Time: 2.19317
Timestep Consumption Time: 2.49179
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.68497

Cumulative Model Updates: 76,254
Cumulative Timesteps: 635,999,004

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302.78151
Policy Entropy: 3.28752
Value Function Loss: 0.00376

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10049
Policy Update Magnitude: 0.52886
Value Function Update Magnitude: 0.63541

Collected Steps per Second: 23,134.81456
Overall Steps per Second: 10,788.89210

Timestep Collection Time: 2.16142
Timestep Consumption Time: 2.47335
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.63477

Cumulative Model Updates: 76,260
Cumulative Timesteps: 636,049,008

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 636049008...
Checkpoint 636049008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.41782
Policy Entropy: 3.29363
Value Function Loss: 0.00382

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.10919
Policy Update Magnitude: 0.52430
Value Function Update Magnitude: 0.62616

Collected Steps per Second: 22,532.44006
Overall Steps per Second: 10,694.67706

Timestep Collection Time: 2.21920
Timestep Consumption Time: 2.45640
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.67560

Cumulative Model Updates: 76,266
Cumulative Timesteps: 636,099,012

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760.51802
Policy Entropy: 3.27055
Value Function Loss: 0.00427

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12070
Policy Update Magnitude: 0.53796
Value Function Update Magnitude: 0.65163

Collected Steps per Second: 22,506.83561
Overall Steps per Second: 10,526.38513

Timestep Collection Time: 2.22226
Timestep Consumption Time: 2.52923
PPO Batch Consumption Time: 0.29779
Total Iteration Time: 4.75149

Cumulative Model Updates: 76,272
Cumulative Timesteps: 636,149,028

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 636149028...
Checkpoint 636149028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.24192
Policy Entropy: 3.26242
Value Function Loss: 0.00430

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.12975
Policy Update Magnitude: 0.55035
Value Function Update Magnitude: 0.68306

Collected Steps per Second: 22,578.15485
Overall Steps per Second: 10,593.81975

Timestep Collection Time: 2.21568
Timestep Consumption Time: 2.50651
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.72219

Cumulative Model Updates: 76,278
Cumulative Timesteps: 636,199,054

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.12970
Policy Entropy: 3.26657
Value Function Loss: 0.00430

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10133
Policy Update Magnitude: 0.55146
Value Function Update Magnitude: 0.70384

Collected Steps per Second: 22,225.23526
Overall Steps per Second: 10,462.71869

Timestep Collection Time: 2.25095
Timestep Consumption Time: 2.53059
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.78155

Cumulative Model Updates: 76,284
Cumulative Timesteps: 636,249,082

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 636249082...
Checkpoint 636249082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 842.71407
Policy Entropy: 3.28021
Value Function Loss: 0.00413

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08364
Policy Update Magnitude: 0.54654
Value Function Update Magnitude: 0.69245

Collected Steps per Second: 22,486.54128
Overall Steps per Second: 10,628.78941

Timestep Collection Time: 2.22382
Timestep Consumption Time: 2.48095
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.70477

Cumulative Model Updates: 76,290
Cumulative Timesteps: 636,299,088

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744.64346
Policy Entropy: 3.27738
Value Function Loss: 0.00400

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08918
Policy Update Magnitude: 0.54809
Value Function Update Magnitude: 0.69009

Collected Steps per Second: 22,440.95979
Overall Steps per Second: 10,529.47638

Timestep Collection Time: 2.22887
Timestep Consumption Time: 2.52141
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.75028

Cumulative Model Updates: 76,296
Cumulative Timesteps: 636,349,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 636349106...
Checkpoint 636349106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.03661
Policy Entropy: 3.28035
Value Function Loss: 0.00398

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08185
Policy Update Magnitude: 0.54806
Value Function Update Magnitude: 0.67231

Collected Steps per Second: 22,610.30400
Overall Steps per Second: 10,582.34281

Timestep Collection Time: 2.21227
Timestep Consumption Time: 2.51448
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.72674

Cumulative Model Updates: 76,302
Cumulative Timesteps: 636,399,126

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.66943
Policy Entropy: 3.27640
Value Function Loss: 0.00418

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09698
Policy Update Magnitude: 0.54063
Value Function Update Magnitude: 0.65596

Collected Steps per Second: 23,000.04245
Overall Steps per Second: 10,633.35938

Timestep Collection Time: 2.17417
Timestep Consumption Time: 2.52858
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.70275

Cumulative Model Updates: 76,308
Cumulative Timesteps: 636,449,132

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 636449132...
Checkpoint 636449132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,503.08097
Policy Entropy: 3.26215
Value Function Loss: 0.00433

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10478
Policy Update Magnitude: 0.54329
Value Function Update Magnitude: 0.66543

Collected Steps per Second: 22,858.86540
Overall Steps per Second: 10,796.63276

Timestep Collection Time: 2.18812
Timestep Consumption Time: 2.44462
PPO Batch Consumption Time: 0.28174
Total Iteration Time: 4.63274

Cumulative Model Updates: 76,314
Cumulative Timesteps: 636,499,150

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 848.15819
Policy Entropy: 3.25218
Value Function Loss: 0.00424

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10882
Policy Update Magnitude: 0.54633
Value Function Update Magnitude: 0.66497

Collected Steps per Second: 22,879.76846
Overall Steps per Second: 10,610.19710

Timestep Collection Time: 2.18534
Timestep Consumption Time: 2.52711
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 4.71245

Cumulative Model Updates: 76,320
Cumulative Timesteps: 636,549,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 636549150...
Checkpoint 636549150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,005.71236
Policy Entropy: 3.24980
Value Function Loss: 0.00405

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.54225
Value Function Update Magnitude: 0.65182

Collected Steps per Second: 22,624.70978
Overall Steps per Second: 10,594.23757

Timestep Collection Time: 2.20997
Timestep Consumption Time: 2.50957
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.71955

Cumulative Model Updates: 76,326
Cumulative Timesteps: 636,599,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.62586
Policy Entropy: 3.24872
Value Function Loss: 0.00409

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08342
Policy Update Magnitude: 0.53560
Value Function Update Magnitude: 0.63119

Collected Steps per Second: 22,729.57952
Overall Steps per Second: 10,601.54777

Timestep Collection Time: 2.20101
Timestep Consumption Time: 2.51793
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.71893

Cumulative Model Updates: 76,332
Cumulative Timesteps: 636,649,178

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 636649178...
Checkpoint 636649178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620.48490
Policy Entropy: 3.25992
Value Function Loss: 0.00410

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.53358
Value Function Update Magnitude: 0.65567

Collected Steps per Second: 22,632.99225
Overall Steps per Second: 10,632.17157

Timestep Collection Time: 2.20961
Timestep Consumption Time: 2.49404
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.70365

Cumulative Model Updates: 76,338
Cumulative Timesteps: 636,699,188

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.86761
Policy Entropy: 3.26744
Value Function Loss: 0.00418

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08578
Policy Update Magnitude: 0.54295
Value Function Update Magnitude: 0.69315

Collected Steps per Second: 22,390.73160
Overall Steps per Second: 10,654.04765

Timestep Collection Time: 2.23414
Timestep Consumption Time: 2.46117
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.69530

Cumulative Model Updates: 76,344
Cumulative Timesteps: 636,749,212

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 636749212...
Checkpoint 636749212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 888.59938
Policy Entropy: 3.27658
Value Function Loss: 0.00412

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07479
Policy Update Magnitude: 0.55324
Value Function Update Magnitude: 0.69753

Collected Steps per Second: 22,080.78266
Overall Steps per Second: 10,355.78529

Timestep Collection Time: 2.26514
Timestep Consumption Time: 2.56463
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.82976

Cumulative Model Updates: 76,350
Cumulative Timesteps: 636,799,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.68804
Policy Entropy: 3.26815
Value Function Loss: 0.00393

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07047
Policy Update Magnitude: 0.55161
Value Function Update Magnitude: 0.69344

Collected Steps per Second: 21,134.94806
Overall Steps per Second: 10,272.01286

Timestep Collection Time: 2.36689
Timestep Consumption Time: 2.50305
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.86993

Cumulative Model Updates: 76,356
Cumulative Timesteps: 636,849,252

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 636849252...
Checkpoint 636849252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.64906
Policy Entropy: 3.26697
Value Function Loss: 0.00383

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.07729
Policy Update Magnitude: 0.54504
Value Function Update Magnitude: 0.66428

Collected Steps per Second: 22,241.61276
Overall Steps per Second: 10,539.36761

Timestep Collection Time: 2.24921
Timestep Consumption Time: 2.49738
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.74658

Cumulative Model Updates: 76,362
Cumulative Timesteps: 636,899,278

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.52575
Policy Entropy: 3.24535
Value Function Loss: 0.00401

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09633
Policy Update Magnitude: 0.54420
Value Function Update Magnitude: 0.64874

Collected Steps per Second: 22,438.91673
Overall Steps per Second: 10,687.01445

Timestep Collection Time: 2.22925
Timestep Consumption Time: 2.45138
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.68063

Cumulative Model Updates: 76,368
Cumulative Timesteps: 636,949,300

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 636949300...
Checkpoint 636949300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636.76141
Policy Entropy: 3.24438
Value Function Loss: 0.00394

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08558
Policy Update Magnitude: 0.54595
Value Function Update Magnitude: 0.68231

Collected Steps per Second: 22,851.88615
Overall Steps per Second: 10,644.89390

Timestep Collection Time: 2.18844
Timestep Consumption Time: 2.50959
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.69803

Cumulative Model Updates: 76,374
Cumulative Timesteps: 636,999,310

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.44618
Policy Entropy: 3.24848
Value Function Loss: 0.00391

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10023
Policy Update Magnitude: 0.54185
Value Function Update Magnitude: 0.70731

Collected Steps per Second: 22,735.36186
Overall Steps per Second: 10,724.42417

Timestep Collection Time: 2.19992
Timestep Consumption Time: 2.46383
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.66375

Cumulative Model Updates: 76,380
Cumulative Timesteps: 637,049,326

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 637049326...
Checkpoint 637049326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.50922
Policy Entropy: 3.26558
Value Function Loss: 0.00394

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08714
Policy Update Magnitude: 0.53361
Value Function Update Magnitude: 0.67402

Collected Steps per Second: 22,602.56905
Overall Steps per Second: 10,822.25206

Timestep Collection Time: 2.21285
Timestep Consumption Time: 2.40874
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.62159

Cumulative Model Updates: 76,386
Cumulative Timesteps: 637,099,342

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 962.54240
Policy Entropy: 3.25473
Value Function Loss: 0.00407

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08127
Policy Update Magnitude: 0.54161
Value Function Update Magnitude: 0.64785

Collected Steps per Second: 22,903.87274
Overall Steps per Second: 10,831.25884

Timestep Collection Time: 2.18374
Timestep Consumption Time: 2.43401
PPO Batch Consumption Time: 0.28364
Total Iteration Time: 4.61775

Cumulative Model Updates: 76,392
Cumulative Timesteps: 637,149,358

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 637149358...
Checkpoint 637149358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750.17273
Policy Entropy: 3.23047
Value Function Loss: 0.00419

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.55061
Value Function Update Magnitude: 0.63691

Collected Steps per Second: 22,234.87518
Overall Steps per Second: 10,637.08932

Timestep Collection Time: 2.24998
Timestep Consumption Time: 2.45319
PPO Batch Consumption Time: 0.28179
Total Iteration Time: 4.70317

Cumulative Model Updates: 76,398
Cumulative Timesteps: 637,199,386

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.33497
Policy Entropy: 3.23865
Value Function Loss: 0.00402

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08992
Policy Update Magnitude: 0.54994
Value Function Update Magnitude: 0.62620

Collected Steps per Second: 22,559.68377
Overall Steps per Second: 10,588.61648

Timestep Collection Time: 2.21696
Timestep Consumption Time: 2.50641
PPO Batch Consumption Time: 0.29735
Total Iteration Time: 4.72337

Cumulative Model Updates: 76,404
Cumulative Timesteps: 637,249,400

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 637249400...
Checkpoint 637249400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 866.28885
Policy Entropy: 3.24660
Value Function Loss: 0.00398

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.53915
Value Function Update Magnitude: 0.62978

Collected Steps per Second: 23,012.70492
Overall Steps per Second: 10,757.96036

Timestep Collection Time: 2.17410
Timestep Consumption Time: 2.47659
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.65070

Cumulative Model Updates: 76,410
Cumulative Timesteps: 637,299,432

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.23172
Policy Entropy: 3.25266
Value Function Loss: 0.00394

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09153
Policy Update Magnitude: 0.53066
Value Function Update Magnitude: 0.61428

Collected Steps per Second: 22,308.08996
Overall Steps per Second: 10,688.80735

Timestep Collection Time: 2.24242
Timestep Consumption Time: 2.43762
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.68004

Cumulative Model Updates: 76,416
Cumulative Timesteps: 637,349,456

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 637349456...
Checkpoint 637349456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 965.83989
Policy Entropy: 3.23090
Value Function Loss: 0.00421

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10126
Policy Update Magnitude: 0.53359
Value Function Update Magnitude: 0.60842

Collected Steps per Second: 22,126.10126
Overall Steps per Second: 10,650.77500

Timestep Collection Time: 2.26005
Timestep Consumption Time: 2.43501
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.69506

Cumulative Model Updates: 76,422
Cumulative Timesteps: 637,399,462

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 812.40611
Policy Entropy: 3.21378
Value Function Loss: 0.00402

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09660
Policy Update Magnitude: 0.54602
Value Function Update Magnitude: 0.62088

Collected Steps per Second: 22,435.43945
Overall Steps per Second: 10,609.89949

Timestep Collection Time: 2.22897
Timestep Consumption Time: 2.48436
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.71333

Cumulative Model Updates: 76,428
Cumulative Timesteps: 637,449,470

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 637449470...
Checkpoint 637449470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 746.54150
Policy Entropy: 3.21693
Value Function Loss: 0.00405

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09987
Policy Update Magnitude: 0.55408
Value Function Update Magnitude: 0.62178

Collected Steps per Second: 22,490.14707
Overall Steps per Second: 10,853.96480

Timestep Collection Time: 2.22391
Timestep Consumption Time: 2.38418
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.60809

Cumulative Model Updates: 76,434
Cumulative Timesteps: 637,499,486

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,461.81306
Policy Entropy: 3.24800
Value Function Loss: 0.00376

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09971
Policy Update Magnitude: 0.54524
Value Function Update Magnitude: 0.60317

Collected Steps per Second: 22,164.01263
Overall Steps per Second: 10,565.31336

Timestep Collection Time: 2.25591
Timestep Consumption Time: 2.47656
PPO Batch Consumption Time: 0.29648
Total Iteration Time: 4.73247

Cumulative Model Updates: 76,440
Cumulative Timesteps: 637,549,486

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 637549486...
Checkpoint 637549486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.18002
Policy Entropy: 3.26302
Value Function Loss: 0.00366

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11162
Policy Update Magnitude: 0.53200
Value Function Update Magnitude: 0.59184

Collected Steps per Second: 22,099.27960
Overall Steps per Second: 10,620.70876

Timestep Collection Time: 2.26378
Timestep Consumption Time: 2.44664
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.71042

Cumulative Model Updates: 76,446
Cumulative Timesteps: 637,599,514

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 935.09279
Policy Entropy: 3.27683
Value Function Loss: 0.00360

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10980
Policy Update Magnitude: 0.52332
Value Function Update Magnitude: 0.59741

Collected Steps per Second: 22,523.75727
Overall Steps per Second: 10,860.37097

Timestep Collection Time: 2.21988
Timestep Consumption Time: 2.38402
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.60389

Cumulative Model Updates: 76,452
Cumulative Timesteps: 637,649,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 637649514...
Checkpoint 637649514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.08257
Policy Entropy: 3.26432
Value Function Loss: 0.00367

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09473
Policy Update Magnitude: 0.52406
Value Function Update Magnitude: 0.59408

Collected Steps per Second: 21,924.01556
Overall Steps per Second: 10,685.97285

Timestep Collection Time: 2.28170
Timestep Consumption Time: 2.39958
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.68128

Cumulative Model Updates: 76,458
Cumulative Timesteps: 637,699,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.77507
Policy Entropy: 3.26084
Value Function Loss: 0.00394

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08334
Policy Update Magnitude: 0.54172
Value Function Update Magnitude: 0.59784

Collected Steps per Second: 21,838.64898
Overall Steps per Second: 10,546.64002

Timestep Collection Time: 2.28961
Timestep Consumption Time: 2.45143
PPO Batch Consumption Time: 0.29654
Total Iteration Time: 4.74104

Cumulative Model Updates: 76,464
Cumulative Timesteps: 637,749,540

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 637749540...
Checkpoint 637749540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.95904
Policy Entropy: 3.27478
Value Function Loss: 0.00390

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.07737
Policy Update Magnitude: 0.54597
Value Function Update Magnitude: 0.60749

Collected Steps per Second: 22,097.90170
Overall Steps per Second: 10,593.81994

Timestep Collection Time: 2.26311
Timestep Consumption Time: 2.45757
PPO Batch Consumption Time: 0.29869
Total Iteration Time: 4.72068

Cumulative Model Updates: 76,470
Cumulative Timesteps: 637,799,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,379.86406
Policy Entropy: 3.28164
Value Function Loss: 0.00418

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08859
Policy Update Magnitude: 0.55078
Value Function Update Magnitude: 0.62277

Collected Steps per Second: 21,861.75266
Overall Steps per Second: 10,622.06788

Timestep Collection Time: 2.28902
Timestep Consumption Time: 2.42211
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.71114

Cumulative Model Updates: 76,476
Cumulative Timesteps: 637,849,592

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 637849592...
Checkpoint 637849592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 950.71897
Policy Entropy: 3.28548
Value Function Loss: 0.00395

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09459
Policy Update Magnitude: 0.54834
Value Function Update Magnitude: 0.62929

Collected Steps per Second: 21,776.62962
Overall Steps per Second: 10,463.33622

Timestep Collection Time: 2.29733
Timestep Consumption Time: 2.48394
PPO Batch Consumption Time: 0.29773
Total Iteration Time: 4.78127

Cumulative Model Updates: 76,482
Cumulative Timesteps: 637,899,620

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.08332
Policy Entropy: 3.27202
Value Function Loss: 0.00432

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.11787
Policy Update Magnitude: 0.55834
Value Function Update Magnitude: 0.63374

Collected Steps per Second: 22,357.90751
Overall Steps per Second: 10,509.57328

Timestep Collection Time: 2.23661
Timestep Consumption Time: 2.52152
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.75814

Cumulative Model Updates: 76,488
Cumulative Timesteps: 637,949,626

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 637949626...
Checkpoint 637949626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 924.61169
Policy Entropy: 3.26731
Value Function Loss: 0.00426

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12130
Policy Update Magnitude: 0.56540
Value Function Update Magnitude: 0.66484

Collected Steps per Second: 22,661.56449
Overall Steps per Second: 10,584.62504

Timestep Collection Time: 2.20638
Timestep Consumption Time: 2.51745
PPO Batch Consumption Time: 0.29752
Total Iteration Time: 4.72383

Cumulative Model Updates: 76,494
Cumulative Timesteps: 637,999,626

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.33558
Policy Entropy: 3.27197
Value Function Loss: 0.00433

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10362
Policy Update Magnitude: 0.57042
Value Function Update Magnitude: 0.67252

Collected Steps per Second: 22,151.65944
Overall Steps per Second: 10,464.16763

Timestep Collection Time: 2.25744
Timestep Consumption Time: 2.52135
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.77878

Cumulative Model Updates: 76,500
Cumulative Timesteps: 638,049,632

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 638049632...
Checkpoint 638049632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 848.56018
Policy Entropy: 3.26259
Value Function Loss: 0.00422

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08731
Policy Update Magnitude: 0.57672
Value Function Update Magnitude: 0.65027

Collected Steps per Second: 22,345.84552
Overall Steps per Second: 10,572.82729

Timestep Collection Time: 2.23809
Timestep Consumption Time: 2.49215
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.73024

Cumulative Model Updates: 76,506
Cumulative Timesteps: 638,099,644

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 852.93294
Policy Entropy: 3.25851
Value Function Loss: 0.00449

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09114
Policy Update Magnitude: 0.58296
Value Function Update Magnitude: 0.63935

Collected Steps per Second: 22,682.58391
Overall Steps per Second: 10,510.16708

Timestep Collection Time: 2.20433
Timestep Consumption Time: 2.55296
PPO Batch Consumption Time: 0.29759
Total Iteration Time: 4.75730

Cumulative Model Updates: 76,512
Cumulative Timesteps: 638,149,644

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 638149644...
Checkpoint 638149644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 962.09777
Policy Entropy: 3.25290
Value Function Loss: 0.00440

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10673
Policy Update Magnitude: 0.58013
Value Function Update Magnitude: 0.63141

Collected Steps per Second: 22,814.32144
Overall Steps per Second: 10,593.16738

Timestep Collection Time: 2.19169
Timestep Consumption Time: 2.52852
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.72021

Cumulative Model Updates: 76,518
Cumulative Timesteps: 638,199,646

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.14726
Policy Entropy: 3.26975
Value Function Loss: 0.00424

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09720
Policy Update Magnitude: 0.56915
Value Function Update Magnitude: 0.62620

Collected Steps per Second: 23,144.14533
Overall Steps per Second: 10,830.60782

Timestep Collection Time: 2.16167
Timestep Consumption Time: 2.45765
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.61932

Cumulative Model Updates: 76,524
Cumulative Timesteps: 638,249,676

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 638249676...
Checkpoint 638249676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597.82280
Policy Entropy: 3.26840
Value Function Loss: 0.00415

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10929
Policy Update Magnitude: 0.56350
Value Function Update Magnitude: 0.62410

Collected Steps per Second: 22,735.57826
Overall Steps per Second: 10,733.52621

Timestep Collection Time: 2.20034
Timestep Consumption Time: 2.46038
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.66072

Cumulative Model Updates: 76,530
Cumulative Timesteps: 638,299,702

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.00589
Policy Entropy: 3.28853
Value Function Loss: 0.00414

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09828
Policy Update Magnitude: 0.55996
Value Function Update Magnitude: 0.61660

Collected Steps per Second: 23,084.49846
Overall Steps per Second: 10,821.75732

Timestep Collection Time: 2.16674
Timestep Consumption Time: 2.45525
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.62198

Cumulative Model Updates: 76,536
Cumulative Timesteps: 638,349,720

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 638349720...
Checkpoint 638349720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.55824
Policy Entropy: 3.29179
Value Function Loss: 0.00436

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08675
Policy Update Magnitude: 0.56204
Value Function Update Magnitude: 0.61780

Collected Steps per Second: 22,811.43193
Overall Steps per Second: 10,735.41544

Timestep Collection Time: 2.19311
Timestep Consumption Time: 2.46698
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.66009

Cumulative Model Updates: 76,542
Cumulative Timesteps: 638,399,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.52845
Policy Entropy: 3.28893
Value Function Loss: 0.00431

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08495
Policy Update Magnitude: 0.56344
Value Function Update Magnitude: 0.63256

Collected Steps per Second: 22,332.07989
Overall Steps per Second: 10,521.70473

Timestep Collection Time: 2.23920
Timestep Consumption Time: 2.51345
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 4.75265

Cumulative Model Updates: 76,548
Cumulative Timesteps: 638,449,754

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 638449754...
Checkpoint 638449754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,630.10656
Policy Entropy: 3.28067
Value Function Loss: 0.00410

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07922
Policy Update Magnitude: 0.56332
Value Function Update Magnitude: 0.64680

Collected Steps per Second: 22,412.60812
Overall Steps per Second: 10,548.14019

Timestep Collection Time: 2.23196
Timestep Consumption Time: 2.51049
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.74245

Cumulative Model Updates: 76,554
Cumulative Timesteps: 638,499,778

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 837.98058
Policy Entropy: 3.27076
Value Function Loss: 0.00405

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08501
Policy Update Magnitude: 0.55960
Value Function Update Magnitude: 0.65739

Collected Steps per Second: 22,393.73989
Overall Steps per Second: 10,499.99458

Timestep Collection Time: 2.23321
Timestep Consumption Time: 2.52965
PPO Batch Consumption Time: 0.29632
Total Iteration Time: 4.76286

Cumulative Model Updates: 76,560
Cumulative Timesteps: 638,549,788

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 638549788...
Checkpoint 638549788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.85217
Policy Entropy: 3.28264
Value Function Loss: 0.00406

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08886
Policy Update Magnitude: 0.55962
Value Function Update Magnitude: 0.67054

Collected Steps per Second: 22,368.12945
Overall Steps per Second: 10,613.82098

Timestep Collection Time: 2.23631
Timestep Consumption Time: 2.47660
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.71291

Cumulative Model Updates: 76,566
Cumulative Timesteps: 638,599,810

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 883.35851
Policy Entropy: 3.27953
Value Function Loss: 0.00402

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08464
Policy Update Magnitude: 0.55944
Value Function Update Magnitude: 0.66656

Collected Steps per Second: 21,863.94240
Overall Steps per Second: 10,442.58487

Timestep Collection Time: 2.28751
Timestep Consumption Time: 2.50192
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.78943

Cumulative Model Updates: 76,572
Cumulative Timesteps: 638,649,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 638649824...
Checkpoint 638649824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,368.52139
Policy Entropy: 3.29225
Value Function Loss: 0.00401

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08406
Policy Update Magnitude: 0.55671
Value Function Update Magnitude: 0.64385

Collected Steps per Second: 22,416.95747
Overall Steps per Second: 10,679.16687

Timestep Collection Time: 2.23126
Timestep Consumption Time: 2.45244
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.68370

Cumulative Model Updates: 76,578
Cumulative Timesteps: 638,699,842

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.30635
Policy Entropy: 3.28506
Value Function Loss: 0.00435

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07968
Policy Update Magnitude: 0.56116
Value Function Update Magnitude: 0.64077

Collected Steps per Second: 22,784.57386
Overall Steps per Second: 10,610.30968

Timestep Collection Time: 2.19447
Timestep Consumption Time: 2.51793
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.71240

Cumulative Model Updates: 76,584
Cumulative Timesteps: 638,749,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 638749842...
Checkpoint 638749842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 879.37972
Policy Entropy: 3.28874
Value Function Loss: 0.00440

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09822
Policy Update Magnitude: 0.57214
Value Function Update Magnitude: 0.64863

Collected Steps per Second: 22,690.79664
Overall Steps per Second: 10,804.40135

Timestep Collection Time: 2.20468
Timestep Consumption Time: 2.42547
PPO Batch Consumption Time: 0.28221
Total Iteration Time: 4.63015

Cumulative Model Updates: 76,590
Cumulative Timesteps: 638,799,868

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713.70626
Policy Entropy: 3.27655
Value Function Loss: 0.00452

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11138
Policy Update Magnitude: 0.57003
Value Function Update Magnitude: 0.64735

Collected Steps per Second: 23,004.02200
Overall Steps per Second: 10,634.66029

Timestep Collection Time: 2.17362
Timestep Consumption Time: 2.52818
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.70180

Cumulative Model Updates: 76,596
Cumulative Timesteps: 638,849,870

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 638849870...
Checkpoint 638849870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.20847
Policy Entropy: 3.28450
Value Function Loss: 0.00428

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08262
Policy Update Magnitude: 0.56064
Value Function Update Magnitude: 0.63862

Collected Steps per Second: 22,734.27068
Overall Steps per Second: 10,692.85261

Timestep Collection Time: 2.20064
Timestep Consumption Time: 2.47818
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.67883

Cumulative Model Updates: 76,602
Cumulative Timesteps: 638,899,900

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.88370
Policy Entropy: 3.27362
Value Function Loss: 0.00429

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.56046
Value Function Update Magnitude: 0.63048

Collected Steps per Second: 22,997.95402
Overall Steps per Second: 10,776.06711

Timestep Collection Time: 2.17445
Timestep Consumption Time: 2.46620
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.64065

Cumulative Model Updates: 76,608
Cumulative Timesteps: 638,949,908

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 638949908...
Checkpoint 638949908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 856.64745
Policy Entropy: 3.28190
Value Function Loss: 0.00395

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08367
Policy Update Magnitude: 0.55295
Value Function Update Magnitude: 0.61784

Collected Steps per Second: 22,630.03084
Overall Steps per Second: 10,611.31159

Timestep Collection Time: 2.21051
Timestep Consumption Time: 2.50370
PPO Batch Consumption Time: 0.29780
Total Iteration Time: 4.71421

Cumulative Model Updates: 76,614
Cumulative Timesteps: 638,999,932

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.97626
Policy Entropy: 3.28141
Value Function Loss: 0.00403

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08997
Policy Update Magnitude: 0.55599
Value Function Update Magnitude: 0.60839

Collected Steps per Second: 22,742.31342
Overall Steps per Second: 10,677.11429

Timestep Collection Time: 2.19934
Timestep Consumption Time: 2.48526
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.68460

Cumulative Model Updates: 76,620
Cumulative Timesteps: 639,049,950

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 639049950...
Checkpoint 639049950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.24483
Policy Entropy: 3.27206
Value Function Loss: 0.00416

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08910
Policy Update Magnitude: 0.56401
Value Function Update Magnitude: 0.63228

Collected Steps per Second: 22,208.94522
Overall Steps per Second: 10,476.22598

Timestep Collection Time: 2.25135
Timestep Consumption Time: 2.52137
PPO Batch Consumption Time: 0.29683
Total Iteration Time: 4.77271

Cumulative Model Updates: 76,626
Cumulative Timesteps: 639,099,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705.64234
Policy Entropy: 3.25971
Value Function Loss: 0.00428

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08688
Policy Update Magnitude: 0.57672
Value Function Update Magnitude: 0.63440

Collected Steps per Second: 22,478.16363
Overall Steps per Second: 10,661.04124

Timestep Collection Time: 2.22580
Timestep Consumption Time: 2.46717
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.69297

Cumulative Model Updates: 76,632
Cumulative Timesteps: 639,149,982

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 639149982...
Checkpoint 639149982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.33422
Policy Entropy: 3.25920
Value Function Loss: 0.00436

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.57664
Value Function Update Magnitude: 0.63925

Collected Steps per Second: 22,079.90361
Overall Steps per Second: 10,532.75955

Timestep Collection Time: 2.26468
Timestep Consumption Time: 2.48279
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.74747

Cumulative Model Updates: 76,638
Cumulative Timesteps: 639,199,986

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.42362
Policy Entropy: 3.28521
Value Function Loss: 0.00409

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08756
Policy Update Magnitude: 0.56320
Value Function Update Magnitude: 0.62818

Collected Steps per Second: 22,622.03476
Overall Steps per Second: 10,798.30815

Timestep Collection Time: 2.21094
Timestep Consumption Time: 2.42089
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.63184

Cumulative Model Updates: 76,644
Cumulative Timesteps: 639,250,002

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 639250002...
Checkpoint 639250002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.87880
Policy Entropy: 3.28059
Value Function Loss: 0.00392

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.07958
Policy Update Magnitude: 0.54751
Value Function Update Magnitude: 0.62555

Collected Steps per Second: 22,262.60136
Overall Steps per Second: 10,613.55858

Timestep Collection Time: 2.24781
Timestep Consumption Time: 2.46711
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.71491

Cumulative Model Updates: 76,650
Cumulative Timesteps: 639,300,044

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,846.09072
Policy Entropy: 3.27532
Value Function Loss: 0.00387

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09555
Policy Update Magnitude: 0.54015
Value Function Update Magnitude: 0.63326

Collected Steps per Second: 23,147.06740
Overall Steps per Second: 10,832.24767

Timestep Collection Time: 2.16114
Timestep Consumption Time: 2.45693
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 4.61806

Cumulative Model Updates: 76,656
Cumulative Timesteps: 639,350,068

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 639350068...
Checkpoint 639350068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.73522
Policy Entropy: 3.27832
Value Function Loss: 0.00389

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09418
Policy Update Magnitude: 0.53904
Value Function Update Magnitude: 0.63053

Collected Steps per Second: 22,705.11285
Overall Steps per Second: 10,700.80451

Timestep Collection Time: 2.20320
Timestep Consumption Time: 2.47158
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.67479

Cumulative Model Updates: 76,662
Cumulative Timesteps: 639,400,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.65653
Policy Entropy: 3.28644
Value Function Loss: 0.00381

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.53930
Value Function Update Magnitude: 0.62660

Collected Steps per Second: 23,169.90681
Overall Steps per Second: 10,876.09177

Timestep Collection Time: 2.15814
Timestep Consumption Time: 2.43946
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.59761

Cumulative Model Updates: 76,668
Cumulative Timesteps: 639,450,096

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 639450096...
Checkpoint 639450096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719.90884
Policy Entropy: 3.28987
Value Function Loss: 0.00379

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09479
Policy Update Magnitude: 0.53676
Value Function Update Magnitude: 0.59958

Collected Steps per Second: 22,389.75918
Overall Steps per Second: 10,698.41776

Timestep Collection Time: 2.23379
Timestep Consumption Time: 2.44111
PPO Batch Consumption Time: 0.28502
Total Iteration Time: 4.67490

Cumulative Model Updates: 76,674
Cumulative Timesteps: 639,500,110

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 930.43304
Policy Entropy: 3.27477
Value Function Loss: 0.00412

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09170
Policy Update Magnitude: 0.54255
Value Function Update Magnitude: 0.59311

Collected Steps per Second: 22,832.58969
Overall Steps per Second: 10,796.90036

Timestep Collection Time: 2.19047
Timestep Consumption Time: 2.44179
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.63226

Cumulative Model Updates: 76,680
Cumulative Timesteps: 639,550,124

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 639550124...
Checkpoint 639550124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 899.41708
Policy Entropy: 3.28933
Value Function Loss: 0.00422

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.55463
Value Function Update Magnitude: 0.62021

Collected Steps per Second: 22,215.68091
Overall Steps per Second: 10,739.25254

Timestep Collection Time: 2.25201
Timestep Consumption Time: 2.40660
PPO Batch Consumption Time: 0.28174
Total Iteration Time: 4.65861

Cumulative Model Updates: 76,686
Cumulative Timesteps: 639,600,154

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.40152
Policy Entropy: 3.27532
Value Function Loss: 0.00411

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09444
Policy Update Magnitude: 0.54875
Value Function Update Magnitude: 0.62101

Collected Steps per Second: 22,215.30811
Overall Steps per Second: 10,518.63439

Timestep Collection Time: 2.25079
Timestep Consumption Time: 2.50287
PPO Batch Consumption Time: 0.29641
Total Iteration Time: 4.75366

Cumulative Model Updates: 76,692
Cumulative Timesteps: 639,650,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 639650156...
Checkpoint 639650156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,631.00298
Policy Entropy: 3.28762
Value Function Loss: 0.00382

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08345
Policy Update Magnitude: 0.53932
Value Function Update Magnitude: 0.61082

Collected Steps per Second: 22,117.27621
Overall Steps per Second: 10,538.55487

Timestep Collection Time: 2.26167
Timestep Consumption Time: 2.48490
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.74657

Cumulative Model Updates: 76,698
Cumulative Timesteps: 639,700,178

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.63659
Policy Entropy: 3.28198
Value Function Loss: 0.00403

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.07912
Policy Update Magnitude: 0.55075
Value Function Update Magnitude: 0.62102

Collected Steps per Second: 21,838.89982
Overall Steps per Second: 10,493.08961

Timestep Collection Time: 2.29004
Timestep Consumption Time: 2.47614
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.76618

Cumulative Model Updates: 76,704
Cumulative Timesteps: 639,750,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 639750190...
Checkpoint 639750190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.13572
Policy Entropy: 3.28312
Value Function Loss: 0.00398

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.55697
Value Function Update Magnitude: 0.63431

Collected Steps per Second: 22,215.10016
Overall Steps per Second: 10,681.79348

Timestep Collection Time: 2.25153
Timestep Consumption Time: 2.43102
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.68255

Cumulative Model Updates: 76,710
Cumulative Timesteps: 639,800,208

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.40538
Policy Entropy: 3.27090
Value Function Loss: 0.00401

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08650
Policy Update Magnitude: 0.55480
Value Function Update Magnitude: 0.63724

Collected Steps per Second: 22,929.82441
Overall Steps per Second: 10,777.38476

Timestep Collection Time: 2.18135
Timestep Consumption Time: 2.45966
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.64101

Cumulative Model Updates: 76,716
Cumulative Timesteps: 639,850,226

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 639850226...
Checkpoint 639850226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.82424
Policy Entropy: 3.28084
Value Function Loss: 0.00376

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.07901
Policy Update Magnitude: 0.54722
Value Function Update Magnitude: 0.65066

Collected Steps per Second: 22,513.63177
Overall Steps per Second: 10,684.19251

Timestep Collection Time: 2.22141
Timestep Consumption Time: 2.45952
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.68093

Cumulative Model Updates: 76,722
Cumulative Timesteps: 639,900,238

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.25622
Policy Entropy: 3.29220
Value Function Loss: 0.00370

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08276
Policy Update Magnitude: 0.53767
Value Function Update Magnitude: 0.63863

Collected Steps per Second: 22,884.00729
Overall Steps per Second: 10,831.33238

Timestep Collection Time: 2.18519
Timestep Consumption Time: 2.43160
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.61679

Cumulative Model Updates: 76,728
Cumulative Timesteps: 639,950,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 639950244...
Checkpoint 639950244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,741.08855
Policy Entropy: 3.30242
Value Function Loss: 0.00371

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08811
Policy Update Magnitude: 0.52397
Value Function Update Magnitude: 0.61603

Collected Steps per Second: 22,379.38846
Overall Steps per Second: 10,738.10653

Timestep Collection Time: 2.23608
Timestep Consumption Time: 2.42415
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.66023

Cumulative Model Updates: 76,734
Cumulative Timesteps: 640,000,286

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,479.34900
Policy Entropy: 3.30938
Value Function Loss: 0.00395

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09906
Policy Update Magnitude: 0.52117
Value Function Update Magnitude: 0.61022

Collected Steps per Second: 22,880.68460
Overall Steps per Second: 10,830.28730

Timestep Collection Time: 2.18525
Timestep Consumption Time: 2.43143
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.61668

Cumulative Model Updates: 76,740
Cumulative Timesteps: 640,050,286

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 640050286...
Checkpoint 640050286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.77570
Policy Entropy: 3.30090
Value Function Loss: 0.00399

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09868
Policy Update Magnitude: 0.53130
Value Function Update Magnitude: 0.61764

Collected Steps per Second: 22,434.36859
Overall Steps per Second: 10,745.51779

Timestep Collection Time: 2.22872
Timestep Consumption Time: 2.42438
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.65310

Cumulative Model Updates: 76,746
Cumulative Timesteps: 640,100,286

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 980.76122
Policy Entropy: 3.29533
Value Function Loss: 0.00405

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11034
Policy Update Magnitude: 0.54422
Value Function Update Magnitude: 0.62800

Collected Steps per Second: 22,401.25246
Overall Steps per Second: 10,602.25116

Timestep Collection Time: 2.23229
Timestep Consumption Time: 2.48426
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.71655

Cumulative Model Updates: 76,752
Cumulative Timesteps: 640,150,292

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 640150292...
Checkpoint 640150292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 878.40007
Policy Entropy: 3.28407
Value Function Loss: 0.00384

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11273
Policy Update Magnitude: 0.54349
Value Function Update Magnitude: 0.62207

Collected Steps per Second: 22,752.93703
Overall Steps per Second: 10,984.84908

Timestep Collection Time: 2.19778
Timestep Consumption Time: 2.35449
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.55227

Cumulative Model Updates: 76,758
Cumulative Timesteps: 640,200,298

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.76446
Policy Entropy: 3.27540
Value Function Loss: 0.00391

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10154
Policy Update Magnitude: 0.54007
Value Function Update Magnitude: 0.62334

Collected Steps per Second: 21,845.48502
Overall Steps per Second: 10,601.06932

Timestep Collection Time: 2.29027
Timestep Consumption Time: 2.42926
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.71952

Cumulative Model Updates: 76,764
Cumulative Timesteps: 640,250,330

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 640250330...
Checkpoint 640250330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 865.74732
Policy Entropy: 3.27902
Value Function Loss: 0.00404

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10383
Policy Update Magnitude: 0.53951
Value Function Update Magnitude: 0.61718

Collected Steps per Second: 21,758.30927
Overall Steps per Second: 10,496.04571

Timestep Collection Time: 2.29862
Timestep Consumption Time: 2.46642
PPO Batch Consumption Time: 0.29722
Total Iteration Time: 4.76503

Cumulative Model Updates: 76,770
Cumulative Timesteps: 640,300,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.39451
Policy Entropy: 3.28203
Value Function Loss: 0.00396

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.54238
Value Function Update Magnitude: 0.61056

Collected Steps per Second: 21,813.55544
Overall Steps per Second: 10,621.75415

Timestep Collection Time: 2.29215
Timestep Consumption Time: 2.41517
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.70732

Cumulative Model Updates: 76,776
Cumulative Timesteps: 640,350,344

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 640350344...
Checkpoint 640350344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,821.48869
Policy Entropy: 3.27223
Value Function Loss: 0.00407

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08116
Policy Update Magnitude: 0.54377
Value Function Update Magnitude: 0.60661

Collected Steps per Second: 22,357.04329
Overall Steps per Second: 10,793.37338

Timestep Collection Time: 2.23661
Timestep Consumption Time: 2.39623
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.63284

Cumulative Model Updates: 76,782
Cumulative Timesteps: 640,400,348

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 838.67101
Policy Entropy: 3.26812
Value Function Loss: 0.00410

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 0.54535
Value Function Update Magnitude: 0.63076

Collected Steps per Second: 22,048.80361
Overall Steps per Second: 10,631.95986

Timestep Collection Time: 2.26842
Timestep Consumption Time: 2.43588
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.70431

Cumulative Model Updates: 76,788
Cumulative Timesteps: 640,450,364

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 640450364...
Checkpoint 640450364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066.65004
Policy Entropy: 3.26198
Value Function Loss: 0.00436

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08710
Policy Update Magnitude: 0.55508
Value Function Update Magnitude: 0.65058

Collected Steps per Second: 21,858.83270
Overall Steps per Second: 10,504.19440

Timestep Collection Time: 2.28869
Timestep Consumption Time: 2.47398
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 4.76267

Cumulative Model Updates: 76,794
Cumulative Timesteps: 640,500,392

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 778.11923
Policy Entropy: 3.26236
Value Function Loss: 0.00442

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08492
Policy Update Magnitude: 0.56272
Value Function Update Magnitude: 0.65839

Collected Steps per Second: 22,264.70382
Overall Steps per Second: 10,711.94630

Timestep Collection Time: 2.24652
Timestep Consumption Time: 2.42285
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.66937

Cumulative Model Updates: 76,800
Cumulative Timesteps: 640,550,410

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 640550410...
Checkpoint 640550410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.31456
Policy Entropy: 3.26297
Value Function Loss: 0.00421

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09002
Policy Update Magnitude: 0.56074
Value Function Update Magnitude: 0.66958

Collected Steps per Second: 22,099.04434
Overall Steps per Second: 10,795.64751

Timestep Collection Time: 2.26381
Timestep Consumption Time: 2.37028
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.63409

Cumulative Model Updates: 76,806
Cumulative Timesteps: 640,600,438

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.69485
Policy Entropy: 3.27889
Value Function Loss: 0.00413

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.55317
Value Function Update Magnitude: 0.64279

Collected Steps per Second: 22,975.71588
Overall Steps per Second: 10,703.50101

Timestep Collection Time: 2.17647
Timestep Consumption Time: 2.49546
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.67193

Cumulative Model Updates: 76,812
Cumulative Timesteps: 640,650,444

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 640650444...
Checkpoint 640650444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 838.01520
Policy Entropy: 3.27164
Value Function Loss: 0.00402

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08025
Policy Update Magnitude: 0.55467
Value Function Update Magnitude: 0.63120

Collected Steps per Second: 22,126.79090
Overall Steps per Second: 10,478.14607

Timestep Collection Time: 2.26043
Timestep Consumption Time: 2.51294
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.77336

Cumulative Model Updates: 76,818
Cumulative Timesteps: 640,700,460

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710.41023
Policy Entropy: 3.27122
Value Function Loss: 0.00392

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10221
Policy Update Magnitude: 0.55655
Value Function Update Magnitude: 0.61504

Collected Steps per Second: 22,555.49663
Overall Steps per Second: 10,568.00379

Timestep Collection Time: 2.21693
Timestep Consumption Time: 2.51471
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.73164

Cumulative Model Updates: 76,824
Cumulative Timesteps: 640,750,464

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 640750464...
Checkpoint 640750464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 905.24052
Policy Entropy: 3.26627
Value Function Loss: 0.00378

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10779
Policy Update Magnitude: 0.55431
Value Function Update Magnitude: 0.60069

Collected Steps per Second: 22,530.94694
Overall Steps per Second: 10,540.93852

Timestep Collection Time: 2.21979
Timestep Consumption Time: 2.52495
PPO Batch Consumption Time: 0.29767
Total Iteration Time: 4.74474

Cumulative Model Updates: 76,830
Cumulative Timesteps: 640,800,478

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.96971
Policy Entropy: 3.26534
Value Function Loss: 0.00376

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09009
Policy Update Magnitude: 0.54586
Value Function Update Magnitude: 0.60177

Collected Steps per Second: 22,346.29981
Overall Steps per Second: 10,482.37719

Timestep Collection Time: 2.23760
Timestep Consumption Time: 2.53250
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.77010

Cumulative Model Updates: 76,836
Cumulative Timesteps: 640,850,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 640850480...
Checkpoint 640850480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.87018
Policy Entropy: 3.25999
Value Function Loss: 0.00396

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08098
Policy Update Magnitude: 0.55280
Value Function Update Magnitude: 0.62137

Collected Steps per Second: 22,678.39673
Overall Steps per Second: 10,573.52818

Timestep Collection Time: 2.20554
Timestep Consumption Time: 2.52496
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.73049

Cumulative Model Updates: 76,842
Cumulative Timesteps: 640,900,498

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657.67021
Policy Entropy: 3.26336
Value Function Loss: 0.00387

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10164
Policy Update Magnitude: 0.55657
Value Function Update Magnitude: 0.64533

Collected Steps per Second: 22,943.65981
Overall Steps per Second: 10,803.29959

Timestep Collection Time: 2.17977
Timestep Consumption Time: 2.44955
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.62933

Cumulative Model Updates: 76,848
Cumulative Timesteps: 640,950,510

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 640950510...
Checkpoint 640950510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.37548
Policy Entropy: 3.26656
Value Function Loss: 0.00390

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10446
Policy Update Magnitude: 0.55861
Value Function Update Magnitude: 0.64147

Collected Steps per Second: 22,663.05894
Overall Steps per Second: 10,685.48543

Timestep Collection Time: 2.20712
Timestep Consumption Time: 2.47400
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.68112

Cumulative Model Updates: 76,854
Cumulative Timesteps: 641,000,530

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.89041
Policy Entropy: 3.27877
Value Function Loss: 0.00391

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10729
Policy Update Magnitude: 0.55998
Value Function Update Magnitude: 0.64010

Collected Steps per Second: 22,718.08157
Overall Steps per Second: 10,596.11575

Timestep Collection Time: 2.20098
Timestep Consumption Time: 2.51792
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.71890

Cumulative Model Updates: 76,860
Cumulative Timesteps: 641,050,532

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 641050532...
Checkpoint 641050532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.23670
Policy Entropy: 3.29569
Value Function Loss: 0.00392

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09171
Policy Update Magnitude: 0.55614
Value Function Update Magnitude: 0.65224

Collected Steps per Second: 22,465.75320
Overall Steps per Second: 10,547.82372

Timestep Collection Time: 2.22605
Timestep Consumption Time: 2.51521
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.74126

Cumulative Model Updates: 76,866
Cumulative Timesteps: 641,100,542

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,312.70814
Policy Entropy: 3.29630
Value Function Loss: 0.00414

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08261
Policy Update Magnitude: 0.56242
Value Function Update Magnitude: 0.66895

Collected Steps per Second: 22,560.14264
Overall Steps per Second: 10,555.01599

Timestep Collection Time: 2.21656
Timestep Consumption Time: 2.52109
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.73765

Cumulative Model Updates: 76,872
Cumulative Timesteps: 641,150,548

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 641150548...
Checkpoint 641150548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 826.06016
Policy Entropy: 3.28060
Value Function Loss: 0.00401

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 0.56232
Value Function Update Magnitude: 0.68844

Collected Steps per Second: 21,949.96538
Overall Steps per Second: 10,590.84966

Timestep Collection Time: 2.27891
Timestep Consumption Time: 2.44422
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.72313

Cumulative Model Updates: 76,878
Cumulative Timesteps: 641,200,570

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 954.53523
Policy Entropy: 3.28365
Value Function Loss: 0.00390

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.55234
Value Function Update Magnitude: 0.65560

Collected Steps per Second: 22,589.74861
Overall Steps per Second: 10,602.10292

Timestep Collection Time: 2.21419
Timestep Consumption Time: 2.50355
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.71774

Cumulative Model Updates: 76,884
Cumulative Timesteps: 641,250,588

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 641250588...
Checkpoint 641250588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,540.87639
Policy Entropy: 3.26347
Value Function Loss: 0.00389

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10063
Policy Update Magnitude: 0.55202
Value Function Update Magnitude: 0.62968

Collected Steps per Second: 22,315.73427
Overall Steps per Second: 10,512.00468

Timestep Collection Time: 2.24183
Timestep Consumption Time: 2.51730
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 4.75913

Cumulative Model Updates: 76,890
Cumulative Timesteps: 641,300,616

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 898.74660
Policy Entropy: 3.26031
Value Function Loss: 0.00376

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.55738
Value Function Update Magnitude: 0.64408

Collected Steps per Second: 23,024.19797
Overall Steps per Second: 10,773.54882

Timestep Collection Time: 2.17189
Timestep Consumption Time: 2.46966
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.64155

Cumulative Model Updates: 76,896
Cumulative Timesteps: 641,350,622

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 641350622...
Checkpoint 641350622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 833.32352
Policy Entropy: 3.26841
Value Function Loss: 0.00396

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10852
Policy Update Magnitude: 0.55764
Value Function Update Magnitude: 0.63019

Collected Steps per Second: 22,646.00067
Overall Steps per Second: 10,690.60486

Timestep Collection Time: 2.20807
Timestep Consumption Time: 2.46931
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.67738

Cumulative Model Updates: 76,902
Cumulative Timesteps: 641,400,626

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.59118
Policy Entropy: 3.28114
Value Function Loss: 0.00383

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11178
Policy Update Magnitude: 0.55445
Value Function Update Magnitude: 0.61849

Collected Steps per Second: 22,930.52410
Overall Steps per Second: 10,831.00463

Timestep Collection Time: 2.18155
Timestep Consumption Time: 2.43705
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.61859

Cumulative Model Updates: 76,908
Cumulative Timesteps: 641,450,650

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 641450650...
Checkpoint 641450650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522.76124
Policy Entropy: 3.26119
Value Function Loss: 0.00396

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.12424
Policy Update Magnitude: 0.54984
Value Function Update Magnitude: 0.59638

Collected Steps per Second: 22,735.77459
Overall Steps per Second: 10,721.13832

Timestep Collection Time: 2.20032
Timestep Consumption Time: 2.46579
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.66611

Cumulative Model Updates: 76,914
Cumulative Timesteps: 641,500,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,364.19786
Policy Entropy: 3.26555
Value Function Loss: 0.00381

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.54851
Value Function Update Magnitude: 0.59106

Collected Steps per Second: 22,775.65186
Overall Steps per Second: 10,851.96709

Timestep Collection Time: 2.19568
Timestep Consumption Time: 2.41252
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.60820

Cumulative Model Updates: 76,920
Cumulative Timesteps: 641,550,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 641550684...
Checkpoint 641550684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.87928
Policy Entropy: 3.26938
Value Function Loss: 0.00393

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.11975
Policy Update Magnitude: 0.54879
Value Function Update Magnitude: 0.59496

Collected Steps per Second: 22,688.55678
Overall Steps per Second: 10,685.24838

Timestep Collection Time: 2.20446
Timestep Consumption Time: 2.47639
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.68085

Cumulative Model Updates: 76,926
Cumulative Timesteps: 641,600,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.01275
Policy Entropy: 3.27611
Value Function Loss: 0.00388

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10774
Policy Update Magnitude: 0.54476
Value Function Update Magnitude: 0.60349

Collected Steps per Second: 22,424.77585
Overall Steps per Second: 10,634.12752

Timestep Collection Time: 2.23030
Timestep Consumption Time: 2.47286
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.70316

Cumulative Model Updates: 76,932
Cumulative Timesteps: 641,650,714

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 641650714...
Checkpoint 641650714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.30357
Policy Entropy: 3.28809
Value Function Loss: 0.00372

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08105
Policy Update Magnitude: 0.54369
Value Function Update Magnitude: 0.60512

Collected Steps per Second: 22,248.01801
Overall Steps per Second: 10,501.78019

Timestep Collection Time: 2.24748
Timestep Consumption Time: 2.51381
PPO Batch Consumption Time: 0.29656
Total Iteration Time: 4.76129

Cumulative Model Updates: 76,938
Cumulative Timesteps: 641,700,716

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 952.65540
Policy Entropy: 3.29765
Value Function Loss: 0.00349

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07409
Policy Update Magnitude: 0.53434
Value Function Update Magnitude: 0.57712

Collected Steps per Second: 22,749.81758
Overall Steps per Second: 10,788.83675

Timestep Collection Time: 2.19905
Timestep Consumption Time: 2.43796
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.63702

Cumulative Model Updates: 76,944
Cumulative Timesteps: 641,750,744

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 641750744...
Checkpoint 641750744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 885.95600
Policy Entropy: 3.30126
Value Function Loss: 0.00363

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07713
Policy Update Magnitude: 0.53476
Value Function Update Magnitude: 0.55990

Collected Steps per Second: 22,362.99679
Overall Steps per Second: 10,755.11027

Timestep Collection Time: 2.23584
Timestep Consumption Time: 2.41312
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.64895

Cumulative Model Updates: 76,950
Cumulative Timesteps: 641,800,744

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.47884
Policy Entropy: 3.29000
Value Function Loss: 0.00388

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08958
Policy Update Magnitude: 0.54395
Value Function Update Magnitude: 0.57769

Collected Steps per Second: 22,587.96642
Overall Steps per Second: 10,604.73963

Timestep Collection Time: 2.21436
Timestep Consumption Time: 2.50221
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.71657

Cumulative Model Updates: 76,956
Cumulative Timesteps: 641,850,762

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 641850762...
Checkpoint 641850762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,548.34626
Policy Entropy: 3.30204
Value Function Loss: 0.00400

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07675
Policy Update Magnitude: 0.55192
Value Function Update Magnitude: 0.59219

Collected Steps per Second: 22,657.51647
Overall Steps per Second: 10,625.88262

Timestep Collection Time: 2.20827
Timestep Consumption Time: 2.50042
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.70869

Cumulative Model Updates: 76,962
Cumulative Timesteps: 641,900,796

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 989.59799
Policy Entropy: 3.29178
Value Function Loss: 0.00413

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08633
Policy Update Magnitude: 0.55949
Value Function Update Magnitude: 0.59587

Collected Steps per Second: 22,917.59841
Overall Steps per Second: 10,734.98713

Timestep Collection Time: 2.18251
Timestep Consumption Time: 2.47683
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.65934

Cumulative Model Updates: 76,968
Cumulative Timesteps: 641,950,814

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 641950814...
Checkpoint 641950814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 751.37680
Policy Entropy: 3.27589
Value Function Loss: 0.00426

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10602
Policy Update Magnitude: 0.55992
Value Function Update Magnitude: 0.59639

Collected Steps per Second: 21,923.92809
Overall Steps per Second: 10,767.21553

Timestep Collection Time: 2.28244
Timestep Consumption Time: 2.36500
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.64744

Cumulative Model Updates: 76,974
Cumulative Timesteps: 642,000,854

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 731.03093
Policy Entropy: 3.26312
Value Function Loss: 0.00417

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09555
Policy Update Magnitude: 0.56624
Value Function Update Magnitude: 0.60600

Collected Steps per Second: 22,647.06800
Overall Steps per Second: 10,756.26830

Timestep Collection Time: 2.20920
Timestep Consumption Time: 2.44222
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.65143

Cumulative Model Updates: 76,980
Cumulative Timesteps: 642,050,886

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 642050886...
Checkpoint 642050886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.46053
Policy Entropy: 3.25865
Value Function Loss: 0.00425

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08807
Policy Update Magnitude: 0.56458
Value Function Update Magnitude: 0.60897

Collected Steps per Second: 22,570.27159
Overall Steps per Second: 10,686.00192

Timestep Collection Time: 2.21584
Timestep Consumption Time: 2.46431
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.68014

Cumulative Model Updates: 76,986
Cumulative Timesteps: 642,100,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 913.15118
Policy Entropy: 3.26911
Value Function Loss: 0.00399

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08768
Policy Update Magnitude: 0.56197
Value Function Update Magnitude: 0.60862

Collected Steps per Second: 22,636.52610
Overall Steps per Second: 10,659.88272

Timestep Collection Time: 2.20917
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.69123

Cumulative Model Updates: 76,992
Cumulative Timesteps: 642,150,906

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 642150906...
Checkpoint 642150906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,446.10829
Policy Entropy: 3.26964
Value Function Loss: 0.00428

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10344
Policy Update Magnitude: 0.56026
Value Function Update Magnitude: 0.61858

Collected Steps per Second: 22,424.21345
Overall Steps per Second: 10,582.01954

Timestep Collection Time: 2.22982
Timestep Consumption Time: 2.49536
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.72518

Cumulative Model Updates: 76,998
Cumulative Timesteps: 642,200,908

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.37183
Policy Entropy: 3.28211
Value Function Loss: 0.00432

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11330
Policy Update Magnitude: 0.56113
Value Function Update Magnitude: 0.61722

Collected Steps per Second: 22,571.37759
Overall Steps per Second: 10,742.98692

Timestep Collection Time: 2.21546
Timestep Consumption Time: 2.43930
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.65476

Cumulative Model Updates: 77,004
Cumulative Timesteps: 642,250,914

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 642250914...
Checkpoint 642250914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 975.66461
Policy Entropy: 3.28081
Value Function Loss: 0.00449

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.12000
Policy Update Magnitude: 0.56101
Value Function Update Magnitude: 0.61535

Collected Steps per Second: 21,943.00663
Overall Steps per Second: 10,669.50663

Timestep Collection Time: 2.27881
Timestep Consumption Time: 2.40781
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.68663

Cumulative Model Updates: 77,010
Cumulative Timesteps: 642,300,918

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 880.11496
Policy Entropy: 3.27779
Value Function Loss: 0.00424

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11211
Policy Update Magnitude: 0.55958
Value Function Update Magnitude: 0.59558

Collected Steps per Second: 21,967.90920
Overall Steps per Second: 10,602.06166

Timestep Collection Time: 2.27696
Timestep Consumption Time: 2.44099
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.71795

Cumulative Model Updates: 77,016
Cumulative Timesteps: 642,350,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 642350938...
Checkpoint 642350938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 764.66417
Policy Entropy: 3.27807
Value Function Loss: 0.00402

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.54849
Value Function Update Magnitude: 0.58741

Collected Steps per Second: 21,916.77628
Overall Steps per Second: 10,617.62624

Timestep Collection Time: 2.28218
Timestep Consumption Time: 2.42867
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.71085

Cumulative Model Updates: 77,022
Cumulative Timesteps: 642,400,956

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 825.15352
Policy Entropy: 3.26552
Value Function Loss: 0.00410

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09776
Policy Update Magnitude: 0.55107
Value Function Update Magnitude: 0.60293

Collected Steps per Second: 22,463.47764
Overall Steps per Second: 10,792.54266

Timestep Collection Time: 2.22601
Timestep Consumption Time: 2.40719
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.63320

Cumulative Model Updates: 77,028
Cumulative Timesteps: 642,450,960

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 642450960...
Checkpoint 642450960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.97704
Policy Entropy: 3.27058
Value Function Loss: 0.00421

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09886
Policy Update Magnitude: 0.56095
Value Function Update Magnitude: 0.63429

Collected Steps per Second: 21,843.90491
Overall Steps per Second: 10,589.93245

Timestep Collection Time: 2.28970
Timestep Consumption Time: 2.43328
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.72298

Cumulative Model Updates: 77,034
Cumulative Timesteps: 642,500,976

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,400.56716
Policy Entropy: 3.26912
Value Function Loss: 0.00422

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.12246
Policy Update Magnitude: 0.57278
Value Function Update Magnitude: 0.65051

Collected Steps per Second: 22,471.78592
Overall Steps per Second: 10,856.22188

Timestep Collection Time: 2.22555
Timestep Consumption Time: 2.38121
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.60676

Cumulative Model Updates: 77,040
Cumulative Timesteps: 642,550,988

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 642550988...
Checkpoint 642550988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,509.85474
Policy Entropy: 3.27132
Value Function Loss: 0.00424

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11790
Policy Update Magnitude: 0.56810
Value Function Update Magnitude: 0.65393

Collected Steps per Second: 22,161.01300
Overall Steps per Second: 10,751.87060

Timestep Collection Time: 2.25630
Timestep Consumption Time: 2.39423
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.65054

Cumulative Model Updates: 77,046
Cumulative Timesteps: 642,600,990

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,867.69637
Policy Entropy: 3.25823
Value Function Loss: 0.00423

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11064
Policy Update Magnitude: 0.57038
Value Function Update Magnitude: 0.64780

Collected Steps per Second: 22,228.28170
Overall Steps per Second: 10,785.02893

Timestep Collection Time: 2.25029
Timestep Consumption Time: 2.38762
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.63791

Cumulative Model Updates: 77,052
Cumulative Timesteps: 642,651,010

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 642651010...
Checkpoint 642651010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.68668
Policy Entropy: 3.26510
Value Function Loss: 0.00442

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12055
Policy Update Magnitude: 0.56643
Value Function Update Magnitude: 0.63731

Collected Steps per Second: 22,583.04694
Overall Steps per Second: 10,738.88542

Timestep Collection Time: 2.21502
Timestep Consumption Time: 2.44300
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.65803

Cumulative Model Updates: 77,058
Cumulative Timesteps: 642,701,032

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 997.97831
Policy Entropy: 3.26358
Value Function Loss: 0.00438

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10151
Policy Update Magnitude: 0.56432
Value Function Update Magnitude: 0.63962

Collected Steps per Second: 22,336.76984
Overall Steps per Second: 10,534.52221

Timestep Collection Time: 2.23909
Timestep Consumption Time: 2.50854
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.74763

Cumulative Model Updates: 77,064
Cumulative Timesteps: 642,751,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 642751046...
Checkpoint 642751046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.49758
Policy Entropy: 3.28217
Value Function Loss: 0.00414

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08765
Policy Update Magnitude: 0.56016
Value Function Update Magnitude: 0.62417

Collected Steps per Second: 22,321.13962
Overall Steps per Second: 10,571.75222

Timestep Collection Time: 2.24021
Timestep Consumption Time: 2.48976
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.72996

Cumulative Model Updates: 77,070
Cumulative Timesteps: 642,801,050

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738.06033
Policy Entropy: 3.27319
Value Function Loss: 0.00399

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09326
Policy Update Magnitude: 0.54524
Value Function Update Magnitude: 0.63724

Collected Steps per Second: 22,803.10656
Overall Steps per Second: 10,671.08720

Timestep Collection Time: 2.19391
Timestep Consumption Time: 2.49427
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.68818

Cumulative Model Updates: 77,076
Cumulative Timesteps: 642,851,078

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 642851078...
Checkpoint 642851078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710.04425
Policy Entropy: 3.28088
Value Function Loss: 0.00418

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08434
Policy Update Magnitude: 0.55407
Value Function Update Magnitude: 0.64552

Collected Steps per Second: 22,565.25217
Overall Steps per Second: 10,552.21092

Timestep Collection Time: 2.21580
Timestep Consumption Time: 2.52255
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.73834

Cumulative Model Updates: 77,082
Cumulative Timesteps: 642,901,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 890.59302
Policy Entropy: 3.27399
Value Function Loss: 0.00442

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10022
Policy Update Magnitude: 0.57231
Value Function Update Magnitude: 0.65749

Collected Steps per Second: 22,700.65564
Overall Steps per Second: 10,702.36804

Timestep Collection Time: 2.20381
Timestep Consumption Time: 2.47067
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.67448

Cumulative Model Updates: 77,088
Cumulative Timesteps: 642,951,106

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 642951106...
Checkpoint 642951106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 886.12775
Policy Entropy: 3.27020
Value Function Loss: 0.00424

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09851
Policy Update Magnitude: 0.56972
Value Function Update Magnitude: 0.64525

Collected Steps per Second: 22,622.75026
Overall Steps per Second: 10,743.37479

Timestep Collection Time: 2.21123
Timestep Consumption Time: 2.44504
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.65627

Cumulative Model Updates: 77,094
Cumulative Timesteps: 643,001,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170.14486
Policy Entropy: 3.26542
Value Function Loss: 0.00427

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10361
Policy Update Magnitude: 0.55453
Value Function Update Magnitude: 0.63241

Collected Steps per Second: 22,538.35345
Overall Steps per Second: 10,535.21295

Timestep Collection Time: 2.21968
Timestep Consumption Time: 2.52896
PPO Batch Consumption Time: 0.29571
Total Iteration Time: 4.74865

Cumulative Model Updates: 77,100
Cumulative Timesteps: 643,051,158

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 643051158...
Checkpoint 643051158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682.58462
Policy Entropy: 3.27379
Value Function Loss: 0.00421

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10052
Policy Update Magnitude: 0.54600
Value Function Update Magnitude: 0.61572

Collected Steps per Second: 22,684.69727
Overall Steps per Second: 10,601.36704

Timestep Collection Time: 2.20448
Timestep Consumption Time: 2.51265
PPO Batch Consumption Time: 0.29619
Total Iteration Time: 4.71713

Cumulative Model Updates: 77,106
Cumulative Timesteps: 643,101,166

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 968.92132
Policy Entropy: 3.27787
Value Function Loss: 0.00423

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10915
Policy Update Magnitude: 0.55660
Value Function Update Magnitude: 0.62149

Collected Steps per Second: 22,750.22933
Overall Steps per Second: 10,735.00148

Timestep Collection Time: 2.19901
Timestep Consumption Time: 2.46126
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.66027

Cumulative Model Updates: 77,112
Cumulative Timesteps: 643,151,194

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 643151194...
Checkpoint 643151194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.69992
Policy Entropy: 3.29105
Value Function Loss: 0.00395

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09088
Policy Update Magnitude: 0.55164
Value Function Update Magnitude: 0.60849

Collected Steps per Second: 22,321.82705
Overall Steps per Second: 10,647.13149

Timestep Collection Time: 2.24068
Timestep Consumption Time: 2.45693
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.69760

Cumulative Model Updates: 77,118
Cumulative Timesteps: 643,201,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.16323
Policy Entropy: 3.29002
Value Function Loss: 0.00389

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08560
Policy Update Magnitude: 0.54132
Value Function Update Magnitude: 0.58852

Collected Steps per Second: 22,448.77325
Overall Steps per Second: 10,542.19670

Timestep Collection Time: 2.22836
Timestep Consumption Time: 2.51676
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.74512

Cumulative Model Updates: 77,124
Cumulative Timesteps: 643,251,234

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 643251234...
Checkpoint 643251234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.28793
Policy Entropy: 3.29878
Value Function Loss: 0.00403

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08879
Policy Update Magnitude: 0.53854
Value Function Update Magnitude: 0.59415

Collected Steps per Second: 22,421.48143
Overall Steps per Second: 10,623.29725

Timestep Collection Time: 2.23009
Timestep Consumption Time: 2.47673
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.70682

Cumulative Model Updates: 77,130
Cumulative Timesteps: 643,301,236

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 922.42741
Policy Entropy: 3.28815
Value Function Loss: 0.00434

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.55189
Value Function Update Magnitude: 0.62274

Collected Steps per Second: 22,293.20982
Overall Steps per Second: 10,548.94948

Timestep Collection Time: 2.24355
Timestep Consumption Time: 2.49777
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.74133

Cumulative Model Updates: 77,136
Cumulative Timesteps: 643,351,252

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 643351252...
Checkpoint 643351252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.23547
Policy Entropy: 3.29515
Value Function Loss: 0.00433

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11295
Policy Update Magnitude: 0.55888
Value Function Update Magnitude: 0.64334

Collected Steps per Second: 22,384.76794
Overall Steps per Second: 10,568.11468

Timestep Collection Time: 2.23375
Timestep Consumption Time: 2.49765
PPO Batch Consumption Time: 0.29670
Total Iteration Time: 4.73140

Cumulative Model Updates: 77,142
Cumulative Timesteps: 643,401,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.29679
Policy Entropy: 3.29848
Value Function Loss: 0.00439

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.55801
Value Function Update Magnitude: 0.63754

Collected Steps per Second: 22,365.56886
Overall Steps per Second: 10,592.76120

Timestep Collection Time: 2.23683
Timestep Consumption Time: 2.48602
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.72285

Cumulative Model Updates: 77,148
Cumulative Timesteps: 643,451,282

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 643451282...
Checkpoint 643451282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 810.99199
Policy Entropy: 3.29928
Value Function Loss: 0.00440

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08378
Policy Update Magnitude: 0.55810
Value Function Update Magnitude: 0.61330

Collected Steps per Second: 22,495.86508
Overall Steps per Second: 10,564.93210

Timestep Collection Time: 2.22290
Timestep Consumption Time: 2.51031
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 4.73321

Cumulative Model Updates: 77,154
Cumulative Timesteps: 643,501,288

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596.65650
Policy Entropy: 3.30316
Value Function Loss: 0.00446

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08415
Policy Update Magnitude: 0.55828
Value Function Update Magnitude: 0.62544

Collected Steps per Second: 23,181.11448
Overall Steps per Second: 10,809.34390

Timestep Collection Time: 2.15814
Timestep Consumption Time: 2.47008
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.62822

Cumulative Model Updates: 77,160
Cumulative Timesteps: 643,551,316

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 643551316...
Checkpoint 643551316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 986.10351
Policy Entropy: 3.28698
Value Function Loss: 0.00424

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08788
Policy Update Magnitude: 0.55977
Value Function Update Magnitude: 0.63502

Collected Steps per Second: 22,794.40667
Overall Steps per Second: 10,684.84982

Timestep Collection Time: 2.19422
Timestep Consumption Time: 2.48680
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.68102

Cumulative Model Updates: 77,166
Cumulative Timesteps: 643,601,332

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 954.31248
Policy Entropy: 3.30541
Value Function Loss: 0.00405

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09096
Policy Update Magnitude: 0.55214
Value Function Update Magnitude: 0.64150

Collected Steps per Second: 22,504.31360
Overall Steps per Second: 10,623.56878

Timestep Collection Time: 2.22233
Timestep Consumption Time: 2.48532
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.70765

Cumulative Model Updates: 77,172
Cumulative Timesteps: 643,651,344

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 643651344...
Checkpoint 643651344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.10673
Policy Entropy: 3.29908
Value Function Loss: 0.00413

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.55316
Value Function Update Magnitude: 0.65212

Collected Steps per Second: 23,114.39036
Overall Steps per Second: 10,883.01352

Timestep Collection Time: 2.16445
Timestep Consumption Time: 2.43262
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.59707

Cumulative Model Updates: 77,178
Cumulative Timesteps: 643,701,374

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,841.69120
Policy Entropy: 3.30346
Value Function Loss: 0.00410

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08022
Policy Update Magnitude: 0.55603
Value Function Update Magnitude: 0.64335

Collected Steps per Second: 22,832.68344
Overall Steps per Second: 10,806.32242

Timestep Collection Time: 2.19054
Timestep Consumption Time: 2.43786
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.62840

Cumulative Model Updates: 77,184
Cumulative Timesteps: 643,751,390

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 643751390...
Checkpoint 643751390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.70133
Policy Entropy: 3.28547
Value Function Loss: 0.00399

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08638
Policy Update Magnitude: 0.55909
Value Function Update Magnitude: 0.62714

Collected Steps per Second: 22,651.52591
Overall Steps per Second: 10,835.71996

Timestep Collection Time: 2.20753
Timestep Consumption Time: 2.40720
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.61474

Cumulative Model Updates: 77,190
Cumulative Timesteps: 643,801,394

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,466.60894
Policy Entropy: 3.28952
Value Function Loss: 0.00391

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07426
Policy Update Magnitude: 0.55061
Value Function Update Magnitude: 0.59258

Collected Steps per Second: 22,047.60838
Overall Steps per Second: 10,503.25191

Timestep Collection Time: 2.26873
Timestep Consumption Time: 2.49361
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.76233

Cumulative Model Updates: 77,196
Cumulative Timesteps: 643,851,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 643851414...
Checkpoint 643851414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661.01214
Policy Entropy: 3.29349
Value Function Loss: 0.00413

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08136
Policy Update Magnitude: 0.54124
Value Function Update Magnitude: 0.58682

Collected Steps per Second: 22,796.20193
Overall Steps per Second: 10,727.35389

Timestep Collection Time: 2.19405
Timestep Consumption Time: 2.46842
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.66247

Cumulative Model Updates: 77,202
Cumulative Timesteps: 643,901,430

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 753.20703
Policy Entropy: 3.29843
Value Function Loss: 0.00445

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09843
Policy Update Magnitude: 0.54763
Value Function Update Magnitude: 0.61627

Collected Steps per Second: 22,311.76760
Overall Steps per Second: 10,720.61726

Timestep Collection Time: 2.24231
Timestep Consumption Time: 2.42439
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.66671

Cumulative Model Updates: 77,208
Cumulative Timesteps: 643,951,460

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 643951460...
Checkpoint 643951460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.53548
Policy Entropy: 3.31299
Value Function Loss: 0.00418

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10452
Policy Update Magnitude: 0.56370
Value Function Update Magnitude: 0.64091

Collected Steps per Second: 22,468.83819
Overall Steps per Second: 10,720.59072

Timestep Collection Time: 2.22530
Timestep Consumption Time: 2.43862
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 4.66392

Cumulative Model Updates: 77,214
Cumulative Timesteps: 644,001,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.99129
Policy Entropy: 3.31719
Value Function Loss: 0.00402

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10833
Policy Update Magnitude: 0.55511
Value Function Update Magnitude: 0.63529

Collected Steps per Second: 21,744.13815
Overall Steps per Second: 10,572.36090

Timestep Collection Time: 2.29993
Timestep Consumption Time: 2.43033
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.73026

Cumulative Model Updates: 77,220
Cumulative Timesteps: 644,051,470

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 644051470...
Checkpoint 644051470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.48165
Policy Entropy: 3.31469
Value Function Loss: 0.00378

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08375
Policy Update Magnitude: 0.54249
Value Function Update Magnitude: 0.63593

Collected Steps per Second: 22,109.20782
Overall Steps per Second: 10,640.15992

Timestep Collection Time: 2.26286
Timestep Consumption Time: 2.43914
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.70200

Cumulative Model Updates: 77,226
Cumulative Timesteps: 644,101,500

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.79314
Policy Entropy: 3.30803
Value Function Loss: 0.00392

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.54368
Value Function Update Magnitude: 0.64423

Collected Steps per Second: 22,158.00502
Overall Steps per Second: 10,723.72837

Timestep Collection Time: 2.25706
Timestep Consumption Time: 2.40661
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.66368

Cumulative Model Updates: 77,232
Cumulative Timesteps: 644,151,512

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 644151512...
Checkpoint 644151512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 859.32382
Policy Entropy: 3.30656
Value Function Loss: 0.00384

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.07961
Policy Update Magnitude: 0.54493
Value Function Update Magnitude: 0.63940

Collected Steps per Second: 22,029.98854
Overall Steps per Second: 10,642.54244

Timestep Collection Time: 2.26963
Timestep Consumption Time: 2.42849
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.69813

Cumulative Model Updates: 77,238
Cumulative Timesteps: 644,201,512

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 765.96401
Policy Entropy: 3.29617
Value Function Loss: 0.00400

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.07990
Policy Update Magnitude: 0.55006
Value Function Update Magnitude: 0.64810

Collected Steps per Second: 22,708.65300
Overall Steps per Second: 10,611.87478

Timestep Collection Time: 2.20233
Timestep Consumption Time: 2.51050
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.71283

Cumulative Model Updates: 77,244
Cumulative Timesteps: 644,251,524

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 644251524...
Checkpoint 644251524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 830.40389
Policy Entropy: 3.29409
Value Function Loss: 0.00388

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08239
Policy Update Magnitude: 0.54846
Value Function Update Magnitude: 0.66267

Collected Steps per Second: 23,065.53301
Overall Steps per Second: 10,845.31069

Timestep Collection Time: 2.16869
Timestep Consumption Time: 2.44363
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.61232

Cumulative Model Updates: 77,250
Cumulative Timesteps: 644,301,546

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.09487
Policy Entropy: 3.28800
Value Function Loss: 0.00399

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08520
Policy Update Magnitude: 0.54642
Value Function Update Magnitude: 0.65267

Collected Steps per Second: 21,979.06396
Overall Steps per Second: 10,588.33884

Timestep Collection Time: 2.27589
Timestep Consumption Time: 2.44836
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.72425

Cumulative Model Updates: 77,256
Cumulative Timesteps: 644,351,568

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 644351568...
Checkpoint 644351568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 918.44523
Policy Entropy: 3.29115
Value Function Loss: 0.00404

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10105
Policy Update Magnitude: 0.54568
Value Function Update Magnitude: 0.64620

Collected Steps per Second: 21,801.40828
Overall Steps per Second: 10,575.58002

Timestep Collection Time: 2.29361
Timestep Consumption Time: 2.43464
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.72825

Cumulative Model Updates: 77,262
Cumulative Timesteps: 644,401,572

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.55881
Policy Entropy: 3.27887
Value Function Loss: 0.00409

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10891
Policy Update Magnitude: 0.54904
Value Function Update Magnitude: 0.65497

Collected Steps per Second: 22,194.84824
Overall Steps per Second: 10,473.30514

Timestep Collection Time: 2.25332
Timestep Consumption Time: 2.52187
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.77519

Cumulative Model Updates: 77,268
Cumulative Timesteps: 644,451,584

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 644451584...
Checkpoint 644451584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 944.33490
Policy Entropy: 3.28174
Value Function Loss: 0.00413

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09489
Policy Update Magnitude: 0.54735
Value Function Update Magnitude: 0.65292

Collected Steps per Second: 22,237.20446
Overall Steps per Second: 10,601.68459

Timestep Collection Time: 2.24992
Timestep Consumption Time: 2.46933
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.71925

Cumulative Model Updates: 77,274
Cumulative Timesteps: 644,501,616

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653.72874
Policy Entropy: 3.28283
Value Function Loss: 0.00416

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08390
Policy Update Magnitude: 0.55370
Value Function Update Magnitude: 0.65679

Collected Steps per Second: 22,598.63821
Overall Steps per Second: 10,582.47507

Timestep Collection Time: 2.21261
Timestep Consumption Time: 2.51237
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.72498

Cumulative Model Updates: 77,280
Cumulative Timesteps: 644,551,618

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 644551618...
Checkpoint 644551618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 880.93333
Policy Entropy: 3.27833
Value Function Loss: 0.00430

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08942
Policy Update Magnitude: 0.55850
Value Function Update Magnitude: 0.67151

Collected Steps per Second: 22,589.15292
Overall Steps per Second: 10,537.31254

Timestep Collection Time: 2.21381
Timestep Consumption Time: 2.53200
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.74580

Cumulative Model Updates: 77,286
Cumulative Timesteps: 644,601,626

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,620.64855
Policy Entropy: 3.28140
Value Function Loss: 0.00420

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08068
Policy Update Magnitude: 0.55904
Value Function Update Magnitude: 0.66020

Collected Steps per Second: 23,029.12558
Overall Steps per Second: 10,773.37381

Timestep Collection Time: 2.17203
Timestep Consumption Time: 2.47090
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.64293

Cumulative Model Updates: 77,292
Cumulative Timesteps: 644,651,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 644651646...
Checkpoint 644651646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641.85640
Policy Entropy: 3.27981
Value Function Loss: 0.00419

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08343
Policy Update Magnitude: 0.56062
Value Function Update Magnitude: 0.66226

Collected Steps per Second: 22,818.77063
Overall Steps per Second: 10,796.27050

Timestep Collection Time: 2.19170
Timestep Consumption Time: 2.44064
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.63234

Cumulative Model Updates: 77,298
Cumulative Timesteps: 644,701,658

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.24518
Policy Entropy: 3.28528
Value Function Loss: 0.00422

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.56334
Value Function Update Magnitude: 0.66667

Collected Steps per Second: 23,241.49249
Overall Steps per Second: 10,881.14375

Timestep Collection Time: 2.15176
Timestep Consumption Time: 2.44427
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.59602

Cumulative Model Updates: 77,304
Cumulative Timesteps: 644,751,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 644751668...
Checkpoint 644751668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 895.52746
Policy Entropy: 3.27721
Value Function Loss: 0.00437

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12342
Policy Update Magnitude: 0.56867
Value Function Update Magnitude: 0.68037

Collected Steps per Second: 22,777.75377
Overall Steps per Second: 10,660.47248

Timestep Collection Time: 2.19574
Timestep Consumption Time: 2.49580
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.69154

Cumulative Model Updates: 77,310
Cumulative Timesteps: 644,801,682

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,533.94586
Policy Entropy: 3.26954
Value Function Loss: 0.00433

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11544
Policy Update Magnitude: 0.57075
Value Function Update Magnitude: 0.69891

Collected Steps per Second: 22,012.92852
Overall Steps per Second: 10,408.44402

Timestep Collection Time: 2.27194
Timestep Consumption Time: 2.53301
PPO Batch Consumption Time: 0.29588
Total Iteration Time: 4.80494

Cumulative Model Updates: 77,316
Cumulative Timesteps: 644,851,694

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 644851694...
Checkpoint 644851694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.70524
Policy Entropy: 3.27293
Value Function Loss: 0.00425

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11696
Policy Update Magnitude: 0.56791
Value Function Update Magnitude: 0.68637

Collected Steps per Second: 22,437.88348
Overall Steps per Second: 10,661.10870

Timestep Collection Time: 2.22998
Timestep Consumption Time: 2.46334
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.69332

Cumulative Model Updates: 77,322
Cumulative Timesteps: 644,901,730

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.94266
Policy Entropy: 3.28272
Value Function Loss: 0.00432

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.11016
Policy Update Magnitude: 0.56569
Value Function Update Magnitude: 0.67358

Collected Steps per Second: 22,430.07893
Overall Steps per Second: 10,511.91040

Timestep Collection Time: 2.22924
Timestep Consumption Time: 2.52746
PPO Batch Consumption Time: 0.29665
Total Iteration Time: 4.75670

Cumulative Model Updates: 77,328
Cumulative Timesteps: 644,951,732

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 644951732...
Checkpoint 644951732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573.74321
Policy Entropy: 3.29209
Value Function Loss: 0.00445

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10065
Policy Update Magnitude: 0.56333
Value Function Update Magnitude: 0.66286

Collected Steps per Second: 22,830.75320
Overall Steps per Second: 10,612.52681

Timestep Collection Time: 2.19064
Timestep Consumption Time: 2.52209
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.71273

Cumulative Model Updates: 77,334
Cumulative Timesteps: 645,001,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.14502
Policy Entropy: 3.28470
Value Function Loss: 0.00431

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.56357
Value Function Update Magnitude: 0.64818

Collected Steps per Second: 22,369.15865
Overall Steps per Second: 10,430.10396

Timestep Collection Time: 2.23611
Timestep Consumption Time: 2.55962
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 4.79573

Cumulative Model Updates: 77,340
Cumulative Timesteps: 645,051,766

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 645051766...
Checkpoint 645051766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.91745
Policy Entropy: 3.30224
Value Function Loss: 0.00426

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09487
Policy Update Magnitude: 0.56188
Value Function Update Magnitude: 0.64369

Collected Steps per Second: 22,749.58914
Overall Steps per Second: 10,605.80824

Timestep Collection Time: 2.19855
Timestep Consumption Time: 2.51736
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.71591

Cumulative Model Updates: 77,346
Cumulative Timesteps: 645,101,782

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.22075
Policy Entropy: 3.28164
Value Function Loss: 0.00411

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09532
Policy Update Magnitude: 0.55411
Value Function Update Magnitude: 0.64230

Collected Steps per Second: 23,058.35508
Overall Steps per Second: 10,742.66148

Timestep Collection Time: 2.16937
Timestep Consumption Time: 2.48702
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.65639

Cumulative Model Updates: 77,352
Cumulative Timesteps: 645,151,804

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 645151804...
Checkpoint 645151804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605.79639
Policy Entropy: 3.28560
Value Function Loss: 0.00388

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09135
Policy Update Magnitude: 0.54930
Value Function Update Magnitude: 0.63838

Collected Steps per Second: 23,045.73652
Overall Steps per Second: 10,784.11657

Timestep Collection Time: 2.16960
Timestep Consumption Time: 2.46685
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.63645

Cumulative Model Updates: 77,358
Cumulative Timesteps: 645,201,804

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 976.63606
Policy Entropy: 3.27239
Value Function Loss: 0.00386

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08946
Policy Update Magnitude: 0.55003
Value Function Update Magnitude: 0.64097

Collected Steps per Second: 22,872.86182
Overall Steps per Second: 10,659.11171

Timestep Collection Time: 2.18626
Timestep Consumption Time: 2.50513
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.69139

Cumulative Model Updates: 77,364
Cumulative Timesteps: 645,251,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 645251810...
Checkpoint 645251810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 903.85241
Policy Entropy: 3.28481
Value Function Loss: 0.00380

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09852
Policy Update Magnitude: 0.54633
Value Function Update Magnitude: 0.62793

Collected Steps per Second: 22,782.69433
Overall Steps per Second: 10,683.39135

Timestep Collection Time: 2.19614
Timestep Consumption Time: 2.48720
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.68334

Cumulative Model Updates: 77,370
Cumulative Timesteps: 645,301,844

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.64167
Policy Entropy: 3.28908
Value Function Loss: 0.00396

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09304
Policy Update Magnitude: 0.54993
Value Function Update Magnitude: 0.62030

Collected Steps per Second: 22,668.93347
Overall Steps per Second: 10,746.48804

Timestep Collection Time: 2.20575
Timestep Consumption Time: 2.44712
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.65287

Cumulative Model Updates: 77,376
Cumulative Timesteps: 645,351,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 645351846...
Checkpoint 645351846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 821.22255
Policy Entropy: 3.29807
Value Function Loss: 0.00396

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09525
Policy Update Magnitude: 0.55448
Value Function Update Magnitude: 0.63681

Collected Steps per Second: 22,359.85894
Overall Steps per Second: 10,641.47809

Timestep Collection Time: 2.23758
Timestep Consumption Time: 2.46402
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.70160

Cumulative Model Updates: 77,382
Cumulative Timesteps: 645,401,878

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672.58478
Policy Entropy: 3.30306
Value Function Loss: 0.00401

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08509
Policy Update Magnitude: 0.55392
Value Function Update Magnitude: 0.62947

Collected Steps per Second: 22,440.36602
Overall Steps per Second: 10,528.73654

Timestep Collection Time: 2.22831
Timestep Consumption Time: 2.52098
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.74929

Cumulative Model Updates: 77,388
Cumulative Timesteps: 645,451,882

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 645451882...
Checkpoint 645451882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 756.70405
Policy Entropy: 3.28844
Value Function Loss: 0.00422

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09085
Policy Update Magnitude: 0.56228
Value Function Update Magnitude: 0.64098

Collected Steps per Second: 22,656.52052
Overall Steps per Second: 10,591.39368

Timestep Collection Time: 2.20758
Timestep Consumption Time: 2.51475
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.72232

Cumulative Model Updates: 77,394
Cumulative Timesteps: 645,501,898

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 835.13153
Policy Entropy: 3.27168
Value Function Loss: 0.00441

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09845
Policy Update Magnitude: 0.56888
Value Function Update Magnitude: 0.65006

Collected Steps per Second: 22,187.53013
Overall Steps per Second: 10,436.69919

Timestep Collection Time: 2.25514
Timestep Consumption Time: 2.53910
PPO Batch Consumption Time: 0.29604
Total Iteration Time: 4.79424

Cumulative Model Updates: 77,400
Cumulative Timesteps: 645,551,934

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 645551934...
Checkpoint 645551934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601.23513
Policy Entropy: 3.26487
Value Function Loss: 0.00441

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09412
Policy Update Magnitude: 0.57803
Value Function Update Magnitude: 0.66308

Collected Steps per Second: 22,629.03961
Overall Steps per Second: 10,623.28429

Timestep Collection Time: 2.21026
Timestep Consumption Time: 2.49789
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.70815

Cumulative Model Updates: 77,406
Cumulative Timesteps: 645,601,950

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 888.81351
Policy Entropy: 3.26537
Value Function Loss: 0.00410

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09351
Policy Update Magnitude: 0.57248
Value Function Update Magnitude: 0.64949

Collected Steps per Second: 22,589.58890
Overall Steps per Second: 10,443.33071

Timestep Collection Time: 2.21359
Timestep Consumption Time: 2.57454
PPO Batch Consumption Time: 0.29698
Total Iteration Time: 4.78813

Cumulative Model Updates: 77,412
Cumulative Timesteps: 645,651,954

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 645651954...
Checkpoint 645651954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 909.43197
Policy Entropy: 3.27466
Value Function Loss: 0.00383

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08293
Policy Update Magnitude: 0.56113
Value Function Update Magnitude: 0.62298

Collected Steps per Second: 22,466.07096
Overall Steps per Second: 10,609.27470

Timestep Collection Time: 2.22674
Timestep Consumption Time: 2.48857
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.71531

Cumulative Model Updates: 77,418
Cumulative Timesteps: 645,701,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 950.50063
Policy Entropy: 3.26870
Value Function Loss: 0.00384

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.55431
Value Function Update Magnitude: 0.60851

Collected Steps per Second: 22,610.17259
Overall Steps per Second: 10,598.62721

Timestep Collection Time: 2.21139
Timestep Consumption Time: 2.50620
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.71759

Cumulative Model Updates: 77,424
Cumulative Timesteps: 645,751,980

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 645751980...
Checkpoint 645751980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636.86301
Policy Entropy: 3.25967
Value Function Loss: 0.00389

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09451
Policy Update Magnitude: 0.55386
Value Function Update Magnitude: 0.59072

Collected Steps per Second: 22,976.61443
Overall Steps per Second: 10,675.60874

Timestep Collection Time: 2.17700
Timestep Consumption Time: 2.50845
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.68545

Cumulative Model Updates: 77,430
Cumulative Timesteps: 645,802,000

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 804.22523
Policy Entropy: 3.25919
Value Function Loss: 0.00413

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09216
Policy Update Magnitude: 0.55515
Value Function Update Magnitude: 0.58013

Collected Steps per Second: 22,739.02937
Overall Steps per Second: 10,727.42276

Timestep Collection Time: 2.19895
Timestep Consumption Time: 2.46219
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.66114

Cumulative Model Updates: 77,436
Cumulative Timesteps: 645,852,002

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 645852002...
Checkpoint 645852002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618.51039
Policy Entropy: 3.26692
Value Function Loss: 0.00416

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10073
Policy Update Magnitude: 0.55886
Value Function Update Magnitude: 0.57714

Collected Steps per Second: 22,829.16612
Overall Steps per Second: 10,685.13379

Timestep Collection Time: 2.19088
Timestep Consumption Time: 2.49001
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.68090

Cumulative Model Updates: 77,442
Cumulative Timesteps: 645,902,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 966.73183
Policy Entropy: 3.27405
Value Function Loss: 0.00410

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10127
Policy Update Magnitude: 0.55589
Value Function Update Magnitude: 0.59017

Collected Steps per Second: 22,862.23543
Overall Steps per Second: 10,639.02731

Timestep Collection Time: 2.18806
Timestep Consumption Time: 2.51387
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.70193

Cumulative Model Updates: 77,448
Cumulative Timesteps: 645,952,042

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 645952042...
Checkpoint 645952042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 739.09571
Policy Entropy: 3.25885
Value Function Loss: 0.00413

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.56042
Value Function Update Magnitude: 0.62464

Collected Steps per Second: 22,611.60156
Overall Steps per Second: 10,817.64861

Timestep Collection Time: 2.21258
Timestep Consumption Time: 2.41227
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.62485

Cumulative Model Updates: 77,454
Cumulative Timesteps: 646,002,072

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.05804
Policy Entropy: 3.24747
Value Function Loss: 0.00433

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12014
Policy Update Magnitude: 0.57355
Value Function Update Magnitude: 0.63850

Collected Steps per Second: 22,086.76611
Overall Steps per Second: 10,473.34532

Timestep Collection Time: 2.26407
Timestep Consumption Time: 2.51053
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 4.77460

Cumulative Model Updates: 77,460
Cumulative Timesteps: 646,052,078

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 646052078...
Checkpoint 646052078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 868.87828
Policy Entropy: 3.24469
Value Function Loss: 0.00452

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11491
Policy Update Magnitude: 0.58348
Value Function Update Magnitude: 0.65328

Collected Steps per Second: 22,459.95669
Overall Steps per Second: 10,591.62890

Timestep Collection Time: 2.22681
Timestep Consumption Time: 2.49522
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.72203

Cumulative Model Updates: 77,466
Cumulative Timesteps: 646,102,092

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 968.85993
Policy Entropy: 3.25882
Value Function Loss: 0.00437

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11030
Policy Update Magnitude: 0.58870
Value Function Update Magnitude: 0.66009

Collected Steps per Second: 22,042.44771
Overall Steps per Second: 10,496.59128

Timestep Collection Time: 2.26962
Timestep Consumption Time: 2.49650
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.76612

Cumulative Model Updates: 77,472
Cumulative Timesteps: 646,152,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 646152120...
Checkpoint 646152120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 990.99865
Policy Entropy: 3.27241
Value Function Loss: 0.00447

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10745
Policy Update Magnitude: 0.58936
Value Function Update Magnitude: 0.65641

Collected Steps per Second: 22,713.43410
Overall Steps per Second: 10,650.05596

Timestep Collection Time: 2.20266
Timestep Consumption Time: 2.49497
PPO Batch Consumption Time: 0.29712
Total Iteration Time: 4.69763

Cumulative Model Updates: 77,478
Cumulative Timesteps: 646,202,150

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 817.24731
Policy Entropy: 3.27648
Value Function Loss: 0.00450

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10591
Policy Update Magnitude: 0.58384
Value Function Update Magnitude: 0.66028

Collected Steps per Second: 22,756.64780
Overall Steps per Second: 10,650.72266

Timestep Collection Time: 2.19821
Timestep Consumption Time: 2.49856
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.69677

Cumulative Model Updates: 77,484
Cumulative Timesteps: 646,252,174

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 646252174...
Checkpoint 646252174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.98979
Policy Entropy: 3.28514
Value Function Loss: 0.00437

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10671
Policy Update Magnitude: 0.57706
Value Function Update Magnitude: 0.67846

Collected Steps per Second: 22,815.07685
Overall Steps per Second: 10,764.32312

Timestep Collection Time: 2.19215
Timestep Consumption Time: 2.45413
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.64627

Cumulative Model Updates: 77,490
Cumulative Timesteps: 646,302,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 871.11950
Policy Entropy: 3.27886
Value Function Loss: 0.00445

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10081
Policy Update Magnitude: 0.57143
Value Function Update Magnitude: 0.67508

Collected Steps per Second: 22,849.62686
Overall Steps per Second: 10,692.37157

Timestep Collection Time: 2.18901
Timestep Consumption Time: 2.48891
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.67791

Cumulative Model Updates: 77,496
Cumulative Timesteps: 646,352,206

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 646352206...
Checkpoint 646352206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,686.06712
Policy Entropy: 3.27386
Value Function Loss: 0.00456

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09464
Policy Update Magnitude: 0.57525
Value Function Update Magnitude: 0.68035

Collected Steps per Second: 22,877.65610
Overall Steps per Second: 10,857.10931

Timestep Collection Time: 2.18563
Timestep Consumption Time: 2.41984
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.60546

Cumulative Model Updates: 77,502
Cumulative Timesteps: 646,402,208

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 917.49605
Policy Entropy: 3.26917
Value Function Loss: 0.00455

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11738
Policy Update Magnitude: 0.57685
Value Function Update Magnitude: 0.67702

Collected Steps per Second: 22,617.53585
Overall Steps per Second: 10,617.07527

Timestep Collection Time: 2.21209
Timestep Consumption Time: 2.50032
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.71241

Cumulative Model Updates: 77,508
Cumulative Timesteps: 646,452,240

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 646452240...
Checkpoint 646452240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.96165
Policy Entropy: 3.29035
Value Function Loss: 0.00430

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10928
Policy Update Magnitude: 0.56618
Value Function Update Magnitude: 0.67492

Collected Steps per Second: 22,770.45860
Overall Steps per Second: 10,689.68560

Timestep Collection Time: 2.19679
Timestep Consumption Time: 2.48267
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.67946

Cumulative Model Updates: 77,514
Cumulative Timesteps: 646,502,262

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467.21365
Policy Entropy: 3.29367
Value Function Loss: 0.00407

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09530
Policy Update Magnitude: 0.55846
Value Function Update Magnitude: 0.68929

Collected Steps per Second: 22,964.37377
Overall Steps per Second: 10,781.01445

Timestep Collection Time: 2.17816
Timestep Consumption Time: 2.46148
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.63964

Cumulative Model Updates: 77,520
Cumulative Timesteps: 646,552,282

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 646552282...
Checkpoint 646552282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.24759
Policy Entropy: 3.29460
Value Function Loss: 0.00418

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08524
Policy Update Magnitude: 0.56492
Value Function Update Magnitude: 0.69599

Collected Steps per Second: 22,387.90435
Overall Steps per Second: 10,649.36783

Timestep Collection Time: 2.23380
Timestep Consumption Time: 2.46226
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.69605

Cumulative Model Updates: 77,526
Cumulative Timesteps: 646,602,292

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.98338
Policy Entropy: 3.29196
Value Function Loss: 0.00415

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09161
Policy Update Magnitude: 0.56869
Value Function Update Magnitude: 0.70307

Collected Steps per Second: 22,064.57984
Overall Steps per Second: 10,426.55772

Timestep Collection Time: 2.26644
Timestep Consumption Time: 2.52978
PPO Batch Consumption Time: 0.29654
Total Iteration Time: 4.79621

Cumulative Model Updates: 77,532
Cumulative Timesteps: 646,652,300

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 646652300...
Checkpoint 646652300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 958.26390
Policy Entropy: 3.28568
Value Function Loss: 0.00416

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08735
Policy Update Magnitude: 0.56560
Value Function Update Magnitude: 0.68396

Collected Steps per Second: 22,582.55003
Overall Steps per Second: 10,660.97195

Timestep Collection Time: 2.21419
Timestep Consumption Time: 2.47600
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.69019

Cumulative Model Updates: 77,538
Cumulative Timesteps: 646,702,302

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 980.23754
Policy Entropy: 3.28520
Value Function Loss: 0.00400

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.56214
Value Function Update Magnitude: 0.67382

Collected Steps per Second: 21,455.61020
Overall Steps per Second: 10,537.85765

Timestep Collection Time: 2.33086
Timestep Consumption Time: 2.41489
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.74575

Cumulative Model Updates: 77,544
Cumulative Timesteps: 646,752,312

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 646752312...
Checkpoint 646752312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.00188
Policy Entropy: 3.28749
Value Function Loss: 0.00389

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.12341
Policy Update Magnitude: 0.54533
Value Function Update Magnitude: 0.65614

Collected Steps per Second: 22,463.07329
Overall Steps per Second: 10,740.68263

Timestep Collection Time: 2.22588
Timestep Consumption Time: 2.42932
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.65520

Cumulative Model Updates: 77,550
Cumulative Timesteps: 646,802,312

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 894.21933
Policy Entropy: 3.30108
Value Function Loss: 0.00369

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09510
Policy Update Magnitude: 0.53155
Value Function Update Magnitude: 0.63164

Collected Steps per Second: 22,365.61956
Overall Steps per Second: 10,652.56391

Timestep Collection Time: 2.23593
Timestep Consumption Time: 2.45852
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.69446

Cumulative Model Updates: 77,556
Cumulative Timesteps: 646,852,320

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 646852320...
Checkpoint 646852320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.07190
Policy Entropy: 3.28939
Value Function Loss: 0.00395

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08678
Policy Update Magnitude: 0.53233
Value Function Update Magnitude: 0.61262

Collected Steps per Second: 22,440.73042
Overall Steps per Second: 10,646.30258

Timestep Collection Time: 2.22934
Timestep Consumption Time: 2.46976
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.69910

Cumulative Model Updates: 77,562
Cumulative Timesteps: 646,902,348

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.71346
Policy Entropy: 3.29043
Value Function Loss: 0.00398

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08854
Policy Update Magnitude: 0.54391
Value Function Update Magnitude: 0.62921

Collected Steps per Second: 22,968.69116
Overall Steps per Second: 10,734.07115

Timestep Collection Time: 2.17766
Timestep Consumption Time: 2.48208
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.65974

Cumulative Model Updates: 77,568
Cumulative Timesteps: 646,952,366

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 646952366...
Checkpoint 646952366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 867.84906
Policy Entropy: 3.28961
Value Function Loss: 0.00407

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08763
Policy Update Magnitude: 0.55875
Value Function Update Magnitude: 0.64124

Collected Steps per Second: 22,812.19430
Overall Steps per Second: 10,818.69514

Timestep Collection Time: 2.19242
Timestep Consumption Time: 2.43050
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.62292

Cumulative Model Updates: 77,574
Cumulative Timesteps: 647,002,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760.97752
Policy Entropy: 3.28885
Value Function Loss: 0.00413

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.56239
Value Function Update Magnitude: 0.63169

Collected Steps per Second: 23,123.44954
Overall Steps per Second: 10,965.65183

Timestep Collection Time: 2.16274
Timestep Consumption Time: 2.39786
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.56060

Cumulative Model Updates: 77,580
Cumulative Timesteps: 647,052,390

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 647052390...
Checkpoint 647052390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.63272
Policy Entropy: 3.26976
Value Function Loss: 0.00441

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11178
Policy Update Magnitude: 0.56541
Value Function Update Magnitude: 0.63611

Collected Steps per Second: 22,092.06384
Overall Steps per Second: 10,642.38344

Timestep Collection Time: 2.26362
Timestep Consumption Time: 2.43533
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.69895

Cumulative Model Updates: 77,586
Cumulative Timesteps: 647,102,398

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.77689
Policy Entropy: 3.26944
Value Function Loss: 0.00440

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10681
Policy Update Magnitude: 0.56719
Value Function Update Magnitude: 0.64549

Collected Steps per Second: 21,728.27312
Overall Steps per Second: 10,534.02698

Timestep Collection Time: 2.30179
Timestep Consumption Time: 2.44606
PPO Batch Consumption Time: 0.29615
Total Iteration Time: 4.74785

Cumulative Model Updates: 77,592
Cumulative Timesteps: 647,152,412

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 647152412...
Checkpoint 647152412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714.84785
Policy Entropy: 3.25961
Value Function Loss: 0.00447

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09646
Policy Update Magnitude: 0.57442
Value Function Update Magnitude: 0.65205

Collected Steps per Second: 22,330.40488
Overall Steps per Second: 10,554.76293

Timestep Collection Time: 2.23928
Timestep Consumption Time: 2.49830
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.73758

Cumulative Model Updates: 77,598
Cumulative Timesteps: 647,202,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 786.35846
Policy Entropy: 3.26328
Value Function Loss: 0.00426

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10299
Policy Update Magnitude: 0.57389
Value Function Update Magnitude: 0.65609

Collected Steps per Second: 22,315.09250
Overall Steps per Second: 10,473.95669

Timestep Collection Time: 2.24198
Timestep Consumption Time: 2.53463
PPO Batch Consumption Time: 0.29695
Total Iteration Time: 4.77661

Cumulative Model Updates: 77,604
Cumulative Timesteps: 647,252,446

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 647252446...
Checkpoint 647252446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 713.85993
Policy Entropy: 3.26635
Value Function Loss: 0.00419

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12089
Policy Update Magnitude: 0.56926
Value Function Update Magnitude: 0.65085

Collected Steps per Second: 22,333.66923
Overall Steps per Second: 10,625.13032

Timestep Collection Time: 2.23895
Timestep Consumption Time: 2.46725
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.70620

Cumulative Model Updates: 77,610
Cumulative Timesteps: 647,302,450

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468.77107
Policy Entropy: 3.26036
Value Function Loss: 0.00407

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11180
Policy Update Magnitude: 0.56441
Value Function Update Magnitude: 0.62632

Collected Steps per Second: 22,494.26759
Overall Steps per Second: 10,524.96537

Timestep Collection Time: 2.22332
Timestep Consumption Time: 2.52843
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.75175

Cumulative Model Updates: 77,616
Cumulative Timesteps: 647,352,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 647352462...
Checkpoint 647352462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 901.48066
Policy Entropy: 3.25714
Value Function Loss: 0.00420

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.55472
Value Function Update Magnitude: 0.62082

Collected Steps per Second: 22,717.09166
Overall Steps per Second: 10,564.55569

Timestep Collection Time: 2.20239
Timestep Consumption Time: 2.53344
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.73584

Cumulative Model Updates: 77,622
Cumulative Timesteps: 647,402,494

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 916.69262
Policy Entropy: 3.25213
Value Function Loss: 0.00425

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.55929
Value Function Update Magnitude: 0.62902

Collected Steps per Second: 22,693.04747
Overall Steps per Second: 10,596.61444

Timestep Collection Time: 2.20358
Timestep Consumption Time: 2.51547
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.71905

Cumulative Model Updates: 77,628
Cumulative Timesteps: 647,452,500

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 647452500...
Checkpoint 647452500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.79137
Policy Entropy: 3.25028
Value Function Loss: 0.00426

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08739
Policy Update Magnitude: 0.56920
Value Function Update Magnitude: 0.63867

Collected Steps per Second: 22,924.82664
Overall Steps per Second: 10,684.76326

Timestep Collection Time: 2.18235
Timestep Consumption Time: 2.50002
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.68237

Cumulative Model Updates: 77,634
Cumulative Timesteps: 647,502,530

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.24612
Policy Entropy: 3.26554
Value Function Loss: 0.00443

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09100
Policy Update Magnitude: 0.57303
Value Function Update Magnitude: 0.64130

Collected Steps per Second: 23,224.74708
Overall Steps per Second: 10,696.36889

Timestep Collection Time: 2.15417
Timestep Consumption Time: 2.52312
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.67729

Cumulative Model Updates: 77,640
Cumulative Timesteps: 647,552,560

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 647552560...
Checkpoint 647552560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 745.99189
Policy Entropy: 3.25531
Value Function Loss: 0.00455

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08489
Policy Update Magnitude: 0.57937
Value Function Update Magnitude: 0.63329

Collected Steps per Second: 22,412.36155
Overall Steps per Second: 10,705.69290

Timestep Collection Time: 2.23136
Timestep Consumption Time: 2.43999
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.67135

Cumulative Model Updates: 77,646
Cumulative Timesteps: 647,602,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.18723
Policy Entropy: 3.25385
Value Function Loss: 0.00438

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08112
Policy Update Magnitude: 0.58602
Value Function Update Magnitude: 0.64993

Collected Steps per Second: 22,972.49184
Overall Steps per Second: 10,721.19428

Timestep Collection Time: 2.17756
Timestep Consumption Time: 2.48834
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.66590

Cumulative Model Updates: 77,652
Cumulative Timesteps: 647,652,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 647652594...
Checkpoint 647652594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 950.07157
Policy Entropy: 3.24386
Value Function Loss: 0.00413

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08308
Policy Update Magnitude: 0.58010
Value Function Update Magnitude: 0.64754

Collected Steps per Second: 22,456.73723
Overall Steps per Second: 10,695.65154

Timestep Collection Time: 2.22677
Timestep Consumption Time: 2.44859
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.67536

Cumulative Model Updates: 77,658
Cumulative Timesteps: 647,702,600

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 804.44465
Policy Entropy: 3.27271
Value Function Loss: 0.00375

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08458
Policy Update Magnitude: 0.56052
Value Function Update Magnitude: 0.62567

Collected Steps per Second: 22,409.23971
Overall Steps per Second: 10,548.70654

Timestep Collection Time: 2.23176
Timestep Consumption Time: 2.50930
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.74106

Cumulative Model Updates: 77,664
Cumulative Timesteps: 647,752,612

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 647752612...
Checkpoint 647752612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 965.23169
Policy Entropy: 3.28398
Value Function Loss: 0.00378

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07844
Policy Update Magnitude: 0.54389
Value Function Update Magnitude: 0.63167

Collected Steps per Second: 22,357.14952
Overall Steps per Second: 10,625.33468

Timestep Collection Time: 2.23696
Timestep Consumption Time: 2.46991
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.70686

Cumulative Model Updates: 77,670
Cumulative Timesteps: 647,802,624

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724.15808
Policy Entropy: 3.28374
Value Function Loss: 0.00390

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10628
Policy Update Magnitude: 0.54231
Value Function Update Magnitude: 0.64384

Collected Steps per Second: 22,295.75387
Overall Steps per Second: 10,442.43339

Timestep Collection Time: 2.24330
Timestep Consumption Time: 2.54639
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.78969

Cumulative Model Updates: 77,676
Cumulative Timesteps: 647,852,640

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 647852640...
Checkpoint 647852640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,632.91303
Policy Entropy: 3.27140
Value Function Loss: 0.00414

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11353
Policy Update Magnitude: 0.55047
Value Function Update Magnitude: 0.65248

Collected Steps per Second: 22,563.98762
Overall Steps per Second: 10,666.18734

Timestep Collection Time: 2.21645
Timestep Consumption Time: 2.47238
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.68884

Cumulative Model Updates: 77,682
Cumulative Timesteps: 647,902,652

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 749.94822
Policy Entropy: 3.25523
Value Function Loss: 0.00439

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10761
Policy Update Magnitude: 0.55379
Value Function Update Magnitude: 0.65639

Collected Steps per Second: 22,482.58384
Overall Steps per Second: 10,548.70478

Timestep Collection Time: 2.22430
Timestep Consumption Time: 2.51638
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.74068

Cumulative Model Updates: 77,688
Cumulative Timesteps: 647,952,660

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 647952660...
Checkpoint 647952660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.75324
Policy Entropy: 3.25580
Value Function Loss: 0.00434

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09284
Policy Update Magnitude: 0.55870
Value Function Update Magnitude: 0.66112

Collected Steps per Second: 22,657.01305
Overall Steps per Second: 10,553.39561

Timestep Collection Time: 2.20691
Timestep Consumption Time: 2.53109
PPO Batch Consumption Time: 0.29835
Total Iteration Time: 4.73800

Cumulative Model Updates: 77,694
Cumulative Timesteps: 648,002,662

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666.51096
Policy Entropy: 3.26379
Value Function Loss: 0.00417

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10559
Policy Update Magnitude: 0.56334
Value Function Update Magnitude: 0.66649

Collected Steps per Second: 23,125.26483
Overall Steps per Second: 10,825.60767

Timestep Collection Time: 2.16274
Timestep Consumption Time: 2.45723
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.61997

Cumulative Model Updates: 77,700
Cumulative Timesteps: 648,052,676

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 648052676...
Checkpoint 648052676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687.93348
Policy Entropy: 3.26826
Value Function Loss: 0.00403

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08834
Policy Update Magnitude: 0.56326
Value Function Update Magnitude: 0.65919

Collected Steps per Second: 22,790.14438
Overall Steps per Second: 10,667.49077

Timestep Collection Time: 2.19498
Timestep Consumption Time: 2.49440
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.68939

Cumulative Model Updates: 77,706
Cumulative Timesteps: 648,102,700

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 939.63726
Policy Entropy: 3.26456
Value Function Loss: 0.00398

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08291
Policy Update Magnitude: 0.56239
Value Function Update Magnitude: 0.66061

Collected Steps per Second: 23,074.04106
Overall Steps per Second: 10,887.20819

Timestep Collection Time: 2.16728
Timestep Consumption Time: 2.42600
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.59328

Cumulative Model Updates: 77,712
Cumulative Timesteps: 648,152,708

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 648152708...
Checkpoint 648152708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.13441
Policy Entropy: 3.26758
Value Function Loss: 0.00402

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.55677
Value Function Update Magnitude: 0.65770

Collected Steps per Second: 22,397.70861
Overall Steps per Second: 10,698.60848

Timestep Collection Time: 2.23264
Timestep Consumption Time: 2.44143
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.67407

Cumulative Model Updates: 77,718
Cumulative Timesteps: 648,202,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 858.96148
Policy Entropy: 3.27268
Value Function Loss: 0.00401

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08735
Policy Update Magnitude: 0.55536
Value Function Update Magnitude: 0.65826

Collected Steps per Second: 22,845.37934
Overall Steps per Second: 10,812.28438

Timestep Collection Time: 2.18924
Timestep Consumption Time: 2.43643
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.62566

Cumulative Model Updates: 77,724
Cumulative Timesteps: 648,252,728

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 648252728...
Checkpoint 648252728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.81288
Policy Entropy: 3.27505
Value Function Loss: 0.00381

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.07788
Policy Update Magnitude: 0.54721
Value Function Update Magnitude: 0.65477

Collected Steps per Second: 22,107.63555
Overall Steps per Second: 10,685.62239

Timestep Collection Time: 2.26257
Timestep Consumption Time: 2.41849
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.68106

Cumulative Model Updates: 77,730
Cumulative Timesteps: 648,302,748

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.72718
Policy Entropy: 3.27423
Value Function Loss: 0.00388

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08244
Policy Update Magnitude: 0.54643
Value Function Update Magnitude: 0.66282

Collected Steps per Second: 22,041.11865
Overall Steps per Second: 10,546.38743

Timestep Collection Time: 2.26894
Timestep Consumption Time: 2.47297
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.74191

Cumulative Model Updates: 77,736
Cumulative Timesteps: 648,352,758

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 648352758...
Checkpoint 648352758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.37992
Policy Entropy: 3.27339
Value Function Loss: 0.00375

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09212
Policy Update Magnitude: 0.54505
Value Function Update Magnitude: 0.66322

Collected Steps per Second: 22,087.47037
Overall Steps per Second: 10,662.15077

Timestep Collection Time: 2.26490
Timestep Consumption Time: 2.42702
PPO Batch Consumption Time: 0.28171
Total Iteration Time: 4.69192

Cumulative Model Updates: 77,742
Cumulative Timesteps: 648,402,784

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.81850
Policy Entropy: 3.28363
Value Function Loss: 0.00385

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09347
Policy Update Magnitude: 0.54026
Value Function Update Magnitude: 0.64293

Collected Steps per Second: 22,393.19091
Overall Steps per Second: 10,573.17258

Timestep Collection Time: 2.23363
Timestep Consumption Time: 2.49703
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.73065

Cumulative Model Updates: 77,748
Cumulative Timesteps: 648,452,802

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 648452802...
Checkpoint 648452802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655.48379
Policy Entropy: 3.28202
Value Function Loss: 0.00395

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.54077
Value Function Update Magnitude: 0.64015

Collected Steps per Second: 22,884.84972
Overall Steps per Second: 10,877.19255

Timestep Collection Time: 2.18599
Timestep Consumption Time: 2.41318
PPO Batch Consumption Time: 0.28421
Total Iteration Time: 4.59916

Cumulative Model Updates: 77,754
Cumulative Timesteps: 648,502,828

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.96693
Policy Entropy: 3.26940
Value Function Loss: 0.00414

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09278
Policy Update Magnitude: 0.55314
Value Function Update Magnitude: 0.66654

Collected Steps per Second: 22,095.69157
Overall Steps per Second: 10,636.74172

Timestep Collection Time: 2.26352
Timestep Consumption Time: 2.43849
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.70200

Cumulative Model Updates: 77,760
Cumulative Timesteps: 648,552,842

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 648552842...
Checkpoint 648552842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688.11008
Policy Entropy: 3.26341
Value Function Loss: 0.00414

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09908
Policy Update Magnitude: 0.55974
Value Function Update Magnitude: 0.67490

Collected Steps per Second: 21,901.85836
Overall Steps per Second: 10,587.66583

Timestep Collection Time: 2.28401
Timestep Consumption Time: 2.44074
PPO Batch Consumption Time: 0.29712
Total Iteration Time: 4.72474

Cumulative Model Updates: 77,766
Cumulative Timesteps: 648,602,866

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 875.10889
Policy Entropy: 3.26794
Value Function Loss: 0.00423

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09493
Policy Update Magnitude: 0.55851
Value Function Update Magnitude: 0.65373

Collected Steps per Second: 21,385.33546
Overall Steps per Second: 10,387.89003

Timestep Collection Time: 2.33861
Timestep Consumption Time: 2.47584
PPO Batch Consumption Time: 0.29840
Total Iteration Time: 4.81445

Cumulative Model Updates: 77,772
Cumulative Timesteps: 648,652,878

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 648652878...
Checkpoint 648652878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,665.99637
Policy Entropy: 3.26348
Value Function Loss: 0.00407

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09474
Policy Update Magnitude: 0.55347
Value Function Update Magnitude: 0.63239

Collected Steps per Second: 22,456.13178
Overall Steps per Second: 10,656.76852

Timestep Collection Time: 2.22763
Timestep Consumption Time: 2.46647
PPO Batch Consumption Time: 0.28196
Total Iteration Time: 4.69411

Cumulative Model Updates: 77,778
Cumulative Timesteps: 648,702,902

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 911.91279
Policy Entropy: 3.26244
Value Function Loss: 0.00434

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10462
Policy Update Magnitude: 0.56325
Value Function Update Magnitude: 0.63445

Collected Steps per Second: 23,256.50621
Overall Steps per Second: 10,894.83264

Timestep Collection Time: 2.15002
Timestep Consumption Time: 2.43949
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.58952

Cumulative Model Updates: 77,784
Cumulative Timesteps: 648,752,904

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 648752904...
Checkpoint 648752904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 737.06127
Policy Entropy: 3.27072
Value Function Loss: 0.00432

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10213
Policy Update Magnitude: 0.57254
Value Function Update Magnitude: 0.65467

Collected Steps per Second: 22,549.77123
Overall Steps per Second: 10,670.65627

Timestep Collection Time: 2.21847
Timestep Consumption Time: 2.46971
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.68818

Cumulative Model Updates: 77,790
Cumulative Timesteps: 648,802,930

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 731.70685
Policy Entropy: 3.27502
Value Function Loss: 0.00446

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.57264
Value Function Update Magnitude: 0.66519

Collected Steps per Second: 22,693.79144
Overall Steps per Second: 10,621.06667

Timestep Collection Time: 2.20333
Timestep Consumption Time: 2.50448
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.70781

Cumulative Model Updates: 77,796
Cumulative Timesteps: 648,852,932

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 648852932...
Checkpoint 648852932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 950.74436
Policy Entropy: 3.28512
Value Function Loss: 0.00433

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.57292
Value Function Update Magnitude: 0.66846

Collected Steps per Second: 22,590.65537
Overall Steps per Second: 10,612.26716

Timestep Collection Time: 2.21348
Timestep Consumption Time: 2.49842
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.71191

Cumulative Model Updates: 77,802
Cumulative Timesteps: 648,902,936

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.15168
Policy Entropy: 3.25805
Value Function Loss: 0.00438

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09518
Policy Update Magnitude: 0.58050
Value Function Update Magnitude: 0.68726

Collected Steps per Second: 22,779.21760
Overall Steps per Second: 10,782.03961

Timestep Collection Time: 2.19533
Timestep Consumption Time: 2.44275
PPO Batch Consumption Time: 0.28178
Total Iteration Time: 4.63808

Cumulative Model Updates: 77,808
Cumulative Timesteps: 648,952,944

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 648952944...
Checkpoint 648952944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.32781
Policy Entropy: 3.24453
Value Function Loss: 0.00441

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10186
Policy Update Magnitude: 0.58358
Value Function Update Magnitude: 0.68202

Collected Steps per Second: 22,222.21728
Overall Steps per Second: 10,585.05713

Timestep Collection Time: 2.25045
Timestep Consumption Time: 2.47413
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.72458

Cumulative Model Updates: 77,814
Cumulative Timesteps: 649,002,954

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564.04407
Policy Entropy: 3.24356
Value Function Loss: 0.00419

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10889
Policy Update Magnitude: 0.58073
Value Function Update Magnitude: 0.66887

Collected Steps per Second: 23,002.78903
Overall Steps per Second: 10,599.76513

Timestep Collection Time: 2.17391
Timestep Consumption Time: 2.54374
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.71765

Cumulative Model Updates: 77,820
Cumulative Timesteps: 649,052,960

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 649052960...
Checkpoint 649052960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,436.22856
Policy Entropy: 3.25758
Value Function Loss: 0.00405

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11807
Policy Update Magnitude: 0.57031
Value Function Update Magnitude: 0.64721

Collected Steps per Second: 22,926.42887
Overall Steps per Second: 10,624.95644

Timestep Collection Time: 2.18150
Timestep Consumption Time: 2.52572
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.70722

Cumulative Model Updates: 77,826
Cumulative Timesteps: 649,102,974

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 860.34935
Policy Entropy: 3.24913
Value Function Loss: 0.00421

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11543
Policy Update Magnitude: 0.55896
Value Function Update Magnitude: 0.63397

Collected Steps per Second: 22,860.61586
Overall Steps per Second: 10,826.06213

Timestep Collection Time: 2.18830
Timestep Consumption Time: 2.43258
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.62089

Cumulative Model Updates: 77,832
Cumulative Timesteps: 649,153,000

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 649153000...
Checkpoint 649153000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 715.49615
Policy Entropy: 3.23150
Value Function Loss: 0.00458

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.13324
Policy Update Magnitude: 0.57367
Value Function Update Magnitude: 0.65446

Collected Steps per Second: 22,056.20681
Overall Steps per Second: 10,615.63848

Timestep Collection Time: 2.26766
Timestep Consumption Time: 2.44388
PPO Batch Consumption Time: 0.28203
Total Iteration Time: 4.71154

Cumulative Model Updates: 77,838
Cumulative Timesteps: 649,203,016

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683.99845
Policy Entropy: 3.23215
Value Function Loss: 0.00469

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11861
Policy Update Magnitude: 0.59088
Value Function Update Magnitude: 0.68349

Collected Steps per Second: 23,001.24348
Overall Steps per Second: 10,799.00438

Timestep Collection Time: 2.17527
Timestep Consumption Time: 2.45793
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.63320

Cumulative Model Updates: 77,844
Cumulative Timesteps: 649,253,050

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 649253050...
Checkpoint 649253050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633.22596
Policy Entropy: 3.23287
Value Function Loss: 0.00466

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.58585
Value Function Update Magnitude: 0.68833

Collected Steps per Second: 22,612.81218
Overall Steps per Second: 10,717.68565

Timestep Collection Time: 2.21140
Timestep Consumption Time: 2.45434
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.66575

Cumulative Model Updates: 77,850
Cumulative Timesteps: 649,303,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.75546
Policy Entropy: 3.24608
Value Function Loss: 0.00453

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09171
Policy Update Magnitude: 0.58357
Value Function Update Magnitude: 0.66804

Collected Steps per Second: 22,796.95577
Overall Steps per Second: 10,635.43649

Timestep Collection Time: 2.19328
Timestep Consumption Time: 2.50799
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.70126

Cumulative Model Updates: 77,856
Cumulative Timesteps: 649,353,056

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 649353056...
Checkpoint 649353056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.18429
Policy Entropy: 3.23705
Value Function Loss: 0.00445

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08765
Policy Update Magnitude: 0.57749
Value Function Update Magnitude: 0.66949

Collected Steps per Second: 22,294.93369
Overall Steps per Second: 10,499.00881

Timestep Collection Time: 2.24302
Timestep Consumption Time: 2.52010
PPO Batch Consumption Time: 0.29572
Total Iteration Time: 4.76312

Cumulative Model Updates: 77,862
Cumulative Timesteps: 649,403,064

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704.54223
Policy Entropy: 3.24654
Value Function Loss: 0.00437

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.10211
Policy Update Magnitude: 0.57857
Value Function Update Magnitude: 0.66825

Collected Steps per Second: 22,450.00995
Overall Steps per Second: 10,479.16756

Timestep Collection Time: 2.22788
Timestep Consumption Time: 2.54501
PPO Batch Consumption Time: 0.29693
Total Iteration Time: 4.77290

Cumulative Model Updates: 77,868
Cumulative Timesteps: 649,453,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 649453080...
Checkpoint 649453080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.55912
Policy Entropy: 3.25907
Value Function Loss: 0.00412

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10028
Policy Update Magnitude: 0.56839
Value Function Update Magnitude: 0.64577

Collected Steps per Second: 21,989.06357
Overall Steps per Second: 10,515.37905

Timestep Collection Time: 2.27531
Timestep Consumption Time: 2.48267
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.75798

Cumulative Model Updates: 77,874
Cumulative Timesteps: 649,503,112

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.00876
Policy Entropy: 3.26670
Value Function Loss: 0.00423

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09437
Policy Update Magnitude: 0.56530
Value Function Update Magnitude: 0.63885

Collected Steps per Second: 22,352.94822
Overall Steps per Second: 10,521.37052

Timestep Collection Time: 2.23684
Timestep Consumption Time: 2.51539
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.75223

Cumulative Model Updates: 77,880
Cumulative Timesteps: 649,553,112

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 649553112...
Checkpoint 649553112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 880.16724
Policy Entropy: 3.26660
Value Function Loss: 0.00419

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09137
Policy Update Magnitude: 0.57124
Value Function Update Magnitude: 0.64811

Collected Steps per Second: 22,380.20983
Overall Steps per Second: 10,675.10737

Timestep Collection Time: 2.23456
Timestep Consumption Time: 2.45017
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.68473

Cumulative Model Updates: 77,886
Cumulative Timesteps: 649,603,122

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.31799
Policy Entropy: 3.25947
Value Function Loss: 0.00419

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09659
Policy Update Magnitude: 0.56968
Value Function Update Magnitude: 0.65341

Collected Steps per Second: 22,951.62820
Overall Steps per Second: 10,613.32146

Timestep Collection Time: 2.17963
Timestep Consumption Time: 2.53388
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.71351

Cumulative Model Updates: 77,892
Cumulative Timesteps: 649,653,148

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 649653148...
Checkpoint 649653148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.30763
Policy Entropy: 3.26100
Value Function Loss: 0.00412

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09796
Policy Update Magnitude: 0.56220
Value Function Update Magnitude: 0.64053

Collected Steps per Second: 23,013.74700
Overall Steps per Second: 10,788.06644

Timestep Collection Time: 2.17296
Timestep Consumption Time: 2.46253
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.63549

Cumulative Model Updates: 77,898
Cumulative Timesteps: 649,703,156

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602.23995
Policy Entropy: 3.24927
Value Function Loss: 0.00425

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.55947
Value Function Update Magnitude: 0.64674

Collected Steps per Second: 22,871.64676
Overall Steps per Second: 10,627.76502

Timestep Collection Time: 2.18629
Timestep Consumption Time: 2.51875
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 4.70503

Cumulative Model Updates: 77,904
Cumulative Timesteps: 649,753,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 649753160...
Checkpoint 649753160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.32266
Policy Entropy: 3.24785
Value Function Loss: 0.00427

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09979
Policy Update Magnitude: 0.55917
Value Function Update Magnitude: 0.66805

Collected Steps per Second: 22,443.84785
Overall Steps per Second: 10,567.56122

Timestep Collection Time: 2.22787
Timestep Consumption Time: 2.50378
PPO Batch Consumption Time: 0.29605
Total Iteration Time: 4.73165

Cumulative Model Updates: 77,910
Cumulative Timesteps: 649,803,162

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 970.89752
Policy Entropy: 3.25975
Value Function Loss: 0.00421

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.56082
Value Function Update Magnitude: 0.66098

Collected Steps per Second: 23,125.45046
Overall Steps per Second: 10,889.42206

Timestep Collection Time: 2.16238
Timestep Consumption Time: 2.42978
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.59216

Cumulative Model Updates: 77,916
Cumulative Timesteps: 649,853,168

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 649853168...
Checkpoint 649853168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701.68401
Policy Entropy: 3.24683
Value Function Loss: 0.00431

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11703
Policy Update Magnitude: 0.56463
Value Function Update Magnitude: 0.65585

Collected Steps per Second: 22,718.98778
Overall Steps per Second: 10,612.78668

Timestep Collection Time: 2.20142
Timestep Consumption Time: 2.51120
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.71262

Cumulative Model Updates: 77,922
Cumulative Timesteps: 649,903,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.81605
Policy Entropy: 3.26441
Value Function Loss: 0.00456

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11215
Policy Update Magnitude: 0.57183
Value Function Update Magnitude: 0.65422

Collected Steps per Second: 22,794.71625
Overall Steps per Second: 10,732.12277

Timestep Collection Time: 2.19419
Timestep Consumption Time: 2.46621
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.66040

Cumulative Model Updates: 77,928
Cumulative Timesteps: 649,953,198

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 649953198...
Checkpoint 649953198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.50562
Policy Entropy: 3.26758
Value Function Loss: 0.00463

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11200
Policy Update Magnitude: 0.57132
Value Function Update Magnitude: 0.67188

Collected Steps per Second: 22,196.85295
Overall Steps per Second: 10,600.82886

Timestep Collection Time: 2.25338
Timestep Consumption Time: 2.46493
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.71831

Cumulative Model Updates: 77,934
Cumulative Timesteps: 650,003,216

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724.00878
Policy Entropy: 3.28459
Value Function Loss: 0.00443

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09886
Policy Update Magnitude: 0.56714
Value Function Update Magnitude: 0.67558

Collected Steps per Second: 22,867.20547
Overall Steps per Second: 10,672.22374

Timestep Collection Time: 2.18654
Timestep Consumption Time: 2.49852
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.68506

Cumulative Model Updates: 77,940
Cumulative Timesteps: 650,053,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 650053216...
Checkpoint 650053216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.63680
Policy Entropy: 3.26575
Value Function Loss: 0.00457

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.11091
Policy Update Magnitude: 0.56619
Value Function Update Magnitude: 0.68222

Collected Steps per Second: 22,138.12729
Overall Steps per Second: 10,693.94594

Timestep Collection Time: 2.25972
Timestep Consumption Time: 2.41825
PPO Batch Consumption Time: 0.28183
Total Iteration Time: 4.67797

Cumulative Model Updates: 77,946
Cumulative Timesteps: 650,103,242

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 762.32011
Policy Entropy: 3.27185
Value Function Loss: 0.00439

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10146
Policy Update Magnitude: 0.56991
Value Function Update Magnitude: 0.66994

Collected Steps per Second: 22,377.68871
Overall Steps per Second: 10,459.43662

Timestep Collection Time: 2.23499
Timestep Consumption Time: 2.54672
PPO Batch Consumption Time: 0.29792
Total Iteration Time: 4.78171

Cumulative Model Updates: 77,952
Cumulative Timesteps: 650,153,256

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 650153256...
Checkpoint 650153256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 819.31248
Policy Entropy: 3.27444
Value Function Loss: 0.00454

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.11097
Policy Update Magnitude: 0.57453
Value Function Update Magnitude: 0.68066

Collected Steps per Second: 22,427.34471
Overall Steps per Second: 10,605.97942

Timestep Collection Time: 2.22942
Timestep Consumption Time: 2.48490
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.71432

Cumulative Model Updates: 77,958
Cumulative Timesteps: 650,203,256

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 881.30020
Policy Entropy: 3.27922
Value Function Loss: 0.00440

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10288
Policy Update Magnitude: 0.57267
Value Function Update Magnitude: 0.69724

Collected Steps per Second: 22,740.40416
Overall Steps per Second: 10,496.12331

Timestep Collection Time: 2.19996
Timestep Consumption Time: 2.56637
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.76633

Cumulative Model Updates: 77,964
Cumulative Timesteps: 650,253,284

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 650253284...
Checkpoint 650253284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,339.85071
Policy Entropy: 3.27779
Value Function Loss: 0.00445

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08423
Policy Update Magnitude: 0.57199
Value Function Update Magnitude: 0.68173

Collected Steps per Second: 22,781.28166
Overall Steps per Second: 10,521.73239

Timestep Collection Time: 2.19610
Timestep Consumption Time: 2.55882
PPO Batch Consumption Time: 0.29610
Total Iteration Time: 4.75492

Cumulative Model Updates: 77,970
Cumulative Timesteps: 650,303,314

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.72600
Policy Entropy: 3.27788
Value Function Loss: 0.00440

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.07936
Policy Update Magnitude: 0.57590
Value Function Update Magnitude: 0.68898

Collected Steps per Second: 22,932.37092
Overall Steps per Second: 10,758.89992

Timestep Collection Time: 2.18128
Timestep Consumption Time: 2.46808
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.64936

Cumulative Model Updates: 77,976
Cumulative Timesteps: 650,353,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 650353336...
Checkpoint 650353336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 867.27793
Policy Entropy: 3.28738
Value Function Loss: 0.00415

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09273
Policy Update Magnitude: 0.56493
Value Function Update Magnitude: 0.68236

Collected Steps per Second: 22,603.00557
Overall Steps per Second: 10,760.87014

Timestep Collection Time: 2.21316
Timestep Consumption Time: 2.43554
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.64869

Cumulative Model Updates: 77,982
Cumulative Timesteps: 650,403,360

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.30019
Policy Entropy: 3.28797
Value Function Loss: 0.00401

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08234
Policy Update Magnitude: 0.55573
Value Function Update Magnitude: 0.66070

Collected Steps per Second: 23,123.88761
Overall Steps per Second: 10,786.58036

Timestep Collection Time: 2.16296
Timestep Consumption Time: 2.47391
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.63687

Cumulative Model Updates: 77,988
Cumulative Timesteps: 650,453,376

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 650453376...
Checkpoint 650453376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 900.65481
Policy Entropy: 3.27908
Value Function Loss: 0.00392

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08651
Policy Update Magnitude: 0.55532
Value Function Update Magnitude: 0.63761

Collected Steps per Second: 22,877.02804
Overall Steps per Second: 10,878.89366

Timestep Collection Time: 2.18604
Timestep Consumption Time: 2.41094
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.59697

Cumulative Model Updates: 77,994
Cumulative Timesteps: 650,503,386

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.17979
Policy Entropy: 3.27016
Value Function Loss: 0.00420

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09087
Policy Update Magnitude: 0.55308
Value Function Update Magnitude: 0.63673

Collected Steps per Second: 22,635.29660
Overall Steps per Second: 10,614.46263

Timestep Collection Time: 2.20991
Timestep Consumption Time: 2.50272
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.71263

Cumulative Model Updates: 78,000
Cumulative Timesteps: 650,553,408

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 650553408...
Checkpoint 650553408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 929.19819
Policy Entropy: 3.26753
Value Function Loss: 0.00433

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10059
Policy Update Magnitude: 0.55349
Value Function Update Magnitude: 0.64075

Collected Steps per Second: 22,275.47600
Overall Steps per Second: 10,552.90191

Timestep Collection Time: 2.24489
Timestep Consumption Time: 2.49371
PPO Batch Consumption Time: 0.29701
Total Iteration Time: 4.73860

Cumulative Model Updates: 78,006
Cumulative Timesteps: 650,603,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,433.06050
Policy Entropy: 3.28629
Value Function Loss: 0.00446

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08616
Policy Update Magnitude: 0.55560
Value Function Update Magnitude: 0.64533

Collected Steps per Second: 22,614.33955
Overall Steps per Second: 10,758.10527

Timestep Collection Time: 2.21161
Timestep Consumption Time: 2.43735
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.64896

Cumulative Model Updates: 78,012
Cumulative Timesteps: 650,653,428

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 650653428...
Checkpoint 650653428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 847.57207
Policy Entropy: 3.28919
Value Function Loss: 0.00433

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09038
Policy Update Magnitude: 0.55432
Value Function Update Magnitude: 0.63400

Collected Steps per Second: 22,301.72672
Overall Steps per Second: 10,689.98150

Timestep Collection Time: 2.24270
Timestep Consumption Time: 2.43608
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.67877

Cumulative Model Updates: 78,018
Cumulative Timesteps: 650,703,444

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.24441
Policy Entropy: 3.28774
Value Function Loss: 0.00424

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10644
Policy Update Magnitude: 0.55790
Value Function Update Magnitude: 0.65311

Collected Steps per Second: 22,343.32936
Overall Steps per Second: 10,548.18243

Timestep Collection Time: 2.23879
Timestep Consumption Time: 2.50345
PPO Batch Consumption Time: 0.29653
Total Iteration Time: 4.74224

Cumulative Model Updates: 78,024
Cumulative Timesteps: 650,753,466

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 650753466...
Checkpoint 650753466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.12360
Policy Entropy: 3.27640
Value Function Loss: 0.00424

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10134
Policy Update Magnitude: 0.55355
Value Function Update Magnitude: 0.64766

Collected Steps per Second: 22,460.38819
Overall Steps per Second: 10,585.58549

Timestep Collection Time: 2.22614
Timestep Consumption Time: 2.49726
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.72340

Cumulative Model Updates: 78,030
Cumulative Timesteps: 650,803,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700.20087
Policy Entropy: 3.28485
Value Function Loss: 0.00424

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09301
Policy Update Magnitude: 0.55171
Value Function Update Magnitude: 0.63067

Collected Steps per Second: 22,550.79519
Overall Steps per Second: 10,670.54498

Timestep Collection Time: 2.21810
Timestep Consumption Time: 2.46957
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.68767

Cumulative Model Updates: 78,036
Cumulative Timesteps: 650,853,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 650853486...
Checkpoint 650853486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 866.56893
Policy Entropy: 3.27771
Value Function Loss: 0.00420

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08222
Policy Update Magnitude: 0.55438
Value Function Update Magnitude: 0.62852

Collected Steps per Second: 22,751.51311
Overall Steps per Second: 10,797.42999

Timestep Collection Time: 2.19862
Timestep Consumption Time: 2.43415
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.63277

Cumulative Model Updates: 78,042
Cumulative Timesteps: 650,903,508

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,477.51138
Policy Entropy: 3.28275
Value Function Loss: 0.00417

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.54578
Value Function Update Magnitude: 0.63797

Collected Steps per Second: 22,548.28032
Overall Steps per Second: 10,599.90080

Timestep Collection Time: 2.21782
Timestep Consumption Time: 2.49996
PPO Batch Consumption Time: 0.29656
Total Iteration Time: 4.71778

Cumulative Model Updates: 78,048
Cumulative Timesteps: 650,953,516

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 650953516...
Checkpoint 650953516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 740.93311
Policy Entropy: 3.27712
Value Function Loss: 0.00405

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.54619
Value Function Update Magnitude: 0.62788

Collected Steps per Second: 22,657.97480
Overall Steps per Second: 10,900.83188

Timestep Collection Time: 2.20832
Timestep Consumption Time: 2.38179
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.59011

Cumulative Model Updates: 78,054
Cumulative Timesteps: 651,003,552

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,145.53231
Policy Entropy: 3.26423
Value Function Loss: 0.00415

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12246
Policy Update Magnitude: 0.54413
Value Function Update Magnitude: 0.63582

Collected Steps per Second: 22,122.24906
Overall Steps per Second: 10,575.84193

Timestep Collection Time: 2.26116
Timestep Consumption Time: 2.46867
PPO Batch Consumption Time: 0.29616
Total Iteration Time: 4.72984

Cumulative Model Updates: 78,060
Cumulative Timesteps: 651,053,574

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 651053574...
Checkpoint 651053574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.71801
Policy Entropy: 3.27514
Value Function Loss: 0.00427

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10556
Policy Update Magnitude: 0.53831
Value Function Update Magnitude: 0.64124

Collected Steps per Second: 22,038.87493
Overall Steps per Second: 10,643.29730

Timestep Collection Time: 2.26881
Timestep Consumption Time: 2.42917
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.69798

Cumulative Model Updates: 78,066
Cumulative Timesteps: 651,103,576

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 761.26066
Policy Entropy: 3.27495
Value Function Loss: 0.00419

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09416
Policy Update Magnitude: 0.53988
Value Function Update Magnitude: 0.64099

Collected Steps per Second: 21,699.83329
Overall Steps per Second: 10,482.75993

Timestep Collection Time: 2.30546
Timestep Consumption Time: 2.46695
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.77241

Cumulative Model Updates: 78,072
Cumulative Timesteps: 651,153,604

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 651153604...
Checkpoint 651153604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,632.64606
Policy Entropy: 3.28490
Value Function Loss: 0.00394

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07570
Policy Update Magnitude: 0.53914
Value Function Update Magnitude: 0.62515

Collected Steps per Second: 21,632.13461
Overall Steps per Second: 10,628.27399

Timestep Collection Time: 2.31230
Timestep Consumption Time: 2.39401
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.70631

Cumulative Model Updates: 78,078
Cumulative Timesteps: 651,203,624

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 961.91263
Policy Entropy: 3.27796
Value Function Loss: 0.00374

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07146
Policy Update Magnitude: 0.53261
Value Function Update Magnitude: 0.60487

Collected Steps per Second: 21,915.08614
Overall Steps per Second: 10,610.40622

Timestep Collection Time: 2.28190
Timestep Consumption Time: 2.43121
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.71311

Cumulative Model Updates: 78,084
Cumulative Timesteps: 651,253,632

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 651253632...
Checkpoint 651253632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 751.75528
Policy Entropy: 3.29372
Value Function Loss: 0.00389

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07560
Policy Update Magnitude: 0.52863
Value Function Update Magnitude: 0.59347

Collected Steps per Second: 22,733.19856
Overall Steps per Second: 10,654.53092

Timestep Collection Time: 2.20031
Timestep Consumption Time: 2.49441
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.69472

Cumulative Model Updates: 78,090
Cumulative Timesteps: 651,303,652

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707.36090
Policy Entropy: 3.29981
Value Function Loss: 0.00398

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07579
Policy Update Magnitude: 0.53356
Value Function Update Magnitude: 0.60300

Collected Steps per Second: 22,128.25026
Overall Steps per Second: 10,628.38031

Timestep Collection Time: 2.26091
Timestep Consumption Time: 2.44630
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.70721

Cumulative Model Updates: 78,096
Cumulative Timesteps: 651,353,682

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 651353682...
Checkpoint 651353682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.74958
Policy Entropy: 3.29177
Value Function Loss: 0.00416

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07665
Policy Update Magnitude: 0.54797
Value Function Update Magnitude: 0.60480

Collected Steps per Second: 22,663.93369
Overall Steps per Second: 10,687.08953

Timestep Collection Time: 2.20624
Timestep Consumption Time: 2.47249
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.67873

Cumulative Model Updates: 78,102
Cumulative Timesteps: 651,403,684

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 787.06323
Policy Entropy: 3.27435
Value Function Loss: 0.00431

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.07961
Policy Update Magnitude: 0.56078
Value Function Update Magnitude: 0.62677

Collected Steps per Second: 22,896.38176
Overall Steps per Second: 10,689.84263

Timestep Collection Time: 2.18419
Timestep Consumption Time: 2.49408
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.67827

Cumulative Model Updates: 78,108
Cumulative Timesteps: 651,453,694

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 651453694...
Checkpoint 651453694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,477.41543
Policy Entropy: 3.27404
Value Function Loss: 0.00434

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08682
Policy Update Magnitude: 0.56550
Value Function Update Magnitude: 0.63372

Collected Steps per Second: 23,213.88020
Overall Steps per Second: 10,840.19440

Timestep Collection Time: 2.15423
Timestep Consumption Time: 2.45897
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.61320

Cumulative Model Updates: 78,114
Cumulative Timesteps: 651,503,702

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.48146
Policy Entropy: 3.27341
Value Function Loss: 0.00429

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10003
Policy Update Magnitude: 0.55806
Value Function Update Magnitude: 0.63248

Collected Steps per Second: 22,851.22603
Overall Steps per Second: 10,674.92015

Timestep Collection Time: 2.18920
Timestep Consumption Time: 2.49711
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.68631

Cumulative Model Updates: 78,120
Cumulative Timesteps: 651,553,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 651553728...
Checkpoint 651553728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,516.36137
Policy Entropy: 3.26453
Value Function Loss: 0.00426

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10555
Policy Update Magnitude: 0.55617
Value Function Update Magnitude: 0.61848

Collected Steps per Second: 22,832.98781
Overall Steps per Second: 10,697.18707

Timestep Collection Time: 2.19051
Timestep Consumption Time: 2.48511
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.67562

Cumulative Model Updates: 78,126
Cumulative Timesteps: 651,603,744

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649.51150
Policy Entropy: 3.23791
Value Function Loss: 0.00448

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10166
Policy Update Magnitude: 0.56100
Value Function Update Magnitude: 0.60312

Collected Steps per Second: 23,417.02011
Overall Steps per Second: 10,736.71096

Timestep Collection Time: 2.13639
Timestep Consumption Time: 2.52313
PPO Batch Consumption Time: 0.29653
Total Iteration Time: 4.65953

Cumulative Model Updates: 78,132
Cumulative Timesteps: 651,653,772

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 651653772...
Checkpoint 651653772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 980.90016
Policy Entropy: 3.24260
Value Function Loss: 0.00453

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.13210
Policy Update Magnitude: 0.56144
Value Function Update Magnitude: 0.60326

Collected Steps per Second: 21,715.21742
Overall Steps per Second: 10,615.26772

Timestep Collection Time: 2.30373
Timestep Consumption Time: 2.40892
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.71265

Cumulative Model Updates: 78,138
Cumulative Timesteps: 651,703,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.92390
Policy Entropy: 3.24690
Value Function Loss: 0.00462

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.14256
Policy Update Magnitude: 0.56675
Value Function Update Magnitude: 0.61795

Collected Steps per Second: 22,032.08164
Overall Steps per Second: 10,425.39700

Timestep Collection Time: 2.27051
Timestep Consumption Time: 2.52778
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.79828

Cumulative Model Updates: 78,144
Cumulative Timesteps: 651,753,822

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 651753822...
Checkpoint 651753822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 905.06243
Policy Entropy: 3.26931
Value Function Loss: 0.00433

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.15244
Policy Update Magnitude: 0.55932
Value Function Update Magnitude: 0.62986

Collected Steps per Second: 22,490.81784
Overall Steps per Second: 10,645.51835

Timestep Collection Time: 2.22429
Timestep Consumption Time: 2.47497
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.69925

Cumulative Model Updates: 78,150
Cumulative Timesteps: 651,803,848

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665.55197
Policy Entropy: 3.28195
Value Function Loss: 0.00421

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.12184
Policy Update Magnitude: 0.54872
Value Function Update Magnitude: 0.62676

Collected Steps per Second: 22,646.84221
Overall Steps per Second: 10,595.08309

Timestep Collection Time: 2.20905
Timestep Consumption Time: 2.51276
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.72181

Cumulative Model Updates: 78,156
Cumulative Timesteps: 651,853,876

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 651853876...
Checkpoint 651853876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 795.40429
Policy Entropy: 3.28377
Value Function Loss: 0.00407

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10677
Policy Update Magnitude: 0.54247
Value Function Update Magnitude: 0.61972

Collected Steps per Second: 23,152.98788
Overall Steps per Second: 10,620.88512

Timestep Collection Time: 2.16093
Timestep Consumption Time: 2.54979
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.71072

Cumulative Model Updates: 78,162
Cumulative Timesteps: 651,903,908

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 743.26702
Policy Entropy: 3.27384
Value Function Loss: 0.00391

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09838
Policy Update Magnitude: 0.54005
Value Function Update Magnitude: 0.60842

Collected Steps per Second: 22,879.62888
Overall Steps per Second: 10,739.62397

Timestep Collection Time: 2.18640
Timestep Consumption Time: 2.47149
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.65789

Cumulative Model Updates: 78,168
Cumulative Timesteps: 651,953,932

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 651953932...
Checkpoint 651953932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 792.58242
Policy Entropy: 3.28776
Value Function Loss: 0.00397

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09396
Policy Update Magnitude: 0.53644
Value Function Update Magnitude: 0.61234

Collected Steps per Second: 22,844.70574
Overall Steps per Second: 10,710.39702

Timestep Collection Time: 2.18939
Timestep Consumption Time: 2.48046
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.66985

Cumulative Model Updates: 78,174
Cumulative Timesteps: 652,003,948

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 927.09512
Policy Entropy: 3.27736
Value Function Loss: 0.00394

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08664
Policy Update Magnitude: 0.54284
Value Function Update Magnitude: 0.61658

Collected Steps per Second: 22,844.46999
Overall Steps per Second: 10,646.25909

Timestep Collection Time: 2.18906
Timestep Consumption Time: 2.50817
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.69724

Cumulative Model Updates: 78,180
Cumulative Timesteps: 652,053,956

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 652053956...
Checkpoint 652053956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 796.29444
Policy Entropy: 3.26663
Value Function Loss: 0.00425

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09024
Policy Update Magnitude: 0.54800
Value Function Update Magnitude: 0.61125

Collected Steps per Second: 22,914.04467
Overall Steps per Second: 10,768.08671

Timestep Collection Time: 2.18329
Timestep Consumption Time: 2.46266
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.64595

Cumulative Model Updates: 78,186
Cumulative Timesteps: 652,103,984

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 920.66727
Policy Entropy: 3.26774
Value Function Loss: 0.00424

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09134
Policy Update Magnitude: 0.55070
Value Function Update Magnitude: 0.60472

Collected Steps per Second: 22,785.54468
Overall Steps per Second: 10,614.88586

Timestep Collection Time: 2.19472
Timestep Consumption Time: 2.51640
PPO Batch Consumption Time: 0.29674
Total Iteration Time: 4.71112

Cumulative Model Updates: 78,192
Cumulative Timesteps: 652,153,992

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 652153992...
Checkpoint 652153992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617.98100
Policy Entropy: 3.27360
Value Function Loss: 0.00421

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08712
Policy Update Magnitude: 0.54834
Value Function Update Magnitude: 0.60445

Collected Steps per Second: 22,820.00426
Overall Steps per Second: 10,607.56790

Timestep Collection Time: 2.19237
Timestep Consumption Time: 2.52407
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.71644

Cumulative Model Updates: 78,198
Cumulative Timesteps: 652,204,022

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,628.27586
Policy Entropy: 3.28252
Value Function Loss: 0.00427

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08951
Policy Update Magnitude: 0.54745
Value Function Update Magnitude: 0.58687

Collected Steps per Second: 22,763.33012
Overall Steps per Second: 10,633.72508

Timestep Collection Time: 2.19757
Timestep Consumption Time: 2.50671
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.70428

Cumulative Model Updates: 78,204
Cumulative Timesteps: 652,254,046

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 652254046...
Checkpoint 652254046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 762.55971
Policy Entropy: 3.28731
Value Function Loss: 0.00420

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.54852
Value Function Update Magnitude: 0.60400

Collected Steps per Second: 22,354.72879
Overall Steps per Second: 10,526.72788

Timestep Collection Time: 2.23729
Timestep Consumption Time: 2.51385
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.75114

Cumulative Model Updates: 78,210
Cumulative Timesteps: 652,304,060

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.61976
Policy Entropy: 3.28476
Value Function Loss: 0.00421

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09453
Policy Update Magnitude: 0.54814
Value Function Update Magnitude: 0.63897

Collected Steps per Second: 22,078.14916
Overall Steps per Second: 10,408.24269

Timestep Collection Time: 2.26532
Timestep Consumption Time: 2.53991
PPO Batch Consumption Time: 0.29803
Total Iteration Time: 4.80523

Cumulative Model Updates: 78,216
Cumulative Timesteps: 652,354,074

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 652354074...
Checkpoint 652354074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.35769
Policy Entropy: 3.28467
Value Function Loss: 0.00406

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08607
Policy Update Magnitude: 0.54470
Value Function Update Magnitude: 0.64307

Collected Steps per Second: 22,023.91929
Overall Steps per Second: 10,578.50272

Timestep Collection Time: 2.27153
Timestep Consumption Time: 2.45768
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.72921

Cumulative Model Updates: 78,222
Cumulative Timesteps: 652,404,102

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 855.37967
Policy Entropy: 3.28770
Value Function Loss: 0.00416

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08107
Policy Update Magnitude: 0.54342
Value Function Update Magnitude: 0.64180

Collected Steps per Second: 22,083.69159
Overall Steps per Second: 10,511.89538

Timestep Collection Time: 2.26466
Timestep Consumption Time: 2.49300
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.75766

Cumulative Model Updates: 78,228
Cumulative Timesteps: 652,454,114

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 652454114...
Checkpoint 652454114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,582.09169
Policy Entropy: 3.29463
Value Function Loss: 0.00406

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09082
Policy Update Magnitude: 0.53741
Value Function Update Magnitude: 0.63084

Collected Steps per Second: 22,452.61991
Overall Steps per Second: 10,578.62284

Timestep Collection Time: 2.22771
Timestep Consumption Time: 2.50050
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.72821

Cumulative Model Updates: 78,234
Cumulative Timesteps: 652,504,132

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.41101
Policy Entropy: 3.29465
Value Function Loss: 0.00405

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08588
Policy Update Magnitude: 0.53236
Value Function Update Magnitude: 0.62800

Collected Steps per Second: 22,396.89204
Overall Steps per Second: 10,537.36805

Timestep Collection Time: 2.23272
Timestep Consumption Time: 2.51287
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.74559

Cumulative Model Updates: 78,240
Cumulative Timesteps: 652,554,138

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 652554138...
Checkpoint 652554138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 825.26405
Policy Entropy: 3.28723
Value Function Loss: 0.00398

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09773
Policy Update Magnitude: 0.53666
Value Function Update Magnitude: 0.62537

Collected Steps per Second: 22,549.02359
Overall Steps per Second: 10,610.36008

Timestep Collection Time: 2.21766
Timestep Consumption Time: 2.49528
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.71294

Cumulative Model Updates: 78,246
Cumulative Timesteps: 652,604,144

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 826.04025
Policy Entropy: 3.28739
Value Function Loss: 0.00394

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09957
Policy Update Magnitude: 0.53227
Value Function Update Magnitude: 0.60829

Collected Steps per Second: 22,741.07063
Overall Steps per Second: 10,665.40287

Timestep Collection Time: 2.19928
Timestep Consumption Time: 2.49009
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.68937

Cumulative Model Updates: 78,252
Cumulative Timesteps: 652,654,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 652654158...
Checkpoint 652654158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 796.38041
Policy Entropy: 3.27551
Value Function Loss: 0.00405

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08517
Policy Update Magnitude: 0.53259
Value Function Update Magnitude: 0.60322

Collected Steps per Second: 23,019.36829
Overall Steps per Second: 10,844.31728

Timestep Collection Time: 2.17330
Timestep Consumption Time: 2.43999
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.61329

Cumulative Model Updates: 78,258
Cumulative Timesteps: 652,704,186

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754.82718
Policy Entropy: 3.27903
Value Function Loss: 0.00415

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09508
Policy Update Magnitude: 0.53926
Value Function Update Magnitude: 0.61215

Collected Steps per Second: 22,735.91443
Overall Steps per Second: 10,627.80138

Timestep Collection Time: 2.19996
Timestep Consumption Time: 2.50638
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.70634

Cumulative Model Updates: 78,264
Cumulative Timesteps: 652,754,204

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 652754204...
Checkpoint 652754204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 748.47996
Policy Entropy: 3.26396
Value Function Loss: 0.00413

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10398
Policy Update Magnitude: 0.54188
Value Function Update Magnitude: 0.63315

Collected Steps per Second: 22,901.82979
Overall Steps per Second: 10,881.64068

Timestep Collection Time: 2.18393
Timestep Consumption Time: 2.41244
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.59637

Cumulative Model Updates: 78,270
Cumulative Timesteps: 652,804,220

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 947.44923
Policy Entropy: 3.27152
Value Function Loss: 0.00391

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09872
Policy Update Magnitude: 0.54202
Value Function Update Magnitude: 0.63279

Collected Steps per Second: 22,434.39062
Overall Steps per Second: 10,558.12392

Timestep Collection Time: 2.22961
Timestep Consumption Time: 2.50797
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 4.73758

Cumulative Model Updates: 78,276
Cumulative Timesteps: 652,854,240

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 652854240...
Checkpoint 652854240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 929.86780
Policy Entropy: 3.27645
Value Function Loss: 0.00398

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08051
Policy Update Magnitude: 0.54661
Value Function Update Magnitude: 0.61866

Collected Steps per Second: 22,036.67414
Overall Steps per Second: 10,568.73806

Timestep Collection Time: 2.26922
Timestep Consumption Time: 2.46228
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.73150

Cumulative Model Updates: 78,282
Cumulative Timesteps: 652,904,246

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.35699
Policy Entropy: 3.28141
Value Function Loss: 0.00389

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08736
Policy Update Magnitude: 0.53815
Value Function Update Magnitude: 0.60653

Collected Steps per Second: 21,988.73369
Overall Steps per Second: 10,452.70332

Timestep Collection Time: 2.27398
Timestep Consumption Time: 2.50966
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.78364

Cumulative Model Updates: 78,288
Cumulative Timesteps: 652,954,248

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 652954248...
Checkpoint 652954248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.54272
Policy Entropy: 3.28756
Value Function Loss: 0.00397

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.53547
Value Function Update Magnitude: 0.59000

Collected Steps per Second: 22,277.37705
Overall Steps per Second: 10,701.02248

Timestep Collection Time: 2.24443
Timestep Consumption Time: 2.42802
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.67245

Cumulative Model Updates: 78,294
Cumulative Timesteps: 653,004,248

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.95782
Policy Entropy: 3.28870
Value Function Loss: 0.00386

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08676
Policy Update Magnitude: 0.53602
Value Function Update Magnitude: 0.59533

Collected Steps per Second: 22,274.81144
Overall Steps per Second: 10,560.39984

Timestep Collection Time: 2.24478
Timestep Consumption Time: 2.49008
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.73486

Cumulative Model Updates: 78,300
Cumulative Timesteps: 653,054,250

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 653054250...
Checkpoint 653054250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 929.93739
Policy Entropy: 3.29858
Value Function Loss: 0.00382

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08693
Policy Update Magnitude: 0.53512
Value Function Update Magnitude: 0.60918

Collected Steps per Second: 23,036.81289
Overall Steps per Second: 10,692.38791

Timestep Collection Time: 2.17131
Timestep Consumption Time: 2.50679
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.67809

Cumulative Model Updates: 78,306
Cumulative Timesteps: 653,104,270

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.32755
Policy Entropy: 3.29621
Value Function Loss: 0.00387

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.53656
Value Function Update Magnitude: 0.60716

Collected Steps per Second: 22,704.60734
Overall Steps per Second: 10,698.87742

Timestep Collection Time: 2.20220
Timestep Consumption Time: 2.47119
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.67339

Cumulative Model Updates: 78,312
Cumulative Timesteps: 653,154,270

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 653154270...
Checkpoint 653154270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608.16910
Policy Entropy: 3.29062
Value Function Loss: 0.00415

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08805
Policy Update Magnitude: 0.54832
Value Function Update Magnitude: 0.62665

Collected Steps per Second: 22,795.19751
Overall Steps per Second: 10,626.90427

Timestep Collection Time: 2.19397
Timestep Consumption Time: 2.51220
PPO Batch Consumption Time: 0.29647
Total Iteration Time: 4.70617

Cumulative Model Updates: 78,318
Cumulative Timesteps: 653,204,282

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.36915
Policy Entropy: 3.28810
Value Function Loss: 0.00409

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.55446
Value Function Update Magnitude: 0.64474

Collected Steps per Second: 22,605.96126
Overall Steps per Second: 10,645.69010

Timestep Collection Time: 2.21234
Timestep Consumption Time: 2.48553
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.69786

Cumulative Model Updates: 78,324
Cumulative Timesteps: 653,254,294

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 653254294...
Checkpoint 653254294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,639.54366
Policy Entropy: 3.27959
Value Function Loss: 0.00406

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.12728
Policy Update Magnitude: 0.55264
Value Function Update Magnitude: 0.65477

Collected Steps per Second: 22,658.14674
Overall Steps per Second: 10,652.67559

Timestep Collection Time: 2.20786
Timestep Consumption Time: 2.48824
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.69610

Cumulative Model Updates: 78,330
Cumulative Timesteps: 653,304,320

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.93639
Policy Entropy: 3.28868
Value Function Loss: 0.00392

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.13266
Policy Update Magnitude: 0.55353
Value Function Update Magnitude: 0.64985

Collected Steps per Second: 22,758.10156
Overall Steps per Second: 10,717.67752

Timestep Collection Time: 2.19799
Timestep Consumption Time: 2.46926
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.66724

Cumulative Model Updates: 78,336
Cumulative Timesteps: 653,354,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 653354342...
Checkpoint 653354342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,484.27486
Policy Entropy: 3.29014
Value Function Loss: 0.00395

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.14605
Policy Update Magnitude: 0.54994
Value Function Update Magnitude: 0.65445

Collected Steps per Second: 22,728.68799
Overall Steps per Second: 10,667.02892

Timestep Collection Time: 2.20004
Timestep Consumption Time: 2.48768
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.68772

Cumulative Model Updates: 78,342
Cumulative Timesteps: 653,404,346

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,639.30233
Policy Entropy: 3.28878
Value Function Loss: 0.00401

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.14423
Policy Update Magnitude: 0.53818
Value Function Update Magnitude: 0.65646

Collected Steps per Second: 22,553.18259
Overall Steps per Second: 10,656.91872

Timestep Collection Time: 2.21787
Timestep Consumption Time: 2.47580
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.69366

Cumulative Model Updates: 78,348
Cumulative Timesteps: 653,454,366

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 653454366...
Checkpoint 653454366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 931.65037
Policy Entropy: 3.29874
Value Function Loss: 0.00382

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13025
Policy Update Magnitude: 0.52827
Value Function Update Magnitude: 0.63835

Collected Steps per Second: 22,366.67559
Overall Steps per Second: 10,636.56614

Timestep Collection Time: 2.23663
Timestep Consumption Time: 2.46658
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.70321

Cumulative Model Updates: 78,354
Cumulative Timesteps: 653,504,392

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741.98899
Policy Entropy: 3.28656
Value Function Loss: 0.00393

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10283
Policy Update Magnitude: 0.53257
Value Function Update Magnitude: 0.62449

Collected Steps per Second: 22,451.19814
Overall Steps per Second: 10,703.48302

Timestep Collection Time: 2.22723
Timestep Consumption Time: 2.44452
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.67175

Cumulative Model Updates: 78,360
Cumulative Timesteps: 653,554,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 653554396...
Checkpoint 653554396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 886.37981
Policy Entropy: 3.29146
Value Function Loss: 0.00401

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09205
Policy Update Magnitude: 0.54757
Value Function Update Magnitude: 0.63707

Collected Steps per Second: 22,433.88345
Overall Steps per Second: 10,639.32927

Timestep Collection Time: 2.22913
Timestep Consumption Time: 2.47117
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.70030

Cumulative Model Updates: 78,366
Cumulative Timesteps: 653,604,404

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 949.12165
Policy Entropy: 3.29594
Value Function Loss: 0.00398

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08351
Policy Update Magnitude: 0.54760
Value Function Update Magnitude: 0.65009

Collected Steps per Second: 22,703.14750
Overall Steps per Second: 10,768.85311

Timestep Collection Time: 2.20375
Timestep Consumption Time: 2.44224
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.64599

Cumulative Model Updates: 78,372
Cumulative Timesteps: 653,654,436

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 653654436...
Checkpoint 653654436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,621.51405
Policy Entropy: 3.30119
Value Function Loss: 0.00391

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08510
Policy Update Magnitude: 0.54838
Value Function Update Magnitude: 0.62307

Collected Steps per Second: 22,794.74099
Overall Steps per Second: 10,791.38367

Timestep Collection Time: 2.19393
Timestep Consumption Time: 2.44033
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.63425

Cumulative Model Updates: 78,378
Cumulative Timesteps: 653,704,446

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 917.79473
Policy Entropy: 3.28822
Value Function Loss: 0.00407

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07790
Policy Update Magnitude: 0.55417
Value Function Update Magnitude: 0.61572

Collected Steps per Second: 22,846.50765
Overall Steps per Second: 10,840.29262

Timestep Collection Time: 2.18896
Timestep Consumption Time: 2.42439
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.61334

Cumulative Model Updates: 78,384
Cumulative Timesteps: 653,754,456

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 653754456...
Checkpoint 653754456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.22142
Policy Entropy: 3.28357
Value Function Loss: 0.00383

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07495
Policy Update Magnitude: 0.55447
Value Function Update Magnitude: 0.63316

Collected Steps per Second: 22,453.68327
Overall Steps per Second: 10,672.92199

Timestep Collection Time: 2.22761
Timestep Consumption Time: 2.45883
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.68644

Cumulative Model Updates: 78,390
Cumulative Timesteps: 653,804,474

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.14828
Policy Entropy: 3.27763
Value Function Loss: 0.00400

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.07658
Policy Update Magnitude: 0.54861
Value Function Update Magnitude: 0.63515

Collected Steps per Second: 22,848.01013
Overall Steps per Second: 10,956.25715

Timestep Collection Time: 2.18942
Timestep Consumption Time: 2.37637
PPO Batch Consumption Time: 0.28196
Total Iteration Time: 4.56579

Cumulative Model Updates: 78,396
Cumulative Timesteps: 653,854,498

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 653854498...
Checkpoint 653854498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 960.32060
Policy Entropy: 3.29747
Value Function Loss: 0.00403

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07587
Policy Update Magnitude: 0.54989
Value Function Update Magnitude: 0.64030

Collected Steps per Second: 22,087.40303
Overall Steps per Second: 10,599.50537

Timestep Collection Time: 2.26564
Timestep Consumption Time: 2.45553
PPO Batch Consumption Time: 0.29577
Total Iteration Time: 4.72116

Cumulative Model Updates: 78,402
Cumulative Timesteps: 653,904,540

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.15787
Policy Entropy: 3.30332
Value Function Loss: 0.00397

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09624
Policy Update Magnitude: 0.55204
Value Function Update Magnitude: 0.65388

Collected Steps per Second: 21,921.25419
Overall Steps per Second: 10,572.99899

Timestep Collection Time: 2.28117
Timestep Consumption Time: 2.44843
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.72959

Cumulative Model Updates: 78,408
Cumulative Timesteps: 653,954,546

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 653954546...
Checkpoint 653954546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390.04016
Policy Entropy: 3.30700
Value Function Loss: 0.00380

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09549
Policy Update Magnitude: 0.53644
Value Function Update Magnitude: 0.64601

Collected Steps per Second: 21,542.93626
Overall Steps per Second: 10,542.75503

Timestep Collection Time: 2.32197
Timestep Consumption Time: 2.42271
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.74468

Cumulative Model Updates: 78,414
Cumulative Timesteps: 654,004,568

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 932.47906
Policy Entropy: 3.30459
Value Function Loss: 0.00380

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08496
Policy Update Magnitude: 0.52457
Value Function Update Magnitude: 0.61760

Collected Steps per Second: 22,436.86917
Overall Steps per Second: 10,578.20775

Timestep Collection Time: 2.22937
Timestep Consumption Time: 2.49922
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.72859

Cumulative Model Updates: 78,420
Cumulative Timesteps: 654,054,588

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 654054588...
Checkpoint 654054588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.24248
Policy Entropy: 3.29611
Value Function Loss: 0.00374

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08199
Policy Update Magnitude: 0.52552
Value Function Update Magnitude: 0.58999

Collected Steps per Second: 22,450.16225
Overall Steps per Second: 10,573.89233

Timestep Collection Time: 2.22778
Timestep Consumption Time: 2.50217
PPO Batch Consumption Time: 0.29586
Total Iteration Time: 4.72995

Cumulative Model Updates: 78,426
Cumulative Timesteps: 654,104,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.07881
Policy Entropy: 3.29917
Value Function Loss: 0.00390

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07502
Policy Update Magnitude: 0.53237
Value Function Update Magnitude: 0.61771

Collected Steps per Second: 22,307.76077
Overall Steps per Second: 10,534.54543

Timestep Collection Time: 2.24263
Timestep Consumption Time: 2.50632
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.74895

Cumulative Model Updates: 78,432
Cumulative Timesteps: 654,154,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 654154630...
Checkpoint 654154630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.59222
Policy Entropy: 3.27638
Value Function Loss: 0.00383

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08654
Policy Update Magnitude: 0.53479
Value Function Update Magnitude: 0.62273

Collected Steps per Second: 22,552.45430
Overall Steps per Second: 10,619.64638

Timestep Collection Time: 2.21705
Timestep Consumption Time: 2.49120
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.70825

Cumulative Model Updates: 78,438
Cumulative Timesteps: 654,204,630

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 941.12155
Policy Entropy: 3.28144
Value Function Loss: 0.00397

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08892
Policy Update Magnitude: 0.53912
Value Function Update Magnitude: 0.61787

Collected Steps per Second: 22,763.68400
Overall Steps per Second: 10,720.29811

Timestep Collection Time: 2.19718
Timestep Consumption Time: 2.46836
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.66554

Cumulative Model Updates: 78,444
Cumulative Timesteps: 654,254,646

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 654254646...
Checkpoint 654254646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.68961
Policy Entropy: 3.27776
Value Function Loss: 0.00402

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09640
Policy Update Magnitude: 0.54182
Value Function Update Magnitude: 0.62516

Collected Steps per Second: 22,757.75293
Overall Steps per Second: 10,690.46813

Timestep Collection Time: 2.19837
Timestep Consumption Time: 2.48150
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.67987

Cumulative Model Updates: 78,450
Cumulative Timesteps: 654,304,676

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686.93081
Policy Entropy: 3.28598
Value Function Loss: 0.00414

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09088
Policy Update Magnitude: 0.54730
Value Function Update Magnitude: 0.63847

Collected Steps per Second: 22,335.26414
Overall Steps per Second: 10,527.71952

Timestep Collection Time: 2.23915
Timestep Consumption Time: 2.51136
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 4.75051

Cumulative Model Updates: 78,456
Cumulative Timesteps: 654,354,688

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 654354688...
Checkpoint 654354688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 828.12502
Policy Entropy: 3.29652
Value Function Loss: 0.00419

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08928
Policy Update Magnitude: 0.55407
Value Function Update Magnitude: 0.63651

Collected Steps per Second: 22,576.32735
Overall Steps per Second: 10,546.17475

Timestep Collection Time: 2.21551
Timestep Consumption Time: 2.52726
PPO Batch Consumption Time: 0.29705
Total Iteration Time: 4.74276

Cumulative Model Updates: 78,462
Cumulative Timesteps: 654,404,706

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 907.63382
Policy Entropy: 3.29759
Value Function Loss: 0.00419

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08545
Policy Update Magnitude: 0.54947
Value Function Update Magnitude: 0.63518

Collected Steps per Second: 22,889.94160
Overall Steps per Second: 10,689.88886

Timestep Collection Time: 2.18559
Timestep Consumption Time: 2.49435
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.67994

Cumulative Model Updates: 78,468
Cumulative Timesteps: 654,454,734

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 654454734...
Checkpoint 654454734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,086.64042
Policy Entropy: 3.29746
Value Function Loss: 0.00412

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08219
Policy Update Magnitude: 0.54897
Value Function Update Magnitude: 0.65558

Collected Steps per Second: 22,205.18267
Overall Steps per Second: 10,801.25497

Timestep Collection Time: 2.25254
Timestep Consumption Time: 2.37822
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.63076

Cumulative Model Updates: 78,474
Cumulative Timesteps: 654,504,752

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 974.82369
Policy Entropy: 3.28787
Value Function Loss: 0.00402

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08395
Policy Update Magnitude: 0.54888
Value Function Update Magnitude: 0.69361

Collected Steps per Second: 21,794.44693
Overall Steps per Second: 10,566.54416

Timestep Collection Time: 2.29517
Timestep Consumption Time: 2.43883
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.73400

Cumulative Model Updates: 78,480
Cumulative Timesteps: 654,554,774

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 654554774...
Checkpoint 654554774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670.52989
Policy Entropy: 3.29180
Value Function Loss: 0.00375

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07464
Policy Update Magnitude: 0.54037
Value Function Update Magnitude: 0.68715

Collected Steps per Second: 21,527.14237
Overall Steps per Second: 10,657.62877

Timestep Collection Time: 2.32265
Timestep Consumption Time: 2.36883
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.69148

Cumulative Model Updates: 78,486
Cumulative Timesteps: 654,604,774

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 840.44474
Policy Entropy: 3.29566
Value Function Loss: 0.00378

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08207
Policy Update Magnitude: 0.52957
Value Function Update Magnitude: 0.65699

Collected Steps per Second: 21,732.28013
Overall Steps per Second: 10,496.77814

Timestep Collection Time: 2.30266
Timestep Consumption Time: 2.46471
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.76737

Cumulative Model Updates: 78,492
Cumulative Timesteps: 654,654,816

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 654654816...
Checkpoint 654654816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 845.69971
Policy Entropy: 3.29182
Value Function Loss: 0.00383

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08235
Policy Update Magnitude: 0.52945
Value Function Update Magnitude: 0.64707

Collected Steps per Second: 22,192.80284
Overall Steps per Second: 10,547.84121

Timestep Collection Time: 2.25316
Timestep Consumption Time: 2.48752
PPO Batch Consumption Time: 0.29692
Total Iteration Time: 4.74069

Cumulative Model Updates: 78,498
Cumulative Timesteps: 654,704,820

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.25603
Policy Entropy: 3.30506
Value Function Loss: 0.00391

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.07938
Policy Update Magnitude: 0.53988
Value Function Update Magnitude: 0.65256

Collected Steps per Second: 22,134.88437
Overall Steps per Second: 10,619.82338

Timestep Collection Time: 2.25978
Timestep Consumption Time: 2.45028
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.71006

Cumulative Model Updates: 78,504
Cumulative Timesteps: 654,754,840

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 654754840...
Checkpoint 654754840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.00103
Policy Entropy: 3.30090
Value Function Loss: 0.00390

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.53893
Value Function Update Magnitude: 0.64506

Collected Steps per Second: 22,336.41491
Overall Steps per Second: 10,828.91183

Timestep Collection Time: 2.23850
Timestep Consumption Time: 2.37877
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.61727

Cumulative Model Updates: 78,510
Cumulative Timesteps: 654,804,840

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 967.09951
Policy Entropy: 3.30734
Value Function Loss: 0.00390

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08534
Policy Update Magnitude: 0.53368
Value Function Update Magnitude: 0.64441

Collected Steps per Second: 22,260.68528
Overall Steps per Second: 10,670.74039

Timestep Collection Time: 2.24683
Timestep Consumption Time: 2.44038
PPO Batch Consumption Time: 0.29565
Total Iteration Time: 4.68721

Cumulative Model Updates: 78,516
Cumulative Timesteps: 654,854,856

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 654854856...
Checkpoint 654854856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.08998
Policy Entropy: 3.30113
Value Function Loss: 0.00403

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09192
Policy Update Magnitude: 0.53810
Value Function Update Magnitude: 0.65050

Collected Steps per Second: 22,013.23849
Overall Steps per Second: 10,597.59137

Timestep Collection Time: 2.27172
Timestep Consumption Time: 2.44708
PPO Batch Consumption Time: 0.29714
Total Iteration Time: 4.71881

Cumulative Model Updates: 78,522
Cumulative Timesteps: 654,904,864

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 815.77962
Policy Entropy: 3.30436
Value Function Loss: 0.00417

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08530
Policy Update Magnitude: 0.54649
Value Function Update Magnitude: 0.70386

Collected Steps per Second: 22,109.23479
Overall Steps per Second: 10,791.81910

Timestep Collection Time: 2.26295
Timestep Consumption Time: 2.37316
PPO Batch Consumption Time: 0.28230
Total Iteration Time: 4.63610

Cumulative Model Updates: 78,528
Cumulative Timesteps: 654,954,896

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 654954896...
Checkpoint 654954896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 890.23918
Policy Entropy: 3.30052
Value Function Loss: 0.00399

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09576
Policy Update Magnitude: 0.54690
Value Function Update Magnitude: 0.68941

Collected Steps per Second: 22,862.73645
Overall Steps per Second: 10,724.74439

Timestep Collection Time: 2.18740
Timestep Consumption Time: 2.47565
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.66305

Cumulative Model Updates: 78,534
Cumulative Timesteps: 655,004,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 922.98857
Policy Entropy: 3.29350
Value Function Loss: 0.00402

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.53634
Value Function Update Magnitude: 0.66192

Collected Steps per Second: 22,862.16188
Overall Steps per Second: 10,796.30590

Timestep Collection Time: 2.18824
Timestep Consumption Time: 2.44556
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.63381

Cumulative Model Updates: 78,540
Cumulative Timesteps: 655,054,934

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 655054934...
Checkpoint 655054934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 739.13120
Policy Entropy: 3.28777
Value Function Loss: 0.00430

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10604
Policy Update Magnitude: 0.54145
Value Function Update Magnitude: 0.64731

Collected Steps per Second: 22,292.08406
Overall Steps per Second: 10,660.55975

Timestep Collection Time: 2.24367
Timestep Consumption Time: 2.44802
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.69169

Cumulative Model Updates: 78,546
Cumulative Timesteps: 655,104,950

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 998.11379
Policy Entropy: 3.28229
Value Function Loss: 0.00434

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10937
Policy Update Magnitude: 0.55025
Value Function Update Magnitude: 0.66581

Collected Steps per Second: 22,502.16456
Overall Steps per Second: 10,547.00987

Timestep Collection Time: 2.22228
Timestep Consumption Time: 2.51897
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.74125

Cumulative Model Updates: 78,552
Cumulative Timesteps: 655,154,956

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 655154956...
Checkpoint 655154956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.85384
Policy Entropy: 3.29050
Value Function Loss: 0.00414

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09130
Policy Update Magnitude: 0.55058
Value Function Update Magnitude: 0.65470

Collected Steps per Second: 22,182.89341
Overall Steps per Second: 10,636.44660

Timestep Collection Time: 2.25444
Timestep Consumption Time: 2.44732
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.70176

Cumulative Model Updates: 78,558
Cumulative Timesteps: 655,204,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.22621
Policy Entropy: 3.28818
Value Function Loss: 0.00405

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08845
Policy Update Magnitude: 0.54630
Value Function Update Magnitude: 0.66064

Collected Steps per Second: 23,060.78785
Overall Steps per Second: 10,631.50267

Timestep Collection Time: 2.16931
Timestep Consumption Time: 2.53614
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.70545

Cumulative Model Updates: 78,564
Cumulative Timesteps: 655,254,992

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 655254992...
Checkpoint 655254992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 942.05749
Policy Entropy: 3.29096
Value Function Loss: 0.00393

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09561
Policy Update Magnitude: 0.54364
Value Function Update Magnitude: 0.67582

Collected Steps per Second: 22,536.50927
Overall Steps per Second: 10,521.37026

Timestep Collection Time: 2.21880
Timestep Consumption Time: 2.53381
PPO Batch Consumption Time: 0.29770
Total Iteration Time: 4.75261

Cumulative Model Updates: 78,570
Cumulative Timesteps: 655,304,996

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.63568
Policy Entropy: 3.28433
Value Function Loss: 0.00390

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09803
Policy Update Magnitude: 0.54166
Value Function Update Magnitude: 0.65641

Collected Steps per Second: 23,083.37174
Overall Steps per Second: 10,803.98616

Timestep Collection Time: 2.16753
Timestep Consumption Time: 2.46353
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.63107

Cumulative Model Updates: 78,576
Cumulative Timesteps: 655,355,030

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 655355030...
Checkpoint 655355030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.87150
Policy Entropy: 3.28483
Value Function Loss: 0.00398

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11079
Policy Update Magnitude: 0.53773
Value Function Update Magnitude: 0.63475

Collected Steps per Second: 22,932.03915
Overall Steps per Second: 10,745.95665

Timestep Collection Time: 2.18158
Timestep Consumption Time: 2.47394
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.65552

Cumulative Model Updates: 78,582
Cumulative Timesteps: 655,405,058

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 756.71378
Policy Entropy: 3.29069
Value Function Loss: 0.00413

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09947
Policy Update Magnitude: 0.53520
Value Function Update Magnitude: 0.63004

Collected Steps per Second: 23,052.05652
Overall Steps per Second: 10,844.19878

Timestep Collection Time: 2.16961
Timestep Consumption Time: 2.44244
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.61205

Cumulative Model Updates: 78,588
Cumulative Timesteps: 655,455,072

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 655455072...
Checkpoint 655455072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.62684
Policy Entropy: 3.28599
Value Function Loss: 0.00398

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10007
Policy Update Magnitude: 0.53747
Value Function Update Magnitude: 0.61136

Collected Steps per Second: 22,464.49448
Overall Steps per Second: 10,653.79689

Timestep Collection Time: 2.22609
Timestep Consumption Time: 2.46782
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.69391

Cumulative Model Updates: 78,594
Cumulative Timesteps: 655,505,080

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 870.82122
Policy Entropy: 3.28556
Value Function Loss: 0.00395

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08179
Policy Update Magnitude: 0.53633
Value Function Update Magnitude: 0.60739

Collected Steps per Second: 22,276.51243
Overall Steps per Second: 10,521.95674

Timestep Collection Time: 2.24550
Timestep Consumption Time: 2.50855
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.75406

Cumulative Model Updates: 78,600
Cumulative Timesteps: 655,555,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 655555102...
Checkpoint 655555102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669.58291
Policy Entropy: 3.28707
Value Function Loss: 0.00387

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07826
Policy Update Magnitude: 0.53508
Value Function Update Magnitude: 0.60635

Collected Steps per Second: 21,852.76878
Overall Steps per Second: 10,382.99252

Timestep Collection Time: 2.28895
Timestep Consumption Time: 2.52854
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.81749

Cumulative Model Updates: 78,606
Cumulative Timesteps: 655,605,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.03624
Policy Entropy: 3.27602
Value Function Loss: 0.00425

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10863
Policy Update Magnitude: 0.54113
Value Function Update Magnitude: 0.62892

Collected Steps per Second: 22,785.55714
Overall Steps per Second: 10,706.10886

Timestep Collection Time: 2.19472
Timestep Consumption Time: 2.47625
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.67098

Cumulative Model Updates: 78,612
Cumulative Timesteps: 655,655,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 655655130...
Checkpoint 655655130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 824.05445
Policy Entropy: 3.27512
Value Function Loss: 0.00429

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11730
Policy Update Magnitude: 0.55419
Value Function Update Magnitude: 0.64514

Collected Steps per Second: 22,057.37732
Overall Steps per Second: 10,558.46479

Timestep Collection Time: 2.26709
Timestep Consumption Time: 2.46902
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.73611

Cumulative Model Updates: 78,618
Cumulative Timesteps: 655,705,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 881.19431
Policy Entropy: 3.27228
Value Function Loss: 0.00421

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.55824
Value Function Update Magnitude: 0.64613

Collected Steps per Second: 22,634.59191
Overall Steps per Second: 10,532.31622

Timestep Collection Time: 2.20954
Timestep Consumption Time: 2.53889
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.74843

Cumulative Model Updates: 78,624
Cumulative Timesteps: 655,755,148

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 655755148...
Checkpoint 655755148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684.41480
Policy Entropy: 3.28163
Value Function Loss: 0.00431

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09931
Policy Update Magnitude: 0.54921
Value Function Update Magnitude: 0.65611

Collected Steps per Second: 22,714.59074
Overall Steps per Second: 10,651.14371

Timestep Collection Time: 2.20140
Timestep Consumption Time: 2.49330
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.69471

Cumulative Model Updates: 78,630
Cumulative Timesteps: 655,805,152

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.24299
Policy Entropy: 3.28077
Value Function Loss: 0.00421

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09648
Policy Update Magnitude: 0.55116
Value Function Update Magnitude: 0.65667

Collected Steps per Second: 23,052.73927
Overall Steps per Second: 10,818.56237

Timestep Collection Time: 2.16963
Timestep Consumption Time: 2.45353
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.62317

Cumulative Model Updates: 78,636
Cumulative Timesteps: 655,855,168

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 655855168...
Checkpoint 655855168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614.25166
Policy Entropy: 3.29078
Value Function Loss: 0.00426

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10967
Policy Update Magnitude: 0.54530
Value Function Update Magnitude: 0.64485

Collected Steps per Second: 22,347.91659
Overall Steps per Second: 10,655.84252

Timestep Collection Time: 2.23770
Timestep Consumption Time: 2.45531
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.69301

Cumulative Model Updates: 78,642
Cumulative Timesteps: 655,905,176

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 902.50352
Policy Entropy: 3.28588
Value Function Loss: 0.00417

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11544
Policy Update Magnitude: 0.54249
Value Function Update Magnitude: 0.63470

Collected Steps per Second: 22,784.48447
Overall Steps per Second: 10,679.89419

Timestep Collection Time: 2.19535
Timestep Consumption Time: 2.48821
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.68357

Cumulative Model Updates: 78,648
Cumulative Timesteps: 655,955,196

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 655955196...
Checkpoint 655955196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,471.92283
Policy Entropy: 3.29026
Value Function Loss: 0.00393

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10898
Policy Update Magnitude: 0.53201
Value Function Update Magnitude: 0.63453

Collected Steps per Second: 20,925.14622
Overall Steps per Second: 10,308.00754

Timestep Collection Time: 2.38976
Timestep Consumption Time: 2.46142
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.85118

Cumulative Model Updates: 78,654
Cumulative Timesteps: 656,005,202

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,000.05534
Policy Entropy: 3.27340
Value Function Loss: 0.00383

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11035
Policy Update Magnitude: 0.52205
Value Function Update Magnitude: 0.63406

Collected Steps per Second: 21,490.94309
Overall Steps per Second: 10,305.27104

Timestep Collection Time: 2.32721
Timestep Consumption Time: 2.52603
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.85324

Cumulative Model Updates: 78,660
Cumulative Timesteps: 656,055,216

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 656055216...
Checkpoint 656055216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,589.32599
Policy Entropy: 3.26820
Value Function Loss: 0.00388

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09636
Policy Update Magnitude: 0.52304
Value Function Update Magnitude: 0.64796

Collected Steps per Second: 21,515.28118
Overall Steps per Second: 10,451.32146

Timestep Collection Time: 2.32449
Timestep Consumption Time: 2.46074
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.78523

Cumulative Model Updates: 78,666
Cumulative Timesteps: 656,105,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.48086
Policy Entropy: 3.26584
Value Function Loss: 0.00403

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09000
Policy Update Magnitude: 0.53877
Value Function Update Magnitude: 0.63871

Collected Steps per Second: 22,320.76301
Overall Steps per Second: 10,545.35397

Timestep Collection Time: 2.24034
Timestep Consumption Time: 2.50166
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.74199

Cumulative Model Updates: 78,672
Cumulative Timesteps: 656,155,234

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 656155234...
Checkpoint 656155234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.23262
Policy Entropy: 3.27442
Value Function Loss: 0.00420

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10150
Policy Update Magnitude: 0.54587
Value Function Update Magnitude: 0.63952

Collected Steps per Second: 22,243.17734
Overall Steps per Second: 10,650.05042

Timestep Collection Time: 2.24851
Timestep Consumption Time: 2.44762
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.69613

Cumulative Model Updates: 78,678
Cumulative Timesteps: 656,205,248

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,322.53272
Policy Entropy: 3.27679
Value Function Loss: 0.00431

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09159
Policy Update Magnitude: 0.55332
Value Function Update Magnitude: 0.62334

Collected Steps per Second: 22,819.12757
Overall Steps per Second: 10,771.31208

Timestep Collection Time: 2.19202
Timestep Consumption Time: 2.45180
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.64382

Cumulative Model Updates: 78,684
Cumulative Timesteps: 656,255,268

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 656255268...
Checkpoint 656255268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643.81915
Policy Entropy: 3.27089
Value Function Loss: 0.00430

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10073
Policy Update Magnitude: 0.54991
Value Function Update Magnitude: 0.62055

Collected Steps per Second: 22,339.28830
Overall Steps per Second: 10,676.43051

Timestep Collection Time: 2.23893
Timestep Consumption Time: 2.44579
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.68471

Cumulative Model Updates: 78,690
Cumulative Timesteps: 656,305,284

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.54353
Policy Entropy: 3.26443
Value Function Loss: 0.00406

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.54355
Value Function Update Magnitude: 0.62383

Collected Steps per Second: 22,866.09616
Overall Steps per Second: 10,685.23588

Timestep Collection Time: 2.18761
Timestep Consumption Time: 2.49381
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.68141

Cumulative Model Updates: 78,696
Cumulative Timesteps: 656,355,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 656355306...
Checkpoint 656355306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 741.56443
Policy Entropy: 3.27791
Value Function Loss: 0.00405

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09458
Policy Update Magnitude: 0.53578
Value Function Update Magnitude: 0.62277

Collected Steps per Second: 22,383.02907
Overall Steps per Second: 10,605.92687

Timestep Collection Time: 2.23437
Timestep Consumption Time: 2.48111
PPO Batch Consumption Time: 0.29578
Total Iteration Time: 4.71548

Cumulative Model Updates: 78,702
Cumulative Timesteps: 656,405,318

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.40093
Policy Entropy: 3.26685
Value Function Loss: 0.00400

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09128
Policy Update Magnitude: 0.52963
Value Function Update Magnitude: 0.61201

Collected Steps per Second: 22,754.06534
Overall Steps per Second: 10,772.16404

Timestep Collection Time: 2.19811
Timestep Consumption Time: 2.44497
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.64308

Cumulative Model Updates: 78,708
Cumulative Timesteps: 656,455,334

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 656455334...
Checkpoint 656455334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.47245
Policy Entropy: 3.25005
Value Function Loss: 0.00409

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.53387
Value Function Update Magnitude: 0.61754

Collected Steps per Second: 22,435.18635
Overall Steps per Second: 10,679.73618

Timestep Collection Time: 2.22891
Timestep Consumption Time: 2.45342
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.68233

Cumulative Model Updates: 78,714
Cumulative Timesteps: 656,505,340

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 976.03806
Policy Entropy: 3.24373
Value Function Loss: 0.00402

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09327
Policy Update Magnitude: 0.54314
Value Function Update Magnitude: 0.62775

Collected Steps per Second: 22,750.55016
Overall Steps per Second: 10,680.18171

Timestep Collection Time: 2.19819
Timestep Consumption Time: 2.48432
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.68250

Cumulative Model Updates: 78,720
Cumulative Timesteps: 656,555,350

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 656555350...
Checkpoint 656555350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 860.14077
Policy Entropy: 3.25427
Value Function Loss: 0.00397

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08128
Policy Update Magnitude: 0.54460
Value Function Update Magnitude: 0.64505

Collected Steps per Second: 23,016.61227
Overall Steps per Second: 10,894.27995

Timestep Collection Time: 2.17260
Timestep Consumption Time: 2.41751
PPO Batch Consumption Time: 0.28231
Total Iteration Time: 4.59012

Cumulative Model Updates: 78,726
Cumulative Timesteps: 656,605,356

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.33821
Policy Entropy: 3.24862
Value Function Loss: 0.00425

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09041
Policy Update Magnitude: 0.54570
Value Function Update Magnitude: 0.65391

Collected Steps per Second: 22,387.67829
Overall Steps per Second: 10,635.05167

Timestep Collection Time: 2.23444
Timestep Consumption Time: 2.46925
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.70369

Cumulative Model Updates: 78,732
Cumulative Timesteps: 656,655,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 656655380...
Checkpoint 656655380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428.07820
Policy Entropy: 3.26860
Value Function Loss: 0.00414

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09862
Policy Update Magnitude: 0.54785
Value Function Update Magnitude: 0.66172

Collected Steps per Second: 21,834.57303
Overall Steps per Second: 10,499.40134

Timestep Collection Time: 2.29050
Timestep Consumption Time: 2.47282
PPO Batch Consumption Time: 0.29762
Total Iteration Time: 4.76332

Cumulative Model Updates: 78,738
Cumulative Timesteps: 656,705,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.23276
Policy Entropy: 3.26775
Value Function Loss: 0.00412

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.54619
Value Function Update Magnitude: 0.67321

Collected Steps per Second: 21,093.89821
Overall Steps per Second: 10,408.90869

Timestep Collection Time: 2.37159
Timestep Consumption Time: 2.43449
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.80608

Cumulative Model Updates: 78,744
Cumulative Timesteps: 656,755,418

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 656755418...
Checkpoint 656755418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559.32047
Policy Entropy: 3.28083
Value Function Loss: 0.00423

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.54774
Value Function Update Magnitude: 0.67324

Collected Steps per Second: 21,501.43598
Overall Steps per Second: 10,620.39239

Timestep Collection Time: 2.32608
Timestep Consumption Time: 2.38316
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.70924

Cumulative Model Updates: 78,750
Cumulative Timesteps: 656,805,432

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.35957
Policy Entropy: 3.27124
Value Function Loss: 0.00427

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.54959
Value Function Update Magnitude: 0.68009

Collected Steps per Second: 20,322.83823
Overall Steps per Second: 10,080.08816

Timestep Collection Time: 2.46048
Timestep Consumption Time: 2.50019
PPO Batch Consumption Time: 0.29762
Total Iteration Time: 4.96067

Cumulative Model Updates: 78,756
Cumulative Timesteps: 656,855,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 656855436...
Checkpoint 656855436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,366.33915
Policy Entropy: 3.27379
Value Function Loss: 0.00423

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07661
Policy Update Magnitude: 0.54522
Value Function Update Magnitude: 0.68402

Collected Steps per Second: 21,453.63086
Overall Steps per Second: 10,653.85426

Timestep Collection Time: 2.33089
Timestep Consumption Time: 2.36281
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.69370

Cumulative Model Updates: 78,762
Cumulative Timesteps: 656,905,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,879.44174
Policy Entropy: 3.28146
Value Function Loss: 0.00409

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08048
Policy Update Magnitude: 0.54213
Value Function Update Magnitude: 0.68165

Collected Steps per Second: 22,377.25017
Overall Steps per Second: 10,816.31705

Timestep Collection Time: 2.23504
Timestep Consumption Time: 2.38890
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.62394

Cumulative Model Updates: 78,768
Cumulative Timesteps: 656,955,456

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 656955456...
Checkpoint 656955456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 925.76297
Policy Entropy: 3.27662
Value Function Loss: 0.00410

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08592
Policy Update Magnitude: 0.54384
Value Function Update Magnitude: 0.68297

Collected Steps per Second: 22,878.70307
Overall Steps per Second: 10,694.69742

Timestep Collection Time: 2.18561
Timestep Consumption Time: 2.48997
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.67559

Cumulative Model Updates: 78,774
Cumulative Timesteps: 657,005,460

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 962.91420
Policy Entropy: 3.27800
Value Function Loss: 0.00414

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09277
Policy Update Magnitude: 0.54513
Value Function Update Magnitude: 0.65981

Collected Steps per Second: 22,918.63659
Overall Steps per Second: 10,664.49096

Timestep Collection Time: 2.18250
Timestep Consumption Time: 2.50783
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.69033

Cumulative Model Updates: 78,780
Cumulative Timesteps: 657,055,480

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 657055480...
Checkpoint 657055480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,676.66441
Policy Entropy: 3.26379
Value Function Loss: 0.00422

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.54615
Value Function Update Magnitude: 0.65606

Collected Steps per Second: 23,018.40902
Overall Steps per Second: 10,788.86755

Timestep Collection Time: 2.17252
Timestep Consumption Time: 2.46263
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.63515

Cumulative Model Updates: 78,786
Cumulative Timesteps: 657,105,488

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.02146
Policy Entropy: 3.27027
Value Function Loss: 0.00399

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09257
Policy Update Magnitude: 0.54264
Value Function Update Magnitude: 0.63559

Collected Steps per Second: 22,929.20581
Overall Steps per Second: 10,644.88854

Timestep Collection Time: 2.18193
Timestep Consumption Time: 2.51797
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.69991

Cumulative Model Updates: 78,792
Cumulative Timesteps: 657,155,518

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 657155518...
Checkpoint 657155518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608.15854
Policy Entropy: 3.27816
Value Function Loss: 0.00383

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09803
Policy Update Magnitude: 0.53384
Value Function Update Magnitude: 0.61706

Collected Steps per Second: 22,864.18864
Overall Steps per Second: 10,626.24725

Timestep Collection Time: 2.18814
Timestep Consumption Time: 2.52002
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.70815

Cumulative Model Updates: 78,798
Cumulative Timesteps: 657,205,548

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 886.76975
Policy Entropy: 3.28869
Value Function Loss: 0.00375

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07674
Policy Update Magnitude: 0.52845
Value Function Update Magnitude: 0.63138

Collected Steps per Second: 22,521.06790
Overall Steps per Second: 10,704.39748

Timestep Collection Time: 2.22032
Timestep Consumption Time: 2.45103
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.67135

Cumulative Model Updates: 78,804
Cumulative Timesteps: 657,255,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 657255552...
Checkpoint 657255552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.52907
Policy Entropy: 3.29454
Value Function Loss: 0.00381

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09124
Policy Update Magnitude: 0.53284
Value Function Update Magnitude: 0.60750

Collected Steps per Second: 22,126.09067
Overall Steps per Second: 10,614.01225

Timestep Collection Time: 2.26086
Timestep Consumption Time: 2.45215
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.71302

Cumulative Model Updates: 78,810
Cumulative Timesteps: 657,305,576

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 753.03106
Policy Entropy: 3.29616
Value Function Loss: 0.00382

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08267
Policy Update Magnitude: 0.53448
Value Function Update Magnitude: 0.61045

Collected Steps per Second: 22,751.08835
Overall Steps per Second: 10,596.89035

Timestep Collection Time: 2.19814
Timestep Consumption Time: 2.52117
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 4.71931

Cumulative Model Updates: 78,816
Cumulative Timesteps: 657,355,586

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 657355586...
Checkpoint 657355586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.26459
Policy Entropy: 3.28916
Value Function Loss: 0.00409

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08176
Policy Update Magnitude: 0.54234
Value Function Update Magnitude: 0.62094

Collected Steps per Second: 22,268.75893
Overall Steps per Second: 10,666.02793

Timestep Collection Time: 2.24602
Timestep Consumption Time: 2.44326
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.68928

Cumulative Model Updates: 78,822
Cumulative Timesteps: 657,405,602

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.81638
Policy Entropy: 3.28861
Value Function Loss: 0.00398

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08944
Policy Update Magnitude: 0.54974
Value Function Update Magnitude: 0.64020

Collected Steps per Second: 22,854.56881
Overall Steps per Second: 10,758.96953

Timestep Collection Time: 2.18888
Timestep Consumption Time: 2.46082
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.64970

Cumulative Model Updates: 78,828
Cumulative Timesteps: 657,455,628

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 657455628...
Checkpoint 657455628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666.92383
Policy Entropy: 3.27988
Value Function Loss: 0.00401

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09166
Policy Update Magnitude: 0.55115
Value Function Update Magnitude: 0.64578

Collected Steps per Second: 22,220.40589
Overall Steps per Second: 10,438.42970

Timestep Collection Time: 2.25117
Timestep Consumption Time: 2.54093
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.79210

Cumulative Model Updates: 78,834
Cumulative Timesteps: 657,505,650

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.18531
Policy Entropy: 3.29238
Value Function Loss: 0.00390

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08401
Policy Update Magnitude: 0.54664
Value Function Update Magnitude: 0.63630

Collected Steps per Second: 22,806.09422
Overall Steps per Second: 10,695.03373

Timestep Collection Time: 2.19345
Timestep Consumption Time: 2.48386
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.67731

Cumulative Model Updates: 78,840
Cumulative Timesteps: 657,555,674

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 657555674...
Checkpoint 657555674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 868.64313
Policy Entropy: 3.28952
Value Function Loss: 0.00397

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.54213
Value Function Update Magnitude: 0.61642

Collected Steps per Second: 22,809.37628
Overall Steps per Second: 10,770.90403

Timestep Collection Time: 2.19252
Timestep Consumption Time: 2.45054
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.64306

Cumulative Model Updates: 78,846
Cumulative Timesteps: 657,605,684

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.62917
Policy Entropy: 3.29390
Value Function Loss: 0.00378

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.53272
Value Function Update Magnitude: 0.61060

Collected Steps per Second: 22,990.99663
Overall Steps per Second: 10,766.65716

Timestep Collection Time: 2.17529
Timestep Consumption Time: 2.46980
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.64508

Cumulative Model Updates: 78,852
Cumulative Timesteps: 657,655,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 657655696...
Checkpoint 657655696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.10409
Policy Entropy: 3.26475
Value Function Loss: 0.00387

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10762
Policy Update Magnitude: 0.52741
Value Function Update Magnitude: 0.59800

Collected Steps per Second: 22,866.24754
Overall Steps per Second: 10,744.77147

Timestep Collection Time: 2.18663
Timestep Consumption Time: 2.46680
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.65343

Cumulative Model Updates: 78,858
Cumulative Timesteps: 657,705,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 978.32314
Policy Entropy: 3.27345
Value Function Loss: 0.00393

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.52600
Value Function Update Magnitude: 0.60033

Collected Steps per Second: 22,719.28105
Overall Steps per Second: 10,650.04713

Timestep Collection Time: 2.20201
Timestep Consumption Time: 2.49544
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.69744

Cumulative Model Updates: 78,864
Cumulative Timesteps: 657,755,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 657755724...
Checkpoint 657755724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660.04466
Policy Entropy: 3.26463
Value Function Loss: 0.00415

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09585
Policy Update Magnitude: 0.54219
Value Function Update Magnitude: 0.62041

Collected Steps per Second: 22,277.14693
Overall Steps per Second: 10,453.13218

Timestep Collection Time: 2.24562
Timestep Consumption Time: 2.54012
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.78574

Cumulative Model Updates: 78,870
Cumulative Timesteps: 657,805,750

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 859.51372
Policy Entropy: 3.27229
Value Function Loss: 0.00395

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11286
Policy Update Magnitude: 0.54838
Value Function Update Magnitude: 0.65031

Collected Steps per Second: 22,582.90803
Overall Steps per Second: 10,566.05900

Timestep Collection Time: 2.21486
Timestep Consumption Time: 2.51898
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.73384

Cumulative Model Updates: 78,876
Cumulative Timesteps: 657,855,768

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 657855768...
Checkpoint 657855768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.01387
Policy Entropy: 3.28534
Value Function Loss: 0.00381

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.10974
Policy Update Magnitude: 0.54109
Value Function Update Magnitude: 0.64844

Collected Steps per Second: 22,246.44043
Overall Steps per Second: 10,545.40091

Timestep Collection Time: 2.24863
Timestep Consumption Time: 2.49505
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.74368

Cumulative Model Updates: 78,882
Cumulative Timesteps: 657,905,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 758.44843
Policy Entropy: 3.28196
Value Function Loss: 0.00398

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.12007
Policy Update Magnitude: 0.53374
Value Function Update Magnitude: 0.64206

Collected Steps per Second: 22,257.51108
Overall Steps per Second: 10,473.55449

Timestep Collection Time: 2.24805
Timestep Consumption Time: 2.52932
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.77737

Cumulative Model Updates: 78,888
Cumulative Timesteps: 657,955,828

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 657955828...
Checkpoint 657955828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.25393
Policy Entropy: 3.28177
Value Function Loss: 0.00403

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11530
Policy Update Magnitude: 0.53900
Value Function Update Magnitude: 0.64104

Collected Steps per Second: 22,928.75920
Overall Steps per Second: 10,646.86248

Timestep Collection Time: 2.18067
Timestep Consumption Time: 2.51555
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.69622

Cumulative Model Updates: 78,894
Cumulative Timesteps: 658,005,828

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.38895
Policy Entropy: 3.27645
Value Function Loss: 0.00426

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.11746
Policy Update Magnitude: 0.54317
Value Function Update Magnitude: 0.64385

Collected Steps per Second: 22,789.26518
Overall Steps per Second: 10,643.79964

Timestep Collection Time: 2.19481
Timestep Consumption Time: 2.50446
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.69926

Cumulative Model Updates: 78,900
Cumulative Timesteps: 658,055,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 658055846...
Checkpoint 658055846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 921.00511
Policy Entropy: 3.25366
Value Function Loss: 0.00412

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11999
Policy Update Magnitude: 0.55122
Value Function Update Magnitude: 0.63754

Collected Steps per Second: 22,899.69362
Overall Steps per Second: 10,785.79009

Timestep Collection Time: 2.18431
Timestep Consumption Time: 2.45327
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.63758

Cumulative Model Updates: 78,906
Cumulative Timesteps: 658,105,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.32812
Policy Entropy: 3.25810
Value Function Loss: 0.00398

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11734
Policy Update Magnitude: 0.54863
Value Function Update Magnitude: 0.60923

Collected Steps per Second: 22,398.07325
Overall Steps per Second: 10,561.40089

Timestep Collection Time: 2.23332
Timestep Consumption Time: 2.50299
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.73630

Cumulative Model Updates: 78,912
Cumulative Timesteps: 658,155,888

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 658155888...
Checkpoint 658155888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.11580
Policy Entropy: 3.24759
Value Function Loss: 0.00402

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10045
Policy Update Magnitude: 0.54353
Value Function Update Magnitude: 0.59699

Collected Steps per Second: 22,829.82023
Overall Steps per Second: 10,637.80337

Timestep Collection Time: 2.19029
Timestep Consumption Time: 2.51030
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.70059

Cumulative Model Updates: 78,918
Cumulative Timesteps: 658,205,892

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 901.44686
Policy Entropy: 3.26282
Value Function Loss: 0.00419

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08556
Policy Update Magnitude: 0.55050
Value Function Update Magnitude: 0.61157

Collected Steps per Second: 22,459.31018
Overall Steps per Second: 10,554.94569

Timestep Collection Time: 2.22741
Timestep Consumption Time: 2.51217
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.73958

Cumulative Model Updates: 78,924
Cumulative Timesteps: 658,255,918

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 658255918...
Checkpoint 658255918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 966.74501
Policy Entropy: 3.26064
Value Function Loss: 0.00440

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08557
Policy Update Magnitude: 0.56714
Value Function Update Magnitude: 0.61952

Collected Steps per Second: 22,327.51738
Overall Steps per Second: 10,534.34401

Timestep Collection Time: 2.24064
Timestep Consumption Time: 2.50839
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.74904

Cumulative Model Updates: 78,930
Cumulative Timesteps: 658,305,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.01808
Policy Entropy: 3.27003
Value Function Loss: 0.00436

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08951
Policy Update Magnitude: 0.57256
Value Function Update Magnitude: 0.62916

Collected Steps per Second: 22,357.26153
Overall Steps per Second: 10,495.58085

Timestep Collection Time: 2.23775
Timestep Consumption Time: 2.52902
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.76677

Cumulative Model Updates: 78,936
Cumulative Timesteps: 658,355,976

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 658355976...
Checkpoint 658355976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.97203
Policy Entropy: 3.25832
Value Function Loss: 0.00405

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09311
Policy Update Magnitude: 0.56292
Value Function Update Magnitude: 0.64612

Collected Steps per Second: 22,402.43718
Overall Steps per Second: 10,603.23322

Timestep Collection Time: 2.23235
Timestep Consumption Time: 2.48414
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.71649

Cumulative Model Updates: 78,942
Cumulative Timesteps: 658,405,986

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 931.07964
Policy Entropy: 3.25835
Value Function Loss: 0.00385

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11609
Policy Update Magnitude: 0.55292
Value Function Update Magnitude: 0.66404

Collected Steps per Second: 22,334.01189
Overall Steps per Second: 10,463.20032

Timestep Collection Time: 2.23883
Timestep Consumption Time: 2.54002
PPO Batch Consumption Time: 0.29736
Total Iteration Time: 4.77884

Cumulative Model Updates: 78,948
Cumulative Timesteps: 658,455,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 658455988...
Checkpoint 658455988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 994.85857
Policy Entropy: 3.25625
Value Function Loss: 0.00410

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11574
Policy Update Magnitude: 0.54330
Value Function Update Magnitude: 0.66650

Collected Steps per Second: 22,780.63488
Overall Steps per Second: 10,639.25197

Timestep Collection Time: 2.19546
Timestep Consumption Time: 2.50543
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.70089

Cumulative Model Updates: 78,954
Cumulative Timesteps: 658,506,002

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.90871
Policy Entropy: 3.24876
Value Function Loss: 0.00431

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11209
Policy Update Magnitude: 0.55940
Value Function Update Magnitude: 0.69116

Collected Steps per Second: 23,030.84354
Overall Steps per Second: 10,803.47310

Timestep Collection Time: 2.17170
Timestep Consumption Time: 2.45793
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.62962

Cumulative Model Updates: 78,960
Cumulative Timesteps: 658,556,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 658556018...
Checkpoint 658556018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 978.93820
Policy Entropy: 3.23753
Value Function Loss: 0.00452

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12198
Policy Update Magnitude: 0.56537
Value Function Update Magnitude: 0.70051

Collected Steps per Second: 22,582.71998
Overall Steps per Second: 10,719.86588

Timestep Collection Time: 2.21426
Timestep Consumption Time: 2.45035
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.66461

Cumulative Model Updates: 78,966
Cumulative Timesteps: 658,606,022

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.92431
Policy Entropy: 3.23665
Value Function Loss: 0.00447

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10904
Policy Update Magnitude: 0.56371
Value Function Update Magnitude: 0.69770

Collected Steps per Second: 22,801.26878
Overall Steps per Second: 10,600.45662

Timestep Collection Time: 2.19391
Timestep Consumption Time: 2.52513
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.71904

Cumulative Model Updates: 78,972
Cumulative Timesteps: 658,656,046

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 658656046...
Checkpoint 658656046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.67657
Policy Entropy: 3.24777
Value Function Loss: 0.00425

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10048
Policy Update Magnitude: 0.55911
Value Function Update Magnitude: 0.68283

Collected Steps per Second: 22,853.40483
Overall Steps per Second: 10,650.26524

Timestep Collection Time: 2.18908
Timestep Consumption Time: 2.50826
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.69735

Cumulative Model Updates: 78,978
Cumulative Timesteps: 658,706,074

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.80396
Policy Entropy: 3.24446
Value Function Loss: 0.00396

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10073
Policy Update Magnitude: 0.54652
Value Function Update Magnitude: 0.66910

Collected Steps per Second: 22,792.96486
Overall Steps per Second: 10,702.26328

Timestep Collection Time: 2.19436
Timestep Consumption Time: 2.47904
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.67340

Cumulative Model Updates: 78,984
Cumulative Timesteps: 658,756,090

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 658756090...
Checkpoint 658756090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649.26151
Policy Entropy: 3.23739
Value Function Loss: 0.00389

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09907
Policy Update Magnitude: 0.53323
Value Function Update Magnitude: 0.65054

Collected Steps per Second: 22,834.56847
Overall Steps per Second: 10,720.90672

Timestep Collection Time: 2.19080
Timestep Consumption Time: 2.47541
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.66621

Cumulative Model Updates: 78,990
Cumulative Timesteps: 658,806,116

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.39355
Policy Entropy: 3.24294
Value Function Loss: 0.00406

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09370
Policy Update Magnitude: 0.53698
Value Function Update Magnitude: 0.64370

Collected Steps per Second: 22,148.08719
Overall Steps per Second: 10,433.12817

Timestep Collection Time: 2.25771
Timestep Consumption Time: 2.53510
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.79281

Cumulative Model Updates: 78,996
Cumulative Timesteps: 658,856,120

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 658856120...
Checkpoint 658856120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.56665
Policy Entropy: 3.24593
Value Function Loss: 0.00452

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.55668
Value Function Update Magnitude: 0.66185

Collected Steps per Second: 22,256.30415
Overall Steps per Second: 10,581.26232

Timestep Collection Time: 2.24700
Timestep Consumption Time: 2.47928
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.72628

Cumulative Model Updates: 79,002
Cumulative Timesteps: 658,906,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.51918
Policy Entropy: 3.24926
Value Function Loss: 0.00431

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10390
Policy Update Magnitude: 0.55712
Value Function Update Magnitude: 0.68427

Collected Steps per Second: 22,239.26268
Overall Steps per Second: 10,574.88123

Timestep Collection Time: 2.24864
Timestep Consumption Time: 2.48031
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.72894

Cumulative Model Updates: 79,008
Cumulative Timesteps: 658,956,138

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 658956138...
Checkpoint 658956138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 802.56539
Policy Entropy: 3.23741
Value Function Loss: 0.00411

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.55154
Value Function Update Magnitude: 0.67486

Collected Steps per Second: 22,575.93525
Overall Steps per Second: 10,610.48947

Timestep Collection Time: 2.21537
Timestep Consumption Time: 2.49827
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.71364

Cumulative Model Updates: 79,014
Cumulative Timesteps: 659,006,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.28574
Policy Entropy: 3.25058
Value Function Loss: 0.00372

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07991
Policy Update Magnitude: 0.54018
Value Function Update Magnitude: 0.64252

Collected Steps per Second: 22,488.57869
Overall Steps per Second: 10,559.20491

Timestep Collection Time: 2.22433
Timestep Consumption Time: 2.51296
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.73729

Cumulative Model Updates: 79,020
Cumulative Timesteps: 659,056,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 659056174...
Checkpoint 659056174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.58522
Policy Entropy: 3.24311
Value Function Loss: 0.00385

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.07980
Policy Update Magnitude: 0.53222
Value Function Update Magnitude: 0.63283

Collected Steps per Second: 22,462.34496
Overall Steps per Second: 10,508.36584

Timestep Collection Time: 2.22648
Timestep Consumption Time: 2.53277
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.75926

Cumulative Model Updates: 79,026
Cumulative Timesteps: 659,106,186

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 893.24434
Policy Entropy: 3.24896
Value Function Loss: 0.00395

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09092
Policy Update Magnitude: 0.54031
Value Function Update Magnitude: 0.63664

Collected Steps per Second: 22,790.32712
Overall Steps per Second: 10,839.79176

Timestep Collection Time: 2.19497
Timestep Consumption Time: 2.41988
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.61485

Cumulative Model Updates: 79,032
Cumulative Timesteps: 659,156,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 659156210...
Checkpoint 659156210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 999.56812
Policy Entropy: 3.25190
Value Function Loss: 0.00409

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09628
Policy Update Magnitude: 0.54203
Value Function Update Magnitude: 0.63535

Collected Steps per Second: 22,666.49240
Overall Steps per Second: 10,754.48348

Timestep Collection Time: 2.20661
Timestep Consumption Time: 2.44411
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.65071

Cumulative Model Updates: 79,038
Cumulative Timesteps: 659,206,226

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 834.24464
Policy Entropy: 3.26243
Value Function Loss: 0.00414

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.54741
Value Function Update Magnitude: 0.63868

Collected Steps per Second: 22,782.82550
Overall Steps per Second: 10,793.39431

Timestep Collection Time: 2.19586
Timestep Consumption Time: 2.43919
PPO Batch Consumption Time: 0.28468
Total Iteration Time: 4.63506

Cumulative Model Updates: 79,044
Cumulative Timesteps: 659,256,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 659256254...
Checkpoint 659256254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 859.64724
Policy Entropy: 3.24994
Value Function Loss: 0.00421

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.54469
Value Function Update Magnitude: 0.63933

Collected Steps per Second: 22,917.49331
Overall Steps per Second: 10,721.23707

Timestep Collection Time: 2.18226
Timestep Consumption Time: 2.48250
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.66476

Cumulative Model Updates: 79,050
Cumulative Timesteps: 659,306,266

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.12844
Policy Entropy: 3.25748
Value Function Loss: 0.00421

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08836
Policy Update Magnitude: 0.54735
Value Function Update Magnitude: 0.64244

Collected Steps per Second: 22,868.54924
Overall Steps per Second: 10,834.67043

Timestep Collection Time: 2.18685
Timestep Consumption Time: 2.42889
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.61574

Cumulative Model Updates: 79,056
Cumulative Timesteps: 659,356,276

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 659356276...
Checkpoint 659356276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525.89014
Policy Entropy: 3.23804
Value Function Loss: 0.00422

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10419
Policy Update Magnitude: 0.54714
Value Function Update Magnitude: 0.63097

Collected Steps per Second: 22,450.34796
Overall Steps per Second: 10,744.36399

Timestep Collection Time: 2.22758
Timestep Consumption Time: 2.42695
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.65453

Cumulative Model Updates: 79,062
Cumulative Timesteps: 659,406,286

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507.92518
Policy Entropy: 3.23231
Value Function Loss: 0.00408

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09913
Policy Update Magnitude: 0.54249
Value Function Update Magnitude: 0.60859

Collected Steps per Second: 22,067.35892
Overall Steps per Second: 10,457.30491

Timestep Collection Time: 2.26651
Timestep Consumption Time: 2.51636
PPO Batch Consumption Time: 0.29678
Total Iteration Time: 4.78288

Cumulative Model Updates: 79,068
Cumulative Timesteps: 659,456,302

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 659456302...
Checkpoint 659456302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 990.68292
Policy Entropy: 3.23097
Value Function Loss: 0.00398

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09813
Policy Update Magnitude: 0.53875
Value Function Update Magnitude: 0.59385

Collected Steps per Second: 22,411.57170
Overall Steps per Second: 10,610.40960

Timestep Collection Time: 2.23135
Timestep Consumption Time: 2.48176
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.71311

Cumulative Model Updates: 79,074
Cumulative Timesteps: 659,506,310

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707.00981
Policy Entropy: 3.24940
Value Function Loss: 0.00388

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.53459
Value Function Update Magnitude: 0.60859

Collected Steps per Second: 22,418.22339
Overall Steps per Second: 10,600.70274

Timestep Collection Time: 2.23042
Timestep Consumption Time: 2.48644
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.71686

Cumulative Model Updates: 79,080
Cumulative Timesteps: 659,556,312

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 659556312...
Checkpoint 659556312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 979.07781
Policy Entropy: 3.23478
Value Function Loss: 0.00381

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08035
Policy Update Magnitude: 0.53676
Value Function Update Magnitude: 0.60976

Collected Steps per Second: 22,613.24001
Overall Steps per Second: 10,608.86410

Timestep Collection Time: 2.21224
Timestep Consumption Time: 2.50325
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.71549

Cumulative Model Updates: 79,086
Cumulative Timesteps: 659,606,338

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.59069
Policy Entropy: 3.23738
Value Function Loss: 0.00386

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08777
Policy Update Magnitude: 0.54108
Value Function Update Magnitude: 0.60514

Collected Steps per Second: 22,900.17139
Overall Steps per Second: 10,761.59612

Timestep Collection Time: 2.18444
Timestep Consumption Time: 2.46394
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.64838

Cumulative Model Updates: 79,092
Cumulative Timesteps: 659,656,362

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 659656362...
Checkpoint 659656362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.77917
Policy Entropy: 3.24473
Value Function Loss: 0.00411

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10626
Policy Update Magnitude: 0.54128
Value Function Update Magnitude: 0.61532

Collected Steps per Second: 22,793.07370
Overall Steps per Second: 10,659.59580

Timestep Collection Time: 2.19374
Timestep Consumption Time: 2.49706
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.69080

Cumulative Model Updates: 79,098
Cumulative Timesteps: 659,706,364

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 901.08326
Policy Entropy: 3.25168
Value Function Loss: 0.00426

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11186
Policy Update Magnitude: 0.55034
Value Function Update Magnitude: 0.63838

Collected Steps per Second: 22,758.09674
Overall Steps per Second: 10,815.36867

Timestep Collection Time: 2.19737
Timestep Consumption Time: 2.42642
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.62379

Cumulative Model Updates: 79,104
Cumulative Timesteps: 659,756,372

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 659756372...
Checkpoint 659756372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662.04808
Policy Entropy: 3.24796
Value Function Loss: 0.00441

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11431
Policy Update Magnitude: 0.55740
Value Function Update Magnitude: 0.64859

Collected Steps per Second: 22,912.60778
Overall Steps per Second: 10,854.08455

Timestep Collection Time: 2.18282
Timestep Consumption Time: 2.42503
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.60785

Cumulative Model Updates: 79,110
Cumulative Timesteps: 659,806,386

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.93926
Policy Entropy: 3.25156
Value Function Loss: 0.00437

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11605
Policy Update Magnitude: 0.55888
Value Function Update Magnitude: 0.64982

Collected Steps per Second: 21,996.64054
Overall Steps per Second: 10,713.65241

Timestep Collection Time: 2.27317
Timestep Consumption Time: 2.39396
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.66713

Cumulative Model Updates: 79,116
Cumulative Timesteps: 659,856,388

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 659856388...
Checkpoint 659856388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 921.62539
Policy Entropy: 3.25648
Value Function Loss: 0.00434

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10014
Policy Update Magnitude: 0.55197
Value Function Update Magnitude: 0.63284

Collected Steps per Second: 22,319.58665
Overall Steps per Second: 10,727.13972

Timestep Collection Time: 2.24072
Timestep Consumption Time: 2.42147
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.66219

Cumulative Model Updates: 79,122
Cumulative Timesteps: 659,906,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 986.73384
Policy Entropy: 3.25723
Value Function Loss: 0.00430

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09780
Policy Update Magnitude: 0.55197
Value Function Update Magnitude: 0.61583

Collected Steps per Second: 21,465.57870
Overall Steps per Second: 10,401.84339

Timestep Collection Time: 2.32931
Timestep Consumption Time: 2.47753
PPO Batch Consumption Time: 0.29843
Total Iteration Time: 4.80684

Cumulative Model Updates: 79,128
Cumulative Timesteps: 659,956,400

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 659956400...
Checkpoint 659956400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.63797
Policy Entropy: 3.26139
Value Function Loss: 0.00430

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09863
Policy Update Magnitude: 0.54718
Value Function Update Magnitude: 0.60819

Collected Steps per Second: 21,686.43744
Overall Steps per Second: 10,696.02078

Timestep Collection Time: 2.30651
Timestep Consumption Time: 2.36999
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.67651

Cumulative Model Updates: 79,134
Cumulative Timesteps: 660,006,420

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.12980
Policy Entropy: 3.26754
Value Function Loss: 0.00440

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08841
Policy Update Magnitude: 0.55231
Value Function Update Magnitude: 0.62435

Collected Steps per Second: 22,322.66120
Overall Steps per Second: 10,508.52462

Timestep Collection Time: 2.24006
Timestep Consumption Time: 2.51837
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.75842

Cumulative Model Updates: 79,140
Cumulative Timesteps: 660,056,424

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 660056424...
Checkpoint 660056424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,145.06580
Policy Entropy: 3.26050
Value Function Loss: 0.00455

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10227
Policy Update Magnitude: 0.55624
Value Function Update Magnitude: 0.64897

Collected Steps per Second: 22,056.58129
Overall Steps per Second: 10,602.29048

Timestep Collection Time: 2.26762
Timestep Consumption Time: 2.44985
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.71747

Cumulative Model Updates: 79,146
Cumulative Timesteps: 660,106,440

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.98884
Policy Entropy: 3.25599
Value Function Loss: 0.00444

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09200
Policy Update Magnitude: 0.55912
Value Function Update Magnitude: 0.63453

Collected Steps per Second: 22,173.38533
Overall Steps per Second: 10,627.06818

Timestep Collection Time: 2.25631
Timestep Consumption Time: 2.45148
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.70779

Cumulative Model Updates: 79,152
Cumulative Timesteps: 660,156,470

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 660156470...
Checkpoint 660156470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.62265
Policy Entropy: 3.26745
Value Function Loss: 0.00437

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09259
Policy Update Magnitude: 0.55785
Value Function Update Magnitude: 0.60285

Collected Steps per Second: 22,859.69677
Overall Steps per Second: 10,793.83751

Timestep Collection Time: 2.18734
Timestep Consumption Time: 2.44511
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.63246

Cumulative Model Updates: 79,158
Cumulative Timesteps: 660,206,472

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.38868
Policy Entropy: 3.26985
Value Function Loss: 0.00442

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09814
Policy Update Magnitude: 0.54868
Value Function Update Magnitude: 0.60113

Collected Steps per Second: 23,006.49189
Overall Steps per Second: 10,671.41103

Timestep Collection Time: 2.17434
Timestep Consumption Time: 2.51332
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.68767

Cumulative Model Updates: 79,164
Cumulative Timesteps: 660,256,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 660256496...
Checkpoint 660256496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421.78285
Policy Entropy: 3.26396
Value Function Loss: 0.00431

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09975
Policy Update Magnitude: 0.55151
Value Function Update Magnitude: 0.62581

Collected Steps per Second: 22,964.38679
Overall Steps per Second: 10,667.96381

Timestep Collection Time: 2.17781
Timestep Consumption Time: 2.51025
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.68805

Cumulative Model Updates: 79,170
Cumulative Timesteps: 660,306,508

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.69356
Policy Entropy: 3.26209
Value Function Loss: 0.00454

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.55188
Value Function Update Magnitude: 0.63876

Collected Steps per Second: 23,159.56283
Overall Steps per Second: 10,786.14275

Timestep Collection Time: 2.15954
Timestep Consumption Time: 2.47734
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.63688

Cumulative Model Updates: 79,176
Cumulative Timesteps: 660,356,522

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 660356522...
Checkpoint 660356522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.90745
Policy Entropy: 3.26424
Value Function Loss: 0.00461

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10411
Policy Update Magnitude: 0.55480
Value Function Update Magnitude: 0.63135

Collected Steps per Second: 22,953.47223
Overall Steps per Second: 10,666.30147

Timestep Collection Time: 2.17841
Timestep Consumption Time: 2.50944
PPO Batch Consumption Time: 0.29623
Total Iteration Time: 4.68785

Cumulative Model Updates: 79,182
Cumulative Timesteps: 660,406,524

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 860.65762
Policy Entropy: 3.26672
Value Function Loss: 0.00449

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08498
Policy Update Magnitude: 0.55746
Value Function Update Magnitude: 0.63961

Collected Steps per Second: 22,224.03958
Overall Steps per Second: 10,457.52629

Timestep Collection Time: 2.24991
Timestep Consumption Time: 2.53153
PPO Batch Consumption Time: 0.29698
Total Iteration Time: 4.78144

Cumulative Model Updates: 79,188
Cumulative Timesteps: 660,456,526

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 660456526...
Checkpoint 660456526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.57720
Policy Entropy: 3.26959
Value Function Loss: 0.00427

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09210
Policy Update Magnitude: 0.55808
Value Function Update Magnitude: 0.63637

Collected Steps per Second: 22,154.22442
Overall Steps per Second: 10,637.35707

Timestep Collection Time: 2.25808
Timestep Consumption Time: 2.44478
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.70286

Cumulative Model Updates: 79,194
Cumulative Timesteps: 660,506,552

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.92726
Policy Entropy: 3.27140
Value Function Loss: 0.00408

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08979
Policy Update Magnitude: 0.54200
Value Function Update Magnitude: 0.61067

Collected Steps per Second: 22,520.00210
Overall Steps per Second: 10,554.80314

Timestep Collection Time: 2.22149
Timestep Consumption Time: 2.51834
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.73983

Cumulative Model Updates: 79,200
Cumulative Timesteps: 660,556,580

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 660556580...
Checkpoint 660556580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 827.60624
Policy Entropy: 3.27032
Value Function Loss: 0.00419

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09970
Policy Update Magnitude: 0.53276
Value Function Update Magnitude: 0.60286

Collected Steps per Second: 22,722.84163
Overall Steps per Second: 10,600.50269

Timestep Collection Time: 2.20087
Timestep Consumption Time: 2.51683
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.71770

Cumulative Model Updates: 79,206
Cumulative Timesteps: 660,606,590

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.39500
Policy Entropy: 3.27371
Value Function Loss: 0.00417

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09838
Policy Update Magnitude: 0.53800
Value Function Update Magnitude: 0.62493

Collected Steps per Second: 22,825.93408
Overall Steps per Second: 10,723.02466

Timestep Collection Time: 2.19067
Timestep Consumption Time: 2.47257
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.66324

Cumulative Model Updates: 79,212
Cumulative Timesteps: 660,656,594

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 660656594...
Checkpoint 660656594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,427.13803
Policy Entropy: 3.27870
Value Function Loss: 0.00395

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10494
Policy Update Magnitude: 0.53897
Value Function Update Magnitude: 0.65404

Collected Steps per Second: 22,452.92430
Overall Steps per Second: 10,677.42518

Timestep Collection Time: 2.22768
Timestep Consumption Time: 2.45678
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.68446

Cumulative Model Updates: 79,218
Cumulative Timesteps: 660,706,612

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.07293
Policy Entropy: 3.28384
Value Function Loss: 0.00385

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.52725
Value Function Update Magnitude: 0.64161

Collected Steps per Second: 22,845.44476
Overall Steps per Second: 10,646.18826

Timestep Collection Time: 2.18976
Timestep Consumption Time: 2.50920
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 4.69896

Cumulative Model Updates: 79,224
Cumulative Timesteps: 660,756,638

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 660756638...
Checkpoint 660756638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 887.04874
Policy Entropy: 3.29371
Value Function Loss: 0.00381

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08908
Policy Update Magnitude: 0.52243
Value Function Update Magnitude: 0.62212

Collected Steps per Second: 22,804.31624
Overall Steps per Second: 10,700.51738

Timestep Collection Time: 2.19309
Timestep Consumption Time: 2.48070
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.67379

Cumulative Model Updates: 79,230
Cumulative Timesteps: 660,806,650

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.66540
Policy Entropy: 3.28253
Value Function Loss: 0.00391

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08426
Policy Update Magnitude: 0.52502
Value Function Update Magnitude: 0.62442

Collected Steps per Second: 22,952.68412
Overall Steps per Second: 10,684.66058

Timestep Collection Time: 2.17970
Timestep Consumption Time: 2.50271
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.68241

Cumulative Model Updates: 79,236
Cumulative Timesteps: 660,856,680

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 660856680...
Checkpoint 660856680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 782.00836
Policy Entropy: 3.28146
Value Function Loss: 0.00378

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08031
Policy Update Magnitude: 0.53074
Value Function Update Magnitude: 0.63970

Collected Steps per Second: 22,445.01443
Overall Steps per Second: 10,657.72477

Timestep Collection Time: 2.22900
Timestep Consumption Time: 2.46524
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.69425

Cumulative Model Updates: 79,242
Cumulative Timesteps: 660,906,710

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 879.63565
Policy Entropy: 3.26640
Value Function Loss: 0.00402

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08384
Policy Update Magnitude: 0.53966
Value Function Update Magnitude: 0.62836

Collected Steps per Second: 22,447.62177
Overall Steps per Second: 10,645.71877

Timestep Collection Time: 2.22865
Timestep Consumption Time: 2.47070
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.69935

Cumulative Model Updates: 79,248
Cumulative Timesteps: 660,956,738

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 660956738...
Checkpoint 660956738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.90235
Policy Entropy: 3.26912
Value Function Loss: 0.00422

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08014
Policy Update Magnitude: 0.55942
Value Function Update Magnitude: 0.63030

Collected Steps per Second: 22,389.17170
Overall Steps per Second: 10,585.80494

Timestep Collection Time: 2.23412
Timestep Consumption Time: 2.49108
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.72520

Cumulative Model Updates: 79,254
Cumulative Timesteps: 661,006,758

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788.67256
Policy Entropy: 3.26916
Value Function Loss: 0.00418

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08446
Policy Update Magnitude: 0.56448
Value Function Update Magnitude: 0.65227

Collected Steps per Second: 22,531.13535
Overall Steps per Second: 10,715.40102

Timestep Collection Time: 2.22039
Timestep Consumption Time: 2.44840
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.66879

Cumulative Model Updates: 79,260
Cumulative Timesteps: 661,056,786

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 661056786...
Checkpoint 661056786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.47587
Policy Entropy: 3.26592
Value Function Loss: 0.00397

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08757
Policy Update Magnitude: 0.55520
Value Function Update Magnitude: 0.63803

Collected Steps per Second: 22,513.39166
Overall Steps per Second: 10,730.49327

Timestep Collection Time: 2.22170
Timestep Consumption Time: 2.43960
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.66130

Cumulative Model Updates: 79,266
Cumulative Timesteps: 661,106,804

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 939.98665
Policy Entropy: 3.27225
Value Function Loss: 0.00401

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08282
Policy Update Magnitude: 0.54821
Value Function Update Magnitude: 0.63173

Collected Steps per Second: 22,878.21126
Overall Steps per Second: 10,812.19877

Timestep Collection Time: 2.18618
Timestep Consumption Time: 2.43970
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.62589

Cumulative Model Updates: 79,272
Cumulative Timesteps: 661,156,820

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 661156820...
Checkpoint 661156820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 797.50492
Policy Entropy: 3.24765
Value Function Loss: 0.00423

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10112
Policy Update Magnitude: 0.55520
Value Function Update Magnitude: 0.63687

Collected Steps per Second: 22,849.13129
Overall Steps per Second: 10,692.00706

Timestep Collection Time: 2.18940
Timestep Consumption Time: 2.48942
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.67882

Cumulative Model Updates: 79,278
Cumulative Timesteps: 661,206,846

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 831.28641
Policy Entropy: 3.24531
Value Function Loss: 0.00426

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11211
Policy Update Magnitude: 0.55069
Value Function Update Magnitude: 0.65633

Collected Steps per Second: 22,744.27587
Overall Steps per Second: 10,801.56739

Timestep Collection Time: 2.19906
Timestep Consumption Time: 2.43138
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 4.63044

Cumulative Model Updates: 79,284
Cumulative Timesteps: 661,256,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 661256862...
Checkpoint 661256862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 814.47441
Policy Entropy: 3.23212
Value Function Loss: 0.00434

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10414
Policy Update Magnitude: 0.55200
Value Function Update Magnitude: 0.66061

Collected Steps per Second: 22,802.25331
Overall Steps per Second: 10,745.06094

Timestep Collection Time: 2.19320
Timestep Consumption Time: 2.46103
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.65423

Cumulative Model Updates: 79,290
Cumulative Timesteps: 661,306,872

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 844.39837
Policy Entropy: 3.25008
Value Function Loss: 0.00446

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10407
Policy Update Magnitude: 0.56136
Value Function Update Magnitude: 0.66244

Collected Steps per Second: 22,934.77620
Overall Steps per Second: 10,919.55222

Timestep Collection Time: 2.18018
Timestep Consumption Time: 2.39894
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.57913

Cumulative Model Updates: 79,296
Cumulative Timesteps: 661,356,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 661356874...
Checkpoint 661356874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.28518
Policy Entropy: 3.24095
Value Function Loss: 0.00442

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10772
Policy Update Magnitude: 0.56549
Value Function Update Magnitude: 0.67812

Collected Steps per Second: 22,005.39541
Overall Steps per Second: 10,647.50927

Timestep Collection Time: 2.27308
Timestep Consumption Time: 2.42473
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.69781

Cumulative Model Updates: 79,302
Cumulative Timesteps: 661,406,894

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.48295
Policy Entropy: 3.25273
Value Function Loss: 0.00435

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11208
Policy Update Magnitude: 0.56089
Value Function Update Magnitude: 0.69392

Collected Steps per Second: 21,752.53084
Overall Steps per Second: 10,532.38780

Timestep Collection Time: 2.29941
Timestep Consumption Time: 2.44956
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.74897

Cumulative Model Updates: 79,308
Cumulative Timesteps: 661,456,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 661456912...
Checkpoint 661456912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421.47521
Policy Entropy: 3.24989
Value Function Loss: 0.00398

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10023
Policy Update Magnitude: 0.55340
Value Function Update Magnitude: 0.67657

Collected Steps per Second: 21,772.33777
Overall Steps per Second: 10,531.02198

Timestep Collection Time: 2.29723
Timestep Consumption Time: 2.45217
PPO Batch Consumption Time: 0.29670
Total Iteration Time: 4.74940

Cumulative Model Updates: 79,314
Cumulative Timesteps: 661,506,928

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.67019
Policy Entropy: 3.25781
Value Function Loss: 0.00395

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09737
Policy Update Magnitude: 0.54218
Value Function Update Magnitude: 0.65726

Collected Steps per Second: 20,660.06100
Overall Steps per Second: 10,354.76223

Timestep Collection Time: 2.42235
Timestep Consumption Time: 2.41078
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.83314

Cumulative Model Updates: 79,320
Cumulative Timesteps: 661,556,974

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 661556974...
Checkpoint 661556974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,378.35310
Policy Entropy: 3.26613
Value Function Loss: 0.00394

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.11851
Policy Update Magnitude: 0.53834
Value Function Update Magnitude: 0.65262

Collected Steps per Second: 21,519.85862
Overall Steps per Second: 10,586.14777

Timestep Collection Time: 2.32409
Timestep Consumption Time: 2.40039
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.72448

Cumulative Model Updates: 79,326
Cumulative Timesteps: 661,606,988

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,586.52472
Policy Entropy: 3.26312
Value Function Loss: 0.00425

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.53837
Value Function Update Magnitude: 0.65764

Collected Steps per Second: 22,755.61144
Overall Steps per Second: 10,654.23833

Timestep Collection Time: 2.19752
Timestep Consumption Time: 2.49601
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.69353

Cumulative Model Updates: 79,332
Cumulative Timesteps: 661,656,994

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 661656994...
Checkpoint 661656994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 739.15001
Policy Entropy: 3.27092
Value Function Loss: 0.00409

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11417
Policy Update Magnitude: 0.53854
Value Function Update Magnitude: 0.66468

Collected Steps per Second: 23,110.75302
Overall Steps per Second: 10,617.16965

Timestep Collection Time: 2.16358
Timestep Consumption Time: 2.54596
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.70954

Cumulative Model Updates: 79,338
Cumulative Timesteps: 661,706,996

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.28228
Policy Entropy: 3.26544
Value Function Loss: 0.00401

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10867
Policy Update Magnitude: 0.53337
Value Function Update Magnitude: 0.66913

Collected Steps per Second: 22,952.07052
Overall Steps per Second: 10,683.29820

Timestep Collection Time: 2.17845
Timestep Consumption Time: 2.50175
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.68020

Cumulative Model Updates: 79,344
Cumulative Timesteps: 661,756,996

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 661756996...
Checkpoint 661756996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.57696
Policy Entropy: 3.27820
Value Function Loss: 0.00400

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10612
Policy Update Magnitude: 0.52869
Value Function Update Magnitude: 0.67324

Collected Steps per Second: 22,975.74013
Overall Steps per Second: 10,819.49017

Timestep Collection Time: 2.17664
Timestep Consumption Time: 2.44557
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.62221

Cumulative Model Updates: 79,350
Cumulative Timesteps: 661,807,006

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.32241
Policy Entropy: 3.27914
Value Function Loss: 0.00397

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08999
Policy Update Magnitude: 0.52879
Value Function Update Magnitude: 0.67005

Collected Steps per Second: 22,405.86879
Overall Steps per Second: 10,512.52389

Timestep Collection Time: 2.23272
Timestep Consumption Time: 2.52599
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.75871

Cumulative Model Updates: 79,356
Cumulative Timesteps: 661,857,032

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 661857032...
Checkpoint 661857032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408.01590
Policy Entropy: 3.28873
Value Function Loss: 0.00398

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08971
Policy Update Magnitude: 0.53273
Value Function Update Magnitude: 0.66833

Collected Steps per Second: 22,621.56263
Overall Steps per Second: 10,620.83820

Timestep Collection Time: 2.21063
Timestep Consumption Time: 2.49785
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.70848

Cumulative Model Updates: 79,362
Cumulative Timesteps: 661,907,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.49212
Policy Entropy: 3.28164
Value Function Loss: 0.00379

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08088
Policy Update Magnitude: 0.52778
Value Function Update Magnitude: 0.66978

Collected Steps per Second: 22,528.58962
Overall Steps per Second: 10,835.27093

Timestep Collection Time: 2.22029
Timestep Consumption Time: 2.39612
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.61641

Cumulative Model Updates: 79,368
Cumulative Timesteps: 661,957,060

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 661957060...
Checkpoint 661957060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 870.79968
Policy Entropy: 3.27051
Value Function Loss: 0.00374

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08224
Policy Update Magnitude: 0.52368
Value Function Update Magnitude: 0.64000

Collected Steps per Second: 21,370.74564
Overall Steps per Second: 10,298.49256

Timestep Collection Time: 2.34002
Timestep Consumption Time: 2.51583
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.85586

Cumulative Model Updates: 79,374
Cumulative Timesteps: 662,007,068

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.54774
Policy Entropy: 3.26364
Value Function Loss: 0.00398

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07891
Policy Update Magnitude: 0.53190
Value Function Update Magnitude: 0.64004

Collected Steps per Second: 22,920.22676
Overall Steps per Second: 10,794.45380

Timestep Collection Time: 2.18253
Timestep Consumption Time: 2.45171
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.63423

Cumulative Model Updates: 79,380
Cumulative Timesteps: 662,057,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 662057092...
Checkpoint 662057092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.12491
Policy Entropy: 3.24560
Value Function Loss: 0.00424

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.07988
Policy Update Magnitude: 0.54505
Value Function Update Magnitude: 0.64446

Collected Steps per Second: 22,234.13393
Overall Steps per Second: 10,658.30436

Timestep Collection Time: 2.24951
Timestep Consumption Time: 2.44316
PPO Batch Consumption Time: 0.28151
Total Iteration Time: 4.69268

Cumulative Model Updates: 79,386
Cumulative Timesteps: 662,107,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 751.21287
Policy Entropy: 3.23748
Value Function Loss: 0.00429

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.55083
Value Function Update Magnitude: 0.64472

Collected Steps per Second: 22,916.28910
Overall Steps per Second: 10,565.17965

Timestep Collection Time: 2.18229
Timestep Consumption Time: 2.55118
PPO Batch Consumption Time: 0.29668
Total Iteration Time: 4.73347

Cumulative Model Updates: 79,392
Cumulative Timesteps: 662,157,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 662157118...
Checkpoint 662157118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.23121
Policy Entropy: 3.23115
Value Function Loss: 0.00418

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09135
Policy Update Magnitude: 0.54807
Value Function Update Magnitude: 0.64344

Collected Steps per Second: 22,737.43540
Overall Steps per Second: 10,638.89454

Timestep Collection Time: 2.19990
Timestep Consumption Time: 2.50172
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.70162

Cumulative Model Updates: 79,398
Cumulative Timesteps: 662,207,138

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,405.11682
Policy Entropy: 3.24177
Value Function Loss: 0.00400

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08570
Policy Update Magnitude: 0.54331
Value Function Update Magnitude: 0.64628

Collected Steps per Second: 23,269.93930
Overall Steps per Second: 10,853.89863

Timestep Collection Time: 2.14887
Timestep Consumption Time: 2.45814
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.60701

Cumulative Model Updates: 79,404
Cumulative Timesteps: 662,257,142

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 662257142...
Checkpoint 662257142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 981.05717
Policy Entropy: 3.24612
Value Function Loss: 0.00406

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08465
Policy Update Magnitude: 0.53778
Value Function Update Magnitude: 0.65989

Collected Steps per Second: 22,697.62653
Overall Steps per Second: 10,657.25532

Timestep Collection Time: 2.20287
Timestep Consumption Time: 2.48877
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.69164

Cumulative Model Updates: 79,410
Cumulative Timesteps: 662,307,142

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.73201
Policy Entropy: 3.25137
Value Function Loss: 0.00401

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10534
Policy Update Magnitude: 0.53844
Value Function Update Magnitude: 0.66925

Collected Steps per Second: 22,907.20243
Overall Steps per Second: 10,657.42756

Timestep Collection Time: 2.18359
Timestep Consumption Time: 2.50985
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.69344

Cumulative Model Updates: 79,416
Cumulative Timesteps: 662,357,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 662357162...
Checkpoint 662357162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515.36907
Policy Entropy: 3.25550
Value Function Loss: 0.00410

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09869
Policy Update Magnitude: 0.54035
Value Function Update Magnitude: 0.67024

Collected Steps per Second: 22,597.30777
Overall Steps per Second: 10,602.03521

Timestep Collection Time: 2.21318
Timestep Consumption Time: 2.50402
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.71721

Cumulative Model Updates: 79,422
Cumulative Timesteps: 662,407,174

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 765.06844
Policy Entropy: 3.25925
Value Function Loss: 0.00408

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09628
Policy Update Magnitude: 0.53836
Value Function Update Magnitude: 0.64336

Collected Steps per Second: 22,940.64467
Overall Steps per Second: 10,801.52885

Timestep Collection Time: 2.18050
Timestep Consumption Time: 2.45051
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.63101

Cumulative Model Updates: 79,428
Cumulative Timesteps: 662,457,196

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 662457196...
Checkpoint 662457196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701.03390
Policy Entropy: 3.26711
Value Function Loss: 0.00438

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09576
Policy Update Magnitude: 0.54280
Value Function Update Magnitude: 0.63367

Collected Steps per Second: 22,117.47231
Overall Steps per Second: 10,636.19300

Timestep Collection Time: 2.26183
Timestep Consumption Time: 2.44154
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.70337

Cumulative Model Updates: 79,434
Cumulative Timesteps: 662,507,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.70077
Policy Entropy: 3.26505
Value Function Loss: 0.00447

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10174
Policy Update Magnitude: 0.54822
Value Function Update Magnitude: 0.63971

Collected Steps per Second: 22,431.14192
Overall Steps per Second: 10,560.55977

Timestep Collection Time: 2.23020
Timestep Consumption Time: 2.50686
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.73706

Cumulative Model Updates: 79,440
Cumulative Timesteps: 662,557,248

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 662557248...
Checkpoint 662557248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658.99374
Policy Entropy: 3.26508
Value Function Loss: 0.00435

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10924
Policy Update Magnitude: 0.54969
Value Function Update Magnitude: 0.62232

Collected Steps per Second: 21,633.85330
Overall Steps per Second: 10,476.02869

Timestep Collection Time: 2.31212
Timestep Consumption Time: 2.46259
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.77471

Cumulative Model Updates: 79,446
Cumulative Timesteps: 662,607,268

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,613.49245
Policy Entropy: 3.25875
Value Function Loss: 0.00422

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.54399
Value Function Update Magnitude: 0.61090

Collected Steps per Second: 22,668.16356
Overall Steps per Second: 10,539.07313

Timestep Collection Time: 2.20697
Timestep Consumption Time: 2.53994
PPO Batch Consumption Time: 0.29682
Total Iteration Time: 4.74691

Cumulative Model Updates: 79,452
Cumulative Timesteps: 662,657,296

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 662657296...
Checkpoint 662657296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349.06713
Policy Entropy: 3.25549
Value Function Loss: 0.00407

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09994
Policy Update Magnitude: 0.54055
Value Function Update Magnitude: 0.60235

Collected Steps per Second: 22,595.28135
Overall Steps per Second: 10,649.13158

Timestep Collection Time: 2.21347
Timestep Consumption Time: 2.48306
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.69653

Cumulative Model Updates: 79,458
Cumulative Timesteps: 662,707,310

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 946.93840
Policy Entropy: 3.26361
Value Function Loss: 0.00400

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11107
Policy Update Magnitude: 0.54361
Value Function Update Magnitude: 0.59825

Collected Steps per Second: 22,993.05690
Overall Steps per Second: 10,854.75664

Timestep Collection Time: 2.17553
Timestep Consumption Time: 2.43278
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.60830

Cumulative Model Updates: 79,464
Cumulative Timesteps: 662,757,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 662757332...
Checkpoint 662757332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 884.44293
Policy Entropy: 3.26491
Value Function Loss: 0.00410

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12556
Policy Update Magnitude: 0.54188
Value Function Update Magnitude: 0.62603

Collected Steps per Second: 22,755.03215
Overall Steps per Second: 10,619.75252

Timestep Collection Time: 2.19811
Timestep Consumption Time: 2.51180
PPO Batch Consumption Time: 0.29771
Total Iteration Time: 4.70990

Cumulative Model Updates: 79,470
Cumulative Timesteps: 662,807,350

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 979.32434
Policy Entropy: 3.27605
Value Function Loss: 0.00394

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10052
Policy Update Magnitude: 0.54155
Value Function Update Magnitude: 0.63076

Collected Steps per Second: 23,091.33253
Overall Steps per Second: 10,846.72796

Timestep Collection Time: 2.16653
Timestep Consumption Time: 2.44574
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.61227

Cumulative Model Updates: 79,476
Cumulative Timesteps: 662,857,378

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 662857378...
Checkpoint 662857378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 963.43465
Policy Entropy: 3.27370
Value Function Loss: 0.00425

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10503
Policy Update Magnitude: 0.53995
Value Function Update Magnitude: 0.62184

Collected Steps per Second: 22,833.77729
Overall Steps per Second: 10,702.74560

Timestep Collection Time: 2.19096
Timestep Consumption Time: 2.48335
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.67431

Cumulative Model Updates: 79,482
Cumulative Timesteps: 662,907,406

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 857.32732
Policy Entropy: 3.27414
Value Function Loss: 0.00418

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09738
Policy Update Magnitude: 0.53965
Value Function Update Magnitude: 0.61697

Collected Steps per Second: 23,085.53944
Overall Steps per Second: 10,881.92257

Timestep Collection Time: 2.16690
Timestep Consumption Time: 2.43008
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.59698

Cumulative Model Updates: 79,488
Cumulative Timesteps: 662,957,430

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 662957430...
Checkpoint 662957430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,444.83928
Policy Entropy: 3.27114
Value Function Loss: 0.00432

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08082
Policy Update Magnitude: 0.54833
Value Function Update Magnitude: 0.62190

Collected Steps per Second: 22,454.61500
Overall Steps per Second: 10,695.93873

Timestep Collection Time: 2.22743
Timestep Consumption Time: 2.44874
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.67617

Cumulative Model Updates: 79,494
Cumulative Timesteps: 663,007,446

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 955.79354
Policy Entropy: 3.27915
Value Function Loss: 0.00418

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09028
Policy Update Magnitude: 0.54738
Value Function Update Magnitude: 0.61941

Collected Steps per Second: 22,800.47998
Overall Steps per Second: 10,823.79524

Timestep Collection Time: 2.19399
Timestep Consumption Time: 2.42768
PPO Batch Consumption Time: 0.28197
Total Iteration Time: 4.62167

Cumulative Model Updates: 79,500
Cumulative Timesteps: 663,057,470

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 663057470...
Checkpoint 663057470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,431.17889
Policy Entropy: 3.28954
Value Function Loss: 0.00426

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09003
Policy Update Magnitude: 0.54140
Value Function Update Magnitude: 0.62147

Collected Steps per Second: 22,502.45517
Overall Steps per Second: 10,739.65964

Timestep Collection Time: 2.22225
Timestep Consumption Time: 2.43395
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.65620

Cumulative Model Updates: 79,506
Cumulative Timesteps: 663,107,476

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.29519
Policy Entropy: 3.27864
Value Function Loss: 0.00423

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08619
Policy Update Magnitude: 0.54341
Value Function Update Magnitude: 0.63744

Collected Steps per Second: 22,620.15720
Overall Steps per Second: 10,790.27279

Timestep Collection Time: 2.21051
Timestep Consumption Time: 2.42348
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.63399

Cumulative Model Updates: 79,512
Cumulative Timesteps: 663,157,478

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 663157478...
Checkpoint 663157478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.15193
Policy Entropy: 3.26651
Value Function Loss: 0.00434

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09385
Policy Update Magnitude: 0.54473
Value Function Update Magnitude: 0.63699

Collected Steps per Second: 21,942.95709
Overall Steps per Second: 10,635.71666

Timestep Collection Time: 2.27873
Timestep Consumption Time: 2.42260
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.70133

Cumulative Model Updates: 79,518
Cumulative Timesteps: 663,207,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.51024
Policy Entropy: 3.25514
Value Function Loss: 0.00435

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.54661
Value Function Update Magnitude: 0.63677

Collected Steps per Second: 22,615.50264
Overall Steps per Second: 10,534.33676

Timestep Collection Time: 2.21185
Timestep Consumption Time: 2.53663
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.74847

Cumulative Model Updates: 79,524
Cumulative Timesteps: 663,257,502

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 663257502...
Checkpoint 663257502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 931.51426
Policy Entropy: 3.25957
Value Function Loss: 0.00420

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.54322
Value Function Update Magnitude: 0.62544

Collected Steps per Second: 22,576.72526
Overall Steps per Second: 10,665.89230

Timestep Collection Time: 2.21582
Timestep Consumption Time: 2.47446
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.69028

Cumulative Model Updates: 79,530
Cumulative Timesteps: 663,307,528

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480.13072
Policy Entropy: 3.27645
Value Function Loss: 0.00422

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11026
Policy Update Magnitude: 0.53555
Value Function Update Magnitude: 0.60981

Collected Steps per Second: 22,906.40752
Overall Steps per Second: 10,822.14932

Timestep Collection Time: 2.18384
Timestep Consumption Time: 2.43853
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.62237

Cumulative Model Updates: 79,536
Cumulative Timesteps: 663,357,552

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 663357552...
Checkpoint 663357552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.06368
Policy Entropy: 3.29123
Value Function Loss: 0.00410

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10141
Policy Update Magnitude: 0.53249
Value Function Update Magnitude: 0.61883

Collected Steps per Second: 22,550.43438
Overall Steps per Second: 10,731.72708

Timestep Collection Time: 2.21805
Timestep Consumption Time: 2.44271
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.66076

Cumulative Model Updates: 79,542
Cumulative Timesteps: 663,407,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 948.78154
Policy Entropy: 3.28771
Value Function Loss: 0.00392

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09750
Policy Update Magnitude: 0.53104
Value Function Update Magnitude: 0.61657

Collected Steps per Second: 22,843.15546
Overall Steps per Second: 10,795.67519

Timestep Collection Time: 2.18989
Timestep Consumption Time: 2.44382
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.63371

Cumulative Model Updates: 79,548
Cumulative Timesteps: 663,457,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 663457594...
Checkpoint 663457594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 981.38571
Policy Entropy: 3.26320
Value Function Loss: 0.00406

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08841
Policy Update Magnitude: 0.54042
Value Function Update Magnitude: 0.61931

Collected Steps per Second: 22,889.43668
Overall Steps per Second: 10,748.23185

Timestep Collection Time: 2.18494
Timestep Consumption Time: 2.46811
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.65304

Cumulative Model Updates: 79,554
Cumulative Timesteps: 663,507,606

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.63194
Policy Entropy: 3.25461
Value Function Loss: 0.00405

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.55053
Value Function Update Magnitude: 0.62611

Collected Steps per Second: 22,063.34013
Overall Steps per Second: 10,458.86312

Timestep Collection Time: 2.26647
Timestep Consumption Time: 2.51473
PPO Batch Consumption Time: 0.29720
Total Iteration Time: 4.78121

Cumulative Model Updates: 79,560
Cumulative Timesteps: 663,557,612

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 663557612...
Checkpoint 663557612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 690.58332
Policy Entropy: 3.24924
Value Function Loss: 0.00410

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08105
Policy Update Magnitude: 0.55985
Value Function Update Magnitude: 0.61862

Collected Steps per Second: 22,006.32224
Overall Steps per Second: 10,647.82100

Timestep Collection Time: 2.27280
Timestep Consumption Time: 2.42450
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.69730

Cumulative Model Updates: 79,566
Cumulative Timesteps: 663,607,628

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,576.90581
Policy Entropy: 3.25686
Value Function Loss: 0.00419

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09317
Policy Update Magnitude: 0.56061
Value Function Update Magnitude: 0.60344

Collected Steps per Second: 22,514.63688
Overall Steps per Second: 10,604.06487

Timestep Collection Time: 2.22122
Timestep Consumption Time: 2.49489
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.71612

Cumulative Model Updates: 79,572
Cumulative Timesteps: 663,657,638

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 663657638...
Checkpoint 663657638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,663.92854
Policy Entropy: 3.26186
Value Function Loss: 0.00397

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08989
Policy Update Magnitude: 0.55197
Value Function Update Magnitude: 0.61451

Collected Steps per Second: 22,553.47545
Overall Steps per Second: 10,609.58290

Timestep Collection Time: 2.21784
Timestep Consumption Time: 2.49677
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.71461

Cumulative Model Updates: 79,578
Cumulative Timesteps: 663,707,658

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,506.54225
Policy Entropy: 3.26438
Value Function Loss: 0.00405

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08486
Policy Update Magnitude: 0.54481
Value Function Update Magnitude: 0.60974

Collected Steps per Second: 23,209.25363
Overall Steps per Second: 10,792.96480

Timestep Collection Time: 2.15474
Timestep Consumption Time: 2.47883
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.63357

Cumulative Model Updates: 79,584
Cumulative Timesteps: 663,757,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 663757668...
Checkpoint 663757668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 840.29860
Policy Entropy: 3.27810
Value Function Loss: 0.00402

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09160
Policy Update Magnitude: 0.54142
Value Function Update Magnitude: 0.59887

Collected Steps per Second: 22,409.34621
Overall Steps per Second: 10,631.52297

Timestep Collection Time: 2.23139
Timestep Consumption Time: 2.47198
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.70337

Cumulative Model Updates: 79,590
Cumulative Timesteps: 663,807,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.26222
Policy Entropy: 3.26848
Value Function Loss: 0.00431

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09317
Policy Update Magnitude: 0.55386
Value Function Update Magnitude: 0.60659

Collected Steps per Second: 23,049.92361
Overall Steps per Second: 10,851.88348

Timestep Collection Time: 2.16999
Timestep Consumption Time: 2.43917
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.60915

Cumulative Model Updates: 79,596
Cumulative Timesteps: 663,857,690

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 663857690...
Checkpoint 663857690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,369.72660
Policy Entropy: 3.27895
Value Function Loss: 0.00446

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09791
Policy Update Magnitude: 0.56405
Value Function Update Magnitude: 0.65456

Collected Steps per Second: 21,797.63983
Overall Steps per Second: 10,399.84664

Timestep Collection Time: 2.29465
Timestep Consumption Time: 2.51484
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.80949

Cumulative Model Updates: 79,602
Cumulative Timesteps: 663,907,708

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684.50607
Policy Entropy: 3.27842
Value Function Loss: 0.00444

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10548
Policy Update Magnitude: 0.56555
Value Function Update Magnitude: 0.68025

Collected Steps per Second: 23,290.66575
Overall Steps per Second: 10,730.29220

Timestep Collection Time: 2.14790
Timestep Consumption Time: 2.51423
PPO Batch Consumption Time: 0.29666
Total Iteration Time: 4.66213

Cumulative Model Updates: 79,608
Cumulative Timesteps: 663,957,734

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 663957734...
Checkpoint 663957734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 987.87914
Policy Entropy: 3.28620
Value Function Loss: 0.00436

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10879
Policy Update Magnitude: 0.55708
Value Function Update Magnitude: 0.66578

Collected Steps per Second: 22,816.21136
Overall Steps per Second: 10,635.77357

Timestep Collection Time: 2.19142
Timestep Consumption Time: 2.50969
PPO Batch Consumption Time: 0.29755
Total Iteration Time: 4.70112

Cumulative Model Updates: 79,614
Cumulative Timesteps: 664,007,734

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.56483
Policy Entropy: 3.27143
Value Function Loss: 0.00446

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12329
Policy Update Magnitude: 0.55764
Value Function Update Magnitude: 0.65123

Collected Steps per Second: 22,255.83728
Overall Steps per Second: 10,498.48645

Timestep Collection Time: 2.24714
Timestep Consumption Time: 2.51659
PPO Batch Consumption Time: 0.29683
Total Iteration Time: 4.76373

Cumulative Model Updates: 79,620
Cumulative Timesteps: 664,057,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 664057746...
Checkpoint 664057746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 933.68368
Policy Entropy: 3.26523
Value Function Loss: 0.00434

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11770
Policy Update Magnitude: 0.55294
Value Function Update Magnitude: 0.64812

Collected Steps per Second: 22,447.90015
Overall Steps per Second: 10,611.66492

Timestep Collection Time: 2.22791
Timestep Consumption Time: 2.48501
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.71293

Cumulative Model Updates: 79,626
Cumulative Timesteps: 664,107,758

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,854.95781
Policy Entropy: 3.24957
Value Function Loss: 0.00432

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.12374
Policy Update Magnitude: 0.54919
Value Function Update Magnitude: 0.65597

Collected Steps per Second: 22,296.77956
Overall Steps per Second: 10,614.14248

Timestep Collection Time: 2.24364
Timestep Consumption Time: 2.46950
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.71315

Cumulative Model Updates: 79,632
Cumulative Timesteps: 664,157,784

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 664157784...
Checkpoint 664157784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 896.72224
Policy Entropy: 3.24424
Value Function Loss: 0.00417

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10865
Policy Update Magnitude: 0.54814
Value Function Update Magnitude: 0.63858

Collected Steps per Second: 22,532.10320
Overall Steps per Second: 10,590.12242

Timestep Collection Time: 2.22012
Timestep Consumption Time: 2.50353
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.72365

Cumulative Model Updates: 79,638
Cumulative Timesteps: 664,207,808

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.85439
Policy Entropy: 3.23960
Value Function Loss: 0.00423

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12692
Policy Update Magnitude: 0.55178
Value Function Update Magnitude: 0.63774

Collected Steps per Second: 22,833.52453
Overall Steps per Second: 10,800.33580

Timestep Collection Time: 2.19055
Timestep Consumption Time: 2.44060
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.63115

Cumulative Model Updates: 79,644
Cumulative Timesteps: 664,257,826

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 664257826...
Checkpoint 664257826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.46620
Policy Entropy: 3.22497
Value Function Loss: 0.00444

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10764
Policy Update Magnitude: 0.55484
Value Function Update Magnitude: 0.63729

Collected Steps per Second: 22,573.23404
Overall Steps per Second: 10,629.87029

Timestep Collection Time: 2.21563
Timestep Consumption Time: 2.48941
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.70504

Cumulative Model Updates: 79,650
Cumulative Timesteps: 664,307,840

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.75273
Policy Entropy: 3.23078
Value Function Loss: 0.00456

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10065
Policy Update Magnitude: 0.56101
Value Function Update Magnitude: 0.63766

Collected Steps per Second: 22,949.04285
Overall Steps per Second: 10,844.74351

Timestep Collection Time: 2.17961
Timestep Consumption Time: 2.43276
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.61237

Cumulative Model Updates: 79,656
Cumulative Timesteps: 664,357,860

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 664357860...
Checkpoint 664357860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.64776
Policy Entropy: 3.23770
Value Function Loss: 0.00440

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09560
Policy Update Magnitude: 0.57091
Value Function Update Magnitude: 0.64430

Collected Steps per Second: 22,585.36069
Overall Steps per Second: 10,710.40992

Timestep Collection Time: 2.21382
Timestep Consumption Time: 2.45453
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.66836

Cumulative Model Updates: 79,662
Cumulative Timesteps: 664,407,860

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,557.83673
Policy Entropy: 3.24491
Value Function Loss: 0.00435

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.56656
Value Function Update Magnitude: 0.63148

Collected Steps per Second: 22,886.27776
Overall Steps per Second: 10,811.94401

Timestep Collection Time: 2.18585
Timestep Consumption Time: 2.44107
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.62692

Cumulative Model Updates: 79,668
Cumulative Timesteps: 664,457,886

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 664457886...
Checkpoint 664457886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 810.00188
Policy Entropy: 3.24331
Value Function Loss: 0.00437

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09845
Policy Update Magnitude: 0.56863
Value Function Update Magnitude: 0.64516

Collected Steps per Second: 22,506.91796
Overall Steps per Second: 10,765.75003

Timestep Collection Time: 2.22172
Timestep Consumption Time: 2.42301
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.64473

Cumulative Model Updates: 79,674
Cumulative Timesteps: 664,507,890

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.06483
Policy Entropy: 3.23153
Value Function Loss: 0.00434

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08289
Policy Update Magnitude: 0.57273
Value Function Update Magnitude: 0.65030

Collected Steps per Second: 22,520.68638
Overall Steps per Second: 10,638.95205

Timestep Collection Time: 2.22018
Timestep Consumption Time: 2.47953
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.69971

Cumulative Model Updates: 79,680
Cumulative Timesteps: 664,557,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 664557890...
Checkpoint 664557890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.01640
Policy Entropy: 3.23273
Value Function Loss: 0.00438

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.57475
Value Function Update Magnitude: 0.64039

Collected Steps per Second: 22,209.99779
Overall Steps per Second: 10,572.25847

Timestep Collection Time: 2.25214
Timestep Consumption Time: 2.47911
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.73125

Cumulative Model Updates: 79,686
Cumulative Timesteps: 664,607,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 786.90606
Policy Entropy: 3.25236
Value Function Loss: 0.00428

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11658
Policy Update Magnitude: 0.57244
Value Function Update Magnitude: 0.63593

Collected Steps per Second: 22,631.98287
Overall Steps per Second: 10,778.34358

Timestep Collection Time: 2.21015
Timestep Consumption Time: 2.43064
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.64079

Cumulative Model Updates: 79,692
Cumulative Timesteps: 664,657,930

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 664657930...
Checkpoint 664657930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 948.44764
Policy Entropy: 3.26359
Value Function Loss: 0.00444

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11222
Policy Update Magnitude: 0.56800
Value Function Update Magnitude: 0.62534

Collected Steps per Second: 22,735.20732
Overall Steps per Second: 10,625.01627

Timestep Collection Time: 2.20038
Timestep Consumption Time: 2.50795
PPO Batch Consumption Time: 0.29852
Total Iteration Time: 4.70832

Cumulative Model Updates: 79,698
Cumulative Timesteps: 664,707,956

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.12410
Policy Entropy: 3.28358
Value Function Loss: 0.00436

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12030
Policy Update Magnitude: 0.55450
Value Function Update Magnitude: 0.61835

Collected Steps per Second: 22,437.68957
Overall Steps per Second: 10,524.67341

Timestep Collection Time: 2.22857
Timestep Consumption Time: 2.52255
PPO Batch Consumption Time: 0.29639
Total Iteration Time: 4.75112

Cumulative Model Updates: 79,704
Cumulative Timesteps: 664,757,960

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 664757960...
Checkpoint 664757960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.70734
Policy Entropy: 3.26531
Value Function Loss: 0.00429

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11340
Policy Update Magnitude: 0.54853
Value Function Update Magnitude: 0.61211

Collected Steps per Second: 22,509.06404
Overall Steps per Second: 10,587.70034

Timestep Collection Time: 2.22222
Timestep Consumption Time: 2.50213
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.72435

Cumulative Model Updates: 79,710
Cumulative Timesteps: 664,807,980

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.84588
Policy Entropy: 3.25718
Value Function Loss: 0.00411

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.55752
Value Function Update Magnitude: 0.61593

Collected Steps per Second: 22,802.84819
Overall Steps per Second: 10,810.88395

Timestep Collection Time: 2.19332
Timestep Consumption Time: 2.43294
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.62626

Cumulative Model Updates: 79,716
Cumulative Timesteps: 664,857,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 664857994...
Checkpoint 664857994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.48885
Policy Entropy: 3.23649
Value Function Loss: 0.00419

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.56340
Value Function Update Magnitude: 0.62337

Collected Steps per Second: 22,534.68573
Overall Steps per Second: 10,640.33446

Timestep Collection Time: 2.21907
Timestep Consumption Time: 2.48060
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.69966

Cumulative Model Updates: 79,722
Cumulative Timesteps: 664,908,000

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.89611
Policy Entropy: 3.23847
Value Function Loss: 0.00452

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11043
Policy Update Magnitude: 0.57627
Value Function Update Magnitude: 0.64056

Collected Steps per Second: 22,644.44700
Overall Steps per Second: 10,620.49032

Timestep Collection Time: 2.20822
Timestep Consumption Time: 2.50003
PPO Batch Consumption Time: 0.29650
Total Iteration Time: 4.70826

Cumulative Model Updates: 79,728
Cumulative Timesteps: 664,958,004

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 664958004...
Checkpoint 664958004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.07518
Policy Entropy: 3.23605
Value Function Loss: 0.00437

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09555
Policy Update Magnitude: 0.57993
Value Function Update Magnitude: 0.66200

Collected Steps per Second: 22,303.95583
Overall Steps per Second: 10,521.74232

Timestep Collection Time: 2.24265
Timestep Consumption Time: 2.51131
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.75397

Cumulative Model Updates: 79,734
Cumulative Timesteps: 665,008,024

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.54929
Policy Entropy: 3.23727
Value Function Loss: 0.00444

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09652
Policy Update Magnitude: 0.57554
Value Function Update Magnitude: 0.64555

Collected Steps per Second: 22,915.78271
Overall Steps per Second: 10,821.46687

Timestep Collection Time: 2.18243
Timestep Consumption Time: 2.43913
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.62155

Cumulative Model Updates: 79,740
Cumulative Timesteps: 665,058,036

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 665058036...
Checkpoint 665058036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644.33922
Policy Entropy: 3.24156
Value Function Loss: 0.00437

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08213
Policy Update Magnitude: 0.57416
Value Function Update Magnitude: 0.62403

Collected Steps per Second: 22,385.00554
Overall Steps per Second: 10,726.49164

Timestep Collection Time: 2.23453
Timestep Consumption Time: 2.42869
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.66322

Cumulative Model Updates: 79,746
Cumulative Timesteps: 665,108,056

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.21140
Policy Entropy: 3.23570
Value Function Loss: 0.00432

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09199
Policy Update Magnitude: 0.57502
Value Function Update Magnitude: 0.61224

Collected Steps per Second: 21,957.62740
Overall Steps per Second: 10,500.62738

Timestep Collection Time: 2.27802
Timestep Consumption Time: 2.48550
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.76352

Cumulative Model Updates: 79,752
Cumulative Timesteps: 665,158,076

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 665158076...
Checkpoint 665158076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613.75307
Policy Entropy: 3.22333
Value Function Loss: 0.00458

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09397
Policy Update Magnitude: 0.57486
Value Function Update Magnitude: 0.61689

Collected Steps per Second: 22,193.82217
Overall Steps per Second: 10,625.43076

Timestep Collection Time: 2.25297
Timestep Consumption Time: 2.45291
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.70588

Cumulative Model Updates: 79,758
Cumulative Timesteps: 665,208,078

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.82959
Policy Entropy: 3.21462
Value Function Loss: 0.00460

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09113
Policy Update Magnitude: 0.58194
Value Function Update Magnitude: 0.65478

Collected Steps per Second: 21,024.22352
Overall Steps per Second: 10,448.18178

Timestep Collection Time: 2.37849
Timestep Consumption Time: 2.40760
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.78610

Cumulative Model Updates: 79,764
Cumulative Timesteps: 665,258,084

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 665258084...
Checkpoint 665258084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.33942
Policy Entropy: 3.20969
Value Function Loss: 0.00474

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10857
Policy Update Magnitude: 0.58258
Value Function Update Magnitude: 0.68035

Collected Steps per Second: 21,792.09118
Overall Steps per Second: 10,645.99378

Timestep Collection Time: 2.29469
Timestep Consumption Time: 2.40248
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.69717

Cumulative Model Updates: 79,770
Cumulative Timesteps: 665,308,090

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.66438
Policy Entropy: 3.21208
Value Function Loss: 0.00446

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11433
Policy Update Magnitude: 0.56903
Value Function Update Magnitude: 0.65379

Collected Steps per Second: 21,925.69289
Overall Steps per Second: 10,509.28548

Timestep Collection Time: 2.28180
Timestep Consumption Time: 2.47875
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.76055

Cumulative Model Updates: 79,776
Cumulative Timesteps: 665,358,120

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 665358120...
Checkpoint 665358120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 774.73536
Policy Entropy: 3.22395
Value Function Loss: 0.00442

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.56177
Value Function Update Magnitude: 0.64117

Collected Steps per Second: 22,575.06840
Overall Steps per Second: 10,606.58559

Timestep Collection Time: 2.21501
Timestep Consumption Time: 2.49942
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.71443

Cumulative Model Updates: 79,782
Cumulative Timesteps: 665,408,124

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.72747
Policy Entropy: 3.22421
Value Function Loss: 0.00420

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11951
Policy Update Magnitude: 0.55481
Value Function Update Magnitude: 0.65221

Collected Steps per Second: 22,905.00953
Overall Steps per Second: 10,876.49421

Timestep Collection Time: 2.18302
Timestep Consumption Time: 2.41424
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.59725

Cumulative Model Updates: 79,788
Cumulative Timesteps: 665,458,126

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 665458126...
Checkpoint 665458126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 751.02023
Policy Entropy: 3.24314
Value Function Loss: 0.00451

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12032
Policy Update Magnitude: 0.56613
Value Function Update Magnitude: 0.67676

Collected Steps per Second: 21,864.58392
Overall Steps per Second: 10,654.79260

Timestep Collection Time: 2.28772
Timestep Consumption Time: 2.40688
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.69460

Cumulative Model Updates: 79,794
Cumulative Timesteps: 665,508,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 818.43797
Policy Entropy: 3.25587
Value Function Loss: 0.00454

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12363
Policy Update Magnitude: 0.56143
Value Function Update Magnitude: 0.68886

Collected Steps per Second: 22,138.20990
Overall Steps per Second: 10,497.79569

Timestep Collection Time: 2.26044
Timestep Consumption Time: 2.50647
PPO Batch Consumption Time: 0.29824
Total Iteration Time: 4.76691

Cumulative Model Updates: 79,800
Cumulative Timesteps: 665,558,188

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 665558188...
Checkpoint 665558188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,272.57968
Policy Entropy: 3.27446
Value Function Loss: 0.00443

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11089
Policy Update Magnitude: 0.55897
Value Function Update Magnitude: 0.67426

Collected Steps per Second: 22,438.49939
Overall Steps per Second: 10,644.09978

Timestep Collection Time: 2.22885
Timestep Consumption Time: 2.46972
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.69857

Cumulative Model Updates: 79,806
Cumulative Timesteps: 665,608,200

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.11594
Policy Entropy: 3.27621
Value Function Loss: 0.00427

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10829
Policy Update Magnitude: 0.55443
Value Function Update Magnitude: 0.64777

Collected Steps per Second: 22,699.75299
Overall Steps per Second: 10,772.06675

Timestep Collection Time: 2.20346
Timestep Consumption Time: 2.43985
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.64331

Cumulative Model Updates: 79,812
Cumulative Timesteps: 665,658,218

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 665658218...
Checkpoint 665658218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 913.57848
Policy Entropy: 3.27384
Value Function Loss: 0.00414

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09688
Policy Update Magnitude: 0.54856
Value Function Update Magnitude: 0.63541

Collected Steps per Second: 21,831.08462
Overall Steps per Second: 10,526.53070

Timestep Collection Time: 2.29086
Timestep Consumption Time: 2.46018
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.75104

Cumulative Model Updates: 79,818
Cumulative Timesteps: 665,708,230

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541.60326
Policy Entropy: 3.27940
Value Function Loss: 0.00395

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10227
Policy Update Magnitude: 0.53457
Value Function Update Magnitude: 0.61898

Collected Steps per Second: 22,213.02957
Overall Steps per Second: 10,654.25858

Timestep Collection Time: 2.25228
Timestep Consumption Time: 2.44349
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.69577

Cumulative Model Updates: 79,824
Cumulative Timesteps: 665,758,260

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 665758260...
Checkpoint 665758260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,358.98210
Policy Entropy: 3.28718
Value Function Loss: 0.00384

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08360
Policy Update Magnitude: 0.52894
Value Function Update Magnitude: 0.62681

Collected Steps per Second: 22,306.67905
Overall Steps per Second: 10,602.27454

Timestep Collection Time: 2.24175
Timestep Consumption Time: 2.47479
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.71654

Cumulative Model Updates: 79,830
Cumulative Timesteps: 665,808,266

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754.94955
Policy Entropy: 3.28879
Value Function Loss: 0.00414

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08150
Policy Update Magnitude: 0.53808
Value Function Update Magnitude: 0.62890

Collected Steps per Second: 22,316.38288
Overall Steps per Second: 10,505.48784

Timestep Collection Time: 2.24069
Timestep Consumption Time: 2.51911
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.75980

Cumulative Model Updates: 79,836
Cumulative Timesteps: 665,858,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 665858270...
Checkpoint 665858270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390.65535
Policy Entropy: 3.27934
Value Function Loss: 0.00420

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09432
Policy Update Magnitude: 0.54935
Value Function Update Magnitude: 0.63060

Collected Steps per Second: 22,844.63320
Overall Steps per Second: 10,639.20708

Timestep Collection Time: 2.18949
Timestep Consumption Time: 2.51180
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.70129

Cumulative Model Updates: 79,842
Cumulative Timesteps: 665,908,288

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.08164
Policy Entropy: 3.27184
Value Function Loss: 0.00402

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10325
Policy Update Magnitude: 0.54650
Value Function Update Magnitude: 0.64297

Collected Steps per Second: 22,832.63335
Overall Steps per Second: 10,807.89922

Timestep Collection Time: 2.19064
Timestep Consumption Time: 2.43727
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.62791

Cumulative Model Updates: 79,848
Cumulative Timesteps: 665,958,306

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 665958306...
Checkpoint 665958306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.17161
Policy Entropy: 3.27448
Value Function Loss: 0.00385

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09839
Policy Update Magnitude: 0.53668
Value Function Update Magnitude: 0.64148

Collected Steps per Second: 22,629.24176
Overall Steps per Second: 10,785.24831

Timestep Collection Time: 2.21050
Timestep Consumption Time: 2.42750
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.63800

Cumulative Model Updates: 79,854
Cumulative Timesteps: 666,008,328

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 959.52876
Policy Entropy: 3.27641
Value Function Loss: 0.00390

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10665
Policy Update Magnitude: 0.53158
Value Function Update Magnitude: 0.62071

Collected Steps per Second: 22,906.00572
Overall Steps per Second: 10,835.87410

Timestep Collection Time: 2.18318
Timestep Consumption Time: 2.43186
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.61504

Cumulative Model Updates: 79,860
Cumulative Timesteps: 666,058,336

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 666058336...
Checkpoint 666058336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 995.90997
Policy Entropy: 3.27185
Value Function Loss: 0.00411

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10749
Policy Update Magnitude: 0.53473
Value Function Update Magnitude: 0.60465

Collected Steps per Second: 22,648.85049
Overall Steps per Second: 10,683.94234

Timestep Collection Time: 2.20841
Timestep Consumption Time: 2.47319
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.68161

Cumulative Model Updates: 79,866
Cumulative Timesteps: 666,108,354

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.72042
Policy Entropy: 3.26386
Value Function Loss: 0.00431

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10652
Policy Update Magnitude: 0.54385
Value Function Update Magnitude: 0.61763

Collected Steps per Second: 22,997.17808
Overall Steps per Second: 10,865.00506

Timestep Collection Time: 2.17444
Timestep Consumption Time: 2.42804
PPO Batch Consumption Time: 0.28334
Total Iteration Time: 4.60248

Cumulative Model Updates: 79,872
Cumulative Timesteps: 666,158,360

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 666158360...
Checkpoint 666158360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672.62655
Policy Entropy: 3.24082
Value Function Loss: 0.00437

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11064
Policy Update Magnitude: 0.55995
Value Function Update Magnitude: 0.62692

Collected Steps per Second: 22,325.98818
Overall Steps per Second: 10,730.82188

Timestep Collection Time: 2.24017
Timestep Consumption Time: 2.42061
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.66078

Cumulative Model Updates: 79,878
Cumulative Timesteps: 666,208,374

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.68368
Policy Entropy: 3.22894
Value Function Loss: 0.00424

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09190
Policy Update Magnitude: 0.56539
Value Function Update Magnitude: 0.63013

Collected Steps per Second: 22,372.29050
Overall Steps per Second: 10,624.61266

Timestep Collection Time: 2.23509
Timestep Consumption Time: 2.47134
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.70643

Cumulative Model Updates: 79,884
Cumulative Timesteps: 666,258,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 666258378...
Checkpoint 666258378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.76681
Policy Entropy: 3.22922
Value Function Loss: 0.00403

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09171
Policy Update Magnitude: 0.55130
Value Function Update Magnitude: 0.62013

Collected Steps per Second: 22,257.46229
Overall Steps per Second: 10,619.83735

Timestep Collection Time: 2.24832
Timestep Consumption Time: 2.46380
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.71212

Cumulative Model Updates: 79,890
Cumulative Timesteps: 666,308,420

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.92833
Policy Entropy: 3.24209
Value Function Loss: 0.00408

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08725
Policy Update Magnitude: 0.54675
Value Function Update Magnitude: 0.61655

Collected Steps per Second: 22,438.23026
Overall Steps per Second: 10,737.09595

Timestep Collection Time: 2.22879
Timestep Consumption Time: 2.42890
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.65768

Cumulative Model Updates: 79,896
Cumulative Timesteps: 666,358,430

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 666358430...
Checkpoint 666358430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 819.04278
Policy Entropy: 3.24371
Value Function Loss: 0.00413

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.54526
Value Function Update Magnitude: 0.62530

Collected Steps per Second: 22,520.08798
Overall Steps per Second: 10,619.48007

Timestep Collection Time: 2.22122
Timestep Consumption Time: 2.48918
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.71040

Cumulative Model Updates: 79,902
Cumulative Timesteps: 666,408,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,366.29028
Policy Entropy: 3.25198
Value Function Loss: 0.00423

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08730
Policy Update Magnitude: 0.54515
Value Function Update Magnitude: 0.62274

Collected Steps per Second: 22,738.73868
Overall Steps per Second: 10,574.77192

Timestep Collection Time: 2.19959
Timestep Consumption Time: 2.53015
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.72975

Cumulative Model Updates: 79,908
Cumulative Timesteps: 666,458,468

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 666458468...
Checkpoint 666458468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 848.95982
Policy Entropy: 3.25736
Value Function Loss: 0.00426

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08768
Policy Update Magnitude: 0.54746
Value Function Update Magnitude: 0.62621

Collected Steps per Second: 23,005.01740
Overall Steps per Second: 10,805.05946

Timestep Collection Time: 2.17387
Timestep Consumption Time: 2.45451
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.62839

Cumulative Model Updates: 79,914
Cumulative Timesteps: 666,508,478

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.34329
Policy Entropy: 3.26619
Value Function Loss: 0.00439

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09778
Policy Update Magnitude: 0.55407
Value Function Update Magnitude: 0.64880

Collected Steps per Second: 22,212.45919
Overall Steps per Second: 10,640.28480

Timestep Collection Time: 2.25135
Timestep Consumption Time: 2.44853
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.69987

Cumulative Model Updates: 79,920
Cumulative Timesteps: 666,558,486

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 666558486...
Checkpoint 666558486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.47780
Policy Entropy: 3.27794
Value Function Loss: 0.00424

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.54779
Value Function Update Magnitude: 0.66477

Collected Steps per Second: 22,895.44689
Overall Steps per Second: 10,658.05260

Timestep Collection Time: 2.18463
Timestep Consumption Time: 2.50835
PPO Batch Consumption Time: 0.29897
Total Iteration Time: 4.69298

Cumulative Model Updates: 79,926
Cumulative Timesteps: 666,608,504

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 880.13830
Policy Entropy: 3.27729
Value Function Loss: 0.00420

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10254
Policy Update Magnitude: 0.55106
Value Function Update Magnitude: 0.67096

Collected Steps per Second: 23,045.32544
Overall Steps per Second: 10,866.39076

Timestep Collection Time: 2.17024
Timestep Consumption Time: 2.43239
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.60263

Cumulative Model Updates: 79,932
Cumulative Timesteps: 666,658,518

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 666658518...
Checkpoint 666658518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 831.75417
Policy Entropy: 3.26562
Value Function Loss: 0.00403

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10591
Policy Update Magnitude: 0.55170
Value Function Update Magnitude: 0.65973

Collected Steps per Second: 22,856.28921
Overall Steps per Second: 10,635.91181

Timestep Collection Time: 2.18758
Timestep Consumption Time: 2.51347
PPO Batch Consumption Time: 0.29798
Total Iteration Time: 4.70105

Cumulative Model Updates: 79,938
Cumulative Timesteps: 666,708,518

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,010.39621
Policy Entropy: 3.25499
Value Function Loss: 0.00419

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10875
Policy Update Magnitude: 0.54877
Value Function Update Magnitude: 0.66742

Collected Steps per Second: 22,229.89186
Overall Steps per Second: 10,543.39464

Timestep Collection Time: 2.24985
Timestep Consumption Time: 2.49378
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 4.74363

Cumulative Model Updates: 79,944
Cumulative Timesteps: 666,758,532

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 666758532...
Checkpoint 666758532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.98734
Policy Entropy: 3.24352
Value Function Loss: 0.00428

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10807
Policy Update Magnitude: 0.54782
Value Function Update Magnitude: 0.68255

Collected Steps per Second: 22,244.56466
Overall Steps per Second: 10,557.88230

Timestep Collection Time: 2.24774
Timestep Consumption Time: 2.48806
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.73580

Cumulative Model Updates: 79,950
Cumulative Timesteps: 666,808,532

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 915.91994
Policy Entropy: 3.26744
Value Function Loss: 0.00415

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10583
Policy Update Magnitude: 0.54984
Value Function Update Magnitude: 0.67193

Collected Steps per Second: 22,483.19884
Overall Steps per Second: 10,824.26412

Timestep Collection Time: 2.22495
Timestep Consumption Time: 2.39652
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.62147

Cumulative Model Updates: 79,956
Cumulative Timesteps: 666,858,556

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 666858556...
Checkpoint 666858556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 930.98751
Policy Entropy: 3.26209
Value Function Loss: 0.00408

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11218
Policy Update Magnitude: 0.54535
Value Function Update Magnitude: 0.67899

Collected Steps per Second: 21,898.33478
Overall Steps per Second: 10,743.76740

Timestep Collection Time: 2.28346
Timestep Consumption Time: 2.37077
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.65423

Cumulative Model Updates: 79,962
Cumulative Timesteps: 666,908,560

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.53248
Policy Entropy: 3.26546
Value Function Loss: 0.00406

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11356
Policy Update Magnitude: 0.53906
Value Function Update Magnitude: 0.69075

Collected Steps per Second: 22,046.46069
Overall Steps per Second: 10,603.85732

Timestep Collection Time: 2.26830
Timestep Consumption Time: 2.44772
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.71602

Cumulative Model Updates: 79,968
Cumulative Timesteps: 666,958,568

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 666958568...
Checkpoint 666958568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424.16718
Policy Entropy: 3.25819
Value Function Loss: 0.00393

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10608
Policy Update Magnitude: 0.53633
Value Function Update Magnitude: 0.68766

Collected Steps per Second: 22,272.12346
Overall Steps per Second: 10,811.00590

Timestep Collection Time: 2.24604
Timestep Consumption Time: 2.38110
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.62714

Cumulative Model Updates: 79,974
Cumulative Timesteps: 667,008,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 958.77903
Policy Entropy: 3.27251
Value Function Loss: 0.00401

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10337
Policy Update Magnitude: 0.52810
Value Function Update Magnitude: 0.65294

Collected Steps per Second: 22,174.87426
Overall Steps per Second: 10,629.24447

Timestep Collection Time: 2.25616
Timestep Consumption Time: 2.45067
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 4.70683

Cumulative Model Updates: 79,980
Cumulative Timesteps: 667,058,622

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 667058622...
Checkpoint 667058622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 834.20403
Policy Entropy: 3.26602
Value Function Loss: 0.00409

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10511
Policy Update Magnitude: 0.52816
Value Function Update Magnitude: 0.63846

Collected Steps per Second: 22,150.70470
Overall Steps per Second: 10,631.60122

Timestep Collection Time: 2.25754
Timestep Consumption Time: 2.44599
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.70352

Cumulative Model Updates: 79,986
Cumulative Timesteps: 667,108,628

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 996.88186
Policy Entropy: 3.27100
Value Function Loss: 0.00419

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10888
Policy Update Magnitude: 0.53111
Value Function Update Magnitude: 0.64793

Collected Steps per Second: 22,075.53660
Overall Steps per Second: 10,772.82399

Timestep Collection Time: 2.26522
Timestep Consumption Time: 2.37664
PPO Batch Consumption Time: 0.28196
Total Iteration Time: 4.64187

Cumulative Model Updates: 79,992
Cumulative Timesteps: 667,158,634

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 667158634...
Checkpoint 667158634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.65947
Policy Entropy: 3.27373
Value Function Loss: 0.00409

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11600
Policy Update Magnitude: 0.53194
Value Function Update Magnitude: 0.63810

Collected Steps per Second: 21,873.27079
Overall Steps per Second: 10,699.25648

Timestep Collection Time: 2.28644
Timestep Consumption Time: 2.38790
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.67434

Cumulative Model Updates: 79,998
Cumulative Timesteps: 667,208,646

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 848.39096
Policy Entropy: 3.26410
Value Function Loss: 0.00421

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09707
Policy Update Magnitude: 0.53159
Value Function Update Magnitude: 0.62757

Collected Steps per Second: 21,884.11806
Overall Steps per Second: 10,609.34869

Timestep Collection Time: 2.28513
Timestep Consumption Time: 2.42845
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.71358

Cumulative Model Updates: 80,004
Cumulative Timesteps: 667,258,654

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 667258654...
Checkpoint 667258654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.95230
Policy Entropy: 3.28182
Value Function Loss: 0.00391

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08928
Policy Update Magnitude: 0.53085
Value Function Update Magnitude: 0.62026

Collected Steps per Second: 21,699.99460
Overall Steps per Second: 10,532.66221

Timestep Collection Time: 2.30479
Timestep Consumption Time: 2.44367
PPO Batch Consumption Time: 0.29705
Total Iteration Time: 4.74847

Cumulative Model Updates: 80,010
Cumulative Timesteps: 667,308,668

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 774.29974
Policy Entropy: 3.27142
Value Function Loss: 0.00393

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.52606
Value Function Update Magnitude: 0.61400

Collected Steps per Second: 21,780.72086
Overall Steps per Second: 10,577.99179

Timestep Collection Time: 2.29699
Timestep Consumption Time: 2.43265
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.72963

Cumulative Model Updates: 80,016
Cumulative Timesteps: 667,358,698

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 667358698...
Checkpoint 667358698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.86767
Policy Entropy: 3.27558
Value Function Loss: 0.00409

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08517
Policy Update Magnitude: 0.53119
Value Function Update Magnitude: 0.60296

Collected Steps per Second: 21,688.84733
Overall Steps per Second: 10,521.48762

Timestep Collection Time: 2.30542
Timestep Consumption Time: 2.44695
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.75237

Cumulative Model Updates: 80,022
Cumulative Timesteps: 667,408,700

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,374.82592
Policy Entropy: 3.26443
Value Function Loss: 0.00442

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08744
Policy Update Magnitude: 0.54602
Value Function Update Magnitude: 0.59926

Collected Steps per Second: 22,018.35993
Overall Steps per Second: 10,728.40080

Timestep Collection Time: 2.27147
Timestep Consumption Time: 2.39036
PPO Batch Consumption Time: 0.28406
Total Iteration Time: 4.66183

Cumulative Model Updates: 80,028
Cumulative Timesteps: 667,458,714

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 667458714...
Checkpoint 667458714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 945.06808
Policy Entropy: 3.26184
Value Function Loss: 0.00453

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.55465
Value Function Update Magnitude: 0.61045

Collected Steps per Second: 22,057.31558
Overall Steps per Second: 10,698.46591

Timestep Collection Time: 2.26691
Timestep Consumption Time: 2.40684
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.67375

Cumulative Model Updates: 80,034
Cumulative Timesteps: 667,508,716

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.32038
Policy Entropy: 3.26692
Value Function Loss: 0.00416

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10180
Policy Update Magnitude: 0.53830
Value Function Update Magnitude: 0.59994

Collected Steps per Second: 21,809.44729
Overall Steps per Second: 10,510.76095

Timestep Collection Time: 2.29359
Timestep Consumption Time: 2.46553
PPO Batch Consumption Time: 0.29627
Total Iteration Time: 4.75912

Cumulative Model Updates: 80,040
Cumulative Timesteps: 667,558,738

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 667558738...
Checkpoint 667558738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.68465
Policy Entropy: 3.25319
Value Function Loss: 0.00411

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11388
Policy Update Magnitude: 0.52632
Value Function Update Magnitude: 0.56186

Collected Steps per Second: 22,232.51670
Overall Steps per Second: 10,627.38236

Timestep Collection Time: 2.24932
Timestep Consumption Time: 2.45626
PPO Batch Consumption Time: 0.29789
Total Iteration Time: 4.70558

Cumulative Model Updates: 80,046
Cumulative Timesteps: 667,608,746

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680.30319
Policy Entropy: 3.22985
Value Function Loss: 0.00403

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11183
Policy Update Magnitude: 0.53266
Value Function Update Magnitude: 0.56128

Collected Steps per Second: 22,972.85940
Overall Steps per Second: 10,760.41075

Timestep Collection Time: 2.17744
Timestep Consumption Time: 2.47127
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.64871

Cumulative Model Updates: 80,052
Cumulative Timesteps: 667,658,768

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 667658768...
Checkpoint 667658768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 922.62576
Policy Entropy: 3.23229
Value Function Loss: 0.00411

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10511
Policy Update Magnitude: 0.53726
Value Function Update Magnitude: 0.58371

Collected Steps per Second: 22,922.80781
Overall Steps per Second: 10,809.60376

Timestep Collection Time: 2.18272
Timestep Consumption Time: 2.44594
PPO Batch Consumption Time: 0.28228
Total Iteration Time: 4.62866

Cumulative Model Updates: 80,058
Cumulative Timesteps: 667,708,802

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730.59560
Policy Entropy: 3.25642
Value Function Loss: 0.00421

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10543
Policy Update Magnitude: 0.54078
Value Function Update Magnitude: 0.59903

Collected Steps per Second: 22,663.53686
Overall Steps per Second: 10,606.52326

Timestep Collection Time: 2.20733
Timestep Consumption Time: 2.50920
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.71653

Cumulative Model Updates: 80,064
Cumulative Timesteps: 667,758,828

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 667758828...
Checkpoint 667758828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.17699
Policy Entropy: 3.27018
Value Function Loss: 0.00493

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09950
Policy Update Magnitude: 0.55247
Value Function Update Magnitude: 0.61246

Collected Steps per Second: 22,901.54834
Overall Steps per Second: 10,711.33340

Timestep Collection Time: 2.18413
Timestep Consumption Time: 2.48569
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.66982

Cumulative Model Updates: 80,070
Cumulative Timesteps: 667,808,848

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 778.61270
Policy Entropy: 3.25437
Value Function Loss: 0.00473

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.56263
Value Function Update Magnitude: 0.63189

Collected Steps per Second: 22,828.49770
Overall Steps per Second: 10,679.11126

Timestep Collection Time: 2.19051
Timestep Consumption Time: 2.49209
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.68260

Cumulative Model Updates: 80,076
Cumulative Timesteps: 667,858,854

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 667858854...
Checkpoint 667858854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 906.77155
Policy Entropy: 3.25587
Value Function Loss: 0.00464

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.56180
Value Function Update Magnitude: 0.62911

Collected Steps per Second: 22,395.30125
Overall Steps per Second: 10,641.63655

Timestep Collection Time: 2.23297
Timestep Consumption Time: 2.46631
PPO Batch Consumption Time: 0.28516
Total Iteration Time: 4.69928

Cumulative Model Updates: 80,082
Cumulative Timesteps: 667,908,862

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 882.12120
Policy Entropy: 3.24647
Value Function Loss: 0.00442

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09472
Policy Update Magnitude: 0.55993
Value Function Update Magnitude: 0.61845

Collected Steps per Second: 22,390.64449
Overall Steps per Second: 10,449.89148

Timestep Collection Time: 2.23379
Timestep Consumption Time: 2.55248
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.78627

Cumulative Model Updates: 80,088
Cumulative Timesteps: 667,958,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 667958878...
Checkpoint 667958878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 954.65256
Policy Entropy: 3.25065
Value Function Loss: 0.00457

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09693
Policy Update Magnitude: 0.56141
Value Function Update Magnitude: 0.62584

Collected Steps per Second: 22,465.82413
Overall Steps per Second: 10,661.54953

Timestep Collection Time: 2.22578
Timestep Consumption Time: 2.46434
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.69013

Cumulative Model Updates: 80,094
Cumulative Timesteps: 668,008,882

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.39573
Policy Entropy: 3.25031
Value Function Loss: 0.00440

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09651
Policy Update Magnitude: 0.55554
Value Function Update Magnitude: 0.65057

Collected Steps per Second: 22,400.67043
Overall Steps per Second: 10,474.13155

Timestep Collection Time: 2.23234
Timestep Consumption Time: 2.54189
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.77424

Cumulative Model Updates: 80,100
Cumulative Timesteps: 668,058,888

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 668058888...
Checkpoint 668058888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 875.98006
Policy Entropy: 3.24680
Value Function Loss: 0.00441

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09689
Policy Update Magnitude: 0.56131
Value Function Update Magnitude: 0.65597

Collected Steps per Second: 22,935.31701
Overall Steps per Second: 10,597.29146

Timestep Collection Time: 2.18057
Timestep Consumption Time: 2.53875
PPO Batch Consumption Time: 0.29795
Total Iteration Time: 4.71932

Cumulative Model Updates: 80,106
Cumulative Timesteps: 668,108,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.62721
Policy Entropy: 3.23709
Value Function Loss: 0.00439

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10436
Policy Update Magnitude: 0.55458
Value Function Update Magnitude: 0.63335

Collected Steps per Second: 22,509.99290
Overall Steps per Second: 10,429.42399

Timestep Collection Time: 2.22230
Timestep Consumption Time: 2.57413
PPO Batch Consumption Time: 0.29714
Total Iteration Time: 4.79643

Cumulative Model Updates: 80,112
Cumulative Timesteps: 668,158,924

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 668158924...
Checkpoint 668158924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 786.05066
Policy Entropy: 3.22584
Value Function Loss: 0.00460

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08842
Policy Update Magnitude: 0.56434
Value Function Update Magnitude: 0.63266

Collected Steps per Second: 22,954.59596
Overall Steps per Second: 10,669.94709

Timestep Collection Time: 2.17935
Timestep Consumption Time: 2.50915
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.68850

Cumulative Model Updates: 80,118
Cumulative Timesteps: 668,208,950

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.07869
Policy Entropy: 3.21900
Value Function Loss: 0.00468

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.57373
Value Function Update Magnitude: 0.63935

Collected Steps per Second: 22,441.64627
Overall Steps per Second: 10,527.19554

Timestep Collection Time: 2.22827
Timestep Consumption Time: 2.52191
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.75017

Cumulative Model Updates: 80,124
Cumulative Timesteps: 668,258,956

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 668258956...
Checkpoint 668258956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 789.36984
Policy Entropy: 3.22864
Value Function Loss: 0.00458

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.11959
Policy Update Magnitude: 0.57061
Value Function Update Magnitude: 0.65387

Collected Steps per Second: 22,873.33371
Overall Steps per Second: 10,606.96019

Timestep Collection Time: 2.18691
Timestep Consumption Time: 2.52905
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.71596

Cumulative Model Updates: 80,130
Cumulative Timesteps: 668,308,978

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 830.67919
Policy Entropy: 3.24169
Value Function Loss: 0.00406

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11133
Policy Update Magnitude: 0.55108
Value Function Update Magnitude: 0.63415

Collected Steps per Second: 22,736.98646
Overall Steps per Second: 10,754.59555

Timestep Collection Time: 2.19932
Timestep Consumption Time: 2.45041
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.64973

Cumulative Model Updates: 80,136
Cumulative Timesteps: 668,358,984

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 668358984...
Checkpoint 668358984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.42040
Policy Entropy: 3.24006
Value Function Loss: 0.00405

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10809
Policy Update Magnitude: 0.53239
Value Function Update Magnitude: 0.60745

Collected Steps per Second: 22,713.65231
Overall Steps per Second: 10,750.39438

Timestep Collection Time: 2.20141
Timestep Consumption Time: 2.44977
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.65118

Cumulative Model Updates: 80,142
Cumulative Timesteps: 668,408,986

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.56742
Policy Entropy: 3.25944
Value Function Loss: 0.00425

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09297
Policy Update Magnitude: 0.53870
Value Function Update Magnitude: 0.60647

Collected Steps per Second: 22,420.31250
Overall Steps per Second: 10,580.21413

Timestep Collection Time: 2.23075
Timestep Consumption Time: 2.49638
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.72713

Cumulative Model Updates: 80,148
Cumulative Timesteps: 668,459,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 668459000...
Checkpoint 668459000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 979.68916
Policy Entropy: 3.24710
Value Function Loss: 0.00438

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08674
Policy Update Magnitude: 0.55050
Value Function Update Magnitude: 0.61561

Collected Steps per Second: 22,058.22141
Overall Steps per Second: 10,516.88087

Timestep Collection Time: 2.26773
Timestep Consumption Time: 2.48863
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.75635

Cumulative Model Updates: 80,154
Cumulative Timesteps: 668,509,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.45227
Policy Entropy: 3.23995
Value Function Loss: 0.00448

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08992
Policy Update Magnitude: 0.55917
Value Function Update Magnitude: 0.62368

Collected Steps per Second: 21,824.50201
Overall Steps per Second: 10,452.00752

Timestep Collection Time: 2.29119
Timestep Consumption Time: 2.49297
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.78415

Cumulative Model Updates: 80,160
Cumulative Timesteps: 668,559,026

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 668559026...
Checkpoint 668559026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,406.62089
Policy Entropy: 3.23422
Value Function Loss: 0.00438

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11873
Policy Update Magnitude: 0.56602
Value Function Update Magnitude: 0.64123

Collected Steps per Second: 22,230.12437
Overall Steps per Second: 10,666.25013

Timestep Collection Time: 2.24974
Timestep Consumption Time: 2.43907
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.68881

Cumulative Model Updates: 80,166
Cumulative Timesteps: 668,609,038

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716.67114
Policy Entropy: 3.24408
Value Function Loss: 0.00434

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11149
Policy Update Magnitude: 0.55937
Value Function Update Magnitude: 0.65656

Collected Steps per Second: 22,233.08636
Overall Steps per Second: 10,462.29965

Timestep Collection Time: 2.24899
Timestep Consumption Time: 2.53026
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 4.77926

Cumulative Model Updates: 80,172
Cumulative Timesteps: 668,659,040

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 668659040...
Checkpoint 668659040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.62653
Policy Entropy: 3.26439
Value Function Loss: 0.00413

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11805
Policy Update Magnitude: 0.55828
Value Function Update Magnitude: 0.65068

Collected Steps per Second: 22,441.96698
Overall Steps per Second: 10,562.81844

Timestep Collection Time: 2.22797
Timestep Consumption Time: 2.50562
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.73359

Cumulative Model Updates: 80,178
Cumulative Timesteps: 668,709,040

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 934.73025
Policy Entropy: 3.26963
Value Function Loss: 0.00416

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11200
Policy Update Magnitude: 0.54313
Value Function Update Magnitude: 0.61144

Collected Steps per Second: 22,677.75401
Overall Steps per Second: 10,666.93645

Timestep Collection Time: 2.20569
Timestep Consumption Time: 2.48357
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.68926

Cumulative Model Updates: 80,184
Cumulative Timesteps: 668,759,060

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 668759060...
Checkpoint 668759060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 844.45290
Policy Entropy: 3.25959
Value Function Loss: 0.00428

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10667
Policy Update Magnitude: 0.54259
Value Function Update Magnitude: 0.58979

Collected Steps per Second: 22,906.55505
Overall Steps per Second: 10,845.47012

Timestep Collection Time: 2.18278
Timestep Consumption Time: 2.42744
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.61022

Cumulative Model Updates: 80,190
Cumulative Timesteps: 668,809,060

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 891.08484
Policy Entropy: 3.24794
Value Function Loss: 0.00446

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09561
Policy Update Magnitude: 0.55422
Value Function Update Magnitude: 0.60283

Collected Steps per Second: 22,673.37943
Overall Steps per Second: 10,609.02500

Timestep Collection Time: 2.20646
Timestep Consumption Time: 2.50914
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.71561

Cumulative Model Updates: 80,196
Cumulative Timesteps: 668,859,088

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 668859088...
Checkpoint 668859088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.02875
Policy Entropy: 3.24303
Value Function Loss: 0.00428

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.55215
Value Function Update Magnitude: 0.61678

Collected Steps per Second: 22,712.46630
Overall Steps per Second: 10,600.69661

Timestep Collection Time: 2.20267
Timestep Consumption Time: 2.51665
PPO Batch Consumption Time: 0.29829
Total Iteration Time: 4.71931

Cumulative Model Updates: 80,202
Cumulative Timesteps: 668,909,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328.04464
Policy Entropy: 3.24451
Value Function Loss: 0.00395

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08835
Policy Update Magnitude: 0.53576
Value Function Update Magnitude: 0.60645

Collected Steps per Second: 23,055.12866
Overall Steps per Second: 10,808.98367

Timestep Collection Time: 2.16898
Timestep Consumption Time: 2.45736
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.62634

Cumulative Model Updates: 80,208
Cumulative Timesteps: 668,959,122

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 668959122...
Checkpoint 668959122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.07348
Policy Entropy: 3.25120
Value Function Loss: 0.00397

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08742
Policy Update Magnitude: 0.52277
Value Function Update Magnitude: 0.59953

Collected Steps per Second: 22,554.86714
Overall Steps per Second: 10,653.81851

Timestep Collection Time: 2.21691
Timestep Consumption Time: 2.47644
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.69334

Cumulative Model Updates: 80,214
Cumulative Timesteps: 669,009,124

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.63514
Policy Entropy: 3.24926
Value Function Loss: 0.00420

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09018
Policy Update Magnitude: 0.52714
Value Function Update Magnitude: 0.60235

Collected Steps per Second: 22,609.69358
Overall Steps per Second: 10,641.85267

Timestep Collection Time: 2.21259
Timestep Consumption Time: 2.48828
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.70087

Cumulative Model Updates: 80,220
Cumulative Timesteps: 669,059,150

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 669059150...
Checkpoint 669059150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,418.33541
Policy Entropy: 3.25930
Value Function Loss: 0.00423

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10361
Policy Update Magnitude: 0.53707
Value Function Update Magnitude: 0.61994

Collected Steps per Second: 22,451.23491
Overall Steps per Second: 10,657.13716

Timestep Collection Time: 2.22847
Timestep Consumption Time: 2.46622
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.69469

Cumulative Model Updates: 80,226
Cumulative Timesteps: 669,109,182

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.57993
Policy Entropy: 3.27803
Value Function Loss: 0.00421

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11184
Policy Update Magnitude: 0.53451
Value Function Update Magnitude: 0.63748

Collected Steps per Second: 22,680.07290
Overall Steps per Second: 10,720.68749

Timestep Collection Time: 2.20537
Timestep Consumption Time: 2.46019
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.66556

Cumulative Model Updates: 80,232
Cumulative Timesteps: 669,159,200

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 669159200...
Checkpoint 669159200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 769.02352
Policy Entropy: 3.28367
Value Function Loss: 0.00412

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10670
Policy Update Magnitude: 0.53908
Value Function Update Magnitude: 0.65144

Collected Steps per Second: 22,549.85911
Overall Steps per Second: 10,639.73383

Timestep Collection Time: 2.21793
Timestep Consumption Time: 2.48275
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.70068

Cumulative Model Updates: 80,238
Cumulative Timesteps: 669,209,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.30064
Policy Entropy: 3.26217
Value Function Loss: 0.00401

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10465
Policy Update Magnitude: 0.54091
Value Function Update Magnitude: 0.65278

Collected Steps per Second: 22,348.23835
Overall Steps per Second: 10,525.56173

Timestep Collection Time: 2.23866
Timestep Consumption Time: 2.51454
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.75319

Cumulative Model Updates: 80,244
Cumulative Timesteps: 669,259,244

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 669259244...
Checkpoint 669259244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 908.33311
Policy Entropy: 3.25742
Value Function Loss: 0.00413

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09189
Policy Update Magnitude: 0.54126
Value Function Update Magnitude: 0.64019

Collected Steps per Second: 22,904.00329
Overall Steps per Second: 10,618.25721

Timestep Collection Time: 2.18433
Timestep Consumption Time: 2.52736
PPO Batch Consumption Time: 0.29717
Total Iteration Time: 4.71170

Cumulative Model Updates: 80,250
Cumulative Timesteps: 669,309,274

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,596.75777
Policy Entropy: 3.25862
Value Function Loss: 0.00401

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09824
Policy Update Magnitude: 0.53966
Value Function Update Magnitude: 0.62332

Collected Steps per Second: 22,969.87744
Overall Steps per Second: 10,879.27947

Timestep Collection Time: 2.17676
Timestep Consumption Time: 2.41913
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.59589

Cumulative Model Updates: 80,256
Cumulative Timesteps: 669,359,274

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 669359274...
Checkpoint 669359274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 763.61342
Policy Entropy: 3.28008
Value Function Loss: 0.00401

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09071
Policy Update Magnitude: 0.53043
Value Function Update Magnitude: 0.60630

Collected Steps per Second: 22,652.91613
Overall Steps per Second: 10,624.54556

Timestep Collection Time: 2.20837
Timestep Consumption Time: 2.50016
PPO Batch Consumption Time: 0.29739
Total Iteration Time: 4.70853

Cumulative Model Updates: 80,262
Cumulative Timesteps: 669,409,300

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.87066
Policy Entropy: 3.25519
Value Function Loss: 0.00408

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.52283
Value Function Update Magnitude: 0.59714

Collected Steps per Second: 22,841.52040
Overall Steps per Second: 10,827.66055

Timestep Collection Time: 2.18908
Timestep Consumption Time: 2.42890
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.61799

Cumulative Model Updates: 80,268
Cumulative Timesteps: 669,459,302

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 669459302...
Checkpoint 669459302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,534.60091
Policy Entropy: 3.25876
Value Function Loss: 0.00440

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09597
Policy Update Magnitude: 0.52932
Value Function Update Magnitude: 0.60174

Collected Steps per Second: 22,367.69990
Overall Steps per Second: 10,740.06344

Timestep Collection Time: 2.23546
Timestep Consumption Time: 2.42020
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.65565

Cumulative Model Updates: 80,274
Cumulative Timesteps: 669,509,304

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.01338
Policy Entropy: 3.24616
Value Function Loss: 0.00439

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09841
Policy Update Magnitude: 0.54782
Value Function Update Magnitude: 0.61604

Collected Steps per Second: 22,881.73835
Overall Steps per Second: 10,823.66835

Timestep Collection Time: 2.18567
Timestep Consumption Time: 2.43494
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.62061

Cumulative Model Updates: 80,280
Cumulative Timesteps: 669,559,316

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 669559316...
Checkpoint 669559316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,354.65861
Policy Entropy: 3.25499
Value Function Loss: 0.00426

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07997
Policy Update Magnitude: 0.55113
Value Function Update Magnitude: 0.64004

Collected Steps per Second: 21,841.25338
Overall Steps per Second: 10,557.13711

Timestep Collection Time: 2.28989
Timestep Consumption Time: 2.44757
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.73746

Cumulative Model Updates: 80,286
Cumulative Timesteps: 669,609,330

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349.37021
Policy Entropy: 3.25127
Value Function Loss: 0.00408

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08497
Policy Update Magnitude: 0.54254
Value Function Update Magnitude: 0.63654

Collected Steps per Second: 22,183.77051
Overall Steps per Second: 10,582.00901

Timestep Collection Time: 2.25489
Timestep Consumption Time: 2.47219
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.72708

Cumulative Model Updates: 80,292
Cumulative Timesteps: 669,659,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 669659352...
Checkpoint 669659352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 842.82517
Policy Entropy: 3.25958
Value Function Loss: 0.00422

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09011
Policy Update Magnitude: 0.54816
Value Function Update Magnitude: 0.62588

Collected Steps per Second: 22,062.96143
Overall Steps per Second: 10,680.12882

Timestep Collection Time: 2.26742
Timestep Consumption Time: 2.41661
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.68403

Cumulative Model Updates: 80,298
Cumulative Timesteps: 669,709,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 938.87633
Policy Entropy: 3.26794
Value Function Loss: 0.00425

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09029
Policy Update Magnitude: 0.54849
Value Function Update Magnitude: 0.64335

Collected Steps per Second: 22,505.69562
Overall Steps per Second: 10,850.29134

Timestep Collection Time: 2.22202
Timestep Consumption Time: 2.38689
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.60891

Cumulative Model Updates: 80,304
Cumulative Timesteps: 669,759,386

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 669759386...
Checkpoint 669759386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 763.22601
Policy Entropy: 3.28017
Value Function Loss: 0.00434

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09860
Policy Update Magnitude: 0.54340
Value Function Update Magnitude: 0.66655

Collected Steps per Second: 21,789.92704
Overall Steps per Second: 10,593.99686

Timestep Collection Time: 2.29684
Timestep Consumption Time: 2.42734
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.72418

Cumulative Model Updates: 80,310
Cumulative Timesteps: 669,809,434

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,394.57643
Policy Entropy: 3.27473
Value Function Loss: 0.00444

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08343
Policy Update Magnitude: 0.55120
Value Function Update Magnitude: 0.66623

Collected Steps per Second: 22,932.86505
Overall Steps per Second: 10,653.09531

Timestep Collection Time: 2.18124
Timestep Consumption Time: 2.51430
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.69554

Cumulative Model Updates: 80,316
Cumulative Timesteps: 669,859,456

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 669859456...
Checkpoint 669859456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 772.13331
Policy Entropy: 3.27670
Value Function Loss: 0.00421

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07375
Policy Update Magnitude: 0.54422
Value Function Update Magnitude: 0.64637

Collected Steps per Second: 22,838.22146
Overall Steps per Second: 10,826.84140

Timestep Collection Time: 2.18975
Timestep Consumption Time: 2.42933
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.61908

Cumulative Model Updates: 80,322
Cumulative Timesteps: 669,909,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386.75553
Policy Entropy: 3.26390
Value Function Loss: 0.00408

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08592
Policy Update Magnitude: 0.53188
Value Function Update Magnitude: 0.62906

Collected Steps per Second: 22,887.46112
Overall Steps per Second: 10,624.14291

Timestep Collection Time: 2.18565
Timestep Consumption Time: 2.52287
PPO Batch Consumption Time: 0.29797
Total Iteration Time: 4.70852

Cumulative Model Updates: 80,328
Cumulative Timesteps: 669,959,490

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 669959490...
Checkpoint 669959490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,579.94970
Policy Entropy: 3.25980
Value Function Loss: 0.00402

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.52428
Value Function Update Magnitude: 0.62062

Collected Steps per Second: 22,673.85484
Overall Steps per Second: 10,599.67438

Timestep Collection Time: 2.20598
Timestep Consumption Time: 2.51285
PPO Batch Consumption Time: 0.29794
Total Iteration Time: 4.71882

Cumulative Model Updates: 80,334
Cumulative Timesteps: 670,009,508

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 973.80601
Policy Entropy: 3.25730
Value Function Loss: 0.00414

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09261
Policy Update Magnitude: 0.52683
Value Function Update Magnitude: 0.60440

Collected Steps per Second: 22,796.18634
Overall Steps per Second: 10,833.25341

Timestep Collection Time: 2.19405
Timestep Consumption Time: 2.42284
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.61690

Cumulative Model Updates: 80,340
Cumulative Timesteps: 670,059,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 670059524...
Checkpoint 670059524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.52919
Policy Entropy: 3.27447
Value Function Loss: 0.00418

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08703
Policy Update Magnitude: 0.52780
Value Function Update Magnitude: 0.60964

Collected Steps per Second: 22,484.92947
Overall Steps per Second: 10,692.08451

Timestep Collection Time: 2.22469
Timestep Consumption Time: 2.45372
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.67841

Cumulative Model Updates: 80,346
Cumulative Timesteps: 670,109,546

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.44075
Policy Entropy: 3.28254
Value Function Loss: 0.00401

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08118
Policy Update Magnitude: 0.52314
Value Function Update Magnitude: 0.62933

Collected Steps per Second: 22,257.39108
Overall Steps per Second: 10,534.66844

Timestep Collection Time: 2.24725
Timestep Consumption Time: 2.50069
PPO Batch Consumption Time: 0.29739
Total Iteration Time: 4.74794

Cumulative Model Updates: 80,352
Cumulative Timesteps: 670,159,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 670159564...
Checkpoint 670159564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,491.38366
Policy Entropy: 3.27213
Value Function Loss: 0.00380

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08040
Policy Update Magnitude: 0.52619
Value Function Update Magnitude: 0.60494

Collected Steps per Second: 22,321.33990
Overall Steps per Second: 10,571.17155

Timestep Collection Time: 2.24037
Timestep Consumption Time: 2.49023
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.73060

Cumulative Model Updates: 80,358
Cumulative Timesteps: 670,209,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.36974
Policy Entropy: 3.26716
Value Function Loss: 0.00390

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.07847
Policy Update Magnitude: 0.52670
Value Function Update Magnitude: 0.58711

Collected Steps per Second: 22,708.64596
Overall Steps per Second: 10,805.09446

Timestep Collection Time: 2.20260
Timestep Consumption Time: 2.42652
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.62911

Cumulative Model Updates: 80,364
Cumulative Timesteps: 670,259,590

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 670259590...
Checkpoint 670259590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 846.58958
Policy Entropy: 3.27642
Value Function Loss: 0.00376

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.07869
Policy Update Magnitude: 0.52320
Value Function Update Magnitude: 0.58638

Collected Steps per Second: 21,472.16653
Overall Steps per Second: 10,346.49869

Timestep Collection Time: 2.32934
Timestep Consumption Time: 2.50476
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.83410

Cumulative Model Updates: 80,370
Cumulative Timesteps: 670,309,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,528.25905
Policy Entropy: 3.29772
Value Function Loss: 0.00377

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07392
Policy Update Magnitude: 0.51490
Value Function Update Magnitude: 0.57614

Collected Steps per Second: 22,841.54270
Overall Steps per Second: 10,736.05910

Timestep Collection Time: 2.19031
Timestep Consumption Time: 2.46969
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.66000

Cumulative Model Updates: 80,376
Cumulative Timesteps: 670,359,636

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 670359636...
Checkpoint 670359636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421.94850
Policy Entropy: 3.29919
Value Function Loss: 0.00388

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07583
Policy Update Magnitude: 0.50510
Value Function Update Magnitude: 0.55764

Collected Steps per Second: 22,621.41509
Overall Steps per Second: 10,709.53667

Timestep Collection Time: 2.21127
Timestep Consumption Time: 2.45952
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.67079

Cumulative Model Updates: 80,382
Cumulative Timesteps: 670,409,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 952.62337
Policy Entropy: 3.29616
Value Function Loss: 0.00424

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07782
Policy Update Magnitude: 0.51587
Value Function Update Magnitude: 0.55782

Collected Steps per Second: 22,531.08262
Overall Steps per Second: 10,574.22883

Timestep Collection Time: 2.21960
Timestep Consumption Time: 2.50982
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.72942

Cumulative Model Updates: 80,388
Cumulative Timesteps: 670,459,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 670459668...
Checkpoint 670459668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 780.97404
Policy Entropy: 3.28377
Value Function Loss: 0.00432

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.53040
Value Function Update Magnitude: 0.56076

Collected Steps per Second: 22,643.88863
Overall Steps per Second: 10,611.13635

Timestep Collection Time: 2.20845
Timestep Consumption Time: 2.50433
PPO Batch Consumption Time: 0.29848
Total Iteration Time: 4.71278

Cumulative Model Updates: 80,394
Cumulative Timesteps: 670,509,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.96884
Policy Entropy: 3.27821
Value Function Loss: 0.00429

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.07962
Policy Update Magnitude: 0.53000
Value Function Update Magnitude: 0.56481

Collected Steps per Second: 22,762.47539
Overall Steps per Second: 10,809.24373

Timestep Collection Time: 2.19721
Timestep Consumption Time: 2.42975
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.62697

Cumulative Model Updates: 80,400
Cumulative Timesteps: 670,559,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 670559690...
Checkpoint 670559690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 940.39720
Policy Entropy: 3.26229
Value Function Loss: 0.00423

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09015
Policy Update Magnitude: 0.52934
Value Function Update Magnitude: 0.56399

Collected Steps per Second: 22,545.23768
Overall Steps per Second: 10,690.15962

Timestep Collection Time: 2.21803
Timestep Consumption Time: 2.45973
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.67776

Cumulative Model Updates: 80,406
Cumulative Timesteps: 670,609,696

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220.31468
Policy Entropy: 3.26794
Value Function Loss: 0.00409

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10100
Policy Update Magnitude: 0.52509
Value Function Update Magnitude: 0.59569

Collected Steps per Second: 22,485.71527
Overall Steps per Second: 10,621.37101

Timestep Collection Time: 2.22470
Timestep Consumption Time: 2.48505
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.70975

Cumulative Model Updates: 80,412
Cumulative Timesteps: 670,659,720

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 670659720...
Checkpoint 670659720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.37894
Policy Entropy: 3.27163
Value Function Loss: 0.00417

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.52791
Value Function Update Magnitude: 0.60552

Collected Steps per Second: 22,094.39573
Overall Steps per Second: 10,496.48403

Timestep Collection Time: 2.26428
Timestep Consumption Time: 2.50188
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.76617

Cumulative Model Updates: 80,418
Cumulative Timesteps: 670,709,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,378.39738
Policy Entropy: 3.29049
Value Function Loss: 0.00404

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07943
Policy Update Magnitude: 0.52509
Value Function Update Magnitude: 0.60357

Collected Steps per Second: 22,550.26053
Overall Steps per Second: 10,633.05156

Timestep Collection Time: 2.21807
Timestep Consumption Time: 2.48594
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.70401

Cumulative Model Updates: 80,424
Cumulative Timesteps: 670,759,766

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 670759766...
Checkpoint 670759766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,443.68429
Policy Entropy: 3.28027
Value Function Loss: 0.00408

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08891
Policy Update Magnitude: 0.52123
Value Function Update Magnitude: 0.59052

Collected Steps per Second: 22,176.39949
Overall Steps per Second: 10,523.13730

Timestep Collection Time: 2.25618
Timestep Consumption Time: 2.49848
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.75467

Cumulative Model Updates: 80,430
Cumulative Timesteps: 670,809,800

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.65639
Policy Entropy: 3.27556
Value Function Loss: 0.00399

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09051
Policy Update Magnitude: 0.52192
Value Function Update Magnitude: 0.59477

Collected Steps per Second: 23,097.32400
Overall Steps per Second: 10,783.60148

Timestep Collection Time: 2.16597
Timestep Consumption Time: 2.47330
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.63927

Cumulative Model Updates: 80,436
Cumulative Timesteps: 670,859,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 670859828...
Checkpoint 670859828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.39718
Policy Entropy: 3.26816
Value Function Loss: 0.00397

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08942
Policy Update Magnitude: 0.51871
Value Function Update Magnitude: 0.59755

Collected Steps per Second: 22,445.43086
Overall Steps per Second: 10,712.87027

Timestep Collection Time: 2.22816
Timestep Consumption Time: 2.44024
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.66840

Cumulative Model Updates: 80,442
Cumulative Timesteps: 670,909,840

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 969.11528
Policy Entropy: 3.26448
Value Function Loss: 0.00396

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09383
Policy Update Magnitude: 0.52528
Value Function Update Magnitude: 0.61651

Collected Steps per Second: 22,914.23835
Overall Steps per Second: 10,808.79951

Timestep Collection Time: 2.18301
Timestep Consumption Time: 2.44489
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.62790

Cumulative Model Updates: 80,448
Cumulative Timesteps: 670,959,862

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 670959862...
Checkpoint 670959862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 886.25200
Policy Entropy: 3.26266
Value Function Loss: 0.00404

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08378
Policy Update Magnitude: 0.53670
Value Function Update Magnitude: 0.63104

Collected Steps per Second: 22,895.44543
Overall Steps per Second: 10,513.92261

Timestep Collection Time: 2.18489
Timestep Consumption Time: 2.57299
PPO Batch Consumption Time: 0.30001
Total Iteration Time: 4.75788

Cumulative Model Updates: 80,454
Cumulative Timesteps: 671,009,886

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.72437
Policy Entropy: 3.26440
Value Function Loss: 0.00409

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08204
Policy Update Magnitude: 0.53548
Value Function Update Magnitude: 0.61127

Collected Steps per Second: 23,326.28081
Overall Steps per Second: 10,758.69845

Timestep Collection Time: 2.14368
Timestep Consumption Time: 2.50410
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.64777

Cumulative Model Updates: 80,460
Cumulative Timesteps: 671,059,890

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 671059890...
Checkpoint 671059890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 775.49516
Policy Entropy: 3.24275
Value Function Loss: 0.00442

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10545
Policy Update Magnitude: 0.54288
Value Function Update Magnitude: 0.60387

Collected Steps per Second: 22,582.69493
Overall Steps per Second: 10,617.70130

Timestep Collection Time: 2.21488
Timestep Consumption Time: 2.49593
PPO Batch Consumption Time: 0.29705
Total Iteration Time: 4.71081

Cumulative Model Updates: 80,466
Cumulative Timesteps: 671,109,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 985.33325
Policy Entropy: 3.23088
Value Function Loss: 0.00438

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10917
Policy Update Magnitude: 0.55759
Value Function Update Magnitude: 0.62391

Collected Steps per Second: 22,125.02141
Overall Steps per Second: 10,564.30853

Timestep Collection Time: 2.26025
Timestep Consumption Time: 2.47343
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.73367

Cumulative Model Updates: 80,472
Cumulative Timesteps: 671,159,916

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 671159916...
Checkpoint 671159916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.01333
Policy Entropy: 3.23187
Value Function Loss: 0.00450

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.56352
Value Function Update Magnitude: 0.62931

Collected Steps per Second: 22,047.34076
Overall Steps per Second: 10,483.93839

Timestep Collection Time: 2.26785
Timestep Consumption Time: 2.50135
PPO Batch Consumption Time: 0.29711
Total Iteration Time: 4.76920

Cumulative Model Updates: 80,478
Cumulative Timesteps: 671,209,916

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 742.94664
Policy Entropy: 3.23565
Value Function Loss: 0.00433

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09545
Policy Update Magnitude: 0.56112
Value Function Update Magnitude: 0.62483

Collected Steps per Second: 22,409.64887
Overall Steps per Second: 10,628.38120

Timestep Collection Time: 2.23181
Timestep Consumption Time: 2.47390
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.70570

Cumulative Model Updates: 80,484
Cumulative Timesteps: 671,259,930

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 671259930...
Checkpoint 671259930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.01903
Policy Entropy: 3.22903
Value Function Loss: 0.00427

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.55067
Value Function Update Magnitude: 0.62108

Collected Steps per Second: 22,202.10755
Overall Steps per Second: 10,509.96690

Timestep Collection Time: 2.25231
Timestep Consumption Time: 2.50565
PPO Batch Consumption Time: 0.29684
Total Iteration Time: 4.75796

Cumulative Model Updates: 80,490
Cumulative Timesteps: 671,309,936

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467.20448
Policy Entropy: 3.23564
Value Function Loss: 0.00425

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11531
Policy Update Magnitude: 0.54622
Value Function Update Magnitude: 0.61947

Collected Steps per Second: 23,199.34922
Overall Steps per Second: 10,835.78872

Timestep Collection Time: 2.15644
Timestep Consumption Time: 2.46048
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.61692

Cumulative Model Updates: 80,496
Cumulative Timesteps: 671,359,964

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 671359964...
Checkpoint 671359964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.41750
Policy Entropy: 3.25993
Value Function Loss: 0.00417

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11123
Policy Update Magnitude: 0.54416
Value Function Update Magnitude: 0.61851

Collected Steps per Second: 22,483.12271
Overall Steps per Second: 10,599.54958

Timestep Collection Time: 2.22442
Timestep Consumption Time: 2.49389
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.71831

Cumulative Model Updates: 80,502
Cumulative Timesteps: 671,409,976

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,738.12385
Policy Entropy: 3.26608
Value Function Loss: 0.00428

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.54159
Value Function Update Magnitude: 0.62094

Collected Steps per Second: 23,083.62202
Overall Steps per Second: 10,857.19120

Timestep Collection Time: 2.16647
Timestep Consumption Time: 2.43969
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.60616

Cumulative Model Updates: 80,508
Cumulative Timesteps: 671,459,986

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 671459986...
Checkpoint 671459986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.54662
Policy Entropy: 3.24780
Value Function Loss: 0.00426

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10468
Policy Update Magnitude: 0.53687
Value Function Update Magnitude: 0.58848

Collected Steps per Second: 22,300.70633
Overall Steps per Second: 10,715.92681

Timestep Collection Time: 2.24235
Timestep Consumption Time: 2.42416
PPO Batch Consumption Time: 0.28172
Total Iteration Time: 4.66651

Cumulative Model Updates: 80,514
Cumulative Timesteps: 671,509,992

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889.42697
Policy Entropy: 3.24760
Value Function Loss: 0.00419

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09461
Policy Update Magnitude: 0.53231
Value Function Update Magnitude: 0.58874

Collected Steps per Second: 22,039.90886
Overall Steps per Second: 10,444.33761

Timestep Collection Time: 2.26979
Timestep Consumption Time: 2.51998
PPO Batch Consumption Time: 0.29798
Total Iteration Time: 4.78977

Cumulative Model Updates: 80,520
Cumulative Timesteps: 671,560,018

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 671560018...
Checkpoint 671560018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.94334
Policy Entropy: 3.26182
Value Function Loss: 0.00399

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.52909
Value Function Update Magnitude: 0.59817

Collected Steps per Second: 21,827.63508
Overall Steps per Second: 10,581.57924

Timestep Collection Time: 2.29177
Timestep Consumption Time: 2.43569
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.72746

Cumulative Model Updates: 80,526
Cumulative Timesteps: 671,610,042

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,483.56484
Policy Entropy: 3.27141
Value Function Loss: 0.00387

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08813
Policy Update Magnitude: 0.53003
Value Function Update Magnitude: 0.60155

Collected Steps per Second: 22,976.58117
Overall Steps per Second: 10,846.23944

Timestep Collection Time: 2.17613
Timestep Consumption Time: 2.43376
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.60989

Cumulative Model Updates: 80,532
Cumulative Timesteps: 671,660,042

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 671660042...
Checkpoint 671660042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 835.17823
Policy Entropy: 3.25603
Value Function Loss: 0.00404

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09617
Policy Update Magnitude: 0.53628
Value Function Update Magnitude: 0.59673

Collected Steps per Second: 22,591.61841
Overall Steps per Second: 10,704.89535

Timestep Collection Time: 2.21356
Timestep Consumption Time: 2.45794
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.67151

Cumulative Model Updates: 80,538
Cumulative Timesteps: 671,710,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,755.57326
Policy Entropy: 3.24888
Value Function Loss: 0.00415

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10391
Policy Update Magnitude: 0.53585
Value Function Update Magnitude: 0.58323

Collected Steps per Second: 22,821.71582
Overall Steps per Second: 10,709.25889

Timestep Collection Time: 2.19177
Timestep Consumption Time: 2.47895
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.67072

Cumulative Model Updates: 80,544
Cumulative Timesteps: 671,760,070

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 671760070...
Checkpoint 671760070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.19978
Policy Entropy: 3.24084
Value Function Loss: 0.00430

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10040
Policy Update Magnitude: 0.54482
Value Function Update Magnitude: 0.59018

Collected Steps per Second: 22,735.12516
Overall Steps per Second: 10,814.39393

Timestep Collection Time: 2.20082
Timestep Consumption Time: 2.42597
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.62680

Cumulative Model Updates: 80,550
Cumulative Timesteps: 671,810,106

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 965.64770
Policy Entropy: 3.25934
Value Function Loss: 0.00403

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09314
Policy Update Magnitude: 0.54380
Value Function Update Magnitude: 0.60415

Collected Steps per Second: 22,947.20976
Overall Steps per Second: 10,871.74761

Timestep Collection Time: 2.17961
Timestep Consumption Time: 2.42094
PPO Batch Consumption Time: 0.28286
Total Iteration Time: 4.60055

Cumulative Model Updates: 80,556
Cumulative Timesteps: 671,860,122

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 671860122...
Checkpoint 671860122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 905.55214
Policy Entropy: 3.25499
Value Function Loss: 0.00409

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11099
Policy Update Magnitude: 0.54714
Value Function Update Magnitude: 0.63570

Collected Steps per Second: 22,414.71408
Overall Steps per Second: 10,722.67143

Timestep Collection Time: 2.23077
Timestep Consumption Time: 2.43244
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.66320

Cumulative Model Updates: 80,562
Cumulative Timesteps: 671,910,124

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.75445
Policy Entropy: 3.26206
Value Function Loss: 0.00414

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11233
Policy Update Magnitude: 0.54570
Value Function Update Magnitude: 0.65014

Collected Steps per Second: 23,001.03895
Overall Steps per Second: 10,831.03450

Timestep Collection Time: 2.17555
Timestep Consumption Time: 2.44450
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.62006

Cumulative Model Updates: 80,568
Cumulative Timesteps: 671,960,164

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 671960164...
Checkpoint 671960164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 713.11052
Policy Entropy: 3.24854
Value Function Loss: 0.00423

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.54459
Value Function Update Magnitude: 0.64790

Collected Steps per Second: 22,098.53854
Overall Steps per Second: 10,646.87673

Timestep Collection Time: 2.26350
Timestep Consumption Time: 2.43459
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.69809

Cumulative Model Updates: 80,574
Cumulative Timesteps: 672,010,184

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.85033
Policy Entropy: 3.24082
Value Function Loss: 0.00426

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11777
Policy Update Magnitude: 0.54084
Value Function Update Magnitude: 0.62986

Collected Steps per Second: 22,533.98830
Overall Steps per Second: 10,573.60910

Timestep Collection Time: 2.21949
Timestep Consumption Time: 2.51059
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 4.73008

Cumulative Model Updates: 80,580
Cumulative Timesteps: 672,060,198

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 672060198...
Checkpoint 672060198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647.00267
Policy Entropy: 3.24423
Value Function Loss: 0.00441

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11651
Policy Update Magnitude: 0.54290
Value Function Update Magnitude: 0.60785

Collected Steps per Second: 22,035.25085
Overall Steps per Second: 10,694.58930

Timestep Collection Time: 2.26955
Timestep Consumption Time: 2.40665
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.67620

Cumulative Model Updates: 80,586
Cumulative Timesteps: 672,110,208

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.27859
Policy Entropy: 3.24442
Value Function Loss: 0.00429

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09804
Policy Update Magnitude: 0.54822
Value Function Update Magnitude: 0.61791

Collected Steps per Second: 22,277.18802
Overall Steps per Second: 10,559.52629

Timestep Collection Time: 2.24463
Timestep Consumption Time: 2.49081
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.73544

Cumulative Model Updates: 80,592
Cumulative Timesteps: 672,160,212

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 672160212...
Checkpoint 672160212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,272.38903
Policy Entropy: 3.24826
Value Function Loss: 0.00420

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11421
Policy Update Magnitude: 0.54664
Value Function Update Magnitude: 0.62086

Collected Steps per Second: 22,574.43657
Overall Steps per Second: 10,649.50093

Timestep Collection Time: 2.21498
Timestep Consumption Time: 2.48026
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.69524

Cumulative Model Updates: 80,598
Cumulative Timesteps: 672,210,214

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.84449
Policy Entropy: 3.25719
Value Function Loss: 0.00408

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11363
Policy Update Magnitude: 0.53668
Value Function Update Magnitude: 0.61293

Collected Steps per Second: 22,888.51797
Overall Steps per Second: 10,783.26993

Timestep Collection Time: 2.18459
Timestep Consumption Time: 2.45241
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.63700

Cumulative Model Updates: 80,604
Cumulative Timesteps: 672,260,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 672260216...
Checkpoint 672260216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.54028
Policy Entropy: 3.25625
Value Function Loss: 0.00398

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09440
Policy Update Magnitude: 0.53638
Value Function Update Magnitude: 0.60317

Collected Steps per Second: 22,569.65141
Overall Steps per Second: 10,592.80426

Timestep Collection Time: 2.21536
Timestep Consumption Time: 2.50482
PPO Batch Consumption Time: 0.29692
Total Iteration Time: 4.72019

Cumulative Model Updates: 80,610
Cumulative Timesteps: 672,310,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.33682
Policy Entropy: 3.26433
Value Function Loss: 0.00386

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08291
Policy Update Magnitude: 0.53835
Value Function Update Magnitude: 0.60730

Collected Steps per Second: 22,929.13721
Overall Steps per Second: 10,833.52614

Timestep Collection Time: 2.18081
Timestep Consumption Time: 2.43487
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.61567

Cumulative Model Updates: 80,616
Cumulative Timesteps: 672,360,220

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 672360220...
Checkpoint 672360220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.35268
Policy Entropy: 3.26431
Value Function Loss: 0.00376

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08433
Policy Update Magnitude: 0.53267
Value Function Update Magnitude: 0.59889

Collected Steps per Second: 22,321.30403
Overall Steps per Second: 10,708.21389

Timestep Collection Time: 2.24028
Timestep Consumption Time: 2.42959
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.66987

Cumulative Model Updates: 80,622
Cumulative Timesteps: 672,410,226

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.49219
Policy Entropy: 3.25723
Value Function Loss: 0.00402

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08197
Policy Update Magnitude: 0.53578
Value Function Update Magnitude: 0.60342

Collected Steps per Second: 23,151.40841
Overall Steps per Second: 10,916.78921

Timestep Collection Time: 2.16056
Timestep Consumption Time: 2.42137
PPO Batch Consumption Time: 0.28121
Total Iteration Time: 4.58193

Cumulative Model Updates: 80,628
Cumulative Timesteps: 672,460,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 672460246...
Checkpoint 672460246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.39449
Policy Entropy: 3.23690
Value Function Loss: 0.00435

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.54533
Value Function Update Magnitude: 0.63022

Collected Steps per Second: 22,451.97658
Overall Steps per Second: 10,626.24751

Timestep Collection Time: 2.22706
Timestep Consumption Time: 2.47845
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.70552

Cumulative Model Updates: 80,634
Cumulative Timesteps: 672,510,248

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.16725
Policy Entropy: 3.23510
Value Function Loss: 0.00440

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09238
Policy Update Magnitude: 0.55558
Value Function Update Magnitude: 0.64918

Collected Steps per Second: 22,908.61053
Overall Steps per Second: 10,816.34990

Timestep Collection Time: 2.18389
Timestep Consumption Time: 2.44151
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.62541

Cumulative Model Updates: 80,640
Cumulative Timesteps: 672,560,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 672560278...
Checkpoint 672560278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,721.42276
Policy Entropy: 3.24351
Value Function Loss: 0.00421

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10188
Policy Update Magnitude: 0.55346
Value Function Update Magnitude: 0.64180

Collected Steps per Second: 22,284.05455
Overall Steps per Second: 10,735.03272

Timestep Collection Time: 2.24439
Timestep Consumption Time: 2.41457
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.65895

Cumulative Model Updates: 80,646
Cumulative Timesteps: 672,610,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581.14806
Policy Entropy: 3.24298
Value Function Loss: 0.00414

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.54973
Value Function Update Magnitude: 0.62009

Collected Steps per Second: 22,380.81466
Overall Steps per Second: 10,566.45274

Timestep Collection Time: 2.23406
Timestep Consumption Time: 2.49790
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.73196

Cumulative Model Updates: 80,652
Cumulative Timesteps: 672,660,292

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 672660292...
Checkpoint 672660292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628.77118
Policy Entropy: 3.25363
Value Function Loss: 0.00416

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.55016
Value Function Update Magnitude: 0.60699

Collected Steps per Second: 22,102.42573
Overall Steps per Second: 10,507.86729

Timestep Collection Time: 2.26247
Timestep Consumption Time: 2.49644
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.75891

Cumulative Model Updates: 80,658
Cumulative Timesteps: 672,710,298

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,417.52618
Policy Entropy: 3.24428
Value Function Loss: 0.00413

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10212
Policy Update Magnitude: 0.54737
Value Function Update Magnitude: 0.62342

Collected Steps per Second: 22,645.68672
Overall Steps per Second: 10,674.04392

Timestep Collection Time: 2.20907
Timestep Consumption Time: 2.47762
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.68670

Cumulative Model Updates: 80,664
Cumulative Timesteps: 672,760,324

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 672760324...
Checkpoint 672760324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,767.54898
Policy Entropy: 3.24227
Value Function Loss: 0.00409

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.54718
Value Function Update Magnitude: 0.63572

Collected Steps per Second: 23,000.89646
Overall Steps per Second: 10,814.94346

Timestep Collection Time: 2.17478
Timestep Consumption Time: 2.45048
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.62527

Cumulative Model Updates: 80,670
Cumulative Timesteps: 672,810,346

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 868.11591
Policy Entropy: 3.23475
Value Function Loss: 0.00414

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09880
Policy Update Magnitude: 0.54958
Value Function Update Magnitude: 0.64708

Collected Steps per Second: 22,976.20971
Overall Steps per Second: 10,834.43355

Timestep Collection Time: 2.17695
Timestep Consumption Time: 2.43963
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.61658

Cumulative Model Updates: 80,676
Cumulative Timesteps: 672,860,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 672860364...
Checkpoint 672860364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 976.58865
Policy Entropy: 3.23496
Value Function Loss: 0.00410

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11241
Policy Update Magnitude: 0.54652
Value Function Update Magnitude: 0.65745

Collected Steps per Second: 22,805.71155
Overall Steps per Second: 10,765.72801

Timestep Collection Time: 2.19366
Timestep Consumption Time: 2.45331
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.64697

Cumulative Model Updates: 80,682
Cumulative Timesteps: 672,910,392

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 927.42138
Policy Entropy: 3.23126
Value Function Loss: 0.00419

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11705
Policy Update Magnitude: 0.54576
Value Function Update Magnitude: 0.65439

Collected Steps per Second: 22,939.54605
Overall Steps per Second: 10,860.75359

Timestep Collection Time: 2.18017
Timestep Consumption Time: 2.42467
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.60484

Cumulative Model Updates: 80,688
Cumulative Timesteps: 672,960,404

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 672960404...
Checkpoint 672960404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.87491
Policy Entropy: 3.24765
Value Function Loss: 0.00413

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09905
Policy Update Magnitude: 0.54903
Value Function Update Magnitude: 0.65331

Collected Steps per Second: 22,681.29927
Overall Steps per Second: 10,693.97148

Timestep Collection Time: 2.20508
Timestep Consumption Time: 2.47176
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.67684

Cumulative Model Updates: 80,694
Cumulative Timesteps: 673,010,418

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.69525
Policy Entropy: 3.24030
Value Function Loss: 0.00428

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10101
Policy Update Magnitude: 0.54638
Value Function Update Magnitude: 0.64571

Collected Steps per Second: 22,982.71150
Overall Steps per Second: 10,876.64062

Timestep Collection Time: 2.17616
Timestep Consumption Time: 2.42214
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.59829

Cumulative Model Updates: 80,700
Cumulative Timesteps: 673,060,432

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 673060432...
Checkpoint 673060432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 962.51063
Policy Entropy: 3.23240
Value Function Loss: 0.00417

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08731
Policy Update Magnitude: 0.55296
Value Function Update Magnitude: 0.62721

Collected Steps per Second: 21,904.56332
Overall Steps per Second: 10,605.53458

Timestep Collection Time: 2.28281
Timestep Consumption Time: 2.43208
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.71490

Cumulative Model Updates: 80,706
Cumulative Timesteps: 673,110,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.56126
Policy Entropy: 3.22242
Value Function Loss: 0.00415

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08441
Policy Update Magnitude: 0.55969
Value Function Update Magnitude: 0.61996

Collected Steps per Second: 22,575.71819
Overall Steps per Second: 10,615.84284

Timestep Collection Time: 2.21539
Timestep Consumption Time: 2.49587
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.71126

Cumulative Model Updates: 80,712
Cumulative Timesteps: 673,160,450

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 673160450...
Checkpoint 673160450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.26235
Policy Entropy: 3.23525
Value Function Loss: 0.00396

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08796
Policy Update Magnitude: 0.55624
Value Function Update Magnitude: 0.62250

Collected Steps per Second: 22,173.98227
Overall Steps per Second: 10,515.40144

Timestep Collection Time: 2.25535
Timestep Consumption Time: 2.50054
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.75588

Cumulative Model Updates: 80,718
Cumulative Timesteps: 673,210,460

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 895.20499
Policy Entropy: 3.25065
Value Function Loss: 0.00390

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08669
Policy Update Magnitude: 0.54445
Value Function Update Magnitude: 0.60362

Collected Steps per Second: 22,652.82348
Overall Steps per Second: 10,659.33864

Timestep Collection Time: 2.20864
Timestep Consumption Time: 2.48508
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.69372

Cumulative Model Updates: 80,724
Cumulative Timesteps: 673,260,492

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 673260492...
Checkpoint 673260492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,671.03531
Policy Entropy: 3.25693
Value Function Loss: 0.00387

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08005
Policy Update Magnitude: 0.54338
Value Function Update Magnitude: 0.60299

Collected Steps per Second: 22,686.64763
Overall Steps per Second: 10,646.76807

Timestep Collection Time: 2.20509
Timestep Consumption Time: 2.49362
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.69870

Cumulative Model Updates: 80,730
Cumulative Timesteps: 673,310,518

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 997.52335
Policy Entropy: 3.24417
Value Function Loss: 0.00387

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09673
Policy Update Magnitude: 0.54508
Value Function Update Magnitude: 0.58063

Collected Steps per Second: 23,081.51467
Overall Steps per Second: 10,680.64429

Timestep Collection Time: 2.16667
Timestep Consumption Time: 2.51563
PPO Batch Consumption Time: 0.29735
Total Iteration Time: 4.68230

Cumulative Model Updates: 80,736
Cumulative Timesteps: 673,360,528

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 673360528...
Checkpoint 673360528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 716.99477
Policy Entropy: 3.23336
Value Function Loss: 0.00412

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.54624
Value Function Update Magnitude: 0.57847

Collected Steps per Second: 22,698.15539
Overall Steps per Second: 10,631.94161

Timestep Collection Time: 2.20300
Timestep Consumption Time: 2.50019
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.70319

Cumulative Model Updates: 80,742
Cumulative Timesteps: 673,410,532

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 832.81126
Policy Entropy: 3.23266
Value Function Loss: 0.00404

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10112
Policy Update Magnitude: 0.54749
Value Function Update Magnitude: 0.59435

Collected Steps per Second: 20,736.70388
Overall Steps per Second: 10,096.72296

Timestep Collection Time: 2.41244
Timestep Consumption Time: 2.54224
PPO Batch Consumption Time: 0.29755
Total Iteration Time: 4.95468

Cumulative Model Updates: 80,748
Cumulative Timesteps: 673,460,558

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 673460558...
Checkpoint 673460558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,775.22604
Policy Entropy: 3.22118
Value Function Loss: 0.00426

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09127
Policy Update Magnitude: 0.55180
Value Function Update Magnitude: 0.58824

Collected Steps per Second: 22,233.05335
Overall Steps per Second: 10,614.90951

Timestep Collection Time: 2.24989
Timestep Consumption Time: 2.46253
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.71243

Cumulative Model Updates: 80,754
Cumulative Timesteps: 673,510,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.95549
Policy Entropy: 3.21629
Value Function Loss: 0.00422

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09887
Policy Update Magnitude: 0.55888
Value Function Update Magnitude: 0.59036

Collected Steps per Second: 22,913.49665
Overall Steps per Second: 10,854.93983

Timestep Collection Time: 2.18229
Timestep Consumption Time: 2.42427
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.60657

Cumulative Model Updates: 80,760
Cumulative Timesteps: 673,560,584

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 673560584...
Checkpoint 673560584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.24965
Policy Entropy: 3.20580
Value Function Loss: 0.00449

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08737
Policy Update Magnitude: 0.57074
Value Function Update Magnitude: 0.60269

Collected Steps per Second: 22,561.04703
Overall Steps per Second: 10,654.81964

Timestep Collection Time: 2.21621
Timestep Consumption Time: 2.47650
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.69271

Cumulative Model Updates: 80,766
Cumulative Timesteps: 673,610,584

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.24278
Policy Entropy: 3.21169
Value Function Loss: 0.00417

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08817
Policy Update Magnitude: 0.56903
Value Function Update Magnitude: 0.60730

Collected Steps per Second: 22,225.47769
Overall Steps per Second: 10,522.55089

Timestep Collection Time: 2.25057
Timestep Consumption Time: 2.50303
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.75360

Cumulative Model Updates: 80,772
Cumulative Timesteps: 673,660,604

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 673660604...
Checkpoint 673660604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.60295
Policy Entropy: 3.22670
Value Function Loss: 0.00428

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09432
Policy Update Magnitude: 0.55919
Value Function Update Magnitude: 0.59721

Collected Steps per Second: 22,293.23108
Overall Steps per Second: 10,610.91390

Timestep Collection Time: 2.24382
Timestep Consumption Time: 2.47038
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.71420

Cumulative Model Updates: 80,778
Cumulative Timesteps: 673,710,626

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.56530
Policy Entropy: 3.22700
Value Function Loss: 0.00404

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09261
Policy Update Magnitude: 0.55099
Value Function Update Magnitude: 0.61114

Collected Steps per Second: 22,745.32529
Overall Steps per Second: 10,786.48437

Timestep Collection Time: 2.19913
Timestep Consumption Time: 2.43815
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.63728

Cumulative Model Updates: 80,784
Cumulative Timesteps: 673,760,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 673760646...
Checkpoint 673760646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,782.82313
Policy Entropy: 3.21823
Value Function Loss: 0.00417

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.55405
Value Function Update Magnitude: 0.62702

Collected Steps per Second: 22,858.16473
Overall Steps per Second: 10,786.35026

Timestep Collection Time: 2.18758
Timestep Consumption Time: 2.44828
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.63586

Cumulative Model Updates: 80,790
Cumulative Timesteps: 673,810,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,145.03221
Policy Entropy: 3.22355
Value Function Loss: 0.00418

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08911
Policy Update Magnitude: 0.55964
Value Function Update Magnitude: 0.63328

Collected Steps per Second: 22,592.00789
Overall Steps per Second: 10,733.99242

Timestep Collection Time: 2.21406
Timestep Consumption Time: 2.44590
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.65996

Cumulative Model Updates: 80,796
Cumulative Timesteps: 673,860,670

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 673860670...
Checkpoint 673860670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.20546
Policy Entropy: 3.23037
Value Function Loss: 0.00416

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08877
Policy Update Magnitude: 0.55806
Value Function Update Magnitude: 0.62378

Collected Steps per Second: 22,577.92212
Overall Steps per Second: 10,812.11063

Timestep Collection Time: 2.21491
Timestep Consumption Time: 2.41028
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.62518

Cumulative Model Updates: 80,802
Cumulative Timesteps: 673,910,678

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 931.96825
Policy Entropy: 3.23222
Value Function Loss: 0.00407

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09467
Policy Update Magnitude: 0.55032
Value Function Update Magnitude: 0.60325

Collected Steps per Second: 23,006.12051
Overall Steps per Second: 10,813.07412

Timestep Collection Time: 2.17386
Timestep Consumption Time: 2.45129
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.62514

Cumulative Model Updates: 80,808
Cumulative Timesteps: 673,960,690

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 673960690...
Checkpoint 673960690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603.85882
Policy Entropy: 3.22459
Value Function Loss: 0.00380

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08741
Policy Update Magnitude: 0.54541
Value Function Update Magnitude: 0.61984

Collected Steps per Second: 23,010.96652
Overall Steps per Second: 10,684.48220

Timestep Collection Time: 2.17401
Timestep Consumption Time: 2.50811
PPO Batch Consumption Time: 0.29642
Total Iteration Time: 4.68212

Cumulative Model Updates: 80,814
Cumulative Timesteps: 674,010,716

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683.60203
Policy Entropy: 3.22056
Value Function Loss: 0.00386

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09315
Policy Update Magnitude: 0.53818
Value Function Update Magnitude: 0.62820

Collected Steps per Second: 22,675.30711
Overall Steps per Second: 10,673.39905

Timestep Collection Time: 2.20504
Timestep Consumption Time: 2.47950
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.68454

Cumulative Model Updates: 80,820
Cumulative Timesteps: 674,060,716

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 674060716...
Checkpoint 674060716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,471.27125
Policy Entropy: 3.23479
Value Function Loss: 0.00400

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09397
Policy Update Magnitude: 0.54414
Value Function Update Magnitude: 0.63785

Collected Steps per Second: 22,836.77567
Overall Steps per Second: 10,845.13927

Timestep Collection Time: 2.19041
Timestep Consumption Time: 2.42197
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.61239

Cumulative Model Updates: 80,826
Cumulative Timesteps: 674,110,738

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.27161
Policy Entropy: 3.23986
Value Function Loss: 0.00424

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08418
Policy Update Magnitude: 0.55073
Value Function Update Magnitude: 0.65942

Collected Steps per Second: 21,827.95940
Overall Steps per Second: 10,516.40448

Timestep Collection Time: 2.29192
Timestep Consumption Time: 2.46522
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.75714

Cumulative Model Updates: 80,832
Cumulative Timesteps: 674,160,766

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 674160766...
Checkpoint 674160766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674.00997
Policy Entropy: 3.25421
Value Function Loss: 0.00425

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07661
Policy Update Magnitude: 0.55694
Value Function Update Magnitude: 0.66669

Collected Steps per Second: 22,414.85889
Overall Steps per Second: 10,634.09620

Timestep Collection Time: 2.23147
Timestep Consumption Time: 2.47208
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.70355

Cumulative Model Updates: 80,838
Cumulative Timesteps: 674,210,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717.31836
Policy Entropy: 3.25332
Value Function Loss: 0.00415

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07748
Policy Update Magnitude: 0.55369
Value Function Update Magnitude: 0.66962

Collected Steps per Second: 22,512.37735
Overall Steps per Second: 10,653.08811

Timestep Collection Time: 2.22136
Timestep Consumption Time: 2.47287
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.69423

Cumulative Model Updates: 80,844
Cumulative Timesteps: 674,260,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 674260792...
Checkpoint 674260792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 931.78666
Policy Entropy: 3.23980
Value Function Loss: 0.00424

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07464
Policy Update Magnitude: 0.55322
Value Function Update Magnitude: 0.66031

Collected Steps per Second: 22,605.12574
Overall Steps per Second: 10,765.36411

Timestep Collection Time: 2.21304
Timestep Consumption Time: 2.43390
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.64694

Cumulative Model Updates: 80,850
Cumulative Timesteps: 674,310,818

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697.64470
Policy Entropy: 3.22799
Value Function Loss: 0.00427

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07876
Policy Update Magnitude: 0.55763
Value Function Update Magnitude: 0.64198

Collected Steps per Second: 23,009.42061
Overall Steps per Second: 10,621.25216

Timestep Collection Time: 2.17389
Timestep Consumption Time: 2.53553
PPO Batch Consumption Time: 0.29665
Total Iteration Time: 4.70943

Cumulative Model Updates: 80,856
Cumulative Timesteps: 674,360,838

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 674360838...
Checkpoint 674360838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 835.93446
Policy Entropy: 3.22487
Value Function Loss: 0.00425

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09463
Policy Update Magnitude: 0.55281
Value Function Update Magnitude: 0.62472

Collected Steps per Second: 22,556.44489
Overall Steps per Second: 10,585.31461

Timestep Collection Time: 2.21737
Timestep Consumption Time: 2.50767
PPO Batch Consumption Time: 0.29653
Total Iteration Time: 4.72504

Cumulative Model Updates: 80,862
Cumulative Timesteps: 674,410,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 926.40196
Policy Entropy: 3.23884
Value Function Loss: 0.00421

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.54758
Value Function Update Magnitude: 0.60615

Collected Steps per Second: 22,690.74192
Overall Steps per Second: 10,656.43059

Timestep Collection Time: 2.20486
Timestep Consumption Time: 2.48995
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.69482

Cumulative Model Updates: 80,868
Cumulative Timesteps: 674,460,884

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 674460884...
Checkpoint 674460884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.31216
Policy Entropy: 3.25074
Value Function Loss: 0.00418

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08420
Policy Update Magnitude: 0.54555
Value Function Update Magnitude: 0.61622

Collected Steps per Second: 22,705.60477
Overall Steps per Second: 10,816.43077

Timestep Collection Time: 2.20298
Timestep Consumption Time: 2.42147
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.62445

Cumulative Model Updates: 80,874
Cumulative Timesteps: 674,510,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.58377
Policy Entropy: 3.23770
Value Function Loss: 0.00414

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08585
Policy Update Magnitude: 0.54529
Value Function Update Magnitude: 0.63487

Collected Steps per Second: 22,649.54156
Overall Steps per Second: 10,639.05732

Timestep Collection Time: 2.20755
Timestep Consumption Time: 2.49211
PPO Batch Consumption Time: 0.29550
Total Iteration Time: 4.69966

Cumulative Model Updates: 80,880
Cumulative Timesteps: 674,560,904

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 674560904...
Checkpoint 674560904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.71152
Policy Entropy: 3.23000
Value Function Loss: 0.00372

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08411
Policy Update Magnitude: 0.54103
Value Function Update Magnitude: 0.61960

Collected Steps per Second: 23,131.81046
Overall Steps per Second: 10,907.78231

Timestep Collection Time: 2.16325
Timestep Consumption Time: 2.42430
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.58755

Cumulative Model Updates: 80,886
Cumulative Timesteps: 674,610,944

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,569.90495
Policy Entropy: 3.22583
Value Function Loss: 0.00365

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08011
Policy Update Magnitude: 0.53145
Value Function Update Magnitude: 0.58563

Collected Steps per Second: 22,575.22339
Overall Steps per Second: 10,567.69188

Timestep Collection Time: 2.21491
Timestep Consumption Time: 2.51669
PPO Batch Consumption Time: 0.29660
Total Iteration Time: 4.73159

Cumulative Model Updates: 80,892
Cumulative Timesteps: 674,660,946

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 674660946...
Checkpoint 674660946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.83258
Policy Entropy: 3.21951
Value Function Loss: 0.00390

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07768
Policy Update Magnitude: 0.53051
Value Function Update Magnitude: 0.58152

Collected Steps per Second: 22,328.49537
Overall Steps per Second: 10,613.94038

Timestep Collection Time: 2.23947
Timestep Consumption Time: 2.47169
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.71116

Cumulative Model Updates: 80,898
Cumulative Timesteps: 674,710,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 776.01724
Policy Entropy: 3.22312
Value Function Loss: 0.00426

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.54926
Value Function Update Magnitude: 0.61967

Collected Steps per Second: 22,605.72174
Overall Steps per Second: 10,663.03943

Timestep Collection Time: 2.21316
Timestep Consumption Time: 2.47875
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.69191

Cumulative Model Updates: 80,904
Cumulative Timesteps: 674,760,980

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 674760980...
Checkpoint 674760980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.12896
Policy Entropy: 3.21374
Value Function Loss: 0.00427

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09684
Policy Update Magnitude: 0.56185
Value Function Update Magnitude: 0.66090

Collected Steps per Second: 22,509.17967
Overall Steps per Second: 10,760.75543

Timestep Collection Time: 2.22274
Timestep Consumption Time: 2.42675
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.64949

Cumulative Model Updates: 80,910
Cumulative Timesteps: 674,811,012

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220.39451
Policy Entropy: 3.23712
Value Function Loss: 0.00426

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.56669
Value Function Update Magnitude: 0.68198

Collected Steps per Second: 22,243.08092
Overall Steps per Second: 10,557.97197

Timestep Collection Time: 2.24825
Timestep Consumption Time: 2.48827
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.73652

Cumulative Model Updates: 80,916
Cumulative Timesteps: 674,861,020

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 674861020...
Checkpoint 674861020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668.90964
Policy Entropy: 3.22734
Value Function Loss: 0.00434

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.56581
Value Function Update Magnitude: 0.69006

Collected Steps per Second: 22,258.59032
Overall Steps per Second: 10,643.97721

Timestep Collection Time: 2.24794
Timestep Consumption Time: 2.45293
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.70087

Cumulative Model Updates: 80,922
Cumulative Timesteps: 674,911,056

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,563.05340
Policy Entropy: 3.23540
Value Function Loss: 0.00422

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.11165
Policy Update Magnitude: 0.56601
Value Function Update Magnitude: 0.67888

Collected Steps per Second: 23,202.77884
Overall Steps per Second: 10,836.14224

Timestep Collection Time: 2.15500
Timestep Consumption Time: 2.45937
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.61437

Cumulative Model Updates: 80,928
Cumulative Timesteps: 674,961,058

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 674961058...
Checkpoint 674961058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711.81618
Policy Entropy: 3.24162
Value Function Loss: 0.00430

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11704
Policy Update Magnitude: 0.56260
Value Function Update Magnitude: 0.64314

Collected Steps per Second: 22,704.41030
Overall Steps per Second: 10,724.25205

Timestep Collection Time: 2.20230
Timestep Consumption Time: 2.46021
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.66252

Cumulative Model Updates: 80,934
Cumulative Timesteps: 675,011,060

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.59677
Policy Entropy: 3.26111
Value Function Loss: 0.00414

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12221
Policy Update Magnitude: 0.55295
Value Function Update Magnitude: 0.62606

Collected Steps per Second: 22,554.67771
Overall Steps per Second: 10,621.82115

Timestep Collection Time: 2.21799
Timestep Consumption Time: 2.49175
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.70974

Cumulative Model Updates: 80,940
Cumulative Timesteps: 675,061,086

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 675061086...
Checkpoint 675061086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.76973
Policy Entropy: 3.25510
Value Function Loss: 0.00412

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11198
Policy Update Magnitude: 0.54654
Value Function Update Magnitude: 0.62039

Collected Steps per Second: 22,493.07951
Overall Steps per Second: 10,631.80376

Timestep Collection Time: 2.22380
Timestep Consumption Time: 2.48096
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.70475

Cumulative Model Updates: 80,946
Cumulative Timesteps: 675,111,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357.34254
Policy Entropy: 3.23428
Value Function Loss: 0.00420

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11368
Policy Update Magnitude: 0.54722
Value Function Update Magnitude: 0.62949

Collected Steps per Second: 22,926.33008
Overall Steps per Second: 10,746.20460

Timestep Collection Time: 2.18151
Timestep Consumption Time: 2.47260
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.65411

Cumulative Model Updates: 80,952
Cumulative Timesteps: 675,161,120

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 675161120...
Checkpoint 675161120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.58131
Policy Entropy: 3.23217
Value Function Loss: 0.00417

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10776
Policy Update Magnitude: 0.55630
Value Function Update Magnitude: 0.64464

Collected Steps per Second: 22,766.48071
Overall Steps per Second: 10,648.62893

Timestep Collection Time: 2.19639
Timestep Consumption Time: 2.49943
PPO Batch Consumption Time: 0.29687
Total Iteration Time: 4.69582

Cumulative Model Updates: 80,958
Cumulative Timesteps: 675,211,124

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 930.51180
Policy Entropy: 3.22593
Value Function Loss: 0.00420

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09876
Policy Update Magnitude: 0.56132
Value Function Update Magnitude: 0.65101

Collected Steps per Second: 22,099.38405
Overall Steps per Second: 10,467.57805

Timestep Collection Time: 2.26341
Timestep Consumption Time: 2.51515
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 4.77856

Cumulative Model Updates: 80,964
Cumulative Timesteps: 675,261,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 675261144...
Checkpoint 675261144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 861.72757
Policy Entropy: 3.23775
Value Function Loss: 0.00420

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.55593
Value Function Update Magnitude: 0.64688

Collected Steps per Second: 22,290.61294
Overall Steps per Second: 10,639.24759

Timestep Collection Time: 2.24390
Timestep Consumption Time: 2.45737
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.70127

Cumulative Model Updates: 80,970
Cumulative Timesteps: 675,311,162

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.33932
Policy Entropy: 3.24291
Value Function Loss: 0.00417

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09042
Policy Update Magnitude: 0.55884
Value Function Update Magnitude: 0.65114

Collected Steps per Second: 22,085.67912
Overall Steps per Second: 10,421.49783

Timestep Collection Time: 2.26445
Timestep Consumption Time: 2.53447
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.79893

Cumulative Model Updates: 80,976
Cumulative Timesteps: 675,361,174

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 675361174...
Checkpoint 675361174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 849.41881
Policy Entropy: 3.24891
Value Function Loss: 0.00431

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.56177
Value Function Update Magnitude: 0.65642

Collected Steps per Second: 22,349.16880
Overall Steps per Second: 10,685.59280

Timestep Collection Time: 2.23856
Timestep Consumption Time: 2.44344
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.68201

Cumulative Model Updates: 80,982
Cumulative Timesteps: 675,411,204

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,816.08192
Policy Entropy: 3.24039
Value Function Loss: 0.00429

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10878
Policy Update Magnitude: 0.56281
Value Function Update Magnitude: 0.67197

Collected Steps per Second: 22,466.28373
Overall Steps per Second: 10,507.02399

Timestep Collection Time: 2.22627
Timestep Consumption Time: 2.53397
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 4.76024

Cumulative Model Updates: 80,988
Cumulative Timesteps: 675,461,220

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 675461220...
Checkpoint 675461220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673.10789
Policy Entropy: 3.22845
Value Function Loss: 0.00448

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10210
Policy Update Magnitude: 0.56419
Value Function Update Magnitude: 0.66341

Collected Steps per Second: 22,674.13499
Overall Steps per Second: 10,608.90430

Timestep Collection Time: 2.20533
Timestep Consumption Time: 2.50807
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.71340

Cumulative Model Updates: 80,994
Cumulative Timesteps: 675,511,224

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392.78946
Policy Entropy: 3.22772
Value Function Loss: 0.00443

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.56370
Value Function Update Magnitude: 0.63841

Collected Steps per Second: 22,764.84245
Overall Steps per Second: 10,790.47709

Timestep Collection Time: 2.19725
Timestep Consumption Time: 2.43832
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.63557

Cumulative Model Updates: 81,000
Cumulative Timesteps: 675,561,244

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 675561244...
Checkpoint 675561244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,428.84460
Policy Entropy: 3.23706
Value Function Loss: 0.00443

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10126
Policy Update Magnitude: 0.56155
Value Function Update Magnitude: 0.63819

Collected Steps per Second: 22,599.70429
Overall Steps per Second: 10,734.28792

Timestep Collection Time: 2.21321
Timestep Consumption Time: 2.44643
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.65965

Cumulative Model Updates: 81,006
Cumulative Timesteps: 675,611,262

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.77809
Policy Entropy: 3.27258
Value Function Loss: 0.00414

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09304
Policy Update Magnitude: 0.54602
Value Function Update Magnitude: 0.64825

Collected Steps per Second: 22,560.96249
Overall Steps per Second: 10,627.93503

Timestep Collection Time: 2.21657
Timestep Consumption Time: 2.48876
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.70534

Cumulative Model Updates: 81,012
Cumulative Timesteps: 675,661,270

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 675661270...
Checkpoint 675661270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667.58649
Policy Entropy: 3.27497
Value Function Loss: 0.00400

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.53646
Value Function Update Magnitude: 0.65572

Collected Steps per Second: 22,881.59486
Overall Steps per Second: 10,848.40115

Timestep Collection Time: 2.18560
Timestep Consumption Time: 2.42430
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.60990

Cumulative Model Updates: 81,018
Cumulative Timesteps: 675,711,280

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.18088
Policy Entropy: 3.28864
Value Function Loss: 0.00390

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09147
Policy Update Magnitude: 0.53381
Value Function Update Magnitude: 0.64173

Collected Steps per Second: 22,448.27661
Overall Steps per Second: 10,512.92212

Timestep Collection Time: 2.22841
Timestep Consumption Time: 2.52992
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.75833

Cumulative Model Updates: 81,024
Cumulative Timesteps: 675,761,304

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 675761304...
Checkpoint 675761304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.12617
Policy Entropy: 3.27471
Value Function Loss: 0.00421

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08191
Policy Update Magnitude: 0.53693
Value Function Update Magnitude: 0.63047

Collected Steps per Second: 22,337.10580
Overall Steps per Second: 10,675.33595

Timestep Collection Time: 2.23852
Timestep Consumption Time: 2.44536
PPO Batch Consumption Time: 0.28204
Total Iteration Time: 4.68388

Cumulative Model Updates: 81,030
Cumulative Timesteps: 675,811,306

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469.24949
Policy Entropy: 3.28539
Value Function Loss: 0.00405

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08693
Policy Update Magnitude: 0.53230
Value Function Update Magnitude: 0.63556

Collected Steps per Second: 22,329.05481
Overall Steps per Second: 10,452.81551

Timestep Collection Time: 2.23968
Timestep Consumption Time: 2.54467
PPO Batch Consumption Time: 0.29644
Total Iteration Time: 4.78436

Cumulative Model Updates: 81,036
Cumulative Timesteps: 675,861,316

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 675861316...
Checkpoint 675861316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,887.57006
Policy Entropy: 3.28248
Value Function Loss: 0.00393

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09020
Policy Update Magnitude: 0.53355
Value Function Update Magnitude: 0.63116

Collected Steps per Second: 22,594.68929
Overall Steps per Second: 10,590.38506

Timestep Collection Time: 2.21353
Timestep Consumption Time: 2.50906
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.72259

Cumulative Model Updates: 81,042
Cumulative Timesteps: 675,911,330

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 908.60046
Policy Entropy: 3.28857
Value Function Loss: 0.00395

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09503
Policy Update Magnitude: 0.53252
Value Function Update Magnitude: 0.63392

Collected Steps per Second: 22,748.31309
Overall Steps per Second: 10,598.69468

Timestep Collection Time: 2.19902
Timestep Consumption Time: 2.52081
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.71983

Cumulative Model Updates: 81,048
Cumulative Timesteps: 675,961,354

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 675961354...
Checkpoint 675961354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.88346
Policy Entropy: 3.28617
Value Function Loss: 0.00403

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09406
Policy Update Magnitude: 0.53281
Value Function Update Magnitude: 0.64858

Collected Steps per Second: 23,064.85225
Overall Steps per Second: 10,847.41092

Timestep Collection Time: 2.16797
Timestep Consumption Time: 2.44179
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.60976

Cumulative Model Updates: 81,054
Cumulative Timesteps: 676,011,358

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 970.46938
Policy Entropy: 3.26883
Value Function Loss: 0.00391

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09635
Policy Update Magnitude: 0.53862
Value Function Update Magnitude: 0.64514

Collected Steps per Second: 22,564.64464
Overall Steps per Second: 10,608.79173

Timestep Collection Time: 2.21674
Timestep Consumption Time: 2.49822
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.71496

Cumulative Model Updates: 81,060
Cumulative Timesteps: 676,061,378

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 676061378...
Checkpoint 676061378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.27804
Policy Entropy: 3.24854
Value Function Loss: 0.00405

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10777
Policy Update Magnitude: 0.54076
Value Function Update Magnitude: 0.64584

Collected Steps per Second: 22,850.69294
Overall Steps per Second: 10,660.28067

Timestep Collection Time: 2.18864
Timestep Consumption Time: 2.50279
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 4.69143

Cumulative Model Updates: 81,066
Cumulative Timesteps: 676,111,390

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.91616
Policy Entropy: 3.22856
Value Function Loss: 0.00411

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10988
Policy Update Magnitude: 0.55116
Value Function Update Magnitude: 0.64632

Collected Steps per Second: 23,150.26044
Overall Steps per Second: 10,906.94388

Timestep Collection Time: 2.15998
Timestep Consumption Time: 2.42463
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.58460

Cumulative Model Updates: 81,072
Cumulative Timesteps: 676,161,394

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 676161394...
Checkpoint 676161394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 909.17438
Policy Entropy: 3.21768
Value Function Loss: 0.00425

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12238
Policy Update Magnitude: 0.56344
Value Function Update Magnitude: 0.65017

Collected Steps per Second: 22,551.99440
Overall Steps per Second: 10,643.26825

Timestep Collection Time: 2.21772
Timestep Consumption Time: 2.48140
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.69912

Cumulative Model Updates: 81,078
Cumulative Timesteps: 676,211,408

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.41962
Policy Entropy: 3.23749
Value Function Loss: 0.00417

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11136
Policy Update Magnitude: 0.56115
Value Function Update Magnitude: 0.64523

Collected Steps per Second: 21,712.62227
Overall Steps per Second: 10,440.89401

Timestep Collection Time: 2.30290
Timestep Consumption Time: 2.48615
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.78905

Cumulative Model Updates: 81,084
Cumulative Timesteps: 676,261,410

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 676261410...
Checkpoint 676261410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693.21917
Policy Entropy: 3.23357
Value Function Loss: 0.00442

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08782
Policy Update Magnitude: 0.56392
Value Function Update Magnitude: 0.64707

Collected Steps per Second: 22,423.44254
Overall Steps per Second: 10,653.20541

Timestep Collection Time: 2.23061
Timestep Consumption Time: 2.46450
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.69511

Cumulative Model Updates: 81,090
Cumulative Timesteps: 676,311,428

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 960.70686
Policy Entropy: 3.23958
Value Function Loss: 0.00444

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08685
Policy Update Magnitude: 0.57184
Value Function Update Magnitude: 0.63604

Collected Steps per Second: 22,238.60897
Overall Steps per Second: 10,537.77524

Timestep Collection Time: 2.24897
Timestep Consumption Time: 2.49719
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.74616

Cumulative Model Updates: 81,096
Cumulative Timesteps: 676,361,442

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 676361442...
Checkpoint 676361442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.23761
Policy Entropy: 3.23007
Value Function Loss: 0.00456

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09627
Policy Update Magnitude: 0.57259
Value Function Update Magnitude: 0.63842

Collected Steps per Second: 22,705.42424
Overall Steps per Second: 10,662.41335

Timestep Collection Time: 2.20309
Timestep Consumption Time: 2.48835
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.69143

Cumulative Model Updates: 81,102
Cumulative Timesteps: 676,411,464

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.67576
Policy Entropy: 3.24917
Value Function Loss: 0.00447

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.56714
Value Function Update Magnitude: 0.64334

Collected Steps per Second: 22,677.34437
Overall Steps per Second: 10,760.26170

Timestep Collection Time: 2.20493
Timestep Consumption Time: 2.44198
PPO Batch Consumption Time: 0.28243
Total Iteration Time: 4.64691

Cumulative Model Updates: 81,108
Cumulative Timesteps: 676,461,466

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 676461466...
Checkpoint 676461466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 840.85488
Policy Entropy: 3.25719
Value Function Loss: 0.00427

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.55809
Value Function Update Magnitude: 0.63556

Collected Steps per Second: 22,387.22085
Overall Steps per Second: 10,651.13604

Timestep Collection Time: 2.23386
Timestep Consumption Time: 2.46141
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.69527

Cumulative Model Updates: 81,114
Cumulative Timesteps: 676,511,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.06810
Policy Entropy: 3.27490
Value Function Loss: 0.00397

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09458
Policy Update Magnitude: 0.54543
Value Function Update Magnitude: 0.60994

Collected Steps per Second: 22,822.19376
Overall Steps per Second: 10,795.69332

Timestep Collection Time: 2.19173
Timestep Consumption Time: 2.44160
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.63333

Cumulative Model Updates: 81,120
Cumulative Timesteps: 676,561,496

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 676561496...
Checkpoint 676561496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,630.97328
Policy Entropy: 3.26819
Value Function Loss: 0.00407

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09894
Policy Update Magnitude: 0.54010
Value Function Update Magnitude: 0.60368

Collected Steps per Second: 22,678.59313
Overall Steps per Second: 10,773.90373

Timestep Collection Time: 2.20472
Timestep Consumption Time: 2.43612
PPO Batch Consumption Time: 0.28178
Total Iteration Time: 4.64084

Cumulative Model Updates: 81,126
Cumulative Timesteps: 676,611,496

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.59810
Policy Entropy: 3.27347
Value Function Loss: 0.00409

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11381
Policy Update Magnitude: 0.54584
Value Function Update Magnitude: 0.60558

Collected Steps per Second: 22,889.31097
Overall Steps per Second: 10,833.78229

Timestep Collection Time: 2.18495
Timestep Consumption Time: 2.43135
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.61630

Cumulative Model Updates: 81,132
Cumulative Timesteps: 676,661,508

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 676661508...
Checkpoint 676661508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.91144
Policy Entropy: 3.27391
Value Function Loss: 0.00408

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10732
Policy Update Magnitude: 0.54813
Value Function Update Magnitude: 0.61445

Collected Steps per Second: 22,676.73188
Overall Steps per Second: 10,724.50448

Timestep Collection Time: 2.20623
Timestep Consumption Time: 2.45879
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.66502

Cumulative Model Updates: 81,138
Cumulative Timesteps: 676,711,538

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,689.10871
Policy Entropy: 3.28561
Value Function Loss: 0.00371

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.53885
Value Function Update Magnitude: 0.62200

Collected Steps per Second: 22,494.09064
Overall Steps per Second: 10,639.19782

Timestep Collection Time: 2.22414
Timestep Consumption Time: 2.47828
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.70242

Cumulative Model Updates: 81,144
Cumulative Timesteps: 676,761,568

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 676761568...
Checkpoint 676761568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,117.22230
Policy Entropy: 3.27288
Value Function Loss: 0.00388

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09050
Policy Update Magnitude: 0.52865
Value Function Update Magnitude: 0.61535

Collected Steps per Second: 22,641.40520
Overall Steps per Second: 10,803.24247

Timestep Collection Time: 2.20834
Timestep Consumption Time: 2.41990
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.62824

Cumulative Model Updates: 81,150
Cumulative Timesteps: 676,811,568

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.11612
Policy Entropy: 3.25706
Value Function Loss: 0.00403

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10051
Policy Update Magnitude: 0.53821
Value Function Update Magnitude: 0.62726

Collected Steps per Second: 12,951.49160
Overall Steps per Second: 6,661.20434

Timestep Collection Time: 3.86473
Timestep Consumption Time: 3.64953
PPO Batch Consumption Time: 0.35974
Total Iteration Time: 7.51426

Cumulative Model Updates: 81,156
Cumulative Timesteps: 676,861,622

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 676861622...
Checkpoint 676861622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,568.97033
Policy Entropy: 3.24773
Value Function Loss: 0.00417

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10237
Policy Update Magnitude: 0.53911
Value Function Update Magnitude: 0.62732

Collected Steps per Second: 13,372.05225
Overall Steps per Second: 7,854.83730

Timestep Collection Time: 3.73974
Timestep Consumption Time: 2.62678
PPO Batch Consumption Time: 0.29765
Total Iteration Time: 6.36652

Cumulative Model Updates: 81,162
Cumulative Timesteps: 676,911,630

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,076.83493
Policy Entropy: 3.24715
Value Function Loss: 0.00419

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09198
Policy Update Magnitude: 0.54165
Value Function Update Magnitude: 0.61122

Collected Steps per Second: 21,841.20808
Overall Steps per Second: 10,334.85603

Timestep Collection Time: 2.29127
Timestep Consumption Time: 2.55099
PPO Batch Consumption Time: 0.29867
Total Iteration Time: 4.84225

Cumulative Model Updates: 81,168
Cumulative Timesteps: 676,961,674

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 676961674...
Checkpoint 676961674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.07532
Policy Entropy: 3.25989
Value Function Loss: 0.00414

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08583
Policy Update Magnitude: 0.53822
Value Function Update Magnitude: 0.62166

Collected Steps per Second: 17,089.37617
Overall Steps per Second: 9,278.00965

Timestep Collection Time: 2.92603
Timestep Consumption Time: 2.46349
PPO Batch Consumption Time: 0.28412
Total Iteration Time: 5.38952

Cumulative Model Updates: 81,174
Cumulative Timesteps: 677,011,678

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,648.17076
Policy Entropy: 3.26576
Value Function Loss: 0.00406

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.54257
Value Function Update Magnitude: 0.62935

Collected Steps per Second: 22,400.95323
Overall Steps per Second: 10,396.64809

Timestep Collection Time: 2.23241
Timestep Consumption Time: 2.57761
PPO Batch Consumption Time: 0.30417
Total Iteration Time: 4.81001

Cumulative Model Updates: 81,180
Cumulative Timesteps: 677,061,686

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 677061686...
Checkpoint 677061686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.16857
Policy Entropy: 3.27171
Value Function Loss: 0.00415

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09390
Policy Update Magnitude: 0.54036
Value Function Update Magnitude: 0.62378

Collected Steps per Second: 20,127.63738
Overall Steps per Second: 10,039.85666

Timestep Collection Time: 2.48444
Timestep Consumption Time: 2.49630
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.98075

Cumulative Model Updates: 81,186
Cumulative Timesteps: 677,111,692

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 677111692...
Checkpoint 677111692 saved!
