Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.32078
Policy Entropy: 2.37225
Value Function Loss: 0.01911

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02153
Policy Update Magnitude: 0.09361
Value Function Update Magnitude: 0.12751

Collected Steps per Second: 8,360.42636
Overall Steps per Second: 5,274.53716

Timestep Collection Time: 5.98343
Timestep Consumption Time: 3.50063
PPO Batch Consumption Time: 1.30426
Total Iteration Time: 9.48405

Cumulative Model Updates: 317,052
Cumulative Timesteps: 2,644,183,698

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.42885
Policy Entropy: 2.43151
Value Function Loss: 0.01275

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.04060
Policy Update Magnitude: 0.10032
Value Function Update Magnitude: 0.16125

Collected Steps per Second: 21,908.18888
Overall Steps per Second: 13,433.02878

Timestep Collection Time: 2.28262
Timestep Consumption Time: 1.44015
PPO Batch Consumption Time: 0.33736
Total Iteration Time: 3.72276

Cumulative Model Updates: 317,054
Cumulative Timesteps: 2,644,233,706

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2644233706...
Checkpoint 2644233706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.21483
Policy Entropy: 2.46083
Value Function Loss: 0.01027

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07210
Policy Update Magnitude: 0.19163
Value Function Update Magnitude: 0.31471

Collected Steps per Second: 22,661.48072
Overall Steps per Second: 11,976.37711

Timestep Collection Time: 2.20709
Timestep Consumption Time: 1.96913
PPO Batch Consumption Time: 0.29712
Total Iteration Time: 4.17622

Cumulative Model Updates: 317,058
Cumulative Timesteps: 2,644,283,722

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.74946
Policy Entropy: 2.49264
Value Function Loss: 0.00721

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08792
Policy Update Magnitude: 0.24408
Value Function Update Magnitude: 0.33622

Collected Steps per Second: 22,075.19354
Overall Steps per Second: 10,586.08150

Timestep Collection Time: 2.26571
Timestep Consumption Time: 2.45898
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.72469

Cumulative Model Updates: 317,064
Cumulative Timesteps: 2,644,333,738

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2644333738...
Checkpoint 2644333738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.20320
Policy Entropy: 2.53203
Value Function Loss: 0.00558

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.09663
Policy Update Magnitude: 0.21071
Value Function Update Magnitude: 0.26628

Collected Steps per Second: 21,740.71246
Overall Steps per Second: 10,606.21800

Timestep Collection Time: 2.30029
Timestep Consumption Time: 2.41487
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.71516

Cumulative Model Updates: 317,070
Cumulative Timesteps: 2,644,383,748

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.58562
Policy Entropy: 2.53283
Value Function Loss: 0.00380

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.09147
Policy Update Magnitude: 0.18497
Value Function Update Magnitude: 0.22449

Collected Steps per Second: 22,596.25189
Overall Steps per Second: 10,572.21892

Timestep Collection Time: 2.21400
Timestep Consumption Time: 2.51803
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.73202

Cumulative Model Updates: 317,076
Cumulative Timesteps: 2,644,433,776

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2644433776...
Checkpoint 2644433776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.32994
Policy Entropy: 2.56884
Value Function Loss: 0.00397

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.07003
Policy Update Magnitude: 0.16870
Value Function Update Magnitude: 0.22520

Collected Steps per Second: 21,982.52381
Overall Steps per Second: 10,583.47861

Timestep Collection Time: 2.27453
Timestep Consumption Time: 2.44981
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.72434

Cumulative Model Updates: 317,082
Cumulative Timesteps: 2,644,483,776

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.61577
Policy Entropy: 2.57618
Value Function Loss: 0.00304

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.06247
Policy Update Magnitude: 0.15418
Value Function Update Magnitude: 0.21323

Collected Steps per Second: 22,261.26370
Overall Steps per Second: 10,704.57310

Timestep Collection Time: 2.24758
Timestep Consumption Time: 2.42650
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.67408

Cumulative Model Updates: 317,088
Cumulative Timesteps: 2,644,533,810

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2644533810...
Checkpoint 2644533810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.88353
Policy Entropy: 2.62284
Value Function Loss: 0.00300

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.04949
Policy Update Magnitude: 0.14450
Value Function Update Magnitude: 0.20137

Collected Steps per Second: 21,900.93398
Overall Steps per Second: 10,403.59756

Timestep Collection Time: 2.28365
Timestep Consumption Time: 2.52373
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.80738

Cumulative Model Updates: 317,094
Cumulative Timesteps: 2,644,583,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.63607
Policy Entropy: 2.61108
Value Function Loss: 0.00331

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.04763
Policy Update Magnitude: 0.14213
Value Function Update Magnitude: 0.19294

Collected Steps per Second: 22,401.40359
Overall Steps per Second: 10,610.25197

Timestep Collection Time: 2.23290
Timestep Consumption Time: 2.48141
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.71431

Cumulative Model Updates: 317,100
Cumulative Timesteps: 2,644,633,844

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2644633844...
Checkpoint 2644633844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.82719
Policy Entropy: 2.61043
Value Function Loss: 0.00344

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.04781
Policy Update Magnitude: 0.13966
Value Function Update Magnitude: 0.19199

Collected Steps per Second: 22,865.54136
Overall Steps per Second: 10,773.18095

Timestep Collection Time: 2.18678
Timestep Consumption Time: 2.45456
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.64134

Cumulative Model Updates: 317,106
Cumulative Timesteps: 2,644,683,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.11278
Policy Entropy: 2.63143
Value Function Loss: 0.00339

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.04866
Policy Update Magnitude: 0.13650
Value Function Update Magnitude: 0.18428

Collected Steps per Second: 22,564.65926
Overall Steps per Second: 10,545.70459

Timestep Collection Time: 2.21710
Timestep Consumption Time: 2.52683
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.74392

Cumulative Model Updates: 317,112
Cumulative Timesteps: 2,644,733,874

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2644733874...
Checkpoint 2644733874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.27696
Policy Entropy: 2.66384
Value Function Loss: 0.00312

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.04873
Policy Update Magnitude: 0.13243
Value Function Update Magnitude: 0.17684

Collected Steps per Second: 22,255.67748
Overall Steps per Second: 10,638.95979

Timestep Collection Time: 2.24725
Timestep Consumption Time: 2.45378
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.70102

Cumulative Model Updates: 317,118
Cumulative Timesteps: 2,644,783,888

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.36046
Policy Entropy: 2.69856
Value Function Loss: 0.00289

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.04142
Policy Update Magnitude: 0.12798
Value Function Update Magnitude: 0.17374

Collected Steps per Second: 22,474.59494
Overall Steps per Second: 10,537.10468

Timestep Collection Time: 2.22473
Timestep Consumption Time: 2.52040
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.74514

Cumulative Model Updates: 317,124
Cumulative Timesteps: 2,644,833,888

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2644833888...
Checkpoint 2644833888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.35546
Policy Entropy: 2.70392
Value Function Loss: 0.00248

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04138
Policy Update Magnitude: 0.11834
Value Function Update Magnitude: 0.16759

Collected Steps per Second: 21,904.86366
Overall Steps per Second: 10,517.15707

Timestep Collection Time: 2.28278
Timestep Consumption Time: 2.47174
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.75452

Cumulative Model Updates: 317,130
Cumulative Timesteps: 2,644,883,892

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.04058
Policy Entropy: 2.73943
Value Function Loss: 0.00196

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04198
Policy Update Magnitude: 0.10836
Value Function Update Magnitude: 0.15351

Collected Steps per Second: 22,457.82076
Overall Steps per Second: 10,849.27753

Timestep Collection Time: 2.22720
Timestep Consumption Time: 2.38306
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.61026

Cumulative Model Updates: 317,136
Cumulative Timesteps: 2,644,933,910

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2644933910...
Checkpoint 2644933910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.50991
Policy Entropy: 2.73088
Value Function Loss: 0.00265

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.03928
Policy Update Magnitude: 0.11201
Value Function Update Magnitude: 0.14334

Collected Steps per Second: 21,932.89885
Overall Steps per Second: 10,411.11828

Timestep Collection Time: 2.28123
Timestep Consumption Time: 2.52459
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.80582

Cumulative Model Updates: 317,142
Cumulative Timesteps: 2,644,983,944

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.50423
Policy Entropy: 2.72773
Value Function Loss: 0.00280

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.03775
Policy Update Magnitude: 0.12334
Value Function Update Magnitude: 0.15284

Collected Steps per Second: 22,357.91597
Overall Steps per Second: 10,569.00291

Timestep Collection Time: 2.23652
Timestep Consumption Time: 2.49467
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.73119

Cumulative Model Updates: 317,148
Cumulative Timesteps: 2,645,033,948

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2645033948...
Checkpoint 2645033948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.52223
Policy Entropy: 2.74196
Value Function Loss: 0.00387

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04021
Policy Update Magnitude: 0.12901
Value Function Update Magnitude: 0.16679

Collected Steps per Second: 23,236.23351
Overall Steps per Second: 10,831.38938

Timestep Collection Time: 2.15224
Timestep Consumption Time: 2.46489
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.61714

Cumulative Model Updates: 317,154
Cumulative Timesteps: 2,645,083,958

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.51847
Policy Entropy: 2.76562
Value Function Loss: 0.00297

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03389
Policy Update Magnitude: 0.12610
Value Function Update Magnitude: 0.16788

Collected Steps per Second: 22,458.51796
Overall Steps per Second: 10,564.78885

Timestep Collection Time: 2.22686
Timestep Consumption Time: 2.50698
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.73384

Cumulative Model Updates: 317,160
Cumulative Timesteps: 2,645,133,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2645133970...
Checkpoint 2645133970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.68795
Policy Entropy: 2.77385
Value Function Loss: 0.00265

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.03427
Policy Update Magnitude: 0.11850
Value Function Update Magnitude: 0.16080

Collected Steps per Second: 21,981.35685
Overall Steps per Second: 10,616.87679

Timestep Collection Time: 2.27566
Timestep Consumption Time: 2.43590
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.71156

Cumulative Model Updates: 317,166
Cumulative Timesteps: 2,645,183,992

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.21596
Policy Entropy: 2.76889
Value Function Loss: 0.00215

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.03715
Policy Update Magnitude: 0.11267
Value Function Update Magnitude: 0.14674

Collected Steps per Second: 22,904.21593
Overall Steps per Second: 10,533.34643

Timestep Collection Time: 2.18379
Timestep Consumption Time: 2.56475
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.74854

Cumulative Model Updates: 317,172
Cumulative Timesteps: 2,645,234,010

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2645234010...
Checkpoint 2645234010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.80432
Policy Entropy: 2.78440
Value Function Loss: 0.00225

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.03489
Policy Update Magnitude: 0.11080
Value Function Update Magnitude: 0.14259

Collected Steps per Second: 22,176.15603
Overall Steps per Second: 10,499.25739

Timestep Collection Time: 2.25531
Timestep Consumption Time: 2.50827
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.76358

Cumulative Model Updates: 317,178
Cumulative Timesteps: 2,645,284,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.54648
Policy Entropy: 2.82131
Value Function Loss: 0.00259

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02727
Policy Update Magnitude: 0.11469
Value Function Update Magnitude: 0.15640

Collected Steps per Second: 22,198.59687
Overall Steps per Second: 10,626.51606

Timestep Collection Time: 2.25266
Timestep Consumption Time: 2.45311
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.70578

Cumulative Model Updates: 317,184
Cumulative Timesteps: 2,645,334,030

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2645334030...
Checkpoint 2645334030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.39677
Policy Entropy: 2.85959
Value Function Loss: 0.00257

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03025
Policy Update Magnitude: 0.11764
Value Function Update Magnitude: 0.16687

Collected Steps per Second: 22,334.54807
Overall Steps per Second: 10,578.10047

Timestep Collection Time: 2.23886
Timestep Consumption Time: 2.48826
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.72712

Cumulative Model Updates: 317,190
Cumulative Timesteps: 2,645,384,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.31358
Policy Entropy: 2.86311
Value Function Loss: 0.00284

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03003
Policy Update Magnitude: 0.11927
Value Function Update Magnitude: 0.16975

Collected Steps per Second: 22,348.93441
Overall Steps per Second: 10,524.18905

Timestep Collection Time: 2.23751
Timestep Consumption Time: 2.51402
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.75153

Cumulative Model Updates: 317,196
Cumulative Timesteps: 2,645,434,040

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2645434040...
Checkpoint 2645434040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.27759
Policy Entropy: 2.85630
Value Function Loss: 0.00304

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02920
Policy Update Magnitude: 0.12281
Value Function Update Magnitude: 0.16953

Collected Steps per Second: 22,406.56528
Overall Steps per Second: 10,697.93960

Timestep Collection Time: 2.23220
Timestep Consumption Time: 2.44309
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.67529

Cumulative Model Updates: 317,202
Cumulative Timesteps: 2,645,484,056

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.48934
Policy Entropy: 2.84765
Value Function Loss: 0.00408

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03338
Policy Update Magnitude: 0.12619
Value Function Update Magnitude: 0.18215

Collected Steps per Second: 22,572.19582
Overall Steps per Second: 10,733.27544

Timestep Collection Time: 2.21556
Timestep Consumption Time: 2.44378
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.65934

Cumulative Model Updates: 317,208
Cumulative Timesteps: 2,645,534,066

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2645534066...
Checkpoint 2645534066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.47588
Policy Entropy: 2.84804
Value Function Loss: 0.00357

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.04140
Policy Update Magnitude: 0.12922
Value Function Update Magnitude: 0.20124

Collected Steps per Second: 21,934.74331
Overall Steps per Second: 10,735.09492

Timestep Collection Time: 2.28004
Timestep Consumption Time: 2.37870
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.65874

Cumulative Model Updates: 317,214
Cumulative Timesteps: 2,645,584,078

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.01682
Policy Entropy: 2.84863
Value Function Loss: 0.00359

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.03522
Policy Update Magnitude: 0.13228
Value Function Update Magnitude: 0.19844

Collected Steps per Second: 22,122.35307
Overall Steps per Second: 10,498.93589

Timestep Collection Time: 2.26016
Timestep Consumption Time: 2.50223
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.76239

Cumulative Model Updates: 317,220
Cumulative Timesteps: 2,645,634,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2645634078...
Checkpoint 2645634078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.33623
Policy Entropy: 2.88793
Value Function Loss: 0.00280

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03369
Policy Update Magnitude: 0.13054
Value Function Update Magnitude: 0.17836

Collected Steps per Second: 22,123.87521
Overall Steps per Second: 10,603.00360

Timestep Collection Time: 2.26100
Timestep Consumption Time: 2.45672
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.71772

Cumulative Model Updates: 317,226
Cumulative Timesteps: 2,645,684,100

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.35569
Policy Entropy: 2.95903
Value Function Loss: 0.00288

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03510
Policy Update Magnitude: 0.12686
Value Function Update Magnitude: 0.16873

Collected Steps per Second: 23,099.46422
Overall Steps per Second: 10,879.99974

Timestep Collection Time: 2.16585
Timestep Consumption Time: 2.43249
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.59835

Cumulative Model Updates: 317,232
Cumulative Timesteps: 2,645,734,130

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2645734130...
Checkpoint 2645734130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.05312
Policy Entropy: 3.00607
Value Function Loss: 0.00333

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03027
Policy Update Magnitude: 0.12554
Value Function Update Magnitude: 0.16931

Collected Steps per Second: 22,028.40111
Overall Steps per Second: 10,468.66699

Timestep Collection Time: 2.27043
Timestep Consumption Time: 2.50706
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.77749

Cumulative Model Updates: 317,238
Cumulative Timesteps: 2,645,784,144

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.06924
Policy Entropy: 3.00542
Value Function Loss: 0.00364

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03160
Policy Update Magnitude: 0.12867
Value Function Update Magnitude: 0.17505

Collected Steps per Second: 22,219.60270
Overall Steps per Second: 10,637.85455

Timestep Collection Time: 2.25063
Timestep Consumption Time: 2.45032
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.70095

Cumulative Model Updates: 317,244
Cumulative Timesteps: 2,645,834,152

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2645834152...
Checkpoint 2645834152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.78091
Policy Entropy: 2.96977
Value Function Loss: 0.00405

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02873
Policy Update Magnitude: 0.13393
Value Function Update Magnitude: 0.19036

Collected Steps per Second: 23,022.07173
Overall Steps per Second: 10,700.12899

Timestep Collection Time: 2.17270
Timestep Consumption Time: 2.50201
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.67471

Cumulative Model Updates: 317,250
Cumulative Timesteps: 2,645,884,172

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.72971
Policy Entropy: 2.94955
Value Function Loss: 0.00306

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03128
Policy Update Magnitude: 0.13000
Value Function Update Magnitude: 0.19197

Collected Steps per Second: 22,558.34576
Overall Steps per Second: 10,504.49803

Timestep Collection Time: 2.21665
Timestep Consumption Time: 2.54359
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.76025

Cumulative Model Updates: 317,256
Cumulative Timesteps: 2,645,934,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2645934176...
Checkpoint 2645934176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.58234
Policy Entropy: 2.96489
Value Function Loss: 0.00313

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03466
Policy Update Magnitude: 0.12918
Value Function Update Magnitude: 0.18014

Collected Steps per Second: 22,269.28037
Overall Steps per Second: 10,663.60960

Timestep Collection Time: 2.24587
Timestep Consumption Time: 2.44428
PPO Batch Consumption Time: 0.29485
Total Iteration Time: 4.69016

Cumulative Model Updates: 317,262
Cumulative Timesteps: 2,645,984,190

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.67828
Policy Entropy: 2.98936
Value Function Loss: 0.00334

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03520
Policy Update Magnitude: 0.13224
Value Function Update Magnitude: 0.18028

Collected Steps per Second: 22,502.72215
Overall Steps per Second: 10,570.01736

Timestep Collection Time: 2.22195
Timestep Consumption Time: 2.50841
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.73036

Cumulative Model Updates: 317,268
Cumulative Timesteps: 2,646,034,190

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2646034190...
Checkpoint 2646034190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.69196
Policy Entropy: 3.03046
Value Function Loss: 0.00325

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02908
Policy Update Magnitude: 0.12943
Value Function Update Magnitude: 0.19383

Collected Steps per Second: 21,757.45762
Overall Steps per Second: 10,430.74055

Timestep Collection Time: 2.29963
Timestep Consumption Time: 2.49716
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.79678

Cumulative Model Updates: 317,274
Cumulative Timesteps: 2,646,084,224

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.48993
Policy Entropy: 3.01286
Value Function Loss: 0.00276

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02821
Policy Update Magnitude: 0.12642
Value Function Update Magnitude: 0.19510

Collected Steps per Second: 23,324.17839
Overall Steps per Second: 10,858.36160

Timestep Collection Time: 2.14507
Timestep Consumption Time: 2.46262
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.60769

Cumulative Model Updates: 317,280
Cumulative Timesteps: 2,646,134,256

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2646134256...
Checkpoint 2646134256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.41910
Policy Entropy: 2.99230
Value Function Loss: 0.00304

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03089
Policy Update Magnitude: 0.13158
Value Function Update Magnitude: 0.18431

Collected Steps per Second: 21,983.20932
Overall Steps per Second: 10,457.55482

Timestep Collection Time: 2.27519
Timestep Consumption Time: 2.50757
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.78276

Cumulative Model Updates: 317,286
Cumulative Timesteps: 2,646,184,272

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.79275
Policy Entropy: 3.00756
Value Function Loss: 0.00274

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02954
Policy Update Magnitude: 0.13012
Value Function Update Magnitude: 0.18844

Collected Steps per Second: 22,682.26539
Overall Steps per Second: 10,780.30669

Timestep Collection Time: 2.20560
Timestep Consumption Time: 2.43508
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.64068

Cumulative Model Updates: 317,292
Cumulative Timesteps: 2,646,234,300

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2646234300...
Checkpoint 2646234300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.74137
Policy Entropy: 3.04837
Value Function Loss: 0.00283

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02928
Policy Update Magnitude: 0.12120
Value Function Update Magnitude: 0.19209

Collected Steps per Second: 22,265.36186
Overall Steps per Second: 10,606.77580

Timestep Collection Time: 2.24573
Timestep Consumption Time: 2.46843
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.71416

Cumulative Model Updates: 317,298
Cumulative Timesteps: 2,646,284,302

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.70505
Policy Entropy: 3.07183
Value Function Loss: 0.00340

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02363
Policy Update Magnitude: 0.12335
Value Function Update Magnitude: 0.17848

Collected Steps per Second: 22,349.20853
Overall Steps per Second: 10,547.40007

Timestep Collection Time: 2.23793
Timestep Consumption Time: 2.50409
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.74202

Cumulative Model Updates: 317,304
Cumulative Timesteps: 2,646,334,318

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2646334318...
Checkpoint 2646334318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.65816
Policy Entropy: 3.07141
Value Function Loss: 0.00398

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02722
Policy Update Magnitude: 0.13657
Value Function Update Magnitude: 0.18404

Collected Steps per Second: 22,069.64739
Overall Steps per Second: 10,655.54912

Timestep Collection Time: 2.26637
Timestep Consumption Time: 2.42771
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.69408

Cumulative Model Updates: 317,310
Cumulative Timesteps: 2,646,384,336

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.80946
Policy Entropy: 3.07862
Value Function Loss: 0.00411

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.02734
Policy Update Magnitude: 0.14250
Value Function Update Magnitude: 0.19139

Collected Steps per Second: 22,569.10978
Overall Steps per Second: 10,555.66967

Timestep Collection Time: 2.21666
Timestep Consumption Time: 2.52279
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.73944

Cumulative Model Updates: 317,316
Cumulative Timesteps: 2,646,434,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2646434364...
Checkpoint 2646434364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.87496
Policy Entropy: 3.10027
Value Function Loss: 0.00359

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.03334
Policy Update Magnitude: 0.14384
Value Function Update Magnitude: 0.19040

Collected Steps per Second: 22,195.68612
Overall Steps per Second: 10,505.67374

Timestep Collection Time: 2.25278
Timestep Consumption Time: 2.50674
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.75952

Cumulative Model Updates: 317,322
Cumulative Timesteps: 2,646,484,366

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.84260
Policy Entropy: 3.08229
Value Function Loss: 0.00334

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03060
Policy Update Magnitude: 0.14439
Value Function Update Magnitude: 0.19295

Collected Steps per Second: 23,389.62664
Overall Steps per Second: 10,883.30958

Timestep Collection Time: 2.13779
Timestep Consumption Time: 2.45659
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.59437

Cumulative Model Updates: 317,328
Cumulative Timesteps: 2,646,534,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2646534368...
Checkpoint 2646534368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.88593
Policy Entropy: 3.10056
Value Function Loss: 0.00334

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02958
Policy Update Magnitude: 0.14328
Value Function Update Magnitude: 0.19392

Collected Steps per Second: 21,951.41995
Overall Steps per Second: 10,571.87448

Timestep Collection Time: 2.27794
Timestep Consumption Time: 2.45197
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.72991

Cumulative Model Updates: 317,334
Cumulative Timesteps: 2,646,584,372

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.18321
Policy Entropy: 3.11598
Value Function Loss: 0.00325

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02954
Policy Update Magnitude: 0.14528
Value Function Update Magnitude: 0.19133

Collected Steps per Second: 22,278.04447
Overall Steps per Second: 10,576.54694

Timestep Collection Time: 2.24598
Timestep Consumption Time: 2.48487
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.73084

Cumulative Model Updates: 317,340
Cumulative Timesteps: 2,646,634,408

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2646634408...
Checkpoint 2646634408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.82613
Policy Entropy: 3.16999
Value Function Loss: 0.00296

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02889
Policy Update Magnitude: 0.13817
Value Function Update Magnitude: 0.18089

Collected Steps per Second: 22,894.75646
Overall Steps per Second: 10,623.36517

Timestep Collection Time: 2.18426
Timestep Consumption Time: 2.52310
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.70736

Cumulative Model Updates: 317,346
Cumulative Timesteps: 2,646,684,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.54847
Policy Entropy: 3.18174
Value Function Loss: 0.00246

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03060
Policy Update Magnitude: 0.12378
Value Function Update Magnitude: 0.17971

Collected Steps per Second: 22,264.21592
Overall Steps per Second: 10,473.51727

Timestep Collection Time: 2.24647
Timestep Consumption Time: 2.52900
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.77547

Cumulative Model Updates: 317,352
Cumulative Timesteps: 2,646,734,432

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2646734432...
Checkpoint 2646734432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.80708
Policy Entropy: 3.16893
Value Function Loss: 0.00270

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02861
Policy Update Magnitude: 0.12211
Value Function Update Magnitude: 0.16615

Collected Steps per Second: 21,914.13853
Overall Steps per Second: 10,636.51475

Timestep Collection Time: 2.28245
Timestep Consumption Time: 2.42003
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.70248

Cumulative Model Updates: 317,358
Cumulative Timesteps: 2,646,784,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51595
Policy Entropy: 3.15910
Value Function Loss: 0.00349

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03127
Policy Update Magnitude: 0.13651
Value Function Update Magnitude: 0.17753

Collected Steps per Second: 22,080.58292
Overall Steps per Second: 10,443.13623

Timestep Collection Time: 2.26552
Timestep Consumption Time: 2.52461
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.79013

Cumulative Model Updates: 317,364
Cumulative Timesteps: 2,646,834,474

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2646834474...
Checkpoint 2646834474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.76624
Policy Entropy: 3.16706
Value Function Loss: 0.00276

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03105
Policy Update Magnitude: 0.13626
Value Function Update Magnitude: 0.18612

Collected Steps per Second: 22,157.74123
Overall Steps per Second: 10,672.44652

Timestep Collection Time: 2.25655
Timestep Consumption Time: 2.42841
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.68496

Cumulative Model Updates: 317,370
Cumulative Timesteps: 2,646,884,474

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.92499
Policy Entropy: 3.22109
Value Function Loss: 0.00258

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02892
Policy Update Magnitude: 0.12241
Value Function Update Magnitude: 0.16088

Collected Steps per Second: 22,713.17668
Overall Steps per Second: 10,906.39622

Timestep Collection Time: 2.20242
Timestep Consumption Time: 2.38424
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.58667

Cumulative Model Updates: 317,376
Cumulative Timesteps: 2,646,934,498

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2646934498...
Checkpoint 2646934498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.34052
Policy Entropy: 3.25746
Value Function Loss: 0.00227

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02662
Policy Update Magnitude: 0.12209
Value Function Update Magnitude: 0.13228

Collected Steps per Second: 22,273.50870
Overall Steps per Second: 10,624.00619

Timestep Collection Time: 2.24608
Timestep Consumption Time: 2.46288
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.70896

Cumulative Model Updates: 317,382
Cumulative Timesteps: 2,646,984,526

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.22589
Policy Entropy: 3.24302
Value Function Loss: 0.00296

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02539
Policy Update Magnitude: 0.12263
Value Function Update Magnitude: 0.13647

Collected Steps per Second: 22,471.31854
Overall Steps per Second: 10,736.04608

Timestep Collection Time: 2.22604
Timestep Consumption Time: 2.43322
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.65926

Cumulative Model Updates: 317,388
Cumulative Timesteps: 2,647,034,548

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2647034548...
Checkpoint 2647034548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.09191
Policy Entropy: 3.22836
Value Function Loss: 0.00299

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03119
Policy Update Magnitude: 0.12585
Value Function Update Magnitude: 0.14244

Collected Steps per Second: 22,225.79428
Overall Steps per Second: 10,499.59025

Timestep Collection Time: 2.25018
Timestep Consumption Time: 2.51306
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.76323

Cumulative Model Updates: 317,394
Cumulative Timesteps: 2,647,084,560

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.00566
Policy Entropy: 3.21941
Value Function Loss: 0.00291

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02999
Policy Update Magnitude: 0.11915
Value Function Update Magnitude: 0.14100

Collected Steps per Second: 22,447.23903
Overall Steps per Second: 10,755.28510

Timestep Collection Time: 2.22869
Timestep Consumption Time: 2.42279
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.65148

Cumulative Model Updates: 317,400
Cumulative Timesteps: 2,647,134,588

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2647134588...
Checkpoint 2647134588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.37472
Policy Entropy: 3.22356
Value Function Loss: 0.00322

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02802
Policy Update Magnitude: 0.11607
Value Function Update Magnitude: 0.14624

Collected Steps per Second: 21,881.38512
Overall Steps per Second: 10,792.51464

Timestep Collection Time: 2.28505
Timestep Consumption Time: 2.34779
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.63284

Cumulative Model Updates: 317,406
Cumulative Timesteps: 2,647,184,588

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.91852
Policy Entropy: 3.20224
Value Function Loss: 0.00292

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02568
Policy Update Magnitude: 0.12011
Value Function Update Magnitude: 0.14627

Collected Steps per Second: 22,545.19745
Overall Steps per Second: 10,587.37694

Timestep Collection Time: 2.21839
Timestep Consumption Time: 2.50554
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.72393

Cumulative Model Updates: 317,412
Cumulative Timesteps: 2,647,234,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2647234602...
Checkpoint 2647234602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.88095
Policy Entropy: 3.21771
Value Function Loss: 0.00269

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03061
Policy Update Magnitude: 0.11763
Value Function Update Magnitude: 0.14501

Collected Steps per Second: 22,270.97899
Overall Steps per Second: 10,539.19788

Timestep Collection Time: 2.24552
Timestep Consumption Time: 2.49962
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.74514

Cumulative Model Updates: 317,418
Cumulative Timesteps: 2,647,284,612

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.20139
Policy Entropy: 3.24741
Value Function Loss: 0.00223

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02614
Policy Update Magnitude: 0.11383
Value Function Update Magnitude: 0.14507

Collected Steps per Second: 22,737.77031
Overall Steps per Second: 10,738.18736

Timestep Collection Time: 2.19942
Timestep Consumption Time: 2.45779
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.65721

Cumulative Model Updates: 317,424
Cumulative Timesteps: 2,647,334,622

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2647334622...
Checkpoint 2647334622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.78934
Policy Entropy: 3.24943
Value Function Loss: 0.00272

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02431
Policy Update Magnitude: 0.12176
Value Function Update Magnitude: 0.15889

Collected Steps per Second: 21,964.45578
Overall Steps per Second: 10,413.01945

Timestep Collection Time: 2.27732
Timestep Consumption Time: 2.52629
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.80360

Cumulative Model Updates: 317,430
Cumulative Timesteps: 2,647,384,642

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.05292
Policy Entropy: 3.24505
Value Function Loss: 0.00343

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03069
Policy Update Magnitude: 0.12836
Value Function Update Magnitude: 0.17007

Collected Steps per Second: 21,383.81053
Overall Steps per Second: 10,297.91921

Timestep Collection Time: 2.33822
Timestep Consumption Time: 2.51713
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.85535

Cumulative Model Updates: 317,436
Cumulative Timesteps: 2,647,434,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2647434642...
Checkpoint 2647434642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.00738
Policy Entropy: 3.24312
Value Function Loss: 0.00319

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02819
Policy Update Magnitude: 0.13444
Value Function Update Magnitude: 0.16360

Collected Steps per Second: 23,045.35077
Overall Steps per Second: 10,684.17057

Timestep Collection Time: 2.17033
Timestep Consumption Time: 2.51099
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.68132

Cumulative Model Updates: 317,442
Cumulative Timesteps: 2,647,484,658

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.11348
Policy Entropy: 3.28166
Value Function Loss: 0.00321

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.03189
Policy Update Magnitude: 0.13155
Value Function Update Magnitude: 0.15469

Collected Steps per Second: 22,495.86880
Overall Steps per Second: 10,488.72573

Timestep Collection Time: 2.22405
Timestep Consumption Time: 2.54602
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.77007

Cumulative Model Updates: 317,448
Cumulative Timesteps: 2,647,534,690

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2647534690...
Checkpoint 2647534690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.77390
Policy Entropy: 3.31525
Value Function Loss: 0.00219

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02407
Policy Update Magnitude: 0.12373
Value Function Update Magnitude: 0.15649

Collected Steps per Second: 22,246.47006
Overall Steps per Second: 10,643.90293

Timestep Collection Time: 2.24836
Timestep Consumption Time: 2.45086
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.69922

Cumulative Model Updates: 317,454
Cumulative Timesteps: 2,647,584,708

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.22106
Policy Entropy: 3.35574
Value Function Loss: 0.00260

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02287
Policy Update Magnitude: 0.12095
Value Function Update Magnitude: 0.17357

Collected Steps per Second: 22,710.33662
Overall Steps per Second: 10,606.56225

Timestep Collection Time: 2.20199
Timestep Consumption Time: 2.51282
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.71482

Cumulative Model Updates: 317,460
Cumulative Timesteps: 2,647,634,716

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2647634716...
Checkpoint 2647634716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.97802
Policy Entropy: 3.36848
Value Function Loss: 0.00320

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02290
Policy Update Magnitude: 0.13045
Value Function Update Magnitude: 0.18745

Collected Steps per Second: 22,140.02415
Overall Steps per Second: 10,516.95792

Timestep Collection Time: 2.25980
Timestep Consumption Time: 2.49747
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.75727

Cumulative Model Updates: 317,466
Cumulative Timesteps: 2,647,684,748

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.66494
Policy Entropy: 3.37270
Value Function Loss: 0.00363

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02684
Policy Update Magnitude: 0.13739
Value Function Update Magnitude: 0.20126

Collected Steps per Second: 23,150.14044
Overall Steps per Second: 10,841.92993

Timestep Collection Time: 2.16111
Timestep Consumption Time: 2.45338
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.61449

Cumulative Model Updates: 317,472
Cumulative Timesteps: 2,647,734,778

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2647734778...
Checkpoint 2647734778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.92457
Policy Entropy: 3.36032
Value Function Loss: 0.00351

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02653
Policy Update Magnitude: 0.13809
Value Function Update Magnitude: 0.20502

Collected Steps per Second: 22,285.35361
Overall Steps per Second: 10,621.00869

Timestep Collection Time: 2.24372
Timestep Consumption Time: 2.46412
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.70784

Cumulative Model Updates: 317,478
Cumulative Timesteps: 2,647,784,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.68096
Policy Entropy: 3.35119
Value Function Loss: 0.00281

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02390
Policy Update Magnitude: 0.13823
Value Function Update Magnitude: 0.18790

Collected Steps per Second: 22,350.39715
Overall Steps per Second: 10,546.99276

Timestep Collection Time: 2.23772
Timestep Consumption Time: 2.50429
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.74202

Cumulative Model Updates: 317,484
Cumulative Timesteps: 2,647,834,794

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2647834794...
Checkpoint 2647834794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.17983
Policy Entropy: 3.38582
Value Function Loss: 0.00240

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02606
Policy Update Magnitude: 0.12916
Value Function Update Magnitude: 0.17504

Collected Steps per Second: 22,937.07287
Overall Steps per Second: 10,637.81647

Timestep Collection Time: 2.17996
Timestep Consumption Time: 2.52044
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.70040

Cumulative Model Updates: 317,490
Cumulative Timesteps: 2,647,884,796

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.66261
Policy Entropy: 3.39483
Value Function Loss: 0.00198

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02507
Policy Update Magnitude: 0.11777
Value Function Update Magnitude: 0.17500

Collected Steps per Second: 22,503.34080
Overall Steps per Second: 10,515.69448

Timestep Collection Time: 2.22305
Timestep Consumption Time: 2.53422
PPO Batch Consumption Time: 0.29522
Total Iteration Time: 4.75727

Cumulative Model Updates: 317,496
Cumulative Timesteps: 2,647,934,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2647934822...
Checkpoint 2647934822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.16725
Policy Entropy: 3.39051
Value Function Loss: 0.00273

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01867
Policy Update Magnitude: 0.12118
Value Function Update Magnitude: 0.18227

Collected Steps per Second: 22,314.66543
Overall Steps per Second: 10,686.75891

Timestep Collection Time: 2.24068
Timestep Consumption Time: 2.43801
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.67869

Cumulative Model Updates: 317,502
Cumulative Timesteps: 2,647,984,822

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.35553
Policy Entropy: 3.36895
Value Function Loss: 0.00329

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02650
Policy Update Magnitude: 0.13104
Value Function Update Magnitude: 0.19234

Collected Steps per Second: 22,822.35724
Overall Steps per Second: 10,730.51658

Timestep Collection Time: 2.19092
Timestep Consumption Time: 2.46887
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.65979

Cumulative Model Updates: 317,508
Cumulative Timesteps: 2,648,034,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2648034824...
Checkpoint 2648034824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.14804
Policy Entropy: 3.36340
Value Function Loss: 0.00416

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02652
Policy Update Magnitude: 0.13983
Value Function Update Magnitude: 0.20516

Collected Steps per Second: 21,876.81887
Overall Steps per Second: 10,617.17757

Timestep Collection Time: 2.28662
Timestep Consumption Time: 2.42499
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.71161

Cumulative Model Updates: 317,514
Cumulative Timesteps: 2,648,084,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.40046
Policy Entropy: 3.38680
Value Function Loss: 0.00381

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02693
Policy Update Magnitude: 0.14496
Value Function Update Magnitude: 0.20559

Collected Steps per Second: 22,600.49812
Overall Steps per Second: 10,909.55770

Timestep Collection Time: 2.21261
Timestep Consumption Time: 2.37108
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.58369

Cumulative Model Updates: 317,520
Cumulative Timesteps: 2,648,134,854

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2648134854...
Checkpoint 2648134854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.93050
Policy Entropy: 3.35318
Value Function Loss: 0.00456

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02664
Policy Update Magnitude: 0.15539
Value Function Update Magnitude: 0.21243

Collected Steps per Second: 22,102.06124
Overall Steps per Second: 10,488.43739

Timestep Collection Time: 2.26259
Timestep Consumption Time: 2.50532
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.76792

Cumulative Model Updates: 317,526
Cumulative Timesteps: 2,648,184,862

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.65227
Policy Entropy: 3.36466
Value Function Loss: 0.00381

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02541
Policy Update Magnitude: 0.15880
Value Function Update Magnitude: 0.21003

Collected Steps per Second: 22,621.64790
Overall Steps per Second: 10,710.78756

Timestep Collection Time: 2.21089
Timestep Consumption Time: 2.45861
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.66950

Cumulative Model Updates: 317,532
Cumulative Timesteps: 2,648,234,876

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2648234876...
Checkpoint 2648234876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.82294
Policy Entropy: 3.37652
Value Function Loss: 0.00358

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02765
Policy Update Magnitude: 0.14651
Value Function Update Magnitude: 0.20309

Collected Steps per Second: 22,869.01004
Overall Steps per Second: 10,616.23671

Timestep Collection Time: 2.18706
Timestep Consumption Time: 2.52421
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.71127

Cumulative Model Updates: 317,538
Cumulative Timesteps: 2,648,284,892

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.19355
Policy Entropy: 3.41183
Value Function Loss: 0.00267

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02672
Policy Update Magnitude: 0.13381
Value Function Update Magnitude: 0.19238

Collected Steps per Second: 22,511.76076
Overall Steps per Second: 10,509.68549

Timestep Collection Time: 2.22133
Timestep Consumption Time: 2.53676
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.75809

Cumulative Model Updates: 317,544
Cumulative Timesteps: 2,648,334,898

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2648334898...
Checkpoint 2648334898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.38825
Policy Entropy: 3.45528
Value Function Loss: 0.00214

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02726
Policy Update Magnitude: 0.12387
Value Function Update Magnitude: 0.17739

Collected Steps per Second: 22,044.73417
Overall Steps per Second: 10,597.99817

Timestep Collection Time: 2.26866
Timestep Consumption Time: 2.45034
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.71900

Cumulative Model Updates: 317,550
Cumulative Timesteps: 2,648,384,910

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.63450
Policy Entropy: 3.47741
Value Function Loss: 0.00231

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.12475
Value Function Update Magnitude: 0.17567

Collected Steps per Second: 22,510.10939
Overall Steps per Second: 10,551.82719

Timestep Collection Time: 2.22229
Timestep Consumption Time: 2.51850
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.74079

Cumulative Model Updates: 317,556
Cumulative Timesteps: 2,648,434,934

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2648434934...
Checkpoint 2648434934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.53205
Policy Entropy: 3.50947
Value Function Loss: 0.00221

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02530
Policy Update Magnitude: 0.12629
Value Function Update Magnitude: 0.19301

Collected Steps per Second: 22,148.93373
Overall Steps per Second: 10,529.15776

Timestep Collection Time: 2.25799
Timestep Consumption Time: 2.49187
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.74986

Cumulative Model Updates: 317,562
Cumulative Timesteps: 2,648,484,946

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.91246
Policy Entropy: 3.49761
Value Function Loss: 0.00311

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02013
Policy Update Magnitude: 0.13007
Value Function Update Magnitude: 0.20398

Collected Steps per Second: 23,257.67658
Overall Steps per Second: 10,871.84481

Timestep Collection Time: 2.15000
Timestep Consumption Time: 2.44940
PPO Batch Consumption Time: 0.28151
Total Iteration Time: 4.59940

Cumulative Model Updates: 317,568
Cumulative Timesteps: 2,648,534,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2648534950...
Checkpoint 2648534950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.56707
Policy Entropy: 3.47960
Value Function Loss: 0.00330

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02348
Policy Update Magnitude: 0.13388
Value Function Update Magnitude: 0.21434

Collected Steps per Second: 22,330.36691
Overall Steps per Second: 10,639.06735

Timestep Collection Time: 2.23955
Timestep Consumption Time: 2.46105
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.70060

Cumulative Model Updates: 317,574
Cumulative Timesteps: 2,648,584,960

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.43606
Policy Entropy: 3.47000
Value Function Loss: 0.00325

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02376
Policy Update Magnitude: 0.13393
Value Function Update Magnitude: 0.20285

Collected Steps per Second: 22,415.21498
Overall Steps per Second: 10,857.90593

Timestep Collection Time: 2.23090
Timestep Consumption Time: 2.37460
PPO Batch Consumption Time: 0.28177
Total Iteration Time: 4.60549

Cumulative Model Updates: 317,580
Cumulative Timesteps: 2,648,634,966

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2648634966...
Checkpoint 2648634966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.16005
Policy Entropy: 3.50087
Value Function Loss: 0.00306

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02430
Policy Update Magnitude: 0.13842
Value Function Update Magnitude: 0.18851

Collected Steps per Second: 22,329.68260
Overall Steps per Second: 10,661.46160

Timestep Collection Time: 2.24025
Timestep Consumption Time: 2.45179
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.69204

Cumulative Model Updates: 317,586
Cumulative Timesteps: 2,648,684,990

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.18305
Policy Entropy: 3.55047
Value Function Loss: 0.00260

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02244
Policy Update Magnitude: 0.13547
Value Function Update Magnitude: 0.19116

Collected Steps per Second: 22,592.75036
Overall Steps per Second: 10,634.71872

Timestep Collection Time: 2.21310
Timestep Consumption Time: 2.48848
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.70158

Cumulative Model Updates: 317,592
Cumulative Timesteps: 2,648,734,990

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2648734990...
Checkpoint 2648734990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.48673
Policy Entropy: 3.59820
Value Function Loss: 0.00257

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01881
Policy Update Magnitude: 0.13009
Value Function Update Magnitude: 0.19012

Collected Steps per Second: 22,209.09720
Overall Steps per Second: 10,653.71529

Timestep Collection Time: 2.25151
Timestep Consumption Time: 2.44206
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.69357

Cumulative Model Updates: 317,598
Cumulative Timesteps: 2,648,784,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.74319
Policy Entropy: 3.55690
Value Function Loss: 0.00357

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02153
Policy Update Magnitude: 0.14076
Value Function Update Magnitude: 0.19028

Collected Steps per Second: 22,674.34990
Overall Steps per Second: 10,735.64067

Timestep Collection Time: 2.20699
Timestep Consumption Time: 2.45431
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.66130

Cumulative Model Updates: 317,604
Cumulative Timesteps: 2,648,835,036

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2648835036...
Checkpoint 2648835036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.77892
Policy Entropy: 3.50753
Value Function Loss: 0.00404

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02275
Policy Update Magnitude: 0.15075
Value Function Update Magnitude: 0.20641

Collected Steps per Second: 22,370.18716
Overall Steps per Second: 10,697.33704

Timestep Collection Time: 2.23619
Timestep Consumption Time: 2.44011
PPO Batch Consumption Time: 0.28134
Total Iteration Time: 4.67630

Cumulative Model Updates: 317,610
Cumulative Timesteps: 2,648,885,060

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.14236
Policy Entropy: 3.48649
Value Function Loss: 0.00418

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02259
Policy Update Magnitude: 0.15167
Value Function Update Magnitude: 0.20773

Collected Steps per Second: 23,323.51673
Overall Steps per Second: 10,903.47382

Timestep Collection Time: 2.14436
Timestep Consumption Time: 2.44262
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.58698

Cumulative Model Updates: 317,616
Cumulative Timesteps: 2,648,935,074

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2648935074...
Checkpoint 2648935074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.16551
Policy Entropy: 3.53165
Value Function Loss: 0.00359

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02474
Policy Update Magnitude: 0.14791
Value Function Update Magnitude: 0.18946

Collected Steps per Second: 22,185.33882
Overall Steps per Second: 10,631.89723

Timestep Collection Time: 2.25437
Timestep Consumption Time: 2.44977
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.70415

Cumulative Model Updates: 317,622
Cumulative Timesteps: 2,648,985,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.37697
Policy Entropy: 3.56843
Value Function Loss: 0.00345

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02358
Policy Update Magnitude: 0.14485
Value Function Update Magnitude: 0.18747

Collected Steps per Second: 22,716.65214
Overall Steps per Second: 10,886.91337

Timestep Collection Time: 2.20156
Timestep Consumption Time: 2.39222
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.59377

Cumulative Model Updates: 317,628
Cumulative Timesteps: 2,649,035,100

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2649035100...
Checkpoint 2649035100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.70473
Policy Entropy: 3.59325
Value Function Loss: 0.00313

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.01901
Policy Update Magnitude: 0.14230
Value Function Update Magnitude: 0.18653

Collected Steps per Second: 22,381.19829
Overall Steps per Second: 10,642.66864

Timestep Collection Time: 2.23563
Timestep Consumption Time: 2.46583
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.70145

Cumulative Model Updates: 317,634
Cumulative Timesteps: 2,649,085,136

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.34271
Policy Entropy: 3.59183
Value Function Loss: 0.00297

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.01816
Policy Update Magnitude: 0.14019
Value Function Update Magnitude: 0.19109

Collected Steps per Second: 22,515.04549
Overall Steps per Second: 10,582.60361

Timestep Collection Time: 2.22091
Timestep Consumption Time: 2.50420
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.72511

Cumulative Model Updates: 317,640
Cumulative Timesteps: 2,649,135,140

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2649135140...
Checkpoint 2649135140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.45671
Policy Entropy: 3.58144
Value Function Loss: 0.00320

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02070
Policy Update Magnitude: 0.13941
Value Function Update Magnitude: 0.21216

Collected Steps per Second: 22,222.89739
Overall Steps per Second: 10,645.97558

Timestep Collection Time: 2.25128
Timestep Consumption Time: 2.44815
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.69943

Cumulative Model Updates: 317,646
Cumulative Timesteps: 2,649,185,170

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.92546
Policy Entropy: 3.55440
Value Function Loss: 0.00325

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02337
Policy Update Magnitude: 0.14509
Value Function Update Magnitude: 0.20525

Collected Steps per Second: 22,726.79346
Overall Steps per Second: 10,641.29768

Timestep Collection Time: 2.20031
Timestep Consumption Time: 2.49893
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.69924

Cumulative Model Updates: 317,652
Cumulative Timesteps: 2,649,235,176

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2649235176...
Checkpoint 2649235176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.92144
Policy Entropy: 3.56228
Value Function Loss: 0.00362

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02391
Policy Update Magnitude: 0.14393
Value Function Update Magnitude: 0.18149

Collected Steps per Second: 22,583.57753
Overall Steps per Second: 10,760.77148

Timestep Collection Time: 2.21400
Timestep Consumption Time: 2.43251
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.64651

Cumulative Model Updates: 317,658
Cumulative Timesteps: 2,649,285,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.11774
Policy Entropy: 3.59726
Value Function Loss: 0.00271

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02295
Policy Update Magnitude: 0.13353
Value Function Update Magnitude: 0.18228

Collected Steps per Second: 23,173.12492
Overall Steps per Second: 10,718.53059

Timestep Collection Time: 2.15793
Timestep Consumption Time: 2.50745
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.66538

Cumulative Model Updates: 317,664
Cumulative Timesteps: 2,649,335,182

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2649335182...
Checkpoint 2649335182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.20440
Policy Entropy: 3.59512
Value Function Loss: 0.00309

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02380
Policy Update Magnitude: 0.13366
Value Function Update Magnitude: 0.18879

Collected Steps per Second: 22,222.09190
Overall Steps per Second: 10,493.07971

Timestep Collection Time: 2.25082
Timestep Consumption Time: 2.51594
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.76676

Cumulative Model Updates: 317,670
Cumulative Timesteps: 2,649,385,200

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.85061
Policy Entropy: 3.58145
Value Function Loss: 0.00305

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02031
Policy Update Magnitude: 0.15148
Value Function Update Magnitude: 0.19897

Collected Steps per Second: 22,507.74463
Overall Steps per Second: 10,603.39772

Timestep Collection Time: 2.22270
Timestep Consumption Time: 2.49541
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.71811

Cumulative Model Updates: 317,676
Cumulative Timesteps: 2,649,435,228

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2649435228...
Checkpoint 2649435228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.24835
Policy Entropy: 3.55811
Value Function Loss: 0.00333

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02426
Policy Update Magnitude: 0.15399
Value Function Update Magnitude: 0.20697

Collected Steps per Second: 23,197.82909
Overall Steps per Second: 10,852.32535

Timestep Collection Time: 2.15537
Timestep Consumption Time: 2.45193
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.60731

Cumulative Model Updates: 317,682
Cumulative Timesteps: 2,649,485,228

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.25701
Policy Entropy: 3.57534
Value Function Loss: 0.00331

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02248
Policy Update Magnitude: 0.14920
Value Function Update Magnitude: 0.20778

Collected Steps per Second: 22,601.81586
Overall Steps per Second: 10,544.52478

Timestep Collection Time: 2.21248
Timestep Consumption Time: 2.52989
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.74237

Cumulative Model Updates: 317,688
Cumulative Timesteps: 2,649,535,234

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2649535234...
Checkpoint 2649535234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.12211
Policy Entropy: 3.59736
Value Function Loss: 0.00250

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02039
Policy Update Magnitude: 0.13749
Value Function Update Magnitude: 0.19401

Collected Steps per Second: 22,147.91367
Overall Steps per Second: 10,656.60210

Timestep Collection Time: 2.25827
Timestep Consumption Time: 2.43516
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.69343

Cumulative Model Updates: 317,694
Cumulative Timesteps: 2,649,585,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.73239
Policy Entropy: 3.61827
Value Function Loss: 0.00198

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.01945
Policy Update Magnitude: 0.12294
Value Function Update Magnitude: 0.17607

Collected Steps per Second: 22,447.04671
Overall Steps per Second: 10,488.08666

Timestep Collection Time: 2.22836
Timestep Consumption Time: 2.54087
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.76922

Cumulative Model Updates: 317,700
Cumulative Timesteps: 2,649,635,270

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2649635270...
Checkpoint 2649635270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.52245
Policy Entropy: 3.65083
Value Function Loss: 0.00148

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01592
Policy Update Magnitude: 0.11422
Value Function Update Magnitude: 0.15976

Collected Steps per Second: 22,350.84380
Overall Steps per Second: 10,596.36235

Timestep Collection Time: 2.23759
Timestep Consumption Time: 2.48214
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.71973

Cumulative Model Updates: 317,706
Cumulative Timesteps: 2,649,685,282

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.13935
Policy Entropy: 3.64946
Value Function Loss: 0.00239

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01514
Policy Update Magnitude: 0.12503
Value Function Update Magnitude: 0.15323

Collected Steps per Second: 23,550.48631
Overall Steps per Second: 10,952.29500

Timestep Collection Time: 2.12378
Timestep Consumption Time: 2.44294
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.56671

Cumulative Model Updates: 317,712
Cumulative Timesteps: 2,649,735,298

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2649735298...
Checkpoint 2649735298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.28896
Policy Entropy: 3.67760
Value Function Loss: 0.00229

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01748
Policy Update Magnitude: 0.13572
Value Function Update Magnitude: 0.16616

Collected Steps per Second: 22,172.58239
Overall Steps per Second: 10,636.74485

Timestep Collection Time: 2.25594
Timestep Consumption Time: 2.44663
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.70257

Cumulative Model Updates: 317,718
Cumulative Timesteps: 2,649,785,318

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.77945
Policy Entropy: 3.63952
Value Function Loss: 0.00275

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.01930
Policy Update Magnitude: 0.14184
Value Function Update Magnitude: 0.17924

Collected Steps per Second: 22,782.67817
Overall Steps per Second: 10,873.22933

Timestep Collection Time: 2.19588
Timestep Consumption Time: 2.40515
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.60102

Cumulative Model Updates: 317,724
Cumulative Timesteps: 2,649,835,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2649835346...
Checkpoint 2649835346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.41114
Policy Entropy: 3.64650
Value Function Loss: 0.00261

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02091
Policy Update Magnitude: 0.14235
Value Function Update Magnitude: 0.18839

Collected Steps per Second: 22,449.10057
Overall Steps per Second: 10,702.46999

Timestep Collection Time: 2.22842
Timestep Consumption Time: 2.44583
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.67425

Cumulative Model Updates: 317,730
Cumulative Timesteps: 2,649,885,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.19148
Policy Entropy: 3.63274
Value Function Loss: 0.00306

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02186
Policy Update Magnitude: 0.14313
Value Function Update Magnitude: 0.19392

Collected Steps per Second: 22,706.92611
Overall Steps per Second: 10,766.22605

Timestep Collection Time: 2.20329
Timestep Consumption Time: 2.44365
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.64694

Cumulative Model Updates: 317,736
Cumulative Timesteps: 2,649,935,402

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2649935402...
Checkpoint 2649935402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.86114
Policy Entropy: 3.64515
Value Function Loss: 0.00340

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02375
Policy Update Magnitude: 0.14076
Value Function Update Magnitude: 0.18997

Collected Steps per Second: 22,299.76591
Overall Steps per Second: 10,660.35889

Timestep Collection Time: 2.24289
Timestep Consumption Time: 2.44888
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.69177

Cumulative Model Updates: 317,742
Cumulative Timesteps: 2,649,985,418

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.71238
Policy Entropy: 3.65191
Value Function Loss: 0.00319

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02130
Policy Update Magnitude: 0.14053
Value Function Update Magnitude: 0.19253

Collected Steps per Second: 22,606.36207
Overall Steps per Second: 10,515.67151

Timestep Collection Time: 2.21283
Timestep Consumption Time: 2.54426
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.75709

Cumulative Model Updates: 317,748
Cumulative Timesteps: 2,650,035,442

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2650035442...
Checkpoint 2650035442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.04442
Policy Entropy: 3.66644
Value Function Loss: 0.00329

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02351
Policy Update Magnitude: 0.14793
Value Function Update Magnitude: 0.20116

Collected Steps per Second: 22,259.78883
Overall Steps per Second: 10,667.02394

Timestep Collection Time: 2.24620
Timestep Consumption Time: 2.44114
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.68734

Cumulative Model Updates: 317,754
Cumulative Timesteps: 2,650,085,442

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.69462
Policy Entropy: 3.67803
Value Function Loss: 0.00300

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02164
Policy Update Magnitude: 0.15137
Value Function Update Magnitude: 0.20583

Collected Steps per Second: 22,790.03193
Overall Steps per Second: 10,791.76949

Timestep Collection Time: 2.19464
Timestep Consumption Time: 2.44000
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.63464

Cumulative Model Updates: 317,760
Cumulative Timesteps: 2,650,135,458

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2650135458...
Checkpoint 2650135458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.52685
Policy Entropy: 3.68589
Value Function Loss: 0.00322

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.01756
Policy Update Magnitude: 0.15547
Value Function Update Magnitude: 0.20397

Collected Steps per Second: 22,040.45713
Overall Steps per Second: 10,674.08683

Timestep Collection Time: 2.26901
Timestep Consumption Time: 2.41617
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.68518

Cumulative Model Updates: 317,766
Cumulative Timesteps: 2,650,185,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.06594
Policy Entropy: 3.66945
Value Function Loss: 0.00379

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02106
Policy Update Magnitude: 0.15750
Value Function Update Magnitude: 0.20516

Collected Steps per Second: 23,421.52268
Overall Steps per Second: 10,912.54820

Timestep Collection Time: 2.13496
Timestep Consumption Time: 2.44729
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.58225

Cumulative Model Updates: 317,772
Cumulative Timesteps: 2,650,235,472

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2650235472...
Checkpoint 2650235472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.63309
Policy Entropy: 3.64634
Value Function Loss: 0.00443

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02373
Policy Update Magnitude: 0.15999
Value Function Update Magnitude: 0.20698

Collected Steps per Second: 22,263.02768
Overall Steps per Second: 10,601.23541

Timestep Collection Time: 2.24659
Timestep Consumption Time: 2.47135
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.71794

Cumulative Model Updates: 317,778
Cumulative Timesteps: 2,650,285,488

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.84709
Policy Entropy: 3.63261
Value Function Loss: 0.00420

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02289
Policy Update Magnitude: 0.16407
Value Function Update Magnitude: 0.22430

Collected Steps per Second: 22,440.41537
Overall Steps per Second: 10,743.96154

Timestep Collection Time: 2.22830
Timestep Consumption Time: 2.42585
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.65415

Cumulative Model Updates: 317,784
Cumulative Timesteps: 2,650,335,492

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2650335492...
Checkpoint 2650335492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.78010
Policy Entropy: 3.65781
Value Function Loss: 0.00410

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02604
Policy Update Magnitude: 0.16284
Value Function Update Magnitude: 0.23306

Collected Steps per Second: 22,441.08844
Overall Steps per Second: 10,529.45101

Timestep Collection Time: 2.22877
Timestep Consumption Time: 2.52134
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.75011

Cumulative Model Updates: 317,790
Cumulative Timesteps: 2,650,385,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.67069
Policy Entropy: 3.67742
Value Function Loss: 0.00410

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02393
Policy Update Magnitude: 0.16509
Value Function Update Magnitude: 0.22713

Collected Steps per Second: 22,679.57943
Overall Steps per Second: 10,756.64281

Timestep Collection Time: 2.20533
Timestep Consumption Time: 2.44445
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.64978

Cumulative Model Updates: 317,796
Cumulative Timesteps: 2,650,435,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2650435524...
Checkpoint 2650435524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.37267
Policy Entropy: 3.67571
Value Function Loss: 0.00384

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02325
Policy Update Magnitude: 0.17096
Value Function Update Magnitude: 0.22309

Collected Steps per Second: 22,308.87640
Overall Steps per Second: 10,723.91392

Timestep Collection Time: 2.24243
Timestep Consumption Time: 2.42248
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.66490

Cumulative Model Updates: 317,802
Cumulative Timesteps: 2,650,485,550

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.71828
Policy Entropy: 3.67192
Value Function Loss: 0.00291

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02279
Policy Update Magnitude: 0.16275
Value Function Update Magnitude: 0.20693

Collected Steps per Second: 22,694.70382
Overall Steps per Second: 10,646.99258

Timestep Collection Time: 2.20351
Timestep Consumption Time: 2.49340
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.69691

Cumulative Model Updates: 317,808
Cumulative Timesteps: 2,650,535,558

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2650535558...
Checkpoint 2650535558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.42009
Policy Entropy: 3.66206
Value Function Loss: 0.00269

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.01868
Policy Update Magnitude: 0.14814
Value Function Update Magnitude: 0.18072

Collected Steps per Second: 22,046.64812
Overall Steps per Second: 10,627.72691

Timestep Collection Time: 2.26928
Timestep Consumption Time: 2.43822
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.70750

Cumulative Model Updates: 317,814
Cumulative Timesteps: 2,650,585,588

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.77452
Policy Entropy: 3.67232
Value Function Loss: 0.00251

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.01814
Policy Update Magnitude: 0.14447
Value Function Update Magnitude: 0.16728

Collected Steps per Second: 22,846.79048
Overall Steps per Second: 10,762.50312

Timestep Collection Time: 2.18937
Timestep Consumption Time: 2.45825
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.64762

Cumulative Model Updates: 317,820
Cumulative Timesteps: 2,650,635,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2650635608...
Checkpoint 2650635608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.41582
Policy Entropy: 3.64982
Value Function Loss: 0.00306

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.01649
Policy Update Magnitude: 0.14916
Value Function Update Magnitude: 0.17935

Collected Steps per Second: 22,512.76270
Overall Steps per Second: 10,582.64370

Timestep Collection Time: 2.22114
Timestep Consumption Time: 2.50396
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.72510

Cumulative Model Updates: 317,826
Cumulative Timesteps: 2,650,685,612

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.72454
Policy Entropy: 3.68528
Value Function Loss: 0.00307

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02206
Policy Update Magnitude: 0.15366
Value Function Update Magnitude: 0.19645

Collected Steps per Second: 22,303.67496
Overall Steps per Second: 10,839.92439

Timestep Collection Time: 2.24187
Timestep Consumption Time: 2.37089
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.61276

Cumulative Model Updates: 317,832
Cumulative Timesteps: 2,650,735,614

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2650735614...
Checkpoint 2650735614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.17480
Policy Entropy: 3.68872
Value Function Loss: 0.00377

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02406
Policy Update Magnitude: 0.16266
Value Function Update Magnitude: 0.20077

Collected Steps per Second: 22,145.74489
Overall Steps per Second: 10,514.43531

Timestep Collection Time: 2.25885
Timestep Consumption Time: 2.49880
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.75765

Cumulative Model Updates: 317,838
Cumulative Timesteps: 2,650,785,638

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.75929
Policy Entropy: 3.74993
Value Function Loss: 0.00351

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02464
Policy Update Magnitude: 0.16369
Value Function Update Magnitude: 0.21053

Collected Steps per Second: 22,692.02538
Overall Steps per Second: 10,792.81530

Timestep Collection Time: 2.20403
Timestep Consumption Time: 2.42997
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.63401

Cumulative Model Updates: 317,844
Cumulative Timesteps: 2,650,835,652

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2650835652...
Checkpoint 2650835652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.08427
Policy Entropy: 3.73688
Value Function Loss: 0.00376

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.01982
Policy Update Magnitude: 0.16440
Value Function Update Magnitude: 0.22111

Collected Steps per Second: 22,347.27305
Overall Steps per Second: 10,737.93594

Timestep Collection Time: 2.23875
Timestep Consumption Time: 2.42043
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.65918

Cumulative Model Updates: 317,850
Cumulative Timesteps: 2,650,885,682

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.47714
Policy Entropy: 3.72364
Value Function Loss: 0.00377

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02088
Policy Update Magnitude: 0.17048
Value Function Update Magnitude: 0.21908

Collected Steps per Second: 22,546.09226
Overall Steps per Second: 10,693.37081

Timestep Collection Time: 2.21883
Timestep Consumption Time: 2.45939
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.67823

Cumulative Model Updates: 317,856
Cumulative Timesteps: 2,650,935,708

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2650935708...
Checkpoint 2650935708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.26965
Policy Entropy: 3.73366
Value Function Loss: 0.00357

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02216
Policy Update Magnitude: 0.16368
Value Function Update Magnitude: 0.21578

Collected Steps per Second: 22,083.96737
Overall Steps per Second: 10,837.75072

Timestep Collection Time: 2.26517
Timestep Consumption Time: 2.35055
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.61572

Cumulative Model Updates: 317,862
Cumulative Timesteps: 2,650,985,732

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.44646
Policy Entropy: 3.74156
Value Function Loss: 0.00332

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02103
Policy Update Magnitude: 0.15601
Value Function Update Magnitude: 0.20355

Collected Steps per Second: 22,733.33329
Overall Steps per Second: 10,766.83515

Timestep Collection Time: 2.19977
Timestep Consumption Time: 2.44487
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.64463

Cumulative Model Updates: 317,868
Cumulative Timesteps: 2,651,035,740

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2651035740...
Checkpoint 2651035740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.06505
Policy Entropy: 3.76492
Value Function Loss: 0.00337

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02090
Policy Update Magnitude: 0.15208
Value Function Update Magnitude: 0.20036

Collected Steps per Second: 22,291.23020
Overall Steps per Second: 10,679.79408

Timestep Collection Time: 2.24483
Timestep Consumption Time: 2.44065
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.68548

Cumulative Model Updates: 317,874
Cumulative Timesteps: 2,651,085,780

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.23347
Policy Entropy: 3.76119
Value Function Loss: 0.00300

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.01950
Policy Update Magnitude: 0.14596
Value Function Update Magnitude: 0.21230

Collected Steps per Second: 22,319.33755
Overall Steps per Second: 10,681.93713

Timestep Collection Time: 2.24066
Timestep Consumption Time: 2.44108
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.68174

Cumulative Model Updates: 317,880
Cumulative Timesteps: 2,651,135,790

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2651135790...
Checkpoint 2651135790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.86036
Policy Entropy: 3.76846
Value Function Loss: 0.00307

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.01731
Policy Update Magnitude: 0.14429
Value Function Update Magnitude: 0.21485

Collected Steps per Second: 22,496.58163
Overall Steps per Second: 10,551.07821

Timestep Collection Time: 2.22292
Timestep Consumption Time: 2.51669
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.73961

Cumulative Model Updates: 317,886
Cumulative Timesteps: 2,651,185,798

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.34354
Policy Entropy: 3.78405
Value Function Loss: 0.00292

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.01861
Policy Update Magnitude: 0.14807
Value Function Update Magnitude: 0.21083

Collected Steps per Second: 22,270.22362
Overall Steps per Second: 10,576.12322

Timestep Collection Time: 2.24614
Timestep Consumption Time: 2.48357
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.72971

Cumulative Model Updates: 317,892
Cumulative Timesteps: 2,651,235,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2651235820...
Checkpoint 2651235820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.73072
Policy Entropy: 3.79732
Value Function Loss: 0.00292

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.01718
Policy Update Magnitude: 0.15049
Value Function Update Magnitude: 0.20437

Collected Steps per Second: 23,233.18883
Overall Steps per Second: 10,871.34778

Timestep Collection Time: 2.15278
Timestep Consumption Time: 2.44794
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.60072

Cumulative Model Updates: 317,898
Cumulative Timesteps: 2,651,285,836

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.81395
Policy Entropy: 3.79561
Value Function Loss: 0.00302

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01911
Policy Update Magnitude: 0.15805
Value Function Update Magnitude: 0.18992

Collected Steps per Second: 22,192.82663
Overall Steps per Second: 10,495.16946

Timestep Collection Time: 2.25370
Timestep Consumption Time: 2.51192
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.76562

Cumulative Model Updates: 317,904
Cumulative Timesteps: 2,651,335,852

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2651335852...
Checkpoint 2651335852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.54572
Policy Entropy: 3.79484
Value Function Loss: 0.00357

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02057
Policy Update Magnitude: 0.16850
Value Function Update Magnitude: 0.18687

Collected Steps per Second: 21,851.67259
Overall Steps per Second: 10,644.43546

Timestep Collection Time: 2.28898
Timestep Consumption Time: 2.41000
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.69898

Cumulative Model Updates: 317,910
Cumulative Timesteps: 2,651,385,870

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.81926
Policy Entropy: 3.78215
Value Function Loss: 0.00423

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02136
Policy Update Magnitude: 0.16667
Value Function Update Magnitude: 0.19192

Collected Steps per Second: 22,698.94093
Overall Steps per Second: 10,624.55661

Timestep Collection Time: 2.20327
Timestep Consumption Time: 2.50393
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.70721

Cumulative Model Updates: 317,916
Cumulative Timesteps: 2,651,435,882

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2651435882...
Checkpoint 2651435882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.94752
Policy Entropy: 3.79598
Value Function Loss: 0.00377

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.01860
Policy Update Magnitude: 0.15723
Value Function Update Magnitude: 0.19985

Collected Steps per Second: 22,475.02911
Overall Steps per Second: 10,628.51609

Timestep Collection Time: 2.22558
Timestep Consumption Time: 2.48063
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.70621

Cumulative Model Updates: 317,922
Cumulative Timesteps: 2,651,485,902

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.15618
Policy Entropy: 3.81621
Value Function Loss: 0.00301

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02447
Policy Update Magnitude: 0.14960
Value Function Update Magnitude: 0.20070

Collected Steps per Second: 22,653.53264
Overall Steps per Second: 10,765.58303

Timestep Collection Time: 2.20831
Timestep Consumption Time: 2.43854
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.64685

Cumulative Model Updates: 317,928
Cumulative Timesteps: 2,651,535,928

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2651535928...
Checkpoint 2651535928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.41640
Policy Entropy: 3.80945
Value Function Loss: 0.00249

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01793
Policy Update Magnitude: 0.14475
Value Function Update Magnitude: 0.19367

Collected Steps per Second: 22,355.88439
Overall Steps per Second: 10,625.28875

Timestep Collection Time: 2.23753
Timestep Consumption Time: 2.47029
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.70782

Cumulative Model Updates: 317,934
Cumulative Timesteps: 2,651,585,950

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.01667
Policy Entropy: 3.81925
Value Function Loss: 0.00224

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02254
Policy Update Magnitude: 0.13138
Value Function Update Magnitude: 0.18965

Collected Steps per Second: 22,789.08937
Overall Steps per Second: 10,803.29086

Timestep Collection Time: 2.19535
Timestep Consumption Time: 2.43565
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.63100

Cumulative Model Updates: 317,940
Cumulative Timesteps: 2,651,635,980

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2651635980...
Checkpoint 2651635980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.08839
Policy Entropy: 3.84054
Value Function Loss: 0.00213

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.01958
Policy Update Magnitude: 0.12708
Value Function Update Magnitude: 0.17549

Collected Steps per Second: 23,191.59005
Overall Steps per Second: 10,738.16560

Timestep Collection Time: 2.15699
Timestep Consumption Time: 2.50153
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.65852

Cumulative Model Updates: 317,946
Cumulative Timesteps: 2,651,686,004

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.23294
Policy Entropy: 3.85438
Value Function Loss: 0.00220

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.01707
Policy Update Magnitude: 0.12517
Value Function Update Magnitude: 0.16246

Collected Steps per Second: 22,739.21383
Overall Steps per Second: 10,591.35017

Timestep Collection Time: 2.19981
Timestep Consumption Time: 2.52310
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.72291

Cumulative Model Updates: 317,952
Cumulative Timesteps: 2,651,736,026

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2651736026...
Checkpoint 2651736026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.74993
Policy Entropy: 3.85160
Value Function Loss: 0.00266

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01405
Policy Update Magnitude: 0.13099
Value Function Update Magnitude: 0.16608

Collected Steps per Second: 22,446.71631
Overall Steps per Second: 10,881.42927

Timestep Collection Time: 2.22839
Timestep Consumption Time: 2.36843
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.59682

Cumulative Model Updates: 317,958
Cumulative Timesteps: 2,651,786,046

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.24638
Policy Entropy: 3.83092
Value Function Loss: 0.00315

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01773
Policy Update Magnitude: 0.14782
Value Function Update Magnitude: 0.18167

Collected Steps per Second: 22,555.66654
Overall Steps per Second: 10,548.05793

Timestep Collection Time: 2.21692
Timestep Consumption Time: 2.52367
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.74059

Cumulative Model Updates: 317,964
Cumulative Timesteps: 2,651,836,050

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2651836050...
Checkpoint 2651836050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.57868
Policy Entropy: 3.81202
Value Function Loss: 0.00359

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01626
Policy Update Magnitude: 0.15904
Value Function Update Magnitude: 0.19120

Collected Steps per Second: 22,130.12841
Overall Steps per Second: 10,592.69303

Timestep Collection Time: 2.25972
Timestep Consumption Time: 2.46127
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.72099

Cumulative Model Updates: 317,970
Cumulative Timesteps: 2,651,886,058

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.82025
Policy Entropy: 3.82961
Value Function Loss: 0.00369

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.01864
Policy Update Magnitude: 0.16226
Value Function Update Magnitude: 0.19854

Collected Steps per Second: 22,554.83912
Overall Steps per Second: 10,875.82713

Timestep Collection Time: 2.21806
Timestep Consumption Time: 2.38187
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.59993

Cumulative Model Updates: 317,976
Cumulative Timesteps: 2,651,936,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2651936086...
Checkpoint 2651936086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.61377
Policy Entropy: 3.82967
Value Function Loss: 0.00378

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.01888
Policy Update Magnitude: 0.16132
Value Function Update Magnitude: 0.19772

Collected Steps per Second: 22,191.05368
Overall Steps per Second: 10,632.97141

Timestep Collection Time: 2.25334
Timestep Consumption Time: 2.44939
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.70273

Cumulative Model Updates: 317,982
Cumulative Timesteps: 2,651,986,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.37032
Policy Entropy: 3.82146
Value Function Loss: 0.00375

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.01712
Policy Update Magnitude: 0.16461
Value Function Update Magnitude: 0.20294

Collected Steps per Second: 22,474.29333
Overall Steps per Second: 10,557.78845

Timestep Collection Time: 2.22530
Timestep Consumption Time: 2.51168
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.73698

Cumulative Model Updates: 317,988
Cumulative Timesteps: 2,652,036,102

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2652036102...
Checkpoint 2652036102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.93846
Policy Entropy: 3.82058
Value Function Loss: 0.00306

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01784
Policy Update Magnitude: 0.15721
Value Function Update Magnitude: 0.20137

Collected Steps per Second: 22,249.50444
Overall Steps per Second: 10,640.81031

Timestep Collection Time: 2.24778
Timestep Consumption Time: 2.45224
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.70002

Cumulative Model Updates: 317,994
Cumulative Timesteps: 2,652,086,114

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.64662
Policy Entropy: 3.82174
Value Function Loss: 0.00241

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.01713
Policy Update Magnitude: 0.14584
Value Function Update Magnitude: 0.18521

Collected Steps per Second: 22,751.52242
Overall Steps per Second: 10,604.16163

Timestep Collection Time: 2.19862
Timestep Consumption Time: 2.51858
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.71720

Cumulative Model Updates: 318,000
Cumulative Timesteps: 2,652,136,136

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2652136136...
Checkpoint 2652136136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.76156
Policy Entropy: 3.85959
Value Function Loss: 0.00213

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01706
Policy Update Magnitude: 0.14086
Value Function Update Magnitude: 0.17234

Collected Steps per Second: 21,922.09088
Overall Steps per Second: 10,626.02636

Timestep Collection Time: 2.28126
Timestep Consumption Time: 2.42511
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.70637

Cumulative Model Updates: 318,006
Cumulative Timesteps: 2,652,186,146

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.59892
Policy Entropy: 3.86458
Value Function Loss: 0.00200

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.01790
Policy Update Magnitude: 0.14662
Value Function Update Magnitude: 0.16095

Collected Steps per Second: 22,893.15405
Overall Steps per Second: 10,729.61581

Timestep Collection Time: 2.18415
Timestep Consumption Time: 2.47604
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.66019

Cumulative Model Updates: 318,012
Cumulative Timesteps: 2,652,236,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2652236148...
Checkpoint 2652236148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.17627
Policy Entropy: 3.86938
Value Function Loss: 0.00243

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01623
Policy Update Magnitude: 0.14395
Value Function Update Magnitude: 0.15389

Collected Steps per Second: 22,396.86279
Overall Steps per Second: 10,695.12360

Timestep Collection Time: 2.23353
Timestep Consumption Time: 2.44374
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.67727

Cumulative Model Updates: 318,018
Cumulative Timesteps: 2,652,286,172

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.23164
Policy Entropy: 3.83074
Value Function Loss: 0.00274

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.01515
Policy Update Magnitude: 0.14679
Value Function Update Magnitude: 0.16194

Collected Steps per Second: 22,550.80005
Overall Steps per Second: 10,848.29202

Timestep Collection Time: 2.21828
Timestep Consumption Time: 2.39295
PPO Batch Consumption Time: 0.28221
Total Iteration Time: 4.61123

Cumulative Model Updates: 318,024
Cumulative Timesteps: 2,652,336,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2652336196...
Checkpoint 2652336196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.80531
Policy Entropy: 3.84163
Value Function Loss: 0.00272

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01604
Policy Update Magnitude: 0.14318
Value Function Update Magnitude: 0.17023

Collected Steps per Second: 22,439.80236
Overall Steps per Second: 10,669.77470

Timestep Collection Time: 2.22845
Timestep Consumption Time: 2.45825
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.68670

Cumulative Model Updates: 318,030
Cumulative Timesteps: 2,652,386,202

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.16613
Policy Entropy: 3.86475
Value Function Loss: 0.00232

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.01780
Policy Update Magnitude: 0.14061
Value Function Update Magnitude: 0.17540

Collected Steps per Second: 22,588.06305
Overall Steps per Second: 10,627.42252

Timestep Collection Time: 2.21409
Timestep Consumption Time: 2.49185
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.70594

Cumulative Model Updates: 318,036
Cumulative Timesteps: 2,652,436,214

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2652436214...
Checkpoint 2652436214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.86710
Policy Entropy: 3.87017
Value Function Loss: 0.00241

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.01538
Policy Update Magnitude: 0.13627
Value Function Update Magnitude: 0.17628

Collected Steps per Second: 23,205.95644
Overall Steps per Second: 10,872.94454

Timestep Collection Time: 2.15479
Timestep Consumption Time: 2.44415
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.59894

Cumulative Model Updates: 318,042
Cumulative Timesteps: 2,652,486,218

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.15478
Policy Entropy: 3.85844
Value Function Loss: 0.00249

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01513
Policy Update Magnitude: 0.14038
Value Function Update Magnitude: 0.17795

Collected Steps per Second: 22,361.37177
Overall Steps per Second: 10,532.56334

Timestep Collection Time: 2.23716
Timestep Consumption Time: 2.51249
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.74965

Cumulative Model Updates: 318,048
Cumulative Timesteps: 2,652,536,244

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2652536244...
Checkpoint 2652536244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.55143
Policy Entropy: 3.86069
Value Function Loss: 0.00273

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01682
Policy Update Magnitude: 0.14678
Value Function Update Magnitude: 0.18226

Collected Steps per Second: 22,506.15373
Overall Steps per Second: 10,658.20966

Timestep Collection Time: 2.22215
Timestep Consumption Time: 2.47020
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.69235

Cumulative Model Updates: 318,054
Cumulative Timesteps: 2,652,586,256

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.99646
Policy Entropy: 3.87965
Value Function Loss: 0.00243

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01557
Policy Update Magnitude: 0.14523
Value Function Update Magnitude: 0.18769

Collected Steps per Second: 23,388.32829
Overall Steps per Second: 10,860.20862

Timestep Collection Time: 2.13808
Timestep Consumption Time: 2.46644
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.60452

Cumulative Model Updates: 318,060
Cumulative Timesteps: 2,652,636,262

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2652636262...
Checkpoint 2652636262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.06548
Policy Entropy: 3.87903
Value Function Loss: 0.00272

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01484
Policy Update Magnitude: 0.15153
Value Function Update Magnitude: 0.19181

Collected Steps per Second: 22,506.02810
Overall Steps per Second: 10,689.78317

Timestep Collection Time: 2.22243
Timestep Consumption Time: 2.45662
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.67905

Cumulative Model Updates: 318,066
Cumulative Timesteps: 2,652,686,280

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.88421
Policy Entropy: 3.88636
Value Function Loss: 0.00227

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01504
Policy Update Magnitude: 0.15078
Value Function Update Magnitude: 0.19129

Collected Steps per Second: 22,571.87694
Overall Steps per Second: 10,853.90098

Timestep Collection Time: 2.21559
Timestep Consumption Time: 2.39197
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.60756

Cumulative Model Updates: 318,072
Cumulative Timesteps: 2,652,736,290

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2652736290...
Checkpoint 2652736290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.84916
Policy Entropy: 3.93235
Value Function Loss: 0.00263

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.01861
Policy Update Magnitude: 0.14300
Value Function Update Magnitude: 0.18300

Collected Steps per Second: 22,418.51383
Overall Steps per Second: 10,723.23639

Timestep Collection Time: 2.23110
Timestep Consumption Time: 2.43335
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.66445

Cumulative Model Updates: 318,078
Cumulative Timesteps: 2,652,786,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.00108
Policy Entropy: 3.93919
Value Function Loss: 0.00286

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.01567
Policy Update Magnitude: 0.14845
Value Function Update Magnitude: 0.18134

Collected Steps per Second: 22,327.26064
Overall Steps per Second: 10,568.00982

Timestep Collection Time: 2.23977
Timestep Consumption Time: 2.49224
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.73202

Cumulative Model Updates: 318,084
Cumulative Timesteps: 2,652,836,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2652836316...
Checkpoint 2652836316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.08515
Policy Entropy: 3.92884
Value Function Loss: 0.00335

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.01540
Policy Update Magnitude: 0.15951
Value Function Update Magnitude: 0.19650

Collected Steps per Second: 22,965.68295
Overall Steps per Second: 10,681.45322

Timestep Collection Time: 2.17760
Timestep Consumption Time: 2.50435
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.68195

Cumulative Model Updates: 318,090
Cumulative Timesteps: 2,652,886,326

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.66077
Policy Entropy: 3.91305
Value Function Loss: 0.00315

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.01783
Policy Update Magnitude: 0.15919
Value Function Update Magnitude: 0.19654

Collected Steps per Second: 22,657.40126
Overall Steps per Second: 10,680.57909

Timestep Collection Time: 2.20899
Timestep Consumption Time: 2.47708
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.68608

Cumulative Model Updates: 318,096
Cumulative Timesteps: 2,652,936,376

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2652936376...
Checkpoint 2652936376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.35649
Policy Entropy: 3.90779
Value Function Loss: 0.00311

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.01937
Policy Update Magnitude: 0.15503
Value Function Update Magnitude: 0.19810

Collected Steps per Second: 22,253.47943
Overall Steps per Second: 10,727.94436

Timestep Collection Time: 2.24702
Timestep Consumption Time: 2.41408
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.66110

Cumulative Model Updates: 318,102
Cumulative Timesteps: 2,652,986,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.65522
Policy Entropy: 3.89010
Value Function Loss: 0.00329

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.01579
Policy Update Magnitude: 0.15069
Value Function Update Magnitude: 0.19950

Collected Steps per Second: 23,407.87794
Overall Steps per Second: 10,837.38249

Timestep Collection Time: 2.13663
Timestep Consumption Time: 2.47832
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.61495

Cumulative Model Updates: 318,108
Cumulative Timesteps: 2,653,036,394

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2653036394...
Checkpoint 2653036394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.98061
Policy Entropy: 3.90301
Value Function Loss: 0.00305

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01710
Policy Update Magnitude: 0.14799
Value Function Update Magnitude: 0.19850

Collected Steps per Second: 22,668.85065
Overall Steps per Second: 10,738.60522

Timestep Collection Time: 2.20655
Timestep Consumption Time: 2.45141
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.65796

Cumulative Model Updates: 318,114
Cumulative Timesteps: 2,653,086,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.11300
Policy Entropy: 3.89788
Value Function Loss: 0.00335

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01570
Policy Update Magnitude: 0.15596
Value Function Update Magnitude: 0.19918

Collected Steps per Second: 22,610.96990
Overall Steps per Second: 10,905.30895

Timestep Collection Time: 2.21229
Timestep Consumption Time: 2.37465
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.58694

Cumulative Model Updates: 318,120
Cumulative Timesteps: 2,653,136,436

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2653136436...
Checkpoint 2653136436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.06993
Policy Entropy: 3.91409
Value Function Loss: 0.00350

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.01596
Policy Update Magnitude: 0.16276
Value Function Update Magnitude: 0.20202

Collected Steps per Second: 21,960.83515
Overall Steps per Second: 10,609.06266

Timestep Collection Time: 2.27724
Timestep Consumption Time: 2.43666
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.71389

Cumulative Model Updates: 318,126
Cumulative Timesteps: 2,653,186,446

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.56964
Policy Entropy: 3.89177
Value Function Loss: 0.00392

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.01765
Policy Update Magnitude: 0.16679
Value Function Update Magnitude: 0.22042

Collected Steps per Second: 22,428.23034
Overall Steps per Second: 10,578.45071

Timestep Collection Time: 2.23023
Timestep Consumption Time: 2.49826
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.72848

Cumulative Model Updates: 318,132
Cumulative Timesteps: 2,653,236,466

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2653236466...
Checkpoint 2653236466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.74241
Policy Entropy: 3.90835
Value Function Loss: 0.00323

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.01967
Policy Update Magnitude: 0.16195
Value Function Update Magnitude: 0.22412

Collected Steps per Second: 23,219.83221
Overall Steps per Second: 10,865.84090

Timestep Collection Time: 2.15419
Timestep Consumption Time: 2.44922
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.60342

Cumulative Model Updates: 318,138
Cumulative Timesteps: 2,653,286,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.73541
Policy Entropy: 3.91525
Value Function Loss: 0.00286

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01852
Policy Update Magnitude: 0.15262
Value Function Update Magnitude: 0.21762

Collected Steps per Second: 22,231.91936
Overall Steps per Second: 10,558.46468

Timestep Collection Time: 2.24992
Timestep Consumption Time: 2.48751
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.73743

Cumulative Model Updates: 318,144
Cumulative Timesteps: 2,653,336,506

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2653336506...
Checkpoint 2653336506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.31279
Policy Entropy: 3.91936
Value Function Loss: 0.00235

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.01883
Policy Update Magnitude: 0.15009
Value Function Update Magnitude: 0.19473

Collected Steps per Second: 22,563.74913
Overall Steps per Second: 10,783.02581

Timestep Collection Time: 2.21594
Timestep Consumption Time: 2.42097
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.63692

Cumulative Model Updates: 318,150
Cumulative Timesteps: 2,653,386,506

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.34863
Policy Entropy: 3.91105
Value Function Loss: 0.00331

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.01783
Policy Update Magnitude: 0.15793
Value Function Update Magnitude: 0.18731

Collected Steps per Second: 22,648.08173
Overall Steps per Second: 10,709.16516

Timestep Collection Time: 2.20893
Timestep Consumption Time: 2.46258
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.67151

Cumulative Model Updates: 318,156
Cumulative Timesteps: 2,653,436,534

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2653436534...
Checkpoint 2653436534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.60581
Policy Entropy: 3.91730
Value Function Loss: 0.00272

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.01938
Policy Update Magnitude: 0.15977
Value Function Update Magnitude: 0.19947

Collected Steps per Second: 22,060.89124
Overall Steps per Second: 10,622.42979

Timestep Collection Time: 2.26736
Timestep Consumption Time: 2.44154
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.70890

Cumulative Model Updates: 318,162
Cumulative Timesteps: 2,653,486,554

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.40391
Policy Entropy: 3.93307
Value Function Loss: 0.00267

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.01958
Policy Update Magnitude: 0.15348
Value Function Update Magnitude: 0.19458

Collected Steps per Second: 23,237.40212
Overall Steps per Second: 10,728.30598

Timestep Collection Time: 2.15231
Timestep Consumption Time: 2.50957
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.66187

Cumulative Model Updates: 318,168
Cumulative Timesteps: 2,653,536,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2653536568...
Checkpoint 2653536568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.90324
Policy Entropy: 3.93514
Value Function Loss: 0.00245

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.01843
Policy Update Magnitude: 0.15378
Value Function Update Magnitude: 0.18838

Collected Steps per Second: 22,343.76771
Overall Steps per Second: 10,473.38327

Timestep Collection Time: 2.23892
Timestep Consumption Time: 2.53756
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.77649

Cumulative Model Updates: 318,174
Cumulative Timesteps: 2,653,586,594

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.88931
Policy Entropy: 3.92694
Value Function Loss: 0.00275

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02041
Policy Update Magnitude: 0.15373
Value Function Update Magnitude: 0.20419

Collected Steps per Second: 22,574.07256
Overall Steps per Second: 10,611.20084

Timestep Collection Time: 2.21555
Timestep Consumption Time: 2.49777
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.71332

Cumulative Model Updates: 318,180
Cumulative Timesteps: 2,653,636,608

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2653636608...
Checkpoint 2653636608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.63195
Policy Entropy: 3.92451
Value Function Loss: 0.00353

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.01692
Policy Update Magnitude: 0.15871
Value Function Update Magnitude: 0.21599

Collected Steps per Second: 23,339.11118
Overall Steps per Second: 10,875.77543

Timestep Collection Time: 2.14301
Timestep Consumption Time: 2.45583
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.59884

Cumulative Model Updates: 318,186
Cumulative Timesteps: 2,653,686,624

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.11385
Policy Entropy: 3.93741
Value Function Loss: 0.00383

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01721
Policy Update Magnitude: 0.16787
Value Function Update Magnitude: 0.21222

Collected Steps per Second: 22,301.40272
Overall Steps per Second: 10,512.59784

Timestep Collection Time: 2.24219
Timestep Consumption Time: 2.51439
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.75658

Cumulative Model Updates: 318,192
Cumulative Timesteps: 2,653,736,628

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2653736628...
Checkpoint 2653736628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.43184
Policy Entropy: 3.95815
Value Function Loss: 0.00364

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02027
Policy Update Magnitude: 0.16749
Value Function Update Magnitude: 0.20204

Collected Steps per Second: 22,261.91861
Overall Steps per Second: 10,645.02647

Timestep Collection Time: 2.24734
Timestep Consumption Time: 2.45251
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.69985

Cumulative Model Updates: 318,198
Cumulative Timesteps: 2,653,786,658

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.27822
Policy Entropy: 3.98046
Value Function Loss: 0.00321

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.01641
Policy Update Magnitude: 0.15443
Value Function Update Magnitude: 0.19239

Collected Steps per Second: 22,750.94070
Overall Steps per Second: 10,584.91126

Timestep Collection Time: 2.19850
Timestep Consumption Time: 2.52690
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.72541

Cumulative Model Updates: 318,204
Cumulative Timesteps: 2,653,836,676

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2653836676...
Checkpoint 2653836676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.47292
Policy Entropy: 3.98448
Value Function Loss: 0.00289

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01460
Policy Update Magnitude: 0.15583
Value Function Update Magnitude: 0.18429

Collected Steps per Second: 22,407.31160
Overall Steps per Second: 10,577.31962

Timestep Collection Time: 2.23141
Timestep Consumption Time: 2.49568
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.72710

Cumulative Model Updates: 318,210
Cumulative Timesteps: 2,653,886,676

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.54898
Policy Entropy: 3.97346
Value Function Loss: 0.00333

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01703
Policy Update Magnitude: 0.16789
Value Function Update Magnitude: 0.19689

Collected Steps per Second: 22,487.00503
Overall Steps per Second: 10,843.10061

Timestep Collection Time: 2.22413
Timestep Consumption Time: 2.38839
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.61252

Cumulative Model Updates: 318,216
Cumulative Timesteps: 2,653,936,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2653936690...
Checkpoint 2653936690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.36230
Policy Entropy: 3.96332
Value Function Loss: 0.00348

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.01969
Policy Update Magnitude: 0.17512
Value Function Update Magnitude: 0.20387

Collected Steps per Second: 22,538.19523
Overall Steps per Second: 10,663.48258

Timestep Collection Time: 2.21881
Timestep Consumption Time: 2.47084
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.68965

Cumulative Model Updates: 318,222
Cumulative Timesteps: 2,653,986,698

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.17053
Policy Entropy: 3.96857
Value Function Loss: 0.00363

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.01878
Policy Update Magnitude: 0.16580
Value Function Update Magnitude: 0.20729

Collected Steps per Second: 22,370.13728
Overall Steps per Second: 10,554.15116

Timestep Collection Time: 2.23646
Timestep Consumption Time: 2.50385
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.74031

Cumulative Model Updates: 318,228
Cumulative Timesteps: 2,654,036,728

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2654036728...
Checkpoint 2654036728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.01656
Policy Entropy: 3.98480
Value Function Loss: 0.00284

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.01690
Policy Update Magnitude: 0.15423
Value Function Update Magnitude: 0.20039

Collected Steps per Second: 23,511.28338
Overall Steps per Second: 10,936.29034

Timestep Collection Time: 2.12783
Timestep Consumption Time: 2.44667
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.57449

Cumulative Model Updates: 318,234
Cumulative Timesteps: 2,654,086,756

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.26689
Policy Entropy: 3.98279
Value Function Loss: 0.00225

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.01568
Policy Update Magnitude: 0.14166
Value Function Update Magnitude: 0.17993

Collected Steps per Second: 21,904.72828
Overall Steps per Second: 10,555.89251

Timestep Collection Time: 2.28261
Timestep Consumption Time: 2.45408
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.73669

Cumulative Model Updates: 318,240
Cumulative Timesteps: 2,654,136,756

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2654136756...
Checkpoint 2654136756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.86941
Policy Entropy: 3.98105
Value Function Loss: 0.00182

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01505
Policy Update Magnitude: 0.13463
Value Function Update Magnitude: 0.16242

Collected Steps per Second: 22,105.48269
Overall Steps per Second: 10,614.46498

Timestep Collection Time: 2.26224
Timestep Consumption Time: 2.44906
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.71131

Cumulative Model Updates: 318,246
Cumulative Timesteps: 2,654,186,764

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.09621
Policy Entropy: 3.97232
Value Function Loss: 0.00217

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01499
Policy Update Magnitude: 0.13961
Value Function Update Magnitude: 0.16672

Collected Steps per Second: 23,152.18290
Overall Steps per Second: 10,828.23786

Timestep Collection Time: 2.16006
Timestep Consumption Time: 2.45842
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.61848

Cumulative Model Updates: 318,252
Cumulative Timesteps: 2,654,236,774

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2654236774...
Checkpoint 2654236774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33609
Policy Entropy: 3.98816
Value Function Loss: 0.00297

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.01735
Policy Update Magnitude: 0.14282
Value Function Update Magnitude: 0.18384

Collected Steps per Second: 22,391.81642
Overall Steps per Second: 10,669.55966

Timestep Collection Time: 2.23421
Timestep Consumption Time: 2.45464
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.68885

Cumulative Model Updates: 318,258
Cumulative Timesteps: 2,654,286,802

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.61991
Policy Entropy: 4.00451
Value Function Loss: 0.00290

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.01585
Policy Update Magnitude: 0.14559
Value Function Update Magnitude: 0.19107

Collected Steps per Second: 22,398.90660
Overall Steps per Second: 10,878.83663

Timestep Collection Time: 2.23332
Timestep Consumption Time: 2.36496
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.59829

Cumulative Model Updates: 318,264
Cumulative Timesteps: 2,654,336,826

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2654336826...
Checkpoint 2654336826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.10558
Policy Entropy: 3.99348
Value Function Loss: 0.00351

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.01691
Policy Update Magnitude: 0.14613
Value Function Update Magnitude: 0.18854

Collected Steps per Second: 22,526.42375
Overall Steps per Second: 10,719.20946

Timestep Collection Time: 2.22095
Timestep Consumption Time: 2.44637
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.66732

Cumulative Model Updates: 318,270
Cumulative Timesteps: 2,654,386,856

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.16653
Policy Entropy: 3.96784
Value Function Loss: 0.00332

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01558
Policy Update Magnitude: 0.15388
Value Function Update Magnitude: 0.18543

Collected Steps per Second: 22,347.11252
Overall Steps per Second: 10,555.33540

Timestep Collection Time: 2.23823
Timestep Consumption Time: 2.50042
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.73865

Cumulative Model Updates: 318,276
Cumulative Timesteps: 2,654,436,874

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2654436874...
Checkpoint 2654436874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.24548
Policy Entropy: 3.94895
Value Function Loss: 0.00345

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.01811
Policy Update Magnitude: 0.16073
Value Function Update Magnitude: 0.20566

Collected Steps per Second: 22,392.64964
Overall Steps per Second: 10,756.81922

Timestep Collection Time: 2.23314
Timestep Consumption Time: 2.41563
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.64877

Cumulative Model Updates: 318,282
Cumulative Timesteps: 2,654,486,880

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.40036
Policy Entropy: 3.97289
Value Function Loss: 0.00323

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.01788
Policy Update Magnitude: 0.15941
Value Function Update Magnitude: 0.22030

Collected Steps per Second: 22,543.78424
Overall Steps per Second: 10,682.05883

Timestep Collection Time: 2.21817
Timestep Consumption Time: 2.46313
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.68131

Cumulative Model Updates: 318,288
Cumulative Timesteps: 2,654,536,886

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2654536886...
Checkpoint 2654536886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.09612
Policy Entropy: 3.98381
Value Function Loss: 0.00340

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.01773
Policy Update Magnitude: 0.16138
Value Function Update Magnitude: 0.22180

Collected Steps per Second: 22,155.88292
Overall Steps per Second: 10,692.33031

Timestep Collection Time: 2.25782
Timestep Consumption Time: 2.42067
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.67849

Cumulative Model Updates: 318,294
Cumulative Timesteps: 2,654,586,910

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.98854
Policy Entropy: 3.97408
Value Function Loss: 0.00323

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01405
Policy Update Magnitude: 0.16229
Value Function Update Magnitude: 0.22375

Collected Steps per Second: 22,461.28283
Overall Steps per Second: 10,550.15488

Timestep Collection Time: 2.22641
Timestep Consumption Time: 2.51362
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.74003

Cumulative Model Updates: 318,300
Cumulative Timesteps: 2,654,636,918

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2654636918...
Checkpoint 2654636918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.80511
Policy Entropy: 3.95255
Value Function Loss: 0.00329

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.01719
Policy Update Magnitude: 0.16537
Value Function Update Magnitude: 0.21756

Collected Steps per Second: 22,351.18784
Overall Steps per Second: 10,559.71604

Timestep Collection Time: 2.23782
Timestep Consumption Time: 2.49886
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.73668

Cumulative Model Updates: 318,306
Cumulative Timesteps: 2,654,686,936

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.86898
Policy Entropy: 3.96330
Value Function Loss: 0.00299

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.01559
Policy Update Magnitude: 0.16959
Value Function Update Magnitude: 0.20187

Collected Steps per Second: 22,336.59882
Overall Steps per Second: 10,821.57383

Timestep Collection Time: 2.23946
Timestep Consumption Time: 2.38297
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.62243

Cumulative Model Updates: 318,312
Cumulative Timesteps: 2,654,736,958

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2654736958...
Checkpoint 2654736958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.05847
Policy Entropy: 3.97907
Value Function Loss: 0.00265

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.01584
Policy Update Magnitude: 0.16425
Value Function Update Magnitude: 0.19665

Collected Steps per Second: 22,237.13432
Overall Steps per Second: 10,634.44257

Timestep Collection Time: 2.24903
Timestep Consumption Time: 2.45380
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.70283

Cumulative Model Updates: 318,318
Cumulative Timesteps: 2,654,786,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.93382
Policy Entropy: 4.02490
Value Function Loss: 0.00226

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01431
Policy Update Magnitude: 0.15500
Value Function Update Magnitude: 0.18828

Collected Steps per Second: 22,246.64723
Overall Steps per Second: 10,519.45961

Timestep Collection Time: 2.24879
Timestep Consumption Time: 2.50697
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.75576

Cumulative Model Updates: 318,324
Cumulative Timesteps: 2,654,836,998

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2654836998...
Checkpoint 2654836998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.64669
Policy Entropy: 3.98836
Value Function Loss: 0.00278

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01293
Policy Update Magnitude: 0.15105
Value Function Update Magnitude: 0.19543

Collected Steps per Second: 23,117.94888
Overall Steps per Second: 10,660.80741

Timestep Collection Time: 2.16325
Timestep Consumption Time: 2.52776
PPO Batch Consumption Time: 0.29495
Total Iteration Time: 4.69101

Cumulative Model Updates: 318,330
Cumulative Timesteps: 2,654,887,008

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.74727
Policy Entropy: 3.97798
Value Function Loss: 0.00328

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.01585
Policy Update Magnitude: 0.16557
Value Function Update Magnitude: 0.21334

Collected Steps per Second: 22,615.70200
Overall Steps per Second: 10,577.46518

Timestep Collection Time: 2.21156
Timestep Consumption Time: 2.51698
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.72854

Cumulative Model Updates: 318,336
Cumulative Timesteps: 2,654,937,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2654937024...
Checkpoint 2654937024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.56700
Policy Entropy: 3.91162
Value Function Loss: 0.00400

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02063
Policy Update Magnitude: 0.17616
Value Function Update Magnitude: 0.21930

Collected Steps per Second: 22,208.20014
Overall Steps per Second: 10,684.16049

Timestep Collection Time: 2.25232
Timestep Consumption Time: 2.42938
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.68170

Cumulative Model Updates: 318,342
Cumulative Timesteps: 2,654,987,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.29124
Policy Entropy: 3.94028
Value Function Loss: 0.00427

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02016
Policy Update Magnitude: 0.19021
Value Function Update Magnitude: 0.23575

Collected Steps per Second: 22,772.34367
Overall Steps per Second: 10,725.05860

Timestep Collection Time: 2.19644
Timestep Consumption Time: 2.46722
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.66366

Cumulative Model Updates: 318,348
Cumulative Timesteps: 2,655,037,062

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2655037062...
Checkpoint 2655037062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.67141
Policy Entropy: 3.93993
Value Function Loss: 0.00406

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02532
Policy Update Magnitude: 0.18800
Value Function Update Magnitude: 0.23902

Collected Steps per Second: 22,441.16317
Overall Steps per Second: 10,657.93224

Timestep Collection Time: 2.22885
Timestep Consumption Time: 2.46418
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.69303

Cumulative Model Updates: 318,354
Cumulative Timesteps: 2,655,087,080

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.49853
Policy Entropy: 3.95717
Value Function Loss: 0.00401

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.01979
Policy Update Magnitude: 0.18458
Value Function Update Magnitude: 0.23143

Collected Steps per Second: 22,454.89227
Overall Steps per Second: 10,855.75664

Timestep Collection Time: 2.22793
Timestep Consumption Time: 2.38050
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.60843

Cumulative Model Updates: 318,360
Cumulative Timesteps: 2,655,137,108

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2655137108...
Checkpoint 2655137108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.88889
Policy Entropy: 3.95587
Value Function Loss: 0.00411

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.01857
Policy Update Magnitude: 0.18139
Value Function Update Magnitude: 0.22217

Collected Steps per Second: 22,454.55653
Overall Steps per Second: 10,677.62575

Timestep Collection Time: 2.22743
Timestep Consumption Time: 2.45676
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.68419

Cumulative Model Updates: 318,366
Cumulative Timesteps: 2,655,187,124

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.72371
Policy Entropy: 3.93309
Value Function Loss: 0.00408

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02018
Policy Update Magnitude: 0.18617
Value Function Update Magnitude: 0.22098

Collected Steps per Second: 22,302.40692
Overall Steps per Second: 10,513.07974

Timestep Collection Time: 2.24263
Timestep Consumption Time: 2.51487
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.75750

Cumulative Model Updates: 318,372
Cumulative Timesteps: 2,655,237,140

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2655237140...
Checkpoint 2655237140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.31664
Policy Entropy: 3.94788
Value Function Loss: 0.00391

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.01789
Policy Update Magnitude: 0.18639
Value Function Update Magnitude: 0.22552

Collected Steps per Second: 22,990.38477
Overall Steps per Second: 10,642.08592

Timestep Collection Time: 2.17526
Timestep Consumption Time: 2.52401
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.69927

Cumulative Model Updates: 318,378
Cumulative Timesteps: 2,655,287,150

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.00381
Policy Entropy: 3.94809
Value Function Loss: 0.00396

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02027
Policy Update Magnitude: 0.18502
Value Function Update Magnitude: 0.22855

Collected Steps per Second: 22,345.15543
Overall Steps per Second: 10,521.73245

Timestep Collection Time: 2.23780
Timestep Consumption Time: 2.51465
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.75245

Cumulative Model Updates: 318,384
Cumulative Timesteps: 2,655,337,154

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2655337154...
Checkpoint 2655337154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.44531
Policy Entropy: 4.01175
Value Function Loss: 0.00308

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01766
Policy Update Magnitude: 0.17263
Value Function Update Magnitude: 0.21695

Collected Steps per Second: 22,473.08292
Overall Steps per Second: 10,563.33709

Timestep Collection Time: 2.22649
Timestep Consumption Time: 2.51027
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.73676

Cumulative Model Updates: 318,390
Cumulative Timesteps: 2,655,387,190

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.66761
Policy Entropy: 4.03884
Value Function Loss: 0.00259

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.01680
Policy Update Magnitude: 0.15273
Value Function Update Magnitude: 0.19143

Collected Steps per Second: 23,390.41980
Overall Steps per Second: 10,902.74502

Timestep Collection Time: 2.13925
Timestep Consumption Time: 2.45023
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.58949

Cumulative Model Updates: 318,396
Cumulative Timesteps: 2,655,437,228

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2655437228...
Checkpoint 2655437228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.93952
Policy Entropy: 4.05350
Value Function Loss: 0.00188

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01482
Policy Update Magnitude: 0.13996
Value Function Update Magnitude: 0.16439

Collected Steps per Second: 22,222.78695
Overall Steps per Second: 10,666.86752

Timestep Collection Time: 2.25084
Timestep Consumption Time: 2.43844
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.68929

Cumulative Model Updates: 318,402
Cumulative Timesteps: 2,655,487,248

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.06168
Policy Entropy: 4.04258
Value Function Loss: 0.00246

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.01606
Policy Update Magnitude: 0.14262
Value Function Update Magnitude: 0.15932

Collected Steps per Second: 22,129.83812
Overall Steps per Second: 10,782.87189

Timestep Collection Time: 2.26066
Timestep Consumption Time: 2.37892
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.63958

Cumulative Model Updates: 318,408
Cumulative Timesteps: 2,655,537,276

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2655537276...
Checkpoint 2655537276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.39605
Policy Entropy: 4.03201
Value Function Loss: 0.00257

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01421
Policy Update Magnitude: 0.14887
Value Function Update Magnitude: 0.16906

Collected Steps per Second: 22,209.07063
Overall Steps per Second: 10,557.81349

Timestep Collection Time: 2.25169
Timestep Consumption Time: 2.48489
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.73659

Cumulative Model Updates: 318,414
Cumulative Timesteps: 2,655,587,284

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.86755
Policy Entropy: 3.99457
Value Function Loss: 0.00348

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.01489
Policy Update Magnitude: 0.17196
Value Function Update Magnitude: 0.18633

Collected Steps per Second: 22,444.20084
Overall Steps per Second: 10,637.64167

Timestep Collection Time: 2.22908
Timestep Consumption Time: 2.47403
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.70311

Cumulative Model Updates: 318,420
Cumulative Timesteps: 2,655,637,314

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2655637314...
Checkpoint 2655637314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.96332
Policy Entropy: 3.98840
Value Function Loss: 0.00323

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.01687
Policy Update Magnitude: 0.18079
Value Function Update Magnitude: 0.20441

Collected Steps per Second: 23,387.12069
Overall Steps per Second: 10,889.52996

Timestep Collection Time: 2.13819
Timestep Consumption Time: 2.45393
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.59212

Cumulative Model Updates: 318,426
Cumulative Timesteps: 2,655,687,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.15923
Policy Entropy: 3.97407
Value Function Loss: 0.00343

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02019
Policy Update Magnitude: 0.17330
Value Function Update Magnitude: 0.21871

Collected Steps per Second: 22,383.18493
Overall Steps per Second: 10,479.68913

Timestep Collection Time: 2.23462
Timestep Consumption Time: 2.53823
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.77285

Cumulative Model Updates: 318,432
Cumulative Timesteps: 2,655,737,338

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2655737338...
Checkpoint 2655737338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.11865
Policy Entropy: 4.01817
Value Function Loss: 0.00276

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.01895
Policy Update Magnitude: 0.17094
Value Function Update Magnitude: 0.21528

Collected Steps per Second: 22,186.17830
Overall Steps per Second: 10,700.64812

Timestep Collection Time: 2.25429
Timestep Consumption Time: 2.41964
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.67392

Cumulative Model Updates: 318,438
Cumulative Timesteps: 2,655,787,352

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.02249
Policy Entropy: 3.97999
Value Function Loss: 0.00337

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.01727
Policy Update Magnitude: 0.17614
Value Function Update Magnitude: 0.21340

Collected Steps per Second: 23,281.75859
Overall Steps per Second: 10,834.04041

Timestep Collection Time: 2.14778
Timestep Consumption Time: 2.46768
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.61545

Cumulative Model Updates: 318,444
Cumulative Timesteps: 2,655,837,356

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2655837356...
Checkpoint 2655837356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.48170
Policy Entropy: 3.97015
Value Function Loss: 0.00395

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.01727
Policy Update Magnitude: 0.18542
Value Function Update Magnitude: 0.22400

Collected Steps per Second: 22,696.30672
Overall Steps per Second: 10,659.58903

Timestep Collection Time: 2.20388
Timestep Consumption Time: 2.48861
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.69249

Cumulative Model Updates: 318,450
Cumulative Timesteps: 2,655,887,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.10271
Policy Entropy: 3.97933
Value Function Loss: 0.00399

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.01856
Policy Update Magnitude: 0.18521
Value Function Update Magnitude: 0.22294

Collected Steps per Second: 22,439.63617
Overall Steps per Second: 10,865.40142

Timestep Collection Time: 2.22909
Timestep Consumption Time: 2.37451
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.60360

Cumulative Model Updates: 318,456
Cumulative Timesteps: 2,655,937,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2655937396...
Checkpoint 2655937396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.81190
Policy Entropy: 4.03798
Value Function Loss: 0.00303

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.01548
Policy Update Magnitude: 0.16775
Value Function Update Magnitude: 0.20557

Collected Steps per Second: 22,526.34149
Overall Steps per Second: 10,752.35485

Timestep Collection Time: 2.22042
Timestep Consumption Time: 2.43140
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.65182

Cumulative Model Updates: 318,462
Cumulative Timesteps: 2,655,987,414

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.06764
Policy Entropy: 4.06156
Value Function Loss: 0.00249

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01317
Policy Update Magnitude: 0.15258
Value Function Update Magnitude: 0.18989

Collected Steps per Second: 22,627.50587
Overall Steps per Second: 10,770.87749

Timestep Collection Time: 2.20979
Timestep Consumption Time: 2.43254
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.64233

Cumulative Model Updates: 318,468
Cumulative Timesteps: 2,656,037,416

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2656037416...
Checkpoint 2656037416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.08186
Policy Entropy: 4.03800
Value Function Loss: 0.00312

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01347
Policy Update Magnitude: 0.16149
Value Function Update Magnitude: 0.20947

Collected Steps per Second: 23,172.77360
Overall Steps per Second: 10,722.44402

Timestep Collection Time: 2.15779
Timestep Consumption Time: 2.50551
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.66330

Cumulative Model Updates: 318,474
Cumulative Timesteps: 2,656,087,418

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.72840
Policy Entropy: 4.01756
Value Function Loss: 0.00293

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.01526
Policy Update Magnitude: 0.17108
Value Function Update Magnitude: 0.24126

Collected Steps per Second: 22,313.85974
Overall Steps per Second: 10,443.82062

Timestep Collection Time: 2.24193
Timestep Consumption Time: 2.54808
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.79001

Cumulative Model Updates: 318,480
Cumulative Timesteps: 2,656,137,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2656137444...
Checkpoint 2656137444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.40700
Policy Entropy: 4.01510
Value Function Loss: 0.00274

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01631
Policy Update Magnitude: 0.16872
Value Function Update Magnitude: 0.24140

Collected Steps per Second: 22,243.16342
Overall Steps per Second: 10,653.75352

Timestep Collection Time: 2.24788
Timestep Consumption Time: 2.44530
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.69318

Cumulative Model Updates: 318,486
Cumulative Timesteps: 2,656,187,444

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.32376
Policy Entropy: 4.02365
Value Function Loss: 0.00271

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.01505
Policy Update Magnitude: 0.16004
Value Function Update Magnitude: 0.22123

Collected Steps per Second: 22,774.28385
Overall Steps per Second: 10,691.08000

Timestep Collection Time: 2.19634
Timestep Consumption Time: 2.48233
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.67867

Cumulative Model Updates: 318,492
Cumulative Timesteps: 2,656,237,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2656237464...
Checkpoint 2656237464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.59331
Policy Entropy: 4.01383
Value Function Loss: 0.00277

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01591
Policy Update Magnitude: 0.15787
Value Function Update Magnitude: 0.21604

Collected Steps per Second: 22,352.76907
Overall Steps per Second: 10,554.97092

Timestep Collection Time: 2.23731
Timestep Consumption Time: 2.50075
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.73805

Cumulative Model Updates: 318,498
Cumulative Timesteps: 2,656,287,474

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.39048
Policy Entropy: 3.99145
Value Function Loss: 0.00359

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.01725
Policy Update Magnitude: 0.16153
Value Function Update Magnitude: 0.22832

Collected Steps per Second: 21,988.66569
Overall Steps per Second: 10,748.06840

Timestep Collection Time: 2.27426
Timestep Consumption Time: 2.37848
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.65274

Cumulative Model Updates: 318,504
Cumulative Timesteps: 2,656,337,482

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2656337482...
Checkpoint 2656337482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.21288
Policy Entropy: 4.02468
Value Function Loss: 0.00305

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.01808
Policy Update Magnitude: 0.16561
Value Function Update Magnitude: 0.24888

Collected Steps per Second: 22,282.25247
Overall Steps per Second: 10,661.01331

Timestep Collection Time: 2.24439
Timestep Consumption Time: 2.44654
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.69092

Cumulative Model Updates: 318,510
Cumulative Timesteps: 2,656,387,492

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.20198
Policy Entropy: 4.03450
Value Function Loss: 0.00284

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.01613
Policy Update Magnitude: 0.16446
Value Function Update Magnitude: 0.22600

Collected Steps per Second: 22,422.58512
Overall Steps per Second: 10,591.49304

Timestep Collection Time: 2.23061
Timestep Consumption Time: 2.49167
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.72228

Cumulative Model Updates: 318,516
Cumulative Timesteps: 2,656,437,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2656437508...
Checkpoint 2656437508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.52762
Policy Entropy: 4.06582
Value Function Loss: 0.00226

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01440
Policy Update Magnitude: 0.15301
Value Function Update Magnitude: 0.20463

Collected Steps per Second: 22,613.66896
Overall Steps per Second: 10,877.69561

Timestep Collection Time: 2.21149
Timestep Consumption Time: 2.38599
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.59748

Cumulative Model Updates: 318,522
Cumulative Timesteps: 2,656,487,518

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.36309
Policy Entropy: 4.04121
Value Function Loss: 0.00211

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01488
Policy Update Magnitude: 0.14305
Value Function Update Magnitude: 0.18064

Collected Steps per Second: 22,617.01497
Overall Steps per Second: 10,535.22068

Timestep Collection Time: 2.21170
Timestep Consumption Time: 2.53638
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.74807

Cumulative Model Updates: 318,528
Cumulative Timesteps: 2,656,537,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2656537540...
Checkpoint 2656537540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.10219
Policy Entropy: 4.03428
Value Function Loss: 0.00239

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01405
Policy Update Magnitude: 0.14779
Value Function Update Magnitude: 0.18005

Collected Steps per Second: 22,147.24794
Overall Steps per Second: 10,693.63590

Timestep Collection Time: 2.25870
Timestep Consumption Time: 2.41922
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.67792

Cumulative Model Updates: 318,534
Cumulative Timesteps: 2,656,587,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.53998
Policy Entropy: 3.99243
Value Function Loss: 0.00273

Mean KL Divergence: 0.00153
SB3 Clip Fraction: 0.01333
Policy Update Magnitude: 0.15746
Value Function Update Magnitude: 0.19339

Collected Steps per Second: 23,311.25630
Overall Steps per Second: 10,898.85792

Timestep Collection Time: 2.14574
Timestep Consumption Time: 2.44373
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.58947

Cumulative Model Updates: 318,540
Cumulative Timesteps: 2,656,637,584

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2656637584...
Checkpoint 2656637584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.72520
Policy Entropy: 3.98086
Value Function Loss: 0.00279

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01546
Policy Update Magnitude: 0.16839
Value Function Update Magnitude: 0.19747

Collected Steps per Second: 22,496.72236
Overall Steps per Second: 10,598.97900

Timestep Collection Time: 2.22317
Timestep Consumption Time: 2.49559
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.71876

Cumulative Model Updates: 318,546
Cumulative Timesteps: 2,656,687,598

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.89650
Policy Entropy: 4.02298
Value Function Loss: 0.00206

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01496
Policy Update Magnitude: 0.15685
Value Function Update Magnitude: 0.19157

Collected Steps per Second: 22,311.41395
Overall Steps per Second: 10,537.64156

Timestep Collection Time: 2.24181
Timestep Consumption Time: 2.50479
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.74660

Cumulative Model Updates: 318,552
Cumulative Timesteps: 2,656,737,616

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2656737616...
Checkpoint 2656737616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.07216
Policy Entropy: 4.04256
Value Function Loss: 0.00222

Mean KL Divergence: 0.00151
SB3 Clip Fraction: 0.01213
Policy Update Magnitude: 0.14732
Value Function Update Magnitude: 0.17586

Collected Steps per Second: 23,103.74217
Overall Steps per Second: 10,688.15544

Timestep Collection Time: 2.16536
Timestep Consumption Time: 2.51533
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.68070

Cumulative Model Updates: 318,558
Cumulative Timesteps: 2,656,787,644

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.18424
Policy Entropy: 4.06955
Value Function Loss: 0.00221

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.01191
Policy Update Magnitude: 0.14366
Value Function Update Magnitude: 0.18231

Collected Steps per Second: 22,582.54526
Overall Steps per Second: 10,700.64522

Timestep Collection Time: 2.21534
Timestep Consumption Time: 2.45989
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.67523

Cumulative Model Updates: 318,564
Cumulative Timesteps: 2,656,837,672

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2656837672...
Checkpoint 2656837672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.75666
Policy Entropy: 4.06285
Value Function Loss: 0.00262

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01363
Policy Update Magnitude: 0.14907
Value Function Update Magnitude: 0.18648

Collected Steps per Second: 22,279.61785
Overall Steps per Second: 10,728.33426

Timestep Collection Time: 2.24438
Timestep Consumption Time: 2.41655
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.66093

Cumulative Model Updates: 318,570
Cumulative Timesteps: 2,656,887,676

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.30602
Policy Entropy: 4.02905
Value Function Loss: 0.00387

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01310
Policy Update Magnitude: 0.16344
Value Function Update Magnitude: 0.18507

Collected Steps per Second: 22,457.24334
Overall Steps per Second: 10,524.80958

Timestep Collection Time: 2.22654
Timestep Consumption Time: 2.52433
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.75087

Cumulative Model Updates: 318,576
Cumulative Timesteps: 2,656,937,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2656937678...
Checkpoint 2656937678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.10513
Policy Entropy: 3.98232
Value Function Loss: 0.00466

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.01503
Policy Update Magnitude: 0.19705
Value Function Update Magnitude: 0.21526

Collected Steps per Second: 22,512.58265
Overall Steps per Second: 10,606.47419

Timestep Collection Time: 2.22169
Timestep Consumption Time: 2.49392
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.71561

Cumulative Model Updates: 318,582
Cumulative Timesteps: 2,656,987,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.93228
Policy Entropy: 3.93687
Value Function Loss: 0.00497

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02018
Policy Update Magnitude: 0.20477
Value Function Update Magnitude: 0.24584

Collected Steps per Second: 22,419.90296
Overall Steps per Second: 10,863.30840

Timestep Collection Time: 2.23150
Timestep Consumption Time: 2.37391
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.60541

Cumulative Model Updates: 318,588
Cumulative Timesteps: 2,657,037,724

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2657037724...
Checkpoint 2657037724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.40838
Policy Entropy: 3.95555
Value Function Loss: 0.00379

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.01910
Policy Update Magnitude: 0.19818
Value Function Update Magnitude: 0.23962

Collected Steps per Second: 22,301.73484
Overall Steps per Second: 10,708.82148

Timestep Collection Time: 2.24305
Timestep Consumption Time: 2.42823
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.67129

Cumulative Model Updates: 318,594
Cumulative Timesteps: 2,657,087,748

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.96685
Policy Entropy: 3.98349
Value Function Loss: 0.00354

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.01929
Policy Update Magnitude: 0.18456
Value Function Update Magnitude: 0.22341

Collected Steps per Second: 22,480.22060
Overall Steps per Second: 10,778.69720

Timestep Collection Time: 2.22516
Timestep Consumption Time: 2.41566
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.64082

Cumulative Model Updates: 318,600
Cumulative Timesteps: 2,657,137,770

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2657137770...
Checkpoint 2657137770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.11036
Policy Entropy: 3.96494
Value Function Loss: 0.00313

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.01810
Policy Update Magnitude: 0.17844
Value Function Update Magnitude: 0.20670

Collected Steps per Second: 22,873.03945
Overall Steps per Second: 10,746.64953

Timestep Collection Time: 2.18642
Timestep Consumption Time: 2.46713
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.65354

Cumulative Model Updates: 318,606
Cumulative Timesteps: 2,657,187,780

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.24483
Policy Entropy: 4.01129
Value Function Loss: 0.00243

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.01764
Policy Update Magnitude: 0.16718
Value Function Update Magnitude: 0.20189

Collected Steps per Second: 22,837.51695
Overall Steps per Second: 10,649.11426

Timestep Collection Time: 2.18964
Timestep Consumption Time: 2.50615
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.69579

Cumulative Model Updates: 318,612
Cumulative Timesteps: 2,657,237,786

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2657237786...
Checkpoint 2657237786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.71217
Policy Entropy: 3.99380
Value Function Loss: 0.00303

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01753
Policy Update Magnitude: 0.16436
Value Function Update Magnitude: 0.20429

Collected Steps per Second: 22,199.55896
Overall Steps per Second: 10,502.02620

Timestep Collection Time: 2.25338
Timestep Consumption Time: 2.50989
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.76327

Cumulative Model Updates: 318,618
Cumulative Timesteps: 2,657,287,810

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.41644
Policy Entropy: 4.05334
Value Function Loss: 0.00291

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01550
Policy Update Magnitude: 0.17285
Value Function Update Magnitude: 0.22509

Collected Steps per Second: 23,252.06595
Overall Steps per Second: 10,871.76649

Timestep Collection Time: 2.15060
Timestep Consumption Time: 2.44902
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.59962

Cumulative Model Updates: 318,624
Cumulative Timesteps: 2,657,337,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2657337816...
Checkpoint 2657337816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.12225
Policy Entropy: 4.02237
Value Function Loss: 0.00372

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.01667
Policy Update Magnitude: 0.18076
Value Function Update Magnitude: 0.23375

Collected Steps per Second: 22,348.05340
Overall Steps per Second: 10,662.50446

Timestep Collection Time: 2.23903
Timestep Consumption Time: 2.45386
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.69289

Cumulative Model Updates: 318,630
Cumulative Timesteps: 2,657,387,854

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.51679
Policy Entropy: 4.04369
Value Function Loss: 0.00303

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.01671
Policy Update Magnitude: 0.17991
Value Function Update Magnitude: 0.23390

Collected Steps per Second: 22,108.13054
Overall Steps per Second: 10,794.34541

Timestep Collection Time: 2.26288
Timestep Consumption Time: 2.37177
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.63465

Cumulative Model Updates: 318,636
Cumulative Timesteps: 2,657,437,882

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2657437882...
Checkpoint 2657437882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.50467
Policy Entropy: 4.01388
Value Function Loss: 0.00294

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.01652
Policy Update Magnitude: 0.17436
Value Function Update Magnitude: 0.24140

Collected Steps per Second: 22,337.32397
Overall Steps per Second: 10,633.53450

Timestep Collection Time: 2.23841
Timestep Consumption Time: 2.46370
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.70211

Cumulative Model Updates: 318,642
Cumulative Timesteps: 2,657,487,882

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.82776
Policy Entropy: 4.00327
Value Function Loss: 0.00254

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01746
Policy Update Magnitude: 0.17653
Value Function Update Magnitude: 0.23260

Collected Steps per Second: 22,309.49689
Overall Steps per Second: 10,524.30697

Timestep Collection Time: 2.24156
Timestep Consumption Time: 2.51011
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.75167

Cumulative Model Updates: 318,648
Cumulative Timesteps: 2,657,537,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2657537890...
Checkpoint 2657537890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.11911
Policy Entropy: 4.01932
Value Function Loss: 0.00278

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01704
Policy Update Magnitude: 0.17497
Value Function Update Magnitude: 0.22389

Collected Steps per Second: 22,004.16292
Overall Steps per Second: 10,660.48825

Timestep Collection Time: 2.27230
Timestep Consumption Time: 2.41792
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.69022

Cumulative Model Updates: 318,654
Cumulative Timesteps: 2,657,587,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.75596
Policy Entropy: 4.02403
Value Function Loss: 0.00355

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.01805
Policy Update Magnitude: 0.17671
Value Function Update Magnitude: 0.22226

Collected Steps per Second: 22,419.12267
Overall Steps per Second: 10,514.34389

Timestep Collection Time: 2.23095
Timestep Consumption Time: 2.52598
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.75693

Cumulative Model Updates: 318,660
Cumulative Timesteps: 2,657,637,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2657637906...
Checkpoint 2657637906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.71873
Policy Entropy: 4.03802
Value Function Loss: 0.00348

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01619
Policy Update Magnitude: 0.17718
Value Function Update Magnitude: 0.24475

Collected Steps per Second: 22,433.80900
Overall Steps per Second: 10,565.86512

Timestep Collection Time: 2.22931
Timestep Consumption Time: 2.50404
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.73336

Cumulative Model Updates: 318,666
Cumulative Timesteps: 2,657,687,918

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33941
Policy Entropy: 4.02847
Value Function Loss: 0.00365

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.01556
Policy Update Magnitude: 0.18529
Value Function Update Magnitude: 0.25896

Collected Steps per Second: 23,096.95434
Overall Steps per Second: 10,861.82879

Timestep Collection Time: 2.16565
Timestep Consumption Time: 2.43946
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.60512

Cumulative Model Updates: 318,672
Cumulative Timesteps: 2,657,737,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2657737938...
Checkpoint 2657737938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.20314
Policy Entropy: 4.02419
Value Function Loss: 0.00318

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01541
Policy Update Magnitude: 0.18232
Value Function Update Magnitude: 0.26071

Collected Steps per Second: 22,465.68858
Overall Steps per Second: 10,664.57988

Timestep Collection Time: 2.22677
Timestep Consumption Time: 2.46408
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.69086

Cumulative Model Updates: 318,678
Cumulative Timesteps: 2,657,787,964

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.99844
Policy Entropy: 4.03203
Value Function Loss: 0.00346

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.01662
Policy Update Magnitude: 0.18842
Value Function Update Magnitude: 0.25191

Collected Steps per Second: 22,363.84681
Overall Steps per Second: 10,850.32010

Timestep Collection Time: 2.23718
Timestep Consumption Time: 2.37393
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.61111

Cumulative Model Updates: 318,684
Cumulative Timesteps: 2,657,837,996

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2657837996...
Checkpoint 2657837996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.48325
Policy Entropy: 4.01182
Value Function Loss: 0.00390

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.01591
Policy Update Magnitude: 0.19098
Value Function Update Magnitude: 0.23103

Collected Steps per Second: 22,348.76961
Overall Steps per Second: 10,659.44708

Timestep Collection Time: 2.23753
Timestep Consumption Time: 2.45371
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.69124

Cumulative Model Updates: 318,690
Cumulative Timesteps: 2,657,888,002

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.75558
Policy Entropy: 4.02164
Value Function Loss: 0.00433

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01741
Policy Update Magnitude: 0.19661
Value Function Update Magnitude: 0.22283

Collected Steps per Second: 22,187.30532
Overall Steps per Second: 10,565.90804

Timestep Collection Time: 2.25462
Timestep Consumption Time: 2.47985
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.73447

Cumulative Model Updates: 318,696
Cumulative Timesteps: 2,657,938,026

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2657938026...
Checkpoint 2657938026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.19494
Policy Entropy: 4.03889
Value Function Loss: 0.00365

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01714
Policy Update Magnitude: 0.18490
Value Function Update Magnitude: 0.22198

Collected Steps per Second: 22,295.06513
Overall Steps per Second: 10,689.51656

Timestep Collection Time: 2.24337
Timestep Consumption Time: 2.43561
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.67898

Cumulative Model Updates: 318,702
Cumulative Timesteps: 2,657,988,042

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.70778
Policy Entropy: 4.04909
Value Function Loss: 0.00343

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01517
Policy Update Magnitude: 0.18115
Value Function Update Magnitude: 0.22443

Collected Steps per Second: 22,493.75984
Overall Steps per Second: 10,590.25343

Timestep Collection Time: 2.22346
Timestep Consumption Time: 2.49918
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.72264

Cumulative Model Updates: 318,708
Cumulative Timesteps: 2,658,038,056

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2658038056...
Checkpoint 2658038056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.88293
Policy Entropy: 4.05295
Value Function Loss: 0.00297

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.01413
Policy Update Magnitude: 0.17536
Value Function Update Magnitude: 0.21213

Collected Steps per Second: 22,485.21136
Overall Steps per Second: 10,653.94820

Timestep Collection Time: 2.22502
Timestep Consumption Time: 2.47089
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.69591

Cumulative Model Updates: 318,714
Cumulative Timesteps: 2,658,088,086

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.00654
Policy Entropy: 4.06120
Value Function Loss: 0.00242

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01457
Policy Update Magnitude: 0.16430
Value Function Update Magnitude: 0.19572

Collected Steps per Second: 23,087.30324
Overall Steps per Second: 10,700.60832

Timestep Collection Time: 2.16656
Timestep Consumption Time: 2.50794
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.67450

Cumulative Model Updates: 318,720
Cumulative Timesteps: 2,658,138,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2658138106...
Checkpoint 2658138106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.10733
Policy Entropy: 4.05450
Value Function Loss: 0.00249

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.01296
Policy Update Magnitude: 0.16028
Value Function Update Magnitude: 0.18187

Collected Steps per Second: 22,291.06659
Overall Steps per Second: 10,667.54309

Timestep Collection Time: 2.24413
Timestep Consumption Time: 2.44524
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.68936

Cumulative Model Updates: 318,726
Cumulative Timesteps: 2,658,188,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.56855
Policy Entropy: 4.03860
Value Function Loss: 0.00305

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.01572
Policy Update Magnitude: 0.18020
Value Function Update Magnitude: 0.19204

Collected Steps per Second: 22,611.73087
Overall Steps per Second: 10,850.81911

Timestep Collection Time: 2.21195
Timestep Consumption Time: 2.39747
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.60942

Cumulative Model Updates: 318,732
Cumulative Timesteps: 2,658,238,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2658238146...
Checkpoint 2658238146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.52889
Policy Entropy: 4.03969
Value Function Loss: 0.00281

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01855
Policy Update Magnitude: 0.17910
Value Function Update Magnitude: 0.21620

Collected Steps per Second: 22,431.02149
Overall Steps per Second: 10,612.08636

Timestep Collection Time: 2.22968
Timestep Consumption Time: 2.48325
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.71293

Cumulative Model Updates: 318,738
Cumulative Timesteps: 2,658,288,160

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.49304
Policy Entropy: 4.07031
Value Function Loss: 0.00276

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01613
Policy Update Magnitude: 0.16977
Value Function Update Magnitude: 0.21199

Collected Steps per Second: 22,403.12898
Overall Steps per Second: 10,503.75726

Timestep Collection Time: 2.23183
Timestep Consumption Time: 2.52837
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.76020

Cumulative Model Updates: 318,744
Cumulative Timesteps: 2,658,338,160

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2658338160...
Checkpoint 2658338160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.52000
Policy Entropy: 4.08394
Value Function Loss: 0.00230

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.01518
Policy Update Magnitude: 0.16359
Value Function Update Magnitude: 0.20724

Collected Steps per Second: 22,450.39029
Overall Steps per Second: 10,721.64703

Timestep Collection Time: 2.22758
Timestep Consumption Time: 2.43682
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.66440

Cumulative Model Updates: 318,750
Cumulative Timesteps: 2,658,388,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.53988
Policy Entropy: 4.05689
Value Function Loss: 0.00282

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.01641
Policy Update Magnitude: 0.17635
Value Function Update Magnitude: 0.20314

Collected Steps per Second: 22,433.71142
Overall Steps per Second: 10,571.60608

Timestep Collection Time: 2.22950
Timestep Consumption Time: 2.50166
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.73116

Cumulative Model Updates: 318,756
Cumulative Timesteps: 2,658,438,186

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2658438186...
Checkpoint 2658438186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.58624
Policy Entropy: 4.05280
Value Function Loss: 0.00329

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01518
Policy Update Magnitude: 0.19083
Value Function Update Magnitude: 0.21211

Collected Steps per Second: 22,403.09245
Overall Steps per Second: 10,600.83470

Timestep Collection Time: 2.23264
Timestep Consumption Time: 2.48567
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.71831

Cumulative Model Updates: 318,762
Cumulative Timesteps: 2,658,488,204

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.26086
Policy Entropy: 4.02767
Value Function Loss: 0.00412

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.01860
Policy Update Magnitude: 0.19633
Value Function Update Magnitude: 0.23860

Collected Steps per Second: 23,410.07144
Overall Steps per Second: 10,775.68188

Timestep Collection Time: 2.13617
Timestep Consumption Time: 2.50465
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.64082

Cumulative Model Updates: 318,768
Cumulative Timesteps: 2,658,538,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2658538212...
Checkpoint 2658538212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.64645
Policy Entropy: 4.03834
Value Function Loss: 0.00358

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.01927
Policy Update Magnitude: 0.19840
Value Function Update Magnitude: 0.24195

Collected Steps per Second: 22,378.62074
Overall Steps per Second: 10,696.12481

Timestep Collection Time: 2.23526
Timestep Consumption Time: 2.44139
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.67665

Cumulative Model Updates: 318,774
Cumulative Timesteps: 2,658,588,234

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.05653
Policy Entropy: 4.00585
Value Function Loss: 0.00393

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.01978
Policy Update Magnitude: 0.20389
Value Function Update Magnitude: 0.23490

Collected Steps per Second: 22,568.99810
Overall Steps per Second: 10,745.87709

Timestep Collection Time: 2.21631
Timestep Consumption Time: 2.43849
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.65481

Cumulative Model Updates: 318,780
Cumulative Timesteps: 2,658,638,254

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2658638254...
Checkpoint 2658638254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.48189
Policy Entropy: 4.02712
Value Function Loss: 0.00344

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.01882
Policy Update Magnitude: 0.19994
Value Function Update Magnitude: 0.22945

Collected Steps per Second: 23,053.96561
Overall Steps per Second: 10,756.05655

Timestep Collection Time: 2.16987
Timestep Consumption Time: 2.48091
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.65078

Cumulative Model Updates: 318,786
Cumulative Timesteps: 2,658,688,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.65265
Policy Entropy: 4.02319
Value Function Loss: 0.00352

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.01701
Policy Update Magnitude: 0.19268
Value Function Update Magnitude: 0.22879

Collected Steps per Second: 22,170.65740
Overall Steps per Second: 10,449.08563

Timestep Collection Time: 2.25541
Timestep Consumption Time: 2.53008
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.78549

Cumulative Model Updates: 318,792
Cumulative Timesteps: 2,658,738,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2658738282...
Checkpoint 2658738282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.23320
Policy Entropy: 4.04356
Value Function Loss: 0.00339

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.01448
Policy Update Magnitude: 0.19764
Value Function Update Magnitude: 0.22396

Collected Steps per Second: 22,115.63671
Overall Steps per Second: 10,627.23274

Timestep Collection Time: 2.26220
Timestep Consumption Time: 2.44552
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.70772

Cumulative Model Updates: 318,798
Cumulative Timesteps: 2,658,788,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.13656
Policy Entropy: 4.03496
Value Function Loss: 0.00344

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.01760
Policy Update Magnitude: 0.19581
Value Function Update Magnitude: 0.23220

Collected Steps per Second: 22,729.95005
Overall Steps per Second: 10,663.99822

Timestep Collection Time: 2.20115
Timestep Consumption Time: 2.49052
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.69167

Cumulative Model Updates: 318,804
Cumulative Timesteps: 2,658,838,344

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2658838344...
Checkpoint 2658838344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.83327
Policy Entropy: 4.01271
Value Function Loss: 0.00396

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.01904
Policy Update Magnitude: 0.20047
Value Function Update Magnitude: 0.24892

Collected Steps per Second: 22,464.95588
Overall Steps per Second: 10,643.15063

Timestep Collection Time: 2.22676
Timestep Consumption Time: 2.47335
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.70011

Cumulative Model Updates: 318,810
Cumulative Timesteps: 2,658,888,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.38579
Policy Entropy: 4.01942
Value Function Loss: 0.00377

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02093
Policy Update Magnitude: 0.19529
Value Function Update Magnitude: 0.26481

Collected Steps per Second: 23,407.36698
Overall Steps per Second: 10,748.97558

Timestep Collection Time: 2.13719
Timestep Consumption Time: 2.51683
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.65402

Cumulative Model Updates: 318,816
Cumulative Timesteps: 2,658,938,394

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2658938394...
Checkpoint 2658938394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.19761
Policy Entropy: 3.99755
Value Function Loss: 0.00396

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02113
Policy Update Magnitude: 0.20274
Value Function Update Magnitude: 0.26630

Collected Steps per Second: 22,466.43558
Overall Steps per Second: 10,622.02203

Timestep Collection Time: 2.22768
Timestep Consumption Time: 2.48404
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.71172

Cumulative Model Updates: 318,822
Cumulative Timesteps: 2,658,988,442

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.26088
Policy Entropy: 4.06671
Value Function Loss: 0.00281

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.01715
Policy Update Magnitude: 0.19015
Value Function Update Magnitude: 0.24451

Collected Steps per Second: 22,554.17463
Overall Steps per Second: 10,884.23488

Timestep Collection Time: 2.21830
Timestep Consumption Time: 2.37844
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.59674

Cumulative Model Updates: 318,828
Cumulative Timesteps: 2,659,038,474

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2659038474...
Checkpoint 2659038474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.13278
Policy Entropy: 4.07587
Value Function Loss: 0.00277

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01726
Policy Update Magnitude: 0.17377
Value Function Update Magnitude: 0.22317

Collected Steps per Second: 22,446.18831
Overall Steps per Second: 10,662.36868

Timestep Collection Time: 2.22764
Timestep Consumption Time: 2.46194
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.68958

Cumulative Model Updates: 318,834
Cumulative Timesteps: 2,659,088,476

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.78755
Policy Entropy: 4.10780
Value Function Loss: 0.00268

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01168
Policy Update Magnitude: 0.16883
Value Function Update Magnitude: 0.20095

Collected Steps per Second: 22,519.57516
Overall Steps per Second: 10,645.57624

Timestep Collection Time: 2.22065
Timestep Consumption Time: 2.47689
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.69754

Cumulative Model Updates: 318,840
Cumulative Timesteps: 2,659,138,484

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2659138484...
Checkpoint 2659138484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.66868
Policy Entropy: 4.07094
Value Function Loss: 0.00360

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01317
Policy Update Magnitude: 0.17276
Value Function Update Magnitude: 0.19829

Collected Steps per Second: 22,449.65400
Overall Steps per Second: 10,871.64205

Timestep Collection Time: 2.22810
Timestep Consumption Time: 2.37286
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.60096

Cumulative Model Updates: 318,846
Cumulative Timesteps: 2,659,188,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.45162
Policy Entropy: 4.03985
Value Function Loss: 0.00359

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.01633
Policy Update Magnitude: 0.17866
Value Function Update Magnitude: 0.21794

Collected Steps per Second: 22,635.40005
Overall Steps per Second: 10,569.68069

Timestep Collection Time: 2.20990
Timestep Consumption Time: 2.52269
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.73259

Cumulative Model Updates: 318,852
Cumulative Timesteps: 2,659,238,526

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2659238526...
Checkpoint 2659238526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.79889
Policy Entropy: 4.04593
Value Function Loss: 0.00315

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.01828
Policy Update Magnitude: 0.17825
Value Function Update Magnitude: 0.22855

Collected Steps per Second: 22,095.33494
Overall Steps per Second: 10,599.30474

Timestep Collection Time: 2.26337
Timestep Consumption Time: 2.45486
PPO Batch Consumption Time: 0.28447
Total Iteration Time: 4.71823

Cumulative Model Updates: 318,858
Cumulative Timesteps: 2,659,288,536

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.27120
Policy Entropy: 4.05821
Value Function Loss: 0.00310

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01627
Policy Update Magnitude: 0.18058
Value Function Update Magnitude: 0.21665

Collected Steps per Second: 23,207.77759
Overall Steps per Second: 10,849.47714

Timestep Collection Time: 2.15505
Timestep Consumption Time: 2.45475
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.60981

Cumulative Model Updates: 318,864
Cumulative Timesteps: 2,659,338,550

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2659338550...
Checkpoint 2659338550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.06707
Policy Entropy: 4.07518
Value Function Loss: 0.00273

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01398
Policy Update Magnitude: 0.17833
Value Function Update Magnitude: 0.19856

Collected Steps per Second: 22,284.21491
Overall Steps per Second: 10,636.41794

Timestep Collection Time: 2.24428
Timestep Consumption Time: 2.45768
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.70196

Cumulative Model Updates: 318,870
Cumulative Timesteps: 2,659,388,562

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.65784
Policy Entropy: 4.07727
Value Function Loss: 0.00295

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.01495
Policy Update Magnitude: 0.17604
Value Function Update Magnitude: 0.20203

Collected Steps per Second: 22,491.37733
Overall Steps per Second: 10,886.39003

Timestep Collection Time: 2.22396
Timestep Consumption Time: 2.37076
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.59473

Cumulative Model Updates: 318,876
Cumulative Timesteps: 2,659,438,582

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2659438582...
Checkpoint 2659438582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.11761
Policy Entropy: 4.07956
Value Function Loss: 0.00267

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.01588
Policy Update Magnitude: 0.17395
Value Function Update Magnitude: 0.20835

Collected Steps per Second: 21,775.60829
Overall Steps per Second: 10,349.38723

Timestep Collection Time: 2.29633
Timestep Consumption Time: 2.53526
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.83159

Cumulative Model Updates: 318,882
Cumulative Timesteps: 2,659,488,586

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.03657
Policy Entropy: 4.06625
Value Function Loss: 0.00291

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01434
Policy Update Magnitude: 0.17670
Value Function Update Magnitude: 0.20633

Collected Steps per Second: 22,359.16097
Overall Steps per Second: 10,606.71423

Timestep Collection Time: 2.23756
Timestep Consumption Time: 2.47926
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.71682

Cumulative Model Updates: 318,888
Cumulative Timesteps: 2,659,538,616

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2659538616...
Checkpoint 2659538616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.29812
Policy Entropy: 4.05802
Value Function Loss: 0.00290

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01669
Policy Update Magnitude: 0.18073
Value Function Update Magnitude: 0.20706

Collected Steps per Second: 23,009.02394
Overall Steps per Second: 10,843.92449

Timestep Collection Time: 2.17402
Timestep Consumption Time: 2.43889
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.61291

Cumulative Model Updates: 318,894
Cumulative Timesteps: 2,659,588,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.88599
Policy Entropy: 4.03935
Value Function Loss: 0.00363

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.01912
Policy Update Magnitude: 0.19252
Value Function Update Magnitude: 0.22183

Collected Steps per Second: 22,514.00542
Overall Steps per Second: 10,502.25431

Timestep Collection Time: 2.22155
Timestep Consumption Time: 2.54086
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.76241

Cumulative Model Updates: 318,900
Cumulative Timesteps: 2,659,638,654

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2659638654...
Checkpoint 2659638654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.22588
Policy Entropy: 4.03238
Value Function Loss: 0.00436

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02138
Policy Update Magnitude: 0.21438
Value Function Update Magnitude: 0.25266

Collected Steps per Second: 22,223.48761
Overall Steps per Second: 10,664.51180

Timestep Collection Time: 2.25140
Timestep Consumption Time: 2.44023
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.69164

Cumulative Model Updates: 318,906
Cumulative Timesteps: 2,659,688,688

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.44694
Policy Entropy: 4.04958
Value Function Loss: 0.00417

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02113
Policy Update Magnitude: 0.21142
Value Function Update Magnitude: 0.28396

Collected Steps per Second: 22,486.57583
Overall Steps per Second: 10,603.32792

Timestep Collection Time: 2.22364
Timestep Consumption Time: 2.49205
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.71569

Cumulative Model Updates: 318,912
Cumulative Timesteps: 2,659,738,690

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2659738690...
Checkpoint 2659738690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.91826
Policy Entropy: 4.07757
Value Function Loss: 0.00364

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02147
Policy Update Magnitude: 0.19823
Value Function Update Magnitude: 0.26615

Collected Steps per Second: 22,472.93730
Overall Steps per Second: 10,644.73001

Timestep Collection Time: 2.22490
Timestep Consumption Time: 2.47226
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.69716

Cumulative Model Updates: 318,918
Cumulative Timesteps: 2,659,788,690

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.76620
Policy Entropy: 4.10818
Value Function Loss: 0.00301

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.01634
Policy Update Magnitude: 0.18292
Value Function Update Magnitude: 0.24115

Collected Steps per Second: 22,612.66547
Overall Steps per Second: 10,740.78159

Timestep Collection Time: 2.21248
Timestep Consumption Time: 2.44547
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.65795

Cumulative Model Updates: 318,924
Cumulative Timesteps: 2,659,838,720

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2659838720...
Checkpoint 2659838720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.28221
Policy Entropy: 4.11981
Value Function Loss: 0.00299

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01326
Policy Update Magnitude: 0.17742
Value Function Update Magnitude: 0.23240

Collected Steps per Second: 22,345.15962
Overall Steps per Second: 10,627.65310

Timestep Collection Time: 2.23816
Timestep Consumption Time: 2.46768
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.70584

Cumulative Model Updates: 318,930
Cumulative Timesteps: 2,659,888,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.00179
Policy Entropy: 4.09090
Value Function Loss: 0.00247

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01430
Policy Update Magnitude: 0.17131
Value Function Update Magnitude: 0.21501

Collected Steps per Second: 22,201.10058
Overall Steps per Second: 10,669.62579

Timestep Collection Time: 2.25277
Timestep Consumption Time: 2.43474
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.68751

Cumulative Model Updates: 318,936
Cumulative Timesteps: 2,659,938,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2659938746...
Checkpoint 2659938746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.68435
Policy Entropy: 4.10012
Value Function Loss: 0.00213

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01439
Policy Update Magnitude: 0.16796
Value Function Update Magnitude: 0.19303

Collected Steps per Second: 22,591.03825
Overall Steps per Second: 10,593.09672

Timestep Collection Time: 2.21406
Timestep Consumption Time: 2.50769
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.72175

Cumulative Model Updates: 318,942
Cumulative Timesteps: 2,659,988,764

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.94197
Policy Entropy: 4.08279
Value Function Loss: 0.00223

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.01642
Policy Update Magnitude: 0.16070
Value Function Update Magnitude: 0.18036

Collected Steps per Second: 22,610.58677
Overall Steps per Second: 10,723.43652

Timestep Collection Time: 2.21153
Timestep Consumption Time: 2.45153
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.66306

Cumulative Model Updates: 318,948
Cumulative Timesteps: 2,660,038,768

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2660038768...
Checkpoint 2660038768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.44079
Policy Entropy: 4.07424
Value Function Loss: 0.00255

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01419
Policy Update Magnitude: 0.16402
Value Function Update Magnitude: 0.20246

Collected Steps per Second: 22,161.46232
Overall Steps per Second: 10,671.14717

Timestep Collection Time: 2.25635
Timestep Consumption Time: 2.42956
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.68591

Cumulative Model Updates: 318,954
Cumulative Timesteps: 2,660,088,772

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.50327
Policy Entropy: 4.07240
Value Function Loss: 0.00283

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01660
Policy Update Magnitude: 0.17526
Value Function Update Magnitude: 0.22135

Collected Steps per Second: 22,768.31061
Overall Steps per Second: 10,591.99218

Timestep Collection Time: 2.19647
Timestep Consumption Time: 2.52502
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.72149

Cumulative Model Updates: 318,960
Cumulative Timesteps: 2,660,138,782

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2660138782...
Checkpoint 2660138782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.88144
Policy Entropy: 4.08020
Value Function Loss: 0.00299

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.01850
Policy Update Magnitude: 0.19015
Value Function Update Magnitude: 0.23211

Collected Steps per Second: 22,346.06629
Overall Steps per Second: 10,705.54506

Timestep Collection Time: 2.23887
Timestep Consumption Time: 2.43441
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.67328

Cumulative Model Updates: 318,966
Cumulative Timesteps: 2,660,188,812

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.56652
Policy Entropy: 4.08067
Value Function Loss: 0.00334

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.01520
Policy Update Magnitude: 0.19000
Value Function Update Magnitude: 0.23976

Collected Steps per Second: 23,332.86511
Overall Steps per Second: 10,898.78868

Timestep Collection Time: 2.14427
Timestep Consumption Time: 2.44633
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.59060

Cumulative Model Updates: 318,972
Cumulative Timesteps: 2,660,238,844

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2660238844...
Checkpoint 2660238844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.51475
Policy Entropy: 4.07077
Value Function Loss: 0.00302

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.01713
Policy Update Magnitude: 0.18799
Value Function Update Magnitude: 0.24016

Collected Steps per Second: 22,165.79263
Overall Steps per Second: 10,518.93076

Timestep Collection Time: 2.25591
Timestep Consumption Time: 2.49781
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.75372

Cumulative Model Updates: 318,978
Cumulative Timesteps: 2,660,288,848

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.35464
Policy Entropy: 4.05394
Value Function Loss: 0.00317

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.01893
Policy Update Magnitude: 0.18907
Value Function Update Magnitude: 0.23276

Collected Steps per Second: 22,690.92469
Overall Steps per Second: 10,706.92431

Timestep Collection Time: 2.20476
Timestep Consumption Time: 2.46773
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.67249

Cumulative Model Updates: 318,984
Cumulative Timesteps: 2,660,338,876

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2660338876...
Checkpoint 2660338876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.40259
Policy Entropy: 4.05866
Value Function Loss: 0.00327

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.01755
Policy Update Magnitude: 0.19161
Value Function Update Magnitude: 0.22496

Collected Steps per Second: 22,900.49103
Overall Steps per Second: 10,620.40960

Timestep Collection Time: 2.18362
Timestep Consumption Time: 2.52486
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.70848

Cumulative Model Updates: 318,990
Cumulative Timesteps: 2,660,388,882

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.29696
Policy Entropy: 4.06706
Value Function Loss: 0.00408

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.01767
Policy Update Magnitude: 0.20130
Value Function Update Magnitude: 0.23754

Collected Steps per Second: 22,626.91886
Overall Steps per Second: 10,555.79998

Timestep Collection Time: 2.21011
Timestep Consumption Time: 2.52738
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.73749

Cumulative Model Updates: 318,996
Cumulative Timesteps: 2,660,438,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2660438890...
Checkpoint 2660438890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.30702
Policy Entropy: 4.08876
Value Function Loss: 0.00336

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.01590
Policy Update Magnitude: 0.19146
Value Function Update Magnitude: 0.24132

Collected Steps per Second: 22,176.98316
Overall Steps per Second: 10,641.04577

Timestep Collection Time: 2.25513
Timestep Consumption Time: 2.44478
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.69991

Cumulative Model Updates: 319,002
Cumulative Timesteps: 2,660,488,902

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.20862
Policy Entropy: 4.09351
Value Function Loss: 0.00326

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01458
Policy Update Magnitude: 0.18938
Value Function Update Magnitude: 0.22970

Collected Steps per Second: 22,520.98015
Overall Steps per Second: 10,575.85197

Timestep Collection Time: 2.22104
Timestep Consumption Time: 2.50860
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.72964

Cumulative Model Updates: 319,008
Cumulative Timesteps: 2,660,538,922

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2660538922...
Checkpoint 2660538922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.06464
Policy Entropy: 4.07160
Value Function Loss: 0.00309

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01502
Policy Update Magnitude: 0.19689
Value Function Update Magnitude: 0.22060

Collected Steps per Second: 22,460.44166
Overall Steps per Second: 10,662.47515

Timestep Collection Time: 2.22614
Timestep Consumption Time: 2.46321
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.68934

Cumulative Model Updates: 319,014
Cumulative Timesteps: 2,660,588,922

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.82662
Policy Entropy: 4.06301
Value Function Loss: 0.00380

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.01823
Policy Update Magnitude: 0.20443
Value Function Update Magnitude: 0.22743

Collected Steps per Second: 23,590.12261
Overall Steps per Second: 10,823.79982

Timestep Collection Time: 2.12072
Timestep Consumption Time: 2.50132
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.62204

Cumulative Model Updates: 319,020
Cumulative Timesteps: 2,660,638,950

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2660638950...
Checkpoint 2660638950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.75896
Policy Entropy: 4.08412
Value Function Loss: 0.00324

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.01888
Policy Update Magnitude: 0.19363
Value Function Update Magnitude: 0.22703

Collected Steps per Second: 22,507.53777
Overall Steps per Second: 10,539.00253

Timestep Collection Time: 2.22148
Timestep Consumption Time: 2.52280
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.74428

Cumulative Model Updates: 319,026
Cumulative Timesteps: 2,660,688,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.90871
Policy Entropy: 4.07844
Value Function Loss: 0.00356

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.01645
Policy Update Magnitude: 0.19194
Value Function Update Magnitude: 0.22548

Collected Steps per Second: 22,245.78793
Overall Steps per Second: 10,838.63153

Timestep Collection Time: 2.24762
Timestep Consumption Time: 2.36551
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.61313

Cumulative Model Updates: 319,032
Cumulative Timesteps: 2,660,738,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2660738950...
Checkpoint 2660738950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.64602
Policy Entropy: 4.08457
Value Function Loss: 0.00286

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.01605
Policy Update Magnitude: 0.19721
Value Function Update Magnitude: 0.22399

Collected Steps per Second: 22,479.64008
Overall Steps per Second: 10,684.68509

Timestep Collection Time: 2.22423
Timestep Consumption Time: 2.45536
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.67960

Cumulative Model Updates: 319,038
Cumulative Timesteps: 2,660,788,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.50263
Policy Entropy: 4.07985
Value Function Loss: 0.00301

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.01832
Policy Update Magnitude: 0.19290
Value Function Update Magnitude: 0.21366

Collected Steps per Second: 22,264.57896
Overall Steps per Second: 10,550.76259

Timestep Collection Time: 2.24716
Timestep Consumption Time: 2.49487
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.74203

Cumulative Model Updates: 319,044
Cumulative Timesteps: 2,660,838,982

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2660838982...
Checkpoint 2660838982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.04293
Policy Entropy: 4.10588
Value Function Loss: 0.00237

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01534
Policy Update Magnitude: 0.18198
Value Function Update Magnitude: 0.20168

Collected Steps per Second: 22,434.53416
Overall Steps per Second: 10,712.91788

Timestep Collection Time: 2.22880
Timestep Consumption Time: 2.43865
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.66745

Cumulative Model Updates: 319,050
Cumulative Timesteps: 2,660,888,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.87304
Policy Entropy: 4.09198
Value Function Loss: 0.00302

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01420
Policy Update Magnitude: 0.17710
Value Function Update Magnitude: 0.20885

Collected Steps per Second: 22,972.34044
Overall Steps per Second: 10,750.34765

Timestep Collection Time: 2.17679
Timestep Consumption Time: 2.47478
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.65157

Cumulative Model Updates: 319,056
Cumulative Timesteps: 2,660,938,990

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2660938990...
Checkpoint 2660938990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.73827
Policy Entropy: 4.08365
Value Function Loss: 0.00311

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.01486
Policy Update Magnitude: 0.18599
Value Function Update Magnitude: 0.21491

Collected Steps per Second: 22,400.74922
Overall Steps per Second: 10,629.52851

Timestep Collection Time: 2.23207
Timestep Consumption Time: 2.47181
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.70388

Cumulative Model Updates: 319,062
Cumulative Timesteps: 2,660,988,990

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.58539
Policy Entropy: 4.08931
Value Function Loss: 0.00388

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.01712
Policy Update Magnitude: 0.19621
Value Function Update Magnitude: 0.23418

Collected Steps per Second: 23,387.54504
Overall Steps per Second: 10,919.91537

Timestep Collection Time: 2.13977
Timestep Consumption Time: 2.44305
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.58282

Cumulative Model Updates: 319,068
Cumulative Timesteps: 2,661,039,034

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2661039034...
Checkpoint 2661039034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.63102
Policy Entropy: 4.10488
Value Function Loss: 0.00318

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.01577
Policy Update Magnitude: 0.19488
Value Function Update Magnitude: 0.24637

Collected Steps per Second: 22,242.64896
Overall Steps per Second: 10,653.45568

Timestep Collection Time: 2.24901
Timestep Consumption Time: 2.44655
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.69557

Cumulative Model Updates: 319,074
Cumulative Timesteps: 2,661,089,058

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.15332
Policy Entropy: 4.13548
Value Function Loss: 0.00245

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.01624
Policy Update Magnitude: 0.17705
Value Function Update Magnitude: 0.23282

Collected Steps per Second: 22,511.58659
Overall Steps per Second: 10,943.70203

Timestep Collection Time: 2.22117
Timestep Consumption Time: 2.34785
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.56902

Cumulative Model Updates: 319,080
Cumulative Timesteps: 2,661,139,060

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2661139060...
Checkpoint 2661139060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.55203
Policy Entropy: 4.12237
Value Function Loss: 0.00306

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.01593
Policy Update Magnitude: 0.17525
Value Function Update Magnitude: 0.20925

Collected Steps per Second: 22,380.02088
Overall Steps per Second: 10,596.68998

Timestep Collection Time: 2.23449
Timestep Consumption Time: 2.48472
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.71921

Cumulative Model Updates: 319,086
Cumulative Timesteps: 2,661,189,068

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.82812
Policy Entropy: 4.13424
Value Function Loss: 0.00275

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.01441
Policy Update Magnitude: 0.17654
Value Function Update Magnitude: 0.22324

Collected Steps per Second: 22,829.98387
Overall Steps per Second: 10,796.87800

Timestep Collection Time: 2.19028
Timestep Consumption Time: 2.44106
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.63134

Cumulative Model Updates: 319,092
Cumulative Timesteps: 2,661,239,072

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2661239072...
Checkpoint 2661239072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.66335
Policy Entropy: 4.10868
Value Function Loss: 0.00267

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01590
Policy Update Magnitude: 0.17284
Value Function Update Magnitude: 0.22009

Collected Steps per Second: 22,133.63241
Overall Steps per Second: 10,779.24923

Timestep Collection Time: 2.25928
Timestep Consumption Time: 2.37982
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.63910

Cumulative Model Updates: 319,098
Cumulative Timesteps: 2,661,289,078

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.63307
Policy Entropy: 4.10090
Value Function Loss: 0.00316

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.01510
Policy Update Magnitude: 0.19359
Value Function Update Magnitude: 0.21480

Collected Steps per Second: 22,722.47974
Overall Steps per Second: 10,647.80459

Timestep Collection Time: 2.20161
Timestep Consumption Time: 2.49664
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.69825

Cumulative Model Updates: 319,104
Cumulative Timesteps: 2,661,339,104

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2661339104...
Checkpoint 2661339104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.21614
Policy Entropy: 4.09883
Value Function Loss: 0.00302

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.01902
Policy Update Magnitude: 0.19894
Value Function Update Magnitude: 0.23469

Collected Steps per Second: 22,528.03673
Overall Steps per Second: 10,661.46059

Timestep Collection Time: 2.21990
Timestep Consumption Time: 2.47083
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.69073

Cumulative Model Updates: 319,110
Cumulative Timesteps: 2,661,389,114

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.80736
Policy Entropy: 4.09984
Value Function Loss: 0.00317

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.01920
Policy Update Magnitude: 0.19504
Value Function Update Magnitude: 0.24697

Collected Steps per Second: 23,458.35073
Overall Steps per Second: 10,781.11595

Timestep Collection Time: 2.13212
Timestep Consumption Time: 2.50710
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.63922

Cumulative Model Updates: 319,116
Cumulative Timesteps: 2,661,439,130

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2661439130...
Checkpoint 2661439130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.58605
Policy Entropy: 4.12194
Value Function Loss: 0.00268

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.01641
Policy Update Magnitude: 0.18321
Value Function Update Magnitude: 0.24823

Collected Steps per Second: 22,315.45835
Overall Steps per Second: 10,511.04001

Timestep Collection Time: 2.24141
Timestep Consumption Time: 2.51721
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.75862

Cumulative Model Updates: 319,122
Cumulative Timesteps: 2,661,489,148

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.41413
Policy Entropy: 4.12814
Value Function Loss: 0.00278

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.01744
Policy Update Magnitude: 0.18623
Value Function Update Magnitude: 0.23731

Collected Steps per Second: 22,594.49842
Overall Steps per Second: 10,656.89598

Timestep Collection Time: 2.21355
Timestep Consumption Time: 2.47956
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.69311

Cumulative Model Updates: 319,128
Cumulative Timesteps: 2,661,539,162

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2661539162...
Checkpoint 2661539162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.82221
Policy Entropy: 4.14883
Value Function Loss: 0.00224

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.01592
Policy Update Magnitude: 0.17373
Value Function Update Magnitude: 0.21665

Collected Steps per Second: 23,238.08731
Overall Steps per Second: 10,887.45514

Timestep Collection Time: 2.15259
Timestep Consumption Time: 2.44188
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.59446

Cumulative Model Updates: 319,134
Cumulative Timesteps: 2,661,589,184

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.01843
Policy Entropy: 4.16631
Value Function Loss: 0.00218

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.01397
Policy Update Magnitude: 0.16365
Value Function Update Magnitude: 0.20813

Collected Steps per Second: 22,625.92312
Overall Steps per Second: 10,567.63135

Timestep Collection Time: 2.21118
Timestep Consumption Time: 2.52309
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.73427

Cumulative Model Updates: 319,140
Cumulative Timesteps: 2,661,639,214

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2661639214...
Checkpoint 2661639214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.58243
Policy Entropy: 4.14579
Value Function Loss: 0.00211

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01143
Policy Update Magnitude: 0.17604
Value Function Update Magnitude: 0.20774

Collected Steps per Second: 22,306.51248
Overall Steps per Second: 10,714.91614

Timestep Collection Time: 2.24230
Timestep Consumption Time: 2.42577
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.66807

Cumulative Model Updates: 319,146
Cumulative Timesteps: 2,661,689,232

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.48676
Policy Entropy: 4.11618
Value Function Loss: 0.00272

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01570
Policy Update Magnitude: 0.18760
Value Function Update Magnitude: 0.21592

Collected Steps per Second: 22,994.41122
Overall Steps per Second: 10,728.09990

Timestep Collection Time: 2.17488
Timestep Consumption Time: 2.48671
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.66159

Cumulative Model Updates: 319,152
Cumulative Timesteps: 2,661,739,242

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2661739242...
Checkpoint 2661739242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.74688
Policy Entropy: 4.06960
Value Function Loss: 0.00394

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.01907
Policy Update Magnitude: 0.20873
Value Function Update Magnitude: 0.23778

Collected Steps per Second: 22,365.08293
Overall Steps per Second: 10,646.00046

Timestep Collection Time: 2.23652
Timestep Consumption Time: 2.46196
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.69848

Cumulative Model Updates: 319,158
Cumulative Timesteps: 2,661,789,262

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.82966
Policy Entropy: 4.07051
Value Function Loss: 0.00374

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02144
Policy Update Magnitude: 0.21235
Value Function Update Magnitude: 0.25610

Collected Steps per Second: 22,635.05735
Overall Steps per Second: 10,903.52061

Timestep Collection Time: 2.20985
Timestep Consumption Time: 2.37766
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.58751

Cumulative Model Updates: 319,164
Cumulative Timesteps: 2,661,839,282

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2661839282...
Checkpoint 2661839282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.69691
Policy Entropy: 4.09232
Value Function Loss: 0.00353

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02009
Policy Update Magnitude: 0.20050
Value Function Update Magnitude: 0.25617

Collected Steps per Second: 22,202.59748
Overall Steps per Second: 10,630.74416

Timestep Collection Time: 2.25226
Timestep Consumption Time: 2.45164
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.70390

Cumulative Model Updates: 319,170
Cumulative Timesteps: 2,661,889,288

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.41594
Policy Entropy: 4.13979
Value Function Loss: 0.00271

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.01692
Policy Update Magnitude: 0.18224
Value Function Update Magnitude: 0.24057

Collected Steps per Second: 22,490.39504
Overall Steps per Second: 10,614.04917

Timestep Collection Time: 2.22362
Timestep Consumption Time: 2.48806
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.71168

Cumulative Model Updates: 319,176
Cumulative Timesteps: 2,661,939,298

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2661939298...
Checkpoint 2661939298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.12843
Policy Entropy: 4.14777
Value Function Loss: 0.00319

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.01568
Policy Update Magnitude: 0.17904
Value Function Update Magnitude: 0.22801

Collected Steps per Second: 23,065.28824
Overall Steps per Second: 10,737.96400

Timestep Collection Time: 2.16776
Timestep Consumption Time: 2.48862
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.65638

Cumulative Model Updates: 319,182
Cumulative Timesteps: 2,661,989,298

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.19598
Policy Entropy: 4.11571
Value Function Loss: 0.00329

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.01667
Policy Update Magnitude: 0.19332
Value Function Update Magnitude: 0.23349

Collected Steps per Second: 22,431.64081
Overall Steps per Second: 10,671.71417

Timestep Collection Time: 2.22971
Timestep Consumption Time: 2.45707
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.68678

Cumulative Model Updates: 319,188
Cumulative Timesteps: 2,662,039,314

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2662039314...
Checkpoint 2662039314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.57850
Policy Entropy: 4.10204
Value Function Loss: 0.00329

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.01711
Policy Update Magnitude: 0.19515
Value Function Update Magnitude: 0.23662

Collected Steps per Second: 22,206.37462
Overall Steps per Second: 10,647.10545

Timestep Collection Time: 2.25215
Timestep Consumption Time: 2.44509
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.69724

Cumulative Model Updates: 319,194
Cumulative Timesteps: 2,662,089,326

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.93376
Policy Entropy: 4.09087
Value Function Loss: 0.00293

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.01905
Policy Update Magnitude: 0.19231
Value Function Update Magnitude: 0.22181

Collected Steps per Second: 22,561.72644
Overall Steps per Second: 10,594.83765

Timestep Collection Time: 2.21641
Timestep Consumption Time: 2.50344
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.71985

Cumulative Model Updates: 319,200
Cumulative Timesteps: 2,662,139,332

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2662139332...
Checkpoint 2662139332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.90767
Policy Entropy: 4.08943
Value Function Loss: 0.00312

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.01662
Policy Update Magnitude: 0.19225
Value Function Update Magnitude: 0.20675

Collected Steps per Second: 22,455.69371
Overall Steps per Second: 10,612.78207

Timestep Collection Time: 2.22732
Timestep Consumption Time: 2.48549
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.71281

Cumulative Model Updates: 319,206
Cumulative Timesteps: 2,662,189,348

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.38762
Policy Entropy: 4.10103
Value Function Loss: 0.00297

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01705
Policy Update Magnitude: 0.19023
Value Function Update Magnitude: 0.21403

Collected Steps per Second: 22,711.19795
Overall Steps per Second: 10,844.44697

Timestep Collection Time: 2.20235
Timestep Consumption Time: 2.40996
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.61231

Cumulative Model Updates: 319,212
Cumulative Timesteps: 2,662,239,366

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2662239366...
Checkpoint 2662239366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.24628
Policy Entropy: 4.08515
Value Function Loss: 0.00409

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.01772
Policy Update Magnitude: 0.20257
Value Function Update Magnitude: 0.22986

Collected Steps per Second: 22,100.51471
Overall Steps per Second: 10,585.25284

Timestep Collection Time: 2.26339
Timestep Consumption Time: 2.46224
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.72563

Cumulative Model Updates: 319,218
Cumulative Timesteps: 2,662,289,388

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.93418
Policy Entropy: 4.10001
Value Function Loss: 0.00341

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.01599
Policy Update Magnitude: 0.20249
Value Function Update Magnitude: 0.24434

Collected Steps per Second: 22,445.66489
Overall Steps per Second: 10,603.77552

Timestep Collection Time: 2.22885
Timestep Consumption Time: 2.48909
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.71794

Cumulative Model Updates: 319,224
Cumulative Timesteps: 2,662,339,416

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2662339416...
Checkpoint 2662339416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.61897
Policy Entropy: 4.09185
Value Function Loss: 0.00375

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.01802
Policy Update Magnitude: 0.20653
Value Function Update Magnitude: 0.25942

Collected Steps per Second: 21,877.29109
Overall Steps per Second: 10,483.93096

Timestep Collection Time: 2.28685
Timestep Consumption Time: 2.48522
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.77207

Cumulative Model Updates: 319,230
Cumulative Timesteps: 2,662,389,446

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.44305
Policy Entropy: 4.13330
Value Function Loss: 0.00244

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.01577
Policy Update Magnitude: 0.19422
Value Function Update Magnitude: 0.24656

Collected Steps per Second: 21,399.88314
Overall Steps per Second: 10,245.16863

Timestep Collection Time: 2.33749
Timestep Consumption Time: 2.54501
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.88250

Cumulative Model Updates: 319,236
Cumulative Timesteps: 2,662,439,468

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2662439468...
Checkpoint 2662439468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.75695
Policy Entropy: 4.11966
Value Function Loss: 0.00321

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.01447
Policy Update Magnitude: 0.18500
Value Function Update Magnitude: 0.22614

Collected Steps per Second: 22,352.99792
Overall Steps per Second: 10,550.20739

Timestep Collection Time: 2.23693
Timestep Consumption Time: 2.50251
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.73943

Cumulative Model Updates: 319,242
Cumulative Timesteps: 2,662,489,470

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.53324
Policy Entropy: 4.11417
Value Function Loss: 0.00313

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.01517
Policy Update Magnitude: 0.19074
Value Function Update Magnitude: 0.24812

Collected Steps per Second: 23,550.93383
Overall Steps per Second: 10,845.32114

Timestep Collection Time: 2.12433
Timestep Consumption Time: 2.48872
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.61305

Cumulative Model Updates: 319,248
Cumulative Timesteps: 2,662,539,500

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2662539500...
Checkpoint 2662539500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.16588
Policy Entropy: 4.11277
Value Function Loss: 0.00320

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.01691
Policy Update Magnitude: 0.18808
Value Function Update Magnitude: 0.24532

Collected Steps per Second: 22,013.27822
Overall Steps per Second: 10,563.76513

Timestep Collection Time: 2.27172
Timestep Consumption Time: 2.46220
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.73392

Cumulative Model Updates: 319,254
Cumulative Timesteps: 2,662,589,508

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.53265
Policy Entropy: 4.13725
Value Function Loss: 0.00311

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01456
Policy Update Magnitude: 0.18864
Value Function Update Magnitude: 0.22406

Collected Steps per Second: 22,537.31881
Overall Steps per Second: 10,876.15044

Timestep Collection Time: 2.21872
Timestep Consumption Time: 2.37886
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.59758

Cumulative Model Updates: 319,260
Cumulative Timesteps: 2,662,639,512

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2662639512...
Checkpoint 2662639512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.85026
Policy Entropy: 4.14247
Value Function Loss: 0.00293

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.01694
Policy Update Magnitude: 0.18421
Value Function Update Magnitude: 0.21590

Collected Steps per Second: 22,197.83314
Overall Steps per Second: 10,473.89594

Timestep Collection Time: 2.25310
Timestep Consumption Time: 2.52201
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.77511

Cumulative Model Updates: 319,266
Cumulative Timesteps: 2,662,689,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.72943
Policy Entropy: 4.13529
Value Function Loss: 0.00256

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.01725
Policy Update Magnitude: 0.17810
Value Function Update Magnitude: 0.21001

Collected Steps per Second: 22,870.38464
Overall Steps per Second: 10,756.93041

Timestep Collection Time: 2.18667
Timestep Consumption Time: 2.46243
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.64910

Cumulative Model Updates: 319,272
Cumulative Timesteps: 2,662,739,536

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2662739536...
Checkpoint 2662739536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.81329
Policy Entropy: 4.10719
Value Function Loss: 0.00295

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01839
Policy Update Magnitude: 0.18164
Value Function Update Magnitude: 0.21021

Collected Steps per Second: 20,331.12158
Overall Steps per Second: 9,628.00894

Timestep Collection Time: 2.46066
Timestep Consumption Time: 2.73543
PPO Batch Consumption Time: 0.31338
Total Iteration Time: 5.19609

Cumulative Model Updates: 319,278
Cumulative Timesteps: 2,662,789,564

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.54672
Policy Entropy: 4.10156
Value Function Loss: 0.00289

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.01781
Policy Update Magnitude: 0.18754
Value Function Update Magnitude: 0.21757

Collected Steps per Second: 20,994.06931
Overall Steps per Second: 10,212.04582

Timestep Collection Time: 2.38267
Timestep Consumption Time: 2.51566
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.89833

Cumulative Model Updates: 319,284
Cumulative Timesteps: 2,662,839,586

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2662839586...
Checkpoint 2662839586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.51098
Policy Entropy: 4.08756
Value Function Loss: 0.00351

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.01889
Policy Update Magnitude: 0.19291
Value Function Update Magnitude: 0.20822

Collected Steps per Second: 22,004.33911
Overall Steps per Second: 10,273.03828

Timestep Collection Time: 2.27337
Timestep Consumption Time: 2.59608
PPO Batch Consumption Time: 0.30575
Total Iteration Time: 4.86945

Cumulative Model Updates: 319,290
Cumulative Timesteps: 2,662,889,610

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.99906
Policy Entropy: 4.10469
Value Function Loss: 0.00318

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01799
Policy Update Magnitude: 0.19446
Value Function Update Magnitude: 0.20585

Collected Steps per Second: 22,612.12891
Overall Steps per Second: 10,796.73028

Timestep Collection Time: 2.21253
Timestep Consumption Time: 2.42128
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.63381

Cumulative Model Updates: 319,296
Cumulative Timesteps: 2,662,939,640

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2662939640...
Checkpoint 2662939640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.69071
Policy Entropy: 4.08765
Value Function Loss: 0.00343

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01781
Policy Update Magnitude: 0.19885
Value Function Update Magnitude: 0.22032

Collected Steps per Second: 21,983.55487
Overall Steps per Second: 10,642.93854

Timestep Collection Time: 2.27570
Timestep Consumption Time: 2.42488
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.70058

Cumulative Model Updates: 319,302
Cumulative Timesteps: 2,662,989,668

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.55129
Policy Entropy: 4.08102
Value Function Loss: 0.00323

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.01726
Policy Update Magnitude: 0.19871
Value Function Update Magnitude: 0.24717

Collected Steps per Second: 22,602.26038
Overall Steps per Second: 10,857.21400

Timestep Collection Time: 2.21235
Timestep Consumption Time: 2.39326
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.60560

Cumulative Model Updates: 319,308
Cumulative Timesteps: 2,663,039,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2663039672...
Checkpoint 2663039672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.90163
Policy Entropy: 4.08780
Value Function Loss: 0.00278

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.01731
Policy Update Magnitude: 0.19105
Value Function Update Magnitude: 0.24295

Collected Steps per Second: 21,930.41498
Overall Steps per Second: 10,438.16653

Timestep Collection Time: 2.28058
Timestep Consumption Time: 2.51088
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.79145

Cumulative Model Updates: 319,314
Cumulative Timesteps: 2,663,089,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.83937
Policy Entropy: 4.09845
Value Function Loss: 0.00257

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01594
Policy Update Magnitude: 0.17956
Value Function Update Magnitude: 0.22784

Collected Steps per Second: 22,621.59060
Overall Steps per Second: 10,805.55389

Timestep Collection Time: 2.21090
Timestep Consumption Time: 2.41765
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.62855

Cumulative Model Updates: 319,320
Cumulative Timesteps: 2,663,139,700

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2663139700...
Checkpoint 2663139700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.76268
Policy Entropy: 4.10234
Value Function Loss: 0.00239

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01351
Policy Update Magnitude: 0.18119
Value Function Update Magnitude: 0.21079

Collected Steps per Second: 22,351.05706
Overall Steps per Second: 10,616.59187

Timestep Collection Time: 2.23828
Timestep Consumption Time: 2.47396
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.71225

Cumulative Model Updates: 319,326
Cumulative Timesteps: 2,663,189,728

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.27114
Policy Entropy: 4.08346
Value Function Loss: 0.00281

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01464
Policy Update Magnitude: 0.18965
Value Function Update Magnitude: 0.19862

Collected Steps per Second: 22,664.35474
Overall Steps per Second: 10,571.87562

Timestep Collection Time: 2.20717
Timestep Consumption Time: 2.52463
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.73180

Cumulative Model Updates: 319,332
Cumulative Timesteps: 2,663,239,752

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2663239752...
Checkpoint 2663239752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.37433
Policy Entropy: 4.08929
Value Function Loss: 0.00317

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.01633
Policy Update Magnitude: 0.18907
Value Function Update Magnitude: 0.21033

Collected Steps per Second: 22,301.20311
Overall Steps per Second: 10,720.11864

Timestep Collection Time: 2.24302
Timestep Consumption Time: 2.42316
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.66618

Cumulative Model Updates: 319,338
Cumulative Timesteps: 2,663,289,774

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.46380
Policy Entropy: 4.10334
Value Function Loss: 0.00299

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.01651
Policy Update Magnitude: 0.18706
Value Function Update Magnitude: 0.23457

Collected Steps per Second: 22,920.14260
Overall Steps per Second: 10,732.22632

Timestep Collection Time: 2.18149
Timestep Consumption Time: 2.47738
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.65887

Cumulative Model Updates: 319,344
Cumulative Timesteps: 2,663,339,774

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2663339774...
Checkpoint 2663339774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.59463
Policy Entropy: 4.13192
Value Function Loss: 0.00248

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01499
Policy Update Magnitude: 0.18170
Value Function Update Magnitude: 0.22356

Collected Steps per Second: 22,276.52414
Overall Steps per Second: 10,666.94279

Timestep Collection Time: 2.24559
Timestep Consumption Time: 2.44404
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.68963

Cumulative Model Updates: 319,350
Cumulative Timesteps: 2,663,389,798

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.14430
Policy Entropy: 4.14376
Value Function Loss: 0.00283

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.01348
Policy Update Magnitude: 0.18512
Value Function Update Magnitude: 0.19799

Collected Steps per Second: 23,299.92056
Overall Steps per Second: 10,850.15271

Timestep Collection Time: 2.14602
Timestep Consumption Time: 2.46240
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 4.60841

Cumulative Model Updates: 319,356
Cumulative Timesteps: 2,663,439,800

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2663439800...
Checkpoint 2663439800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.79043
Policy Entropy: 4.13351
Value Function Loss: 0.00288

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.01469
Policy Update Magnitude: 0.18809
Value Function Update Magnitude: 0.19775

Collected Steps per Second: 22,150.09066
Overall Steps per Second: 10,634.56557

Timestep Collection Time: 2.25868
Timestep Consumption Time: 2.44579
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.70447

Cumulative Model Updates: 319,362
Cumulative Timesteps: 2,663,489,830

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.63026
Policy Entropy: 4.11310
Value Function Loss: 0.00315

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01503
Policy Update Magnitude: 0.19242
Value Function Update Magnitude: 0.20540

Collected Steps per Second: 22,337.53466
Overall Steps per Second: 10,556.71740

Timestep Collection Time: 2.23892
Timestep Consumption Time: 2.49854
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.73746

Cumulative Model Updates: 319,368
Cumulative Timesteps: 2,663,539,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2663539842...
Checkpoint 2663539842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.93590
Policy Entropy: 4.08605
Value Function Loss: 0.00332

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.01650
Policy Update Magnitude: 0.19695
Value Function Update Magnitude: 0.21034

Collected Steps per Second: 23,032.85119
Overall Steps per Second: 10,371.66824

Timestep Collection Time: 2.17203
Timestep Consumption Time: 2.65150
PPO Batch Consumption Time: 0.30246
Total Iteration Time: 4.82352

Cumulative Model Updates: 319,374
Cumulative Timesteps: 2,663,589,870

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.48876
Policy Entropy: 4.08272
Value Function Loss: 0.00403

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.01767
Policy Update Magnitude: 0.21318
Value Function Update Magnitude: 0.23155

Collected Steps per Second: 22,965.38107
Overall Steps per Second: 10,487.69743

Timestep Collection Time: 2.17780
Timestep Consumption Time: 2.59103
PPO Batch Consumption Time: 0.31410
Total Iteration Time: 4.76883

Cumulative Model Updates: 319,380
Cumulative Timesteps: 2,663,639,884

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2663639884...
Checkpoint 2663639884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.54317
Policy Entropy: 4.08697
Value Function Loss: 0.00419

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.01839
Policy Update Magnitude: 0.21134
Value Function Update Magnitude: 0.25159

Collected Steps per Second: 22,450.44427
Overall Steps per Second: 10,896.44976

Timestep Collection Time: 2.22784
Timestep Consumption Time: 2.36228
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.59012

Cumulative Model Updates: 319,386
Cumulative Timesteps: 2,663,689,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.81821
Policy Entropy: 4.12091
Value Function Loss: 0.00340

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.01689
Policy Update Magnitude: 0.19625
Value Function Update Magnitude: 0.25580

Collected Steps per Second: 22,137.78738
Overall Steps per Second: 10,253.70397

Timestep Collection Time: 2.26039
Timestep Consumption Time: 2.61980
PPO Batch Consumption Time: 0.29777
Total Iteration Time: 4.88019

Cumulative Model Updates: 319,392
Cumulative Timesteps: 2,663,739,940

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2663739940...
Checkpoint 2663739940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.18235
Policy Entropy: 4.13064
Value Function Loss: 0.00266

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.01636
Policy Update Magnitude: 0.18339
Value Function Update Magnitude: 0.22437

Collected Steps per Second: 20,335.87046
Overall Steps per Second: 10,368.07495

Timestep Collection Time: 2.45891
Timestep Consumption Time: 2.36398
PPO Batch Consumption Time: 0.28494
Total Iteration Time: 4.82288

Cumulative Model Updates: 319,398
Cumulative Timesteps: 2,663,789,944

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.63821
Policy Entropy: 4.14424
Value Function Loss: 0.00214

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01556
Policy Update Magnitude: 0.17523
Value Function Update Magnitude: 0.20533

Collected Steps per Second: 22,185.23205
Overall Steps per Second: 10,793.88581

Timestep Collection Time: 2.25447
Timestep Consumption Time: 2.37926
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.63373

Cumulative Model Updates: 319,404
Cumulative Timesteps: 2,663,839,960

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2663839960...
Checkpoint 2663839960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.05767
Policy Entropy: 4.14062
Value Function Loss: 0.00243

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.01396
Policy Update Magnitude: 0.18843
Value Function Update Magnitude: 0.20526

Collected Steps per Second: 22,373.82058
Overall Steps per Second: 10,715.81971

Timestep Collection Time: 2.23538
Timestep Consumption Time: 2.43192
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.66731

Cumulative Model Updates: 319,410
Cumulative Timesteps: 2,663,889,974

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.44729
Policy Entropy: 4.11145
Value Function Loss: 0.00275

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.01652
Policy Update Magnitude: 0.19489
Value Function Update Magnitude: 0.21658

Collected Steps per Second: 21,981.37520
Overall Steps per Second: 10,734.48334

Timestep Collection Time: 2.27565
Timestep Consumption Time: 2.38428
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 4.65994

Cumulative Model Updates: 319,416
Cumulative Timesteps: 2,663,939,996

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2663939996...
Checkpoint 2663939996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.36810
Policy Entropy: 4.09190
Value Function Loss: 0.00295

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.01789
Policy Update Magnitude: 0.20569
Value Function Update Magnitude: 0.23283

Collected Steps per Second: 22,566.78470
Overall Steps per Second: 10,599.48811

Timestep Collection Time: 2.21591
Timestep Consumption Time: 2.50186
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.71778

Cumulative Model Updates: 319,422
Cumulative Timesteps: 2,663,990,002

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.72482
Policy Entropy: 4.04180
Value Function Loss: 0.00407

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02029
Policy Update Magnitude: 0.21581
Value Function Update Magnitude: 0.24363

Collected Steps per Second: 22,488.48390
Overall Steps per Second: 10,761.16116

Timestep Collection Time: 2.22363
Timestep Consumption Time: 2.42327
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.64690

Cumulative Model Updates: 319,428
Cumulative Timesteps: 2,664,040,008

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2664040008...
Checkpoint 2664040008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.18859
Policy Entropy: 4.04776
Value Function Loss: 0.00412

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.02205
Policy Update Magnitude: 0.22137
Value Function Update Magnitude: 0.25557

Collected Steps per Second: 22,266.94967
Overall Steps per Second: 10,622.71441

Timestep Collection Time: 2.24575
Timestep Consumption Time: 2.46171
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.70746

Cumulative Model Updates: 319,434
Cumulative Timesteps: 2,664,090,014

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.49816
Policy Entropy: 4.04805
Value Function Loss: 0.00446

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02134
Policy Update Magnitude: 0.22309
Value Function Update Magnitude: 0.26789

Collected Steps per Second: 22,535.56615
Overall Steps per Second: 10,512.13568

Timestep Collection Time: 2.21934
Timestep Consumption Time: 2.53840
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.75774

Cumulative Model Updates: 319,440
Cumulative Timesteps: 2,664,140,028

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2664140028...
Checkpoint 2664140028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.76338
Policy Entropy: 4.09366
Value Function Loss: 0.00327

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.01907
Policy Update Magnitude: 0.21628
Value Function Update Magnitude: 0.25182

Collected Steps per Second: 22,308.95199
Overall Steps per Second: 10,608.40819

Timestep Collection Time: 2.24134
Timestep Consumption Time: 2.47209
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.71343

Cumulative Model Updates: 319,446
Cumulative Timesteps: 2,664,190,030

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.83271
Policy Entropy: 4.11113
Value Function Loss: 0.00294

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.01751
Policy Update Magnitude: 0.20441
Value Function Update Magnitude: 0.23794

Collected Steps per Second: 22,710.31281
Overall Steps per Second: 10,877.64240

Timestep Collection Time: 2.20279
Timestep Consumption Time: 2.39619
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.59897

Cumulative Model Updates: 319,452
Cumulative Timesteps: 2,664,240,056

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2664240056...
Checkpoint 2664240056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.46006
Policy Entropy: 4.12558
Value Function Loss: 0.00234

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.01823
Policy Update Magnitude: 0.18738
Value Function Update Magnitude: 0.22557

Collected Steps per Second: 22,117.87523
Overall Steps per Second: 10,595.75675

Timestep Collection Time: 2.26107
Timestep Consumption Time: 2.45875
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.71981

Cumulative Model Updates: 319,458
Cumulative Timesteps: 2,664,290,066

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.78376
Policy Entropy: 4.10366
Value Function Loss: 0.00315

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01645
Policy Update Magnitude: 0.20352
Value Function Update Magnitude: 0.22273

Collected Steps per Second: 22,226.18425
Overall Steps per Second: 10,683.75817

Timestep Collection Time: 2.24969
Timestep Consumption Time: 2.43050
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.68019

Cumulative Model Updates: 319,464
Cumulative Timesteps: 2,664,340,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2664340068...
Checkpoint 2664340068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.37548
Policy Entropy: 4.09741
Value Function Loss: 0.00364

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.01964
Policy Update Magnitude: 0.21901
Value Function Update Magnitude: 0.22632

Collected Steps per Second: 22,488.43493
Overall Steps per Second: 10,485.44681

Timestep Collection Time: 2.22532
Timestep Consumption Time: 2.54739
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.77271

Cumulative Model Updates: 319,470
Cumulative Timesteps: 2,664,390,112

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.99024
Policy Entropy: 4.10419
Value Function Loss: 0.00361

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02069
Policy Update Magnitude: 0.21246
Value Function Update Magnitude: 0.23485

Collected Steps per Second: 22,438.99812
Overall Steps per Second: 10,474.72928

Timestep Collection Time: 2.22862
Timestep Consumption Time: 2.54554
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.77416

Cumulative Model Updates: 319,476
Cumulative Timesteps: 2,664,440,120

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2664440120...
Checkpoint 2664440120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78.83669
Policy Entropy: 4.12525
Value Function Loss: 0.00363

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.01761
Policy Update Magnitude: 0.19961
Value Function Update Magnitude: 0.23471

Collected Steps per Second: 21,992.48038
Overall Steps per Second: 10,686.85075

Timestep Collection Time: 2.27450
Timestep Consumption Time: 2.40620
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.68071

Cumulative Model Updates: 319,482
Cumulative Timesteps: 2,664,490,142

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.90459
Policy Entropy: 4.14017
Value Function Loss: 0.00339

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.01550
Policy Update Magnitude: 0.19969
Value Function Update Magnitude: 0.23001

Collected Steps per Second: 22,640.84960
Overall Steps per Second: 10,617.91640

Timestep Collection Time: 2.20866
Timestep Consumption Time: 2.50092
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.70959

Cumulative Model Updates: 319,488
Cumulative Timesteps: 2,664,540,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2664540148...
Checkpoint 2664540148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.52308
Policy Entropy: 4.13925
Value Function Loss: 0.00396

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.01692
Policy Update Magnitude: 0.20348
Value Function Update Magnitude: 0.23727

Collected Steps per Second: 22,335.74062
Overall Steps per Second: 10,895.68125

Timestep Collection Time: 2.24071
Timestep Consumption Time: 2.35267
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.59338

Cumulative Model Updates: 319,494
Cumulative Timesteps: 2,664,590,196

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.03532
Policy Entropy: 4.15255
Value Function Loss: 0.00257

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.01672
Policy Update Magnitude: 0.19200
Value Function Update Magnitude: 0.23934

Collected Steps per Second: 22,706.93757
Overall Steps per Second: 10,603.20288

Timestep Collection Time: 2.20241
Timestep Consumption Time: 2.51409
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.71650

Cumulative Model Updates: 319,500
Cumulative Timesteps: 2,664,640,206

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2664640206...
Checkpoint 2664640206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65.76466
Policy Entropy: 4.13194
Value Function Loss: 0.00261

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.01481
Policy Update Magnitude: 0.18249
Value Function Update Magnitude: 0.22093

Collected Steps per Second: 22,139.37002
Overall Steps per Second: 10,531.43328

Timestep Collection Time: 2.25896
Timestep Consumption Time: 2.48987
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.74883

Cumulative Model Updates: 319,506
Cumulative Timesteps: 2,664,690,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.14084
Policy Entropy: 4.11990
Value Function Loss: 0.00310

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.01400
Policy Update Magnitude: 0.18678
Value Function Update Magnitude: 0.23655

Collected Steps per Second: 22,371.38466
Overall Steps per Second: 10,850.71483

Timestep Collection Time: 2.23616
Timestep Consumption Time: 2.37423
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.61039

Cumulative Model Updates: 319,512
Cumulative Timesteps: 2,664,740,244

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2664740244...
Checkpoint 2664740244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.29726
Policy Entropy: 4.12137
Value Function Loss: 0.00359

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.01657
Policy Update Magnitude: 0.19505
Value Function Update Magnitude: 0.26120

Collected Steps per Second: 22,431.13417
Overall Steps per Second: 10,616.00058

Timestep Collection Time: 2.22967
Timestep Consumption Time: 2.48152
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.71119

Cumulative Model Updates: 319,518
Cumulative Timesteps: 2,664,790,258

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.95314
Policy Entropy: 4.10719
Value Function Loss: 0.00416

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.01767
Policy Update Magnitude: 0.21531
Value Function Update Magnitude: 0.26235

Collected Steps per Second: 20,328.84572
Overall Steps per Second: 10,208.62841

Timestep Collection Time: 2.46025
Timestep Consumption Time: 2.43894
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.89919

Cumulative Model Updates: 319,524
Cumulative Timesteps: 2,664,840,272

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2664840272...
Checkpoint 2664840272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.91696
Policy Entropy: 4.11846
Value Function Loss: 0.00343

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.01930
Policy Update Magnitude: 0.21069
Value Function Update Magnitude: 0.25691

Collected Steps per Second: 23,363.15444
Overall Steps per Second: 10,951.42707

Timestep Collection Time: 2.14072
Timestep Consumption Time: 2.42617
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.56689

Cumulative Model Updates: 319,530
Cumulative Timesteps: 2,664,890,286

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.66786
Policy Entropy: 4.08664
Value Function Loss: 0.00329

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.01641
Policy Update Magnitude: 0.20657
Value Function Update Magnitude: 0.24693

Collected Steps per Second: 22,594.55387
Overall Steps per Second: 10,578.92840

Timestep Collection Time: 2.21319
Timestep Consumption Time: 2.51376
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.72694

Cumulative Model Updates: 319,536
Cumulative Timesteps: 2,664,940,292

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2664940292...
Checkpoint 2664940292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.85866
Policy Entropy: 4.10103
Value Function Loss: 0.00265

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.01640
Policy Update Magnitude: 0.20781
Value Function Update Magnitude: 0.24029

Collected Steps per Second: 22,160.22004
Overall Steps per Second: 10,619.10738

Timestep Collection Time: 2.25702
Timestep Consumption Time: 2.45298
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.71000

Cumulative Model Updates: 319,542
Cumulative Timesteps: 2,664,990,308

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.24539
Policy Entropy: 4.10601
Value Function Loss: 0.00304

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.01958
Policy Update Magnitude: 0.21420
Value Function Update Magnitude: 0.23977

Collected Steps per Second: 22,855.16727
Overall Steps per Second: 10,793.13770

Timestep Collection Time: 2.18900
Timestep Consumption Time: 2.44635
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.63535

Cumulative Model Updates: 319,548
Cumulative Timesteps: 2,665,040,338

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2665040338...
Checkpoint 2665040338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.89420
Policy Entropy: 4.14305
Value Function Loss: 0.00258

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.01701
Policy Update Magnitude: 0.20090
Value Function Update Magnitude: 0.23886

Collected Steps per Second: 22,646.13668
Overall Steps per Second: 10,789.65370

Timestep Collection Time: 2.20841
Timestep Consumption Time: 2.42677
PPO Batch Consumption Time: 0.27694
Total Iteration Time: 4.63518

Cumulative Model Updates: 319,554
Cumulative Timesteps: 2,665,090,350

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.86056
Policy Entropy: 4.13486
Value Function Loss: 0.00281

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01448
Policy Update Magnitude: 0.19747
Value Function Update Magnitude: 0.23053

Collected Steps per Second: 22,711.30805
Overall Steps per Second: 10,898.78046

Timestep Collection Time: 2.20216
Timestep Consumption Time: 2.38679
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.58895

Cumulative Model Updates: 319,560
Cumulative Timesteps: 2,665,140,364

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2665140364...
Checkpoint 2665140364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.01184
Policy Entropy: 4.12110
Value Function Loss: 0.00297

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.01749
Policy Update Magnitude: 0.21144
Value Function Update Magnitude: 0.22994

Collected Steps per Second: 22,474.78631
Overall Steps per Second: 10,597.27882

Timestep Collection Time: 2.22516
Timestep Consumption Time: 2.49398
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.71914

Cumulative Model Updates: 319,566
Cumulative Timesteps: 2,665,190,374

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.90077
Policy Entropy: 4.07269
Value Function Loss: 0.00420

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.01971
Policy Update Magnitude: 0.22815
Value Function Update Magnitude: 0.25583

Collected Steps per Second: 22,526.12381
Overall Steps per Second: 10,720.81803

Timestep Collection Time: 2.22080
Timestep Consumption Time: 2.44545
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.66625

Cumulative Model Updates: 319,572
Cumulative Timesteps: 2,665,240,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2665240400...
Checkpoint 2665240400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.35583
Policy Entropy: 4.08659
Value Function Loss: 0.00383

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02177
Policy Update Magnitude: 0.22910
Value Function Update Magnitude: 0.27502

Collected Steps per Second: 23,123.31428
Overall Steps per Second: 10,881.14642

Timestep Collection Time: 2.16336
Timestep Consumption Time: 2.43395
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.59731

Cumulative Model Updates: 319,578
Cumulative Timesteps: 2,665,290,424

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.82419
Policy Entropy: 4.08135
Value Function Loss: 0.00388

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02101
Policy Update Magnitude: 0.22059
Value Function Update Magnitude: 0.27490

Collected Steps per Second: 22,643.09988
Overall Steps per Second: 10,637.88594

Timestep Collection Time: 2.20941
Timestep Consumption Time: 2.49340
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.70281

Cumulative Model Updates: 319,584
Cumulative Timesteps: 2,665,340,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2665340452...
Checkpoint 2665340452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.18557
Policy Entropy: 4.14856
Value Function Loss: 0.00316

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01700
Policy Update Magnitude: 0.20920
Value Function Update Magnitude: 0.27477

Collected Steps per Second: 22,637.14243
Overall Steps per Second: 10,922.78841

Timestep Collection Time: 2.20885
Timestep Consumption Time: 2.36892
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.57777

Cumulative Model Updates: 319,590
Cumulative Timesteps: 2,665,390,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.50730
Policy Entropy: 4.14292
Value Function Loss: 0.00326

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.01657
Policy Update Magnitude: 0.20198
Value Function Update Magnitude: 0.27048

Collected Steps per Second: 23,077.68990
Overall Steps per Second: 10,844.45548

Timestep Collection Time: 2.16677
Timestep Consumption Time: 2.44425
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.61102

Cumulative Model Updates: 319,596
Cumulative Timesteps: 2,665,440,458

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2665440458...
Checkpoint 2665440458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.69233
Policy Entropy: 4.17111
Value Function Loss: 0.00312

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01564
Policy Update Magnitude: 0.20426
Value Function Update Magnitude: 0.27303

Collected Steps per Second: 22,354.63655
Overall Steps per Second: 10,693.33660

Timestep Collection Time: 2.23793
Timestep Consumption Time: 2.44050
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.67843

Cumulative Model Updates: 319,602
Cumulative Timesteps: 2,665,490,486

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.76147
Policy Entropy: 4.16343
Value Function Loss: 0.00258

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.01633
Policy Update Magnitude: 0.19371
Value Function Update Magnitude: 0.26447

Collected Steps per Second: 22,852.63156
Overall Steps per Second: 10,915.03091

Timestep Collection Time: 2.18828
Timestep Consumption Time: 2.39329
PPO Batch Consumption Time: 0.28561
Total Iteration Time: 4.58157

Cumulative Model Updates: 319,608
Cumulative Timesteps: 2,665,540,494

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2665540494...
Checkpoint 2665540494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.01993
Policy Entropy: 4.18144
Value Function Loss: 0.00207

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01440
Policy Update Magnitude: 0.18216
Value Function Update Magnitude: 0.25559

Collected Steps per Second: 22,463.48303
Overall Steps per Second: 10,666.68099

Timestep Collection Time: 2.22717
Timestep Consumption Time: 2.46314
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.69031

Cumulative Model Updates: 319,614
Cumulative Timesteps: 2,665,590,524

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.20732
Policy Entropy: 4.17496
Value Function Loss: 0.00235

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01540
Policy Update Magnitude: 0.18256
Value Function Update Magnitude: 0.24555

Collected Steps per Second: 22,612.27715
Overall Steps per Second: 10,809.07969

Timestep Collection Time: 2.21234
Timestep Consumption Time: 2.41581
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.62815

Cumulative Model Updates: 319,620
Cumulative Timesteps: 2,665,640,550

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2665640550...
Checkpoint 2665640550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.44170
Policy Entropy: 4.13846
Value Function Loss: 0.00309

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.01634
Policy Update Magnitude: 0.19835
Value Function Update Magnitude: 0.25377

Collected Steps per Second: 23,108.29002
Overall Steps per Second: 10,692.84820

Timestep Collection Time: 2.16433
Timestep Consumption Time: 2.51300
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.67733

Cumulative Model Updates: 319,626
Cumulative Timesteps: 2,665,690,564

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.45595
Policy Entropy: 4.12197
Value Function Loss: 0.00337

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02106
Policy Update Magnitude: 0.20572
Value Function Update Magnitude: 0.26767

Collected Steps per Second: 22,456.91971
Overall Steps per Second: 10,588.79038

Timestep Collection Time: 2.22764
Timestep Consumption Time: 2.49679
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.72443

Cumulative Model Updates: 319,632
Cumulative Timesteps: 2,665,740,590

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2665740590...
Checkpoint 2665740590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105.33044
Policy Entropy: 4.08327
Value Function Loss: 0.00378

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.01954
Policy Update Magnitude: 0.21335
Value Function Update Magnitude: 0.26804

Collected Steps per Second: 22,145.62573
Overall Steps per Second: 10,764.55678

Timestep Collection Time: 2.25923
Timestep Consumption Time: 2.38862
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.64785

Cumulative Model Updates: 319,638
Cumulative Timesteps: 2,665,790,622

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.00769
Policy Entropy: 4.08153
Value Function Loss: 0.00390

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.01642
Policy Update Magnitude: 0.23149
Value Function Update Magnitude: 0.26082

Collected Steps per Second: 22,723.60463
Overall Steps per Second: 10,671.51552

Timestep Collection Time: 2.20141
Timestep Consumption Time: 2.48621
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.68762

Cumulative Model Updates: 319,644
Cumulative Timesteps: 2,665,840,646

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2665840646...
Checkpoint 2665840646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.68138
Policy Entropy: 4.10318
Value Function Loss: 0.00346

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.01958
Policy Update Magnitude: 0.22206
Value Function Update Magnitude: 0.25163

Collected Steps per Second: 22,270.63027
Overall Steps per Second: 10,703.10303

Timestep Collection Time: 2.24637
Timestep Consumption Time: 2.42779
PPO Batch Consumption Time: 0.27699
Total Iteration Time: 4.67416

Cumulative Model Updates: 319,650
Cumulative Timesteps: 2,665,890,674

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.94986
Policy Entropy: 4.09912
Value Function Loss: 0.00336

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.01793
Policy Update Magnitude: 0.21693
Value Function Update Magnitude: 0.24343

Collected Steps per Second: 22,701.33544
Overall Steps per Second: 10,891.01140

Timestep Collection Time: 2.20287
Timestep Consumption Time: 2.38881
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.59168

Cumulative Model Updates: 319,656
Cumulative Timesteps: 2,665,940,682

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2665940682...
Checkpoint 2665940682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.56695
Policy Entropy: 4.12791
Value Function Loss: 0.00275

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.01723
Policy Update Magnitude: 0.21220
Value Function Update Magnitude: 0.23865

Collected Steps per Second: 22,782.28742
Overall Steps per Second: 10,628.41396

Timestep Collection Time: 2.19495
Timestep Consumption Time: 2.50998
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.70494

Cumulative Model Updates: 319,662
Cumulative Timesteps: 2,665,990,688

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.32514
Policy Entropy: 4.10348
Value Function Loss: 0.00286

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02031
Policy Update Magnitude: 0.20235
Value Function Update Magnitude: 0.24106

Collected Steps per Second: 22,666.84502
Overall Steps per Second: 10,808.13072

Timestep Collection Time: 2.20613
Timestep Consumption Time: 2.42057
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.62670

Cumulative Model Updates: 319,668
Cumulative Timesteps: 2,666,040,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2666040694...
Checkpoint 2666040694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.68039
Policy Entropy: 4.12309
Value Function Loss: 0.00281

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.01584
Policy Update Magnitude: 0.19613
Value Function Update Magnitude: 0.22792

Collected Steps per Second: 22,258.58973
Overall Steps per Second: 10,732.37785

Timestep Collection Time: 2.24767
Timestep Consumption Time: 2.41392
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.66160

Cumulative Model Updates: 319,674
Cumulative Timesteps: 2,666,090,724

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.11279
Policy Entropy: 4.14679
Value Function Loss: 0.00245

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.01637
Policy Update Magnitude: 0.19052
Value Function Update Magnitude: 0.22142

Collected Steps per Second: 22,742.36849
Overall Steps per Second: 10,688.70375

Timestep Collection Time: 2.19854
Timestep Consumption Time: 2.47930
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.67784

Cumulative Model Updates: 319,680
Cumulative Timesteps: 2,666,140,724

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2666140724...
Checkpoint 2666140724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.80051
Policy Entropy: 4.14070
Value Function Loss: 0.00282

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01400
Policy Update Magnitude: 0.18846
Value Function Update Magnitude: 0.22791

Collected Steps per Second: 21,505.02310
Overall Steps per Second: 10,384.96314

Timestep Collection Time: 2.32560
Timestep Consumption Time: 2.49021
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.81581

Cumulative Model Updates: 319,686
Cumulative Timesteps: 2,666,190,736

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.31797
Policy Entropy: 4.14176
Value Function Loss: 0.00269

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.01234
Policy Update Magnitude: 0.20199
Value Function Update Magnitude: 0.21665

Collected Steps per Second: 23,234.49049
Overall Steps per Second: 10,918.21331

Timestep Collection Time: 2.15223
Timestep Consumption Time: 2.42782
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.58005

Cumulative Model Updates: 319,692
Cumulative Timesteps: 2,666,240,742

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2666240742...
Checkpoint 2666240742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.83754
Policy Entropy: 4.11864
Value Function Loss: 0.00333

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.01573
Policy Update Magnitude: 0.21190
Value Function Update Magnitude: 0.23144

Collected Steps per Second: 22,285.60796
Overall Steps per Second: 10,700.71086

Timestep Collection Time: 2.24432
Timestep Consumption Time: 2.42976
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.67408

Cumulative Model Updates: 319,698
Cumulative Timesteps: 2,666,290,758

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.73028
Policy Entropy: 4.11569
Value Function Loss: 0.00335

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.01784
Policy Update Magnitude: 0.21601
Value Function Update Magnitude: 0.24519

Collected Steps per Second: 22,647.62426
Overall Steps per Second: 10,803.75940

Timestep Collection Time: 2.20880
Timestep Consumption Time: 2.42144
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.63024

Cumulative Model Updates: 319,704
Cumulative Timesteps: 2,666,340,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2666340782...
Checkpoint 2666340782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.68140
Policy Entropy: 4.10025
Value Function Loss: 0.00409

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.01831
Policy Update Magnitude: 0.22939
Value Function Update Magnitude: 0.26954

Collected Steps per Second: 23,166.97698
Overall Steps per Second: 10,686.39459

Timestep Collection Time: 2.15919
Timestep Consumption Time: 2.52171
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.68091

Cumulative Model Updates: 319,710
Cumulative Timesteps: 2,666,390,804

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.54352
Policy Entropy: 4.10305
Value Function Loss: 0.00353

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.01981
Policy Update Magnitude: 0.22400
Value Function Update Magnitude: 0.28769

Collected Steps per Second: 22,829.35597
Overall Steps per Second: 10,683.50010

Timestep Collection Time: 2.19113
Timestep Consumption Time: 2.49105
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.68217

Cumulative Model Updates: 319,716
Cumulative Timesteps: 2,666,440,826

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2666440826...
Checkpoint 2666440826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.62046
Policy Entropy: 4.07257
Value Function Loss: 0.00414

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02160
Policy Update Magnitude: 0.22852
Value Function Update Magnitude: 0.28647

Collected Steps per Second: 22,369.89717
Overall Steps per Second: 10,879.39114

Timestep Collection Time: 2.23640
Timestep Consumption Time: 2.36202
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.59842

Cumulative Model Updates: 319,722
Cumulative Timesteps: 2,666,490,854

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.73654
Policy Entropy: 4.11663
Value Function Loss: 0.00292

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.01960
Policy Update Magnitude: 0.21997
Value Function Update Magnitude: 0.26784

Collected Steps per Second: 22,738.01825
Overall Steps per Second: 10,652.59284

Timestep Collection Time: 2.19922
Timestep Consumption Time: 2.49503
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.69426

Cumulative Model Updates: 319,728
Cumulative Timesteps: 2,666,540,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2666540860...
Checkpoint 2666540860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.65845
Policy Entropy: 4.12234
Value Function Loss: 0.00297

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.01749
Policy Update Magnitude: 0.20621
Value Function Update Magnitude: 0.25103

Collected Steps per Second: 22,547.61032
Overall Steps per Second: 10,845.87618

Timestep Collection Time: 2.21771
Timestep Consumption Time: 2.39271
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.61042

Cumulative Model Updates: 319,734
Cumulative Timesteps: 2,666,590,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.60757
Policy Entropy: 4.14427
Value Function Loss: 0.00271

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01333
Policy Update Magnitude: 0.20568
Value Function Update Magnitude: 0.23564

Collected Steps per Second: 23,367.12160
Overall Steps per Second: 10,918.38560

Timestep Collection Time: 2.14087
Timestep Consumption Time: 2.44094
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.58181

Cumulative Model Updates: 319,740
Cumulative Timesteps: 2,666,640,890

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2666640890...
Checkpoint 2666640890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51231
Policy Entropy: 4.11394
Value Function Loss: 0.00309

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.01706
Policy Update Magnitude: 0.21539
Value Function Update Magnitude: 0.24218

Collected Steps per Second: 22,247.57921
Overall Steps per Second: 10,726.32169

Timestep Collection Time: 2.24851
Timestep Consumption Time: 2.41515
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.66367

Cumulative Model Updates: 319,746
Cumulative Timesteps: 2,666,690,914

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.02957
Policy Entropy: 4.12569
Value Function Loss: 0.00296

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.01919
Policy Update Magnitude: 0.21353
Value Function Update Magnitude: 0.24600

Collected Steps per Second: 22,536.72241
Overall Steps per Second: 10,933.81025

Timestep Collection Time: 2.21975
Timestep Consumption Time: 2.35559
PPO Batch Consumption Time: 0.27682
Total Iteration Time: 4.57535

Cumulative Model Updates: 319,752
Cumulative Timesteps: 2,666,740,940

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2666740940...
Checkpoint 2666740940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.66956
Policy Entropy: 4.12921
Value Function Loss: 0.00298

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01602
Policy Update Magnitude: 0.21088
Value Function Update Magnitude: 0.24105

Collected Steps per Second: 22,677.68908
Overall Steps per Second: 10,596.35284

Timestep Collection Time: 2.20587
Timestep Consumption Time: 2.51500
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.72087

Cumulative Model Updates: 319,758
Cumulative Timesteps: 2,666,790,964

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.52931
Policy Entropy: 4.14503
Value Function Loss: 0.00314

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01354
Policy Update Magnitude: 0.21112
Value Function Update Magnitude: 0.25331

Collected Steps per Second: 22,534.47779
Overall Steps per Second: 10,693.70785

Timestep Collection Time: 2.21980
Timestep Consumption Time: 2.45791
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.67770

Cumulative Model Updates: 319,764
Cumulative Timesteps: 2,666,840,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2666840986...
Checkpoint 2666840986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.38653
Policy Entropy: 4.11859
Value Function Loss: 0.00326

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.01844
Policy Update Magnitude: 0.21118
Value Function Update Magnitude: 0.26530

Collected Steps per Second: 22,548.89410
Overall Steps per Second: 10,838.99226

Timestep Collection Time: 2.21847
Timestep Consumption Time: 2.39672
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.61519

Cumulative Model Updates: 319,770
Cumulative Timesteps: 2,666,891,010

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.64809
Policy Entropy: 4.12891
Value Function Loss: 0.00282

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.01814
Policy Update Magnitude: 0.20710
Value Function Update Magnitude: 0.24842

Collected Steps per Second: 21,876.71014
Overall Steps per Second: 10,484.91792

Timestep Collection Time: 2.28636
Timestep Consumption Time: 2.48411
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.77047

Cumulative Model Updates: 319,776
Cumulative Timesteps: 2,666,941,028

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2666941028...
Checkpoint 2666941028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.34614
Policy Entropy: 4.13507
Value Function Loss: 0.00360

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.01997
Policy Update Magnitude: 0.20688
Value Function Update Magnitude: 0.23190

Collected Steps per Second: 22,366.74441
Overall Steps per Second: 10,698.81341

Timestep Collection Time: 2.23653
Timestep Consumption Time: 2.43912
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.67566

Cumulative Model Updates: 319,782
Cumulative Timesteps: 2,666,991,052

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.87775
Policy Entropy: 4.13005
Value Function Loss: 0.00338

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02203
Policy Update Magnitude: 0.20241
Value Function Update Magnitude: 0.23186

Collected Steps per Second: 23,480.74351
Overall Steps per Second: 10,836.02833

Timestep Collection Time: 2.13034
Timestep Consumption Time: 2.48593
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.61627

Cumulative Model Updates: 319,788
Cumulative Timesteps: 2,667,041,074

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2667041074...
Checkpoint 2667041074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.65650
Policy Entropy: 4.13354
Value Function Loss: 0.00361

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02053
Policy Update Magnitude: 0.20939
Value Function Update Magnitude: 0.23481

Collected Steps per Second: 22,423.13042
Overall Steps per Second: 10,729.50322

Timestep Collection Time: 2.22993
Timestep Consumption Time: 2.43030
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.66023

Cumulative Model Updates: 319,794
Cumulative Timesteps: 2,667,091,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.92367
Policy Entropy: 4.13343
Value Function Loss: 0.00259

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02192
Policy Update Magnitude: 0.20360
Value Function Update Magnitude: 0.22084

Collected Steps per Second: 22,125.53429
Overall Steps per Second: 10,820.27297

Timestep Collection Time: 2.26028
Timestep Consumption Time: 2.36160
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.62188

Cumulative Model Updates: 319,800
Cumulative Timesteps: 2,667,141,086

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2667141086...
Checkpoint 2667141086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.16255
Policy Entropy: 4.14098
Value Function Loss: 0.00315

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02065
Policy Update Magnitude: 0.20244
Value Function Update Magnitude: 0.21441

Collected Steps per Second: 22,550.68064
Overall Steps per Second: 10,725.57643

Timestep Collection Time: 2.21785
Timestep Consumption Time: 2.44521
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.66306

Cumulative Model Updates: 319,806
Cumulative Timesteps: 2,667,191,100

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.37702
Policy Entropy: 4.12306
Value Function Loss: 0.00322

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.01847
Policy Update Magnitude: 0.21106
Value Function Update Magnitude: 0.20882

Collected Steps per Second: 22,711.31621
Overall Steps per Second: 10,825.28886

Timestep Collection Time: 2.20172
Timestep Consumption Time: 2.41746
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.61918

Cumulative Model Updates: 319,812
Cumulative Timesteps: 2,667,241,104

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2667241104...
Checkpoint 2667241104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.96756
Policy Entropy: 4.10709
Value Function Loss: 0.00334

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.01933
Policy Update Magnitude: 0.21593
Value Function Update Magnitude: 0.21296

Collected Steps per Second: 22,404.55547
Overall Steps per Second: 10,716.56964

Timestep Collection Time: 2.23169
Timestep Consumption Time: 2.43398
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.66567

Cumulative Model Updates: 319,818
Cumulative Timesteps: 2,667,291,104

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.23627
Policy Entropy: 4.09367
Value Function Loss: 0.00361

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.01893
Policy Update Magnitude: 0.22466
Value Function Update Magnitude: 0.22668

Collected Steps per Second: 22,919.58602
Overall Steps per Second: 10,818.74736

Timestep Collection Time: 2.18285
Timestep Consumption Time: 2.44153
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.62438

Cumulative Model Updates: 319,824
Cumulative Timesteps: 2,667,341,134

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2667341134...
Checkpoint 2667341134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.59896
Policy Entropy: 4.08796
Value Function Loss: 0.00371

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.01872
Policy Update Magnitude: 0.22951
Value Function Update Magnitude: 0.23374

Collected Steps per Second: 22,347.84263
Overall Steps per Second: 10,711.50640

Timestep Collection Time: 2.23780
Timestep Consumption Time: 2.43101
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.66881

Cumulative Model Updates: 319,830
Cumulative Timesteps: 2,667,391,144

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.64371
Policy Entropy: 4.09736
Value Function Loss: 0.00352

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.01853
Policy Update Magnitude: 0.22822
Value Function Update Magnitude: 0.24746

Collected Steps per Second: 23,345.48417
Overall Steps per Second: 10,970.81680

Timestep Collection Time: 2.14183
Timestep Consumption Time: 2.41590
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.55773

Cumulative Model Updates: 319,836
Cumulative Timesteps: 2,667,441,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2667441146...
Checkpoint 2667441146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.77346
Policy Entropy: 4.08602
Value Function Loss: 0.00435

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.01806
Policy Update Magnitude: 0.23385
Value Function Update Magnitude: 0.25535

Collected Steps per Second: 22,299.07205
Overall Steps per Second: 10,544.48184

Timestep Collection Time: 2.24287
Timestep Consumption Time: 2.50027
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.74314

Cumulative Model Updates: 319,842
Cumulative Timesteps: 2,667,491,160

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.43555
Policy Entropy: 4.11811
Value Function Loss: 0.00345

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02002
Policy Update Magnitude: 0.22859
Value Function Update Magnitude: 0.26055

Collected Steps per Second: 22,670.43691
Overall Steps per Second: 10,921.08830

Timestep Collection Time: 2.20552
Timestep Consumption Time: 2.37278
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.57830

Cumulative Model Updates: 319,848
Cumulative Timesteps: 2,667,541,160

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2667541160...
Checkpoint 2667541160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.78765
Policy Entropy: 4.13108
Value Function Loss: 0.00325

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02077
Policy Update Magnitude: 0.21162
Value Function Update Magnitude: 0.25703

Collected Steps per Second: 22,228.24515
Overall Steps per Second: 10,702.38522

Timestep Collection Time: 2.25029
Timestep Consumption Time: 2.42343
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.67372

Cumulative Model Updates: 319,854
Cumulative Timesteps: 2,667,591,180

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.55573
Policy Entropy: 4.14127
Value Function Loss: 0.00268

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01678
Policy Update Magnitude: 0.21296
Value Function Update Magnitude: 0.24645

Collected Steps per Second: 22,010.41608
Overall Steps per Second: 10,427.37697

Timestep Collection Time: 2.27283
Timestep Consumption Time: 2.52473
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.79756

Cumulative Model Updates: 319,860
Cumulative Timesteps: 2,667,641,206

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2667641206...
Checkpoint 2667641206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.25849
Policy Entropy: 4.11855
Value Function Loss: 0.00278

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.01794
Policy Update Magnitude: 0.20983
Value Function Update Magnitude: 0.24007

Collected Steps per Second: 22,408.66146
Overall Steps per Second: 10,765.29480

Timestep Collection Time: 2.23253
Timestep Consumption Time: 2.41463
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.64716

Cumulative Model Updates: 319,866
Cumulative Timesteps: 2,667,691,234

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.98641
Policy Entropy: 4.11499
Value Function Loss: 0.00308

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.01917
Policy Update Magnitude: 0.21759
Value Function Update Magnitude: 0.24551

Collected Steps per Second: 22,696.17184
Overall Steps per Second: 10,793.72963

Timestep Collection Time: 2.20434
Timestep Consumption Time: 2.43076
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.63510

Cumulative Model Updates: 319,872
Cumulative Timesteps: 2,667,741,264

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2667741264...
Checkpoint 2667741264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.33303
Policy Entropy: 4.13065
Value Function Loss: 0.00290

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.01683
Policy Update Magnitude: 0.20990
Value Function Update Magnitude: 0.24370

Collected Steps per Second: 22,507.24723
Overall Steps per Second: 10,662.50307

Timestep Collection Time: 2.22257
Timestep Consumption Time: 2.46901
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.69158

Cumulative Model Updates: 319,878
Cumulative Timesteps: 2,667,791,288

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.49085
Policy Entropy: 4.13544
Value Function Loss: 0.00283

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.01578
Policy Update Magnitude: 0.20121
Value Function Update Magnitude: 0.25509

Collected Steps per Second: 23,347.48212
Overall Steps per Second: 10,953.63857

Timestep Collection Time: 2.14259
Timestep Consumption Time: 2.42430
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.56688

Cumulative Model Updates: 319,884
Cumulative Timesteps: 2,667,841,312

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2667841312...
Checkpoint 2667841312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.42187
Policy Entropy: 4.14279
Value Function Loss: 0.00232

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01683
Policy Update Magnitude: 0.19942
Value Function Update Magnitude: 0.24757

Collected Steps per Second: 22,452.16673
Overall Steps per Second: 10,567.25861

Timestep Collection Time: 2.22803
Timestep Consumption Time: 2.50584
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.73387

Cumulative Model Updates: 319,890
Cumulative Timesteps: 2,667,891,336

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.20686
Policy Entropy: 4.14895
Value Function Loss: 0.00325

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01866
Policy Update Magnitude: 0.20897
Value Function Update Magnitude: 0.23440

Collected Steps per Second: 22,753.54572
Overall Steps per Second: 10,850.14771

Timestep Collection Time: 2.19807
Timestep Consumption Time: 2.41145
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.60952

Cumulative Model Updates: 319,896
Cumulative Timesteps: 2,667,941,350

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2667941350...
Checkpoint 2667941350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.21680
Policy Entropy: 4.16354
Value Function Loss: 0.00325

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01771
Policy Update Magnitude: 0.21240
Value Function Update Magnitude: 0.24001

Collected Steps per Second: 23,241.20787
Overall Steps per Second: 10,758.29764

Timestep Collection Time: 2.15281
Timestep Consumption Time: 2.49792
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.65074

Cumulative Model Updates: 319,902
Cumulative Timesteps: 2,667,991,384

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.88792
Policy Entropy: 4.14642
Value Function Loss: 0.00405

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.01938
Policy Update Magnitude: 0.21781
Value Function Update Magnitude: 0.24404

Collected Steps per Second: 22,498.87162
Overall Steps per Second: 10,595.54001

Timestep Collection Time: 2.22331
Timestep Consumption Time: 2.49773
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.72104

Cumulative Model Updates: 319,908
Cumulative Timesteps: 2,668,041,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2668041406...
Checkpoint 2668041406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.13106
Policy Entropy: 4.14604
Value Function Loss: 0.00340

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.01877
Policy Update Magnitude: 0.21199
Value Function Update Magnitude: 0.24517

Collected Steps per Second: 21,761.84268
Overall Steps per Second: 10,555.22768

Timestep Collection Time: 2.29870
Timestep Consumption Time: 2.44056
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.73926

Cumulative Model Updates: 319,914
Cumulative Timesteps: 2,668,091,430

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.21158
Policy Entropy: 4.15332
Value Function Loss: 0.00321

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.01876
Policy Update Magnitude: 0.20259
Value Function Update Magnitude: 0.23936

Collected Steps per Second: 22,743.87103
Overall Steps per Second: 10,797.53349

Timestep Collection Time: 2.19875
Timestep Consumption Time: 2.43268
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.63143

Cumulative Model Updates: 319,920
Cumulative Timesteps: 2,668,141,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2668141438...
Checkpoint 2668141438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.03327
Policy Entropy: 4.17205
Value Function Loss: 0.00293

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.01681
Policy Update Magnitude: 0.19543
Value Function Update Magnitude: 0.23629

Collected Steps per Second: 22,469.32330
Overall Steps per Second: 10,715.80268

Timestep Collection Time: 2.22650
Timestep Consumption Time: 2.44212
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.66862

Cumulative Model Updates: 319,926
Cumulative Timesteps: 2,668,191,466

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.10730
Policy Entropy: 4.15669
Value Function Loss: 0.00418

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01603
Policy Update Magnitude: 0.20974
Value Function Update Magnitude: 0.25858

Collected Steps per Second: 23,439.32541
Overall Steps per Second: 10,899.04882

Timestep Collection Time: 2.13351
Timestep Consumption Time: 2.45478
PPO Batch Consumption Time: 0.28364
Total Iteration Time: 4.58829

Cumulative Model Updates: 319,932
Cumulative Timesteps: 2,668,241,474

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2668241474...
Checkpoint 2668241474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.36182
Policy Entropy: 4.13408
Value Function Loss: 0.00395

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.01797
Policy Update Magnitude: 0.23269
Value Function Update Magnitude: 0.28479

Collected Steps per Second: 22,680.60171
Overall Steps per Second: 10,683.32938

Timestep Collection Time: 2.20523
Timestep Consumption Time: 2.47645
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.68169

Cumulative Model Updates: 319,938
Cumulative Timesteps: 2,668,291,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.93246
Policy Entropy: 4.13406
Value Function Loss: 0.00372

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.01922
Policy Update Magnitude: 0.23179
Value Function Update Magnitude: 0.28721

Collected Steps per Second: 22,491.09441
Overall Steps per Second: 10,902.34742

Timestep Collection Time: 2.22408
Timestep Consumption Time: 2.36411
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.58819

Cumulative Model Updates: 319,944
Cumulative Timesteps: 2,668,341,512

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2668341512...
Checkpoint 2668341512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.83998
Policy Entropy: 4.16073
Value Function Loss: 0.00229

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.01699
Policy Update Magnitude: 0.21104
Value Function Update Magnitude: 0.26243

Collected Steps per Second: 22,258.60086
Overall Steps per Second: 10,718.28290

Timestep Collection Time: 2.24686
Timestep Consumption Time: 2.41918
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.66605

Cumulative Model Updates: 319,950
Cumulative Timesteps: 2,668,391,524

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.94130
Policy Entropy: 4.15530
Value Function Loss: 0.00291

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01585
Policy Update Magnitude: 0.21397
Value Function Update Magnitude: 0.24490

Collected Steps per Second: 22,575.44908
Overall Steps per Second: 10,803.10698

Timestep Collection Time: 2.21550
Timestep Consumption Time: 2.41428
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.62978

Cumulative Model Updates: 319,956
Cumulative Timesteps: 2,668,441,540

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2668441540...
Checkpoint 2668441540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.39765
Policy Entropy: 4.13162
Value Function Loss: 0.00362

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.01780
Policy Update Magnitude: 0.21889
Value Function Update Magnitude: 0.26141

Collected Steps per Second: 22,503.73158
Overall Steps per Second: 10,754.48688

Timestep Collection Time: 2.22265
Timestep Consumption Time: 2.42824
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.65090

Cumulative Model Updates: 319,962
Cumulative Timesteps: 2,668,491,558

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.85540
Policy Entropy: 4.13903
Value Function Loss: 0.00320

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.01803
Policy Update Magnitude: 0.21440
Value Function Update Magnitude: 0.26725

Collected Steps per Second: 22,389.06188
Overall Steps per Second: 10,592.25366

Timestep Collection Time: 2.23395
Timestep Consumption Time: 2.48799
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.72194

Cumulative Model Updates: 319,968
Cumulative Timesteps: 2,668,541,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2668541574...
Checkpoint 2668541574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.12893
Policy Entropy: 4.14360
Value Function Loss: 0.00338

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.01799
Policy Update Magnitude: 0.21940
Value Function Update Magnitude: 0.25299

Collected Steps per Second: 22,559.30137
Overall Steps per Second: 10,823.07984

Timestep Collection Time: 2.21736
Timestep Consumption Time: 2.40443
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.62179

Cumulative Model Updates: 319,974
Cumulative Timesteps: 2,668,591,596

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.57406
Policy Entropy: 4.16882
Value Function Loss: 0.00273

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.01721
Policy Update Magnitude: 0.21190
Value Function Update Magnitude: 0.23697

Collected Steps per Second: 23,383.02698
Overall Steps per Second: 10,930.13002

Timestep Collection Time: 2.13873
Timestep Consumption Time: 2.43670
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.57543

Cumulative Model Updates: 319,980
Cumulative Timesteps: 2,668,641,606

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2668641606...
Checkpoint 2668641606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.72051
Policy Entropy: 4.15781
Value Function Loss: 0.00304

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.01775
Policy Update Magnitude: 0.20648
Value Function Update Magnitude: 0.23898

Collected Steps per Second: 22,503.63083
Overall Steps per Second: 10,753.84815

Timestep Collection Time: 2.22284
Timestep Consumption Time: 2.42870
PPO Batch Consumption Time: 0.27718
Total Iteration Time: 4.65154

Cumulative Model Updates: 319,986
Cumulative Timesteps: 2,668,691,628

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.89194
Policy Entropy: 4.15772
Value Function Loss: 0.00302

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01595
Policy Update Magnitude: 0.21473
Value Function Update Magnitude: 0.25525

Collected Steps per Second: 22,467.99871
Overall Steps per Second: 10,942.39148

Timestep Collection Time: 2.22628
Timestep Consumption Time: 2.34494
PPO Batch Consumption Time: 0.27691
Total Iteration Time: 4.57121

Cumulative Model Updates: 319,992
Cumulative Timesteps: 2,668,741,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2668741648...
Checkpoint 2668741648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.48017
Policy Entropy: 4.14187
Value Function Loss: 0.00317

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.01778
Policy Update Magnitude: 0.22071
Value Function Update Magnitude: 0.26325

Collected Steps per Second: 22,488.49108
Overall Steps per Second: 10,603.84335

Timestep Collection Time: 2.22443
Timestep Consumption Time: 2.49311
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.71753

Cumulative Model Updates: 319,998
Cumulative Timesteps: 2,668,791,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.39615
Policy Entropy: 4.12765
Value Function Loss: 0.00336

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.01822
Policy Update Magnitude: 0.21627
Value Function Update Magnitude: 0.27033

Collected Steps per Second: 22,632.02987
Overall Steps per Second: 10,812.03474

Timestep Collection Time: 2.20988
Timestep Consumption Time: 2.41589
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.62577

Cumulative Model Updates: 320,004
Cumulative Timesteps: 2,668,841,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2668841686...
Checkpoint 2668841686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.37636
Policy Entropy: 4.09811
Value Function Loss: 0.00343

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01944
Policy Update Magnitude: 0.22438
Value Function Update Magnitude: 0.26999

Collected Steps per Second: 22,476.59396
Overall Steps per Second: 10,742.22331

Timestep Collection Time: 2.22471
Timestep Consumption Time: 2.43019
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.65490

Cumulative Model Updates: 320,010
Cumulative Timesteps: 2,668,891,690

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.50629
Policy Entropy: 4.09420
Value Function Loss: 0.00347

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02007
Policy Update Magnitude: 0.22610
Value Function Update Magnitude: 0.26357

Collected Steps per Second: 22,624.14997
Overall Steps per Second: 10,678.69021

Timestep Collection Time: 2.21135
Timestep Consumption Time: 2.47368
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.68503

Cumulative Model Updates: 320,016
Cumulative Timesteps: 2,668,941,720

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2668941720...
Checkpoint 2668941720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.16021
Policy Entropy: 4.07781
Value Function Loss: 0.00368

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.01880
Policy Update Magnitude: 0.23057
Value Function Update Magnitude: 0.24590

Collected Steps per Second: 21,918.49712
Overall Steps per Second: 10,569.39442

Timestep Collection Time: 2.28118
Timestep Consumption Time: 2.44946
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.73064

Cumulative Model Updates: 320,022
Cumulative Timesteps: 2,668,991,720

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.34955
Policy Entropy: 4.10076
Value Function Loss: 0.00510

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.01865
Policy Update Magnitude: 0.26239
Value Function Update Magnitude: 0.26809

Collected Steps per Second: 22,810.60044
Overall Steps per Second: 10,828.86532

Timestep Collection Time: 2.19337
Timestep Consumption Time: 2.42688
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.62024

Cumulative Model Updates: 320,028
Cumulative Timesteps: 2,669,041,752

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2669041752...
Checkpoint 2669041752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.59057
Policy Entropy: 4.09149
Value Function Loss: 0.00434

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02346
Policy Update Magnitude: 0.26332
Value Function Update Magnitude: 0.30632

Collected Steps per Second: 22,425.26406
Overall Steps per Second: 10,557.99154

Timestep Collection Time: 2.23052
Timestep Consumption Time: 2.50712
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.73764

Cumulative Model Updates: 320,034
Cumulative Timesteps: 2,669,091,772

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.93640
Policy Entropy: 4.12054
Value Function Loss: 0.00386

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.01976
Policy Update Magnitude: 0.24420
Value Function Update Magnitude: 0.30339

Collected Steps per Second: 22,742.55699
Overall Steps per Second: 10,842.48958

Timestep Collection Time: 2.19879
Timestep Consumption Time: 2.41326
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.61204

Cumulative Model Updates: 320,040
Cumulative Timesteps: 2,669,141,778

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2669141778...
Checkpoint 2669141778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.51694
Policy Entropy: 4.13157
Value Function Loss: 0.00274

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.01770
Policy Update Magnitude: 0.22037
Value Function Update Magnitude: 0.27551

Collected Steps per Second: 22,953.05268
Overall Steps per Second: 10,742.66539

Timestep Collection Time: 2.17967
Timestep Consumption Time: 2.47746
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.65713

Cumulative Model Updates: 320,046
Cumulative Timesteps: 2,669,191,808

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.03706
Policy Entropy: 4.14676
Value Function Loss: 0.00270

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01645
Policy Update Magnitude: 0.20797
Value Function Update Magnitude: 0.23853

Collected Steps per Second: 22,483.94870
Overall Steps per Second: 10,642.69265

Timestep Collection Time: 2.22505
Timestep Consumption Time: 2.47564
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.70069

Cumulative Model Updates: 320,052
Cumulative Timesteps: 2,669,241,836

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2669241836...
Checkpoint 2669241836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.81651
Policy Entropy: 4.15705
Value Function Loss: 0.00280

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.01574
Policy Update Magnitude: 0.20701
Value Function Update Magnitude: 0.21526

Collected Steps per Second: 22,400.25169
Overall Steps per Second: 10,898.85572

Timestep Collection Time: 2.23256
Timestep Consumption Time: 2.35599
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.58856

Cumulative Model Updates: 320,058
Cumulative Timesteps: 2,669,291,846

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.62819
Policy Entropy: 4.14133
Value Function Loss: 0.00294

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.01649
Policy Update Magnitude: 0.20616
Value Function Update Magnitude: 0.21780

Collected Steps per Second: 22,943.35969
Overall Steps per Second: 10,855.26677

Timestep Collection Time: 2.17954
Timestep Consumption Time: 2.42707
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.60661

Cumulative Model Updates: 320,064
Cumulative Timesteps: 2,669,341,852

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2669341852...
Checkpoint 2669341852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.85889
Policy Entropy: 4.14082
Value Function Loss: 0.00271

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.01634
Policy Update Magnitude: 0.21569
Value Function Update Magnitude: 0.22687

Collected Steps per Second: 22,457.97983
Overall Steps per Second: 10,662.38205

Timestep Collection Time: 2.22763
Timestep Consumption Time: 2.46438
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.69201

Cumulative Model Updates: 320,070
Cumulative Timesteps: 2,669,391,880

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.87304
Policy Entropy: 4.13716
Value Function Loss: 0.00260

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.01786
Policy Update Magnitude: 0.21420
Value Function Update Magnitude: 0.23909

Collected Steps per Second: 22,665.51167
Overall Steps per Second: 10,915.57447

Timestep Collection Time: 2.20652
Timestep Consumption Time: 2.37519
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.58171

Cumulative Model Updates: 320,076
Cumulative Timesteps: 2,669,441,892

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2669441892...
Checkpoint 2669441892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.40686
Policy Entropy: 4.14656
Value Function Loss: 0.00256

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.01647
Policy Update Magnitude: 0.20565
Value Function Update Magnitude: 0.24616

Collected Steps per Second: 22,420.42677
Overall Steps per Second: 10,632.86267

Timestep Collection Time: 2.23011
Timestep Consumption Time: 2.47229
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.70240

Cumulative Model Updates: 320,082
Cumulative Timesteps: 2,669,491,892

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.91702
Policy Entropy: 4.15184
Value Function Loss: 0.00268

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.01688
Policy Update Magnitude: 0.20633
Value Function Update Magnitude: 0.25601

Collected Steps per Second: 22,613.46065
Overall Steps per Second: 10,720.09394

Timestep Collection Time: 2.21116
Timestep Consumption Time: 2.45316
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.66432

Cumulative Model Updates: 320,088
Cumulative Timesteps: 2,669,541,894

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2669541894...
Checkpoint 2669541894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.57849
Policy Entropy: 4.13758
Value Function Loss: 0.00295

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.01682
Policy Update Magnitude: 0.21615
Value Function Update Magnitude: 0.26552

Collected Steps per Second: 23,096.19257
Overall Steps per Second: 10,902.67598

Timestep Collection Time: 2.16616
Timestep Consumption Time: 2.42262
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.58878

Cumulative Model Updates: 320,094
Cumulative Timesteps: 2,669,591,924

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.38527
Policy Entropy: 4.14991
Value Function Loss: 0.00297

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.01951
Policy Update Magnitude: 0.22413
Value Function Update Magnitude: 0.26651

Collected Steps per Second: 22,736.31589
Overall Steps per Second: 10,804.48888

Timestep Collection Time: 2.19930
Timestep Consumption Time: 2.42878
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.62808

Cumulative Model Updates: 320,100
Cumulative Timesteps: 2,669,641,928

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2669641928...
Checkpoint 2669641928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.24170
Policy Entropy: 4.12962
Value Function Loss: 0.00383

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02133
Policy Update Magnitude: 0.23632
Value Function Update Magnitude: 0.26418

Collected Steps per Second: 22,513.15320
Overall Steps per Second: 10,723.28929

Timestep Collection Time: 2.22092
Timestep Consumption Time: 2.44182
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.66275

Cumulative Model Updates: 320,106
Cumulative Timesteps: 2,669,691,928

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.26378
Policy Entropy: 4.13318
Value Function Loss: 0.00396

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.01890
Policy Update Magnitude: 0.23964
Value Function Update Magnitude: 0.27172

Collected Steps per Second: 23,323.46672
Overall Steps per Second: 10,890.21226

Timestep Collection Time: 2.14471
Timestep Consumption Time: 2.44859
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.59330

Cumulative Model Updates: 320,112
Cumulative Timesteps: 2,669,741,950

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2669741950...
Checkpoint 2669741950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.56367
Policy Entropy: 4.13133
Value Function Loss: 0.00358

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.01974
Policy Update Magnitude: 0.22565
Value Function Update Magnitude: 0.26631

Collected Steps per Second: 22,515.29155
Overall Steps per Second: 10,630.16793

Timestep Collection Time: 2.22080
Timestep Consumption Time: 2.48298
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.70378

Cumulative Model Updates: 320,118
Cumulative Timesteps: 2,669,791,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.02757
Policy Entropy: 4.15870
Value Function Loss: 0.00274

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01717
Policy Update Magnitude: 0.20876
Value Function Update Magnitude: 0.25502

Collected Steps per Second: 22,311.19360
Overall Steps per Second: 10,873.54224

Timestep Collection Time: 2.24174
Timestep Consumption Time: 2.35804
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.59979

Cumulative Model Updates: 320,124
Cumulative Timesteps: 2,669,841,968

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2669841968...
Checkpoint 2669841968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.79467
Policy Entropy: 4.16018
Value Function Loss: 0.00268

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.01582
Policy Update Magnitude: 0.22073
Value Function Update Magnitude: 0.24187

Collected Steps per Second: 22,670.89055
Overall Steps per Second: 10,704.91275

Timestep Collection Time: 2.20609
Timestep Consumption Time: 2.46597
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.67206

Cumulative Model Updates: 320,130
Cumulative Timesteps: 2,669,891,982

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.09240
Policy Entropy: 4.12088
Value Function Loss: 0.00326

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.01872
Policy Update Magnitude: 0.22333
Value Function Update Magnitude: 0.24197

Collected Steps per Second: 22,454.21318
Overall Steps per Second: 10,773.14039

Timestep Collection Time: 2.22764
Timestep Consumption Time: 2.41538
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.64303

Cumulative Model Updates: 320,136
Cumulative Timesteps: 2,669,942,002

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2669942002...
Checkpoint 2669942002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.79799
Policy Entropy: 4.10219
Value Function Loss: 0.00380

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02006
Policy Update Magnitude: 0.23420
Value Function Update Magnitude: 0.25583

Collected Steps per Second: 23,337.37863
Overall Steps per Second: 10,764.84875

Timestep Collection Time: 2.14249
Timestep Consumption Time: 2.50226
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.64475

Cumulative Model Updates: 320,142
Cumulative Timesteps: 2,669,992,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.42304
Policy Entropy: 4.08754
Value Function Loss: 0.00413

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02244
Policy Update Magnitude: 0.24503
Value Function Update Magnitude: 0.26782

Collected Steps per Second: 22,579.46427
Overall Steps per Second: 10,638.52214

Timestep Collection Time: 2.21484
Timestep Consumption Time: 2.48600
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.70084

Cumulative Model Updates: 320,148
Cumulative Timesteps: 2,670,042,012

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2670042012...
Checkpoint 2670042012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.48963
Policy Entropy: 4.09657
Value Function Loss: 0.00394

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02298
Policy Update Magnitude: 0.24963
Value Function Update Magnitude: 0.27655

Collected Steps per Second: 22,665.23778
Overall Steps per Second: 10,827.79375

Timestep Collection Time: 2.20620
Timestep Consumption Time: 2.41192
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.61812

Cumulative Model Updates: 320,154
Cumulative Timesteps: 2,670,092,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.00506
Policy Entropy: 4.09677
Value Function Loss: 0.00405

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.02358
Policy Update Magnitude: 0.24969
Value Function Update Magnitude: 0.28359

Collected Steps per Second: 23,360.86468
Overall Steps per Second: 10,857.95896

Timestep Collection Time: 2.14076
Timestep Consumption Time: 2.46508
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.60584

Cumulative Model Updates: 320,160
Cumulative Timesteps: 2,670,142,026

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2670142026...
Checkpoint 2670142026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.89738
Policy Entropy: 4.09165
Value Function Loss: 0.00377

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.02381
Policy Update Magnitude: 0.24268
Value Function Update Magnitude: 0.28226

Collected Steps per Second: 22,270.67695
Overall Steps per Second: 10,686.23931

Timestep Collection Time: 2.24654
Timestep Consumption Time: 2.43537
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.68191

Cumulative Model Updates: 320,166
Cumulative Timesteps: 2,670,192,058

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.70022
Policy Entropy: 4.11094
Value Function Loss: 0.00344

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02113
Policy Update Magnitude: 0.23228
Value Function Update Magnitude: 0.27121

Collected Steps per Second: 22,243.33817
Overall Steps per Second: 10,564.27666

Timestep Collection Time: 2.24885
Timestep Consumption Time: 2.48616
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.73501

Cumulative Model Updates: 320,172
Cumulative Timesteps: 2,670,242,080

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2670242080...
Checkpoint 2670242080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.90970
Policy Entropy: 4.12480
Value Function Loss: 0.00316

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02076
Policy Update Magnitude: 0.22986
Value Function Update Magnitude: 0.25362

Collected Steps per Second: 23,486.55776
Overall Steps per Second: 10,972.66677

Timestep Collection Time: 2.12947
Timestep Consumption Time: 2.42858
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.55805

Cumulative Model Updates: 320,178
Cumulative Timesteps: 2,670,292,094

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.89913
Policy Entropy: 4.17250
Value Function Loss: 0.00225

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.01681
Policy Update Magnitude: 0.21035
Value Function Update Magnitude: 0.23745

Collected Steps per Second: 22,698.20420
Overall Steps per Second: 10,629.93243

Timestep Collection Time: 2.20326
Timestep Consumption Time: 2.50138
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.70464

Cumulative Model Updates: 320,184
Cumulative Timesteps: 2,670,342,104

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2670342104...
Checkpoint 2670342104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.55682
Policy Entropy: 4.16615
Value Function Loss: 0.00212

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.01428
Policy Update Magnitude: 0.19259
Value Function Update Magnitude: 0.22153

Collected Steps per Second: 22,595.99865
Overall Steps per Second: 10,934.27651

Timestep Collection Time: 2.21314
Timestep Consumption Time: 2.36037
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.57351

Cumulative Model Updates: 320,190
Cumulative Timesteps: 2,670,392,112

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.77986
Policy Entropy: 4.17463
Value Function Loss: 0.00165

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01400
Policy Update Magnitude: 0.18751
Value Function Update Magnitude: 0.20783

Collected Steps per Second: 22,620.07007
Overall Steps per Second: 10,631.87685

Timestep Collection Time: 2.21096
Timestep Consumption Time: 2.49301
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.70397

Cumulative Model Updates: 320,196
Cumulative Timesteps: 2,670,442,124

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2670442124...
Checkpoint 2670442124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.99661
Policy Entropy: 4.14826
Value Function Loss: 0.00197

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.01614
Policy Update Magnitude: 0.18585
Value Function Update Magnitude: 0.21413

Collected Steps per Second: 22,343.72263
Overall Steps per Second: 10,603.96970

Timestep Collection Time: 2.23794
Timestep Consumption Time: 2.47765
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.71559

Cumulative Model Updates: 320,202
Cumulative Timesteps: 2,670,492,128

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.80363
Policy Entropy: 4.15824
Value Function Loss: 0.00278

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.01548
Policy Update Magnitude: 0.20121
Value Function Update Magnitude: 0.23267

Collected Steps per Second: 22,666.03428
Overall Steps per Second: 10,859.88649

Timestep Collection Time: 2.20665
Timestep Consumption Time: 2.39892
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.60557

Cumulative Model Updates: 320,208
Cumulative Timesteps: 2,670,542,144

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2670542144...
Checkpoint 2670542144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.78144
Policy Entropy: 4.15870
Value Function Loss: 0.00322

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01887
Policy Update Magnitude: 0.21779
Value Function Update Magnitude: 0.29092

Collected Steps per Second: 22,450.87037
Overall Steps per Second: 10,640.92451

Timestep Collection Time: 2.22735
Timestep Consumption Time: 2.47205
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.69940

Cumulative Model Updates: 320,214
Cumulative Timesteps: 2,670,592,150

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.23612
Policy Entropy: 4.16846
Value Function Loss: 0.00337

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.01888
Policy Update Magnitude: 0.21907
Value Function Update Magnitude: 0.29867

Collected Steps per Second: 22,501.92439
Overall Steps per Second: 10,822.63660

Timestep Collection Time: 2.22239
Timestep Consumption Time: 2.39830
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.62069

Cumulative Model Updates: 320,220
Cumulative Timesteps: 2,670,642,158

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2670642158...
Checkpoint 2670642158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.98401
Policy Entropy: 4.14515
Value Function Loss: 0.00351

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.01741
Policy Update Magnitude: 0.22469
Value Function Update Magnitude: 0.26573

Collected Steps per Second: 23,180.44321
Overall Steps per Second: 10,748.39967

Timestep Collection Time: 2.15734
Timestep Consumption Time: 2.49526
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.65260

Cumulative Model Updates: 320,226
Cumulative Timesteps: 2,670,692,166

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.79976
Policy Entropy: 4.14704
Value Function Loss: 0.00351

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02151
Policy Update Magnitude: 0.23390
Value Function Update Magnitude: 0.26370

Collected Steps per Second: 22,928.08752
Overall Steps per Second: 10,813.40772

Timestep Collection Time: 2.18108
Timestep Consumption Time: 2.44355
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.62463

Cumulative Model Updates: 320,232
Cumulative Timesteps: 2,670,742,174

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2670742174...
Checkpoint 2670742174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.19010
Policy Entropy: 4.14901
Value Function Loss: 0.00283

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02088
Policy Update Magnitude: 0.21901
Value Function Update Magnitude: 0.24715

Collected Steps per Second: 22,207.09510
Overall Steps per Second: 10,723.97715

Timestep Collection Time: 2.25261
Timestep Consumption Time: 2.41207
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.66469

Cumulative Model Updates: 320,238
Cumulative Timesteps: 2,670,792,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.80649
Policy Entropy: 4.15014
Value Function Loss: 0.00312

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01746
Policy Update Magnitude: 0.21684
Value Function Update Magnitude: 0.24269

Collected Steps per Second: 23,312.56103
Overall Steps per Second: 10,945.61185

Timestep Collection Time: 2.14571
Timestep Consumption Time: 2.42434
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.57005

Cumulative Model Updates: 320,244
Cumulative Timesteps: 2,670,842,220

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2670842220...
Checkpoint 2670842220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.02389
Policy Entropy: 4.09747
Value Function Loss: 0.00320

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.01854
Policy Update Magnitude: 0.23323
Value Function Update Magnitude: 0.26076

Collected Steps per Second: 22,504.94684
Overall Steps per Second: 10,574.59262

Timestep Collection Time: 2.22218
Timestep Consumption Time: 2.50708
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.72926

Cumulative Model Updates: 320,250
Cumulative Timesteps: 2,670,892,230

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.75077
Policy Entropy: 4.10780
Value Function Loss: 0.00348

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02021
Policy Update Magnitude: 0.23592
Value Function Update Magnitude: 0.28270

Collected Steps per Second: 22,601.78419
Overall Steps per Second: 10,913.10971

Timestep Collection Time: 2.21248
Timestep Consumption Time: 2.36972
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.58220

Cumulative Model Updates: 320,256
Cumulative Timesteps: 2,670,942,236

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2670942236...
Checkpoint 2670942236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.78887
Policy Entropy: 4.13534
Value Function Loss: 0.00306

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02155
Policy Update Magnitude: 0.23316
Value Function Update Magnitude: 0.28285

Collected Steps per Second: 22,575.90508
Overall Steps per Second: 10,629.45605

Timestep Collection Time: 2.21590
Timestep Consumption Time: 2.49045
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.70636

Cumulative Model Updates: 320,262
Cumulative Timesteps: 2,670,992,262

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.52567
Policy Entropy: 4.13908
Value Function Loss: 0.00375

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.01941
Policy Update Magnitude: 0.24018
Value Function Update Magnitude: 0.27109

Collected Steps per Second: 22,456.42536
Overall Steps per Second: 10,680.64108

Timestep Collection Time: 2.22778
Timestep Consumption Time: 2.45621
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.68399

Cumulative Model Updates: 320,268
Cumulative Timesteps: 2,671,042,290

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2671042290...
Checkpoint 2671042290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.43785
Policy Entropy: 4.14463
Value Function Loss: 0.00313

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02384
Policy Update Magnitude: 0.23845
Value Function Update Magnitude: 0.27515

Collected Steps per Second: 23,473.81045
Overall Steps per Second: 10,942.93856

Timestep Collection Time: 2.13080
Timestep Consumption Time: 2.44000
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.57080

Cumulative Model Updates: 320,274
Cumulative Timesteps: 2,671,092,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.69760
Policy Entropy: 4.13024
Value Function Loss: 0.00385

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02209
Policy Update Magnitude: 0.22942
Value Function Update Magnitude: 0.27328

Collected Steps per Second: 22,728.88842
Overall Steps per Second: 10,776.25453

Timestep Collection Time: 2.20002
Timestep Consumption Time: 2.44018
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.64020

Cumulative Model Updates: 320,280
Cumulative Timesteps: 2,671,142,312

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2671142312...
Checkpoint 2671142312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.32970
Policy Entropy: 4.14308
Value Function Loss: 0.00331

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.01773
Policy Update Magnitude: 0.23407
Value Function Update Magnitude: 0.27307

Collected Steps per Second: 22,361.03910
Overall Steps per Second: 10,716.09211

Timestep Collection Time: 2.23702
Timestep Consumption Time: 2.43092
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.66793

Cumulative Model Updates: 320,286
Cumulative Timesteps: 2,671,192,334

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.81719
Policy Entropy: 4.10978
Value Function Loss: 0.00399

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.01958
Policy Update Magnitude: 0.24729
Value Function Update Magnitude: 0.27606

Collected Steps per Second: 22,694.33253
Overall Steps per Second: 10,706.18191

Timestep Collection Time: 2.20434
Timestep Consumption Time: 2.46829
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.67263

Cumulative Model Updates: 320,292
Cumulative Timesteps: 2,671,242,360

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2671242360...
Checkpoint 2671242360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.99368
Policy Entropy: 4.11059
Value Function Loss: 0.00340

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02238
Policy Update Magnitude: 0.24486
Value Function Update Magnitude: 0.28945

Collected Steps per Second: 22,565.81357
Overall Steps per Second: 10,835.34342

Timestep Collection Time: 2.21672
Timestep Consumption Time: 2.39984
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.61656

Cumulative Model Updates: 320,298
Cumulative Timesteps: 2,671,292,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.98855
Policy Entropy: 4.13144
Value Function Loss: 0.00291

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02195
Policy Update Magnitude: 0.23360
Value Function Update Magnitude: 0.28936

Collected Steps per Second: 23,419.11385
Overall Steps per Second: 10,928.64421

Timestep Collection Time: 2.13612
Timestep Consumption Time: 2.44139
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.57751

Cumulative Model Updates: 320,304
Cumulative Timesteps: 2,671,342,408

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2671342408...
Checkpoint 2671342408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.90790
Policy Entropy: 4.10854
Value Function Loss: 0.00349

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.01999
Policy Update Magnitude: 0.23474
Value Function Update Magnitude: 0.27186

Collected Steps per Second: 22,464.62080
Overall Steps per Second: 10,693.51403

Timestep Collection Time: 2.22706
Timestep Consumption Time: 2.45148
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.67854

Cumulative Model Updates: 320,310
Cumulative Timesteps: 2,671,392,438

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.07945
Policy Entropy: 4.10805
Value Function Loss: 0.00354

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02330
Policy Update Magnitude: 0.22920
Value Function Update Magnitude: 0.26268

Collected Steps per Second: 22,328.86929
Overall Steps per Second: 10,605.07728

Timestep Collection Time: 2.24033
Timestep Consumption Time: 2.47666
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.71699

Cumulative Model Updates: 320,316
Cumulative Timesteps: 2,671,442,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2671442462...
Checkpoint 2671442462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.41335
Policy Entropy: 4.12116
Value Function Loss: 0.00344

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02381
Policy Update Magnitude: 0.23216
Value Function Update Magnitude: 0.27113

Collected Steps per Second: 23,327.63331
Overall Steps per Second: 10,928.76143

Timestep Collection Time: 2.14450
Timestep Consumption Time: 2.43297
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.57746

Cumulative Model Updates: 320,322
Cumulative Timesteps: 2,671,492,488

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.52991
Policy Entropy: 4.14328
Value Function Loss: 0.00247

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.01833
Policy Update Magnitude: 0.21022
Value Function Update Magnitude: 0.26696

Collected Steps per Second: 22,467.98364
Overall Steps per Second: 10,611.22372

Timestep Collection Time: 2.22574
Timestep Consumption Time: 2.48700
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.71275

Cumulative Model Updates: 320,328
Cumulative Timesteps: 2,671,542,496

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2671542496...
Checkpoint 2671542496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.07151
Policy Entropy: 4.13259
Value Function Loss: 0.00291

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.01719
Policy Update Magnitude: 0.21907
Value Function Update Magnitude: 0.24994

Collected Steps per Second: 22,621.05699
Overall Steps per Second: 10,992.06762

Timestep Collection Time: 2.21060
Timestep Consumption Time: 2.33869
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.54928

Cumulative Model Updates: 320,334
Cumulative Timesteps: 2,671,592,502

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.18235
Policy Entropy: 4.12296
Value Function Loss: 0.00309

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.01742
Policy Update Magnitude: 0.23485
Value Function Update Magnitude: 0.25515

Collected Steps per Second: 22,616.75207
Overall Steps per Second: 10,650.50535

Timestep Collection Time: 2.21199
Timestep Consumption Time: 2.48525
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.69724

Cumulative Model Updates: 320,340
Cumulative Timesteps: 2,671,642,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2671642530...
Checkpoint 2671642530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.86101
Policy Entropy: 4.10354
Value Function Loss: 0.00324

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02123
Policy Update Magnitude: 0.23350
Value Function Update Magnitude: 0.26192

Collected Steps per Second: 22,457.07722
Overall Steps per Second: 10,794.37586

Timestep Collection Time: 2.22736
Timestep Consumption Time: 2.40653
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.63389

Cumulative Model Updates: 320,346
Cumulative Timesteps: 2,671,692,550

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.45454
Policy Entropy: 4.13404
Value Function Loss: 0.00300

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01861
Policy Update Magnitude: 0.22388
Value Function Update Magnitude: 0.26622

Collected Steps per Second: 22,704.44670
Overall Steps per Second: 10,926.71136

Timestep Collection Time: 2.20283
Timestep Consumption Time: 2.37440
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.57722

Cumulative Model Updates: 320,352
Cumulative Timesteps: 2,671,742,564

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2671742564...
Checkpoint 2671742564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.65870
Policy Entropy: 4.13806
Value Function Loss: 0.00249

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.01941
Policy Update Magnitude: 0.21900
Value Function Update Magnitude: 0.26169

Collected Steps per Second: 22,547.97633
Overall Steps per Second: 10,719.57505

Timestep Collection Time: 2.21785
Timestep Consumption Time: 2.44726
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.66511

Cumulative Model Updates: 320,358
Cumulative Timesteps: 2,671,792,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.93078
Policy Entropy: 4.14432
Value Function Loss: 0.00307

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.01898
Policy Update Magnitude: 0.23396
Value Function Update Magnitude: 0.26045

Collected Steps per Second: 22,385.25486
Overall Steps per Second: 10,611.08236

Timestep Collection Time: 2.23388
Timestep Consumption Time: 2.47874
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.71262

Cumulative Model Updates: 320,364
Cumulative Timesteps: 2,671,842,578

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2671842578...
Checkpoint 2671842578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.68380
Policy Entropy: 4.15205
Value Function Loss: 0.00305

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02059
Policy Update Magnitude: 0.22983
Value Function Update Magnitude: 0.27135

Collected Steps per Second: 23,438.01984
Overall Steps per Second: 10,943.44518

Timestep Collection Time: 2.13405
Timestep Consumption Time: 2.43654
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.57059

Cumulative Model Updates: 320,370
Cumulative Timesteps: 2,671,892,596

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.29968
Policy Entropy: 4.12643
Value Function Loss: 0.00369

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02204
Policy Update Magnitude: 0.23746
Value Function Update Magnitude: 0.27844

Collected Steps per Second: 22,596.67408
Overall Steps per Second: 10,672.48042

Timestep Collection Time: 2.21360
Timestep Consumption Time: 2.47322
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.68682

Cumulative Model Updates: 320,376
Cumulative Timesteps: 2,671,942,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2671942616...
Checkpoint 2671942616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.86289
Policy Entropy: 4.15617
Value Function Loss: 0.00352

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02070
Policy Update Magnitude: 0.25088
Value Function Update Magnitude: 0.27586

Collected Steps per Second: 22,483.85218
Overall Steps per Second: 10,918.06486

Timestep Collection Time: 2.22497
Timestep Consumption Time: 2.35697
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.58195

Cumulative Model Updates: 320,382
Cumulative Timesteps: 2,671,992,642

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.76121
Policy Entropy: 4.15817
Value Function Loss: 0.00264

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.02384
Policy Update Magnitude: 0.22763
Value Function Update Magnitude: 0.27233

Collected Steps per Second: 22,725.47518
Overall Steps per Second: 10,796.53426

Timestep Collection Time: 2.20123
Timestep Consumption Time: 2.43211
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.63334

Cumulative Model Updates: 320,388
Cumulative Timesteps: 2,672,042,666

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2672042666...
Checkpoint 2672042666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.13765
Policy Entropy: 4.18225
Value Function Loss: 0.00246

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.01674
Policy Update Magnitude: 0.21288
Value Function Update Magnitude: 0.25673

Collected Steps per Second: 22,190.36717
Overall Steps per Second: 10,727.23258

Timestep Collection Time: 2.25368
Timestep Consumption Time: 2.40829
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.66197

Cumulative Model Updates: 320,394
Cumulative Timesteps: 2,672,092,676

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.37753
Policy Entropy: 4.16610
Value Function Loss: 0.00242

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01623
Policy Update Magnitude: 0.20971
Value Function Update Magnitude: 0.25275

Collected Steps per Second: 22,940.60746
Overall Steps per Second: 10,829.75924

Timestep Collection Time: 2.18067
Timestep Consumption Time: 2.43863
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.61931

Cumulative Model Updates: 320,400
Cumulative Timesteps: 2,672,142,702

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2672142702...
Checkpoint 2672142702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.94483
Policy Entropy: 4.15055
Value Function Loss: 0.00301

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.01836
Policy Update Magnitude: 0.21669
Value Function Update Magnitude: 0.25287

Collected Steps per Second: 22,021.08293
Overall Steps per Second: 10,643.71091

Timestep Collection Time: 2.27191
Timestep Consumption Time: 2.42851
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.70043

Cumulative Model Updates: 320,406
Cumulative Timesteps: 2,672,192,732

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.92157
Policy Entropy: 4.16174
Value Function Loss: 0.00294

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.01959
Policy Update Magnitude: 0.22032
Value Function Update Magnitude: 0.26878

Collected Steps per Second: 22,486.87093
Overall Steps per Second: 10,609.07991

Timestep Collection Time: 2.22379
Timestep Consumption Time: 2.48972
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.71351

Cumulative Model Updates: 320,412
Cumulative Timesteps: 2,672,242,738

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2672242738...
Checkpoint 2672242738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.52864
Policy Entropy: 4.17382
Value Function Loss: 0.00361

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.01847
Policy Update Magnitude: 0.23379
Value Function Update Magnitude: 0.28041

Collected Steps per Second: 23,096.18357
Overall Steps per Second: 10,781.30252

Timestep Collection Time: 2.16529
Timestep Consumption Time: 2.47329
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.63859

Cumulative Model Updates: 320,418
Cumulative Timesteps: 2,672,292,748

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.31049
Policy Entropy: 4.17077
Value Function Loss: 0.00333

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.01728
Policy Update Magnitude: 0.23399
Value Function Update Magnitude: 0.30246

Collected Steps per Second: 22,860.28835
Overall Steps per Second: 10,740.43025

Timestep Collection Time: 2.18799
Timestep Consumption Time: 2.46900
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.65698

Cumulative Model Updates: 320,424
Cumulative Timesteps: 2,672,342,766

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2672342766...
Checkpoint 2672342766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.37156
Policy Entropy: 4.13707
Value Function Loss: 0.00340

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.01781
Policy Update Magnitude: 0.24104
Value Function Update Magnitude: 0.30007

Collected Steps per Second: 22,576.08847
Overall Steps per Second: 10,842.72786

Timestep Collection Time: 2.21588
Timestep Consumption Time: 2.39790
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.61378

Cumulative Model Updates: 320,430
Cumulative Timesteps: 2,672,392,792

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.07255
Policy Entropy: 4.14012
Value Function Loss: 0.00263

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02293
Policy Update Magnitude: 0.23758
Value Function Update Magnitude: 0.28351

Collected Steps per Second: 22,570.10376
Overall Steps per Second: 10,690.64381

Timestep Collection Time: 2.21532
Timestep Consumption Time: 2.46167
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.67699

Cumulative Model Updates: 320,436
Cumulative Timesteps: 2,672,442,792

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2672442792...
Checkpoint 2672442792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.56904
Policy Entropy: 4.15079
Value Function Loss: 0.00260

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02077
Policy Update Magnitude: 0.22383
Value Function Update Magnitude: 0.25673

Collected Steps per Second: 22,510.79368
Overall Steps per Second: 10,600.17185

Timestep Collection Time: 2.22213
Timestep Consumption Time: 2.49685
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.71898

Cumulative Model Updates: 320,442
Cumulative Timesteps: 2,672,492,814

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.18529
Policy Entropy: 4.18391
Value Function Loss: 0.00278

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.01633
Policy Update Magnitude: 0.20902
Value Function Update Magnitude: 0.24456

Collected Steps per Second: 23,619.41212
Overall Steps per Second: 10,999.55008

Timestep Collection Time: 2.11766
Timestep Consumption Time: 2.42961
PPO Batch Consumption Time: 0.27655
Total Iteration Time: 4.54728

Cumulative Model Updates: 320,448
Cumulative Timesteps: 2,672,542,832

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2672542832...
Checkpoint 2672542832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.68460
Policy Entropy: 4.17783
Value Function Loss: 0.00294

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.01736
Policy Update Magnitude: 0.20733
Value Function Update Magnitude: 0.25901

Collected Steps per Second: 22,493.87909
Overall Steps per Second: 10,568.05917

Timestep Collection Time: 2.22336
Timestep Consumption Time: 2.50901
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.73237

Cumulative Model Updates: 320,454
Cumulative Timesteps: 2,672,592,844

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.82473
Policy Entropy: 4.15218
Value Function Loss: 0.00276

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.01860
Policy Update Magnitude: 0.21532
Value Function Update Magnitude: 0.26847

Collected Steps per Second: 22,453.02886
Overall Steps per Second: 10,912.78554

Timestep Collection Time: 2.22812
Timestep Consumption Time: 2.35623
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.58435

Cumulative Model Updates: 320,460
Cumulative Timesteps: 2,672,642,872

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2672642872...
Checkpoint 2672642872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.73625
Policy Entropy: 4.13730
Value Function Loss: 0.00291

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.01855
Policy Update Magnitude: 0.22963
Value Function Update Magnitude: 0.26888

Collected Steps per Second: 22,757.04518
Overall Steps per Second: 10,682.59214

Timestep Collection Time: 2.19826
Timestep Consumption Time: 2.48468
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.68295

Cumulative Model Updates: 320,466
Cumulative Timesteps: 2,672,692,898

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.16592
Policy Entropy: 4.11095
Value Function Loss: 0.00322

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.02237
Policy Update Magnitude: 0.23912
Value Function Update Magnitude: 0.27924

Collected Steps per Second: 22,371.08250
Overall Steps per Second: 10,676.68382

Timestep Collection Time: 2.23592
Timestep Consumption Time: 2.44905
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.68498

Cumulative Model Updates: 320,472
Cumulative Timesteps: 2,672,742,918

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2672742918...
Checkpoint 2672742918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.79543
Policy Entropy: 4.07957
Value Function Loss: 0.00437

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.02451
Policy Update Magnitude: 0.25975
Value Function Update Magnitude: 0.30656

Collected Steps per Second: 22,210.67913
Overall Steps per Second: 10,813.08718

Timestep Collection Time: 2.25243
Timestep Consumption Time: 2.37419
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.62662

Cumulative Model Updates: 320,478
Cumulative Timesteps: 2,672,792,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.17073
Policy Entropy: 4.07942
Value Function Loss: 0.00411

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.02827
Policy Update Magnitude: 0.26271
Value Function Update Magnitude: 0.32376

Collected Steps per Second: 22,657.61123
Overall Steps per Second: 10,635.26158

Timestep Collection Time: 2.20756
Timestep Consumption Time: 2.49548
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.70303

Cumulative Model Updates: 320,484
Cumulative Timesteps: 2,672,842,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2672842964...
Checkpoint 2672842964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.65104
Policy Entropy: 4.08334
Value Function Loss: 0.00415

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.02770
Policy Update Magnitude: 0.26025
Value Function Update Magnitude: 0.32067

Collected Steps per Second: 22,370.60329
Overall Steps per Second: 10,664.83960

Timestep Collection Time: 2.23606
Timestep Consumption Time: 2.45431
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.69037

Cumulative Model Updates: 320,490
Cumulative Timesteps: 2,672,892,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.77568
Policy Entropy: 4.13330
Value Function Loss: 0.00290

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02352
Policy Update Magnitude: 0.23935
Value Function Update Magnitude: 0.30123

Collected Steps per Second: 20,546.96075
Overall Steps per Second: 10,070.42939

Timestep Collection Time: 2.43442
Timestep Consumption Time: 2.53259
PPO Batch Consumption Time: 0.29927
Total Iteration Time: 4.96702

Cumulative Model Updates: 320,496
Cumulative Timesteps: 2,672,943,006

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2672943006...
Checkpoint 2672943006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.16823
Policy Entropy: 4.14654
Value Function Loss: 0.00289

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02169
Policy Update Magnitude: 0.22963
Value Function Update Magnitude: 0.29463

Collected Steps per Second: 15,852.91619
Overall Steps per Second: 8,455.34257

Timestep Collection Time: 3.15412
Timestep Consumption Time: 2.75954
PPO Batch Consumption Time: 0.31975
Total Iteration Time: 5.91366

Cumulative Model Updates: 320,502
Cumulative Timesteps: 2,672,993,008

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.31419
Policy Entropy: 4.16346
Value Function Loss: 0.00271

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.01885
Policy Update Magnitude: 0.21931
Value Function Update Magnitude: 0.27004

Collected Steps per Second: 19,157.00006
Overall Steps per Second: 9,638.18490

Timestep Collection Time: 2.61033
Timestep Consumption Time: 2.57800
PPO Batch Consumption Time: 0.29944
Total Iteration Time: 5.18832

Cumulative Model Updates: 320,508
Cumulative Timesteps: 2,673,043,014

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2673043014...
Checkpoint 2673043014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.98419
Policy Entropy: 4.17778
Value Function Loss: 0.00265

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.01688
Policy Update Magnitude: 0.21383
Value Function Update Magnitude: 0.25941

Collected Steps per Second: 20,183.76147
Overall Steps per Second: 8,815.85691

Timestep Collection Time: 2.47863
Timestep Consumption Time: 3.19615
PPO Batch Consumption Time: 0.38767
Total Iteration Time: 5.67477

Cumulative Model Updates: 320,514
Cumulative Timesteps: 2,673,093,042

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.88758
Policy Entropy: 4.14186
Value Function Loss: 0.00312

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.01920
Policy Update Magnitude: 0.22724
Value Function Update Magnitude: 0.25922

Collected Steps per Second: 21,562.23836
Overall Steps per Second: 10,318.89052

Timestep Collection Time: 2.31952
Timestep Consumption Time: 2.52732
PPO Batch Consumption Time: 0.29816
Total Iteration Time: 4.84684

Cumulative Model Updates: 320,520
Cumulative Timesteps: 2,673,143,056

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2673143056...
Checkpoint 2673143056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.14044
Policy Entropy: 4.14382
Value Function Loss: 0.00306

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.01949
Policy Update Magnitude: 0.24159
Value Function Update Magnitude: 0.26500

Collected Steps per Second: 22,607.96018
Overall Steps per Second: 10,608.58409

Timestep Collection Time: 2.21188
Timestep Consumption Time: 2.50185
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.71373

Cumulative Model Updates: 320,526
Cumulative Timesteps: 2,673,193,062

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.62365
Policy Entropy: 4.12169
Value Function Loss: 0.00326

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.02258
Policy Update Magnitude: 0.23848
Value Function Update Magnitude: 0.28838

Collected Steps per Second: 21,498.39783
Overall Steps per Second: 10,350.00961

Timestep Collection Time: 2.32603
Timestep Consumption Time: 2.50546
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.83149

Cumulative Model Updates: 320,532
Cumulative Timesteps: 2,673,243,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2673243068...
Checkpoint 2673243068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.31013
Policy Entropy: 4.14469
Value Function Loss: 0.00286

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02022
Policy Update Magnitude: 0.23605
Value Function Update Magnitude: 0.30201

Collected Steps per Second: 21,548.15426
Overall Steps per Second: 10,295.88151

Timestep Collection Time: 2.32066
Timestep Consumption Time: 2.53623
PPO Batch Consumption Time: 0.29847
Total Iteration Time: 4.85689

Cumulative Model Updates: 320,538
Cumulative Timesteps: 2,673,293,074

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.99975
Policy Entropy: 4.15037
Value Function Loss: 0.00297

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02089
Policy Update Magnitude: 0.24095
Value Function Update Magnitude: 0.29993

Collected Steps per Second: 22,706.62848
Overall Steps per Second: 10,507.77464

Timestep Collection Time: 2.20235
Timestep Consumption Time: 2.55679
PPO Batch Consumption Time: 0.29784
Total Iteration Time: 4.75914

Cumulative Model Updates: 320,544
Cumulative Timesteps: 2,673,343,082

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2673343082...
Checkpoint 2673343082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.71183
Policy Entropy: 4.17312
Value Function Loss: 0.00301

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02066
Policy Update Magnitude: 0.23137
Value Function Update Magnitude: 0.27898

Collected Steps per Second: 21,316.08478
Overall Steps per Second: 10,178.14604

Timestep Collection Time: 2.34668
Timestep Consumption Time: 2.56797
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 4.91465

Cumulative Model Updates: 320,550
Cumulative Timesteps: 2,673,393,104

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.70581
Policy Entropy: 4.15328
Value Function Loss: 0.00255

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02067
Policy Update Magnitude: 0.21805
Value Function Update Magnitude: 0.26841

Collected Steps per Second: 21,708.81118
Overall Steps per Second: 10,451.98492

Timestep Collection Time: 2.30367
Timestep Consumption Time: 2.48106
PPO Batch Consumption Time: 0.29866
Total Iteration Time: 4.78474

Cumulative Model Updates: 320,556
Cumulative Timesteps: 2,673,443,114

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2673443114...
Checkpoint 2673443114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.85152
Policy Entropy: 4.14236
Value Function Loss: 0.00293

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.01940
Policy Update Magnitude: 0.22577
Value Function Update Magnitude: 0.24844

Collected Steps per Second: 21,576.18575
Overall Steps per Second: 10,280.55392

Timestep Collection Time: 2.31811
Timestep Consumption Time: 2.54700
PPO Batch Consumption Time: 0.29710
Total Iteration Time: 4.86511

Cumulative Model Updates: 320,562
Cumulative Timesteps: 2,673,493,130

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.48260
Policy Entropy: 4.12310
Value Function Loss: 0.00294

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02229
Policy Update Magnitude: 0.23117
Value Function Update Magnitude: 0.25102

Collected Steps per Second: 22,048.63854
Overall Steps per Second: 10,433.79559

Timestep Collection Time: 2.26862
Timestep Consumption Time: 2.52542
PPO Batch Consumption Time: 0.29769
Total Iteration Time: 4.79404

Cumulative Model Updates: 320,568
Cumulative Timesteps: 2,673,543,150

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2673543150...
Checkpoint 2673543150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.56228
Policy Entropy: 4.14449
Value Function Loss: 0.00305

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.01911
Policy Update Magnitude: 0.24388
Value Function Update Magnitude: 0.25868

Collected Steps per Second: 21,609.76267
Overall Steps per Second: 10,563.39308

Timestep Collection Time: 2.31405
Timestep Consumption Time: 2.41985
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.73390

Cumulative Model Updates: 320,574
Cumulative Timesteps: 2,673,593,156

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.49587
Policy Entropy: 4.15298
Value Function Loss: 0.00284

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02130
Policy Update Magnitude: 0.23867
Value Function Update Magnitude: 0.27071

Collected Steps per Second: 22,112.38656
Overall Steps per Second: 10,495.16038

Timestep Collection Time: 2.26271
Timestep Consumption Time: 2.50463
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.76734

Cumulative Model Updates: 320,580
Cumulative Timesteps: 2,673,643,190

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2673643190...
Checkpoint 2673643190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.28554
Policy Entropy: 4.15490
Value Function Loss: 0.00319

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.01841
Policy Update Magnitude: 0.23480
Value Function Update Magnitude: 0.27901

Collected Steps per Second: 21,525.09508
Overall Steps per Second: 10,365.31862

Timestep Collection Time: 2.32343
Timestep Consumption Time: 2.50151
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.82494

Cumulative Model Updates: 320,586
Cumulative Timesteps: 2,673,693,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.22347
Policy Entropy: 4.14349
Value Function Loss: 0.00349

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.01853
Policy Update Magnitude: 0.23874
Value Function Update Magnitude: 0.29759

Collected Steps per Second: 22,752.82417
Overall Steps per Second: 10,685.15878

Timestep Collection Time: 2.19771
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.67976

Cumulative Model Updates: 320,592
Cumulative Timesteps: 2,673,743,206

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2673743206...
Checkpoint 2673743206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.68324
Policy Entropy: 4.11555
Value Function Loss: 0.00373

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.02156
Policy Update Magnitude: 0.25054
Value Function Update Magnitude: 0.29114

Collected Steps per Second: 21,442.25511
Overall Steps per Second: 10,266.41063

Timestep Collection Time: 2.33250
Timestep Consumption Time: 2.53912
PPO Batch Consumption Time: 0.29739
Total Iteration Time: 4.87162

Cumulative Model Updates: 320,598
Cumulative Timesteps: 2,673,793,220

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.29117
Policy Entropy: 4.13180
Value Function Loss: 0.00362

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02208
Policy Update Magnitude: 0.25167
Value Function Update Magnitude: 0.29735

Collected Steps per Second: 21,952.71541
Overall Steps per Second: 10,432.84065

Timestep Collection Time: 2.27826
Timestep Consumption Time: 2.51564
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.79390

Cumulative Model Updates: 320,604
Cumulative Timesteps: 2,673,843,234

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2673843234...
Checkpoint 2673843234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.32161
Policy Entropy: 4.12503
Value Function Loss: 0.00368

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02292
Policy Update Magnitude: 0.24862
Value Function Update Magnitude: 0.29054

Collected Steps per Second: 22,514.25508
Overall Steps per Second: 10,599.70347

Timestep Collection Time: 2.22135
Timestep Consumption Time: 2.49690
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.71825

Cumulative Model Updates: 320,610
Cumulative Timesteps: 2,673,893,246

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.42975
Policy Entropy: 4.13848
Value Function Loss: 0.00370

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02076
Policy Update Magnitude: 0.24743
Value Function Update Magnitude: 0.27786

Collected Steps per Second: 22,030.41775
Overall Steps per Second: 10,531.95979

Timestep Collection Time: 2.27004
Timestep Consumption Time: 2.47836
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.74840

Cumulative Model Updates: 320,616
Cumulative Timesteps: 2,673,943,256

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2673943256...
Checkpoint 2673943256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.30391
Policy Entropy: 4.11112
Value Function Loss: 0.00383

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02500
Policy Update Magnitude: 0.24941
Value Function Update Magnitude: 0.27407

Collected Steps per Second: 21,315.77752
Overall Steps per Second: 10,552.36126

Timestep Collection Time: 2.34662
Timestep Consumption Time: 2.39355
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.74017

Cumulative Model Updates: 320,622
Cumulative Timesteps: 2,673,993,276

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.45166
Policy Entropy: 4.12401
Value Function Loss: 0.00365

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02250
Policy Update Magnitude: 0.24182
Value Function Update Magnitude: 0.27140

Collected Steps per Second: 22,028.96553
Overall Steps per Second: 10,517.87757

Timestep Collection Time: 2.26974
Timestep Consumption Time: 2.48407
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.75381

Cumulative Model Updates: 320,628
Cumulative Timesteps: 2,674,043,276

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2674043276...
Checkpoint 2674043276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.20733
Policy Entropy: 4.14482
Value Function Loss: 0.00328

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.02040
Policy Update Magnitude: 0.23958
Value Function Update Magnitude: 0.26222

Collected Steps per Second: 21,940.82258
Overall Steps per Second: 10,506.75676

Timestep Collection Time: 2.28032
Timestep Consumption Time: 2.48157
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.76189

Cumulative Model Updates: 320,634
Cumulative Timesteps: 2,674,093,308

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.77049
Policy Entropy: 4.15995
Value Function Loss: 0.00294

Mean KL Divergence: 0.04950
SB3 Clip Fraction: 0.01815
Policy Update Magnitude: 0.23451
Value Function Update Magnitude: 0.24406

Collected Steps per Second: 22,106.27964
Overall Steps per Second: 10,606.25533

Timestep Collection Time: 2.26198
Timestep Consumption Time: 2.45259
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.71458

Cumulative Model Updates: 320,640
Cumulative Timesteps: 2,674,143,312

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2674143312...
Checkpoint 2674143312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.40295
Policy Entropy: 4.17274
Value Function Loss: 0.00298

Mean KL Divergence: 0.05277
SB3 Clip Fraction: 0.01812
Policy Update Magnitude: 0.22188
Value Function Update Magnitude: 0.23420

Collected Steps per Second: 21,778.78854
Overall Steps per Second: 10,396.31920

Timestep Collection Time: 2.29719
Timestep Consumption Time: 2.51509
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.81228

Cumulative Model Updates: 320,646
Cumulative Timesteps: 2,674,193,342

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.91502
Policy Entropy: 4.16259
Value Function Loss: 0.00341

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.01865
Policy Update Magnitude: 0.22050
Value Function Update Magnitude: 0.24919

Collected Steps per Second: 22,057.68867
Overall Steps per Second: 10,538.52437

Timestep Collection Time: 2.26706
Timestep Consumption Time: 2.47801
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.74507

Cumulative Model Updates: 320,652
Cumulative Timesteps: 2,674,243,348

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2674243348...
Checkpoint 2674243348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.02931
Policy Entropy: 4.16899
Value Function Loss: 0.00324

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.01663
Policy Update Magnitude: 0.22759
Value Function Update Magnitude: 0.26273

Collected Steps per Second: 21,645.30547
Overall Steps per Second: 10,548.40953

Timestep Collection Time: 2.31071
Timestep Consumption Time: 2.43086
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.74157

Cumulative Model Updates: 320,658
Cumulative Timesteps: 2,674,293,364

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.08968
Policy Entropy: 4.13935
Value Function Loss: 0.00352

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.01949
Policy Update Magnitude: 0.23520
Value Function Update Magnitude: 0.27330

Collected Steps per Second: 22,349.83171
Overall Steps per Second: 10,574.29035

Timestep Collection Time: 2.23787
Timestep Consumption Time: 2.49209
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.72996

Cumulative Model Updates: 320,664
Cumulative Timesteps: 2,674,343,380

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2674343380...
Checkpoint 2674343380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.78967
Policy Entropy: 4.11919
Value Function Loss: 0.00334

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.01933
Policy Update Magnitude: 0.24973
Value Function Update Magnitude: 0.28404

Collected Steps per Second: 21,558.08613
Overall Steps per Second: 10,521.84440

Timestep Collection Time: 2.32015
Timestep Consumption Time: 2.43358
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.75373

Cumulative Model Updates: 320,670
Cumulative Timesteps: 2,674,393,398

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.45119
Policy Entropy: 4.09963
Value Function Loss: 0.00346

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02257
Policy Update Magnitude: 0.25527
Value Function Update Magnitude: 0.28865

Collected Steps per Second: 22,111.60133
Overall Steps per Second: 10,438.78991

Timestep Collection Time: 2.26144
Timestep Consumption Time: 2.52877
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.79021

Cumulative Model Updates: 320,676
Cumulative Timesteps: 2,674,443,402

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2674443402...
Checkpoint 2674443402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.19412
Policy Entropy: 4.12010
Value Function Loss: 0.00343

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.02354
Policy Update Magnitude: 0.25405
Value Function Update Magnitude: 0.29377

Collected Steps per Second: 21,815.42698
Overall Steps per Second: 10,480.99432

Timestep Collection Time: 2.29388
Timestep Consumption Time: 2.48067
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.77455

Cumulative Model Updates: 320,682
Cumulative Timesteps: 2,674,493,444

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.45063
Policy Entropy: 4.14568
Value Function Loss: 0.00322

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.02404
Policy Update Magnitude: 0.24654
Value Function Update Magnitude: 0.27888

Collected Steps per Second: 22,057.49833
Overall Steps per Second: 10,540.54618

Timestep Collection Time: 2.26825
Timestep Consumption Time: 2.47837
PPO Batch Consumption Time: 0.29627
Total Iteration Time: 4.74662

Cumulative Model Updates: 320,688
Cumulative Timesteps: 2,674,543,476

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2674543476...
Checkpoint 2674543476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.86717
Policy Entropy: 4.19246
Value Function Loss: 0.00266

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02110
Policy Update Magnitude: 0.23453
Value Function Update Magnitude: 0.26152

Collected Steps per Second: 21,710.24094
Overall Steps per Second: 10,312.23689

Timestep Collection Time: 2.30398
Timestep Consumption Time: 2.54657
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.85055

Cumulative Model Updates: 320,694
Cumulative Timesteps: 2,674,593,496

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.54586
Policy Entropy: 4.17584
Value Function Loss: 0.00277

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.02074
Policy Update Magnitude: 0.21751
Value Function Update Magnitude: 0.25940

Collected Steps per Second: 22,144.57841
Overall Steps per Second: 10,727.45811

Timestep Collection Time: 2.25789
Timestep Consumption Time: 2.40305
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.66094

Cumulative Model Updates: 320,700
Cumulative Timesteps: 2,674,643,496

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2674643496...
Checkpoint 2674643496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.35655
Policy Entropy: 4.18534
Value Function Loss: 0.00275

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.01871
Policy Update Magnitude: 0.22053
Value Function Update Magnitude: 0.25312

Collected Steps per Second: 21,971.44020
Overall Steps per Second: 10,487.92612

Timestep Collection Time: 2.27668
Timestep Consumption Time: 2.49280
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.76948

Cumulative Model Updates: 320,706
Cumulative Timesteps: 2,674,693,518

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.32598
Policy Entropy: 4.17881
Value Function Loss: 0.00315

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02035
Policy Update Magnitude: 0.23352
Value Function Update Magnitude: 0.24636

Collected Steps per Second: 22,102.89997
Overall Steps per Second: 10,599.28494

Timestep Collection Time: 2.26278
Timestep Consumption Time: 2.45584
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.71862

Cumulative Model Updates: 320,712
Cumulative Timesteps: 2,674,743,532

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2674743532...
Checkpoint 2674743532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.31498
Policy Entropy: 4.17050
Value Function Loss: 0.00321

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.01996
Policy Update Magnitude: 0.22836
Value Function Update Magnitude: 0.25032

Collected Steps per Second: 21,625.50019
Overall Steps per Second: 10,604.32119

Timestep Collection Time: 2.31236
Timestep Consumption Time: 2.40326
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.71562

Cumulative Model Updates: 320,718
Cumulative Timesteps: 2,674,793,538

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.67859
Policy Entropy: 4.18511
Value Function Loss: 0.00264

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.01777
Policy Update Magnitude: 0.22190
Value Function Update Magnitude: 0.24136

Collected Steps per Second: 22,359.92398
Overall Steps per Second: 10,482.92884

Timestep Collection Time: 2.23740
Timestep Consumption Time: 2.53493
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.77233

Cumulative Model Updates: 320,724
Cumulative Timesteps: 2,674,843,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2674843566...
Checkpoint 2674843566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.97771
Policy Entropy: 4.18348
Value Function Loss: 0.00275

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.01800
Policy Update Magnitude: 0.21221
Value Function Update Magnitude: 0.22672

Collected Steps per Second: 21,726.12603
Overall Steps per Second: 10,065.42283

Timestep Collection Time: 2.30156
Timestep Consumption Time: 2.66634
PPO Batch Consumption Time: 0.32071
Total Iteration Time: 4.96790

Cumulative Model Updates: 320,730
Cumulative Timesteps: 2,674,893,570

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.08542
Policy Entropy: 4.18833
Value Function Loss: 0.00309

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.01508
Policy Update Magnitude: 0.20924
Value Function Update Magnitude: 0.23363

Collected Steps per Second: 23,654.13761
Overall Steps per Second: 10,869.97419

Timestep Collection Time: 2.11413
Timestep Consumption Time: 2.48643
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.60056

Cumulative Model Updates: 320,736
Cumulative Timesteps: 2,674,943,578

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2674943578...
Checkpoint 2674943578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.74315
Policy Entropy: 4.13750
Value Function Loss: 0.00397

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01700
Policy Update Magnitude: 0.23792
Value Function Update Magnitude: 0.26909

Collected Steps per Second: 22,262.50211
Overall Steps per Second: 10,554.50331

Timestep Collection Time: 2.24656
Timestep Consumption Time: 2.49208
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.73864

Cumulative Model Updates: 320,742
Cumulative Timesteps: 2,674,993,592

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.51101
Policy Entropy: 4.14543
Value Function Loss: 0.00292

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02087
Policy Update Magnitude: 0.23944
Value Function Update Magnitude: 0.29256

Collected Steps per Second: 22,965.90729
Overall Steps per Second: 10,792.24681

Timestep Collection Time: 2.17775
Timestep Consumption Time: 2.45650
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.63425

Cumulative Model Updates: 320,748
Cumulative Timesteps: 2,675,043,606

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2675043606...
Checkpoint 2675043606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.31316
Policy Entropy: 4.17141
Value Function Loss: 0.00247

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.01813
Policy Update Magnitude: 0.22208
Value Function Update Magnitude: 0.26964

Collected Steps per Second: 22,653.76611
Overall Steps per Second: 10,689.50081

Timestep Collection Time: 2.20732
Timestep Consumption Time: 2.47055
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.67786

Cumulative Model Updates: 320,754
Cumulative Timesteps: 2,675,093,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.50374
Policy Entropy: 4.19116
Value Function Loss: 0.00282

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.01479
Policy Update Magnitude: 0.21887
Value Function Update Magnitude: 0.26020

Collected Steps per Second: 22,600.40443
Overall Steps per Second: 10,643.46591

Timestep Collection Time: 2.21368
Timestep Consumption Time: 2.48686
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.70054

Cumulative Model Updates: 320,760
Cumulative Timesteps: 2,675,143,640

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2675143640...
Checkpoint 2675143640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.75010
Policy Entropy: 4.17525
Value Function Loss: 0.00317

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.01847
Policy Update Magnitude: 0.23357
Value Function Update Magnitude: 0.27964

Collected Steps per Second: 21,693.38286
Overall Steps per Second: 10,633.58629

Timestep Collection Time: 2.30485
Timestep Consumption Time: 2.39723
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.70208

Cumulative Model Updates: 320,766
Cumulative Timesteps: 2,675,193,640

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.86874
Policy Entropy: 4.18888
Value Function Loss: 0.00261

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.01764
Policy Update Magnitude: 0.22191
Value Function Update Magnitude: 0.27794

Collected Steps per Second: 22,524.11563
Overall Steps per Second: 10,748.03473

Timestep Collection Time: 2.22100
Timestep Consumption Time: 2.43343
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.65443

Cumulative Model Updates: 320,772
Cumulative Timesteps: 2,675,243,666

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2675243666...
Checkpoint 2675243666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.05720
Policy Entropy: 4.21202
Value Function Loss: 0.00242

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01544
Policy Update Magnitude: 0.19835
Value Function Update Magnitude: 0.26533

Collected Steps per Second: 22,014.17651
Overall Steps per Second: 10,669.74524

Timestep Collection Time: 2.27126
Timestep Consumption Time: 2.41488
PPO Batch Consumption Time: 0.27647
Total Iteration Time: 4.68615

Cumulative Model Updates: 320,778
Cumulative Timesteps: 2,675,293,666

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.30721
Policy Entropy: 4.16744
Value Function Loss: 0.00279

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01541
Policy Update Magnitude: 0.21555
Value Function Update Magnitude: 0.28580

Collected Steps per Second: 22,158.60683
Overall Steps per Second: 10,805.08351

Timestep Collection Time: 2.25700
Timestep Consumption Time: 2.37156
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.62856

Cumulative Model Updates: 320,784
Cumulative Timesteps: 2,675,343,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2675343678...
Checkpoint 2675343678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.54167
Policy Entropy: 4.12366
Value Function Loss: 0.00305

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.01848
Policy Update Magnitude: 0.23769
Value Function Update Magnitude: 0.30128

Collected Steps per Second: 21,896.81523
Overall Steps per Second: 10,543.11590

Timestep Collection Time: 2.28444
Timestep Consumption Time: 2.46008
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.74452

Cumulative Model Updates: 320,790
Cumulative Timesteps: 2,675,393,700

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.20856
Policy Entropy: 4.11568
Value Function Loss: 0.00310

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.02267
Policy Update Magnitude: 0.23835
Value Function Update Magnitude: 0.28598

Collected Steps per Second: 22,459.31473
Overall Steps per Second: 10,591.87773

Timestep Collection Time: 2.22625
Timestep Consumption Time: 2.49435
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.72060

Cumulative Model Updates: 320,796
Cumulative Timesteps: 2,675,443,700

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2675443700...
Checkpoint 2675443700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.56550
Policy Entropy: 4.14306
Value Function Loss: 0.00277

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.01917
Policy Update Magnitude: 0.23725
Value Function Update Magnitude: 0.26743

Collected Steps per Second: 22,926.02804
Overall Steps per Second: 10,650.74661

Timestep Collection Time: 2.18215
Timestep Consumption Time: 2.51499
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.69714

Cumulative Model Updates: 320,802
Cumulative Timesteps: 2,675,493,728

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.66660
Policy Entropy: 4.15751
Value Function Loss: 0.00280

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02042
Policy Update Magnitude: 0.23314
Value Function Update Magnitude: 0.28512

Collected Steps per Second: 22,664.71855
Overall Steps per Second: 10,623.01150

Timestep Collection Time: 2.20678
Timestep Consumption Time: 2.50149
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.70827

Cumulative Model Updates: 320,808
Cumulative Timesteps: 2,675,543,744

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2675543744...
Checkpoint 2675543744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.70022
Policy Entropy: 4.16565
Value Function Loss: 0.00263

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02032
Policy Update Magnitude: 0.22605
Value Function Update Magnitude: 0.28125

Collected Steps per Second: 22,258.18957
Overall Steps per Second: 10,877.26216

Timestep Collection Time: 2.24654
Timestep Consumption Time: 2.35057
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.59711

Cumulative Model Updates: 320,814
Cumulative Timesteps: 2,675,593,748

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.50322
Policy Entropy: 4.18038
Value Function Loss: 0.00282

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.01768
Policy Update Magnitude: 0.23064
Value Function Update Magnitude: 0.27166

Collected Steps per Second: 22,507.59923
Overall Steps per Second: 10,572.91880

Timestep Collection Time: 2.22263
Timestep Consumption Time: 2.50890
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.73152

Cumulative Model Updates: 320,820
Cumulative Timesteps: 2,675,643,774

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2675643774...
Checkpoint 2675643774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.39837
Policy Entropy: 4.17237
Value Function Loss: 0.00276

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.01742
Policy Update Magnitude: 0.22075
Value Function Update Magnitude: 0.24928

Collected Steps per Second: 22,256.10078
Overall Steps per Second: 10,548.40177

Timestep Collection Time: 2.24783
Timestep Consumption Time: 2.49488
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.74271

Cumulative Model Updates: 320,826
Cumulative Timesteps: 2,675,693,802

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.60124
Policy Entropy: 4.12957
Value Function Loss: 0.00333

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.01654
Policy Update Magnitude: 0.23223
Value Function Update Magnitude: 0.24298

Collected Steps per Second: 22,493.49176
Overall Steps per Second: 10,887.58575

Timestep Collection Time: 2.22349
Timestep Consumption Time: 2.37018
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.59367

Cumulative Model Updates: 320,832
Cumulative Timesteps: 2,675,743,816

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2675743816...
Checkpoint 2675743816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.22039
Policy Entropy: 4.10126
Value Function Loss: 0.00314

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02102
Policy Update Magnitude: 0.24501
Value Function Update Magnitude: 0.25242

Collected Steps per Second: 21,934.53647
Overall Steps per Second: 10,620.91628

Timestep Collection Time: 2.28006
Timestep Consumption Time: 2.42876
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.70882

Cumulative Model Updates: 320,838
Cumulative Timesteps: 2,675,793,828

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.47869
Policy Entropy: 4.11988
Value Function Loss: 0.00314

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02151
Policy Update Magnitude: 0.23724
Value Function Update Magnitude: 0.28407

Collected Steps per Second: 22,374.09840
Overall Steps per Second: 10,566.48479

Timestep Collection Time: 2.23571
Timestep Consumption Time: 2.49831
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.73402

Cumulative Model Updates: 320,844
Cumulative Timesteps: 2,675,843,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2675843850...
Checkpoint 2675843850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.94454
Policy Entropy: 4.17657
Value Function Loss: 0.00267

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02017
Policy Update Magnitude: 0.23114
Value Function Update Magnitude: 0.29402

Collected Steps per Second: 22,354.70181
Overall Steps per Second: 10,773.82093

Timestep Collection Time: 2.23676
Timestep Consumption Time: 2.40431
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.64106

Cumulative Model Updates: 320,850
Cumulative Timesteps: 2,675,893,852

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.90072
Policy Entropy: 4.18417
Value Function Loss: 0.00276

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.01597
Policy Update Magnitude: 0.22397
Value Function Update Magnitude: 0.27426

Collected Steps per Second: 22,406.45426
Overall Steps per Second: 10,715.16863

Timestep Collection Time: 2.23212
Timestep Consumption Time: 2.43546
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.66759

Cumulative Model Updates: 320,856
Cumulative Timesteps: 2,675,943,866

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2675943866...
Checkpoint 2675943866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51194
Policy Entropy: 4.12653
Value Function Loss: 0.00360

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.01911
Policy Update Magnitude: 0.24343
Value Function Update Magnitude: 0.26836

Collected Steps per Second: 22,137.27501
Overall Steps per Second: 10,648.80468

Timestep Collection Time: 2.25881
Timestep Consumption Time: 2.43692
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.69574

Cumulative Model Updates: 320,862
Cumulative Timesteps: 2,675,993,870

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.91290
Policy Entropy: 4.11304
Value Function Loss: 0.00342

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.02216
Policy Update Magnitude: 0.25456
Value Function Update Magnitude: 0.28446

Collected Steps per Second: 23,161.95921
Overall Steps per Second: 10,872.33308

Timestep Collection Time: 2.16044
Timestep Consumption Time: 2.44207
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.60251

Cumulative Model Updates: 320,868
Cumulative Timesteps: 2,676,043,910

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2676043910...
Checkpoint 2676043910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.14314
Policy Entropy: 4.12566
Value Function Loss: 0.00338

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.02190
Policy Update Magnitude: 0.25216
Value Function Update Magnitude: 0.29438

Collected Steps per Second: 21,923.60934
Overall Steps per Second: 10,609.66952

Timestep Collection Time: 2.28147
Timestep Consumption Time: 2.43291
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.71438

Cumulative Model Updates: 320,874
Cumulative Timesteps: 2,676,093,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.16747
Policy Entropy: 4.19279
Value Function Loss: 0.00215

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.01783
Policy Update Magnitude: 0.22103
Value Function Update Magnitude: 0.27648

Collected Steps per Second: 22,332.27594
Overall Steps per Second: 10,764.88434

Timestep Collection Time: 2.23927
Timestep Consumption Time: 2.40620
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.64547

Cumulative Model Updates: 320,880
Cumulative Timesteps: 2,676,143,936

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2676143936...
Checkpoint 2676143936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.41326
Policy Entropy: 4.16494
Value Function Loss: 0.00238

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.01649
Policy Update Magnitude: 0.21530
Value Function Update Magnitude: 0.24458

Collected Steps per Second: 22,127.03136
Overall Steps per Second: 10,548.46068

Timestep Collection Time: 2.25995
Timestep Consumption Time: 2.48065
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.74060

Cumulative Model Updates: 320,886
Cumulative Timesteps: 2,676,193,942

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.66397
Policy Entropy: 4.14671
Value Function Loss: 0.00239

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.01834
Policy Update Magnitude: 0.21697
Value Function Update Magnitude: 0.24300

Collected Steps per Second: 22,294.07016
Overall Steps per Second: 10,697.22384

Timestep Collection Time: 2.24329
Timestep Consumption Time: 2.43194
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.67523

Cumulative Model Updates: 320,892
Cumulative Timesteps: 2,676,243,954

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2676243954...
Checkpoint 2676243954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.07045
Policy Entropy: 4.13447
Value Function Loss: 0.00260

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.02164
Policy Update Magnitude: 0.22529
Value Function Update Magnitude: 0.27397

Collected Steps per Second: 22,152.30153
Overall Steps per Second: 10,723.57863

Timestep Collection Time: 2.25719
Timestep Consumption Time: 2.40562
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.66281

Cumulative Model Updates: 320,898
Cumulative Timesteps: 2,676,293,956

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.84939
Policy Entropy: 4.13520
Value Function Loss: 0.00307

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.01827
Policy Update Magnitude: 0.24041
Value Function Update Magnitude: 0.29276

Collected Steps per Second: 22,403.56421
Overall Steps per Second: 10,585.38827

Timestep Collection Time: 2.23223
Timestep Consumption Time: 2.49220
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.72444

Cumulative Model Updates: 320,904
Cumulative Timesteps: 2,676,343,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2676343966...
Checkpoint 2676343966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.24481
Policy Entropy: 4.14292
Value Function Loss: 0.00307

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.01797
Policy Update Magnitude: 0.24218
Value Function Update Magnitude: 0.30423

Collected Steps per Second: 22,684.08031
Overall Steps per Second: 10,839.33642

Timestep Collection Time: 2.20551
Timestep Consumption Time: 2.41008
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.61560

Cumulative Model Updates: 320,910
Cumulative Timesteps: 2,676,393,996

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.49750
Policy Entropy: 4.09823
Value Function Loss: 0.00369

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02045
Policy Update Magnitude: 0.24537
Value Function Update Magnitude: 0.28883

Collected Steps per Second: 23,033.16772
Overall Steps per Second: 10,639.11417

Timestep Collection Time: 2.17130
Timestep Consumption Time: 2.52946
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.70077

Cumulative Model Updates: 320,916
Cumulative Timesteps: 2,676,444,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2676444008...
Checkpoint 2676444008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.61173
Policy Entropy: 4.13506
Value Function Loss: 0.00317

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.01991
Policy Update Magnitude: 0.24749
Value Function Update Magnitude: 0.27948

Collected Steps per Second: 22,403.28676
Overall Steps per Second: 9,596.72952

Timestep Collection Time: 2.23208
Timestep Consumption Time: 2.97865
PPO Batch Consumption Time: 0.35187
Total Iteration Time: 5.21073

Cumulative Model Updates: 320,922
Cumulative Timesteps: 2,676,494,014

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.24942
Policy Entropy: 4.14981
Value Function Loss: 0.00325

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.02273
Policy Update Magnitude: 0.23894
Value Function Update Magnitude: 0.27705

Collected Steps per Second: 20,014.36584
Overall Steps per Second: 9,455.08266

Timestep Collection Time: 2.49871
Timestep Consumption Time: 2.79051
PPO Batch Consumption Time: 0.33404
Total Iteration Time: 5.28922

Cumulative Model Updates: 320,928
Cumulative Timesteps: 2,676,544,024

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2676544024...
Checkpoint 2676544024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.24586
Policy Entropy: 4.17353
Value Function Loss: 0.00313

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02002
Policy Update Magnitude: 0.23296
Value Function Update Magnitude: 0.29199

Collected Steps per Second: 21,851.31618
Overall Steps per Second: 10,439.99171

Timestep Collection Time: 2.28956
Timestep Consumption Time: 2.50258
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.79215

Cumulative Model Updates: 320,934
Cumulative Timesteps: 2,676,594,054

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.63543
Policy Entropy: 4.15230
Value Function Loss: 0.00288

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02374
Policy Update Magnitude: 0.23809
Value Function Update Magnitude: 0.28818

Collected Steps per Second: 21,973.90956
Overall Steps per Second: 10,557.60224

Timestep Collection Time: 2.27561
Timestep Consumption Time: 2.46069
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.73630

Cumulative Model Updates: 320,940
Cumulative Timesteps: 2,676,644,058

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2676644058...
Checkpoint 2676644058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.03776
Policy Entropy: 4.14431
Value Function Loss: 0.00300

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02404
Policy Update Magnitude: 0.23548
Value Function Update Magnitude: 0.29166

Collected Steps per Second: 21,804.81301
Overall Steps per Second: 10,626.87628

Timestep Collection Time: 2.29381
Timestep Consumption Time: 2.41275
PPO Batch Consumption Time: 0.28453
Total Iteration Time: 4.70656

Cumulative Model Updates: 320,946
Cumulative Timesteps: 2,676,694,074

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.76882
Policy Entropy: 4.17445
Value Function Loss: 0.00287

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02429
Policy Update Magnitude: 0.23023
Value Function Update Magnitude: 0.29574

Collected Steps per Second: 21,949.06080
Overall Steps per Second: 10,470.49628

Timestep Collection Time: 2.27846
Timestep Consumption Time: 2.49782
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.77628

Cumulative Model Updates: 320,952
Cumulative Timesteps: 2,676,744,084

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2676744084...
Checkpoint 2676744084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.38839
Policy Entropy: 4.19379
Value Function Loss: 0.00318

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02133
Policy Update Magnitude: 0.22075
Value Function Update Magnitude: 0.28519

Collected Steps per Second: 21,550.32944
Overall Steps per Second: 10,357.56352

Timestep Collection Time: 2.32099
Timestep Consumption Time: 2.50814
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.82913

Cumulative Model Updates: 320,958
Cumulative Timesteps: 2,676,794,102

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.23694
Policy Entropy: 4.20123
Value Function Loss: 0.00324

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02134
Policy Update Magnitude: 0.23024
Value Function Update Magnitude: 0.28870

Collected Steps per Second: 22,818.46917
Overall Steps per Second: 10,661.94549

Timestep Collection Time: 2.19200
Timestep Consumption Time: 2.49927
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.69126

Cumulative Model Updates: 320,964
Cumulative Timesteps: 2,676,844,120

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2676844120...
Checkpoint 2676844120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.20638
Policy Entropy: 4.20554
Value Function Loss: 0.00264

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.01964
Policy Update Magnitude: 0.21960
Value Function Update Magnitude: 0.27480

Collected Steps per Second: 21,431.89991
Overall Steps per Second: 10,307.98659

Timestep Collection Time: 2.33418
Timestep Consumption Time: 2.51895
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.85313

Cumulative Model Updates: 320,970
Cumulative Timesteps: 2,676,894,146

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.20462
Policy Entropy: 4.21509
Value Function Loss: 0.00211

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.01930
Policy Update Magnitude: 0.20929
Value Function Update Magnitude: 0.25865

Collected Steps per Second: 21,835.71053
Overall Steps per Second: 10,520.89807

Timestep Collection Time: 2.29010
Timestep Consumption Time: 2.46291
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.75302

Cumulative Model Updates: 320,976
Cumulative Timesteps: 2,676,944,152

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2676944152...
Checkpoint 2676944152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.31961
Policy Entropy: 4.21856
Value Function Loss: 0.00250

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.01832
Policy Update Magnitude: 0.21685
Value Function Update Magnitude: 0.24727

Collected Steps per Second: 22,661.37829
Overall Steps per Second: 10,603.69050

Timestep Collection Time: 2.20746
Timestep Consumption Time: 2.51015
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.71760

Cumulative Model Updates: 320,982
Cumulative Timesteps: 2,676,994,176

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.55312
Policy Entropy: 4.18858
Value Function Loss: 0.00275

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.01774
Policy Update Magnitude: 0.22867
Value Function Update Magnitude: 0.26092

Collected Steps per Second: 21,605.69091
Overall Steps per Second: 10,361.38839

Timestep Collection Time: 2.31448
Timestep Consumption Time: 2.51170
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.82619

Cumulative Model Updates: 320,988
Cumulative Timesteps: 2,677,044,182

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2677044182...
Checkpoint 2677044182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.55730
Policy Entropy: 4.14529
Value Function Loss: 0.00374

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02177
Policy Update Magnitude: 0.24506
Value Function Update Magnitude: 0.27909

Collected Steps per Second: 21,686.25786
Overall Steps per Second: 10,615.99829

Timestep Collection Time: 2.30653
Timestep Consumption Time: 2.40523
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.71176

Cumulative Model Updates: 320,994
Cumulative Timesteps: 2,677,094,202

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.25873
Policy Entropy: 4.14926
Value Function Loss: 0.00356

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.02364
Policy Update Magnitude: 0.25226
Value Function Update Magnitude: 0.28971

Collected Steps per Second: 21,924.43790
Overall Steps per Second: 10,477.31414

Timestep Collection Time: 2.28065
Timestep Consumption Time: 2.49175
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.77241

Cumulative Model Updates: 321,000
Cumulative Timesteps: 2,677,144,204

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2677144204...
Checkpoint 2677144204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.01274
Policy Entropy: 4.17771
Value Function Loss: 0.00331

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02129
Policy Update Magnitude: 0.25271
Value Function Update Magnitude: 0.31116

Collected Steps per Second: 21,434.57869
Overall Steps per Second: 10,284.35093

Timestep Collection Time: 2.33277
Timestep Consumption Time: 2.52918
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.86195

Cumulative Model Updates: 321,006
Cumulative Timesteps: 2,677,194,206

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.07267
Policy Entropy: 4.20204
Value Function Loss: 0.00268

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.02054
Policy Update Magnitude: 0.23287
Value Function Update Magnitude: 0.31343

Collected Steps per Second: 22,012.00072
Overall Steps per Second: 10,512.89785

Timestep Collection Time: 2.27240
Timestep Consumption Time: 2.48557
PPO Batch Consumption Time: 0.29798
Total Iteration Time: 4.75797

Cumulative Model Updates: 321,012
Cumulative Timesteps: 2,677,244,226

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2677244226...
Checkpoint 2677244226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.47436
Policy Entropy: 4.19943
Value Function Loss: 0.00289

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.01667
Policy Update Magnitude: 0.22427
Value Function Update Magnitude: 0.29013

Collected Steps per Second: 21,921.89706
Overall Steps per Second: 10,473.82128

Timestep Collection Time: 2.28192
Timestep Consumption Time: 2.49418
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.77610

Cumulative Model Updates: 321,018
Cumulative Timesteps: 2,677,294,250

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.73271
Policy Entropy: 4.18538
Value Function Loss: 0.00340

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.01737
Policy Update Magnitude: 0.23774
Value Function Update Magnitude: 0.27848

Collected Steps per Second: 21,780.71187
Overall Steps per Second: 10,603.94317

Timestep Collection Time: 2.29680
Timestep Consumption Time: 2.42088
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.71768

Cumulative Model Updates: 321,024
Cumulative Timesteps: 2,677,344,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2677344276...
Checkpoint 2677344276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.83386
Policy Entropy: 4.15187
Value Function Loss: 0.00302

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02076
Policy Update Magnitude: 0.24457
Value Function Update Magnitude: 0.27313

Collected Steps per Second: 21,943.65756
Overall Steps per Second: 10,368.76209

Timestep Collection Time: 2.27938
Timestep Consumption Time: 2.54453
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.82391

Cumulative Model Updates: 321,030
Cumulative Timesteps: 2,677,394,294

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.40121
Policy Entropy: 4.16823
Value Function Loss: 0.00272

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02034
Policy Update Magnitude: 0.23442
Value Function Update Magnitude: 0.26733

Collected Steps per Second: 21,974.86331
Overall Steps per Second: 10,358.49390

Timestep Collection Time: 2.27596
Timestep Consumption Time: 2.55234
PPO Batch Consumption Time: 0.29779
Total Iteration Time: 4.82831

Cumulative Model Updates: 321,036
Cumulative Timesteps: 2,677,444,308

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2677444308...
Checkpoint 2677444308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.99545
Policy Entropy: 4.17275
Value Function Loss: 0.00251

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.01798
Policy Update Magnitude: 0.22446
Value Function Update Magnitude: 0.25847

Collected Steps per Second: 22,066.26411
Overall Steps per Second: 10,534.95233

Timestep Collection Time: 2.26599
Timestep Consumption Time: 2.48030
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 4.74630

Cumulative Model Updates: 321,042
Cumulative Timesteps: 2,677,494,310

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.08793
Policy Entropy: 4.19076
Value Function Loss: 0.00234

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.01483
Policy Update Magnitude: 0.22490
Value Function Update Magnitude: 0.25280

Collected Steps per Second: 21,779.72960
Overall Steps per Second: 10,489.79147

Timestep Collection Time: 2.29663
Timestep Consumption Time: 2.47181
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.76845

Cumulative Model Updates: 321,048
Cumulative Timesteps: 2,677,544,330

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2677544330...
Checkpoint 2677544330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.28056
Policy Entropy: 4.14815
Value Function Loss: 0.00316

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.01794
Policy Update Magnitude: 0.23672
Value Function Update Magnitude: 0.26291

Collected Steps per Second: 21,743.62826
Overall Steps per Second: 10,628.18605

Timestep Collection Time: 2.30063
Timestep Consumption Time: 2.40610
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.70673

Cumulative Model Updates: 321,054
Cumulative Timesteps: 2,677,594,354

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.95083
Policy Entropy: 4.15402
Value Function Loss: 0.00288

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02009
Policy Update Magnitude: 0.24129
Value Function Update Magnitude: 0.28445

Collected Steps per Second: 21,975.60292
Overall Steps per Second: 10,456.08968

Timestep Collection Time: 2.27589
Timestep Consumption Time: 2.50735
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.78324

Cumulative Model Updates: 321,060
Cumulative Timesteps: 2,677,644,368

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2677644368...
Checkpoint 2677644368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.68235
Policy Entropy: 4.16999
Value Function Loss: 0.00322

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.02310
Policy Update Magnitude: 0.24179
Value Function Update Magnitude: 0.29172

Collected Steps per Second: 21,808.30590
Overall Steps per Second: 10,531.24035

Timestep Collection Time: 2.29325
Timestep Consumption Time: 2.45566
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.74892

Cumulative Model Updates: 321,066
Cumulative Timesteps: 2,677,694,380

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.96576
Policy Entropy: 4.18514
Value Function Loss: 0.00295

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.02114
Policy Update Magnitude: 0.23109
Value Function Update Magnitude: 0.28536

Collected Steps per Second: 21,733.70268
Overall Steps per Second: 10,584.91029

Timestep Collection Time: 2.30057
Timestep Consumption Time: 2.42313
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.72371

Cumulative Model Updates: 321,072
Cumulative Timesteps: 2,677,744,380

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2677744380...
Checkpoint 2677744380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.11624
Policy Entropy: 4.19701
Value Function Loss: 0.00291

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.02109
Policy Update Magnitude: 0.22182
Value Function Update Magnitude: 0.26813

Collected Steps per Second: 21,873.60380
Overall Steps per Second: 10,398.54659

Timestep Collection Time: 2.28723
Timestep Consumption Time: 2.52402
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.81125

Cumulative Model Updates: 321,078
Cumulative Timesteps: 2,677,794,410

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.81795
Policy Entropy: 4.17059
Value Function Loss: 0.00314

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02081
Policy Update Magnitude: 0.23556
Value Function Update Magnitude: 0.27250

Collected Steps per Second: 21,834.54533
Overall Steps per Second: 10,625.21977

Timestep Collection Time: 2.29077
Timestep Consumption Time: 2.41671
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.70748

Cumulative Model Updates: 321,084
Cumulative Timesteps: 2,677,844,428

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2677844428...
Checkpoint 2677844428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.91138
Policy Entropy: 4.17366
Value Function Loss: 0.00306

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.02325
Policy Update Magnitude: 0.24772
Value Function Update Magnitude: 0.27735

Collected Steps per Second: 21,551.49656
Overall Steps per Second: 10,250.17781

Timestep Collection Time: 2.32021
Timestep Consumption Time: 2.55814
PPO Batch Consumption Time: 0.29688
Total Iteration Time: 4.87835

Cumulative Model Updates: 321,090
Cumulative Timesteps: 2,677,894,432

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.68445
Policy Entropy: 4.14035
Value Function Loss: 0.00326

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.24749
Value Function Update Magnitude: 0.29146

Collected Steps per Second: 21,492.27558
Overall Steps per Second: 10,378.19952

Timestep Collection Time: 2.32753
Timestep Consumption Time: 2.49257
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.82010

Cumulative Model Updates: 321,096
Cumulative Timesteps: 2,677,944,456

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2677944456...
Checkpoint 2677944456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.15735
Policy Entropy: 4.15419
Value Function Loss: 0.00316

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02321
Policy Update Magnitude: 0.25482
Value Function Update Magnitude: 0.29925

Collected Steps per Second: 21,863.98089
Overall Steps per Second: 10,660.13693

Timestep Collection Time: 2.28705
Timestep Consumption Time: 2.40370
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.69075

Cumulative Model Updates: 321,102
Cumulative Timesteps: 2,677,994,460

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.55623
Policy Entropy: 4.17420
Value Function Loss: 0.00257

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02356
Policy Update Magnitude: 0.23544
Value Function Update Magnitude: 0.27056

Collected Steps per Second: 21,963.20706
Overall Steps per Second: 10,475.77799

Timestep Collection Time: 2.27763
Timestep Consumption Time: 2.49758
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.77521

Cumulative Model Updates: 321,108
Cumulative Timesteps: 2,678,044,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2678044484...
Checkpoint 2678044484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.50627
Policy Entropy: 4.17798
Value Function Loss: 0.00244

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02063
Policy Update Magnitude: 0.21676
Value Function Update Magnitude: 0.23390

Collected Steps per Second: 21,240.74141
Overall Steps per Second: 10,247.82050

Timestep Collection Time: 2.35510
Timestep Consumption Time: 2.52633
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.88143

Cumulative Model Updates: 321,114
Cumulative Timesteps: 2,678,094,508

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.01494
Policy Entropy: 4.16858
Value Function Loss: 0.00273

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.01812
Policy Update Magnitude: 0.22672
Value Function Update Magnitude: 0.23261

Collected Steps per Second: 21,673.03503
Overall Steps per Second: 10,481.07510

Timestep Collection Time: 2.30711
Timestep Consumption Time: 2.46359
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.77069

Cumulative Model Updates: 321,120
Cumulative Timesteps: 2,678,144,510

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2678144510...
Checkpoint 2678144510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.49990
Policy Entropy: 4.16038
Value Function Loss: 0.00262

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.01970
Policy Update Magnitude: 0.23755
Value Function Update Magnitude: 0.25323

Collected Steps per Second: 21,943.91702
Overall Steps per Second: 10,379.43125

Timestep Collection Time: 2.27881
Timestep Consumption Time: 2.53899
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.81780

Cumulative Model Updates: 321,126
Cumulative Timesteps: 2,678,194,516

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.01668
Policy Entropy: 4.17120
Value Function Loss: 0.00241

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.01997
Policy Update Magnitude: 0.23349
Value Function Update Magnitude: 0.25694

Collected Steps per Second: 22,051.97628
Overall Steps per Second: 10,444.34585

Timestep Collection Time: 2.26873
Timestep Consumption Time: 2.52142
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.79015

Cumulative Model Updates: 321,132
Cumulative Timesteps: 2,678,244,546

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2678244546...
Checkpoint 2678244546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.36584
Policy Entropy: 4.17976
Value Function Loss: 0.00291

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.01816
Policy Update Magnitude: 0.23981
Value Function Update Magnitude: 0.25899

Collected Steps per Second: 22,555.26986
Overall Steps per Second: 10,479.27693

Timestep Collection Time: 2.21784
Timestep Consumption Time: 2.55577
PPO Batch Consumption Time: 0.29850
Total Iteration Time: 4.77361

Cumulative Model Updates: 321,138
Cumulative Timesteps: 2,678,294,570

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.58886
Policy Entropy: 4.19048
Value Function Loss: 0.00305

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.01642
Policy Update Magnitude: 0.23838
Value Function Update Magnitude: 0.25584

Collected Steps per Second: 21,851.49080
Overall Steps per Second: 10,481.98955

Timestep Collection Time: 2.28817
Timestep Consumption Time: 2.48191
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.77009

Cumulative Model Updates: 321,144
Cumulative Timesteps: 2,678,344,570

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2678344570...
Checkpoint 2678344570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.85997
Policy Entropy: 4.15591
Value Function Loss: 0.00406

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.01869
Policy Update Magnitude: 0.25235
Value Function Update Magnitude: 0.26355

Collected Steps per Second: 21,383.94980
Overall Steps per Second: 10,199.28691

Timestep Collection Time: 2.33830
Timestep Consumption Time: 2.56420
PPO Batch Consumption Time: 0.29852
Total Iteration Time: 4.90250

Cumulative Model Updates: 321,150
Cumulative Timesteps: 2,678,394,572

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.44857
Policy Entropy: 4.14956
Value Function Loss: 0.00363

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.01943
Policy Update Magnitude: 0.26511
Value Function Update Magnitude: 0.29521

Collected Steps per Second: 22,739.38681
Overall Steps per Second: 10,515.99997

Timestep Collection Time: 2.19936
Timestep Consumption Time: 2.55645
PPO Batch Consumption Time: 0.29759
Total Iteration Time: 4.75580

Cumulative Model Updates: 321,156
Cumulative Timesteps: 2,678,444,584

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2678444584...
Checkpoint 2678444584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.15753
Policy Entropy: 4.15341
Value Function Loss: 0.00323

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.02185
Policy Update Magnitude: 0.25189
Value Function Update Magnitude: 0.29471

Collected Steps per Second: 21,838.29601
Overall Steps per Second: 10,458.12435

Timestep Collection Time: 2.29020
Timestep Consumption Time: 2.49211
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.78231

Cumulative Model Updates: 321,162
Cumulative Timesteps: 2,678,494,598

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.43524
Policy Entropy: 4.15640
Value Function Loss: 0.00303

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02016
Policy Update Magnitude: 0.24494
Value Function Update Magnitude: 0.28376

Collected Steps per Second: 21,759.57015
Overall Steps per Second: 10,590.80062

Timestep Collection Time: 2.29913
Timestep Consumption Time: 2.42460
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.72372

Cumulative Model Updates: 321,168
Cumulative Timesteps: 2,678,544,626

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2678544626...
Checkpoint 2678544626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.15899
Policy Entropy: 4.14378
Value Function Loss: 0.00271

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02014
Policy Update Magnitude: 0.24861
Value Function Update Magnitude: 0.27435

Collected Steps per Second: 21,940.58185
Overall Steps per Second: 10,522.36738

Timestep Collection Time: 2.27916
Timestep Consumption Time: 2.47320
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.75235

Cumulative Model Updates: 321,174
Cumulative Timesteps: 2,678,594,632

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.62293
Policy Entropy: 4.15040
Value Function Loss: 0.00236

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02229
Policy Update Magnitude: 0.23839
Value Function Update Magnitude: 0.26829

Collected Steps per Second: 21,871.06732
Overall Steps per Second: 10,555.85896

Timestep Collection Time: 2.28859
Timestep Consumption Time: 2.45323
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.74182

Cumulative Model Updates: 321,180
Cumulative Timesteps: 2,678,644,686

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 2678644686...
Checkpoint 2678644686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.04184
Policy Entropy: 4.17528
Value Function Loss: 0.00265

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.01819
Policy Update Magnitude: 0.22916
Value Function Update Magnitude: 0.26885

Collected Steps per Second: 22,373.99700
Overall Steps per Second: 10,588.48218

Timestep Collection Time: 2.23599
Timestep Consumption Time: 2.48877
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.72476

Cumulative Model Updates: 321,186
Cumulative Timesteps: 2,678,694,714

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.31907
Policy Entropy: 4.20959
Value Function Loss: 0.00260

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.01408
Policy Update Magnitude: 0.23285
Value Function Update Magnitude: 0.27396

Collected Steps per Second: 22,114.36317
Overall Steps per Second: 9,657.84964

Timestep Collection Time: 2.26215
Timestep Consumption Time: 2.91768
PPO Batch Consumption Time: 0.35339
Total Iteration Time: 5.17983

Cumulative Model Updates: 321,192
Cumulative Timesteps: 2,678,744,740

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2678744740...
Checkpoint 2678744740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.83895
Policy Entropy: 4.18516
Value Function Loss: 0.00298

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.01768
Policy Update Magnitude: 0.23604
Value Function Update Magnitude: 0.27760

Collected Steps per Second: 20,742.42192
Overall Steps per Second: 10,275.88269

Timestep Collection Time: 2.41100
Timestep Consumption Time: 2.45573
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.86674

Cumulative Model Updates: 321,198
Cumulative Timesteps: 2,678,794,750

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.91605
Policy Entropy: 4.17433
Value Function Loss: 0.00279

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02080
Policy Update Magnitude: 0.24253
Value Function Update Magnitude: 0.28303

Collected Steps per Second: 22,974.95687
Overall Steps per Second: 10,570.65178

Timestep Collection Time: 2.17637
Timestep Consumption Time: 2.55390
PPO Batch Consumption Time: 0.29874
Total Iteration Time: 4.73027

Cumulative Model Updates: 321,204
Cumulative Timesteps: 2,678,844,752

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2678844752...
Checkpoint 2678844752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.08668
Policy Entropy: 4.17553
Value Function Loss: 0.00326

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.02294
Policy Update Magnitude: 0.24345
Value Function Update Magnitude: 0.28313

Collected Steps per Second: 21,906.48707
Overall Steps per Second: 10,481.21046

Timestep Collection Time: 2.28362
Timestep Consumption Time: 2.48931
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.77292

Cumulative Model Updates: 321,210
Cumulative Timesteps: 2,678,894,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.32015
Policy Entropy: 4.16939
Value Function Loss: 0.00338

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02100
Policy Update Magnitude: 0.25431
Value Function Update Magnitude: 0.28073

Collected Steps per Second: 22,128.97641
Overall Steps per Second: 10,578.12314

Timestep Collection Time: 2.25957
Timestep Consumption Time: 2.46735
PPO Batch Consumption Time: 0.29679
Total Iteration Time: 4.72693

Cumulative Model Updates: 321,216
Cumulative Timesteps: 2,678,944,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2678944780...
Checkpoint 2678944780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.60413
Policy Entropy: 4.18283
Value Function Loss: 0.00357

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.02054
Policy Update Magnitude: 0.24951
Value Function Update Magnitude: 0.28362

Collected Steps per Second: 21,663.80049
Overall Steps per Second: 10,296.08277

Timestep Collection Time: 2.30929
Timestep Consumption Time: 2.54965
PPO Batch Consumption Time: 0.29752
Total Iteration Time: 4.85894

Cumulative Model Updates: 321,222
Cumulative Timesteps: 2,678,994,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.12802
Policy Entropy: 4.19411
Value Function Loss: 0.00307

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02143
Policy Update Magnitude: 0.24202
Value Function Update Magnitude: 0.27388

Collected Steps per Second: 20,554.31821
Overall Steps per Second: 9,915.97252

Timestep Collection Time: 2.43375
Timestep Consumption Time: 2.61104
PPO Batch Consumption Time: 0.29997
Total Iteration Time: 5.04479

Cumulative Model Updates: 321,228
Cumulative Timesteps: 2,679,044,832

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2679044832...
Checkpoint 2679044832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.49501
Policy Entropy: 4.20349
Value Function Loss: 0.00280

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.01741
Policy Update Magnitude: 0.22013
Value Function Update Magnitude: 0.25201

Collected Steps per Second: 20,911.97359
Overall Steps per Second: 10,204.63309

Timestep Collection Time: 2.39193
Timestep Consumption Time: 2.50976
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.90170

Cumulative Model Updates: 321,234
Cumulative Timesteps: 2,679,094,852

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.82170
Policy Entropy: 4.20389
Value Function Loss: 0.00331

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.01906
Policy Update Magnitude: 0.23308
Value Function Update Magnitude: 0.24454

Collected Steps per Second: 22,120.68223
Overall Steps per Second: 10,500.32491

Timestep Collection Time: 2.26159
Timestep Consumption Time: 2.50283
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.76442

Cumulative Model Updates: 321,240
Cumulative Timesteps: 2,679,144,880

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2679144880...
Checkpoint 2679144880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.79827
Policy Entropy: 4.19924
Value Function Loss: 0.00281

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.01866
Policy Update Magnitude: 0.22920
Value Function Update Magnitude: 0.25409

Collected Steps per Second: 21,657.10502
Overall Steps per Second: 10,617.80892

Timestep Collection Time: 2.30917
Timestep Consumption Time: 2.40084
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.71001

Cumulative Model Updates: 321,246
Cumulative Timesteps: 2,679,194,890

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.25971
Policy Entropy: 4.23071
Value Function Loss: 0.00215

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.01801
Policy Update Magnitude: 0.20696
Value Function Update Magnitude: 0.24816

Collected Steps per Second: 21,733.86832
Overall Steps per Second: 10,385.74361

Timestep Collection Time: 2.30111
Timestep Consumption Time: 2.51434
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.81545

Cumulative Model Updates: 321,252
Cumulative Timesteps: 2,679,244,902

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2679244902...
Checkpoint 2679244902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.01448
Policy Entropy: 4.25151
Value Function Loss: 0.00175

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01353
Policy Update Magnitude: 0.19211
Value Function Update Magnitude: 0.22963

Collected Steps per Second: 21,544.17214
Overall Steps per Second: 10,334.99200

Timestep Collection Time: 2.32183
Timestep Consumption Time: 2.51823
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.84006

Cumulative Model Updates: 321,258
Cumulative Timesteps: 2,679,294,924

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.32672
Policy Entropy: 4.22436
Value Function Loss: 0.00209

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.01384
Policy Update Magnitude: 0.20058
Value Function Update Magnitude: 0.24512

Collected Steps per Second: 22,700.02492
Overall Steps per Second: 10,480.46104

Timestep Collection Time: 2.20493
Timestep Consumption Time: 2.57081
PPO Batch Consumption Time: 0.29830
Total Iteration Time: 4.77574

Cumulative Model Updates: 321,264
Cumulative Timesteps: 2,679,344,976

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 2679344976...
Checkpoint 2679344976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.88551
Policy Entropy: 4.21292
Value Function Loss: 0.00191

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.01586
Policy Update Magnitude: 0.20270
Value Function Update Magnitude: 0.24195

Collected Steps per Second: 21,953.79658
Overall Steps per Second: 10,366.19884

Timestep Collection Time: 2.27778
Timestep Consumption Time: 2.54616
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.82395

Cumulative Model Updates: 321,270
Cumulative Timesteps: 2,679,394,982

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.12860
Policy Entropy: 4.22358
Value Function Loss: 0.00248

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.01480
Policy Update Magnitude: 0.22200
Value Function Update Magnitude: 0.24236

Collected Steps per Second: 21,938.61031
Overall Steps per Second: 10,424.26300

Timestep Collection Time: 2.27991
Timestep Consumption Time: 2.51832
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.79823

Cumulative Model Updates: 321,276
Cumulative Timesteps: 2,679,445,000

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2679445000...
Checkpoint 2679445000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.60767
Policy Entropy: 4.23821
Value Function Loss: 0.00225

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.01408
Policy Update Magnitude: 0.22158
Value Function Update Magnitude: 0.25166

Collected Steps per Second: 22,483.44237
Overall Steps per Second: 10,526.11622

Timestep Collection Time: 2.22493
Timestep Consumption Time: 2.52744
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.75237

Cumulative Model Updates: 321,282
Cumulative Timesteps: 2,679,495,024

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.24847
Policy Entropy: 4.23170
Value Function Loss: 0.00258

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.01607
Policy Update Magnitude: 0.21618
Value Function Update Magnitude: 0.26228

Collected Steps per Second: 22,285.52642
Overall Steps per Second: 10,427.25696

Timestep Collection Time: 2.24451
Timestep Consumption Time: 2.55254
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.79704

Cumulative Model Updates: 321,288
Cumulative Timesteps: 2,679,545,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2679545044...
Checkpoint 2679545044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.28524
Policy Entropy: 4.20268
Value Function Loss: 0.00236

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.01587
Policy Update Magnitude: 0.22522
Value Function Update Magnitude: 0.25252

Collected Steps per Second: 21,858.35716
Overall Steps per Second: 10,682.10099

Timestep Collection Time: 2.28828
Timestep Consumption Time: 2.39413
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.68241

Cumulative Model Updates: 321,294
Cumulative Timesteps: 2,679,595,062

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.31551
Policy Entropy: 4.19865
Value Function Loss: 0.00268

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.01698
Policy Update Magnitude: 0.23531
Value Function Update Magnitude: 0.24860

Collected Steps per Second: 21,711.71904
Overall Steps per Second: 10,360.27336

Timestep Collection Time: 2.30355
Timestep Consumption Time: 2.52393
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.82748

Cumulative Model Updates: 321,300
Cumulative Timesteps: 2,679,645,076

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2679645076...
Checkpoint 2679645076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.67616
Policy Entropy: 4.19038
Value Function Loss: 0.00219

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02018
Policy Update Magnitude: 0.22550
Value Function Update Magnitude: 0.25804

Collected Steps per Second: 21,573.07286
Overall Steps per Second: 10,315.42073

Timestep Collection Time: 2.31854
Timestep Consumption Time: 2.53032
PPO Batch Consumption Time: 0.29826
Total Iteration Time: 4.84886

Cumulative Model Updates: 321,306
Cumulative Timesteps: 2,679,695,094

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.85690
Policy Entropy: 4.22281
Value Function Loss: 0.00214

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.01608
Policy Update Magnitude: 0.20994
Value Function Update Magnitude: 0.24641

Collected Steps per Second: 22,188.70012
Overall Steps per Second: 10,617.15515

Timestep Collection Time: 2.25430
Timestep Consumption Time: 2.45694
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.71124

Cumulative Model Updates: 321,312
Cumulative Timesteps: 2,679,745,114

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2679745114...
Checkpoint 2679745114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.21450
Policy Entropy: 4.22417
Value Function Loss: 0.00263

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.01549
Policy Update Magnitude: 0.20735
Value Function Update Magnitude: 0.25715

Collected Steps per Second: 22,041.09356
Overall Steps per Second: 10,492.54581

Timestep Collection Time: 2.26967
Timestep Consumption Time: 2.49810
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.76777

Cumulative Model Updates: 321,318
Cumulative Timesteps: 2,679,795,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.19544
Policy Entropy: 4.20605
Value Function Loss: 0.00326

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.01744
Policy Update Magnitude: 0.23404
Value Function Update Magnitude: 0.27203

Collected Steps per Second: 22,157.94143
Overall Steps per Second: 10,417.49459

Timestep Collection Time: 2.25725
Timestep Consumption Time: 2.54390
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.80115

Cumulative Model Updates: 321,324
Cumulative Timesteps: 2,679,845,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2679845156...
Checkpoint 2679845156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.81493
Policy Entropy: 4.17281
Value Function Loss: 0.00362

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.01898
Policy Update Magnitude: 0.25098
Value Function Update Magnitude: 0.27084

Collected Steps per Second: 21,976.94643
Overall Steps per Second: 10,400.62986

Timestep Collection Time: 2.27639
Timestep Consumption Time: 2.53371
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.81009

Cumulative Model Updates: 321,330
Cumulative Timesteps: 2,679,895,184

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.81943
Policy Entropy: 4.20667
Value Function Loss: 0.00307

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02167
Policy Update Magnitude: 0.24528
Value Function Update Magnitude: 0.27004

Collected Steps per Second: 22,206.22285
Overall Steps per Second: 10,433.55660

Timestep Collection Time: 2.25342
Timestep Consumption Time: 2.54264
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.79606

Cumulative Model Updates: 321,336
Cumulative Timesteps: 2,679,945,224

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2679945224...
Checkpoint 2679945224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.99134
Policy Entropy: 4.21673
Value Function Loss: 0.00251

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.01831
Policy Update Magnitude: 0.22768
Value Function Update Magnitude: 0.27718

Collected Steps per Second: 21,867.21224
Overall Steps per Second: 10,548.81115

Timestep Collection Time: 2.28680
Timestep Consumption Time: 2.45364
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.74044

Cumulative Model Updates: 321,342
Cumulative Timesteps: 2,679,995,230

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.75174
Policy Entropy: 4.25519
Value Function Loss: 0.00165

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01512
Policy Update Magnitude: 0.19982
Value Function Update Magnitude: 0.26601

Collected Steps per Second: 23,079.86819
Overall Steps per Second: 10,734.05488

Timestep Collection Time: 2.16656
Timestep Consumption Time: 2.49188
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.65844

Cumulative Model Updates: 321,348
Cumulative Timesteps: 2,680,045,234

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2680045234...
Checkpoint 2680045234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.17379
Policy Entropy: 4.21461
Value Function Loss: 0.00185

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01384
Policy Update Magnitude: 0.18684
Value Function Update Magnitude: 0.24361

Collected Steps per Second: 21,495.62233
Overall Steps per Second: 10,295.50431

Timestep Collection Time: 2.32736
Timestep Consumption Time: 2.53185
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.85921

Cumulative Model Updates: 321,354
Cumulative Timesteps: 2,680,095,262

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.54979
Policy Entropy: 4.20429
Value Function Loss: 0.00254

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01266
Policy Update Magnitude: 0.21714
Value Function Update Magnitude: 0.24681

Collected Steps per Second: 22,177.17063
Overall Steps per Second: 10,591.13357

Timestep Collection Time: 2.25583
Timestep Consumption Time: 2.46774
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.72357

Cumulative Model Updates: 321,360
Cumulative Timesteps: 2,680,145,290

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2680145290...
Checkpoint 2680145290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.93787
Policy Entropy: 4.15024
Value Function Loss: 0.00314

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02012
Policy Update Magnitude: 0.25187
Value Function Update Magnitude: 0.28029

Collected Steps per Second: 21,706.33543
Overall Steps per Second: 10,431.74970

Timestep Collection Time: 2.30476
Timestep Consumption Time: 2.49098
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.79574

Cumulative Model Updates: 321,366
Cumulative Timesteps: 2,680,195,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.18605
Policy Entropy: 4.15960
Value Function Loss: 0.00277

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.02287
Policy Update Magnitude: 0.24294
Value Function Update Magnitude: 0.28760

Collected Steps per Second: 21,964.61836
Overall Steps per Second: 10,507.69748

Timestep Collection Time: 2.27739
Timestep Consumption Time: 2.48312
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.76051

Cumulative Model Updates: 321,372
Cumulative Timesteps: 2,680,245,340

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2680245340...
Checkpoint 2680245340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.40367
Policy Entropy: 4.16646
Value Function Loss: 0.00244

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.01945
Policy Update Magnitude: 0.23045
Value Function Update Magnitude: 0.25878

Collected Steps per Second: 21,691.25256
Overall Steps per Second: 10,541.34437

Timestep Collection Time: 2.30628
Timestep Consumption Time: 2.43942
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.74569

Cumulative Model Updates: 321,378
Cumulative Timesteps: 2,680,295,366

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.74895
Policy Entropy: 4.15427
Value Function Loss: 0.00278

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.01761
Policy Update Magnitude: 0.23588
Value Function Update Magnitude: 0.23828

Collected Steps per Second: 22,121.98806
Overall Steps per Second: 10,441.07017

Timestep Collection Time: 2.26029
Timestep Consumption Time: 2.52869
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.78897

Cumulative Model Updates: 321,384
Cumulative Timesteps: 2,680,345,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2680345368...
Checkpoint 2680345368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.72369
Policy Entropy: 4.14749
Value Function Loss: 0.00333

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.01966
Policy Update Magnitude: 0.25338
Value Function Update Magnitude: 0.25675

Collected Steps per Second: 21,919.73181
Overall Steps per Second: 10,443.59773

Timestep Collection Time: 2.28169
Timestep Consumption Time: 2.50727
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.78896

Cumulative Model Updates: 321,390
Cumulative Timesteps: 2,680,395,382

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.38675
Policy Entropy: 4.16690
Value Function Loss: 0.00324

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02172
Policy Update Magnitude: 0.24963
Value Function Update Magnitude: 0.26973

Collected Steps per Second: 22,688.67152
Overall Steps per Second: 10,432.12295

Timestep Collection Time: 2.20489
Timestep Consumption Time: 2.59049
PPO Batch Consumption Time: 0.29774
Total Iteration Time: 4.79538

Cumulative Model Updates: 321,396
Cumulative Timesteps: 2,680,445,408

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2680445408...
Checkpoint 2680445408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.84488
Policy Entropy: 4.20548
Value Function Loss: 0.00278

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.01803
Policy Update Magnitude: 0.24974
Value Function Update Magnitude: 0.25956

Collected Steps per Second: 22,163.42249
Overall Steps per Second: 10,540.37350

Timestep Collection Time: 2.25651
Timestep Consumption Time: 2.48829
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.74480

Cumulative Model Updates: 321,402
Cumulative Timesteps: 2,680,495,420

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.85573
Policy Entropy: 4.21140
Value Function Loss: 0.00297

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.01763
Policy Update Magnitude: 0.23430
Value Function Update Magnitude: 0.24828

Collected Steps per Second: 21,987.04116
Overall Steps per Second: 10,537.08197

Timestep Collection Time: 2.27525
Timestep Consumption Time: 2.47236
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.74761

Cumulative Model Updates: 321,408
Cumulative Timesteps: 2,680,545,446

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2680545446...
Checkpoint 2680545446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.81290
Policy Entropy: 4.18479
Value Function Loss: 0.00295

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02103
Policy Update Magnitude: 0.23261
Value Function Update Magnitude: 0.23713

Collected Steps per Second: 22,843.74120
Overall Steps per Second: 10,731.32180

Timestep Collection Time: 2.18992
Timestep Consumption Time: 2.47176
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.66168

Cumulative Model Updates: 321,414
Cumulative Timesteps: 2,680,595,472

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.63112
Policy Entropy: 4.17984
Value Function Loss: 0.00302

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02033
Policy Update Magnitude: 0.22959
Value Function Update Magnitude: 0.24365

Collected Steps per Second: 21,840.21639
Overall Steps per Second: 10,457.69214

Timestep Collection Time: 2.29009
Timestep Consumption Time: 2.49261
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.78270

Cumulative Model Updates: 321,420
Cumulative Timesteps: 2,680,645,488

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2680645488...
Checkpoint 2680645488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.25271
Policy Entropy: 4.17976
Value Function Loss: 0.00230

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02037
Policy Update Magnitude: 0.22487
Value Function Update Magnitude: 0.25512

Collected Steps per Second: 21,892.21562
Overall Steps per Second: 10,595.39006

Timestep Collection Time: 2.28401
Timestep Consumption Time: 2.43521
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.71922

Cumulative Model Updates: 321,426
Cumulative Timesteps: 2,680,695,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.87417
Policy Entropy: 4.17352
Value Function Loss: 0.00262

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.01859
Policy Update Magnitude: 0.22981
Value Function Update Magnitude: 0.25307

Collected Steps per Second: 21,893.75461
Overall Steps per Second: 10,454.55860

Timestep Collection Time: 2.28412
Timestep Consumption Time: 2.49925
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.78337

Cumulative Model Updates: 321,432
Cumulative Timesteps: 2,680,745,498

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2680745498...
Checkpoint 2680745498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.98230
Policy Entropy: 4.15302
Value Function Loss: 0.00288

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.01954
Policy Update Magnitude: 0.23876
Value Function Update Magnitude: 0.26916

Collected Steps per Second: 22,110.20207
Overall Steps per Second: 10,579.58946

Timestep Collection Time: 2.26285
Timestep Consumption Time: 2.46626
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.72911

Cumulative Model Updates: 321,438
Cumulative Timesteps: 2,680,795,530

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.03133
Policy Entropy: 4.16981
Value Function Loss: 0.00276

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02095
Policy Update Magnitude: 0.23197
Value Function Update Magnitude: 0.27931

Collected Steps per Second: 22,358.60327
Overall Steps per Second: 10,579.90471

Timestep Collection Time: 2.23654
Timestep Consumption Time: 2.48996
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.72651

Cumulative Model Updates: 321,444
Cumulative Timesteps: 2,680,845,536

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2680845536...
Checkpoint 2680845536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.45896
Policy Entropy: 4.16557
Value Function Loss: 0.00315

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.01916
Policy Update Magnitude: 0.23359
Value Function Update Magnitude: 0.29549

Collected Steps per Second: 21,402.88442
Overall Steps per Second: 10,202.55987

Timestep Collection Time: 2.33754
Timestep Consumption Time: 2.56614
PPO Batch Consumption Time: 0.29770
Total Iteration Time: 4.90367

Cumulative Model Updates: 321,450
Cumulative Timesteps: 2,680,895,566

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.79875
Policy Entropy: 4.19128
Value Function Loss: 0.00307

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.01861
Policy Update Magnitude: 0.23818
Value Function Update Magnitude: 0.30148

Collected Steps per Second: 21,651.37834
Overall Steps per Second: 10,449.79338

Timestep Collection Time: 2.30932
Timestep Consumption Time: 2.47546
PPO Batch Consumption Time: 0.29624
Total Iteration Time: 4.78478

Cumulative Model Updates: 321,456
Cumulative Timesteps: 2,680,945,566

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2680945566...
Checkpoint 2680945566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.61402
Policy Entropy: 4.15197
Value Function Loss: 0.00375

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02233
Policy Update Magnitude: 0.24479
Value Function Update Magnitude: 0.29426

Collected Steps per Second: 21,956.39811
Overall Steps per Second: 10,419.26894

Timestep Collection Time: 2.27852
Timestep Consumption Time: 2.52297
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.80149

Cumulative Model Updates: 321,462
Cumulative Timesteps: 2,680,995,594

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.41213
Policy Entropy: 4.18208
Value Function Loss: 0.00291

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02048
Policy Update Magnitude: 0.24269
Value Function Update Magnitude: 0.28942

Collected Steps per Second: 21,967.51015
Overall Steps per Second: 10,448.02597

Timestep Collection Time: 2.27645
Timestep Consumption Time: 2.50991
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.78636

Cumulative Model Updates: 321,468
Cumulative Timesteps: 2,681,045,602

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2681045602...
Checkpoint 2681045602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.23805
Policy Entropy: 4.15170
Value Function Loss: 0.00325

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.01905
Policy Update Magnitude: 0.24271
Value Function Update Magnitude: 0.27594

Collected Steps per Second: 21,888.30347
Overall Steps per Second: 10,582.24371

Timestep Collection Time: 2.28451
Timestep Consumption Time: 2.44077
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.72527

Cumulative Model Updates: 321,474
Cumulative Timesteps: 2,681,095,606

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.22414
Policy Entropy: 4.15683
Value Function Loss: 0.00316

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02052
Policy Update Magnitude: 0.24610
Value Function Update Magnitude: 0.27779

Collected Steps per Second: 21,976.97133
Overall Steps per Second: 10,308.47394

Timestep Collection Time: 2.27593
Timestep Consumption Time: 2.57620
PPO Batch Consumption Time: 0.29847
Total Iteration Time: 4.85212

Cumulative Model Updates: 321,480
Cumulative Timesteps: 2,681,145,624

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2681145624...
Checkpoint 2681145624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.42578
Policy Entropy: 4.13604
Value Function Loss: 0.00350

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.02299
Policy Update Magnitude: 0.25640
Value Function Update Magnitude: 0.30776

Collected Steps per Second: 21,751.75389
Overall Steps per Second: 10,365.25395

Timestep Collection Time: 2.29903
Timestep Consumption Time: 2.52555
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.82458

Cumulative Model Updates: 321,486
Cumulative Timesteps: 2,681,195,632

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.85590
Policy Entropy: 4.14289
Value Function Loss: 0.00303

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.02438
Policy Update Magnitude: 0.25089
Value Function Update Magnitude: 0.31209

Collected Steps per Second: 20,323.70359
Overall Steps per Second: 9,941.77754

Timestep Collection Time: 2.46126
Timestep Consumption Time: 2.57023
PPO Batch Consumption Time: 0.29847
Total Iteration Time: 5.03149

Cumulative Model Updates: 321,492
Cumulative Timesteps: 2,681,245,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2681245654...
Checkpoint 2681245654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.43471
Policy Entropy: 4.16979
Value Function Loss: 0.00268

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.02221
Policy Update Magnitude: 0.24189
Value Function Update Magnitude: 0.28897

Collected Steps per Second: 21,931.20716
Overall Steps per Second: 10,486.22725

Timestep Collection Time: 2.28086
Timestep Consumption Time: 2.48940
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.77026

Cumulative Model Updates: 321,498
Cumulative Timesteps: 2,681,295,676

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.69990
Policy Entropy: 4.12978
Value Function Loss: 0.00337

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.02535
Policy Update Magnitude: 0.26005
Value Function Update Magnitude: 0.27554

Collected Steps per Second: 21,523.69401
Overall Steps per Second: 10,442.69789

Timestep Collection Time: 2.32339
Timestep Consumption Time: 2.46541
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.78880

Cumulative Model Updates: 321,504
Cumulative Timesteps: 2,681,345,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2681345684...
Checkpoint 2681345684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.85463
Policy Entropy: 4.14348
Value Function Loss: 0.00335

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.02335
Policy Update Magnitude: 0.28093
Value Function Update Magnitude: 0.28606

Collected Steps per Second: 22,453.74980
Overall Steps per Second: 10,555.72367

Timestep Collection Time: 2.22760
Timestep Consumption Time: 2.51087
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.73847

Cumulative Model Updates: 321,510
Cumulative Timesteps: 2,681,395,702

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.32273
Policy Entropy: 4.10983
Value Function Loss: 0.00381

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.02613
Policy Update Magnitude: 0.28677
Value Function Update Magnitude: 0.29907

Collected Steps per Second: 21,917.40486
Overall Steps per Second: 10,321.74501

Timestep Collection Time: 2.28220
Timestep Consumption Time: 2.56388
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.84608

Cumulative Model Updates: 321,516
Cumulative Timesteps: 2,681,445,722

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2681445722...
Checkpoint 2681445722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.70018
Policy Entropy: 4.14980
Value Function Loss: 0.00294

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.02264
Policy Update Magnitude: 0.26768
Value Function Update Magnitude: 0.30346

Collected Steps per Second: 21,409.93072
Overall Steps per Second: 10,559.06015

Timestep Collection Time: 2.33686
Timestep Consumption Time: 2.40144
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.73830

Cumulative Model Updates: 321,522
Cumulative Timesteps: 2,681,495,754

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.21129
Policy Entropy: 4.16032
Value Function Loss: 0.00273

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02185
Policy Update Magnitude: 0.24738
Value Function Update Magnitude: 0.29455

Collected Steps per Second: 21,913.20475
Overall Steps per Second: 10,476.29793

Timestep Collection Time: 2.28273
Timestep Consumption Time: 2.49205
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.77478

Cumulative Model Updates: 321,528
Cumulative Timesteps: 2,681,545,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2681545776...
Checkpoint 2681545776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.29782
Policy Entropy: 4.19792
Value Function Loss: 0.00235

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.01925
Policy Update Magnitude: 0.23294
Value Function Update Magnitude: 0.27290

Collected Steps per Second: 21,913.69405
Overall Steps per Second: 10,521.85972

Timestep Collection Time: 2.28332
Timestep Consumption Time: 2.47211
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.75543

Cumulative Model Updates: 321,534
Cumulative Timesteps: 2,681,595,812

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.83650
Policy Entropy: 4.22860
Value Function Loss: 0.00202

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.01703
Policy Update Magnitude: 0.20664
Value Function Update Magnitude: 0.25064

Collected Steps per Second: 22,560.29786
Overall Steps per Second: 10,504.40379

Timestep Collection Time: 2.21664
Timestep Consumption Time: 2.54403
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.76067

Cumulative Model Updates: 321,540
Cumulative Timesteps: 2,681,645,820

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2681645820...
Checkpoint 2681645820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.22672
Policy Entropy: 4.23024
Value Function Loss: 0.00226

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.01527
Policy Update Magnitude: 0.21059
Value Function Update Magnitude: 0.23024

Collected Steps per Second: 21,797.42053
Overall Steps per Second: 10,327.14090

Timestep Collection Time: 2.29385
Timestep Consumption Time: 2.54776
PPO Batch Consumption Time: 0.29802
Total Iteration Time: 4.84161

Cumulative Model Updates: 321,546
Cumulative Timesteps: 2,681,695,820

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.45757
Policy Entropy: 4.22230
Value Function Loss: 0.00245

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.01683
Policy Update Magnitude: 0.21225
Value Function Update Magnitude: 0.23380

Collected Steps per Second: 21,812.88095
Overall Steps per Second: 10,505.26383

Timestep Collection Time: 2.29287
Timestep Consumption Time: 2.46799
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.76085

Cumulative Model Updates: 321,552
Cumulative Timesteps: 2,681,745,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2681745834...
Checkpoint 2681745834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.19285
Policy Entropy: 4.17342
Value Function Loss: 0.00278

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.01725
Policy Update Magnitude: 0.22412
Value Function Update Magnitude: 0.26386

Collected Steps per Second: 21,786.56353
Overall Steps per Second: 10,475.89699

Timestep Collection Time: 2.29637
Timestep Consumption Time: 2.47936
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.77572

Cumulative Model Updates: 321,558
Cumulative Timesteps: 2,681,795,864

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.12615
Policy Entropy: 4.15750
Value Function Loss: 0.00293

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02104
Policy Update Magnitude: 0.24271
Value Function Update Magnitude: 0.28104

Collected Steps per Second: 21,508.88154
Overall Steps per Second: 10,227.04075

Timestep Collection Time: 2.32527
Timestep Consumption Time: 2.56510
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.89037

Cumulative Model Updates: 321,564
Cumulative Timesteps: 2,681,845,878

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2681845878...
Checkpoint 2681845878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.30150
Policy Entropy: 4.15039
Value Function Loss: 0.00323

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.02788
Policy Update Magnitude: 0.27201
Value Function Update Magnitude: 0.29047

Collected Steps per Second: 21,483.43667
Overall Steps per Second: 10,484.88364

Timestep Collection Time: 2.32877
Timestep Consumption Time: 2.44286
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.77163

Cumulative Model Updates: 321,570
Cumulative Timesteps: 2,681,895,908

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.31980
Policy Entropy: 4.17683
Value Function Loss: 0.00328

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.02610
Policy Update Magnitude: 0.27240
Value Function Update Magnitude: 0.29011

Collected Steps per Second: 21,856.07102
Overall Steps per Second: 10,479.84328

Timestep Collection Time: 2.28788
Timestep Consumption Time: 2.48357
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.77145

Cumulative Model Updates: 321,576
Cumulative Timesteps: 2,681,945,912

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2681945912...
Checkpoint 2681945912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.59674
Policy Entropy: 4.16278
Value Function Loss: 0.00337

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.02384
Policy Update Magnitude: 0.26400
Value Function Update Magnitude: 0.28354

Collected Steps per Second: 21,839.60847
Overall Steps per Second: 10,513.69732

Timestep Collection Time: 2.29033
Timestep Consumption Time: 2.46727
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.75760

Cumulative Model Updates: 321,582
Cumulative Timesteps: 2,681,995,932

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.45405
Policy Entropy: 4.15394
Value Function Loss: 0.00329

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.02226
Policy Update Magnitude: 0.25801
Value Function Update Magnitude: 0.28908

Collected Steps per Second: 21,412.70320
Overall Steps per Second: 10,526.17023

Timestep Collection Time: 2.33553
Timestep Consumption Time: 2.41549
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.75102

Cumulative Model Updates: 321,588
Cumulative Timesteps: 2,682,045,942

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2682045942...
Checkpoint 2682045942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.56975
Policy Entropy: 4.14503
Value Function Loss: 0.00313

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.02271
Policy Update Magnitude: 0.24805
Value Function Update Magnitude: 0.28574

Collected Steps per Second: 21,922.65670
Overall Steps per Second: 10,354.04770

Timestep Collection Time: 2.28175
Timestep Consumption Time: 2.54941
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.83115

Cumulative Model Updates: 321,594
Cumulative Timesteps: 2,682,095,964

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.10594
Policy Entropy: 4.18374
Value Function Loss: 0.00263

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02056
Policy Update Magnitude: 0.24264
Value Function Update Magnitude: 0.28197

Collected Steps per Second: 19,890.53286
Overall Steps per Second: 9,892.46074

Timestep Collection Time: 2.51396
Timestep Consumption Time: 2.54080
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 5.05476

Cumulative Model Updates: 321,600
Cumulative Timesteps: 2,682,145,968

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2682145968...
Checkpoint 2682145968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.21038
Policy Entropy: 4.14728
Value Function Loss: 0.00293

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02153
Policy Update Magnitude: 0.25000
Value Function Update Magnitude: 0.28670

Collected Steps per Second: 22,603.16132
Overall Steps per Second: 10,631.25957

Timestep Collection Time: 2.21288
Timestep Consumption Time: 2.49193
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.70480

Cumulative Model Updates: 321,606
Cumulative Timesteps: 2,682,195,986

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.42479
Policy Entropy: 4.15056
Value Function Loss: 0.00298

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02253
Policy Update Magnitude: 0.26549
Value Function Update Magnitude: 0.29838

Collected Steps per Second: 21,711.53071
Overall Steps per Second: 10,311.48314

Timestep Collection Time: 2.30421
Timestep Consumption Time: 2.54746
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.85168

Cumulative Model Updates: 321,612
Cumulative Timesteps: 2,682,246,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2682246014...
Checkpoint 2682246014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.33602
Policy Entropy: 4.14190
Value Function Loss: 0.00280

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.02406
Policy Update Magnitude: 0.25480
Value Function Update Magnitude: 0.30610

Collected Steps per Second: 21,642.46325
Overall Steps per Second: 10,471.81839

Timestep Collection Time: 2.31138
Timestep Consumption Time: 2.46563
PPO Batch Consumption Time: 0.29889
Total Iteration Time: 4.77701

Cumulative Model Updates: 321,618
Cumulative Timesteps: 2,682,296,038

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.64288
Policy Entropy: 4.16081
Value Function Loss: 0.00234

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.01948
Policy Update Magnitude: 0.23773
Value Function Update Magnitude: 0.28153

Collected Steps per Second: 22,074.80678
Overall Steps per Second: 10,442.32463

Timestep Collection Time: 2.26611
Timestep Consumption Time: 2.52439
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.79050

Cumulative Model Updates: 321,624
Cumulative Timesteps: 2,682,346,062

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2682346062...
Checkpoint 2682346062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.78816
Policy Entropy: 4.15275
Value Function Loss: 0.00252

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.01813
Policy Update Magnitude: 0.23724
Value Function Update Magnitude: 0.25664

Collected Steps per Second: 21,367.15525
Overall Steps per Second: 10,208.63018

Timestep Collection Time: 2.34032
Timestep Consumption Time: 2.55808
PPO Batch Consumption Time: 0.29800
Total Iteration Time: 4.89840

Cumulative Model Updates: 321,630
Cumulative Timesteps: 2,682,396,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.76193
Policy Entropy: 4.14150
Value Function Loss: 0.00261

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02062
Policy Update Magnitude: 0.25078
Value Function Update Magnitude: 0.24510

Collected Steps per Second: 21,973.90751
Overall Steps per Second: 10,523.40354

Timestep Collection Time: 2.27661
Timestep Consumption Time: 2.47718
PPO Batch Consumption Time: 0.29716
Total Iteration Time: 4.75379

Cumulative Model Updates: 321,636
Cumulative Timesteps: 2,682,446,094

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2682446094...
Checkpoint 2682446094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.54887
Policy Entropy: 4.15480
Value Function Loss: 0.00265

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02088
Policy Update Magnitude: 0.23701
Value Function Update Magnitude: 0.25346

Collected Steps per Second: 21,557.98957
Overall Steps per Second: 10,240.07058

Timestep Collection Time: 2.31979
Timestep Consumption Time: 2.56397
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.88376

Cumulative Model Updates: 321,642
Cumulative Timesteps: 2,682,496,104

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.98914
Policy Entropy: 4.17979
Value Function Loss: 0.00201

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02064
Policy Update Magnitude: 0.22330
Value Function Update Magnitude: 0.24827

Collected Steps per Second: 22,210.59735
Overall Steps per Second: 10,497.08142

Timestep Collection Time: 2.25226
Timestep Consumption Time: 2.51326
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.76552

Cumulative Model Updates: 321,648
Cumulative Timesteps: 2,682,546,128

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2682546128...
Checkpoint 2682546128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.33426
Policy Entropy: 4.20115
Value Function Loss: 0.00207

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.01734
Policy Update Magnitude: 0.22381
Value Function Update Magnitude: 0.23242

Collected Steps per Second: 21,825.17321
Overall Steps per Second: 10,503.14964

Timestep Collection Time: 2.29102
Timestep Consumption Time: 2.46964
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 4.76067

Cumulative Model Updates: 321,654
Cumulative Timesteps: 2,682,596,130

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.44431
Policy Entropy: 4.21603
Value Function Loss: 0.00262

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.01536
Policy Update Magnitude: 0.22155
Value Function Update Magnitude: 0.24868

Collected Steps per Second: 21,632.82168
Overall Steps per Second: 10,405.72139

Timestep Collection Time: 2.31177
Timestep Consumption Time: 2.49424
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.80601

Cumulative Model Updates: 321,660
Cumulative Timesteps: 2,682,646,140

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2682646140...
Checkpoint 2682646140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.97242
Policy Entropy: 4.18954
Value Function Loss: 0.00326

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.01844
Policy Update Magnitude: 0.24095
Value Function Update Magnitude: 0.26925

Collected Steps per Second: 21,655.04444
Overall Steps per Second: 10,606.73061

Timestep Collection Time: 2.30967
Timestep Consumption Time: 2.40583
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.71550

Cumulative Model Updates: 321,666
Cumulative Timesteps: 2,682,696,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.45851
Policy Entropy: 4.18787
Value Function Loss: 0.00292

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.01912
Policy Update Magnitude: 0.24111
Value Function Update Magnitude: 0.28834

Collected Steps per Second: 21,888.51308
Overall Steps per Second: 10,479.46638

Timestep Collection Time: 2.28522
Timestep Consumption Time: 2.48793
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.77314

Cumulative Model Updates: 321,672
Cumulative Timesteps: 2,682,746,176

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2682746176...
Checkpoint 2682746176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.26371
Policy Entropy: 4.17886
Value Function Loss: 0.00251

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.01864
Policy Update Magnitude: 0.23037
Value Function Update Magnitude: 0.27806

Collected Steps per Second: 21,399.82325
Overall Steps per Second: 10,289.64897

Timestep Collection Time: 2.33759
Timestep Consumption Time: 2.52400
PPO Batch Consumption Time: 0.29903
Total Iteration Time: 4.86158

Cumulative Model Updates: 321,678
Cumulative Timesteps: 2,682,796,200

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.59370
Policy Entropy: 4.16622
Value Function Loss: 0.00288

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.01793
Policy Update Magnitude: 0.24033
Value Function Update Magnitude: 0.27303

Collected Steps per Second: 21,926.80878
Overall Steps per Second: 10,516.23190

Timestep Collection Time: 2.28040
Timestep Consumption Time: 2.47434
PPO Batch Consumption Time: 0.29695
Total Iteration Time: 4.75474

Cumulative Model Updates: 321,684
Cumulative Timesteps: 2,682,846,202

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2682846202...
Checkpoint 2682846202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.77121
Policy Entropy: 4.14540
Value Function Loss: 0.00307

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.02223
Policy Update Magnitude: 0.25633
Value Function Update Magnitude: 0.30794

Collected Steps per Second: 21,974.27712
Overall Steps per Second: 10,480.90641

Timestep Collection Time: 2.27712
Timestep Consumption Time: 2.49709
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.77421

Cumulative Model Updates: 321,690
Cumulative Timesteps: 2,682,896,240

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.05521
Policy Entropy: 4.13461
Value Function Loss: 0.00369

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.02420
Policy Update Magnitude: 0.25960
Value Function Update Magnitude: 0.32063

Collected Steps per Second: 21,862.80374
Overall Steps per Second: 10,500.25832

Timestep Collection Time: 2.28736
Timestep Consumption Time: 2.47519
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.76255

Cumulative Model Updates: 321,696
Cumulative Timesteps: 2,682,946,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2682946248...
Checkpoint 2682946248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.36420
Policy Entropy: 4.14607
Value Function Loss: 0.00315

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02195
Policy Update Magnitude: 0.25577
Value Function Update Magnitude: 0.30793

Collected Steps per Second: 21,961.62445
Overall Steps per Second: 10,347.38042

Timestep Collection Time: 2.27788
Timestep Consumption Time: 2.55677
PPO Batch Consumption Time: 0.29749
Total Iteration Time: 4.83465

Cumulative Model Updates: 321,702
Cumulative Timesteps: 2,682,996,274

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.30063
Policy Entropy: 4.15067
Value Function Loss: 0.00282

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02307
Policy Update Magnitude: 0.24102
Value Function Update Magnitude: 0.29617

Collected Steps per Second: 22,100.58933
Overall Steps per Second: 10,365.73288

Timestep Collection Time: 2.26256
Timestep Consumption Time: 2.56141
PPO Batch Consumption Time: 0.29734
Total Iteration Time: 4.82397

Cumulative Model Updates: 321,708
Cumulative Timesteps: 2,683,046,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2683046278...
Checkpoint 2683046278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.25770
Policy Entropy: 4.15392
Value Function Loss: 0.00250

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02201
Policy Update Magnitude: 0.23507
Value Function Update Magnitude: 0.28476

Collected Steps per Second: 21,629.39824
Overall Steps per Second: 10,556.40224

Timestep Collection Time: 2.31296
Timestep Consumption Time: 2.42615
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.73911

Cumulative Model Updates: 321,714
Cumulative Timesteps: 2,683,096,306

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.24623
Policy Entropy: 4.17160
Value Function Loss: 0.00284

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02129
Policy Update Magnitude: 0.23534
Value Function Update Magnitude: 0.27727

Collected Steps per Second: 22,118.86329
Overall Steps per Second: 10,526.11399

Timestep Collection Time: 2.26142
Timestep Consumption Time: 2.49057
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.75199

Cumulative Model Updates: 321,720
Cumulative Timesteps: 2,683,146,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2683146326...
Checkpoint 2683146326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.67827
Policy Entropy: 4.16732
Value Function Loss: 0.00324

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02009
Policy Update Magnitude: 0.23921
Value Function Update Magnitude: 0.30727

Collected Steps per Second: 21,576.27490
Overall Steps per Second: 10,212.36301

Timestep Collection Time: 2.31847
Timestep Consumption Time: 2.57990
PPO Batch Consumption Time: 0.30091
Total Iteration Time: 4.89838

Cumulative Model Updates: 321,726
Cumulative Timesteps: 2,683,196,350

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.34613
Policy Entropy: 4.16223
Value Function Loss: 0.00351

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02215
Policy Update Magnitude: 0.24628
Value Function Update Magnitude: 0.32476

Collected Steps per Second: 22,147.93435
Overall Steps per Second: 10,559.50027

Timestep Collection Time: 2.25872
Timestep Consumption Time: 2.47881
PPO Batch Consumption Time: 0.29813
Total Iteration Time: 4.73753

Cumulative Model Updates: 321,732
Cumulative Timesteps: 2,683,246,376

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2683246376...
Checkpoint 2683246376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.34251
Policy Entropy: 4.15315
Value Function Loss: 0.00318

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02434
Policy Update Magnitude: 0.25428
Value Function Update Magnitude: 0.33075

Collected Steps per Second: 21,917.41168
Overall Steps per Second: 10,481.59923

Timestep Collection Time: 2.28275
Timestep Consumption Time: 2.49057
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.77332

Cumulative Model Updates: 321,738
Cumulative Timesteps: 2,683,296,408

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.48504
Policy Entropy: 4.13623
Value Function Loss: 0.00329

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.02116
Policy Update Magnitude: 0.25658
Value Function Update Magnitude: 0.31329

Collected Steps per Second: 22,037.06842
Overall Steps per Second: 10,506.68127

Timestep Collection Time: 2.26918
Timestep Consumption Time: 2.49027
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.75945

Cumulative Model Updates: 321,744
Cumulative Timesteps: 2,683,346,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2683346414...
Checkpoint 2683346414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.42693
Policy Entropy: 4.12882
Value Function Loss: 0.00324

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02131
Policy Update Magnitude: 0.25651
Value Function Update Magnitude: 0.28123

Collected Steps per Second: 21,523.50648
Overall Steps per Second: 10,605.89809

Timestep Collection Time: 2.32323
Timestep Consumption Time: 2.39151
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.71474

Cumulative Model Updates: 321,750
Cumulative Timesteps: 2,683,396,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.87293
Policy Entropy: 4.15508
Value Function Loss: 0.00307

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02233
Policy Update Magnitude: 0.23758
Value Function Update Magnitude: 0.28714

Collected Steps per Second: 21,800.34905
Overall Steps per Second: 10,424.81964

Timestep Collection Time: 2.29363
Timestep Consumption Time: 2.50280
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.79644

Cumulative Model Updates: 321,756
Cumulative Timesteps: 2,683,446,420

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2683446420...
Checkpoint 2683446420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.01270
Policy Entropy: 4.20995
Value Function Loss: 0.00254

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.01953
Policy Update Magnitude: 0.21965
Value Function Update Magnitude: 0.28593

Collected Steps per Second: 21,612.59716
Overall Steps per Second: 10,388.11377

Timestep Collection Time: 2.31467
Timestep Consumption Time: 2.50103
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.81570

Cumulative Model Updates: 321,762
Cumulative Timesteps: 2,683,496,446

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.31073
Policy Entropy: 4.21013
Value Function Loss: 0.00241

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.01492
Policy Update Magnitude: 0.21839
Value Function Update Magnitude: 0.25438

Collected Steps per Second: 22,912.99904
Overall Steps per Second: 10,589.20798

Timestep Collection Time: 2.18295
Timestep Consumption Time: 2.54054
PPO Batch Consumption Time: 0.29556
Total Iteration Time: 4.72349

Cumulative Model Updates: 321,768
Cumulative Timesteps: 2,683,546,464

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2683546464...
Checkpoint 2683546464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.67526
Policy Entropy: 4.18573
Value Function Loss: 0.00244

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.01536
Policy Update Magnitude: 0.22066
Value Function Update Magnitude: 0.26807

Collected Steps per Second: 21,546.19748
Overall Steps per Second: 10,396.04747

Timestep Collection Time: 2.32143
Timestep Consumption Time: 2.48982
PPO Batch Consumption Time: 0.28470
Total Iteration Time: 4.81125

Cumulative Model Updates: 321,774
Cumulative Timesteps: 2,683,596,482

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.59091
Policy Entropy: 4.14431
Value Function Loss: 0.00351

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02147
Policy Update Magnitude: 0.24414
Value Function Update Magnitude: 0.27991

Collected Steps per Second: 21,962.14999
Overall Steps per Second: 10,576.88234

Timestep Collection Time: 2.27701
Timestep Consumption Time: 2.45104
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.72805

Cumulative Model Updates: 321,780
Cumulative Timesteps: 2,683,646,490

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2683646490...
Checkpoint 2683646490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.62714
Policy Entropy: 4.15621
Value Function Loss: 0.00353

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02510
Policy Update Magnitude: 0.24366
Value Function Update Magnitude: 0.27876

Collected Steps per Second: 21,725.14538
Overall Steps per Second: 10,308.86007

Timestep Collection Time: 2.30277
Timestep Consumption Time: 2.55014
PPO Batch Consumption Time: 0.29717
Total Iteration Time: 4.85291

Cumulative Model Updates: 321,786
Cumulative Timesteps: 2,683,696,518

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.80198
Policy Entropy: 4.16056
Value Function Loss: 0.00364

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.02745
Policy Update Magnitude: 0.24157
Value Function Update Magnitude: 0.28012

Collected Steps per Second: 22,000.64803
Overall Steps per Second: 10,414.58662

Timestep Collection Time: 2.27366
Timestep Consumption Time: 2.52941
PPO Batch Consumption Time: 0.29773
Total Iteration Time: 4.80307

Cumulative Model Updates: 321,792
Cumulative Timesteps: 2,683,746,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2683746540...
Checkpoint 2683746540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.90685
Policy Entropy: 4.14191
Value Function Loss: 0.00342

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.02716
Policy Update Magnitude: 0.25225
Value Function Update Magnitude: 0.28863

Collected Steps per Second: 22,407.43849
Overall Steps per Second: 10,604.04667

Timestep Collection Time: 2.23194
Timestep Consumption Time: 2.48438
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.71631

Cumulative Model Updates: 321,798
Cumulative Timesteps: 2,683,796,552

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.73691
Policy Entropy: 4.13296
Value Function Loss: 0.00340

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.02525
Policy Update Magnitude: 0.26995
Value Function Update Magnitude: 0.31769

Collected Steps per Second: 21,918.66911
Overall Steps per Second: 10,407.43809

Timestep Collection Time: 2.28116
Timestep Consumption Time: 2.52310
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.80426

Cumulative Model Updates: 321,804
Cumulative Timesteps: 2,683,846,552

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2683846552...
Checkpoint 2683846552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.68237
Policy Entropy: 4.12030
Value Function Loss: 0.00326

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.02553
Policy Update Magnitude: 0.26956
Value Function Update Magnitude: 0.31939

Collected Steps per Second: 21,746.00793
Overall Steps per Second: 10,416.05475

Timestep Collection Time: 2.30019
Timestep Consumption Time: 2.50201
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.80220

Cumulative Model Updates: 321,810
Cumulative Timesteps: 2,683,896,572

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.65590
Policy Entropy: 4.14214
Value Function Loss: 0.00262

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.02524
Policy Update Magnitude: 0.25863
Value Function Update Magnitude: 0.30894

Collected Steps per Second: 22,802.49609
Overall Steps per Second: 10,687.85198

Timestep Collection Time: 2.19274
Timestep Consumption Time: 2.48547
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.67821

Cumulative Model Updates: 321,816
Cumulative Timesteps: 2,683,946,572

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2683946572...
Checkpoint 2683946572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.27011
Policy Entropy: 4.14125
Value Function Loss: 0.00311

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.02377
Policy Update Magnitude: 0.25571
Value Function Update Magnitude: 0.30462

Collected Steps per Second: 21,476.45129
Overall Steps per Second: 10,246.46826

Timestep Collection Time: 2.32934
Timestep Consumption Time: 2.55293
PPO Batch Consumption Time: 0.29692
Total Iteration Time: 4.88227

Cumulative Model Updates: 321,822
Cumulative Timesteps: 2,683,996,598

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.12562
Policy Entropy: 4.12818
Value Function Loss: 0.00335

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.02484
Policy Update Magnitude: 0.25951
Value Function Update Magnitude: 0.31624

Collected Steps per Second: 21,953.37169
Overall Steps per Second: 10,529.24175

Timestep Collection Time: 2.27847
Timestep Consumption Time: 2.47211
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 4.75058

Cumulative Model Updates: 321,828
Cumulative Timesteps: 2,684,046,618

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2684046618...
Checkpoint 2684046618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.42561
Policy Entropy: 4.11550
Value Function Loss: 0.00365

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.02569
Policy Update Magnitude: 0.26686
Value Function Update Magnitude: 0.32646

Collected Steps per Second: 21,735.34697
Overall Steps per Second: 10,440.22112

Timestep Collection Time: 2.30178
Timestep Consumption Time: 2.49026
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.79204

Cumulative Model Updates: 321,834
Cumulative Timesteps: 2,684,096,648

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.21369
Policy Entropy: 4.14521
Value Function Loss: 0.00306

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.02631
Policy Update Magnitude: 0.25602
Value Function Update Magnitude: 0.32271

Collected Steps per Second: 21,862.37847
Overall Steps per Second: 10,528.03246

Timestep Collection Time: 2.28786
Timestep Consumption Time: 2.46308
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.75094

Cumulative Model Updates: 321,840
Cumulative Timesteps: 2,684,146,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2684146666...
Checkpoint 2684146666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.07230
Policy Entropy: 4.18906
Value Function Loss: 0.00277

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02185
Policy Update Magnitude: 0.24193
Value Function Update Magnitude: 0.29878

Collected Steps per Second: 22,252.21956
Overall Steps per Second: 10,462.76925

Timestep Collection Time: 2.24724
Timestep Consumption Time: 2.53219
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.77942

Cumulative Model Updates: 321,846
Cumulative Timesteps: 2,684,196,672

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.87386
Policy Entropy: 4.22607
Value Function Loss: 0.00320

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02090
Policy Update Magnitude: 0.23982
Value Function Update Magnitude: 0.29290

Collected Steps per Second: 22,039.02869
Overall Steps per Second: 10,328.73879

Timestep Collection Time: 2.26979
Timestep Consumption Time: 2.57339
PPO Batch Consumption Time: 0.29786
Total Iteration Time: 4.84319

Cumulative Model Updates: 321,852
Cumulative Timesteps: 2,684,246,696

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2684246696...
Checkpoint 2684246696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.67904
Policy Entropy: 4.21365
Value Function Loss: 0.00292

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02231
Policy Update Magnitude: 0.23890
Value Function Update Magnitude: 0.29961

Collected Steps per Second: 21,532.94879
Overall Steps per Second: 10,444.88595

Timestep Collection Time: 2.32295
Timestep Consumption Time: 2.46599
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.78895

Cumulative Model Updates: 321,858
Cumulative Timesteps: 2,684,296,716

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.26817
Policy Entropy: 4.19563
Value Function Loss: 0.00310

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02378
Policy Update Magnitude: 0.24402
Value Function Update Magnitude: 0.29641

Collected Steps per Second: 22,509.56645
Overall Steps per Second: 10,557.55499

Timestep Collection Time: 2.22217
Timestep Consumption Time: 2.51567
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.73784

Cumulative Model Updates: 321,864
Cumulative Timesteps: 2,684,346,736

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2684346736...
Checkpoint 2684346736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.73588
Policy Entropy: 4.19700
Value Function Loss: 0.00282

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02414
Policy Update Magnitude: 0.23994
Value Function Update Magnitude: 0.29408

Collected Steps per Second: 21,626.14707
Overall Steps per Second: 10,275.29092

Timestep Collection Time: 2.31340
Timestep Consumption Time: 2.55556
PPO Batch Consumption Time: 0.29871
Total Iteration Time: 4.86896

Cumulative Model Updates: 321,870
Cumulative Timesteps: 2,684,396,766

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.32575
Policy Entropy: 4.18316
Value Function Loss: 0.00342

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02341
Policy Update Magnitude: 0.24373
Value Function Update Magnitude: 0.29760

Collected Steps per Second: 22,127.02410
Overall Steps per Second: 10,547.07813

Timestep Collection Time: 2.26095
Timestep Consumption Time: 2.48236
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.74330

Cumulative Model Updates: 321,876
Cumulative Timesteps: 2,684,446,794

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2684446794...
Checkpoint 2684446794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.49905
Policy Entropy: 4.19622
Value Function Loss: 0.00312

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02271
Policy Update Magnitude: 0.24612
Value Function Update Magnitude: 0.31460

Collected Steps per Second: 22,175.10934
Overall Steps per Second: 10,506.45123

Timestep Collection Time: 2.25595
Timestep Consumption Time: 2.50550
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.76146

Cumulative Model Updates: 321,882
Cumulative Timesteps: 2,684,496,820

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.53456
Policy Entropy: 4.19183
Value Function Loss: 0.00262

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02337
Policy Update Magnitude: 0.23220
Value Function Update Magnitude: 0.31474

Collected Steps per Second: 22,145.01678
Overall Steps per Second: 10,474.79730

Timestep Collection Time: 2.25848
Timestep Consumption Time: 2.51622
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.77470

Cumulative Model Updates: 321,888
Cumulative Timesteps: 2,684,546,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2684546834...
Checkpoint 2684546834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.30699
Policy Entropy: 4.21017
Value Function Loss: 0.00223

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.01861
Policy Update Magnitude: 0.22670
Value Function Update Magnitude: 0.29208

Collected Steps per Second: 21,530.42589
Overall Steps per Second: 10,569.80862

Timestep Collection Time: 2.32322
Timestep Consumption Time: 2.40912
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.73235

Cumulative Model Updates: 321,894
Cumulative Timesteps: 2,684,596,854

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.08551
Policy Entropy: 4.19891
Value Function Loss: 0.00240

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.01768
Policy Update Magnitude: 0.22667
Value Function Update Magnitude: 0.27473

Collected Steps per Second: 21,900.31455
Overall Steps per Second: 10,449.96606

Timestep Collection Time: 2.28335
Timestep Consumption Time: 2.50193
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.78528

Cumulative Model Updates: 321,900
Cumulative Timesteps: 2,684,646,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2684646860...
Checkpoint 2684646860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.93493
Policy Entropy: 4.19817
Value Function Loss: 0.00271

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.01726
Policy Update Magnitude: 0.23002
Value Function Update Magnitude: 0.27672

Collected Steps per Second: 21,828.22992
Overall Steps per Second: 10,379.70756

Timestep Collection Time: 2.29116
Timestep Consumption Time: 2.52709
PPO Batch Consumption Time: 0.29708
Total Iteration Time: 4.81825

Cumulative Model Updates: 321,906
Cumulative Timesteps: 2,684,696,872

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.47582
Policy Entropy: 4.15861
Value Function Loss: 0.00349

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02014
Policy Update Magnitude: 0.25590
Value Function Update Magnitude: 0.29106

Collected Steps per Second: 22,393.01760
Overall Steps per Second: 10,444.22317

Timestep Collection Time: 2.23373
Timestep Consumption Time: 2.55552
PPO Batch Consumption Time: 0.29745
Total Iteration Time: 4.78925

Cumulative Model Updates: 321,912
Cumulative Timesteps: 2,684,746,892

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2684746892...
Checkpoint 2684746892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.56609
Policy Entropy: 4.15724
Value Function Loss: 0.00399

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02103
Policy Update Magnitude: 0.27041
Value Function Update Magnitude: 0.33359

Collected Steps per Second: 22,087.90481
Overall Steps per Second: 10,518.18038

Timestep Collection Time: 2.26495
Timestep Consumption Time: 2.49139
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.75634

Cumulative Model Updates: 321,918
Cumulative Timesteps: 2,684,796,920

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.57328
Policy Entropy: 4.15603
Value Function Loss: 0.00345

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.02052
Policy Update Magnitude: 0.25991
Value Function Update Magnitude: 0.36146

Collected Steps per Second: 21,774.26435
Overall Steps per Second: 10,517.76851

Timestep Collection Time: 2.29748
Timestep Consumption Time: 2.45885
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.75633

Cumulative Model Updates: 321,924
Cumulative Timesteps: 2,684,846,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2684846946...
Checkpoint 2684846946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.65988
Policy Entropy: 4.16561
Value Function Loss: 0.00325

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.01755
Policy Update Magnitude: 0.25696
Value Function Update Magnitude: 0.33135

Collected Steps per Second: 21,951.09299
Overall Steps per Second: 10,354.52875

Timestep Collection Time: 2.27852
Timestep Consumption Time: 2.55183
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.83035

Cumulative Model Updates: 321,930
Cumulative Timesteps: 2,684,896,962

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.51399
Policy Entropy: 4.16770
Value Function Loss: 0.00282

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.01885
Policy Update Magnitude: 0.25478
Value Function Update Magnitude: 0.32524

Collected Steps per Second: 21,830.56177
Overall Steps per Second: 10,397.13977

Timestep Collection Time: 2.29174
Timestep Consumption Time: 2.52016
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.81190

Cumulative Model Updates: 321,936
Cumulative Timesteps: 2,684,946,992

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2684946992...
Checkpoint 2684946992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.84840
Policy Entropy: 4.16203
Value Function Loss: 0.00263

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.01957
Policy Update Magnitude: 0.24524
Value Function Update Magnitude: 0.31197

Collected Steps per Second: 21,533.72851
Overall Steps per Second: 10,610.47374

Timestep Collection Time: 2.32240
Timestep Consumption Time: 2.39086
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.71327

Cumulative Model Updates: 321,942
Cumulative Timesteps: 2,684,997,002

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.08104
Policy Entropy: 4.18815
Value Function Loss: 0.00261

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.01914
Policy Update Magnitude: 0.23654
Value Function Update Magnitude: 0.29828

Collected Steps per Second: 22,105.83426
Overall Steps per Second: 10,408.72014

Timestep Collection Time: 2.26194
Timestep Consumption Time: 2.54192
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.80386

Cumulative Model Updates: 321,948
Cumulative Timesteps: 2,685,047,004

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2685047004...
Checkpoint 2685047004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.24012
Policy Entropy: 4.19527
Value Function Loss: 0.00260

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.01804
Policy Update Magnitude: 0.24423
Value Function Update Magnitude: 0.30365

Collected Steps per Second: 21,615.36979
Overall Steps per Second: 10,329.34933

Timestep Collection Time: 2.31335
Timestep Consumption Time: 2.52761
PPO Batch Consumption Time: 0.29634
Total Iteration Time: 4.84096

Cumulative Model Updates: 321,954
Cumulative Timesteps: 2,685,097,008

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.18207
Policy Entropy: 4.19336
Value Function Loss: 0.00241

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.01791
Policy Update Magnitude: 0.22981
Value Function Update Magnitude: 0.29080

Collected Steps per Second: 22,631.12786
Overall Steps per Second: 10,545.43156

Timestep Collection Time: 2.21023
Timestep Consumption Time: 2.53306
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.74329

Cumulative Model Updates: 321,960
Cumulative Timesteps: 2,685,147,028

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2685147028...
Checkpoint 2685147028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.83202
Policy Entropy: 4.20028
Value Function Loss: 0.00220

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.01744
Policy Update Magnitude: 0.22173
Value Function Update Magnitude: 0.28016

Collected Steps per Second: 21,813.12389
Overall Steps per Second: 10,451.75871

Timestep Collection Time: 2.29256
Timestep Consumption Time: 2.49208
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.78465

Cumulative Model Updates: 321,966
Cumulative Timesteps: 2,685,197,036

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.32212
Policy Entropy: 4.20221
Value Function Loss: 0.00253

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.01781
Policy Update Magnitude: 0.23162
Value Function Update Magnitude: 0.27555

Collected Steps per Second: 22,054.30032
Overall Steps per Second: 10,560.03862

Timestep Collection Time: 2.26804
Timestep Consumption Time: 2.46869
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.73673

Cumulative Model Updates: 321,972
Cumulative Timesteps: 2,685,247,056

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2685247056...
Checkpoint 2685247056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.24319
Policy Entropy: 4.19568
Value Function Loss: 0.00267

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.01584
Policy Update Magnitude: 0.22642
Value Function Update Magnitude: 0.29729

Collected Steps per Second: 21,879.10591
Overall Steps per Second: 10,457.81779

Timestep Collection Time: 2.28657
Timestep Consumption Time: 2.49722
PPO Batch Consumption Time: 0.28493
Total Iteration Time: 4.78379

Cumulative Model Updates: 321,978
Cumulative Timesteps: 2,685,297,084

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.19189
Policy Entropy: 4.18456
Value Function Loss: 0.00293

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.01795
Policy Update Magnitude: 0.23668
Value Function Update Magnitude: 0.29144

Collected Steps per Second: 21,866.17688
Overall Steps per Second: 10,476.02529

Timestep Collection Time: 2.28792
Timestep Consumption Time: 2.48756
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.77548

Cumulative Model Updates: 321,984
Cumulative Timesteps: 2,685,347,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2685347112...
Checkpoint 2685347112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.17215
Policy Entropy: 4.16075
Value Function Loss: 0.00320

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.01950
Policy Update Magnitude: 0.24146
Value Function Update Magnitude: 0.28626

Collected Steps per Second: 22,424.70545
Overall Steps per Second: 10,611.67133

Timestep Collection Time: 2.23102
Timestep Consumption Time: 2.48360
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.71462

Cumulative Model Updates: 321,990
Cumulative Timesteps: 2,685,397,142

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.56963
Policy Entropy: 4.15743
Value Function Loss: 0.00372

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.01985
Policy Update Magnitude: 0.25330
Value Function Update Magnitude: 0.29795

Collected Steps per Second: 21,934.37033
Overall Steps per Second: 10,442.63345

Timestep Collection Time: 2.28090
Timestep Consumption Time: 2.51004
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.79094

Cumulative Model Updates: 321,996
Cumulative Timesteps: 2,685,447,172

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2685447172...
Checkpoint 2685447172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.09172
Policy Entropy: 4.13500
Value Function Loss: 0.00381

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.02610
Policy Update Magnitude: 0.27100
Value Function Update Magnitude: 0.32640

Collected Steps per Second: 21,708.51668
Overall Steps per Second: 10,321.90582

Timestep Collection Time: 2.30416
Timestep Consumption Time: 2.54184
PPO Batch Consumption Time: 0.29758
Total Iteration Time: 4.84600

Cumulative Model Updates: 322,002
Cumulative Timesteps: 2,685,497,192

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.89572
Policy Entropy: 4.14390
Value Function Loss: 0.00372

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.02447
Policy Update Magnitude: 0.27355
Value Function Update Magnitude: 0.34182

Collected Steps per Second: 22,412.04728
Overall Steps per Second: 10,458.28432

Timestep Collection Time: 2.23094
Timestep Consumption Time: 2.54996
PPO Batch Consumption Time: 0.29816
Total Iteration Time: 4.78090

Cumulative Model Updates: 322,008
Cumulative Timesteps: 2,685,547,192

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2685547192...
Checkpoint 2685547192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.43653
Policy Entropy: 4.16830
Value Function Loss: 0.00326

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.02396
Policy Update Magnitude: 0.25886
Value Function Update Magnitude: 0.33037

Collected Steps per Second: 21,493.85887
Overall Steps per Second: 10,258.37305

Timestep Collection Time: 2.32634
Timestep Consumption Time: 2.54792
PPO Batch Consumption Time: 0.29825
Total Iteration Time: 4.87426

Cumulative Model Updates: 322,014
Cumulative Timesteps: 2,685,597,194

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.15760
Policy Entropy: 4.19495
Value Function Loss: 0.00295

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.02041
Policy Update Magnitude: 0.24222
Value Function Update Magnitude: 0.30730

Collected Steps per Second: 22,112.10525
Overall Steps per Second: 10,720.27642

Timestep Collection Time: 2.26202
Timestep Consumption Time: 2.40372
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.66574

Cumulative Model Updates: 322,020
Cumulative Timesteps: 2,685,647,212

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2685647212...
Checkpoint 2685647212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.94854
Policy Entropy: 4.20309
Value Function Loss: 0.00304

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.01858
Policy Update Magnitude: 0.23717
Value Function Update Magnitude: 0.29567

Collected Steps per Second: 21,891.51786
Overall Steps per Second: 10,370.52873

Timestep Collection Time: 2.28408
Timestep Consumption Time: 2.53747
PPO Batch Consumption Time: 0.29716
Total Iteration Time: 4.82155

Cumulative Model Updates: 322,026
Cumulative Timesteps: 2,685,697,214

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.69067
Policy Entropy: 4.17866
Value Function Loss: 0.00301

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02077
Policy Update Magnitude: 0.23500
Value Function Update Magnitude: 0.29245

Collected Steps per Second: 21,558.61577
Overall Steps per Second: 10,418.15462

Timestep Collection Time: 2.32009
Timestep Consumption Time: 2.48095
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.80104

Cumulative Model Updates: 322,032
Cumulative Timesteps: 2,685,747,232

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2685747232...
Checkpoint 2685747232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.09795
Policy Entropy: 4.16311
Value Function Loss: 0.00288

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02001
Policy Update Magnitude: 0.23476
Value Function Update Magnitude: 0.28561

Collected Steps per Second: 22,392.82742
Overall Steps per Second: 10,528.70455

Timestep Collection Time: 2.23393
Timestep Consumption Time: 2.51727
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.75120

Cumulative Model Updates: 322,038
Cumulative Timesteps: 2,685,797,256

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.16050
Policy Entropy: 4.15195
Value Function Loss: 0.00302

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.01757
Policy Update Magnitude: 0.24562
Value Function Update Magnitude: 0.27925

Collected Steps per Second: 21,718.99515
Overall Steps per Second: 10,224.89097

Timestep Collection Time: 2.30268
Timestep Consumption Time: 2.58852
PPO Batch Consumption Time: 0.30084
Total Iteration Time: 4.89120

Cumulative Model Updates: 322,044
Cumulative Timesteps: 2,685,847,268

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2685847268...
Checkpoint 2685847268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.89682
Policy Entropy: 4.18178
Value Function Loss: 0.00238

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.01889
Policy Update Magnitude: 0.23648
Value Function Update Magnitude: 0.27511

Collected Steps per Second: 22,170.51761
Overall Steps per Second: 10,668.28259

Timestep Collection Time: 2.25615
Timestep Consumption Time: 2.43252
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.68866

Cumulative Model Updates: 322,050
Cumulative Timesteps: 2,685,897,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.39635
Policy Entropy: 4.18988
Value Function Loss: 0.00252

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.01697
Policy Update Magnitude: 0.22925
Value Function Update Magnitude: 0.25623

Collected Steps per Second: 22,632.08682
Overall Steps per Second: 10,781.83706

Timestep Collection Time: 2.21058
Timestep Consumption Time: 2.42963
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.64021

Cumulative Model Updates: 322,056
Cumulative Timesteps: 2,685,947,318

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2685947318...
Checkpoint 2685947318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.24280
Policy Entropy: 4.17364
Value Function Loss: 0.00297

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.01972
Policy Update Magnitude: 0.23307
Value Function Update Magnitude: 0.26046

Collected Steps per Second: 22,662.12488
Overall Steps per Second: 10,723.93556

Timestep Collection Time: 2.20659
Timestep Consumption Time: 2.45644
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.66303

Cumulative Model Updates: 322,062
Cumulative Timesteps: 2,685,997,324

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.91211
Policy Entropy: 4.17253
Value Function Loss: 0.00306

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.02244
Policy Update Magnitude: 0.23614
Value Function Update Magnitude: 0.26615

Collected Steps per Second: 22,274.19842
Overall Steps per Second: 10,851.13412

Timestep Collection Time: 2.24556
Timestep Consumption Time: 2.36391
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.60947

Cumulative Model Updates: 322,068
Cumulative Timesteps: 2,686,047,342

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2686047342...
Checkpoint 2686047342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.18578
Policy Entropy: 4.18884
Value Function Loss: 0.00258

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02135
Policy Update Magnitude: 0.23202
Value Function Update Magnitude: 0.26427

Collected Steps per Second: 22,486.51048
Overall Steps per Second: 10,715.39750

Timestep Collection Time: 2.22436
Timestep Consumption Time: 2.44351
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.66786

Cumulative Model Updates: 322,074
Cumulative Timesteps: 2,686,097,360

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.72529
Policy Entropy: 4.20665
Value Function Loss: 0.00224

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.01740
Policy Update Magnitude: 0.21611
Value Function Update Magnitude: 0.24506

Collected Steps per Second: 21,962.12030
Overall Steps per Second: 10,475.52489

Timestep Collection Time: 2.27829
Timestep Consumption Time: 2.49818
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.77647

Cumulative Model Updates: 322,080
Cumulative Timesteps: 2,686,147,396

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2686147396...
Checkpoint 2686147396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.04220
Policy Entropy: 4.21698
Value Function Loss: 0.00239

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.01688
Policy Update Magnitude: 0.21845
Value Function Update Magnitude: 0.25314

Collected Steps per Second: 21,711.42227
Overall Steps per Second: 10,610.28737

Timestep Collection Time: 2.30312
Timestep Consumption Time: 2.40967
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.71278

Cumulative Model Updates: 322,086
Cumulative Timesteps: 2,686,197,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.15901
Policy Entropy: 4.19197
Value Function Loss: 0.00261

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.01968
Policy Update Magnitude: 0.22183
Value Function Update Magnitude: 0.28391

Collected Steps per Second: 22,235.80257
Overall Steps per Second: 10,506.60019

Timestep Collection Time: 2.24917
Timestep Consumption Time: 2.51089
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.76006

Cumulative Model Updates: 322,092
Cumulative Timesteps: 2,686,247,412

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2686247412...
Checkpoint 2686247412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.82377
Policy Entropy: 4.19911
Value Function Loss: 0.00308

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.01833
Policy Update Magnitude: 0.23559
Value Function Update Magnitude: 0.27756

Collected Steps per Second: 21,822.15853
Overall Steps per Second: 10,568.58885

Timestep Collection Time: 2.29152
Timestep Consumption Time: 2.44004
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.73157

Cumulative Model Updates: 322,098
Cumulative Timesteps: 2,686,297,418

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.74972
Policy Entropy: 4.18154
Value Function Loss: 0.00282

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.01938
Policy Update Magnitude: 0.23219
Value Function Update Magnitude: 0.29597

Collected Steps per Second: 23,059.50270
Overall Steps per Second: 10,896.35466

Timestep Collection Time: 2.16943
Timestep Consumption Time: 2.42165
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.59108

Cumulative Model Updates: 322,104
Cumulative Timesteps: 2,686,347,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2686347444...
Checkpoint 2686347444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.87083
Policy Entropy: 4.21686
Value Function Loss: 0.00228

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01592
Policy Update Magnitude: 0.22242
Value Function Update Magnitude: 0.27348

Collected Steps per Second: 22,145.19563
Overall Steps per Second: 10,638.82530

Timestep Collection Time: 2.25873
Timestep Consumption Time: 2.44292
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.70165

Cumulative Model Updates: 322,110
Cumulative Timesteps: 2,686,397,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.18386
Policy Entropy: 4.19898
Value Function Loss: 0.00243

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.01693
Policy Update Magnitude: 0.21857
Value Function Update Magnitude: 0.25515

Collected Steps per Second: 22,324.29826
Overall Steps per Second: 10,578.72031

Timestep Collection Time: 2.24016
Timestep Consumption Time: 2.48725
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.72741

Cumulative Model Updates: 322,116
Cumulative Timesteps: 2,686,447,474

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2686447474...
Checkpoint 2686447474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.59357
Policy Entropy: 4.18774
Value Function Loss: 0.00259

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.01796
Policy Update Magnitude: 0.23167
Value Function Update Magnitude: 0.26838

Collected Steps per Second: 23,123.44444
Overall Steps per Second: 10,802.88481

Timestep Collection Time: 2.16248
Timestep Consumption Time: 2.46628
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.62876

Cumulative Model Updates: 322,122
Cumulative Timesteps: 2,686,497,478

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.15395
Policy Entropy: 4.16225
Value Function Loss: 0.00289

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02351
Policy Update Magnitude: 0.24819
Value Function Update Magnitude: 0.28691

Collected Steps per Second: 22,199.68344
Overall Steps per Second: 10,674.66117

Timestep Collection Time: 2.25301
Timestep Consumption Time: 2.43248
PPO Batch Consumption Time: 0.27709
Total Iteration Time: 4.68549

Cumulative Model Updates: 322,128
Cumulative Timesteps: 2,686,547,494

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2686547494...
Checkpoint 2686547494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.27268
Policy Entropy: 4.18198
Value Function Loss: 0.00287

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02226
Policy Update Magnitude: 0.24879
Value Function Update Magnitude: 0.28138

Collected Steps per Second: 22,085.67474
Overall Steps per Second: 10,663.08133

Timestep Collection Time: 2.26518
Timestep Consumption Time: 2.42652
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.69170

Cumulative Model Updates: 322,134
Cumulative Timesteps: 2,686,597,522

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.47275
Policy Entropy: 4.21043
Value Function Loss: 0.00262

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.01998
Policy Update Magnitude: 0.23367
Value Function Update Magnitude: 0.27043

Collected Steps per Second: 22,670.04014
Overall Steps per Second: 10,786.10867

Timestep Collection Time: 2.20635
Timestep Consumption Time: 2.43091
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.63726

Cumulative Model Updates: 322,140
Cumulative Timesteps: 2,686,647,540

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2686647540...
Checkpoint 2686647540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.52966
Policy Entropy: 4.22310
Value Function Loss: 0.00242

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.01896
Policy Update Magnitude: 0.22113
Value Function Update Magnitude: 0.25687

Collected Steps per Second: 20,237.54080
Overall Steps per Second: 9,858.80902

Timestep Collection Time: 2.47095
Timestep Consumption Time: 2.60126
PPO Batch Consumption Time: 0.30501
Total Iteration Time: 5.07222

Cumulative Model Updates: 322,146
Cumulative Timesteps: 2,686,697,546

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.72932
Policy Entropy: 4.19611
Value Function Loss: 0.00306

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.01873
Policy Update Magnitude: 0.22598
Value Function Update Magnitude: 0.25587

Collected Steps per Second: 22,880.63968
Overall Steps per Second: 10,638.06792

Timestep Collection Time: 2.18534
Timestep Consumption Time: 2.51495
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.70029

Cumulative Model Updates: 322,152
Cumulative Timesteps: 2,686,747,548

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2686747548...
Checkpoint 2686747548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.14018
Policy Entropy: 4.19870
Value Function Loss: 0.00287

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02183
Policy Update Magnitude: 0.22823
Value Function Update Magnitude: 0.25522

Collected Steps per Second: 21,971.63381
Overall Steps per Second: 10,458.02069

Timestep Collection Time: 2.27584
Timestep Consumption Time: 2.50556
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.78140

Cumulative Model Updates: 322,158
Cumulative Timesteps: 2,686,797,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.40132
Policy Entropy: 4.18312
Value Function Loss: 0.00300

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02414
Policy Update Magnitude: 0.23291
Value Function Update Magnitude: 0.25898

Collected Steps per Second: 22,300.04161
Overall Steps per Second: 10,551.48565

Timestep Collection Time: 2.24331
Timestep Consumption Time: 2.49782
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.74113

Cumulative Model Updates: 322,164
Cumulative Timesteps: 2,686,847,578

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2686847578...
Checkpoint 2686847578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.59943
Policy Entropy: 4.21509
Value Function Loss: 0.00211

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.01820
Policy Update Magnitude: 0.23856
Value Function Update Magnitude: 0.24693

Collected Steps per Second: 23,129.03365
Overall Steps per Second: 10,703.00274

Timestep Collection Time: 2.16204
Timestep Consumption Time: 2.51010
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.67215

Cumulative Model Updates: 322,170
Cumulative Timesteps: 2,686,897,584

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.33135
Policy Entropy: 4.19900
Value Function Loss: 0.00246

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02055
Policy Update Magnitude: 0.22863
Value Function Update Magnitude: 0.24345

Collected Steps per Second: 22,079.56985
Overall Steps per Second: 10,448.05625

Timestep Collection Time: 2.26635
Timestep Consumption Time: 2.52306
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.78941

Cumulative Model Updates: 322,176
Cumulative Timesteps: 2,686,947,624

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2686947624...
Checkpoint 2686947624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.71595
Policy Entropy: 4.19143
Value Function Loss: 0.00237

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02039
Policy Update Magnitude: 0.22708
Value Function Update Magnitude: 0.25364

Collected Steps per Second: 22,473.78224
Overall Steps per Second: 10,902.46652

Timestep Collection Time: 2.22544
Timestep Consumption Time: 2.36196
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.58740

Cumulative Model Updates: 322,182
Cumulative Timesteps: 2,686,997,638

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.80917
Policy Entropy: 4.17506
Value Function Loss: 0.00298

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02274
Policy Update Magnitude: 0.22930
Value Function Update Magnitude: 0.25465

Collected Steps per Second: 22,061.54002
Overall Steps per Second: 10,603.79419

Timestep Collection Time: 2.26693
Timestep Consumption Time: 2.44949
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.71643

Cumulative Model Updates: 322,188
Cumulative Timesteps: 2,687,047,650

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2687047650...
Checkpoint 2687047650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.34603
Policy Entropy: 4.15384
Value Function Loss: 0.00325

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02338
Policy Update Magnitude: 0.24243
Value Function Update Magnitude: 0.26342

Collected Steps per Second: 22,174.35953
Overall Steps per Second: 10,560.78307

Timestep Collection Time: 2.25576
Timestep Consumption Time: 2.48063
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.73639

Cumulative Model Updates: 322,194
Cumulative Timesteps: 2,687,097,670

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.46497
Policy Entropy: 4.16537
Value Function Loss: 0.00294

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02112
Policy Update Magnitude: 0.25003
Value Function Update Magnitude: 0.29194

Collected Steps per Second: 23,067.78796
Overall Steps per Second: 10,833.65560

Timestep Collection Time: 2.16822
Timestep Consumption Time: 2.44851
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.61672

Cumulative Model Updates: 322,200
Cumulative Timesteps: 2,687,147,686

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2687147686...
Checkpoint 2687147686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.89611
Policy Entropy: 4.17129
Value Function Loss: 0.00269

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02148
Policy Update Magnitude: 0.24804
Value Function Update Magnitude: 0.29861

Collected Steps per Second: 22,011.27775
Overall Steps per Second: 10,617.80436

Timestep Collection Time: 2.27256
Timestep Consumption Time: 2.43858
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.71114

Cumulative Model Updates: 322,206
Cumulative Timesteps: 2,687,197,708

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.25811
Policy Entropy: 4.21886
Value Function Loss: 0.00200

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.01743
Policy Update Magnitude: 0.22414
Value Function Update Magnitude: 0.27743

Collected Steps per Second: 22,383.18398
Overall Steps per Second: 10,735.57051

Timestep Collection Time: 2.23480
Timestep Consumption Time: 2.42466
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.65946

Cumulative Model Updates: 322,212
Cumulative Timesteps: 2,687,247,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2687247730...
Checkpoint 2687247730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.28319
Policy Entropy: 4.24062
Value Function Loss: 0.00167

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.01556
Policy Update Magnitude: 0.20082
Value Function Update Magnitude: 0.24387

Collected Steps per Second: 21,322.50422
Overall Steps per Second: 10,376.28975

Timestep Collection Time: 2.34597
Timestep Consumption Time: 2.47483
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.82080

Cumulative Model Updates: 322,218
Cumulative Timesteps: 2,687,297,752

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.71158
Policy Entropy: 4.22346
Value Function Loss: 0.00261

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.01519
Policy Update Magnitude: 0.22295
Value Function Update Magnitude: 0.23347

Collected Steps per Second: 22,302.28246
Overall Steps per Second: 10,547.64446

Timestep Collection Time: 2.24192
Timestep Consumption Time: 2.49847
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.74039

Cumulative Model Updates: 322,224
Cumulative Timesteps: 2,687,347,752

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2687347752...
Checkpoint 2687347752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.57814
Policy Entropy: 4.19054
Value Function Loss: 0.00314

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.01969
Policy Update Magnitude: 0.24367
Value Function Update Magnitude: 0.26628

Collected Steps per Second: 22,279.05740
Overall Steps per Second: 10,633.33516

Timestep Collection Time: 2.24462
Timestep Consumption Time: 2.45833
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.70295

Cumulative Model Updates: 322,230
Cumulative Timesteps: 2,687,397,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.60047
Policy Entropy: 4.16002
Value Function Loss: 0.00341

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02279
Policy Update Magnitude: 0.25395
Value Function Update Magnitude: 0.29721

Collected Steps per Second: 22,318.31036
Overall Steps per Second: 10,474.40367

Timestep Collection Time: 2.24130
Timestep Consumption Time: 2.53434
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.77564

Cumulative Model Updates: 322,236
Cumulative Timesteps: 2,687,447,782

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2687447782...
Checkpoint 2687447782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.33628
Policy Entropy: 4.18619
Value Function Loss: 0.00247

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.01982
Policy Update Magnitude: 0.24467
Value Function Update Magnitude: 0.29855

Collected Steps per Second: 21,653.12423
Overall Steps per Second: 10,554.18996

Timestep Collection Time: 2.30914
Timestep Consumption Time: 2.42832
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.73746

Cumulative Model Updates: 322,242
Cumulative Timesteps: 2,687,497,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.38014
Policy Entropy: 4.17963
Value Function Loss: 0.00224

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.02089
Policy Update Magnitude: 0.23843
Value Function Update Magnitude: 0.27944

Collected Steps per Second: 23,069.88830
Overall Steps per Second: 10,700.87775

Timestep Collection Time: 2.16802
Timestep Consumption Time: 2.50599
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.67401

Cumulative Model Updates: 322,248
Cumulative Timesteps: 2,687,547,798

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2687547798...
Checkpoint 2687547798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.17454
Policy Entropy: 4.17974
Value Function Loss: 0.00218

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.01870
Policy Update Magnitude: 0.23575
Value Function Update Magnitude: 0.27590

Collected Steps per Second: 22,349.36983
Overall Steps per Second: 10,494.44653

Timestep Collection Time: 2.23827
Timestep Consumption Time: 2.52844
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.76671

Cumulative Model Updates: 322,254
Cumulative Timesteps: 2,687,597,822

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.05876
Policy Entropy: 4.16226
Value Function Loss: 0.00241

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.01965
Policy Update Magnitude: 0.24302
Value Function Update Magnitude: 0.27642

Collected Steps per Second: 21,926.25375
Overall Steps per Second: 10,454.60757

Timestep Collection Time: 2.28092
Timestep Consumption Time: 2.50281
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.78373

Cumulative Model Updates: 322,260
Cumulative Timesteps: 2,687,647,834

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2687647834...
Checkpoint 2687647834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.32289
Policy Entropy: 4.17477
Value Function Loss: 0.00248

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.01887
Policy Update Magnitude: 0.23569
Value Function Update Magnitude: 0.26881

Collected Steps per Second: 22,621.50588
Overall Steps per Second: 10,625.93200

Timestep Collection Time: 2.21029
Timestep Consumption Time: 2.49518
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.70547

Cumulative Model Updates: 322,266
Cumulative Timesteps: 2,687,697,834

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.35552
Policy Entropy: 4.14609
Value Function Loss: 0.00350

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.01969
Policy Update Magnitude: 0.25805
Value Function Update Magnitude: 0.28129

Collected Steps per Second: 22,245.89111
Overall Steps per Second: 10,463.54189

Timestep Collection Time: 2.24815
Timestep Consumption Time: 2.53150
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.77964

Cumulative Model Updates: 322,272
Cumulative Timesteps: 2,687,747,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2687747846...
Checkpoint 2687747846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.53850
Policy Entropy: 4.13307
Value Function Loss: 0.00359

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02238
Policy Update Magnitude: 0.26752
Value Function Update Magnitude: 0.30793

Collected Steps per Second: 22,315.92784
Overall Steps per Second: 10,638.35874

Timestep Collection Time: 2.24118
Timestep Consumption Time: 2.46011
PPO Batch Consumption Time: 0.29556
Total Iteration Time: 4.70129

Cumulative Model Updates: 322,278
Cumulative Timesteps: 2,687,797,860

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.84820
Policy Entropy: 4.12879
Value Function Loss: 0.00394

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.02629
Policy Update Magnitude: 0.26616
Value Function Update Magnitude: 0.32479

Collected Steps per Second: 22,641.74717
Overall Steps per Second: 10,566.66185

Timestep Collection Time: 2.20955
Timestep Consumption Time: 2.52497
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.73451

Cumulative Model Updates: 322,284
Cumulative Timesteps: 2,687,847,888

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2687847888...
Checkpoint 2687847888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.33753
Policy Entropy: 4.15846
Value Function Loss: 0.00358

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02267
Policy Update Magnitude: 0.26415
Value Function Update Magnitude: 0.31895

Collected Steps per Second: 22,011.53995
Overall Steps per Second: 10,538.87834

Timestep Collection Time: 2.27190
Timestep Consumption Time: 2.47320
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.74510

Cumulative Model Updates: 322,290
Cumulative Timesteps: 2,687,897,896

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.53204
Policy Entropy: 4.18225
Value Function Loss: 0.00312

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02276
Policy Update Magnitude: 0.25165
Value Function Update Magnitude: 0.30443

Collected Steps per Second: 22,242.53668
Overall Steps per Second: 10,807.27034

Timestep Collection Time: 2.24875
Timestep Consumption Time: 2.37943
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.62818

Cumulative Model Updates: 322,296
Cumulative Timesteps: 2,687,947,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2687947914...
Checkpoint 2687947914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.13225
Policy Entropy: 4.17650
Value Function Loss: 0.00366

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.01943
Policy Update Magnitude: 0.24776
Value Function Update Magnitude: 0.29021

Collected Steps per Second: 22,329.73842
Overall Steps per Second: 10,623.61143

Timestep Collection Time: 2.23970
Timestep Consumption Time: 2.46792
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.70763

Cumulative Model Updates: 322,302
Cumulative Timesteps: 2,687,997,926

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.06362
Policy Entropy: 4.16699
Value Function Loss: 0.00325

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02148
Policy Update Magnitude: 0.25325
Value Function Update Magnitude: 0.30352

Collected Steps per Second: 22,387.42537
Overall Steps per Second: 10,587.75437

Timestep Collection Time: 2.23411
Timestep Consumption Time: 2.48984
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.72395

Cumulative Model Updates: 322,308
Cumulative Timesteps: 2,688,047,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2688047942...
Checkpoint 2688047942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95118
Policy Entropy: 4.17025
Value Function Loss: 0.00256

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.02248
Policy Update Magnitude: 0.24813
Value Function Update Magnitude: 0.30165

Collected Steps per Second: 22,896.34298
Overall Steps per Second: 10,654.90853

Timestep Collection Time: 2.18437
Timestep Consumption Time: 2.50962
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.69399

Cumulative Model Updates: 322,314
Cumulative Timesteps: 2,688,097,956

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.37766
Policy Entropy: 4.21409
Value Function Loss: 0.00190

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.01662
Policy Update Magnitude: 0.22272
Value Function Update Magnitude: 0.26893

Collected Steps per Second: 22,152.60686
Overall Steps per Second: 10,442.89097

Timestep Collection Time: 2.25815
Timestep Consumption Time: 2.53209
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.79024

Cumulative Model Updates: 322,320
Cumulative Timesteps: 2,688,147,980

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2688147980...
Checkpoint 2688147980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.30256
Policy Entropy: 4.21547
Value Function Loss: 0.00190

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.01494
Policy Update Magnitude: 0.20663
Value Function Update Magnitude: 0.24387

Collected Steps per Second: 22,132.99419
Overall Steps per Second: 10,619.75059

Timestep Collection Time: 2.25970
Timestep Consumption Time: 2.44982
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.70953

Cumulative Model Updates: 322,326
Cumulative Timesteps: 2,688,197,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.16263
Policy Entropy: 4.19419
Value Function Loss: 0.00283

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.01635
Policy Update Magnitude: 0.22255
Value Function Update Magnitude: 0.24468

Collected Steps per Second: 22,171.62662
Overall Steps per Second: 10,464.11780

Timestep Collection Time: 2.25522
Timestep Consumption Time: 2.52320
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.77842

Cumulative Model Updates: 322,332
Cumulative Timesteps: 2,688,247,996

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2688247996...
Checkpoint 2688247996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.66537
Policy Entropy: 4.15473
Value Function Loss: 0.00367

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.01904
Policy Update Magnitude: 0.24524
Value Function Update Magnitude: 0.27870

Collected Steps per Second: 22,074.86812
Overall Steps per Second: 10,539.72767

Timestep Collection Time: 2.26565
Timestep Consumption Time: 2.47963
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.74528

Cumulative Model Updates: 322,338
Cumulative Timesteps: 2,688,298,010

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.83930
Policy Entropy: 4.16774
Value Function Loss: 0.00394

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02532
Policy Update Magnitude: 0.25834
Value Function Update Magnitude: 0.31169

Collected Steps per Second: 22,441.31607
Overall Steps per Second: 10,752.39443

Timestep Collection Time: 2.22919
Timestep Consumption Time: 2.42335
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.65255

Cumulative Model Updates: 322,344
Cumulative Timesteps: 2,688,348,036

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2688348036...
Checkpoint 2688348036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.46864
Policy Entropy: 4.17154
Value Function Loss: 0.00379

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02218
Policy Update Magnitude: 0.24918
Value Function Update Magnitude: 0.31722

Collected Steps per Second: 22,240.74556
Overall Steps per Second: 10,619.46286

Timestep Collection Time: 2.24930
Timestep Consumption Time: 2.46149
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.71078

Cumulative Model Updates: 322,350
Cumulative Timesteps: 2,688,398,062

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.04329
Policy Entropy: 4.16766
Value Function Loss: 0.00386

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.01944
Policy Update Magnitude: 0.25112
Value Function Update Magnitude: 0.32738

Collected Steps per Second: 21,958.38926
Overall Steps per Second: 10,524.53096

Timestep Collection Time: 2.27776
Timestep Consumption Time: 2.47456
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.75233

Cumulative Model Updates: 322,356
Cumulative Timesteps: 2,688,448,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2688448078...
Checkpoint 2688448078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.70032
Policy Entropy: 4.16465
Value Function Loss: 0.00329

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02181
Policy Update Magnitude: 0.25244
Value Function Update Magnitude: 0.32689

Collected Steps per Second: 22,998.19777
Overall Steps per Second: 10,650.43642

Timestep Collection Time: 2.17408
Timestep Consumption Time: 2.52056
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.69464

Cumulative Model Updates: 322,362
Cumulative Timesteps: 2,688,498,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.41281
Policy Entropy: 4.19168
Value Function Loss: 0.00301

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02021
Policy Update Magnitude: 0.24827
Value Function Update Magnitude: 0.30254

Collected Steps per Second: 22,319.44345
Overall Steps per Second: 10,408.53099

Timestep Collection Time: 2.24101
Timestep Consumption Time: 2.56448
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.80548

Cumulative Model Updates: 322,368
Cumulative Timesteps: 2,688,548,096

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2688548096...
Checkpoint 2688548096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.08512
Policy Entropy: 4.21743
Value Function Loss: 0.00250

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.01589
Policy Update Magnitude: 0.23581
Value Function Update Magnitude: 0.28986

Collected Steps per Second: 21,877.01672
Overall Steps per Second: 10,671.72494

Timestep Collection Time: 2.28651
Timestep Consumption Time: 2.40083
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.68734

Cumulative Model Updates: 322,374
Cumulative Timesteps: 2,688,598,118

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.09527
Policy Entropy: 4.22780
Value Function Loss: 0.00209

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.01412
Policy Update Magnitude: 0.22386
Value Function Update Magnitude: 0.28084

Collected Steps per Second: 22,257.54870
Overall Steps per Second: 10,432.77501

Timestep Collection Time: 2.24805
Timestep Consumption Time: 2.54799
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.79604

Cumulative Model Updates: 322,380
Cumulative Timesteps: 2,688,648,154

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2688648154...
Checkpoint 2688648154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.12943
Policy Entropy: 4.18986
Value Function Loss: 0.00311

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.01592
Policy Update Magnitude: 0.24048
Value Function Update Magnitude: 0.27337

Collected Steps per Second: 21,922.58242
Overall Steps per Second: 10,603.30516

Timestep Collection Time: 2.28075
Timestep Consumption Time: 2.43476
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.71551

Cumulative Model Updates: 322,386
Cumulative Timesteps: 2,688,698,154

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.69707
Policy Entropy: 4.18420
Value Function Loss: 0.00321

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.01929
Policy Update Magnitude: 0.24998
Value Function Update Magnitude: 0.28613

Collected Steps per Second: 23,040.21262
Overall Steps per Second: 10,662.55650

Timestep Collection Time: 2.17081
Timestep Consumption Time: 2.51999
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.69081

Cumulative Model Updates: 322,392
Cumulative Timesteps: 2,688,748,170

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2688748170...
Checkpoint 2688748170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.49581
Policy Entropy: 4.15138
Value Function Loss: 0.00346

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02238
Policy Update Magnitude: 0.25586
Value Function Update Magnitude: 0.28778

Collected Steps per Second: 22,332.37827
Overall Steps per Second: 10,673.37342

Timestep Collection Time: 2.24016
Timestep Consumption Time: 2.44702
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.68718

Cumulative Model Updates: 322,398
Cumulative Timesteps: 2,688,798,198

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.23315
Policy Entropy: 4.17851
Value Function Loss: 0.00323

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02292
Policy Update Magnitude: 0.26030
Value Function Update Magnitude: 0.29771

Collected Steps per Second: 22,494.63637
Overall Steps per Second: 10,645.66664

Timestep Collection Time: 2.22284
Timestep Consumption Time: 2.47409
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.69693

Cumulative Model Updates: 322,404
Cumulative Timesteps: 2,688,848,200

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2688848200...
Checkpoint 2688848200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.24273
Policy Entropy: 4.17812
Value Function Loss: 0.00284

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.02440
Policy Update Magnitude: 0.25278
Value Function Update Magnitude: 0.32532

Collected Steps per Second: 22,562.18427
Overall Steps per Second: 10,592.84005

Timestep Collection Time: 2.21672
Timestep Consumption Time: 2.50477
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.72149

Cumulative Model Updates: 322,410
Cumulative Timesteps: 2,688,898,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.58128
Policy Entropy: 4.20070
Value Function Loss: 0.00305

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02270
Policy Update Magnitude: 0.24593
Value Function Update Magnitude: 0.32293

Collected Steps per Second: 22,694.36817
Overall Steps per Second: 10,757.10550

Timestep Collection Time: 2.20389
Timestep Consumption Time: 2.44568
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.64958

Cumulative Model Updates: 322,416
Cumulative Timesteps: 2,688,948,230

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2688948230...
Checkpoint 2688948230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.20067
Policy Entropy: 4.22000
Value Function Loss: 0.00258

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02076
Policy Update Magnitude: 0.23727
Value Function Update Magnitude: 0.31097

Collected Steps per Second: 21,999.59177
Overall Steps per Second: 10,564.67725

Timestep Collection Time: 2.27322
Timestep Consumption Time: 2.46047
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.73370

Cumulative Model Updates: 322,422
Cumulative Timesteps: 2,688,998,240

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.44377
Policy Entropy: 4.20991
Value Function Loss: 0.00267

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.01943
Policy Update Magnitude: 0.22779
Value Function Update Magnitude: 0.32333

Collected Steps per Second: 22,375.45083
Overall Steps per Second: 10,480.78534

Timestep Collection Time: 2.23540
Timestep Consumption Time: 2.53696
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.77235

Cumulative Model Updates: 322,428
Cumulative Timesteps: 2,689,048,258

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2689048258...
Checkpoint 2689048258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.50819
Policy Entropy: 4.20895
Value Function Loss: 0.00268

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.01664
Policy Update Magnitude: 0.23575
Value Function Update Magnitude: 0.31584

Collected Steps per Second: 21,839.80529
Overall Steps per Second: 10,574.13962

Timestep Collection Time: 2.28940
Timestep Consumption Time: 2.43912
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.72852

Cumulative Model Updates: 322,434
Cumulative Timesteps: 2,689,098,258

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.39006
Policy Entropy: 4.16392
Value Function Loss: 0.00384

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02161
Policy Update Magnitude: 0.26682
Value Function Update Magnitude: 0.32648

Collected Steps per Second: 22,886.60929
Overall Steps per Second: 10,615.18359

Timestep Collection Time: 2.18538
Timestep Consumption Time: 2.52636
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.71174

Cumulative Model Updates: 322,440
Cumulative Timesteps: 2,689,148,274

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2689148274...
Checkpoint 2689148274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.83222
Policy Entropy: 4.15925
Value Function Loss: 0.00392

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.02377
Policy Update Magnitude: 0.27544
Value Function Update Magnitude: 0.34097

Collected Steps per Second: 21,956.63937
Overall Steps per Second: 10,525.79818

Timestep Collection Time: 2.27740
Timestep Consumption Time: 2.47322
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.75061

Cumulative Model Updates: 322,446
Cumulative Timesteps: 2,689,198,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.21121
Policy Entropy: 4.13361
Value Function Loss: 0.00401

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.02980
Policy Update Magnitude: 0.27976
Value Function Update Magnitude: 0.34243

Collected Steps per Second: 22,150.11055
Overall Steps per Second: 10,499.55392

Timestep Collection Time: 2.25832
Timestep Consumption Time: 2.50588
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.76420

Cumulative Model Updates: 322,452
Cumulative Timesteps: 2,689,248,300

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2689248300...
Checkpoint 2689248300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.96304
Policy Entropy: 4.13535
Value Function Loss: 0.00323

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.03079
Policy Update Magnitude: 0.27866
Value Function Update Magnitude: 0.33592

Collected Steps per Second: 22,719.66511
Overall Steps per Second: 10,640.04794

Timestep Collection Time: 2.20144
Timestep Consumption Time: 2.49929
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.70073

Cumulative Model Updates: 322,458
Cumulative Timesteps: 2,689,298,316

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.26336
Policy Entropy: 4.14385
Value Function Loss: 0.00344

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.02726
Policy Update Magnitude: 0.28213
Value Function Update Magnitude: 0.33950

Collected Steps per Second: 22,482.47002
Overall Steps per Second: 10,525.09620

Timestep Collection Time: 2.22636
Timestep Consumption Time: 2.52932
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.75568

Cumulative Model Updates: 322,464
Cumulative Timesteps: 2,689,348,370

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 2689348370...
Checkpoint 2689348370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.29258
Policy Entropy: 4.14927
Value Function Loss: 0.00360

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.02433
Policy Update Magnitude: 0.27587
Value Function Update Magnitude: 0.35002

Collected Steps per Second: 21,736.33434
Overall Steps per Second: 10,570.33339

Timestep Collection Time: 2.30057
Timestep Consumption Time: 2.43022
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.73079

Cumulative Model Updates: 322,470
Cumulative Timesteps: 2,689,398,376

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.71286
Policy Entropy: 4.17487
Value Function Loss: 0.00314

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.02441
Policy Update Magnitude: 0.26877
Value Function Update Magnitude: 0.35954

Collected Steps per Second: 22,399.19957
Overall Steps per Second: 10,526.41351

Timestep Collection Time: 2.23240
Timestep Consumption Time: 2.51793
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.75034

Cumulative Model Updates: 322,476
Cumulative Timesteps: 2,689,448,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2689448380...
Checkpoint 2689448380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.31251
Policy Entropy: 4.18731
Value Function Loss: 0.00250

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02081
Policy Update Magnitude: 0.25241
Value Function Update Magnitude: 0.31598

Collected Steps per Second: 21,973.30835
Overall Steps per Second: 10,603.77134

Timestep Collection Time: 2.27631
Timestep Consumption Time: 2.44069
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.71700

Cumulative Model Updates: 322,482
Cumulative Timesteps: 2,689,498,398

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.27910
Policy Entropy: 4.18877
Value Function Loss: 0.00306

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.01770
Policy Update Magnitude: 0.24759
Value Function Update Magnitude: 0.29559

Collected Steps per Second: 23,064.26575
Overall Steps per Second: 10,804.37127

Timestep Collection Time: 2.16907
Timestep Consumption Time: 2.46128
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.63035

Cumulative Model Updates: 322,488
Cumulative Timesteps: 2,689,548,426

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2689548426...
Checkpoint 2689548426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.47706
Policy Entropy: 4.14099
Value Function Loss: 0.00404

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02173
Policy Update Magnitude: 0.27148
Value Function Update Magnitude: 0.32228

Collected Steps per Second: 21,805.91013
Overall Steps per Second: 10,333.59752

Timestep Collection Time: 2.29323
Timestep Consumption Time: 2.54594
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.83917

Cumulative Model Updates: 322,494
Cumulative Timesteps: 2,689,598,432

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.20853
Policy Entropy: 4.11174
Value Function Loss: 0.00441

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02532
Policy Update Magnitude: 0.28973
Value Function Update Magnitude: 0.35696

Collected Steps per Second: 22,480.44082
Overall Steps per Second: 10,654.49711

Timestep Collection Time: 2.22567
Timestep Consumption Time: 2.47038
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.69605

Cumulative Model Updates: 322,500
Cumulative Timesteps: 2,689,648,466

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2689648466...
Checkpoint 2689648466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.74369
Policy Entropy: 4.11406
Value Function Loss: 0.00417

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.02762
Policy Update Magnitude: 0.29548
Value Function Update Magnitude: 0.35761

Collected Steps per Second: 22,800.23462
Overall Steps per Second: 10,551.25185

Timestep Collection Time: 2.19349
Timestep Consumption Time: 2.54643
PPO Batch Consumption Time: 0.29784
Total Iteration Time: 4.73991

Cumulative Model Updates: 322,506
Cumulative Timesteps: 2,689,698,478

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.80281
Policy Entropy: 4.13577
Value Function Loss: 0.00370

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02216
Policy Update Magnitude: 0.28883
Value Function Update Magnitude: 0.33123

Collected Steps per Second: 19,836.62616
Overall Steps per Second: 9,691.09368

Timestep Collection Time: 2.52220
Timestep Consumption Time: 2.64048
PPO Batch Consumption Time: 0.31246
Total Iteration Time: 5.16268

Cumulative Model Updates: 322,512
Cumulative Timesteps: 2,689,748,510

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2689748510...
Checkpoint 2689748510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.86098
Policy Entropy: 4.14763
Value Function Loss: 0.00307

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.02226
Policy Update Magnitude: 0.27227
Value Function Update Magnitude: 0.31232

Collected Steps per Second: 22,148.44525
Overall Steps per Second: 10,834.39251

Timestep Collection Time: 2.25786
Timestep Consumption Time: 2.35782
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.61567

Cumulative Model Updates: 322,518
Cumulative Timesteps: 2,689,798,518

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.67246
Policy Entropy: 4.13192
Value Function Loss: 0.00337

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.02437
Policy Update Magnitude: 0.27118
Value Function Update Magnitude: 0.29195

Collected Steps per Second: 22,355.44232
Overall Steps per Second: 10,562.95025

Timestep Collection Time: 2.23695
Timestep Consumption Time: 2.49733
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.73428

Cumulative Model Updates: 322,524
Cumulative Timesteps: 2,689,848,526

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2689848526...
Checkpoint 2689848526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.55415
Policy Entropy: 4.14960
Value Function Loss: 0.00266

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02354
Policy Update Magnitude: 0.26657
Value Function Update Magnitude: 0.28366

Collected Steps per Second: 22,115.56530
Overall Steps per Second: 10,638.26393

Timestep Collection Time: 2.26166
Timestep Consumption Time: 2.44004
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.70171

Cumulative Model Updates: 322,530
Cumulative Timesteps: 2,689,898,544

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.04927
Policy Entropy: 4.16167
Value Function Loss: 0.00262

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02223
Policy Update Magnitude: 0.24500
Value Function Update Magnitude: 0.28311

Collected Steps per Second: 23,363.33760
Overall Steps per Second: 10,875.41643

Timestep Collection Time: 2.14036
Timestep Consumption Time: 2.45771
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.59808

Cumulative Model Updates: 322,536
Cumulative Timesteps: 2,689,948,550

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2689948550...
Checkpoint 2689948550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.45514
Policy Entropy: 4.16755
Value Function Loss: 0.00298

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02122
Policy Update Magnitude: 0.25397
Value Function Update Magnitude: 0.28205

Collected Steps per Second: 21,017.32513
Overall Steps per Second: 10,045.10998

Timestep Collection Time: 2.37899
Timestep Consumption Time: 2.59856
PPO Batch Consumption Time: 0.30945
Total Iteration Time: 4.97755

Cumulative Model Updates: 322,542
Cumulative Timesteps: 2,689,998,550

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.76999
Policy Entropy: 4.17136
Value Function Loss: 0.00319

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02266
Policy Update Magnitude: 0.25421
Value Function Update Magnitude: 0.30661

Collected Steps per Second: 21,431.89026
Overall Steps per Second: 10,341.90662

Timestep Collection Time: 2.33344
Timestep Consumption Time: 2.50223
PPO Batch Consumption Time: 0.30969
Total Iteration Time: 4.83567

Cumulative Model Updates: 322,548
Cumulative Timesteps: 2,690,048,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2690048560...
Checkpoint 2690048560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.13325
Policy Entropy: 4.15668
Value Function Loss: 0.00310

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.02374
Policy Update Magnitude: 0.25176
Value Function Update Magnitude: 0.31604

Collected Steps per Second: 21,897.83738
Overall Steps per Second: 10,428.05050

Timestep Collection Time: 2.28388
Timestep Consumption Time: 2.51203
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.79591

Cumulative Model Updates: 322,554
Cumulative Timesteps: 2,690,098,572

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.67953
Policy Entropy: 4.19422
Value Function Loss: 0.00283

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.02486
Policy Update Magnitude: 0.24718
Value Function Update Magnitude: 0.30396

Collected Steps per Second: 20,469.80712
Overall Steps per Second: 10,145.52986

Timestep Collection Time: 2.44379
Timestep Consumption Time: 2.48685
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.93064

Cumulative Model Updates: 322,560
Cumulative Timesteps: 2,690,148,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2690148596...
Checkpoint 2690148596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.69096
Policy Entropy: 4.19703
Value Function Loss: 0.00304

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02022
Policy Update Magnitude: 0.25134
Value Function Update Magnitude: 0.28867

Collected Steps per Second: 22,233.91092
Overall Steps per Second: 10,645.79796

Timestep Collection Time: 2.24909
Timestep Consumption Time: 2.44817
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.69725

Cumulative Model Updates: 322,566
Cumulative Timesteps: 2,690,198,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.30685
Policy Entropy: 4.20268
Value Function Loss: 0.00337

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02039
Policy Update Magnitude: 0.25062
Value Function Update Magnitude: 0.28948

Collected Steps per Second: 22,455.18694
Overall Steps per Second: 10,517.85804

Timestep Collection Time: 2.22728
Timestep Consumption Time: 2.52787
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.75515

Cumulative Model Updates: 322,572
Cumulative Timesteps: 2,690,248,616

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2690248616...
Checkpoint 2690248616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.43569
Policy Entropy: 4.20888
Value Function Loss: 0.00269

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02014
Policy Update Magnitude: 0.23505
Value Function Update Magnitude: 0.28746

Collected Steps per Second: 22,042.76761
Overall Steps per Second: 10,601.53696

Timestep Collection Time: 2.26886
Timestep Consumption Time: 2.44857
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.71743

Cumulative Model Updates: 322,578
Cumulative Timesteps: 2,690,298,628

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.60723
Policy Entropy: 4.19613
Value Function Loss: 0.00310

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.01839
Policy Update Magnitude: 0.23201
Value Function Update Magnitude: 0.26711

Collected Steps per Second: 22,076.90562
Overall Steps per Second: 10,774.67742

Timestep Collection Time: 2.26544
Timestep Consumption Time: 2.37637
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.64181

Cumulative Model Updates: 322,584
Cumulative Timesteps: 2,690,348,642

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2690348642...
Checkpoint 2690348642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.36140
Policy Entropy: 4.20298
Value Function Loss: 0.00309

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.01841
Policy Update Magnitude: 0.24420
Value Function Update Magnitude: 0.26835

Collected Steps per Second: 22,278.92606
Overall Steps per Second: 10,456.57136

Timestep Collection Time: 2.24535
Timestep Consumption Time: 2.53863
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.78398

Cumulative Model Updates: 322,590
Cumulative Timesteps: 2,690,398,666

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.47587
Policy Entropy: 4.17211
Value Function Loss: 0.00398

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.01988
Policy Update Magnitude: 0.25722
Value Function Update Magnitude: 0.28109

Collected Steps per Second: 22,318.26256
Overall Steps per Second: 10,788.03231

Timestep Collection Time: 2.24130
Timestep Consumption Time: 2.39550
PPO Batch Consumption Time: 0.28383
Total Iteration Time: 4.63680

Cumulative Model Updates: 322,596
Cumulative Timesteps: 2,690,448,688

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2690448688...
Checkpoint 2690448688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.51190
Policy Entropy: 4.18871
Value Function Loss: 0.00352

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.02020
Policy Update Magnitude: 0.26277
Value Function Update Magnitude: 0.28632

Collected Steps per Second: 21,941.89547
Overall Steps per Second: 10,574.34708

Timestep Collection Time: 2.27966
Timestep Consumption Time: 2.45066
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.73032

Cumulative Model Updates: 322,602
Cumulative Timesteps: 2,690,498,708

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.17638
Policy Entropy: 4.17229
Value Function Loss: 0.00355

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02014
Policy Update Magnitude: 0.25116
Value Function Update Magnitude: 0.29281

Collected Steps per Second: 21,217.67340
Overall Steps per Second: 10,273.93927

Timestep Collection Time: 2.35785
Timestep Consumption Time: 2.51156
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.86941

Cumulative Model Updates: 322,608
Cumulative Timesteps: 2,690,548,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2690548736...
Checkpoint 2690548736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.99497
Policy Entropy: 4.16105
Value Function Loss: 0.00332

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.02422
Policy Update Magnitude: 0.30035
Value Function Update Magnitude: 0.30492

Collected Steps per Second: 22,029.24968
Overall Steps per Second: 10,691.66206

Timestep Collection Time: 2.26989
Timestep Consumption Time: 2.40702
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.67692

Cumulative Model Updates: 322,614
Cumulative Timesteps: 2,690,598,740

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.56520
Policy Entropy: 4.14567
Value Function Loss: 0.00319

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.02584
Policy Update Magnitude: 0.27361
Value Function Update Magnitude: 0.30059

Collected Steps per Second: 22,548.23259
Overall Steps per Second: 10,640.29032

Timestep Collection Time: 2.21747
Timestep Consumption Time: 2.48165
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.69912

Cumulative Model Updates: 322,620
Cumulative Timesteps: 2,690,648,740

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2690648740...
Checkpoint 2690648740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.48705
Policy Entropy: 4.17550
Value Function Loss: 0.00277

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.26169
Value Function Update Magnitude: 0.28232

Collected Steps per Second: 22,178.07360
Overall Steps per Second: 10,655.34074

Timestep Collection Time: 2.25511
Timestep Consumption Time: 2.43869
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.69380

Cumulative Model Updates: 322,626
Cumulative Timesteps: 2,690,698,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.55371
Policy Entropy: 4.21261
Value Function Loss: 0.00234

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02083
Policy Update Magnitude: 0.23732
Value Function Update Magnitude: 0.25694

Collected Steps per Second: 23,158.93892
Overall Steps per Second: 10,729.12455

Timestep Collection Time: 2.15934
Timestep Consumption Time: 2.50162
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.66096

Cumulative Model Updates: 322,632
Cumulative Timesteps: 2,690,748,762

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2690748762...
Checkpoint 2690748762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.68815
Policy Entropy: 4.20442
Value Function Loss: 0.00241

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.01785
Policy Update Magnitude: 0.23135
Value Function Update Magnitude: 0.23427

Collected Steps per Second: 22,090.97675
Overall Steps per Second: 10,437.06275

Timestep Collection Time: 2.26427
Timestep Consumption Time: 2.52826
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.79254

Cumulative Model Updates: 322,638
Cumulative Timesteps: 2,690,798,782

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.24566
Policy Entropy: 4.20214
Value Function Loss: 0.00237

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.01719
Policy Update Magnitude: 0.23652
Value Function Update Magnitude: 0.23607

Collected Steps per Second: 21,975.05571
Overall Steps per Second: 10,430.56005

Timestep Collection Time: 2.27540
Timestep Consumption Time: 2.51840
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.79380

Cumulative Model Updates: 322,644
Cumulative Timesteps: 2,690,848,784

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2690848784...
Checkpoint 2690848784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.59687
Policy Entropy: 4.18272
Value Function Loss: 0.00253

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.01742
Policy Update Magnitude: 0.23870
Value Function Update Magnitude: 0.23665

Collected Steps per Second: 22,927.98430
Overall Steps per Second: 10,654.03456

Timestep Collection Time: 2.18074
Timestep Consumption Time: 2.51232
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.69306

Cumulative Model Updates: 322,650
Cumulative Timesteps: 2,690,898,784

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.86585
Policy Entropy: 4.16852
Value Function Loss: 0.00352

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.01735
Policy Update Magnitude: 0.26630
Value Function Update Magnitude: 0.24811

Collected Steps per Second: 22,357.63510
Overall Steps per Second: 10,482.87593

Timestep Collection Time: 2.23754
Timestep Consumption Time: 2.53463
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.77216

Cumulative Model Updates: 322,656
Cumulative Timesteps: 2,690,948,810

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2690948810...
Checkpoint 2690948810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.61430
Policy Entropy: 4.15756
Value Function Loss: 0.00380

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.02510
Policy Update Magnitude: 0.27600
Value Function Update Magnitude: 0.28563

Collected Steps per Second: 22,311.52523
Overall Steps per Second: 10,298.96890

Timestep Collection Time: 2.24153
Timestep Consumption Time: 2.61449
PPO Batch Consumption Time: 0.32190
Total Iteration Time: 4.85602

Cumulative Model Updates: 322,662
Cumulative Timesteps: 2,690,998,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.61200
Policy Entropy: 4.14214
Value Function Loss: 0.00401

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.02618
Policy Update Magnitude: 0.26504
Value Function Update Magnitude: 0.31073

Collected Steps per Second: 19,982.17389
Overall Steps per Second: 9,903.84297

Timestep Collection Time: 2.50363
Timestep Consumption Time: 2.54774
PPO Batch Consumption Time: 0.29876
Total Iteration Time: 5.05137

Cumulative Model Updates: 322,668
Cumulative Timesteps: 2,691,048,850

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2691048850...
Checkpoint 2691048850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.31737
Policy Entropy: 4.16224
Value Function Loss: 0.00354

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.02313
Policy Update Magnitude: 0.26567
Value Function Update Magnitude: 0.33298

Collected Steps per Second: 21,932.10687
Overall Steps per Second: 10,638.72086

Timestep Collection Time: 2.28013
Timestep Consumption Time: 2.42044
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.70057

Cumulative Model Updates: 322,674
Cumulative Timesteps: 2,691,098,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.19554
Policy Entropy: 4.16303
Value Function Loss: 0.00384

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.02590
Policy Update Magnitude: 0.27132
Value Function Update Magnitude: 0.33426

Collected Steps per Second: 23,214.73584
Overall Steps per Second: 10,849.09601

Timestep Collection Time: 2.15415
Timestep Consumption Time: 2.45527
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.60942

Cumulative Model Updates: 322,680
Cumulative Timesteps: 2,691,148,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2691148866...
Checkpoint 2691148866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.71987
Policy Entropy: 4.17536
Value Function Loss: 0.00344

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.02527
Policy Update Magnitude: 0.26742
Value Function Update Magnitude: 0.33406

Collected Steps per Second: 22,084.54802
Overall Steps per Second: 10,481.59026

Timestep Collection Time: 2.26475
Timestep Consumption Time: 2.50704
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.77179

Cumulative Model Updates: 322,686
Cumulative Timesteps: 2,691,198,882

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.65201
Policy Entropy: 4.16914
Value Function Loss: 0.00296

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.02128
Policy Update Magnitude: 0.25130
Value Function Update Magnitude: 0.33403

Collected Steps per Second: 22,207.49125
Overall Steps per Second: 10,682.75472

Timestep Collection Time: 2.25149
Timestep Consumption Time: 2.42895
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.68044

Cumulative Model Updates: 322,692
Cumulative Timesteps: 2,691,248,882

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2691248882...
Checkpoint 2691248882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.46664
Policy Entropy: 4.16382
Value Function Loss: 0.00262

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02112
Policy Update Magnitude: 0.24116
Value Function Update Magnitude: 0.31882

Collected Steps per Second: 22,583.57977
Overall Steps per Second: 10,696.78984

Timestep Collection Time: 2.21418
Timestep Consumption Time: 2.46050
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.67467

Cumulative Model Updates: 322,698
Cumulative Timesteps: 2,691,298,886

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.06389
Policy Entropy: 4.17565
Value Function Loss: 0.00247

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.01914
Policy Update Magnitude: 0.24868
Value Function Update Magnitude: 0.29976

Collected Steps per Second: 22,224.21648
Overall Steps per Second: 10,475.94480

Timestep Collection Time: 2.24980
Timestep Consumption Time: 2.52304
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.77284

Cumulative Model Updates: 322,704
Cumulative Timesteps: 2,691,348,886

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2691348886...
Checkpoint 2691348886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.03305
Policy Entropy: 4.17800
Value Function Loss: 0.00256

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.01714
Policy Update Magnitude: 0.24356
Value Function Update Magnitude: 0.28982

Collected Steps per Second: 22,224.26076
Overall Steps per Second: 10,655.58552

Timestep Collection Time: 2.24997
Timestep Consumption Time: 2.44278
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.69275

Cumulative Model Updates: 322,710
Cumulative Timesteps: 2,691,398,890

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.96093
Policy Entropy: 4.17196
Value Function Loss: 0.00311

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.01859
Policy Update Magnitude: 0.26199
Value Function Update Magnitude: 0.30807

Collected Steps per Second: 22,148.09211
Overall Steps per Second: 10,454.78918

Timestep Collection Time: 2.25789
Timestep Consumption Time: 2.52537
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.78326

Cumulative Model Updates: 322,716
Cumulative Timesteps: 2,691,448,898

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2691448898...
Checkpoint 2691448898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.36729
Policy Entropy: 4.15925
Value Function Loss: 0.00332

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02198
Policy Update Magnitude: 0.25987
Value Function Update Magnitude: 0.30495

Collected Steps per Second: 22,040.01785
Overall Steps per Second: 10,598.63425

Timestep Collection Time: 2.26942
Timestep Consumption Time: 2.44987
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.71929

Cumulative Model Updates: 322,722
Cumulative Timesteps: 2,691,498,916

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.61879
Policy Entropy: 4.18254
Value Function Loss: 0.00308

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02118
Policy Update Magnitude: 0.24766
Value Function Update Magnitude: 0.28956

Collected Steps per Second: 23,347.66788
Overall Steps per Second: 10,561.37312

Timestep Collection Time: 2.14291
Timestep Consumption Time: 2.59435
PPO Batch Consumption Time: 0.29986
Total Iteration Time: 4.73726

Cumulative Model Updates: 322,728
Cumulative Timesteps: 2,691,548,948

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2691548948...
Checkpoint 2691548948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.19638
Policy Entropy: 4.18075
Value Function Loss: 0.00282

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02076
Policy Update Magnitude: 0.25027
Value Function Update Magnitude: 0.28115

Collected Steps per Second: 21,893.53846
Overall Steps per Second: 10,507.16541

Timestep Collection Time: 2.28405
Timestep Consumption Time: 2.47518
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.75923

Cumulative Model Updates: 322,734
Cumulative Timesteps: 2,691,598,954

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.15158
Policy Entropy: 4.19029
Value Function Loss: 0.00282

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.01865
Policy Update Magnitude: 0.25114
Value Function Update Magnitude: 0.27936

Collected Steps per Second: 20,709.78791
Overall Steps per Second: 10,138.40528

Timestep Collection Time: 2.41586
Timestep Consumption Time: 2.51904
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.93490

Cumulative Model Updates: 322,740
Cumulative Timesteps: 2,691,648,986

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2691648986...
Checkpoint 2691648986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.69758
Policy Entropy: 4.15890
Value Function Loss: 0.00341

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02126
Policy Update Magnitude: 0.25747
Value Function Update Magnitude: 0.28602

Collected Steps per Second: 22,580.80337
Overall Steps per Second: 10,573.76439

Timestep Collection Time: 2.21427
Timestep Consumption Time: 2.51441
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.72868

Cumulative Model Updates: 322,746
Cumulative Timesteps: 2,691,698,986

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.79340
Policy Entropy: 4.18641
Value Function Loss: 0.00364

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02225
Policy Update Magnitude: 0.25090
Value Function Update Magnitude: 0.28975

Collected Steps per Second: 22,357.20718
Overall Steps per Second: 10,472.07541

Timestep Collection Time: 2.23722
Timestep Consumption Time: 2.53910
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.77632

Cumulative Model Updates: 322,752
Cumulative Timesteps: 2,691,749,004

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2691749004...
Checkpoint 2691749004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.42904
Policy Entropy: 4.20594
Value Function Loss: 0.00331

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.01999
Policy Update Magnitude: 0.23870
Value Function Update Magnitude: 0.30671

Collected Steps per Second: 22,283.06548
Overall Steps per Second: 10,653.82540

Timestep Collection Time: 2.24511
Timestep Consumption Time: 2.45067
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.69578

Cumulative Model Updates: 322,758
Cumulative Timesteps: 2,691,799,032

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.02924
Policy Entropy: 4.20205
Value Function Loss: 0.00359

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02135
Policy Update Magnitude: 0.25583
Value Function Update Magnitude: 0.31885

Collected Steps per Second: 22,498.47276
Overall Steps per Second: 10,541.11722

Timestep Collection Time: 2.22362
Timestep Consumption Time: 2.52237
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.74599

Cumulative Model Updates: 322,764
Cumulative Timesteps: 2,691,849,060

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2691849060...
Checkpoint 2691849060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.74432
Policy Entropy: 4.16414
Value Function Loss: 0.00357

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.02601
Policy Update Magnitude: 0.26677
Value Function Update Magnitude: 0.32607

Collected Steps per Second: 22,322.35597
Overall Steps per Second: 10,565.26714

Timestep Collection Time: 2.24080
Timestep Consumption Time: 2.49358
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.73438

Cumulative Model Updates: 322,770
Cumulative Timesteps: 2,691,899,080

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.64077
Policy Entropy: 4.15472
Value Function Loss: 0.00344

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.02464
Policy Update Magnitude: 0.27403
Value Function Update Magnitude: 0.30937

Collected Steps per Second: 21,241.23547
Overall Steps per Second: 10,198.41383

Timestep Collection Time: 2.35401
Timestep Consumption Time: 2.54891
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.90292

Cumulative Model Updates: 322,776
Cumulative Timesteps: 2,691,949,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2691949082...
Checkpoint 2691949082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.72393
Policy Entropy: 4.16608
Value Function Loss: 0.00391

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.02843
Policy Update Magnitude: 0.27188
Value Function Update Magnitude: 0.30916

Collected Steps per Second: 22,179.71600
Overall Steps per Second: 10,109.93580

Timestep Collection Time: 2.25530
Timestep Consumption Time: 2.69250
PPO Batch Consumption Time: 0.32241
Total Iteration Time: 4.94781

Cumulative Model Updates: 322,782
Cumulative Timesteps: 2,691,999,104

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.73278
Policy Entropy: 4.13644
Value Function Loss: 0.00390

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.02662
Policy Update Magnitude: 0.27409
Value Function Update Magnitude: 0.35035

Collected Steps per Second: 21,985.34764
Overall Steps per Second: 10,583.16944

Timestep Collection Time: 2.27561
Timestep Consumption Time: 2.45171
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.72732

Cumulative Model Updates: 322,788
Cumulative Timesteps: 2,692,049,134

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2692049134...
Checkpoint 2692049134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.20980
Policy Entropy: 4.11227
Value Function Loss: 0.00402

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.02816
Policy Update Magnitude: 0.28906
Value Function Update Magnitude: 0.35959

Collected Steps per Second: 21,734.75216
Overall Steps per Second: 10,601.16399

Timestep Collection Time: 2.30138
Timestep Consumption Time: 2.41697
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.71835

Cumulative Model Updates: 322,794
Cumulative Timesteps: 2,692,099,154

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.79407
Policy Entropy: 4.11198
Value Function Loss: 0.00409

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.02889
Policy Update Magnitude: 0.29104
Value Function Update Magnitude: 0.33476

Collected Steps per Second: 22,187.77240
Overall Steps per Second: 10,612.08234

Timestep Collection Time: 2.25358
Timestep Consumption Time: 2.45822
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.71180

Cumulative Model Updates: 322,800
Cumulative Timesteps: 2,692,149,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2692149156...
Checkpoint 2692149156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.21877
Policy Entropy: 4.14999
Value Function Loss: 0.00434

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.02679
Policy Update Magnitude: 0.29321
Value Function Update Magnitude: 0.33341

Collected Steps per Second: 22,037.40532
Overall Steps per Second: 10,787.97038

Timestep Collection Time: 2.26896
Timestep Consumption Time: 2.36602
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.63498

Cumulative Model Updates: 322,806
Cumulative Timesteps: 2,692,199,158

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.55019
Policy Entropy: 4.18295
Value Function Loss: 0.00352

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.02177
Policy Update Magnitude: 0.27867
Value Function Update Magnitude: 0.33008

Collected Steps per Second: 22,431.43037
Overall Steps per Second: 10,571.44870

Timestep Collection Time: 2.23000
Timestep Consumption Time: 2.50181
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.73180

Cumulative Model Updates: 322,812
Cumulative Timesteps: 2,692,249,180

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2692249180...
Checkpoint 2692249180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.21041
Policy Entropy: 4.18284
Value Function Loss: 0.00317

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.02298
Policy Update Magnitude: 0.24678
Value Function Update Magnitude: 0.31251

Collected Steps per Second: 21,217.17195
Overall Steps per Second: 10,059.26003

Timestep Collection Time: 2.35771
Timestep Consumption Time: 2.61522
PPO Batch Consumption Time: 0.31629
Total Iteration Time: 4.97293

Cumulative Model Updates: 322,818
Cumulative Timesteps: 2,692,299,204

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.22218
Policy Entropy: 4.18584
Value Function Loss: 0.00300

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.01776
Policy Update Magnitude: 0.24019
Value Function Update Magnitude: 0.29018

Collected Steps per Second: 22,925.37191
Overall Steps per Second: 10,816.18593

Timestep Collection Time: 2.18099
Timestep Consumption Time: 2.44171
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.62270

Cumulative Model Updates: 322,824
Cumulative Timesteps: 2,692,349,204

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2692349204...
Checkpoint 2692349204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.81388
Policy Entropy: 4.15772
Value Function Loss: 0.00332

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.01908
Policy Update Magnitude: 0.24924
Value Function Update Magnitude: 0.29032

Collected Steps per Second: 20,121.77155
Overall Steps per Second: 9,757.77915

Timestep Collection Time: 2.48626
Timestep Consumption Time: 2.64072
PPO Batch Consumption Time: 0.31167
Total Iteration Time: 5.12699

Cumulative Model Updates: 322,830
Cumulative Timesteps: 2,692,399,232

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.34551
Policy Entropy: 4.15185
Value Function Loss: 0.00378

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02377
Policy Update Magnitude: 0.27010
Value Function Update Magnitude: 0.30563

Collected Steps per Second: 20,804.59980
Overall Steps per Second: 10,206.48378

Timestep Collection Time: 2.40428
Timestep Consumption Time: 2.49653
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.90081

Cumulative Model Updates: 322,836
Cumulative Timesteps: 2,692,449,252

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2692449252...
Checkpoint 2692449252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.52765
Policy Entropy: 4.13149
Value Function Loss: 0.00350

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.02486
Policy Update Magnitude: 0.27942
Value Function Update Magnitude: 0.32990

Collected Steps per Second: 22,913.82095
Overall Steps per Second: 10,635.22636

Timestep Collection Time: 2.18340
Timestep Consumption Time: 2.52078
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.70418

Cumulative Model Updates: 322,842
Cumulative Timesteps: 2,692,499,282

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.40133
Policy Entropy: 4.14355
Value Function Loss: 0.00328

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.02493
Policy Update Magnitude: 0.26815
Value Function Update Magnitude: 0.34903

Collected Steps per Second: 22,057.06222
Overall Steps per Second: 10,443.03013

Timestep Collection Time: 2.26812
Timestep Consumption Time: 2.52245
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.79056

Cumulative Model Updates: 322,848
Cumulative Timesteps: 2,692,549,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2692549310...
Checkpoint 2692549310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.98099
Policy Entropy: 4.15217
Value Function Loss: 0.00316

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.02532
Policy Update Magnitude: 0.26344
Value Function Update Magnitude: 0.35368

Collected Steps per Second: 21,909.59495
Overall Steps per Second: 10,654.84164

Timestep Collection Time: 2.28311
Timestep Consumption Time: 2.41166
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.69477

Cumulative Model Updates: 322,854
Cumulative Timesteps: 2,692,599,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.74043
Policy Entropy: 4.18979
Value Function Loss: 0.00296

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02325
Policy Update Magnitude: 0.25273
Value Function Update Magnitude: 0.34793

Collected Steps per Second: 22,556.45033
Overall Steps per Second: 10,547.45395

Timestep Collection Time: 2.21702
Timestep Consumption Time: 2.52422
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.74124

Cumulative Model Updates: 322,860
Cumulative Timesteps: 2,692,649,340

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2692649340...
Checkpoint 2692649340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.27988
Policy Entropy: 4.19002
Value Function Loss: 0.00270

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.01917
Policy Update Magnitude: 0.23854
Value Function Update Magnitude: 0.34044

Collected Steps per Second: 22,099.55594
Overall Steps per Second: 10,559.29815

Timestep Collection Time: 2.26249
Timestep Consumption Time: 2.47267
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.73516

Cumulative Model Updates: 322,866
Cumulative Timesteps: 2,692,699,340

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.57811
Policy Entropy: 4.16734
Value Function Loss: 0.00337

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.01914
Policy Update Magnitude: 0.25127
Value Function Update Magnitude: 0.32761

Collected Steps per Second: 22,271.44328
Overall Steps per Second: 10,801.11796

Timestep Collection Time: 2.24646
Timestep Consumption Time: 2.38565
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.63211

Cumulative Model Updates: 322,872
Cumulative Timesteps: 2,692,749,372

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2692749372...
Checkpoint 2692749372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68.98411
Policy Entropy: 4.11674
Value Function Loss: 0.00369

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.02433
Policy Update Magnitude: 0.26474
Value Function Update Magnitude: 0.33379

Collected Steps per Second: 22,374.41000
Overall Steps per Second: 10,639.54954

Timestep Collection Time: 2.23541
Timestep Consumption Time: 2.46554
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.70095

Cumulative Model Updates: 322,878
Cumulative Timesteps: 2,692,799,388

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.11501
Policy Entropy: 4.13940
Value Function Loss: 0.00338

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.02461
Policy Update Magnitude: 0.26736
Value Function Update Magnitude: 0.32291

Collected Steps per Second: 22,217.46328
Overall Steps per Second: 10,558.19690

Timestep Collection Time: 2.25120
Timestep Consumption Time: 2.48597
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.73717

Cumulative Model Updates: 322,884
Cumulative Timesteps: 2,692,849,404

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2692849404...
Checkpoint 2692849404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.72991
Policy Entropy: 4.13449
Value Function Loss: 0.00365

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.02422
Policy Update Magnitude: 0.27162
Value Function Update Magnitude: 0.30558

Collected Steps per Second: 22,855.15370
Overall Steps per Second: 10,619.52406

Timestep Collection Time: 2.18787
Timestep Consumption Time: 2.52082
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.70869

Cumulative Model Updates: 322,890
Cumulative Timesteps: 2,692,899,408

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.01196
Policy Entropy: 4.16789
Value Function Loss: 0.00347

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.01972
Policy Update Magnitude: 0.27060
Value Function Update Magnitude: 0.30756

Collected Steps per Second: 21,984.07339
Overall Steps per Second: 10,458.18755

Timestep Collection Time: 2.27501
Timestep Consumption Time: 2.50727
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.78228

Cumulative Model Updates: 322,896
Cumulative Timesteps: 2,692,949,422

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2692949422...
Checkpoint 2692949422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.53187
Policy Entropy: 4.14195
Value Function Loss: 0.00370

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.02736
Policy Update Magnitude: 0.27021
Value Function Update Magnitude: 0.31833

Collected Steps per Second: 22,220.02201
Overall Steps per Second: 10,662.75034

Timestep Collection Time: 2.25130
Timestep Consumption Time: 2.44017
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.69147

Cumulative Model Updates: 322,902
Cumulative Timesteps: 2,692,999,446

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.91244
Policy Entropy: 4.17875
Value Function Loss: 0.00297

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02327
Policy Update Magnitude: 0.25183
Value Function Update Magnitude: 0.31944

Collected Steps per Second: 22,509.69919
Overall Steps per Second: 10,514.39766

Timestep Collection Time: 2.22269
Timestep Consumption Time: 2.53574
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.75843

Cumulative Model Updates: 322,908
Cumulative Timesteps: 2,693,049,478

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2693049478...
Checkpoint 2693049478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.47478
Policy Entropy: 4.20502
Value Function Loss: 0.00244

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02088
Policy Update Magnitude: 0.22774
Value Function Update Magnitude: 0.31619

Collected Steps per Second: 22,371.74580
Overall Steps per Second: 10,605.44926

Timestep Collection Time: 2.23630
Timestep Consumption Time: 2.48108
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.71739

Cumulative Model Updates: 322,914
Cumulative Timesteps: 2,693,099,508

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.52414
Policy Entropy: 4.21491
Value Function Loss: 0.00237

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.01800
Policy Update Magnitude: 0.22991
Value Function Update Magnitude: 0.28984

Collected Steps per Second: 22,263.61174
Overall Steps per Second: 10,784.06534

Timestep Collection Time: 2.24609
Timestep Consumption Time: 2.39094
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.63703

Cumulative Model Updates: 322,920
Cumulative Timesteps: 2,693,149,514

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2693149514...
Checkpoint 2693149514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.39993
Policy Entropy: 4.20153
Value Function Loss: 0.00251

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.01847
Policy Update Magnitude: 0.23060
Value Function Update Magnitude: 0.29618

Collected Steps per Second: 22,297.48068
Overall Steps per Second: 10,588.36338

Timestep Collection Time: 2.24241
Timestep Consumption Time: 2.47976
PPO Batch Consumption Time: 0.28189
Total Iteration Time: 4.72217

Cumulative Model Updates: 322,926
Cumulative Timesteps: 2,693,199,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.07740
Policy Entropy: 4.16889
Value Function Loss: 0.00282

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.01887
Policy Update Magnitude: 0.23498
Value Function Update Magnitude: 0.31572

Collected Steps per Second: 22,187.48599
Overall Steps per Second: 10,620.95042

Timestep Collection Time: 2.25451
Timestep Consumption Time: 2.45523
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.70975

Cumulative Model Updates: 322,932
Cumulative Timesteps: 2,693,249,536

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2693249536...
Checkpoint 2693249536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.31938
Policy Entropy: 4.15772
Value Function Loss: 0.00317

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.01901
Policy Update Magnitude: 0.25105
Value Function Update Magnitude: 0.33995

Collected Steps per Second: 23,101.23557
Overall Steps per Second: 10,679.69640

Timestep Collection Time: 2.16508
Timestep Consumption Time: 2.51820
PPO Batch Consumption Time: 0.29492
Total Iteration Time: 4.68328

Cumulative Model Updates: 322,938
Cumulative Timesteps: 2,693,299,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.60691
Policy Entropy: 4.13443
Value Function Loss: 0.00324

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02169
Policy Update Magnitude: 0.26073
Value Function Update Magnitude: 0.33102

Collected Steps per Second: 22,092.47083
Overall Steps per Second: 10,451.70256

Timestep Collection Time: 2.26421
Timestep Consumption Time: 2.52180
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.78601

Cumulative Model Updates: 322,944
Cumulative Timesteps: 2,693,349,574

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2693349574...
Checkpoint 2693349574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.38350
Policy Entropy: 4.15078
Value Function Loss: 0.00308

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.02195
Policy Update Magnitude: 0.26485
Value Function Update Magnitude: 0.31163

Collected Steps per Second: 22,334.22920
Overall Steps per Second: 10,664.38459

Timestep Collection Time: 2.23988
Timestep Consumption Time: 2.45106
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.69094

Cumulative Model Updates: 322,950
Cumulative Timesteps: 2,693,399,600

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.97877
Policy Entropy: 4.16665
Value Function Loss: 0.00311

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02252
Policy Update Magnitude: 0.24946
Value Function Update Magnitude: 0.30431

Collected Steps per Second: 22,397.10655
Overall Steps per Second: 10,503.20335

Timestep Collection Time: 2.23323
Timestep Consumption Time: 2.52893
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.76217

Cumulative Model Updates: 322,956
Cumulative Timesteps: 2,693,449,618

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2693449618...
Checkpoint 2693449618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.40932
Policy Entropy: 4.19485
Value Function Loss: 0.00274

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.01650
Policy Update Magnitude: 0.23655
Value Function Update Magnitude: 0.28793

Collected Steps per Second: 22,180.79785
Overall Steps per Second: 10,546.21896

Timestep Collection Time: 2.25519
Timestep Consumption Time: 2.48793
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.74312

Cumulative Model Updates: 322,962
Cumulative Timesteps: 2,693,499,640

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.59403
Policy Entropy: 4.19920
Value Function Loss: 0.00271

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.01707
Policy Update Magnitude: 0.23088
Value Function Update Magnitude: 0.27975

Collected Steps per Second: 22,349.35585
Overall Steps per Second: 10,827.41619

Timestep Collection Time: 2.23827
Timestep Consumption Time: 2.38185
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.62012

Cumulative Model Updates: 322,968
Cumulative Timesteps: 2,693,549,664

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2693549664...
Checkpoint 2693549664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.09162
Policy Entropy: 4.18993
Value Function Loss: 0.00271

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.01662
Policy Update Magnitude: 0.23483
Value Function Update Magnitude: 0.27090

Collected Steps per Second: 22,117.65005
Overall Steps per Second: 10,603.97604

Timestep Collection Time: 2.26208
Timestep Consumption Time: 2.45615
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.71823

Cumulative Model Updates: 322,974
Cumulative Timesteps: 2,693,599,696

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.20041
Policy Entropy: 4.18854
Value Function Loss: 0.00306

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.01869
Policy Update Magnitude: 0.23766
Value Function Update Magnitude: 0.27787

Collected Steps per Second: 22,232.60218
Overall Steps per Second: 10,582.90098

Timestep Collection Time: 2.24985
Timestep Consumption Time: 2.47664
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.72649

Cumulative Model Updates: 322,980
Cumulative Timesteps: 2,693,649,716

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2693649716...
Checkpoint 2693649716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.91080
Policy Entropy: 4.17804
Value Function Loss: 0.00302

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02008
Policy Update Magnitude: 0.24540
Value Function Update Magnitude: 0.29532

Collected Steps per Second: 22,837.27474
Overall Steps per Second: 10,634.73060

Timestep Collection Time: 2.18975
Timestep Consumption Time: 2.51258
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.70233

Cumulative Model Updates: 322,986
Cumulative Timesteps: 2,693,699,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.61312
Policy Entropy: 4.19516
Value Function Loss: 0.00271

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.01969
Policy Update Magnitude: 0.24032
Value Function Update Magnitude: 0.29613

Collected Steps per Second: 22,506.54783
Overall Steps per Second: 10,474.51264

Timestep Collection Time: 2.22184
Timestep Consumption Time: 2.55222
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.77406

Cumulative Model Updates: 322,992
Cumulative Timesteps: 2,693,749,730

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2693749730...
Checkpoint 2693749730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.78030
Policy Entropy: 4.19391
Value Function Loss: 0.00248

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.01860
Policy Update Magnitude: 0.23391
Value Function Update Magnitude: 0.27985

Collected Steps per Second: 21,738.25527
Overall Steps per Second: 10,614.13069

Timestep Collection Time: 2.30018
Timestep Consumption Time: 2.41071
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.71089

Cumulative Model Updates: 322,998
Cumulative Timesteps: 2,693,799,732

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.11468
Policy Entropy: 4.19295
Value Function Loss: 0.00303

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.01997
Policy Update Magnitude: 0.22533
Value Function Update Magnitude: 0.25863

Collected Steps per Second: 22,319.25080
Overall Steps per Second: 10,513.16758

Timestep Collection Time: 2.24058
Timestep Consumption Time: 2.51612
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.75670

Cumulative Model Updates: 323,004
Cumulative Timesteps: 2,693,849,740

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2693849740...
Checkpoint 2693849740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.40088
Policy Entropy: 4.19548
Value Function Loss: 0.00278

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02015
Policy Update Magnitude: 0.22324
Value Function Update Magnitude: 0.26772

Collected Steps per Second: 21,788.27211
Overall Steps per Second: 10,604.74373

Timestep Collection Time: 2.29527
Timestep Consumption Time: 2.42054
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.71581

Cumulative Model Updates: 323,010
Cumulative Timesteps: 2,693,899,750

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.25023
Policy Entropy: 4.20486
Value Function Loss: 0.00294

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.01589
Policy Update Magnitude: 0.21726
Value Function Update Magnitude: 0.27284

Collected Steps per Second: 22,210.60297
Overall Steps per Second: 10,793.89939

Timestep Collection Time: 2.25163
Timestep Consumption Time: 2.38155
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.63317

Cumulative Model Updates: 323,016
Cumulative Timesteps: 2,693,949,760

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2693949760...
Checkpoint 2693949760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.50408
Policy Entropy: 4.20581
Value Function Loss: 0.00253

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.01271
Policy Update Magnitude: 0.22205
Value Function Update Magnitude: 0.25536

Collected Steps per Second: 22,138.83818
Overall Steps per Second: 10,588.26709

Timestep Collection Time: 2.25956
Timestep Consumption Time: 2.46492
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.72447

Cumulative Model Updates: 323,022
Cumulative Timesteps: 2,693,999,784

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.28436
Policy Entropy: 4.19881
Value Function Loss: 0.00265

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.01907
Policy Update Magnitude: 0.22701
Value Function Update Magnitude: 0.25700

Collected Steps per Second: 22,048.25211
Overall Steps per Second: 10,629.74478

Timestep Collection Time: 2.26812
Timestep Consumption Time: 2.43642
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.70453

Cumulative Model Updates: 323,028
Cumulative Timesteps: 2,694,049,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2694049792...
Checkpoint 2694049792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.49001
Policy Entropy: 4.20096
Value Function Loss: 0.00253

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.01800
Policy Update Magnitude: 0.21707
Value Function Update Magnitude: 0.26166

Collected Steps per Second: 22,970.85534
Overall Steps per Second: 10,598.03930

Timestep Collection Time: 2.17728
Timestep Consumption Time: 2.54189
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.71917

Cumulative Model Updates: 323,034
Cumulative Timesteps: 2,694,099,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.93653
Policy Entropy: 4.19317
Value Function Loss: 0.00278

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.01686
Policy Update Magnitude: 0.22502
Value Function Update Magnitude: 0.25774

Collected Steps per Second: 20,542.36864
Overall Steps per Second: 9,970.50111

Timestep Collection Time: 2.43497
Timestep Consumption Time: 2.58183
PPO Batch Consumption Time: 0.30073
Total Iteration Time: 5.01680

Cumulative Model Updates: 323,040
Cumulative Timesteps: 2,694,149,826

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2694149826...
Checkpoint 2694149826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.05686
Policy Entropy: 4.20562
Value Function Loss: 0.00300

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.01835
Policy Update Magnitude: 0.22445
Value Function Update Magnitude: 0.27015

Collected Steps per Second: 22,443.32133
Overall Steps per Second: 10,721.51588

Timestep Collection Time: 2.22881
Timestep Consumption Time: 2.43676
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.66557

Cumulative Model Updates: 323,046
Cumulative Timesteps: 2,694,199,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.10509
Policy Entropy: 4.22672
Value Function Loss: 0.00238

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.01639
Policy Update Magnitude: 0.21711
Value Function Update Magnitude: 0.26501

Collected Steps per Second: 22,455.13753
Overall Steps per Second: 10,590.24562

Timestep Collection Time: 2.22782
Timestep Consumption Time: 2.49596
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.72378

Cumulative Model Updates: 323,052
Cumulative Timesteps: 2,694,249,874

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2694249874...
Checkpoint 2694249874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.98550
Policy Entropy: 4.23634
Value Function Loss: 0.00196

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.01314
Policy Update Magnitude: 0.20928
Value Function Update Magnitude: 0.25388

Collected Steps per Second: 22,666.45554
Overall Steps per Second: 10,651.50211

Timestep Collection Time: 2.20590
Timestep Consumption Time: 2.48827
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.69417

Cumulative Model Updates: 323,058
Cumulative Timesteps: 2,694,299,874

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.81115
Policy Entropy: 4.20642
Value Function Loss: 0.00238

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.01549
Policy Update Magnitude: 0.21679
Value Function Update Magnitude: 0.25537

Collected Steps per Second: 20,416.61119
Overall Steps per Second: 10,310.86616

Timestep Collection Time: 2.45006
Timestep Consumption Time: 2.40132
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.85139

Cumulative Model Updates: 323,064
Cumulative Timesteps: 2,694,349,896

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2694349896...
Checkpoint 2694349896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.17986
Policy Entropy: 4.16087
Value Function Loss: 0.00337

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02028
Policy Update Magnitude: 0.24213
Value Function Update Magnitude: 0.29420

Collected Steps per Second: 22,241.09541
Overall Steps per Second: 10,585.05452

Timestep Collection Time: 2.24881
Timestep Consumption Time: 2.47634
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.72515

Cumulative Model Updates: 323,070
Cumulative Timesteps: 2,694,399,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.79609
Policy Entropy: 4.13847
Value Function Loss: 0.00401

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02230
Policy Update Magnitude: 0.26226
Value Function Update Magnitude: 0.33059

Collected Steps per Second: 21,957.42790
Overall Steps per Second: 10,458.72662

Timestep Collection Time: 2.27741
Timestep Consumption Time: 2.50386
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.78127

Cumulative Model Updates: 323,076
Cumulative Timesteps: 2,694,449,918

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2694449918...
Checkpoint 2694449918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.86446
Policy Entropy: 4.10199
Value Function Loss: 0.00422

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.02652
Policy Update Magnitude: 0.28621
Value Function Update Magnitude: 0.34336

Collected Steps per Second: 21,703.37226
Overall Steps per Second: 10,699.03203

Timestep Collection Time: 2.30388
Timestep Consumption Time: 2.36963
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.67351

Cumulative Model Updates: 323,082
Cumulative Timesteps: 2,694,499,920

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.18389
Policy Entropy: 4.08782
Value Function Loss: 0.00406

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.02770
Policy Update Magnitude: 0.28977
Value Function Update Magnitude: 0.33848

Collected Steps per Second: 22,581.45068
Overall Steps per Second: 10,455.33367

Timestep Collection Time: 2.21456
Timestep Consumption Time: 2.56845
PPO Batch Consumption Time: 0.29869
Total Iteration Time: 4.78301

Cumulative Model Updates: 323,088
Cumulative Timesteps: 2,694,549,928

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2694549928...
Checkpoint 2694549928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.84356
Policy Entropy: 4.07780
Value Function Loss: 0.00421

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.02950
Policy Update Magnitude: 0.29184
Value Function Update Magnitude: 0.32935

Collected Steps per Second: 21,303.63692
Overall Steps per Second: 10,338.80675

Timestep Collection Time: 2.34796
Timestep Consumption Time: 2.49013
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.83808

Cumulative Model Updates: 323,094
Cumulative Timesteps: 2,694,599,948

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.24009
Policy Entropy: 4.10040
Value Function Loss: 0.00410

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.02929
Policy Update Magnitude: 0.28162
Value Function Update Magnitude: 0.32271

Collected Steps per Second: 22,390.68668
Overall Steps per Second: 10,739.51417

Timestep Collection Time: 2.23343
Timestep Consumption Time: 2.42302
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.65645

Cumulative Model Updates: 323,100
Cumulative Timesteps: 2,694,649,956

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2694649956...
Checkpoint 2694649956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.09529
Policy Entropy: 4.12081
Value Function Loss: 0.00379

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.02918
Policy Update Magnitude: 0.26319
Value Function Update Magnitude: 0.31328

Collected Steps per Second: 21,516.84969
Overall Steps per Second: 10,397.57683

Timestep Collection Time: 2.32385
Timestep Consumption Time: 2.48515
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 4.80901

Cumulative Model Updates: 323,106
Cumulative Timesteps: 2,694,699,958

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.30683
Policy Entropy: 4.12379
Value Function Loss: 0.00417

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.27205
Value Function Update Magnitude: 0.30486

Collected Steps per Second: 22,275.75218
Overall Steps per Second: 10,547.96178

Timestep Collection Time: 2.24468
Timestep Consumption Time: 2.49576
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.74044

Cumulative Model Updates: 323,112
Cumulative Timesteps: 2,694,749,960

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2694749960...
Checkpoint 2694749960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.44384
Policy Entropy: 4.10719
Value Function Loss: 0.00463

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.02861
Policy Update Magnitude: 0.29190
Value Function Update Magnitude: 0.32164

Collected Steps per Second: 22,421.92572
Overall Steps per Second: 10,567.22031

Timestep Collection Time: 2.23067
Timestep Consumption Time: 2.50245
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.73313

Cumulative Model Updates: 323,118
Cumulative Timesteps: 2,694,799,976

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.84246
Policy Entropy: 4.11796
Value Function Loss: 0.00421

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.03055
Policy Update Magnitude: 0.29128
Value Function Update Magnitude: 0.33797

Collected Steps per Second: 22,349.61360
Overall Steps per Second: 10,556.01179

Timestep Collection Time: 2.23816
Timestep Consumption Time: 2.50056
PPO Batch Consumption Time: 0.28494
Total Iteration Time: 4.73872

Cumulative Model Updates: 323,124
Cumulative Timesteps: 2,694,849,998

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2694849998...
Checkpoint 2694849998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.73329
Policy Entropy: 4.12964
Value Function Loss: 0.00381

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.02678
Policy Update Magnitude: 0.28051
Value Function Update Magnitude: 0.33217

Collected Steps per Second: 21,507.73201
Overall Steps per Second: 10,543.91706

Timestep Collection Time: 2.32521
Timestep Consumption Time: 2.41781
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.74302

Cumulative Model Updates: 323,130
Cumulative Timesteps: 2,694,900,008

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.15685
Policy Entropy: 4.15569
Value Function Loss: 0.00302

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.02317
Policy Update Magnitude: 0.26464
Value Function Update Magnitude: 0.31610

Collected Steps per Second: 22,198.17216
Overall Steps per Second: 10,510.54523

Timestep Collection Time: 2.25271
Timestep Consumption Time: 2.50499
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.75770

Cumulative Model Updates: 323,136
Cumulative Timesteps: 2,694,950,014

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2694950014...
Checkpoint 2694950014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.10715
Policy Entropy: 4.13798
Value Function Loss: 0.00387

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.02215
Policy Update Magnitude: 0.26191
Value Function Update Magnitude: 0.30866

Collected Steps per Second: 21,582.69253
Overall Steps per Second: 10,324.12378

Timestep Collection Time: 2.31751
Timestep Consumption Time: 2.52726
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 4.84477

Cumulative Model Updates: 323,142
Cumulative Timesteps: 2,695,000,032

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.48330
Policy Entropy: 4.14207
Value Function Loss: 0.00356

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02181
Policy Update Magnitude: 0.26453
Value Function Update Magnitude: 0.31322

Collected Steps per Second: 22,744.26414
Overall Steps per Second: 10,737.52526

Timestep Collection Time: 2.19897
Timestep Consumption Time: 2.45890
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.65787

Cumulative Model Updates: 323,148
Cumulative Timesteps: 2,695,050,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2695050046...
Checkpoint 2695050046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.51244
Policy Entropy: 4.14653
Value Function Loss: 0.00370

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.02474
Policy Update Magnitude: 0.26392
Value Function Update Magnitude: 0.31213

Collected Steps per Second: 21,484.93630
Overall Steps per Second: 10,226.58566

Timestep Collection Time: 2.32824
Timestep Consumption Time: 2.56313
PPO Batch Consumption Time: 0.29729
Total Iteration Time: 4.89137

Cumulative Model Updates: 323,154
Cumulative Timesteps: 2,695,100,068

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.86176
Policy Entropy: 4.15036
Value Function Loss: 0.00394

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.02345
Policy Update Magnitude: 0.27196
Value Function Update Magnitude: 0.31997

Collected Steps per Second: 21,975.78805
Overall Steps per Second: 10,513.16935

Timestep Collection Time: 2.27560
Timestep Consumption Time: 2.48111
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.75670

Cumulative Model Updates: 323,160
Cumulative Timesteps: 2,695,150,076

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2695150076...
Checkpoint 2695150076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.23815
Policy Entropy: 4.14850
Value Function Loss: 0.00420

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.02533
Policy Update Magnitude: 0.28602
Value Function Update Magnitude: 0.32973

Collected Steps per Second: 22,383.72131
Overall Steps per Second: 10,569.06038

Timestep Collection Time: 2.23430
Timestep Consumption Time: 2.49762
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.73192

Cumulative Model Updates: 323,166
Cumulative Timesteps: 2,695,200,088

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.51284
Policy Entropy: 4.14283
Value Function Loss: 0.00405

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.02671
Policy Update Magnitude: 0.28618
Value Function Update Magnitude: 0.32497

Collected Steps per Second: 21,704.02508
Overall Steps per Second: 10,490.95205

Timestep Collection Time: 2.30400
Timestep Consumption Time: 2.46259
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.76658

Cumulative Model Updates: 323,172
Cumulative Timesteps: 2,695,250,094

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2695250094...
Checkpoint 2695250094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.65956
Policy Entropy: 4.18435
Value Function Loss: 0.00324

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02331
Policy Update Magnitude: 0.26077
Value Function Update Magnitude: 0.31839

Collected Steps per Second: 21,991.44551
Overall Steps per Second: 10,688.27823

Timestep Collection Time: 2.27434
Timestep Consumption Time: 2.40518
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.67952

Cumulative Model Updates: 323,178
Cumulative Timesteps: 2,695,300,110

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.52334
Policy Entropy: 4.18571
Value Function Loss: 0.00278

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.01903
Policy Update Magnitude: 0.24653
Value Function Update Magnitude: 0.29349

Collected Steps per Second: 22,363.15248
Overall Steps per Second: 10,493.35383

Timestep Collection Time: 2.23600
Timestep Consumption Time: 2.52930
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.76530

Cumulative Model Updates: 323,184
Cumulative Timesteps: 2,695,350,114

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2695350114...
Checkpoint 2695350114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.49182
Policy Entropy: 4.19027
Value Function Loss: 0.00317

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.01811
Policy Update Magnitude: 0.25427
Value Function Update Magnitude: 0.27671

Collected Steps per Second: 22,032.80193
Overall Steps per Second: 10,509.39470

Timestep Collection Time: 2.27034
Timestep Consumption Time: 2.48940
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.75974

Cumulative Model Updates: 323,190
Cumulative Timesteps: 2,695,400,136

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51328
Policy Entropy: 4.18538
Value Function Loss: 0.00325

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.02282
Policy Update Magnitude: 0.25223
Value Function Update Magnitude: 0.27901

Collected Steps per Second: 22,660.19532
Overall Steps per Second: 10,562.90512

Timestep Collection Time: 2.20766
Timestep Consumption Time: 2.52835
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.73601

Cumulative Model Updates: 323,196
Cumulative Timesteps: 2,695,450,162

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2695450162...
Checkpoint 2695450162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.78047
Policy Entropy: 4.18611
Value Function Loss: 0.00346

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.02248
Policy Update Magnitude: 0.24328
Value Function Update Magnitude: 0.27858

Collected Steps per Second: 21,894.47645
Overall Steps per Second: 10,493.47230

Timestep Collection Time: 2.28386
Timestep Consumption Time: 2.48138
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.76525

Cumulative Model Updates: 323,202
Cumulative Timesteps: 2,695,500,166

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51448
Policy Entropy: 4.18874
Value Function Loss: 0.00306

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.01949
Policy Update Magnitude: 0.24445
Value Function Update Magnitude: 0.27385

Collected Steps per Second: 22,041.66727
Overall Steps per Second: 10,632.09273

Timestep Collection Time: 2.26907
Timestep Consumption Time: 2.43499
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.70406

Cumulative Model Updates: 323,208
Cumulative Timesteps: 2,695,550,180

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2695550180...
Checkpoint 2695550180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.71680
Policy Entropy: 4.17189
Value Function Loss: 0.00287

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02251
Policy Update Magnitude: 0.23829
Value Function Update Magnitude: 0.29317

Collected Steps per Second: 22,899.75008
Overall Steps per Second: 10,563.80258

Timestep Collection Time: 2.18474
Timestep Consumption Time: 2.55124
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.73598

Cumulative Model Updates: 323,214
Cumulative Timesteps: 2,695,600,210

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.45937
Policy Entropy: 4.19143
Value Function Loss: 0.00240

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.01801
Policy Update Magnitude: 0.23513
Value Function Update Magnitude: 0.28389

Collected Steps per Second: 21,886.86674
Overall Steps per Second: 10,479.85476

Timestep Collection Time: 2.28493
Timestep Consumption Time: 2.48708
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.77201

Cumulative Model Updates: 323,220
Cumulative Timesteps: 2,695,650,220

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2695650220...
Checkpoint 2695650220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.65344
Policy Entropy: 4.16090
Value Function Loss: 0.00270

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02009
Policy Update Magnitude: 0.23890
Value Function Update Magnitude: 0.27015

Collected Steps per Second: 21,798.39932
Overall Steps per Second: 10,333.26494

Timestep Collection Time: 2.29448
Timestep Consumption Time: 2.54581
PPO Batch Consumption Time: 0.31012
Total Iteration Time: 4.84029

Cumulative Model Updates: 323,226
Cumulative Timesteps: 2,695,700,236

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.43786
Policy Entropy: 4.18202
Value Function Loss: 0.00288

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.01994
Policy Update Magnitude: 0.24413
Value Function Update Magnitude: 0.26998

Collected Steps per Second: 21,857.33817
Overall Steps per Second: 10,338.93476

Timestep Collection Time: 2.28912
Timestep Consumption Time: 2.55026
PPO Batch Consumption Time: 0.29732
Total Iteration Time: 4.83938

Cumulative Model Updates: 323,232
Cumulative Timesteps: 2,695,750,270

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2695750270...
Checkpoint 2695750270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.78152
Policy Entropy: 4.18261
Value Function Loss: 0.00283

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.01933
Policy Update Magnitude: 0.23388
Value Function Update Magnitude: 0.27636

Collected Steps per Second: 22,049.23147
Overall Steps per Second: 10,467.30242

Timestep Collection Time: 2.26865
Timestep Consumption Time: 2.51023
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.77888

Cumulative Model Updates: 323,238
Cumulative Timesteps: 2,695,800,292

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.40440
Policy Entropy: 4.20446
Value Function Loss: 0.00291

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.01496
Policy Update Magnitude: 0.23162
Value Function Update Magnitude: 0.29258

Collected Steps per Second: 22,850.55566
Overall Steps per Second: 10,581.17031

Timestep Collection Time: 2.18918
Timestep Consumption Time: 2.53846
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.72764

Cumulative Model Updates: 323,244
Cumulative Timesteps: 2,695,850,316

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2695850316...
Checkpoint 2695850316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.22125
Policy Entropy: 4.17863
Value Function Loss: 0.00280

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.01841
Policy Update Magnitude: 0.23741
Value Function Update Magnitude: 0.30714

Collected Steps per Second: 21,442.71146
Overall Steps per Second: 10,287.39150

Timestep Collection Time: 2.33198
Timestep Consumption Time: 2.52873
PPO Batch Consumption Time: 0.29547
Total Iteration Time: 4.86071

Cumulative Model Updates: 323,250
Cumulative Timesteps: 2,695,900,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.41063
Policy Entropy: 4.16483
Value Function Loss: 0.00283

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.01906
Policy Update Magnitude: 0.25438
Value Function Update Magnitude: 0.30895

Collected Steps per Second: 22,153.46510
Overall Steps per Second: 10,600.94420

Timestep Collection Time: 2.25771
Timestep Consumption Time: 2.46036
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.71807

Cumulative Model Updates: 323,256
Cumulative Timesteps: 2,695,950,336

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2695950336...
Checkpoint 2695950336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.68024
Policy Entropy: 4.15744
Value Function Loss: 0.00339

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02003
Policy Update Magnitude: 0.25194
Value Function Update Magnitude: 0.30321

Collected Steps per Second: 21,890.91043
Overall Steps per Second: 10,493.81891

Timestep Collection Time: 2.28506
Timestep Consumption Time: 2.48175
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.76681

Cumulative Model Updates: 323,262
Cumulative Timesteps: 2,696,000,358

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.81076
Policy Entropy: 4.17659
Value Function Loss: 0.00315

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02044
Policy Update Magnitude: 0.24845
Value Function Update Magnitude: 0.29460

Collected Steps per Second: 22,237.60768
Overall Steps per Second: 10,429.75362

Timestep Collection Time: 2.24844
Timestep Consumption Time: 2.54553
PPO Batch Consumption Time: 0.29925
Total Iteration Time: 4.79398

Cumulative Model Updates: 323,268
Cumulative Timesteps: 2,696,050,358

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2696050358...
Checkpoint 2696050358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.01663
Policy Entropy: 4.17886
Value Function Loss: 0.00349

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.02402
Policy Update Magnitude: 0.24955
Value Function Update Magnitude: 0.30293

Collected Steps per Second: 21,435.10717
Overall Steps per Second: 10,647.58765

Timestep Collection Time: 2.33300
Timestep Consumption Time: 2.36366
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.69665

Cumulative Model Updates: 323,274
Cumulative Timesteps: 2,696,100,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.76293
Policy Entropy: 4.20016
Value Function Loss: 0.00247

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02013
Policy Update Magnitude: 0.24018
Value Function Update Magnitude: 0.31234

Collected Steps per Second: 22,394.65050
Overall Steps per Second: 10,470.56931

Timestep Collection Time: 2.23321
Timestep Consumption Time: 2.54322
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.77644

Cumulative Model Updates: 323,280
Cumulative Timesteps: 2,696,150,378

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2696150378...
Checkpoint 2696150378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.42325
Policy Entropy: 4.17866
Value Function Loss: 0.00265

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.01893
Policy Update Magnitude: 0.23467
Value Function Update Magnitude: 0.30068

Collected Steps per Second: 21,674.70124
Overall Steps per Second: 10,460.97831

Timestep Collection Time: 2.30813
Timestep Consumption Time: 2.47422
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.78234

Cumulative Model Updates: 323,286
Cumulative Timesteps: 2,696,200,406

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.59154
Policy Entropy: 4.15476
Value Function Loss: 0.00306

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01881
Policy Update Magnitude: 0.24500
Value Function Update Magnitude: 0.28668

Collected Steps per Second: 22,441.47159
Overall Steps per Second: 10,638.71802

Timestep Collection Time: 2.23025
Timestep Consumption Time: 2.47427
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.70451

Cumulative Model Updates: 323,292
Cumulative Timesteps: 2,696,250,456

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2696250456...
Checkpoint 2696250456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.63185
Policy Entropy: 4.14298
Value Function Loss: 0.00346

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02028
Policy Update Magnitude: 0.25326
Value Function Update Magnitude: 0.30157

Collected Steps per Second: 21,745.58242
Overall Steps per Second: 10,397.82834

Timestep Collection Time: 2.30061
Timestep Consumption Time: 2.51078
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.81139

Cumulative Model Updates: 323,298
Cumulative Timesteps: 2,696,300,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.13770
Policy Entropy: 4.13885
Value Function Loss: 0.00378

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.02570
Policy Update Magnitude: 0.27146
Value Function Update Magnitude: 0.32570

Collected Steps per Second: 22,202.77269
Overall Steps per Second: 10,746.47640

Timestep Collection Time: 2.25278
Timestep Consumption Time: 2.40158
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.65436

Cumulative Model Updates: 323,304
Cumulative Timesteps: 2,696,350,502

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2696350502...
Checkpoint 2696350502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.37348
Policy Entropy: 4.15407
Value Function Loss: 0.00342

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.02347
Policy Update Magnitude: 0.26336
Value Function Update Magnitude: 0.33837

Collected Steps per Second: 21,718.73050
Overall Steps per Second: 10,402.61399

Timestep Collection Time: 2.30244
Timestep Consumption Time: 2.50462
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.80706

Cumulative Model Updates: 323,310
Cumulative Timesteps: 2,696,400,508

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.68454
Policy Entropy: 4.14947
Value Function Loss: 0.00400

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.02330
Policy Update Magnitude: 0.27350
Value Function Update Magnitude: 0.35394

Collected Steps per Second: 22,681.39801
Overall Steps per Second: 10,621.49869

Timestep Collection Time: 2.20507
Timestep Consumption Time: 2.50368
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.70875

Cumulative Model Updates: 323,316
Cumulative Timesteps: 2,696,450,522

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2696450522...
Checkpoint 2696450522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109.66385
Policy Entropy: 4.14101
Value Function Loss: 0.00357

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02192
Policy Update Magnitude: 0.28189
Value Function Update Magnitude: 0.36555

Collected Steps per Second: 21,380.45463
Overall Steps per Second: 10,505.79110

Timestep Collection Time: 2.33943
Timestep Consumption Time: 2.42157
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.76099

Cumulative Model Updates: 323,322
Cumulative Timesteps: 2,696,500,540

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.78267
Policy Entropy: 4.14313
Value Function Loss: 0.00346

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.02269
Policy Update Magnitude: 0.27586
Value Function Update Magnitude: 0.37020

Collected Steps per Second: 22,514.56332
Overall Steps per Second: 10,637.28620

Timestep Collection Time: 2.22078
Timestep Consumption Time: 2.47966
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.70045

Cumulative Model Updates: 323,328
Cumulative Timesteps: 2,696,550,540

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2696550540...
Checkpoint 2696550540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.13093
Policy Entropy: 4.15565
Value Function Loss: 0.00318

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02003
Policy Update Magnitude: 0.25961
Value Function Update Magnitude: 0.35719

Collected Steps per Second: 21,726.75329
Overall Steps per Second: 10,396.51967

Timestep Collection Time: 2.30140
Timestep Consumption Time: 2.50809
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.80949

Cumulative Model Updates: 323,334
Cumulative Timesteps: 2,696,600,542

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.77922
Policy Entropy: 4.13823
Value Function Loss: 0.00387

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02088
Policy Update Magnitude: 0.26304
Value Function Update Magnitude: 0.33403

Collected Steps per Second: 22,455.93696
Overall Steps per Second: 10,786.08082

Timestep Collection Time: 2.22747
Timestep Consumption Time: 2.40998
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.63746

Cumulative Model Updates: 323,340
Cumulative Timesteps: 2,696,650,562

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2696650562...
Checkpoint 2696650562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.34854
Policy Entropy: 4.15606
Value Function Loss: 0.00356

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02084
Policy Update Magnitude: 0.26683
Value Function Update Magnitude: 0.33221

Collected Steps per Second: 22,031.46475
Overall Steps per Second: 10,520.11418

Timestep Collection Time: 2.27003
Timestep Consumption Time: 2.48391
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.75394

Cumulative Model Updates: 323,346
Cumulative Timesteps: 2,696,700,574

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.93406
Policy Entropy: 4.16085
Value Function Loss: 0.00304

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02287
Policy Update Magnitude: 0.25420
Value Function Update Magnitude: 0.31885

Collected Steps per Second: 22,324.47154
Overall Steps per Second: 10,577.55095

Timestep Collection Time: 2.24023
Timestep Consumption Time: 2.48789
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.72813

Cumulative Model Updates: 323,352
Cumulative Timesteps: 2,696,750,586

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2696750586...
Checkpoint 2696750586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.15865
Policy Entropy: 4.19427
Value Function Loss: 0.00238

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.01934
Policy Update Magnitude: 0.23996
Value Function Update Magnitude: 0.29478

Collected Steps per Second: 22,580.88009
Overall Steps per Second: 10,586.98561

Timestep Collection Time: 2.21479
Timestep Consumption Time: 2.50912
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.72391

Cumulative Model Updates: 323,358
Cumulative Timesteps: 2,696,800,598

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.30230
Policy Entropy: 4.18986
Value Function Loss: 0.00276

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.01779
Policy Update Magnitude: 0.24061
Value Function Update Magnitude: 0.27705

Collected Steps per Second: 22,386.11975
Overall Steps per Second: 10,524.85696

Timestep Collection Time: 2.23424
Timestep Consumption Time: 2.51794
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.75218

Cumulative Model Updates: 323,364
Cumulative Timesteps: 2,696,850,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2696850614...
Checkpoint 2696850614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.44211
Policy Entropy: 4.16861
Value Function Loss: 0.00281

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.01990
Policy Update Magnitude: 0.23587
Value Function Update Magnitude: 0.29451

Collected Steps per Second: 21,861.80718
Overall Steps per Second: 10,595.86820

Timestep Collection Time: 2.28728
Timestep Consumption Time: 2.43192
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.71920

Cumulative Model Updates: 323,370
Cumulative Timesteps: 2,696,900,618

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.33457
Policy Entropy: 4.17713
Value Function Loss: 0.00317

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02068
Policy Update Magnitude: 0.25588
Value Function Update Magnitude: 0.31427

Collected Steps per Second: 22,288.00499
Overall Steps per Second: 10,476.62135

Timestep Collection Time: 2.24453
Timestep Consumption Time: 2.53049
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.77501

Cumulative Model Updates: 323,376
Cumulative Timesteps: 2,696,950,644

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2696950644...
Checkpoint 2696950644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.85539
Policy Entropy: 4.17196
Value Function Loss: 0.00303

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.02052
Policy Update Magnitude: 0.25195
Value Function Update Magnitude: 0.32554

Collected Steps per Second: 21,984.01929
Overall Steps per Second: 10,552.65585

Timestep Collection Time: 2.27574
Timestep Consumption Time: 2.46524
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.74099

Cumulative Model Updates: 323,382
Cumulative Timesteps: 2,697,000,674

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.66936
Policy Entropy: 4.21528
Value Function Loss: 0.00228

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.01825
Policy Update Magnitude: 0.22429
Value Function Update Magnitude: 0.31119

Collected Steps per Second: 21,866.49605
Overall Steps per Second: 10,541.98107

Timestep Collection Time: 2.28688
Timestep Consumption Time: 2.45663
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.74351

Cumulative Model Updates: 323,388
Cumulative Timesteps: 2,697,050,680

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2697050680...
Checkpoint 2697050680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.75001
Policy Entropy: 4.21678
Value Function Loss: 0.00268

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.01687
Policy Update Magnitude: 0.21900
Value Function Update Magnitude: 0.27349

Collected Steps per Second: 22,017.66671
Overall Steps per Second: 10,364.38368

Timestep Collection Time: 2.27099
Timestep Consumption Time: 2.55341
PPO Batch Consumption Time: 0.29513
Total Iteration Time: 4.82441

Cumulative Model Updates: 323,394
Cumulative Timesteps: 2,697,100,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.97426
Policy Entropy: 4.17109
Value Function Loss: 0.00320

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.01648
Policy Update Magnitude: 0.25098
Value Function Update Magnitude: 0.28303

Collected Steps per Second: 22,085.47514
Overall Steps per Second: 10,533.31237

Timestep Collection Time: 2.26493
Timestep Consumption Time: 2.48401
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.74893

Cumulative Model Updates: 323,400
Cumulative Timesteps: 2,697,150,704

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2697150704...
Checkpoint 2697150704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.40690
Policy Entropy: 4.11681
Value Function Loss: 0.00367

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02284
Policy Update Magnitude: 0.27102
Value Function Update Magnitude: 0.30797

Collected Steps per Second: 22,779.20819
Overall Steps per Second: 10,702.16972

Timestep Collection Time: 2.19630
Timestep Consumption Time: 2.47845
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.67475

Cumulative Model Updates: 323,406
Cumulative Timesteps: 2,697,200,734

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.24528
Policy Entropy: 4.09251
Value Function Loss: 0.00388

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.02319
Policy Update Magnitude: 0.27463
Value Function Update Magnitude: 0.33053

Collected Steps per Second: 21,844.01455
Overall Steps per Second: 10,542.97280

Timestep Collection Time: 2.28905
Timestep Consumption Time: 2.45364
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.74269

Cumulative Model Updates: 323,412
Cumulative Timesteps: 2,697,250,736

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2697250736...
Checkpoint 2697250736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.22745
Policy Entropy: 4.13123
Value Function Loss: 0.00317

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02253
Policy Update Magnitude: 0.26050
Value Function Update Magnitude: 0.33906

Collected Steps per Second: 21,733.73391
Overall Steps per Second: 10,341.62961

Timestep Collection Time: 2.30140
Timestep Consumption Time: 2.53517
PPO Batch Consumption Time: 0.29712
Total Iteration Time: 4.83657

Cumulative Model Updates: 323,418
Cumulative Timesteps: 2,697,300,754

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.90427
Policy Entropy: 4.17702
Value Function Loss: 0.00280

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.01859
Policy Update Magnitude: 0.24550
Value Function Update Magnitude: 0.31494

Collected Steps per Second: 22,621.94340
Overall Steps per Second: 10,592.17614

Timestep Collection Time: 2.21069
Timestep Consumption Time: 2.51072
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.72141

Cumulative Model Updates: 323,424
Cumulative Timesteps: 2,697,350,764

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2697350764...
Checkpoint 2697350764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.32448
Policy Entropy: 4.17806
Value Function Loss: 0.00278

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.01561
Policy Update Magnitude: 0.23983
Value Function Update Magnitude: 0.31182

Collected Steps per Second: 22,251.43607
Overall Steps per Second: 10,433.51157

Timestep Collection Time: 2.24794
Timestep Consumption Time: 2.54622
PPO Batch Consumption Time: 0.29820
Total Iteration Time: 4.79417

Cumulative Model Updates: 323,430
Cumulative Timesteps: 2,697,400,784

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.82443
Policy Entropy: 4.17532
Value Function Loss: 0.00296

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.01932
Policy Update Magnitude: 0.24909
Value Function Update Magnitude: 0.31032

Collected Steps per Second: 21,925.30644
Overall Steps per Second: 10,469.20662

Timestep Collection Time: 2.28175
Timestep Consumption Time: 2.49684
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.77859

Cumulative Model Updates: 323,436
Cumulative Timesteps: 2,697,450,812

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2697450812...
Checkpoint 2697450812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.25941
Policy Entropy: 4.17237
Value Function Loss: 0.00315

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02010
Policy Update Magnitude: 0.25107
Value Function Update Magnitude: 0.29611

Collected Steps per Second: 23,032.93363
Overall Steps per Second: 10,639.46132

Timestep Collection Time: 2.17141
Timestep Consumption Time: 2.52939
PPO Batch Consumption Time: 0.29627
Total Iteration Time: 4.70080

Cumulative Model Updates: 323,442
Cumulative Timesteps: 2,697,500,826

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.07648
Policy Entropy: 4.19636
Value Function Loss: 0.00328

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.01972
Policy Update Magnitude: 0.24348
Value Function Update Magnitude: 0.27842

Collected Steps per Second: 21,845.76729
Overall Steps per Second: 10,467.53876

Timestep Collection Time: 2.28951
Timestep Consumption Time: 2.48870
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.77820

Cumulative Model Updates: 323,448
Cumulative Timesteps: 2,697,550,842

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2697550842...
Checkpoint 2697550842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.10401
Policy Entropy: 4.19563
Value Function Loss: 0.00283

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.01992
Policy Update Magnitude: 0.23325
Value Function Update Magnitude: 0.28656

Collected Steps per Second: 22,095.61070
Overall Steps per Second: 10,633.04864

Timestep Collection Time: 2.26362
Timestep Consumption Time: 2.44021
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.70382

Cumulative Model Updates: 323,454
Cumulative Timesteps: 2,697,600,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.85822
Policy Entropy: 4.17947
Value Function Loss: 0.00282

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.01751
Policy Update Magnitude: 0.22772
Value Function Update Magnitude: 0.29274

Collected Steps per Second: 22,387.05274
Overall Steps per Second: 10,410.29611

Timestep Collection Time: 2.23370
Timestep Consumption Time: 2.56981
PPO Batch Consumption Time: 0.29700
Total Iteration Time: 4.80351

Cumulative Model Updates: 323,460
Cumulative Timesteps: 2,697,650,864

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2697650864...
Checkpoint 2697650864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.09441
Policy Entropy: 4.15142
Value Function Loss: 0.00283

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.01745
Policy Update Magnitude: 0.23328
Value Function Update Magnitude: 0.28491

Collected Steps per Second: 22,321.77129
Overall Steps per Second: 10,662.73872

Timestep Collection Time: 2.24050
Timestep Consumption Time: 2.44985
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.69035

Cumulative Model Updates: 323,466
Cumulative Timesteps: 2,697,700,876

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.63719
Policy Entropy: 4.12145
Value Function Loss: 0.00342

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.01878
Policy Update Magnitude: 0.26090
Value Function Update Magnitude: 0.29051

Collected Steps per Second: 21,792.29772
Overall Steps per Second: 10,447.38183

Timestep Collection Time: 2.29448
Timestep Consumption Time: 2.49160
PPO Batch Consumption Time: 0.29897
Total Iteration Time: 4.78608

Cumulative Model Updates: 323,472
Cumulative Timesteps: 2,697,750,878

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2697750878...
Checkpoint 2697750878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.17948
Policy Entropy: 4.10738
Value Function Loss: 0.00335

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.02289
Policy Update Magnitude: 0.26827
Value Function Update Magnitude: 0.30628

Collected Steps per Second: 22,259.81896
Overall Steps per Second: 10,631.12149

Timestep Collection Time: 2.24665
Timestep Consumption Time: 2.45746
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.70411

Cumulative Model Updates: 323,478
Cumulative Timesteps: 2,697,800,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.17468
Policy Entropy: 4.09359
Value Function Loss: 0.00373

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02418
Policy Update Magnitude: 0.27365
Value Function Update Magnitude: 0.32210

Collected Steps per Second: 21,989.32323
Overall Steps per Second: 10,450.97967

Timestep Collection Time: 2.27438
Timestep Consumption Time: 2.51101
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.78539

Cumulative Model Updates: 323,484
Cumulative Timesteps: 2,697,850,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2697850900...
Checkpoint 2697850900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.21979
Policy Entropy: 4.09602
Value Function Loss: 0.00375

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02333
Policy Update Magnitude: 0.28535
Value Function Update Magnitude: 0.33542

Collected Steps per Second: 22,745.46128
Overall Steps per Second: 9,925.50121

Timestep Collection Time: 2.19956
Timestep Consumption Time: 2.84099
PPO Batch Consumption Time: 0.32651
Total Iteration Time: 5.04055

Cumulative Model Updates: 323,490
Cumulative Timesteps: 2,697,900,930

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.84667
Policy Entropy: 4.09648
Value Function Loss: 0.00344

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.02348
Policy Update Magnitude: 0.29238
Value Function Update Magnitude: 0.34203

Collected Steps per Second: 21,836.62326
Overall Steps per Second: 10,173.10328

Timestep Collection Time: 2.28982
Timestep Consumption Time: 2.62529
PPO Batch Consumption Time: 0.29894
Total Iteration Time: 4.91512

Cumulative Model Updates: 323,496
Cumulative Timesteps: 2,697,950,932

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2697950932...
Checkpoint 2697950932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.30877
Policy Entropy: 4.12108
Value Function Loss: 0.00307

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.02494
Policy Update Magnitude: 0.28114
Value Function Update Magnitude: 0.32270

Collected Steps per Second: 21,689.06593
Overall Steps per Second: 10,552.19601

Timestep Collection Time: 2.30642
Timestep Consumption Time: 2.43421
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.74062

Cumulative Model Updates: 323,502
Cumulative Timesteps: 2,698,000,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.16620
Policy Entropy: 4.16203
Value Function Loss: 0.00287

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.02271
Policy Update Magnitude: 0.27579
Value Function Update Magnitude: 0.30543

Collected Steps per Second: 22,373.65080
Overall Steps per Second: 10,494.56019

Timestep Collection Time: 2.23504
Timestep Consumption Time: 2.52991
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.76494

Cumulative Model Updates: 323,508
Cumulative Timesteps: 2,698,050,962

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2698050962...
Checkpoint 2698050962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.67214
Policy Entropy: 4.18018
Value Function Loss: 0.00304

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.02060
Policy Update Magnitude: 0.26479
Value Function Update Magnitude: 0.29462

Collected Steps per Second: 22,148.16971
Overall Steps per Second: 10,552.81968

Timestep Collection Time: 2.25888
Timestep Consumption Time: 2.48204
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.74091

Cumulative Model Updates: 323,514
Cumulative Timesteps: 2,698,100,992

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.71365
Policy Entropy: 4.18547
Value Function Loss: 0.00307

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.02124
Policy Update Magnitude: 0.25849
Value Function Update Magnitude: 0.28610

Collected Steps per Second: 22,000.22827
Overall Steps per Second: 10,681.80106

Timestep Collection Time: 2.27279
Timestep Consumption Time: 2.40825
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.68105

Cumulative Model Updates: 323,520
Cumulative Timesteps: 2,698,150,994

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2698150994...
Checkpoint 2698150994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.48870
Policy Entropy: 4.18155
Value Function Loss: 0.00306

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.01933
Policy Update Magnitude: 0.24942
Value Function Update Magnitude: 0.28890

Collected Steps per Second: 21,743.51219
Overall Steps per Second: 10,378.29618

Timestep Collection Time: 2.30055
Timestep Consumption Time: 2.51932
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.81987

Cumulative Model Updates: 323,526
Cumulative Timesteps: 2,698,201,016

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.19765
Policy Entropy: 4.15954
Value Function Loss: 0.00328

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02254
Policy Update Magnitude: 0.24779
Value Function Update Magnitude: 0.29486

Collected Steps per Second: 22,215.92481
Overall Steps per Second: 10,490.52934

Timestep Collection Time: 2.25172
Timestep Consumption Time: 2.51677
PPO Batch Consumption Time: 0.29763
Total Iteration Time: 4.76849

Cumulative Model Updates: 323,532
Cumulative Timesteps: 2,698,251,040

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2698251040...
Checkpoint 2698251040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.12446
Policy Entropy: 4.14914
Value Function Loss: 0.00305

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02353
Policy Update Magnitude: 0.24639
Value Function Update Magnitude: 0.31272

Collected Steps per Second: 22,580.99215
Overall Steps per Second: 10,602.83944

Timestep Collection Time: 2.21540
Timestep Consumption Time: 2.50277
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.71817

Cumulative Model Updates: 323,538
Cumulative Timesteps: 2,698,301,066

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.16117
Policy Entropy: 4.11770
Value Function Loss: 0.00364

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.02582
Policy Update Magnitude: 0.25672
Value Function Update Magnitude: 0.32480

Collected Steps per Second: 21,910.38989
Overall Steps per Second: 10,364.88851

Timestep Collection Time: 2.28239
Timestep Consumption Time: 2.54236
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.82475

Cumulative Model Updates: 323,544
Cumulative Timesteps: 2,698,351,074

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2698351074...
Checkpoint 2698351074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.95011
Policy Entropy: 4.13007
Value Function Loss: 0.00347

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.02454
Policy Update Magnitude: 0.26180
Value Function Update Magnitude: 0.33837

Collected Steps per Second: 21,710.46676
Overall Steps per Second: 10,644.57491

Timestep Collection Time: 2.30423
Timestep Consumption Time: 2.39544
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.69967

Cumulative Model Updates: 323,550
Cumulative Timesteps: 2,698,401,100

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.53732
Policy Entropy: 4.12862
Value Function Loss: 0.00350

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.02331
Policy Update Magnitude: 0.28560
Value Function Update Magnitude: 0.35181

Collected Steps per Second: 22,524.69692
Overall Steps per Second: 10,488.98326

Timestep Collection Time: 2.22076
Timestep Consumption Time: 2.54824
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.76900

Cumulative Model Updates: 323,556
Cumulative Timesteps: 2,698,451,122

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2698451122...
Checkpoint 2698451122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.95242
Policy Entropy: 4.14325
Value Function Loss: 0.00362

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.02614
Policy Update Magnitude: 0.28420
Value Function Update Magnitude: 0.35378

Collected Steps per Second: 21,661.55012
Overall Steps per Second: 10,324.67206

Timestep Collection Time: 2.30888
Timestep Consumption Time: 2.53524
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.84412

Cumulative Model Updates: 323,562
Cumulative Timesteps: 2,698,501,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.97895
Policy Entropy: 4.13205
Value Function Loss: 0.00366

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.02793
Policy Update Magnitude: 0.28350
Value Function Update Magnitude: 0.35576

Collected Steps per Second: 22,013.52681
Overall Steps per Second: 10,726.09347

Timestep Collection Time: 2.27178
Timestep Consumption Time: 2.39068
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.66246

Cumulative Model Updates: 323,568
Cumulative Timesteps: 2,698,551,146

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2698551146...
Checkpoint 2698551146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.27030
Policy Entropy: 4.13040
Value Function Loss: 0.00366

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.02727
Policy Update Magnitude: 0.27989
Value Function Update Magnitude: 0.33734

Collected Steps per Second: 21,819.09340
Overall Steps per Second: 10,349.38208

Timestep Collection Time: 2.29212
Timestep Consumption Time: 2.54024
PPO Batch Consumption Time: 0.29736
Total Iteration Time: 4.83237

Cumulative Model Updates: 323,574
Cumulative Timesteps: 2,698,601,158

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.33726
Policy Entropy: 4.11692
Value Function Loss: 0.00395

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.02586
Policy Update Magnitude: 0.28468
Value Function Update Magnitude: 0.33852

Collected Steps per Second: 21,947.10144
Overall Steps per Second: 10,494.45017

Timestep Collection Time: 2.27830
Timestep Consumption Time: 2.48632
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.76461

Cumulative Model Updates: 323,580
Cumulative Timesteps: 2,698,651,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2698651160...
Checkpoint 2698651160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.41827
Policy Entropy: 4.16111
Value Function Loss: 0.00309

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.02750
Policy Update Magnitude: 0.27490
Value Function Update Magnitude: 0.34654

Collected Steps per Second: 22,876.84251
Overall Steps per Second: 10,579.84517

Timestep Collection Time: 2.18702
Timestep Consumption Time: 2.54198
PPO Batch Consumption Time: 0.29873
Total Iteration Time: 4.72899

Cumulative Model Updates: 323,586
Cumulative Timesteps: 2,698,701,192

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.41138
Policy Entropy: 4.16886
Value Function Loss: 0.00297

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.02293
Policy Update Magnitude: 0.24926
Value Function Update Magnitude: 0.31359

Collected Steps per Second: 22,228.63439
Overall Steps per Second: 10,465.03842

Timestep Collection Time: 2.24989
Timestep Consumption Time: 2.52907
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.77896

Cumulative Model Updates: 323,592
Cumulative Timesteps: 2,698,751,204

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2698751204...
Checkpoint 2698751204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.23187
Policy Entropy: 4.19642
Value Function Loss: 0.00241

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.01903
Policy Update Magnitude: 0.22991
Value Function Update Magnitude: 0.28558

Collected Steps per Second: 21,750.36800
Overall Steps per Second: 10,480.78484

Timestep Collection Time: 2.29955
Timestep Consumption Time: 2.47261
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.77216

Cumulative Model Updates: 323,598
Cumulative Timesteps: 2,698,801,220

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.22726
Policy Entropy: 4.16466
Value Function Loss: 0.00270

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02277
Policy Update Magnitude: 0.23357
Value Function Update Magnitude: 0.26847

Collected Steps per Second: 22,984.88256
Overall Steps per Second: 10,660.31099

Timestep Collection Time: 2.17691
Timestep Consumption Time: 2.51676
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.69367

Cumulative Model Updates: 323,604
Cumulative Timesteps: 2,698,851,256

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2698851256...
Checkpoint 2698851256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.23903
Policy Entropy: 4.19501
Value Function Loss: 0.00235

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.01853
Policy Update Magnitude: 0.23818
Value Function Update Magnitude: 0.27922

Collected Steps per Second: 22,345.92831
Overall Steps per Second: 10,586.10259

Timestep Collection Time: 2.23763
Timestep Consumption Time: 2.48573
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.72336

Cumulative Model Updates: 323,610
Cumulative Timesteps: 2,698,901,258

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.17539
Policy Entropy: 4.19319
Value Function Loss: 0.00265

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.01846
Policy Update Magnitude: 0.23257
Value Function Update Magnitude: 0.28184

Collected Steps per Second: 21,836.15092
Overall Steps per Second: 10,522.23732

Timestep Collection Time: 2.29125
Timestep Consumption Time: 2.46364
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.75488

Cumulative Model Updates: 323,616
Cumulative Timesteps: 2,698,951,290

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2698951290...
Checkpoint 2698951290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.82227
Policy Entropy: 4.18376
Value Function Loss: 0.00256

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01458
Policy Update Magnitude: 0.23809
Value Function Update Magnitude: 0.28112

Collected Steps per Second: 22,873.12133
Overall Steps per Second: 10,530.71659

Timestep Collection Time: 2.18737
Timestep Consumption Time: 2.56368
PPO Batch Consumption Time: 0.29738
Total Iteration Time: 4.75105

Cumulative Model Updates: 323,622
Cumulative Timesteps: 2,699,001,322

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.06692
Policy Entropy: 4.17699
Value Function Loss: 0.00253

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.01733
Policy Update Magnitude: 0.23565
Value Function Update Magnitude: 0.27277

Collected Steps per Second: 22,013.74330
Overall Steps per Second: 10,589.76950

Timestep Collection Time: 2.27340
Timestep Consumption Time: 2.45248
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.72588

Cumulative Model Updates: 323,628
Cumulative Timesteps: 2,699,051,368

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2699051368...
Checkpoint 2699051368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.17132
Policy Entropy: 4.19598
Value Function Loss: 0.00220

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01590
Policy Update Magnitude: 0.22402
Value Function Update Magnitude: 0.27291

Collected Steps per Second: 22,485.84688
Overall Steps per Second: 10,673.83332

Timestep Collection Time: 2.22433
Timestep Consumption Time: 2.46152
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.68585

Cumulative Model Updates: 323,634
Cumulative Timesteps: 2,699,101,384

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.65521
Policy Entropy: 4.22177
Value Function Loss: 0.00202

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.01443
Policy Update Magnitude: 0.20972
Value Function Update Magnitude: 0.27174

Collected Steps per Second: 21,892.35652
Overall Steps per Second: 10,382.01419

Timestep Collection Time: 2.28399
Timestep Consumption Time: 2.53222
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.81621

Cumulative Model Updates: 323,640
Cumulative Timesteps: 2,699,151,386

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2699151386...
Checkpoint 2699151386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.35856
Policy Entropy: 4.18617
Value Function Loss: 0.00268

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01559
Policy Update Magnitude: 0.23827
Value Function Update Magnitude: 0.28130

Collected Steps per Second: 19,730.16142
Overall Steps per Second: 9,657.21539

Timestep Collection Time: 2.53490
Timestep Consumption Time: 2.64402
PPO Batch Consumption Time: 0.30438
Total Iteration Time: 5.17893

Cumulative Model Updates: 323,646
Cumulative Timesteps: 2,699,201,400

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.01950
Policy Entropy: 4.16491
Value Function Loss: 0.00309

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02249
Policy Update Magnitude: 0.24954
Value Function Update Magnitude: 0.30167

Collected Steps per Second: 21,449.44118
Overall Steps per Second: 10,343.84816

Timestep Collection Time: 2.33181
Timestep Consumption Time: 2.50353
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.83534

Cumulative Model Updates: 323,652
Cumulative Timesteps: 2,699,251,416

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2699251416...
Checkpoint 2699251416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.55115
Policy Entropy: 4.15639
Value Function Loss: 0.00281

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02061
Policy Update Magnitude: 0.24402
Value Function Update Magnitude: 0.31338

Collected Steps per Second: 22,042.27374
Overall Steps per Second: 10,476.31714

Timestep Collection Time: 2.26882
Timestep Consumption Time: 2.50480
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.77362

Cumulative Model Updates: 323,658
Cumulative Timesteps: 2,699,301,426

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.98650
Policy Entropy: 4.15686
Value Function Loss: 0.00301

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.01850
Policy Update Magnitude: 0.25553
Value Function Update Magnitude: 0.31760

Collected Steps per Second: 21,434.72533
Overall Steps per Second: 10,461.73085

Timestep Collection Time: 2.33360
Timestep Consumption Time: 2.44764
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.78124

Cumulative Model Updates: 323,664
Cumulative Timesteps: 2,699,351,446

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2699351446...
Checkpoint 2699351446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.37538
Policy Entropy: 4.16014
Value Function Loss: 0.00312

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.01835
Policy Update Magnitude: 0.27000
Value Function Update Magnitude: 0.34377

Collected Steps per Second: 22,242.36432
Overall Steps per Second: 10,621.89896

Timestep Collection Time: 2.24913
Timestep Consumption Time: 2.46057
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.70970

Cumulative Model Updates: 323,670
Cumulative Timesteps: 2,699,401,472

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.10410
Policy Entropy: 4.17059
Value Function Loss: 0.00316

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.02153
Policy Update Magnitude: 0.25329
Value Function Update Magnitude: 0.36400

Collected Steps per Second: 21,468.24032
Overall Steps per Second: 10,327.46697

Timestep Collection Time: 2.32977
Timestep Consumption Time: 2.51324
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.84301

Cumulative Model Updates: 323,676
Cumulative Timesteps: 2,699,451,488

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2699451488...
Checkpoint 2699451488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.28282
Policy Entropy: 4.20337
Value Function Loss: 0.00294

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.01996
Policy Update Magnitude: 0.24243
Value Function Update Magnitude: 0.34311

Collected Steps per Second: 22,025.86619
Overall Steps per Second: 10,753.77111

Timestep Collection Time: 2.27069
Timestep Consumption Time: 2.38014
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.65083

Cumulative Model Updates: 323,682
Cumulative Timesteps: 2,699,501,502

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.09928
Policy Entropy: 4.20988
Value Function Loss: 0.00295

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.01899
Policy Update Magnitude: 0.24928
Value Function Update Magnitude: 0.30933

Collected Steps per Second: 22,046.41964
Overall Steps per Second: 10,453.50313

Timestep Collection Time: 2.26921
Timestep Consumption Time: 2.51655
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.78576

Cumulative Model Updates: 323,688
Cumulative Timesteps: 2,699,551,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2699551530...
Checkpoint 2699551530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.61416
Policy Entropy: 4.17838
Value Function Loss: 0.00321

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.02058
Policy Update Magnitude: 0.27454
Value Function Update Magnitude: 0.30896

Collected Steps per Second: 21,967.90462
Overall Steps per Second: 10,610.00104

Timestep Collection Time: 2.27723
Timestep Consumption Time: 2.43775
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.71499

Cumulative Model Updates: 323,694
Cumulative Timesteps: 2,699,601,556

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.12875
Policy Entropy: 4.15586
Value Function Loss: 0.00295

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.02738
Policy Update Magnitude: 0.27739
Value Function Update Magnitude: 0.32502

Collected Steps per Second: 21,915.46108
Overall Steps per Second: 10,458.40507

Timestep Collection Time: 2.28177
Timestep Consumption Time: 2.49965
PPO Batch Consumption Time: 0.29913
Total Iteration Time: 4.78142

Cumulative Model Updates: 323,700
Cumulative Timesteps: 2,699,651,562

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2699651562...
Checkpoint 2699651562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.59869
Policy Entropy: 4.16421
Value Function Loss: 0.00230

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.02610
Policy Update Magnitude: 0.25211
Value Function Update Magnitude: 0.31153

Collected Steps per Second: 22,187.97960
Overall Steps per Second: 10,638.89148

Timestep Collection Time: 2.25482
Timestep Consumption Time: 2.44773
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.70256

Cumulative Model Updates: 323,706
Cumulative Timesteps: 2,699,701,592

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.31377
Policy Entropy: 4.17495
Value Function Loss: 0.00209

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.02306
Policy Update Magnitude: 0.25587
Value Function Update Magnitude: 0.29350

Collected Steps per Second: 22,005.77229
Overall Steps per Second: 10,494.74995

Timestep Collection Time: 2.27286
Timestep Consumption Time: 2.49295
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.76581

Cumulative Model Updates: 323,712
Cumulative Timesteps: 2,699,751,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2699751608...
Checkpoint 2699751608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.59469
Policy Entropy: 4.21898
Value Function Loss: 0.00177

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.02436
Policy Update Magnitude: 0.25011
Value Function Update Magnitude: 0.28416

Collected Steps per Second: 22,582.94410
Overall Steps per Second: 10,700.60600

Timestep Collection Time: 2.21477
Timestep Consumption Time: 2.45936
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.67413

Cumulative Model Updates: 323,718
Cumulative Timesteps: 2,699,801,624

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.22107
Policy Entropy: 4.24427
Value Function Loss: 0.00180

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.02033
Policy Update Magnitude: 0.21411
Value Function Update Magnitude: 0.28508

Collected Steps per Second: 22,333.32970
Overall Steps per Second: 10,410.98386

Timestep Collection Time: 2.23943
Timestep Consumption Time: 2.56453
PPO Batch Consumption Time: 0.29786
Total Iteration Time: 4.80396

Cumulative Model Updates: 323,724
Cumulative Timesteps: 2,699,851,638

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2699851638...
Checkpoint 2699851638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.68815
Policy Entropy: 4.21179
Value Function Loss: 0.00261

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.01960
Policy Update Magnitude: 0.23074
Value Function Update Magnitude: 0.28680

Collected Steps per Second: 21,842.58090
Overall Steps per Second: 10,700.59292

Timestep Collection Time: 2.28956
Timestep Consumption Time: 2.38401
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.67357

Cumulative Model Updates: 323,730
Cumulative Timesteps: 2,699,901,648

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.71614
Policy Entropy: 4.18188
Value Function Loss: 0.00319

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.01989
Policy Update Magnitude: 0.26147
Value Function Update Magnitude: 0.30887

Collected Steps per Second: 21,414.10855
Overall Steps per Second: 10,272.53746

Timestep Collection Time: 2.33603
Timestep Consumption Time: 2.53365
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.86968

Cumulative Model Updates: 323,736
Cumulative Timesteps: 2,699,951,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2699951672...
Checkpoint 2699951672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.90507
Policy Entropy: 4.14628
Value Function Loss: 0.00350

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.02456
Policy Update Magnitude: 0.27185
Value Function Update Magnitude: 0.34422

Collected Steps per Second: 21,710.87043
Overall Steps per Second: 10,401.31498

Timestep Collection Time: 2.30299
Timestep Consumption Time: 2.50409
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.80708

Cumulative Model Updates: 323,742
Cumulative Timesteps: 2,700,001,672

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.92272
Policy Entropy: 4.15866
Value Function Loss: 0.00345

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.02098
Policy Update Magnitude: 0.27275
Value Function Update Magnitude: 0.36135

Collected Steps per Second: 22,372.27905
Overall Steps per Second: 10,754.94013

Timestep Collection Time: 2.23616
Timestep Consumption Time: 2.41547
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.65163

Cumulative Model Updates: 323,748
Cumulative Timesteps: 2,700,051,700

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2700051700...
Checkpoint 2700051700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.31166
Policy Entropy: 4.16630
Value Function Loss: 0.00365

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02138
Policy Update Magnitude: 0.28061
Value Function Update Magnitude: 0.35875

Collected Steps per Second: 21,701.49098
Overall Steps per Second: 10,333.17505

Timestep Collection Time: 2.30436
Timestep Consumption Time: 2.53520
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.83956

Cumulative Model Updates: 323,754
Cumulative Timesteps: 2,700,101,708

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.44500
Policy Entropy: 4.17475
Value Function Loss: 0.00340

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02110
Policy Update Magnitude: 0.26724
Value Function Update Magnitude: 0.35639

Collected Steps per Second: 22,434.74708
Overall Steps per Second: 10,526.16466

Timestep Collection Time: 2.22869
Timestep Consumption Time: 2.52138
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 4.75007

Cumulative Model Updates: 323,760
Cumulative Timesteps: 2,700,151,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2700151708...
Checkpoint 2700151708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.21270
Policy Entropy: 4.18716
Value Function Loss: 0.00326

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.01994
Policy Update Magnitude: 0.25966
Value Function Update Magnitude: 0.34435

Collected Steps per Second: 22,111.91120
Overall Steps per Second: 10,573.57546

Timestep Collection Time: 2.26213
Timestep Consumption Time: 2.46853
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.73066

Cumulative Model Updates: 323,766
Cumulative Timesteps: 2,700,201,728

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.87335
Policy Entropy: 4.18853
Value Function Loss: 0.00262

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02105
Policy Update Magnitude: 0.24311
Value Function Update Magnitude: 0.34211

Collected Steps per Second: 22,212.93846
Overall Steps per Second: 10,403.45864

Timestep Collection Time: 2.25220
Timestep Consumption Time: 2.55658
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.80879

Cumulative Model Updates: 323,772
Cumulative Timesteps: 2,700,251,756

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2700251756...
Checkpoint 2700251756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.82934
Policy Entropy: 4.19382
Value Function Loss: 0.00249

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.01882
Policy Update Magnitude: 0.24500
Value Function Update Magnitude: 0.31994

Collected Steps per Second: 21,564.33768
Overall Steps per Second: 10,336.23391

Timestep Collection Time: 2.31911
Timestep Consumption Time: 2.51921
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 4.83832

Cumulative Model Updates: 323,778
Cumulative Timesteps: 2,700,301,766

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.43917
Policy Entropy: 4.18232
Value Function Loss: 0.00329

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.01852
Policy Update Magnitude: 0.25625
Value Function Update Magnitude: 0.30781

Collected Steps per Second: 23,119.35829
Overall Steps per Second: 10,762.80162

Timestep Collection Time: 2.16286
Timestep Consumption Time: 2.48314
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.64600

Cumulative Model Updates: 323,784
Cumulative Timesteps: 2,700,351,770

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2700351770...
Checkpoint 2700351770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.58442
Policy Entropy: 4.15110
Value Function Loss: 0.00333

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.01941
Policy Update Magnitude: 0.27465
Value Function Update Magnitude: 0.33386

Collected Steps per Second: 21,549.56978
Overall Steps per Second: 10,254.10956

Timestep Collection Time: 2.32088
Timestep Consumption Time: 2.55658
PPO Batch Consumption Time: 0.29771
Total Iteration Time: 4.87746

Cumulative Model Updates: 323,790
Cumulative Timesteps: 2,700,401,784

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.01153
Policy Entropy: 4.16381
Value Function Loss: 0.00264

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02063
Policy Update Magnitude: 0.25108
Value Function Update Magnitude: 0.33285

Collected Steps per Second: 22,564.80752
Overall Steps per Second: 10,851.92538

Timestep Collection Time: 2.21699
Timestep Consumption Time: 2.39288
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.60987

Cumulative Model Updates: 323,796
Cumulative Timesteps: 2,700,451,810

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2700451810...
Checkpoint 2700451810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.54986
Policy Entropy: 4.19439
Value Function Loss: 0.00272

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02178
Policy Update Magnitude: 0.23404
Value Function Update Magnitude: 0.30955

Collected Steps per Second: 21,672.38859
Overall Steps per Second: 10,285.73714

Timestep Collection Time: 2.30727
Timestep Consumption Time: 2.55422
PPO Batch Consumption Time: 0.29874
Total Iteration Time: 4.86149

Cumulative Model Updates: 323,802
Cumulative Timesteps: 2,700,501,814

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.15492
Policy Entropy: 4.22624
Value Function Loss: 0.00274

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.01797
Policy Update Magnitude: 0.23334
Value Function Update Magnitude: 0.28395

Collected Steps per Second: 22,020.71752
Overall Steps per Second: 10,434.75403

Timestep Collection Time: 2.27195
Timestep Consumption Time: 2.52260
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.79455

Cumulative Model Updates: 323,808
Cumulative Timesteps: 2,700,551,844

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2700551844...
Checkpoint 2700551844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.44360
Policy Entropy: 4.18716
Value Function Loss: 0.00342

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02255
Policy Update Magnitude: 0.24877
Value Function Update Magnitude: 0.29930

Collected Steps per Second: 22,694.28665
Overall Steps per Second: 10,590.10593

Timestep Collection Time: 2.20417
Timestep Consumption Time: 2.51930
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.72347

Cumulative Model Updates: 323,814
Cumulative Timesteps: 2,700,601,866

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.74673
Policy Entropy: 4.16332
Value Function Loss: 0.00375

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.02258
Policy Update Magnitude: 0.24931
Value Function Update Magnitude: 0.32688

Collected Steps per Second: 22,413.25320
Overall Steps per Second: 10,536.86510

Timestep Collection Time: 2.23091
Timestep Consumption Time: 2.51452
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.74543

Cumulative Model Updates: 323,820
Cumulative Timesteps: 2,700,651,868

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2700651868...
Checkpoint 2700651868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.99435
Policy Entropy: 4.14194
Value Function Loss: 0.00359

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.02486
Policy Update Magnitude: 0.25542
Value Function Update Magnitude: 0.34228

Collected Steps per Second: 21,134.66433
Overall Steps per Second: 10,335.53914

Timestep Collection Time: 2.36578
Timestep Consumption Time: 2.47190
PPO Batch Consumption Time: 0.29647
Total Iteration Time: 4.83768

Cumulative Model Updates: 323,826
Cumulative Timesteps: 2,700,701,868

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.87451
Policy Entropy: 4.13970
Value Function Loss: 0.00369

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02206
Policy Update Magnitude: 0.26840
Value Function Update Magnitude: 0.34440

Collected Steps per Second: 19,952.66228
Overall Steps per Second: 9,481.08820

Timestep Collection Time: 2.50713
Timestep Consumption Time: 2.76905
PPO Batch Consumption Time: 0.33077
Total Iteration Time: 5.27619

Cumulative Model Updates: 323,832
Cumulative Timesteps: 2,700,751,892

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2700751892...
Checkpoint 2700751892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.58823
Policy Entropy: 4.15064
Value Function Loss: 0.00343

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.02411
Policy Update Magnitude: 0.26668
Value Function Update Magnitude: 0.35184

Collected Steps per Second: 21,420.53183
Overall Steps per Second: 10,235.73626

Timestep Collection Time: 2.33505
Timestep Consumption Time: 2.55156
PPO Batch Consumption Time: 0.29754
Total Iteration Time: 4.88660

Cumulative Model Updates: 323,838
Cumulative Timesteps: 2,700,801,910

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.78683
Policy Entropy: 4.15418
Value Function Loss: 0.00317

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02188
Policy Update Magnitude: 0.25703
Value Function Update Magnitude: 0.33673

Collected Steps per Second: 22,370.85949
Overall Steps per Second: 10,824.60701

Timestep Collection Time: 2.23639
Timestep Consumption Time: 2.38549
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.62188

Cumulative Model Updates: 323,844
Cumulative Timesteps: 2,700,851,940

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2700851940...
Checkpoint 2700851940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.22096
Policy Entropy: 4.17094
Value Function Loss: 0.00268

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.02185
Policy Update Magnitude: 0.25238
Value Function Update Magnitude: 0.31819

Collected Steps per Second: 21,756.16384
Overall Steps per Second: 10,358.50437

Timestep Collection Time: 2.29893
Timestep Consumption Time: 2.52956
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.82850

Cumulative Model Updates: 323,850
Cumulative Timesteps: 2,700,901,956

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.54761
Policy Entropy: 4.20022
Value Function Loss: 0.00218

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02063
Policy Update Magnitude: 0.23010
Value Function Update Magnitude: 0.29241

Collected Steps per Second: 22,488.60092
Overall Steps per Second: 10,783.11744

Timestep Collection Time: 2.22406
Timestep Consumption Time: 2.41430
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.63836

Cumulative Model Updates: 323,856
Cumulative Timesteps: 2,700,951,972

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2700951972...
Checkpoint 2700951972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.51750
Policy Entropy: 4.23912
Value Function Loss: 0.00145

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.01631
Policy Update Magnitude: 0.20124
Value Function Update Magnitude: 0.24894

Collected Steps per Second: 22,280.90183
Overall Steps per Second: 10,639.63411

Timestep Collection Time: 2.24416
Timestep Consumption Time: 2.45543
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.69960

Cumulative Model Updates: 323,862
Cumulative Timesteps: 2,701,001,974

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.24319
Policy Entropy: 4.23924
Value Function Loss: 0.00189

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01307
Policy Update Magnitude: 0.20439
Value Function Update Magnitude: 0.23888

Collected Steps per Second: 22,358.95767
Overall Steps per Second: 10,548.25754

Timestep Collection Time: 2.23660
Timestep Consumption Time: 2.50428
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.74088

Cumulative Model Updates: 323,868
Cumulative Timesteps: 2,701,051,982

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2701051982...
Checkpoint 2701051982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.10932
Policy Entropy: 4.19692
Value Function Loss: 0.00326

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.01715
Policy Update Magnitude: 0.23374
Value Function Update Magnitude: 0.26777

Collected Steps per Second: 21,899.84265
Overall Steps per Second: 10,648.01070

Timestep Collection Time: 2.28413
Timestep Consumption Time: 2.41365
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.69778

Cumulative Model Updates: 323,874
Cumulative Timesteps: 2,701,102,004

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.97473
Policy Entropy: 4.16874
Value Function Loss: 0.00413

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02450
Policy Update Magnitude: 0.26258
Value Function Update Magnitude: 0.29222

Collected Steps per Second: 22,095.21686
Overall Steps per Second: 10,424.40230

Timestep Collection Time: 2.26393
Timestep Consumption Time: 2.53462
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.79855

Cumulative Model Updates: 323,880
Cumulative Timesteps: 2,701,152,026

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2701152026...
Checkpoint 2701152026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.87049
Policy Entropy: 4.15504
Value Function Loss: 0.00407

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.02472
Policy Update Magnitude: 0.26923
Value Function Update Magnitude: 0.29455

Collected Steps per Second: 22,119.23925
Overall Steps per Second: 10,644.02319

Timestep Collection Time: 2.26156
Timestep Consumption Time: 2.43817
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.69973

Cumulative Model Updates: 323,886
Cumulative Timesteps: 2,701,202,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.02864
Policy Entropy: 4.20222
Value Function Loss: 0.00316

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02141
Policy Update Magnitude: 0.24824
Value Function Update Magnitude: 0.29762

Collected Steps per Second: 23,556.67004
Overall Steps per Second: 10,903.12885

Timestep Collection Time: 2.12331
Timestep Consumption Time: 2.46419
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.58749

Cumulative Model Updates: 323,892
Cumulative Timesteps: 2,701,252,068

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2701252068...
Checkpoint 2701252068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.57263
Policy Entropy: 4.18220
Value Function Loss: 0.00262

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.01902
Policy Update Magnitude: 0.23352
Value Function Update Magnitude: 0.29085

Collected Steps per Second: 21,828.38485
Overall Steps per Second: 10,415.92308

Timestep Collection Time: 2.29215
Timestep Consumption Time: 2.51145
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.80361

Cumulative Model Updates: 323,898
Cumulative Timesteps: 2,701,302,102

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.97451
Policy Entropy: 4.21481
Value Function Loss: 0.00231

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.01782
Policy Update Magnitude: 0.23048
Value Function Update Magnitude: 0.27869

Collected Steps per Second: 22,696.88403
Overall Steps per Second: 10,712.54285

Timestep Collection Time: 2.20312
Timestep Consumption Time: 2.46468
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.66780

Cumulative Model Updates: 323,904
Cumulative Timesteps: 2,701,352,106

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2701352106...
Checkpoint 2701352106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.36658
Policy Entropy: 4.17305
Value Function Loss: 0.00256

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02194
Policy Update Magnitude: 0.23599
Value Function Update Magnitude: 0.28333

Collected Steps per Second: 22,372.72238
Overall Steps per Second: 10,664.76032

Timestep Collection Time: 2.23594
Timestep Consumption Time: 2.45465
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.69059

Cumulative Model Updates: 323,910
Cumulative Timesteps: 2,701,402,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.86023
Policy Entropy: 4.22144
Value Function Loss: 0.00203

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.01856
Policy Update Magnitude: 0.22890
Value Function Update Magnitude: 0.27705

Collected Steps per Second: 22,309.17343
Overall Steps per Second: 10,578.73069

Timestep Collection Time: 2.24159
Timestep Consumption Time: 2.48563
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.72722

Cumulative Model Updates: 323,916
Cumulative Timesteps: 2,701,452,138

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2701452138...
Checkpoint 2701452138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.88594
Policy Entropy: 4.21480
Value Function Loss: 0.00190

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.01870
Policy Update Magnitude: 0.24548
Value Function Update Magnitude: 0.26778

Collected Steps per Second: 22,238.75533
Overall Steps per Second: 10,715.00604

Timestep Collection Time: 2.24842
Timestep Consumption Time: 2.41812
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.66654

Cumulative Model Updates: 323,922
Cumulative Timesteps: 2,701,502,140

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.61726
Policy Entropy: 4.22365
Value Function Loss: 0.00221

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.01460
Policy Update Magnitude: 0.23623
Value Function Update Magnitude: 0.24945

Collected Steps per Second: 22,758.73119
Overall Steps per Second: 10,684.72368

Timestep Collection Time: 2.19749
Timestep Consumption Time: 2.48322
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.68070

Cumulative Model Updates: 323,928
Cumulative Timesteps: 2,701,552,152

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2701552152...
Checkpoint 2701552152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.15719
Policy Entropy: 4.21504
Value Function Loss: 0.00249

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.01641
Policy Update Magnitude: 0.23045
Value Function Update Magnitude: 0.26192

Collected Steps per Second: 21,891.74590
Overall Steps per Second: 10,602.08892

Timestep Collection Time: 2.28451
Timestep Consumption Time: 2.43267
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.71718

Cumulative Model Updates: 323,934
Cumulative Timesteps: 2,701,602,164

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.33018
Policy Entropy: 4.20471
Value Function Loss: 0.00244

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.01740
Policy Update Magnitude: 0.21648
Value Function Update Magnitude: 0.28035

Collected Steps per Second: 23,397.21760
Overall Steps per Second: 10,895.00634

Timestep Collection Time: 2.13718
Timestep Consumption Time: 2.45245
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.58963

Cumulative Model Updates: 323,940
Cumulative Timesteps: 2,701,652,168

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2701652168...
Checkpoint 2701652168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.26394
Policy Entropy: 4.17654
Value Function Loss: 0.00354

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01670
Policy Update Magnitude: 0.23652
Value Function Update Magnitude: 0.30725

Collected Steps per Second: 21,789.59917
Overall Steps per Second: 10,444.77192

Timestep Collection Time: 2.29660
Timestep Consumption Time: 2.49450
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.79111

Cumulative Model Updates: 323,946
Cumulative Timesteps: 2,701,702,210

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.47293
Policy Entropy: 4.13389
Value Function Loss: 0.00389

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02089
Policy Update Magnitude: 0.26447
Value Function Update Magnitude: 0.34300

Collected Steps per Second: 22,085.35614
Overall Steps per Second: 10,648.01252

Timestep Collection Time: 2.26431
Timestep Consumption Time: 2.43216
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.69646

Cumulative Model Updates: 323,952
Cumulative Timesteps: 2,701,752,218

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2701752218...
Checkpoint 2701752218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.55636
Policy Entropy: 4.12878
Value Function Loss: 0.00348

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.02580
Policy Update Magnitude: 0.26361
Value Function Update Magnitude: 0.33319

Collected Steps per Second: 21,784.79339
Overall Steps per Second: 10,332.23517

Timestep Collection Time: 2.29536
Timestep Consumption Time: 2.54425
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.83961

Cumulative Model Updates: 323,958
Cumulative Timesteps: 2,701,802,222

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.05429
Policy Entropy: 4.16698
Value Function Loss: 0.00276

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02212
Policy Update Magnitude: 0.24400
Value Function Update Magnitude: 0.31550

Collected Steps per Second: 22,387.08430
Overall Steps per Second: 10,509.15616

Timestep Collection Time: 2.23406
Timestep Consumption Time: 2.52503
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.75909

Cumulative Model Updates: 323,964
Cumulative Timesteps: 2,701,852,236

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2701852236...
Checkpoint 2701852236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.19039
Policy Entropy: 4.18868
Value Function Loss: 0.00269

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02116
Policy Update Magnitude: 0.23467
Value Function Update Magnitude: 0.32266

Collected Steps per Second: 21,830.75559
Overall Steps per Second: 10,569.72103

Timestep Collection Time: 2.29071
Timestep Consumption Time: 2.44054
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.73125

Cumulative Model Updates: 323,970
Cumulative Timesteps: 2,701,902,244

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.11058
Policy Entropy: 4.17284
Value Function Loss: 0.00320

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.01949
Policy Update Magnitude: 0.24044
Value Function Update Magnitude: 0.33002

Collected Steps per Second: 22,369.68845
Overall Steps per Second: 10,486.89161

Timestep Collection Time: 2.23553
Timestep Consumption Time: 2.53309
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.76862

Cumulative Model Updates: 323,976
Cumulative Timesteps: 2,701,952,252

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2701952252...
Checkpoint 2701952252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.79330
Policy Entropy: 4.17279
Value Function Loss: 0.00314

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02034
Policy Update Magnitude: 0.24348
Value Function Update Magnitude: 0.34218

Collected Steps per Second: 21,988.27204
Overall Steps per Second: 10,542.06615

Timestep Collection Time: 2.27412
Timestep Consumption Time: 2.46916
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.74328

Cumulative Model Updates: 323,982
Cumulative Timesteps: 2,702,002,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.57528
Policy Entropy: 4.16709
Value Function Loss: 0.00319

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02237
Policy Update Magnitude: 0.24871
Value Function Update Magnitude: 0.35033

Collected Steps per Second: 21,882.85568
Overall Steps per Second: 10,508.50734

Timestep Collection Time: 2.28581
Timestep Consumption Time: 2.47415
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.75995

Cumulative Model Updates: 323,988
Cumulative Timesteps: 2,702,052,276

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2702052276...
Checkpoint 2702052276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.31491
Policy Entropy: 4.17607
Value Function Loss: 0.00311

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02287
Policy Update Magnitude: 0.24972
Value Function Update Magnitude: 0.33228

Collected Steps per Second: 22,210.63575
Overall Steps per Second: 10,594.19011

Timestep Collection Time: 2.25243
Timestep Consumption Time: 2.46978
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.72221

Cumulative Model Updates: 323,994
Cumulative Timesteps: 2,702,102,304

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.75984
Policy Entropy: 4.16894
Value Function Loss: 0.00302

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02108
Policy Update Magnitude: 0.24642
Value Function Update Magnitude: 0.31511

Collected Steps per Second: 21,835.39530
Overall Steps per Second: 10,493.02427

Timestep Collection Time: 2.29114
Timestep Consumption Time: 2.47660
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.76774

Cumulative Model Updates: 324,000
Cumulative Timesteps: 2,702,152,332

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2702152332...
Checkpoint 2702152332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.09480
Policy Entropy: 4.16707
Value Function Loss: 0.00340

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.02767
Policy Update Magnitude: 0.26012
Value Function Update Magnitude: 0.30348

Collected Steps per Second: 22,550.03627
Overall Steps per Second: 10,644.27198

Timestep Collection Time: 2.21765
Timestep Consumption Time: 2.48047
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.69811

Cumulative Model Updates: 324,006
Cumulative Timesteps: 2,702,202,340

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.92287
Policy Entropy: 4.16243
Value Function Loss: 0.00341

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.02668
Policy Update Magnitude: 0.25803
Value Function Update Magnitude: 0.30654

Collected Steps per Second: 22,821.04479
Overall Steps per Second: 10,588.81969

Timestep Collection Time: 2.19219
Timestep Consumption Time: 2.53242
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.72461

Cumulative Model Updates: 324,012
Cumulative Timesteps: 2,702,252,368

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2702252368...
Checkpoint 2702252368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.08840
Policy Entropy: 4.18003
Value Function Loss: 0.00329

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.02484
Policy Update Magnitude: 0.25572
Value Function Update Magnitude: 0.30116

Collected Steps per Second: 22,120.73072
Overall Steps per Second: 10,170.59657

Timestep Collection Time: 2.26059
Timestep Consumption Time: 2.65613
PPO Batch Consumption Time: 0.32790
Total Iteration Time: 4.91672

Cumulative Model Updates: 324,018
Cumulative Timesteps: 2,702,302,374

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.92962
Policy Entropy: 4.18325
Value Function Loss: 0.00334

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.02397
Policy Update Magnitude: 0.26172
Value Function Update Magnitude: 0.28423

Collected Steps per Second: 22,312.08178
Overall Steps per Second: 10,434.64517

Timestep Collection Time: 2.24175
Timestep Consumption Time: 2.55171
PPO Batch Consumption Time: 0.29729
Total Iteration Time: 4.79345

Cumulative Model Updates: 324,024
Cumulative Timesteps: 2,702,352,392

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2702352392...
Checkpoint 2702352392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.82177
Policy Entropy: 4.15283
Value Function Loss: 0.00414

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.01866
Policy Update Magnitude: 0.27388
Value Function Update Magnitude: 0.28563

Collected Steps per Second: 21,916.14000
Overall Steps per Second: 10,616.74667

Timestep Collection Time: 2.28215
Timestep Consumption Time: 2.42889
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.71105

Cumulative Model Updates: 324,030
Cumulative Timesteps: 2,702,402,408

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.82527
Policy Entropy: 4.13871
Value Function Loss: 0.00453

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.02266
Policy Update Magnitude: 0.29312
Value Function Update Magnitude: 0.30225

Collected Steps per Second: 22,446.40014
Overall Steps per Second: 10,836.29261

Timestep Collection Time: 2.22931
Timestep Consumption Time: 2.38850
PPO Batch Consumption Time: 0.28177
Total Iteration Time: 4.61782

Cumulative Model Updates: 324,036
Cumulative Timesteps: 2,702,452,448

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2702452448...
Checkpoint 2702452448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.10722
Policy Entropy: 4.11124
Value Function Loss: 0.00418

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.02699
Policy Update Magnitude: 0.28159
Value Function Update Magnitude: 0.30437

Collected Steps per Second: 22,147.37410
Overall Steps per Second: 10,619.95405

Timestep Collection Time: 2.25797
Timestep Consumption Time: 2.45091
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.70887

Cumulative Model Updates: 324,042
Cumulative Timesteps: 2,702,502,456

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.80497
Policy Entropy: 4.14969
Value Function Loss: 0.00335

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.02314
Policy Update Magnitude: 0.27675
Value Function Update Magnitude: 0.29393

Collected Steps per Second: 22,124.73150
Overall Steps per Second: 10,484.98034

Timestep Collection Time: 2.26073
Timestep Consumption Time: 2.50971
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.77044

Cumulative Model Updates: 324,048
Cumulative Timesteps: 2,702,552,474

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2702552474...
Checkpoint 2702552474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.34178
Policy Entropy: 4.11869
Value Function Loss: 0.00353

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.02615
Policy Update Magnitude: 0.26459
Value Function Update Magnitude: 0.30428

Collected Steps per Second: 21,476.13764
Overall Steps per Second: 10,582.04641

Timestep Collection Time: 2.32826
Timestep Consumption Time: 2.39691
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.72517

Cumulative Model Updates: 324,054
Cumulative Timesteps: 2,702,602,476

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.61538
Policy Entropy: 4.13004
Value Function Loss: 0.00319

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02330
Policy Update Magnitude: 0.26592
Value Function Update Magnitude: 0.32481

Collected Steps per Second: 22,252.30562
Overall Steps per Second: 10,552.01449

Timestep Collection Time: 2.24768
Timestep Consumption Time: 2.49227
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.73995

Cumulative Model Updates: 324,060
Cumulative Timesteps: 2,702,652,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2702652492...
Checkpoint 2702652492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.08934
Policy Entropy: 4.09542
Value Function Loss: 0.00343

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02505
Policy Update Magnitude: 0.27864
Value Function Update Magnitude: 0.32068

Collected Steps per Second: 22,087.31142
Overall Steps per Second: 10,669.52496

Timestep Collection Time: 2.26474
Timestep Consumption Time: 2.42357
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.68831

Cumulative Model Updates: 324,066
Cumulative Timesteps: 2,702,702,514

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.86027
Policy Entropy: 4.13327
Value Function Loss: 0.00285

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02226
Policy Update Magnitude: 0.26615
Value Function Update Magnitude: 0.31627

Collected Steps per Second: 23,375.08658
Overall Steps per Second: 10,890.46467

Timestep Collection Time: 2.13971
Timestep Consumption Time: 2.45293
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.59264

Cumulative Model Updates: 324,072
Cumulative Timesteps: 2,702,752,530

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2702752530...
Checkpoint 2702752530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.18051
Policy Entropy: 4.15761
Value Function Loss: 0.00280

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.01880
Policy Update Magnitude: 0.24748
Value Function Update Magnitude: 0.29998

Collected Steps per Second: 21,925.65300
Overall Steps per Second: 10,564.67361

Timestep Collection Time: 2.28153
Timestep Consumption Time: 2.45350
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.73503

Cumulative Model Updates: 324,078
Cumulative Timesteps: 2,702,802,554

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.50110
Policy Entropy: 4.19825
Value Function Loss: 0.00270

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.01785
Policy Update Magnitude: 0.25215
Value Function Update Magnitude: 0.27285

Collected Steps per Second: 21,870.26201
Overall Steps per Second: 10,542.22172

Timestep Collection Time: 2.28703
Timestep Consumption Time: 2.45751
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.74454

Cumulative Model Updates: 324,084
Cumulative Timesteps: 2,702,852,572

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2702852572...
Checkpoint 2702852572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.76162
Policy Entropy: 4.16922
Value Function Loss: 0.00325

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02066
Policy Update Magnitude: 0.25436
Value Function Update Magnitude: 0.28364

Collected Steps per Second: 22,194.86368
Overall Steps per Second: 10,668.65381

Timestep Collection Time: 2.25304
Timestep Consumption Time: 2.43415
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.68719

Cumulative Model Updates: 324,090
Cumulative Timesteps: 2,702,902,578

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.37377
Policy Entropy: 4.14706
Value Function Loss: 0.00376

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.02412
Policy Update Magnitude: 0.26466
Value Function Update Magnitude: 0.30796

Collected Steps per Second: 22,521.26985
Overall Steps per Second: 10,503.80609

Timestep Collection Time: 2.22048
Timestep Consumption Time: 2.54046
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.76094

Cumulative Model Updates: 324,096
Cumulative Timesteps: 2,702,952,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2702952586...
Checkpoint 2702952586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.64112
Policy Entropy: 4.14333
Value Function Loss: 0.00370

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.02554
Policy Update Magnitude: 0.26788
Value Function Update Magnitude: 0.32898

Collected Steps per Second: 21,862.46306
Overall Steps per Second: 10,537.20483

Timestep Collection Time: 2.28712
Timestep Consumption Time: 2.45816
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.74528

Cumulative Model Updates: 324,102
Cumulative Timesteps: 2,703,002,588

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.31975
Policy Entropy: 4.16579
Value Function Loss: 0.00351

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.02460
Policy Update Magnitude: 0.27143
Value Function Update Magnitude: 0.32847

Collected Steps per Second: 22,425.04532
Overall Steps per Second: 10,511.88270

Timestep Collection Time: 2.23027
Timestep Consumption Time: 2.52758
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.75785

Cumulative Model Updates: 324,108
Cumulative Timesteps: 2,703,052,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2703052602...
Checkpoint 2703052602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.76463
Policy Entropy: 4.20326
Value Function Loss: 0.00261

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02067
Policy Update Magnitude: 0.25746
Value Function Update Magnitude: 0.31468

Collected Steps per Second: 21,489.14748
Overall Steps per Second: 9,921.06586

Timestep Collection Time: 2.32759
Timestep Consumption Time: 2.71400
PPO Batch Consumption Time: 0.32236
Total Iteration Time: 5.04160

Cumulative Model Updates: 324,114
Cumulative Timesteps: 2,703,102,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.78554
Policy Entropy: 4.20173
Value Function Loss: 0.00278

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.01906
Policy Update Magnitude: 0.24030
Value Function Update Magnitude: 0.30100

Collected Steps per Second: 22,201.71160
Overall Steps per Second: 10,493.85408

Timestep Collection Time: 2.25325
Timestep Consumption Time: 2.51392
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.76717

Cumulative Model Updates: 324,120
Cumulative Timesteps: 2,703,152,646

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2703152646...
Checkpoint 2703152646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.04574
Policy Entropy: 4.18811
Value Function Loss: 0.00302

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.01830
Policy Update Magnitude: 0.25010
Value Function Update Magnitude: 0.29942

Collected Steps per Second: 22,415.95708
Overall Steps per Second: 10,482.65896

Timestep Collection Time: 2.23145
Timestep Consumption Time: 2.54024
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.77169

Cumulative Model Updates: 324,126
Cumulative Timesteps: 2,703,202,666

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.38542
Policy Entropy: 4.19218
Value Function Loss: 0.00316

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02323
Policy Update Magnitude: 0.25548
Value Function Update Magnitude: 0.32914

Collected Steps per Second: 21,385.69539
Overall Steps per Second: 10,346.29788

Timestep Collection Time: 2.33839
Timestep Consumption Time: 2.49503
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.83342

Cumulative Model Updates: 324,132
Cumulative Timesteps: 2,703,252,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2703252674...
Checkpoint 2703252674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.60604
Policy Entropy: 4.18541
Value Function Loss: 0.00370

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.01935
Policy Update Magnitude: 0.25475
Value Function Update Magnitude: 0.33864

Collected Steps per Second: 22,771.70237
Overall Steps per Second: 10,736.34948

Timestep Collection Time: 2.19632
Timestep Consumption Time: 2.46206
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.65838

Cumulative Model Updates: 324,138
Cumulative Timesteps: 2,703,302,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.69802
Policy Entropy: 4.20683
Value Function Loss: 0.00319

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01565
Policy Update Magnitude: 0.24686
Value Function Update Magnitude: 0.32405

Collected Steps per Second: 20,932.34460
Overall Steps per Second: 10,064.73986

Timestep Collection Time: 2.38874
Timestep Consumption Time: 2.57929
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.96804

Cumulative Model Updates: 324,144
Cumulative Timesteps: 2,703,352,690

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2703352690...
Checkpoint 2703352690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.88426
Policy Entropy: 4.20816
Value Function Loss: 0.00310

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.01598
Policy Update Magnitude: 0.23786
Value Function Update Magnitude: 0.30773

Collected Steps per Second: 21,549.16239
Overall Steps per Second: 10,491.97742

Timestep Collection Time: 2.32028
Timestep Consumption Time: 2.44527
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.76555

Cumulative Model Updates: 324,150
Cumulative Timesteps: 2,703,402,690

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.99990
Policy Entropy: 4.22187
Value Function Loss: 0.00255

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01631
Policy Update Magnitude: 0.23197
Value Function Update Magnitude: 0.29253

Collected Steps per Second: 21,411.73062
Overall Steps per Second: 10,251.52664

Timestep Collection Time: 2.33582
Timestep Consumption Time: 2.54287
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.87869

Cumulative Model Updates: 324,156
Cumulative Timesteps: 2,703,452,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2703452704...
Checkpoint 2703452704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.82199
Policy Entropy: 4.20937
Value Function Loss: 0.00280

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.01612
Policy Update Magnitude: 0.22704
Value Function Update Magnitude: 0.27776

Collected Steps per Second: 21,802.41427
Overall Steps per Second: 9,842.85453

Timestep Collection Time: 2.29442
Timestep Consumption Time: 2.78784
PPO Batch Consumption Time: 0.33084
Total Iteration Time: 5.08227

Cumulative Model Updates: 324,162
Cumulative Timesteps: 2,703,502,728

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.06591
Policy Entropy: 4.23331
Value Function Loss: 0.00234

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.01936
Policy Update Magnitude: 0.22206
Value Function Update Magnitude: 0.29036

Collected Steps per Second: 20,782.86126
Overall Steps per Second: 9,892.51802

Timestep Collection Time: 2.40756
Timestep Consumption Time: 2.65040
PPO Batch Consumption Time: 0.32326
Total Iteration Time: 5.05796

Cumulative Model Updates: 324,168
Cumulative Timesteps: 2,703,552,764

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2703552764...
Checkpoint 2703552764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.31553
Policy Entropy: 4.22063
Value Function Loss: 0.00319

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.01635
Policy Update Magnitude: 0.22940
Value Function Update Magnitude: 0.29798

Collected Steps per Second: 20,669.99438
Overall Steps per Second: 9,699.55341

Timestep Collection Time: 2.41906
Timestep Consumption Time: 2.73602
PPO Batch Consumption Time: 0.32236
Total Iteration Time: 5.15508

Cumulative Model Updates: 324,174
Cumulative Timesteps: 2,703,602,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.77995
Policy Entropy: 4.24775
Value Function Loss: 0.00300

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.01426
Policy Update Magnitude: 0.22505
Value Function Update Magnitude: 0.30131

Collected Steps per Second: 20,755.52932
Overall Steps per Second: 9,739.74572

Timestep Collection Time: 2.40977
Timestep Consumption Time: 2.72548
PPO Batch Consumption Time: 0.32712
Total Iteration Time: 5.13525

Cumulative Model Updates: 324,180
Cumulative Timesteps: 2,703,652,782

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2703652782...
Checkpoint 2703652782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.92679
Policy Entropy: 4.18699
Value Function Loss: 0.00406

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.01702
Policy Update Magnitude: 0.24702
Value Function Update Magnitude: 0.30076

Collected Steps per Second: 21,229.07626
Overall Steps per Second: 9,775.98524

Timestep Collection Time: 2.35639
Timestep Consumption Time: 2.76064
PPO Batch Consumption Time: 0.32958
Total Iteration Time: 5.11703

Cumulative Model Updates: 324,186
Cumulative Timesteps: 2,703,702,806

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.21161
Policy Entropy: 4.20225
Value Function Loss: 0.00315

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.01725
Policy Update Magnitude: 0.24997
Value Function Update Magnitude: 0.32377

Collected Steps per Second: 20,548.41816
Overall Steps per Second: 9,662.19219

Timestep Collection Time: 2.43445
Timestep Consumption Time: 2.74285
PPO Batch Consumption Time: 0.32477
Total Iteration Time: 5.17729

Cumulative Model Updates: 324,192
Cumulative Timesteps: 2,703,752,830

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2703752830...
Checkpoint 2703752830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.03637
Policy Entropy: 4.20907
Value Function Loss: 0.00228

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.01892
Policy Update Magnitude: 0.23656
Value Function Update Magnitude: 0.30024

Collected Steps per Second: 20,619.06249
Overall Steps per Second: 9,802.11476

Timestep Collection Time: 2.42552
Timestep Consumption Time: 2.67664
PPO Batch Consumption Time: 0.32468
Total Iteration Time: 5.10216

Cumulative Model Updates: 324,198
Cumulative Timesteps: 2,703,802,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.43243
Policy Entropy: 4.22674
Value Function Loss: 0.00243

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01598
Policy Update Magnitude: 0.24991
Value Function Update Magnitude: 0.27118

Collected Steps per Second: 20,815.86927
Overall Steps per Second: 9,581.15464

Timestep Collection Time: 2.40422
Timestep Consumption Time: 2.81916
PPO Batch Consumption Time: 0.34130
Total Iteration Time: 5.22338

Cumulative Model Updates: 324,204
Cumulative Timesteps: 2,703,852,888

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2703852888...
Checkpoint 2703852888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.97102
Policy Entropy: 4.21805
Value Function Loss: 0.00289

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.01644
Policy Update Magnitude: 0.25508
Value Function Update Magnitude: 0.28436

Collected Steps per Second: 20,393.10211
Overall Steps per Second: 9,680.32471

Timestep Collection Time: 2.45191
Timestep Consumption Time: 2.71342
PPO Batch Consumption Time: 0.32932
Total Iteration Time: 5.16532

Cumulative Model Updates: 324,210
Cumulative Timesteps: 2,703,902,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.95651
Policy Entropy: 4.18176
Value Function Loss: 0.00418

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.01985
Policy Update Magnitude: 0.25224
Value Function Update Magnitude: 0.31494

Collected Steps per Second: 21,520.55068
Overall Steps per Second: 9,857.88502

Timestep Collection Time: 2.32438
Timestep Consumption Time: 2.74993
PPO Batch Consumption Time: 0.32636
Total Iteration Time: 5.07431

Cumulative Model Updates: 324,216
Cumulative Timesteps: 2,703,952,912

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2703952912...
Checkpoint 2703952912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.98357
Policy Entropy: 4.17636
Value Function Loss: 0.00420

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02052
Policy Update Magnitude: 0.26165
Value Function Update Magnitude: 0.32222

Collected Steps per Second: 20,370.90841
Overall Steps per Second: 9,626.09682

Timestep Collection Time: 2.45507
Timestep Consumption Time: 2.74039
PPO Batch Consumption Time: 0.32512
Total Iteration Time: 5.19546

Cumulative Model Updates: 324,222
Cumulative Timesteps: 2,704,002,924

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.82324
Policy Entropy: 4.14730
Value Function Loss: 0.00434

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02301
Policy Update Magnitude: 0.27456
Value Function Update Magnitude: 0.33023

Collected Steps per Second: 20,806.07653
Overall Steps per Second: 9,837.63031

Timestep Collection Time: 2.40353
Timestep Consumption Time: 2.67981
PPO Batch Consumption Time: 0.32674
Total Iteration Time: 5.08334

Cumulative Model Updates: 324,228
Cumulative Timesteps: 2,704,052,932

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2704052932...
Checkpoint 2704052932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.09280
Policy Entropy: 4.15597
Value Function Loss: 0.00381

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02307
Policy Update Magnitude: 0.26548
Value Function Update Magnitude: 0.34403

Collected Steps per Second: 20,203.65047
Overall Steps per Second: 9,630.96733

Timestep Collection Time: 2.47589
Timestep Consumption Time: 2.71798
PPO Batch Consumption Time: 0.32540
Total Iteration Time: 5.19387

Cumulative Model Updates: 324,234
Cumulative Timesteps: 2,704,102,954

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.81715
Policy Entropy: 4.17643
Value Function Loss: 0.00336

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02060
Policy Update Magnitude: 0.25118
Value Function Update Magnitude: 0.34257

Collected Steps per Second: 20,774.32151
Overall Steps per Second: 9,770.95185

Timestep Collection Time: 2.40778
Timestep Consumption Time: 2.71148
PPO Batch Consumption Time: 0.32577
Total Iteration Time: 5.11926

Cumulative Model Updates: 324,240
Cumulative Timesteps: 2,704,152,974

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2704152974...
Checkpoint 2704152974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.70927
Policy Entropy: 4.18851
Value Function Loss: 0.00321

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.01853
Policy Update Magnitude: 0.25314
Value Function Update Magnitude: 0.33323

Collected Steps per Second: 20,424.93650
Overall Steps per Second: 9,783.38834

Timestep Collection Time: 2.44936
Timestep Consumption Time: 2.66421
PPO Batch Consumption Time: 0.32701
Total Iteration Time: 5.11357

Cumulative Model Updates: 324,246
Cumulative Timesteps: 2,704,203,002

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.20386
Policy Entropy: 4.18023
Value Function Loss: 0.00248

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.01969
Policy Update Magnitude: 0.25033
Value Function Update Magnitude: 0.31830

Collected Steps per Second: 20,996.64083
Overall Steps per Second: 9,728.66841

Timestep Collection Time: 2.38133
Timestep Consumption Time: 2.75812
PPO Batch Consumption Time: 0.32821
Total Iteration Time: 5.13945

Cumulative Model Updates: 324,252
Cumulative Timesteps: 2,704,253,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2704253002...
Checkpoint 2704253002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.34707
Policy Entropy: 4.15350
Value Function Loss: 0.00278

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.01995
Policy Update Magnitude: 0.24347
Value Function Update Magnitude: 0.30251

Collected Steps per Second: 20,035.97808
Overall Steps per Second: 9,582.38334

Timestep Collection Time: 2.49641
Timestep Consumption Time: 2.72338
PPO Batch Consumption Time: 0.33136
Total Iteration Time: 5.21979

Cumulative Model Updates: 324,258
Cumulative Timesteps: 2,704,303,020

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.68614
Policy Entropy: 4.18383
Value Function Loss: 0.00212

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.01761
Policy Update Magnitude: 0.23773
Value Function Update Magnitude: 0.29346

Collected Steps per Second: 21,362.08738
Overall Steps per Second: 9,775.88077

Timestep Collection Time: 2.34163
Timestep Consumption Time: 2.77525
PPO Batch Consumption Time: 0.32572
Total Iteration Time: 5.11688

Cumulative Model Updates: 324,264
Cumulative Timesteps: 2,704,353,042

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2704353042...
Checkpoint 2704353042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.84857
Policy Entropy: 4.20819
Value Function Loss: 0.00229

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.01657
Policy Update Magnitude: 0.22310
Value Function Update Magnitude: 0.27798

Collected Steps per Second: 20,623.71499
Overall Steps per Second: 9,670.47311

Timestep Collection Time: 2.42468
Timestep Consumption Time: 2.74631
PPO Batch Consumption Time: 0.32860
Total Iteration Time: 5.17100

Cumulative Model Updates: 324,270
Cumulative Timesteps: 2,704,403,048

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.72472
Policy Entropy: 4.24002
Value Function Loss: 0.00246

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01503
Policy Update Magnitude: 0.22506
Value Function Update Magnitude: 0.26380

Collected Steps per Second: 20,577.34003
Overall Steps per Second: 9,724.46292

Timestep Collection Time: 2.42995
Timestep Consumption Time: 2.71192
PPO Batch Consumption Time: 0.32670
Total Iteration Time: 5.14188

Cumulative Model Updates: 324,276
Cumulative Timesteps: 2,704,453,050

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2704453050...
Checkpoint 2704453050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.38404
Policy Entropy: 4.21102
Value Function Loss: 0.00260

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.01853
Policy Update Magnitude: 0.22374
Value Function Update Magnitude: 0.28106

Collected Steps per Second: 21,475.38100
Overall Steps per Second: 9,909.71167

Timestep Collection Time: 2.32918
Timestep Consumption Time: 2.71839
PPO Batch Consumption Time: 0.32402
Total Iteration Time: 5.04757

Cumulative Model Updates: 324,282
Cumulative Timesteps: 2,704,503,070

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.74070
Policy Entropy: 4.20836
Value Function Loss: 0.00261

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.01950
Policy Update Magnitude: 0.23640
Value Function Update Magnitude: 0.29227

Collected Steps per Second: 20,792.47620
Overall Steps per Second: 9,704.13524

Timestep Collection Time: 2.40549
Timestep Consumption Time: 2.74861
PPO Batch Consumption Time: 0.32611
Total Iteration Time: 5.15409

Cumulative Model Updates: 324,288
Cumulative Timesteps: 2,704,553,086

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2704553086...
Checkpoint 2704553086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.28907
Policy Entropy: 4.21436
Value Function Loss: 0.00260

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.01892
Policy Update Magnitude: 0.22793
Value Function Update Magnitude: 0.28705

Collected Steps per Second: 20,718.67586
Overall Steps per Second: 9,831.39581

Timestep Collection Time: 2.41347
Timestep Consumption Time: 2.67268
PPO Batch Consumption Time: 0.32842
Total Iteration Time: 5.08615

Cumulative Model Updates: 324,294
Cumulative Timesteps: 2,704,603,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.12795
Policy Entropy: 4.21357
Value Function Loss: 0.00270

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.01759
Policy Update Magnitude: 0.22340
Value Function Update Magnitude: 0.28521

Collected Steps per Second: 20,621.41047
Overall Steps per Second: 9,655.55987

Timestep Collection Time: 2.42544
Timestep Consumption Time: 2.75458
PPO Batch Consumption Time: 0.32833
Total Iteration Time: 5.18002

Cumulative Model Updates: 324,300
Cumulative Timesteps: 2,704,653,106

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2704653106...
Checkpoint 2704653106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.95170
Policy Entropy: 4.21243
Value Function Loss: 0.00255

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.01709
Policy Update Magnitude: 0.22599
Value Function Update Magnitude: 0.28693

Collected Steps per Second: 20,570.35744
Overall Steps per Second: 9,712.46404

Timestep Collection Time: 2.43204
Timestep Consumption Time: 2.71886
PPO Batch Consumption Time: 0.32336
Total Iteration Time: 5.15091

Cumulative Model Updates: 324,306
Cumulative Timesteps: 2,704,703,134

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.04114
Policy Entropy: 4.21045
Value Function Loss: 0.00265

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.01875
Policy Update Magnitude: 0.23354
Value Function Update Magnitude: 0.28843

Collected Steps per Second: 21,333.50537
Overall Steps per Second: 9,755.28611

Timestep Collection Time: 2.34373
Timestep Consumption Time: 2.78170
PPO Batch Consumption Time: 0.33378
Total Iteration Time: 5.12543

Cumulative Model Updates: 324,312
Cumulative Timesteps: 2,704,753,134

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2704753134...
Checkpoint 2704753134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08628
Policy Entropy: 4.24393
Value Function Loss: 0.00275

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01503
Policy Update Magnitude: 0.23596
Value Function Update Magnitude: 0.29187

Collected Steps per Second: 20,670.78829
Overall Steps per Second: 9,680.36183

Timestep Collection Time: 2.41916
Timestep Consumption Time: 2.74655
PPO Batch Consumption Time: 0.32559
Total Iteration Time: 5.16572

Cumulative Model Updates: 324,318
Cumulative Timesteps: 2,704,803,140

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.23661
Policy Entropy: 4.23542
Value Function Loss: 0.00333

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.01501
Policy Update Magnitude: 0.24328
Value Function Update Magnitude: 0.30139

Collected Steps per Second: 20,734.41010
Overall Steps per Second: 9,758.36028

Timestep Collection Time: 2.41174
Timestep Consumption Time: 2.71269
PPO Batch Consumption Time: 0.34258
Total Iteration Time: 5.12443

Cumulative Model Updates: 324,324
Cumulative Timesteps: 2,704,853,146

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2704853146...
Checkpoint 2704853146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.68523
Policy Entropy: 4.23261
Value Function Loss: 0.00295

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.01635
Policy Update Magnitude: 0.23499
Value Function Update Magnitude: 0.30256

Collected Steps per Second: 20,673.16423
Overall Steps per Second: 9,695.65563

Timestep Collection Time: 2.41917
Timestep Consumption Time: 2.73901
PPO Batch Consumption Time: 0.32620
Total Iteration Time: 5.15819

Cumulative Model Updates: 324,330
Cumulative Timesteps: 2,704,903,158

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.40535
Policy Entropy: 4.23884
Value Function Loss: 0.00255

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.01642
Policy Update Magnitude: 0.22403
Value Function Update Magnitude: 0.29263

Collected Steps per Second: 20,788.35247
Overall Steps per Second: 9,725.65011

Timestep Collection Time: 2.40635
Timestep Consumption Time: 2.73716
PPO Batch Consumption Time: 0.32909
Total Iteration Time: 5.14351

Cumulative Model Updates: 324,336
Cumulative Timesteps: 2,704,953,182

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2704953182...
Checkpoint 2704953182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.19873
Policy Entropy: 4.20863
Value Function Loss: 0.00265

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01480
Policy Update Magnitude: 0.25336
Value Function Update Magnitude: 0.28946

Collected Steps per Second: 20,510.21759
Overall Steps per Second: 9,828.28381

Timestep Collection Time: 2.43908
Timestep Consumption Time: 2.65093
PPO Batch Consumption Time: 0.32497
Total Iteration Time: 5.09000

Cumulative Model Updates: 324,342
Cumulative Timesteps: 2,705,003,208

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.43985
Policy Entropy: 4.17255
Value Function Loss: 0.00372

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.01871
Policy Update Magnitude: 0.27159
Value Function Update Magnitude: 0.32008

Collected Steps per Second: 20,773.20741
Overall Steps per Second: 9,681.75850

Timestep Collection Time: 2.40762
Timestep Consumption Time: 2.75818
PPO Batch Consumption Time: 0.32851
Total Iteration Time: 5.16580

Cumulative Model Updates: 324,348
Cumulative Timesteps: 2,705,053,222

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2705053222...
Checkpoint 2705053222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.10055
Policy Entropy: 4.14053
Value Function Loss: 0.00336

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.02286
Policy Update Magnitude: 0.27386
Value Function Update Magnitude: 0.34772

Collected Steps per Second: 20,248.20165
Overall Steps per Second: 9,659.77462

Timestep Collection Time: 2.46936
Timestep Consumption Time: 2.70675
PPO Batch Consumption Time: 0.32638
Total Iteration Time: 5.17610

Cumulative Model Updates: 324,354
Cumulative Timesteps: 2,705,103,222

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.12038
Policy Entropy: 4.18178
Value Function Loss: 0.00296

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.01946
Policy Update Magnitude: 0.25779
Value Function Update Magnitude: 0.33761

Collected Steps per Second: 21,638.93822
Overall Steps per Second: 9,774.17616

Timestep Collection Time: 2.31130
Timestep Consumption Time: 2.80566
PPO Batch Consumption Time: 0.33972
Total Iteration Time: 5.11695

Cumulative Model Updates: 324,360
Cumulative Timesteps: 2,705,153,236

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2705153236...
Checkpoint 2705153236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.80020
Policy Entropy: 4.21871
Value Function Loss: 0.00216

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01595
Policy Update Magnitude: 0.24087
Value Function Update Magnitude: 0.30978

Collected Steps per Second: 20,543.19799
Overall Steps per Second: 9,692.17063

Timestep Collection Time: 2.43575
Timestep Consumption Time: 2.72698
PPO Batch Consumption Time: 0.32547
Total Iteration Time: 5.16272

Cumulative Model Updates: 324,366
Cumulative Timesteps: 2,705,203,274

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.32228
Policy Entropy: 4.23536
Value Function Loss: 0.00225

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.01480
Policy Update Magnitude: 0.24771
Value Function Update Magnitude: 0.29543

Collected Steps per Second: 20,725.71316
Overall Steps per Second: 9,744.58695

Timestep Collection Time: 2.41381
Timestep Consumption Time: 2.72011
PPO Batch Consumption Time: 0.32448
Total Iteration Time: 5.13393

Cumulative Model Updates: 324,372
Cumulative Timesteps: 2,705,253,302

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2705253302...
Checkpoint 2705253302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.71293
Policy Entropy: 4.21265
Value Function Loss: 0.00317

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.01618
Policy Update Magnitude: 0.26729
Value Function Update Magnitude: 0.32765

Collected Steps per Second: 21,223.72471
Overall Steps per Second: 9,808.69304

Timestep Collection Time: 2.35736
Timestep Consumption Time: 2.74342
PPO Batch Consumption Time: 0.32746
Total Iteration Time: 5.10078

Cumulative Model Updates: 324,378
Cumulative Timesteps: 2,705,303,334

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.76014
Policy Entropy: 4.18842
Value Function Loss: 0.00386

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.01988
Policy Update Magnitude: 0.29109
Value Function Update Magnitude: 0.35973

Collected Steps per Second: 20,846.23253
Overall Steps per Second: 9,647.26675

Timestep Collection Time: 2.39986
Timestep Consumption Time: 2.78586
PPO Batch Consumption Time: 0.33099
Total Iteration Time: 5.18572

Cumulative Model Updates: 324,384
Cumulative Timesteps: 2,705,353,362

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2705353362...
Checkpoint 2705353362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.36062
Policy Entropy: 4.17936
Value Function Loss: 0.00399

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.02431
Policy Update Magnitude: 0.28532
Value Function Update Magnitude: 0.36339

Collected Steps per Second: 20,424.22824
Overall Steps per Second: 9,778.84857

Timestep Collection Time: 2.44886
Timestep Consumption Time: 2.66586
PPO Batch Consumption Time: 0.32748
Total Iteration Time: 5.11471

Cumulative Model Updates: 324,390
Cumulative Timesteps: 2,705,403,378

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.83552
Policy Entropy: 4.18498
Value Function Loss: 0.00450

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02245
Policy Update Magnitude: 0.27686
Value Function Update Magnitude: 0.34473

Collected Steps per Second: 20,800.57937
Overall Steps per Second: 9,691.23407

Timestep Collection Time: 2.40397
Timestep Consumption Time: 2.75574
PPO Batch Consumption Time: 0.32779
Total Iteration Time: 5.15971

Cumulative Model Updates: 324,396
Cumulative Timesteps: 2,705,453,382

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2705453382...
Checkpoint 2705453382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.77446
Policy Entropy: 4.19321
Value Function Loss: 0.00368

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02186
Policy Update Magnitude: 0.27106
Value Function Update Magnitude: 0.33297

Collected Steps per Second: 20,576.01315
Overall Steps per Second: 9,742.03954

Timestep Collection Time: 2.43021
Timestep Consumption Time: 2.70260
PPO Batch Consumption Time: 0.32562
Total Iteration Time: 5.13281

Cumulative Model Updates: 324,402
Cumulative Timesteps: 2,705,503,386

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.42860
Policy Entropy: 4.19504
Value Function Loss: 0.00344

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02115
Policy Update Magnitude: 0.25026
Value Function Update Magnitude: 0.32345

Collected Steps per Second: 21,471.02673
Overall Steps per Second: 9,777.83543

Timestep Collection Time: 2.32974
Timestep Consumption Time: 2.78611
PPO Batch Consumption Time: 0.33221
Total Iteration Time: 5.11586

Cumulative Model Updates: 324,408
Cumulative Timesteps: 2,705,553,408

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2705553408...
Checkpoint 2705553408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.96054
Policy Entropy: 4.18728
Value Function Loss: 0.00355

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.01868
Policy Update Magnitude: 0.26108
Value Function Update Magnitude: 0.30548

Collected Steps per Second: 20,679.00249
Overall Steps per Second: 9,639.32759

Timestep Collection Time: 2.41791
Timestep Consumption Time: 2.76917
PPO Batch Consumption Time: 0.32881
Total Iteration Time: 5.18708

Cumulative Model Updates: 324,414
Cumulative Timesteps: 2,705,603,408

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.15609
Policy Entropy: 4.18620
Value Function Loss: 0.00320

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02109
Policy Update Magnitude: 0.25552
Value Function Update Magnitude: 0.30495

Collected Steps per Second: 20,500.80563
Overall Steps per Second: 9,666.60834

Timestep Collection Time: 2.43903
Timestep Consumption Time: 2.73363
PPO Batch Consumption Time: 0.32721
Total Iteration Time: 5.17265

Cumulative Model Updates: 324,420
Cumulative Timesteps: 2,705,653,410

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2705653410...
Checkpoint 2705653410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.24589
Policy Entropy: 4.18726
Value Function Loss: 0.00274

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.01975
Policy Update Magnitude: 0.24114
Value Function Update Magnitude: 0.29897

Collected Steps per Second: 21,480.22679
Overall Steps per Second: 9,832.68200

Timestep Collection Time: 2.32809
Timestep Consumption Time: 2.75780
PPO Batch Consumption Time: 0.32658
Total Iteration Time: 5.08590

Cumulative Model Updates: 324,426
Cumulative Timesteps: 2,705,703,418

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.84921
Policy Entropy: 4.21137
Value Function Loss: 0.00250

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.01849
Policy Update Magnitude: 0.23736
Value Function Update Magnitude: 0.27550

Collected Steps per Second: 20,727.96414
Overall Steps per Second: 9,607.70898

Timestep Collection Time: 2.41249
Timestep Consumption Time: 2.79229
PPO Batch Consumption Time: 0.33138
Total Iteration Time: 5.20478

Cumulative Model Updates: 324,432
Cumulative Timesteps: 2,705,753,424

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2705753424...
Checkpoint 2705753424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.54030
Policy Entropy: 4.22028
Value Function Loss: 0.00250

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.01742
Policy Update Magnitude: 0.24015
Value Function Update Magnitude: 0.27753

Collected Steps per Second: 20,791.55697
Overall Steps per Second: 9,869.00856

Timestep Collection Time: 2.40492
Timestep Consumption Time: 2.66165
PPO Batch Consumption Time: 0.32700
Total Iteration Time: 5.06657

Cumulative Model Updates: 324,438
Cumulative Timesteps: 2,705,803,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.46878
Policy Entropy: 4.23650
Value Function Loss: 0.00294

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.01827
Policy Update Magnitude: 0.23753
Value Function Update Magnitude: 0.30643

Collected Steps per Second: 20,664.28139
Overall Steps per Second: 9,681.37464

Timestep Collection Time: 2.42099
Timestep Consumption Time: 2.74646
PPO Batch Consumption Time: 0.32802
Total Iteration Time: 5.16745

Cumulative Model Updates: 324,444
Cumulative Timesteps: 2,705,853,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2705853454...
Checkpoint 2705853454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.82768
Policy Entropy: 4.25524
Value Function Loss: 0.00262

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.01935
Policy Update Magnitude: 0.23847
Value Function Update Magnitude: 0.31403

Collected Steps per Second: 20,574.53418
Overall Steps per Second: 9,728.57990

Timestep Collection Time: 2.43048
Timestep Consumption Time: 2.70963
PPO Batch Consumption Time: 0.32515
Total Iteration Time: 5.14011

Cumulative Model Updates: 324,450
Cumulative Timesteps: 2,705,903,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.24632
Policy Entropy: 4.24224
Value Function Loss: 0.00289

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.01601
Policy Update Magnitude: 0.24407
Value Function Update Magnitude: 0.28930

Collected Steps per Second: 21,003.71067
Overall Steps per Second: 9,870.48189

Timestep Collection Time: 2.38167
Timestep Consumption Time: 2.68637
PPO Batch Consumption Time: 0.33348
Total Iteration Time: 5.06804

Cumulative Model Updates: 324,456
Cumulative Timesteps: 2,705,953,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2705953484...
Checkpoint 2705953484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.42659
Policy Entropy: 4.21833
Value Function Loss: 0.00321

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.01908
Policy Update Magnitude: 0.25037
Value Function Update Magnitude: 0.29193

Collected Steps per Second: 20,674.98609
Overall Steps per Second: 9,682.15840

Timestep Collection Time: 2.41945
Timestep Consumption Time: 2.74696
PPO Batch Consumption Time: 0.32642
Total Iteration Time: 5.16641

Cumulative Model Updates: 324,462
Cumulative Timesteps: 2,706,003,506

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.41213
Policy Entropy: 4.20436
Value Function Loss: 0.00325

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02140
Policy Update Magnitude: 0.25030
Value Function Update Magnitude: 0.31302

Collected Steps per Second: 20,670.12292
Overall Steps per Second: 9,718.68129

Timestep Collection Time: 2.42079
Timestep Consumption Time: 2.72785
PPO Batch Consumption Time: 0.32785
Total Iteration Time: 5.14864

Cumulative Model Updates: 324,468
Cumulative Timesteps: 2,706,053,544

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2706053544...
Checkpoint 2706053544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.73675
Policy Entropy: 4.20954
Value Function Loss: 0.00341

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.01807
Policy Update Magnitude: 0.24551
Value Function Update Magnitude: 0.31587

Collected Steps per Second: 21,037.40321
Overall Steps per Second: 9,751.52526

Timestep Collection Time: 2.37700
Timestep Consumption Time: 2.75101
PPO Batch Consumption Time: 0.32904
Total Iteration Time: 5.12802

Cumulative Model Updates: 324,474
Cumulative Timesteps: 2,706,103,550

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.29840
Policy Entropy: 4.22400
Value Function Loss: 0.00325

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.01773
Policy Update Magnitude: 0.23567
Value Function Update Magnitude: 0.30860

Collected Steps per Second: 20,828.64164
Overall Steps per Second: 9,632.62785

Timestep Collection Time: 2.40140
Timestep Consumption Time: 2.79116
PPO Batch Consumption Time: 0.33208
Total Iteration Time: 5.19256

Cumulative Model Updates: 324,480
Cumulative Timesteps: 2,706,153,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2706153568...
Checkpoint 2706153568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.12813
Policy Entropy: 4.22121
Value Function Loss: 0.00292

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02036
Policy Update Magnitude: 0.23017
Value Function Update Magnitude: 0.29803

Collected Steps per Second: 19,851.48740
Overall Steps per Second: 9,640.35682

Timestep Collection Time: 2.51901
Timestep Consumption Time: 2.66815
PPO Batch Consumption Time: 0.32859
Total Iteration Time: 5.18715

Cumulative Model Updates: 324,486
Cumulative Timesteps: 2,706,203,574

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.72380
Policy Entropy: 4.22475
Value Function Loss: 0.00255

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.01568
Policy Update Magnitude: 0.22115
Value Function Update Magnitude: 0.27164

Collected Steps per Second: 20,667.54432
Overall Steps per Second: 9,718.77330

Timestep Collection Time: 2.41925
Timestep Consumption Time: 2.72543
PPO Batch Consumption Time: 0.32699
Total Iteration Time: 5.14468

Cumulative Model Updates: 324,492
Cumulative Timesteps: 2,706,253,574

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2706253574...
Checkpoint 2706253574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.82765
Policy Entropy: 4.21330
Value Function Loss: 0.00221

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.01518
Policy Update Magnitude: 0.22107
Value Function Update Magnitude: 0.26324

Collected Steps per Second: 20,678.72142
Overall Steps per Second: 9,796.59545

Timestep Collection Time: 2.41814
Timestep Consumption Time: 2.68608
PPO Batch Consumption Time: 0.32546
Total Iteration Time: 5.10422

Cumulative Model Updates: 324,498
Cumulative Timesteps: 2,706,303,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.44069
Policy Entropy: 4.22556
Value Function Loss: 0.00209

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.01638
Policy Update Magnitude: 0.21860
Value Function Update Magnitude: 0.26402

Collected Steps per Second: 21,605.03842
Overall Steps per Second: 9,746.17895

Timestep Collection Time: 2.31455
Timestep Consumption Time: 2.81628
PPO Batch Consumption Time: 0.33943
Total Iteration Time: 5.13083

Cumulative Model Updates: 324,504
Cumulative Timesteps: 2,706,353,584

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2706353584...
Checkpoint 2706353584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.97155
Policy Entropy: 4.25173
Value Function Loss: 0.00248

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.01496
Policy Update Magnitude: 0.22200
Value Function Update Magnitude: 0.25327

Collected Steps per Second: 20,477.14842
Overall Steps per Second: 9,586.61751

Timestep Collection Time: 2.44282
Timestep Consumption Time: 2.77508
PPO Batch Consumption Time: 0.33510
Total Iteration Time: 5.21790

Cumulative Model Updates: 324,510
Cumulative Timesteps: 2,706,403,606

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.92200
Policy Entropy: 4.22615
Value Function Loss: 0.00294

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.01549
Policy Update Magnitude: 0.22148
Value Function Update Magnitude: 0.24141

Collected Steps per Second: 20,515.16871
Overall Steps per Second: 9,806.28527

Timestep Collection Time: 2.43722
Timestep Consumption Time: 2.66155
PPO Batch Consumption Time: 0.32668
Total Iteration Time: 5.09877

Cumulative Model Updates: 324,516
Cumulative Timesteps: 2,706,453,606

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2706453606...
Checkpoint 2706453606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.45428
Policy Entropy: 4.19036
Value Function Loss: 0.00330

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.01587
Policy Update Magnitude: 0.23539
Value Function Update Magnitude: 0.24866

Collected Steps per Second: 20,510.55119
Overall Steps per Second: 9,618.85688

Timestep Collection Time: 2.43787
Timestep Consumption Time: 2.76046
PPO Batch Consumption Time: 0.33311
Total Iteration Time: 5.19833

Cumulative Model Updates: 324,522
Cumulative Timesteps: 2,706,503,608

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.91762
Policy Entropy: 4.16798
Value Function Loss: 0.00340

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02002
Policy Update Magnitude: 0.24689
Value Function Update Magnitude: 0.28494

Collected Steps per Second: 20,670.01332
Overall Steps per Second: 9,728.88538

Timestep Collection Time: 2.41925
Timestep Consumption Time: 2.72070
PPO Batch Consumption Time: 0.32857
Total Iteration Time: 5.13995

Cumulative Model Updates: 324,528
Cumulative Timesteps: 2,706,553,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2706553614...
Checkpoint 2706553614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.99665
Policy Entropy: 4.19542
Value Function Loss: 0.00272

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.01846
Policy Update Magnitude: 0.24176
Value Function Update Magnitude: 0.30497

Collected Steps per Second: 21,309.21749
Overall Steps per Second: 9,835.58452

Timestep Collection Time: 2.34650
Timestep Consumption Time: 2.73729
PPO Batch Consumption Time: 0.32932
Total Iteration Time: 5.08379

Cumulative Model Updates: 324,534
Cumulative Timesteps: 2,706,603,616

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.72730
Policy Entropy: 4.19551
Value Function Loss: 0.00279

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.01878
Policy Update Magnitude: 0.24291
Value Function Update Magnitude: 0.28625

Collected Steps per Second: 20,765.46582
Overall Steps per Second: 9,707.46499

Timestep Collection Time: 2.40861
Timestep Consumption Time: 2.74371
PPO Batch Consumption Time: 0.32801
Total Iteration Time: 5.15232

Cumulative Model Updates: 324,540
Cumulative Timesteps: 2,706,653,632

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2706653632...
Checkpoint 2706653632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.49838
Policy Entropy: 4.21235
Value Function Loss: 0.00246

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02026
Policy Update Magnitude: 0.23746
Value Function Update Magnitude: 0.28098

Collected Steps per Second: 20,801.33239
Overall Steps per Second: 9,860.27078

Timestep Collection Time: 2.40494
Timestep Consumption Time: 2.66855
PPO Batch Consumption Time: 0.32831
Total Iteration Time: 5.07349

Cumulative Model Updates: 324,546
Cumulative Timesteps: 2,706,703,658

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.47885
Policy Entropy: 4.20461
Value Function Loss: 0.00293

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.01922
Policy Update Magnitude: 0.24337
Value Function Update Magnitude: 0.28775

Collected Steps per Second: 20,759.18339
Overall Steps per Second: 9,715.87355

Timestep Collection Time: 2.40905
Timestep Consumption Time: 2.73819
PPO Batch Consumption Time: 0.32435
Total Iteration Time: 5.14725

Cumulative Model Updates: 324,552
Cumulative Timesteps: 2,706,753,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2706753668...
Checkpoint 2706753668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.65915
Policy Entropy: 4.26301
Value Function Loss: 0.00235

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.01557
Policy Update Magnitude: 0.22845
Value Function Update Magnitude: 0.28602

Collected Steps per Second: 20,292.51855
Overall Steps per Second: 9,665.80547

Timestep Collection Time: 2.46436
Timestep Consumption Time: 2.70935
PPO Batch Consumption Time: 0.32765
Total Iteration Time: 5.17370

Cumulative Model Updates: 324,558
Cumulative Timesteps: 2,706,803,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.75641
Policy Entropy: 4.25718
Value Function Loss: 0.00257

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.01722
Policy Update Magnitude: 0.20491
Value Function Update Magnitude: 0.26627

Collected Steps per Second: 21,549.52902
Overall Steps per Second: 9,848.43131

Timestep Collection Time: 2.32098
Timestep Consumption Time: 2.75760
PPO Batch Consumption Time: 0.32982
Total Iteration Time: 5.07858

Cumulative Model Updates: 324,564
Cumulative Timesteps: 2,706,853,692

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2706853692...
Checkpoint 2706853692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.75511
Policy Entropy: 4.26404
Value Function Loss: 0.00251

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.01561
Policy Update Magnitude: 0.22692
Value Function Update Magnitude: 0.25413

Collected Steps per Second: 20,387.62818
Overall Steps per Second: 9,612.57030

Timestep Collection Time: 2.45404
Timestep Consumption Time: 2.75081
PPO Batch Consumption Time: 0.32932
Total Iteration Time: 5.20485

Cumulative Model Updates: 324,570
Cumulative Timesteps: 2,706,903,724

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.52630
Policy Entropy: 4.21490
Value Function Loss: 0.00336

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.01693
Policy Update Magnitude: 0.23661
Value Function Update Magnitude: 0.30446

Collected Steps per Second: 20,716.83325
Overall Steps per Second: 9,868.39457

Timestep Collection Time: 2.41427
Timestep Consumption Time: 2.65403
PPO Batch Consumption Time: 0.32706
Total Iteration Time: 5.06830

Cumulative Model Updates: 324,576
Cumulative Timesteps: 2,706,953,740

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2706953740...
Checkpoint 2706953740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.94873
Policy Entropy: 4.21900
Value Function Loss: 0.00252

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.01817
Policy Update Magnitude: 0.23921
Value Function Update Magnitude: 0.33534

Collected Steps per Second: 20,503.90341
Overall Steps per Second: 9,640.70928

Timestep Collection Time: 2.44002
Timestep Consumption Time: 2.74943
PPO Batch Consumption Time: 0.32561
Total Iteration Time: 5.18945

Cumulative Model Updates: 324,582
Cumulative Timesteps: 2,707,003,770

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.93922
Policy Entropy: 4.21092
Value Function Loss: 0.00247

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01652
Policy Update Magnitude: 0.23351
Value Function Update Magnitude: 0.32476

Collected Steps per Second: 20,810.28584
Overall Steps per Second: 9,764.59724

Timestep Collection Time: 2.40400
Timestep Consumption Time: 2.71940
PPO Batch Consumption Time: 0.32702
Total Iteration Time: 5.12341

Cumulative Model Updates: 324,588
Cumulative Timesteps: 2,707,053,798

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2707053798...
Checkpoint 2707053798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.93630
Policy Entropy: 4.24118
Value Function Loss: 0.00157

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.01604
Policy Update Magnitude: 0.22108
Value Function Update Magnitude: 0.29177

Collected Steps per Second: 20,325.48321
Overall Steps per Second: 9,827.36303

Timestep Collection Time: 2.46115
Timestep Consumption Time: 2.62913
PPO Batch Consumption Time: 0.32450
Total Iteration Time: 5.09028

Cumulative Model Updates: 324,594
Cumulative Timesteps: 2,707,103,822

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.83968
Policy Entropy: 4.20855
Value Function Loss: 0.00226

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.01756
Policy Update Magnitude: 0.22243
Value Function Update Magnitude: 0.26577

Collected Steps per Second: 20,756.55127
Overall Steps per Second: 9,631.20518

Timestep Collection Time: 2.40955
Timestep Consumption Time: 2.78336
PPO Batch Consumption Time: 0.33312
Total Iteration Time: 5.19291

Cumulative Model Updates: 324,600
Cumulative Timesteps: 2,707,153,836

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2707153836...
Checkpoint 2707153836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.71271
Policy Entropy: 4.21350
Value Function Loss: 0.00270

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.01744
Policy Update Magnitude: 0.23300
Value Function Update Magnitude: 0.28249

Collected Steps per Second: 20,152.27930
Overall Steps per Second: 9,667.68581

Timestep Collection Time: 2.48240
Timestep Consumption Time: 2.69216
PPO Batch Consumption Time: 0.32686
Total Iteration Time: 5.17456

Cumulative Model Updates: 324,606
Cumulative Timesteps: 2,707,203,862

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.27825
Policy Entropy: 4.19659
Value Function Loss: 0.00285

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.01819
Policy Update Magnitude: 0.24076
Value Function Update Magnitude: 0.31216

Collected Steps per Second: 21,533.13382
Overall Steps per Second: 9,864.45123

Timestep Collection Time: 2.32358
Timestep Consumption Time: 2.74857
PPO Batch Consumption Time: 0.32878
Total Iteration Time: 5.07215

Cumulative Model Updates: 324,612
Cumulative Timesteps: 2,707,253,896

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2707253896...
Checkpoint 2707253896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.71620
Policy Entropy: 4.21031
Value Function Loss: 0.00268

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.01787
Policy Update Magnitude: 0.23825
Value Function Update Magnitude: 0.32179

Collected Steps per Second: 20,588.77711
Overall Steps per Second: 9,667.12363

Timestep Collection Time: 2.42919
Timestep Consumption Time: 2.74443
PPO Batch Consumption Time: 0.32448
Total Iteration Time: 5.17362

Cumulative Model Updates: 324,618
Cumulative Timesteps: 2,707,303,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.04952
Policy Entropy: 4.23861
Value Function Loss: 0.00219

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.01565
Policy Update Magnitude: 0.22334
Value Function Update Magnitude: 0.30699

Collected Steps per Second: 20,570.51247
Overall Steps per Second: 9,623.18754

Timestep Collection Time: 2.43066
Timestep Consumption Time: 2.76512
PPO Batch Consumption Time: 0.32751
Total Iteration Time: 5.19578

Cumulative Model Updates: 324,624
Cumulative Timesteps: 2,707,353,910

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2707353910...
Checkpoint 2707353910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.47320
Policy Entropy: 4.25235
Value Function Loss: 0.00181

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01267
Policy Update Magnitude: 0.20192
Value Function Update Magnitude: 0.25940

Collected Steps per Second: 21,506.60480
Overall Steps per Second: 9,918.88620

Timestep Collection Time: 2.32654
Timestep Consumption Time: 2.71798
PPO Batch Consumption Time: 0.32466
Total Iteration Time: 5.04452

Cumulative Model Updates: 324,630
Cumulative Timesteps: 2,707,403,946

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.23131
Policy Entropy: 4.25326
Value Function Loss: 0.00215

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01280
Policy Update Magnitude: 0.20371
Value Function Update Magnitude: 0.22404

Collected Steps per Second: 20,442.26356
Overall Steps per Second: 9,581.86924

Timestep Collection Time: 2.44728
Timestep Consumption Time: 2.77383
PPO Batch Consumption Time: 0.32873
Total Iteration Time: 5.22111

Cumulative Model Updates: 324,636
Cumulative Timesteps: 2,707,453,974

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2707453974...
Checkpoint 2707453974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.41266
Policy Entropy: 4.22074
Value Function Loss: 0.00301

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01521
Policy Update Magnitude: 0.22454
Value Function Update Magnitude: 0.23591

Collected Steps per Second: 20,696.26469
Overall Steps per Second: 9,863.32106

Timestep Collection Time: 2.41647
Timestep Consumption Time: 2.65403
PPO Batch Consumption Time: 0.32499
Total Iteration Time: 5.07050

Cumulative Model Updates: 324,642
Cumulative Timesteps: 2,707,503,986

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.39619
Policy Entropy: 4.21698
Value Function Loss: 0.00253

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.01815
Policy Update Magnitude: 0.22256
Value Function Update Magnitude: 0.26000

Collected Steps per Second: 21,159.40848
Overall Steps per Second: 9,645.43573

Timestep Collection Time: 2.36339
Timestep Consumption Time: 2.82124
PPO Batch Consumption Time: 0.33668
Total Iteration Time: 5.18463

Cumulative Model Updates: 324,648
Cumulative Timesteps: 2,707,553,994

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2707553994...
Checkpoint 2707553994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.92617
Policy Entropy: 4.21003
Value Function Loss: 0.00210

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.01892
Policy Update Magnitude: 0.21964
Value Function Update Magnitude: 0.26474

Collected Steps per Second: 20,306.91573
Overall Steps per Second: 9,573.05738

Timestep Collection Time: 2.46281
Timestep Consumption Time: 2.76144
PPO Batch Consumption Time: 0.32877
Total Iteration Time: 5.22425

Cumulative Model Updates: 324,654
Cumulative Timesteps: 2,707,604,006

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.33043
Policy Entropy: 4.21486
Value Function Loss: 0.00200

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.01749
Policy Update Magnitude: 0.21913
Value Function Update Magnitude: 0.26642

Collected Steps per Second: 21,237.55841
Overall Steps per Second: 9,811.62781

Timestep Collection Time: 2.35536
Timestep Consumption Time: 2.74288
PPO Batch Consumption Time: 0.32645
Total Iteration Time: 5.09824

Cumulative Model Updates: 324,660
Cumulative Timesteps: 2,707,654,028

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2707654028...
Checkpoint 2707654028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.92276
Policy Entropy: 4.18937
Value Function Loss: 0.00303

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.01887
Policy Update Magnitude: 0.23105
Value Function Update Magnitude: 0.29492

Collected Steps per Second: 20,682.04268
Overall Steps per Second: 9,577.10703

Timestep Collection Time: 2.41862
Timestep Consumption Time: 2.80446
PPO Batch Consumption Time: 0.34008
Total Iteration Time: 5.22308

Cumulative Model Updates: 324,666
Cumulative Timesteps: 2,707,704,050

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.72919
Policy Entropy: 4.17888
Value Function Loss: 0.00345

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.01694
Policy Update Magnitude: 0.24727
Value Function Update Magnitude: 0.32237

Collected Steps per Second: 20,371.07075
Overall Steps per Second: 9,618.60646

Timestep Collection Time: 2.45476
Timestep Consumption Time: 2.74413
PPO Batch Consumption Time: 0.33005
Total Iteration Time: 5.19888

Cumulative Model Updates: 324,672
Cumulative Timesteps: 2,707,754,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2707754056...
Checkpoint 2707754056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.42633
Policy Entropy: 4.17359
Value Function Loss: 0.00336

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.01913
Policy Update Magnitude: 0.25077
Value Function Update Magnitude: 0.34600

Collected Steps per Second: 21,334.00906
Overall Steps per Second: 9,838.66188

Timestep Collection Time: 2.34414
Timestep Consumption Time: 2.73886
PPO Batch Consumption Time: 0.32668
Total Iteration Time: 5.08301

Cumulative Model Updates: 324,678
Cumulative Timesteps: 2,707,804,066

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.89977
Policy Entropy: 4.19954
Value Function Loss: 0.00246

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.01899
Policy Update Magnitude: 0.24759
Value Function Update Magnitude: 0.33285

Collected Steps per Second: 20,803.67063
Overall Steps per Second: 9,677.39857

Timestep Collection Time: 2.40390
Timestep Consumption Time: 2.76381
PPO Batch Consumption Time: 0.32939
Total Iteration Time: 5.16771

Cumulative Model Updates: 324,684
Cumulative Timesteps: 2,707,854,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2707854076...
Checkpoint 2707854076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.03047
Policy Entropy: 4.20347
Value Function Loss: 0.00269

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.01905
Policy Update Magnitude: 0.24904
Value Function Update Magnitude: 0.29222

Collected Steps per Second: 20,321.74360
Overall Steps per Second: 9,760.53865

Timestep Collection Time: 2.46042
Timestep Consumption Time: 2.66225
PPO Batch Consumption Time: 0.32659
Total Iteration Time: 5.12267

Cumulative Model Updates: 324,690
Cumulative Timesteps: 2,707,904,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.48660
Policy Entropy: 4.22014
Value Function Loss: 0.00254

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.02338
Policy Update Magnitude: 0.24091
Value Function Update Magnitude: 0.28233

Collected Steps per Second: 20,767.48929
Overall Steps per Second: 9,694.43136

Timestep Collection Time: 2.40799
Timestep Consumption Time: 2.75043
PPO Batch Consumption Time: 0.32820
Total Iteration Time: 5.15843

Cumulative Model Updates: 324,696
Cumulative Timesteps: 2,707,954,084

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2707954084...
Checkpoint 2707954084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.18730
Policy Entropy: 4.23322
Value Function Loss: 0.00237

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.01913
Policy Update Magnitude: 0.22737
Value Function Update Magnitude: 0.27326

Collected Steps per Second: 20,366.87822
Overall Steps per Second: 9,649.65767

Timestep Collection Time: 2.45614
Timestep Consumption Time: 2.72787
PPO Batch Consumption Time: 0.32707
Total Iteration Time: 5.18402

Cumulative Model Updates: 324,702
Cumulative Timesteps: 2,708,004,108

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.56918
Policy Entropy: 4.25404
Value Function Loss: 0.00180

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.01444
Policy Update Magnitude: 0.20342
Value Function Update Magnitude: 0.27050

Collected Steps per Second: 21,002.11004
Overall Steps per Second: 9,818.63769

Timestep Collection Time: 2.38148
Timestep Consumption Time: 2.71251
PPO Batch Consumption Time: 0.33387
Total Iteration Time: 5.09399

Cumulative Model Updates: 324,708
Cumulative Timesteps: 2,708,054,124

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2708054124...
Checkpoint 2708054124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.83616
Policy Entropy: 4.25439
Value Function Loss: 0.00176

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.01433
Policy Update Magnitude: 0.19529
Value Function Update Magnitude: 0.25860

Collected Steps per Second: 20,568.99856
Overall Steps per Second: 9,668.74961

Timestep Collection Time: 2.43084
Timestep Consumption Time: 2.74046
PPO Batch Consumption Time: 0.32518
Total Iteration Time: 5.17130

Cumulative Model Updates: 324,714
Cumulative Timesteps: 2,708,104,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.27592
Policy Entropy: 4.22231
Value Function Loss: 0.00233

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.01461
Policy Update Magnitude: 0.20629
Value Function Update Magnitude: 0.25517

Collected Steps per Second: 20,797.26654
Overall Steps per Second: 9,734.95179

Timestep Collection Time: 2.40445
Timestep Consumption Time: 2.73230
PPO Batch Consumption Time: 0.33800
Total Iteration Time: 5.13675

Cumulative Model Updates: 324,720
Cumulative Timesteps: 2,708,154,130

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2708154130...
Checkpoint 2708154130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.41332
Policy Entropy: 4.21537
Value Function Loss: 0.00308

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.01764
Policy Update Magnitude: 0.23492
Value Function Update Magnitude: 0.27567

Collected Steps per Second: 20,306.46090
Overall Steps per Second: 9,640.06715

Timestep Collection Time: 2.46247
Timestep Consumption Time: 2.72463
PPO Batch Consumption Time: 0.32838
Total Iteration Time: 5.18710

Cumulative Model Updates: 324,726
Cumulative Timesteps: 2,708,204,134

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.19586
Policy Entropy: 4.22978
Value Function Loss: 0.00310

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.01904
Policy Update Magnitude: 0.24080
Value Function Update Magnitude: 0.29197

Collected Steps per Second: 20,645.94580
Overall Steps per Second: 9,739.43630

Timestep Collection Time: 2.42304
Timestep Consumption Time: 2.71339
PPO Batch Consumption Time: 0.32572
Total Iteration Time: 5.13644

Cumulative Model Updates: 324,732
Cumulative Timesteps: 2,708,254,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2708254160...
Checkpoint 2708254160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.16154
Policy Entropy: 4.22111
Value Function Loss: 0.00307

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.01932
Policy Update Magnitude: 0.24746
Value Function Update Magnitude: 0.30588

Collected Steps per Second: 20,579.22617
Overall Steps per Second: 9,803.01629

Timestep Collection Time: 2.43031
Timestep Consumption Time: 2.67158
PPO Batch Consumption Time: 0.32649
Total Iteration Time: 5.10190

Cumulative Model Updates: 324,738
Cumulative Timesteps: 2,708,304,174

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.24437
Policy Entropy: 4.20532
Value Function Loss: 0.00286

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02195
Policy Update Magnitude: 0.26173
Value Function Update Magnitude: 0.31168

Collected Steps per Second: 20,826.93483
Overall Steps per Second: 9,732.73147

Timestep Collection Time: 2.40160
Timestep Consumption Time: 2.73755
PPO Batch Consumption Time: 0.32496
Total Iteration Time: 5.13915

Cumulative Model Updates: 324,744
Cumulative Timesteps: 2,708,354,192

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2708354192...
Checkpoint 2708354192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.25328
Policy Entropy: 4.17231
Value Function Loss: 0.00296

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.02051
Policy Update Magnitude: 0.25711
Value Function Update Magnitude: 0.31490

Collected Steps per Second: 20,526.87844
Overall Steps per Second: 9,738.22175

Timestep Collection Time: 2.43593
Timestep Consumption Time: 2.69868
PPO Batch Consumption Time: 0.32481
Total Iteration Time: 5.13461

Cumulative Model Updates: 324,750
Cumulative Timesteps: 2,708,404,194

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.47075
Policy Entropy: 4.20027
Value Function Loss: 0.00249

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02040
Policy Update Magnitude: 0.24015
Value Function Update Magnitude: 0.31782

Collected Steps per Second: 21,498.02494
Overall Steps per Second: 9,778.73897

Timestep Collection Time: 2.32682
Timestep Consumption Time: 2.78857
PPO Batch Consumption Time: 0.33497
Total Iteration Time: 5.11538

Cumulative Model Updates: 324,756
Cumulative Timesteps: 2,708,454,216

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2708454216...
Checkpoint 2708454216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.39311
Policy Entropy: 4.19642
Value Function Loss: 0.00212

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02062
Policy Update Magnitude: 0.22081
Value Function Update Magnitude: 0.30463

Collected Steps per Second: 20,593.01509
Overall Steps per Second: 9,684.41654

Timestep Collection Time: 2.42830
Timestep Consumption Time: 2.73525
PPO Batch Consumption Time: 0.32552
Total Iteration Time: 5.16355

Cumulative Model Updates: 324,762
Cumulative Timesteps: 2,708,504,222

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.07084
Policy Entropy: 4.19545
Value Function Loss: 0.00334

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02059
Policy Update Magnitude: 0.22842
Value Function Update Magnitude: 0.29484

Collected Steps per Second: 20,331.03313
Overall Steps per Second: 9,628.18677

Timestep Collection Time: 2.45929
Timestep Consumption Time: 2.73379
PPO Batch Consumption Time: 0.32725
Total Iteration Time: 5.19309

Cumulative Model Updates: 324,768
Cumulative Timesteps: 2,708,554,222

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2708554222...
Checkpoint 2708554222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.72846
Policy Entropy: 4.15827
Value Function Loss: 0.00364

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02478
Policy Update Magnitude: 0.25222
Value Function Update Magnitude: 0.32713

Collected Steps per Second: 21,211.88992
Overall Steps per Second: 9,789.17253

Timestep Collection Time: 2.35830
Timestep Consumption Time: 2.75184
PPO Batch Consumption Time: 0.32695
Total Iteration Time: 5.11014

Cumulative Model Updates: 324,774
Cumulative Timesteps: 2,708,604,246

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.68841
Policy Entropy: 4.14689
Value Function Loss: 0.00386

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.02712
Policy Update Magnitude: 0.26834
Value Function Update Magnitude: 0.33377

Collected Steps per Second: 20,560.19946
Overall Steps per Second: 9,667.17291

Timestep Collection Time: 2.43276
Timestep Consumption Time: 2.74125
PPO Batch Consumption Time: 0.32762
Total Iteration Time: 5.17400

Cumulative Model Updates: 324,780
Cumulative Timesteps: 2,708,654,264

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2708654264...
Checkpoint 2708654264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.21641
Policy Entropy: 4.19076
Value Function Loss: 0.00283

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02562
Policy Update Magnitude: 0.26008
Value Function Update Magnitude: 0.33354

Collected Steps per Second: 20,495.91090
Overall Steps per Second: 9,816.75810

Timestep Collection Time: 2.44049
Timestep Consumption Time: 2.65488
PPO Batch Consumption Time: 0.32717
Total Iteration Time: 5.09537

Cumulative Model Updates: 324,786
Cumulative Timesteps: 2,708,704,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.86696
Policy Entropy: 4.22036
Value Function Loss: 0.00208

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.01954
Policy Update Magnitude: 0.23110
Value Function Update Magnitude: 0.31085

Collected Steps per Second: 20,285.87587
Overall Steps per Second: 9,615.02442

Timestep Collection Time: 2.46477
Timestep Consumption Time: 2.73543
PPO Batch Consumption Time: 0.32683
Total Iteration Time: 5.20019

Cumulative Model Updates: 324,792
Cumulative Timesteps: 2,708,754,284

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2708754284...
Checkpoint 2708754284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.78998
Policy Entropy: 4.23287
Value Function Loss: 0.00217

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.01577
Policy Update Magnitude: 0.22972
Value Function Update Magnitude: 0.29526

Collected Steps per Second: 20,684.79054
Overall Steps per Second: 9,678.37466

Timestep Collection Time: 2.41830
Timestep Consumption Time: 2.75013
PPO Batch Consumption Time: 0.33254
Total Iteration Time: 5.16843

Cumulative Model Updates: 324,798
Cumulative Timesteps: 2,708,804,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.18650
Policy Entropy: 4.20154
Value Function Loss: 0.00364

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02103
Policy Update Magnitude: 0.26882
Value Function Update Magnitude: 0.33720

Collected Steps per Second: 21,100.22569
Overall Steps per Second: 9,792.12053

Timestep Collection Time: 2.36964
Timestep Consumption Time: 2.73650
PPO Batch Consumption Time: 0.32529
Total Iteration Time: 5.10615

Cumulative Model Updates: 324,804
Cumulative Timesteps: 2,708,854,306

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2708854306...
Checkpoint 2708854306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51625
Policy Entropy: 4.20255
Value Function Loss: 0.00366

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02031
Policy Update Magnitude: 0.27299
Value Function Update Magnitude: 0.37430

Collected Steps per Second: 20,573.70501
Overall Steps per Second: 9,636.88516

Timestep Collection Time: 2.43097
Timestep Consumption Time: 2.75888
PPO Batch Consumption Time: 0.33020
Total Iteration Time: 5.18985

Cumulative Model Updates: 324,810
Cumulative Timesteps: 2,708,904,320

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.62714
Policy Entropy: 4.23077
Value Function Loss: 0.00270

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.01919
Policy Update Magnitude: 0.24495
Value Function Update Magnitude: 0.34604

Collected Steps per Second: 20,588.31158
Overall Steps per Second: 9,814.80445

Timestep Collection Time: 2.42895
Timestep Consumption Time: 2.66621
PPO Batch Consumption Time: 0.32717
Total Iteration Time: 5.09516

Cumulative Model Updates: 324,816
Cumulative Timesteps: 2,708,954,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2708954328...
Checkpoint 2708954328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.59331
Policy Entropy: 4.24742
Value Function Loss: 0.00240

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.01591
Policy Update Magnitude: 0.22745
Value Function Update Magnitude: 0.30123

Collected Steps per Second: 20,588.89460
Overall Steps per Second: 9,554.47196

Timestep Collection Time: 2.42859
Timestep Consumption Time: 2.80477
PPO Batch Consumption Time: 0.34198
Total Iteration Time: 5.23336

Cumulative Model Updates: 324,822
Cumulative Timesteps: 2,709,004,330

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.01124
Policy Entropy: 4.24367
Value Function Loss: 0.00229

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.01403
Policy Update Magnitude: 0.22970
Value Function Update Magnitude: 0.26953

Collected Steps per Second: 20,659.84459
Overall Steps per Second: 9,652.97328

Timestep Collection Time: 2.42122
Timestep Consumption Time: 2.76081
PPO Batch Consumption Time: 0.33508
Total Iteration Time: 5.18203

Cumulative Model Updates: 324,828
Cumulative Timesteps: 2,709,054,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2709054352...
Checkpoint 2709054352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.42181
Policy Entropy: 4.19343
Value Function Loss: 0.00323

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.01596
Policy Update Magnitude: 0.24209
Value Function Update Magnitude: 0.27383

Collected Steps per Second: 20,231.27922
Overall Steps per Second: 9,718.94418

Timestep Collection Time: 2.47231
Timestep Consumption Time: 2.67413
PPO Batch Consumption Time: 0.32975
Total Iteration Time: 5.14644

Cumulative Model Updates: 324,834
Cumulative Timesteps: 2,709,104,370

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.19920
Policy Entropy: 4.19215
Value Function Loss: 0.00304

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02029
Policy Update Magnitude: 0.25832
Value Function Update Magnitude: 0.31276

Collected Steps per Second: 20,966.09744
Overall Steps per Second: 9,785.71637

Timestep Collection Time: 2.38509
Timestep Consumption Time: 2.72501
PPO Batch Consumption Time: 0.32463
Total Iteration Time: 5.11010

Cumulative Model Updates: 324,840
Cumulative Timesteps: 2,709,154,376

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2709154376...
Checkpoint 2709154376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.69459
Policy Entropy: 4.18488
Value Function Loss: 0.00290

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02027
Policy Update Magnitude: 0.25789
Value Function Update Magnitude: 0.32210

Collected Steps per Second: 20,445.98421
Overall Steps per Second: 9,676.66416

Timestep Collection Time: 2.44654
Timestep Consumption Time: 2.72280
PPO Batch Consumption Time: 0.32379
Total Iteration Time: 5.16934

Cumulative Model Updates: 324,846
Cumulative Timesteps: 2,709,204,398

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.17707
Policy Entropy: 4.17730
Value Function Loss: 0.00361

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.01983
Policy Update Magnitude: 0.26609
Value Function Update Magnitude: 0.31783

Collected Steps per Second: 21,394.29590
Overall Steps per Second: 9,793.77194

Timestep Collection Time: 2.33782
Timestep Consumption Time: 2.76910
PPO Batch Consumption Time: 0.33519
Total Iteration Time: 5.10692

Cumulative Model Updates: 324,852
Cumulative Timesteps: 2,709,254,414

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2709254414...
Checkpoint 2709254414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.41243
Policy Entropy: 4.16017
Value Function Loss: 0.00406

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.02122
Policy Update Magnitude: 0.28122
Value Function Update Magnitude: 0.33816

Collected Steps per Second: 20,376.62902
Overall Steps per Second: 9,622.96457

Timestep Collection Time: 2.45409
Timestep Consumption Time: 2.74244
PPO Batch Consumption Time: 0.32690
Total Iteration Time: 5.19653

Cumulative Model Updates: 324,858
Cumulative Timesteps: 2,709,304,420

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33484
Policy Entropy: 4.16339
Value Function Loss: 0.00376

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.02741
Policy Update Magnitude: 0.27588
Value Function Update Magnitude: 0.34647

Collected Steps per Second: 20,856.43753
Overall Steps per Second: 9,786.25867

Timestep Collection Time: 2.39801
Timestep Consumption Time: 2.71262
PPO Batch Consumption Time: 0.32546
Total Iteration Time: 5.11064

Cumulative Model Updates: 324,864
Cumulative Timesteps: 2,709,354,434

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2709354434...
Checkpoint 2709354434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.00014
Policy Entropy: 4.21371
Value Function Loss: 0.00278

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02290
Policy Update Magnitude: 0.25375
Value Function Update Magnitude: 0.31455

Collected Steps per Second: 20,937.44302
Overall Steps per Second: 9,740.10991

Timestep Collection Time: 2.38807
Timestep Consumption Time: 2.74535
PPO Batch Consumption Time: 0.32505
Total Iteration Time: 5.13341

Cumulative Model Updates: 324,870
Cumulative Timesteps: 2,709,404,434

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.17389
Policy Entropy: 4.21762
Value Function Loss: 0.00315

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02147
Policy Update Magnitude: 0.23781
Value Function Update Magnitude: 0.29170

Collected Steps per Second: 21,032.46698
Overall Steps per Second: 9,712.20050

Timestep Collection Time: 2.37728
Timestep Consumption Time: 2.77089
PPO Batch Consumption Time: 0.32833
Total Iteration Time: 5.14816

Cumulative Model Updates: 324,876
Cumulative Timesteps: 2,709,454,434

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2709454434...
Checkpoint 2709454434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.70775
Policy Entropy: 4.21084
Value Function Loss: 0.00349

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02046
Policy Update Magnitude: 0.24549
Value Function Update Magnitude: 0.30021

Collected Steps per Second: 20,745.59847
Overall Steps per Second: 9,867.89689

Timestep Collection Time: 2.41015
Timestep Consumption Time: 2.65679
PPO Batch Consumption Time: 0.32725
Total Iteration Time: 5.06694

Cumulative Model Updates: 324,882
Cumulative Timesteps: 2,709,504,434

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.39200
Policy Entropy: 4.18796
Value Function Loss: 0.00368

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.01961
Policy Update Magnitude: 0.25362
Value Function Update Magnitude: 0.31960

Collected Steps per Second: 20,745.05974
Overall Steps per Second: 9,594.48191

Timestep Collection Time: 2.41147
Timestep Consumption Time: 2.80257
PPO Batch Consumption Time: 0.33754
Total Iteration Time: 5.21404

Cumulative Model Updates: 324,888
Cumulative Timesteps: 2,709,554,460

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2709554460...
Checkpoint 2709554460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.26447
Policy Entropy: 4.17127
Value Function Loss: 0.00354

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02373
Policy Update Magnitude: 0.27803
Value Function Update Magnitude: 0.34378

Collected Steps per Second: 20,550.79752
Overall Steps per Second: 9,740.27232

Timestep Collection Time: 2.43446
Timestep Consumption Time: 2.70195
PPO Batch Consumption Time: 0.32443
Total Iteration Time: 5.13641

Cumulative Model Updates: 324,894
Cumulative Timesteps: 2,709,604,490

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.61227
Policy Entropy: 4.16133
Value Function Loss: 0.00358

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.02452
Policy Update Magnitude: 0.28644
Value Function Update Magnitude: 0.34880

Collected Steps per Second: 20,824.42822
Overall Steps per Second: 9,806.29932

Timestep Collection Time: 2.40218
Timestep Consumption Time: 2.69903
PPO Batch Consumption Time: 0.33590
Total Iteration Time: 5.10121

Cumulative Model Updates: 324,900
Cumulative Timesteps: 2,709,654,514

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2709654514...
Checkpoint 2709654514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.65203
Policy Entropy: 4.20637
Value Function Loss: 0.00252

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02144
Policy Update Magnitude: 0.26125
Value Function Update Magnitude: 0.32955

Collected Steps per Second: 20,503.92286
Overall Steps per Second: 9,658.84931

Timestep Collection Time: 2.43983
Timestep Consumption Time: 2.73947
PPO Batch Consumption Time: 0.32627
Total Iteration Time: 5.17929

Cumulative Model Updates: 324,906
Cumulative Timesteps: 2,709,704,540

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.97206
Policy Entropy: 4.20464
Value Function Loss: 0.00332

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.01905
Policy Update Magnitude: 0.25193
Value Function Update Magnitude: 0.29043

Collected Steps per Second: 20,685.55438
Overall Steps per Second: 9,776.46043

Timestep Collection Time: 2.41753
Timestep Consumption Time: 2.69761
PPO Batch Consumption Time: 0.32470
Total Iteration Time: 5.11514

Cumulative Model Updates: 324,912
Cumulative Timesteps: 2,709,754,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2709754548...
Checkpoint 2709754548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.38704
Policy Entropy: 4.21397
Value Function Loss: 0.00313

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.01944
Policy Update Magnitude: 0.25073
Value Function Update Magnitude: 0.28946

Collected Steps per Second: 21,390.86102
Overall Steps per Second: 9,794.09106

Timestep Collection Time: 2.33819
Timestep Consumption Time: 2.76856
PPO Batch Consumption Time: 0.32895
Total Iteration Time: 5.10675

Cumulative Model Updates: 324,918
Cumulative Timesteps: 2,709,804,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.65341
Policy Entropy: 4.19624
Value Function Loss: 0.00346

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.02212
Policy Update Magnitude: 0.24395
Value Function Update Magnitude: 0.31394

Collected Steps per Second: 20,805.16799
Overall Steps per Second: 9,629.09561

Timestep Collection Time: 2.40440
Timestep Consumption Time: 2.79069
PPO Batch Consumption Time: 0.33332
Total Iteration Time: 5.19509

Cumulative Model Updates: 324,924
Cumulative Timesteps: 2,709,854,588

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2709854588...
Checkpoint 2709854588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.91417
Policy Entropy: 4.22704
Value Function Loss: 0.00278

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.01813
Policy Update Magnitude: 0.23671
Value Function Update Magnitude: 0.30652

Collected Steps per Second: 20,651.28189
Overall Steps per Second: 9,719.53512

Timestep Collection Time: 2.42135
Timestep Consumption Time: 2.72334
PPO Batch Consumption Time: 0.32607
Total Iteration Time: 5.14469

Cumulative Model Updates: 324,930
Cumulative Timesteps: 2,709,904,592

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.07188
Policy Entropy: 4.22342
Value Function Loss: 0.00297

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.01810
Policy Update Magnitude: 0.24420
Value Function Update Magnitude: 0.29415

Collected Steps per Second: 21,470.33733
Overall Steps per Second: 9,799.87708

Timestep Collection Time: 2.32945
Timestep Consumption Time: 2.77409
PPO Batch Consumption Time: 0.33058
Total Iteration Time: 5.10353

Cumulative Model Updates: 324,936
Cumulative Timesteps: 2,709,954,606

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2709954606...
Checkpoint 2709954606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.68242
Policy Entropy: 4.21878
Value Function Loss: 0.00298

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.01773
Policy Update Magnitude: 0.24559
Value Function Update Magnitude: 0.29660

Collected Steps per Second: 20,455.86670
Overall Steps per Second: 9,667.30766

Timestep Collection Time: 2.44448
Timestep Consumption Time: 2.72800
PPO Batch Consumption Time: 0.32491
Total Iteration Time: 5.17248

Cumulative Model Updates: 324,942
Cumulative Timesteps: 2,710,004,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.29479
Policy Entropy: 4.20638
Value Function Loss: 0.00312

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.01959
Policy Update Magnitude: 0.23460
Value Function Update Magnitude: 0.29874

Collected Steps per Second: 20,927.59035
Overall Steps per Second: 9,842.75565

Timestep Collection Time: 2.38948
Timestep Consumption Time: 2.69101
PPO Batch Consumption Time: 0.33319
Total Iteration Time: 5.08049

Cumulative Model Updates: 324,948
Cumulative Timesteps: 2,710,054,616

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2710054616...
Checkpoint 2710054616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.25929
Policy Entropy: 4.20433
Value Function Loss: 0.00286

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.01939
Policy Update Magnitude: 0.22888
Value Function Update Magnitude: 0.27855

Collected Steps per Second: 20,631.36261
Overall Steps per Second: 9,686.17847

Timestep Collection Time: 2.42349
Timestep Consumption Time: 2.73850
PPO Batch Consumption Time: 0.32505
Total Iteration Time: 5.16199

Cumulative Model Updates: 324,954
Cumulative Timesteps: 2,710,104,616

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.25716
Policy Entropy: 4.19531
Value Function Loss: 0.00277

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.01867
Policy Update Magnitude: 0.24213
Value Function Update Magnitude: 0.27217

Collected Steps per Second: 20,776.37313
Overall Steps per Second: 9,728.29428

Timestep Collection Time: 2.40764
Timestep Consumption Time: 2.73427
PPO Batch Consumption Time: 0.32858
Total Iteration Time: 5.14191

Cumulative Model Updates: 324,960
Cumulative Timesteps: 2,710,154,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2710154638...
Checkpoint 2710154638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.99251
Policy Entropy: 4.20038
Value Function Loss: 0.00240

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.01846
Policy Update Magnitude: 0.24565
Value Function Update Magnitude: 0.30638

Collected Steps per Second: 20,334.28723
Overall Steps per Second: 9,803.14455

Timestep Collection Time: 2.45988
Timestep Consumption Time: 2.64256
PPO Batch Consumption Time: 0.32492
Total Iteration Time: 5.10244

Cumulative Model Updates: 324,966
Cumulative Timesteps: 2,710,204,658

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.13511
Policy Entropy: 4.19994
Value Function Loss: 0.00234

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.01970
Policy Update Magnitude: 0.23867
Value Function Update Magnitude: 0.30543

Collected Steps per Second: 20,706.64842
Overall Steps per Second: 9,600.96357

Timestep Collection Time: 2.41613
Timestep Consumption Time: 2.79480
PPO Batch Consumption Time: 0.33658
Total Iteration Time: 5.21094

Cumulative Model Updates: 324,972
Cumulative Timesteps: 2,710,254,688

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2710254688...
Checkpoint 2710254688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.09002
Policy Entropy: 4.19946
Value Function Loss: 0.00269

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.01930
Policy Update Magnitude: 0.23766
Value Function Update Magnitude: 0.27570

Collected Steps per Second: 20,321.28025
Overall Steps per Second: 9,641.42350

Timestep Collection Time: 2.46047
Timestep Consumption Time: 2.72548
PPO Batch Consumption Time: 0.33020
Total Iteration Time: 5.18596

Cumulative Model Updates: 324,978
Cumulative Timesteps: 2,710,304,688

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.78542
Policy Entropy: 4.18703
Value Function Loss: 0.00326

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.01980
Policy Update Magnitude: 0.24804
Value Function Update Magnitude: 0.25665

Collected Steps per Second: 21,479.50633
Overall Steps per Second: 9,824.46581

Timestep Collection Time: 2.32827
Timestep Consumption Time: 2.76209
PPO Batch Consumption Time: 0.32984
Total Iteration Time: 5.09035

Cumulative Model Updates: 324,984
Cumulative Timesteps: 2,710,354,698

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2710354698...
Checkpoint 2710354698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.69842
Policy Entropy: 4.20619
Value Function Loss: 0.00322

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02145
Policy Update Magnitude: 0.24895
Value Function Update Magnitude: 0.26870

Collected Steps per Second: 20,321.82273
Overall Steps per Second: 9,461.47591

Timestep Collection Time: 2.46149
Timestep Consumption Time: 2.82542
PPO Batch Consumption Time: 0.34326
Total Iteration Time: 5.28691

Cumulative Model Updates: 324,990
Cumulative Timesteps: 2,710,404,720

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.93158
Policy Entropy: 4.20659
Value Function Loss: 0.00295

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02074
Policy Update Magnitude: 0.24260
Value Function Update Magnitude: 0.28276

Collected Steps per Second: 20,453.50069
Overall Steps per Second: 9,682.27415

Timestep Collection Time: 2.44574
Timestep Consumption Time: 2.72081
PPO Batch Consumption Time: 0.33989
Total Iteration Time: 5.16655

Cumulative Model Updates: 324,996
Cumulative Timesteps: 2,710,454,744

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2710454744...
Checkpoint 2710454744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.44301
Policy Entropy: 4.21859
Value Function Loss: 0.00218

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02018
Policy Update Magnitude: 0.23761
Value Function Update Magnitude: 0.28430

Collected Steps per Second: 20,534.06896
Overall Steps per Second: 9,687.92669

Timestep Collection Time: 2.43498
Timestep Consumption Time: 2.72609
PPO Batch Consumption Time: 0.32534
Total Iteration Time: 5.16106

Cumulative Model Updates: 325,002
Cumulative Timesteps: 2,710,504,744

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.50541
Policy Entropy: 4.20921
Value Function Loss: 0.00262

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02040
Policy Update Magnitude: 0.23407
Value Function Update Magnitude: 0.27176

Collected Steps per Second: 20,582.44713
Overall Steps per Second: 9,675.64876

Timestep Collection Time: 2.43052
Timestep Consumption Time: 2.73978
PPO Batch Consumption Time: 0.32751
Total Iteration Time: 5.17030

Cumulative Model Updates: 325,008
Cumulative Timesteps: 2,710,554,770

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2710554770...
Checkpoint 2710554770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.28390
Policy Entropy: 4.20453
Value Function Loss: 0.00304

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02177
Policy Update Magnitude: 0.24097
Value Function Update Magnitude: 0.27788

Collected Steps per Second: 20,742.86936
Overall Steps per Second: 9,907.65628

Timestep Collection Time: 2.41047
Timestep Consumption Time: 2.63614
PPO Batch Consumption Time: 0.32520
Total Iteration Time: 5.04660

Cumulative Model Updates: 325,014
Cumulative Timesteps: 2,710,604,770

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.31995
Policy Entropy: 4.20926
Value Function Loss: 0.00313

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.01941
Policy Update Magnitude: 0.24027
Value Function Update Magnitude: 0.30460

Collected Steps per Second: 20,834.10565
Overall Steps per Second: 9,663.84398

Timestep Collection Time: 2.40078
Timestep Consumption Time: 2.77501
PPO Batch Consumption Time: 0.33459
Total Iteration Time: 5.17579

Cumulative Model Updates: 325,020
Cumulative Timesteps: 2,710,654,788

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2710654788...
Checkpoint 2710654788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.90112
Policy Entropy: 4.22146
Value Function Loss: 0.00271

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.01755
Policy Update Magnitude: 0.23835
Value Function Update Magnitude: 0.31477

Collected Steps per Second: 20,635.53400
Overall Steps per Second: 9,718.90988

Timestep Collection Time: 2.42300
Timestep Consumption Time: 2.72160
PPO Batch Consumption Time: 0.32621
Total Iteration Time: 5.14461

Cumulative Model Updates: 325,026
Cumulative Timesteps: 2,710,704,788

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.76088
Policy Entropy: 4.21561
Value Function Loss: 0.00243

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.01775
Policy Update Magnitude: 0.23327
Value Function Update Magnitude: 0.30001

Collected Steps per Second: 21,550.92620
Overall Steps per Second: 9,915.89595

Timestep Collection Time: 2.32009
Timestep Consumption Time: 2.72232
PPO Batch Consumption Time: 0.32936
Total Iteration Time: 5.04241

Cumulative Model Updates: 325,032
Cumulative Timesteps: 2,710,754,788

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2710754788...
Checkpoint 2710754788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.57482
Policy Entropy: 4.21896
Value Function Loss: 0.00219

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.01673
Policy Update Magnitude: 0.21524
Value Function Update Magnitude: 0.28034

Collected Steps per Second: 20,640.54369
Overall Steps per Second: 9,664.69149

Timestep Collection Time: 2.42271
Timestep Consumption Time: 2.75138
PPO Batch Consumption Time: 0.33316
Total Iteration Time: 5.17409

Cumulative Model Updates: 325,038
Cumulative Timesteps: 2,710,804,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.88788
Policy Entropy: 4.21426
Value Function Loss: 0.00261

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.01501
Policy Update Magnitude: 0.22112
Value Function Update Magnitude: 0.27279

Collected Steps per Second: 20,572.53615
Overall Steps per Second: 9,856.29832

Timestep Collection Time: 2.43042
Timestep Consumption Time: 2.64247
PPO Batch Consumption Time: 0.32514
Total Iteration Time: 5.07290

Cumulative Model Updates: 325,044
Cumulative Timesteps: 2,710,854,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2710854794...
Checkpoint 2710854794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.97152
Policy Entropy: 4.21176
Value Function Loss: 0.00313

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.01738
Policy Update Magnitude: 0.23700
Value Function Update Magnitude: 0.30000

Collected Steps per Second: 20,776.77421
Overall Steps per Second: 9,643.93262

Timestep Collection Time: 2.40740
Timestep Consumption Time: 2.77907
PPO Batch Consumption Time: 0.33237
Total Iteration Time: 5.18647

Cumulative Model Updates: 325,050
Cumulative Timesteps: 2,710,904,812

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.26500
Policy Entropy: 4.20449
Value Function Loss: 0.00318

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.01769
Policy Update Magnitude: 0.24073
Value Function Update Magnitude: 0.31779

Collected Steps per Second: 20,650.96155
Overall Steps per Second: 9,619.86640

Timestep Collection Time: 2.42187
Timestep Consumption Time: 2.77716
PPO Batch Consumption Time: 0.33137
Total Iteration Time: 5.19903

Cumulative Model Updates: 325,056
Cumulative Timesteps: 2,710,954,826

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2710954826...
Checkpoint 2710954826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.62667
Policy Entropy: 4.17660
Value Function Loss: 0.00312

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.01903
Policy Update Magnitude: 0.24797
Value Function Update Magnitude: 0.32998

Collected Steps per Second: 20,123.18985
Overall Steps per Second: 9,663.63624

Timestep Collection Time: 2.48499
Timestep Consumption Time: 2.68966
PPO Batch Consumption Time: 0.32910
Total Iteration Time: 5.17466

Cumulative Model Updates: 325,062
Cumulative Timesteps: 2,711,004,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.99857
Policy Entropy: 4.18158
Value Function Loss: 0.00292

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02194
Policy Update Magnitude: 0.25059
Value Function Update Magnitude: 0.33001

Collected Steps per Second: 20,815.05836
Overall Steps per Second: 9,692.45223

Timestep Collection Time: 2.40288
Timestep Consumption Time: 2.75743
PPO Batch Consumption Time: 0.32411
Total Iteration Time: 5.16030

Cumulative Model Updates: 325,068
Cumulative Timesteps: 2,711,054,848

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2711054848...
Checkpoint 2711054848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.72664
Policy Entropy: 4.16853
Value Function Loss: 0.00253

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02241
Policy Update Magnitude: 0.24733
Value Function Update Magnitude: 0.32692

Collected Steps per Second: 20,459.65931
Overall Steps per Second: 9,591.05383

Timestep Collection Time: 2.44501
Timestep Consumption Time: 2.77069
PPO Batch Consumption Time: 0.33574
Total Iteration Time: 5.21569

Cumulative Model Updates: 325,074
Cumulative Timesteps: 2,711,104,872

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.81252
Policy Entropy: 4.18264
Value Function Loss: 0.00267

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02141
Policy Update Magnitude: 0.25046
Value Function Update Magnitude: 0.32186

Collected Steps per Second: 21,440.66335
Overall Steps per Second: 9,866.93803

Timestep Collection Time: 2.33202
Timestep Consumption Time: 2.73541
PPO Batch Consumption Time: 0.32426
Total Iteration Time: 5.06743

Cumulative Model Updates: 325,080
Cumulative Timesteps: 2,711,154,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2711154872...
Checkpoint 2711154872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.98008
Policy Entropy: 4.19004
Value Function Loss: 0.00287

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.01746
Policy Update Magnitude: 0.25301
Value Function Update Magnitude: 0.31864

Collected Steps per Second: 20,758.11825
Overall Steps per Second: 9,701.78220

Timestep Collection Time: 2.40976
Timestep Consumption Time: 2.74620
PPO Batch Consumption Time: 0.33079
Total Iteration Time: 5.15596

Cumulative Model Updates: 325,086
Cumulative Timesteps: 2,711,204,894

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.30823
Policy Entropy: 4.19944
Value Function Loss: 0.00298

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.01730
Policy Update Magnitude: 0.25175
Value Function Update Magnitude: 0.31039

Collected Steps per Second: 20,744.77810
Overall Steps per Second: 9,775.17508

Timestep Collection Time: 2.41111
Timestep Consumption Time: 2.70573
PPO Batch Consumption Time: 0.32414
Total Iteration Time: 5.11684

Cumulative Model Updates: 325,092
Cumulative Timesteps: 2,711,254,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2711254912...
Checkpoint 2711254912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.51997
Policy Entropy: 4.19179
Value Function Loss: 0.00297

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.01859
Policy Update Magnitude: 0.24644
Value Function Update Magnitude: 0.30510

Collected Steps per Second: 21,191.45748
Overall Steps per Second: 9,840.54028

Timestep Collection Time: 2.36029
Timestep Consumption Time: 2.72256
PPO Batch Consumption Time: 0.32343
Total Iteration Time: 5.08285

Cumulative Model Updates: 325,098
Cumulative Timesteps: 2,711,304,930

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.59814
Policy Entropy: 4.17715
Value Function Loss: 0.00315

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.01983
Policy Update Magnitude: 0.26173
Value Function Update Magnitude: 0.31487

Collected Steps per Second: 20,879.00337
Overall Steps per Second: 9,753.33142

Timestep Collection Time: 2.39590
Timestep Consumption Time: 2.73301
PPO Batch Consumption Time: 0.32431
Total Iteration Time: 5.12891

Cumulative Model Updates: 325,104
Cumulative Timesteps: 2,711,354,954

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2711354954...
Checkpoint 2711354954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.25329
Policy Entropy: 4.16043
Value Function Loss: 0.00408

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02140
Policy Update Magnitude: 0.27071
Value Function Update Magnitude: 0.33658

Collected Steps per Second: 20,603.51210
Overall Steps per Second: 9,755.33082

Timestep Collection Time: 2.42852
Timestep Consumption Time: 2.70058
PPO Batch Consumption Time: 0.33626
Total Iteration Time: 5.12909

Cumulative Model Updates: 325,110
Cumulative Timesteps: 2,711,404,990

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.71373
Policy Entropy: 4.17476
Value Function Loss: 0.00358

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02143
Policy Update Magnitude: 0.26918
Value Function Update Magnitude: 0.36262

Collected Steps per Second: 20,313.97395
Overall Steps per Second: 9,583.99282

Timestep Collection Time: 2.46234
Timestep Consumption Time: 2.75677
PPO Batch Consumption Time: 0.32723
Total Iteration Time: 5.21912

Cumulative Model Updates: 325,116
Cumulative Timesteps: 2,711,455,010

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2711455010...
Checkpoint 2711455010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.39803
Policy Entropy: 4.17661
Value Function Loss: 0.00324

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02201
Policy Update Magnitude: 0.25654
Value Function Update Magnitude: 0.34689

Collected Steps per Second: 20,589.63695
Overall Steps per Second: 9,721.63327

Timestep Collection Time: 2.42947
Timestep Consumption Time: 2.71596
PPO Batch Consumption Time: 0.32941
Total Iteration Time: 5.14543

Cumulative Model Updates: 325,122
Cumulative Timesteps: 2,711,505,032

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.98556
Policy Entropy: 4.18044
Value Function Loss: 0.00254

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.01953
Policy Update Magnitude: 0.24183
Value Function Update Magnitude: 0.31605

Collected Steps per Second: 20,709.55871
Overall Steps per Second: 9,860.46375

Timestep Collection Time: 2.41492
Timestep Consumption Time: 2.65705
PPO Batch Consumption Time: 0.32579
Total Iteration Time: 5.07197

Cumulative Model Updates: 325,128
Cumulative Timesteps: 2,711,555,044

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2711555044...
Checkpoint 2711555044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.28250
Policy Entropy: 4.13683
Value Function Loss: 0.00354

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02406
Policy Update Magnitude: 0.27580
Value Function Update Magnitude: 0.30606

Collected Steps per Second: 20,452.45473
Overall Steps per Second: 9,614.09051

Timestep Collection Time: 2.44489
Timestep Consumption Time: 2.75623
PPO Batch Consumption Time: 0.32906
Total Iteration Time: 5.20112

Cumulative Model Updates: 325,134
Cumulative Timesteps: 2,711,605,048

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.47271
Policy Entropy: 4.12693
Value Function Loss: 0.00354

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.02554
Policy Update Magnitude: 0.27679
Value Function Update Magnitude: 0.32089

Collected Steps per Second: 20,616.28014
Overall Steps per Second: 9,690.33789

Timestep Collection Time: 2.42633
Timestep Consumption Time: 2.73571
PPO Batch Consumption Time: 0.32599
Total Iteration Time: 5.16205

Cumulative Model Updates: 325,140
Cumulative Timesteps: 2,711,655,070

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2711655070...
Checkpoint 2711655070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.51625
Policy Entropy: 4.13734
Value Function Loss: 0.00301

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.02325
Policy Update Magnitude: 0.25858
Value Function Update Magnitude: 0.32900

Collected Steps per Second: 21,454.70319
Overall Steps per Second: 9,883.52986

Timestep Collection Time: 2.33077
Timestep Consumption Time: 2.72876
PPO Batch Consumption Time: 0.32719
Total Iteration Time: 5.05953

Cumulative Model Updates: 325,146
Cumulative Timesteps: 2,711,705,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.45323
Policy Entropy: 4.16130
Value Function Loss: 0.00289

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.01868
Policy Update Magnitude: 0.26302
Value Function Update Magnitude: 0.32304

Collected Steps per Second: 20,745.01152
Overall Steps per Second: 9,719.08478

Timestep Collection Time: 2.41031
Timestep Consumption Time: 2.73441
PPO Batch Consumption Time: 0.32472
Total Iteration Time: 5.14472

Cumulative Model Updates: 325,152
Cumulative Timesteps: 2,711,755,078

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2711755078...
Checkpoint 2711755078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.64199
Policy Entropy: 4.17310
Value Function Loss: 0.00263

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.01816
Policy Update Magnitude: 0.27080
Value Function Update Magnitude: 0.33768

Collected Steps per Second: 20,725.02367
Overall Steps per Second: 9,784.66729

Timestep Collection Time: 2.41370
Timestep Consumption Time: 2.69879
PPO Batch Consumption Time: 0.33710
Total Iteration Time: 5.11249

Cumulative Model Updates: 325,158
Cumulative Timesteps: 2,711,805,102

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.98485
Policy Entropy: 4.15455
Value Function Loss: 0.00324

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.02444
Policy Update Magnitude: 0.27229
Value Function Update Magnitude: 0.35735

Collected Steps per Second: 20,268.27832
Overall Steps per Second: 9,624.30794

Timestep Collection Time: 2.46770
Timestep Consumption Time: 2.72914
PPO Batch Consumption Time: 0.32581
Total Iteration Time: 5.19684

Cumulative Model Updates: 325,164
Cumulative Timesteps: 2,711,855,118

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2711855118...
Checkpoint 2711855118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.67680
Policy Entropy: 4.17139
Value Function Loss: 0.00274

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02334
Policy Update Magnitude: 0.26086
Value Function Update Magnitude: 0.33772

Collected Steps per Second: 20,650.42907
Overall Steps per Second: 9,726.57947

Timestep Collection Time: 2.42223
Timestep Consumption Time: 2.72038
PPO Batch Consumption Time: 0.32472
Total Iteration Time: 5.14261

Cumulative Model Updates: 325,170
Cumulative Timesteps: 2,711,905,138

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.52680
Policy Entropy: 4.16005
Value Function Loss: 0.00362

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.01975
Policy Update Magnitude: 0.26546
Value Function Update Magnitude: 0.33098

Collected Steps per Second: 20,848.69145
Overall Steps per Second: 9,790.88522

Timestep Collection Time: 2.39938
Timestep Consumption Time: 2.70986
PPO Batch Consumption Time: 0.33916
Total Iteration Time: 5.10924

Cumulative Model Updates: 325,176
Cumulative Timesteps: 2,711,955,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2711955162...
Checkpoint 2711955162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.29806
Policy Entropy: 4.18907
Value Function Loss: 0.00264

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.01863
Policy Update Magnitude: 0.25682
Value Function Update Magnitude: 0.32760

Collected Steps per Second: 20,609.92603
Overall Steps per Second: 9,624.96886

Timestep Collection Time: 2.42602
Timestep Consumption Time: 2.76881
PPO Batch Consumption Time: 0.33086
Total Iteration Time: 5.19482

Cumulative Model Updates: 325,182
Cumulative Timesteps: 2,712,005,162

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.74126
Policy Entropy: 4.17813
Value Function Loss: 0.00303

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.02476
Policy Update Magnitude: 0.25102
Value Function Update Magnitude: 0.32685

Collected Steps per Second: 20,861.18295
Overall Steps per Second: 9,777.75730

Timestep Collection Time: 2.39852
Timestep Consumption Time: 2.71881
PPO Batch Consumption Time: 0.32428
Total Iteration Time: 5.11733

Cumulative Model Updates: 325,188
Cumulative Timesteps: 2,712,055,198

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2712055198...
Checkpoint 2712055198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.24340
Policy Entropy: 4.19019
Value Function Loss: 0.00324

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02078
Policy Update Magnitude: 0.26989
Value Function Update Magnitude: 0.32458

Collected Steps per Second: 21,208.84390
Overall Steps per Second: 9,831.81101

Timestep Collection Time: 2.35854
Timestep Consumption Time: 2.72923
PPO Batch Consumption Time: 0.32338
Total Iteration Time: 5.08777

Cumulative Model Updates: 325,194
Cumulative Timesteps: 2,712,105,220

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.15099
Policy Entropy: 4.18423
Value Function Loss: 0.00354

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02135
Policy Update Magnitude: 0.26828
Value Function Update Magnitude: 0.34666

Collected Steps per Second: 20,944.13006
Overall Steps per Second: 9,698.72683

Timestep Collection Time: 2.38778
Timestep Consumption Time: 2.76857
PPO Batch Consumption Time: 0.32957
Total Iteration Time: 5.15635

Cumulative Model Updates: 325,200
Cumulative Timesteps: 2,712,155,230

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2712155230...
Checkpoint 2712155230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.18713
Policy Entropy: 4.17238
Value Function Loss: 0.00405

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02224
Policy Update Magnitude: 0.27583
Value Function Update Magnitude: 0.36414

Collected Steps per Second: 20,446.17524
Overall Steps per Second: 9,808.02314

Timestep Collection Time: 2.44574
Timestep Consumption Time: 2.65274
PPO Batch Consumption Time: 0.32472
Total Iteration Time: 5.09848

Cumulative Model Updates: 325,206
Cumulative Timesteps: 2,712,205,236

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.25887
Policy Entropy: 4.16147
Value Function Loss: 0.00344

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02150
Policy Update Magnitude: 0.28285
Value Function Update Magnitude: 0.35048

Collected Steps per Second: 20,695.42999
Overall Steps per Second: 9,692.36450

Timestep Collection Time: 2.41715
Timestep Consumption Time: 2.74402
PPO Batch Consumption Time: 0.32495
Total Iteration Time: 5.16118

Cumulative Model Updates: 325,212
Cumulative Timesteps: 2,712,255,260

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2712255260...
Checkpoint 2712255260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.07998
Policy Entropy: 4.14346
Value Function Loss: 0.00384

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.02472
Policy Update Magnitude: 0.28509
Value Function Update Magnitude: 0.35418

Collected Steps per Second: 20,603.25076
Overall Steps per Second: 9,746.54862

Timestep Collection Time: 2.42787
Timestep Consumption Time: 2.70441
PPO Batch Consumption Time: 0.32523
Total Iteration Time: 5.13228

Cumulative Model Updates: 325,218
Cumulative Timesteps: 2,712,305,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.03327
Policy Entropy: 4.15935
Value Function Loss: 0.00320

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.02282
Policy Update Magnitude: 0.27950
Value Function Update Magnitude: 0.36903

Collected Steps per Second: 20,674.38912
Overall Steps per Second: 9,898.79107

Timestep Collection Time: 2.41961
Timestep Consumption Time: 2.63393
PPO Batch Consumption Time: 0.32487
Total Iteration Time: 5.05355

Cumulative Model Updates: 325,224
Cumulative Timesteps: 2,712,355,306

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2712355306...
Checkpoint 2712355306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.93570
Policy Entropy: 4.18127
Value Function Loss: 0.00309

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02196
Policy Update Magnitude: 0.26476
Value Function Update Magnitude: 0.34236

Collected Steps per Second: 20,579.84199
Overall Steps per Second: 9,583.98839

Timestep Collection Time: 2.42956
Timestep Consumption Time: 2.78747
PPO Batch Consumption Time: 0.34052
Total Iteration Time: 5.21703

Cumulative Model Updates: 325,230
Cumulative Timesteps: 2,712,405,306

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.43613
Policy Entropy: 4.20391
Value Function Loss: 0.00235

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02246
Policy Update Magnitude: 0.25383
Value Function Update Magnitude: 0.29465

Collected Steps per Second: 20,632.23852
Overall Steps per Second: 9,638.03249

Timestep Collection Time: 2.42417
Timestep Consumption Time: 2.76527
PPO Batch Consumption Time: 0.33640
Total Iteration Time: 5.18944

Cumulative Model Updates: 325,236
Cumulative Timesteps: 2,712,455,322

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2712455322...
Checkpoint 2712455322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.85092
Policy Entropy: 4.20567
Value Function Loss: 0.00248

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02197
Policy Update Magnitude: 0.23708
Value Function Update Magnitude: 0.29612

Collected Steps per Second: 21,050.22214
Overall Steps per Second: 9,791.74998

Timestep Collection Time: 2.37575
Timestep Consumption Time: 2.73161
PPO Batch Consumption Time: 0.32553
Total Iteration Time: 5.10736

Cumulative Model Updates: 325,242
Cumulative Timesteps: 2,712,505,332

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.25198
Policy Entropy: 4.19097
Value Function Loss: 0.00271

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.01953
Policy Update Magnitude: 0.24253
Value Function Update Magnitude: 0.32310

Collected Steps per Second: 20,686.11568
Overall Steps per Second: 9,700.21708

Timestep Collection Time: 2.41921
Timestep Consumption Time: 2.73985
PPO Batch Consumption Time: 0.32715
Total Iteration Time: 5.15906

Cumulative Model Updates: 325,248
Cumulative Timesteps: 2,712,555,376

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2712555376...
Checkpoint 2712555376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.44961
Policy Entropy: 4.18456
Value Function Loss: 0.00315

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02185
Policy Update Magnitude: 0.24944
Value Function Update Magnitude: 0.32399

Collected Steps per Second: 20,610.45106
Overall Steps per Second: 9,676.12500

Timestep Collection Time: 2.42595
Timestep Consumption Time: 2.74140
PPO Batch Consumption Time: 0.32597
Total Iteration Time: 5.16736

Cumulative Model Updates: 325,254
Cumulative Timesteps: 2,712,605,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.19430
Policy Entropy: 4.18819
Value Function Loss: 0.00344

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.02395
Policy Update Magnitude: 0.26030
Value Function Update Magnitude: 0.32017

Collected Steps per Second: 21,306.09423
Overall Steps per Second: 9,787.23942

Timestep Collection Time: 2.34862
Timestep Consumption Time: 2.76416
PPO Batch Consumption Time: 0.32905
Total Iteration Time: 5.11278

Cumulative Model Updates: 325,260
Cumulative Timesteps: 2,712,655,416

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2712655416...
Checkpoint 2712655416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.04568
Policy Entropy: 4.17621
Value Function Loss: 0.00411

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02204
Policy Update Magnitude: 0.26855
Value Function Update Magnitude: 0.32924

Collected Steps per Second: 20,529.86767
Overall Steps per Second: 9,621.01143

Timestep Collection Time: 2.43548
Timestep Consumption Time: 2.76148
PPO Batch Consumption Time: 0.33032
Total Iteration Time: 5.19696

Cumulative Model Updates: 325,266
Cumulative Timesteps: 2,712,705,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.82887
Policy Entropy: 4.18492
Value Function Loss: 0.00364

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02358
Policy Update Magnitude: 0.26608
Value Function Update Magnitude: 0.34977

Collected Steps per Second: 20,579.08693
Overall Steps per Second: 9,803.52390

Timestep Collection Time: 2.42994
Timestep Consumption Time: 2.67088
PPO Batch Consumption Time: 0.33024
Total Iteration Time: 5.10082

Cumulative Model Updates: 325,272
Cumulative Timesteps: 2,712,755,422

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2712755422...
Checkpoint 2712755422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.80489
Policy Entropy: 4.18634
Value Function Loss: 0.00365

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02392
Policy Update Magnitude: 0.25233
Value Function Update Magnitude: 0.33101

Collected Steps per Second: 20,500.87812
Overall Steps per Second: 9,678.66986

Timestep Collection Time: 2.44009
Timestep Consumption Time: 2.72839
PPO Batch Consumption Time: 0.32678
Total Iteration Time: 5.16848

Cumulative Model Updates: 325,278
Cumulative Timesteps: 2,712,805,446

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.24709
Policy Entropy: 4.21993
Value Function Loss: 0.00323

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.01645
Policy Update Magnitude: 0.23893
Value Function Update Magnitude: 0.31223

Collected Steps per Second: 20,698.68704
Overall Steps per Second: 9,727.94883

Timestep Collection Time: 2.41658
Timestep Consumption Time: 2.72531
PPO Batch Consumption Time: 0.32774
Total Iteration Time: 5.14189

Cumulative Model Updates: 325,284
Cumulative Timesteps: 2,712,855,466

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2712855466...
Checkpoint 2712855466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.63563
Policy Entropy: 4.19164
Value Function Loss: 0.00311

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01686
Policy Update Magnitude: 0.23550
Value Function Update Magnitude: 0.30547

Collected Steps per Second: 20,987.53223
Overall Steps per Second: 9,706.88244

Timestep Collection Time: 2.38237
Timestep Consumption Time: 2.76862
PPO Batch Consumption Time: 0.32836
Total Iteration Time: 5.15098

Cumulative Model Updates: 325,290
Cumulative Timesteps: 2,712,905,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.61324
Policy Entropy: 4.18303
Value Function Loss: 0.00277

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.01848
Policy Update Magnitude: 0.24354
Value Function Update Magnitude: 0.31049

Collected Steps per Second: 20,802.41214
Overall Steps per Second: 9,710.39247

Timestep Collection Time: 2.40511
Timestep Consumption Time: 2.74731
PPO Batch Consumption Time: 0.32443
Total Iteration Time: 5.15242

Cumulative Model Updates: 325,296
Cumulative Timesteps: 2,712,955,498

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2712955498...
Checkpoint 2712955498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.75993
Policy Entropy: 4.19410
Value Function Loss: 0.00338

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02009
Policy Update Magnitude: 0.25756
Value Function Update Magnitude: 0.30159

Collected Steps per Second: 20,283.33466
Overall Steps per Second: 9,517.76130

Timestep Collection Time: 2.46508
Timestep Consumption Time: 2.78826
PPO Batch Consumption Time: 0.33794
Total Iteration Time: 5.25334

Cumulative Model Updates: 325,302
Cumulative Timesteps: 2,713,005,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.48520
Policy Entropy: 4.22195
Value Function Loss: 0.00312

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.01902
Policy Update Magnitude: 0.25119
Value Function Update Magnitude: 0.30057

Collected Steps per Second: 21,283.66294
Overall Steps per Second: 9,794.13650

Timestep Collection Time: 2.34978
Timestep Consumption Time: 2.75654
PPO Batch Consumption Time: 0.33240
Total Iteration Time: 5.10632

Cumulative Model Updates: 325,308
Cumulative Timesteps: 2,713,055,510

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2713055510...
Checkpoint 2713055510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.43790
Policy Entropy: 4.21178
Value Function Loss: 0.00292

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.01752
Policy Update Magnitude: 0.24278
Value Function Update Magnitude: 0.28956

Collected Steps per Second: 20,479.36098
Overall Steps per Second: 9,592.51743

Timestep Collection Time: 2.44275
Timestep Consumption Time: 2.77235
PPO Batch Consumption Time: 0.32773
Total Iteration Time: 5.21511

Cumulative Model Updates: 325,314
Cumulative Timesteps: 2,713,105,536

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.42987
Policy Entropy: 4.18004
Value Function Loss: 0.00269

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.01822
Policy Update Magnitude: 0.24884
Value Function Update Magnitude: 0.27979

Collected Steps per Second: 20,871.43630
Overall Steps per Second: 9,849.33193

Timestep Collection Time: 2.39619
Timestep Consumption Time: 2.68151
PPO Batch Consumption Time: 0.33268
Total Iteration Time: 5.07770

Cumulative Model Updates: 325,320
Cumulative Timesteps: 2,713,155,548

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2713155548...
Checkpoint 2713155548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.53005
Policy Entropy: 4.14122
Value Function Loss: 0.00301

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02288
Policy Update Magnitude: 0.25917
Value Function Update Magnitude: 0.29584

Collected Steps per Second: 20,450.58669
Overall Steps per Second: 9,641.14361

Timestep Collection Time: 2.44590
Timestep Consumption Time: 2.74229
PPO Batch Consumption Time: 0.32578
Total Iteration Time: 5.18818

Cumulative Model Updates: 325,326
Cumulative Timesteps: 2,713,205,568

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.41450
Policy Entropy: 4.16035
Value Function Loss: 0.00283

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02300
Policy Update Magnitude: 0.25445
Value Function Update Magnitude: 0.31374

Collected Steps per Second: 20,969.42085
Overall Steps per Second: 9,752.28335

Timestep Collection Time: 2.38509
Timestep Consumption Time: 2.74335
PPO Batch Consumption Time: 0.33035
Total Iteration Time: 5.12844

Cumulative Model Updates: 325,332
Cumulative Timesteps: 2,713,255,582

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2713255582...
Checkpoint 2713255582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.06693
Policy Entropy: 4.17490
Value Function Loss: 0.00296

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02047
Policy Update Magnitude: 0.25543
Value Function Update Magnitude: 0.31522

Collected Steps per Second: 20,296.85355
Overall Steps per Second: 9,747.95574

Timestep Collection Time: 2.46472
Timestep Consumption Time: 2.66723
PPO Batch Consumption Time: 0.32690
Total Iteration Time: 5.13195

Cumulative Model Updates: 325,338
Cumulative Timesteps: 2,713,305,608

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.76675
Policy Entropy: 4.22467
Value Function Loss: 0.00246

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.01972
Policy Update Magnitude: 0.23479
Value Function Update Magnitude: 0.30444

Collected Steps per Second: 20,338.47564
Overall Steps per Second: 9,590.61434

Timestep Collection Time: 2.45849
Timestep Consumption Time: 2.75515
PPO Batch Consumption Time: 0.32748
Total Iteration Time: 5.21364

Cumulative Model Updates: 325,344
Cumulative Timesteps: 2,713,355,610

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2713355610...
Checkpoint 2713355610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.21876
Policy Entropy: 4.20041
Value Function Loss: 0.00309

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.01826
Policy Update Magnitude: 0.23184
Value Function Update Magnitude: 0.29668

Collected Steps per Second: 20,759.15309
Overall Steps per Second: 9,891.30798

Timestep Collection Time: 2.40858
Timestep Consumption Time: 2.64637
PPO Batch Consumption Time: 0.32494
Total Iteration Time: 5.05494

Cumulative Model Updates: 325,350
Cumulative Timesteps: 2,713,405,610

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.08151
Policy Entropy: 4.19132
Value Function Loss: 0.00276

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.01649
Policy Update Magnitude: 0.24475
Value Function Update Magnitude: 0.31763

Collected Steps per Second: 20,803.95072
Overall Steps per Second: 9,647.93469

Timestep Collection Time: 2.40377
Timestep Consumption Time: 2.77951
PPO Batch Consumption Time: 0.33464
Total Iteration Time: 5.18329

Cumulative Model Updates: 325,356
Cumulative Timesteps: 2,713,455,618

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2713455618...
Checkpoint 2713455618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.50906
Policy Entropy: 4.15058
Value Function Loss: 0.00276

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02067
Policy Update Magnitude: 0.24969
Value Function Update Magnitude: 0.32674

Collected Steps per Second: 20,292.08067
Overall Steps per Second: 9,698.33001

Timestep Collection Time: 2.46461
Timestep Consumption Time: 2.69216
PPO Batch Consumption Time: 0.32451
Total Iteration Time: 5.15676

Cumulative Model Updates: 325,362
Cumulative Timesteps: 2,713,505,630

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.04015
Policy Entropy: 4.18854
Value Function Loss: 0.00200

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.01826
Policy Update Magnitude: 0.24072
Value Function Update Magnitude: 0.31195

Collected Steps per Second: 20,741.00288
Overall Steps per Second: 9,821.72667

Timestep Collection Time: 2.41203
Timestep Consumption Time: 2.68157
PPO Batch Consumption Time: 0.32844
Total Iteration Time: 5.09361

Cumulative Model Updates: 325,368
Cumulative Timesteps: 2,713,555,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2713555658...
Checkpoint 2713555658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.45090
Policy Entropy: 4.22148
Value Function Loss: 0.00167

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.01527
Policy Update Magnitude: 0.21179
Value Function Update Magnitude: 0.26866

Collected Steps per Second: 20,798.15821
Overall Steps per Second: 9,720.39959

Timestep Collection Time: 2.40541
Timestep Consumption Time: 2.74130
PPO Batch Consumption Time: 0.32691
Total Iteration Time: 5.14670

Cumulative Model Updates: 325,374
Cumulative Timesteps: 2,713,605,686

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.08648
Policy Entropy: 4.24818
Value Function Loss: 0.00216

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01399
Policy Update Magnitude: 0.20244
Value Function Update Magnitude: 0.24968

Collected Steps per Second: 20,706.40078
Overall Steps per Second: 9,771.41737

Timestep Collection Time: 2.41529
Timestep Consumption Time: 2.70290
PPO Batch Consumption Time: 0.33291
Total Iteration Time: 5.11819

Cumulative Model Updates: 325,380
Cumulative Timesteps: 2,713,655,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2713655698...
Checkpoint 2713655698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.18237
Policy Entropy: 4.24379
Value Function Loss: 0.00244

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.01460
Policy Update Magnitude: 0.21198
Value Function Update Magnitude: 0.26822

Collected Steps per Second: 20,585.92214
Overall Steps per Second: 9,684.47994

Timestep Collection Time: 2.43098
Timestep Consumption Time: 2.73646
PPO Batch Consumption Time: 0.32654
Total Iteration Time: 5.16744

Cumulative Model Updates: 325,386
Cumulative Timesteps: 2,713,705,742

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.95441
Policy Entropy: 4.22405
Value Function Loss: 0.00305

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.01431
Policy Update Magnitude: 0.23445
Value Function Update Magnitude: 0.29067

Collected Steps per Second: 20,804.63816
Overall Steps per Second: 9,712.00023

Timestep Collection Time: 2.40437
Timestep Consumption Time: 2.74617
PPO Batch Consumption Time: 0.32779
Total Iteration Time: 5.15054

Cumulative Model Updates: 325,392
Cumulative Timesteps: 2,713,755,764

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2713755764...
Checkpoint 2713755764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.99686
Policy Entropy: 4.20153
Value Function Loss: 0.00288

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.01825
Policy Update Magnitude: 0.24254
Value Function Update Magnitude: 0.32761

Collected Steps per Second: 20,625.32285
Overall Steps per Second: 9,823.55864

Timestep Collection Time: 2.42566
Timestep Consumption Time: 2.66720
PPO Batch Consumption Time: 0.33017
Total Iteration Time: 5.09286

Cumulative Model Updates: 325,398
Cumulative Timesteps: 2,713,805,794

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.55746
Policy Entropy: 4.21843
Value Function Loss: 0.00240

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.01901
Policy Update Magnitude: 0.23777
Value Function Update Magnitude: 0.33388

Collected Steps per Second: 20,552.53928
Overall Steps per Second: 9,643.21511

Timestep Collection Time: 2.43435
Timestep Consumption Time: 2.75396
PPO Batch Consumption Time: 0.32841
Total Iteration Time: 5.18831

Cumulative Model Updates: 325,404
Cumulative Timesteps: 2,713,855,826

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2713855826...
Checkpoint 2713855826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.07229
Policy Entropy: 4.20527
Value Function Loss: 0.00266

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.01859
Policy Update Magnitude: 0.24291
Value Function Update Magnitude: 0.31360

Collected Steps per Second: 20,490.79742
Overall Steps per Second: 9,717.76301

Timestep Collection Time: 2.44061
Timestep Consumption Time: 2.70564
PPO Batch Consumption Time: 0.32472
Total Iteration Time: 5.14625

Cumulative Model Updates: 325,410
Cumulative Timesteps: 2,713,905,836

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.36145
Policy Entropy: 4.21656
Value Function Loss: 0.00265

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.01770
Policy Update Magnitude: 0.24865
Value Function Update Magnitude: 0.29768

Collected Steps per Second: 21,842.15602
Overall Steps per Second: 9,981.18253

Timestep Collection Time: 2.29025
Timestep Consumption Time: 2.72158
PPO Batch Consumption Time: 0.32505
Total Iteration Time: 5.01183

Cumulative Model Updates: 325,416
Cumulative Timesteps: 2,713,955,860

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2713955860...
Checkpoint 2713955860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.32025
Policy Entropy: 4.19862
Value Function Loss: 0.00312

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.01943
Policy Update Magnitude: 0.24101
Value Function Update Magnitude: 0.29732

Collected Steps per Second: 20,582.96650
Overall Steps per Second: 9,541.27959

Timestep Collection Time: 2.43007
Timestep Consumption Time: 2.81221
PPO Batch Consumption Time: 0.33989
Total Iteration Time: 5.24227

Cumulative Model Updates: 325,422
Cumulative Timesteps: 2,714,005,878

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.17172
Policy Entropy: 4.22563
Value Function Loss: 0.00303

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01665
Policy Update Magnitude: 0.23458
Value Function Update Magnitude: 0.28028

Collected Steps per Second: 20,833.60496
Overall Steps per Second: 9,858.14649

Timestep Collection Time: 2.40064
Timestep Consumption Time: 2.67273
PPO Batch Consumption Time: 0.33049
Total Iteration Time: 5.07337

Cumulative Model Updates: 325,428
Cumulative Timesteps: 2,714,055,892

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2714055892...
Checkpoint 2714055892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.34154
Policy Entropy: 4.19976
Value Function Loss: 0.00355

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.01839
Policy Update Magnitude: 0.23783
Value Function Update Magnitude: 0.28194

Collected Steps per Second: 20,469.36601
Overall Steps per Second: 9,636.38738

Timestep Collection Time: 2.44297
Timestep Consumption Time: 2.74632
PPO Batch Consumption Time: 0.32627
Total Iteration Time: 5.18929

Cumulative Model Updates: 325,434
Cumulative Timesteps: 2,714,105,898

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.02182
Policy Entropy: 4.20962
Value Function Loss: 0.00281

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.01851
Policy Update Magnitude: 0.24180
Value Function Update Magnitude: 0.29586

Collected Steps per Second: 20,711.32621
Overall Steps per Second: 9,650.25828

Timestep Collection Time: 2.41559
Timestep Consumption Time: 2.76873
PPO Batch Consumption Time: 0.33301
Total Iteration Time: 5.18432

Cumulative Model Updates: 325,440
Cumulative Timesteps: 2,714,155,928

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2714155928...
Checkpoint 2714155928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.49255
Policy Entropy: 4.23217
Value Function Loss: 0.00248

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.01817
Policy Update Magnitude: 0.21968
Value Function Update Magnitude: 0.27611

Collected Steps per Second: 20,359.20323
Overall Steps per Second: 9,740.14599

Timestep Collection Time: 2.45786
Timestep Consumption Time: 2.67964
PPO Batch Consumption Time: 0.32806
Total Iteration Time: 5.13750

Cumulative Model Updates: 325,446
Cumulative Timesteps: 2,714,205,968

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.37743
Policy Entropy: 4.27432
Value Function Loss: 0.00191

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01353
Policy Update Magnitude: 0.19363
Value Function Update Magnitude: 0.23592

Collected Steps per Second: 20,879.41900
Overall Steps per Second: 9,737.41457

Timestep Collection Time: 2.39671
Timestep Consumption Time: 2.74243
PPO Batch Consumption Time: 0.32641
Total Iteration Time: 5.13915

Cumulative Model Updates: 325,452
Cumulative Timesteps: 2,714,256,010

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2714256010...
Checkpoint 2714256010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.66830
Policy Entropy: 4.26970
Value Function Loss: 0.00224

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01117
Policy Update Magnitude: 0.19594
Value Function Update Magnitude: 0.21736

Collected Steps per Second: 20,505.34467
Overall Steps per Second: 9,691.06846

Timestep Collection Time: 2.43849
Timestep Consumption Time: 2.72111
PPO Batch Consumption Time: 0.32489
Total Iteration Time: 5.15960

Cumulative Model Updates: 325,458
Cumulative Timesteps: 2,714,306,012

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.30468
Policy Entropy: 4.25394
Value Function Loss: 0.00254

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01469
Policy Update Magnitude: 0.21144
Value Function Update Magnitude: 0.26150

Collected Steps per Second: 21,414.30889
Overall Steps per Second: 9,797.34160

Timestep Collection Time: 2.33489
Timestep Consumption Time: 2.76854
PPO Batch Consumption Time: 0.33008
Total Iteration Time: 5.10343

Cumulative Model Updates: 325,464
Cumulative Timesteps: 2,714,356,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2714356012...
Checkpoint 2714356012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.33241
Policy Entropy: 4.21537
Value Function Loss: 0.00310

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.01634
Policy Update Magnitude: 0.23519
Value Function Update Magnitude: 0.29459

Collected Steps per Second: 20,585.20455
Overall Steps per Second: 9,702.84400

Timestep Collection Time: 2.43048
Timestep Consumption Time: 2.72594
PPO Batch Consumption Time: 0.32526
Total Iteration Time: 5.15643

Cumulative Model Updates: 325,470
Cumulative Timesteps: 2,714,406,044

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.71305
Policy Entropy: 4.21021
Value Function Loss: 0.00334

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.01889
Policy Update Magnitude: 0.24947
Value Function Update Magnitude: 0.31208

Collected Steps per Second: 20,604.54241
Overall Steps per Second: 9,717.69502

Timestep Collection Time: 2.42801
Timestep Consumption Time: 2.72013
PPO Batch Consumption Time: 0.32498
Total Iteration Time: 5.14813

Cumulative Model Updates: 325,476
Cumulative Timesteps: 2,714,456,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2714456072...
Checkpoint 2714456072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.16634
Policy Entropy: 4.19678
Value Function Loss: 0.00351

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02087
Policy Update Magnitude: 0.25309
Value Function Update Magnitude: 0.33745

Collected Steps per Second: 20,909.76155
Overall Steps per Second: 9,712.14547

Timestep Collection Time: 2.39132
Timestep Consumption Time: 2.75708
PPO Batch Consumption Time: 0.32616
Total Iteration Time: 5.14840

Cumulative Model Updates: 325,482
Cumulative Timesteps: 2,714,506,074

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.03481
Policy Entropy: 4.22195
Value Function Loss: 0.00289

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.01794
Policy Update Magnitude: 0.25633
Value Function Update Magnitude: 0.34047

Collected Steps per Second: 20,652.83596
Overall Steps per Second: 9,628.16721

Timestep Collection Time: 2.42117
Timestep Consumption Time: 2.77234
PPO Batch Consumption Time: 0.32992
Total Iteration Time: 5.19351

Cumulative Model Updates: 325,488
Cumulative Timesteps: 2,714,556,078

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2714556078...
Checkpoint 2714556078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.85374
Policy Entropy: 4.22334
Value Function Loss: 0.00255

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.01918
Policy Update Magnitude: 0.25587
Value Function Update Magnitude: 0.32191

Collected Steps per Second: 20,607.71714
Overall Steps per Second: 9,773.73058

Timestep Collection Time: 2.42734
Timestep Consumption Time: 2.69066
PPO Batch Consumption Time: 0.32930
Total Iteration Time: 5.11800

Cumulative Model Updates: 325,494
Cumulative Timesteps: 2,714,606,100

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.87792
Policy Entropy: 4.20981
Value Function Loss: 0.00310

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.01876
Policy Update Magnitude: 0.25781
Value Function Update Magnitude: 0.31163

Collected Steps per Second: 20,540.70176
Overall Steps per Second: 9,617.77080

Timestep Collection Time: 2.43546
Timestep Consumption Time: 2.76596
PPO Batch Consumption Time: 0.32867
Total Iteration Time: 5.20141

Cumulative Model Updates: 325,500
Cumulative Timesteps: 2,714,656,126

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2714656126...
Checkpoint 2714656126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.25839
Policy Entropy: 4.20311
Value Function Loss: 0.00295

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.02151
Policy Update Magnitude: 0.26414
Value Function Update Magnitude: 0.32186

Collected Steps per Second: 20,523.65515
Overall Steps per Second: 9,664.25933

Timestep Collection Time: 2.43758
Timestep Consumption Time: 2.73902
PPO Batch Consumption Time: 0.32739
Total Iteration Time: 5.17660

Cumulative Model Updates: 325,506
Cumulative Timesteps: 2,714,706,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.56837
Policy Entropy: 4.21566
Value Function Loss: 0.00297

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.02274
Policy Update Magnitude: 0.25626
Value Function Update Magnitude: 0.30948

Collected Steps per Second: 20,571.96801
Overall Steps per Second: 9,820.31155

Timestep Collection Time: 2.43088
Timestep Consumption Time: 2.66142
PPO Batch Consumption Time: 0.32574
Total Iteration Time: 5.09230

Cumulative Model Updates: 325,512
Cumulative Timesteps: 2,714,756,162

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2714756162...
Checkpoint 2714756162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.58628
Policy Entropy: 4.23879
Value Function Loss: 0.00241

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.01897
Policy Update Magnitude: 0.22736
Value Function Update Magnitude: 0.29931

Collected Steps per Second: 20,786.74415
Overall Steps per Second: 9,684.00743

Timestep Collection Time: 2.40663
Timestep Consumption Time: 2.75921
PPO Batch Consumption Time: 0.32956
Total Iteration Time: 5.16584

Cumulative Model Updates: 325,518
Cumulative Timesteps: 2,714,806,188

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.21698
Policy Entropy: 4.23513
Value Function Loss: 0.00273

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.01494
Policy Update Magnitude: 0.22082
Value Function Update Magnitude: 0.28586

Collected Steps per Second: 20,178.03244
Overall Steps per Second: 9,669.41643

Timestep Collection Time: 2.47854
Timestep Consumption Time: 2.69365
PPO Batch Consumption Time: 0.33427
Total Iteration Time: 5.17218

Cumulative Model Updates: 325,524
Cumulative Timesteps: 2,714,856,200

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2714856200...
Checkpoint 2714856200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.98305
Policy Entropy: 4.20782
Value Function Loss: 0.00276

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.01739
Policy Update Magnitude: 0.23152
Value Function Update Magnitude: 0.28992

Collected Steps per Second: 20,732.72115
Overall Steps per Second: 9,668.75514

Timestep Collection Time: 2.41213
Timestep Consumption Time: 2.76020
PPO Batch Consumption Time: 0.32962
Total Iteration Time: 5.17233

Cumulative Model Updates: 325,530
Cumulative Timesteps: 2,714,906,210

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.36562
Policy Entropy: 4.17290
Value Function Loss: 0.00330

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.01916
Policy Update Magnitude: 0.23698
Value Function Update Magnitude: 0.30092

Collected Steps per Second: 20,457.85052
Overall Steps per Second: 9,693.02721

Timestep Collection Time: 2.44542
Timestep Consumption Time: 2.71582
PPO Batch Consumption Time: 0.32795
Total Iteration Time: 5.16124

Cumulative Model Updates: 325,536
Cumulative Timesteps: 2,714,956,238

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2714956238...
Checkpoint 2714956238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.38757
Policy Entropy: 4.16905
Value Function Loss: 0.00349

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02140
Policy Update Magnitude: 0.24534
Value Function Update Magnitude: 0.29439

Collected Steps per Second: 20,474.68607
Overall Steps per Second: 9,806.09265

Timestep Collection Time: 2.44302
Timestep Consumption Time: 2.65789
PPO Batch Consumption Time: 0.32565
Total Iteration Time: 5.10091

Cumulative Model Updates: 325,542
Cumulative Timesteps: 2,715,006,258

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.89188
Policy Entropy: 4.18450
Value Function Loss: 0.00310

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02159
Policy Update Magnitude: 0.25042
Value Function Update Magnitude: 0.29630

Collected Steps per Second: 20,781.76229
Overall Steps per Second: 9,636.74796

Timestep Collection Time: 2.40740
Timestep Consumption Time: 2.78419
PPO Batch Consumption Time: 0.33704
Total Iteration Time: 5.19159

Cumulative Model Updates: 325,548
Cumulative Timesteps: 2,715,056,288

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2715056288...
Checkpoint 2715056288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.53036
Policy Entropy: 4.16440
Value Function Loss: 0.00316

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.01873
Policy Update Magnitude: 0.24427
Value Function Update Magnitude: 0.29972

Collected Steps per Second: 20,446.10068
Overall Steps per Second: 9,737.72988

Timestep Collection Time: 2.44673
Timestep Consumption Time: 2.69061
PPO Batch Consumption Time: 0.32403
Total Iteration Time: 5.13734

Cumulative Model Updates: 325,554
Cumulative Timesteps: 2,715,106,314

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.40287
Policy Entropy: 4.16019
Value Function Loss: 0.00320

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.01898
Policy Update Magnitude: 0.26039
Value Function Update Magnitude: 0.29544

Collected Steps per Second: 21,281.90221
Overall Steps per Second: 9,780.05879

Timestep Collection Time: 2.34960
Timestep Consumption Time: 2.76325
PPO Batch Consumption Time: 0.32863
Total Iteration Time: 5.11285

Cumulative Model Updates: 325,560
Cumulative Timesteps: 2,715,156,318

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2715156318...
Checkpoint 2715156318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.48301
Policy Entropy: 4.13106
Value Function Loss: 0.00354

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02312
Policy Update Magnitude: 0.27252
Value Function Update Magnitude: 0.32474

Collected Steps per Second: 20,409.39792
Overall Steps per Second: 9,652.66981

Timestep Collection Time: 2.45132
Timestep Consumption Time: 2.73170
PPO Batch Consumption Time: 0.32655
Total Iteration Time: 5.18302

Cumulative Model Updates: 325,566
Cumulative Timesteps: 2,715,206,348

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.20924
Policy Entropy: 4.15528
Value Function Loss: 0.00337

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02046
Policy Update Magnitude: 0.28160
Value Function Update Magnitude: 0.35476

Collected Steps per Second: 20,734.93255
Overall Steps per Second: 9,692.11316

Timestep Collection Time: 2.41284
Timestep Consumption Time: 2.74909
PPO Batch Consumption Time: 0.32449
Total Iteration Time: 5.16193

Cumulative Model Updates: 325,572
Cumulative Timesteps: 2,715,256,378

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2715256378...
Checkpoint 2715256378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.65959
Policy Entropy: 4.17400
Value Function Loss: 0.00318

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.02328
Policy Update Magnitude: 0.27413
Value Function Update Magnitude: 0.38271

Collected Steps per Second: 21,279.39976
Overall Steps per Second: 9,812.87792

Timestep Collection Time: 2.34997
Timestep Consumption Time: 2.74598
PPO Batch Consumption Time: 0.32742
Total Iteration Time: 5.09596

Cumulative Model Updates: 325,578
Cumulative Timesteps: 2,715,306,384

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.54145
Policy Entropy: 4.20423
Value Function Loss: 0.00246

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02305
Policy Update Magnitude: 0.24703
Value Function Update Magnitude: 0.36631

Collected Steps per Second: 21,019.58211
Overall Steps per Second: 9,758.14879

Timestep Collection Time: 2.37959
Timestep Consumption Time: 2.74618
PPO Batch Consumption Time: 0.32768
Total Iteration Time: 5.12577

Cumulative Model Updates: 325,584
Cumulative Timesteps: 2,715,356,402

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2715356402...
Checkpoint 2715356402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.72171
Policy Entropy: 4.22246
Value Function Loss: 0.00196

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02295
Policy Update Magnitude: 0.22117
Value Function Update Magnitude: 0.32152

Collected Steps per Second: 20,434.30123
Overall Steps per Second: 9,661.11388

Timestep Collection Time: 2.44706
Timestep Consumption Time: 2.72874
PPO Batch Consumption Time: 0.32828
Total Iteration Time: 5.17580

Cumulative Model Updates: 325,590
Cumulative Timesteps: 2,715,406,406

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.79613
Policy Entropy: 4.22218
Value Function Loss: 0.00209

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.01893
Policy Update Magnitude: 0.21079
Value Function Update Magnitude: 0.27148

Collected Steps per Second: 21,449.80843
Overall Steps per Second: 9,788.12071

Timestep Collection Time: 2.33205
Timestep Consumption Time: 2.77843
PPO Batch Consumption Time: 0.33136
Total Iteration Time: 5.11048

Cumulative Model Updates: 325,596
Cumulative Timesteps: 2,715,456,428

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2715456428...
Checkpoint 2715456428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.44841
Policy Entropy: 4.19889
Value Function Loss: 0.00252

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.01629
Policy Update Magnitude: 0.23599
Value Function Update Magnitude: 0.26751

Collected Steps per Second: 20,445.56850
Overall Steps per Second: 9,651.57557

Timestep Collection Time: 2.44591
Timestep Consumption Time: 2.73542
PPO Batch Consumption Time: 0.32485
Total Iteration Time: 5.18133

Cumulative Model Updates: 325,602
Cumulative Timesteps: 2,715,506,436

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.60399
Policy Entropy: 4.16709
Value Function Loss: 0.00384

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02154
Policy Update Magnitude: 0.26432
Value Function Update Magnitude: 0.29610

Collected Steps per Second: 20,530.37767
Overall Steps per Second: 9,771.87829

Timestep Collection Time: 2.43658
Timestep Consumption Time: 2.68260
PPO Batch Consumption Time: 0.33040
Total Iteration Time: 5.11918

Cumulative Model Updates: 325,608
Cumulative Timesteps: 2,715,556,460

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2715556460...
Checkpoint 2715556460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.93697
Policy Entropy: 4.16309
Value Function Loss: 0.00401

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.02428
Policy Update Magnitude: 0.27573
Value Function Update Magnitude: 0.32378

Collected Steps per Second: 20,531.84178
Overall Steps per Second: 9,715.00465

Timestep Collection Time: 2.43592
Timestep Consumption Time: 2.71220
PPO Batch Consumption Time: 0.32462
Total Iteration Time: 5.14812

Cumulative Model Updates: 325,614
Cumulative Timesteps: 2,715,606,474

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.80145
Policy Entropy: 4.17407
Value Function Loss: 0.00399

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.02521
Policy Update Magnitude: 0.27154
Value Function Update Magnitude: 0.34621

Collected Steps per Second: 20,652.65871
Overall Steps per Second: 9,693.75245

Timestep Collection Time: 2.42100
Timestep Consumption Time: 2.73697
PPO Batch Consumption Time: 0.32643
Total Iteration Time: 5.15796

Cumulative Model Updates: 325,620
Cumulative Timesteps: 2,715,656,474

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2715656474...
Checkpoint 2715656474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.99957
Policy Entropy: 4.18485
Value Function Loss: 0.00327

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02220
Policy Update Magnitude: 0.25635
Value Function Update Magnitude: 0.34096

Collected Steps per Second: 20,598.65304
Overall Steps per Second: 9,832.60456

Timestep Collection Time: 2.42861
Timestep Consumption Time: 2.65916
PPO Batch Consumption Time: 0.32736
Total Iteration Time: 5.08777

Cumulative Model Updates: 325,626
Cumulative Timesteps: 2,715,706,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.24527
Policy Entropy: 4.20414
Value Function Loss: 0.00302

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.01935
Policy Update Magnitude: 0.24953
Value Function Update Magnitude: 0.32835

Collected Steps per Second: 20,864.41124
Overall Steps per Second: 9,740.50452

Timestep Collection Time: 2.39700
Timestep Consumption Time: 2.73744
PPO Batch Consumption Time: 0.32470
Total Iteration Time: 5.13444

Cumulative Model Updates: 325,632
Cumulative Timesteps: 2,715,756,512

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2715756512...
Checkpoint 2715756512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.62392
Policy Entropy: 4.19097
Value Function Loss: 0.00306

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02034
Policy Update Magnitude: 0.23748
Value Function Update Magnitude: 0.31629

Collected Steps per Second: 20,654.82194
Overall Steps per Second: 9,731.13139

Timestep Collection Time: 2.42190
Timestep Consumption Time: 2.71871
PPO Batch Consumption Time: 0.32464
Total Iteration Time: 5.14062

Cumulative Model Updates: 325,638
Cumulative Timesteps: 2,715,806,536

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.51073
Policy Entropy: 4.20030
Value Function Loss: 0.00269

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.01726
Policy Update Magnitude: 0.24006
Value Function Update Magnitude: 0.29428

Collected Steps per Second: 21,367.75232
Overall Steps per Second: 9,776.49902

Timestep Collection Time: 2.34072
Timestep Consumption Time: 2.77522
PPO Batch Consumption Time: 0.33660
Total Iteration Time: 5.11594

Cumulative Model Updates: 325,644
Cumulative Timesteps: 2,715,856,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2715856552...
Checkpoint 2715856552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.48349
Policy Entropy: 4.16829
Value Function Loss: 0.00384

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02281
Policy Update Magnitude: 0.26952
Value Function Update Magnitude: 0.29675

Collected Steps per Second: 20,719.40796
Overall Steps per Second: 9,712.47170

Timestep Collection Time: 2.41435
Timestep Consumption Time: 2.73614
PPO Batch Consumption Time: 0.32455
Total Iteration Time: 5.15049

Cumulative Model Updates: 325,650
Cumulative Timesteps: 2,715,906,576

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.42037
Policy Entropy: 4.19235
Value Function Loss: 0.00390

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02180
Policy Update Magnitude: 0.27434
Value Function Update Magnitude: 0.31680

Collected Steps per Second: 20,858.17704
Overall Steps per Second: 9,865.10151

Timestep Collection Time: 2.39724
Timestep Consumption Time: 2.67134
PPO Batch Consumption Time: 0.32698
Total Iteration Time: 5.06857

Cumulative Model Updates: 325,656
Cumulative Timesteps: 2,715,956,578

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2715956578...
Checkpoint 2715956578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.21360
Policy Entropy: 4.19775
Value Function Loss: 0.00364

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.01976
Policy Update Magnitude: 0.25992
Value Function Update Magnitude: 0.32063

Collected Steps per Second: 20,407.20341
Overall Steps per Second: 9,613.71646

Timestep Collection Time: 2.45149
Timestep Consumption Time: 2.75233
PPO Batch Consumption Time: 0.32653
Total Iteration Time: 5.20381

Cumulative Model Updates: 325,662
Cumulative Timesteps: 2,716,006,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.93606
Policy Entropy: 4.21820
Value Function Loss: 0.00273

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.01825
Policy Update Magnitude: 0.23701
Value Function Update Magnitude: 0.30749

Collected Steps per Second: 20,656.91927
Overall Steps per Second: 9,608.59478

Timestep Collection Time: 2.42166
Timestep Consumption Time: 2.78451
PPO Batch Consumption Time: 0.33946
Total Iteration Time: 5.20617

Cumulative Model Updates: 325,668
Cumulative Timesteps: 2,716,056,630

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2716056630...
Checkpoint 2716056630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.37707
Policy Entropy: 4.18824
Value Function Loss: 0.00315

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.01803
Policy Update Magnitude: 0.24260
Value Function Update Magnitude: 0.30048

Collected Steps per Second: 20,533.44011
Overall Steps per Second: 9,804.60177

Timestep Collection Time: 2.43632
Timestep Consumption Time: 2.66598
PPO Batch Consumption Time: 0.32695
Total Iteration Time: 5.10230

Cumulative Model Updates: 325,674
Cumulative Timesteps: 2,716,106,656

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.48865
Policy Entropy: 4.19357
Value Function Loss: 0.00289

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02247
Policy Update Magnitude: 0.25896
Value Function Update Magnitude: 0.30256

Collected Steps per Second: 21,096.98855
Overall Steps per Second: 9,689.06702

Timestep Collection Time: 2.37010
Timestep Consumption Time: 2.79056
PPO Batch Consumption Time: 0.33783
Total Iteration Time: 5.16066

Cumulative Model Updates: 325,680
Cumulative Timesteps: 2,716,156,658

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2716156658...
Checkpoint 2716156658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.64596
Policy Entropy: 4.21520
Value Function Loss: 0.00249

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.02369
Policy Update Magnitude: 0.23582
Value Function Update Magnitude: 0.29251

Collected Steps per Second: 20,169.09283
Overall Steps per Second: 9,644.18270

Timestep Collection Time: 2.47904
Timestep Consumption Time: 2.70543
PPO Batch Consumption Time: 0.32833
Total Iteration Time: 5.18447

Cumulative Model Updates: 325,686
Cumulative Timesteps: 2,716,206,658

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.72250
Policy Entropy: 4.25312
Value Function Loss: 0.00134

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.01625
Policy Update Magnitude: 0.20506
Value Function Update Magnitude: 0.26014

Collected Steps per Second: 21,381.71225
Overall Steps per Second: 9,836.73185

Timestep Collection Time: 2.33929
Timestep Consumption Time: 2.74553
PPO Batch Consumption Time: 0.32651
Total Iteration Time: 5.08482

Cumulative Model Updates: 325,692
Cumulative Timesteps: 2,716,256,676

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2716256676...
Checkpoint 2716256676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.39390
Policy Entropy: 4.24797
Value Function Loss: 0.00173

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01419
Policy Update Magnitude: 0.21427
Value Function Update Magnitude: 0.22164

Collected Steps per Second: 20,353.10290
Overall Steps per Second: 9,603.21219

Timestep Collection Time: 2.45741
Timestep Consumption Time: 2.75084
PPO Batch Consumption Time: 0.32870
Total Iteration Time: 5.20826

Cumulative Model Updates: 325,698
Cumulative Timesteps: 2,716,306,692

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.77578
Policy Entropy: 4.20414
Value Function Loss: 0.00278

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.01677
Policy Update Magnitude: 0.24087
Value Function Update Magnitude: 0.25352

Collected Steps per Second: 20,854.04662
Overall Steps per Second: 9,773.52896

Timestep Collection Time: 2.39762
Timestep Consumption Time: 2.71824
PPO Batch Consumption Time: 0.32479
Total Iteration Time: 5.11586

Cumulative Model Updates: 325,704
Cumulative Timesteps: 2,716,356,692

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2716356692...
Checkpoint 2716356692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.06137
Policy Entropy: 4.16011
Value Function Loss: 0.00443

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.02014
Policy Update Magnitude: 0.26852
Value Function Update Magnitude: 0.30439

Collected Steps per Second: 21,010.54821
Overall Steps per Second: 9,765.40608

Timestep Collection Time: 2.38014
Timestep Consumption Time: 2.74080
PPO Batch Consumption Time: 0.32689
Total Iteration Time: 5.12093

Cumulative Model Updates: 325,710
Cumulative Timesteps: 2,716,406,700

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.68382
Policy Entropy: 4.15470
Value Function Loss: 0.00428

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02160
Policy Update Magnitude: 0.28585
Value Function Update Magnitude: 0.34797

Collected Steps per Second: 20,877.66770
Overall Steps per Second: 9,645.40030

Timestep Collection Time: 2.39557
Timestep Consumption Time: 2.78970
PPO Batch Consumption Time: 0.32959
Total Iteration Time: 5.18527

Cumulative Model Updates: 325,716
Cumulative Timesteps: 2,716,456,714

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2716456714...
Checkpoint 2716456714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.74642
Policy Entropy: 4.15587
Value Function Loss: 0.00387

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02233
Policy Update Magnitude: 0.28726
Value Function Update Magnitude: 0.36094

Collected Steps per Second: 20,552.37719
Overall Steps per Second: 9,830.85064

Timestep Collection Time: 2.43359
Timestep Consumption Time: 2.65407
PPO Batch Consumption Time: 0.32714
Total Iteration Time: 5.08766

Cumulative Model Updates: 325,722
Cumulative Timesteps: 2,716,506,730

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.23239
Policy Entropy: 4.15338
Value Function Loss: 0.00392

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.02242
Policy Update Magnitude: 0.28567
Value Function Update Magnitude: 0.37286

Collected Steps per Second: 20,782.75247
Overall Steps per Second: 9,728.36869

Timestep Collection Time: 2.40671
Timestep Consumption Time: 2.73475
PPO Batch Consumption Time: 0.32597
Total Iteration Time: 5.14146

Cumulative Model Updates: 325,728
Cumulative Timesteps: 2,716,556,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2716556748...
Checkpoint 2716556748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.79116
Policy Entropy: 4.17028
Value Function Loss: 0.00356

Mean KL Divergence: 0.02929
SB3 Clip Fraction: 0.02202
Policy Update Magnitude: 0.27702
Value Function Update Magnitude: 0.38096

Collected Steps per Second: 20,589.16263
Overall Steps per Second: 9,712.39291

Timestep Collection Time: 2.42885
Timestep Consumption Time: 2.72004
PPO Batch Consumption Time: 0.32733
Total Iteration Time: 5.14889

Cumulative Model Updates: 325,734
Cumulative Timesteps: 2,716,606,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.72702
Policy Entropy: 4.20145
Value Function Loss: 0.00301

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.01957
Policy Update Magnitude: 0.25475
Value Function Update Magnitude: 0.33940

Collected Steps per Second: 20,901.20482
Overall Steps per Second: 9,768.64354

Timestep Collection Time: 2.39297
Timestep Consumption Time: 2.72708
PPO Batch Consumption Time: 0.33730
Total Iteration Time: 5.12006

Cumulative Model Updates: 325,740
Cumulative Timesteps: 2,716,656,772

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2716656772...
Checkpoint 2716656772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.15067
Policy Entropy: 4.22034
Value Function Loss: 0.00252

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.01576
Policy Update Magnitude: 0.23464
Value Function Update Magnitude: 0.28910

Collected Steps per Second: 20,396.66822
Overall Steps per Second: 9,657.40819

Timestep Collection Time: 2.45217
Timestep Consumption Time: 2.72686
PPO Batch Consumption Time: 0.32597
Total Iteration Time: 5.17903

Cumulative Model Updates: 325,746
Cumulative Timesteps: 2,716,706,788

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.79349
Policy Entropy: 4.23937
Value Function Loss: 0.00220

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.01623
Policy Update Magnitude: 0.23073
Value Function Update Magnitude: 0.27350

Collected Steps per Second: 20,558.82436
Overall Steps per Second: 9,785.71093

Timestep Collection Time: 2.43302
Timestep Consumption Time: 2.67852
PPO Batch Consumption Time: 0.32774
Total Iteration Time: 5.11153

Cumulative Model Updates: 325,752
Cumulative Timesteps: 2,716,756,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2716756808...
Checkpoint 2716756808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.40082
Policy Entropy: 4.22232
Value Function Loss: 0.00194

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.01670
Policy Update Magnitude: 0.21740
Value Function Update Magnitude: 0.28179

Collected Steps per Second: 20,603.01638
Overall Steps per Second: 9,706.99795

Timestep Collection Time: 2.42761
Timestep Consumption Time: 2.72497
PPO Batch Consumption Time: 0.32651
Total Iteration Time: 5.15257

Cumulative Model Updates: 325,758
Cumulative Timesteps: 2,716,806,824

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.51391
Policy Entropy: 4.21016
Value Function Loss: 0.00245

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.01522
Policy Update Magnitude: 0.23153
Value Function Update Magnitude: 0.28054

Collected Steps per Second: 20,699.41948
Overall Steps per Second: 9,632.46878

Timestep Collection Time: 2.41562
Timestep Consumption Time: 2.77536
PPO Batch Consumption Time: 0.33096
Total Iteration Time: 5.19098

Cumulative Model Updates: 325,764
Cumulative Timesteps: 2,716,856,826

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2716856826...
Checkpoint 2716856826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.42163
Policy Entropy: 4.18454
Value Function Loss: 0.00318

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.01782
Policy Update Magnitude: 0.25182
Value Function Update Magnitude: 0.30480

Collected Steps per Second: 20,753.40537
Overall Steps per Second: 9,843.73077

Timestep Collection Time: 2.41040
Timestep Consumption Time: 2.67141
PPO Batch Consumption Time: 0.32826
Total Iteration Time: 5.08181

Cumulative Model Updates: 325,770
Cumulative Timesteps: 2,716,906,850

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.83690
Policy Entropy: 4.18348
Value Function Loss: 0.00320

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02093
Policy Update Magnitude: 0.25435
Value Function Update Magnitude: 0.31229

Collected Steps per Second: 20,904.54705
Overall Steps per Second: 9,709.44936

Timestep Collection Time: 2.39192
Timestep Consumption Time: 2.75791
PPO Batch Consumption Time: 0.32962
Total Iteration Time: 5.14983

Cumulative Model Updates: 325,776
Cumulative Timesteps: 2,716,956,852

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2716956852...
Checkpoint 2716956852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.72230
Policy Entropy: 4.20827
Value Function Loss: 0.00358

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.01775
Policy Update Magnitude: 0.24937
Value Function Update Magnitude: 0.29951

Collected Steps per Second: 20,381.11230
Overall Steps per Second: 9,735.60822

Timestep Collection Time: 2.45463
Timestep Consumption Time: 2.68404
PPO Batch Consumption Time: 0.32409
Total Iteration Time: 5.13866

Cumulative Model Updates: 325,782
Cumulative Timesteps: 2,717,006,880

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.22678
Policy Entropy: 4.23579
Value Function Loss: 0.00274

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.01614
Policy Update Magnitude: 0.23875
Value Function Update Magnitude: 0.29478

Collected Steps per Second: 20,945.43248
Overall Steps per Second: 9,800.91879

Timestep Collection Time: 2.38849
Timestep Consumption Time: 2.71593
PPO Batch Consumption Time: 0.33343
Total Iteration Time: 5.10442

Cumulative Model Updates: 325,788
Cumulative Timesteps: 2,717,056,908

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2717056908...
Checkpoint 2717056908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.82204
Policy Entropy: 4.26857
Value Function Loss: 0.00217

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.01656
Policy Update Magnitude: 0.21873
Value Function Update Magnitude: 0.28473

Collected Steps per Second: 20,602.08079
Overall Steps per Second: 9,598.47389

Timestep Collection Time: 2.42704
Timestep Consumption Time: 2.78233
PPO Batch Consumption Time: 0.33116
Total Iteration Time: 5.20937

Cumulative Model Updates: 325,794
Cumulative Timesteps: 2,717,106,910

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.24976
Policy Entropy: 4.28707
Value Function Loss: 0.00188

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01331
Policy Update Magnitude: 0.19328
Value Function Update Magnitude: 0.24554

Collected Steps per Second: 20,907.88808
Overall Steps per Second: 9,765.21712

Timestep Collection Time: 2.39307
Timestep Consumption Time: 2.73063
PPO Batch Consumption Time: 0.32700
Total Iteration Time: 5.12370

Cumulative Model Updates: 325,800
Cumulative Timesteps: 2,717,156,944

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2717156944...
Checkpoint 2717156944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.91938
Policy Entropy: 4.25124
Value Function Loss: 0.00258

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.01625
Policy Update Magnitude: 0.20942
Value Function Update Magnitude: 0.24669

Collected Steps per Second: 21,014.11445
Overall Steps per Second: 9,762.80919

Timestep Collection Time: 2.37964
Timestep Consumption Time: 2.74245
PPO Batch Consumption Time: 0.32414
Total Iteration Time: 5.12209

Cumulative Model Updates: 325,806
Cumulative Timesteps: 2,717,206,950

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.14819
Policy Entropy: 4.20694
Value Function Loss: 0.00319

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02025
Policy Update Magnitude: 0.24536
Value Function Update Magnitude: 0.26896

Collected Steps per Second: 20,500.74427
Overall Steps per Second: 9,632.96574

Timestep Collection Time: 2.43903
Timestep Consumption Time: 2.75168
PPO Batch Consumption Time: 0.32581
Total Iteration Time: 5.19072

Cumulative Model Updates: 325,812
Cumulative Timesteps: 2,717,256,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2717256952...
Checkpoint 2717256952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.30111
Policy Entropy: 4.21317
Value Function Loss: 0.00258

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02084
Policy Update Magnitude: 0.24809
Value Function Update Magnitude: 0.28418

Collected Steps per Second: 20,438.84769
Overall Steps per Second: 9,531.51800

Timestep Collection Time: 2.44750
Timestep Consumption Time: 2.80078
PPO Batch Consumption Time: 0.34213
Total Iteration Time: 5.24827

Cumulative Model Updates: 325,818
Cumulative Timesteps: 2,717,306,976

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.45191
Policy Entropy: 4.22166
Value Function Loss: 0.00265

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.01908
Policy Update Magnitude: 0.23387
Value Function Update Magnitude: 0.28421

Collected Steps per Second: 21,497.93416
Overall Steps per Second: 9,884.96219

Timestep Collection Time: 2.32618
Timestep Consumption Time: 2.73282
PPO Batch Consumption Time: 0.32875
Total Iteration Time: 5.05900

Cumulative Model Updates: 325,824
Cumulative Timesteps: 2,717,356,984

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2717356984...
Checkpoint 2717356984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.28555
Policy Entropy: 4.22922
Value Function Loss: 0.00271

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.01772
Policy Update Magnitude: 0.23685
Value Function Update Magnitude: 0.27447

Collected Steps per Second: 20,736.06696
Overall Steps per Second: 9,622.26059

Timestep Collection Time: 2.41251
Timestep Consumption Time: 2.78647
PPO Batch Consumption Time: 0.33492
Total Iteration Time: 5.19899

Cumulative Model Updates: 325,830
Cumulative Timesteps: 2,717,407,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.49088
Policy Entropy: 4.22502
Value Function Loss: 0.00276

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.01993
Policy Update Magnitude: 0.24425
Value Function Update Magnitude: 0.26661

Collected Steps per Second: 20,620.79825
Overall Steps per Second: 9,836.93362

Timestep Collection Time: 2.42561
Timestep Consumption Time: 2.65911
PPO Batch Consumption Time: 0.32866
Total Iteration Time: 5.08471

Cumulative Model Updates: 325,836
Cumulative Timesteps: 2,717,457,028

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2717457028...
Checkpoint 2717457028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.36721
Policy Entropy: 4.24795
Value Function Loss: 0.00235

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.01783
Policy Update Magnitude: 0.23954
Value Function Update Magnitude: 0.27280

Collected Steps per Second: 20,328.05736
Overall Steps per Second: 9,634.16727

Timestep Collection Time: 2.46044
Timestep Consumption Time: 2.73108
PPO Batch Consumption Time: 0.32581
Total Iteration Time: 5.19152

Cumulative Model Updates: 325,842
Cumulative Timesteps: 2,717,507,044

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.67939
Policy Entropy: 4.24653
Value Function Loss: 0.00263

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.01562
Policy Update Magnitude: 0.22564
Value Function Update Magnitude: 0.28079

Collected Steps per Second: 20,704.80614
Overall Steps per Second: 9,591.18582

Timestep Collection Time: 2.41596
Timestep Consumption Time: 2.79945
PPO Batch Consumption Time: 0.33975
Total Iteration Time: 5.21541

Cumulative Model Updates: 325,848
Cumulative Timesteps: 2,717,557,066

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2717557066...
Checkpoint 2717557066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.27783
Policy Entropy: 4.24213
Value Function Loss: 0.00260

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.01410
Policy Update Magnitude: 0.23118
Value Function Update Magnitude: 0.27177

Collected Steps per Second: 21,275.37051
Overall Steps per Second: 9,851.00280

Timestep Collection Time: 2.35126
Timestep Consumption Time: 2.72680
PPO Batch Consumption Time: 0.32654
Total Iteration Time: 5.07806

Cumulative Model Updates: 325,854
Cumulative Timesteps: 2,717,607,090

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.79600
Policy Entropy: 4.23833
Value Function Loss: 0.00249

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01528
Policy Update Magnitude: 0.22629
Value Function Update Magnitude: 0.26269

Collected Steps per Second: 20,508.18384
Overall Steps per Second: 9,592.93220

Timestep Collection Time: 2.43942
Timestep Consumption Time: 2.77567
PPO Batch Consumption Time: 0.33168
Total Iteration Time: 5.21509

Cumulative Model Updates: 325,860
Cumulative Timesteps: 2,717,657,118

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2717657118...
Checkpoint 2717657118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.65004
Policy Entropy: 4.24487
Value Function Loss: 0.00239

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.01490
Policy Update Magnitude: 0.23798
Value Function Update Magnitude: 0.27917

Collected Steps per Second: 20,791.97377
Overall Steps per Second: 9,896.31835

Timestep Collection Time: 2.40583
Timestep Consumption Time: 2.64877
PPO Batch Consumption Time: 0.32593
Total Iteration Time: 5.05461

Cumulative Model Updates: 325,866
Cumulative Timesteps: 2,717,707,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.48862
Policy Entropy: 4.22870
Value Function Loss: 0.00241

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.02045
Policy Update Magnitude: 0.24416
Value Function Update Magnitude: 0.30031

Collected Steps per Second: 20,366.94788
Overall Steps per Second: 9,643.00320

Timestep Collection Time: 2.45614
Timestep Consumption Time: 2.73146
PPO Batch Consumption Time: 0.32687
Total Iteration Time: 5.18760

Cumulative Model Updates: 325,872
Cumulative Timesteps: 2,717,757,164

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2717757164...
Checkpoint 2717757164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.03159
Policy Entropy: 4.20049
Value Function Loss: 0.00246

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.02310
Policy Update Magnitude: 0.25400
Value Function Update Magnitude: 0.30138

Collected Steps per Second: 20,843.61239
Overall Steps per Second: 9,750.90655

Timestep Collection Time: 2.39930
Timestep Consumption Time: 2.72946
PPO Batch Consumption Time: 0.32615
Total Iteration Time: 5.12875

Cumulative Model Updates: 325,878
Cumulative Timesteps: 2,717,807,174

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.89508
Policy Entropy: 4.20738
Value Function Loss: 0.00264

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.02162
Policy Update Magnitude: 0.25409
Value Function Update Magnitude: 0.30023

Collected Steps per Second: 20,867.64102
Overall Steps per Second: 9,848.94200

Timestep Collection Time: 2.39730
Timestep Consumption Time: 2.68203
PPO Batch Consumption Time: 0.33163
Total Iteration Time: 5.07933

Cumulative Model Updates: 325,884
Cumulative Timesteps: 2,717,857,200

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2717857200...
Checkpoint 2717857200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.46970
Policy Entropy: 4.21783
Value Function Loss: 0.00219

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.01916
Policy Update Magnitude: 0.23945
Value Function Update Magnitude: 0.30141

Collected Steps per Second: 20,454.32804
Overall Steps per Second: 9,379.41741

Timestep Collection Time: 2.44506
Timestep Consumption Time: 2.88704
PPO Batch Consumption Time: 0.34680
Total Iteration Time: 5.33210

Cumulative Model Updates: 325,890
Cumulative Timesteps: 2,717,907,212

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.15795
Policy Entropy: 4.23663
Value Function Loss: 0.00226

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.01607
Policy Update Magnitude: 0.22405
Value Function Update Magnitude: 0.28727

Collected Steps per Second: 20,717.23399
Overall Steps per Second: 10,115.69871

Timestep Collection Time: 2.41422
Timestep Consumption Time: 2.53017
PPO Batch Consumption Time: 0.29668
Total Iteration Time: 4.94439

Cumulative Model Updates: 325,896
Cumulative Timesteps: 2,717,957,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2717957228...
Checkpoint 2717957228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.24494
Policy Entropy: 4.24964
Value Function Loss: 0.00173

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01392
Policy Update Magnitude: 0.20298
Value Function Update Magnitude: 0.26421

Collected Steps per Second: 23,316.13668
Overall Steps per Second: 10,866.52063

Timestep Collection Time: 2.14555
Timestep Consumption Time: 2.45813
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.60368

Cumulative Model Updates: 325,902
Cumulative Timesteps: 2,718,007,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.47234
Policy Entropy: 4.24301
Value Function Loss: 0.00247

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01306
Policy Update Magnitude: 0.21654
Value Function Update Magnitude: 0.27214

Collected Steps per Second: 22,787.90017
Overall Steps per Second: 10,691.21066

Timestep Collection Time: 2.19538
Timestep Consumption Time: 2.48398
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.67936

Cumulative Model Updates: 325,908
Cumulative Timesteps: 2,718,057,282

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2718057282...
Checkpoint 2718057282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.77862
Policy Entropy: 4.23865
Value Function Loss: 0.00254

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.01527
Policy Update Magnitude: 0.23945
Value Function Update Magnitude: 0.28373

Collected Steps per Second: 22,489.27101
Overall Steps per Second: 10,627.27663

Timestep Collection Time: 2.22390
Timestep Consumption Time: 2.48229
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.70619

Cumulative Model Updates: 325,914
Cumulative Timesteps: 2,718,107,296

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.53040
Policy Entropy: 4.22823
Value Function Loss: 0.00275

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.01751
Policy Update Magnitude: 0.23537
Value Function Update Magnitude: 0.28299

Collected Steps per Second: 23,458.91981
Overall Steps per Second: 10,951.06175

Timestep Collection Time: 2.13241
Timestep Consumption Time: 2.43555
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.56796

Cumulative Model Updates: 325,920
Cumulative Timesteps: 2,718,157,320

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2718157320...
Checkpoint 2718157320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.62957
Policy Entropy: 4.21791
Value Function Loss: 0.00277

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02196
Policy Update Magnitude: 0.23710
Value Function Update Magnitude: 0.28289

Collected Steps per Second: 22,891.13644
Overall Steps per Second: 10,730.80387

Timestep Collection Time: 2.18495
Timestep Consumption Time: 2.47602
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.66097

Cumulative Model Updates: 325,926
Cumulative Timesteps: 2,718,207,336

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.82038
Policy Entropy: 4.22893
Value Function Loss: 0.00240

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.01923
Policy Update Magnitude: 0.23492
Value Function Update Magnitude: 0.29876

Collected Steps per Second: 22,623.70180
Overall Steps per Second: 10,778.52279

Timestep Collection Time: 2.21122
Timestep Consumption Time: 2.43005
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.64127

Cumulative Model Updates: 325,932
Cumulative Timesteps: 2,718,257,362

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2718257362...
Checkpoint 2718257362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.87474
Policy Entropy: 4.21934
Value Function Loss: 0.00264

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02077
Policy Update Magnitude: 0.22631
Value Function Update Magnitude: 0.29326

Collected Steps per Second: 22,524.76378
Overall Steps per Second: 10,606.15161

Timestep Collection Time: 2.22084
Timestep Consumption Time: 2.49566
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.71651

Cumulative Model Updates: 325,938
Cumulative Timesteps: 2,718,307,386

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.90859
Policy Entropy: 4.23252
Value Function Loss: 0.00261

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01744
Policy Update Magnitude: 0.22990
Value Function Update Magnitude: 0.30423

Collected Steps per Second: 22,554.67560
Overall Steps per Second: 10,854.57625

Timestep Collection Time: 2.21701
Timestep Consumption Time: 2.38971
PPO Batch Consumption Time: 0.27642
Total Iteration Time: 4.60672

Cumulative Model Updates: 325,944
Cumulative Timesteps: 2,718,357,390

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2718357390...
Checkpoint 2718357390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.53447
Policy Entropy: 4.23583
Value Function Loss: 0.00280

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.01698
Policy Update Magnitude: 0.23064
Value Function Update Magnitude: 0.31893

Collected Steps per Second: 23,180.36413
Overall Steps per Second: 10,785.46850

Timestep Collection Time: 2.15717
Timestep Consumption Time: 2.47907
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.63624

Cumulative Model Updates: 325,950
Cumulative Timesteps: 2,718,407,394

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.48037
Policy Entropy: 4.25245
Value Function Loss: 0.00222

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02065
Policy Update Magnitude: 0.22060
Value Function Update Magnitude: 0.29756

Collected Steps per Second: 22,808.82299
Overall Steps per Second: 10,833.88059

Timestep Collection Time: 2.19248
Timestep Consumption Time: 2.42340
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.61589

Cumulative Model Updates: 325,956
Cumulative Timesteps: 2,718,457,402

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2718457402...
Checkpoint 2718457402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.47501
Policy Entropy: 4.25275
Value Function Loss: 0.00222

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.01624
Policy Update Magnitude: 0.21489
Value Function Update Magnitude: 0.27153

Collected Steps per Second: 22,398.97220
Overall Steps per Second: 10,644.14598

Timestep Collection Time: 2.23296
Timestep Consumption Time: 2.46596
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.69892

Cumulative Model Updates: 325,962
Cumulative Timesteps: 2,718,507,418

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.72730
Policy Entropy: 4.24496
Value Function Loss: 0.00198

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.01757
Policy Update Magnitude: 0.20835
Value Function Update Magnitude: 0.25875

Collected Steps per Second: 23,558.02922
Overall Steps per Second: 10,929.90727

Timestep Collection Time: 2.12310
Timestep Consumption Time: 2.45297
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.57607

Cumulative Model Updates: 325,968
Cumulative Timesteps: 2,718,557,434

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2718557434...
Checkpoint 2718557434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.89179
Policy Entropy: 4.23733
Value Function Loss: 0.00213

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.01600
Policy Update Magnitude: 0.22232
Value Function Update Magnitude: 0.24561

Collected Steps per Second: 22,571.91012
Overall Steps per Second: 10,642.77240

Timestep Collection Time: 2.21647
Timestep Consumption Time: 2.48437
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.70084

Cumulative Model Updates: 325,974
Cumulative Timesteps: 2,718,607,464

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.27059
Policy Entropy: 4.24813
Value Function Loss: 0.00230

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.01601
Policy Update Magnitude: 0.21688
Value Function Update Magnitude: 0.25620

Collected Steps per Second: 22,781.85576
Overall Steps per Second: 10,925.47400

Timestep Collection Time: 2.19490
Timestep Consumption Time: 2.38192
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.57683

Cumulative Model Updates: 325,980
Cumulative Timesteps: 2,718,657,468

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2718657468...
Checkpoint 2718657468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.35751
Policy Entropy: 4.26031
Value Function Loss: 0.00225

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.01583
Policy Update Magnitude: 0.21630
Value Function Update Magnitude: 0.27017

Collected Steps per Second: 22,677.95195
Overall Steps per Second: 10,645.48968

Timestep Collection Time: 2.20514
Timestep Consumption Time: 2.49244
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.69758

Cumulative Model Updates: 325,986
Cumulative Timesteps: 2,718,707,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.91214
Policy Entropy: 4.26797
Value Function Loss: 0.00214

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.01402
Policy Update Magnitude: 0.21542
Value Function Update Magnitude: 0.26658

Collected Steps per Second: 22,980.25194
Overall Steps per Second: 10,913.67767

Timestep Collection Time: 2.17691
Timestep Consumption Time: 2.40688
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.58379

Cumulative Model Updates: 325,992
Cumulative Timesteps: 2,718,757,502

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2718757502...
Checkpoint 2718757502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.87192
Policy Entropy: 4.24335
Value Function Loss: 0.00277

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.01656
Policy Update Magnitude: 0.22736
Value Function Update Magnitude: 0.26224

Collected Steps per Second: 22,785.89871
Overall Steps per Second: 11,036.56978

Timestep Collection Time: 2.19469
Timestep Consumption Time: 2.33643
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.53112

Cumulative Model Updates: 325,998
Cumulative Timesteps: 2,718,807,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.01626
Policy Entropy: 4.23818
Value Function Loss: 0.00300

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.01595
Policy Update Magnitude: 0.22447
Value Function Update Magnitude: 0.27430

Collected Steps per Second: 23,219.35288
Overall Steps per Second: 10,921.59424

Timestep Collection Time: 2.15407
Timestep Consumption Time: 2.42549
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.57955

Cumulative Model Updates: 326,004
Cumulative Timesteps: 2,718,857,526

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2718857526...
Checkpoint 2718857526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.02541
Policy Entropy: 4.21650
Value Function Loss: 0.00381

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.01627
Policy Update Magnitude: 0.23638
Value Function Update Magnitude: 0.29182

Collected Steps per Second: 22,570.92133
Overall Steps per Second: 10,642.21480

Timestep Collection Time: 2.21657
Timestep Consumption Time: 2.48452
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.70109

Cumulative Model Updates: 326,010
Cumulative Timesteps: 2,718,907,556

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.54009
Policy Entropy: 4.24559
Value Function Loss: 0.00295

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.01487
Policy Update Magnitude: 0.23076
Value Function Update Magnitude: 0.32039

Collected Steps per Second: 23,682.00880
Overall Steps per Second: 10,969.32025

Timestep Collection Time: 2.11198
Timestep Consumption Time: 2.44764
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.55963

Cumulative Model Updates: 326,016
Cumulative Timesteps: 2,718,957,572

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2718957572...
Checkpoint 2718957572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.65167
Policy Entropy: 4.24387
Value Function Loss: 0.00249

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.01794
Policy Update Magnitude: 0.22805
Value Function Update Magnitude: 0.31292

Collected Steps per Second: 22,575.11405
Overall Steps per Second: 10,616.39048

Timestep Collection Time: 2.21527
Timestep Consumption Time: 2.49537
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.71064

Cumulative Model Updates: 326,022
Cumulative Timesteps: 2,719,007,582

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.68295
Policy Entropy: 4.26064
Value Function Loss: 0.00202

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02134
Policy Update Magnitude: 0.21717
Value Function Update Magnitude: 0.29890

Collected Steps per Second: 22,435.69662
Overall Steps per Second: 10,968.65522

Timestep Collection Time: 2.22966
Timestep Consumption Time: 2.33097
PPO Batch Consumption Time: 0.27553
Total Iteration Time: 4.56063

Cumulative Model Updates: 326,028
Cumulative Timesteps: 2,719,057,606

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2719057606...
Checkpoint 2719057606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.26806
Policy Entropy: 4.26201
Value Function Loss: 0.00254

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02052
Policy Update Magnitude: 0.21822
Value Function Update Magnitude: 0.28105

Collected Steps per Second: 22,425.36290
Overall Steps per Second: 10,605.39715

Timestep Collection Time: 2.23033
Timestep Consumption Time: 2.48576
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.71609

Cumulative Model Updates: 326,034
Cumulative Timesteps: 2,719,107,622

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.52045
Policy Entropy: 4.25389
Value Function Loss: 0.00307

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.01767
Policy Update Magnitude: 0.24016
Value Function Update Magnitude: 0.27992

Collected Steps per Second: 22,712.84094
Overall Steps per Second: 10,891.68075

Timestep Collection Time: 2.20237
Timestep Consumption Time: 2.39031
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.59268

Cumulative Model Updates: 326,040
Cumulative Timesteps: 2,719,157,644

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2719157644...
Checkpoint 2719157644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.35679
Policy Entropy: 4.25199
Value Function Loss: 0.00311

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.01823
Policy Update Magnitude: 0.24658
Value Function Update Magnitude: 0.31170

Collected Steps per Second: 22,730.94186
Overall Steps per Second: 11,017.53617

Timestep Collection Time: 2.20017
Timestep Consumption Time: 2.33914
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.53931

Cumulative Model Updates: 326,046
Cumulative Timesteps: 2,719,207,656

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.94233
Policy Entropy: 4.24122
Value Function Loss: 0.00262

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.01976
Policy Update Magnitude: 0.23229
Value Function Update Magnitude: 0.32101

Collected Steps per Second: 22,886.33379
Overall Steps per Second: 10,726.43470

Timestep Collection Time: 2.18471
Timestep Consumption Time: 2.47667
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.66138

Cumulative Model Updates: 326,052
Cumulative Timesteps: 2,719,257,656

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2719257656...
Checkpoint 2719257656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.66611
Policy Entropy: 4.24057
Value Function Loss: 0.00262

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.01630
Policy Update Magnitude: 0.22696
Value Function Update Magnitude: 0.29311

Collected Steps per Second: 22,506.91796
Overall Steps per Second: 10,807.30859

Timestep Collection Time: 2.22172
Timestep Consumption Time: 2.40515
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.62687

Cumulative Model Updates: 326,058
Cumulative Timesteps: 2,719,307,660

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.13789
Policy Entropy: 4.24367
Value Function Loss: 0.00231

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.01618
Policy Update Magnitude: 0.22400
Value Function Update Magnitude: 0.27755

Collected Steps per Second: 23,227.24969
Overall Steps per Second: 10,947.74758

Timestep Collection Time: 2.15394
Timestep Consumption Time: 2.41595
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.56989

Cumulative Model Updates: 326,064
Cumulative Timesteps: 2,719,357,690

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2719357690...
Checkpoint 2719357690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.92431
Policy Entropy: 4.25319
Value Function Loss: 0.00243

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.01654
Policy Update Magnitude: 0.21719
Value Function Update Magnitude: 0.27649

Collected Steps per Second: 22,738.26244
Overall Steps per Second: 10,730.44460

Timestep Collection Time: 2.19999
Timestep Consumption Time: 2.46188
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.66188

Cumulative Model Updates: 326,070
Cumulative Timesteps: 2,719,407,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.35765
Policy Entropy: 4.25382
Value Function Loss: 0.00268

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.01346
Policy Update Magnitude: 0.22140
Value Function Update Magnitude: 0.29942

Collected Steps per Second: 22,704.62951
Overall Steps per Second: 10,900.10907

Timestep Collection Time: 2.20255
Timestep Consumption Time: 2.38530
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.58784

Cumulative Model Updates: 326,076
Cumulative Timesteps: 2,719,457,722

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2719457722...
Checkpoint 2719457722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.31056
Policy Entropy: 4.24356
Value Function Loss: 0.00330

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01657
Policy Update Magnitude: 0.25449
Value Function Update Magnitude: 0.30433

Collected Steps per Second: 22,519.80725
Overall Steps per Second: 10,612.27304

Timestep Collection Time: 2.22133
Timestep Consumption Time: 2.49245
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.71379

Cumulative Model Updates: 326,082
Cumulative Timesteps: 2,719,507,746

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.74800
Policy Entropy: 4.22763
Value Function Loss: 0.00349

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.01896
Policy Update Magnitude: 0.25940
Value Function Update Magnitude: 0.31577

Collected Steps per Second: 22,758.71507
Overall Steps per Second: 10,886.46233

Timestep Collection Time: 2.19731
Timestep Consumption Time: 2.39628
PPO Batch Consumption Time: 0.27718
Total Iteration Time: 4.59360

Cumulative Model Updates: 326,088
Cumulative Timesteps: 2,719,557,754

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2719557754...
Checkpoint 2719557754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.97687
Policy Entropy: 4.21880
Value Function Loss: 0.00385

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.01847
Policy Update Magnitude: 0.26131
Value Function Update Magnitude: 0.32705

Collected Steps per Second: 22,603.02873
Overall Steps per Second: 10,863.34542

Timestep Collection Time: 2.21333
Timestep Consumption Time: 2.39188
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.60521

Cumulative Model Updates: 326,094
Cumulative Timesteps: 2,719,607,782

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.51823
Policy Entropy: 4.21264
Value Function Loss: 0.00314

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02231
Policy Update Magnitude: 0.24928
Value Function Update Magnitude: 0.33200

Collected Steps per Second: 22,930.75199
Overall Steps per Second: 10,737.57701

Timestep Collection Time: 2.18144
Timestep Consumption Time: 2.47716
PPO Batch Consumption Time: 0.28485
Total Iteration Time: 4.65859

Cumulative Model Updates: 326,100
Cumulative Timesteps: 2,719,657,804

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2719657804...
Checkpoint 2719657804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.10001
Policy Entropy: 4.23068
Value Function Loss: 0.00273

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.01861
Policy Update Magnitude: 0.23781
Value Function Update Magnitude: 0.31774

Collected Steps per Second: 22,559.25628
Overall Steps per Second: 10,689.48481

Timestep Collection Time: 2.21683
Timestep Consumption Time: 2.46160
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.67843

Cumulative Model Updates: 326,106
Cumulative Timesteps: 2,719,707,814

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.64855
Policy Entropy: 4.25652
Value Function Loss: 0.00225

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01323
Policy Update Magnitude: 0.23804
Value Function Update Magnitude: 0.29946

Collected Steps per Second: 23,623.12879
Overall Steps per Second: 10,853.05724

Timestep Collection Time: 2.11784
Timestep Consumption Time: 2.49192
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.60976

Cumulative Model Updates: 326,112
Cumulative Timesteps: 2,719,757,844

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2719757844...
Checkpoint 2719757844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.25647
Policy Entropy: 4.25720
Value Function Loss: 0.00251

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.01721
Policy Update Magnitude: 0.24168
Value Function Update Magnitude: 0.31597

Collected Steps per Second: 22,658.92604
Overall Steps per Second: 10,653.52170

Timestep Collection Time: 2.20770
Timestep Consumption Time: 2.48784
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.69554

Cumulative Model Updates: 326,118
Cumulative Timesteps: 2,719,807,868

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.63283
Policy Entropy: 4.24472
Value Function Loss: 0.00243

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.01634
Policy Update Magnitude: 0.22964
Value Function Update Magnitude: 0.31295

Collected Steps per Second: 22,551.66568
Overall Steps per Second: 10,909.15683

Timestep Collection Time: 2.21731
Timestep Consumption Time: 2.36636
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.58367

Cumulative Model Updates: 326,124
Cumulative Timesteps: 2,719,857,872

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2719857872...
Checkpoint 2719857872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.95105
Policy Entropy: 4.23701
Value Function Loss: 0.00294

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.01579
Policy Update Magnitude: 0.23304
Value Function Update Magnitude: 0.29693

Collected Steps per Second: 22,982.94802
Overall Steps per Second: 10,704.94953

Timestep Collection Time: 2.17570
Timestep Consumption Time: 2.49541
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.67111

Cumulative Model Updates: 326,130
Cumulative Timesteps: 2,719,907,876

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.23523
Policy Entropy: 4.24853
Value Function Loss: 0.00293

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.01597
Policy Update Magnitude: 0.22883
Value Function Update Magnitude: 0.29024

Collected Steps per Second: 22,928.77133
Overall Steps per Second: 10,855.04516

Timestep Collection Time: 2.18084
Timestep Consumption Time: 2.42568
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.60652

Cumulative Model Updates: 326,136
Cumulative Timesteps: 2,719,957,880

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2719957880...
Checkpoint 2719957880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.01897
Policy Entropy: 4.26985
Value Function Loss: 0.00262

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.01533
Policy Update Magnitude: 0.21385
Value Function Update Magnitude: 0.28496

Collected Steps per Second: 22,618.30178
Overall Steps per Second: 10,992.60647

Timestep Collection Time: 2.21131
Timestep Consumption Time: 2.33866
PPO Batch Consumption Time: 0.27690
Total Iteration Time: 4.54997

Cumulative Model Updates: 326,142
Cumulative Timesteps: 2,720,007,896

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.77582
Policy Entropy: 4.28877
Value Function Loss: 0.00269

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.01278
Policy Update Magnitude: 0.19887
Value Function Update Magnitude: 0.27768

Collected Steps per Second: 22,751.88776
Overall Steps per Second: 10,685.40129

Timestep Collection Time: 2.19867
Timestep Consumption Time: 2.48285
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.68153

Cumulative Model Updates: 326,148
Cumulative Timesteps: 2,720,057,920

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2720057920...
Checkpoint 2720057920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.39936
Policy Entropy: 4.28238
Value Function Loss: 0.00228

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01219
Policy Update Magnitude: 0.20764
Value Function Update Magnitude: 0.27391

Collected Steps per Second: 22,940.51028
Overall Steps per Second: 10,936.93930

Timestep Collection Time: 2.17990
Timestep Consumption Time: 2.39250
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.57239

Cumulative Model Updates: 326,154
Cumulative Timesteps: 2,720,107,928

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.07160
Policy Entropy: 4.26188
Value Function Loss: 0.00215

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.01517
Policy Update Magnitude: 0.21793
Value Function Update Magnitude: 0.27153

Collected Steps per Second: 23,610.57368
Overall Steps per Second: 10,951.62840

Timestep Collection Time: 2.11812
Timestep Consumption Time: 2.44833
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.56644

Cumulative Model Updates: 326,160
Cumulative Timesteps: 2,720,157,938

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2720157938...
Checkpoint 2720157938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.94307
Policy Entropy: 4.24893
Value Function Loss: 0.00211

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.01839
Policy Update Magnitude: 0.21606
Value Function Update Magnitude: 0.26088

Collected Steps per Second: 22,685.10992
Overall Steps per Second: 10,671.58335

Timestep Collection Time: 2.20444
Timestep Consumption Time: 2.48165
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.68609

Cumulative Model Updates: 326,166
Cumulative Timesteps: 2,720,207,946

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.26559
Policy Entropy: 4.22639
Value Function Loss: 0.00283

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.01685
Policy Update Magnitude: 0.23690
Value Function Update Magnitude: 0.28249

Collected Steps per Second: 22,659.11115
Overall Steps per Second: 10,869.28817

Timestep Collection Time: 2.20759
Timestep Consumption Time: 2.39455
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.60214

Cumulative Model Updates: 326,172
Cumulative Timesteps: 2,720,257,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2720257968...
Checkpoint 2720257968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.34992
Policy Entropy: 4.23445
Value Function Loss: 0.00267

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.01709
Policy Update Magnitude: 0.24225
Value Function Update Magnitude: 0.32145

Collected Steps per Second: 23,629.17298
Overall Steps per Second: 11,035.62698

Timestep Collection Time: 2.11798
Timestep Consumption Time: 2.41697
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.53495

Cumulative Model Updates: 326,178
Cumulative Timesteps: 2,720,308,014

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.12336
Policy Entropy: 4.24842
Value Function Loss: 0.00219

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.01812
Policy Update Magnitude: 0.23431
Value Function Update Magnitude: 0.31678

Collected Steps per Second: 22,860.60067
Overall Steps per Second: 10,709.71387

Timestep Collection Time: 2.18734
Timestep Consumption Time: 2.48169
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.66903

Cumulative Model Updates: 326,184
Cumulative Timesteps: 2,720,358,018

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2720358018...
Checkpoint 2720358018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.19775
Policy Entropy: 4.25165
Value Function Loss: 0.00254

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01265
Policy Update Magnitude: 0.23042
Value Function Update Magnitude: 0.30690

Collected Steps per Second: 22,566.55191
Overall Steps per Second: 10,935.98729

Timestep Collection Time: 2.21673
Timestep Consumption Time: 2.35752
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.57426

Cumulative Model Updates: 326,190
Cumulative Timesteps: 2,720,408,042

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.25050
Policy Entropy: 4.25075
Value Function Loss: 0.00231

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.01414
Policy Update Magnitude: 0.22922
Value Function Update Magnitude: 0.31723

Collected Steps per Second: 22,866.13039
Overall Steps per Second: 10,831.81592

Timestep Collection Time: 2.18690
Timestep Consumption Time: 2.42968
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.61659

Cumulative Model Updates: 326,196
Cumulative Timesteps: 2,720,458,048

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2720458048...
Checkpoint 2720458048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.14340
Policy Entropy: 4.23535
Value Function Loss: 0.00252

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.01667
Policy Update Magnitude: 0.22034
Value Function Update Magnitude: 0.31473

Collected Steps per Second: 22,571.39578
Overall Steps per Second: 10,666.24958

Timestep Collection Time: 2.21643
Timestep Consumption Time: 2.47387
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.69031

Cumulative Model Updates: 326,202
Cumulative Timesteps: 2,720,508,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.11900
Policy Entropy: 4.27325
Value Function Loss: 0.00197

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.01359
Policy Update Magnitude: 0.21287
Value Function Update Magnitude: 0.28396

Collected Steps per Second: 22,993.15905
Overall Steps per Second: 10,947.40050

Timestep Collection Time: 2.17569
Timestep Consumption Time: 2.39398
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.56967

Cumulative Model Updates: 326,208
Cumulative Timesteps: 2,720,558,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2720558102...
Checkpoint 2720558102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.12119
Policy Entropy: 4.26237
Value Function Loss: 0.00252

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01245
Policy Update Magnitude: 0.21254
Value Function Update Magnitude: 0.26117

Collected Steps per Second: 22,628.73726
Overall Steps per Second: 10,642.86134

Timestep Collection Time: 2.20993
Timestep Consumption Time: 2.48880
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.69874

Cumulative Model Updates: 326,214
Cumulative Timesteps: 2,720,608,110

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.15843
Policy Entropy: 4.26543
Value Function Loss: 0.00216

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.01244
Policy Update Magnitude: 0.20897
Value Function Update Magnitude: 0.25900

Collected Steps per Second: 22,936.44943
Overall Steps per Second: 10,954.78393

Timestep Collection Time: 2.18185
Timestep Consumption Time: 2.38638
PPO Batch Consumption Time: 0.27564
Total Iteration Time: 4.56823

Cumulative Model Updates: 326,220
Cumulative Timesteps: 2,720,658,154

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2720658154...
Checkpoint 2720658154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.05467
Policy Entropy: 4.25620
Value Function Loss: 0.00271

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01287
Policy Update Magnitude: 0.21713
Value Function Update Magnitude: 0.26551

Collected Steps per Second: 23,594.09664
Overall Steps per Second: 11,030.47874

Timestep Collection Time: 2.12011
Timestep Consumption Time: 2.41478
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.53489

Cumulative Model Updates: 326,226
Cumulative Timesteps: 2,720,708,176

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.89682
Policy Entropy: 4.26584
Value Function Loss: 0.00243

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01346
Policy Update Magnitude: 0.22265
Value Function Update Magnitude: 0.26899

Collected Steps per Second: 23,025.17330
Overall Steps per Second: 10,857.41180

Timestep Collection Time: 2.17180
Timestep Consumption Time: 2.43390
PPO Batch Consumption Time: 0.27670
Total Iteration Time: 4.60570

Cumulative Model Updates: 326,232
Cumulative Timesteps: 2,720,758,182

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2720758182...
Checkpoint 2720758182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.69082
Policy Entropy: 4.27472
Value Function Loss: 0.00228

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.01585
Policy Update Magnitude: 0.21578
Value Function Update Magnitude: 0.25960

Collected Steps per Second: 22,516.58884
Overall Steps per Second: 10,815.73449

Timestep Collection Time: 2.22201
Timestep Consumption Time: 2.40385
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.62585

Cumulative Model Updates: 326,238
Cumulative Timesteps: 2,720,808,214

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.75415
Policy Entropy: 4.27241
Value Function Loss: 0.00233

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01379
Policy Update Magnitude: 0.21433
Value Function Update Magnitude: 0.25482

Collected Steps per Second: 23,185.03155
Overall Steps per Second: 10,826.62299

Timestep Collection Time: 2.15820
Timestep Consumption Time: 2.46355
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.62176

Cumulative Model Updates: 326,244
Cumulative Timesteps: 2,720,858,252

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2720858252...
Checkpoint 2720858252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.07521
Policy Entropy: 4.25938
Value Function Loss: 0.00322

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.01705
Policy Update Magnitude: 0.25947
Value Function Update Magnitude: 0.27723

Collected Steps per Second: 22,642.32449
Overall Steps per Second: 10,725.74380

Timestep Collection Time: 2.20843
Timestep Consumption Time: 2.45362
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.66205

Cumulative Model Updates: 326,250
Cumulative Timesteps: 2,720,908,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.88520
Policy Entropy: 4.26408
Value Function Loss: 0.00300

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.01848
Policy Update Magnitude: 0.25514
Value Function Update Magnitude: 0.29625

Collected Steps per Second: 22,999.93695
Overall Steps per Second: 10,932.15496

Timestep Collection Time: 2.17453
Timestep Consumption Time: 2.40042
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.57494

Cumulative Model Updates: 326,256
Cumulative Timesteps: 2,720,958,270

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2720958270...
Checkpoint 2720958270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.85503
Policy Entropy: 4.25546
Value Function Loss: 0.00282

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.01694
Policy Update Magnitude: 0.24229
Value Function Update Magnitude: 0.30166

Collected Steps per Second: 22,709.76258
Overall Steps per Second: 10,706.48113

Timestep Collection Time: 2.20249
Timestep Consumption Time: 2.46926
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.67175

Cumulative Model Updates: 326,262
Cumulative Timesteps: 2,721,008,288

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.86467
Policy Entropy: 4.26921
Value Function Loss: 0.00256

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.01537
Policy Update Magnitude: 0.23449
Value Function Update Magnitude: 0.27663

Collected Steps per Second: 22,866.06408
Overall Steps per Second: 10,747.58561

Timestep Collection Time: 2.18778
Timestep Consumption Time: 2.46684
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.65463

Cumulative Model Updates: 326,268
Cumulative Timesteps: 2,721,058,314

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2721058314...
Checkpoint 2721058314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.30270
Policy Entropy: 4.23608
Value Function Loss: 0.00301

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.01729
Policy Update Magnitude: 0.24326
Value Function Update Magnitude: 0.28185

Collected Steps per Second: 23,524.89365
Overall Steps per Second: 11,034.29448

Timestep Collection Time: 2.12634
Timestep Consumption Time: 2.40698
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.53332

Cumulative Model Updates: 326,274
Cumulative Timesteps: 2,721,108,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.46105
Policy Entropy: 4.23892
Value Function Loss: 0.00335

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.01848
Policy Update Magnitude: 0.25664
Value Function Update Magnitude: 0.31078

Collected Steps per Second: 22,916.90359
Overall Steps per Second: 10,861.60644

Timestep Collection Time: 2.18249
Timestep Consumption Time: 2.42235
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.60484

Cumulative Model Updates: 326,280
Cumulative Timesteps: 2,721,158,352

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2721158352...
Checkpoint 2721158352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.29162
Policy Entropy: 4.23364
Value Function Loss: 0.00281

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02234
Policy Update Magnitude: 0.24574
Value Function Update Magnitude: 0.33696

Collected Steps per Second: 22,904.04559
Overall Steps per Second: 10,950.68134

Timestep Collection Time: 2.18363
Timestep Consumption Time: 2.38357
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.56720

Cumulative Model Updates: 326,286
Cumulative Timesteps: 2,721,208,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.50724
Policy Entropy: 4.23537
Value Function Loss: 0.00232

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.01797
Policy Update Magnitude: 0.24098
Value Function Update Magnitude: 0.33638

Collected Steps per Second: 22,956.67863
Overall Steps per Second: 10,678.97645

Timestep Collection Time: 2.17836
Timestep Consumption Time: 2.50448
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.68285

Cumulative Model Updates: 326,292
Cumulative Timesteps: 2,721,258,374

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2721258374...
Checkpoint 2721258374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.51978
Policy Entropy: 4.21063
Value Function Loss: 0.00282

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.01790
Policy Update Magnitude: 0.24759
Value Function Update Magnitude: 0.32312

Collected Steps per Second: 22,634.49851
Overall Steps per Second: 10,752.28828

Timestep Collection Time: 2.20981
Timestep Consumption Time: 2.44203
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.65185

Cumulative Model Updates: 326,298
Cumulative Timesteps: 2,721,308,392

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.35839
Policy Entropy: 4.20257
Value Function Loss: 0.00318

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.01873
Policy Update Magnitude: 0.25787
Value Function Update Magnitude: 0.32360

Collected Steps per Second: 22,644.80023
Overall Steps per Second: 10,799.98956

Timestep Collection Time: 2.20925
Timestep Consumption Time: 2.42298
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.63223

Cumulative Model Updates: 326,304
Cumulative Timesteps: 2,721,358,420

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2721358420...
Checkpoint 2721358420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.43375
Policy Entropy: 4.19270
Value Function Loss: 0.00376

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02200
Policy Update Magnitude: 0.28595
Value Function Update Magnitude: 0.32052

Collected Steps per Second: 22,687.18069
Overall Steps per Second: 10,679.45520

Timestep Collection Time: 2.20521
Timestep Consumption Time: 2.47949
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.68470

Cumulative Model Updates: 326,310
Cumulative Timesteps: 2,721,408,450

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.55888
Policy Entropy: 4.21555
Value Function Loss: 0.00346

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.02206
Policy Update Magnitude: 0.28905
Value Function Update Magnitude: 0.31690

Collected Steps per Second: 22,689.82241
Overall Steps per Second: 10,887.34235

Timestep Collection Time: 2.20407
Timestep Consumption Time: 2.38934
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.59341

Cumulative Model Updates: 326,316
Cumulative Timesteps: 2,721,458,460

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2721458460...
Checkpoint 2721458460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.04249
Policy Entropy: 4.24611
Value Function Loss: 0.00324

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.02359
Policy Update Magnitude: 0.27398
Value Function Update Magnitude: 0.31988

Collected Steps per Second: 23,476.80321
Overall Steps per Second: 10,995.49823

Timestep Collection Time: 2.13027
Timestep Consumption Time: 2.41813
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.54841

Cumulative Model Updates: 326,322
Cumulative Timesteps: 2,721,508,472

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.38464
Policy Entropy: 4.25674
Value Function Loss: 0.00290

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.01997
Policy Update Magnitude: 0.26034
Value Function Update Magnitude: 0.30365

Collected Steps per Second: 22,754.98061
Overall Steps per Second: 10,686.21518

Timestep Collection Time: 2.19785
Timestep Consumption Time: 2.48220
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.68005

Cumulative Model Updates: 326,328
Cumulative Timesteps: 2,721,558,484

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2721558484...
Checkpoint 2721558484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.08888
Policy Entropy: 4.25396
Value Function Loss: 0.00303

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.01808
Policy Update Magnitude: 0.25014
Value Function Update Magnitude: 0.30162

Collected Steps per Second: 22,717.10222
Overall Steps per Second: 10,792.31303

Timestep Collection Time: 2.20178
Timestep Consumption Time: 2.43282
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.63460

Cumulative Model Updates: 326,334
Cumulative Timesteps: 2,721,608,502

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.28807
Policy Entropy: 4.23974
Value Function Loss: 0.00278

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.01986
Policy Update Magnitude: 0.24804
Value Function Update Magnitude: 0.28613

Collected Steps per Second: 23,519.59430
Overall Steps per Second: 10,938.47296

Timestep Collection Time: 2.12682
Timestep Consumption Time: 2.44621
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.57303

Cumulative Model Updates: 326,340
Cumulative Timesteps: 2,721,658,524

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2721658524...
Checkpoint 2721658524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.84362
Policy Entropy: 4.24266
Value Function Loss: 0.00325

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.01954
Policy Update Magnitude: 0.25122
Value Function Update Magnitude: 0.29382

Collected Steps per Second: 22,584.62086
Overall Steps per Second: 10,799.93343

Timestep Collection Time: 2.21434
Timestep Consumption Time: 2.41625
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.63058

Cumulative Model Updates: 326,346
Cumulative Timesteps: 2,721,708,534

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.22194
Policy Entropy: 4.26773
Value Function Loss: 0.00265

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.01604
Policy Update Magnitude: 0.24538
Value Function Update Magnitude: 0.30479

Collected Steps per Second: 22,555.76562
Overall Steps per Second: 10,976.30415

Timestep Collection Time: 2.21708
Timestep Consumption Time: 2.33891
PPO Batch Consumption Time: 0.27607
Total Iteration Time: 4.55600

Cumulative Model Updates: 326,352
Cumulative Timesteps: 2,721,758,542

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2721758542...
Checkpoint 2721758542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.35895
Policy Entropy: 4.26767
Value Function Loss: 0.00265

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.01671
Policy Update Magnitude: 0.22883
Value Function Update Magnitude: 0.28202

Collected Steps per Second: 22,779.88350
Overall Steps per Second: 10,679.91616

Timestep Collection Time: 2.19597
Timestep Consumption Time: 2.48796
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.68393

Cumulative Model Updates: 326,358
Cumulative Timesteps: 2,721,808,566

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.42816
Policy Entropy: 4.27319
Value Function Loss: 0.00251

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.01380
Policy Update Magnitude: 0.21724
Value Function Update Magnitude: 0.27687

Collected Steps per Second: 22,694.72143
Overall Steps per Second: 10,896.50455

Timestep Collection Time: 2.20421
Timestep Consumption Time: 2.38662
PPO Batch Consumption Time: 0.27573
Total Iteration Time: 4.59083

Cumulative Model Updates: 326,364
Cumulative Timesteps: 2,721,858,590

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2721858590...
Checkpoint 2721858590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.95319
Policy Entropy: 4.26133
Value Function Loss: 0.00235

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.01561
Policy Update Magnitude: 0.21725
Value Function Update Magnitude: 0.29977

Collected Steps per Second: 23,460.52939
Overall Steps per Second: 10,948.56296

Timestep Collection Time: 2.13209
Timestep Consumption Time: 2.43654
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.56864

Cumulative Model Updates: 326,370
Cumulative Timesteps: 2,721,908,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.63696
Policy Entropy: 4.26861
Value Function Loss: 0.00203

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.01400
Policy Update Magnitude: 0.21084
Value Function Update Magnitude: 0.30081

Collected Steps per Second: 22,719.65570
Overall Steps per Second: 10,677.41976

Timestep Collection Time: 2.20171
Timestep Consumption Time: 2.48313
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.68484

Cumulative Model Updates: 326,376
Cumulative Timesteps: 2,721,958,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2721958632...
Checkpoint 2721958632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.57211
Policy Entropy: 4.26864
Value Function Loss: 0.00218

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.01626
Policy Update Magnitude: 0.22251
Value Function Update Magnitude: 0.28790

Collected Steps per Second: 22,790.79919
Overall Steps per Second: 11,004.92206

Timestep Collection Time: 2.19518
Timestep Consumption Time: 2.35096
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.54615

Cumulative Model Updates: 326,382
Cumulative Timesteps: 2,722,008,662

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.92296
Policy Entropy: 4.27071
Value Function Loss: 0.00278

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.01573
Policy Update Magnitude: 0.22918
Value Function Update Magnitude: 0.29734

Collected Steps per Second: 22,827.91549
Overall Steps per Second: 10,842.01506

Timestep Collection Time: 2.19153
Timestep Consumption Time: 2.42274
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.61427

Cumulative Model Updates: 326,388
Cumulative Timesteps: 2,722,058,690

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2722058690...
Checkpoint 2722058690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.60400
Policy Entropy: 4.28445
Value Function Loss: 0.00219

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.01753
Policy Update Magnitude: 0.22367
Value Function Update Magnitude: 0.31214

Collected Steps per Second: 22,555.10654
Overall Steps per Second: 10,684.94300

Timestep Collection Time: 2.21741
Timestep Consumption Time: 2.46338
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.68079

Cumulative Model Updates: 326,394
Cumulative Timesteps: 2,722,108,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.80953
Policy Entropy: 4.29152
Value Function Loss: 0.00244

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01391
Policy Update Magnitude: 0.21405
Value Function Update Magnitude: 0.29969

Collected Steps per Second: 23,610.05727
Overall Steps per Second: 10,953.88553

Timestep Collection Time: 2.11791
Timestep Consumption Time: 2.44704
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.56496

Cumulative Model Updates: 326,400
Cumulative Timesteps: 2,722,158,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2722158708...
Checkpoint 2722158708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.71315
Policy Entropy: 4.28057
Value Function Loss: 0.00219

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.01486
Policy Update Magnitude: 0.21127
Value Function Update Magnitude: 0.28772

Collected Steps per Second: 22,575.66538
Overall Steps per Second: 10,630.80872

Timestep Collection Time: 2.21522
Timestep Consumption Time: 2.48903
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.70425

Cumulative Model Updates: 326,406
Cumulative Timesteps: 2,722,208,718

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.99868
Policy Entropy: 4.24533
Value Function Loss: 0.00315

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.01563
Policy Update Magnitude: 0.23408
Value Function Update Magnitude: 0.28441

Collected Steps per Second: 22,787.98786
Overall Steps per Second: 10,882.60063

Timestep Collection Time: 2.19423
Timestep Consumption Time: 2.40045
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.59467

Cumulative Model Updates: 326,412
Cumulative Timesteps: 2,722,258,720

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2722258720...
Checkpoint 2722258720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.20520
Policy Entropy: 4.24431
Value Function Loss: 0.00303

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.01645
Policy Update Magnitude: 0.24741
Value Function Update Magnitude: 0.30439

Collected Steps per Second: 22,966.38205
Overall Steps per Second: 10,740.27168

Timestep Collection Time: 2.17814
Timestep Consumption Time: 2.47947
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.65761

Cumulative Model Updates: 326,418
Cumulative Timesteps: 2,722,308,744

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.84198
Policy Entropy: 4.24377
Value Function Loss: 0.00308

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.01696
Policy Update Magnitude: 0.24912
Value Function Update Magnitude: 0.30825

Collected Steps per Second: 22,868.09112
Overall Steps per Second: 10,840.28084

Timestep Collection Time: 2.18733
Timestep Consumption Time: 2.42694
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.61427

Cumulative Model Updates: 326,424
Cumulative Timesteps: 2,722,358,764

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2722358764...
Checkpoint 2722358764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.89876
Policy Entropy: 4.27487
Value Function Loss: 0.00233

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01486
Policy Update Magnitude: 0.23121
Value Function Update Magnitude: 0.30974

Collected Steps per Second: 22,671.79113
Overall Steps per Second: 11,026.11809

Timestep Collection Time: 2.20618
Timestep Consumption Time: 2.33014
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.53632

Cumulative Model Updates: 326,430
Cumulative Timesteps: 2,722,408,782

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.62128
Policy Entropy: 4.25138
Value Function Loss: 0.00281

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01378
Policy Update Magnitude: 0.22159
Value Function Update Magnitude: 0.29236

Collected Steps per Second: 22,653.73209
Overall Steps per Second: 10,698.51784

Timestep Collection Time: 2.20741
Timestep Consumption Time: 2.46670
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.67411

Cumulative Model Updates: 326,436
Cumulative Timesteps: 2,722,458,788

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2722458788...
Checkpoint 2722458788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.11072
Policy Entropy: 4.24007
Value Function Loss: 0.00299

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.01629
Policy Update Magnitude: 0.25100
Value Function Update Magnitude: 0.30062

Collected Steps per Second: 22,434.51945
Overall Steps per Second: 10,817.01159

Timestep Collection Time: 2.22942
Timestep Consumption Time: 2.39441
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.62383

Cumulative Model Updates: 326,442
Cumulative Timesteps: 2,722,508,804

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.99932
Policy Entropy: 4.22381
Value Function Loss: 0.00305

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02052
Policy Update Magnitude: 0.26086
Value Function Update Magnitude: 0.29710

Collected Steps per Second: 22,825.69866
Overall Steps per Second: 10,989.80888

Timestep Collection Time: 2.19156
Timestep Consumption Time: 2.36029
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.55185

Cumulative Model Updates: 326,448
Cumulative Timesteps: 2,722,558,828

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2722558828...
Checkpoint 2722558828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.18751
Policy Entropy: 4.24081
Value Function Loss: 0.00301

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.01895
Policy Update Magnitude: 0.24323
Value Function Update Magnitude: 0.28125

Collected Steps per Second: 22,790.84119
Overall Steps per Second: 10,671.80310

Timestep Collection Time: 2.19509
Timestep Consumption Time: 2.49278
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.68787

Cumulative Model Updates: 326,454
Cumulative Timesteps: 2,722,608,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.65738
Policy Entropy: 4.24260
Value Function Loss: 0.00314

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.01842
Policy Update Magnitude: 0.23974
Value Function Update Magnitude: 0.27652

Collected Steps per Second: 22,730.17633
Overall Steps per Second: 10,889.82869

Timestep Collection Time: 2.20025
Timestep Consumption Time: 2.39230
PPO Batch Consumption Time: 0.27658
Total Iteration Time: 4.59254

Cumulative Model Updates: 326,460
Cumulative Timesteps: 2,722,658,868

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2722658868...
Checkpoint 2722658868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.91736
Policy Entropy: 4.23720
Value Function Loss: 0.00297

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.02254
Policy Update Magnitude: 0.24351
Value Function Update Magnitude: 0.28903

Collected Steps per Second: 23,635.01635
Overall Steps per Second: 11,030.39169

Timestep Collection Time: 2.11551
Timestep Consumption Time: 2.41743
PPO Batch Consumption Time: 0.27718
Total Iteration Time: 4.53293

Cumulative Model Updates: 326,466
Cumulative Timesteps: 2,722,708,868

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.33509
Policy Entropy: 4.24204
Value Function Loss: 0.00242

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02174
Policy Update Magnitude: 0.22841
Value Function Update Magnitude: 0.28010

Collected Steps per Second: 23,162.97296
Overall Steps per Second: 10,917.42015

Timestep Collection Time: 2.15948
Timestep Consumption Time: 2.42219
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.58167

Cumulative Model Updates: 326,472
Cumulative Timesteps: 2,722,758,888

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2722758888...
Checkpoint 2722758888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.50453
Policy Entropy: 4.27066
Value Function Loss: 0.00199

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.01587
Policy Update Magnitude: 0.21211
Value Function Update Magnitude: 0.26291

Collected Steps per Second: 22,694.99068
Overall Steps per Second: 10,907.83408

Timestep Collection Time: 2.20436
Timestep Consumption Time: 2.38207
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.58643

Cumulative Model Updates: 326,478
Cumulative Timesteps: 2,722,808,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.79627
Policy Entropy: 4.26941
Value Function Loss: 0.00201

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01554
Policy Update Magnitude: 0.20794
Value Function Update Magnitude: 0.25376

Collected Steps per Second: 23,048.03622
Overall Steps per Second: 10,697.65836

Timestep Collection Time: 2.17051
Timestep Consumption Time: 2.50584
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.67635

Cumulative Model Updates: 326,484
Cumulative Timesteps: 2,722,858,942

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2722858942...
Checkpoint 2722858942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.92136
Policy Entropy: 4.26255
Value Function Loss: 0.00241

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.01599
Policy Update Magnitude: 0.22050
Value Function Update Magnitude: 0.25598

Collected Steps per Second: 22,825.14458
Overall Steps per Second: 10,755.31075

Timestep Collection Time: 2.19162
Timestep Consumption Time: 2.45948
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.65110

Cumulative Model Updates: 326,490
Cumulative Timesteps: 2,722,908,966

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.14597
Policy Entropy: 4.26209
Value Function Loss: 0.00216

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.01841
Policy Update Magnitude: 0.22888
Value Function Update Magnitude: 0.27982

Collected Steps per Second: 23,680.96975
Overall Steps per Second: 10,932.17051

Timestep Collection Time: 2.11182
Timestep Consumption Time: 2.46275
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.57457

Cumulative Model Updates: 326,496
Cumulative Timesteps: 2,722,958,976

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2722958976...
Checkpoint 2722958976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.21499
Policy Entropy: 4.27746
Value Function Loss: 0.00190

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.01715
Policy Update Magnitude: 0.22098
Value Function Update Magnitude: 0.26916

Collected Steps per Second: 22,906.86893
Overall Steps per Second: 10,873.28941

Timestep Collection Time: 2.18284
Timestep Consumption Time: 2.41577
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.59861

Cumulative Model Updates: 326,502
Cumulative Timesteps: 2,723,008,978

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.78165
Policy Entropy: 4.26786
Value Function Loss: 0.00182

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01448
Policy Update Magnitude: 0.21659
Value Function Update Magnitude: 0.23963

Collected Steps per Second: 22,394.09489
Overall Steps per Second: 10,910.42232

Timestep Collection Time: 2.23416
Timestep Consumption Time: 2.35155
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.58571

Cumulative Model Updates: 326,508
Cumulative Timesteps: 2,723,059,010

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2723059010...
Checkpoint 2723059010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.42972
Policy Entropy: 4.26681
Value Function Loss: 0.00240

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01264
Policy Update Magnitude: 0.22219
Value Function Update Magnitude: 0.24540

Collected Steps per Second: 22,235.75062
Overall Steps per Second: 10,694.75309

Timestep Collection Time: 2.24926
Timestep Consumption Time: 2.42724
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.67650

Cumulative Model Updates: 326,514
Cumulative Timesteps: 2,723,109,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.56437
Policy Entropy: 4.23592
Value Function Loss: 0.00262

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.01585
Policy Update Magnitude: 0.24954
Value Function Update Magnitude: 0.27165

Collected Steps per Second: 22,820.96252
Overall Steps per Second: 10,904.80815

Timestep Collection Time: 2.19106
Timestep Consumption Time: 2.39426
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.58532

Cumulative Model Updates: 326,520
Cumulative Timesteps: 2,723,159,026

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2723159026...
Checkpoint 2723159026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.15793
Policy Entropy: 4.25530
Value Function Loss: 0.00246

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.01638
Policy Update Magnitude: 0.24325
Value Function Update Magnitude: 0.27003

Collected Steps per Second: 22,522.55903
Overall Steps per Second: 10,864.22426

Timestep Collection Time: 2.22097
Timestep Consumption Time: 2.38331
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.60429

Cumulative Model Updates: 326,526
Cumulative Timesteps: 2,723,209,048

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.51508
Policy Entropy: 4.22659
Value Function Loss: 0.00267

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.01978
Policy Update Magnitude: 0.25270
Value Function Update Magnitude: 0.26014

Collected Steps per Second: 23,101.08359
Overall Steps per Second: 10,743.52849

Timestep Collection Time: 2.16561
Timestep Consumption Time: 2.49096
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.65657

Cumulative Model Updates: 326,532
Cumulative Timesteps: 2,723,259,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2723259076...
Checkpoint 2723259076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.74864
Policy Entropy: 4.23951
Value Function Loss: 0.00247

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.01999
Policy Update Magnitude: 0.25654
Value Function Update Magnitude: 0.26420

Collected Steps per Second: 22,729.18932
Overall Steps per Second: 10,749.91649

Timestep Collection Time: 2.20087
Timestep Consumption Time: 2.45256
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.65343

Cumulative Model Updates: 326,538
Cumulative Timesteps: 2,723,309,100

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.25007
Policy Entropy: 4.23652
Value Function Loss: 0.00248

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.02474
Policy Update Magnitude: 0.25025
Value Function Update Magnitude: 0.26207

Collected Steps per Second: 23,597.37082
Overall Steps per Second: 10,892.22622

Timestep Collection Time: 2.11930
Timestep Consumption Time: 2.47204
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.59135

Cumulative Model Updates: 326,544
Cumulative Timesteps: 2,723,359,110

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2723359110...
Checkpoint 2723359110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.93378
Policy Entropy: 4.26143
Value Function Loss: 0.00232

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.02295
Policy Update Magnitude: 0.24121
Value Function Update Magnitude: 0.25081

Collected Steps per Second: 23,021.61002
Overall Steps per Second: 10,892.92663

Timestep Collection Time: 2.17265
Timestep Consumption Time: 2.41913
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.59179

Cumulative Model Updates: 326,550
Cumulative Timesteps: 2,723,409,128

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.78373
Policy Entropy: 4.26053
Value Function Loss: 0.00304

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.01872
Policy Update Magnitude: 0.24944
Value Function Update Magnitude: 0.25504

Collected Steps per Second: 22,498.93383
Overall Steps per Second: 10,647.60261

Timestep Collection Time: 2.22268
Timestep Consumption Time: 2.47396
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.69664

Cumulative Model Updates: 326,556
Cumulative Timesteps: 2,723,459,136

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2723459136...
Checkpoint 2723459136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.64713
Policy Entropy: 4.23139
Value Function Loss: 0.00387

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.02224
Policy Update Magnitude: 0.26399
Value Function Update Magnitude: 0.29322

Collected Steps per Second: 23,424.85333
Overall Steps per Second: 10,975.71007

Timestep Collection Time: 2.13483
Timestep Consumption Time: 2.42142
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.55624

Cumulative Model Updates: 326,562
Cumulative Timesteps: 2,723,509,144

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.89836
Policy Entropy: 4.23731
Value Function Loss: 0.00356

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.02250
Policy Update Magnitude: 0.26567
Value Function Update Magnitude: 0.32321

Collected Steps per Second: 22,843.10756
Overall Steps per Second: 10,731.19881

Timestep Collection Time: 2.19007
Timestep Consumption Time: 2.47185
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.66192

Cumulative Model Updates: 326,568
Cumulative Timesteps: 2,723,559,172

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2723559172...
Checkpoint 2723559172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.36037
Policy Entropy: 4.24869
Value Function Loss: 0.00288

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02298
Policy Update Magnitude: 0.24963
Value Function Update Magnitude: 0.31846

Collected Steps per Second: 22,741.70347
Overall Steps per Second: 10,880.09278

Timestep Collection Time: 2.19922
Timestep Consumption Time: 2.39762
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.59684

Cumulative Model Updates: 326,574
Cumulative Timesteps: 2,723,609,186

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.82610
Policy Entropy: 4.26966
Value Function Loss: 0.00251

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.01697
Policy Update Magnitude: 0.24205
Value Function Update Magnitude: 0.29560

Collected Steps per Second: 23,044.81244
Overall Steps per Second: 10,879.81258

Timestep Collection Time: 2.16969
Timestep Consumption Time: 2.42598
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.59567

Cumulative Model Updates: 326,580
Cumulative Timesteps: 2,723,659,186

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2723659186...
Checkpoint 2723659186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.09092
Policy Entropy: 4.25864
Value Function Loss: 0.00288

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.01630
Policy Update Magnitude: 0.22588
Value Function Update Magnitude: 0.27364

Collected Steps per Second: 22,571.42030
Overall Steps per Second: 10,651.99865

Timestep Collection Time: 2.21537
Timestep Consumption Time: 2.47896
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.69433

Cumulative Model Updates: 326,586
Cumulative Timesteps: 2,723,709,190

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.39551
Policy Entropy: 4.26161
Value Function Loss: 0.00296

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.01630
Policy Update Magnitude: 0.22808
Value Function Update Magnitude: 0.26737

Collected Steps per Second: 22,971.24818
Overall Steps per Second: 10,937.14603

Timestep Collection Time: 2.17716
Timestep Consumption Time: 2.39552
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.57267

Cumulative Model Updates: 326,592
Cumulative Timesteps: 2,723,759,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2723759202...
Checkpoint 2723759202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.02075
Policy Entropy: 4.26549
Value Function Loss: 0.00308

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01592
Policy Update Magnitude: 0.23390
Value Function Update Magnitude: 0.27806

Collected Steps per Second: 22,856.89631
Overall Steps per Second: 10,699.93493

Timestep Collection Time: 2.18796
Timestep Consumption Time: 2.48590
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.67386

Cumulative Model Updates: 326,598
Cumulative Timesteps: 2,723,809,212

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.56911
Policy Entropy: 4.29014
Value Function Loss: 0.00236

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.01560
Policy Update Magnitude: 0.22603
Value Function Update Magnitude: 0.30249

Collected Steps per Second: 22,742.68219
Overall Steps per Second: 10,843.24302

Timestep Collection Time: 2.19965
Timestep Consumption Time: 2.41391
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.61356

Cumulative Model Updates: 326,604
Cumulative Timesteps: 2,723,859,238

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2723859238...
Checkpoint 2723859238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.67270
Policy Entropy: 4.30329
Value Function Loss: 0.00195

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.01590
Policy Update Magnitude: 0.20691
Value Function Update Magnitude: 0.28635

Collected Steps per Second: 23,540.13120
Overall Steps per Second: 11,044.29691

Timestep Collection Time: 2.12522
Timestep Consumption Time: 2.40454
PPO Batch Consumption Time: 0.27666
Total Iteration Time: 4.52976

Cumulative Model Updates: 326,610
Cumulative Timesteps: 2,723,909,266

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.56647
Policy Entropy: 4.28585
Value Function Loss: 0.00191

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01432
Policy Update Magnitude: 0.20275
Value Function Update Magnitude: 0.26614

Collected Steps per Second: 22,985.53225
Overall Steps per Second: 10,877.07636

Timestep Collection Time: 2.17554
Timestep Consumption Time: 2.42183
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.59738

Cumulative Model Updates: 326,616
Cumulative Timesteps: 2,723,959,272

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2723959272...
Checkpoint 2723959272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.23377
Policy Entropy: 4.26612
Value Function Loss: 0.00232

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.01424
Policy Update Magnitude: 0.23198
Value Function Update Magnitude: 0.26108

Collected Steps per Second: 22,997.26729
Overall Steps per Second: 10,761.19540

Timestep Collection Time: 2.17539
Timestep Consumption Time: 2.47354
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.64893

Cumulative Model Updates: 326,622
Cumulative Timesteps: 2,724,009,300

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.72233
Policy Entropy: 4.23081
Value Function Loss: 0.00290

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.01814
Policy Update Magnitude: 0.24248
Value Function Update Magnitude: 0.27700

Collected Steps per Second: 23,619.65612
Overall Steps per Second: 10,889.91773

Timestep Collection Time: 2.11807
Timestep Consumption Time: 2.47591
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.59397

Cumulative Model Updates: 326,628
Cumulative Timesteps: 2,724,059,328

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2724059328...
Checkpoint 2724059328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.31186
Policy Entropy: 4.23640
Value Function Loss: 0.00293

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.01804
Policy Update Magnitude: 0.25872
Value Function Update Magnitude: 0.30156

Collected Steps per Second: 22,535.23614
Overall Steps per Second: 10,592.70246

Timestep Collection Time: 2.22008
Timestep Consumption Time: 2.50298
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.72306

Cumulative Model Updates: 326,634
Cumulative Timesteps: 2,724,109,358

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.35507
Policy Entropy: 4.23692
Value Function Loss: 0.00312

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.01875
Policy Update Magnitude: 0.25871
Value Function Update Magnitude: 0.31226

Collected Steps per Second: 22,788.70450
Overall Steps per Second: 10,961.43040

Timestep Collection Time: 2.19486
Timestep Consumption Time: 2.36823
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.56309

Cumulative Model Updates: 326,640
Cumulative Timesteps: 2,724,159,376

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2724159376...
Checkpoint 2724159376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.17508
Policy Entropy: 4.23117
Value Function Loss: 0.00318

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.01842
Policy Update Magnitude: 0.26440
Value Function Update Magnitude: 0.30006

Collected Steps per Second: 22,755.36540
Overall Steps per Second: 10,692.41031

Timestep Collection Time: 2.19816
Timestep Consumption Time: 2.47992
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.67808

Cumulative Model Updates: 326,646
Cumulative Timesteps: 2,724,209,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.00000
Policy Entropy: 4.24650
Value Function Loss: 0.00316

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.01845
Policy Update Magnitude: 0.26558
Value Function Update Magnitude: 0.31192

Collected Steps per Second: 22,716.51543
Overall Steps per Second: 10,900.60876

Timestep Collection Time: 2.20210
Timestep Consumption Time: 2.38700
PPO Batch Consumption Time: 0.27598
Total Iteration Time: 4.58910

Cumulative Model Updates: 326,652
Cumulative Timesteps: 2,724,259,420

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2724259420...
Checkpoint 2724259420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.97839
Policy Entropy: 4.24675
Value Function Loss: 0.00250

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.01765
Policy Update Magnitude: 0.24911
Value Function Update Magnitude: 0.31767

Collected Steps per Second: 23,575.33333
Overall Steps per Second: 11,069.24249

Timestep Collection Time: 2.12188
Timestep Consumption Time: 2.39731
PPO Batch Consumption Time: 0.27590
Total Iteration Time: 4.51919

Cumulative Model Updates: 326,658
Cumulative Timesteps: 2,724,309,444

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.08671
Policy Entropy: 4.25973
Value Function Loss: 0.00219

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.01535
Policy Update Magnitude: 0.23471
Value Function Update Magnitude: 0.28472

Collected Steps per Second: 22,905.55075
Overall Steps per Second: 10,854.41632

Timestep Collection Time: 2.18401
Timestep Consumption Time: 2.42480
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.60882

Cumulative Model Updates: 326,664
Cumulative Timesteps: 2,724,359,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2724359470...
Checkpoint 2724359470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.94509
Policy Entropy: 4.27588
Value Function Loss: 0.00191

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.01463
Policy Update Magnitude: 0.22028
Value Function Update Magnitude: 0.24892

Collected Steps per Second: 22,876.60499
Overall Steps per Second: 10,763.55461

Timestep Collection Time: 2.18599
Timestep Consumption Time: 2.46006
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.64605

Cumulative Model Updates: 326,670
Cumulative Timesteps: 2,724,409,478

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.37286
Policy Entropy: 4.27535
Value Function Loss: 0.00223

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01237
Policy Update Magnitude: 0.21460
Value Function Update Magnitude: 0.23977

Collected Steps per Second: 23,458.97030
Overall Steps per Second: 10,810.46455

Timestep Collection Time: 2.13223
Timestep Consumption Time: 2.49476
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.62700

Cumulative Model Updates: 326,676
Cumulative Timesteps: 2,724,459,498

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2724459498...
Checkpoint 2724459498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.71431
Policy Entropy: 4.27172
Value Function Loss: 0.00187

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.01384
Policy Update Magnitude: 0.22163
Value Function Update Magnitude: 0.23924

Collected Steps per Second: 22,647.10009
Overall Steps per Second: 10,642.20313

Timestep Collection Time: 2.20867
Timestep Consumption Time: 2.49148
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.70015

Cumulative Model Updates: 326,682
Cumulative Timesteps: 2,724,509,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.05846
Policy Entropy: 4.24995
Value Function Loss: 0.00269

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.01657
Policy Update Magnitude: 0.22085
Value Function Update Magnitude: 0.24284

Collected Steps per Second: 22,630.10467
Overall Steps per Second: 10,940.32309

Timestep Collection Time: 2.21086
Timestep Consumption Time: 2.36231
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.57317

Cumulative Model Updates: 326,688
Cumulative Timesteps: 2,724,559,550

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2724559550...
Checkpoint 2724559550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.44941
Policy Entropy: 4.24914
Value Function Loss: 0.00290

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.01749
Policy Update Magnitude: 0.22395
Value Function Update Magnitude: 0.24939

Collected Steps per Second: 22,838.22156
Overall Steps per Second: 10,727.75648

Timestep Collection Time: 2.18940
Timestep Consumption Time: 2.47159
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.66099

Cumulative Model Updates: 326,694
Cumulative Timesteps: 2,724,609,552

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.99881
Policy Entropy: 4.24253
Value Function Loss: 0.00295

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.01675
Policy Update Magnitude: 0.23003
Value Function Update Magnitude: 0.26417

Collected Steps per Second: 23,064.37957
Overall Steps per Second: 10,815.65136

Timestep Collection Time: 2.16845
Timestep Consumption Time: 2.45577
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.62422

Cumulative Model Updates: 326,700
Cumulative Timesteps: 2,724,659,566

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2724659566...
Checkpoint 2724659566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.98754
Policy Entropy: 4.23564
Value Function Loss: 0.00270

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.01627
Policy Update Magnitude: 0.23138
Value Function Update Magnitude: 0.27152

Collected Steps per Second: 22,713.52031
Overall Steps per Second: 11,017.24953

Timestep Collection Time: 2.20160
Timestep Consumption Time: 2.33729
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.53888

Cumulative Model Updates: 326,706
Cumulative Timesteps: 2,724,709,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.83399
Policy Entropy: 4.24035
Value Function Loss: 0.00237

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.01665
Policy Update Magnitude: 0.23305
Value Function Update Magnitude: 0.27065

Collected Steps per Second: 22,852.96988
Overall Steps per Second: 10,778.97163

Timestep Collection Time: 2.18877
Timestep Consumption Time: 2.45174
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.64052

Cumulative Model Updates: 326,712
Cumulative Timesteps: 2,724,759,592

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2724759592...
Checkpoint 2724759592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.11936
Policy Entropy: 4.22125
Value Function Loss: 0.00279

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.01866
Policy Update Magnitude: 0.24017
Value Function Update Magnitude: 0.27650

Collected Steps per Second: 22,644.72011
Overall Steps per Second: 10,886.43059

Timestep Collection Time: 2.20961
Timestep Consumption Time: 2.38657
PPO Batch Consumption Time: 0.27522
Total Iteration Time: 4.59618

Cumulative Model Updates: 326,718
Cumulative Timesteps: 2,724,809,628

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.34582
Policy Entropy: 4.22523
Value Function Loss: 0.00246

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.01966
Policy Update Magnitude: 0.25052
Value Function Update Magnitude: 0.28977

Collected Steps per Second: 23,696.69706
Overall Steps per Second: 10,868.60491

Timestep Collection Time: 2.11084
Timestep Consumption Time: 2.49140
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.60225

Cumulative Model Updates: 326,724
Cumulative Timesteps: 2,724,859,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2724859648...
Checkpoint 2724859648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.16712
Policy Entropy: 4.24684
Value Function Loss: 0.00218

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.01891
Policy Update Magnitude: 0.24100
Value Function Update Magnitude: 0.28919

Collected Steps per Second: 22,687.92172
Overall Steps per Second: 10,645.72794

Timestep Collection Time: 2.20434
Timestep Consumption Time: 2.49350
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.69785

Cumulative Model Updates: 326,730
Cumulative Timesteps: 2,724,909,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.93469
Policy Entropy: 4.24692
Value Function Loss: 0.00244

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.01773
Policy Update Magnitude: 0.22885
Value Function Update Magnitude: 0.28585

Collected Steps per Second: 22,937.05698
Overall Steps per Second: 10,903.35445

Timestep Collection Time: 2.18014
Timestep Consumption Time: 2.40615
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.58630

Cumulative Model Updates: 326,736
Cumulative Timesteps: 2,724,959,666

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2724959666...
Checkpoint 2724959666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.77100
Policy Entropy: 4.24829
Value Function Loss: 0.00281

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01605
Policy Update Magnitude: 0.26215
Value Function Update Magnitude: 0.29755

Collected Steps per Second: 22,686.30617
Overall Steps per Second: 10,613.33199

Timestep Collection Time: 2.20424
Timestep Consumption Time: 2.50738
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.71162

Cumulative Model Updates: 326,742
Cumulative Timesteps: 2,725,009,672

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.04996
Policy Entropy: 4.22728
Value Function Loss: 0.00278

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02117
Policy Update Magnitude: 0.25552
Value Function Update Magnitude: 0.30970

Collected Steps per Second: 22,768.07778
Overall Steps per Second: 10,683.84077

Timestep Collection Time: 2.19720
Timestep Consumption Time: 2.48520
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.68240

Cumulative Model Updates: 326,748
Cumulative Timesteps: 2,725,059,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2725059698...
Checkpoint 2725059698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.96032
Policy Entropy: 4.26095
Value Function Loss: 0.00263

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02000
Policy Update Magnitude: 0.23802
Value Function Update Magnitude: 0.28751

Collected Steps per Second: 22,590.18708
Overall Steps per Second: 10,914.98148

Timestep Collection Time: 2.21539
Timestep Consumption Time: 2.36969
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.58507

Cumulative Model Updates: 326,754
Cumulative Timesteps: 2,725,109,744

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.58492
Policy Entropy: 4.25027
Value Function Loss: 0.00264

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02014
Policy Update Magnitude: 0.23617
Value Function Update Magnitude: 0.24936

Collected Steps per Second: 23,000.38426
Overall Steps per Second: 10,940.04066

Timestep Collection Time: 2.17431
Timestep Consumption Time: 2.39697
PPO Batch Consumption Time: 0.27570
Total Iteration Time: 4.57128

Cumulative Model Updates: 326,760
Cumulative Timesteps: 2,725,159,754

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2725159754...
Checkpoint 2725159754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.58682
Policy Entropy: 4.24518
Value Function Loss: 0.00309

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.01883
Policy Update Magnitude: 0.23869
Value Function Update Magnitude: 0.24796

Collected Steps per Second: 22,733.04256
Overall Steps per Second: 10,782.17566

Timestep Collection Time: 2.19953
Timestep Consumption Time: 2.43794
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.63747

Cumulative Model Updates: 326,766
Cumulative Timesteps: 2,725,209,756

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.27371
Policy Entropy: 4.24896
Value Function Loss: 0.00253

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.01897
Policy Update Magnitude: 0.23905
Value Function Update Magnitude: 0.27738

Collected Steps per Second: 22,834.19905
Overall Steps per Second: 10,938.62623

Timestep Collection Time: 2.18970
Timestep Consumption Time: 2.38126
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.57096

Cumulative Model Updates: 326,772
Cumulative Timesteps: 2,725,259,756

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2725259756...
Checkpoint 2725259756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.46021
Policy Entropy: 4.23991
Value Function Loss: 0.00305

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.01758
Policy Update Magnitude: 0.24715
Value Function Update Magnitude: 0.29798

Collected Steps per Second: 22,663.91795
Overall Steps per Second: 10,811.14543

Timestep Collection Time: 2.20694
Timestep Consumption Time: 2.41958
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.62652

Cumulative Model Updates: 326,778
Cumulative Timesteps: 2,725,309,774

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.17994
Policy Entropy: 4.25690
Value Function Loss: 0.00259

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.01759
Policy Update Magnitude: 0.23877
Value Function Update Magnitude: 0.31034

Collected Steps per Second: 22,628.63145
Overall Steps per Second: 10,738.71088

Timestep Collection Time: 2.21012
Timestep Consumption Time: 2.44705
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.65717

Cumulative Model Updates: 326,784
Cumulative Timesteps: 2,725,359,786

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2725359786...
Checkpoint 2725359786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.62673
Policy Entropy: 4.26350
Value Function Loss: 0.00229

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.01655
Policy Update Magnitude: 0.23394
Value Function Update Magnitude: 0.29938

Collected Steps per Second: 23,495.03046
Overall Steps per Second: 10,899.82862

Timestep Collection Time: 2.12879
Timestep Consumption Time: 2.45991
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.58870

Cumulative Model Updates: 326,790
Cumulative Timesteps: 2,725,409,802

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.56277
Policy Entropy: 4.27747
Value Function Loss: 0.00252

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01379
Policy Update Magnitude: 0.23750
Value Function Update Magnitude: 0.27052

Collected Steps per Second: 22,706.59612
Overall Steps per Second: 10,776.30524

Timestep Collection Time: 2.20297
Timestep Consumption Time: 2.43888
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.64185

Cumulative Model Updates: 326,796
Cumulative Timesteps: 2,725,459,824

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2725459824...
Checkpoint 2725459824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.80007
Policy Entropy: 4.26997
Value Function Loss: 0.00239

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.01441
Policy Update Magnitude: 0.23308
Value Function Update Magnitude: 0.25764

Collected Steps per Second: 22,446.45839
Overall Steps per Second: 10,759.72715

Timestep Collection Time: 2.22788
Timestep Consumption Time: 2.41982
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.64770

Cumulative Model Updates: 326,802
Cumulative Timesteps: 2,725,509,832

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.53965
Policy Entropy: 4.22291
Value Function Loss: 0.00352

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.01956
Policy Update Magnitude: 0.26943
Value Function Update Magnitude: 0.27871

Collected Steps per Second: 23,105.72502
Overall Steps per Second: 10,898.42933

Timestep Collection Time: 2.16492
Timestep Consumption Time: 2.42492
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.58984

Cumulative Model Updates: 326,808
Cumulative Timesteps: 2,725,559,854

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2725559854...
Checkpoint 2725559854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.57889
Policy Entropy: 4.21826
Value Function Loss: 0.00353

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.02182
Policy Update Magnitude: 0.28260
Value Function Update Magnitude: 0.31758

Collected Steps per Second: 22,729.81311
Overall Steps per Second: 10,756.65073

Timestep Collection Time: 2.20081
Timestep Consumption Time: 2.44971
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.65052

Cumulative Model Updates: 326,814
Cumulative Timesteps: 2,725,609,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.00382
Policy Entropy: 4.21479
Value Function Loss: 0.00340

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.02050
Policy Update Magnitude: 0.26993
Value Function Update Magnitude: 0.33657

Collected Steps per Second: 22,431.14399
Overall Steps per Second: 10,804.11990

Timestep Collection Time: 2.22949
Timestep Consumption Time: 2.39930
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.62879

Cumulative Model Updates: 326,820
Cumulative Timesteps: 2,725,659,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2725659888...
Checkpoint 2725659888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.48572
Policy Entropy: 4.24530
Value Function Loss: 0.00276

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.01840
Policy Update Magnitude: 0.25564
Value Function Update Magnitude: 0.30712

Collected Steps per Second: 22,726.66855
Overall Steps per Second: 10,665.02800

Timestep Collection Time: 2.20059
Timestep Consumption Time: 2.48876
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.68935

Cumulative Model Updates: 326,826
Cumulative Timesteps: 2,725,709,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.47054
Policy Entropy: 4.25882
Value Function Loss: 0.00259

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.01797
Policy Update Magnitude: 0.23485
Value Function Update Magnitude: 0.28585

Collected Steps per Second: 22,727.24898
Overall Steps per Second: 10,843.96093

Timestep Collection Time: 2.20097
Timestep Consumption Time: 2.41192
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.61289

Cumulative Model Updates: 326,832
Cumulative Timesteps: 2,725,759,922

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2725759922...
Checkpoint 2725759922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.77831
Policy Entropy: 4.26076
Value Function Loss: 0.00262

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01531
Policy Update Magnitude: 0.22251
Value Function Update Magnitude: 0.29800

Collected Steps per Second: 23,388.79247
Overall Steps per Second: 10,891.61545

Timestep Collection Time: 2.13829
Timestep Consumption Time: 2.45350
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.59179

Cumulative Model Updates: 326,838
Cumulative Timesteps: 2,725,809,934

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.30106
Policy Entropy: 4.23507
Value Function Loss: 0.00281

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.01703
Policy Update Magnitude: 0.23841
Value Function Update Magnitude: 0.32715

Collected Steps per Second: 22,625.73014
Overall Steps per Second: 10,697.09586

Timestep Collection Time: 2.21049
Timestep Consumption Time: 2.46498
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.67547

Cumulative Model Updates: 326,844
Cumulative Timesteps: 2,725,859,948

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2725859948...
Checkpoint 2725859948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.99998
Policy Entropy: 4.24368
Value Function Loss: 0.00293

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.01672
Policy Update Magnitude: 0.25178
Value Function Update Magnitude: 0.31558

Collected Steps per Second: 22,854.85036
Overall Steps per Second: 10,793.53011

Timestep Collection Time: 2.18851
Timestep Consumption Time: 2.44557
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.63407

Cumulative Model Updates: 326,850
Cumulative Timesteps: 2,725,909,966

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.30135
Policy Entropy: 4.21437
Value Function Loss: 0.00330

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02177
Policy Update Magnitude: 0.26285
Value Function Update Magnitude: 0.31867

Collected Steps per Second: 24,022.29684
Overall Steps per Second: 11,000.02958

Timestep Collection Time: 2.08223
Timestep Consumption Time: 2.46503
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.54726

Cumulative Model Updates: 326,856
Cumulative Timesteps: 2,725,959,986

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2725959986...
Checkpoint 2725959986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.68027
Policy Entropy: 4.23026
Value Function Loss: 0.00277

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02164
Policy Update Magnitude: 0.25177
Value Function Update Magnitude: 0.33441

Collected Steps per Second: 22,434.90467
Overall Steps per Second: 10,794.06011

Timestep Collection Time: 2.22992
Timestep Consumption Time: 2.40485
PPO Batch Consumption Time: 0.27700
Total Iteration Time: 4.63477

Cumulative Model Updates: 326,862
Cumulative Timesteps: 2,726,010,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.72122
Policy Entropy: 4.23006
Value Function Loss: 0.00257

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02266
Policy Update Magnitude: 0.24474
Value Function Update Magnitude: 0.33246

Collected Steps per Second: 22,690.24777
Overall Steps per Second: 11,006.37622

Timestep Collection Time: 2.20447
Timestep Consumption Time: 2.34017
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.54464

Cumulative Model Updates: 326,868
Cumulative Timesteps: 2,726,060,034

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2726060034...
Checkpoint 2726060034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.19996
Policy Entropy: 4.24304
Value Function Loss: 0.00224

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02430
Policy Update Magnitude: 0.23452
Value Function Update Magnitude: 0.29308

Collected Steps per Second: 22,558.91958
Overall Steps per Second: 10,664.10163

Timestep Collection Time: 2.21704
Timestep Consumption Time: 2.47290
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.68994

Cumulative Model Updates: 326,874
Cumulative Timesteps: 2,726,110,048

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.36463
Policy Entropy: 4.27014
Value Function Loss: 0.00207

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02148
Policy Update Magnitude: 0.22262
Value Function Update Magnitude: 0.27808

Collected Steps per Second: 23,172.97232
Overall Steps per Second: 10,889.51420

Timestep Collection Time: 2.15898
Timestep Consumption Time: 2.43535
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.59433

Cumulative Model Updates: 326,880
Cumulative Timesteps: 2,726,160,078

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2726160078...
Checkpoint 2726160078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.31758
Policy Entropy: 4.25378
Value Function Loss: 0.00226

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.01986
Policy Update Magnitude: 0.22709
Value Function Update Magnitude: 0.28965

Collected Steps per Second: 23,420.34400
Overall Steps per Second: 11,010.44626

Timestep Collection Time: 2.13601
Timestep Consumption Time: 2.40750
PPO Batch Consumption Time: 0.27703
Total Iteration Time: 4.54350

Cumulative Model Updates: 326,886
Cumulative Timesteps: 2,726,210,104

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.89357
Policy Entropy: 4.27307
Value Function Loss: 0.00198

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.01973
Policy Update Magnitude: 0.22166
Value Function Update Magnitude: 0.29270

Collected Steps per Second: 22,880.34688
Overall Steps per Second: 10,730.26090

Timestep Collection Time: 2.18563
Timestep Consumption Time: 2.47483
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.66046

Cumulative Model Updates: 326,892
Cumulative Timesteps: 2,726,260,112

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2726260112...
Checkpoint 2726260112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.87009
Policy Entropy: 4.25459
Value Function Loss: 0.00180

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.01694
Policy Update Magnitude: 0.22184
Value Function Update Magnitude: 0.28391

Collected Steps per Second: 22,283.12410
Overall Steps per Second: 10,934.58563

Timestep Collection Time: 2.24412
Timestep Consumption Time: 2.32908
PPO Batch Consumption Time: 0.27527
Total Iteration Time: 4.57320

Cumulative Model Updates: 326,898
Cumulative Timesteps: 2,726,310,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.51641
Policy Entropy: 4.23918
Value Function Loss: 0.00266

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01636
Policy Update Magnitude: 0.24927
Value Function Update Magnitude: 0.30325

Collected Steps per Second: 22,872.76431
Overall Steps per Second: 10,871.89559

Timestep Collection Time: 2.18644
Timestep Consumption Time: 2.41349
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.59993

Cumulative Model Updates: 326,904
Cumulative Timesteps: 2,726,360,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2726360128...
Checkpoint 2726360128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.67073
Policy Entropy: 4.20758
Value Function Loss: 0.00335

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02224
Policy Update Magnitude: 0.27921
Value Function Update Magnitude: 0.34228

Collected Steps per Second: 22,697.64745
Overall Steps per Second: 10,733.69382

Timestep Collection Time: 2.20305
Timestep Consumption Time: 2.45555
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.65860

Cumulative Model Updates: 326,910
Cumulative Timesteps: 2,726,410,132

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.36823
Policy Entropy: 4.19200
Value Function Loss: 0.00407

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.02450
Policy Update Magnitude: 0.30107
Value Function Update Magnitude: 0.37846

Collected Steps per Second: 23,651.77728
Overall Steps per Second: 10,898.59851

Timestep Collection Time: 2.11451
Timestep Consumption Time: 2.47433
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.58885

Cumulative Model Updates: 326,916
Cumulative Timesteps: 2,726,460,144

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2726460144...
Checkpoint 2726460144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.17586
Policy Entropy: 4.22077
Value Function Loss: 0.00399

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.02272
Policy Update Magnitude: 0.29936
Value Function Update Magnitude: 0.38712

Collected Steps per Second: 23,000.38585
Overall Steps per Second: 10,922.76396

Timestep Collection Time: 2.17518
Timestep Consumption Time: 2.40516
PPO Batch Consumption Time: 0.27704
Total Iteration Time: 4.58034

Cumulative Model Updates: 326,922
Cumulative Timesteps: 2,726,510,174

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.28286
Policy Entropy: 4.24697
Value Function Loss: 0.00323

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.02223
Policy Update Magnitude: 0.28169
Value Function Update Magnitude: 0.36218

Collected Steps per Second: 23,040.66477
Overall Steps per Second: 10,948.15113

Timestep Collection Time: 2.17077
Timestep Consumption Time: 2.39767
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.56844

Cumulative Model Updates: 326,928
Cumulative Timesteps: 2,726,560,190

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2726560190...
Checkpoint 2726560190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.50749
Policy Entropy: 4.24206
Value Function Loss: 0.00285

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02063
Policy Update Magnitude: 0.24937
Value Function Update Magnitude: 0.31904

Collected Steps per Second: 23,193.31454
Overall Steps per Second: 10,801.17132

Timestep Collection Time: 2.15622
Timestep Consumption Time: 2.47383
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.63005

Cumulative Model Updates: 326,934
Cumulative Timesteps: 2,726,610,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.50878
Policy Entropy: 4.22381
Value Function Loss: 0.00260

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.01733
Policy Update Magnitude: 0.24675
Value Function Update Magnitude: 0.30019

Collected Steps per Second: 22,587.04574
Overall Steps per Second: 10,759.48560

Timestep Collection Time: 2.21472
Timestep Consumption Time: 2.43457
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.64929

Cumulative Model Updates: 326,940
Cumulative Timesteps: 2,726,660,224

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2726660224...
Checkpoint 2726660224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.10755
Policy Entropy: 4.18504
Value Function Loss: 0.00301

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02103
Policy Update Magnitude: 0.25606
Value Function Update Magnitude: 0.32172

Collected Steps per Second: 22,619.60944
Overall Steps per Second: 10,878.41789

Timestep Collection Time: 2.21136
Timestep Consumption Time: 2.38674
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.59810

Cumulative Model Updates: 326,946
Cumulative Timesteps: 2,726,710,244

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.69040
Policy Entropy: 4.18692
Value Function Loss: 0.00312

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02223
Policy Update Magnitude: 0.26421
Value Function Update Magnitude: 0.32588

Collected Steps per Second: 22,761.68254
Overall Steps per Second: 10,730.20194

Timestep Collection Time: 2.19711
Timestep Consumption Time: 2.46356
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.66068

Cumulative Model Updates: 326,952
Cumulative Timesteps: 2,726,760,254

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2726760254...
Checkpoint 2726760254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.21500
Policy Entropy: 4.20875
Value Function Loss: 0.00282

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.02162
Policy Update Magnitude: 0.26555
Value Function Update Magnitude: 0.31481

Collected Steps per Second: 22,539.43454
Overall Steps per Second: 10,661.23312

Timestep Collection Time: 2.21842
Timestep Consumption Time: 2.47165
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.69008

Cumulative Model Updates: 326,958
Cumulative Timesteps: 2,726,810,256

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.92140
Policy Entropy: 4.25094
Value Function Loss: 0.00234

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.01606
Policy Update Magnitude: 0.24244
Value Function Update Magnitude: 0.30400

Collected Steps per Second: 23,532.26840
Overall Steps per Second: 10,886.81877

Timestep Collection Time: 2.12508
Timestep Consumption Time: 2.46836
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.59344

Cumulative Model Updates: 326,964
Cumulative Timesteps: 2,726,860,264

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2726860264...
Checkpoint 2726860264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.38231
Policy Entropy: 4.25201
Value Function Loss: 0.00254

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01418
Policy Update Magnitude: 0.23999
Value Function Update Magnitude: 0.28846

Collected Steps per Second: 22,845.89412
Overall Steps per Second: 10,681.87682

Timestep Collection Time: 2.18945
Timestep Consumption Time: 2.49325
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.68270

Cumulative Model Updates: 326,970
Cumulative Timesteps: 2,726,910,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.60187
Policy Entropy: 4.24979
Value Function Loss: 0.00267

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.01608
Policy Update Magnitude: 0.24407
Value Function Update Magnitude: 0.29013

Collected Steps per Second: 22,710.57657
Overall Steps per Second: 10,836.41125

Timestep Collection Time: 2.20206
Timestep Consumption Time: 2.41294
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.61500

Cumulative Model Updates: 326,976
Cumulative Timesteps: 2,726,960,294

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2726960294...
Checkpoint 2726960294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.98201
Policy Entropy: 4.22721
Value Function Loss: 0.00324

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.01726
Policy Update Magnitude: 0.24610
Value Function Update Magnitude: 0.31479

Collected Steps per Second: 23,036.88891
Overall Steps per Second: 10,761.05158

Timestep Collection Time: 2.17113
Timestep Consumption Time: 2.47675
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.64787

Cumulative Model Updates: 326,982
Cumulative Timesteps: 2,727,010,310

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.15524
Policy Entropy: 4.18166
Value Function Loss: 0.00391

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.01701
Policy Update Magnitude: 0.27309
Value Function Update Magnitude: 0.33832

Collected Steps per Second: 22,813.08831
Overall Steps per Second: 10,789.61907

Timestep Collection Time: 2.19172
Timestep Consumption Time: 2.44236
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.63408

Cumulative Model Updates: 326,988
Cumulative Timesteps: 2,727,060,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2727060310...
Checkpoint 2727060310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.52110
Policy Entropy: 4.16966
Value Function Loss: 0.00353

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02148
Policy Update Magnitude: 0.29265
Value Function Update Magnitude: 0.36288

Collected Steps per Second: 22,594.42328
Overall Steps per Second: 10,886.44328

Timestep Collection Time: 2.21426
Timestep Consumption Time: 2.38136
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.59562

Cumulative Model Updates: 326,994
Cumulative Timesteps: 2,727,110,340

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.75453
Policy Entropy: 4.17975
Value Function Loss: 0.00304

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.02385
Policy Update Magnitude: 0.27776
Value Function Update Magnitude: 0.35884

Collected Steps per Second: 22,916.85907
Overall Steps per Second: 10,729.60637

Timestep Collection Time: 2.18293
Timestep Consumption Time: 2.47949
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.66243

Cumulative Model Updates: 327,000
Cumulative Timesteps: 2,727,160,366

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2727160366...
Checkpoint 2727160366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.87125
Policy Entropy: 4.22215
Value Function Loss: 0.00230

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.01867
Policy Update Magnitude: 0.25435
Value Function Update Magnitude: 0.31157

Collected Steps per Second: 22,671.03285
Overall Steps per Second: 10,764.61678

Timestep Collection Time: 2.20678
Timestep Consumption Time: 2.44085
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.64763

Cumulative Model Updates: 327,006
Cumulative Timesteps: 2,727,210,396

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.26245
Policy Entropy: 4.24209
Value Function Loss: 0.00247

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.01733
Policy Update Magnitude: 0.23592
Value Function Update Magnitude: 0.29837

Collected Steps per Second: 23,883.80988
Overall Steps per Second: 10,967.19895

Timestep Collection Time: 2.09531
Timestep Consumption Time: 2.46775
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.56306

Cumulative Model Updates: 327,012
Cumulative Timesteps: 2,727,260,440

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2727260440...
Checkpoint 2727260440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.95490
Policy Entropy: 4.21921
Value Function Loss: 0.00224

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01771
Policy Update Magnitude: 0.23274
Value Function Update Magnitude: 0.30692

Collected Steps per Second: 22,642.48667
Overall Steps per Second: 10,803.51056

Timestep Collection Time: 2.20877
Timestep Consumption Time: 2.42047
PPO Batch Consumption Time: 0.27690
Total Iteration Time: 4.62924

Cumulative Model Updates: 327,018
Cumulative Timesteps: 2,727,310,452

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.24900
Policy Entropy: 4.23835
Value Function Loss: 0.00243

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01767
Policy Update Magnitude: 0.23140
Value Function Update Magnitude: 0.30324

Collected Steps per Second: 22,910.15489
Overall Steps per Second: 10,941.71651

Timestep Collection Time: 2.18322
Timestep Consumption Time: 2.38809
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.57131

Cumulative Model Updates: 327,024
Cumulative Timesteps: 2,727,360,470

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2727360470...
Checkpoint 2727360470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.27170
Policy Entropy: 4.23675
Value Function Loss: 0.00247

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.01863
Policy Update Magnitude: 0.24508
Value Function Update Magnitude: 0.30099

Collected Steps per Second: 23,460.89210
Overall Steps per Second: 10,882.27774

Timestep Collection Time: 2.13146
Timestep Consumption Time: 2.46372
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.59518

Cumulative Model Updates: 327,030
Cumulative Timesteps: 2,727,410,476

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.69889
Policy Entropy: 4.23657
Value Function Loss: 0.00305

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.01713
Policy Update Magnitude: 0.24710
Value Function Update Magnitude: 0.29660

Collected Steps per Second: 22,877.33248
Overall Steps per Second: 10,719.41050

Timestep Collection Time: 2.18636
Timestep Consumption Time: 2.47976
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.66611

Cumulative Model Updates: 327,036
Cumulative Timesteps: 2,727,460,494

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2727460494...
Checkpoint 2727460494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.32947
Policy Entropy: 4.22054
Value Function Loss: 0.00292

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.01926
Policy Update Magnitude: 0.25375
Value Function Update Magnitude: 0.30293

Collected Steps per Second: 22,573.32268
Overall Steps per Second: 11,009.67007

Timestep Collection Time: 2.21598
Timestep Consumption Time: 2.32748
PPO Batch Consumption Time: 0.27678
Total Iteration Time: 4.54346

Cumulative Model Updates: 327,042
Cumulative Timesteps: 2,727,510,516

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.28265
Policy Entropy: 4.20264
Value Function Loss: 0.00330

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02154
Policy Update Magnitude: 0.26077
Value Function Update Magnitude: 0.30815

Collected Steps per Second: 22,824.40436
Overall Steps per Second: 10,716.70039

Timestep Collection Time: 2.19143
Timestep Consumption Time: 2.47587
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.66729

Cumulative Model Updates: 327,048
Cumulative Timesteps: 2,727,560,534

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2727560534...
Checkpoint 2727560534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.92508
Policy Entropy: 4.19966
Value Function Loss: 0.00348

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.01982
Policy Update Magnitude: 0.27202
Value Function Update Magnitude: 0.31595

Collected Steps per Second: 22,603.50193
Overall Steps per Second: 10,860.70678

Timestep Collection Time: 2.21214
Timestep Consumption Time: 2.39180
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.60394

Cumulative Model Updates: 327,054
Cumulative Timesteps: 2,727,610,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.20471
Policy Entropy: 4.21360
Value Function Loss: 0.00325

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02292
Policy Update Magnitude: 0.27203
Value Function Update Magnitude: 0.31191

Collected Steps per Second: 22,905.43345
Overall Steps per Second: 11,052.12579

Timestep Collection Time: 2.18411
Timestep Consumption Time: 2.34244
PPO Batch Consumption Time: 0.27589
Total Iteration Time: 4.52655

Cumulative Model Updates: 327,060
Cumulative Timesteps: 2,727,660,564

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2727660564...
Checkpoint 2727660564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.84795
Policy Entropy: 4.23588
Value Function Loss: 0.00263

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02099
Policy Update Magnitude: 0.24399
Value Function Update Magnitude: 0.30241

Collected Steps per Second: 22,779.41141
Overall Steps per Second: 10,715.69781

Timestep Collection Time: 2.19663
Timestep Consumption Time: 2.47297
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.66960

Cumulative Model Updates: 327,066
Cumulative Timesteps: 2,727,710,602

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.95744
Policy Entropy: 4.26872
Value Function Loss: 0.00189

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01539
Policy Update Magnitude: 0.22007
Value Function Update Magnitude: 0.26365

Collected Steps per Second: 22,976.73639
Overall Steps per Second: 10,774.82351

Timestep Collection Time: 2.17690
Timestep Consumption Time: 2.46522
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.64212

Cumulative Model Updates: 327,072
Cumulative Timesteps: 2,727,760,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2727760620...
Checkpoint 2727760620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.66733
Policy Entropy: 4.29714
Value Function Loss: 0.00161

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.01474
Policy Update Magnitude: 0.19695
Value Function Update Magnitude: 0.22796

Collected Steps per Second: 23,709.59136
Overall Steps per Second: 11,042.74311

Timestep Collection Time: 2.10902
Timestep Consumption Time: 2.41920
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.52822

Cumulative Model Updates: 327,078
Cumulative Timesteps: 2,727,810,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.67282
Policy Entropy: 4.26980
Value Function Loss: 0.00197

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.01408
Policy Update Magnitude: 0.20318
Value Function Update Magnitude: 0.22624

Collected Steps per Second: 22,830.97624
Overall Steps per Second: 10,755.12077

Timestep Collection Time: 2.19097
Timestep Consumption Time: 2.46002
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.65099

Cumulative Model Updates: 327,084
Cumulative Timesteps: 2,727,860,646

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2727860646...
Checkpoint 2727860646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.57677
Policy Entropy: 4.24756
Value Function Loss: 0.00234

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.01521
Policy Update Magnitude: 0.23133
Value Function Update Magnitude: 0.26043

Collected Steps per Second: 22,467.29439
Overall Steps per Second: 10,786.31666

Timestep Collection Time: 2.22590
Timestep Consumption Time: 2.41053
PPO Batch Consumption Time: 0.27662
Total Iteration Time: 4.63643

Cumulative Model Updates: 327,090
Cumulative Timesteps: 2,727,910,656

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.79873
Policy Entropy: 4.24255
Value Function Loss: 0.00215

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.01917
Policy Update Magnitude: 0.23750
Value Function Update Magnitude: 0.26790

Collected Steps per Second: 23,546.58513
Overall Steps per Second: 11,035.64016

Timestep Collection Time: 2.12354
Timestep Consumption Time: 2.40742
PPO Batch Consumption Time: 0.27573
Total Iteration Time: 4.53096

Cumulative Model Updates: 327,096
Cumulative Timesteps: 2,727,960,658

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2727960658...
Checkpoint 2727960658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.26322
Policy Entropy: 4.26696
Value Function Loss: 0.00179

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.01841
Policy Update Magnitude: 0.21512
Value Function Update Magnitude: 0.25347

Collected Steps per Second: 22,959.68423
Overall Steps per Second: 10,770.60953

Timestep Collection Time: 2.17869
Timestep Consumption Time: 2.46562
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.64431

Cumulative Model Updates: 327,102
Cumulative Timesteps: 2,728,010,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.84208
Policy Entropy: 4.27388
Value Function Loss: 0.00230

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02054
Policy Update Magnitude: 0.22557
Value Function Update Magnitude: 0.25157

Collected Steps per Second: 22,915.30882
Overall Steps per Second: 10,948.60788

Timestep Collection Time: 2.18299
Timestep Consumption Time: 2.38599
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.56898

Cumulative Model Updates: 327,108
Cumulative Timesteps: 2,728,060,704

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2728060704...
Checkpoint 2728060704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.33853
Policy Entropy: 4.25080
Value Function Loss: 0.00321

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.02453
Policy Update Magnitude: 0.26232
Value Function Update Magnitude: 0.29731

Collected Steps per Second: 22,804.36543
Overall Steps per Second: 10,840.64552

Timestep Collection Time: 2.19414
Timestep Consumption Time: 2.42145
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.61559

Cumulative Model Updates: 327,114
Cumulative Timesteps: 2,728,110,740

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.90007
Policy Entropy: 4.25289
Value Function Loss: 0.00305

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.02493
Policy Update Magnitude: 0.26567
Value Function Update Magnitude: 0.35110

Collected Steps per Second: 22,975.73308
Overall Steps per Second: 10,929.50417

Timestep Collection Time: 2.17760
Timestep Consumption Time: 2.40010
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.57770

Cumulative Model Updates: 327,120
Cumulative Timesteps: 2,728,160,772

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2728160772...
Checkpoint 2728160772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.17099
Policy Entropy: 4.26180
Value Function Loss: 0.00278

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02178
Policy Update Magnitude: 0.25134
Value Function Update Magnitude: 0.31315

Collected Steps per Second: 23,384.15608
Overall Steps per Second: 10,857.86771

Timestep Collection Time: 2.13914
Timestep Consumption Time: 2.46784
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.60698

Cumulative Model Updates: 327,126
Cumulative Timesteps: 2,728,210,794

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.41386
Policy Entropy: 4.25984
Value Function Loss: 0.00281

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02090
Policy Update Magnitude: 0.24657
Value Function Update Magnitude: 0.29130

Collected Steps per Second: 22,898.84198
Overall Steps per Second: 10,743.16051

Timestep Collection Time: 2.18474
Timestep Consumption Time: 2.47199
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.65673

Cumulative Model Updates: 327,132
Cumulative Timesteps: 2,728,260,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2728260822...
Checkpoint 2728260822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.33046
Policy Entropy: 4.26063
Value Function Loss: 0.00234

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.01921
Policy Update Magnitude: 0.23955
Value Function Update Magnitude: 0.29029

Collected Steps per Second: 22,498.33953
Overall Steps per Second: 10,660.20345

Timestep Collection Time: 2.22301
Timestep Consumption Time: 2.46865
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.69166

Cumulative Model Updates: 327,138
Cumulative Timesteps: 2,728,310,836

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.70262
Policy Entropy: 4.27029
Value Function Loss: 0.00241

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01517
Policy Update Magnitude: 0.22918
Value Function Update Magnitude: 0.26556

Collected Steps per Second: 23,720.99534
Overall Steps per Second: 10,873.01683

Timestep Collection Time: 2.10876
Timestep Consumption Time: 2.49180
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.60056

Cumulative Model Updates: 327,144
Cumulative Timesteps: 2,728,360,858

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2728360858...
Checkpoint 2728360858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.38564
Policy Entropy: 4.25880
Value Function Loss: 0.00266

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01779
Policy Update Magnitude: 0.24006
Value Function Update Magnitude: 0.25385

Collected Steps per Second: 22,748.08536
Overall Steps per Second: 10,684.81291

Timestep Collection Time: 2.19808
Timestep Consumption Time: 2.48165
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.67973

Cumulative Model Updates: 327,150
Cumulative Timesteps: 2,728,410,860

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.78907
Policy Entropy: 4.23405
Value Function Loss: 0.00335

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.01914
Policy Update Magnitude: 0.25821
Value Function Update Magnitude: 0.27914

Collected Steps per Second: 22,992.16758
Overall Steps per Second: 10,906.78724

Timestep Collection Time: 2.17465
Timestep Consumption Time: 2.40965
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.58430

Cumulative Model Updates: 327,156
Cumulative Timesteps: 2,728,460,860

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2728460860...
Checkpoint 2728460860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.40970
Policy Entropy: 4.22827
Value Function Loss: 0.00328

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.02150
Policy Update Magnitude: 0.26344
Value Function Update Magnitude: 0.29550

Collected Steps per Second: 22,960.83572
Overall Steps per Second: 10,764.75251

Timestep Collection Time: 2.17788
Timestep Consumption Time: 2.46746
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.64535

Cumulative Model Updates: 327,162
Cumulative Timesteps: 2,728,510,866

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.36468
Policy Entropy: 4.22628
Value Function Loss: 0.00295

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.02165
Policy Update Magnitude: 0.25070
Value Function Update Magnitude: 0.28145

Collected Steps per Second: 22,861.59899
Overall Steps per Second: 10,716.57292

Timestep Collection Time: 2.18716
Timestep Consumption Time: 2.47870
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.66586

Cumulative Model Updates: 327,168
Cumulative Timesteps: 2,728,560,868

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2728560868...
Checkpoint 2728560868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.51984
Policy Entropy: 4.23124
Value Function Loss: 0.00304

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.01929
Policy Update Magnitude: 0.25896
Value Function Update Magnitude: 0.28050

Collected Steps per Second: 22,427.25627
Overall Steps per Second: 10,772.37530

Timestep Collection Time: 2.22979
Timestep Consumption Time: 2.41246
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.64224

Cumulative Model Updates: 327,174
Cumulative Timesteps: 2,728,610,876

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.44224
Policy Entropy: 4.22964
Value Function Loss: 0.00260

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.02706
Policy Update Magnitude: 0.24173
Value Function Update Magnitude: 0.29248

Collected Steps per Second: 22,846.11907
Overall Steps per Second: 10,776.52375

Timestep Collection Time: 2.18934
Timestep Consumption Time: 2.45204
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.64139

Cumulative Model Updates: 327,180
Cumulative Timesteps: 2,728,660,894

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2728660894...
Checkpoint 2728660894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.91052
Policy Entropy: 4.23041
Value Function Loss: 0.00250

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.01760
Policy Update Magnitude: 0.23731
Value Function Update Magnitude: 0.28242

Collected Steps per Second: 22,709.34356
Overall Steps per Second: 10,744.33327

Timestep Collection Time: 2.20235
Timestep Consumption Time: 2.45257
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.65492

Cumulative Model Updates: 327,186
Cumulative Timesteps: 2,728,710,908

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.60751
Policy Entropy: 4.19652
Value Function Loss: 0.00312

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.01848
Policy Update Magnitude: 0.25806
Value Function Update Magnitude: 0.29575

Collected Steps per Second: 22,893.70163
Overall Steps per Second: 10,908.85794

Timestep Collection Time: 2.18444
Timestep Consumption Time: 2.39990
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.58435

Cumulative Model Updates: 327,192
Cumulative Timesteps: 2,728,760,918

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2728760918...
Checkpoint 2728760918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.57320
Policy Entropy: 4.18966
Value Function Loss: 0.00318

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.01944
Policy Update Magnitude: 0.26381
Value Function Update Magnitude: 0.32563

Collected Steps per Second: 22,687.03789
Overall Steps per Second: 10,750.33837

Timestep Collection Time: 2.20478
Timestep Consumption Time: 2.44809
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.65288

Cumulative Model Updates: 327,198
Cumulative Timesteps: 2,728,810,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.04598
Policy Entropy: 4.18905
Value Function Loss: 0.00396

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02146
Policy Update Magnitude: 0.27101
Value Function Update Magnitude: 0.31504

Collected Steps per Second: 22,421.52165
Overall Steps per Second: 10,817.34995

Timestep Collection Time: 2.23125
Timestep Consumption Time: 2.39354
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.62479

Cumulative Model Updates: 327,204
Cumulative Timesteps: 2,728,860,966

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2728860966...
Checkpoint 2728860966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.64342
Policy Entropy: 4.22594
Value Function Loss: 0.00335

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01749
Policy Update Magnitude: 0.26242
Value Function Update Magnitude: 0.30359

Collected Steps per Second: 22,731.40798
Overall Steps per Second: 10,883.22377

Timestep Collection Time: 2.20004
Timestep Consumption Time: 2.39511
PPO Batch Consumption Time: 0.27694
Total Iteration Time: 4.59515

Cumulative Model Updates: 327,210
Cumulative Timesteps: 2,728,910,976

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.20965
Policy Entropy: 4.21886
Value Function Loss: 0.00338

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.01788
Policy Update Magnitude: 0.25445
Value Function Update Magnitude: 0.30064

Collected Steps per Second: 22,804.20901
Overall Steps per Second: 10,931.16214

Timestep Collection Time: 2.19275
Timestep Consumption Time: 2.38169
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.57445

Cumulative Model Updates: 327,216
Cumulative Timesteps: 2,728,960,980

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2728960980...
Checkpoint 2728960980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.47561
Policy Entropy: 4.21758
Value Function Loss: 0.00267

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.01790
Policy Update Magnitude: 0.25348
Value Function Update Magnitude: 0.30590

Collected Steps per Second: 22,490.58171
Overall Steps per Second: 10,833.75211

Timestep Collection Time: 2.22413
Timestep Consumption Time: 2.39311
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.61724

Cumulative Model Updates: 327,222
Cumulative Timesteps: 2,729,011,002

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.78617
Policy Entropy: 4.21543
Value Function Loss: 0.00284

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02183
Policy Update Magnitude: 0.25076
Value Function Update Magnitude: 0.30131

Collected Steps per Second: 22,894.46807
Overall Steps per Second: 10,810.01992

Timestep Collection Time: 2.18472
Timestep Consumption Time: 2.44228
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.62700

Cumulative Model Updates: 327,228
Cumulative Timesteps: 2,729,061,020

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2729061020...
Checkpoint 2729061020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.99081
Policy Entropy: 4.20958
Value Function Loss: 0.00280

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02087
Policy Update Magnitude: 0.25167
Value Function Update Magnitude: 0.30163

Collected Steps per Second: 22,782.02586
Overall Steps per Second: 10,801.81660

Timestep Collection Time: 2.19498
Timestep Consumption Time: 2.43443
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.62941

Cumulative Model Updates: 327,234
Cumulative Timesteps: 2,729,111,026

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.32800
Policy Entropy: 4.21868
Value Function Loss: 0.00274

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02276
Policy Update Magnitude: 0.25103
Value Function Update Magnitude: 0.30281

Collected Steps per Second: 23,834.84190
Overall Steps per Second: 10,968.62922

Timestep Collection Time: 2.09920
Timestep Consumption Time: 2.46236
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.56155

Cumulative Model Updates: 327,240
Cumulative Timesteps: 2,729,161,060

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2729161060...
Checkpoint 2729161060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.26588
Policy Entropy: 4.21357
Value Function Loss: 0.00286

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.01933
Policy Update Magnitude: 0.25605
Value Function Update Magnitude: 0.31429

Collected Steps per Second: 22,458.64869
Overall Steps per Second: 10,685.21396

Timestep Collection Time: 2.22729
Timestep Consumption Time: 2.45413
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.68142

Cumulative Model Updates: 327,246
Cumulative Timesteps: 2,729,211,082

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.21078
Policy Entropy: 4.23015
Value Function Loss: 0.00314

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.02243
Policy Update Magnitude: 0.27023
Value Function Update Magnitude: 0.32393

Collected Steps per Second: 22,689.75213
Overall Steps per Second: 10,710.41612

Timestep Collection Time: 2.20364
Timestep Consumption Time: 2.46471
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.66835

Cumulative Model Updates: 327,252
Cumulative Timesteps: 2,729,261,082

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2729261082...
Checkpoint 2729261082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.44081
Policy Entropy: 4.23495
Value Function Loss: 0.00297

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.01955
Policy Update Magnitude: 0.27130
Value Function Update Magnitude: 0.32751

Collected Steps per Second: 23,578.10407
Overall Steps per Second: 11,052.04156

Timestep Collection Time: 2.12180
Timestep Consumption Time: 2.40479
PPO Batch Consumption Time: 0.27674
Total Iteration Time: 4.52658

Cumulative Model Updates: 327,258
Cumulative Timesteps: 2,729,311,110

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.41015
Policy Entropy: 4.25113
Value Function Loss: 0.00256

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.01970
Policy Update Magnitude: 0.26745
Value Function Update Magnitude: 0.32732

Collected Steps per Second: 22,894.45191
Overall Steps per Second: 10,844.33747

Timestep Collection Time: 2.18481
Timestep Consumption Time: 2.42774
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.61255

Cumulative Model Updates: 327,264
Cumulative Timesteps: 2,729,361,130

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2729361130...
Checkpoint 2729361130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.66214
Policy Entropy: 4.25302
Value Function Loss: 0.00227

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.01818
Policy Update Magnitude: 0.24095
Value Function Update Magnitude: 0.31055

Collected Steps per Second: 22,858.81799
Overall Steps per Second: 10,924.80064

Timestep Collection Time: 2.18865
Timestep Consumption Time: 2.39084
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.57949

Cumulative Model Updates: 327,270
Cumulative Timesteps: 2,729,411,160

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.46808
Policy Entropy: 4.23872
Value Function Loss: 0.00268

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.01746
Policy Update Magnitude: 0.24381
Value Function Update Magnitude: 0.29123

Collected Steps per Second: 22,652.13981
Overall Steps per Second: 10,715.97090

Timestep Collection Time: 2.20827
Timestep Consumption Time: 2.45972
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.66799

Cumulative Model Updates: 327,276
Cumulative Timesteps: 2,729,461,182

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2729461182...
Checkpoint 2729461182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.63769
Policy Entropy: 4.21120
Value Function Loss: 0.00326

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02000
Policy Update Magnitude: 0.25753
Value Function Update Magnitude: 0.28278

Collected Steps per Second: 22,786.93148
Overall Steps per Second: 10,794.10907

Timestep Collection Time: 2.19468
Timestep Consumption Time: 2.43840
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.63308

Cumulative Model Updates: 327,282
Cumulative Timesteps: 2,729,511,192

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.72867
Policy Entropy: 4.20018
Value Function Loss: 0.00314

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02027
Policy Update Magnitude: 0.26654
Value Function Update Magnitude: 0.31515

Collected Steps per Second: 23,966.10873
Overall Steps per Second: 11,104.27890

Timestep Collection Time: 2.08670
Timestep Consumption Time: 2.41697
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.50367

Cumulative Model Updates: 327,288
Cumulative Timesteps: 2,729,561,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2729561202...
Checkpoint 2729561202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.00135
Policy Entropy: 4.20368
Value Function Loss: 0.00324

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02202
Policy Update Magnitude: 0.27001
Value Function Update Magnitude: 0.31798

Collected Steps per Second: 22,865.72265
Overall Steps per Second: 10,723.26191

Timestep Collection Time: 2.18747
Timestep Consumption Time: 2.47697
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.66444

Cumulative Model Updates: 327,294
Cumulative Timesteps: 2,729,611,220

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.72508
Policy Entropy: 4.20573
Value Function Loss: 0.00306

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02151
Policy Update Magnitude: 0.26162
Value Function Update Magnitude: 0.31490

Collected Steps per Second: 22,836.24688
Overall Steps per Second: 10,894.10341

Timestep Collection Time: 2.18968
Timestep Consumption Time: 2.40033
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.59001

Cumulative Model Updates: 327,300
Cumulative Timesteps: 2,729,661,224

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2729661224...
Checkpoint 2729661224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.91827
Policy Entropy: 4.22294
Value Function Loss: 0.00271

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.01961
Policy Update Magnitude: 0.25815
Value Function Update Magnitude: 0.30960

Collected Steps per Second: 23,525.26611
Overall Steps per Second: 11,025.40232

Timestep Collection Time: 2.12554
Timestep Consumption Time: 2.40980
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.53534

Cumulative Model Updates: 327,306
Cumulative Timesteps: 2,729,711,228

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.80429
Policy Entropy: 4.24502
Value Function Loss: 0.00233

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.01778
Policy Update Magnitude: 0.24773
Value Function Update Magnitude: 0.27681

Collected Steps per Second: 22,797.77330
Overall Steps per Second: 10,685.60443

Timestep Collection Time: 2.19399
Timestep Consumption Time: 2.48689
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.68088

Cumulative Model Updates: 327,312
Cumulative Timesteps: 2,729,761,246

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2729761246...
Checkpoint 2729761246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.79355
Policy Entropy: 4.23564
Value Function Loss: 0.00257

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01651
Policy Update Magnitude: 0.24789
Value Function Update Magnitude: 0.27377

Collected Steps per Second: 22,801.98855
Overall Steps per Second: 10,952.14127

Timestep Collection Time: 2.19349
Timestep Consumption Time: 2.37329
PPO Batch Consumption Time: 0.28231
Total Iteration Time: 4.56678

Cumulative Model Updates: 327,318
Cumulative Timesteps: 2,729,811,262

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.23599
Policy Entropy: 4.22151
Value Function Loss: 0.00270

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.01810
Policy Update Magnitude: 0.25396
Value Function Update Magnitude: 0.29980

Collected Steps per Second: 22,891.80382
Overall Steps per Second: 10,846.39365

Timestep Collection Time: 2.18489
Timestep Consumption Time: 2.42642
PPO Batch Consumption Time: 0.27704
Total Iteration Time: 4.61130

Cumulative Model Updates: 327,324
Cumulative Timesteps: 2,729,861,278

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2729861278...
Checkpoint 2729861278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.01898
Policy Entropy: 4.22556
Value Function Loss: 0.00269

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.01995
Policy Update Magnitude: 0.26042
Value Function Update Magnitude: 0.31663

Collected Steps per Second: 22,646.82606
Overall Steps per Second: 10,717.57503

Timestep Collection Time: 2.20852
Timestep Consumption Time: 2.45821
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.66673

Cumulative Model Updates: 327,330
Cumulative Timesteps: 2,729,911,294

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.73865
Policy Entropy: 4.24449
Value Function Loss: 0.00230

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.01720
Policy Update Magnitude: 0.25122
Value Function Update Magnitude: 0.30733

Collected Steps per Second: 23,611.88673
Overall Steps per Second: 10,913.90450

Timestep Collection Time: 2.11766
Timestep Consumption Time: 2.46383
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.58150

Cumulative Model Updates: 327,336
Cumulative Timesteps: 2,729,961,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2729961296...
Checkpoint 2729961296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.33967
Policy Entropy: 4.23983
Value Function Loss: 0.00214

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.01951
Policy Update Magnitude: 0.25571
Value Function Update Magnitude: 0.29007

Collected Steps per Second: 22,461.47737
Overall Steps per Second: 10,599.96834

Timestep Collection Time: 2.22657
Timestep Consumption Time: 2.49156
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.71813

Cumulative Model Updates: 327,342
Cumulative Timesteps: 2,730,011,308

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.86089
Policy Entropy: 4.22705
Value Function Loss: 0.00262

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02014
Policy Update Magnitude: 0.24729
Value Function Update Magnitude: 0.27833

Collected Steps per Second: 22,867.79091
Overall Steps per Second: 10,957.88998

Timestep Collection Time: 2.18674
Timestep Consumption Time: 2.37673
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.56347

Cumulative Model Updates: 327,348
Cumulative Timesteps: 2,730,061,314

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2730061314...
Checkpoint 2730061314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.67489
Policy Entropy: 4.21841
Value Function Loss: 0.00275

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.01988
Policy Update Magnitude: 0.24142
Value Function Update Magnitude: 0.27962

Collected Steps per Second: 22,929.31300
Overall Steps per Second: 10,754.94166

Timestep Collection Time: 2.18192
Timestep Consumption Time: 2.46989
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.65182

Cumulative Model Updates: 327,354
Cumulative Timesteps: 2,730,111,344

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.14145
Policy Entropy: 4.21582
Value Function Loss: 0.00271

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.01936
Policy Update Magnitude: 0.24573
Value Function Update Magnitude: 0.28236

Collected Steps per Second: 23,004.47138
Overall Steps per Second: 10,767.82148

Timestep Collection Time: 2.17349
Timestep Consumption Time: 2.46997
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.64346

Cumulative Model Updates: 327,360
Cumulative Timesteps: 2,730,161,344

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2730161344...
Checkpoint 2730161344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.64550
Policy Entropy: 4.19933
Value Function Loss: 0.00275

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.01876
Policy Update Magnitude: 0.25280
Value Function Update Magnitude: 0.29520

Collected Steps per Second: 22,721.37367
Overall Steps per Second: 11,029.40609

Timestep Collection Time: 2.20066
Timestep Consumption Time: 2.33286
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.53352

Cumulative Model Updates: 327,366
Cumulative Timesteps: 2,730,211,346

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.99233
Policy Entropy: 4.19464
Value Function Loss: 0.00328

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.02113
Policy Update Magnitude: 0.26897
Value Function Update Magnitude: 0.34900

Collected Steps per Second: 22,810.84657
Overall Steps per Second: 10,737.45145

Timestep Collection Time: 2.19308
Timestep Consumption Time: 2.46594
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.65902

Cumulative Model Updates: 327,372
Cumulative Timesteps: 2,730,261,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2730261372...
Checkpoint 2730261372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.47235
Policy Entropy: 4.22005
Value Function Loss: 0.00324

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02100
Policy Update Magnitude: 0.27345
Value Function Update Magnitude: 0.36016

Collected Steps per Second: 22,708.13493
Overall Steps per Second: 10,938.05600

Timestep Collection Time: 2.20185
Timestep Consumption Time: 2.36934
PPO Batch Consumption Time: 0.27549
Total Iteration Time: 4.57120

Cumulative Model Updates: 327,378
Cumulative Timesteps: 2,730,311,372

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.38712
Policy Entropy: 4.24112
Value Function Loss: 0.00270

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.01888
Policy Update Magnitude: 0.25916
Value Function Update Magnitude: 0.34363

Collected Steps per Second: 22,982.11193
Overall Steps per Second: 10,890.38904

Timestep Collection Time: 2.17595
Timestep Consumption Time: 2.41599
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.59194

Cumulative Model Updates: 327,384
Cumulative Timesteps: 2,730,361,380

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2730361380...
Checkpoint 2730361380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.84660
Policy Entropy: 4.27017
Value Function Loss: 0.00272

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.01872
Policy Update Magnitude: 0.24679
Value Function Update Magnitude: 0.32134

Collected Steps per Second: 22,764.68407
Overall Steps per Second: 10,656.44793

Timestep Collection Time: 2.19665
Timestep Consumption Time: 2.49591
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.69256

Cumulative Model Updates: 327,390
Cumulative Timesteps: 2,730,411,386

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.10058
Policy Entropy: 4.25261
Value Function Loss: 0.00273

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.01949
Policy Update Magnitude: 0.25048
Value Function Update Magnitude: 0.30415

Collected Steps per Second: 22,565.08882
Overall Steps per Second: 10,860.43593

Timestep Collection Time: 2.21652
Timestep Consumption Time: 2.38882
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.60534

Cumulative Model Updates: 327,396
Cumulative Timesteps: 2,730,461,402

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2730461402...
Checkpoint 2730461402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.88096
Policy Entropy: 4.25801
Value Function Loss: 0.00245

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.01900
Policy Update Magnitude: 0.24542
Value Function Update Magnitude: 0.28274

Collected Steps per Second: 22,925.02890
Overall Steps per Second: 10,755.22919

Timestep Collection Time: 2.18181
Timestep Consumption Time: 2.46877
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.65057

Cumulative Model Updates: 327,402
Cumulative Timesteps: 2,730,511,420

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.84144
Policy Entropy: 4.23422
Value Function Loss: 0.00232

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.01826
Policy Update Magnitude: 0.24143
Value Function Update Magnitude: 0.25808

Collected Steps per Second: 22,535.96797
Overall Steps per Second: 10,769.62427

Timestep Collection Time: 2.21868
Timestep Consumption Time: 2.42401
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.64269

Cumulative Model Updates: 327,408
Cumulative Timesteps: 2,730,561,420

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2730561420...
Checkpoint 2730561420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.17242
Policy Entropy: 4.27452
Value Function Loss: 0.00170

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.01687
Policy Update Magnitude: 0.23052
Value Function Update Magnitude: 0.24930

Collected Steps per Second: 22,716.15155
Overall Steps per Second: 11,011.66580

Timestep Collection Time: 2.20117
Timestep Consumption Time: 2.33966
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.54082

Cumulative Model Updates: 327,414
Cumulative Timesteps: 2,730,611,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.70301
Policy Entropy: 4.27007
Value Function Loss: 0.00205

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.01766
Policy Update Magnitude: 0.21695
Value Function Update Magnitude: 0.24833

Collected Steps per Second: 22,831.24305
Overall Steps per Second: 10,732.21049

Timestep Collection Time: 2.19051
Timestep Consumption Time: 2.46948
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.65999

Cumulative Model Updates: 327,420
Cumulative Timesteps: 2,730,661,434

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2730661434...
Checkpoint 2730661434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.50634
Policy Entropy: 4.25767
Value Function Loss: 0.00282

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.01641
Policy Update Magnitude: 0.23615
Value Function Update Magnitude: 0.26905

Collected Steps per Second: 22,731.77240
Overall Steps per Second: 10,908.56581

Timestep Collection Time: 2.19965
Timestep Consumption Time: 2.38408
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.58374

Cumulative Model Updates: 327,426
Cumulative Timesteps: 2,730,711,436

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.62877
Policy Entropy: 4.19942
Value Function Loss: 0.00389

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.02225
Policy Update Magnitude: 0.27136
Value Function Update Magnitude: 0.33011

Collected Steps per Second: 22,824.45384
Overall Steps per Second: 10,841.00185

Timestep Collection Time: 2.19160
Timestep Consumption Time: 2.42255
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.61415

Cumulative Model Updates: 327,432
Cumulative Timesteps: 2,730,761,458

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2730761458...
Checkpoint 2730761458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.13935
Policy Entropy: 4.18167
Value Function Loss: 0.00408

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.02422
Policy Update Magnitude: 0.28560
Value Function Update Magnitude: 0.36508

Collected Steps per Second: 22,839.97138
Overall Steps per Second: 10,687.87689

Timestep Collection Time: 2.18914
Timestep Consumption Time: 2.48905
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.67820

Cumulative Model Updates: 327,438
Cumulative Timesteps: 2,730,811,458

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.48648
Policy Entropy: 4.17177
Value Function Loss: 0.00385

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.02442
Policy Update Magnitude: 0.28343
Value Function Update Magnitude: 0.35616

Collected Steps per Second: 22,669.25078
Overall Steps per Second: 10,953.56261

Timestep Collection Time: 2.20563
Timestep Consumption Time: 2.35909
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.56472

Cumulative Model Updates: 327,444
Cumulative Timesteps: 2,730,861,458

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2730861458...
Checkpoint 2730861458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.35451
Policy Entropy: 4.18865
Value Function Loss: 0.00326

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02225
Policy Update Magnitude: 0.27078
Value Function Update Magnitude: 0.33077

Collected Steps per Second: 22,676.48631
Overall Steps per Second: 10,585.23815

Timestep Collection Time: 2.20599
Timestep Consumption Time: 2.51984
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.72583

Cumulative Model Updates: 327,450
Cumulative Timesteps: 2,730,911,482

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.09885
Policy Entropy: 4.17605
Value Function Loss: 0.00285

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02211
Policy Update Magnitude: 0.26798
Value Function Update Magnitude: 0.31239

Collected Steps per Second: 22,394.72966
Overall Steps per Second: 10,702.65601

Timestep Collection Time: 2.23311
Timestep Consumption Time: 2.43956
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.67267

Cumulative Model Updates: 327,456
Cumulative Timesteps: 2,730,961,492

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2730961492...
Checkpoint 2730961492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.14722
Policy Entropy: 4.19439
Value Function Loss: 0.00329

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02172
Policy Update Magnitude: 0.27560
Value Function Update Magnitude: 0.30647

Collected Steps per Second: 22,626.68272
Overall Steps per Second: 10,865.66043

Timestep Collection Time: 2.20978
Timestep Consumption Time: 2.39187
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.60165

Cumulative Model Updates: 327,462
Cumulative Timesteps: 2,731,011,492

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.82353
Policy Entropy: 4.20989
Value Function Loss: 0.00374

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02282
Policy Update Magnitude: 0.28338
Value Function Update Magnitude: 0.32377

Collected Steps per Second: 22,408.82301
Overall Steps per Second: 10,644.41309

Timestep Collection Time: 2.23180
Timestep Consumption Time: 2.46663
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.69843

Cumulative Model Updates: 327,468
Cumulative Timesteps: 2,731,061,504

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2731061504...
Checkpoint 2731061504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.14379
Policy Entropy: 4.23937
Value Function Loss: 0.00301

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.01944
Policy Update Magnitude: 0.25322
Value Function Update Magnitude: 0.32498

Collected Steps per Second: 23,073.32053
Overall Steps per Second: 10,931.16233

Timestep Collection Time: 2.16770
Timestep Consumption Time: 2.40784
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.57554

Cumulative Model Updates: 327,474
Cumulative Timesteps: 2,731,111,520

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.44998
Policy Entropy: 4.19662
Value Function Loss: 0.00373

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02136
Policy Update Magnitude: 0.27804
Value Function Update Magnitude: 0.32242

Collected Steps per Second: 22,657.05542
Overall Steps per Second: 10,874.26716

Timestep Collection Time: 2.20682
Timestep Consumption Time: 2.39119
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.59801

Cumulative Model Updates: 327,480
Cumulative Timesteps: 2,731,161,520

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2731161520...
Checkpoint 2731161520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.43176
Policy Entropy: 4.17485
Value Function Loss: 0.00337

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.02681
Policy Update Magnitude: 0.29240
Value Function Update Magnitude: 0.32870

Collected Steps per Second: 22,689.67259
Overall Steps per Second: 10,637.34255

Timestep Collection Time: 2.20417
Timestep Consumption Time: 2.49738
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.70155

Cumulative Model Updates: 327,486
Cumulative Timesteps: 2,731,211,532

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.44723
Policy Entropy: 4.13408
Value Function Loss: 0.00431

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.02676
Policy Update Magnitude: 0.30115
Value Function Update Magnitude: 0.36407

Collected Steps per Second: 22,570.16922
Overall Steps per Second: 10,832.75681

Timestep Collection Time: 2.21620
Timestep Consumption Time: 2.40128
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.61748

Cumulative Model Updates: 327,492
Cumulative Timesteps: 2,731,261,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2731261552...
Checkpoint 2731261552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.24946
Policy Entropy: 4.18753
Value Function Loss: 0.00333

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02387
Policy Update Magnitude: 0.29847
Value Function Update Magnitude: 0.37298

Collected Steps per Second: 23,445.39810
Overall Steps per Second: 10,891.61877

Timestep Collection Time: 2.13313
Timestep Consumption Time: 2.45866
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.59179

Cumulative Model Updates: 327,498
Cumulative Timesteps: 2,731,311,564

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.11905
Policy Entropy: 4.17057
Value Function Loss: 0.00386

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.02243
Policy Update Magnitude: 0.29401
Value Function Update Magnitude: 0.36481

Collected Steps per Second: 23,016.35601
Overall Steps per Second: 10,725.16366

Timestep Collection Time: 2.17246
Timestep Consumption Time: 2.48966
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.66212

Cumulative Model Updates: 327,504
Cumulative Timesteps: 2,731,361,566

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2731361566...
Checkpoint 2731361566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.43602
Policy Entropy: 4.18760
Value Function Loss: 0.00361

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.02241
Policy Update Magnitude: 0.28915
Value Function Update Magnitude: 0.36165

Collected Steps per Second: 22,661.81207
Overall Steps per Second: 11,007.45376

Timestep Collection Time: 2.20750
Timestep Consumption Time: 2.33724
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.54474

Cumulative Model Updates: 327,510
Cumulative Timesteps: 2,731,411,592

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.74774
Policy Entropy: 4.19001
Value Function Loss: 0.00296

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.02262
Policy Update Magnitude: 0.28241
Value Function Update Magnitude: 0.34939

Collected Steps per Second: 22,701.27669
Overall Steps per Second: 10,685.62732

Timestep Collection Time: 2.20270
Timestep Consumption Time: 2.47686
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.67956

Cumulative Model Updates: 327,516
Cumulative Timesteps: 2,731,461,596

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2731461596...
Checkpoint 2731461596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.49697
Policy Entropy: 4.23712
Value Function Loss: 0.00271

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.01854
Policy Update Magnitude: 0.26442
Value Function Update Magnitude: 0.34376

Collected Steps per Second: 22,619.14608
Overall Steps per Second: 10,897.18517

Timestep Collection Time: 2.21140
Timestep Consumption Time: 2.37878
PPO Batch Consumption Time: 0.27696
Total Iteration Time: 4.59018

Cumulative Model Updates: 327,522
Cumulative Timesteps: 2,731,511,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.89194
Policy Entropy: 4.23184
Value Function Loss: 0.00276

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.01801
Policy Update Magnitude: 0.25868
Value Function Update Magnitude: 0.33134

Collected Steps per Second: 22,804.05725
Overall Steps per Second: 10,960.52493

Timestep Collection Time: 2.19294
Timestep Consumption Time: 2.36961
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.56256

Cumulative Model Updates: 327,528
Cumulative Timesteps: 2,731,561,624

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2731561624...
Checkpoint 2731561624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.97768
Policy Entropy: 4.21742
Value Function Loss: 0.00309

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.01789
Policy Update Magnitude: 0.26433
Value Function Update Magnitude: 0.32291

Collected Steps per Second: 22,626.99390
Overall Steps per Second: 10,626.43314

Timestep Collection Time: 2.20984
Timestep Consumption Time: 2.49560
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.70544

Cumulative Model Updates: 327,534
Cumulative Timesteps: 2,731,611,626

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.95993
Policy Entropy: 4.19411
Value Function Loss: 0.00353

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.01963
Policy Update Magnitude: 0.27689
Value Function Update Magnitude: 0.32210

Collected Steps per Second: 22,870.82896
Overall Steps per Second: 10,914.20269

Timestep Collection Time: 2.18733
Timestep Consumption Time: 2.39624
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.58357

Cumulative Model Updates: 327,540
Cumulative Timesteps: 2,731,661,652

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2731661652...
Checkpoint 2731661652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.15480
Policy Entropy: 4.22448
Value Function Loss: 0.00264

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02063
Policy Update Magnitude: 0.26192
Value Function Update Magnitude: 0.32245

Collected Steps per Second: 23,364.81129
Overall Steps per Second: 10,901.87938

Timestep Collection Time: 2.14031
Timestep Consumption Time: 2.44679
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.58710

Cumulative Model Updates: 327,546
Cumulative Timesteps: 2,731,711,660

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.31645
Policy Entropy: 4.22594
Value Function Loss: 0.00279

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02252
Policy Update Magnitude: 0.25259
Value Function Update Magnitude: 0.30952

Collected Steps per Second: 22,878.33240
Overall Steps per Second: 10,662.20058

Timestep Collection Time: 2.18652
Timestep Consumption Time: 2.50519
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.69171

Cumulative Model Updates: 327,552
Cumulative Timesteps: 2,731,761,684

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2731761684...
Checkpoint 2731761684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.91412
Policy Entropy: 4.21153
Value Function Loss: 0.00316

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02015
Policy Update Magnitude: 0.26669
Value Function Update Magnitude: 0.30841

Collected Steps per Second: 22,528.97725
Overall Steps per Second: 10,669.42560

Timestep Collection Time: 2.21990
Timestep Consumption Time: 2.46752
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.68741

Cumulative Model Updates: 327,558
Cumulative Timesteps: 2,731,811,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.46478
Policy Entropy: 4.19285
Value Function Loss: 0.00368

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02016
Policy Update Magnitude: 0.26683
Value Function Update Magnitude: 0.32393

Collected Steps per Second: 23,475.44760
Overall Steps per Second: 10,913.04398

Timestep Collection Time: 2.13065
Timestep Consumption Time: 2.45267
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.58332

Cumulative Model Updates: 327,564
Cumulative Timesteps: 2,731,861,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2731861714...
Checkpoint 2731861714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.83136
Policy Entropy: 4.18143
Value Function Loss: 0.00399

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02059
Policy Update Magnitude: 0.28457
Value Function Update Magnitude: 0.33169

Collected Steps per Second: 22,558.99404
Overall Steps per Second: 10,627.32457

Timestep Collection Time: 2.21659
Timestep Consumption Time: 2.48864
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.70523

Cumulative Model Updates: 327,570
Cumulative Timesteps: 2,731,911,718

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.22207
Policy Entropy: 4.16173
Value Function Loss: 0.00416

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02189
Policy Update Magnitude: 0.30048
Value Function Update Magnitude: 0.35081

Collected Steps per Second: 22,750.25692
Overall Steps per Second: 10,916.07142

Timestep Collection Time: 2.19874
Timestep Consumption Time: 2.38367
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.58242

Cumulative Model Updates: 327,576
Cumulative Timesteps: 2,731,961,740

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2731961740...
Checkpoint 2731961740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.34033
Policy Entropy: 4.13890
Value Function Loss: 0.00423

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.02982
Policy Update Magnitude: 0.32049
Value Function Update Magnitude: 0.36618

Collected Steps per Second: 22,917.24906
Overall Steps per Second: 10,694.01497

Timestep Collection Time: 2.18246
Timestep Consumption Time: 2.49455
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.67701

Cumulative Model Updates: 327,582
Cumulative Timesteps: 2,732,011,756

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.50553
Policy Entropy: 4.14143
Value Function Loss: 0.00425

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.03761
Policy Update Magnitude: 0.32735
Value Function Update Magnitude: 0.36263

Collected Steps per Second: 22,760.44831
Overall Steps per Second: 10,879.30883

Timestep Collection Time: 2.19706
Timestep Consumption Time: 2.39937
PPO Batch Consumption Time: 0.27602
Total Iteration Time: 4.59643

Cumulative Model Updates: 327,588
Cumulative Timesteps: 2,732,061,762

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2732061762...
Checkpoint 2732061762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.81555
Policy Entropy: 4.16810
Value Function Loss: 0.00378

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.03121
Policy Update Magnitude: 0.29294
Value Function Update Magnitude: 0.34281

Collected Steps per Second: 22,863.03096
Overall Steps per Second: 11,044.31956

Timestep Collection Time: 2.18746
Timestep Consumption Time: 2.34084
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.52830

Cumulative Model Updates: 327,594
Cumulative Timesteps: 2,732,111,774

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.48257
Policy Entropy: 4.20492
Value Function Loss: 0.00308

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02624
Policy Update Magnitude: 0.26671
Value Function Update Magnitude: 0.30901

Collected Steps per Second: 23,003.86161
Overall Steps per Second: 10,884.80819

Timestep Collection Time: 2.17477
Timestep Consumption Time: 2.42137
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.59613

Cumulative Model Updates: 327,600
Cumulative Timesteps: 2,732,161,802

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2732161802...
Checkpoint 2732161802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.92455
Policy Entropy: 4.19028
Value Function Loss: 0.00340

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.02151
Policy Update Magnitude: 0.25825
Value Function Update Magnitude: 0.29326

Collected Steps per Second: 22,440.01501
Overall Steps per Second: 10,681.94174

Timestep Collection Time: 2.22950
Timestep Consumption Time: 2.45411
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.68361

Cumulative Model Updates: 327,606
Cumulative Timesteps: 2,732,211,832

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.67794
Policy Entropy: 4.20350
Value Function Loss: 0.00325

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02012
Policy Update Magnitude: 0.26029
Value Function Update Magnitude: 0.29388

Collected Steps per Second: 23,671.07147
Overall Steps per Second: 10,960.00274

Timestep Collection Time: 2.11347
Timestep Consumption Time: 2.45113
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.56460

Cumulative Model Updates: 327,612
Cumulative Timesteps: 2,732,261,860

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2732261860...
Checkpoint 2732261860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.54334
Policy Entropy: 4.17454
Value Function Loss: 0.00420

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02339
Policy Update Magnitude: 0.28579
Value Function Update Magnitude: 0.31456

Collected Steps per Second: 22,442.71425
Overall Steps per Second: 10,610.96339

Timestep Collection Time: 2.22950
Timestep Consumption Time: 2.48600
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.71550

Cumulative Model Updates: 327,618
Cumulative Timesteps: 2,732,311,896

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.52714
Policy Entropy: 4.20878
Value Function Loss: 0.00367

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02226
Policy Update Magnitude: 0.27532
Value Function Update Magnitude: 0.33180

Collected Steps per Second: 22,621.49769
Overall Steps per Second: 10,922.36321

Timestep Collection Time: 2.21029
Timestep Consumption Time: 2.36748
PPO Batch Consumption Time: 0.28178
Total Iteration Time: 4.57776

Cumulative Model Updates: 327,624
Cumulative Timesteps: 2,732,361,896

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2732361896...
Checkpoint 2732361896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.28728
Policy Entropy: 4.22363
Value Function Loss: 0.00319

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02188
Policy Update Magnitude: 0.25930
Value Function Update Magnitude: 0.32324

Collected Steps per Second: 22,884.95467
Overall Steps per Second: 10,718.31297

Timestep Collection Time: 2.18563
Timestep Consumption Time: 2.48096
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.66659

Cumulative Model Updates: 327,630
Cumulative Timesteps: 2,732,411,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.59261
Policy Entropy: 4.23512
Value Function Loss: 0.00317

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.01723
Policy Update Magnitude: 0.24761
Value Function Update Magnitude: 0.30757

Collected Steps per Second: 22,552.00795
Overall Steps per Second: 10,890.49849

Timestep Collection Time: 2.21754
Timestep Consumption Time: 2.37454
PPO Batch Consumption Time: 0.27529
Total Iteration Time: 4.59208

Cumulative Model Updates: 327,636
Cumulative Timesteps: 2,732,461,924

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2732461924...
Checkpoint 2732461924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.76049
Policy Entropy: 4.22622
Value Function Loss: 0.00329

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.01928
Policy Update Magnitude: 0.25260
Value Function Update Magnitude: 0.31363

Collected Steps per Second: 22,441.93287
Overall Steps per Second: 10,988.08966

Timestep Collection Time: 2.22851
Timestep Consumption Time: 2.32297
PPO Batch Consumption Time: 0.27681
Total Iteration Time: 4.55147

Cumulative Model Updates: 327,642
Cumulative Timesteps: 2,732,511,936

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.54444
Policy Entropy: 4.22474
Value Function Loss: 0.00327

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.01853
Policy Update Magnitude: 0.24809
Value Function Update Magnitude: 0.32992

Collected Steps per Second: 22,914.62363
Overall Steps per Second: 10,885.73446

Timestep Collection Time: 2.18385
Timestep Consumption Time: 2.41318
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.59703

Cumulative Model Updates: 327,648
Cumulative Timesteps: 2,732,561,978

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2732561978...
Checkpoint 2732561978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.17218
Policy Entropy: 4.23383
Value Function Loss: 0.00294

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.01592
Policy Update Magnitude: 0.24773
Value Function Update Magnitude: 0.31729

Collected Steps per Second: 22,704.78285
Overall Steps per Second: 10,701.90887

Timestep Collection Time: 2.20271
Timestep Consumption Time: 2.47048
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.67318

Cumulative Model Updates: 327,654
Cumulative Timesteps: 2,732,611,990

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.33933
Policy Entropy: 4.20854
Value Function Loss: 0.00320

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.01908
Policy Update Magnitude: 0.24042
Value Function Update Magnitude: 0.29285

Collected Steps per Second: 23,741.17842
Overall Steps per Second: 10,905.07261

Timestep Collection Time: 2.10621
Timestep Consumption Time: 2.47918
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.58539

Cumulative Model Updates: 327,660
Cumulative Timesteps: 2,732,661,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2732661994...
Checkpoint 2732661994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.07984
Policy Entropy: 4.19801
Value Function Loss: 0.00336

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.01827
Policy Update Magnitude: 0.24910
Value Function Update Magnitude: 0.29129

Collected Steps per Second: 22,639.32541
Overall Steps per Second: 10,684.94468

Timestep Collection Time: 2.20987
Timestep Consumption Time: 2.47242
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.68229

Cumulative Model Updates: 327,666
Cumulative Timesteps: 2,732,712,024

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.17199
Policy Entropy: 4.16858
Value Function Loss: 0.00375

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02215
Policy Update Magnitude: 0.26974
Value Function Update Magnitude: 0.31188

Collected Steps per Second: 22,740.84717
Overall Steps per Second: 10,881.51827

Timestep Collection Time: 2.19965
Timestep Consumption Time: 2.39731
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.59697

Cumulative Model Updates: 327,672
Cumulative Timesteps: 2,732,762,046

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2732762046...
Checkpoint 2732762046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.70791
Policy Entropy: 4.18150
Value Function Loss: 0.00388

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02393
Policy Update Magnitude: 0.29334
Value Function Update Magnitude: 0.34399

Collected Steps per Second: 23,363.21446
Overall Steps per Second: 10,887.97968

Timestep Collection Time: 2.14072
Timestep Consumption Time: 2.45279
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.59351

Cumulative Model Updates: 327,678
Cumulative Timesteps: 2,732,812,060

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.82040
Policy Entropy: 4.18082
Value Function Loss: 0.00351

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.02242
Policy Update Magnitude: 0.27663
Value Function Update Magnitude: 0.34782

Collected Steps per Second: 22,792.30537
Overall Steps per Second: 10,650.81951

Timestep Collection Time: 2.19390
Timestep Consumption Time: 2.50095
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.69485

Cumulative Model Updates: 327,684
Cumulative Timesteps: 2,732,862,064

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2732862064...
Checkpoint 2732862064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.01454
Policy Entropy: 4.22009
Value Function Loss: 0.00360

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02171
Policy Update Magnitude: 0.25940
Value Function Update Magnitude: 0.34108

Collected Steps per Second: 22,633.88024
Overall Steps per Second: 11,032.71371

Timestep Collection Time: 2.20978
Timestep Consumption Time: 2.32364
PPO Batch Consumption Time: 0.27694
Total Iteration Time: 4.53343

Cumulative Model Updates: 327,690
Cumulative Timesteps: 2,732,912,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.44300
Policy Entropy: 4.21398
Value Function Loss: 0.00314

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02425
Policy Update Magnitude: 0.25541
Value Function Update Magnitude: 0.34146

Collected Steps per Second: 22,770.35528
Overall Steps per Second: 10,741.22553

Timestep Collection Time: 2.19636
Timestep Consumption Time: 2.45972
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.65608

Cumulative Model Updates: 327,696
Cumulative Timesteps: 2,732,962,092

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2732962092...
Checkpoint 2732962092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.31796
Policy Entropy: 4.20584
Value Function Loss: 0.00302

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02122
Policy Update Magnitude: 0.25739
Value Function Update Magnitude: 0.33868

Collected Steps per Second: 22,631.90258
Overall Steps per Second: 10,894.19835

Timestep Collection Time: 2.20998
Timestep Consumption Time: 2.38109
PPO Batch Consumption Time: 0.27681
Total Iteration Time: 4.59107

Cumulative Model Updates: 327,702
Cumulative Timesteps: 2,733,012,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.36660
Policy Entropy: 4.16491
Value Function Loss: 0.00361

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02419
Policy Update Magnitude: 0.26676
Value Function Update Magnitude: 0.32362

Collected Steps per Second: 23,423.98590
Overall Steps per Second: 10,954.06307

Timestep Collection Time: 2.13567
Timestep Consumption Time: 2.43122
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.56689

Cumulative Model Updates: 327,708
Cumulative Timesteps: 2,733,062,134

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2733062134...
Checkpoint 2733062134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.18746
Policy Entropy: 4.17037
Value Function Loss: 0.00389

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.02650
Policy Update Magnitude: 0.26527
Value Function Update Magnitude: 0.33553

Collected Steps per Second: 22,412.72084
Overall Steps per Second: 10,604.41003

Timestep Collection Time: 2.23150
Timestep Consumption Time: 2.48484
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.71634

Cumulative Model Updates: 327,714
Cumulative Timesteps: 2,733,112,148

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.53148
Policy Entropy: 4.17950
Value Function Loss: 0.00386

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02400
Policy Update Magnitude: 0.26600
Value Function Update Magnitude: 0.34979

Collected Steps per Second: 22,688.21867
Overall Steps per Second: 10,840.68946

Timestep Collection Time: 2.20440
Timestep Consumption Time: 2.40914
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.61354

Cumulative Model Updates: 327,720
Cumulative Timesteps: 2,733,162,162

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2733162162...
Checkpoint 2733162162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.20883
Policy Entropy: 4.18665
Value Function Loss: 0.00391

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02404
Policy Update Magnitude: 0.26726
Value Function Update Magnitude: 0.34540

Collected Steps per Second: 23,168.37002
Overall Steps per Second: 10,756.10729

Timestep Collection Time: 2.15881
Timestep Consumption Time: 2.49120
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.65001

Cumulative Model Updates: 327,726
Cumulative Timesteps: 2,733,212,178

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.68094
Policy Entropy: 4.18099
Value Function Loss: 0.00460

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.02484
Policy Update Magnitude: 0.27445
Value Function Update Magnitude: 0.34128

Collected Steps per Second: 22,734.88702
Overall Steps per Second: 10,794.07854

Timestep Collection Time: 2.20041
Timestep Consumption Time: 2.43417
PPO Batch Consumption Time: 0.27694
Total Iteration Time: 4.63458

Cumulative Model Updates: 327,732
Cumulative Timesteps: 2,733,262,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2733262204...
Checkpoint 2733262204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.41110
Policy Entropy: 4.19501
Value Function Loss: 0.00390

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.02358
Policy Update Magnitude: 0.27985
Value Function Update Magnitude: 0.34730

Collected Steps per Second: 22,702.49485
Overall Steps per Second: 10,860.70949

Timestep Collection Time: 2.20275
Timestep Consumption Time: 2.40173
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.60449

Cumulative Model Updates: 327,738
Cumulative Timesteps: 2,733,312,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.70492
Policy Entropy: 4.21701
Value Function Loss: 0.00321

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.02230
Policy Update Magnitude: 0.27064
Value Function Update Magnitude: 0.32587

Collected Steps per Second: 23,083.66773
Overall Steps per Second: 10,804.42513

Timestep Collection Time: 2.16707
Timestep Consumption Time: 2.46288
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.62995

Cumulative Model Updates: 327,744
Cumulative Timesteps: 2,733,362,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2733362236...
Checkpoint 2733362236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.70401
Policy Entropy: 4.21780
Value Function Loss: 0.00284

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.01955
Policy Update Magnitude: 0.26594
Value Function Update Magnitude: 0.32125

Collected Steps per Second: 22,892.79511
Overall Steps per Second: 10,775.30321

Timestep Collection Time: 2.18453
Timestep Consumption Time: 2.45664
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.64117

Cumulative Model Updates: 327,750
Cumulative Timesteps: 2,733,412,246

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.35685
Policy Entropy: 4.22643
Value Function Loss: 0.00251

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.01920
Policy Update Magnitude: 0.25431
Value Function Update Magnitude: 0.31530

Collected Steps per Second: 22,896.77736
Overall Steps per Second: 10,937.56473

Timestep Collection Time: 2.18494
Timestep Consumption Time: 2.38903
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.57396

Cumulative Model Updates: 327,756
Cumulative Timesteps: 2,733,462,274

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2733462274...
Checkpoint 2733462274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.54245
Policy Entropy: 4.19823
Value Function Loss: 0.00328

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02054
Policy Update Magnitude: 0.26067
Value Function Update Magnitude: 0.33108

Collected Steps per Second: 22,992.03380
Overall Steps per Second: 10,891.42223

Timestep Collection Time: 2.17501
Timestep Consumption Time: 2.41649
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.59150

Cumulative Model Updates: 327,762
Cumulative Timesteps: 2,733,512,282

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.25804
Policy Entropy: 4.20177
Value Function Loss: 0.00345

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02226
Policy Update Magnitude: 0.27188
Value Function Update Magnitude: 0.33063

Collected Steps per Second: 22,912.26559
Overall Steps per Second: 10,911.68129

Timestep Collection Time: 2.18285
Timestep Consumption Time: 2.40068
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.58353

Cumulative Model Updates: 327,768
Cumulative Timesteps: 2,733,562,296

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2733562296...
Checkpoint 2733562296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.25797
Policy Entropy: 4.18133
Value Function Loss: 0.00383

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.02471
Policy Update Magnitude: 0.28108
Value Function Update Magnitude: 0.34390

Collected Steps per Second: 23,081.55881
Overall Steps per Second: 10,752.48919

Timestep Collection Time: 2.16744
Timestep Consumption Time: 2.48525
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.65269

Cumulative Model Updates: 327,774
Cumulative Timesteps: 2,733,612,324

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.10582
Policy Entropy: 4.19815
Value Function Loss: 0.00361

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02046
Policy Update Magnitude: 0.27479
Value Function Update Magnitude: 0.34215

Collected Steps per Second: 22,966.62529
Overall Steps per Second: 10,851.19954

Timestep Collection Time: 2.17777
Timestep Consumption Time: 2.43149
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.60926

Cumulative Model Updates: 327,780
Cumulative Timesteps: 2,733,662,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2733662340...
Checkpoint 2733662340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.84286
Policy Entropy: 4.19147
Value Function Loss: 0.00354

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02029
Policy Update Magnitude: 0.27156
Value Function Update Magnitude: 0.33109

Collected Steps per Second: 22,673.02665
Overall Steps per Second: 11,041.24123

Timestep Collection Time: 2.20623
Timestep Consumption Time: 2.32424
PPO Batch Consumption Time: 0.27685
Total Iteration Time: 4.53047

Cumulative Model Updates: 327,786
Cumulative Timesteps: 2,733,712,362

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.34908
Policy Entropy: 4.17749
Value Function Loss: 0.00369

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02417
Policy Update Magnitude: 0.27669
Value Function Update Magnitude: 0.33153

Collected Steps per Second: 22,584.00561
Overall Steps per Second: 10,687.13998

Timestep Collection Time: 2.21466
Timestep Consumption Time: 2.46535
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.68002

Cumulative Model Updates: 327,792
Cumulative Timesteps: 2,733,762,378

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2733762378...
Checkpoint 2733762378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.37114
Policy Entropy: 4.16365
Value Function Loss: 0.00382

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.02642
Policy Update Magnitude: 0.28955
Value Function Update Magnitude: 0.35546

Collected Steps per Second: 22,938.09854
Overall Steps per Second: 10,861.67281

Timestep Collection Time: 2.18109
Timestep Consumption Time: 2.42502
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.60610

Cumulative Model Updates: 327,798
Cumulative Timesteps: 2,733,812,408

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.40349
Policy Entropy: 4.15317
Value Function Loss: 0.00445

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.02627
Policy Update Magnitude: 0.29405
Value Function Update Magnitude: 0.37985

Collected Steps per Second: 22,197.86557
Overall Steps per Second: 10,877.58862

Timestep Collection Time: 2.25373
Timestep Consumption Time: 2.34545
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.59918

Cumulative Model Updates: 327,804
Cumulative Timesteps: 2,733,862,436

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2733862436...
Checkpoint 2733862436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.29967
Policy Entropy: 4.15627
Value Function Loss: 0.00409

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02353
Policy Update Magnitude: 0.29125
Value Function Update Magnitude: 0.38098

Collected Steps per Second: 22,562.90599
Overall Steps per Second: 10,736.09536

Timestep Collection Time: 2.21709
Timestep Consumption Time: 2.44233
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.65942

Cumulative Model Updates: 327,810
Cumulative Timesteps: 2,733,912,460

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.78464
Policy Entropy: 4.17088
Value Function Loss: 0.00357

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02148
Policy Update Magnitude: 0.27143
Value Function Update Magnitude: 0.36438

Collected Steps per Second: 22,802.65680
Overall Steps per Second: 10,860.55147

Timestep Collection Time: 2.19325
Timestep Consumption Time: 2.41167
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.60492

Cumulative Model Updates: 327,816
Cumulative Timesteps: 2,733,962,472

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2733962472...
Checkpoint 2733962472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.90324
Policy Entropy: 4.19314
Value Function Loss: 0.00326

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.01840
Policy Update Magnitude: 0.26095
Value Function Update Magnitude: 0.33760

Collected Steps per Second: 22,720.68790
Overall Steps per Second: 10,898.36678

Timestep Collection Time: 2.20134
Timestep Consumption Time: 2.38797
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.58931

Cumulative Model Updates: 327,822
Cumulative Timesteps: 2,734,012,488

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.19033
Policy Entropy: 4.21152
Value Function Loss: 0.00332

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.01765
Policy Update Magnitude: 0.26755
Value Function Update Magnitude: 0.33336

Collected Steps per Second: 22,792.82194
Overall Steps per Second: 10,700.62000

Timestep Collection Time: 2.19464
Timestep Consumption Time: 2.48004
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.67468

Cumulative Model Updates: 327,828
Cumulative Timesteps: 2,734,062,510

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2734062510...
Checkpoint 2734062510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.83349
Policy Entropy: 4.21242
Value Function Loss: 0.00329

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.01812
Policy Update Magnitude: 0.25112
Value Function Update Magnitude: 0.33526

Collected Steps per Second: 22,842.06413
Overall Steps per Second: 10,788.66407

Timestep Collection Time: 2.19026
Timestep Consumption Time: 2.44702
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.63727

Cumulative Model Updates: 327,834
Cumulative Timesteps: 2,734,112,540

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.48330
Policy Entropy: 4.20398
Value Function Loss: 0.00325

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.01734
Policy Update Magnitude: 0.25880
Value Function Update Magnitude: 0.32758

Collected Steps per Second: 23,765.88466
Overall Steps per Second: 10,973.41817

Timestep Collection Time: 2.10503
Timestep Consumption Time: 2.45398
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.55902

Cumulative Model Updates: 327,840
Cumulative Timesteps: 2,734,162,568

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2734162568...
Checkpoint 2734162568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.76125
Policy Entropy: 4.16853
Value Function Loss: 0.00369

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.01806
Policy Update Magnitude: 0.27899
Value Function Update Magnitude: 0.33695

Collected Steps per Second: 22,736.98503
Overall Steps per Second: 10,861.93593

Timestep Collection Time: 2.19941
Timestep Consumption Time: 2.40456
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.60397

Cumulative Model Updates: 327,846
Cumulative Timesteps: 2,734,212,576

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.40256
Policy Entropy: 4.18345
Value Function Loss: 0.00292

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02273
Policy Update Magnitude: 0.28104
Value Function Update Magnitude: 0.34969

Collected Steps per Second: 22,814.89016
Overall Steps per Second: 10,914.16949

Timestep Collection Time: 2.19225
Timestep Consumption Time: 2.39041
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.58267

Cumulative Model Updates: 327,852
Cumulative Timesteps: 2,734,262,592

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2734262592...
Checkpoint 2734262592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.13781
Policy Entropy: 4.18877
Value Function Loss: 0.00269

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.02371
Policy Update Magnitude: 0.29101
Value Function Update Magnitude: 0.32571

Collected Steps per Second: 23,359.78147
Overall Steps per Second: 10,888.47016

Timestep Collection Time: 2.14052
Timestep Consumption Time: 2.45168
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.59220

Cumulative Model Updates: 327,858
Cumulative Timesteps: 2,734,312,594

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.13034
Policy Entropy: 4.22387
Value Function Loss: 0.00291

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.02928
Policy Update Magnitude: 0.33436
Value Function Update Magnitude: 0.30259

Collected Steps per Second: 22,773.52611
Overall Steps per Second: 10,703.05062

Timestep Collection Time: 2.19650
Timestep Consumption Time: 2.47712
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.67362

Cumulative Model Updates: 327,864
Cumulative Timesteps: 2,734,362,616

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2734362616...
Checkpoint 2734362616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.19560
Policy Entropy: 4.18793
Value Function Loss: 0.00336

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.03343
Policy Update Magnitude: 0.29588
Value Function Update Magnitude: 0.30623

Collected Steps per Second: 22,389.25617
Overall Steps per Second: 10,593.83186

Timestep Collection Time: 2.23357
Timestep Consumption Time: 2.48691
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.72048

Cumulative Model Updates: 327,870
Cumulative Timesteps: 2,734,412,624

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.06318
Policy Entropy: 4.20257
Value Function Loss: 0.00366

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.03222
Policy Update Magnitude: 0.28566
Value Function Update Magnitude: 0.32089

Collected Steps per Second: 23,500.22473
Overall Steps per Second: 10,948.42139

Timestep Collection Time: 2.12875
Timestep Consumption Time: 2.44050
PPO Batch Consumption Time: 0.28169
Total Iteration Time: 4.56924

Cumulative Model Updates: 327,876
Cumulative Timesteps: 2,734,462,650

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2734462650...
Checkpoint 2734462650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.81431
Policy Entropy: 4.15965
Value Function Loss: 0.00364

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.03044
Policy Update Magnitude: 0.27638
Value Function Update Magnitude: 0.32228

Collected Steps per Second: 22,499.53373
Overall Steps per Second: 10,637.27589

Timestep Collection Time: 2.22298
Timestep Consumption Time: 2.47898
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.70196

Cumulative Model Updates: 327,882
Cumulative Timesteps: 2,734,512,666

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.54904
Policy Entropy: 4.14544
Value Function Loss: 0.00400

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.02671
Policy Update Magnitude: 0.28315
Value Function Update Magnitude: 0.32573

Collected Steps per Second: 22,741.92783
Overall Steps per Second: 10,921.84667

Timestep Collection Time: 2.19858
Timestep Consumption Time: 2.37940
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.57798

Cumulative Model Updates: 327,888
Cumulative Timesteps: 2,734,562,666

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2734562666...
Checkpoint 2734562666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.61245
Policy Entropy: 4.13815
Value Function Loss: 0.00369

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.02713
Policy Update Magnitude: 0.28718
Value Function Update Magnitude: 0.32562

Collected Steps per Second: 22,940.18036
Overall Steps per Second: 10,708.78013

Timestep Collection Time: 2.18072
Timestep Consumption Time: 2.49078
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.67149

Cumulative Model Updates: 327,894
Cumulative Timesteps: 2,734,612,692

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.01389
Policy Entropy: 4.17789
Value Function Loss: 0.00356

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02405
Policy Update Magnitude: 0.27013
Value Function Update Magnitude: 0.31562

Collected Steps per Second: 22,866.52249
Overall Steps per Second: 10,833.81181

Timestep Collection Time: 2.18687
Timestep Consumption Time: 2.42887
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.61573

Cumulative Model Updates: 327,900
Cumulative Timesteps: 2,734,662,698

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2734662698...
Checkpoint 2734662698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.33342
Policy Entropy: 4.18797
Value Function Loss: 0.00382

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02001
Policy Update Magnitude: 0.26763
Value Function Update Magnitude: 0.30596

Collected Steps per Second: 22,594.51495
Overall Steps per Second: 10,850.12984

Timestep Collection Time: 2.21417
Timestep Consumption Time: 2.39665
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.61082

Cumulative Model Updates: 327,906
Cumulative Timesteps: 2,734,712,726

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.81296
Policy Entropy: 4.18385
Value Function Loss: 0.00406

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02116
Policy Update Magnitude: 0.27536
Value Function Update Magnitude: 0.31778

Collected Steps per Second: 22,949.79639
Overall Steps per Second: 10,668.08197

Timestep Collection Time: 2.17910
Timestep Consumption Time: 2.50871
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.68782

Cumulative Model Updates: 327,912
Cumulative Timesteps: 2,734,762,736

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2734762736...
Checkpoint 2734762736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.39563
Policy Entropy: 4.17364
Value Function Loss: 0.00397

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.02163
Policy Update Magnitude: 0.27285
Value Function Update Magnitude: 0.33206

Collected Steps per Second: 22,624.41699
Overall Steps per Second: 10,692.01641

Timestep Collection Time: 2.21097
Timestep Consumption Time: 2.46747
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.67844

Cumulative Model Updates: 327,918
Cumulative Timesteps: 2,734,812,758

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.89509
Policy Entropy: 4.22004
Value Function Loss: 0.00280

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02008
Policy Update Magnitude: 0.26489
Value Function Update Magnitude: 0.32588

Collected Steps per Second: 23,655.69147
Overall Steps per Second: 10,855.75695

Timestep Collection Time: 2.11467
Timestep Consumption Time: 2.49339
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.60806

Cumulative Model Updates: 327,924
Cumulative Timesteps: 2,734,862,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2734862782...
Checkpoint 2734862782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.90008
Policy Entropy: 4.20699
Value Function Loss: 0.00369

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.01826
Policy Update Magnitude: 0.26615
Value Function Update Magnitude: 0.32717

Collected Steps per Second: 22,880.71632
Overall Steps per Second: 10,695.35484

Timestep Collection Time: 2.18551
Timestep Consumption Time: 2.48998
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.67549

Cumulative Model Updates: 327,930
Cumulative Timesteps: 2,734,912,788

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.47899
Policy Entropy: 4.21113
Value Function Loss: 0.00315

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.01935
Policy Update Magnitude: 0.26805
Value Function Update Magnitude: 0.33580

Collected Steps per Second: 22,924.62272
Overall Steps per Second: 10,851.23090

Timestep Collection Time: 2.18193
Timestep Consumption Time: 2.42768
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.60962

Cumulative Model Updates: 327,936
Cumulative Timesteps: 2,734,962,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2734962808...
Checkpoint 2734962808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.51750
Policy Entropy: 4.14116
Value Function Loss: 0.00366

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.02259
Policy Update Magnitude: 0.26506
Value Function Update Magnitude: 0.32272

Collected Steps per Second: 22,802.10060
Overall Steps per Second: 10,678.66286

Timestep Collection Time: 2.19410
Timestep Consumption Time: 2.49095
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.68504

Cumulative Model Updates: 327,942
Cumulative Timesteps: 2,735,012,838

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.91521
Policy Entropy: 4.16053
Value Function Loss: 0.00301

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02393
Policy Update Magnitude: 0.26937
Value Function Update Magnitude: 0.30133

Collected Steps per Second: 22,848.61752
Overall Steps per Second: 10,828.54709

Timestep Collection Time: 2.18910
Timestep Consumption Time: 2.42998
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.61909

Cumulative Model Updates: 327,948
Cumulative Timesteps: 2,735,062,856

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2735062856...
Checkpoint 2735062856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.51929
Policy Entropy: 4.15887
Value Function Loss: 0.00286

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02333
Policy Update Magnitude: 0.26031
Value Function Update Magnitude: 0.29433

Collected Steps per Second: 22,708.76336
Overall Steps per Second: 10,896.41044

Timestep Collection Time: 2.20294
Timestep Consumption Time: 2.38812
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.59105

Cumulative Model Updates: 327,954
Cumulative Timesteps: 2,735,112,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.94869
Policy Entropy: 4.20639
Value Function Loss: 0.00248

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.01837
Policy Update Magnitude: 0.24504
Value Function Update Magnitude: 0.28574

Collected Steps per Second: 22,927.93129
Overall Steps per Second: 10,711.51146

Timestep Collection Time: 2.18179
Timestep Consumption Time: 2.48832
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.67012

Cumulative Model Updates: 327,960
Cumulative Timesteps: 2,735,162,906

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2735162906...
Checkpoint 2735162906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.40776
Policy Entropy: 4.22080
Value Function Loss: 0.00300

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.01614
Policy Update Magnitude: 0.24230
Value Function Update Magnitude: 0.28031

Collected Steps per Second: 22,845.27698
Overall Steps per Second: 10,781.44620

Timestep Collection Time: 2.18942
Timestep Consumption Time: 2.44984
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.63927

Cumulative Model Updates: 327,966
Cumulative Timesteps: 2,735,212,924

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.24024
Policy Entropy: 4.23332
Value Function Loss: 0.00291

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01487
Policy Update Magnitude: 0.23754
Value Function Update Magnitude: 0.29003

Collected Steps per Second: 22,936.40558
Overall Steps per Second: 10,907.91158

Timestep Collection Time: 2.18081
Timestep Consumption Time: 2.40485
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.58566

Cumulative Model Updates: 327,972
Cumulative Timesteps: 2,735,262,944

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2735262944...
Checkpoint 2735262944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.94363
Policy Entropy: 4.21608
Value Function Loss: 0.00335

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.01804
Policy Update Magnitude: 0.24274
Value Function Update Magnitude: 0.29524

Collected Steps per Second: 22,715.01207
Overall Steps per Second: 10,707.76535

Timestep Collection Time: 2.20198
Timestep Consumption Time: 2.46921
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.67119

Cumulative Model Updates: 327,978
Cumulative Timesteps: 2,735,312,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.22917
Policy Entropy: 4.19600
Value Function Loss: 0.00343

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.01873
Policy Update Magnitude: 0.26529
Value Function Update Magnitude: 0.30913

Collected Steps per Second: 23,057.58875
Overall Steps per Second: 10,800.58266

Timestep Collection Time: 2.16944
Timestep Consumption Time: 2.46198
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.63142

Cumulative Model Updates: 327,984
Cumulative Timesteps: 2,735,362,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2735362984...
Checkpoint 2735362984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.87234
Policy Entropy: 4.15728
Value Function Loss: 0.00338

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02238
Policy Update Magnitude: 0.27733
Value Function Update Magnitude: 0.31640

Collected Steps per Second: 22,683.25728
Overall Steps per Second: 11,051.27013

Timestep Collection Time: 2.20506
Timestep Consumption Time: 2.32093
PPO Batch Consumption Time: 0.27574
Total Iteration Time: 4.52600

Cumulative Model Updates: 327,990
Cumulative Timesteps: 2,735,413,002

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.20891
Policy Entropy: 4.18193
Value Function Loss: 0.00404

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02179
Policy Update Magnitude: 0.28060
Value Function Update Magnitude: 0.31433

Collected Steps per Second: 23,268.97556
Overall Steps per Second: 10,893.57083

Timestep Collection Time: 2.14896
Timestep Consumption Time: 2.44127
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.59023

Cumulative Model Updates: 327,996
Cumulative Timesteps: 2,735,463,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2735463006...
Checkpoint 2735463006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.87457
Policy Entropy: 4.16254
Value Function Loss: 0.00358

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02082
Policy Update Magnitude: 0.26895
Value Function Update Magnitude: 0.30711

Collected Steps per Second: 22,581.21984
Overall Steps per Second: 10,672.98138

Timestep Collection Time: 2.21441
Timestep Consumption Time: 2.47069
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.68510

Cumulative Model Updates: 328,002
Cumulative Timesteps: 2,735,513,010

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.46272
Policy Entropy: 4.17072
Value Function Loss: 0.00386

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02298
Policy Update Magnitude: 0.27778
Value Function Update Magnitude: 0.30164

Collected Steps per Second: 23,799.50322
Overall Steps per Second: 10,895.55079

Timestep Collection Time: 2.10139
Timestep Consumption Time: 2.48874
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.59013

Cumulative Model Updates: 328,008
Cumulative Timesteps: 2,735,563,022

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2735563022...
Checkpoint 2735563022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.84780
Policy Entropy: 4.17719
Value Function Loss: 0.00302

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02218
Policy Update Magnitude: 0.27048
Value Function Update Magnitude: 0.32770

Collected Steps per Second: 22,818.98663
Overall Steps per Second: 10,690.33797

Timestep Collection Time: 2.19177
Timestep Consumption Time: 2.48666
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.67843

Cumulative Model Updates: 328,014
Cumulative Timesteps: 2,735,613,036

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.13832
Policy Entropy: 4.19603
Value Function Loss: 0.00301

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.01864
Policy Update Magnitude: 0.26037
Value Function Update Magnitude: 0.32358

Collected Steps per Second: 22,741.95313
Overall Steps per Second: 10,801.01573

Timestep Collection Time: 2.19928
Timestep Consumption Time: 2.43139
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.63068

Cumulative Model Updates: 328,020
Cumulative Timesteps: 2,735,663,052

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2735663052...
Checkpoint 2735663052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.82958
Policy Entropy: 4.19967
Value Function Loss: 0.00285

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.01634
Policy Update Magnitude: 0.25110
Value Function Update Magnitude: 0.29589

Collected Steps per Second: 22,612.61570
Overall Steps per Second: 10,651.65380

Timestep Collection Time: 2.21177
Timestep Consumption Time: 2.48365
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.69542

Cumulative Model Updates: 328,026
Cumulative Timesteps: 2,735,713,066

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.66994
Policy Entropy: 4.16281
Value Function Loss: 0.00345

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.01820
Policy Update Magnitude: 0.25961
Value Function Update Magnitude: 0.30646

Collected Steps per Second: 22,926.58000
Overall Steps per Second: 10,947.49125

Timestep Collection Time: 2.18218
Timestep Consumption Time: 2.38781
PPO Batch Consumption Time: 0.27621
Total Iteration Time: 4.57000

Cumulative Model Updates: 328,032
Cumulative Timesteps: 2,735,763,096

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2735763096...
Checkpoint 2735763096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.97188
Policy Entropy: 4.16490
Value Function Loss: 0.00378

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02083
Policy Update Magnitude: 0.26603
Value Function Update Magnitude: 0.31129

Collected Steps per Second: 22,755.11974
Overall Steps per Second: 11,024.46884

Timestep Collection Time: 2.19854
Timestep Consumption Time: 2.33937
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.53791

Cumulative Model Updates: 328,038
Cumulative Timesteps: 2,735,813,124

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.99524
Policy Entropy: 4.19384
Value Function Loss: 0.00344

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.01895
Policy Update Magnitude: 0.25733
Value Function Update Magnitude: 0.30961

Collected Steps per Second: 22,792.78590
Overall Steps per Second: 10,727.64900

Timestep Collection Time: 2.19376
Timestep Consumption Time: 2.46728
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.66104

Cumulative Model Updates: 328,044
Cumulative Timesteps: 2,735,863,126

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2735863126...
Checkpoint 2735863126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.77918
Policy Entropy: 4.22762
Value Function Loss: 0.00278

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.01795
Policy Update Magnitude: 0.23208
Value Function Update Magnitude: 0.29681

Collected Steps per Second: 22,540.58023
Overall Steps per Second: 10,852.98597

Timestep Collection Time: 2.21849
Timestep Consumption Time: 2.38909
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.60758

Cumulative Model Updates: 328,050
Cumulative Timesteps: 2,735,913,132

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.84406
Policy Entropy: 4.21883
Value Function Loss: 0.00260

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.01290
Policy Update Magnitude: 0.23255
Value Function Update Magnitude: 0.28537

Collected Steps per Second: 23,660.46532
Overall Steps per Second: 10,942.50269

Timestep Collection Time: 2.11357
Timestep Consumption Time: 2.45650
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.57007

Cumulative Model Updates: 328,056
Cumulative Timesteps: 2,735,963,140

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2735963140...
Checkpoint 2735963140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.02847
Policy Entropy: 4.18832
Value Function Loss: 0.00352

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01545
Policy Update Magnitude: 0.25274
Value Function Update Magnitude: 0.31236

Collected Steps per Second: 22,929.48384
Overall Steps per Second: 10,738.41514

Timestep Collection Time: 2.18138
Timestep Consumption Time: 2.47647
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.65786

Cumulative Model Updates: 328,062
Cumulative Timesteps: 2,736,013,158

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.03830
Policy Entropy: 4.17901
Value Function Loss: 0.00381

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02085
Policy Update Magnitude: 0.26984
Value Function Update Magnitude: 0.35746

Collected Steps per Second: 22,768.30085
Overall Steps per Second: 10,796.09313

Timestep Collection Time: 2.19639
Timestep Consumption Time: 2.43566
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.63205

Cumulative Model Updates: 328,068
Cumulative Timesteps: 2,736,063,166

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2736063166...
Checkpoint 2736063166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.61941
Policy Entropy: 4.18629
Value Function Loss: 0.00343

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02374
Policy Update Magnitude: 0.26571
Value Function Update Magnitude: 0.35509

Collected Steps per Second: 23,030.63395
Overall Steps per Second: 10,800.94768

Timestep Collection Time: 2.17137
Timestep Consumption Time: 2.45860
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.62996

Cumulative Model Updates: 328,074
Cumulative Timesteps: 2,736,113,174

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.32969
Policy Entropy: 4.21555
Value Function Loss: 0.00304

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.01833
Policy Update Magnitude: 0.24869
Value Function Update Magnitude: 0.33312

Collected Steps per Second: 23,049.72377
Overall Steps per Second: 10,827.31692

Timestep Collection Time: 2.16948
Timestep Consumption Time: 2.44902
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.61850

Cumulative Model Updates: 328,080
Cumulative Timesteps: 2,736,163,180

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2736163180...
Checkpoint 2736163180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.87678
Policy Entropy: 4.20460
Value Function Loss: 0.00277

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.01904
Policy Update Magnitude: 0.24235
Value Function Update Magnitude: 0.32923

Collected Steps per Second: 22,522.32178
Overall Steps per Second: 10,959.83963

Timestep Collection Time: 2.22144
Timestep Consumption Time: 2.34359
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.56503

Cumulative Model Updates: 328,086
Cumulative Timesteps: 2,736,213,212

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.90753
Policy Entropy: 4.24806
Value Function Loss: 0.00213

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.01542
Policy Update Magnitude: 0.22040
Value Function Update Magnitude: 0.31768

Collected Steps per Second: 22,878.65172
Overall Steps per Second: 10,739.96320

Timestep Collection Time: 2.18658
Timestep Consumption Time: 2.47135
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.65793

Cumulative Model Updates: 328,092
Cumulative Timesteps: 2,736,263,238

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2736263238...
Checkpoint 2736263238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.76659
Policy Entropy: 4.24037
Value Function Loss: 0.00232

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.01437
Policy Update Magnitude: 0.21771
Value Function Update Magnitude: 0.30719

Collected Steps per Second: 22,646.35188
Overall Steps per Second: 10,919.89587

Timestep Collection Time: 2.20830
Timestep Consumption Time: 2.37141
PPO Batch Consumption Time: 0.27549
Total Iteration Time: 4.57971

Cumulative Model Updates: 328,098
Cumulative Timesteps: 2,736,313,248

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.25900
Policy Entropy: 4.25137
Value Function Loss: 0.00262

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01160
Policy Update Magnitude: 0.22210
Value Function Update Magnitude: 0.31001

Collected Steps per Second: 23,715.66505
Overall Steps per Second: 10,851.98074

Timestep Collection Time: 2.10882
Timestep Consumption Time: 2.49974
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.60856

Cumulative Model Updates: 328,104
Cumulative Timesteps: 2,736,363,260

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2736363260...
Checkpoint 2736363260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.18702
Policy Entropy: 4.20177
Value Function Loss: 0.00294

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.01488
Policy Update Magnitude: 0.23748
Value Function Update Magnitude: 0.32503

Collected Steps per Second: 22,749.02401
Overall Steps per Second: 10,632.68516

Timestep Collection Time: 2.19851
Timestep Consumption Time: 2.50529
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.70380

Cumulative Model Updates: 328,110
Cumulative Timesteps: 2,736,413,274

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.94425
Policy Entropy: 4.18247
Value Function Loss: 0.00325

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.01740
Policy Update Magnitude: 0.25128
Value Function Update Magnitude: 0.35567

Collected Steps per Second: 22,821.26184
Overall Steps per Second: 10,870.04441

Timestep Collection Time: 2.19111
Timestep Consumption Time: 2.40905
PPO Batch Consumption Time: 0.27699
Total Iteration Time: 4.60017

Cumulative Model Updates: 328,116
Cumulative Timesteps: 2,736,463,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2736463278...
Checkpoint 2736463278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.74733
Policy Entropy: 4.18007
Value Function Loss: 0.00315

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02062
Policy Update Magnitude: 0.25182
Value Function Update Magnitude: 0.36983

Collected Steps per Second: 23,483.16085
Overall Steps per Second: 10,897.38993

Timestep Collection Time: 2.12961
Timestep Consumption Time: 2.45956
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.58917

Cumulative Model Updates: 328,122
Cumulative Timesteps: 2,736,513,288

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.05220
Policy Entropy: 4.18940
Value Function Loss: 0.00385

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.01926
Policy Update Magnitude: 0.26059
Value Function Update Magnitude: 0.35993

Collected Steps per Second: 22,661.30738
Overall Steps per Second: 10,729.69955

Timestep Collection Time: 2.20808
Timestep Consumption Time: 2.45542
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.66350

Cumulative Model Updates: 328,128
Cumulative Timesteps: 2,736,563,326

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2736563326...
Checkpoint 2736563326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.64783
Policy Entropy: 4.22171
Value Function Loss: 0.00304

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.01773
Policy Update Magnitude: 0.25406
Value Function Update Magnitude: 0.34609

Collected Steps per Second: 22,720.55682
Overall Steps per Second: 11,039.01263

Timestep Collection Time: 2.20135
Timestep Consumption Time: 2.32949
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.53084

Cumulative Model Updates: 328,134
Cumulative Timesteps: 2,736,613,342

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.40207
Policy Entropy: 4.18833
Value Function Loss: 0.00320

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.01747
Policy Update Magnitude: 0.25428
Value Function Update Magnitude: 0.34423

Collected Steps per Second: 22,799.16726
Overall Steps per Second: 10,737.66334

Timestep Collection Time: 2.19324
Timestep Consumption Time: 2.46364
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.65688

Cumulative Model Updates: 328,140
Cumulative Timesteps: 2,736,663,346

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2736663346...
Checkpoint 2736663346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.07136
Policy Entropy: 4.16735
Value Function Loss: 0.00340

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02214
Policy Update Magnitude: 0.28153
Value Function Update Magnitude: 0.35902

Collected Steps per Second: 21,974.56497
Overall Steps per Second: 10,483.76560

Timestep Collection Time: 2.27663
Timestep Consumption Time: 2.49532
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.77195

Cumulative Model Updates: 328,146
Cumulative Timesteps: 2,736,713,374

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.32688
Policy Entropy: 4.14828
Value Function Loss: 0.00391

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.02544
Policy Update Magnitude: 0.30845
Value Function Update Magnitude: 0.38263

Collected Steps per Second: 22,824.91062
Overall Steps per Second: 10,831.78562

Timestep Collection Time: 2.19103
Timestep Consumption Time: 2.42594
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.61697

Cumulative Model Updates: 328,152
Cumulative Timesteps: 2,736,763,384

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2736763384...
Checkpoint 2736763384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.01994
Policy Entropy: 4.19090
Value Function Loss: 0.00370

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.02254
Policy Update Magnitude: 0.30058
Value Function Update Magnitude: 0.38668

Collected Steps per Second: 22,790.86508
Overall Steps per Second: 10,646.13203

Timestep Collection Time: 2.19412
Timestep Consumption Time: 2.50298
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.69711

Cumulative Model Updates: 328,158
Cumulative Timesteps: 2,736,813,390

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.53780
Policy Entropy: 4.19727
Value Function Loss: 0.00340

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.02278
Policy Update Magnitude: 0.28006
Value Function Update Magnitude: 0.37085

Collected Steps per Second: 22,680.24253
Overall Steps per Second: 10,875.74626

Timestep Collection Time: 2.20588
Timestep Consumption Time: 2.39426
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.60014

Cumulative Model Updates: 328,164
Cumulative Timesteps: 2,736,863,420

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2736863420...
Checkpoint 2736863420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.34770
Policy Entropy: 4.18753
Value Function Loss: 0.00349

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02187
Policy Update Magnitude: 0.27553
Value Function Update Magnitude: 0.35833

Collected Steps per Second: 23,446.58851
Overall Steps per Second: 10,938.12304

Timestep Collection Time: 2.13327
Timestep Consumption Time: 2.43954
PPO Batch Consumption Time: 0.28470
Total Iteration Time: 4.57281

Cumulative Model Updates: 328,170
Cumulative Timesteps: 2,736,913,438

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.59081
Policy Entropy: 4.16197
Value Function Loss: 0.00394

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.02363
Policy Update Magnitude: 0.27730
Value Function Update Magnitude: 0.37147

Collected Steps per Second: 22,324.91642
Overall Steps per Second: 10,628.96337

Timestep Collection Time: 2.23992
Timestep Consumption Time: 2.46477
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.70469

Cumulative Model Updates: 328,176
Cumulative Timesteps: 2,736,963,444

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2736963444...
Checkpoint 2736963444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.90734
Policy Entropy: 4.17306
Value Function Loss: 0.00377

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.26899
Value Function Update Magnitude: 0.38233

Collected Steps per Second: 22,242.53580
Overall Steps per Second: 10,743.00600

Timestep Collection Time: 2.24830
Timestep Consumption Time: 2.40663
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.65494

Cumulative Model Updates: 328,182
Cumulative Timesteps: 2,737,013,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.03174
Policy Entropy: 4.20353
Value Function Loss: 0.00316

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02248
Policy Update Magnitude: 0.25938
Value Function Update Magnitude: 0.36182

Collected Steps per Second: 22,912.75711
Overall Steps per Second: 10,832.40795

Timestep Collection Time: 2.18333
Timestep Consumption Time: 2.43485
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.61818

Cumulative Model Updates: 328,188
Cumulative Timesteps: 2,737,063,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2737063478...
Checkpoint 2737063478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.15908
Policy Entropy: 4.23420
Value Function Loss: 0.00324

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.01875
Policy Update Magnitude: 0.24483
Value Function Update Magnitude: 0.32173

Collected Steps per Second: 22,609.12135
Overall Steps per Second: 10,623.80279

Timestep Collection Time: 2.21265
Timestep Consumption Time: 2.49621
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.70886

Cumulative Model Updates: 328,194
Cumulative Timesteps: 2,737,113,504

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.67491
Policy Entropy: 4.23362
Value Function Loss: 0.00312

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.01771
Policy Update Magnitude: 0.23751
Value Function Update Magnitude: 0.31081

Collected Steps per Second: 22,832.01313
Overall Steps per Second: 10,931.90526

Timestep Collection Time: 2.19087
Timestep Consumption Time: 2.38491
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.57578

Cumulative Model Updates: 328,200
Cumulative Timesteps: 2,737,163,526

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2737163526...
Checkpoint 2737163526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.29637
Policy Entropy: 4.21906
Value Function Loss: 0.00302

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.01697
Policy Update Magnitude: 0.23960
Value Function Update Magnitude: 0.32279

Collected Steps per Second: 22,897.65529
Overall Steps per Second: 10,712.02063

Timestep Collection Time: 2.18442
Timestep Consumption Time: 2.48492
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.66933

Cumulative Model Updates: 328,206
Cumulative Timesteps: 2,737,213,544

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.15475
Policy Entropy: 4.20757
Value Function Loss: 0.00301

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02015
Policy Update Magnitude: 0.25648
Value Function Update Magnitude: 0.31698

Collected Steps per Second: 22,771.13971
Overall Steps per Second: 10,846.48939

Timestep Collection Time: 2.19646
Timestep Consumption Time: 2.41480
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.61126

Cumulative Model Updates: 328,212
Cumulative Timesteps: 2,737,263,560

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2737263560...
Checkpoint 2737263560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.57481
Policy Entropy: 4.21675
Value Function Loss: 0.00286

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.01766
Policy Update Magnitude: 0.25671
Value Function Update Magnitude: 0.32909

Collected Steps per Second: 22,152.72654
Overall Steps per Second: 10,680.90674

Timestep Collection Time: 2.25814
Timestep Consumption Time: 2.42536
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.68350

Cumulative Model Updates: 328,218
Cumulative Timesteps: 2,737,313,584

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.77102
Policy Entropy: 4.17266
Value Function Loss: 0.00397

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.01832
Policy Update Magnitude: 0.27063
Value Function Update Magnitude: 0.34236

Collected Steps per Second: 23,123.12886
Overall Steps per Second: 10,822.50216

Timestep Collection Time: 2.16268
Timestep Consumption Time: 2.45806
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.62074

Cumulative Model Updates: 328,224
Cumulative Timesteps: 2,737,363,592

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2737363592...
Checkpoint 2737363592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.52630
Policy Entropy: 4.16426
Value Function Loss: 0.00392

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02157
Policy Update Magnitude: 0.28055
Value Function Update Magnitude: 0.35929

Collected Steps per Second: 22,503.31543
Overall Steps per Second: 10,684.63263

Timestep Collection Time: 2.22234
Timestep Consumption Time: 2.45821
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.68055

Cumulative Model Updates: 328,230
Cumulative Timesteps: 2,737,413,602

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.08308
Policy Entropy: 4.14918
Value Function Loss: 0.00445

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.02496
Policy Update Magnitude: 0.28174
Value Function Update Magnitude: 0.37757

Collected Steps per Second: 22,844.70619
Overall Steps per Second: 10,889.00774

Timestep Collection Time: 2.18965
Timestep Consumption Time: 2.40415
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.59381

Cumulative Model Updates: 328,236
Cumulative Timesteps: 2,737,463,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2737463624...
Checkpoint 2737463624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.46109
Policy Entropy: 4.19530
Value Function Loss: 0.00358

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.02315
Policy Update Magnitude: 0.27500
Value Function Update Magnitude: 0.38207

Collected Steps per Second: 22,650.94203
Overall Steps per Second: 10,627.14659

Timestep Collection Time: 2.20768
Timestep Consumption Time: 2.49782
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.70550

Cumulative Model Updates: 328,242
Cumulative Timesteps: 2,737,513,630

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.09506
Policy Entropy: 4.18705
Value Function Loss: 0.00325

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02051
Policy Update Magnitude: 0.26509
Value Function Update Magnitude: 0.37013

Collected Steps per Second: 22,710.05851
Overall Steps per Second: 10,870.14153

Timestep Collection Time: 2.20272
Timestep Consumption Time: 2.39924
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.60196

Cumulative Model Updates: 328,248
Cumulative Timesteps: 2,737,563,654

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2737563654...
Checkpoint 2737563654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.73952
Policy Entropy: 4.20523
Value Function Loss: 0.00286

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.01882
Policy Update Magnitude: 0.26567
Value Function Update Magnitude: 0.35955

Collected Steps per Second: 23,249.37318
Overall Steps per Second: 10,841.11646

Timestep Collection Time: 2.15163
Timestep Consumption Time: 2.46266
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.61428

Cumulative Model Updates: 328,254
Cumulative Timesteps: 2,737,613,678

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.57423
Policy Entropy: 4.18425
Value Function Loss: 0.00328

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02110
Policy Update Magnitude: 0.27451
Value Function Update Magnitude: 0.35568

Collected Steps per Second: 22,918.85103
Overall Steps per Second: 10,757.44671

Timestep Collection Time: 2.18170
Timestep Consumption Time: 2.46643
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.64813

Cumulative Model Updates: 328,260
Cumulative Timesteps: 2,737,663,680

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2737663680...
Checkpoint 2737663680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.52195
Policy Entropy: 4.18234
Value Function Loss: 0.00409

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.02249
Policy Update Magnitude: 0.27750
Value Function Update Magnitude: 0.36686

Collected Steps per Second: 22,743.80020
Overall Steps per Second: 10,756.21605

Timestep Collection Time: 2.19937
Timestep Consumption Time: 2.45115
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.65052

Cumulative Model Updates: 328,266
Cumulative Timesteps: 2,737,713,702

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.76927
Policy Entropy: 4.16760
Value Function Loss: 0.00408

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.02912
Policy Update Magnitude: 0.28266
Value Function Update Magnitude: 0.38054

Collected Steps per Second: 23,575.69592
Overall Steps per Second: 10,868.74462

Timestep Collection Time: 2.12142
Timestep Consumption Time: 2.48021
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.60164

Cumulative Model Updates: 328,272
Cumulative Timesteps: 2,737,763,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2737763716...
Checkpoint 2737763716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.31291
Policy Entropy: 4.19692
Value Function Loss: 0.00419

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.02606
Policy Update Magnitude: 0.27141
Value Function Update Magnitude: 0.36442

Collected Steps per Second: 22,777.19723
Overall Steps per Second: 10,717.88330

Timestep Collection Time: 2.19641
Timestep Consumption Time: 2.47131
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.66771

Cumulative Model Updates: 328,278
Cumulative Timesteps: 2,737,813,744

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.86785
Policy Entropy: 4.17809
Value Function Loss: 0.00459

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.02062
Policy Update Magnitude: 0.29005
Value Function Update Magnitude: 0.34624

Collected Steps per Second: 22,673.63291
Overall Steps per Second: 10,739.64691

Timestep Collection Time: 2.20609
Timestep Consumption Time: 2.45142
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.65751

Cumulative Model Updates: 328,284
Cumulative Timesteps: 2,737,863,764

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2737863764...
Checkpoint 2737863764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.54522
Policy Entropy: 4.18304
Value Function Loss: 0.00431

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02328
Policy Update Magnitude: 0.28833
Value Function Update Magnitude: 0.35562

Collected Steps per Second: 23,512.16531
Overall Steps per Second: 11,010.33775

Timestep Collection Time: 2.12681
Timestep Consumption Time: 2.41492
PPO Batch Consumption Time: 0.27659
Total Iteration Time: 4.54173

Cumulative Model Updates: 328,290
Cumulative Timesteps: 2,737,913,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.18314
Policy Entropy: 4.12768
Value Function Loss: 0.00428

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.02628
Policy Update Magnitude: 0.30556
Value Function Update Magnitude: 0.37016

Collected Steps per Second: 22,778.75387
Overall Steps per Second: 10,672.08240

Timestep Collection Time: 2.19599
Timestep Consumption Time: 2.49119
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.68718

Cumulative Model Updates: 328,296
Cumulative Timesteps: 2,737,963,792

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2737963792...
Checkpoint 2737963792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.80755
Policy Entropy: 4.14004
Value Function Loss: 0.00361

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.02556
Policy Update Magnitude: 0.30924
Value Function Update Magnitude: 0.38061

Collected Steps per Second: 22,795.87580
Overall Steps per Second: 10,884.52827

Timestep Collection Time: 2.19461
Timestep Consumption Time: 2.40164
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.59625

Cumulative Model Updates: 328,302
Cumulative Timesteps: 2,738,013,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.52926
Policy Entropy: 4.13287
Value Function Loss: 0.00336

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.02888
Policy Update Magnitude: 0.29156
Value Function Update Magnitude: 0.37521

Collected Steps per Second: 23,345.04116
Overall Steps per Second: 11,002.09910

Timestep Collection Time: 2.14290
Timestep Consumption Time: 2.40405
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.54695

Cumulative Model Updates: 328,308
Cumulative Timesteps: 2,738,063,846

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2738063846...
Checkpoint 2738063846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.37708
Policy Entropy: 4.15497
Value Function Loss: 0.00315

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.02580
Policy Update Magnitude: 0.27785
Value Function Update Magnitude: 0.35144

Collected Steps per Second: 22,784.46086
Overall Steps per Second: 10,669.13241

Timestep Collection Time: 2.19483
Timestep Consumption Time: 2.49234
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.68717

Cumulative Model Updates: 328,314
Cumulative Timesteps: 2,738,113,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.87942
Policy Entropy: 4.15344
Value Function Loss: 0.00355

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02222
Policy Update Magnitude: 0.27155
Value Function Update Magnitude: 0.34728

Collected Steps per Second: 22,731.16311
Overall Steps per Second: 10,863.82625

Timestep Collection Time: 2.20006
Timestep Consumption Time: 2.40329
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.60335

Cumulative Model Updates: 328,320
Cumulative Timesteps: 2,738,163,864

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2738163864...
Checkpoint 2738163864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.57392
Policy Entropy: 4.13303
Value Function Loss: 0.00389

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02201
Policy Update Magnitude: 0.28173
Value Function Update Magnitude: 0.35696

Collected Steps per Second: 23,433.81248
Overall Steps per Second: 10,856.30153

Timestep Collection Time: 2.13452
Timestep Consumption Time: 2.47294
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.60746

Cumulative Model Updates: 328,326
Cumulative Timesteps: 2,738,213,884

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.99593
Policy Entropy: 4.12798
Value Function Loss: 0.00388

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02165
Policy Update Magnitude: 0.29329
Value Function Update Magnitude: 0.36502

Collected Steps per Second: 22,687.67504
Overall Steps per Second: 10,753.99941

Timestep Collection Time: 2.20393
Timestep Consumption Time: 2.44569
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.64962

Cumulative Model Updates: 328,332
Cumulative Timesteps: 2,738,263,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2738263886...
Checkpoint 2738263886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.01525
Policy Entropy: 4.12465
Value Function Loss: 0.00472

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.02465
Policy Update Magnitude: 0.30233
Value Function Update Magnitude: 0.36456

Collected Steps per Second: 22,693.11744
Overall Steps per Second: 10,704.06457

Timestep Collection Time: 2.20410
Timestep Consumption Time: 2.46870
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.67280

Cumulative Model Updates: 328,338
Cumulative Timesteps: 2,738,313,904

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.63410
Policy Entropy: 4.16361
Value Function Loss: 0.00475

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.02792
Policy Update Magnitude: 0.28805
Value Function Update Magnitude: 0.37133

Collected Steps per Second: 23,885.95973
Overall Steps per Second: 10,911.72687

Timestep Collection Time: 2.09428
Timestep Consumption Time: 2.49014
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.58443

Cumulative Model Updates: 328,344
Cumulative Timesteps: 2,738,363,928

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2738363928...
Checkpoint 2738363928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.45728
Policy Entropy: 4.16914
Value Function Loss: 0.00485

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02295
Policy Update Magnitude: 0.28160
Value Function Update Magnitude: 0.39231

Collected Steps per Second: 22,826.14255
Overall Steps per Second: 10,753.74635

Timestep Collection Time: 2.19161
Timestep Consumption Time: 2.46035
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.65196

Cumulative Model Updates: 328,350
Cumulative Timesteps: 2,738,413,954

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.66210
Policy Entropy: 4.16530
Value Function Loss: 0.00482

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02403
Policy Update Magnitude: 0.28414
Value Function Update Magnitude: 0.38193

Collected Steps per Second: 22,516.37886
Overall Steps per Second: 10,813.37637

Timestep Collection Time: 2.22158
Timestep Consumption Time: 2.40435
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.62594

Cumulative Model Updates: 328,356
Cumulative Timesteps: 2,738,463,976

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2738463976...
Checkpoint 2738463976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.85746
Policy Entropy: 4.14157
Value Function Loss: 0.00464

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.03026
Policy Update Magnitude: 0.29175
Value Function Update Magnitude: 0.37647

Collected Steps per Second: 22,938.62985
Overall Steps per Second: 10,900.31292

Timestep Collection Time: 2.18008
Timestep Consumption Time: 2.40768
PPO Batch Consumption Time: 0.27701
Total Iteration Time: 4.58776

Cumulative Model Updates: 328,362
Cumulative Timesteps: 2,738,513,984

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.74069
Policy Entropy: 4.14481
Value Function Loss: 0.00446

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.02820
Policy Update Magnitude: 0.29476
Value Function Update Magnitude: 0.38102

Collected Steps per Second: 22,793.96666
Overall Steps per Second: 10,895.52797

Timestep Collection Time: 2.19435
Timestep Consumption Time: 2.39634
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.59069

Cumulative Model Updates: 328,368
Cumulative Timesteps: 2,738,564,002

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2738564002...
Checkpoint 2738564002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.47041
Policy Entropy: 4.18467
Value Function Loss: 0.00367

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02521
Policy Update Magnitude: 0.27666
Value Function Update Magnitude: 0.37170

Collected Steps per Second: 23,321.27724
Overall Steps per Second: 10,777.60611

Timestep Collection Time: 2.14439
Timestep Consumption Time: 2.49578
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.64018

Cumulative Model Updates: 328,374
Cumulative Timesteps: 2,738,614,012

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.66023
Policy Entropy: 4.17932
Value Function Loss: 0.00345

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02074
Policy Update Magnitude: 0.26562
Value Function Update Magnitude: 0.35515

Collected Steps per Second: 22,635.78950
Overall Steps per Second: 10,799.80139

Timestep Collection Time: 2.20942
Timestep Consumption Time: 2.42140
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.63083

Cumulative Model Updates: 328,380
Cumulative Timesteps: 2,738,664,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2738664024...
Checkpoint 2738664024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.46066
Policy Entropy: 4.19955
Value Function Loss: 0.00305

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02115
Policy Update Magnitude: 0.25442
Value Function Update Magnitude: 0.33952

Collected Steps per Second: 22,421.42014
Overall Steps per Second: 10,749.72613

Timestep Collection Time: 2.23090
Timestep Consumption Time: 2.42224
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.65314

Cumulative Model Updates: 328,386
Cumulative Timesteps: 2,738,714,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.28274
Policy Entropy: 4.20328
Value Function Loss: 0.00305

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02125
Policy Update Magnitude: 0.24199
Value Function Update Magnitude: 0.33014

Collected Steps per Second: 23,666.10099
Overall Steps per Second: 10,902.09435

Timestep Collection Time: 2.11315
Timestep Consumption Time: 2.47404
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.58719

Cumulative Model Updates: 328,392
Cumulative Timesteps: 2,738,764,054

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2738764054...
Checkpoint 2738764054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.66359
Policy Entropy: 4.21779
Value Function Loss: 0.00267

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.01789
Policy Update Magnitude: 0.23450
Value Function Update Magnitude: 0.32303

Collected Steps per Second: 22,630.46793
Overall Steps per Second: 10,631.07738

Timestep Collection Time: 2.21012
Timestep Consumption Time: 2.49458
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.70470

Cumulative Model Updates: 328,398
Cumulative Timesteps: 2,738,814,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.85598
Policy Entropy: 4.18640
Value Function Loss: 0.00370

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.01903
Policy Update Magnitude: 0.24996
Value Function Update Magnitude: 0.33180

Collected Steps per Second: 22,760.01059
Overall Steps per Second: 10,947.27389

Timestep Collection Time: 2.19727
Timestep Consumption Time: 2.37099
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.56826

Cumulative Model Updates: 328,404
Cumulative Timesteps: 2,738,864,080

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2738864080...
Checkpoint 2738864080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.81393
Policy Entropy: 4.14727
Value Function Loss: 0.00425

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02464
Policy Update Magnitude: 0.27698
Value Function Update Magnitude: 0.36079

Collected Steps per Second: 22,778.54953
Overall Steps per Second: 10,676.29216

Timestep Collection Time: 2.19601
Timestep Consumption Time: 2.48932
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.68533

Cumulative Model Updates: 328,410
Cumulative Timesteps: 2,738,914,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.28343
Policy Entropy: 4.12351
Value Function Loss: 0.00439

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.02781
Policy Update Magnitude: 0.29306
Value Function Update Magnitude: 0.37357

Collected Steps per Second: 22,884.09005
Overall Steps per Second: 10,873.10484

Timestep Collection Time: 2.18510
Timestep Consumption Time: 2.41377
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.59887

Cumulative Model Updates: 328,416
Cumulative Timesteps: 2,738,964,106

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2738964106...
Checkpoint 2738964106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.51876
Policy Entropy: 4.17042
Value Function Loss: 0.00346

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.02378
Policy Update Magnitude: 0.27991
Value Function Update Magnitude: 0.36122

Collected Steps per Second: 22,832.50711
Overall Steps per Second: 11,052.07871

Timestep Collection Time: 2.19082
Timestep Consumption Time: 2.33520
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.52603

Cumulative Model Updates: 328,422
Cumulative Timesteps: 2,739,014,128

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.96680
Policy Entropy: 4.20676
Value Function Loss: 0.00299

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.01978
Policy Update Magnitude: 0.25027
Value Function Update Magnitude: 0.34016

Collected Steps per Second: 22,778.78601
Overall Steps per Second: 10,865.12605

Timestep Collection Time: 2.19582
Timestep Consumption Time: 2.40772
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.60354

Cumulative Model Updates: 328,428
Cumulative Timesteps: 2,739,064,146

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2739064146...
Checkpoint 2739064146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.74934
Policy Entropy: 4.20739
Value Function Loss: 0.00322

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01705
Policy Update Magnitude: 0.24822
Value Function Update Magnitude: 0.32877

Collected Steps per Second: 22,432.41907
Overall Steps per Second: 10,758.35845

Timestep Collection Time: 2.22972
Timestep Consumption Time: 2.41950
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.64922

Cumulative Model Updates: 328,434
Cumulative Timesteps: 2,739,114,164

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.93963
Policy Entropy: 4.20292
Value Function Loss: 0.00326

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.01937
Policy Update Magnitude: 0.26704
Value Function Update Magnitude: 0.33907

Collected Steps per Second: 23,986.36415
Overall Steps per Second: 10,948.59275

Timestep Collection Time: 2.08527
Timestep Consumption Time: 2.48317
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.56844

Cumulative Model Updates: 328,440
Cumulative Timesteps: 2,739,164,182

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2739164182...
Checkpoint 2739164182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.20307
Policy Entropy: 4.18688
Value Function Loss: 0.00347

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02175
Policy Update Magnitude: 0.25868
Value Function Update Magnitude: 0.33989

Collected Steps per Second: 22,852.81518
Overall Steps per Second: 10,737.48060

Timestep Collection Time: 2.18870
Timestep Consumption Time: 2.46956
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.65826

Cumulative Model Updates: 328,446
Cumulative Timesteps: 2,739,214,200

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.72707
Policy Entropy: 4.19552
Value Function Loss: 0.00359

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02091
Policy Update Magnitude: 0.26064
Value Function Update Magnitude: 0.35372

Collected Steps per Second: 22,676.66518
Overall Steps per Second: 10,811.79287

Timestep Collection Time: 2.20597
Timestep Consumption Time: 2.42083
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.62680

Cumulative Model Updates: 328,452
Cumulative Timesteps: 2,739,264,224

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2739264224...
Checkpoint 2739264224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.12408
Policy Entropy: 4.17516
Value Function Loss: 0.00334

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02131
Policy Update Magnitude: 0.27121
Value Function Update Magnitude: 0.36254

Collected Steps per Second: 22,953.79771
Overall Steps per Second: 10,799.33614

Timestep Collection Time: 2.17890
Timestep Consumption Time: 2.45231
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.63121

Cumulative Model Updates: 328,458
Cumulative Timesteps: 2,739,314,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.21048
Policy Entropy: 4.18136
Value Function Loss: 0.00378

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.01966
Policy Update Magnitude: 0.26764
Value Function Update Magnitude: 0.36169

Collected Steps per Second: 22,912.85093
Overall Steps per Second: 10,802.14130

Timestep Collection Time: 2.18236
Timestep Consumption Time: 2.44673
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.62908

Cumulative Model Updates: 328,464
Cumulative Timesteps: 2,739,364,242

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2739364242...
Checkpoint 2739364242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.94680
Policy Entropy: 4.19640
Value Function Loss: 0.00355

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.01876
Policy Update Magnitude: 0.26777
Value Function Update Magnitude: 0.36093

Collected Steps per Second: 22,805.48822
Overall Steps per Second: 10,967.11834

Timestep Collection Time: 2.19281
Timestep Consumption Time: 2.36701
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.55981

Cumulative Model Updates: 328,470
Cumulative Timesteps: 2,739,414,250

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.78010
Policy Entropy: 4.21547
Value Function Loss: 0.00309

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.01837
Policy Update Magnitude: 0.25303
Value Function Update Magnitude: 0.35045

Collected Steps per Second: 22,805.43095
Overall Steps per Second: 10,862.56063

Timestep Collection Time: 2.19316
Timestep Consumption Time: 2.41128
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.60444

Cumulative Model Updates: 328,476
Cumulative Timesteps: 2,739,464,266

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2739464266...
Checkpoint 2739464266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.99445
Policy Entropy: 4.22266
Value Function Loss: 0.00313

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.01823
Policy Update Magnitude: 0.25364
Value Function Update Magnitude: 0.32933

Collected Steps per Second: 22,736.47031
Overall Steps per Second: 10,696.09676

Timestep Collection Time: 2.20043
Timestep Consumption Time: 2.47698
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.67741

Cumulative Model Updates: 328,482
Cumulative Timesteps: 2,739,514,296

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.53985
Policy Entropy: 4.21558
Value Function Loss: 0.00415

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.01867
Policy Update Magnitude: 0.26781
Value Function Update Magnitude: 0.31263

Collected Steps per Second: 23,524.63377
Overall Steps per Second: 10,948.06475

Timestep Collection Time: 2.12543
Timestep Consumption Time: 2.44159
PPO Batch Consumption Time: 0.28139
Total Iteration Time: 4.56702

Cumulative Model Updates: 328,488
Cumulative Timesteps: 2,739,564,296

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2739564296...
Checkpoint 2739564296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.12084
Policy Entropy: 4.21144
Value Function Loss: 0.00367

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.01886
Policy Update Magnitude: 0.26323
Value Function Update Magnitude: 0.33226

Collected Steps per Second: 22,883.02298
Overall Steps per Second: 10,731.96490

Timestep Collection Time: 2.18564
Timestep Consumption Time: 2.47465
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.66028

Cumulative Model Updates: 328,494
Cumulative Timesteps: 2,739,614,310

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.02300
Policy Entropy: 4.22012
Value Function Loss: 0.00298

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01729
Policy Update Magnitude: 0.23821
Value Function Update Magnitude: 0.31330

Collected Steps per Second: 22,725.43307
Overall Steps per Second: 10,803.51984

Timestep Collection Time: 2.20027
Timestep Consumption Time: 2.42804
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.62831

Cumulative Model Updates: 328,500
Cumulative Timesteps: 2,739,664,312

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2739664312...
Checkpoint 2739664312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.78279
Policy Entropy: 4.21536
Value Function Loss: 0.00307

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.01693
Policy Update Magnitude: 0.23712
Value Function Update Magnitude: 0.28969

Collected Steps per Second: 23,461.32035
Overall Steps per Second: 10,893.00674

Timestep Collection Time: 2.13125
Timestep Consumption Time: 2.45903
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.59028

Cumulative Model Updates: 328,506
Cumulative Timesteps: 2,739,714,314

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.63047
Policy Entropy: 4.21107
Value Function Loss: 0.00375

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.01668
Policy Update Magnitude: 0.24899
Value Function Update Magnitude: 0.31610

Collected Steps per Second: 22,866.93553
Overall Steps per Second: 10,744.13594

Timestep Collection Time: 2.18683
Timestep Consumption Time: 2.46743
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.65426

Cumulative Model Updates: 328,512
Cumulative Timesteps: 2,739,764,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2739764320...
Checkpoint 2739764320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.21519
Policy Entropy: 4.21885
Value Function Loss: 0.00364

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.01866
Policy Update Magnitude: 0.25841
Value Function Update Magnitude: 0.33377

Collected Steps per Second: 22,640.45071
Overall Steps per Second: 11,006.54856

Timestep Collection Time: 2.20985
Timestep Consumption Time: 2.33581
PPO Batch Consumption Time: 0.27696
Total Iteration Time: 4.54566

Cumulative Model Updates: 328,518
Cumulative Timesteps: 2,739,814,352

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.57141
Policy Entropy: 4.21121
Value Function Loss: 0.00420

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.01693
Policy Update Magnitude: 0.27464
Value Function Update Magnitude: 0.34977

Collected Steps per Second: 23,029.74965
Overall Steps per Second: 10,885.88742

Timestep Collection Time: 2.17110
Timestep Consumption Time: 2.42200
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.59310

Cumulative Model Updates: 328,524
Cumulative Timesteps: 2,739,864,352

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2739864352...
Checkpoint 2739864352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.44106
Policy Entropy: 4.22144
Value Function Loss: 0.00373

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.01964
Policy Update Magnitude: 0.26544
Value Function Update Magnitude: 0.36083

Collected Steps per Second: 22,572.00965
Overall Steps per Second: 10,743.88863

Timestep Collection Time: 2.21602
Timestep Consumption Time: 2.43965
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.65567

Cumulative Model Updates: 328,530
Cumulative Timesteps: 2,739,914,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.58743
Policy Entropy: 4.16357
Value Function Loss: 0.00376

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.02124
Policy Update Magnitude: 0.27368
Value Function Update Magnitude: 0.34550

Collected Steps per Second: 23,728.25471
Overall Steps per Second: 10,906.39678

Timestep Collection Time: 2.10846
Timestep Consumption Time: 2.47876
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.58722

Cumulative Model Updates: 328,536
Cumulative Timesteps: 2,739,964,402

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2739964402...
Checkpoint 2739964402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.72612
Policy Entropy: 4.14594
Value Function Loss: 0.00380

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02045
Policy Update Magnitude: 0.28506
Value Function Update Magnitude: 0.34745

Collected Steps per Second: 22,832.78323
Overall Steps per Second: 10,700.25334

Timestep Collection Time: 2.19088
Timestep Consumption Time: 2.48414
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.67503

Cumulative Model Updates: 328,542
Cumulative Timesteps: 2,740,014,426

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.90248
Policy Entropy: 4.14628
Value Function Loss: 0.00361

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.02573
Policy Update Magnitude: 0.28658
Value Function Update Magnitude: 0.35681

Collected Steps per Second: 22,823.64616
Overall Steps per Second: 10,829.22159

Timestep Collection Time: 2.19089
Timestep Consumption Time: 2.42662
PPO Batch Consumption Time: 0.28177
Total Iteration Time: 4.61751

Cumulative Model Updates: 328,548
Cumulative Timesteps: 2,740,064,430

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2740064430...
Checkpoint 2740064430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.03758
Policy Entropy: 4.20015
Value Function Loss: 0.00300

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02279
Policy Update Magnitude: 0.26687
Value Function Update Magnitude: 0.35484

Collected Steps per Second: 23,667.48868
Overall Steps per Second: 11,070.78094

Timestep Collection Time: 2.11303
Timestep Consumption Time: 2.40427
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.51730

Cumulative Model Updates: 328,554
Cumulative Timesteps: 2,740,114,440

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.61553
Policy Entropy: 4.26832
Value Function Loss: 0.00217

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01576
Policy Update Magnitude: 0.23103
Value Function Update Magnitude: 0.30982

Collected Steps per Second: 22,782.14851
Overall Steps per Second: 10,649.58804

Timestep Collection Time: 2.19558
Timestep Consumption Time: 2.50132
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.69690

Cumulative Model Updates: 328,560
Cumulative Timesteps: 2,740,164,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2740164460...
Checkpoint 2740164460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.27574
Policy Entropy: 4.27455
Value Function Loss: 0.00246

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.01631
Policy Update Magnitude: 0.20913
Value Function Update Magnitude: 0.27604

Collected Steps per Second: 22,758.81165
Overall Steps per Second: 10,909.59727

Timestep Collection Time: 2.19801
Timestep Consumption Time: 2.38731
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.58532

Cumulative Model Updates: 328,566
Cumulative Timesteps: 2,740,214,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.83902
Policy Entropy: 4.25085
Value Function Loss: 0.00313

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.01501
Policy Update Magnitude: 0.22807
Value Function Update Magnitude: 0.29096

Collected Steps per Second: 22,963.38699
Overall Steps per Second: 10,873.05005

Timestep Collection Time: 2.17825
Timestep Consumption Time: 2.42212
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.60037

Cumulative Model Updates: 328,572
Cumulative Timesteps: 2,740,264,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2740264504...
Checkpoint 2740264504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.92539
Policy Entropy: 4.20487
Value Function Loss: 0.00373

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.01815
Policy Update Magnitude: 0.25160
Value Function Update Magnitude: 0.32920

Collected Steps per Second: 22,365.89620
Overall Steps per Second: 10,770.17105

Timestep Collection Time: 2.23573
Timestep Consumption Time: 2.40710
PPO Batch Consumption Time: 0.27526
Total Iteration Time: 4.64282

Cumulative Model Updates: 328,578
Cumulative Timesteps: 2,740,314,508

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.83541
Policy Entropy: 4.17880
Value Function Loss: 0.00430

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.02312
Policy Update Magnitude: 0.28045
Value Function Update Magnitude: 0.34410

Collected Steps per Second: 23,123.32643
Overall Steps per Second: 10,923.16800

Timestep Collection Time: 2.16292
Timestep Consumption Time: 2.41578
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.57871

Cumulative Model Updates: 328,584
Cumulative Timesteps: 2,740,364,522

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2740364522...
Checkpoint 2740364522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.84517
Policy Entropy: 4.23119
Value Function Loss: 0.00330

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02054
Policy Update Magnitude: 0.26429
Value Function Update Magnitude: 0.34100

Collected Steps per Second: 22,814.50927
Overall Steps per Second: 10,717.25949

Timestep Collection Time: 2.19229
Timestep Consumption Time: 2.47458
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.66686

Cumulative Model Updates: 328,590
Cumulative Timesteps: 2,740,414,538

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.63940
Policy Entropy: 4.25285
Value Function Loss: 0.00375

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02007
Policy Update Magnitude: 0.24801
Value Function Update Magnitude: 0.32626

Collected Steps per Second: 23,206.27596
Overall Steps per Second: 10,815.29532

Timestep Collection Time: 2.15545
Timestep Consumption Time: 2.46948
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.62493

Cumulative Model Updates: 328,596
Cumulative Timesteps: 2,740,464,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2740464558...
Checkpoint 2740464558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.56337
Policy Entropy: 4.25942
Value Function Loss: 0.00359

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.01563
Policy Update Magnitude: 0.25109
Value Function Update Magnitude: 0.30149

Collected Steps per Second: 23,531.46806
Overall Steps per Second: 11,007.45463

Timestep Collection Time: 2.12490
Timestep Consumption Time: 2.41766
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.54256

Cumulative Model Updates: 328,602
Cumulative Timesteps: 2,740,514,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.24784
Policy Entropy: 4.20298
Value Function Loss: 0.00385

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.01984
Policy Update Magnitude: 0.25753
Value Function Update Magnitude: 0.30622

Collected Steps per Second: 22,617.64070
Overall Steps per Second: 10,657.63849

Timestep Collection Time: 2.21093
Timestep Consumption Time: 2.48110
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.69203

Cumulative Model Updates: 328,608
Cumulative Timesteps: 2,740,564,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2740564566...
Checkpoint 2740564566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.18666
Policy Entropy: 4.18414
Value Function Loss: 0.00359

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02022
Policy Update Magnitude: 0.26778
Value Function Update Magnitude: 0.31906

Collected Steps per Second: 22,688.74515
Overall Steps per Second: 10,879.05923

Timestep Collection Time: 2.20409
Timestep Consumption Time: 2.39263
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.59672

Cumulative Model Updates: 328,614
Cumulative Timesteps: 2,740,614,574

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.64659
Policy Entropy: 4.17532
Value Function Loss: 0.00385

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.02297
Policy Update Magnitude: 0.27522
Value Function Update Magnitude: 0.33451

Collected Steps per Second: 23,589.32760
Overall Steps per Second: 10,995.39065

Timestep Collection Time: 2.12011
Timestep Consumption Time: 2.42834
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.54845

Cumulative Model Updates: 328,620
Cumulative Timesteps: 2,740,664,586

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2740664586...
Checkpoint 2740664586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65.51673
Policy Entropy: 4.14967
Value Function Loss: 0.00470

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.02240
Policy Update Magnitude: 0.29032
Value Function Update Magnitude: 0.34831

Collected Steps per Second: 22,418.40732
Overall Steps per Second: 10,624.49552

Timestep Collection Time: 2.23111
Timestep Consumption Time: 2.47669
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.70780

Cumulative Model Updates: 328,626
Cumulative Timesteps: 2,740,714,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.52824
Policy Entropy: 4.16036
Value Function Loss: 0.00384

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02149
Policy Update Magnitude: 0.28530
Value Function Update Magnitude: 0.35413

Collected Steps per Second: 22,779.39297
Overall Steps per Second: 10,907.03445

Timestep Collection Time: 2.19523
Timestep Consumption Time: 2.38952
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.58475

Cumulative Model Updates: 328,632
Cumulative Timesteps: 2,740,764,610

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2740764610...
Checkpoint 2740764610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.03977
Policy Entropy: 4.15084
Value Function Loss: 0.00398

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02372
Policy Update Magnitude: 0.27288
Value Function Update Magnitude: 0.33215

Collected Steps per Second: 22,770.95926
Overall Steps per Second: 10,682.42711

Timestep Collection Time: 2.19675
Timestep Consumption Time: 2.48590
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.68264

Cumulative Model Updates: 328,638
Cumulative Timesteps: 2,740,814,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.40946
Policy Entropy: 4.21087
Value Function Loss: 0.00279

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.01902
Policy Update Magnitude: 0.25340
Value Function Update Magnitude: 0.31075

Collected Steps per Second: 22,708.11421
Overall Steps per Second: 10,904.63571

Timestep Collection Time: 2.20291
Timestep Consumption Time: 2.38449
PPO Batch Consumption Time: 0.27531
Total Iteration Time: 4.58741

Cumulative Model Updates: 328,644
Cumulative Timesteps: 2,740,864,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2740864656...
Checkpoint 2740864656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.51552
Policy Entropy: 4.20825
Value Function Loss: 0.00329

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.01828
Policy Update Magnitude: 0.25111
Value Function Update Magnitude: 0.30766

Collected Steps per Second: 22,772.23585
Overall Steps per Second: 11,026.15187

Timestep Collection Time: 2.19645
Timestep Consumption Time: 2.33986
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.53631

Cumulative Model Updates: 328,650
Cumulative Timesteps: 2,740,914,674

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.71749
Policy Entropy: 4.20679
Value Function Loss: 0.00354

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.01647
Policy Update Magnitude: 0.25707
Value Function Update Magnitude: 0.32129

Collected Steps per Second: 22,881.69609
Overall Steps per Second: 10,876.70317

Timestep Collection Time: 2.18515
Timestep Consumption Time: 2.41183
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.59698

Cumulative Model Updates: 328,656
Cumulative Timesteps: 2,740,964,674

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2740964674...
Checkpoint 2740964674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.47773
Policy Entropy: 4.16304
Value Function Loss: 0.00423

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.01833
Policy Update Magnitude: 0.27779
Value Function Update Magnitude: 0.33897

Collected Steps per Second: 22,573.83733
Overall Steps per Second: 10,692.69365

Timestep Collection Time: 2.21495
Timestep Consumption Time: 2.46114
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.67609

Cumulative Model Updates: 328,662
Cumulative Timesteps: 2,741,014,674

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.63167
Policy Entropy: 4.17917
Value Function Loss: 0.00387

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02139
Policy Update Magnitude: 0.28087
Value Function Update Magnitude: 0.33429

Collected Steps per Second: 23,488.14992
Overall Steps per Second: 10,947.54816

Timestep Collection Time: 2.12958
Timestep Consumption Time: 2.43948
PPO Batch Consumption Time: 0.28168
Total Iteration Time: 4.56906

Cumulative Model Updates: 328,668
Cumulative Timesteps: 2,741,064,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2741064694...
Checkpoint 2741064694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.75256
Policy Entropy: 4.18433
Value Function Loss: 0.00407

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02069
Policy Update Magnitude: 0.27417
Value Function Update Magnitude: 0.31847

Collected Steps per Second: 22,709.94233
Overall Steps per Second: 10,643.93781

Timestep Collection Time: 2.20238
Timestep Consumption Time: 2.49663
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.69901

Cumulative Model Updates: 328,674
Cumulative Timesteps: 2,741,114,710

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.02487
Policy Entropy: 4.18615
Value Function Loss: 0.00412

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02059
Policy Update Magnitude: 0.27742
Value Function Update Magnitude: 0.31837

Collected Steps per Second: 22,790.24153
Overall Steps per Second: 10,892.09683

Timestep Collection Time: 2.19506
Timestep Consumption Time: 2.39781
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.59287

Cumulative Model Updates: 328,680
Cumulative Timesteps: 2,741,164,736

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2741164736...
Checkpoint 2741164736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.55969
Policy Entropy: 4.15282
Value Function Loss: 0.00500

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.02520
Policy Update Magnitude: 0.27819
Value Function Update Magnitude: 0.33724

Collected Steps per Second: 22,717.83809
Overall Steps per Second: 10,684.81073

Timestep Collection Time: 2.20223
Timestep Consumption Time: 2.48011
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.68235

Cumulative Model Updates: 328,686
Cumulative Timesteps: 2,741,214,766

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.42371
Policy Entropy: 4.18243
Value Function Loss: 0.00384

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.02219
Policy Update Magnitude: 0.27245
Value Function Update Magnitude: 0.33925

Collected Steps per Second: 22,910.11396
Overall Steps per Second: 10,869.19934

Timestep Collection Time: 2.18323
Timestep Consumption Time: 2.41858
PPO Batch Consumption Time: 0.28153
Total Iteration Time: 4.60181

Cumulative Model Updates: 328,692
Cumulative Timesteps: 2,741,264,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2741264784...
Checkpoint 2741264784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.75257
Policy Entropy: 4.20776
Value Function Loss: 0.00298

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02062
Policy Update Magnitude: 0.25471
Value Function Update Magnitude: 0.32927

Collected Steps per Second: 22,746.72451
Overall Steps per Second: 11,058.05059

Timestep Collection Time: 2.19891
Timestep Consumption Time: 2.32431
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.52322

Cumulative Model Updates: 328,698
Cumulative Timesteps: 2,741,314,802

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.75903
Policy Entropy: 4.21882
Value Function Loss: 0.00266

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.01575
Policy Update Magnitude: 0.24536
Value Function Update Magnitude: 0.30052

Collected Steps per Second: 22,967.87996
Overall Steps per Second: 10,859.67403

Timestep Collection Time: 2.17739
Timestep Consumption Time: 2.42772
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.60511

Cumulative Model Updates: 328,704
Cumulative Timesteps: 2,741,364,812

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2741364812...
Checkpoint 2741364812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.11992
Policy Entropy: 4.18837
Value Function Loss: 0.00337

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.01985
Policy Update Magnitude: 0.25256
Value Function Update Magnitude: 0.30659

Collected Steps per Second: 22,550.35358
Overall Steps per Second: 10,834.09119

Timestep Collection Time: 2.21850
Timestep Consumption Time: 2.39914
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.61765

Cumulative Model Updates: 328,710
Cumulative Timesteps: 2,741,414,840

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.62039
Policy Entropy: 4.16853
Value Function Loss: 0.00371

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.01923
Policy Update Magnitude: 0.25893
Value Function Update Magnitude: 0.32943

Collected Steps per Second: 22,771.33661
Overall Steps per Second: 10,817.70393

Timestep Collection Time: 2.19583
Timestep Consumption Time: 2.42641
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.62224

Cumulative Model Updates: 328,716
Cumulative Timesteps: 2,741,464,842

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2741464842...
Checkpoint 2741464842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.84728
Policy Entropy: 4.19219
Value Function Loss: 0.00289

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.01796
Policy Update Magnitude: 0.25095
Value Function Update Magnitude: 0.32231

Collected Steps per Second: 22,691.29934
Overall Steps per Second: 10,678.33676

Timestep Collection Time: 2.20428
Timestep Consumption Time: 2.47978
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.68406

Cumulative Model Updates: 328,722
Cumulative Timesteps: 2,741,514,860

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51903
Policy Entropy: 4.19890
Value Function Loss: 0.00369

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.01867
Policy Update Magnitude: 0.25077
Value Function Update Magnitude: 0.30429

Collected Steps per Second: 22,970.21334
Overall Steps per Second: 10,886.82746

Timestep Collection Time: 2.17778
Timestep Consumption Time: 2.41713
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.59491

Cumulative Model Updates: 328,728
Cumulative Timesteps: 2,741,564,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2741564884...
Checkpoint 2741564884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.18698
Policy Entropy: 4.20667
Value Function Loss: 0.00387

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.01838
Policy Update Magnitude: 0.25775
Value Function Update Magnitude: 0.30730

Collected Steps per Second: 22,778.56801
Overall Steps per Second: 10,702.62880

Timestep Collection Time: 2.19513
Timestep Consumption Time: 2.47680
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.67194

Cumulative Model Updates: 328,734
Cumulative Timesteps: 2,741,614,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.38921
Policy Entropy: 4.21487
Value Function Loss: 0.00358

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.01950
Policy Update Magnitude: 0.25426
Value Function Update Magnitude: 0.33266

Collected Steps per Second: 22,723.61820
Overall Steps per Second: 10,826.36146

Timestep Collection Time: 2.20088
Timestep Consumption Time: 2.41858
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.61947

Cumulative Model Updates: 328,740
Cumulative Timesteps: 2,741,664,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2741664898...
Checkpoint 2741664898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.31367
Policy Entropy: 4.17494
Value Function Loss: 0.00371

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.01861
Policy Update Magnitude: 0.25617
Value Function Update Magnitude: 0.32695

Collected Steps per Second: 22,718.98984
Overall Steps per Second: 11,042.90567

Timestep Collection Time: 2.20142
Timestep Consumption Time: 2.32764
PPO Batch Consumption Time: 0.27677
Total Iteration Time: 4.52906

Cumulative Model Updates: 328,746
Cumulative Timesteps: 2,741,714,912

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.00659
Policy Entropy: 4.18398
Value Function Loss: 0.00359

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02093
Policy Update Magnitude: 0.27822
Value Function Update Magnitude: 0.31338

Collected Steps per Second: 22,923.63733
Overall Steps per Second: 10,870.62028

Timestep Collection Time: 2.18185
Timestep Consumption Time: 2.41917
PPO Batch Consumption Time: 0.27685
Total Iteration Time: 4.60103

Cumulative Model Updates: 328,752
Cumulative Timesteps: 2,741,764,928

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2741764928...
Checkpoint 2741764928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.67506
Policy Entropy: 4.14967
Value Function Loss: 0.00385

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.02969
Policy Update Magnitude: 0.28119
Value Function Update Magnitude: 0.34005

Collected Steps per Second: 22,522.03279
Overall Steps per Second: 10,716.56018

Timestep Collection Time: 2.22129
Timestep Consumption Time: 2.44700
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.66829

Cumulative Model Updates: 328,758
Cumulative Timesteps: 2,741,814,956

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.56272
Policy Entropy: 4.20191
Value Function Loss: 0.00361

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.02144
Policy Update Magnitude: 0.27219
Value Function Update Magnitude: 0.35230

Collected Steps per Second: 23,579.86177
Overall Steps per Second: 10,963.81979

Timestep Collection Time: 2.12147
Timestep Consumption Time: 2.44117
PPO Batch Consumption Time: 0.28174
Total Iteration Time: 4.56264

Cumulative Model Updates: 328,764
Cumulative Timesteps: 2,741,864,980

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2741864980...
Checkpoint 2741864980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.74087
Policy Entropy: 4.22173
Value Function Loss: 0.00293

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02015
Policy Update Magnitude: 0.25626
Value Function Update Magnitude: 0.34893

Collected Steps per Second: 22,756.69985
Overall Steps per Second: 10,677.06510

Timestep Collection Time: 2.19803
Timestep Consumption Time: 2.48677
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.68481

Cumulative Model Updates: 328,770
Cumulative Timesteps: 2,741,915,000

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.69608
Policy Entropy: 4.22790
Value Function Loss: 0.00279

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.01770
Policy Update Magnitude: 0.24142
Value Function Update Magnitude: 0.32759

Collected Steps per Second: 22,944.34155
Overall Steps per Second: 10,878.50981

Timestep Collection Time: 2.17980
Timestep Consumption Time: 2.41771
PPO Batch Consumption Time: 0.28142
Total Iteration Time: 4.59750

Cumulative Model Updates: 328,776
Cumulative Timesteps: 2,741,965,014

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2741965014...
Checkpoint 2741965014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.65828
Policy Entropy: 4.20216
Value Function Loss: 0.00300

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.01542
Policy Update Magnitude: 0.24689
Value Function Update Magnitude: 0.30759

Collected Steps per Second: 23,474.41417
Overall Steps per Second: 11,040.34833

Timestep Collection Time: 2.13075
Timestep Consumption Time: 2.39973
PPO Batch Consumption Time: 0.27711
Total Iteration Time: 4.53047

Cumulative Model Updates: 328,782
Cumulative Timesteps: 2,742,015,032

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.43935
Policy Entropy: 4.18271
Value Function Loss: 0.00348

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.01894
Policy Update Magnitude: 0.25852
Value Function Update Magnitude: 0.29521

Collected Steps per Second: 22,819.55522
Overall Steps per Second: 10,864.19253

Timestep Collection Time: 2.19154
Timestep Consumption Time: 2.41165
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.60320

Cumulative Model Updates: 328,788
Cumulative Timesteps: 2,742,065,042

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2742065042...
Checkpoint 2742065042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.23426
Policy Entropy: 4.19934
Value Function Loss: 0.00373

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.01982
Policy Update Magnitude: 0.26184
Value Function Update Magnitude: 0.29687

Collected Steps per Second: 22,529.62406
Overall Steps per Second: 10,857.76613

Timestep Collection Time: 2.22037
Timestep Consumption Time: 2.38684
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.60721

Cumulative Model Updates: 328,794
Cumulative Timesteps: 2,742,115,066

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.99535
Policy Entropy: 4.23556
Value Function Loss: 0.00326

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.01635
Policy Update Magnitude: 0.25467
Value Function Update Magnitude: 0.30128

Collected Steps per Second: 23,037.58274
Overall Steps per Second: 10,768.86414

Timestep Collection Time: 2.17158
Timestep Consumption Time: 2.47403
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.64562

Cumulative Model Updates: 328,800
Cumulative Timesteps: 2,742,165,094

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2742165094...
Checkpoint 2742165094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.24427
Policy Entropy: 4.23200
Value Function Loss: 0.00358

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.01638
Policy Update Magnitude: 0.24902
Value Function Update Magnitude: 0.29145

Collected Steps per Second: 22,367.55079
Overall Steps per Second: 10,639.98122

Timestep Collection Time: 2.23663
Timestep Consumption Time: 2.46526
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.70189

Cumulative Model Updates: 328,806
Cumulative Timesteps: 2,742,215,122

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.43827
Policy Entropy: 4.22702
Value Function Loss: 0.00376

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.01670
Policy Update Magnitude: 0.24792
Value Function Update Magnitude: 0.30532

Collected Steps per Second: 23,505.44182
Overall Steps per Second: 10,933.10346

Timestep Collection Time: 2.12776
Timestep Consumption Time: 2.44678
PPO Batch Consumption Time: 0.28502
Total Iteration Time: 4.57455

Cumulative Model Updates: 328,812
Cumulative Timesteps: 2,742,265,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2742265136...
Checkpoint 2742265136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.26772
Policy Entropy: 4.19601
Value Function Loss: 0.00414

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.01917
Policy Update Magnitude: 0.25548
Value Function Update Magnitude: 0.31652

Collected Steps per Second: 22,865.43330
Overall Steps per Second: 10,724.04283

Timestep Collection Time: 2.18854
Timestep Consumption Time: 2.47779
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.66634

Cumulative Model Updates: 328,818
Cumulative Timesteps: 2,742,315,178

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.33039
Policy Entropy: 4.15092
Value Function Loss: 0.00427

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.01889
Policy Update Magnitude: 0.26615
Value Function Update Magnitude: 0.31726

Collected Steps per Second: 22,846.68008
Overall Steps per Second: 10,789.60791

Timestep Collection Time: 2.18920
Timestep Consumption Time: 2.44637
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.63557

Cumulative Model Updates: 328,824
Cumulative Timesteps: 2,742,365,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2742365194...
Checkpoint 2742365194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.61250
Policy Entropy: 4.12512
Value Function Loss: 0.00437

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02326
Policy Update Magnitude: 0.28445
Value Function Update Magnitude: 0.30852

Collected Steps per Second: 23,253.58863
Overall Steps per Second: 10,846.79007

Timestep Collection Time: 2.15072
Timestep Consumption Time: 2.46004
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.61077

Cumulative Model Updates: 328,830
Cumulative Timesteps: 2,742,415,206

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.39828
Policy Entropy: 4.10580
Value Function Loss: 0.00397

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.02788
Policy Update Magnitude: 0.28869
Value Function Update Magnitude: 0.32625

Collected Steps per Second: 22,859.15615
Overall Steps per Second: 10,753.35498

Timestep Collection Time: 2.18774
Timestep Consumption Time: 2.46290
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.65064

Cumulative Model Updates: 328,836
Cumulative Timesteps: 2,742,465,216

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2742465216...
Checkpoint 2742465216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.51990
Policy Entropy: 4.17290
Value Function Loss: 0.00333

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02285
Policy Update Magnitude: 0.27132
Value Function Update Magnitude: 0.32036

Collected Steps per Second: 22,391.01624
Overall Steps per Second: 10,855.17203

Timestep Collection Time: 2.23411
Timestep Consumption Time: 2.37420
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.60831

Cumulative Model Updates: 328,842
Cumulative Timesteps: 2,742,515,240

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.29505
Policy Entropy: 4.19046
Value Function Loss: 0.00291

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02294
Policy Update Magnitude: 0.25628
Value Function Update Magnitude: 0.30382

Collected Steps per Second: 22,791.24269
Overall Steps per Second: 10,647.30405

Timestep Collection Time: 2.19418
Timestep Consumption Time: 2.50260
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.69678

Cumulative Model Updates: 328,848
Cumulative Timesteps: 2,742,565,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2742565248...
Checkpoint 2742565248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.96686
Policy Entropy: 4.21416
Value Function Loss: 0.00321

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.01875
Policy Update Magnitude: 0.25259
Value Function Update Magnitude: 0.30256

Collected Steps per Second: 22,807.64551
Overall Steps per Second: 10,776.48464

Timestep Collection Time: 2.19339
Timestep Consumption Time: 2.44876
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.64214

Cumulative Model Updates: 328,854
Cumulative Timesteps: 2,742,615,274

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.67080
Policy Entropy: 4.18749
Value Function Loss: 0.00305

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.01846
Policy Update Magnitude: 0.24599
Value Function Update Magnitude: 0.31762

Collected Steps per Second: 23,730.13859
Overall Steps per Second: 10,925.32976

Timestep Collection Time: 2.10703
Timestep Consumption Time: 2.46950
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.57652

Cumulative Model Updates: 328,860
Cumulative Timesteps: 2,742,665,274

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2742665274...
Checkpoint 2742665274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.07625
Policy Entropy: 4.16126
Value Function Loss: 0.00365

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02028
Policy Update Magnitude: 0.25690
Value Function Update Magnitude: 0.31956

Collected Steps per Second: 22,678.29175
Overall Steps per Second: 10,729.32029

Timestep Collection Time: 2.20563
Timestep Consumption Time: 2.45636
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.66199

Cumulative Model Updates: 328,866
Cumulative Timesteps: 2,742,715,294

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.97029
Policy Entropy: 4.13227
Value Function Loss: 0.00401

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.02552
Policy Update Magnitude: 0.27642
Value Function Update Magnitude: 0.33926

Collected Steps per Second: 22,700.25956
Overall Steps per Second: 10,715.52428

Timestep Collection Time: 2.20288
Timestep Consumption Time: 2.46380
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.66669

Cumulative Model Updates: 328,872
Cumulative Timesteps: 2,742,765,300

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2742765300...
Checkpoint 2742765300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.68540
Policy Entropy: 4.13053
Value Function Loss: 0.00416

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.02672
Policy Update Magnitude: 0.28586
Value Function Update Magnitude: 0.35755

Collected Steps per Second: 23,623.18945
Overall Steps per Second: 11,045.73659

Timestep Collection Time: 2.11775
Timestep Consumption Time: 2.41142
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.52917

Cumulative Model Updates: 328,878
Cumulative Timesteps: 2,742,815,328

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.68899
Policy Entropy: 4.15952
Value Function Loss: 0.00378

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.02586
Policy Update Magnitude: 0.27520
Value Function Update Magnitude: 0.35724

Collected Steps per Second: 22,923.28561
Overall Steps per Second: 10,880.43787

Timestep Collection Time: 2.18285
Timestep Consumption Time: 2.41605
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.59890

Cumulative Model Updates: 328,884
Cumulative Timesteps: 2,742,865,366

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2742865366...
Checkpoint 2742865366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.33566
Policy Entropy: 4.16713
Value Function Loss: 0.00442

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02125
Policy Update Magnitude: 0.28828
Value Function Update Magnitude: 0.35712

Collected Steps per Second: 22,591.33583
Overall Steps per Second: 10,848.23443

Timestep Collection Time: 2.21333
Timestep Consumption Time: 2.39590
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.60923

Cumulative Model Updates: 328,890
Cumulative Timesteps: 2,742,915,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.32138
Policy Entropy: 4.18785
Value Function Loss: 0.00425

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.02143
Policy Update Magnitude: 0.28565
Value Function Update Magnitude: 0.36492

Collected Steps per Second: 23,015.59904
Overall Steps per Second: 10,787.71278

Timestep Collection Time: 2.17435
Timestep Consumption Time: 2.46463
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.63898

Cumulative Model Updates: 328,896
Cumulative Timesteps: 2,742,965,412

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2742965412...
Checkpoint 2742965412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.50470
Policy Entropy: 4.17536
Value Function Loss: 0.00437

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.02433
Policy Update Magnitude: 0.27366
Value Function Update Magnitude: 0.37924

Collected Steps per Second: 22,595.71660
Overall Steps per Second: 10,696.97233

Timestep Collection Time: 2.21369
Timestep Consumption Time: 2.46240
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.67609

Cumulative Model Updates: 328,902
Cumulative Timesteps: 2,743,015,432

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.35099
Policy Entropy: 4.19427
Value Function Loss: 0.00369

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.01965
Policy Update Magnitude: 0.26681
Value Function Update Magnitude: 0.36136

Collected Steps per Second: 22,833.01074
Overall Steps per Second: 10,859.27085

Timestep Collection Time: 2.19051
Timestep Consumption Time: 2.41532
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.60583

Cumulative Model Updates: 328,908
Cumulative Timesteps: 2,743,065,448

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2743065448...
Checkpoint 2743065448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.16733
Policy Entropy: 4.16260
Value Function Loss: 0.00347

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02158
Policy Update Magnitude: 0.25912
Value Function Update Magnitude: 0.36344

Collected Steps per Second: 22,723.18468
Overall Steps per Second: 10,686.16040

Timestep Collection Time: 2.20154
Timestep Consumption Time: 2.47984
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.68138

Cumulative Model Updates: 328,914
Cumulative Timesteps: 2,743,115,474

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.55662
Policy Entropy: 4.16892
Value Function Loss: 0.00377

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02147
Policy Update Magnitude: 0.25841
Value Function Update Magnitude: 0.36010

Collected Steps per Second: 22,828.94359
Overall Steps per Second: 10,848.05015

Timestep Collection Time: 2.19029
Timestep Consumption Time: 2.41902
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.60931

Cumulative Model Updates: 328,920
Cumulative Timesteps: 2,743,165,476

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2743165476...
Checkpoint 2743165476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.86343
Policy Entropy: 4.15173
Value Function Loss: 0.00384

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02345
Policy Update Magnitude: 0.26835
Value Function Update Magnitude: 0.35240

Collected Steps per Second: 23,526.73334
Overall Steps per Second: 11,019.91402

Timestep Collection Time: 2.12592
Timestep Consumption Time: 2.41277
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.53869

Cumulative Model Updates: 328,926
Cumulative Timesteps: 2,743,215,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.73837
Policy Entropy: 4.19091
Value Function Loss: 0.00348

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02153
Policy Update Magnitude: 0.26754
Value Function Update Magnitude: 0.34417

Collected Steps per Second: 22,922.02529
Overall Steps per Second: 10,738.81442

Timestep Collection Time: 2.18227
Timestep Consumption Time: 2.47579
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.65806

Cumulative Model Updates: 328,932
Cumulative Timesteps: 2,743,265,514

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2743265514...
Checkpoint 2743265514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.38384
Policy Entropy: 4.20548
Value Function Loss: 0.00329

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02240
Policy Update Magnitude: 0.25616
Value Function Update Magnitude: 0.33415

Collected Steps per Second: 22,962.21690
Overall Steps per Second: 10,938.49859

Timestep Collection Time: 2.17784
Timestep Consumption Time: 2.39390
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.57174

Cumulative Model Updates: 328,938
Cumulative Timesteps: 2,743,315,522

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.33810
Policy Entropy: 4.23433
Value Function Loss: 0.00297

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.01752
Policy Update Magnitude: 0.24229
Value Function Update Magnitude: 0.30498

Collected Steps per Second: 22,968.33703
Overall Steps per Second: 10,850.79769

Timestep Collection Time: 2.17761
Timestep Consumption Time: 2.43182
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.60943

Cumulative Model Updates: 328,944
Cumulative Timesteps: 2,743,365,538

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2743365538...
Checkpoint 2743365538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.96782
Policy Entropy: 4.24199
Value Function Loss: 0.00292

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.01747
Policy Update Magnitude: 0.23460
Value Function Update Magnitude: 0.28303

Collected Steps per Second: 22,706.82910
Overall Steps per Second: 10,724.23910

Timestep Collection Time: 2.20251
Timestep Consumption Time: 2.46095
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.66345

Cumulative Model Updates: 328,950
Cumulative Timesteps: 2,743,415,550

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.96306
Policy Entropy: 4.25122
Value Function Loss: 0.00305

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.01672
Policy Update Magnitude: 0.22658
Value Function Update Magnitude: 0.28023

Collected Steps per Second: 22,937.42838
Overall Steps per Second: 10,861.23541

Timestep Collection Time: 2.18010
Timestep Consumption Time: 2.42398
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.60408

Cumulative Model Updates: 328,956
Cumulative Timesteps: 2,743,465,556

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2743465556...
Checkpoint 2743465556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.51703
Policy Entropy: 4.23907
Value Function Loss: 0.00289

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.01608
Policy Update Magnitude: 0.23616
Value Function Update Magnitude: 0.28925

Collected Steps per Second: 22,579.86389
Overall Steps per Second: 10,620.02242

Timestep Collection Time: 2.21516
Timestep Consumption Time: 2.49462
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.70978

Cumulative Model Updates: 328,962
Cumulative Timesteps: 2,743,515,574

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.63564
Policy Entropy: 4.22537
Value Function Loss: 0.00284

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.01740
Policy Update Magnitude: 0.24446
Value Function Update Magnitude: 0.30392

Collected Steps per Second: 22,788.33266
Overall Steps per Second: 10,864.31324

Timestep Collection Time: 2.19419
Timestep Consumption Time: 2.40821
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.60241

Cumulative Model Updates: 328,968
Cumulative Timesteps: 2,743,565,576

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2743565576...
Checkpoint 2743565576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.34216
Policy Entropy: 4.19024
Value Function Loss: 0.00326

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02010
Policy Update Magnitude: 0.24620
Value Function Update Magnitude: 0.31023

Collected Steps per Second: 23,278.46387
Overall Steps per Second: 10,801.16843

Timestep Collection Time: 2.14868
Timestep Consumption Time: 2.48211
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.63080

Cumulative Model Updates: 328,974
Cumulative Timesteps: 2,743,615,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.19235
Policy Entropy: 4.17858
Value Function Loss: 0.00422

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02231
Policy Update Magnitude: 0.26916
Value Function Update Magnitude: 0.30863

Collected Steps per Second: 22,795.26998
Overall Steps per Second: 10,841.26960

Timestep Collection Time: 2.19414
Timestep Consumption Time: 2.41934
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.61348

Cumulative Model Updates: 328,980
Cumulative Timesteps: 2,743,665,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2743665610...
Checkpoint 2743665610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.80758
Policy Entropy: 4.16493
Value Function Loss: 0.00533

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.02332
Policy Update Magnitude: 0.28336
Value Function Update Magnitude: 0.34768

Collected Steps per Second: 22,891.69448
Overall Steps per Second: 11,059.00865

Timestep Collection Time: 2.18472
Timestep Consumption Time: 2.33756
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.52229

Cumulative Model Updates: 328,986
Cumulative Timesteps: 2,743,715,622

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.36655
Policy Entropy: 4.17441
Value Function Loss: 0.00529

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.01999
Policy Update Magnitude: 0.28811
Value Function Update Magnitude: 0.38047

Collected Steps per Second: 22,929.66980
Overall Steps per Second: 10,851.96592

Timestep Collection Time: 2.18058
Timestep Consumption Time: 2.42688
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.60746

Cumulative Model Updates: 328,992
Cumulative Timesteps: 2,743,765,622

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2743765622...
Checkpoint 2743765622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.17660
Policy Entropy: 4.17977
Value Function Loss: 0.00452

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02058
Policy Update Magnitude: 0.27406
Value Function Update Magnitude: 0.37675

Collected Steps per Second: 22,461.94824
Overall Steps per Second: 10,762.19053

Timestep Collection Time: 2.22714
Timestep Consumption Time: 2.42117
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.64831

Cumulative Model Updates: 328,998
Cumulative Timesteps: 2,743,815,648

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.28052
Policy Entropy: 4.17158
Value Function Loss: 0.00434

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.02379
Policy Update Magnitude: 0.27948
Value Function Update Magnitude: 0.36333

Collected Steps per Second: 22,666.52233
Overall Steps per Second: 10,880.28727

Timestep Collection Time: 2.20590
Timestep Consumption Time: 2.38957
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.59547

Cumulative Model Updates: 329,004
Cumulative Timesteps: 2,743,865,648

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2743865648...
Checkpoint 2743865648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.28113
Policy Entropy: 4.19095
Value Function Loss: 0.00390

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.02503
Policy Update Magnitude: 0.27527
Value Function Update Magnitude: 0.35987

Collected Steps per Second: 22,772.09077
Overall Steps per Second: 10,683.79194

Timestep Collection Time: 2.19681
Timestep Consumption Time: 2.48561
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.68242

Cumulative Model Updates: 329,010
Cumulative Timesteps: 2,743,915,674

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.66726
Policy Entropy: 4.18289
Value Function Loss: 0.00393

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02227
Policy Update Magnitude: 0.26790
Value Function Update Magnitude: 0.35122

Collected Steps per Second: 22,903.99275
Overall Steps per Second: 10,859.42893

Timestep Collection Time: 2.18390
Timestep Consumption Time: 2.42224
PPO Batch Consumption Time: 0.28191
Total Iteration Time: 4.60614

Cumulative Model Updates: 329,016
Cumulative Timesteps: 2,743,965,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2743965694...
Checkpoint 2743965694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.98881
Policy Entropy: 4.20605
Value Function Loss: 0.00370

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.01974
Policy Update Magnitude: 0.25343
Value Function Update Magnitude: 0.33329

Collected Steps per Second: 22,761.26745
Overall Steps per Second: 11,028.09533

Timestep Collection Time: 2.19707
Timestep Consumption Time: 2.33753
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.53460

Cumulative Model Updates: 329,022
Cumulative Timesteps: 2,744,015,702

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.93070
Policy Entropy: 4.20430
Value Function Loss: 0.00384

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.01889
Policy Update Magnitude: 0.25393
Value Function Update Magnitude: 0.33390

Collected Steps per Second: 22,904.96085
Overall Steps per Second: 10,727.26859

Timestep Collection Time: 2.18433
Timestep Consumption Time: 2.47967
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.66400

Cumulative Model Updates: 329,028
Cumulative Timesteps: 2,744,065,734

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2744065734...
Checkpoint 2744065734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.56038
Policy Entropy: 4.22591
Value Function Loss: 0.00356

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.01581
Policy Update Magnitude: 0.23844
Value Function Update Magnitude: 0.33035

Collected Steps per Second: 22,683.99113
Overall Steps per Second: 10,938.66288

Timestep Collection Time: 2.20517
Timestep Consumption Time: 2.36779
PPO Batch Consumption Time: 0.27543
Total Iteration Time: 4.57295

Cumulative Model Updates: 329,034
Cumulative Timesteps: 2,744,115,756

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.76373
Policy Entropy: 4.22523
Value Function Loss: 0.00372

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01487
Policy Update Magnitude: 0.24447
Value Function Update Magnitude: 0.32317

Collected Steps per Second: 23,650.20065
Overall Steps per Second: 10,868.19830

Timestep Collection Time: 2.11432
Timestep Consumption Time: 2.48663
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.60095

Cumulative Model Updates: 329,040
Cumulative Timesteps: 2,744,165,760

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2744165760...
Checkpoint 2744165760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.57039
Policy Entropy: 4.18135
Value Function Loss: 0.00452

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01776
Policy Update Magnitude: 0.27677
Value Function Update Magnitude: 0.34198

Collected Steps per Second: 22,807.16078
Overall Steps per Second: 10,693.34193

Timestep Collection Time: 2.19361
Timestep Consumption Time: 2.48500
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.67861

Cumulative Model Updates: 329,046
Cumulative Timesteps: 2,744,215,790

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.57127
Policy Entropy: 4.15787
Value Function Loss: 0.00400

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.02174
Policy Update Magnitude: 0.28099
Value Function Update Magnitude: 0.36779

Collected Steps per Second: 22,890.36396
Overall Steps per Second: 10,850.42064

Timestep Collection Time: 2.18546
Timestep Consumption Time: 2.42505
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.61051

Cumulative Model Updates: 329,052
Cumulative Timesteps: 2,744,265,816

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2744265816...
Checkpoint 2744265816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.37696
Policy Entropy: 4.14198
Value Function Loss: 0.00391

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.02367
Policy Update Magnitude: 0.28167
Value Function Update Magnitude: 0.37808

Collected Steps per Second: 22,926.80617
Overall Steps per Second: 10,703.03149

Timestep Collection Time: 2.18146
Timestep Consumption Time: 2.49142
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.67288

Cumulative Model Updates: 329,058
Cumulative Timesteps: 2,744,315,830

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.34508
Policy Entropy: 4.13813
Value Function Loss: 0.00491

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02348
Policy Update Magnitude: 0.28221
Value Function Update Magnitude: 0.37091

Collected Steps per Second: 23,108.98964
Overall Steps per Second: 10,874.39925

Timestep Collection Time: 2.16487
Timestep Consumption Time: 2.43566
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.60053

Cumulative Model Updates: 329,064
Cumulative Timesteps: 2,744,365,858

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2744365858...
Checkpoint 2744365858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.87363
Policy Entropy: 4.15387
Value Function Loss: 0.00483

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.02436
Policy Update Magnitude: 0.28492
Value Function Update Magnitude: 0.36048

Collected Steps per Second: 22,320.19338
Overall Steps per Second: 10,823.22160

Timestep Collection Time: 2.24084
Timestep Consumption Time: 2.38033
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.62117

Cumulative Model Updates: 329,070
Cumulative Timesteps: 2,744,415,874

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.74462
Policy Entropy: 4.16734
Value Function Loss: 0.00449

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.02557
Policy Update Magnitude: 0.26724
Value Function Update Magnitude: 0.34838

Collected Steps per Second: 23,082.82163
Overall Steps per Second: 10,703.43304

Timestep Collection Time: 2.16611
Timestep Consumption Time: 2.50529
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.67140

Cumulative Model Updates: 329,076
Cumulative Timesteps: 2,744,465,874

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2744465874...
Checkpoint 2744465874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.17141
Policy Entropy: 4.19349
Value Function Loss: 0.00354

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02053
Policy Update Magnitude: 0.25142
Value Function Update Magnitude: 0.33081

Collected Steps per Second: 22,606.44081
Overall Steps per Second: 10,757.65328

Timestep Collection Time: 2.21220
Timestep Consumption Time: 2.43658
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.64878

Cumulative Model Updates: 329,082
Cumulative Timesteps: 2,744,515,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.66514
Policy Entropy: 4.18589
Value Function Loss: 0.00351

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.01883
Policy Update Magnitude: 0.25706
Value Function Update Magnitude: 0.32335

Collected Steps per Second: 22,985.86803
Overall Steps per Second: 10,929.54320

Timestep Collection Time: 2.17534
Timestep Consumption Time: 2.39960
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.57494

Cumulative Model Updates: 329,088
Cumulative Timesteps: 2,744,565,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2744565886...
Checkpoint 2744565886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.39807
Policy Entropy: 4.18870
Value Function Loss: 0.00339

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.01819
Policy Update Magnitude: 0.26045
Value Function Update Magnitude: 0.32087

Collected Steps per Second: 22,871.20338
Overall Steps per Second: 10,886.48697

Timestep Collection Time: 2.18712
Timestep Consumption Time: 2.40775
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.59487

Cumulative Model Updates: 329,094
Cumulative Timesteps: 2,744,615,908

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.27556
Policy Entropy: 4.19507
Value Function Loss: 0.00324

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.01901
Policy Update Magnitude: 0.25032
Value Function Update Magnitude: 0.31443

Collected Steps per Second: 22,543.67516
Overall Steps per Second: 10,683.04480

Timestep Collection Time: 2.21854
Timestep Consumption Time: 2.46309
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.68162

Cumulative Model Updates: 329,100
Cumulative Timesteps: 2,744,665,922

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2744665922...
Checkpoint 2744665922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.63491
Policy Entropy: 4.19297
Value Function Loss: 0.00438

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.01756
Policy Update Magnitude: 0.25262
Value Function Update Magnitude: 0.32233

Collected Steps per Second: 23,096.66567
Overall Steps per Second: 10,925.07705

Timestep Collection Time: 2.16646
Timestep Consumption Time: 2.41365
PPO Batch Consumption Time: 0.27709
Total Iteration Time: 4.58011

Cumulative Model Updates: 329,106
Cumulative Timesteps: 2,744,715,960

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.82887
Policy Entropy: 4.20207
Value Function Loss: 0.00386

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02182
Policy Update Magnitude: 0.25612
Value Function Update Magnitude: 0.34275

Collected Steps per Second: 22,843.51561
Overall Steps per Second: 10,857.38419

Timestep Collection Time: 2.18889
Timestep Consumption Time: 2.41645
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.60534

Cumulative Model Updates: 329,112
Cumulative Timesteps: 2,744,765,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2744765962...
Checkpoint 2744765962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.30486
Policy Entropy: 4.22122
Value Function Loss: 0.00357

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.01846
Policy Update Magnitude: 0.24913
Value Function Update Magnitude: 0.33785

Collected Steps per Second: 22,663.98869
Overall Steps per Second: 10,834.36108

Timestep Collection Time: 2.20614
Timestep Consumption Time: 2.40880
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.61495

Cumulative Model Updates: 329,118
Cumulative Timesteps: 2,744,815,962

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.61634
Policy Entropy: 4.19280
Value Function Loss: 0.00342

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.01655
Policy Update Magnitude: 0.25981
Value Function Update Magnitude: 0.32818

Collected Steps per Second: 23,030.72984
Overall Steps per Second: 10,831.15503

Timestep Collection Time: 2.17145
Timestep Consumption Time: 2.44579
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.61724

Cumulative Model Updates: 329,124
Cumulative Timesteps: 2,744,865,972

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2744865972...
Checkpoint 2744865972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.43328
Policy Entropy: 4.12960
Value Function Loss: 0.00424

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.02241
Policy Update Magnitude: 0.27975
Value Function Update Magnitude: 0.34318

Collected Steps per Second: 22,697.38154
Overall Steps per Second: 10,792.88855

Timestep Collection Time: 2.20413
Timestep Consumption Time: 2.43114
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.63527

Cumulative Model Updates: 329,130
Cumulative Timesteps: 2,744,916,000

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.47809
Policy Entropy: 4.09675
Value Function Loss: 0.00466

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.02838
Policy Update Magnitude: 0.30585
Value Function Update Magnitude: 0.36388

Collected Steps per Second: 23,110.49156
Overall Steps per Second: 11,045.85869

Timestep Collection Time: 2.16387
Timestep Consumption Time: 2.36344
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.52731

Cumulative Model Updates: 329,136
Cumulative Timesteps: 2,744,966,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2744966008...
Checkpoint 2744966008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.47413
Policy Entropy: 4.14234
Value Function Loss: 0.00410

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.02848
Policy Update Magnitude: 0.29554
Value Function Update Magnitude: 0.36073

Collected Steps per Second: 22,532.39268
Overall Steps per Second: 10,790.82503

Timestep Collection Time: 2.22027
Timestep Consumption Time: 2.41589
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.63616

Cumulative Model Updates: 329,142
Cumulative Timesteps: 2,745,016,036

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.85224
Policy Entropy: 4.18557
Value Function Loss: 0.00365

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02335
Policy Update Magnitude: 0.27671
Value Function Update Magnitude: 0.33303

Collected Steps per Second: 22,737.35743
Overall Steps per Second: 10,859.72796

Timestep Collection Time: 2.19955
Timestep Consumption Time: 2.40572
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.60527

Cumulative Model Updates: 329,148
Cumulative Timesteps: 2,745,066,048

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2745066048...
Checkpoint 2745066048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.29662
Policy Entropy: 4.18407
Value Function Loss: 0.00334

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02188
Policy Update Magnitude: 0.26211
Value Function Update Magnitude: 0.31415

Collected Steps per Second: 23,166.81445
Overall Steps per Second: 10,803.59722

Timestep Collection Time: 2.15964
Timestep Consumption Time: 2.47141
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.63105

Cumulative Model Updates: 329,154
Cumulative Timesteps: 2,745,116,080

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.95007
Policy Entropy: 4.15705
Value Function Loss: 0.00387

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02024
Policy Update Magnitude: 0.26208
Value Function Update Magnitude: 0.30862

Collected Steps per Second: 22,887.96710
Overall Steps per Second: 10,778.15444

Timestep Collection Time: 2.18552
Timestep Consumption Time: 2.45554
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.64105

Cumulative Model Updates: 329,160
Cumulative Timesteps: 2,745,166,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2745166102...
Checkpoint 2745166102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.60656
Policy Entropy: 4.13779
Value Function Loss: 0.00430

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02499
Policy Update Magnitude: 0.27234
Value Function Update Magnitude: 0.33394

Collected Steps per Second: 22,715.80434
Overall Steps per Second: 10,736.55701

Timestep Collection Time: 2.20111
Timestep Consumption Time: 2.45588
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.65699

Cumulative Model Updates: 329,166
Cumulative Timesteps: 2,745,216,102

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.59072
Policy Entropy: 4.16544
Value Function Loss: 0.00439

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.02326
Policy Update Magnitude: 0.27895
Value Function Update Magnitude: 0.35022

Collected Steps per Second: 23,584.52002
Overall Steps per Second: 10,834.94497

Timestep Collection Time: 2.12215
Timestep Consumption Time: 2.49716
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.61931

Cumulative Model Updates: 329,172
Cumulative Timesteps: 2,745,266,152

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2745266152...
Checkpoint 2745266152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.81333
Policy Entropy: 4.17813
Value Function Loss: 0.00450

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.02268
Policy Update Magnitude: 0.27218
Value Function Update Magnitude: 0.34611

Collected Steps per Second: 22,795.66565
Overall Steps per Second: 10,687.53710

Timestep Collection Time: 2.19357
Timestep Consumption Time: 2.48515
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.67872

Cumulative Model Updates: 329,178
Cumulative Timesteps: 2,745,316,156

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.61969
Policy Entropy: 4.14789
Value Function Loss: 0.00446

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02002
Policy Update Magnitude: 0.27914
Value Function Update Magnitude: 0.35151

Collected Steps per Second: 22,589.44685
Overall Steps per Second: 10,852.25988

Timestep Collection Time: 2.21475
Timestep Consumption Time: 2.39535
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.61010

Cumulative Model Updates: 329,184
Cumulative Timesteps: 2,745,366,186

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2745366186...
Checkpoint 2745366186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.28913
Policy Entropy: 4.12732
Value Function Loss: 0.00446

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02235
Policy Update Magnitude: 0.29123
Value Function Update Magnitude: 0.36279

Collected Steps per Second: 22,827.43863
Overall Steps per Second: 10,694.37511

Timestep Collection Time: 2.19043
Timestep Consumption Time: 2.48511
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.67554

Cumulative Model Updates: 329,190
Cumulative Timesteps: 2,745,416,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.79168
Policy Entropy: 4.09628
Value Function Loss: 0.00511

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02530
Policy Update Magnitude: 0.30435
Value Function Update Magnitude: 0.37991

Collected Steps per Second: 22,724.49378
Overall Steps per Second: 10,869.22670

Timestep Collection Time: 2.20080
Timestep Consumption Time: 2.40045
PPO Batch Consumption Time: 0.27694
Total Iteration Time: 4.60125

Cumulative Model Updates: 329,196
Cumulative Timesteps: 2,745,466,200

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2745466200...
Checkpoint 2745466200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.26694
Policy Entropy: 4.14697
Value Function Loss: 0.00481

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02204
Policy Update Magnitude: 0.30446
Value Function Update Magnitude: 0.39652

Collected Steps per Second: 22,853.22751
Overall Steps per Second: 11,052.14718

Timestep Collection Time: 2.18919
Timestep Consumption Time: 2.33753
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.52672

Cumulative Model Updates: 329,202
Cumulative Timesteps: 2,745,516,230

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.53421
Policy Entropy: 4.13658
Value Function Loss: 0.00467

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02519
Policy Update Magnitude: 0.29803
Value Function Update Magnitude: 0.38295

Collected Steps per Second: 22,941.70325
Overall Steps per Second: 10,860.49911

Timestep Collection Time: 2.17996
Timestep Consumption Time: 2.42498
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.60494

Cumulative Model Updates: 329,208
Cumulative Timesteps: 2,745,566,242

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2745566242...
Checkpoint 2745566242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.58891
Policy Entropy: 4.15749
Value Function Loss: 0.00397

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02218
Policy Update Magnitude: 0.29179
Value Function Update Magnitude: 0.36556

Collected Steps per Second: 22,673.36839
Overall Steps per Second: 10,747.62067

Timestep Collection Time: 2.20576
Timestep Consumption Time: 2.44755
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.65331

Cumulative Model Updates: 329,214
Cumulative Timesteps: 2,745,616,254

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.76951
Policy Entropy: 4.14396
Value Function Loss: 0.00410

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.02576
Policy Update Magnitude: 0.29066
Value Function Update Magnitude: 0.36862

Collected Steps per Second: 23,656.82959
Overall Steps per Second: 10,879.70967

Timestep Collection Time: 2.11364
Timestep Consumption Time: 2.48226
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.59589

Cumulative Model Updates: 329,220
Cumulative Timesteps: 2,745,666,256

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2745666256...
Checkpoint 2745666256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.71743
Policy Entropy: 4.16575
Value Function Loss: 0.00392

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02273
Policy Update Magnitude: 0.27813
Value Function Update Magnitude: 0.37178

Collected Steps per Second: 22,629.33779
Overall Steps per Second: 10,658.60660

Timestep Collection Time: 2.21058
Timestep Consumption Time: 2.48271
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.69330

Cumulative Model Updates: 329,226
Cumulative Timesteps: 2,745,716,280

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.01418
Policy Entropy: 4.14968
Value Function Loss: 0.00471

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02044
Policy Update Magnitude: 0.28728
Value Function Update Magnitude: 0.36308

Collected Steps per Second: 22,603.31237
Overall Steps per Second: 10,841.08482

Timestep Collection Time: 2.21242
Timestep Consumption Time: 2.40040
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.61282

Cumulative Model Updates: 329,232
Cumulative Timesteps: 2,745,766,288

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2745766288...
Checkpoint 2745766288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.42853
Policy Entropy: 4.17164
Value Function Loss: 0.00437

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.02265
Policy Update Magnitude: 0.28226
Value Function Update Magnitude: 0.35822

Collected Steps per Second: 23,436.05517
Overall Steps per Second: 10,879.51308

Timestep Collection Time: 2.13423
Timestep Consumption Time: 2.46322
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.59745

Cumulative Model Updates: 329,238
Cumulative Timesteps: 2,745,816,306

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.35670
Policy Entropy: 4.13642
Value Function Loss: 0.00500

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.02456
Policy Update Magnitude: 0.27874
Value Function Update Magnitude: 0.37047

Collected Steps per Second: 23,001.84783
Overall Steps per Second: 10,717.60975

Timestep Collection Time: 2.17461
Timestep Consumption Time: 2.49248
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.66709

Cumulative Model Updates: 329,244
Cumulative Timesteps: 2,745,866,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2745866326...
Checkpoint 2745866326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.49193
Policy Entropy: 4.17075
Value Function Loss: 0.00468

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.01871
Policy Update Magnitude: 0.28806
Value Function Update Magnitude: 0.37544

Collected Steps per Second: 22,533.61544
Overall Steps per Second: 10,827.59754

Timestep Collection Time: 2.21917
Timestep Consumption Time: 2.39921
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.61838

Cumulative Model Updates: 329,250
Cumulative Timesteps: 2,745,916,332

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.38632
Policy Entropy: 4.15290
Value Function Loss: 0.00455

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.02322
Policy Update Magnitude: 0.28608
Value Function Update Magnitude: 0.36822

Collected Steps per Second: 22,951.85278
Overall Steps per Second: 10,802.49454

Timestep Collection Time: 2.17900
Timestep Consumption Time: 2.45068
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.62967

Cumulative Model Updates: 329,256
Cumulative Timesteps: 2,745,966,344

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2745966344...
Checkpoint 2745966344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.30049
Policy Entropy: 4.16405
Value Function Loss: 0.00506

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02225
Policy Update Magnitude: 0.28792
Value Function Update Magnitude: 0.33998

Collected Steps per Second: 22,723.13340
Overall Steps per Second: 10,735.68589

Timestep Collection Time: 2.20172
Timestep Consumption Time: 2.45844
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.66016

Cumulative Model Updates: 329,262
Cumulative Timesteps: 2,746,016,374

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.87287
Policy Entropy: 4.15441
Value Function Loss: 0.00531

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.02406
Policy Update Magnitude: 0.29616
Value Function Update Magnitude: 0.35524

Collected Steps per Second: 22,904.84618
Overall Steps per Second: 10,906.37876

Timestep Collection Time: 2.18417
Timestep Consumption Time: 2.40287
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.58704

Cumulative Model Updates: 329,268
Cumulative Timesteps: 2,746,066,402

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2746066402...
Checkpoint 2746066402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.15701
Policy Entropy: 4.15399
Value Function Loss: 0.00501

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.02464
Policy Update Magnitude: 0.28617
Value Function Update Magnitude: 0.37716

Collected Steps per Second: 22,875.29562
Overall Steps per Second: 10,747.72299

Timestep Collection Time: 2.18690
Timestep Consumption Time: 2.46767
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.65457

Cumulative Model Updates: 329,274
Cumulative Timesteps: 2,746,116,428

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.83088
Policy Entropy: 4.16720
Value Function Loss: 0.00415

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.02699
Policy Update Magnitude: 0.26920
Value Function Update Magnitude: 0.35313

Collected Steps per Second: 22,856.06805
Overall Steps per Second: 10,746.19008

Timestep Collection Time: 2.18830
Timestep Consumption Time: 2.46600
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.65430

Cumulative Model Updates: 329,280
Cumulative Timesteps: 2,746,166,444

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2746166444...
Checkpoint 2746166444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.02146
Policy Entropy: 4.16887
Value Function Loss: 0.00424

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02159
Policy Update Magnitude: 0.26059
Value Function Update Magnitude: 0.32936

Collected Steps per Second: 23,379.05696
Overall Steps per Second: 11,004.27008

Timestep Collection Time: 2.13986
Timestep Consumption Time: 2.40637
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.54624

Cumulative Model Updates: 329,286
Cumulative Timesteps: 2,746,216,472

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.02728
Policy Entropy: 4.15807
Value Function Loss: 0.00401

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02312
Policy Update Magnitude: 0.27084
Value Function Update Magnitude: 0.33448

Collected Steps per Second: 22,897.13046
Overall Steps per Second: 10,730.89371

Timestep Collection Time: 2.18508
Timestep Consumption Time: 2.47735
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.66243

Cumulative Model Updates: 329,292
Cumulative Timesteps: 2,746,266,504

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2746266504...
Checkpoint 2746266504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.37613
Policy Entropy: 4.15448
Value Function Loss: 0.00385

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.02231
Policy Update Magnitude: 0.26868
Value Function Update Magnitude: 0.33081

Collected Steps per Second: 22,701.37050
Overall Steps per Second: 10,932.09974

Timestep Collection Time: 2.20330
Timestep Consumption Time: 2.37203
PPO Batch Consumption Time: 0.27520
Total Iteration Time: 4.57533

Cumulative Model Updates: 329,298
Cumulative Timesteps: 2,746,316,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.02782
Policy Entropy: 4.18012
Value Function Loss: 0.00350

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.02376
Policy Update Magnitude: 0.25846
Value Function Update Magnitude: 0.31616

Collected Steps per Second: 23,536.28910
Overall Steps per Second: 10,833.48053

Timestep Collection Time: 2.12565
Timestep Consumption Time: 2.49244
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.61809

Cumulative Model Updates: 329,304
Cumulative Timesteps: 2,746,366,552

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2746366552...
Checkpoint 2746366552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.76793
Policy Entropy: 4.19032
Value Function Loss: 0.00383

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02124
Policy Update Magnitude: 0.26184
Value Function Update Magnitude: 0.31255

Collected Steps per Second: 22,694.24917
Overall Steps per Second: 10,650.45211

Timestep Collection Time: 2.20373
Timestep Consumption Time: 2.49203
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.69576

Cumulative Model Updates: 329,310
Cumulative Timesteps: 2,746,416,564

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.85647
Policy Entropy: 4.17657
Value Function Loss: 0.00398

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.01994
Policy Update Magnitude: 0.26438
Value Function Update Magnitude: 0.33053

Collected Steps per Second: 22,577.66218
Overall Steps per Second: 10,952.54437

Timestep Collection Time: 2.21493
Timestep Consumption Time: 2.35095
PPO Batch Consumption Time: 0.28243
Total Iteration Time: 4.56588

Cumulative Model Updates: 329,316
Cumulative Timesteps: 2,746,466,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2746466572...
Checkpoint 2746466572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.57404
Policy Entropy: 4.14301
Value Function Loss: 0.00446

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02243
Policy Update Magnitude: 0.27815
Value Function Update Magnitude: 0.36005

Collected Steps per Second: 22,958.71550
Overall Steps per Second: 10,752.40608

Timestep Collection Time: 2.17791
Timestep Consumption Time: 2.47240
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.65031

Cumulative Model Updates: 329,322
Cumulative Timesteps: 2,746,516,574

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.95625
Policy Entropy: 4.16602
Value Function Loss: 0.00352

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.02242
Policy Update Magnitude: 0.26391
Value Function Update Magnitude: 0.35360

Collected Steps per Second: 22,760.01819
Overall Steps per Second: 10,765.95832

Timestep Collection Time: 2.19683
Timestep Consumption Time: 2.44743
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.64427

Cumulative Model Updates: 329,328
Cumulative Timesteps: 2,746,566,574

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2746566574...
Checkpoint 2746566574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.90819
Policy Entropy: 4.17909
Value Function Loss: 0.00365

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.01908
Policy Update Magnitude: 0.25307
Value Function Update Magnitude: 0.32354

Collected Steps per Second: 23,178.55755
Overall Steps per Second: 10,851.80132

Timestep Collection Time: 2.15820
Timestep Consumption Time: 2.45154
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.60974

Cumulative Model Updates: 329,334
Cumulative Timesteps: 2,746,616,598

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.77206
Policy Entropy: 4.17169
Value Function Loss: 0.00376

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02337
Policy Update Magnitude: 0.26420
Value Function Update Magnitude: 0.30554

Collected Steps per Second: 22,444.11141
Overall Steps per Second: 10,691.90321

Timestep Collection Time: 2.22838
Timestep Consumption Time: 2.44937
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.67775

Cumulative Model Updates: 329,340
Cumulative Timesteps: 2,746,666,612

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2746666612...
Checkpoint 2746666612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.78745
Policy Entropy: 4.17820
Value Function Loss: 0.00344

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.02486
Policy Update Magnitude: 0.25642
Value Function Update Magnitude: 0.30936

Collected Steps per Second: 22,551.27663
Overall Steps per Second: 10,883.50080

Timestep Collection Time: 2.21770
Timestep Consumption Time: 2.37751
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.59521

Cumulative Model Updates: 329,346
Cumulative Timesteps: 2,746,716,624

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.58236
Policy Entropy: 4.18754
Value Function Loss: 0.00295

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02053
Policy Update Magnitude: 0.23983
Value Function Update Magnitude: 0.32346

Collected Steps per Second: 22,834.88521
Overall Steps per Second: 10,762.62936

Timestep Collection Time: 2.19025
Timestep Consumption Time: 2.45676
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.64701

Cumulative Model Updates: 329,352
Cumulative Timesteps: 2,746,766,638

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2746766638...
Checkpoint 2746766638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.84094
Policy Entropy: 4.18408
Value Function Loss: 0.00326

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.01734
Policy Update Magnitude: 0.24570
Value Function Update Magnitude: 0.29875

Collected Steps per Second: 22,562.53021
Overall Steps per Second: 10,897.74572

Timestep Collection Time: 2.21624
Timestep Consumption Time: 2.37223
PPO Batch Consumption Time: 0.27675
Total Iteration Time: 4.58847

Cumulative Model Updates: 329,358
Cumulative Timesteps: 2,746,816,642

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.14471
Policy Entropy: 4.14356
Value Function Loss: 0.00385

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.01986
Policy Update Magnitude: 0.25416
Value Function Update Magnitude: 0.30362

Collected Steps per Second: 22,841.87970
Overall Steps per Second: 11,038.14322

Timestep Collection Time: 2.18940
Timestep Consumption Time: 2.34125
PPO Batch Consumption Time: 0.27612
Total Iteration Time: 4.53065

Cumulative Model Updates: 329,364
Cumulative Timesteps: 2,746,866,652

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2746866652...
Checkpoint 2746866652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.54134
Policy Entropy: 4.13826
Value Function Loss: 0.00468

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.02344
Policy Update Magnitude: 0.26764
Value Function Update Magnitude: 0.33126

Collected Steps per Second: 22,603.87409
Overall Steps per Second: 10,651.14920

Timestep Collection Time: 2.21245
Timestep Consumption Time: 2.48282
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.69527

Cumulative Model Updates: 329,370
Cumulative Timesteps: 2,746,916,662

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.14414
Policy Entropy: 4.14683
Value Function Loss: 0.00457

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.02249
Policy Update Magnitude: 0.27753
Value Function Update Magnitude: 0.34033

Collected Steps per Second: 22,995.13865
Overall Steps per Second: 10,854.42797

Timestep Collection Time: 2.17481
Timestep Consumption Time: 2.43253
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.60734

Cumulative Model Updates: 329,376
Cumulative Timesteps: 2,746,966,672

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2746966672...
Checkpoint 2746966672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.67330
Policy Entropy: 4.13742
Value Function Loss: 0.00459

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.02184
Policy Update Magnitude: 0.27475
Value Function Update Magnitude: 0.33310

Collected Steps per Second: 23,570.77441
Overall Steps per Second: 11,041.20506

Timestep Collection Time: 2.12212
Timestep Consumption Time: 2.40818
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.53030

Cumulative Model Updates: 329,382
Cumulative Timesteps: 2,747,016,692

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.94308
Policy Entropy: 4.15668
Value Function Loss: 0.00394

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02146
Policy Update Magnitude: 0.26633
Value Function Update Magnitude: 0.34561

Collected Steps per Second: 22,713.76187
Overall Steps per Second: 10,698.25595

Timestep Collection Time: 2.20210
Timestep Consumption Time: 2.47324
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.67534

Cumulative Model Updates: 329,388
Cumulative Timesteps: 2,747,066,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2747066710...
Checkpoint 2747066710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.19631
Policy Entropy: 4.15587
Value Function Loss: 0.00371

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.01978
Policy Update Magnitude: 0.25575
Value Function Update Magnitude: 0.33716

Collected Steps per Second: 22,580.64764
Overall Steps per Second: 10,865.20298

Timestep Collection Time: 2.21544
Timestep Consumption Time: 2.38880
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.60424

Cumulative Model Updates: 329,394
Cumulative Timesteps: 2,747,116,736

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.37095
Policy Entropy: 4.14823
Value Function Loss: 0.00389

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02034
Policy Update Magnitude: 0.25903
Value Function Update Magnitude: 0.33394

Collected Steps per Second: 23,562.71070
Overall Steps per Second: 11,008.50780

Timestep Collection Time: 2.12217
Timestep Consumption Time: 2.42014
PPO Batch Consumption Time: 0.27680
Total Iteration Time: 4.54231

Cumulative Model Updates: 329,400
Cumulative Timesteps: 2,747,166,740

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2747166740...
Checkpoint 2747166740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.34921
Policy Entropy: 4.13101
Value Function Loss: 0.00381

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02458
Policy Update Magnitude: 0.26923
Value Function Update Magnitude: 0.33614

Collected Steps per Second: 22,748.87726
Overall Steps per Second: 10,694.76604

Timestep Collection Time: 2.19809
Timestep Consumption Time: 2.47747
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.67556

Cumulative Model Updates: 329,406
Cumulative Timesteps: 2,747,216,744

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.76245
Policy Entropy: 4.16299
Value Function Loss: 0.00394

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02420
Policy Update Magnitude: 0.27341
Value Function Update Magnitude: 0.34627

Collected Steps per Second: 22,874.91705
Overall Steps per Second: 10,833.50469

Timestep Collection Time: 2.18641
Timestep Consumption Time: 2.43019
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.61660

Cumulative Model Updates: 329,412
Cumulative Timesteps: 2,747,266,758

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2747266758...
Checkpoint 2747266758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.01678
Policy Entropy: 4.16475
Value Function Loss: 0.00396

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.02318
Policy Update Magnitude: 0.26450
Value Function Update Magnitude: 0.35232

Collected Steps per Second: 22,383.16885
Overall Steps per Second: 10,632.87595

Timestep Collection Time: 2.23445
Timestep Consumption Time: 2.46927
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.70371

Cumulative Model Updates: 329,418
Cumulative Timesteps: 2,747,316,772

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.54591
Policy Entropy: 4.14362
Value Function Loss: 0.00474

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.02253
Policy Update Magnitude: 0.26770
Value Function Update Magnitude: 0.36057

Collected Steps per Second: 22,753.92886
Overall Steps per Second: 10,900.50805

Timestep Collection Time: 2.19769
Timestep Consumption Time: 2.38981
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.58749

Cumulative Model Updates: 329,424
Cumulative Timesteps: 2,747,366,778

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2747366778...
Checkpoint 2747366778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.49786
Policy Entropy: 4.09686
Value Function Loss: 0.00498

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.02782
Policy Update Magnitude: 0.29438
Value Function Update Magnitude: 0.37379

Collected Steps per Second: 23,210.84572
Overall Steps per Second: 10,845.88515

Timestep Collection Time: 2.15485
Timestep Consumption Time: 2.45666
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.61152

Cumulative Model Updates: 329,430
Cumulative Timesteps: 2,747,416,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.27403
Policy Entropy: 4.13515
Value Function Loss: 0.00471

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.02529
Policy Update Magnitude: 0.29332
Value Function Update Magnitude: 0.35903

Collected Steps per Second: 22,949.27562
Overall Steps per Second: 10,748.14833

Timestep Collection Time: 2.17907
Timestep Consumption Time: 2.47364
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.65271

Cumulative Model Updates: 329,436
Cumulative Timesteps: 2,747,466,802

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2747466802...
Checkpoint 2747466802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.72875
Policy Entropy: 4.16691
Value Function Loss: 0.00401

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.02448
Policy Update Magnitude: 0.28311
Value Function Update Magnitude: 0.33585

Collected Steps per Second: 22,526.30415
Overall Steps per Second: 10,686.73184

Timestep Collection Time: 2.21972
Timestep Consumption Time: 2.45917
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.67889

Cumulative Model Updates: 329,442
Cumulative Timesteps: 2,747,516,804

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.79989
Policy Entropy: 4.17538
Value Function Loss: 0.00433

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.02374
Policy Update Magnitude: 0.27891
Value Function Update Magnitude: 0.31031

Collected Steps per Second: 23,402.51036
Overall Steps per Second: 10,855.47464

Timestep Collection Time: 2.13746
Timestep Consumption Time: 2.47053
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.60800

Cumulative Model Updates: 329,448
Cumulative Timesteps: 2,747,566,826

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2747566826...
Checkpoint 2747566826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.75798
Policy Entropy: 4.13854
Value Function Loss: 0.00472

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.02447
Policy Update Magnitude: 0.28522
Value Function Update Magnitude: 0.30214

Collected Steps per Second: 22,780.32858
Overall Steps per Second: 10,659.58681

Timestep Collection Time: 2.19584
Timestep Consumption Time: 2.49684
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.69268

Cumulative Model Updates: 329,454
Cumulative Timesteps: 2,747,616,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.97600
Policy Entropy: 4.12396
Value Function Loss: 0.00481

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.02579
Policy Update Magnitude: 0.27965
Value Function Update Magnitude: 0.32805

Collected Steps per Second: 22,985.61266
Overall Steps per Second: 10,859.07821

Timestep Collection Time: 2.17562
Timestep Consumption Time: 2.42956
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.60518

Cumulative Model Updates: 329,460
Cumulative Timesteps: 2,747,666,856

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2747666856...
Checkpoint 2747666856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.12918
Policy Entropy: 4.10632
Value Function Loss: 0.00495

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.02708
Policy Update Magnitude: 0.28579
Value Function Update Magnitude: 0.34717

Collected Steps per Second: 22,638.26034
Overall Steps per Second: 10,655.55322

Timestep Collection Time: 2.20927
Timestep Consumption Time: 2.48443
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.69370

Cumulative Model Updates: 329,466
Cumulative Timesteps: 2,747,716,870

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.95301
Policy Entropy: 4.14105
Value Function Loss: 0.00443

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02558
Policy Update Magnitude: 0.28742
Value Function Update Magnitude: 0.33809

Collected Steps per Second: 22,862.57732
Overall Steps per Second: 10,940.48520

Timestep Collection Time: 2.18794
Timestep Consumption Time: 2.38425
PPO Batch Consumption Time: 0.27699
Total Iteration Time: 4.57219

Cumulative Model Updates: 329,472
Cumulative Timesteps: 2,747,766,892

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2747766892...
Checkpoint 2747766892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.82030
Policy Entropy: 4.13382
Value Function Loss: 0.00487

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.28780
Value Function Update Magnitude: 0.35448

Collected Steps per Second: 23,648.76907
Overall Steps per Second: 11,087.07134

Timestep Collection Time: 2.11529
Timestep Consumption Time: 2.39663
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.51192

Cumulative Model Updates: 329,478
Cumulative Timesteps: 2,747,816,916

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.90702
Policy Entropy: 4.18962
Value Function Loss: 0.00381

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.02015
Policy Update Magnitude: 0.26592
Value Function Update Magnitude: 0.34283

Collected Steps per Second: 22,429.57050
Overall Steps per Second: 10,600.36738

Timestep Collection Time: 2.22938
Timestep Consumption Time: 2.48782
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.71720

Cumulative Model Updates: 329,484
Cumulative Timesteps: 2,747,866,920

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2747866920...
Checkpoint 2747866920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.18984
Policy Entropy: 4.19954
Value Function Loss: 0.00378

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.01678
Policy Update Magnitude: 0.24532
Value Function Update Magnitude: 0.32853

Collected Steps per Second: 22,744.50065
Overall Steps per Second: 10,981.81365

Timestep Collection Time: 2.19965
Timestep Consumption Time: 2.35606
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.55571

Cumulative Model Updates: 329,490
Cumulative Timesteps: 2,747,916,950

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.36213
Policy Entropy: 4.19264
Value Function Loss: 0.00364

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.01778
Policy Update Magnitude: 0.24550
Value Function Update Magnitude: 0.30950

Collected Steps per Second: 23,211.41763
Overall Steps per Second: 10,974.90997

Timestep Collection Time: 2.15506
Timestep Consumption Time: 2.40279
PPO Batch Consumption Time: 0.27556
Total Iteration Time: 4.55785

Cumulative Model Updates: 329,496
Cumulative Timesteps: 2,747,966,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2747966972...
Checkpoint 2747966972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.27319
Policy Entropy: 4.16745
Value Function Loss: 0.00358

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.01939
Policy Update Magnitude: 0.25871
Value Function Update Magnitude: 0.31888

Collected Steps per Second: 22,685.87678
Overall Steps per Second: 10,664.85866

Timestep Collection Time: 2.20410
Timestep Consumption Time: 2.48438
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.68848

Cumulative Model Updates: 329,502
Cumulative Timesteps: 2,748,016,974

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.95379
Policy Entropy: 4.15445
Value Function Loss: 0.00394

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.02258
Policy Update Magnitude: 0.27173
Value Function Update Magnitude: 0.35599

Collected Steps per Second: 22,893.35224
Overall Steps per Second: 10,865.27399

Timestep Collection Time: 2.18456
Timestep Consumption Time: 2.41836
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.60292

Cumulative Model Updates: 329,508
Cumulative Timesteps: 2,748,066,986

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2748066986...
Checkpoint 2748066986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.44742
Policy Entropy: 4.16318
Value Function Loss: 0.00371

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02359
Policy Update Magnitude: 0.27257
Value Function Update Magnitude: 0.36018

Collected Steps per Second: 22,677.35953
Overall Steps per Second: 10,658.55392

Timestep Collection Time: 2.20528
Timestep Consumption Time: 2.48672
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.69201

Cumulative Model Updates: 329,514
Cumulative Timesteps: 2,748,116,996

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.33289
Policy Entropy: 4.15530
Value Function Loss: 0.00359

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02264
Policy Update Magnitude: 0.27115
Value Function Update Magnitude: 0.33873

Collected Steps per Second: 22,842.78318
Overall Steps per Second: 10,877.74567

Timestep Collection Time: 2.19010
Timestep Consumption Time: 2.40901
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.59911

Cumulative Model Updates: 329,520
Cumulative Timesteps: 2,748,167,024

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2748167024...
Checkpoint 2748167024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.16439
Policy Entropy: 4.15375
Value Function Loss: 0.00347

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02163
Policy Update Magnitude: 0.25926
Value Function Update Magnitude: 0.32000

Collected Steps per Second: 22,562.51650
Overall Steps per Second: 10,994.36795

Timestep Collection Time: 2.21739
Timestep Consumption Time: 2.33312
PPO Batch Consumption Time: 0.27690
Total Iteration Time: 4.55051

Cumulative Model Updates: 329,526
Cumulative Timesteps: 2,748,217,054

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.86223
Policy Entropy: 4.13852
Value Function Loss: 0.00408

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02211
Policy Update Magnitude: 0.26011
Value Function Update Magnitude: 0.31687

Collected Steps per Second: 22,740.73444
Overall Steps per Second: 10,703.63968

Timestep Collection Time: 2.19984
Timestep Consumption Time: 2.47390
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.67374

Cumulative Model Updates: 329,532
Cumulative Timesteps: 2,748,267,080

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2748267080...
Checkpoint 2748267080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.39227
Policy Entropy: 4.15407
Value Function Loss: 0.00390

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.01948
Policy Update Magnitude: 0.26874
Value Function Update Magnitude: 0.32930

Collected Steps per Second: 22,720.82672
Overall Steps per Second: 10,943.10367

Timestep Collection Time: 2.20150
Timestep Consumption Time: 2.36941
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.57092

Cumulative Model Updates: 329,538
Cumulative Timesteps: 2,748,317,100

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.73274
Policy Entropy: 4.17102
Value Function Loss: 0.00365

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.01931
Policy Update Magnitude: 0.25411
Value Function Update Magnitude: 0.33244

Collected Steps per Second: 22,797.25780
Overall Steps per Second: 10,841.65710

Timestep Collection Time: 2.19430
Timestep Consumption Time: 2.41976
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.61405

Cumulative Model Updates: 329,544
Cumulative Timesteps: 2,748,367,124

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2748367124...
Checkpoint 2748367124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.18725
Policy Entropy: 4.16645
Value Function Loss: 0.00349

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.01911
Policy Update Magnitude: 0.24340
Value Function Update Magnitude: 0.32321

Collected Steps per Second: 22,665.15747
Overall Steps per Second: 10,733.82920

Timestep Collection Time: 2.20638
Timestep Consumption Time: 2.45253
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.65892

Cumulative Model Updates: 329,550
Cumulative Timesteps: 2,748,417,132

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.73897
Policy Entropy: 4.17442
Value Function Loss: 0.00323

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02121
Policy Update Magnitude: 0.24491
Value Function Update Magnitude: 0.31919

Collected Steps per Second: 22,795.92597
Overall Steps per Second: 10,893.74008

Timestep Collection Time: 2.19443
Timestep Consumption Time: 2.39757
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.59200

Cumulative Model Updates: 329,556
Cumulative Timesteps: 2,748,467,156

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2748467156...
Checkpoint 2748467156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.15491
Policy Entropy: 4.14489
Value Function Loss: 0.00436

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02154
Policy Update Magnitude: 0.25951
Value Function Update Magnitude: 0.31749

Collected Steps per Second: 22,673.81578
Overall Steps per Second: 10,637.82523

Timestep Collection Time: 2.20598
Timestep Consumption Time: 2.49592
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.70190

Cumulative Model Updates: 329,562
Cumulative Timesteps: 2,748,517,174

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.37186
Policy Entropy: 4.13454
Value Function Loss: 0.00486

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02483
Policy Update Magnitude: 0.28424
Value Function Update Magnitude: 0.33714

Collected Steps per Second: 22,767.63279
Overall Steps per Second: 10,933.81499

Timestep Collection Time: 2.19715
Timestep Consumption Time: 2.37801
PPO Batch Consumption Time: 0.27605
Total Iteration Time: 4.57516

Cumulative Model Updates: 329,568
Cumulative Timesteps: 2,748,567,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2748567198...
Checkpoint 2748567198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.79426
Policy Entropy: 4.12576
Value Function Loss: 0.00535

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.02699
Policy Update Magnitude: 0.29797
Value Function Update Magnitude: 0.37287

Collected Steps per Second: 22,809.33935
Overall Steps per Second: 11,045.89731

Timestep Collection Time: 2.19331
Timestep Consumption Time: 2.33579
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.52910

Cumulative Model Updates: 329,574
Cumulative Timesteps: 2,748,617,226

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.57902
Policy Entropy: 4.14857
Value Function Loss: 0.00419

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.02538
Policy Update Magnitude: 0.29770
Value Function Update Magnitude: 0.38292

Collected Steps per Second: 22,870.10594
Overall Steps per Second: 10,863.54875

Timestep Collection Time: 2.18713
Timestep Consumption Time: 2.41725
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.60439

Cumulative Model Updates: 329,580
Cumulative Timesteps: 2,748,667,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2748667246...
Checkpoint 2748667246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.68809
Policy Entropy: 4.16309
Value Function Loss: 0.00411

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.02191
Policy Update Magnitude: 0.27743
Value Function Update Magnitude: 0.35784

Collected Steps per Second: 22,405.77092
Overall Steps per Second: 10,702.08384

Timestep Collection Time: 2.23166
Timestep Consumption Time: 2.44052
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.67217

Cumulative Model Updates: 329,586
Cumulative Timesteps: 2,748,717,248

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.47827
Policy Entropy: 4.16077
Value Function Loss: 0.00441

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.02382
Policy Update Magnitude: 0.27479
Value Function Update Magnitude: 0.34419

Collected Steps per Second: 23,635.29893
Overall Steps per Second: 10,958.51924

Timestep Collection Time: 2.11633
Timestep Consumption Time: 2.44816
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.56449

Cumulative Model Updates: 329,592
Cumulative Timesteps: 2,748,767,268

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2748767268...
Checkpoint 2748767268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.53100
Policy Entropy: 4.12952
Value Function Loss: 0.00485

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02359
Policy Update Magnitude: 0.28164
Value Function Update Magnitude: 0.34955

Collected Steps per Second: 22,581.60780
Overall Steps per Second: 10,596.47594

Timestep Collection Time: 2.21534
Timestep Consumption Time: 2.50566
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.72100

Cumulative Model Updates: 329,598
Cumulative Timesteps: 2,748,817,294

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.88190
Policy Entropy: 4.12827
Value Function Loss: 0.00395

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.02290
Policy Update Magnitude: 0.28448
Value Function Update Magnitude: 0.35287

Collected Steps per Second: 22,657.72978
Overall Steps per Second: 10,920.71341

Timestep Collection Time: 2.20799
Timestep Consumption Time: 2.37303
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.58102

Cumulative Model Updates: 329,604
Cumulative Timesteps: 2,748,867,322

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2748867322...
Checkpoint 2748867322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12156
Policy Entropy: 4.13932
Value Function Loss: 0.00432

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.02342
Policy Update Magnitude: 0.28009
Value Function Update Magnitude: 0.33091

Collected Steps per Second: 22,720.24231
Overall Steps per Second: 10,639.90279

Timestep Collection Time: 2.20147
Timestep Consumption Time: 2.49951
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.70098

Cumulative Model Updates: 329,610
Cumulative Timesteps: 2,748,917,340

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.50365
Policy Entropy: 4.15548
Value Function Loss: 0.00431

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02163
Policy Update Magnitude: 0.26849
Value Function Update Magnitude: 0.32456

Collected Steps per Second: 23,143.75296
Overall Steps per Second: 10,906.64722

Timestep Collection Time: 2.16093
Timestep Consumption Time: 2.42453
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.58546

Cumulative Model Updates: 329,616
Cumulative Timesteps: 2,748,967,352

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2748967352...
Checkpoint 2748967352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.47447
Policy Entropy: 4.14977
Value Function Loss: 0.00456

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.02381
Policy Update Magnitude: 0.27457
Value Function Update Magnitude: 0.33638

Collected Steps per Second: 22,589.17846
Overall Steps per Second: 10,848.84091

Timestep Collection Time: 2.21451
Timestep Consumption Time: 2.39649
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.61100

Cumulative Model Updates: 329,622
Cumulative Timesteps: 2,749,017,376

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.39927
Policy Entropy: 4.10835
Value Function Loss: 0.00545

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.02546
Policy Update Magnitude: 0.28726
Value Function Update Magnitude: 0.34532

Collected Steps per Second: 23,176.77733
Overall Steps per Second: 10,713.19286

Timestep Collection Time: 2.15802
Timestep Consumption Time: 2.51061
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.66864

Cumulative Model Updates: 329,628
Cumulative Timesteps: 2,749,067,392

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2749067392...
Checkpoint 2749067392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.16960
Policy Entropy: 4.09772
Value Function Loss: 0.00537

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.02920
Policy Update Magnitude: 0.30001
Value Function Update Magnitude: 0.37339

Collected Steps per Second: 22,696.55839
Overall Steps per Second: 10,704.17138

Timestep Collection Time: 2.20403
Timestep Consumption Time: 2.46928
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.67332

Cumulative Model Updates: 329,634
Cumulative Timesteps: 2,749,117,416

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.20353
Policy Entropy: 4.10543
Value Function Loss: 0.00485

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.02802
Policy Update Magnitude: 0.30451
Value Function Update Magnitude: 0.37630

Collected Steps per Second: 22,956.43303
Overall Steps per Second: 10,862.86089

Timestep Collection Time: 2.17917
Timestep Consumption Time: 2.42606
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.60523

Cumulative Model Updates: 329,640
Cumulative Timesteps: 2,749,167,442

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2749167442...
Checkpoint 2749167442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.57453
Policy Entropy: 4.09576
Value Function Loss: 0.00451

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.02561
Policy Update Magnitude: 0.29677
Value Function Update Magnitude: 0.34617

Collected Steps per Second: 22,673.05218
Overall Steps per Second: 10,631.12842

Timestep Collection Time: 2.20526
Timestep Consumption Time: 2.49791
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.70317

Cumulative Model Updates: 329,646
Cumulative Timesteps: 2,749,217,442

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.18729
Policy Entropy: 4.07432
Value Function Loss: 0.00487

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.02635
Policy Update Magnitude: 0.29445
Value Function Update Magnitude: 0.34457

Collected Steps per Second: 22,792.11161
Overall Steps per Second: 10,889.70667

Timestep Collection Time: 2.19418
Timestep Consumption Time: 2.39823
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.59241

Cumulative Model Updates: 329,652
Cumulative Timesteps: 2,749,267,452

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2749267452...
Checkpoint 2749267452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.37363
Policy Entropy: 4.06444
Value Function Loss: 0.00488

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.02999
Policy Update Magnitude: 0.28941
Value Function Update Magnitude: 0.35160

Collected Steps per Second: 23,340.86176
Overall Steps per Second: 10,808.56037

Timestep Collection Time: 2.14268
Timestep Consumption Time: 2.48439
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.62707

Cumulative Model Updates: 329,658
Cumulative Timesteps: 2,749,317,464

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.23894
Policy Entropy: 4.11577
Value Function Loss: 0.00449

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.02875
Policy Update Magnitude: 0.27974
Value Function Update Magnitude: 0.34426

Collected Steps per Second: 23,070.42502
Overall Steps per Second: 10,766.99993

Timestep Collection Time: 2.16858
Timestep Consumption Time: 2.47803
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.64661

Cumulative Model Updates: 329,664
Cumulative Timesteps: 2,749,367,494

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2749367494...
Checkpoint 2749367494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.26650
Policy Entropy: 4.13573
Value Function Loss: 0.00446

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02417
Policy Update Magnitude: 0.26270
Value Function Update Magnitude: 0.33570

Collected Steps per Second: 22,421.88541
Overall Steps per Second: 10,628.13443

Timestep Collection Time: 2.23130
Timestep Consumption Time: 2.47602
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.70732

Cumulative Model Updates: 329,670
Cumulative Timesteps: 2,749,417,524

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.17790
Policy Entropy: 4.13375
Value Function Loss: 0.00430

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02223
Policy Update Magnitude: 0.26391
Value Function Update Magnitude: 0.32176

Collected Steps per Second: 23,506.53941
Overall Steps per Second: 10,956.21261

Timestep Collection Time: 2.12741
Timestep Consumption Time: 2.43694
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.56435

Cumulative Model Updates: 329,676
Cumulative Timesteps: 2,749,467,532

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2749467532...
Checkpoint 2749467532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.79550
Policy Entropy: 4.09742
Value Function Loss: 0.00411

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.02877
Policy Update Magnitude: 0.26726
Value Function Update Magnitude: 0.32225

Collected Steps per Second: 22,655.66006
Overall Steps per Second: 10,676.11344

Timestep Collection Time: 2.20784
Timestep Consumption Time: 2.47739
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.68523

Cumulative Model Updates: 329,682
Cumulative Timesteps: 2,749,517,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.97201
Policy Entropy: 4.13273
Value Function Loss: 0.00304

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02592
Policy Update Magnitude: 0.26258
Value Function Update Magnitude: 0.30177

Collected Steps per Second: 22,844.98774
Overall Steps per Second: 10,856.77535

Timestep Collection Time: 2.18998
Timestep Consumption Time: 2.41821
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.60818

Cumulative Model Updates: 329,688
Cumulative Timesteps: 2,749,567,582

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2749567582...
Checkpoint 2749567582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.78202
Policy Entropy: 4.14849
Value Function Loss: 0.00364

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.02431
Policy Update Magnitude: 0.25602
Value Function Update Magnitude: 0.28279

Collected Steps per Second: 22,792.88869
Overall Steps per Second: 10,703.07536

Timestep Collection Time: 2.19393
Timestep Consumption Time: 2.47819
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.67212

Cumulative Model Updates: 329,694
Cumulative Timesteps: 2,749,617,588

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.39455
Policy Entropy: 4.17472
Value Function Loss: 0.00363

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02094
Policy Update Magnitude: 0.25760
Value Function Update Magnitude: 0.29181

Collected Steps per Second: 22,661.40622
Overall Steps per Second: 10,902.31632

Timestep Collection Time: 2.20701
Timestep Consumption Time: 2.38045
PPO Batch Consumption Time: 0.27630
Total Iteration Time: 4.58747

Cumulative Model Updates: 329,700
Cumulative Timesteps: 2,749,667,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2749667602...
Checkpoint 2749667602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.95059
Policy Entropy: 4.17672
Value Function Loss: 0.00396

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02447
Policy Update Magnitude: 0.25195
Value Function Update Magnitude: 0.32141

Collected Steps per Second: 23,270.18996
Overall Steps per Second: 10,956.16330

Timestep Collection Time: 2.14893
Timestep Consumption Time: 2.41526
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.56419

Cumulative Model Updates: 329,706
Cumulative Timesteps: 2,749,717,608

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.79482
Policy Entropy: 4.19135
Value Function Loss: 0.00364

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.01861
Policy Update Magnitude: 0.25348
Value Function Update Magnitude: 0.33233

Collected Steps per Second: 22,704.30826
Overall Steps per Second: 10,690.20189

Timestep Collection Time: 2.20390
Timestep Consumption Time: 2.47684
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.68073

Cumulative Model Updates: 329,712
Cumulative Timesteps: 2,749,767,646

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2749767646...
Checkpoint 2749767646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.39725
Policy Entropy: 4.18825
Value Function Loss: 0.00373

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02161
Policy Update Magnitude: 0.25828
Value Function Update Magnitude: 0.33563

Collected Steps per Second: 22,666.34691
Overall Steps per Second: 10,889.90829

Timestep Collection Time: 2.20671
Timestep Consumption Time: 2.38635
PPO Batch Consumption Time: 0.27713
Total Iteration Time: 4.59306

Cumulative Model Updates: 329,718
Cumulative Timesteps: 2,749,817,664

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.65227
Policy Entropy: 4.15652
Value Function Loss: 0.00414

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.02570
Policy Update Magnitude: 0.27593
Value Function Update Magnitude: 0.32189

Collected Steps per Second: 23,598.07407
Overall Steps per Second: 11,051.83502

Timestep Collection Time: 2.11950
Timestep Consumption Time: 2.40609
PPO Batch Consumption Time: 0.27637
Total Iteration Time: 4.52558

Cumulative Model Updates: 329,724
Cumulative Timesteps: 2,749,867,680

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2749867680...
Checkpoint 2749867680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.15046
Policy Entropy: 4.13729
Value Function Loss: 0.00421

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.02655
Policy Update Magnitude: 0.27249
Value Function Update Magnitude: 0.30399

Collected Steps per Second: 22,623.78659
Overall Steps per Second: 10,643.75048

Timestep Collection Time: 2.21077
Timestep Consumption Time: 2.48833
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.69910

Cumulative Model Updates: 329,730
Cumulative Timesteps: 2,749,917,696

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.60792
Policy Entropy: 4.12875
Value Function Loss: 0.00398

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.02742
Policy Update Magnitude: 0.26771
Value Function Update Magnitude: 0.31002

Collected Steps per Second: 22,845.80942
Overall Steps per Second: 10,843.02186

Timestep Collection Time: 2.18902
Timestep Consumption Time: 2.42316
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.61218

Cumulative Model Updates: 329,736
Cumulative Timesteps: 2,749,967,706

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2749967706...
Checkpoint 2749967706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.82004
Policy Entropy: 4.13844
Value Function Loss: 0.00348

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.02450
Policy Update Magnitude: 0.26110
Value Function Update Magnitude: 0.31212

Collected Steps per Second: 22,771.22981
Overall Steps per Second: 10,674.50462

Timestep Collection Time: 2.19672
Timestep Consumption Time: 2.48940
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.68612

Cumulative Model Updates: 329,742
Cumulative Timesteps: 2,750,017,728

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.86515
Policy Entropy: 4.13500
Value Function Loss: 0.00376

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.25989
Value Function Update Magnitude: 0.32331

Collected Steps per Second: 22,899.94809
Overall Steps per Second: 10,864.56850

Timestep Collection Time: 2.18446
Timestep Consumption Time: 2.41987
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.60432

Cumulative Model Updates: 329,748
Cumulative Timesteps: 2,750,067,752

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2750067752...
Checkpoint 2750067752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.71569
Policy Entropy: 4.12421
Value Function Loss: 0.00427

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02274
Policy Update Magnitude: 0.26697
Value Function Update Magnitude: 0.32848

Collected Steps per Second: 23,455.50803
Overall Steps per Second: 11,027.95758

Timestep Collection Time: 2.13212
Timestep Consumption Time: 2.40272
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.53484

Cumulative Model Updates: 329,754
Cumulative Timesteps: 2,750,117,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.23520
Policy Entropy: 4.12343
Value Function Loss: 0.00464

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02370
Policy Update Magnitude: 0.28029
Value Function Update Magnitude: 0.32674

Collected Steps per Second: 22,774.25501
Overall Steps per Second: 10,709.08499

Timestep Collection Time: 2.19643
Timestep Consumption Time: 2.47456
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.67099

Cumulative Model Updates: 329,760
Cumulative Timesteps: 2,750,167,784

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2750167784...
Checkpoint 2750167784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.16767
Policy Entropy: 4.11618
Value Function Loss: 0.00432

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.02580
Policy Update Magnitude: 0.27330
Value Function Update Magnitude: 0.31341

Collected Steps per Second: 22,640.08325
Overall Steps per Second: 10,862.24358

Timestep Collection Time: 2.20883
Timestep Consumption Time: 2.39501
PPO Batch Consumption Time: 0.27682
Total Iteration Time: 4.60384

Cumulative Model Updates: 329,766
Cumulative Timesteps: 2,750,217,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.85936
Policy Entropy: 4.11863
Value Function Loss: 0.00447

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.02336
Policy Update Magnitude: 0.26799
Value Function Update Magnitude: 0.31853

Collected Steps per Second: 23,602.08352
Overall Steps per Second: 11,053.19731

Timestep Collection Time: 2.11947
Timestep Consumption Time: 2.40628
PPO Batch Consumption Time: 0.27657
Total Iteration Time: 4.52575

Cumulative Model Updates: 329,772
Cumulative Timesteps: 2,750,267,816

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2750267816...
Checkpoint 2750267816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.03099
Policy Entropy: 4.12966
Value Function Loss: 0.00370

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02497
Policy Update Magnitude: 0.26338
Value Function Update Magnitude: 0.31891

Collected Steps per Second: 22,727.47305
Overall Steps per Second: 10,653.73929

Timestep Collection Time: 2.20104
Timestep Consumption Time: 2.49440
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.69544

Cumulative Model Updates: 329,778
Cumulative Timesteps: 2,750,317,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.73164
Policy Entropy: 4.14920
Value Function Loss: 0.00407

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02281
Policy Update Magnitude: 0.25977
Value Function Update Magnitude: 0.30614

Collected Steps per Second: 22,967.95920
Overall Steps per Second: 10,889.59889

Timestep Collection Time: 2.17773
Timestep Consumption Time: 2.41546
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.59319

Cumulative Model Updates: 329,784
Cumulative Timesteps: 2,750,367,858

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2750367858...
Checkpoint 2750367858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.70061
Policy Entropy: 4.15665
Value Function Loss: 0.00390

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.01987
Policy Update Magnitude: 0.25618
Value Function Update Magnitude: 0.31215

Collected Steps per Second: 22,635.64992
Overall Steps per Second: 10,699.75852

Timestep Collection Time: 2.20908
Timestep Consumption Time: 2.46429
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.67338

Cumulative Model Updates: 329,790
Cumulative Timesteps: 2,750,417,862

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.19930
Policy Entropy: 4.13172
Value Function Loss: 0.00423

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02235
Policy Update Magnitude: 0.26131
Value Function Update Magnitude: 0.31658

Collected Steps per Second: 22,963.18888
Overall Steps per Second: 10,821.42224

Timestep Collection Time: 2.17809
Timestep Consumption Time: 2.44385
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.62194

Cumulative Model Updates: 329,796
Cumulative Timesteps: 2,750,467,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2750467878...
Checkpoint 2750467878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.55724
Policy Entropy: 4.15631
Value Function Loss: 0.00396

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02192
Policy Update Magnitude: 0.26988
Value Function Update Magnitude: 0.30647

Collected Steps per Second: 23,411.59099
Overall Steps per Second: 10,995.74897

Timestep Collection Time: 2.13680
Timestep Consumption Time: 2.41277
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.54958

Cumulative Model Updates: 329,802
Cumulative Timesteps: 2,750,517,904

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.05735
Policy Entropy: 4.12399
Value Function Loss: 0.00457

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02407
Policy Update Magnitude: 0.26729
Value Function Update Magnitude: 0.31013

Collected Steps per Second: 22,786.61676
Overall Steps per Second: 10,746.41716

Timestep Collection Time: 2.19445
Timestep Consumption Time: 2.45864
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.65309

Cumulative Model Updates: 329,808
Cumulative Timesteps: 2,750,567,908

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2750567908...
Checkpoint 2750567908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.53406
Policy Entropy: 4.12091
Value Function Loss: 0.00429

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02318
Policy Update Magnitude: 0.27730
Value Function Update Magnitude: 0.33188

Collected Steps per Second: 22,685.51229
Overall Steps per Second: 10,874.04035

Timestep Collection Time: 2.20440
Timestep Consumption Time: 2.39444
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.59884

Cumulative Model Updates: 329,814
Cumulative Timesteps: 2,750,617,916

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.88211
Policy Entropy: 4.10700
Value Function Loss: 0.00414

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.02483
Policy Update Magnitude: 0.28227
Value Function Update Magnitude: 0.34593

Collected Steps per Second: 23,281.31626
Overall Steps per Second: 10,970.28510

Timestep Collection Time: 2.14773
Timestep Consumption Time: 2.41022
PPO Batch Consumption Time: 0.27685
Total Iteration Time: 4.55795

Cumulative Model Updates: 329,820
Cumulative Timesteps: 2,750,667,918

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2750667918...
Checkpoint 2750667918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.50323
Policy Entropy: 4.13680
Value Function Loss: 0.00418

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.02547
Policy Update Magnitude: 0.27512
Value Function Update Magnitude: 0.34337

Collected Steps per Second: 22,703.81631
Overall Steps per Second: 10,668.87477

Timestep Collection Time: 2.20351
Timestep Consumption Time: 2.48565
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.68915

Cumulative Model Updates: 329,826
Cumulative Timesteps: 2,750,717,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.89587
Policy Entropy: 4.14256
Value Function Loss: 0.00454

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02324
Policy Update Magnitude: 0.27110
Value Function Update Magnitude: 0.35298

Collected Steps per Second: 22,760.04788
Overall Steps per Second: 10,823.82160

Timestep Collection Time: 2.19727
Timestep Consumption Time: 2.42309
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.62036

Cumulative Model Updates: 329,832
Cumulative Timesteps: 2,750,767,956

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2750767956...
Checkpoint 2750767956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.99826
Policy Entropy: 4.11283
Value Function Loss: 0.00488

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.02508
Policy Update Magnitude: 0.27822
Value Function Update Magnitude: 0.36369

Collected Steps per Second: 22,623.05158
Overall Steps per Second: 10,668.63060

Timestep Collection Time: 2.21040
Timestep Consumption Time: 2.47680
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.68720

Cumulative Model Updates: 329,838
Cumulative Timesteps: 2,750,817,962

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.60195
Policy Entropy: 4.10739
Value Function Loss: 0.00446

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.02487
Policy Update Magnitude: 0.27508
Value Function Update Magnitude: 0.36172

Collected Steps per Second: 22,404.80076
Overall Steps per Second: 10,803.46022

Timestep Collection Time: 2.23265
Timestep Consumption Time: 2.39754
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.63018

Cumulative Model Updates: 329,844
Cumulative Timesteps: 2,750,867,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2750867984...
Checkpoint 2750867984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.27728
Policy Entropy: 4.11743
Value Function Loss: 0.00405

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02384
Policy Update Magnitude: 0.27087
Value Function Update Magnitude: 0.34076

Collected Steps per Second: 23,626.40293
Overall Steps per Second: 10,914.84494

Timestep Collection Time: 2.11670
Timestep Consumption Time: 2.46513
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.58183

Cumulative Model Updates: 329,850
Cumulative Timesteps: 2,750,917,994

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.04778
Policy Entropy: 4.13576
Value Function Loss: 0.00389

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02319
Policy Update Magnitude: 0.26744
Value Function Update Magnitude: 0.32400

Collected Steps per Second: 22,914.39763
Overall Steps per Second: 10,761.61040

Timestep Collection Time: 2.18265
Timestep Consumption Time: 2.46480
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.64745

Cumulative Model Updates: 329,856
Cumulative Timesteps: 2,750,968,008

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2750968008...
Checkpoint 2750968008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72.72763
Policy Entropy: 4.12924
Value Function Loss: 0.00416

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.02555
Policy Update Magnitude: 0.27396
Value Function Update Magnitude: 0.31598

Collected Steps per Second: 22,440.34663
Overall Steps per Second: 10,647.82594

Timestep Collection Time: 2.22822
Timestep Consumption Time: 2.46776
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.69598

Cumulative Model Updates: 329,862
Cumulative Timesteps: 2,751,018,010

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.38856
Policy Entropy: 4.10515
Value Function Loss: 0.00421

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02270
Policy Update Magnitude: 0.27447
Value Function Update Magnitude: 0.32290

Collected Steps per Second: 23,497.80639
Overall Steps per Second: 10,860.72530

Timestep Collection Time: 2.12786
Timestep Consumption Time: 2.47589
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.60374

Cumulative Model Updates: 329,868
Cumulative Timesteps: 2,751,068,010

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2751068010...
Checkpoint 2751068010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.44134
Policy Entropy: 4.11741
Value Function Loss: 0.00408

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.02597
Policy Update Magnitude: 0.27668
Value Function Update Magnitude: 0.31304

Collected Steps per Second: 22,682.91217
Overall Steps per Second: 10,665.91943

Timestep Collection Time: 2.20430
Timestep Consumption Time: 2.48353
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.68783

Cumulative Model Updates: 329,874
Cumulative Timesteps: 2,751,118,010

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.87415
Policy Entropy: 4.13119
Value Function Loss: 0.00343

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02423
Policy Update Magnitude: 0.26599
Value Function Update Magnitude: 0.29575

Collected Steps per Second: 22,959.44364
Overall Steps per Second: 10,895.87982

Timestep Collection Time: 2.17845
Timestep Consumption Time: 2.41191
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.59036

Cumulative Model Updates: 329,880
Cumulative Timesteps: 2,751,168,026

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2751168026...
Checkpoint 2751168026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.43564
Policy Entropy: 4.14772
Value Function Loss: 0.00410

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.02351
Policy Update Magnitude: 0.26057
Value Function Update Magnitude: 0.29329

Collected Steps per Second: 22,746.31640
Overall Steps per Second: 10,683.00099

Timestep Collection Time: 2.19877
Timestep Consumption Time: 2.48287
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.68164

Cumulative Model Updates: 329,886
Cumulative Timesteps: 2,751,218,040

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.86326
Policy Entropy: 4.12384
Value Function Loss: 0.00443

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.02400
Policy Update Magnitude: 0.27652
Value Function Update Magnitude: 0.31099

Collected Steps per Second: 22,342.61611
Overall Steps per Second: 10,765.52025

Timestep Collection Time: 2.23904
Timestep Consumption Time: 2.40783
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.64687

Cumulative Model Updates: 329,892
Cumulative Timesteps: 2,751,268,066

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2751268066...
Checkpoint 2751268066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.46231
Policy Entropy: 4.12791
Value Function Loss: 0.00508

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02373
Policy Update Magnitude: 0.28202
Value Function Update Magnitude: 0.34097

Collected Steps per Second: 23,075.89489
Overall Steps per Second: 10,799.86456

Timestep Collection Time: 2.16737
Timestep Consumption Time: 2.46361
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.63098

Cumulative Model Updates: 329,898
Cumulative Timesteps: 2,751,318,080

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.09098
Policy Entropy: 4.09968
Value Function Loss: 0.00452

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.02517
Policy Update Magnitude: 0.27517
Value Function Update Magnitude: 0.35909

Collected Steps per Second: 22,982.59181
Overall Steps per Second: 10,848.65525

Timestep Collection Time: 2.17643
Timestep Consumption Time: 2.43428
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.61071

Cumulative Model Updates: 329,904
Cumulative Timesteps: 2,751,368,100

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2751368100...
Checkpoint 2751368100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.86604
Policy Entropy: 4.09874
Value Function Loss: 0.00442

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.02356
Policy Update Magnitude: 0.27900
Value Function Update Magnitude: 0.35771

Collected Steps per Second: 22,577.06312
Overall Steps per Second: 10,669.92577

Timestep Collection Time: 2.21481
Timestep Consumption Time: 2.47163
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.68644

Cumulative Model Updates: 329,910
Cumulative Timesteps: 2,751,418,104

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.82278
Policy Entropy: 4.08475
Value Function Loss: 0.00486

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.02634
Policy Update Magnitude: 0.27770
Value Function Update Magnitude: 0.35156

Collected Steps per Second: 23,501.09274
Overall Steps per Second: 10,883.76801

Timestep Collection Time: 2.12952
Timestep Consumption Time: 2.46871
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.59822

Cumulative Model Updates: 329,916
Cumulative Timesteps: 2,751,468,150

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2751468150...
Checkpoint 2751468150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.95852
Policy Entropy: 4.13988
Value Function Loss: 0.00503

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02171
Policy Update Magnitude: 0.27535
Value Function Update Magnitude: 0.35141

Collected Steps per Second: 22,729.81713
Overall Steps per Second: 10,656.55058

Timestep Collection Time: 2.20002
Timestep Consumption Time: 2.49250
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.69251

Cumulative Model Updates: 329,922
Cumulative Timesteps: 2,751,518,156

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.84666
Policy Entropy: 4.16623
Value Function Loss: 0.00492

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02036
Policy Update Magnitude: 0.27966
Value Function Update Magnitude: 0.35763

Collected Steps per Second: 23,022.01536
Overall Steps per Second: 10,898.00935

Timestep Collection Time: 2.17244
Timestep Consumption Time: 2.41684
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.58928

Cumulative Model Updates: 329,928
Cumulative Timesteps: 2,751,568,170

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2751568170...
Checkpoint 2751568170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.09998
Policy Entropy: 4.17320
Value Function Loss: 0.00411

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.01979
Policy Update Magnitude: 0.26481
Value Function Update Magnitude: 0.35225

Collected Steps per Second: 23,299.74430
Overall Steps per Second: 10,871.08196

Timestep Collection Time: 2.14663
Timestep Consumption Time: 2.45420
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.60083

Cumulative Model Updates: 329,934
Cumulative Timesteps: 2,751,618,186

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.10429
Policy Entropy: 4.15905
Value Function Loss: 0.00386

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.01986
Policy Update Magnitude: 0.26183
Value Function Update Magnitude: 0.33995

Collected Steps per Second: 22,932.61129
Overall Steps per Second: 10,695.46001

Timestep Collection Time: 2.18100
Timestep Consumption Time: 2.49538
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.67638

Cumulative Model Updates: 329,940
Cumulative Timesteps: 2,751,668,202

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2751668202...
Checkpoint 2751668202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.37594
Policy Entropy: 4.16226
Value Function Loss: 0.00346

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02198
Policy Update Magnitude: 0.25689
Value Function Update Magnitude: 0.33157

Collected Steps per Second: 22,558.14427
Overall Steps per Second: 10,966.63530

Timestep Collection Time: 2.21667
Timestep Consumption Time: 2.34298
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.55965

Cumulative Model Updates: 329,946
Cumulative Timesteps: 2,751,718,206

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.88906
Policy Entropy: 4.16477
Value Function Loss: 0.00483

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.02634
Policy Update Magnitude: 0.25245
Value Function Update Magnitude: 0.33869

Collected Steps per Second: 22,941.09794
Overall Steps per Second: 10,691.43300

Timestep Collection Time: 2.17967
Timestep Consumption Time: 2.49735
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.67702

Cumulative Model Updates: 329,952
Cumulative Timesteps: 2,751,768,210

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2751768210...
Checkpoint 2751768210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.14194
Policy Entropy: 4.14435
Value Function Loss: 0.00518

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02152
Policy Update Magnitude: 0.26817
Value Function Update Magnitude: 0.35946

Collected Steps per Second: 22,520.46220
Overall Steps per Second: 10,863.81141

Timestep Collection Time: 2.22020
Timestep Consumption Time: 2.38223
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.60244

Cumulative Model Updates: 329,958
Cumulative Timesteps: 2,751,818,210

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.62185
Policy Entropy: 4.13177
Value Function Loss: 0.00511

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.02606
Policy Update Magnitude: 0.27522
Value Function Update Magnitude: 0.37064

Collected Steps per Second: 22,863.18091
Overall Steps per Second: 11,005.88600

Timestep Collection Time: 2.18727
Timestep Consumption Time: 2.35648
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.54375

Cumulative Model Updates: 329,964
Cumulative Timesteps: 2,751,868,218

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2751868218...
Checkpoint 2751868218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.82980
Policy Entropy: 4.11994
Value Function Loss: 0.00448

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.02814
Policy Update Magnitude: 0.26667
Value Function Update Magnitude: 0.35958

Collected Steps per Second: 22,486.39046
Overall Steps per Second: 10,644.76022

Timestep Collection Time: 2.22463
Timestep Consumption Time: 2.47477
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.69940

Cumulative Model Updates: 329,970
Cumulative Timesteps: 2,751,918,242

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.00289
Policy Entropy: 4.12359
Value Function Loss: 0.00470

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.02847
Policy Update Magnitude: 0.27167
Value Function Update Magnitude: 0.35465

Collected Steps per Second: 22,916.98939
Overall Steps per Second: 10,936.74785

Timestep Collection Time: 2.18196
Timestep Consumption Time: 2.39015
PPO Batch Consumption Time: 0.27587
Total Iteration Time: 4.57211

Cumulative Model Updates: 329,976
Cumulative Timesteps: 2,751,968,246

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2751968246...
Checkpoint 2751968246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.41652
Policy Entropy: 4.12248
Value Function Loss: 0.00476

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.02731
Policy Update Magnitude: 0.27249
Value Function Update Magnitude: 0.35741

Collected Steps per Second: 23,545.29451
Overall Steps per Second: 11,018.00680

Timestep Collection Time: 2.12365
Timestep Consumption Time: 2.41456
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.53821

Cumulative Model Updates: 329,982
Cumulative Timesteps: 2,752,018,248

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.32453
Policy Entropy: 4.13033
Value Function Loss: 0.00463

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.02729
Policy Update Magnitude: 0.27100
Value Function Update Magnitude: 0.35774

Collected Steps per Second: 22,947.04673
Overall Steps per Second: 10,747.97620

Timestep Collection Time: 2.17980
Timestep Consumption Time: 2.47410
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.65390

Cumulative Model Updates: 329,988
Cumulative Timesteps: 2,752,068,268

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2752068268...
Checkpoint 2752068268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.36593
Policy Entropy: 4.13140
Value Function Loss: 0.00462

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.02684
Policy Update Magnitude: 0.27362
Value Function Update Magnitude: 0.34664

Collected Steps per Second: 22,522.35216
Overall Steps per Second: 10,834.53279

Timestep Collection Time: 2.22108
Timestep Consumption Time: 2.39601
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.61709

Cumulative Model Updates: 329,994
Cumulative Timesteps: 2,752,118,292

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.93991
Policy Entropy: 4.10099
Value Function Loss: 0.00498

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02615
Policy Update Magnitude: 0.27477
Value Function Update Magnitude: 0.34368

Collected Steps per Second: 23,747.61845
Overall Steps per Second: 10,972.21282

Timestep Collection Time: 2.10598
Timestep Consumption Time: 2.45208
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.55806

Cumulative Model Updates: 330,000
Cumulative Timesteps: 2,752,168,304

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2752168304...
Checkpoint 2752168304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81590
Policy Entropy: 4.09467
Value Function Loss: 0.00533

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.02712
Policy Update Magnitude: 0.28249
Value Function Update Magnitude: 0.36219

Collected Steps per Second: 22,771.99249
Overall Steps per Second: 10,718.32904

Timestep Collection Time: 2.19656
Timestep Consumption Time: 2.47021
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.66677

Cumulative Model Updates: 330,006
Cumulative Timesteps: 2,752,218,324

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.67013
Policy Entropy: 4.10050
Value Function Loss: 0.00490

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.02958
Policy Update Magnitude: 0.29351
Value Function Update Magnitude: 0.36400

Collected Steps per Second: 22,916.42092
Overall Steps per Second: 10,880.00617

Timestep Collection Time: 2.18210
Timestep Consumption Time: 2.41403
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.59614

Cumulative Model Updates: 330,012
Cumulative Timesteps: 2,752,268,330

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2752268330...
Checkpoint 2752268330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.20277
Policy Entropy: 4.13079
Value Function Loss: 0.00442

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.02596
Policy Update Magnitude: 0.28145
Value Function Update Magnitude: 0.33393

Collected Steps per Second: 22,770.29070
Overall Steps per Second: 10,685.66363

Timestep Collection Time: 2.19707
Timestep Consumption Time: 2.48471
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.68179

Cumulative Model Updates: 330,018
Cumulative Timesteps: 2,752,318,358

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.39108
Policy Entropy: 4.11191
Value Function Loss: 0.00483

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.02933
Policy Update Magnitude: 0.27891
Value Function Update Magnitude: 0.33351

Collected Steps per Second: 22,842.24084
Overall Steps per Second: 10,798.03115

Timestep Collection Time: 2.18954
Timestep Consumption Time: 2.44223
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.63177

Cumulative Model Updates: 330,024
Cumulative Timesteps: 2,752,368,372

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2752368372...
Checkpoint 2752368372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.63954
Policy Entropy: 4.10965
Value Function Loss: 0.00485

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.02763
Policy Update Magnitude: 0.28486
Value Function Update Magnitude: 0.36193

Collected Steps per Second: 22,701.21903
Overall Steps per Second: 11,003.35042

Timestep Collection Time: 2.20323
Timestep Consumption Time: 2.34229
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.54552

Cumulative Model Updates: 330,030
Cumulative Timesteps: 2,752,418,388

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.81640
Policy Entropy: 4.11376
Value Function Loss: 0.00416

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.02732
Policy Update Magnitude: 0.27608
Value Function Update Magnitude: 0.37545

Collected Steps per Second: 22,717.36231
Overall Steps per Second: 10,676.19047

Timestep Collection Time: 2.20131
Timestep Consumption Time: 2.48276
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.68407

Cumulative Model Updates: 330,036
Cumulative Timesteps: 2,752,468,396

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2752468396...
Checkpoint 2752468396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.51482
Policy Entropy: 4.13880
Value Function Loss: 0.00405

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02526
Policy Update Magnitude: 0.26262
Value Function Update Magnitude: 0.36253

Collected Steps per Second: 22,772.59198
Overall Steps per Second: 10,886.80422

Timestep Collection Time: 2.19659
Timestep Consumption Time: 2.39815
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.59474

Cumulative Model Updates: 330,042
Cumulative Timesteps: 2,752,518,418

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.09328
Policy Entropy: 4.11663
Value Function Loss: 0.00431

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.03044
Policy Update Magnitude: 0.27129
Value Function Update Magnitude: 0.35918

Collected Steps per Second: 23,229.71862
Overall Steps per Second: 10,923.37794

Timestep Collection Time: 2.15302
Timestep Consumption Time: 2.42560
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.57862

Cumulative Model Updates: 330,048
Cumulative Timesteps: 2,752,568,432

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2752568432...
Checkpoint 2752568432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.46971
Policy Entropy: 4.10842
Value Function Loss: 0.00495

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.02805
Policy Update Magnitude: 0.27202
Value Function Update Magnitude: 0.37721

Collected Steps per Second: 22,500.57027
Overall Steps per Second: 10,717.89318

Timestep Collection Time: 2.22350
Timestep Consumption Time: 2.44440
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.66790

Cumulative Model Updates: 330,054
Cumulative Timesteps: 2,752,618,462

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.78444
Policy Entropy: 4.08662
Value Function Loss: 0.00478

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.02747
Policy Update Magnitude: 0.28456
Value Function Update Magnitude: 0.36544

Collected Steps per Second: 22,771.05837
Overall Steps per Second: 10,868.71037

Timestep Collection Time: 2.19577
Timestep Consumption Time: 2.40459
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.60036

Cumulative Model Updates: 330,060
Cumulative Timesteps: 2,752,668,462

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2752668462...
Checkpoint 2752668462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.25884
Policy Entropy: 4.11500
Value Function Loss: 0.00496

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.28465
Value Function Update Magnitude: 0.32656

Collected Steps per Second: 23,309.10084
Overall Steps per Second: 10,866.48470

Timestep Collection Time: 2.14534
Timestep Consumption Time: 2.45651
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.60186

Cumulative Model Updates: 330,066
Cumulative Timesteps: 2,752,718,468

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.29829
Policy Entropy: 4.14400
Value Function Loss: 0.00391

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.02814
Policy Update Magnitude: 0.26650
Value Function Update Magnitude: 0.31503

Collected Steps per Second: 22,996.30496
Overall Steps per Second: 10,710.57799

Timestep Collection Time: 2.17470
Timestep Consumption Time: 2.49452
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.66922

Cumulative Model Updates: 330,072
Cumulative Timesteps: 2,752,768,478

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2752768478...
Checkpoint 2752768478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.60579
Policy Entropy: 4.16095
Value Function Loss: 0.00412

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02264
Policy Update Magnitude: 0.24934
Value Function Update Magnitude: 0.31263

Collected Steps per Second: 22,212.72915
Overall Steps per Second: 10,735.18210

Timestep Collection Time: 2.25240
Timestep Consumption Time: 2.40816
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.66056

Cumulative Model Updates: 330,078
Cumulative Timesteps: 2,752,818,510

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.12191
Policy Entropy: 4.18472
Value Function Loss: 0.00441

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02248
Policy Update Magnitude: 0.25896
Value Function Update Magnitude: 0.31460

Collected Steps per Second: 23,004.07485
Overall Steps per Second: 10,802.56451

Timestep Collection Time: 2.17466
Timestep Consumption Time: 2.45628
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.63094

Cumulative Model Updates: 330,084
Cumulative Timesteps: 2,752,868,536

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2752868536...
Checkpoint 2752868536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.37702
Policy Entropy: 4.15831
Value Function Loss: 0.00414

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02261
Policy Update Magnitude: 0.26398
Value Function Update Magnitude: 0.32812

Collected Steps per Second: 22,761.45977
Overall Steps per Second: 10,694.82620

Timestep Collection Time: 2.19687
Timestep Consumption Time: 2.47866
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.67553

Cumulative Model Updates: 330,090
Cumulative Timesteps: 2,752,918,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.41943
Policy Entropy: 4.18686
Value Function Loss: 0.00327

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.01984
Policy Update Magnitude: 0.24909
Value Function Update Magnitude: 0.32779

Collected Steps per Second: 23,666.92571
Overall Steps per Second: 10,861.72367

Timestep Collection Time: 2.11358
Timestep Consumption Time: 2.49176
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.60535

Cumulative Model Updates: 330,096
Cumulative Timesteps: 2,752,968,562

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2752968562...
Checkpoint 2752968562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.37610
Policy Entropy: 4.16688
Value Function Loss: 0.00269

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.01845
Policy Update Magnitude: 0.22967
Value Function Update Magnitude: 0.29844

Collected Steps per Second: 22,862.84374
Overall Steps per Second: 10,689.99533

Timestep Collection Time: 2.18713
Timestep Consumption Time: 2.49052
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.67764

Cumulative Model Updates: 330,102
Cumulative Timesteps: 2,753,018,566

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.48042
Policy Entropy: 4.16118
Value Function Loss: 0.00384

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.01930
Policy Update Magnitude: 0.24235
Value Function Update Magnitude: 0.27604

Collected Steps per Second: 22,753.38731
Overall Steps per Second: 10,892.53644

Timestep Collection Time: 2.19835
Timestep Consumption Time: 2.39378
PPO Batch Consumption Time: 0.27607
Total Iteration Time: 4.59214

Cumulative Model Updates: 330,108
Cumulative Timesteps: 2,753,068,586

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2753068586...
Checkpoint 2753068586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.79533
Policy Entropy: 4.10200
Value Function Loss: 0.00482

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02242
Policy Update Magnitude: 0.25979
Value Function Update Magnitude: 0.31471

Collected Steps per Second: 23,319.17809
Overall Steps per Second: 10,980.79573

Timestep Collection Time: 2.14493
Timestep Consumption Time: 2.41011
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.55504

Cumulative Model Updates: 330,114
Cumulative Timesteps: 2,753,118,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.69880
Policy Entropy: 4.08271
Value Function Loss: 0.00547

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.02688
Policy Update Magnitude: 0.27909
Value Function Update Magnitude: 0.35877

Collected Steps per Second: 22,800.24690
Overall Steps per Second: 10,717.74884

Timestep Collection Time: 2.19340
Timestep Consumption Time: 2.47269
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.66609

Cumulative Model Updates: 330,120
Cumulative Timesteps: 2,753,168,614

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2753168614...
Checkpoint 2753168614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.22338
Policy Entropy: 4.08885
Value Function Loss: 0.00495

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02546
Policy Update Magnitude: 0.28464
Value Function Update Magnitude: 0.36435

Collected Steps per Second: 22,531.73738
Overall Steps per Second: 10,938.27380

Timestep Collection Time: 2.21954
Timestep Consumption Time: 2.35248
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.57202

Cumulative Model Updates: 330,126
Cumulative Timesteps: 2,753,218,624

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.43899
Policy Entropy: 4.12170
Value Function Loss: 0.00400

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02501
Policy Update Magnitude: 0.27046
Value Function Update Magnitude: 0.36019

Collected Steps per Second: 22,803.58145
Overall Steps per Second: 10,866.94754

Timestep Collection Time: 2.19369
Timestep Consumption Time: 2.40963
PPO Batch Consumption Time: 0.27692
Total Iteration Time: 4.60332

Cumulative Model Updates: 330,132
Cumulative Timesteps: 2,753,268,648

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2753268648...
Checkpoint 2753268648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.61309
Policy Entropy: 4.13695
Value Function Loss: 0.00395

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02197
Policy Update Magnitude: 0.26167
Value Function Update Magnitude: 0.34616

Collected Steps per Second: 22,087.80171
Overall Steps per Second: 10,641.40152

Timestep Collection Time: 2.26387
Timestep Consumption Time: 2.43513
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.69901

Cumulative Model Updates: 330,138
Cumulative Timesteps: 2,753,318,652

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.77483
Policy Entropy: 4.14130
Value Function Loss: 0.00432

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02242
Policy Update Magnitude: 0.26200
Value Function Update Magnitude: 0.32859

Collected Steps per Second: 23,561.22528
Overall Steps per Second: 10,967.91487

Timestep Collection Time: 2.12340
Timestep Consumption Time: 2.43808
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 4.56149

Cumulative Model Updates: 330,144
Cumulative Timesteps: 2,753,368,682

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2753368682...
Checkpoint 2753368682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.47102
Policy Entropy: 4.12378
Value Function Loss: 0.00469

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02153
Policy Update Magnitude: 0.26609
Value Function Update Magnitude: 0.34600

Collected Steps per Second: 22,453.64414
Overall Steps per Second: 10,608.35403

Timestep Collection Time: 2.22788
Timestep Consumption Time: 2.48765
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.71553

Cumulative Model Updates: 330,150
Cumulative Timesteps: 2,753,418,706

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.34619
Policy Entropy: 4.13930
Value Function Loss: 0.00392

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02162
Policy Update Magnitude: 0.25867
Value Function Update Magnitude: 0.34356

Collected Steps per Second: 22,812.88812
Overall Steps per Second: 10,933.24139

Timestep Collection Time: 2.19271
Timestep Consumption Time: 2.38251
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.57522

Cumulative Model Updates: 330,156
Cumulative Timesteps: 2,753,468,728

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2753468728...
Checkpoint 2753468728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.70493
Policy Entropy: 4.08736
Value Function Loss: 0.00437

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02105
Policy Update Magnitude: 0.26670
Value Function Update Magnitude: 0.32754

Collected Steps per Second: 22,500.76426
Overall Steps per Second: 10,629.76252

Timestep Collection Time: 2.22241
Timestep Consumption Time: 2.48193
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.70434

Cumulative Model Updates: 330,162
Cumulative Timesteps: 2,753,518,734

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.21482
Policy Entropy: 4.08101
Value Function Loss: 0.00523

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02535
Policy Update Magnitude: 0.29004
Value Function Update Magnitude: 0.33985

Collected Steps per Second: 22,931.21630
Overall Steps per Second: 10,883.03270

Timestep Collection Time: 2.18174
Timestep Consumption Time: 2.41532
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.59706

Cumulative Model Updates: 330,168
Cumulative Timesteps: 2,753,568,764

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2753568764...
Checkpoint 2753568764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.06251
Policy Entropy: 4.07881
Value Function Loss: 0.00472

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.03065
Policy Update Magnitude: 0.28689
Value Function Update Magnitude: 0.35872

Collected Steps per Second: 22,671.79397
Overall Steps per Second: 10,873.37562

Timestep Collection Time: 2.20662
Timestep Consumption Time: 2.39434
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.60096

Cumulative Model Updates: 330,174
Cumulative Timesteps: 2,753,618,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.93358
Policy Entropy: 4.10577
Value Function Loss: 0.00474

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.02851
Policy Update Magnitude: 0.28042
Value Function Update Magnitude: 0.34180

Collected Steps per Second: 22,902.28292
Overall Steps per Second: 10,779.90073

Timestep Collection Time: 2.18424
Timestep Consumption Time: 2.45625
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.64049

Cumulative Model Updates: 330,180
Cumulative Timesteps: 2,753,668,816

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2753668816...
Checkpoint 2753668816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.31835
Policy Entropy: 4.12924
Value Function Loss: 0.00454

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02157
Policy Update Magnitude: 0.28349
Value Function Update Magnitude: 0.33053

Collected Steps per Second: 22,529.77917
Overall Steps per Second: 10,691.71789

Timestep Collection Time: 2.22008
Timestep Consumption Time: 2.45812
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.67820

Cumulative Model Updates: 330,186
Cumulative Timesteps: 2,753,718,834

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.80540
Policy Entropy: 4.10721
Value Function Loss: 0.00443

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.02441
Policy Update Magnitude: 0.26305
Value Function Update Magnitude: 0.34033

Collected Steps per Second: 22,669.37847
Overall Steps per Second: 10,870.54455

Timestep Collection Time: 2.20606
Timestep Consumption Time: 2.39445
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.60051

Cumulative Model Updates: 330,192
Cumulative Timesteps: 2,753,768,844

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2753768844...
Checkpoint 2753768844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.33258
Policy Entropy: 4.12374
Value Function Loss: 0.00432

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02023
Policy Update Magnitude: 0.25986
Value Function Update Magnitude: 0.33272

Collected Steps per Second: 22,727.14773
Overall Steps per Second: 10,679.02495

Timestep Collection Time: 2.20001
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.68208

Cumulative Model Updates: 330,198
Cumulative Timesteps: 2,753,818,844

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.59321
Policy Entropy: 4.11868
Value Function Loss: 0.00428

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02337
Policy Update Magnitude: 0.26330
Value Function Update Magnitude: 0.32701

Collected Steps per Second: 22,502.00246
Overall Steps per Second: 10,812.60855

Timestep Collection Time: 2.22327
Timestep Consumption Time: 2.40355
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.62682

Cumulative Model Updates: 330,204
Cumulative Timesteps: 2,753,868,872

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2753868872...
Checkpoint 2753868872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.78248
Policy Entropy: 4.12426
Value Function Loss: 0.00461

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02408
Policy Update Magnitude: 0.26820
Value Function Update Magnitude: 0.34123

Collected Steps per Second: 22,400.55705
Overall Steps per Second: 10,800.94032

Timestep Collection Time: 2.23289
Timestep Consumption Time: 2.39800
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.63089

Cumulative Model Updates: 330,210
Cumulative Timesteps: 2,753,918,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.34748
Policy Entropy: 4.13023
Value Function Loss: 0.00489

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02297
Policy Update Magnitude: 0.26895
Value Function Update Magnitude: 0.36585

Collected Steps per Second: 22,878.97506
Overall Steps per Second: 10,762.68619

Timestep Collection Time: 2.18550
Timestep Consumption Time: 2.46037
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.64587

Cumulative Model Updates: 330,216
Cumulative Timesteps: 2,753,968,892

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2753968892...
Checkpoint 2753968892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.17378
Policy Entropy: 4.08793
Value Function Loss: 0.00532

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02041
Policy Update Magnitude: 0.27396
Value Function Update Magnitude: 0.36623

Collected Steps per Second: 22,562.27021
Overall Steps per Second: 10,664.52762

Timestep Collection Time: 2.21680
Timestep Consumption Time: 2.47314
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.68994

Cumulative Model Updates: 330,222
Cumulative Timesteps: 2,754,018,908

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.79688
Policy Entropy: 4.06657
Value Function Loss: 0.00553

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.02643
Policy Update Magnitude: 0.28821
Value Function Update Magnitude: 0.37205

Collected Steps per Second: 23,643.40358
Overall Steps per Second: 10,920.73954

Timestep Collection Time: 2.11518
Timestep Consumption Time: 2.46418
PPO Batch Consumption Time: 0.28438
Total Iteration Time: 4.57936

Cumulative Model Updates: 330,228
Cumulative Timesteps: 2,754,068,918

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2754068918...
Checkpoint 2754068918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.88899
Policy Entropy: 4.05139
Value Function Loss: 0.00574

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.02917
Policy Update Magnitude: 0.30272
Value Function Update Magnitude: 0.37146

Collected Steps per Second: 22,607.75642
Overall Steps per Second: 10,606.21402

Timestep Collection Time: 2.21198
Timestep Consumption Time: 2.50299
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.71497

Cumulative Model Updates: 330,234
Cumulative Timesteps: 2,754,118,926

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.22857
Policy Entropy: 4.10928
Value Function Loss: 0.00443

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.02517
Policy Update Magnitude: 0.28621
Value Function Update Magnitude: 0.35607

Collected Steps per Second: 23,197.93138
Overall Steps per Second: 10,923.05467

Timestep Collection Time: 2.15657
Timestep Consumption Time: 2.42347
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.58004

Cumulative Model Updates: 330,240
Cumulative Timesteps: 2,754,168,954

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2754168954...
Checkpoint 2754168954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.03295
Policy Entropy: 4.14063
Value Function Loss: 0.00425

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02247
Policy Update Magnitude: 0.27221
Value Function Update Magnitude: 0.33472

Collected Steps per Second: 22,951.86706
Overall Steps per Second: 10,749.64435

Timestep Collection Time: 2.17934
Timestep Consumption Time: 2.47383
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.65318

Cumulative Model Updates: 330,246
Cumulative Timesteps: 2,754,218,974

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.47208
Policy Entropy: 4.13967
Value Function Loss: 0.00428

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.01972
Policy Update Magnitude: 0.26424
Value Function Update Magnitude: 0.32541

Collected Steps per Second: 23,159.90662
Overall Steps per Second: 10,794.48823

Timestep Collection Time: 2.15959
Timestep Consumption Time: 2.47388
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.63348

Cumulative Model Updates: 330,252
Cumulative Timesteps: 2,754,268,990

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2754268990...
Checkpoint 2754268990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.03426
Policy Entropy: 4.11618
Value Function Loss: 0.00510

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.02226
Policy Update Magnitude: 0.27506
Value Function Update Magnitude: 0.35961

Collected Steps per Second: 22,733.07710
Overall Steps per Second: 11,014.82511

Timestep Collection Time: 2.20014
Timestep Consumption Time: 2.34065
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.54079

Cumulative Model Updates: 330,258
Cumulative Timesteps: 2,754,319,006

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.82263
Policy Entropy: 4.07481
Value Function Loss: 0.00508

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.02285
Policy Update Magnitude: 0.27990
Value Function Update Magnitude: 0.39020

Collected Steps per Second: 22,773.91578
Overall Steps per Second: 10,692.47436

Timestep Collection Time: 2.19549
Timestep Consumption Time: 2.48069
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.67619

Cumulative Model Updates: 330,264
Cumulative Timesteps: 2,754,369,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2754369006...
Checkpoint 2754369006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60.99202
Policy Entropy: 4.06185
Value Function Loss: 0.00606

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.02662
Policy Update Magnitude: 0.29487
Value Function Update Magnitude: 0.38715

Collected Steps per Second: 22,881.45838
Overall Steps per Second: 10,922.31229

Timestep Collection Time: 2.18640
Timestep Consumption Time: 2.39395
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.58035

Cumulative Model Updates: 330,270
Cumulative Timesteps: 2,754,419,034

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.13829
Policy Entropy: 4.06444
Value Function Loss: 0.00542

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.02818
Policy Update Magnitude: 0.29565
Value Function Update Magnitude: 0.37992

Collected Steps per Second: 22,759.71955
Overall Steps per Second: 10,952.08588

Timestep Collection Time: 2.19695
Timestep Consumption Time: 2.36857
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.56552

Cumulative Model Updates: 330,276
Cumulative Timesteps: 2,754,469,036

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2754469036...
Checkpoint 2754469036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.26134
Policy Entropy: 4.09669
Value Function Loss: 0.00513

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.02906
Policy Update Magnitude: 0.28888
Value Function Update Magnitude: 0.37125

Collected Steps per Second: 22,315.79981
Overall Steps per Second: 10,638.11838

Timestep Collection Time: 2.24057
Timestep Consumption Time: 2.45951
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.70008

Cumulative Model Updates: 330,282
Cumulative Timesteps: 2,754,519,036

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.31858
Policy Entropy: 4.13088
Value Function Loss: 0.00445

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.02746
Policy Update Magnitude: 0.27079
Value Function Update Magnitude: 0.35082

Collected Steps per Second: 22,781.70927
Overall Steps per Second: 10,883.32831

Timestep Collection Time: 2.19588
Timestep Consumption Time: 2.40069
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.59657

Cumulative Model Updates: 330,288
Cumulative Timesteps: 2,754,569,062

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2754569062...
Checkpoint 2754569062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.89426
Policy Entropy: 4.15010
Value Function Loss: 0.00439

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02300
Policy Update Magnitude: 0.25695
Value Function Update Magnitude: 0.33971

Collected Steps per Second: 23,279.77592
Overall Steps per Second: 10,830.71905

Timestep Collection Time: 2.14856
Timestep Consumption Time: 2.46960
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.61816

Cumulative Model Updates: 330,294
Cumulative Timesteps: 2,754,619,080

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.04846
Policy Entropy: 4.11002
Value Function Loss: 0.00530

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02560
Policy Update Magnitude: 0.27897
Value Function Update Magnitude: 0.35426

Collected Steps per Second: 22,871.31082
Overall Steps per Second: 10,772.67098

Timestep Collection Time: 2.18763
Timestep Consumption Time: 2.45690
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.64453

Cumulative Model Updates: 330,300
Cumulative Timesteps: 2,754,669,114

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2754669114...
Checkpoint 2754669114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.59611
Policy Entropy: 4.10012
Value Function Loss: 0.00511

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02505
Policy Update Magnitude: 0.28841
Value Function Update Magnitude: 0.37356

Collected Steps per Second: 22,389.81462
Overall Steps per Second: 10,621.55143

Timestep Collection Time: 2.23423
Timestep Consumption Time: 2.47544
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.70967

Cumulative Model Updates: 330,306
Cumulative Timesteps: 2,754,719,138

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.91668
Policy Entropy: 4.04562
Value Function Loss: 0.00574

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.02606
Policy Update Magnitude: 0.29867
Value Function Update Magnitude: 0.37397

Collected Steps per Second: 23,498.85621
Overall Steps per Second: 10,894.00052

Timestep Collection Time: 2.12827
Timestep Consumption Time: 2.46251
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.59078

Cumulative Model Updates: 330,312
Cumulative Timesteps: 2,754,769,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2754769150...
Checkpoint 2754769150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.57667
Policy Entropy: 4.03256
Value Function Loss: 0.00562

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.03123
Policy Update Magnitude: 0.30347
Value Function Update Magnitude: 0.36802

Collected Steps per Second: 22,397.32113
Overall Steps per Second: 10,653.64795

Timestep Collection Time: 2.23330
Timestep Consumption Time: 2.46180
PPO Batch Consumption Time: 0.28516
Total Iteration Time: 4.69511

Cumulative Model Updates: 330,318
Cumulative Timesteps: 2,754,819,170

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.06163
Policy Entropy: 4.04456
Value Function Loss: 0.00504

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.03201
Policy Update Magnitude: 0.29515
Value Function Update Magnitude: 0.36577

Collected Steps per Second: 22,603.82179
Overall Steps per Second: 10,847.91632

Timestep Collection Time: 2.21255
Timestep Consumption Time: 2.39774
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.61029

Cumulative Model Updates: 330,324
Cumulative Timesteps: 2,754,869,182

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2754869182...
Checkpoint 2754869182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.53419
Policy Entropy: 4.08400
Value Function Loss: 0.00470

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.02678
Policy Update Magnitude: 0.27927
Value Function Update Magnitude: 0.35570

Collected Steps per Second: 23,470.04558
Overall Steps per Second: 10,857.88118

Timestep Collection Time: 2.13055
Timestep Consumption Time: 2.47477
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.60532

Cumulative Model Updates: 330,330
Cumulative Timesteps: 2,754,919,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.01251
Policy Entropy: 4.13957
Value Function Loss: 0.00403

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02086
Policy Update Magnitude: 0.26638
Value Function Update Magnitude: 0.32474

Collected Steps per Second: 23,068.22521
Overall Steps per Second: 10,749.40182

Timestep Collection Time: 2.16852
Timestep Consumption Time: 2.48513
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.65365

Cumulative Model Updates: 330,336
Cumulative Timesteps: 2,754,969,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2754969210...
Checkpoint 2754969210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.66666
Policy Entropy: 4.13111
Value Function Loss: 0.00443

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02064
Policy Update Magnitude: 0.25650
Value Function Update Magnitude: 0.31954

Collected Steps per Second: 22,643.20667
Overall Steps per Second: 10,885.06038

Timestep Collection Time: 2.20914
Timestep Consumption Time: 2.38633
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.59547

Cumulative Model Updates: 330,342
Cumulative Timesteps: 2,755,019,232

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.95012
Policy Entropy: 4.11232
Value Function Loss: 0.00529

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.01942
Policy Update Magnitude: 0.26241
Value Function Update Magnitude: 0.31766

Collected Steps per Second: 22,827.43192
Overall Steps per Second: 10,660.41404

Timestep Collection Time: 2.19079
Timestep Consumption Time: 2.50040
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.69119

Cumulative Model Updates: 330,348
Cumulative Timesteps: 2,755,069,242

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2755069242...
Checkpoint 2755069242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.03807
Policy Entropy: 4.08833
Value Function Loss: 0.00627

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02272
Policy Update Magnitude: 0.27654
Value Function Update Magnitude: 0.32977

Collected Steps per Second: 22,427.06360
Overall Steps per Second: 10,641.35645

Timestep Collection Time: 2.22963
Timestep Consumption Time: 2.46940
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.69902

Cumulative Model Updates: 330,354
Cumulative Timesteps: 2,755,119,246

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.52926
Policy Entropy: 4.10136
Value Function Loss: 0.00603

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02352
Policy Update Magnitude: 0.27179
Value Function Update Magnitude: 0.35142

Collected Steps per Second: 23,522.14871
Overall Steps per Second: 10,919.76577

Timestep Collection Time: 2.12583
Timestep Consumption Time: 2.45339
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.57922

Cumulative Model Updates: 330,360
Cumulative Timesteps: 2,755,169,250

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2755169250...
Checkpoint 2755169250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.77538
Policy Entropy: 4.12506
Value Function Loss: 0.00526

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02155
Policy Update Magnitude: 0.26473
Value Function Update Magnitude: 0.35036

Collected Steps per Second: 22,740.89445
Overall Steps per Second: 10,674.70824

Timestep Collection Time: 2.20053
Timestep Consumption Time: 2.48737
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.68790

Cumulative Model Updates: 330,366
Cumulative Timesteps: 2,755,219,292

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.63861
Policy Entropy: 4.12609
Value Function Loss: 0.00416

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.01777
Policy Update Magnitude: 0.26298
Value Function Update Magnitude: 0.33731

Collected Steps per Second: 22,751.49151
Overall Steps per Second: 10,890.06576

Timestep Collection Time: 2.19880
Timestep Consumption Time: 2.39493
PPO Batch Consumption Time: 0.27621
Total Iteration Time: 4.59373

Cumulative Model Updates: 330,372
Cumulative Timesteps: 2,755,269,318

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2755269318...
Checkpoint 2755269318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.46706
Policy Entropy: 4.11078
Value Function Loss: 0.00442

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02008
Policy Update Magnitude: 0.26690
Value Function Update Magnitude: 0.34024

Collected Steps per Second: 22,876.69341
Overall Steps per Second: 10,729.51428

Timestep Collection Time: 2.18581
Timestep Consumption Time: 2.47461
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.66042

Cumulative Model Updates: 330,378
Cumulative Timesteps: 2,755,319,322

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.26139
Policy Entropy: 4.10586
Value Function Loss: 0.00447

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02197
Policy Update Magnitude: 0.26648
Value Function Update Magnitude: 0.33692

Collected Steps per Second: 22,767.73428
Overall Steps per Second: 10,778.06161

Timestep Collection Time: 2.19653
Timestep Consumption Time: 2.44345
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.63998

Cumulative Model Updates: 330,384
Cumulative Timesteps: 2,755,369,332

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2755369332...
Checkpoint 2755369332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.15129
Policy Entropy: 4.12693
Value Function Loss: 0.00490

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02285
Policy Update Magnitude: 0.27061
Value Function Update Magnitude: 0.32858

Collected Steps per Second: 22,524.19256
Overall Steps per Second: 10,872.74904

Timestep Collection Time: 2.21984
Timestep Consumption Time: 2.37882
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.59865

Cumulative Model Updates: 330,390
Cumulative Timesteps: 2,755,419,332

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.76283
Policy Entropy: 4.13827
Value Function Loss: 0.00436

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02291
Policy Update Magnitude: 0.25562
Value Function Update Magnitude: 0.32228

Collected Steps per Second: 22,845.01125
Overall Steps per Second: 10,716.15571

Timestep Collection Time: 2.18989
Timestep Consumption Time: 2.47858
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.66847

Cumulative Model Updates: 330,396
Cumulative Timesteps: 2,755,469,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2755469360...
Checkpoint 2755469360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.29925
Policy Entropy: 4.11521
Value Function Loss: 0.00445

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.01968
Policy Update Magnitude: 0.25120
Value Function Update Magnitude: 0.31189

Collected Steps per Second: 22,799.11613
Overall Steps per Second: 10,823.00656

Timestep Collection Time: 2.19394
Timestep Consumption Time: 2.42769
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.62164

Cumulative Model Updates: 330,402
Cumulative Timesteps: 2,755,519,380

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.01983
Policy Entropy: 4.12916
Value Function Loss: 0.00473

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.01919
Policy Update Magnitude: 0.26589
Value Function Update Magnitude: 0.30738

Collected Steps per Second: 22,882.81787
Overall Steps per Second: 11,096.26748

Timestep Collection Time: 2.18609
Timestep Consumption Time: 2.32209
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.50818

Cumulative Model Updates: 330,408
Cumulative Timesteps: 2,755,569,404

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2755569404...
Checkpoint 2755569404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.28360
Policy Entropy: 4.10951
Value Function Loss: 0.00529

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.02572
Policy Update Magnitude: 0.27317
Value Function Update Magnitude: 0.32366

Collected Steps per Second: 22,541.98871
Overall Steps per Second: 10,692.39889

Timestep Collection Time: 2.21879
Timestep Consumption Time: 2.45892
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.67772

Cumulative Model Updates: 330,414
Cumulative Timesteps: 2,755,619,420

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.27619
Policy Entropy: 4.10683
Value Function Loss: 0.00518

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.02246
Policy Update Magnitude: 0.26374
Value Function Update Magnitude: 0.33293

Collected Steps per Second: 22,648.38429
Overall Steps per Second: 10,868.94120

Timestep Collection Time: 2.20766
Timestep Consumption Time: 2.39260
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.60026

Cumulative Model Updates: 330,420
Cumulative Timesteps: 2,755,669,420

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2755669420...
Checkpoint 2755669420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.95710
Policy Entropy: 4.09337
Value Function Loss: 0.00492

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02459
Policy Update Magnitude: 0.26683
Value Function Update Magnitude: 0.35240

Collected Steps per Second: 23,552.06447
Overall Steps per Second: 10,885.92172

Timestep Collection Time: 2.12321
Timestep Consumption Time: 2.47043
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.59364

Cumulative Model Updates: 330,426
Cumulative Timesteps: 2,755,719,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.86356
Policy Entropy: 4.12550
Value Function Loss: 0.00437

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02038
Policy Update Magnitude: 0.26636
Value Function Update Magnitude: 0.36519

Collected Steps per Second: 23,086.72346
Overall Steps per Second: 10,714.13252

Timestep Collection Time: 2.16601
Timestep Consumption Time: 2.50129
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.66729

Cumulative Model Updates: 330,432
Cumulative Timesteps: 2,755,769,432

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2755769432...
Checkpoint 2755769432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.21377
Policy Entropy: 4.13733
Value Function Loss: 0.00458

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.01730
Policy Update Magnitude: 0.26511
Value Function Update Magnitude: 0.36742

Collected Steps per Second: 22,366.24078
Overall Steps per Second: 10,611.53641

Timestep Collection Time: 2.23632
Timestep Consumption Time: 2.47723
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.71355

Cumulative Model Updates: 330,438
Cumulative Timesteps: 2,755,819,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.58328
Policy Entropy: 4.09437
Value Function Loss: 0.00494

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02114
Policy Update Magnitude: 0.27930
Value Function Update Magnitude: 0.36548

Collected Steps per Second: 23,700.69922
Overall Steps per Second: 10,951.04272

Timestep Collection Time: 2.11082
Timestep Consumption Time: 2.45751
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.56833

Cumulative Model Updates: 330,444
Cumulative Timesteps: 2,755,869,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2755869478...
Checkpoint 2755869478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.56379
Policy Entropy: 4.05699
Value Function Loss: 0.00503

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.02456
Policy Update Magnitude: 0.27899
Value Function Update Magnitude: 0.37481

Collected Steps per Second: 21,026.64892
Overall Steps per Second: 10,174.98683

Timestep Collection Time: 2.37908
Timestep Consumption Time: 2.53729
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.91637

Cumulative Model Updates: 330,450
Cumulative Timesteps: 2,755,919,502

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.63379
Policy Entropy: 4.06969
Value Function Loss: 0.00420

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.26544
Value Function Update Magnitude: 0.36691

Collected Steps per Second: 22,844.77680
Overall Steps per Second: 10,945.94690

Timestep Collection Time: 2.18903
Timestep Consumption Time: 2.37960
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.56863

Cumulative Model Updates: 330,456
Cumulative Timesteps: 2,755,969,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2755969510...
Checkpoint 2755969510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.40786
Policy Entropy: 4.09801
Value Function Loss: 0.00424

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02285
Policy Update Magnitude: 0.25617
Value Function Update Magnitude: 0.33672

Collected Steps per Second: 22,637.44059
Overall Steps per Second: 10,628.86811

Timestep Collection Time: 2.20970
Timestep Consumption Time: 2.49654
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.70624

Cumulative Model Updates: 330,462
Cumulative Timesteps: 2,756,019,532

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.11798
Policy Entropy: 4.10845
Value Function Loss: 0.00417

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02054
Policy Update Magnitude: 0.25659
Value Function Update Magnitude: 0.32357

Collected Steps per Second: 22,632.37130
Overall Steps per Second: 10,840.97631

Timestep Collection Time: 2.21002
Timestep Consumption Time: 2.40377
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.61379

Cumulative Model Updates: 330,468
Cumulative Timesteps: 2,756,069,550

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2756069550...
Checkpoint 2756069550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.27384
Policy Entropy: 4.08894
Value Function Loss: 0.00494

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02312
Policy Update Magnitude: 0.26922
Value Function Update Magnitude: 0.33460

Collected Steps per Second: 22,371.22155
Overall Steps per Second: 10,756.30411

Timestep Collection Time: 2.23546
Timestep Consumption Time: 2.41391
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.64937

Cumulative Model Updates: 330,474
Cumulative Timesteps: 2,756,119,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.03729
Policy Entropy: 4.09912
Value Function Loss: 0.00494

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02403
Policy Update Magnitude: 0.27475
Value Function Update Magnitude: 0.36355

Collected Steps per Second: 22,735.47531
Overall Steps per Second: 10,810.32703

Timestep Collection Time: 2.20053
Timestep Consumption Time: 2.42746
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.62798

Cumulative Model Updates: 330,480
Cumulative Timesteps: 2,756,169,590

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2756169590...
Checkpoint 2756169590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.50678
Policy Entropy: 4.08578
Value Function Loss: 0.00543

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.02509
Policy Update Magnitude: 0.27173
Value Function Update Magnitude: 0.38831

Collected Steps per Second: 22,478.09768
Overall Steps per Second: 10,695.56138

Timestep Collection Time: 2.22483
Timestep Consumption Time: 2.45094
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.67577

Cumulative Model Updates: 330,486
Cumulative Timesteps: 2,756,219,600

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.36374
Policy Entropy: 4.13025
Value Function Loss: 0.00477

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02057
Policy Update Magnitude: 0.25991
Value Function Update Magnitude: 0.38896

Collected Steps per Second: 22,682.80991
Overall Steps per Second: 10,938.37069

Timestep Collection Time: 2.20475
Timestep Consumption Time: 2.36723
PPO Batch Consumption Time: 0.28221
Total Iteration Time: 4.57198

Cumulative Model Updates: 330,492
Cumulative Timesteps: 2,756,269,610

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2756269610...
Checkpoint 2756269610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.67045
Policy Entropy: 4.10732
Value Function Loss: 0.00470

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02096
Policy Update Magnitude: 0.26358
Value Function Update Magnitude: 0.38355

Collected Steps per Second: 22,711.30289
Overall Steps per Second: 10,639.17457

Timestep Collection Time: 2.20216
Timestep Consumption Time: 2.49877
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.70093

Cumulative Model Updates: 330,498
Cumulative Timesteps: 2,756,319,624

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.38056
Policy Entropy: 4.12522
Value Function Loss: 0.00435

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.02312
Policy Update Magnitude: 0.26400
Value Function Update Magnitude: 0.36594

Collected Steps per Second: 22,719.68599
Overall Steps per Second: 10,866.45695

Timestep Collection Time: 2.20091
Timestep Consumption Time: 2.40077
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.60168

Cumulative Model Updates: 330,504
Cumulative Timesteps: 2,756,369,628

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2756369628...
Checkpoint 2756369628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.36189
Policy Entropy: 4.09247
Value Function Loss: 0.00458

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02527
Policy Update Magnitude: 0.26228
Value Function Update Magnitude: 0.36726

Collected Steps per Second: 23,391.88615
Overall Steps per Second: 10,868.00080

Timestep Collection Time: 2.13860
Timestep Consumption Time: 2.46445
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.60305

Cumulative Model Updates: 330,510
Cumulative Timesteps: 2,756,419,654

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.75825
Policy Entropy: 4.10110
Value Function Loss: 0.00480

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02430
Policy Update Magnitude: 0.26091
Value Function Update Magnitude: 0.36749

Collected Steps per Second: 22,710.92217
Overall Steps per Second: 10,740.64714

Timestep Collection Time: 2.20176
Timestep Consumption Time: 2.45383
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.65559

Cumulative Model Updates: 330,516
Cumulative Timesteps: 2,756,469,658

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2756469658...
Checkpoint 2756469658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.97133
Policy Entropy: 4.09787
Value Function Loss: 0.00499

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02359
Policy Update Magnitude: 0.26541
Value Function Update Magnitude: 0.36748

Collected Steps per Second: 22,577.40596
Overall Steps per Second: 10,684.05769

Timestep Collection Time: 2.21460
Timestep Consumption Time: 2.46527
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.67987

Cumulative Model Updates: 330,522
Cumulative Timesteps: 2,756,519,658

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.42690
Policy Entropy: 4.06132
Value Function Loss: 0.00534

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.02542
Policy Update Magnitude: 0.28314
Value Function Update Magnitude: 0.38096

Collected Steps per Second: 23,568.38066
Overall Steps per Second: 10,842.65365

Timestep Collection Time: 2.12157
Timestep Consumption Time: 2.49003
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.61160

Cumulative Model Updates: 330,528
Cumulative Timesteps: 2,756,569,660

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2756569660...
Checkpoint 2756569660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.07962
Policy Entropy: 4.07367
Value Function Loss: 0.00522

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.02941
Policy Update Magnitude: 0.28984
Value Function Update Magnitude: 0.39130

Collected Steps per Second: 22,973.76066
Overall Steps per Second: 10,741.87128

Timestep Collection Time: 2.17692
Timestep Consumption Time: 2.47888
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.65580

Cumulative Model Updates: 330,534
Cumulative Timesteps: 2,756,619,672

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09239
Policy Entropy: 4.07218
Value Function Loss: 0.00527

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.02666
Policy Update Magnitude: 0.28334
Value Function Update Magnitude: 0.38214

Collected Steps per Second: 22,810.25268
Overall Steps per Second: 10,821.90176

Timestep Collection Time: 2.19270
Timestep Consumption Time: 2.42904
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.62174

Cumulative Model Updates: 330,540
Cumulative Timesteps: 2,756,669,688

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2756669688...
Checkpoint 2756669688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.91941
Policy Entropy: 4.11564
Value Function Loss: 0.00486

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.02117
Policy Update Magnitude: 0.26961
Value Function Update Magnitude: 0.36434

Collected Steps per Second: 22,762.10236
Overall Steps per Second: 10,696.50735

Timestep Collection Time: 2.19778
Timestep Consumption Time: 2.47908
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.67685

Cumulative Model Updates: 330,546
Cumulative Timesteps: 2,756,719,714

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.25223
Policy Entropy: 4.12586
Value Function Loss: 0.00406

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02011
Policy Update Magnitude: 0.25695
Value Function Update Magnitude: 0.34308

Collected Steps per Second: 22,510.84846
Overall Steps per Second: 10,820.93556

Timestep Collection Time: 2.22195
Timestep Consumption Time: 2.40039
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.62234

Cumulative Model Updates: 330,552
Cumulative Timesteps: 2,756,769,732

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2756769732...
Checkpoint 2756769732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.65465
Policy Entropy: 4.13782
Value Function Loss: 0.00348

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02100
Policy Update Magnitude: 0.24630
Value Function Update Magnitude: 0.32430

Collected Steps per Second: 22,396.02132
Overall Steps per Second: 10,774.67430

Timestep Collection Time: 2.23254
Timestep Consumption Time: 2.40797
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.64051

Cumulative Model Updates: 330,558
Cumulative Timesteps: 2,756,819,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.64044
Policy Entropy: 4.14469
Value Function Loss: 0.00379

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02043
Policy Update Magnitude: 0.24020
Value Function Update Magnitude: 0.32012

Collected Steps per Second: 22,771.13200
Overall Steps per Second: 10,835.01823

Timestep Collection Time: 2.19576
Timestep Consumption Time: 2.41890
PPO Batch Consumption Time: 0.27592
Total Iteration Time: 4.61467

Cumulative Model Updates: 330,564
Cumulative Timesteps: 2,756,869,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2756869732...
Checkpoint 2756869732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.70859
Policy Entropy: 4.14858
Value Function Loss: 0.00475

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02124
Policy Update Magnitude: 0.26560
Value Function Update Magnitude: 0.34378

Collected Steps per Second: 22,574.32211
Overall Steps per Second: 10,720.80307

Timestep Collection Time: 2.21570
Timestep Consumption Time: 2.44981
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.66551

Cumulative Model Updates: 330,570
Cumulative Timesteps: 2,756,919,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.20692
Policy Entropy: 4.11295
Value Function Loss: 0.00512

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.02381
Policy Update Magnitude: 0.27649
Value Function Update Magnitude: 0.36471

Collected Steps per Second: 22,799.85316
Overall Steps per Second: 10,909.87321

Timestep Collection Time: 2.19308
Timestep Consumption Time: 2.39010
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.58319

Cumulative Model Updates: 330,576
Cumulative Timesteps: 2,756,969,752

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2756969752...
Checkpoint 2756969752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71.44180
Policy Entropy: 4.09367
Value Function Loss: 0.00537

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.02389
Policy Update Magnitude: 0.27912
Value Function Update Magnitude: 0.37818

Collected Steps per Second: 22,836.58397
Overall Steps per Second: 10,864.47447

Timestep Collection Time: 2.18956
Timestep Consumption Time: 2.41278
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.60234

Cumulative Model Updates: 330,582
Cumulative Timesteps: 2,757,019,754

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.81044
Policy Entropy: 4.09152
Value Function Loss: 0.00509

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02394
Policy Update Magnitude: 0.27277
Value Function Update Magnitude: 0.37645

Collected Steps per Second: 22,587.00753
Overall Steps per Second: 10,703.08543

Timestep Collection Time: 2.21464
Timestep Consumption Time: 2.45897
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.67361

Cumulative Model Updates: 330,588
Cumulative Timesteps: 2,757,069,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2757069776...
Checkpoint 2757069776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.22122
Policy Entropy: 4.08434
Value Function Loss: 0.00544

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02398
Policy Update Magnitude: 0.27052
Value Function Update Magnitude: 0.35739

Collected Steps per Second: 23,504.12111
Overall Steps per Second: 10,981.60557

Timestep Collection Time: 2.12848
Timestep Consumption Time: 2.42714
PPO Batch Consumption Time: 0.28172
Total Iteration Time: 4.55562

Cumulative Model Updates: 330,594
Cumulative Timesteps: 2,757,119,804

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.52084
Policy Entropy: 4.09352
Value Function Loss: 0.00519

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.02334
Policy Update Magnitude: 0.28143
Value Function Update Magnitude: 0.36087

Collected Steps per Second: 22,740.58521
Overall Steps per Second: 10,815.25640

Timestep Collection Time: 2.19906
Timestep Consumption Time: 2.42477
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.62384

Cumulative Model Updates: 330,600
Cumulative Timesteps: 2,757,169,812

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2757169812...
Checkpoint 2757169812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.68550
Policy Entropy: 4.06965
Value Function Loss: 0.00514

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.02563
Policy Update Magnitude: 0.28923
Value Function Update Magnitude: 0.37126

Collected Steps per Second: 22,483.83761
Overall Steps per Second: 10,685.46881

Timestep Collection Time: 2.22524
Timestep Consumption Time: 2.45700
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.68225

Cumulative Model Updates: 330,606
Cumulative Timesteps: 2,757,219,844

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.90747
Policy Entropy: 4.07590
Value Function Loss: 0.00521

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.02663
Policy Update Magnitude: 0.28889
Value Function Update Magnitude: 0.36495

Collected Steps per Second: 23,398.17748
Overall Steps per Second: 10,966.29421

Timestep Collection Time: 2.13829
Timestep Consumption Time: 2.42406
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.56234

Cumulative Model Updates: 330,612
Cumulative Timesteps: 2,757,269,876

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2757269876...
Checkpoint 2757269876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.75624
Policy Entropy: 4.08949
Value Function Loss: 0.00480

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.02468
Policy Update Magnitude: 0.28164
Value Function Update Magnitude: 0.35599

Collected Steps per Second: 22,860.55527
Overall Steps per Second: 10,727.07463

Timestep Collection Time: 2.18831
Timestep Consumption Time: 2.47522
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.66353

Cumulative Model Updates: 330,618
Cumulative Timesteps: 2,757,319,902

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.96392
Policy Entropy: 4.12423
Value Function Loss: 0.00452

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.02393
Policy Update Magnitude: 0.27685
Value Function Update Magnitude: 0.36889

Collected Steps per Second: 22,801.33160
Overall Steps per Second: 10,848.48580

Timestep Collection Time: 2.19294
Timestep Consumption Time: 2.41618
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.60912

Cumulative Model Updates: 330,624
Cumulative Timesteps: 2,757,369,904

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2757369904...
Checkpoint 2757369904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.05941
Policy Entropy: 4.13353
Value Function Loss: 0.00408

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.02398
Policy Update Magnitude: 0.27210
Value Function Update Magnitude: 0.38260

Collected Steps per Second: 22,668.58046
Overall Steps per Second: 10,665.69048

Timestep Collection Time: 2.20658
Timestep Consumption Time: 2.48323
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.68980

Cumulative Model Updates: 330,630
Cumulative Timesteps: 2,757,419,924

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.49336
Policy Entropy: 4.09941
Value Function Loss: 0.00510

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.02373
Policy Update Magnitude: 0.27821
Value Function Update Magnitude: 0.37313

Collected Steps per Second: 22,783.98339
Overall Steps per Second: 10,853.62604

Timestep Collection Time: 2.19531
Timestep Consumption Time: 2.41310
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.60841

Cumulative Model Updates: 330,636
Cumulative Timesteps: 2,757,469,942

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2757469942...
Checkpoint 2757469942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.49671
Policy Entropy: 4.07190
Value Function Loss: 0.00528

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.02925
Policy Update Magnitude: 0.29161
Value Function Update Magnitude: 0.38298

Collected Steps per Second: 22,996.42815
Overall Steps per Second: 10,732.13026

Timestep Collection Time: 2.17425
Timestep Consumption Time: 2.48466
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.65891

Cumulative Model Updates: 330,642
Cumulative Timesteps: 2,757,519,942

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.71674
Policy Entropy: 4.08176
Value Function Loss: 0.00501

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.03148
Policy Update Magnitude: 0.28993
Value Function Update Magnitude: 0.39756

Collected Steps per Second: 23,070.56322
Overall Steps per Second: 10,812.32100

Timestep Collection Time: 2.16865
Timestep Consumption Time: 2.45866
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.62731

Cumulative Model Updates: 330,648
Cumulative Timesteps: 2,757,569,974

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2757569974...
Checkpoint 2757569974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.76256
Policy Entropy: 4.12149
Value Function Loss: 0.00416

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.02615
Policy Update Magnitude: 0.27380
Value Function Update Magnitude: 0.38188

Collected Steps per Second: 22,369.53906
Overall Steps per Second: 10,598.69191

Timestep Collection Time: 2.23518
Timestep Consumption Time: 2.48238
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.71756

Cumulative Model Updates: 330,654
Cumulative Timesteps: 2,757,619,974

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.40336
Policy Entropy: 4.11424
Value Function Loss: 0.00464

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02341
Policy Update Magnitude: 0.27119
Value Function Update Magnitude: 0.35603

Collected Steps per Second: 23,499.32840
Overall Steps per Second: 10,937.24375

Timestep Collection Time: 2.12789
Timestep Consumption Time: 2.44401
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.57190

Cumulative Model Updates: 330,660
Cumulative Timesteps: 2,757,669,978

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2757669978...
Checkpoint 2757669978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.35127
Policy Entropy: 4.10065
Value Function Loss: 0.00520

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02407
Policy Update Magnitude: 0.27260
Value Function Update Magnitude: 0.35704

Collected Steps per Second: 22,325.52891
Overall Steps per Second: 10,615.64298

Timestep Collection Time: 2.24013
Timestep Consumption Time: 2.47103
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.71116

Cumulative Model Updates: 330,666
Cumulative Timesteps: 2,757,719,990

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.14502
Policy Entropy: 4.11757
Value Function Loss: 0.00445

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02299
Policy Update Magnitude: 0.27069
Value Function Update Magnitude: 0.37755

Collected Steps per Second: 22,893.68385
Overall Steps per Second: 10,945.57015

Timestep Collection Time: 2.18532
Timestep Consumption Time: 2.38548
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.57080

Cumulative Model Updates: 330,672
Cumulative Timesteps: 2,757,770,020

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2757770020...
Checkpoint 2757770020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.19719
Policy Entropy: 4.10823
Value Function Loss: 0.00539

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02419
Policy Update Magnitude: 0.28780
Value Function Update Magnitude: 0.37848

Collected Steps per Second: 22,720.67007
Overall Steps per Second: 10,612.03150

Timestep Collection Time: 2.20090
Timestep Consumption Time: 2.51130
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.71220

Cumulative Model Updates: 330,678
Cumulative Timesteps: 2,757,820,026

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.34781
Policy Entropy: 4.13713
Value Function Loss: 0.00464

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.02257
Policy Update Magnitude: 0.28156
Value Function Update Magnitude: 0.35942

Collected Steps per Second: 22,883.51088
Overall Steps per Second: 10,935.97674

Timestep Collection Time: 2.18559
Timestep Consumption Time: 2.38775
PPO Batch Consumption Time: 0.27639
Total Iteration Time: 4.57335

Cumulative Model Updates: 330,684
Cumulative Timesteps: 2,757,870,040

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2757870040...
Checkpoint 2757870040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.28537
Policy Entropy: 4.09948
Value Function Loss: 0.00565

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.02455
Policy Update Magnitude: 0.27139
Value Function Update Magnitude: 0.35012

Collected Steps per Second: 23,058.08391
Overall Steps per Second: 10,802.24929

Timestep Collection Time: 2.16913
Timestep Consumption Time: 2.46102
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.63015

Cumulative Model Updates: 330,690
Cumulative Timesteps: 2,757,920,056

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.39174
Policy Entropy: 4.11737
Value Function Loss: 0.00475

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02398
Policy Update Magnitude: 0.26363
Value Function Update Magnitude: 0.36595

Collected Steps per Second: 23,057.74276
Overall Steps per Second: 10,733.48562

Timestep Collection Time: 2.16873
Timestep Consumption Time: 2.49015
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.65888

Cumulative Model Updates: 330,696
Cumulative Timesteps: 2,757,970,062

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2757970062...
Checkpoint 2757970062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.81595
Policy Entropy: 4.12504
Value Function Loss: 0.00480

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02496
Policy Update Magnitude: 0.26881
Value Function Update Magnitude: 0.37162

Collected Steps per Second: 22,644.47388
Overall Steps per Second: 10,715.01478

Timestep Collection Time: 2.20831
Timestep Consumption Time: 2.45860
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.66691

Cumulative Model Updates: 330,702
Cumulative Timesteps: 2,758,020,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.81886
Policy Entropy: 4.16972
Value Function Loss: 0.00439

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.01954
Policy Update Magnitude: 0.26014
Value Function Update Magnitude: 0.35549

Collected Steps per Second: 23,599.60599
Overall Steps per Second: 10,827.69537

Timestep Collection Time: 2.11987
Timestep Consumption Time: 2.50051
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.62037

Cumulative Model Updates: 330,708
Cumulative Timesteps: 2,758,070,096

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2758070096...
Checkpoint 2758070096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.90038
Policy Entropy: 4.15106
Value Function Loss: 0.00448

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.01690
Policy Update Magnitude: 0.24688
Value Function Update Magnitude: 0.32962

Collected Steps per Second: 22,674.76439
Overall Steps per Second: 10,656.32268

Timestep Collection Time: 2.20562
Timestep Consumption Time: 2.48755
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.69318

Cumulative Model Updates: 330,714
Cumulative Timesteps: 2,758,120,108

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.11660
Policy Entropy: 4.13858
Value Function Loss: 0.00460

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.01781
Policy Update Magnitude: 0.24424
Value Function Update Magnitude: 0.32111

Collected Steps per Second: 23,119.63400
Overall Steps per Second: 10,884.64624

Timestep Collection Time: 2.16275
Timestep Consumption Time: 2.43106
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.59381

Cumulative Model Updates: 330,720
Cumulative Timesteps: 2,758,170,110

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2758170110...
Checkpoint 2758170110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.62771
Policy Entropy: 4.09724
Value Function Loss: 0.00494

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02405
Policy Update Magnitude: 0.25252
Value Function Update Magnitude: 0.32992

Collected Steps per Second: 22,458.90224
Overall Steps per Second: 10,644.12990

Timestep Collection Time: 2.22700
Timestep Consumption Time: 2.47193
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.69893

Cumulative Model Updates: 330,726
Cumulative Timesteps: 2,758,220,126

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.47821
Policy Entropy: 4.12818
Value Function Loss: 0.00475

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02239
Policy Update Magnitude: 0.25988
Value Function Update Magnitude: 0.34427

Collected Steps per Second: 22,694.41536
Overall Steps per Second: 10,875.52664

Timestep Collection Time: 2.20415
Timestep Consumption Time: 2.39535
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.59950

Cumulative Model Updates: 330,732
Cumulative Timesteps: 2,758,270,148

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2758270148...
Checkpoint 2758270148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.56973
Policy Entropy: 4.12120
Value Function Loss: 0.00465

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02194
Policy Update Magnitude: 0.25690
Value Function Update Magnitude: 0.36087

Collected Steps per Second: 23,374.69248
Overall Steps per Second: 10,856.27890

Timestep Collection Time: 2.13924
Timestep Consumption Time: 2.46676
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.60600

Cumulative Model Updates: 330,738
Cumulative Timesteps: 2,758,320,152

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.99786
Policy Entropy: 4.13741
Value Function Loss: 0.00405

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02003
Policy Update Magnitude: 0.25835
Value Function Update Magnitude: 0.36185

Collected Steps per Second: 23,094.57733
Overall Steps per Second: 10,723.42608

Timestep Collection Time: 2.16588
Timestep Consumption Time: 2.49868
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.66455

Cumulative Model Updates: 330,744
Cumulative Timesteps: 2,758,370,172

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2758370172...
Checkpoint 2758370172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.07064
Policy Entropy: 4.13212
Value Function Loss: 0.00370

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.01983
Policy Update Magnitude: 0.25084
Value Function Update Magnitude: 0.34644

Collected Steps per Second: 22,559.68494
Overall Steps per Second: 10,652.85573

Timestep Collection Time: 2.21732
Timestep Consumption Time: 2.47832
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.69564

Cumulative Model Updates: 330,750
Cumulative Timesteps: 2,758,420,194

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.60754
Policy Entropy: 4.13188
Value Function Loss: 0.00356

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.01830
Policy Update Magnitude: 0.24641
Value Function Update Magnitude: 0.32005

Collected Steps per Second: 23,326.77241
Overall Steps per Second: 10,902.97964

Timestep Collection Time: 2.14380
Timestep Consumption Time: 2.44283
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.58664

Cumulative Model Updates: 330,756
Cumulative Timesteps: 2,758,470,202

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2758470202...
Checkpoint 2758470202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.68561
Policy Entropy: 4.11442
Value Function Loss: 0.00425

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.01991
Policy Update Magnitude: 0.26099
Value Function Update Magnitude: 0.33960

Collected Steps per Second: 22,671.30212
Overall Steps per Second: 10,637.00715

Timestep Collection Time: 2.20578
Timestep Consumption Time: 2.49554
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.70132

Cumulative Model Updates: 330,762
Cumulative Timesteps: 2,758,520,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.61454
Policy Entropy: 4.07364
Value Function Loss: 0.00560

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02381
Policy Update Magnitude: 0.28386
Value Function Update Magnitude: 0.36742

Collected Steps per Second: 22,529.16394
Overall Steps per Second: 10,967.96453

Timestep Collection Time: 2.22023
Timestep Consumption Time: 2.34032
PPO Batch Consumption Time: 0.27594
Total Iteration Time: 4.56055

Cumulative Model Updates: 330,768
Cumulative Timesteps: 2,758,570,230

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2758570230...
Checkpoint 2758570230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.09589
Policy Entropy: 4.07340
Value Function Loss: 0.00505

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.02724
Policy Update Magnitude: 0.28944
Value Function Update Magnitude: 0.37410

Collected Steps per Second: 22,788.85429
Overall Steps per Second: 10,731.55716

Timestep Collection Time: 2.19432
Timestep Consumption Time: 2.46540
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.65972

Cumulative Model Updates: 330,774
Cumulative Timesteps: 2,758,620,236

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.27074
Policy Entropy: 4.09028
Value Function Loss: 0.00451

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02540
Policy Update Magnitude: 0.27266
Value Function Update Magnitude: 0.34804

Collected Steps per Second: 22,906.30355
Overall Steps per Second: 10,763.64746

Timestep Collection Time: 2.18377
Timestep Consumption Time: 2.46354
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.64731

Cumulative Model Updates: 330,780
Cumulative Timesteps: 2,758,670,258

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2758670258...
Checkpoint 2758670258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.85979
Policy Entropy: 4.12356
Value Function Loss: 0.00446

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02238
Policy Update Magnitude: 0.26054
Value Function Update Magnitude: 0.32680

Collected Steps per Second: 22,613.88238
Overall Steps per Second: 11,013.13634

Timestep Collection Time: 2.21227
Timestep Consumption Time: 2.33031
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.54258

Cumulative Model Updates: 330,786
Cumulative Timesteps: 2,758,720,286

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.96817
Policy Entropy: 4.09126
Value Function Loss: 0.00508

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02556
Policy Update Magnitude: 0.26882
Value Function Update Magnitude: 0.32659

Collected Steps per Second: 22,883.20831
Overall Steps per Second: 10,726.98469

Timestep Collection Time: 2.18614
Timestep Consumption Time: 2.47742
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.66357

Cumulative Model Updates: 330,792
Cumulative Timesteps: 2,758,770,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2758770312...
Checkpoint 2758770312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.63302
Policy Entropy: 4.10283
Value Function Loss: 0.00512

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.02739
Policy Update Magnitude: 0.27117
Value Function Update Magnitude: 0.34702

Collected Steps per Second: 22,761.45574
Overall Steps per Second: 10,877.45334

Timestep Collection Time: 2.19766
Timestep Consumption Time: 2.40102
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.59869

Cumulative Model Updates: 330,798
Cumulative Timesteps: 2,758,820,334

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.28145
Policy Entropy: 4.08790
Value Function Loss: 0.00522

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02496
Policy Update Magnitude: 0.27550
Value Function Update Magnitude: 0.35804

Collected Steps per Second: 23,469.45593
Overall Steps per Second: 10,999.06511

Timestep Collection Time: 2.13145
Timestep Consumption Time: 2.41657
PPO Batch Consumption Time: 0.27666
Total Iteration Time: 4.54802

Cumulative Model Updates: 330,804
Cumulative Timesteps: 2,758,870,358

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2758870358...
Checkpoint 2758870358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.31483
Policy Entropy: 4.12741
Value Function Loss: 0.00450

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02480
Policy Update Magnitude: 0.26891
Value Function Update Magnitude: 0.35087

Collected Steps per Second: 22,886.87630
Overall Steps per Second: 10,735.48161

Timestep Collection Time: 2.18475
Timestep Consumption Time: 2.47289
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.65764

Cumulative Model Updates: 330,810
Cumulative Timesteps: 2,758,920,360

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.93924
Policy Entropy: 4.11033
Value Function Loss: 0.00496

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.02856
Policy Update Magnitude: 0.24912
Value Function Update Magnitude: 0.33192

Collected Steps per Second: 22,720.06480
Overall Steps per Second: 10,812.34105

Timestep Collection Time: 2.20149
Timestep Consumption Time: 2.42452
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.62601

Cumulative Model Updates: 330,816
Cumulative Timesteps: 2,758,970,378

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2758970378...
Checkpoint 2758970378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.42102
Policy Entropy: 4.09829
Value Function Loss: 0.00526

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02395
Policy Update Magnitude: 0.25932
Value Function Update Magnitude: 0.32772

Collected Steps per Second: 22,675.02035
Overall Steps per Second: 10,672.29550

Timestep Collection Time: 2.20551
Timestep Consumption Time: 2.48045
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.68596

Cumulative Model Updates: 330,822
Cumulative Timesteps: 2,759,020,388

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.38339
Policy Entropy: 4.09251
Value Function Loss: 0.00469

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02427
Policy Update Magnitude: 0.26170
Value Function Update Magnitude: 0.33337

Collected Steps per Second: 22,803.70910
Overall Steps per Second: 10,918.85758

Timestep Collection Time: 2.19333
Timestep Consumption Time: 2.38737
PPO Batch Consumption Time: 0.27622
Total Iteration Time: 4.58070

Cumulative Model Updates: 330,828
Cumulative Timesteps: 2,759,070,404

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2759070404...
Checkpoint 2759070404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.13759
Policy Entropy: 4.07725
Value Function Loss: 0.00473

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.02539
Policy Update Magnitude: 0.27929
Value Function Update Magnitude: 0.33839

Collected Steps per Second: 22,566.82803
Overall Steps per Second: 9,408.81251

Timestep Collection Time: 2.21644
Timestep Consumption Time: 3.09964
PPO Batch Consumption Time: 0.40387
Total Iteration Time: 5.31608

Cumulative Model Updates: 330,834
Cumulative Timesteps: 2,759,120,422

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.63007
Policy Entropy: 4.03826
Value Function Loss: 0.00542

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.02718
Policy Update Magnitude: 0.30401
Value Function Update Magnitude: 0.35053

Collected Steps per Second: 10,498.59800
Overall Steps per Second: 6,592.95789

Timestep Collection Time: 4.76559
Timestep Consumption Time: 2.82311
PPO Batch Consumption Time: 0.31669
Total Iteration Time: 7.58870

Cumulative Model Updates: 330,840
Cumulative Timesteps: 2,759,170,454

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2759170454...
Checkpoint 2759170454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.92387
Policy Entropy: 4.00529
Value Function Loss: 0.00529

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.03054
Policy Update Magnitude: 0.30561
Value Function Update Magnitude: 0.37883

Collected Steps per Second: 16,518.96466
Overall Steps per Second: 8,622.98045

Timestep Collection Time: 3.02852
Timestep Consumption Time: 2.77319
PPO Batch Consumption Time: 0.31632
Total Iteration Time: 5.80171

Cumulative Model Updates: 330,846
Cumulative Timesteps: 2,759,220,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.47341
Policy Entropy: 4.00570
Value Function Loss: 0.00515

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.02877
Policy Update Magnitude: 0.29438
Value Function Update Magnitude: 0.37015

Collected Steps per Second: 20,121.54184
Overall Steps per Second: 9,828.03899

Timestep Collection Time: 2.48589
Timestep Consumption Time: 2.60363
PPO Batch Consumption Time: 0.31832
Total Iteration Time: 5.08952

Cumulative Model Updates: 330,852
Cumulative Timesteps: 2,759,270,502

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2759270502...
Checkpoint 2759270502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.26991
Policy Entropy: 4.06715
Value Function Loss: 0.00483

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.02418
Policy Update Magnitude: 0.29183
Value Function Update Magnitude: 0.36166

Collected Steps per Second: 20,081.60223
Overall Steps per Second: 10,206.57240

Timestep Collection Time: 2.49094
Timestep Consumption Time: 2.41002
PPO Batch Consumption Time: 0.28216
Total Iteration Time: 4.90096

Cumulative Model Updates: 330,858
Cumulative Timesteps: 2,759,320,524

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.21729
Policy Entropy: 4.10905
Value Function Loss: 0.00441

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.02490
Policy Update Magnitude: 0.27386
Value Function Update Magnitude: 0.36540

Collected Steps per Second: 20,249.11833
Overall Steps per Second: 9,519.01020

Timestep Collection Time: 2.46993
Timestep Consumption Time: 2.78418
PPO Batch Consumption Time: 0.32611
Total Iteration Time: 5.25412

Cumulative Model Updates: 330,864
Cumulative Timesteps: 2,759,370,538

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2759370538...
Checkpoint 2759370538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.92624
Policy Entropy: 4.15117
Value Function Loss: 0.00427

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.02655
Policy Update Magnitude: 0.25667
Value Function Update Magnitude: 0.35658

Collected Steps per Second: 14,988.43102
Overall Steps per Second: 7,585.89626

Timestep Collection Time: 3.33737
Timestep Consumption Time: 3.25671
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 6.59408

Cumulative Model Updates: 330,870
Cumulative Timesteps: 2,759,420,560

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.21101
Policy Entropy: 4.17199
Value Function Loss: 0.00421

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02102
Policy Update Magnitude: 0.25487
Value Function Update Magnitude: 0.33361

Collected Steps per Second: 18,630.42993
Overall Steps per Second: 9,236.47980

Timestep Collection Time: 2.68561
Timestep Consumption Time: 2.73139
PPO Batch Consumption Time: 0.32115
Total Iteration Time: 5.41700

Cumulative Model Updates: 330,876
Cumulative Timesteps: 2,759,470,594

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2759470594...
Checkpoint 2759470594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.63991
Policy Entropy: 4.15676
Value Function Loss: 0.00454

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.02082
Policy Update Magnitude: 0.26151
Value Function Update Magnitude: 0.35473

Collected Steps per Second: 19,976.55371
Overall Steps per Second: 9,700.21996

Timestep Collection Time: 2.50394
Timestep Consumption Time: 2.65265
PPO Batch Consumption Time: 0.32486
Total Iteration Time: 5.15658

Cumulative Model Updates: 330,882
Cumulative Timesteps: 2,759,520,614

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.56218
Policy Entropy: 4.11904
Value Function Loss: 0.00467

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.02239
Policy Update Magnitude: 0.26266
Value Function Update Magnitude: 0.37764

Collected Steps per Second: 19,567.85808
Overall Steps per Second: 9,569.44099

Timestep Collection Time: 2.55542
Timestep Consumption Time: 2.66997
PPO Batch Consumption Time: 0.31517
Total Iteration Time: 5.22538

Cumulative Model Updates: 330,888
Cumulative Timesteps: 2,759,570,618

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2759570618...
Checkpoint 2759570618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.79255
Policy Entropy: 4.07965
Value Function Loss: 0.00534

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02267
Policy Update Magnitude: 0.27865
Value Function Update Magnitude: 0.38647

Collected Steps per Second: 19,934.36776
Overall Steps per Second: 9,823.41409

Timestep Collection Time: 2.50843
Timestep Consumption Time: 2.58186
PPO Batch Consumption Time: 0.29997
Total Iteration Time: 5.09029

Cumulative Model Updates: 330,894
Cumulative Timesteps: 2,759,620,622

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.76083
Policy Entropy: 4.05563
Value Function Loss: 0.00577

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.02759
Policy Update Magnitude: 0.29343
Value Function Update Magnitude: 0.38483

Collected Steps per Second: 21,561.86310
Overall Steps per Second: 10,200.76171

Timestep Collection Time: 2.31928
Timestep Consumption Time: 2.58310
PPO Batch Consumption Time: 0.31862
Total Iteration Time: 4.90238

Cumulative Model Updates: 330,900
Cumulative Timesteps: 2,759,670,630

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2759670630...
Checkpoint 2759670630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.10084
Policy Entropy: 4.05937
Value Function Loss: 0.00566

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.02951
Policy Update Magnitude: 0.28329
Value Function Update Magnitude: 0.37684

Collected Steps per Second: 21,340.92471
Overall Steps per Second: 10,202.89122

Timestep Collection Time: 2.34413
Timestep Consumption Time: 2.55899
PPO Batch Consumption Time: 0.29981
Total Iteration Time: 4.90312

Cumulative Model Updates: 330,906
Cumulative Timesteps: 2,759,720,656

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.34444
Policy Entropy: 4.08609
Value Function Loss: 0.00529

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.02452
Policy Update Magnitude: 0.27368
Value Function Update Magnitude: 0.35822

Collected Steps per Second: 21,501.74759
Overall Steps per Second: 10,005.74008

Timestep Collection Time: 2.32669
Timestep Consumption Time: 2.67324
PPO Batch Consumption Time: 0.32438
Total Iteration Time: 4.99993

Cumulative Model Updates: 330,912
Cumulative Timesteps: 2,759,770,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2759770684...
Checkpoint 2759770684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.52160
Policy Entropy: 4.09200
Value Function Loss: 0.00580

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02385
Policy Update Magnitude: 0.27641
Value Function Update Magnitude: 0.34735

Collected Steps per Second: 19,415.92999
Overall Steps per Second: 9,551.43409

Timestep Collection Time: 2.57520
Timestep Consumption Time: 2.65961
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 5.23482

Cumulative Model Updates: 330,918
Cumulative Timesteps: 2,759,820,684

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.79269
Policy Entropy: 4.07942
Value Function Loss: 0.00644

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.02374
Policy Update Magnitude: 0.28759
Value Function Update Magnitude: 0.37966

Collected Steps per Second: 18,590.14272
Overall Steps per Second: 9,237.12547

Timestep Collection Time: 2.69110
Timestep Consumption Time: 2.72487
PPO Batch Consumption Time: 0.30504
Total Iteration Time: 5.41597

Cumulative Model Updates: 330,924
Cumulative Timesteps: 2,759,870,712

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2759870712...
Checkpoint 2759870712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.93455
Policy Entropy: 4.08249
Value Function Loss: 0.00625

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02229
Policy Update Magnitude: 0.29463
Value Function Update Magnitude: 0.41724

Collected Steps per Second: 15,069.41898
Overall Steps per Second: 8,356.49590

Timestep Collection Time: 3.32037
Timestep Consumption Time: 2.66731
PPO Batch Consumption Time: 0.31586
Total Iteration Time: 5.98768

Cumulative Model Updates: 330,930
Cumulative Timesteps: 2,759,920,748

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.54242
Policy Entropy: 4.06796
Value Function Loss: 0.00613

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02250
Policy Update Magnitude: 0.30984
Value Function Update Magnitude: 0.40156

Collected Steps per Second: 14,655.02121
Overall Steps per Second: 6,548.28207

Timestep Collection Time: 3.41330
Timestep Consumption Time: 4.22565
PPO Batch Consumption Time: 0.54071
Total Iteration Time: 7.63895

Cumulative Model Updates: 330,936
Cumulative Timesteps: 2,759,970,770

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2759970770...
Checkpoint 2759970770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.79188
Policy Entropy: 4.09645
Value Function Loss: 0.00522

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.02454
Policy Update Magnitude: 0.29627
Value Function Update Magnitude: 0.36943

Collected Steps per Second: 14,832.82143
Overall Steps per Second: 7,271.89698

Timestep Collection Time: 3.37185
Timestep Consumption Time: 3.50586
PPO Batch Consumption Time: 0.45214
Total Iteration Time: 6.87771

Cumulative Model Updates: 330,942
Cumulative Timesteps: 2,760,020,784

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.49529
Policy Entropy: 4.11524
Value Function Loss: 0.00519

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.02505
Policy Update Magnitude: 0.27784
Value Function Update Magnitude: 0.35429

Collected Steps per Second: 15,808.92358
Overall Steps per Second: 7,798.04124

Timestep Collection Time: 3.16416
Timestep Consumption Time: 3.25053
PPO Batch Consumption Time: 0.42617
Total Iteration Time: 6.41469

Cumulative Model Updates: 330,948
Cumulative Timesteps: 2,760,070,806

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2760070806...
Checkpoint 2760070806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76.39979
Policy Entropy: 4.11930
Value Function Loss: 0.00430

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02263
Policy Update Magnitude: 0.26313
Value Function Update Magnitude: 0.33214

Collected Steps per Second: 16,229.75574
Overall Steps per Second: 7,402.89372

Timestep Collection Time: 3.08323
Timestep Consumption Time: 3.67629
PPO Batch Consumption Time: 0.48143
Total Iteration Time: 6.75952

Cumulative Model Updates: 330,954
Cumulative Timesteps: 2,760,120,846

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.58433
Policy Entropy: 4.11668
Value Function Loss: 0.00516

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02118
Policy Update Magnitude: 0.25803
Value Function Update Magnitude: 0.33154

Collected Steps per Second: 15,403.11658
Overall Steps per Second: 7,180.93525

Timestep Collection Time: 3.24752
Timestep Consumption Time: 3.71842
PPO Batch Consumption Time: 0.49065
Total Iteration Time: 6.96594

Cumulative Model Updates: 330,960
Cumulative Timesteps: 2,760,170,868

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2760170868...
Checkpoint 2760170868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.58633
Policy Entropy: 4.09836
Value Function Loss: 0.00551

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02466
Policy Update Magnitude: 0.26949
Value Function Update Magnitude: 0.34891

Collected Steps per Second: 15,123.30216
Overall Steps per Second: 6,935.12728

Timestep Collection Time: 3.30629
Timestep Consumption Time: 3.90367
PPO Batch Consumption Time: 0.51300
Total Iteration Time: 7.20996

Cumulative Model Updates: 330,966
Cumulative Timesteps: 2,760,220,870

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.32773
Policy Entropy: 4.08306
Value Function Loss: 0.00572

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.02400
Policy Update Magnitude: 0.27481
Value Function Update Magnitude: 0.35514

Collected Steps per Second: 15,117.53909
Overall Steps per Second: 7,137.91462

Timestep Collection Time: 3.30808
Timestep Consumption Time: 3.69817
PPO Batch Consumption Time: 0.48730
Total Iteration Time: 7.00625

Cumulative Model Updates: 330,972
Cumulative Timesteps: 2,760,270,880

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2760270880...
Checkpoint 2760270880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.09715
Policy Entropy: 4.06558
Value Function Loss: 0.00538

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02329
Policy Update Magnitude: 0.28178
Value Function Update Magnitude: 0.34330

Collected Steps per Second: 13,515.26244
Overall Steps per Second: 6,237.90682

Timestep Collection Time: 3.70189
Timestep Consumption Time: 4.31875
PPO Batch Consumption Time: 0.57730
Total Iteration Time: 8.02064

Cumulative Model Updates: 330,978
Cumulative Timesteps: 2,760,320,912

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.27959
Policy Entropy: 4.05721
Value Function Loss: 0.00557

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02473
Policy Update Magnitude: 0.28470
Value Function Update Magnitude: 0.34658

Collected Steps per Second: 14,578.87402
Overall Steps per Second: 7,063.35268

Timestep Collection Time: 3.43182
Timestep Consumption Time: 3.65151
PPO Batch Consumption Time: 0.47385
Total Iteration Time: 7.08332

Cumulative Model Updates: 330,984
Cumulative Timesteps: 2,760,370,944

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2760370944...
Checkpoint 2760370944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.30964
Policy Entropy: 4.07881
Value Function Loss: 0.00527

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.02814
Policy Update Magnitude: 0.28497
Value Function Update Magnitude: 0.35794

Collected Steps per Second: 15,540.75442
Overall Steps per Second: 7,261.42228

Timestep Collection Time: 3.21786
Timestep Consumption Time: 3.66894
PPO Batch Consumption Time: 0.47528
Total Iteration Time: 6.88681

Cumulative Model Updates: 330,990
Cumulative Timesteps: 2,760,420,952

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.99701
Policy Entropy: 4.07941
Value Function Loss: 0.00586

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.02695
Policy Update Magnitude: 0.28303
Value Function Update Magnitude: 0.36181

Collected Steps per Second: 15,545.58233
Overall Steps per Second: 7,490.95042

Timestep Collection Time: 3.21699
Timestep Consumption Time: 3.45906
PPO Batch Consumption Time: 0.45768
Total Iteration Time: 6.67606

Cumulative Model Updates: 330,996
Cumulative Timesteps: 2,760,470,962

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2760470962...
Checkpoint 2760470962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.11398
Policy Entropy: 4.09049
Value Function Loss: 0.00562

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.02616
Policy Update Magnitude: 0.28052
Value Function Update Magnitude: 0.37376

Collected Steps per Second: 15,479.18840
Overall Steps per Second: 6,986.51909

Timestep Collection Time: 3.23208
Timestep Consumption Time: 3.92885
PPO Batch Consumption Time: 0.52148
Total Iteration Time: 7.16093

Cumulative Model Updates: 331,002
Cumulative Timesteps: 2,760,520,992

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.91442
Policy Entropy: 4.06511
Value Function Loss: 0.00538

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.02848
Policy Update Magnitude: 0.27786
Value Function Update Magnitude: 0.35664

Collected Steps per Second: 15,118.37127
Overall Steps per Second: 6,870.66453

Timestep Collection Time: 3.30803
Timestep Consumption Time: 3.97103
PPO Batch Consumption Time: 0.52872
Total Iteration Time: 7.27906

Cumulative Model Updates: 331,008
Cumulative Timesteps: 2,760,571,004

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2760571004...
Checkpoint 2760571004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.61385
Policy Entropy: 4.04377
Value Function Loss: 0.00494

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02661
Policy Update Magnitude: 0.27933
Value Function Update Magnitude: 0.33220

Collected Steps per Second: 14,748.72312
Overall Steps per Second: 6,922.56293

Timestep Collection Time: 3.39053
Timestep Consumption Time: 3.83309
PPO Batch Consumption Time: 0.50447
Total Iteration Time: 7.22363

Cumulative Model Updates: 331,014
Cumulative Timesteps: 2,760,621,010

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.16329
Policy Entropy: 4.03344
Value Function Loss: 0.00542

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02689
Policy Update Magnitude: 0.28773
Value Function Update Magnitude: 0.33175

Collected Steps per Second: 15,887.42126
Overall Steps per Second: 7,320.47852

Timestep Collection Time: 3.14928
Timestep Consumption Time: 3.68552
PPO Batch Consumption Time: 0.48223
Total Iteration Time: 6.83480

Cumulative Model Updates: 331,020
Cumulative Timesteps: 2,760,671,044

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2760671044...
Checkpoint 2760671044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.76745
Policy Entropy: 4.03948
Value Function Loss: 0.00590

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02913
Policy Update Magnitude: 0.29391
Value Function Update Magnitude: 0.34226

Collected Steps per Second: 14,874.36380
Overall Steps per Second: 7,275.33700

Timestep Collection Time: 3.36351
Timestep Consumption Time: 3.51315
PPO Batch Consumption Time: 0.45750
Total Iteration Time: 6.87666

Cumulative Model Updates: 331,026
Cumulative Timesteps: 2,760,721,074

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.11136
Policy Entropy: 4.08016
Value Function Loss: 0.00562

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.02956
Policy Update Magnitude: 0.29635
Value Function Update Magnitude: 0.35963

Collected Steps per Second: 15,574.23725
Overall Steps per Second: 7,322.12051

Timestep Collection Time: 3.21120
Timestep Consumption Time: 3.61906
PPO Batch Consumption Time: 0.48573
Total Iteration Time: 6.83026

Cumulative Model Updates: 331,032
Cumulative Timesteps: 2,760,771,086

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2760771086...
Checkpoint 2760771086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.66850
Policy Entropy: 4.13588
Value Function Loss: 0.00458

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02453
Policy Update Magnitude: 0.26881
Value Function Update Magnitude: 0.36487

Collected Steps per Second: 16,218.47056
Overall Steps per Second: 7,698.66035

Timestep Collection Time: 3.08401
Timestep Consumption Time: 3.41296
PPO Batch Consumption Time: 0.43525
Total Iteration Time: 6.49697

Cumulative Model Updates: 331,038
Cumulative Timesteps: 2,760,821,104

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.99656
Policy Entropy: 4.14357
Value Function Loss: 0.00435

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.01856
Policy Update Magnitude: 0.24213
Value Function Update Magnitude: 0.34152

Collected Steps per Second: 16,499.14991
Overall Steps per Second: 8,805.55094

Timestep Collection Time: 3.03204
Timestep Consumption Time: 2.64915
PPO Batch Consumption Time: 0.31023
Total Iteration Time: 5.68119

Cumulative Model Updates: 331,044
Cumulative Timesteps: 2,760,871,130

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2760871130...
Checkpoint 2760871130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.81482
Policy Entropy: 4.12061
Value Function Loss: 0.00548

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01826
Policy Update Magnitude: 0.24623
Value Function Update Magnitude: 0.33117

Collected Steps per Second: 18,090.31078
Overall Steps per Second: 9,298.42998

Timestep Collection Time: 2.76468
Timestep Consumption Time: 2.61407
PPO Batch Consumption Time: 0.30667
Total Iteration Time: 5.37876

Cumulative Model Updates: 331,050
Cumulative Timesteps: 2,760,921,144

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.68173
Policy Entropy: 4.08450
Value Function Loss: 0.00552

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.02850
Policy Update Magnitude: 0.27056
Value Function Update Magnitude: 0.34911

Collected Steps per Second: 17,204.32178
Overall Steps per Second: 8,906.82152

Timestep Collection Time: 2.90834
Timestep Consumption Time: 2.70938
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 5.61772

Cumulative Model Updates: 331,056
Cumulative Timesteps: 2,760,971,180

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2760971180...
Checkpoint 2760971180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.99276
Policy Entropy: 4.12473
Value Function Loss: 0.00442

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02334
Policy Update Magnitude: 0.26092
Value Function Update Magnitude: 0.33273

Collected Steps per Second: 16,078.90831
Overall Steps per Second: 8,948.88530

Timestep Collection Time: 3.11203
Timestep Consumption Time: 2.47951
PPO Batch Consumption Time: 0.30060
Total Iteration Time: 5.59153

Cumulative Model Updates: 331,062
Cumulative Timesteps: 2,761,021,218

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.96142
Policy Entropy: 4.14648
Value Function Loss: 0.00405

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02071
Policy Update Magnitude: 0.24668
Value Function Update Magnitude: 0.30809

Collected Steps per Second: 17,443.53302
Overall Steps per Second: 9,065.58627

Timestep Collection Time: 2.86639
Timestep Consumption Time: 2.64897
PPO Batch Consumption Time: 0.30346
Total Iteration Time: 5.51536

Cumulative Model Updates: 331,068
Cumulative Timesteps: 2,761,071,218

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2761071218...
Checkpoint 2761071218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.04455
Policy Entropy: 4.15622
Value Function Loss: 0.00366

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.01740
Policy Update Magnitude: 0.23959
Value Function Update Magnitude: 0.30756

Collected Steps per Second: 17,369.94193
Overall Steps per Second: 8,940.05257

Timestep Collection Time: 2.87877
Timestep Consumption Time: 2.71449
PPO Batch Consumption Time: 0.31246
Total Iteration Time: 5.59326

Cumulative Model Updates: 331,074
Cumulative Timesteps: 2,761,121,222

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.65610
Policy Entropy: 4.13907
Value Function Loss: 0.00400

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02207
Policy Update Magnitude: 0.23806
Value Function Update Magnitude: 0.31337

Collected Steps per Second: 18,232.90873
Overall Steps per Second: 9,538.40033

Timestep Collection Time: 2.74240
Timestep Consumption Time: 2.49977
PPO Batch Consumption Time: 0.29711
Total Iteration Time: 5.24218

Cumulative Model Updates: 331,080
Cumulative Timesteps: 2,761,171,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2761171224...
Checkpoint 2761171224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.60418
Policy Entropy: 4.12572
Value Function Loss: 0.00459

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02180
Policy Update Magnitude: 0.25139
Value Function Update Magnitude: 0.34262

Collected Steps per Second: 19,265.30646
Overall Steps per Second: 9,483.19830

Timestep Collection Time: 2.59658
Timestep Consumption Time: 2.67843
PPO Batch Consumption Time: 0.31261
Total Iteration Time: 5.27501

Cumulative Model Updates: 331,086
Cumulative Timesteps: 2,761,221,248

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.59875
Policy Entropy: 4.11069
Value Function Loss: 0.00465

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02284
Policy Update Magnitude: 0.26247
Value Function Update Magnitude: 0.34986

Collected Steps per Second: 18,602.17812
Overall Steps per Second: 9,774.67303

Timestep Collection Time: 2.68872
Timestep Consumption Time: 2.42818
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 5.11690

Cumulative Model Updates: 331,092
Cumulative Timesteps: 2,761,271,264

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2761271264...
Checkpoint 2761271264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.42528
Policy Entropy: 4.10657
Value Function Loss: 0.00449

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.02383
Policy Update Magnitude: 0.26120
Value Function Update Magnitude: 0.35758

Collected Steps per Second: 22,753.46294
Overall Steps per Second: 10,126.66225

Timestep Collection Time: 2.19782
Timestep Consumption Time: 2.74043
PPO Batch Consumption Time: 0.32383
Total Iteration Time: 4.93825

Cumulative Model Updates: 331,098
Cumulative Timesteps: 2,761,321,272

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.22554
Policy Entropy: 4.12421
Value Function Loss: 0.00394

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02139
Policy Update Magnitude: 0.24752
Value Function Update Magnitude: 0.35283

Collected Steps per Second: 21,561.39246
Overall Steps per Second: 10,017.88172

Timestep Collection Time: 2.31961
Timestep Consumption Time: 2.67286
PPO Batch Consumption Time: 0.29833
Total Iteration Time: 4.99247

Cumulative Model Updates: 331,104
Cumulative Timesteps: 2,761,371,286

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2761371286...
Checkpoint 2761371286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.74676
Policy Entropy: 4.15904
Value Function Loss: 0.00389

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.01801
Policy Update Magnitude: 0.23917
Value Function Update Magnitude: 0.34273

Collected Steps per Second: 20,103.70137
Overall Steps per Second: 10,238.18667

Timestep Collection Time: 2.48770
Timestep Consumption Time: 2.39715
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.88485

Cumulative Model Updates: 331,110
Cumulative Timesteps: 2,761,421,298

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.45972
Policy Entropy: 4.16598
Value Function Loss: 0.00430

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01674
Policy Update Magnitude: 0.24499
Value Function Update Magnitude: 0.34075

Collected Steps per Second: 21,959.11483
Overall Steps per Second: 10,509.85813

Timestep Collection Time: 2.27869
Timestep Consumption Time: 2.48236
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.76105

Cumulative Model Updates: 331,116
Cumulative Timesteps: 2,761,471,336

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2761471336...
Checkpoint 2761471336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.26207
Policy Entropy: 4.16331
Value Function Loss: 0.00395

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02020
Policy Update Magnitude: 0.24216
Value Function Update Magnitude: 0.32761

Collected Steps per Second: 18,726.44244
Overall Steps per Second: 9,579.37388

Timestep Collection Time: 2.67130
Timestep Consumption Time: 2.55075
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 5.22205

Cumulative Model Updates: 331,122
Cumulative Timesteps: 2,761,521,360

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.10427
Policy Entropy: 4.11030
Value Function Loss: 0.00480

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02286
Policy Update Magnitude: 0.24689
Value Function Update Magnitude: 0.32417

Collected Steps per Second: 22,142.26331
Overall Steps per Second: 10,170.90331

Timestep Collection Time: 2.25858
Timestep Consumption Time: 2.65839
PPO Batch Consumption Time: 0.32465
Total Iteration Time: 4.91697

Cumulative Model Updates: 331,128
Cumulative Timesteps: 2,761,571,370

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2761571370...
Checkpoint 2761571370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.42490
Policy Entropy: 4.09177
Value Function Loss: 0.00508

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02213
Policy Update Magnitude: 0.25525
Value Function Update Magnitude: 0.34602

Collected Steps per Second: 19,076.76948
Overall Steps per Second: 9,306.00407

Timestep Collection Time: 2.62193
Timestep Consumption Time: 2.75288
PPO Batch Consumption Time: 0.32456
Total Iteration Time: 5.37481

Cumulative Model Updates: 331,134
Cumulative Timesteps: 2,761,621,388

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.19792
Policy Entropy: 4.09400
Value Function Loss: 0.00559

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.02567
Policy Update Magnitude: 0.26723
Value Function Update Magnitude: 0.36639

Collected Steps per Second: 19,567.03630
Overall Steps per Second: 9,548.88084

Timestep Collection Time: 2.55695
Timestep Consumption Time: 2.68261
PPO Batch Consumption Time: 0.30926
Total Iteration Time: 5.23957

Cumulative Model Updates: 331,140
Cumulative Timesteps: 2,761,671,420

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2761671420...
Checkpoint 2761671420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.85538
Policy Entropy: 4.12722
Value Function Loss: 0.00514

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.02332
Policy Update Magnitude: 0.26703
Value Function Update Magnitude: 0.37063

Collected Steps per Second: 19,320.50583
Overall Steps per Second: 9,414.94371

Timestep Collection Time: 2.58937
Timestep Consumption Time: 2.72431
PPO Batch Consumption Time: 0.31840
Total Iteration Time: 5.31368

Cumulative Model Updates: 331,146
Cumulative Timesteps: 2,761,721,448

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.92006
Policy Entropy: 4.14918
Value Function Loss: 0.00479

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.02163
Policy Update Magnitude: 0.25867
Value Function Update Magnitude: 0.35041

Collected Steps per Second: 19,196.58864
Overall Steps per Second: 9,351.81362

Timestep Collection Time: 2.60494
Timestep Consumption Time: 2.74226
PPO Batch Consumption Time: 0.31531
Total Iteration Time: 5.34720

Cumulative Model Updates: 331,152
Cumulative Timesteps: 2,761,771,454

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2761771454...
Checkpoint 2761771454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.30824
Policy Entropy: 4.13457
Value Function Loss: 0.00474

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02335
Policy Update Magnitude: 0.25456
Value Function Update Magnitude: 0.32862

Collected Steps per Second: 18,888.13877
Overall Steps per Second: 9,374.65546

Timestep Collection Time: 2.64833
Timestep Consumption Time: 2.68755
PPO Batch Consumption Time: 0.31435
Total Iteration Time: 5.33588

Cumulative Model Updates: 331,158
Cumulative Timesteps: 2,761,821,476

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.00625
Policy Entropy: 4.11802
Value Function Loss: 0.00489

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.02728
Policy Update Magnitude: 0.26491
Value Function Update Magnitude: 0.31198

Collected Steps per Second: 19,916.65023
Overall Steps per Second: 9,726.53279

Timestep Collection Time: 2.51197
Timestep Consumption Time: 2.63169
PPO Batch Consumption Time: 0.30061
Total Iteration Time: 5.14366

Cumulative Model Updates: 331,164
Cumulative Timesteps: 2,761,871,506

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2761871506...
Checkpoint 2761871506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.48726
Policy Entropy: 4.11956
Value Function Loss: 0.00590

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.02885
Policy Update Magnitude: 0.27451
Value Function Update Magnitude: 0.34378

Collected Steps per Second: 22,221.09451
Overall Steps per Second: 10,378.22773

Timestep Collection Time: 2.25038
Timestep Consumption Time: 2.56797
PPO Batch Consumption Time: 0.29862
Total Iteration Time: 4.81836

Cumulative Model Updates: 331,170
Cumulative Timesteps: 2,761,921,512

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.28663
Policy Entropy: 4.11923
Value Function Loss: 0.00544

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.02576
Policy Update Magnitude: 0.27366
Value Function Update Magnitude: 0.37768

Collected Steps per Second: 19,774.58710
Overall Steps per Second: 9,676.90491

Timestep Collection Time: 2.53001
Timestep Consumption Time: 2.64003
PPO Batch Consumption Time: 0.31793
Total Iteration Time: 5.17004

Cumulative Model Updates: 331,176
Cumulative Timesteps: 2,761,971,542

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2761971542...
Checkpoint 2761971542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.53579
Policy Entropy: 4.12937
Value Function Loss: 0.00538

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02403
Policy Update Magnitude: 0.26259
Value Function Update Magnitude: 0.37164

Collected Steps per Second: 19,769.43406
Overall Steps per Second: 9,697.36536

Timestep Collection Time: 2.53057
Timestep Consumption Time: 2.62835
PPO Batch Consumption Time: 0.30334
Total Iteration Time: 5.15893

Cumulative Model Updates: 331,182
Cumulative Timesteps: 2,762,021,570

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.17726
Policy Entropy: 4.10446
Value Function Loss: 0.00466

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02419
Policy Update Magnitude: 0.25509
Value Function Update Magnitude: 0.35366

Collected Steps per Second: 22,259.96622
Overall Steps per Second: 10,615.43336

Timestep Collection Time: 2.24618
Timestep Consumption Time: 2.46394
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.71012

Cumulative Model Updates: 331,188
Cumulative Timesteps: 2,762,071,570

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2762071570...
Checkpoint 2762071570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.38422
Policy Entropy: 4.11158
Value Function Loss: 0.00469

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02201
Policy Update Magnitude: 0.25331
Value Function Update Magnitude: 0.33551

Collected Steps per Second: 22,200.77957
Overall Steps per Second: 10,993.47756

Timestep Collection Time: 2.25262
Timestep Consumption Time: 2.29644
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.54906

Cumulative Model Updates: 331,194
Cumulative Timesteps: 2,762,121,580

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.76805
Policy Entropy: 4.10836
Value Function Loss: 0.00494

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02183
Policy Update Magnitude: 0.24845
Value Function Update Magnitude: 0.32011

Collected Steps per Second: 22,289.12197
Overall Steps per Second: 10,664.76146

Timestep Collection Time: 2.24405
Timestep Consumption Time: 2.44597
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.69003

Cumulative Model Updates: 331,200
Cumulative Timesteps: 2,762,171,598

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2762171598...
Checkpoint 2762171598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.36335
Policy Entropy: 4.15691
Value Function Loss: 0.00458

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.01963
Policy Update Magnitude: 0.23757
Value Function Update Magnitude: 0.30980

Collected Steps per Second: 22,142.19053
Overall Steps per Second: 10,689.66026

Timestep Collection Time: 2.25886
Timestep Consumption Time: 2.42006
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.67891

Cumulative Model Updates: 331,206
Cumulative Timesteps: 2,762,221,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.53533
Policy Entropy: 4.15243
Value Function Loss: 0.00442

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.01654
Policy Update Magnitude: 0.23404
Value Function Update Magnitude: 0.30336

Collected Steps per Second: 23,149.93998
Overall Steps per Second: 10,678.55394

Timestep Collection Time: 2.16001
Timestep Consumption Time: 2.52265
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.68266

Cumulative Model Updates: 331,212
Cumulative Timesteps: 2,762,271,618

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2762271618...
Checkpoint 2762271618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.80022
Policy Entropy: 4.12807
Value Function Loss: 0.00525

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.01934
Policy Update Magnitude: 0.25707
Value Function Update Magnitude: 0.31078

Collected Steps per Second: 19,118.83167
Overall Steps per Second: 9,269.92999

Timestep Collection Time: 2.61564
Timestep Consumption Time: 2.77901
PPO Batch Consumption Time: 0.32598
Total Iteration Time: 5.39465

Cumulative Model Updates: 331,218
Cumulative Timesteps: 2,762,321,626

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.76388
Policy Entropy: 4.07652
Value Function Loss: 0.00552

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.02659
Policy Update Magnitude: 0.28017
Value Function Update Magnitude: 0.35117

Collected Steps per Second: 19,464.83878
Overall Steps per Second: 9,436.92196

Timestep Collection Time: 2.56884
Timestep Consumption Time: 2.72971
PPO Batch Consumption Time: 0.32494
Total Iteration Time: 5.29855

Cumulative Model Updates: 331,224
Cumulative Timesteps: 2,762,371,628

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2762371628...
Checkpoint 2762371628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.39450
Policy Entropy: 4.08551
Value Function Loss: 0.00535

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02663
Policy Update Magnitude: 0.27861
Value Function Update Magnitude: 0.36914

Collected Steps per Second: 23,000.25603
Overall Steps per Second: 10,693.56308

Timestep Collection Time: 2.17476
Timestep Consumption Time: 2.50282
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.67758

Cumulative Model Updates: 331,230
Cumulative Timesteps: 2,762,421,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.81603
Policy Entropy: 4.11108
Value Function Loss: 0.00464

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02561
Policy Update Magnitude: 0.26468
Value Function Update Magnitude: 0.36165

Collected Steps per Second: 22,396.51188
Overall Steps per Second: 10,121.24052

Timestep Collection Time: 2.23249
Timestep Consumption Time: 2.70762
PPO Batch Consumption Time: 0.31386
Total Iteration Time: 4.94011

Cumulative Model Updates: 331,236
Cumulative Timesteps: 2,762,471,648

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2762471648...
Checkpoint 2762471648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.22724
Policy Entropy: 4.17108
Value Function Loss: 0.00352

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02162
Policy Update Magnitude: 0.24789
Value Function Update Magnitude: 0.33386

Collected Steps per Second: 19,468.04145
Overall Steps per Second: 9,599.53444

Timestep Collection Time: 2.56872
Timestep Consumption Time: 2.64070
PPO Batch Consumption Time: 0.31725
Total Iteration Time: 5.20942

Cumulative Model Updates: 331,242
Cumulative Timesteps: 2,762,521,656

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.66697
Policy Entropy: 4.18726
Value Function Loss: 0.00396

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.01959
Policy Update Magnitude: 0.23974
Value Function Update Magnitude: 0.29054

Collected Steps per Second: 19,976.94218
Overall Steps per Second: 10,098.99177

Timestep Collection Time: 2.50319
Timestep Consumption Time: 2.44840
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.95158

Cumulative Model Updates: 331,248
Cumulative Timesteps: 2,762,571,662

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2762571662...
Checkpoint 2762571662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.20712
Policy Entropy: 4.16161
Value Function Loss: 0.00444

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.01692
Policy Update Magnitude: 0.23337
Value Function Update Magnitude: 0.27644

Collected Steps per Second: 22,432.80416
Overall Steps per Second: 10,569.36261

Timestep Collection Time: 2.23013
Timestep Consumption Time: 2.50318
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.73330

Cumulative Model Updates: 331,254
Cumulative Timesteps: 2,762,621,690

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.33458
Policy Entropy: 4.12074
Value Function Loss: 0.00524

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02019
Policy Update Magnitude: 0.25407
Value Function Update Magnitude: 0.30283

Collected Steps per Second: 23,224.04847
Overall Steps per Second: 10,874.95478

Timestep Collection Time: 2.15423
Timestep Consumption Time: 2.44625
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.60048

Cumulative Model Updates: 331,260
Cumulative Timesteps: 2,762,671,720

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2762671720...
Checkpoint 2762671720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.85560
Policy Entropy: 4.12571
Value Function Loss: 0.00512

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02285
Policy Update Magnitude: 0.26297
Value Function Update Magnitude: 0.32785

Collected Steps per Second: 19,715.51282
Overall Steps per Second: 9,488.29699

Timestep Collection Time: 2.53719
Timestep Consumption Time: 2.73478
PPO Batch Consumption Time: 0.31972
Total Iteration Time: 5.27197

Cumulative Model Updates: 331,266
Cumulative Timesteps: 2,762,721,742

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.21336
Policy Entropy: 4.15311
Value Function Loss: 0.00529

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02117
Policy Update Magnitude: 0.27439
Value Function Update Magnitude: 0.35029

Collected Steps per Second: 19,304.74736
Overall Steps per Second: 9,423.82291

Timestep Collection Time: 2.59107
Timestep Consumption Time: 2.71675
PPO Batch Consumption Time: 0.31833
Total Iteration Time: 5.30782

Cumulative Model Updates: 331,272
Cumulative Timesteps: 2,762,771,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2762771762...
Checkpoint 2762771762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.65604
Policy Entropy: 4.17529
Value Function Loss: 0.00502

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02022
Policy Update Magnitude: 0.26437
Value Function Update Magnitude: 0.34708

Collected Steps per Second: 19,764.25473
Overall Steps per Second: 9,553.86047

Timestep Collection Time: 2.53053
Timestep Consumption Time: 2.70442
PPO Batch Consumption Time: 0.31439
Total Iteration Time: 5.23495

Cumulative Model Updates: 331,278
Cumulative Timesteps: 2,762,821,776

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.05493
Policy Entropy: 4.18370
Value Function Loss: 0.00537

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.01983
Policy Update Magnitude: 0.26442
Value Function Update Magnitude: 0.35004

Collected Steps per Second: 19,703.90948
Overall Steps per Second: 9,416.67030

Timestep Collection Time: 2.53818
Timestep Consumption Time: 2.77283
PPO Batch Consumption Time: 0.31785
Total Iteration Time: 5.31101

Cumulative Model Updates: 331,284
Cumulative Timesteps: 2,762,871,788

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2762871788...
Checkpoint 2762871788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.73047
Policy Entropy: 4.19839
Value Function Loss: 0.00468

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.01809
Policy Update Magnitude: 0.24406
Value Function Update Magnitude: 0.34203

Collected Steps per Second: 19,190.40678
Overall Steps per Second: 9,500.32891

Timestep Collection Time: 2.60557
Timestep Consumption Time: 2.65761
PPO Batch Consumption Time: 0.32641
Total Iteration Time: 5.26319

Cumulative Model Updates: 331,290
Cumulative Timesteps: 2,762,921,790

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.46030
Policy Entropy: 4.18461
Value Function Loss: 0.00460

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.01519
Policy Update Magnitude: 0.23137
Value Function Update Magnitude: 0.31936

Collected Steps per Second: 19,234.80628
Overall Steps per Second: 9,694.26819

Timestep Collection Time: 2.60091
Timestep Consumption Time: 2.55967
PPO Batch Consumption Time: 0.29616
Total Iteration Time: 5.16058

Cumulative Model Updates: 331,296
Cumulative Timesteps: 2,762,971,818

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2762971818...
Checkpoint 2762971818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.26762
Policy Entropy: 4.18066
Value Function Loss: 0.00403

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.01918
Policy Update Magnitude: 0.22795
Value Function Update Magnitude: 0.29633

Collected Steps per Second: 19,506.98522
Overall Steps per Second: 9,882.92107

Timestep Collection Time: 2.56472
Timestep Consumption Time: 2.49755
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 5.06227

Cumulative Model Updates: 331,302
Cumulative Timesteps: 2,763,021,848

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.19952
Policy Entropy: 4.15011
Value Function Loss: 0.00439

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.01827
Policy Update Magnitude: 0.23066
Value Function Update Magnitude: 0.27696

Collected Steps per Second: 20,907.24973
Overall Steps per Second: 10,124.63533

Timestep Collection Time: 2.39209
Timestep Consumption Time: 2.54755
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.93963

Cumulative Model Updates: 331,308
Cumulative Timesteps: 2,763,071,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2763071860...
Checkpoint 2763071860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.03637
Policy Entropy: 4.11561
Value Function Loss: 0.00517

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.01972
Policy Update Magnitude: 0.24181
Value Function Update Magnitude: 0.29100

Collected Steps per Second: 17,681.84658
Overall Steps per Second: 9,078.02600

Timestep Collection Time: 2.82934
Timestep Consumption Time: 2.68155
PPO Batch Consumption Time: 0.29814
Total Iteration Time: 5.51089

Cumulative Model Updates: 331,314
Cumulative Timesteps: 2,763,121,888

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.76848
Policy Entropy: 4.08774
Value Function Loss: 0.00613

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02080
Policy Update Magnitude: 0.26546
Value Function Update Magnitude: 0.33812

Collected Steps per Second: 21,635.25542
Overall Steps per Second: 10,302.60987

Timestep Collection Time: 2.31206
Timestep Consumption Time: 2.54321
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 4.85527

Cumulative Model Updates: 331,320
Cumulative Timesteps: 2,763,171,910

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2763171910...
Checkpoint 2763171910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.20884
Policy Entropy: 4.10819
Value Function Loss: 0.00568

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02129
Policy Update Magnitude: 0.27547
Value Function Update Magnitude: 0.34146

Collected Steps per Second: 20,662.66855
Overall Steps per Second: 10,011.61503

Timestep Collection Time: 2.42079
Timestep Consumption Time: 2.57541
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.99620

Cumulative Model Updates: 331,326
Cumulative Timesteps: 2,763,221,930

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.14117
Policy Entropy: 4.14472
Value Function Loss: 0.00514

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.01941
Policy Update Magnitude: 0.27004
Value Function Update Magnitude: 0.33545

Collected Steps per Second: 21,598.79799
Overall Steps per Second: 10,371.54182

Timestep Collection Time: 2.31652
Timestep Consumption Time: 2.50764
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.82416

Cumulative Model Updates: 331,332
Cumulative Timesteps: 2,763,271,964

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2763271964...
Checkpoint 2763271964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.56461
Policy Entropy: 4.15423
Value Function Loss: 0.00454

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.01910
Policy Update Magnitude: 0.25673
Value Function Update Magnitude: 0.33492

Collected Steps per Second: 21,419.37407
Overall Steps per Second: 10,375.65821

Timestep Collection Time: 2.33452
Timestep Consumption Time: 2.48483
PPO Batch Consumption Time: 0.30424
Total Iteration Time: 4.81936

Cumulative Model Updates: 331,338
Cumulative Timesteps: 2,763,321,968

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.64924
Policy Entropy: 4.14137
Value Function Loss: 0.00444

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.01996
Policy Update Magnitude: 0.24666
Value Function Update Magnitude: 0.32075

Collected Steps per Second: 22,111.15223
Overall Steps per Second: 10,441.61310

Timestep Collection Time: 2.26230
Timestep Consumption Time: 2.52834
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.79064

Cumulative Model Updates: 331,344
Cumulative Timesteps: 2,763,371,990

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2763371990...
Checkpoint 2763371990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.37176
Policy Entropy: 4.16253
Value Function Loss: 0.00389

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02075
Policy Update Magnitude: 0.23482
Value Function Update Magnitude: 0.30465

Collected Steps per Second: 22,172.51050
Overall Steps per Second: 10,375.07804

Timestep Collection Time: 2.25523
Timestep Consumption Time: 2.56440
PPO Batch Consumption Time: 0.30184
Total Iteration Time: 4.81963

Cumulative Model Updates: 331,350
Cumulative Timesteps: 2,763,421,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.59477
Policy Entropy: 4.16971
Value Function Loss: 0.00344

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.01894
Policy Update Magnitude: 0.22166
Value Function Update Magnitude: 0.28688

Collected Steps per Second: 22,612.79015
Overall Steps per Second: 10,617.48145

Timestep Collection Time: 2.21149
Timestep Consumption Time: 2.49848
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.70997

Cumulative Model Updates: 331,356
Cumulative Timesteps: 2,763,472,002

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2763472002...
Checkpoint 2763472002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.52548
Policy Entropy: 4.15203
Value Function Loss: 0.00377

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.01664
Policy Update Magnitude: 0.22843
Value Function Update Magnitude: 0.27638

Collected Steps per Second: 22,017.86153
Overall Steps per Second: 10,672.87791

Timestep Collection Time: 2.27225
Timestep Consumption Time: 2.41534
PPO Batch Consumption Time: 0.27701
Total Iteration Time: 4.68758

Cumulative Model Updates: 331,362
Cumulative Timesteps: 2,763,522,032

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.10874
Policy Entropy: 4.12734
Value Function Loss: 0.00390

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02053
Policy Update Magnitude: 0.24093
Value Function Update Magnitude: 0.28312

Collected Steps per Second: 22,392.49547
Overall Steps per Second: 10,836.02833

Timestep Collection Time: 2.23387
Timestep Consumption Time: 2.38239
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.61627

Cumulative Model Updates: 331,368
Cumulative Timesteps: 2,763,572,054

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2763572054...
Checkpoint 2763572054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.32179
Policy Entropy: 4.12222
Value Function Loss: 0.00443

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.01938
Policy Update Magnitude: 0.24838
Value Function Update Magnitude: 0.30687

Collected Steps per Second: 22,670.65380
Overall Steps per Second: 10,525.76978

Timestep Collection Time: 2.20549
Timestep Consumption Time: 2.54475
PPO Batch Consumption Time: 0.29640
Total Iteration Time: 4.75025

Cumulative Model Updates: 331,374
Cumulative Timesteps: 2,763,622,054

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.46846
Policy Entropy: 4.16220
Value Function Loss: 0.00342

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.01787
Policy Update Magnitude: 0.24015
Value Function Update Magnitude: 0.31175

Collected Steps per Second: 22,784.13427
Overall Steps per Second: 10,610.54651

Timestep Collection Time: 2.19469
Timestep Consumption Time: 2.51798
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.71267

Cumulative Model Updates: 331,380
Cumulative Timesteps: 2,763,672,058

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2763672058...
Checkpoint 2763672058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.64729
Policy Entropy: 4.17129
Value Function Loss: 0.00391

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.01727
Policy Update Magnitude: 0.24399
Value Function Update Magnitude: 0.31925

Collected Steps per Second: 22,722.35850
Overall Steps per Second: 10,957.15889

Timestep Collection Time: 2.20048
Timestep Consumption Time: 2.36275
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.56323

Cumulative Model Updates: 331,386
Cumulative Timesteps: 2,763,722,058

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.19086
Policy Entropy: 4.17364
Value Function Loss: 0.00392

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01586
Policy Update Magnitude: 0.24172
Value Function Update Magnitude: 0.32304

Collected Steps per Second: 22,067.00550
Overall Steps per Second: 10,225.08788

Timestep Collection Time: 2.26655
Timestep Consumption Time: 2.62495
PPO Batch Consumption Time: 0.31137
Total Iteration Time: 4.89150

Cumulative Model Updates: 331,392
Cumulative Timesteps: 2,763,772,074

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2763772074...
Checkpoint 2763772074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.06163
Policy Entropy: 4.13431
Value Function Loss: 0.00478

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.01812
Policy Update Magnitude: 0.24792
Value Function Update Magnitude: 0.32571

Collected Steps per Second: 22,030.76882
Overall Steps per Second: 10,568.69483

Timestep Collection Time: 2.27064
Timestep Consumption Time: 2.46258
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.73322

Cumulative Model Updates: 331,398
Cumulative Timesteps: 2,763,822,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.83681
Policy Entropy: 4.11826
Value Function Loss: 0.00481

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02018
Policy Update Magnitude: 0.25809
Value Function Update Magnitude: 0.33165

Collected Steps per Second: 21,813.77024
Overall Steps per Second: 10,631.19364

Timestep Collection Time: 2.29231
Timestep Consumption Time: 2.41120
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.70352

Cumulative Model Updates: 331,404
Cumulative Timesteps: 2,763,872,102

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2763872102...
Checkpoint 2763872102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.53199
Policy Entropy: 4.09575
Value Function Loss: 0.00460

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02245
Policy Update Magnitude: 0.25925
Value Function Update Magnitude: 0.32769

Collected Steps per Second: 22,031.77736
Overall Steps per Second: 10,472.82560

Timestep Collection Time: 2.26954
Timestep Consumption Time: 2.50491
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.77445

Cumulative Model Updates: 331,410
Cumulative Timesteps: 2,763,922,104

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.16587
Policy Entropy: 4.09853
Value Function Loss: 0.00495

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02218
Policy Update Magnitude: 0.27172
Value Function Update Magnitude: 0.32334

Collected Steps per Second: 21,852.23057
Overall Steps per Second: 10,093.42094

Timestep Collection Time: 2.28910
Timestep Consumption Time: 2.66680
PPO Batch Consumption Time: 0.30571
Total Iteration Time: 4.95590

Cumulative Model Updates: 331,416
Cumulative Timesteps: 2,763,972,126

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2763972126...
Checkpoint 2763972126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.37594
Policy Entropy: 4.09946
Value Function Loss: 0.00462

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02670
Policy Update Magnitude: 0.26900
Value Function Update Magnitude: 0.33693

Collected Steps per Second: 20,281.52476
Overall Steps per Second: 10,190.75454

Timestep Collection Time: 2.46628
Timestep Consumption Time: 2.44209
PPO Batch Consumption Time: 0.30116
Total Iteration Time: 4.90837

Cumulative Model Updates: 331,422
Cumulative Timesteps: 2,764,022,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.26815
Policy Entropy: 4.10314
Value Function Loss: 0.00458

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.02647
Policy Update Magnitude: 0.26495
Value Function Update Magnitude: 0.34750

Collected Steps per Second: 20,199.73472
Overall Steps per Second: 10,047.77927

Timestep Collection Time: 2.47677
Timestep Consumption Time: 2.50244
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.97921

Cumulative Model Updates: 331,428
Cumulative Timesteps: 2,764,072,176

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2764072176...
Checkpoint 2764072176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.19009
Policy Entropy: 4.12578
Value Function Loss: 0.00464

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02434
Policy Update Magnitude: 0.26517
Value Function Update Magnitude: 0.34132

Collected Steps per Second: 22,319.92702
Overall Steps per Second: 10,021.24439

Timestep Collection Time: 2.24024
Timestep Consumption Time: 2.74936
PPO Batch Consumption Time: 0.34195
Total Iteration Time: 4.98960

Cumulative Model Updates: 331,434
Cumulative Timesteps: 2,764,122,178

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.92712
Policy Entropy: 4.11294
Value Function Loss: 0.00500

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02194
Policy Update Magnitude: 0.25454
Value Function Update Magnitude: 0.33794

Collected Steps per Second: 21,317.60586
Overall Steps per Second: 10,287.24948

Timestep Collection Time: 2.34623
Timestep Consumption Time: 2.51571
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.86194

Cumulative Model Updates: 331,440
Cumulative Timesteps: 2,764,172,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2764172194...
Checkpoint 2764172194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.84701
Policy Entropy: 4.10458
Value Function Loss: 0.00514

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02129
Policy Update Magnitude: 0.25957
Value Function Update Magnitude: 0.34805

Collected Steps per Second: 21,716.69303
Overall Steps per Second: 10,551.64766

Timestep Collection Time: 2.30293
Timestep Consumption Time: 2.43680
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.73973

Cumulative Model Updates: 331,446
Cumulative Timesteps: 2,764,222,206

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.94077
Policy Entropy: 4.09172
Value Function Loss: 0.00537

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02091
Policy Update Magnitude: 0.26821
Value Function Update Magnitude: 0.36411

Collected Steps per Second: 20,670.84352
Overall Steps per Second: 10,574.13211

Timestep Collection Time: 2.41945
Timestep Consumption Time: 2.31021
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.72966

Cumulative Model Updates: 331,452
Cumulative Timesteps: 2,764,272,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2764272218...
Checkpoint 2764272218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.10865
Policy Entropy: 4.09009
Value Function Loss: 0.00529

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02298
Policy Update Magnitude: 0.27559
Value Function Update Magnitude: 0.37366

Collected Steps per Second: 16,719.98199
Overall Steps per Second: 8,815.86543

Timestep Collection Time: 2.99151
Timestep Consumption Time: 2.68212
PPO Batch Consumption Time: 0.30265
Total Iteration Time: 5.67363

Cumulative Model Updates: 331,458
Cumulative Timesteps: 2,764,322,236

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.61288
Policy Entropy: 4.10996
Value Function Loss: 0.00478

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.02421
Policy Update Magnitude: 0.27085
Value Function Update Magnitude: 0.37742

Collected Steps per Second: 19,558.21058
Overall Steps per Second: 9,536.94022

Timestep Collection Time: 2.55770
Timestep Consumption Time: 2.68759
PPO Batch Consumption Time: 0.31559
Total Iteration Time: 5.24529

Cumulative Model Updates: 331,464
Cumulative Timesteps: 2,764,372,260

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2764372260...
Checkpoint 2764372260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.62237
Policy Entropy: 4.12291
Value Function Loss: 0.00432

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.02237
Policy Update Magnitude: 0.25569
Value Function Update Magnitude: 0.37011

Collected Steps per Second: 17,774.23805
Overall Steps per Second: 9,045.50705

Timestep Collection Time: 2.81554
Timestep Consumption Time: 2.71693
PPO Batch Consumption Time: 0.30763
Total Iteration Time: 5.53247

Cumulative Model Updates: 331,470
Cumulative Timesteps: 2,764,422,304

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.08851
Policy Entropy: 4.15040
Value Function Loss: 0.00354

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02079
Policy Update Magnitude: 0.23662
Value Function Update Magnitude: 0.34374

Collected Steps per Second: 20,460.67008
Overall Steps per Second: 10,030.86047

Timestep Collection Time: 2.44586
Timestep Consumption Time: 2.54314
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.98900

Cumulative Model Updates: 331,476
Cumulative Timesteps: 2,764,472,348

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2764472348...
Checkpoint 2764472348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.82399
Policy Entropy: 4.14348
Value Function Loss: 0.00369

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02049
Policy Update Magnitude: 0.22000
Value Function Update Magnitude: 0.30634

Collected Steps per Second: 22,020.85978
Overall Steps per Second: 10,566.76942

Timestep Collection Time: 2.27185
Timestep Consumption Time: 2.46262
PPO Batch Consumption Time: 0.28216
Total Iteration Time: 4.73446

Cumulative Model Updates: 331,482
Cumulative Timesteps: 2,764,522,376

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.63199
Policy Entropy: 4.14616
Value Function Loss: 0.00354

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.01723
Policy Update Magnitude: 0.21709
Value Function Update Magnitude: 0.29246

Collected Steps per Second: 22,133.50488
Overall Steps per Second: 10,466.35795

Timestep Collection Time: 2.25956
Timestep Consumption Time: 2.51880
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.77836

Cumulative Model Updates: 331,488
Cumulative Timesteps: 2,764,572,388

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2764572388...
Checkpoint 2764572388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.39572
Policy Entropy: 4.13016
Value Function Loss: 0.00364

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.01667
Policy Update Magnitude: 0.23153
Value Function Update Magnitude: 0.31256

Collected Steps per Second: 21,698.44962
Overall Steps per Second: 10,260.40224

Timestep Collection Time: 2.30431
Timestep Consumption Time: 2.56879
PPO Batch Consumption Time: 0.29754
Total Iteration Time: 4.87310

Cumulative Model Updates: 331,494
Cumulative Timesteps: 2,764,622,388

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.56930
Policy Entropy: 4.11512
Value Function Loss: 0.00416

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.01786
Policy Update Magnitude: 0.24797
Value Function Update Magnitude: 0.33909

Collected Steps per Second: 21,778.36885
Overall Steps per Second: 10,514.46650

Timestep Collection Time: 2.29705
Timestep Consumption Time: 2.46078
PPO Batch Consumption Time: 0.29697
Total Iteration Time: 4.75783

Cumulative Model Updates: 331,500
Cumulative Timesteps: 2,764,672,414

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2764672414...
Checkpoint 2764672414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.91665
Policy Entropy: 4.10664
Value Function Loss: 0.00537

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02035
Policy Update Magnitude: 0.26246
Value Function Update Magnitude: 0.35978

Collected Steps per Second: 21,711.44961
Overall Steps per Second: 10,405.15861

Timestep Collection Time: 2.30312
Timestep Consumption Time: 2.50258
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.80569

Cumulative Model Updates: 331,506
Cumulative Timesteps: 2,764,722,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.32293
Policy Entropy: 4.11736
Value Function Loss: 0.00554

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02118
Policy Update Magnitude: 0.26692
Value Function Update Magnitude: 0.36775

Collected Steps per Second: 21,701.37138
Overall Steps per Second: 10,429.40383

Timestep Collection Time: 2.30529
Timestep Consumption Time: 2.49153
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.79682

Cumulative Model Updates: 331,512
Cumulative Timesteps: 2,764,772,446

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2764772446...
Checkpoint 2764772446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.58257
Policy Entropy: 4.09956
Value Function Loss: 0.00585

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.01923
Policy Update Magnitude: 0.26623
Value Function Update Magnitude: 0.36879

Collected Steps per Second: 21,783.72315
Overall Steps per Second: 10,563.43218

Timestep Collection Time: 2.29649
Timestep Consumption Time: 2.43929
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.73577

Cumulative Model Updates: 331,518
Cumulative Timesteps: 2,764,822,472

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.27029
Policy Entropy: 4.07852
Value Function Loss: 0.00608

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02129
Policy Update Magnitude: 0.29029
Value Function Update Magnitude: 0.38008

Collected Steps per Second: 22,446.52294
Overall Steps per Second: 10,534.46369

Timestep Collection Time: 2.22885
Timestep Consumption Time: 2.52032
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.74917

Cumulative Model Updates: 331,524
Cumulative Timesteps: 2,764,872,502

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2764872502...
Checkpoint 2764872502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.22275
Policy Entropy: 4.06400
Value Function Loss: 0.00524

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.02694
Policy Update Magnitude: 0.28932
Value Function Update Magnitude: 0.40379

Collected Steps per Second: 21,898.48901
Overall Steps per Second: 10,382.77580

Timestep Collection Time: 2.28399
Timestep Consumption Time: 2.53322
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 4.81721

Cumulative Model Updates: 331,530
Cumulative Timesteps: 2,764,922,518

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.39602
Policy Entropy: 4.10136
Value Function Loss: 0.00458

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.02484
Policy Update Magnitude: 0.26584
Value Function Update Magnitude: 0.38957

Collected Steps per Second: 22,848.79525
Overall Steps per Second: 10,578.76498

Timestep Collection Time: 2.18944
Timestep Consumption Time: 2.53947
PPO Batch Consumption Time: 0.29728
Total Iteration Time: 4.72891

Cumulative Model Updates: 331,536
Cumulative Timesteps: 2,764,972,544

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2764972544...
Checkpoint 2764972544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.51564
Policy Entropy: 4.14805
Value Function Loss: 0.00373

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02007
Policy Update Magnitude: 0.24029
Value Function Update Magnitude: 0.34331

Collected Steps per Second: 21,820.58363
Overall Steps per Second: 10,386.87583

Timestep Collection Time: 2.29251
Timestep Consumption Time: 2.52356
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.81608

Cumulative Model Updates: 331,542
Cumulative Timesteps: 2,765,022,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.08407
Policy Entropy: 4.14108
Value Function Loss: 0.00408

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02052
Policy Update Magnitude: 0.23082
Value Function Update Magnitude: 0.30031

Collected Steps per Second: 21,261.65105
Overall Steps per Second: 10,396.76769

Timestep Collection Time: 2.35193
Timestep Consumption Time: 2.45783
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.80976

Cumulative Model Updates: 331,548
Cumulative Timesteps: 2,765,072,574

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2765072574...
Checkpoint 2765072574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.85973
Policy Entropy: 4.13535
Value Function Loss: 0.00441

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02177
Policy Update Magnitude: 0.24713
Value Function Update Magnitude: 0.29779

Collected Steps per Second: 22,087.57530
Overall Steps per Second: 10,332.42083

Timestep Collection Time: 2.26426
Timestep Consumption Time: 2.57604
PPO Batch Consumption Time: 0.30078
Total Iteration Time: 4.84030

Cumulative Model Updates: 331,554
Cumulative Timesteps: 2,765,122,586

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.20497
Policy Entropy: 4.11786
Value Function Loss: 0.00475

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02603
Policy Update Magnitude: 0.26866
Value Function Update Magnitude: 0.31747

Collected Steps per Second: 21,697.19615
Overall Steps per Second: 10,327.07982

Timestep Collection Time: 2.30454
Timestep Consumption Time: 2.53730
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.84183

Cumulative Model Updates: 331,560
Cumulative Timesteps: 2,765,172,588

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2765172588...
Checkpoint 2765172588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.72666
Policy Entropy: 4.09667
Value Function Loss: 0.00500

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.02776
Policy Update Magnitude: 0.26294
Value Function Update Magnitude: 0.33272

Collected Steps per Second: 19,747.59347
Overall Steps per Second: 10,108.54517

Timestep Collection Time: 2.53236
Timestep Consumption Time: 2.41474
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.94710

Cumulative Model Updates: 331,566
Cumulative Timesteps: 2,765,222,596

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.42988
Policy Entropy: 4.06060
Value Function Loss: 0.00544

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.02365
Policy Update Magnitude: 0.27580
Value Function Update Magnitude: 0.33596

Collected Steps per Second: 18,828.14130
Overall Steps per Second: 9,508.46718

Timestep Collection Time: 2.65666
Timestep Consumption Time: 2.60391
PPO Batch Consumption Time: 0.30600
Total Iteration Time: 5.26057

Cumulative Model Updates: 331,572
Cumulative Timesteps: 2,765,272,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2765272616...
Checkpoint 2765272616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.51196
Policy Entropy: 4.06216
Value Function Loss: 0.00511

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.02612
Policy Update Magnitude: 0.28380
Value Function Update Magnitude: 0.33874

Collected Steps per Second: 21,885.12711
Overall Steps per Second: 10,295.51530

Timestep Collection Time: 2.28530
Timestep Consumption Time: 2.57255
PPO Batch Consumption Time: 0.30487
Total Iteration Time: 4.85784

Cumulative Model Updates: 331,578
Cumulative Timesteps: 2,765,322,630

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.25845
Policy Entropy: 4.06627
Value Function Loss: 0.00508

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.02555
Policy Update Magnitude: 0.29467
Value Function Update Magnitude: 0.34389

Collected Steps per Second: 20,835.92557
Overall Steps per Second: 10,445.84532

Timestep Collection Time: 2.39980
Timestep Consumption Time: 2.38699
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.78678

Cumulative Model Updates: 331,584
Cumulative Timesteps: 2,765,372,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2765372632...
Checkpoint 2765372632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.66594
Policy Entropy: 4.10193
Value Function Loss: 0.00420

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02620
Policy Update Magnitude: 0.27586
Value Function Update Magnitude: 0.33934

Collected Steps per Second: 22,043.44653
Overall Steps per Second: 10,497.93328

Timestep Collection Time: 2.26934
Timestep Consumption Time: 2.49579
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.76513

Cumulative Model Updates: 331,590
Cumulative Timesteps: 2,765,422,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.82264
Policy Entropy: 4.12051
Value Function Loss: 0.00463

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02522
Policy Update Magnitude: 0.26409
Value Function Update Magnitude: 0.32824

Collected Steps per Second: 21,377.25402
Overall Steps per Second: 10,289.82690

Timestep Collection Time: 2.33903
Timestep Consumption Time: 2.52033
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.85936

Cumulative Model Updates: 331,596
Cumulative Timesteps: 2,765,472,658

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2765472658...
Checkpoint 2765472658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.74284
Policy Entropy: 4.15804
Value Function Loss: 0.00410

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02334
Policy Update Magnitude: 0.25225
Value Function Update Magnitude: 0.29987

Collected Steps per Second: 21,634.23096
Overall Steps per Second: 10,387.66572

Timestep Collection Time: 2.31180
Timestep Consumption Time: 2.50295
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.81475

Cumulative Model Updates: 331,602
Cumulative Timesteps: 2,765,522,672

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.71731
Policy Entropy: 4.14122
Value Function Loss: 0.00463

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01944
Policy Update Magnitude: 0.24492
Value Function Update Magnitude: 0.29755

Collected Steps per Second: 21,776.25842
Overall Steps per Second: 10,254.54032

Timestep Collection Time: 2.29617
Timestep Consumption Time: 2.57991
PPO Batch Consumption Time: 0.30073
Total Iteration Time: 4.87608

Cumulative Model Updates: 331,608
Cumulative Timesteps: 2,765,572,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2765572674...
Checkpoint 2765572674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.09798
Policy Entropy: 4.11279
Value Function Loss: 0.00489

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02240
Policy Update Magnitude: 0.26062
Value Function Update Magnitude: 0.33309

Collected Steps per Second: 20,799.12634
Overall Steps per Second: 10,186.19142

Timestep Collection Time: 2.40424
Timestep Consumption Time: 2.50496
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.90920

Cumulative Model Updates: 331,614
Cumulative Timesteps: 2,765,622,680

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.87131
Policy Entropy: 4.09347
Value Function Loss: 0.00501

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02370
Policy Update Magnitude: 0.26482
Value Function Update Magnitude: 0.35254

Collected Steps per Second: 20,462.40755
Overall Steps per Second: 9,559.15423

Timestep Collection Time: 2.44487
Timestep Consumption Time: 2.78864
PPO Batch Consumption Time: 0.32701
Total Iteration Time: 5.23352

Cumulative Model Updates: 331,620
Cumulative Timesteps: 2,765,672,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2765672708...
Checkpoint 2765672708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.76186
Policy Entropy: 4.08963
Value Function Loss: 0.00483

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02240
Policy Update Magnitude: 0.25740
Value Function Update Magnitude: 0.33573

Collected Steps per Second: 16,823.31433
Overall Steps per Second: 8,862.20712

Timestep Collection Time: 2.97254
Timestep Consumption Time: 2.67030
PPO Batch Consumption Time: 0.30268
Total Iteration Time: 5.64284

Cumulative Model Updates: 331,626
Cumulative Timesteps: 2,765,722,716

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.80242
Policy Entropy: 4.14474
Value Function Loss: 0.00417

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02045
Policy Update Magnitude: 0.24497
Value Function Update Magnitude: 0.32164

Collected Steps per Second: 18,869.58439
Overall Steps per Second: 9,178.45371

Timestep Collection Time: 2.65083
Timestep Consumption Time: 2.79889
PPO Batch Consumption Time: 0.34421
Total Iteration Time: 5.44972

Cumulative Model Updates: 331,632
Cumulative Timesteps: 2,765,772,736

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2765772736...
Checkpoint 2765772736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.17849
Policy Entropy: 4.10540
Value Function Loss: 0.00479

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02212
Policy Update Magnitude: 0.25335
Value Function Update Magnitude: 0.31757

Collected Steps per Second: 18,285.80168
Overall Steps per Second: 9,655.26854

Timestep Collection Time: 2.73578
Timestep Consumption Time: 2.44543
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 5.18121

Cumulative Model Updates: 331,638
Cumulative Timesteps: 2,765,822,762

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2765822762...
Checkpoint 2765822762 saved!
