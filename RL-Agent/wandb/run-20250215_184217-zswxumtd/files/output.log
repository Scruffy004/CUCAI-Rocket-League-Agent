Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.30734
Policy Entropy: 2.39027
Value Function Loss: 0.02581

Mean KL Divergence: 0.00109
SB3 Clip Fraction: 0.00885
Policy Update Magnitude: 0.19286
Value Function Update Magnitude: 0.23041

Collected Steps per Second: 6,172.65866
Overall Steps per Second: 3,700.90228

Timestep Collection Time: 8.10315
Timestep Consumption Time: 5.41193
PPO Batch Consumption Time: 2.15139
Total Iteration Time: 13.51508

Cumulative Model Updates: 301,074
Cumulative Timesteps: 2,510,941,702

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.16780
Policy Entropy: 2.45996
Value Function Loss: 0.02205

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.05260
Policy Update Magnitude: 0.41643
Value Function Update Magnitude: 0.47115

Collected Steps per Second: 21,499.47442
Overall Steps per Second: 11,646.73442

Timestep Collection Time: 2.32620
Timestep Consumption Time: 1.96788
PPO Batch Consumption Time: 0.30075
Total Iteration Time: 4.29408

Cumulative Model Updates: 301,078
Cumulative Timesteps: 2,510,991,714

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2510991714...
Checkpoint 2510991714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.59889
Policy Entropy: 2.46573
Value Function Loss: 0.01969

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.57516
Value Function Update Magnitude: 0.70782

Collected Steps per Second: 21,474.80134
Overall Steps per Second: 10,632.35025

Timestep Collection Time: 2.32961
Timestep Consumption Time: 2.37565
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.70526

Cumulative Model Updates: 301,084
Cumulative Timesteps: 2,511,041,742

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.00128
Policy Entropy: 2.46551
Value Function Loss: 0.02060

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.10919
Policy Update Magnitude: 0.52746
Value Function Update Magnitude: 0.68637

Collected Steps per Second: 21,831.16346
Overall Steps per Second: 10,369.28471

Timestep Collection Time: 2.29140
Timestep Consumption Time: 2.53284
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.82425

Cumulative Model Updates: 301,090
Cumulative Timesteps: 2,511,091,766

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2511091766...
Checkpoint 2511091766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.41399
Policy Entropy: 2.45457
Value Function Loss: 0.02031

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.10620
Policy Update Magnitude: 0.51742
Value Function Update Magnitude: 0.66331

Collected Steps per Second: 21,312.06613
Overall Steps per Second: 10,360.30467

Timestep Collection Time: 2.34778
Timestep Consumption Time: 2.48181
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.82959

Cumulative Model Updates: 301,096
Cumulative Timesteps: 2,511,141,802

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.79975
Policy Entropy: 2.44500
Value Function Loss: 0.02090

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.11411
Policy Update Magnitude: 0.50017
Value Function Update Magnitude: 0.64940

Collected Steps per Second: 21,002.71193
Overall Steps per Second: 10,276.09791

Timestep Collection Time: 2.38122
Timestep Consumption Time: 2.48561
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.86683

Cumulative Model Updates: 301,102
Cumulative Timesteps: 2,511,191,814

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2511191814...
Checkpoint 2511191814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.50377
Policy Entropy: 2.47022
Value Function Loss: 0.01877

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.11517
Policy Update Magnitude: 0.48364
Value Function Update Magnitude: 0.62237

Collected Steps per Second: 21,728.54606
Overall Steps per Second: 10,522.53024

Timestep Collection Time: 2.30241
Timestep Consumption Time: 2.45196
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.75437

Cumulative Model Updates: 301,108
Cumulative Timesteps: 2,511,241,842

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.84460
Policy Entropy: 2.45752
Value Function Loss: 0.01876

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.11374
Policy Update Magnitude: 0.48462
Value Function Update Magnitude: 0.62167

Collected Steps per Second: 21,908.59229
Overall Steps per Second: 10,406.25071

Timestep Collection Time: 2.28312
Timestep Consumption Time: 2.52360
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.80673

Cumulative Model Updates: 301,114
Cumulative Timesteps: 2,511,291,862

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2511291862...
Checkpoint 2511291862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.44440
Policy Entropy: 2.46348
Value Function Loss: 0.01813

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.10233
Policy Update Magnitude: 0.48076
Value Function Update Magnitude: 0.61451

Collected Steps per Second: 21,433.94956
Overall Steps per Second: 10,324.56824

Timestep Collection Time: 2.33405
Timestep Consumption Time: 2.51148
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.84553

Cumulative Model Updates: 301,120
Cumulative Timesteps: 2,511,341,890

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.74156
Policy Entropy: 2.44036
Value Function Loss: 0.01847

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.11520
Policy Update Magnitude: 0.48492
Value Function Update Magnitude: 0.61781

Collected Steps per Second: 21,991.05822
Overall Steps per Second: 10,589.87900

Timestep Collection Time: 2.27447
Timestep Consumption Time: 2.44872
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.72319

Cumulative Model Updates: 301,126
Cumulative Timesteps: 2,511,391,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2511391908...
Checkpoint 2511391908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.86568
Policy Entropy: 2.44086
Value Function Loss: 0.01968

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.11263
Policy Update Magnitude: 0.48690
Value Function Update Magnitude: 0.62870

Collected Steps per Second: 21,795.51982
Overall Steps per Second: 10,517.22396

Timestep Collection Time: 2.29414
Timestep Consumption Time: 2.46016
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.75430

Cumulative Model Updates: 301,132
Cumulative Timesteps: 2,511,441,910

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.37245
Policy Entropy: 2.43116
Value Function Loss: 0.01977

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.13350
Policy Update Magnitude: 0.48943
Value Function Update Magnitude: 0.65042

Collected Steps per Second: 21,902.61101
Overall Steps per Second: 10,463.48323

Timestep Collection Time: 2.28384
Timestep Consumption Time: 2.49679
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.78063

Cumulative Model Updates: 301,138
Cumulative Timesteps: 2,511,491,932

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2511491932...
Checkpoint 2511491932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.95238
Policy Entropy: 2.44804
Value Function Loss: 0.01981

Mean KL Divergence: 0.02522
SB3 Clip Fraction: 0.15099
Policy Update Magnitude: 0.53703
Value Function Update Magnitude: 0.66854

Collected Steps per Second: 21,647.59927
Overall Steps per Second: 10,547.48213

Timestep Collection Time: 2.31093
Timestep Consumption Time: 2.43201
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.74293

Cumulative Model Updates: 301,144
Cumulative Timesteps: 2,511,541,958

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.23779
Policy Entropy: 2.45699
Value Function Loss: 0.01883

Mean KL Divergence: 0.02766
SB3 Clip Fraction: 0.15898
Policy Update Magnitude: 0.52653
Value Function Update Magnitude: 0.65621

Collected Steps per Second: 21,981.55486
Overall Steps per Second: 10,553.65149

Timestep Collection Time: 2.27564
Timestep Consumption Time: 2.46415
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.73978

Cumulative Model Updates: 301,150
Cumulative Timesteps: 2,511,591,980

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2511591980...
Checkpoint 2511591980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.89116
Policy Entropy: 2.46349
Value Function Loss: 0.01930

Mean KL Divergence: 0.02368
SB3 Clip Fraction: 0.14725
Policy Update Magnitude: 0.51448
Value Function Update Magnitude: 0.64946

Collected Steps per Second: 21,573.04713
Overall Steps per Second: 10,475.25307

Timestep Collection Time: 2.31780
Timestep Consumption Time: 2.45555
PPO Batch Consumption Time: 0.28121
Total Iteration Time: 4.77335

Cumulative Model Updates: 301,156
Cumulative Timesteps: 2,511,641,982

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.34489
Policy Entropy: 2.46102
Value Function Loss: 0.01909

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.50217
Value Function Update Magnitude: 0.64191

Collected Steps per Second: 21,710.98139
Overall Steps per Second: 10,501.32271

Timestep Collection Time: 2.30427
Timestep Consumption Time: 2.45970
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.76397

Cumulative Model Updates: 301,162
Cumulative Timesteps: 2,511,692,010

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2511692010...
Checkpoint 2511692010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.91586
Policy Entropy: 2.47105
Value Function Loss: 0.01835

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.11122
Policy Update Magnitude: 0.49672
Value Function Update Magnitude: 0.62501

Collected Steps per Second: 21,765.76594
Overall Steps per Second: 10,164.46132

Timestep Collection Time: 2.29728
Timestep Consumption Time: 2.62202
PPO Batch Consumption Time: 0.30783
Total Iteration Time: 4.91930

Cumulative Model Updates: 301,168
Cumulative Timesteps: 2,511,742,012

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.54980
Policy Entropy: 2.46434
Value Function Loss: 0.01829

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.10407
Policy Update Magnitude: 0.49615
Value Function Update Magnitude: 0.61024

Collected Steps per Second: 22,023.02347
Overall Steps per Second: 10,576.23500

Timestep Collection Time: 2.27099
Timestep Consumption Time: 2.45792
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.72890

Cumulative Model Updates: 301,174
Cumulative Timesteps: 2,511,792,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2511792026...
Checkpoint 2511792026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.74314
Policy Entropy: 2.46892
Value Function Loss: 0.01977

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.09957
Policy Update Magnitude: 0.50123
Value Function Update Magnitude: 0.62139

Collected Steps per Second: 21,243.62500
Overall Steps per Second: 10,236.03570

Timestep Collection Time: 2.35412
Timestep Consumption Time: 2.53156
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.88568

Cumulative Model Updates: 301,180
Cumulative Timesteps: 2,511,842,036

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.68162
Policy Entropy: 2.46195
Value Function Loss: 0.02020

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.09771
Policy Update Magnitude: 0.49601
Value Function Update Magnitude: 0.65082

Collected Steps per Second: 21,915.44610
Overall Steps per Second: 10,431.98133

Timestep Collection Time: 2.28168
Timestep Consumption Time: 2.51166
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.79334

Cumulative Model Updates: 301,186
Cumulative Timesteps: 2,511,892,040

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2511892040...
Checkpoint 2511892040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.12906
Policy Entropy: 2.46264
Value Function Loss: 0.01980

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.49782
Value Function Update Magnitude: 0.65998

Collected Steps per Second: 21,638.60604
Overall Steps per Second: 10,682.78384

Timestep Collection Time: 2.31207
Timestep Consumption Time: 2.37116
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.68324

Cumulative Model Updates: 301,192
Cumulative Timesteps: 2,511,942,070

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.40296
Policy Entropy: 2.45452
Value Function Loss: 0.01842

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.10797
Policy Update Magnitude: 0.49442
Value Function Update Magnitude: 0.66202

Collected Steps per Second: 22,060.97256
Overall Steps per Second: 10,371.46094

Timestep Collection Time: 2.26744
Timestep Consumption Time: 2.55560
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 4.82304

Cumulative Model Updates: 301,198
Cumulative Timesteps: 2,511,992,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2511992092...
Checkpoint 2511992092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.48008
Policy Entropy: 2.46675
Value Function Loss: 0.01849

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.11906
Policy Update Magnitude: 0.49381
Value Function Update Magnitude: 0.66744

Collected Steps per Second: 20,921.32273
Overall Steps per Second: 10,258.80243

Timestep Collection Time: 2.39124
Timestep Consumption Time: 2.48535
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.87659

Cumulative Model Updates: 301,204
Cumulative Timesteps: 2,512,042,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.79894
Policy Entropy: 2.47052
Value Function Loss: 0.01827

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.10468
Policy Update Magnitude: 0.49890
Value Function Update Magnitude: 0.70812

Collected Steps per Second: 20,848.51913
Overall Steps per Second: 10,339.54386

Timestep Collection Time: 2.39835
Timestep Consumption Time: 2.43765
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.83600

Cumulative Model Updates: 301,210
Cumulative Timesteps: 2,512,092,122

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2512092122...
Checkpoint 2512092122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.40592
Policy Entropy: 2.48929
Value Function Loss: 0.01779

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.49935
Value Function Update Magnitude: 0.71889

Collected Steps per Second: 21,736.44658
Overall Steps per Second: 10,695.78360

Timestep Collection Time: 2.30120
Timestep Consumption Time: 2.37541
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.67661

Cumulative Model Updates: 301,216
Cumulative Timesteps: 2,512,142,142

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.89765
Policy Entropy: 2.48031
Value Function Loss: 0.01750

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.09341
Policy Update Magnitude: 0.50598
Value Function Update Magnitude: 0.69248

Collected Steps per Second: 22,254.32999
Overall Steps per Second: 10,499.63786

Timestep Collection Time: 2.24729
Timestep Consumption Time: 2.51592
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.76321

Cumulative Model Updates: 301,222
Cumulative Timesteps: 2,512,192,154

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2512192154...
Checkpoint 2512192154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.83928
Policy Entropy: 2.47081
Value Function Loss: 0.01860

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.09779
Policy Update Magnitude: 0.50021
Value Function Update Magnitude: 0.67001

Collected Steps per Second: 21,715.24652
Overall Steps per Second: 10,364.27126

Timestep Collection Time: 2.30271
Timestep Consumption Time: 2.52194
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.82465

Cumulative Model Updates: 301,228
Cumulative Timesteps: 2,512,242,158

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.13987
Policy Entropy: 2.47453
Value Function Loss: 0.01829

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.10535
Policy Update Magnitude: 0.49641
Value Function Update Magnitude: 0.67046

Collected Steps per Second: 21,834.82752
Overall Steps per Second: 10,399.98543

Timestep Collection Time: 2.29056
Timestep Consumption Time: 2.51848
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.80905

Cumulative Model Updates: 301,234
Cumulative Timesteps: 2,512,292,172

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2512292172...
Checkpoint 2512292172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.59269
Policy Entropy: 2.46380
Value Function Loss: 0.01962

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.09717
Policy Update Magnitude: 0.49695
Value Function Update Magnitude: 0.65517

Collected Steps per Second: 21,884.37356
Overall Steps per Second: 10,539.06278

Timestep Collection Time: 2.28528
Timestep Consumption Time: 2.46011
PPO Batch Consumption Time: 0.29603
Total Iteration Time: 4.74539

Cumulative Model Updates: 301,240
Cumulative Timesteps: 2,512,342,184

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.22151
Policy Entropy: 2.48117
Value Function Loss: 0.01993

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.10430
Policy Update Magnitude: 0.50029
Value Function Update Magnitude: 0.65208

Collected Steps per Second: 22,320.44416
Overall Steps per Second: 10,290.01169

Timestep Collection Time: 2.24028
Timestep Consumption Time: 2.61919
PPO Batch Consumption Time: 0.30726
Total Iteration Time: 4.85947

Cumulative Model Updates: 301,246
Cumulative Timesteps: 2,512,392,188

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2512392188...
Checkpoint 2512392188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.39084
Policy Entropy: 2.48042
Value Function Loss: 0.01986

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.10651
Policy Update Magnitude: 0.50215
Value Function Update Magnitude: 0.65203

Collected Steps per Second: 21,471.97970
Overall Steps per Second: 10,378.54392

Timestep Collection Time: 2.32880
Timestep Consumption Time: 2.48921
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.81802

Cumulative Model Updates: 301,252
Cumulative Timesteps: 2,512,442,192

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.36380
Policy Entropy: 2.49464
Value Function Loss: 0.01985

Mean KL Divergence: 0.02149
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.49985
Value Function Update Magnitude: 0.64688

Collected Steps per Second: 22,150.12189
Overall Steps per Second: 10,472.68576

Timestep Collection Time: 2.25759
Timestep Consumption Time: 2.51730
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.77490

Cumulative Model Updates: 301,258
Cumulative Timesteps: 2,512,492,198

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2512492198...
Checkpoint 2512492198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.78971
Policy Entropy: 2.49745
Value Function Loss: 0.01885

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.12386
Policy Update Magnitude: 0.50407
Value Function Update Magnitude: 0.65092

Collected Steps per Second: 22,563.70781
Overall Steps per Second: 10,606.73727

Timestep Collection Time: 2.21675
Timestep Consumption Time: 2.49894
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.71568

Cumulative Model Updates: 301,264
Cumulative Timesteps: 2,512,542,216

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.69471
Policy Entropy: 2.47159
Value Function Loss: 0.01927

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.12244
Policy Update Magnitude: 0.51055
Value Function Update Magnitude: 0.66168

Collected Steps per Second: 22,054.94588
Overall Steps per Second: 10,433.40981

Timestep Collection Time: 2.26752
Timestep Consumption Time: 2.52574
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.79326

Cumulative Model Updates: 301,270
Cumulative Timesteps: 2,512,592,226

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2512592226...
Checkpoint 2512592226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.22492
Policy Entropy: 2.46620
Value Function Loss: 0.01936

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.11344
Policy Update Magnitude: 0.50572
Value Function Update Magnitude: 0.66371

Collected Steps per Second: 21,684.64669
Overall Steps per Second: 10,557.02776

Timestep Collection Time: 2.30707
Timestep Consumption Time: 2.43176
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.73883

Cumulative Model Updates: 301,276
Cumulative Timesteps: 2,512,642,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.52327
Policy Entropy: 2.46412
Value Function Loss: 0.01985

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.11044
Policy Update Magnitude: 0.48967
Value Function Update Magnitude: 0.64733

Collected Steps per Second: 22,191.20042
Overall Steps per Second: 10,544.52373

Timestep Collection Time: 2.25333
Timestep Consumption Time: 2.48885
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.74218

Cumulative Model Updates: 301,282
Cumulative Timesteps: 2,512,692,258

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2512692258...
Checkpoint 2512692258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.13750
Policy Entropy: 2.46279
Value Function Loss: 0.01979

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.10935
Policy Update Magnitude: 0.48699
Value Function Update Magnitude: 0.63739

Collected Steps per Second: 22,478.19491
Overall Steps per Second: 10,662.83896

Timestep Collection Time: 2.22438
Timestep Consumption Time: 2.46480
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.68918

Cumulative Model Updates: 301,288
Cumulative Timesteps: 2,512,742,258

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.94965
Policy Entropy: 2.47383
Value Function Loss: 0.01884

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.10839
Policy Update Magnitude: 0.49919
Value Function Update Magnitude: 0.63431

Collected Steps per Second: 22,150.07656
Overall Steps per Second: 10,424.60896

Timestep Collection Time: 2.25787
Timestep Consumption Time: 2.53962
PPO Batch Consumption Time: 0.29572
Total Iteration Time: 4.79749

Cumulative Model Updates: 301,294
Cumulative Timesteps: 2,512,792,270

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2512792270...
Checkpoint 2512792270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.23247
Policy Entropy: 2.45493
Value Function Loss: 0.01839

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.49700
Value Function Update Magnitude: 0.64491

Collected Steps per Second: 21,745.24673
Overall Steps per Second: 10,565.83595

Timestep Collection Time: 2.29963
Timestep Consumption Time: 2.43317
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.73280

Cumulative Model Updates: 301,300
Cumulative Timesteps: 2,512,842,276

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.90792
Policy Entropy: 2.48093
Value Function Loss: 0.01884

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.10491
Policy Update Magnitude: 0.48946
Value Function Update Magnitude: 0.66562

Collected Steps per Second: 21,940.93738
Overall Steps per Second: 10,564.57697

Timestep Collection Time: 2.27985
Timestep Consumption Time: 2.45503
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.73488

Cumulative Model Updates: 301,306
Cumulative Timesteps: 2,512,892,298

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2512892298...
Checkpoint 2512892298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.86379
Policy Entropy: 2.47576
Value Function Loss: 0.02168

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.09618
Policy Update Magnitude: 0.50634
Value Function Update Magnitude: 0.69757

Collected Steps per Second: 21,787.87152
Overall Steps per Second: 10,414.63080

Timestep Collection Time: 2.29531
Timestep Consumption Time: 2.50658
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.80190

Cumulative Model Updates: 301,312
Cumulative Timesteps: 2,512,942,308

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.93785
Policy Entropy: 2.48405
Value Function Loss: 0.02191

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.10124
Policy Update Magnitude: 0.51037
Value Function Update Magnitude: 0.71947

Collected Steps per Second: 22,325.02036
Overall Steps per Second: 10,623.04018

Timestep Collection Time: 2.23973
Timestep Consumption Time: 2.46721
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.70694

Cumulative Model Updates: 301,318
Cumulative Timesteps: 2,512,992,310

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2512992310...
Checkpoint 2512992310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.64283
Policy Entropy: 2.48225
Value Function Loss: 0.02088

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.09695
Policy Update Magnitude: 0.50442
Value Function Update Magnitude: 0.70916

Collected Steps per Second: 21,890.39045
Overall Steps per Second: 10,306.09816

Timestep Collection Time: 2.28429
Timestep Consumption Time: 2.56759
PPO Batch Consumption Time: 0.30349
Total Iteration Time: 4.85188

Cumulative Model Updates: 301,324
Cumulative Timesteps: 2,513,042,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.40639
Policy Entropy: 2.47418
Value Function Loss: 0.01988

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.50043
Value Function Update Magnitude: 0.68274

Collected Steps per Second: 22,075.87652
Overall Steps per Second: 10,588.97372

Timestep Collection Time: 2.26573
Timestep Consumption Time: 2.45786
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.72359

Cumulative Model Updates: 301,330
Cumulative Timesteps: 2,513,092,332

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2513092332...
Checkpoint 2513092332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.07235
Policy Entropy: 2.48594
Value Function Loss: 0.01969

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.11061
Policy Update Magnitude: 0.49845
Value Function Update Magnitude: 0.66884

Collected Steps per Second: 22,083.54129
Overall Steps per Second: 10,501.77780

Timestep Collection Time: 2.26549
Timestep Consumption Time: 2.49847
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.76396

Cumulative Model Updates: 301,336
Cumulative Timesteps: 2,513,142,362

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.34770
Policy Entropy: 2.48094
Value Function Loss: 0.02022

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.10751
Policy Update Magnitude: 0.48952
Value Function Update Magnitude: 0.65232

Collected Steps per Second: 22,002.19732
Overall Steps per Second: 10,447.80550

Timestep Collection Time: 2.27286
Timestep Consumption Time: 2.51360
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.78646

Cumulative Model Updates: 301,342
Cumulative Timesteps: 2,513,192,370

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2513192370...
Checkpoint 2513192370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.51455
Policy Entropy: 2.48629
Value Function Loss: 0.01981

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.14012
Policy Update Magnitude: 0.48693
Value Function Update Magnitude: 0.66024

Collected Steps per Second: 21,583.03145
Overall Steps per Second: 10,410.56561

Timestep Collection Time: 2.31802
Timestep Consumption Time: 2.48767
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.80569

Cumulative Model Updates: 301,348
Cumulative Timesteps: 2,513,242,400

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.27501
Policy Entropy: 2.48608
Value Function Loss: 0.01942

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.13760
Policy Update Magnitude: 0.51623
Value Function Update Magnitude: 0.67107

Collected Steps per Second: 21,853.72460
Overall Steps per Second: 10,708.42288

Timestep Collection Time: 2.28840
Timestep Consumption Time: 2.38176
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.67016

Cumulative Model Updates: 301,354
Cumulative Timesteps: 2,513,292,410

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2513292410...
Checkpoint 2513292410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.32330
Policy Entropy: 2.48728
Value Function Loss: 0.01844

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.49722
Value Function Update Magnitude: 0.68361

Collected Steps per Second: 22,237.13395
Overall Steps per Second: 10,620.81511

Timestep Collection Time: 2.24849
Timestep Consumption Time: 2.45925
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.70774

Cumulative Model Updates: 301,360
Cumulative Timesteps: 2,513,342,410

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.40288
Policy Entropy: 2.47419
Value Function Loss: 0.01888

Mean KL Divergence: 0.02346
SB3 Clip Fraction: 0.14275
Policy Update Magnitude: 0.47659
Value Function Update Magnitude: 0.66458

Collected Steps per Second: 22,138.73908
Overall Steps per Second: 10,451.90463

Timestep Collection Time: 2.25885
Timestep Consumption Time: 2.52574
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.78458

Cumulative Model Updates: 301,366
Cumulative Timesteps: 2,513,392,418

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2513392418...
Checkpoint 2513392418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.94371
Policy Entropy: 2.47391
Value Function Loss: 0.02034

Mean KL Divergence: 0.02337
SB3 Clip Fraction: 0.14523
Policy Update Magnitude: 0.46756
Value Function Update Magnitude: 0.66072

Collected Steps per Second: 21,973.11125
Overall Steps per Second: 10,627.95411

Timestep Collection Time: 2.27669
Timestep Consumption Time: 2.43033
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.70702

Cumulative Model Updates: 301,372
Cumulative Timesteps: 2,513,442,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.73083
Policy Entropy: 2.46753
Value Function Loss: 0.02143

Mean KL Divergence: 0.02074
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.50771
Value Function Update Magnitude: 0.69387

Collected Steps per Second: 21,297.56800
Overall Steps per Second: 10,487.09482

Timestep Collection Time: 2.34900
Timestep Consumption Time: 2.42143
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.77043

Cumulative Model Updates: 301,378
Cumulative Timesteps: 2,513,492,472

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2513492472...
Checkpoint 2513492472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.37115
Policy Entropy: 2.47970
Value Function Loss: 0.02109

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.52072
Value Function Update Magnitude: 0.69342

Collected Steps per Second: 21,912.24137
Overall Steps per Second: 10,569.48916

Timestep Collection Time: 2.28338
Timestep Consumption Time: 2.45043
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.73381

Cumulative Model Updates: 301,384
Cumulative Timesteps: 2,513,542,506

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.54467
Policy Entropy: 2.47657
Value Function Loss: 0.02080

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.11188
Policy Update Magnitude: 0.51625
Value Function Update Magnitude: 0.69545

Collected Steps per Second: 21,725.08296
Overall Steps per Second: 10,315.72143

Timestep Collection Time: 2.30213
Timestep Consumption Time: 2.54620
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.84833

Cumulative Model Updates: 301,390
Cumulative Timesteps: 2,513,592,520

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2513592520...
Checkpoint 2513592520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.93121
Policy Entropy: 2.48594
Value Function Loss: 0.02045

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.09945
Policy Update Magnitude: 0.50542
Value Function Update Magnitude: 0.69232

Collected Steps per Second: 21,435.07042
Overall Steps per Second: 10,371.35735

Timestep Collection Time: 2.33300
Timestep Consumption Time: 2.48874
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.82174

Cumulative Model Updates: 301,396
Cumulative Timesteps: 2,513,642,528

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.17657
Policy Entropy: 2.46937
Value Function Loss: 0.02024

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.10460
Policy Update Magnitude: 0.50159
Value Function Update Magnitude: 0.69425

Collected Steps per Second: 21,597.49354
Overall Steps per Second: 10,286.31850

Timestep Collection Time: 2.31629
Timestep Consumption Time: 2.54707
PPO Batch Consumption Time: 0.30678
Total Iteration Time: 4.86335

Cumulative Model Updates: 301,402
Cumulative Timesteps: 2,513,692,554

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2513692554...
Checkpoint 2513692554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.98063
Policy Entropy: 2.46073
Value Function Loss: 0.02144

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.10833
Policy Update Magnitude: 0.50231
Value Function Update Magnitude: 0.66721

Collected Steps per Second: 22,029.25598
Overall Steps per Second: 10,335.27611

Timestep Collection Time: 2.27107
Timestep Consumption Time: 2.56963
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.84070

Cumulative Model Updates: 301,408
Cumulative Timesteps: 2,513,742,584

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.89300
Policy Entropy: 2.45942
Value Function Loss: 0.02141

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.12200
Policy Update Magnitude: 0.49945
Value Function Update Magnitude: 0.67632

Collected Steps per Second: 21,728.44002
Overall Steps per Second: 10,444.72059

Timestep Collection Time: 2.30214
Timestep Consumption Time: 2.48707
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.78921

Cumulative Model Updates: 301,414
Cumulative Timesteps: 2,513,792,606

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2513792606...
Checkpoint 2513792606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.71040
Policy Entropy: 2.47894
Value Function Loss: 0.02005

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.11560
Policy Update Magnitude: 0.49873
Value Function Update Magnitude: 0.68849

Collected Steps per Second: 21,751.55989
Overall Steps per Second: 10,578.47296

Timestep Collection Time: 2.29924
Timestep Consumption Time: 2.42848
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.72771

Cumulative Model Updates: 301,420
Cumulative Timesteps: 2,513,842,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.52737
Policy Entropy: 2.48426
Value Function Loss: 0.01876

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.10932
Policy Update Magnitude: 0.48830
Value Function Update Magnitude: 0.67880

Collected Steps per Second: 21,362.97178
Overall Steps per Second: 10,231.31348

Timestep Collection Time: 2.34125
Timestep Consumption Time: 2.54727
PPO Batch Consumption Time: 0.29813
Total Iteration Time: 4.88852

Cumulative Model Updates: 301,426
Cumulative Timesteps: 2,513,892,634

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2513892634...
Checkpoint 2513892634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.90455
Policy Entropy: 2.49025
Value Function Loss: 0.01916

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.10512
Policy Update Magnitude: 0.48484
Value Function Update Magnitude: 0.68418

Collected Steps per Second: 21,713.63742
Overall Steps per Second: 10,439.71230

Timestep Collection Time: 2.30353
Timestep Consumption Time: 2.48760
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.79113

Cumulative Model Updates: 301,432
Cumulative Timesteps: 2,513,942,652

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.78066
Policy Entropy: 2.48619
Value Function Loss: 0.02034

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.10071
Policy Update Magnitude: 0.49951
Value Function Update Magnitude: 0.71993

Collected Steps per Second: 21,784.85521
Overall Steps per Second: 10,458.78246

Timestep Collection Time: 2.29554
Timestep Consumption Time: 2.48590
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.78144

Cumulative Model Updates: 301,438
Cumulative Timesteps: 2,513,992,660

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2513992660...
Checkpoint 2513992660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.12943
Policy Entropy: 2.50404
Value Function Loss: 0.02009

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.50290
Value Function Update Magnitude: 0.74395

Collected Steps per Second: 21,557.17995
Overall Steps per Second: 10,453.28619

Timestep Collection Time: 2.31997
Timestep Consumption Time: 2.46436
PPO Batch Consumption Time: 0.29712
Total Iteration Time: 4.78433

Cumulative Model Updates: 301,444
Cumulative Timesteps: 2,514,042,672

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.17702
Policy Entropy: 2.48467
Value Function Loss: 0.01915

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.49778
Value Function Update Magnitude: 0.73441

Collected Steps per Second: 21,729.15616
Overall Steps per Second: 10,319.55291

Timestep Collection Time: 2.30179
Timestep Consumption Time: 2.54493
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.84672

Cumulative Model Updates: 301,450
Cumulative Timesteps: 2,514,092,688

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2514092688...
Checkpoint 2514092688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.46564
Policy Entropy: 2.49837
Value Function Loss: 0.01807

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.49116
Value Function Update Magnitude: 0.71307

Collected Steps per Second: 21,626.81528
Overall Steps per Second: 10,285.04741

Timestep Collection Time: 2.31259
Timestep Consumption Time: 2.55020
PPO Batch Consumption Time: 0.29940
Total Iteration Time: 4.86279

Cumulative Model Updates: 301,456
Cumulative Timesteps: 2,514,142,702

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.12389
Policy Entropy: 2.48869
Value Function Loss: 0.01866

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.49798
Value Function Update Magnitude: 0.70374

Collected Steps per Second: 21,444.76163
Overall Steps per Second: 10,350.27619

Timestep Collection Time: 2.33316
Timestep Consumption Time: 2.50092
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.83407

Cumulative Model Updates: 301,462
Cumulative Timesteps: 2,514,192,736

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2514192736...
Checkpoint 2514192736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.52473
Policy Entropy: 2.49149
Value Function Loss: 0.01894

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.10259
Policy Update Magnitude: 0.48759
Value Function Update Magnitude: 0.70536

Collected Steps per Second: 21,710.53206
Overall Steps per Second: 10,362.77890

Timestep Collection Time: 2.30349
Timestep Consumption Time: 2.52244
PPO Batch Consumption Time: 0.29706
Total Iteration Time: 4.82593

Cumulative Model Updates: 301,468
Cumulative Timesteps: 2,514,242,746

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.82839
Policy Entropy: 2.47003
Value Function Loss: 0.01993

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.09971
Policy Update Magnitude: 0.49839
Value Function Update Magnitude: 0.68772

Collected Steps per Second: 22,436.00968
Overall Steps per Second: 10,473.07908

Timestep Collection Time: 2.23008
Timestep Consumption Time: 2.54732
PPO Batch Consumption Time: 0.29712
Total Iteration Time: 4.77739

Cumulative Model Updates: 301,474
Cumulative Timesteps: 2,514,292,780

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2514292780...
Checkpoint 2514292780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.51693
Policy Entropy: 2.46983
Value Function Loss: 0.02005

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.10001
Policy Update Magnitude: 0.49904
Value Function Update Magnitude: 0.68424

Collected Steps per Second: 22,017.12438
Overall Steps per Second: 10,503.20417

Timestep Collection Time: 2.27214
Timestep Consumption Time: 2.49079
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.76293

Cumulative Model Updates: 301,480
Cumulative Timesteps: 2,514,342,806

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.82513
Policy Entropy: 2.47311
Value Function Loss: 0.02115

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.11438
Policy Update Magnitude: 0.50352
Value Function Update Magnitude: 0.71825

Collected Steps per Second: 21,752.30306
Overall Steps per Second: 10,362.13238

Timestep Collection Time: 2.29989
Timestep Consumption Time: 2.52807
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.82796

Cumulative Model Updates: 301,486
Cumulative Timesteps: 2,514,392,834

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2514392834...
Checkpoint 2514392834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.11674
Policy Entropy: 2.47859
Value Function Loss: 0.02022

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.11363
Policy Update Magnitude: 0.49746
Value Function Update Magnitude: 0.74633

Collected Steps per Second: 21,803.74847
Overall Steps per Second: 10,576.85488

Timestep Collection Time: 2.29328
Timestep Consumption Time: 2.43422
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.72749

Cumulative Model Updates: 301,492
Cumulative Timesteps: 2,514,442,836

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.48108
Policy Entropy: 2.47167
Value Function Loss: 0.01972

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.10336
Policy Update Magnitude: 0.49919
Value Function Update Magnitude: 0.73191

Collected Steps per Second: 21,609.91209
Overall Steps per Second: 10,204.05082

Timestep Collection Time: 2.31422
Timestep Consumption Time: 2.58678
PPO Batch Consumption Time: 0.29954
Total Iteration Time: 4.90099

Cumulative Model Updates: 301,498
Cumulative Timesteps: 2,514,492,846

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2514492846...
Checkpoint 2514492846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.06339
Policy Entropy: 2.46722
Value Function Loss: 0.01936

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.09588
Policy Update Magnitude: 0.49528
Value Function Update Magnitude: 0.69798

Collected Steps per Second: 21,493.36365
Overall Steps per Second: 10,232.36589

Timestep Collection Time: 2.32639
Timestep Consumption Time: 2.56026
PPO Batch Consumption Time: 0.30069
Total Iteration Time: 4.88665

Cumulative Model Updates: 301,504
Cumulative Timesteps: 2,514,542,848

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.58463
Policy Entropy: 2.47950
Value Function Loss: 0.02042

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.49134
Value Function Update Magnitude: 0.67691

Collected Steps per Second: 21,756.68194
Overall Steps per Second: 10,393.90713

Timestep Collection Time: 2.29833
Timestep Consumption Time: 2.51257
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.81090

Cumulative Model Updates: 301,510
Cumulative Timesteps: 2,514,592,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2514592852...
Checkpoint 2514592852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.45105
Policy Entropy: 2.48801
Value Function Loss: 0.01959

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.11101
Policy Update Magnitude: 0.47634
Value Function Update Magnitude: 0.67454

Collected Steps per Second: 21,661.83024
Overall Steps per Second: 10,331.47494

Timestep Collection Time: 2.30904
Timestep Consumption Time: 2.53228
PPO Batch Consumption Time: 0.29866
Total Iteration Time: 4.84132

Cumulative Model Updates: 301,516
Cumulative Timesteps: 2,514,642,870

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.69852
Policy Entropy: 2.47998
Value Function Loss: 0.02000

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.11533
Policy Update Magnitude: 0.47840
Value Function Update Magnitude: 0.66622

Collected Steps per Second: 22,791.74502
Overall Steps per Second: 10,692.24884

Timestep Collection Time: 2.19492
Timestep Consumption Time: 2.48380
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.67872

Cumulative Model Updates: 301,522
Cumulative Timesteps: 2,514,692,896

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2514692896...
Checkpoint 2514692896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.35575
Policy Entropy: 2.49193
Value Function Loss: 0.02002

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.10937
Policy Update Magnitude: 0.48341
Value Function Update Magnitude: 0.66539

Collected Steps per Second: 21,333.23781
Overall Steps per Second: 10,301.26357

Timestep Collection Time: 2.34489
Timestep Consumption Time: 2.51122
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.85610

Cumulative Model Updates: 301,528
Cumulative Timesteps: 2,514,742,920

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.51880
Policy Entropy: 2.48714
Value Function Loss: 0.02094

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.09989
Policy Update Magnitude: 0.48232
Value Function Update Magnitude: 0.65298

Collected Steps per Second: 21,852.91079
Overall Steps per Second: 10,494.23375

Timestep Collection Time: 2.28839
Timestep Consumption Time: 2.47689
PPO Batch Consumption Time: 0.28536
Total Iteration Time: 4.76528

Cumulative Model Updates: 301,534
Cumulative Timesteps: 2,514,792,928

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2514792928...
Checkpoint 2514792928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.55906
Policy Entropy: 2.49466
Value Function Loss: 0.01965

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.09867
Policy Update Magnitude: 0.48318
Value Function Update Magnitude: 0.63680

Collected Steps per Second: 21,715.34652
Overall Steps per Second: 10,580.19242

Timestep Collection Time: 2.30316
Timestep Consumption Time: 2.42397
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.72714

Cumulative Model Updates: 301,540
Cumulative Timesteps: 2,514,842,942

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.92837
Policy Entropy: 2.47639
Value Function Loss: 0.01934

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.10728
Policy Update Magnitude: 0.47899
Value Function Update Magnitude: 0.62740

Collected Steps per Second: 21,824.59209
Overall Steps per Second: 10,424.26196

Timestep Collection Time: 2.29200
Timestep Consumption Time: 2.50661
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.79861

Cumulative Model Updates: 301,546
Cumulative Timesteps: 2,514,892,964

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2514892964...
Checkpoint 2514892964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.58137
Policy Entropy: 2.50210
Value Function Loss: 0.01774

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.09908
Policy Update Magnitude: 0.48133
Value Function Update Magnitude: 0.63849

Collected Steps per Second: 21,582.31148
Overall Steps per Second: 10,271.11491

Timestep Collection Time: 2.31671
Timestep Consumption Time: 2.55131
PPO Batch Consumption Time: 0.29565
Total Iteration Time: 4.86802

Cumulative Model Updates: 301,552
Cumulative Timesteps: 2,514,942,964

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.70788
Policy Entropy: 2.52190
Value Function Loss: 0.01717

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.10658
Policy Update Magnitude: 0.47603
Value Function Update Magnitude: 0.63044

Collected Steps per Second: 21,845.96672
Overall Steps per Second: 10,403.00475

Timestep Collection Time: 2.28967
Timestep Consumption Time: 2.51856
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.80823

Cumulative Model Updates: 301,558
Cumulative Timesteps: 2,514,992,984

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2514992984...
Checkpoint 2514992984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.05716
Policy Entropy: 2.55232
Value Function Loss: 0.01729

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.10307
Policy Update Magnitude: 0.47224
Value Function Update Magnitude: 0.61197

Collected Steps per Second: 21,616.88828
Overall Steps per Second: 10,583.39461

Timestep Collection Time: 2.31412
Timestep Consumption Time: 2.41253
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.72665

Cumulative Model Updates: 301,564
Cumulative Timesteps: 2,515,043,008

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.05069
Policy Entropy: 2.55596
Value Function Loss: 0.01936

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.10633
Policy Update Magnitude: 0.47340
Value Function Update Magnitude: 0.61737

Collected Steps per Second: 21,839.89000
Overall Steps per Second: 10,466.44416

Timestep Collection Time: 2.29021
Timestep Consumption Time: 2.48868
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.77889

Cumulative Model Updates: 301,570
Cumulative Timesteps: 2,515,093,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2515093026...
Checkpoint 2515093026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.20060
Policy Entropy: 2.56331
Value Function Loss: 0.02031

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.47455
Value Function Update Magnitude: 0.64464

Collected Steps per Second: 21,545.95919
Overall Steps per Second: 10,333.49720

Timestep Collection Time: 2.32155
Timestep Consumption Time: 2.51902
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.84057

Cumulative Model Updates: 301,576
Cumulative Timesteps: 2,515,143,046

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.43310
Policy Entropy: 2.57074
Value Function Loss: 0.01976

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.10101
Policy Update Magnitude: 0.46988
Value Function Update Magnitude: 0.64741

Collected Steps per Second: 21,489.30977
Overall Steps per Second: 10,429.33933

Timestep Collection Time: 2.32795
Timestep Consumption Time: 2.46871
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.79666

Cumulative Model Updates: 301,582
Cumulative Timesteps: 2,515,193,072

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2515193072...
Checkpoint 2515193072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.00385
Policy Entropy: 2.55416
Value Function Loss: 0.01917

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.09304
Policy Update Magnitude: 0.46792
Value Function Update Magnitude: 0.62548

Collected Steps per Second: 21,471.54775
Overall Steps per Second: 10,529.24814

Timestep Collection Time: 2.33015
Timestep Consumption Time: 2.42156
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.75172

Cumulative Model Updates: 301,588
Cumulative Timesteps: 2,515,243,104

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.39494
Policy Entropy: 2.55890
Value Function Loss: 0.01805

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.46878
Value Function Update Magnitude: 0.61866

Collected Steps per Second: 22,149.50566
Overall Steps per Second: 10,504.82081

Timestep Collection Time: 2.25784
Timestep Consumption Time: 2.50283
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.76067

Cumulative Model Updates: 301,594
Cumulative Timesteps: 2,515,293,114

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2515293114...
Checkpoint 2515293114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.25586
Policy Entropy: 2.52582
Value Function Loss: 0.01861

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.46763
Value Function Update Magnitude: 0.62076

Collected Steps per Second: 21,485.33083
Overall Steps per Second: 10,287.75285

Timestep Collection Time: 2.32782
Timestep Consumption Time: 2.53369
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.86151

Cumulative Model Updates: 301,600
Cumulative Timesteps: 2,515,343,128

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.49925
Policy Entropy: 2.55202
Value Function Loss: 0.01829

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.10352
Policy Update Magnitude: 0.47219
Value Function Update Magnitude: 0.60785

Collected Steps per Second: 21,868.99518
Overall Steps per Second: 10,413.22900

Timestep Collection Time: 2.28634
Timestep Consumption Time: 2.51524
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.80158

Cumulative Model Updates: 301,606
Cumulative Timesteps: 2,515,393,128

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2515393128...
Checkpoint 2515393128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.23278
Policy Entropy: 2.54501
Value Function Loss: 0.01980

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.10334
Policy Update Magnitude: 0.47191
Value Function Update Magnitude: 0.59866

Collected Steps per Second: 21,361.46584
Overall Steps per Second: 10,211.04702

Timestep Collection Time: 2.34123
Timestep Consumption Time: 2.55661
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.89783

Cumulative Model Updates: 301,612
Cumulative Timesteps: 2,515,443,140

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.88300
Policy Entropy: 2.53644
Value Function Loss: 0.02030

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.10381
Policy Update Magnitude: 0.47603
Value Function Update Magnitude: 0.62074

Collected Steps per Second: 21,971.74942
Overall Steps per Second: 10,489.86750

Timestep Collection Time: 2.27574
Timestep Consumption Time: 2.49095
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.76670

Cumulative Model Updates: 301,618
Cumulative Timesteps: 2,515,493,142

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2515493142...
Checkpoint 2515493142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.96330
Policy Entropy: 2.52268
Value Function Loss: 0.02196

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.10652
Policy Update Magnitude: 0.48760
Value Function Update Magnitude: 0.64745

Collected Steps per Second: 21,710.59391
Overall Steps per Second: 10,375.77951

Timestep Collection Time: 2.30376
Timestep Consumption Time: 2.51670
PPO Batch Consumption Time: 0.29604
Total Iteration Time: 4.82046

Cumulative Model Updates: 301,624
Cumulative Timesteps: 2,515,543,158

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.46026
Policy Entropy: 2.51894
Value Function Loss: 0.02077

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.11001
Policy Update Magnitude: 0.48889
Value Function Update Magnitude: 0.64382

Collected Steps per Second: 22,330.37509
Overall Steps per Second: 10,749.15254

Timestep Collection Time: 2.24000
Timestep Consumption Time: 2.41339
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.65339

Cumulative Model Updates: 301,630
Cumulative Timesteps: 2,515,593,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2515593178...
Checkpoint 2515593178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.05488
Policy Entropy: 2.52074
Value Function Loss: 0.01964

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.09905
Policy Update Magnitude: 0.48265
Value Function Update Magnitude: 0.62014

Collected Steps per Second: 21,523.48022
Overall Steps per Second: 10,236.69675

Timestep Collection Time: 2.32351
Timestep Consumption Time: 2.56186
PPO Batch Consumption Time: 0.30039
Total Iteration Time: 4.88536

Cumulative Model Updates: 301,636
Cumulative Timesteps: 2,515,643,188

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.39373
Policy Entropy: 2.52416
Value Function Loss: 0.01953

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.09104
Policy Update Magnitude: 0.48913
Value Function Update Magnitude: 0.60339

Collected Steps per Second: 22,066.58720
Overall Steps per Second: 10,400.75058

Timestep Collection Time: 2.26668
Timestep Consumption Time: 2.54239
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.80908

Cumulative Model Updates: 301,642
Cumulative Timesteps: 2,515,693,206

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2515693206...
Checkpoint 2515693206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.75715
Policy Entropy: 2.51729
Value Function Loss: 0.01870

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.09554
Policy Update Magnitude: 0.48603
Value Function Update Magnitude: 0.61815

Collected Steps per Second: 21,315.77984
Overall Steps per Second: 10,213.74553

Timestep Collection Time: 2.34577
Timestep Consumption Time: 2.54979
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.89556

Cumulative Model Updates: 301,648
Cumulative Timesteps: 2,515,743,208

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.90448
Policy Entropy: 2.52221
Value Function Loss: 0.01749

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.09510
Policy Update Magnitude: 0.47264
Value Function Update Magnitude: 0.61253

Collected Steps per Second: 21,803.78615
Overall Steps per Second: 10,466.73861

Timestep Collection Time: 2.29382
Timestep Consumption Time: 2.48455
PPO Batch Consumption Time: 0.29620
Total Iteration Time: 4.77837

Cumulative Model Updates: 301,654
Cumulative Timesteps: 2,515,793,222

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2515793222...
Checkpoint 2515793222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.18987
Policy Entropy: 2.51386
Value Function Loss: 0.01742

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.09154
Policy Update Magnitude: 0.47816
Value Function Update Magnitude: 0.61634

Collected Steps per Second: 21,165.96697
Overall Steps per Second: 10,189.43165

Timestep Collection Time: 2.36351
Timestep Consumption Time: 2.54609
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.90960

Cumulative Model Updates: 301,660
Cumulative Timesteps: 2,515,843,248

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.62175
Policy Entropy: 2.51893
Value Function Loss: 0.01932

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.10148
Policy Update Magnitude: 0.48787
Value Function Update Magnitude: 0.63618

Collected Steps per Second: 21,705.53441
Overall Steps per Second: 10,368.34942

Timestep Collection Time: 2.30430
Timestep Consumption Time: 2.51961
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.82391

Cumulative Model Updates: 301,666
Cumulative Timesteps: 2,515,893,264

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2515893264...
Checkpoint 2515893264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.35370
Policy Entropy: 2.51409
Value Function Loss: 0.02096

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.10350
Policy Update Magnitude: 0.48436
Value Function Update Magnitude: 0.62966

Collected Steps per Second: 21,464.09124
Overall Steps per Second: 10,286.88163

Timestep Collection Time: 2.32957
Timestep Consumption Time: 2.53119
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.86075

Cumulative Model Updates: 301,672
Cumulative Timesteps: 2,515,943,266

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.42517
Policy Entropy: 2.52159
Value Function Loss: 0.02103

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.09642
Policy Update Magnitude: 0.49169
Value Function Update Magnitude: 0.65329

Collected Steps per Second: 21,886.59374
Overall Steps per Second: 10,447.30666

Timestep Collection Time: 2.28450
Timestep Consumption Time: 2.50142
PPO Batch Consumption Time: 0.29949
Total Iteration Time: 4.78592

Cumulative Model Updates: 301,678
Cumulative Timesteps: 2,515,993,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2515993266...
Checkpoint 2515993266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.51992
Policy Entropy: 2.54152
Value Function Loss: 0.02058

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.09284
Policy Update Magnitude: 0.49844
Value Function Update Magnitude: 0.67342

Collected Steps per Second: 21,698.38465
Overall Steps per Second: 10,228.13974

Timestep Collection Time: 2.30533
Timestep Consumption Time: 2.58529
PPO Batch Consumption Time: 0.29864
Total Iteration Time: 4.89063

Cumulative Model Updates: 301,684
Cumulative Timesteps: 2,516,043,288

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.77047
Policy Entropy: 2.54620
Value Function Loss: 0.02088

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.09117
Policy Update Magnitude: 0.49626
Value Function Update Magnitude: 0.66515

Collected Steps per Second: 21,674.71100
Overall Steps per Second: 10,390.94103

Timestep Collection Time: 2.30730
Timestep Consumption Time: 2.50555
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.81285

Cumulative Model Updates: 301,690
Cumulative Timesteps: 2,516,093,298

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2516093298...
Checkpoint 2516093298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.22530
Policy Entropy: 2.56108
Value Function Loss: 0.01982

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.09018
Policy Update Magnitude: 0.48768
Value Function Update Magnitude: 0.64113

Collected Steps per Second: 21,530.31133
Overall Steps per Second: 10,292.54432

Timestep Collection Time: 2.32398
Timestep Consumption Time: 2.53740
PPO Batch Consumption Time: 0.30046
Total Iteration Time: 4.86138

Cumulative Model Updates: 301,696
Cumulative Timesteps: 2,516,143,334

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.81737
Policy Entropy: 2.53895
Value Function Loss: 0.01943

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.10541
Policy Update Magnitude: 0.48232
Value Function Update Magnitude: 0.60915

Collected Steps per Second: 21,863.67666
Overall Steps per Second: 10,439.50600

Timestep Collection Time: 2.28717
Timestep Consumption Time: 2.50290
PPO Batch Consumption Time: 0.30051
Total Iteration Time: 4.79007

Cumulative Model Updates: 301,702
Cumulative Timesteps: 2,516,193,340

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2516193340...
Checkpoint 2516193340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.98606
Policy Entropy: 2.53581
Value Function Loss: 0.01864

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.10620
Policy Update Magnitude: 0.47201
Value Function Update Magnitude: 0.63457

Collected Steps per Second: 21,712.19852
Overall Steps per Second: 10,290.81658

Timestep Collection Time: 2.30396
Timestep Consumption Time: 2.55707
PPO Batch Consumption Time: 0.29815
Total Iteration Time: 4.86103

Cumulative Model Updates: 301,708
Cumulative Timesteps: 2,516,243,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.54610
Policy Entropy: 2.53396
Value Function Loss: 0.01802

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.09569
Policy Update Magnitude: 0.47200
Value Function Update Magnitude: 0.65580

Collected Steps per Second: 22,088.92908
Overall Steps per Second: 10,344.96997

Timestep Collection Time: 2.26385
Timestep Consumption Time: 2.57000
PPO Batch Consumption Time: 0.29794
Total Iteration Time: 4.83385

Cumulative Model Updates: 301,714
Cumulative Timesteps: 2,516,293,370

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2516293370...
Checkpoint 2516293370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.27191
Policy Entropy: 2.52400
Value Function Loss: 0.01807

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.08745
Policy Update Magnitude: 0.47635
Value Function Update Magnitude: 0.64662

Collected Steps per Second: 21,401.91717
Overall Steps per Second: 10,252.11922

Timestep Collection Time: 2.33643
Timestep Consumption Time: 2.54100
PPO Batch Consumption Time: 0.29977
Total Iteration Time: 4.87743

Cumulative Model Updates: 301,720
Cumulative Timesteps: 2,516,343,374

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.64555
Policy Entropy: 2.52223
Value Function Loss: 0.01893

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.09525
Policy Update Magnitude: 0.47766
Value Function Update Magnitude: 0.63408

Collected Steps per Second: 21,967.38255
Overall Steps per Second: 10,492.33723

Timestep Collection Time: 2.27683
Timestep Consumption Time: 2.49008
PPO Batch Consumption Time: 0.29986
Total Iteration Time: 4.76691

Cumulative Model Updates: 301,726
Cumulative Timesteps: 2,516,393,390

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2516393390...
Checkpoint 2516393390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.10919
Policy Entropy: 2.53268
Value Function Loss: 0.01918

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.10569
Policy Update Magnitude: 0.47302
Value Function Update Magnitude: 0.65223

Collected Steps per Second: 21,554.78401
Overall Steps per Second: 10,256.56924

Timestep Collection Time: 2.32078
Timestep Consumption Time: 2.55648
PPO Batch Consumption Time: 0.29869
Total Iteration Time: 4.87726

Cumulative Model Updates: 301,732
Cumulative Timesteps: 2,516,443,414

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.65482
Policy Entropy: 2.52378
Value Function Loss: 0.01962

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.11530
Policy Update Magnitude: 0.48053
Value Function Update Magnitude: 0.67489

Collected Steps per Second: 21,910.61203
Overall Steps per Second: 10,337.74494

Timestep Collection Time: 2.28218
Timestep Consumption Time: 2.55485
PPO Batch Consumption Time: 0.29621
Total Iteration Time: 4.83703

Cumulative Model Updates: 301,738
Cumulative Timesteps: 2,516,493,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2516493418...
Checkpoint 2516493418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.57871
Policy Entropy: 2.52505
Value Function Loss: 0.02093

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.11799
Policy Update Magnitude: 0.49436
Value Function Update Magnitude: 0.66065

Collected Steps per Second: 21,789.26866
Overall Steps per Second: 10,355.20953

Timestep Collection Time: 2.29535
Timestep Consumption Time: 2.53449
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.82984

Cumulative Model Updates: 301,744
Cumulative Timesteps: 2,516,543,432

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.62738
Policy Entropy: 2.51127
Value Function Loss: 0.02045

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.11126
Policy Update Magnitude: 0.49368
Value Function Update Magnitude: 0.63387

Collected Steps per Second: 21,889.14002
Overall Steps per Second: 10,612.34955

Timestep Collection Time: 2.28469
Timestep Consumption Time: 2.42774
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.71243

Cumulative Model Updates: 301,750
Cumulative Timesteps: 2,516,593,442

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2516593442...
Checkpoint 2516593442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.97172
Policy Entropy: 2.54363
Value Function Loss: 0.01994

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.11261
Policy Update Magnitude: 0.47773
Value Function Update Magnitude: 0.60919

Collected Steps per Second: 21,690.13881
Overall Steps per Second: 10,337.79158

Timestep Collection Time: 2.30612
Timestep Consumption Time: 2.53244
PPO Batch Consumption Time: 0.29572
Total Iteration Time: 4.83856

Cumulative Model Updates: 301,756
Cumulative Timesteps: 2,516,643,462

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.50706
Policy Entropy: 2.53467
Value Function Loss: 0.02022

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.11117
Policy Update Magnitude: 0.47562
Value Function Update Magnitude: 0.61503

Collected Steps per Second: 21,720.66163
Overall Steps per Second: 10,415.04552

Timestep Collection Time: 2.30306
Timestep Consumption Time: 2.49999
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.80305

Cumulative Model Updates: 301,762
Cumulative Timesteps: 2,516,693,486

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2516693486...
Checkpoint 2516693486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.89731
Policy Entropy: 2.53473
Value Function Loss: 0.02037

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.48951
Value Function Update Magnitude: 0.64896

Collected Steps per Second: 21,469.87359
Overall Steps per Second: 10,282.42008

Timestep Collection Time: 2.32912
Timestep Consumption Time: 2.53413
PPO Batch Consumption Time: 0.29977
Total Iteration Time: 4.86325

Cumulative Model Updates: 301,768
Cumulative Timesteps: 2,516,743,492

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.96911
Policy Entropy: 2.53385
Value Function Loss: 0.01916

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.09791
Policy Update Magnitude: 0.48728
Value Function Update Magnitude: 0.66831

Collected Steps per Second: 21,679.92415
Overall Steps per Second: 10,410.53854

Timestep Collection Time: 2.30766
Timestep Consumption Time: 2.49804
PPO Batch Consumption Time: 0.29983
Total Iteration Time: 4.80571

Cumulative Model Updates: 301,774
Cumulative Timesteps: 2,516,793,522

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2516793522...
Checkpoint 2516793522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.40912
Policy Entropy: 2.52826
Value Function Loss: 0.01782

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.09217
Policy Update Magnitude: 0.47482
Value Function Update Magnitude: 0.65759

Collected Steps per Second: 21,507.01623
Overall Steps per Second: 10,232.60839

Timestep Collection Time: 2.32510
Timestep Consumption Time: 2.56182
PPO Batch Consumption Time: 0.29950
Total Iteration Time: 4.88693

Cumulative Model Updates: 301,780
Cumulative Timesteps: 2,516,843,528

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.18050
Policy Entropy: 2.51383
Value Function Loss: 0.01819

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.09045
Policy Update Magnitude: 0.47327
Value Function Update Magnitude: 0.65049

Collected Steps per Second: 21,920.78368
Overall Steps per Second: 10,483.50470

Timestep Collection Time: 2.28131
Timestep Consumption Time: 2.48886
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.77016

Cumulative Model Updates: 301,786
Cumulative Timesteps: 2,516,893,536

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2516893536...
Checkpoint 2516893536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.99233
Policy Entropy: 2.51587
Value Function Loss: 0.01911

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.09960
Policy Update Magnitude: 0.46939
Value Function Update Magnitude: 0.64712

Collected Steps per Second: 21,897.07429
Overall Steps per Second: 10,543.98514

Timestep Collection Time: 2.28423
Timestep Consumption Time: 2.45952
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.74375

Cumulative Model Updates: 301,792
Cumulative Timesteps: 2,516,943,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.75912
Policy Entropy: 2.53070
Value Function Loss: 0.01947

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.09167
Policy Update Magnitude: 0.47643
Value Function Update Magnitude: 0.66026

Collected Steps per Second: 21,570.82933
Overall Steps per Second: 10,474.62747

Timestep Collection Time: 2.31906
Timestep Consumption Time: 2.45667
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.77573

Cumulative Model Updates: 301,798
Cumulative Timesteps: 2,516,993,578

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2516993578...
Checkpoint 2516993578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.61074
Policy Entropy: 2.55139
Value Function Loss: 0.01848

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.09892
Policy Update Magnitude: 0.46882
Value Function Update Magnitude: 0.66372

Collected Steps per Second: 21,616.44043
Overall Steps per Second: 10,257.88376

Timestep Collection Time: 2.31315
Timestep Consumption Time: 2.56135
PPO Batch Consumption Time: 0.30007
Total Iteration Time: 4.87449

Cumulative Model Updates: 301,804
Cumulative Timesteps: 2,517,043,580

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.45413
Policy Entropy: 2.54348
Value Function Loss: 0.01831

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.09630
Policy Update Magnitude: 0.47095
Value Function Update Magnitude: 0.63820

Collected Steps per Second: 21,615.87669
Overall Steps per Second: 10,306.33121

Timestep Collection Time: 2.31348
Timestep Consumption Time: 2.53868
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.85216

Cumulative Model Updates: 301,810
Cumulative Timesteps: 2,517,093,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2517093588...
Checkpoint 2517093588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.16934
Policy Entropy: 2.52310
Value Function Loss: 0.01837

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.47515
Value Function Update Magnitude: 0.62057

Collected Steps per Second: 21,789.56401
Overall Steps per Second: 10,553.59729

Timestep Collection Time: 2.29523
Timestep Consumption Time: 2.44363
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.73886

Cumulative Model Updates: 301,816
Cumulative Timesteps: 2,517,143,600

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.28218
Policy Entropy: 2.51849
Value Function Loss: 0.01895

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.10324
Policy Update Magnitude: 0.46509
Value Function Update Magnitude: 0.61310

Collected Steps per Second: 21,967.72409
Overall Steps per Second: 10,357.94087

Timestep Collection Time: 2.27743
Timestep Consumption Time: 2.55268
PPO Batch Consumption Time: 0.29719
Total Iteration Time: 4.83011

Cumulative Model Updates: 301,822
Cumulative Timesteps: 2,517,193,630

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2517193630...
Checkpoint 2517193630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.90222
Policy Entropy: 2.49002
Value Function Loss: 0.01960

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.10418
Policy Update Magnitude: 0.47207
Value Function Update Magnitude: 0.60954

Collected Steps per Second: 21,898.37095
Overall Steps per Second: 10,458.12211

Timestep Collection Time: 2.28455
Timestep Consumption Time: 2.49910
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.78365

Cumulative Model Updates: 301,828
Cumulative Timesteps: 2,517,243,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.50843
Policy Entropy: 2.49059
Value Function Loss: 0.02017

Mean KL Divergence: 0.02423
SB3 Clip Fraction: 0.14086
Policy Update Magnitude: 0.46561
Value Function Update Magnitude: 0.63518

Collected Steps per Second: 21,505.24414
Overall Steps per Second: 10,411.88058

Timestep Collection Time: 2.32613
Timestep Consumption Time: 2.47838
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.80451

Cumulative Model Updates: 301,834
Cumulative Timesteps: 2,517,293,682

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2517293682...
Checkpoint 2517293682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.65201
Policy Entropy: 2.49378
Value Function Loss: 0.01950

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.12007
Policy Update Magnitude: 0.47230
Value Function Update Magnitude: 0.65152

Collected Steps per Second: 21,768.71577
Overall Steps per Second: 10,363.66867

Timestep Collection Time: 2.29770
Timestep Consumption Time: 2.52858
PPO Batch Consumption Time: 0.29978
Total Iteration Time: 4.82628

Cumulative Model Updates: 301,840
Cumulative Timesteps: 2,517,343,700

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.10162
Policy Entropy: 2.51124
Value Function Loss: 0.01812

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.10706
Policy Update Magnitude: 0.49052
Value Function Update Magnitude: 0.65022

Collected Steps per Second: 22,234.62913
Overall Steps per Second: 10,392.16027

Timestep Collection Time: 2.24946
Timestep Consumption Time: 2.56339
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.81286

Cumulative Model Updates: 301,846
Cumulative Timesteps: 2,517,393,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2517393716...
Checkpoint 2517393716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.36932
Policy Entropy: 2.52080
Value Function Loss: 0.01825

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.10361
Policy Update Magnitude: 0.48827
Value Function Update Magnitude: 0.65712

Collected Steps per Second: 21,354.22934
Overall Steps per Second: 10,212.72669

Timestep Collection Time: 2.34267
Timestep Consumption Time: 2.55572
PPO Batch Consumption Time: 0.29784
Total Iteration Time: 4.89840

Cumulative Model Updates: 301,852
Cumulative Timesteps: 2,517,443,742

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.82661
Policy Entropy: 2.52010
Value Function Loss: 0.01916

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.10380
Policy Update Magnitude: 0.48375
Value Function Update Magnitude: 0.63839

Collected Steps per Second: 21,663.10076
Overall Steps per Second: 10,466.90823

Timestep Collection Time: 2.30900
Timestep Consumption Time: 2.46988
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.77887

Cumulative Model Updates: 301,858
Cumulative Timesteps: 2,517,493,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2517493762...
Checkpoint 2517493762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.11775
Policy Entropy: 2.50860
Value Function Loss: 0.02018

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.10204
Policy Update Magnitude: 0.48663
Value Function Update Magnitude: 0.64437

Collected Steps per Second: 21,675.67646
Overall Steps per Second: 10,581.51175

Timestep Collection Time: 2.30729
Timestep Consumption Time: 2.41907
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.72636

Cumulative Model Updates: 301,864
Cumulative Timesteps: 2,517,543,774

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.63888
Policy Entropy: 2.50147
Value Function Loss: 0.02129

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.10071
Policy Update Magnitude: 0.49977
Value Function Update Magnitude: 0.67753

Collected Steps per Second: 21,437.63515
Overall Steps per Second: 10,248.53917

Timestep Collection Time: 2.33253
Timestep Consumption Time: 2.54660
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.87913

Cumulative Model Updates: 301,870
Cumulative Timesteps: 2,517,593,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2517593778...
Checkpoint 2517593778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.28682
Policy Entropy: 2.49694
Value Function Loss: 0.02031

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.50718
Value Function Update Magnitude: 0.68263

Collected Steps per Second: 21,804.34722
Overall Steps per Second: 10,434.30979

Timestep Collection Time: 2.29385
Timestep Consumption Time: 2.49956
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.79342

Cumulative Model Updates: 301,876
Cumulative Timesteps: 2,517,643,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.38309
Policy Entropy: 2.49490
Value Function Loss: 0.02115

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.09057
Policy Update Magnitude: 0.50443
Value Function Update Magnitude: 0.68271

Collected Steps per Second: 21,797.57187
Overall Steps per Second: 10,502.23821

Timestep Collection Time: 2.29457
Timestep Consumption Time: 2.46785
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.76241

Cumulative Model Updates: 301,882
Cumulative Timesteps: 2,517,693,810

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2517693810...
Checkpoint 2517693810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.01797
Policy Entropy: 2.49775
Value Function Loss: 0.02070

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.49326
Value Function Update Magnitude: 0.68566

Collected Steps per Second: 21,662.35560
Overall Steps per Second: 10,297.27054

Timestep Collection Time: 2.30898
Timestep Consumption Time: 2.54842
PPO Batch Consumption Time: 0.30240
Total Iteration Time: 4.85740

Cumulative Model Updates: 301,888
Cumulative Timesteps: 2,517,743,828

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.91206
Policy Entropy: 2.48826
Value Function Loss: 0.02093

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.10030
Policy Update Magnitude: 0.48198
Value Function Update Magnitude: 0.66725

Collected Steps per Second: 21,755.38969
Overall Steps per Second: 10,488.77301

Timestep Collection Time: 2.29929
Timestep Consumption Time: 2.46981
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 4.76910

Cumulative Model Updates: 301,894
Cumulative Timesteps: 2,517,793,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2517793850...
Checkpoint 2517793850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.73015
Policy Entropy: 2.47895
Value Function Loss: 0.02051

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.10240
Policy Update Magnitude: 0.49056
Value Function Update Magnitude: 0.68781

Collected Steps per Second: 21,719.28257
Overall Steps per Second: 10,406.63703

Timestep Collection Time: 2.30339
Timestep Consumption Time: 2.50393
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.80732

Cumulative Model Updates: 301,900
Cumulative Timesteps: 2,517,843,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.56628
Policy Entropy: 2.47223
Value Function Loss: 0.02107

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.49805
Value Function Update Magnitude: 0.69442

Collected Steps per Second: 21,899.06088
Overall Steps per Second: 10,422.61525

Timestep Collection Time: 2.28375
Timestep Consumption Time: 2.51466
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.79841

Cumulative Model Updates: 301,906
Cumulative Timesteps: 2,517,893,890

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2517893890...
Checkpoint 2517893890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.95064
Policy Entropy: 2.47487
Value Function Loss: 0.02048

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.09440
Policy Update Magnitude: 0.50837
Value Function Update Magnitude: 0.71085

Collected Steps per Second: 22,004.77209
Overall Steps per Second: 10,426.51857

Timestep Collection Time: 2.27305
Timestep Consumption Time: 2.52414
PPO Batch Consumption Time: 0.29967
Total Iteration Time: 4.79719

Cumulative Model Updates: 301,912
Cumulative Timesteps: 2,517,943,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.27151
Policy Entropy: 2.47238
Value Function Loss: 0.02093

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.50560
Value Function Update Magnitude: 0.71544

Collected Steps per Second: 22,626.49162
Overall Steps per Second: 10,462.85323

Timestep Collection Time: 2.21051
Timestep Consumption Time: 2.56983
PPO Batch Consumption Time: 0.29884
Total Iteration Time: 4.78034

Cumulative Model Updates: 301,918
Cumulative Timesteps: 2,517,993,924

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2517993924...
Checkpoint 2517993924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.78748
Policy Entropy: 2.46397
Value Function Loss: 0.02111

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.10415
Policy Update Magnitude: 0.50109
Value Function Update Magnitude: 0.71651

Collected Steps per Second: 21,991.01814
Overall Steps per Second: 10,443.14833

Timestep Collection Time: 2.27438
Timestep Consumption Time: 2.51498
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.78936

Cumulative Model Updates: 301,924
Cumulative Timesteps: 2,518,043,940

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.36235
Policy Entropy: 2.46092
Value Function Loss: 0.02045

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.09879
Policy Update Magnitude: 0.50725
Value Function Update Magnitude: 0.71831

Collected Steps per Second: 21,747.84012
Overall Steps per Second: 10,462.94570

Timestep Collection Time: 2.29954
Timestep Consumption Time: 2.48019
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.77972

Cumulative Model Updates: 301,930
Cumulative Timesteps: 2,518,093,950

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2518093950...
Checkpoint 2518093950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.34891
Policy Entropy: 2.46393
Value Function Loss: 0.02053

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.09066
Policy Update Magnitude: 0.51132
Value Function Update Magnitude: 0.71879

Collected Steps per Second: 21,905.32328
Overall Steps per Second: 10,677.15320

Timestep Collection Time: 2.28264
Timestep Consumption Time: 2.40044
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.68308

Cumulative Model Updates: 301,936
Cumulative Timesteps: 2,518,143,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.13622
Policy Entropy: 2.47919
Value Function Loss: 0.02054

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.51463
Value Function Update Magnitude: 0.74378

Collected Steps per Second: 21,715.30981
Overall Steps per Second: 10,400.04544

Timestep Collection Time: 2.30381
Timestep Consumption Time: 2.50655
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.81036

Cumulative Model Updates: 301,942
Cumulative Timesteps: 2,518,193,980

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2518193980...
Checkpoint 2518193980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.19988
Policy Entropy: 2.48462
Value Function Loss: 0.01924

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.50751
Value Function Update Magnitude: 0.75752

Collected Steps per Second: 21,586.11641
Overall Steps per Second: 10,319.70214

Timestep Collection Time: 2.31677
Timestep Consumption Time: 2.52930
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.84607

Cumulative Model Updates: 301,948
Cumulative Timesteps: 2,518,243,990

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.16527
Policy Entropy: 2.50821
Value Function Loss: 0.01930

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.48209
Value Function Update Magnitude: 0.73365

Collected Steps per Second: 21,694.18315
Overall Steps per Second: 10,473.46069

Timestep Collection Time: 2.30550
Timestep Consumption Time: 2.47000
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.77550

Cumulative Model Updates: 301,954
Cumulative Timesteps: 2,518,294,006

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2518294006...
Checkpoint 2518294006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.52391
Policy Entropy: 2.50958
Value Function Loss: 0.01979

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.10643
Policy Update Magnitude: 0.49135
Value Function Update Magnitude: 0.71933

Collected Steps per Second: 21,763.56029
Overall Steps per Second: 10,635.44113

Timestep Collection Time: 2.29806
Timestep Consumption Time: 2.40452
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.70258

Cumulative Model Updates: 301,960
Cumulative Timesteps: 2,518,344,020

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.84453
Policy Entropy: 2.50963
Value Function Loss: 0.02047

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.10295
Policy Update Magnitude: 0.49538
Value Function Update Magnitude: 0.70527

Collected Steps per Second: 21,676.89296
Overall Steps per Second: 10,292.62121

Timestep Collection Time: 2.30771
Timestep Consumption Time: 2.55247
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.86018

Cumulative Model Updates: 301,966
Cumulative Timesteps: 2,518,394,044

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2518394044...
Checkpoint 2518394044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.13247
Policy Entropy: 2.51290
Value Function Loss: 0.02105

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.09746
Policy Update Magnitude: 0.49240
Value Function Update Magnitude: 0.68559

Collected Steps per Second: 21,819.45213
Overall Steps per Second: 10,337.54381

Timestep Collection Time: 2.29236
Timestep Consumption Time: 2.54612
PPO Batch Consumption Time: 0.29608
Total Iteration Time: 4.83848

Cumulative Model Updates: 301,972
Cumulative Timesteps: 2,518,444,062

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.46601
Policy Entropy: 2.51716
Value Function Loss: 0.02079

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.09689
Policy Update Magnitude: 0.49459
Value Function Update Magnitude: 0.69952

Collected Steps per Second: 21,827.78446
Overall Steps per Second: 10,475.39391

Timestep Collection Time: 2.29066
Timestep Consumption Time: 2.48243
PPO Batch Consumption Time: 0.29722
Total Iteration Time: 4.77309

Cumulative Model Updates: 301,978
Cumulative Timesteps: 2,518,494,062

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2518494062...
Checkpoint 2518494062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.42976
Policy Entropy: 2.51461
Value Function Loss: 0.02053

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.10575
Policy Update Magnitude: 0.48720
Value Function Update Magnitude: 0.71546

Collected Steps per Second: 21,600.52020
Overall Steps per Second: 10,257.85626

Timestep Collection Time: 2.31541
Timestep Consumption Time: 2.56027
PPO Batch Consumption Time: 0.29933
Total Iteration Time: 4.87568

Cumulative Model Updates: 301,984
Cumulative Timesteps: 2,518,544,076

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.30598
Policy Entropy: 2.50901
Value Function Loss: 0.01934

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.10645
Policy Update Magnitude: 0.48537
Value Function Update Magnitude: 0.71320

Collected Steps per Second: 22,003.96635
Overall Steps per Second: 10,381.33897

Timestep Collection Time: 2.27232
Timestep Consumption Time: 2.54402
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.81633

Cumulative Model Updates: 301,990
Cumulative Timesteps: 2,518,594,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2518594076...
Checkpoint 2518594076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.49925
Policy Entropy: 2.50958
Value Function Loss: 0.01957

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 0.48856
Value Function Update Magnitude: 0.69054

Collected Steps per Second: 21,732.20680
Overall Steps per Second: 10,363.62824

Timestep Collection Time: 2.30119
Timestep Consumption Time: 2.52434
PPO Batch Consumption Time: 0.29723
Total Iteration Time: 4.82553

Cumulative Model Updates: 301,996
Cumulative Timesteps: 2,518,644,086

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.36048
Policy Entropy: 2.51003
Value Function Loss: 0.02013

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.10864
Policy Update Magnitude: 0.49928
Value Function Update Magnitude: 0.68984

Collected Steps per Second: 21,575.35083
Overall Steps per Second: 10,321.86243

Timestep Collection Time: 2.31857
Timestep Consumption Time: 2.52784
PPO Batch Consumption Time: 0.29513
Total Iteration Time: 4.84641

Cumulative Model Updates: 302,002
Cumulative Timesteps: 2,518,694,110

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2518694110...
Checkpoint 2518694110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.37793
Policy Entropy: 2.49714
Value Function Loss: 0.02015

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.10678
Policy Update Magnitude: 0.49340
Value Function Update Magnitude: 0.72219

Collected Steps per Second: 22,260.73063
Overall Steps per Second: 10,576.04475

Timestep Collection Time: 2.24719
Timestep Consumption Time: 2.48275
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.72993

Cumulative Model Updates: 302,008
Cumulative Timesteps: 2,518,744,134

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.09531
Policy Entropy: 2.47586
Value Function Loss: 0.01975

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.10862
Policy Update Magnitude: 0.50541
Value Function Update Magnitude: 0.72133

Collected Steps per Second: 22,042.55907
Overall Steps per Second: 10,480.39604

Timestep Collection Time: 2.26952
Timestep Consumption Time: 2.50377
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.77329

Cumulative Model Updates: 302,014
Cumulative Timesteps: 2,518,794,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2518794160...
Checkpoint 2518794160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.05100
Policy Entropy: 2.48203
Value Function Loss: 0.01978

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.11708
Policy Update Magnitude: 0.50589
Value Function Update Magnitude: 0.73309

Collected Steps per Second: 21,629.99053
Overall Steps per Second: 10,320.64643

Timestep Collection Time: 2.31281
Timestep Consumption Time: 2.53437
PPO Batch Consumption Time: 0.29993
Total Iteration Time: 4.84718

Cumulative Model Updates: 302,020
Cumulative Timesteps: 2,518,844,186

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.90043
Policy Entropy: 2.49131
Value Function Loss: 0.02012

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.11264
Policy Update Magnitude: 0.51123
Value Function Update Magnitude: 0.73388

Collected Steps per Second: 22,057.12989
Overall Steps per Second: 10,561.86923

Timestep Collection Time: 2.26757
Timestep Consumption Time: 2.46796
PPO Batch Consumption Time: 0.29700
Total Iteration Time: 4.73553

Cumulative Model Updates: 302,026
Cumulative Timesteps: 2,518,894,202

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2518894202...
Checkpoint 2518894202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.47704
Policy Entropy: 2.52634
Value Function Loss: 0.01862

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.11055
Policy Update Magnitude: 0.48985
Value Function Update Magnitude: 0.72390

Collected Steps per Second: 21,614.75092
Overall Steps per Second: 10,406.68195

Timestep Collection Time: 2.31425
Timestep Consumption Time: 2.49247
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.80672

Cumulative Model Updates: 302,032
Cumulative Timesteps: 2,518,944,224

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.55147
Policy Entropy: 2.52490
Value Function Loss: 0.01854

Mean KL Divergence: 0.02443
SB3 Clip Fraction: 0.14051
Policy Update Magnitude: 0.46254
Value Function Update Magnitude: 0.71563

Collected Steps per Second: 22,120.65883
Overall Steps per Second: 10,509.81337

Timestep Collection Time: 2.26096
Timestep Consumption Time: 2.49783
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.75879

Cumulative Model Updates: 302,038
Cumulative Timesteps: 2,518,994,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2518994238...
Checkpoint 2518994238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.47037
Policy Entropy: 2.50547
Value Function Loss: 0.01938

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.11265
Policy Update Magnitude: 0.50328
Value Function Update Magnitude: 0.71389

Collected Steps per Second: 21,310.99009
Overall Steps per Second: 10,127.97341

Timestep Collection Time: 2.34762
Timestep Consumption Time: 2.59217
PPO Batch Consumption Time: 0.31049
Total Iteration Time: 4.93978

Cumulative Model Updates: 302,044
Cumulative Timesteps: 2,519,044,268

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.24007
Policy Entropy: 2.48900
Value Function Loss: 0.02214

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.10283
Policy Update Magnitude: 0.52262
Value Function Update Magnitude: 0.72747

Collected Steps per Second: 22,129.72195
Overall Steps per Second: 10,593.31101

Timestep Collection Time: 2.25940
Timestep Consumption Time: 2.46055
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.71996

Cumulative Model Updates: 302,050
Cumulative Timesteps: 2,519,094,268

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2519094268...
Checkpoint 2519094268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.13125
Policy Entropy: 2.48861
Value Function Loss: 0.02172

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.10821
Policy Update Magnitude: 0.52530
Value Function Update Magnitude: 0.75246

Collected Steps per Second: 21,526.92163
Overall Steps per Second: 10,252.29239

Timestep Collection Time: 2.32379
Timestep Consumption Time: 2.55551
PPO Batch Consumption Time: 0.29905
Total Iteration Time: 4.87930

Cumulative Model Updates: 302,056
Cumulative Timesteps: 2,519,144,292

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.02494
Policy Entropy: 2.50898
Value Function Loss: 0.02135

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.09655
Policy Update Magnitude: 0.52120
Value Function Update Magnitude: 0.74997

Collected Steps per Second: 21,802.86885
Overall Steps per Second: 10,367.11698

Timestep Collection Time: 2.29419
Timestep Consumption Time: 2.53068
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.82487

Cumulative Model Updates: 302,062
Cumulative Timesteps: 2,519,194,312

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2519194312...
Checkpoint 2519194312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.04482
Policy Entropy: 2.50655
Value Function Loss: 0.01932

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.09080
Policy Update Magnitude: 0.50879
Value Function Update Magnitude: 0.71771

Collected Steps per Second: 21,444.45163
Overall Steps per Second: 10,269.85939

Timestep Collection Time: 2.33300
Timestep Consumption Time: 2.53853
PPO Batch Consumption Time: 0.30023
Total Iteration Time: 4.87154

Cumulative Model Updates: 302,068
Cumulative Timesteps: 2,519,244,342

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.15651
Policy Entropy: 2.51151
Value Function Loss: 0.01976

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.09698
Policy Update Magnitude: 0.50376
Value Function Update Magnitude: 0.68920

Collected Steps per Second: 20,994.75463
Overall Steps per Second: 10,404.67374

Timestep Collection Time: 2.38240
Timestep Consumption Time: 2.42486
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.80726

Cumulative Model Updates: 302,074
Cumulative Timesteps: 2,519,294,360

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2519294360...
Checkpoint 2519294360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.92733
Policy Entropy: 2.52448
Value Function Loss: 0.01916

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.12383
Policy Update Magnitude: 0.47215
Value Function Update Magnitude: 0.69235

Collected Steps per Second: 21,412.36846
Overall Steps per Second: 10,207.92867

Timestep Collection Time: 2.33529
Timestep Consumption Time: 2.56326
PPO Batch Consumption Time: 0.29784
Total Iteration Time: 4.89855

Cumulative Model Updates: 302,080
Cumulative Timesteps: 2,519,344,364

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.82023
Policy Entropy: 2.53413
Value Function Loss: 0.02063

Mean KL Divergence: 0.02475
SB3 Clip Fraction: 0.14636
Policy Update Magnitude: 0.45035
Value Function Update Magnitude: 0.69348

Collected Steps per Second: 21,948.63967
Overall Steps per Second: 10,435.11245

Timestep Collection Time: 2.27969
Timestep Consumption Time: 2.51528
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.79497

Cumulative Model Updates: 302,086
Cumulative Timesteps: 2,519,394,400

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2519394400...
Checkpoint 2519394400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.32671
Policy Entropy: 2.53691
Value Function Loss: 0.02047

Mean KL Divergence: 0.02527
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.49286
Value Function Update Magnitude: 0.68647

Collected Steps per Second: 21,563.60918
Overall Steps per Second: 10,276.92287

Timestep Collection Time: 2.31909
Timestep Consumption Time: 2.54696
PPO Batch Consumption Time: 0.30047
Total Iteration Time: 4.86605

Cumulative Model Updates: 302,092
Cumulative Timesteps: 2,519,444,408

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.60196
Policy Entropy: 2.53873
Value Function Loss: 0.01966

Mean KL Divergence: 0.02499
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.50115
Value Function Update Magnitude: 0.68750

Collected Steps per Second: 21,834.01730
Overall Steps per Second: 10,449.44170

Timestep Collection Time: 2.29147
Timestep Consumption Time: 2.49654
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.78801

Cumulative Model Updates: 302,098
Cumulative Timesteps: 2,519,494,440

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2519494440...
Checkpoint 2519494440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.71163
Policy Entropy: 2.54403
Value Function Loss: 0.01826

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.48863
Value Function Update Magnitude: 0.67960

Collected Steps per Second: 22,258.96747
Overall Steps per Second: 10,549.75263

Timestep Collection Time: 2.24718
Timestep Consumption Time: 2.49416
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.74134

Cumulative Model Updates: 302,104
Cumulative Timesteps: 2,519,544,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.99830
Policy Entropy: 2.55842
Value Function Loss: 0.01872

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.11005
Policy Update Magnitude: 0.49037
Value Function Update Magnitude: 0.68248

Collected Steps per Second: 21,946.20652
Overall Steps per Second: 10,456.67906

Timestep Collection Time: 2.27866
Timestep Consumption Time: 2.50374
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.78240

Cumulative Model Updates: 302,110
Cumulative Timesteps: 2,519,594,468

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2519594468...
Checkpoint 2519594468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.12506
Policy Entropy: 2.54703
Value Function Loss: 0.01978

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.12738
Policy Update Magnitude: 0.47737
Value Function Update Magnitude: 0.72503

Collected Steps per Second: 21,318.06110
Overall Steps per Second: 10,311.17051

Timestep Collection Time: 2.34674
Timestep Consumption Time: 2.50508
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.85183

Cumulative Model Updates: 302,116
Cumulative Timesteps: 2,519,644,496

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.80882
Policy Entropy: 2.55084
Value Function Loss: 0.01979

Mean KL Divergence: 0.02385
SB3 Clip Fraction: 0.14017
Policy Update Magnitude: 0.47855
Value Function Update Magnitude: 0.72632

Collected Steps per Second: 21,606.37345
Overall Steps per Second: 10,345.25944

Timestep Collection Time: 2.31571
Timestep Consumption Time: 2.52071
PPO Batch Consumption Time: 0.30655
Total Iteration Time: 4.83642

Cumulative Model Updates: 302,122
Cumulative Timesteps: 2,519,694,530

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2519694530...
Checkpoint 2519694530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.03539
Policy Entropy: 2.53500
Value Function Loss: 0.02081

Mean KL Divergence: 0.02212
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.47301
Value Function Update Magnitude: 0.71774

Collected Steps per Second: 21,821.79392
Overall Steps per Second: 10,345.46066

Timestep Collection Time: 2.29230
Timestep Consumption Time: 2.54287
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.83516

Cumulative Model Updates: 302,128
Cumulative Timesteps: 2,519,744,552

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.71955
Policy Entropy: 2.53517
Value Function Loss: 0.02027

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.12189
Policy Update Magnitude: 0.48456
Value Function Update Magnitude: 0.70515

Collected Steps per Second: 21,755.45869
Overall Steps per Second: 10,405.52707

Timestep Collection Time: 2.29956
Timestep Consumption Time: 2.50827
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.80783

Cumulative Model Updates: 302,134
Cumulative Timesteps: 2,519,794,580

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2519794580...
Checkpoint 2519794580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.59287
Policy Entropy: 2.52405
Value Function Loss: 0.02047

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.13202
Policy Update Magnitude: 0.46839
Value Function Update Magnitude: 0.68157

Collected Steps per Second: 21,585.79763
Overall Steps per Second: 10,286.67974

Timestep Collection Time: 2.31643
Timestep Consumption Time: 2.54442
PPO Batch Consumption Time: 0.30063
Total Iteration Time: 4.86085

Cumulative Model Updates: 302,140
Cumulative Timesteps: 2,519,844,582

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.74035
Policy Entropy: 2.54147
Value Function Loss: 0.02023

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.12100
Policy Update Magnitude: 0.47057
Value Function Update Magnitude: 0.68968

Collected Steps per Second: 21,946.21444
Overall Steps per Second: 10,517.11990

Timestep Collection Time: 2.27930
Timestep Consumption Time: 2.47695
PPO Batch Consumption Time: 0.29780
Total Iteration Time: 4.75625

Cumulative Model Updates: 302,146
Cumulative Timesteps: 2,519,894,604

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2519894604...
Checkpoint 2519894604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.08146
Policy Entropy: 2.52246
Value Function Loss: 0.01985

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.10971
Policy Update Magnitude: 0.49309
Value Function Update Magnitude: 0.69430

Collected Steps per Second: 21,945.76123
Overall Steps per Second: 10,456.72114

Timestep Collection Time: 2.27834
Timestep Consumption Time: 2.50327
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.78161

Cumulative Model Updates: 302,152
Cumulative Timesteps: 2,519,944,604

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.72198
Policy Entropy: 2.53398
Value Function Loss: 0.02089

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.10378
Policy Update Magnitude: 0.49919
Value Function Update Magnitude: 0.69808

Collected Steps per Second: 21,720.09273
Overall Steps per Second: 10,459.38656

Timestep Collection Time: 2.30275
Timestep Consumption Time: 2.47917
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.78192

Cumulative Model Updates: 302,158
Cumulative Timesteps: 2,519,994,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2519994620...
Checkpoint 2519994620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.92900
Policy Entropy: 2.53652
Value Function Loss: 0.01982

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.49799
Value Function Update Magnitude: 0.69299

Collected Steps per Second: 21,623.84539
Overall Steps per Second: 10,475.21031

Timestep Collection Time: 2.31309
Timestep Consumption Time: 2.46180
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.77489

Cumulative Model Updates: 302,164
Cumulative Timesteps: 2,520,044,638

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.76681
Policy Entropy: 2.53729
Value Function Loss: 0.02012

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.09747
Policy Update Magnitude: 0.50004
Value Function Update Magnitude: 0.69203

Collected Steps per Second: 21,602.52867
Overall Steps per Second: 10,450.92412

Timestep Collection Time: 2.31584
Timestep Consumption Time: 2.47111
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.78695

Cumulative Model Updates: 302,170
Cumulative Timesteps: 2,520,094,666

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2520094666...
Checkpoint 2520094666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.87465
Policy Entropy: 2.52501
Value Function Loss: 0.02031

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.10218
Policy Update Magnitude: 0.51071
Value Function Update Magnitude: 0.67726

Collected Steps per Second: 21,377.63331
Overall Steps per Second: 10,379.38217

Timestep Collection Time: 2.33899
Timestep Consumption Time: 2.47845
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.81744

Cumulative Model Updates: 302,176
Cumulative Timesteps: 2,520,144,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.66763
Policy Entropy: 2.51401
Value Function Loss: 0.02011

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.50007
Value Function Update Magnitude: 0.67505

Collected Steps per Second: 21,848.44810
Overall Steps per Second: 10,416.31470

Timestep Collection Time: 2.28858
Timestep Consumption Time: 2.51177
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.80035

Cumulative Model Updates: 302,182
Cumulative Timesteps: 2,520,194,670

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2520194670...
Checkpoint 2520194670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.39286
Policy Entropy: 2.53715
Value Function Loss: 0.01881

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.10685
Policy Update Magnitude: 0.48333
Value Function Update Magnitude: 0.68130

Collected Steps per Second: 21,656.48654
Overall Steps per Second: 10,304.52831

Timestep Collection Time: 2.30952
Timestep Consumption Time: 2.54427
PPO Batch Consumption Time: 0.29860
Total Iteration Time: 4.85379

Cumulative Model Updates: 302,188
Cumulative Timesteps: 2,520,244,686

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.97586
Policy Entropy: 2.54675
Value Function Loss: 0.01837

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.09824
Policy Update Magnitude: 0.47772
Value Function Update Magnitude: 0.65228

Collected Steps per Second: 22,604.33611
Overall Steps per Second: 10,394.78568

Timestep Collection Time: 2.21232
Timestep Consumption Time: 2.59855
PPO Batch Consumption Time: 0.30282
Total Iteration Time: 4.81087

Cumulative Model Updates: 302,194
Cumulative Timesteps: 2,520,294,694

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2520294694...
Checkpoint 2520294694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.44483
Policy Entropy: 2.55097
Value Function Loss: 0.01933

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.09843
Policy Update Magnitude: 0.47791
Value Function Update Magnitude: 0.63809

Collected Steps per Second: 21,638.60509
Overall Steps per Second: 10,168.03570

Timestep Collection Time: 2.31105
Timestep Consumption Time: 2.60710
PPO Batch Consumption Time: 0.30708
Total Iteration Time: 4.91816

Cumulative Model Updates: 302,200
Cumulative Timesteps: 2,520,344,702

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.31837
Policy Entropy: 2.53015
Value Function Loss: 0.02186

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.10633
Policy Update Magnitude: 0.47906
Value Function Update Magnitude: 0.66676

Collected Steps per Second: 21,486.09278
Overall Steps per Second: 10,317.89002

Timestep Collection Time: 2.32802
Timestep Consumption Time: 2.51987
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.84789

Cumulative Model Updates: 302,206
Cumulative Timesteps: 2,520,394,722

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2520394722...
Checkpoint 2520394722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.88181
Policy Entropy: 2.52480
Value Function Loss: 0.02167

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.49904
Value Function Update Magnitude: 0.67854

Collected Steps per Second: 21,826.03666
Overall Steps per Second: 10,474.37081

Timestep Collection Time: 2.29103
Timestep Consumption Time: 2.48291
PPO Batch Consumption Time: 0.30055
Total Iteration Time: 4.77394

Cumulative Model Updates: 302,212
Cumulative Timesteps: 2,520,444,726

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.85518
Policy Entropy: 2.51100
Value Function Loss: 0.02211

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.10486
Policy Update Magnitude: 0.50344
Value Function Update Magnitude: 0.68826

Collected Steps per Second: 21,954.36417
Overall Steps per Second: 10,418.20909

Timestep Collection Time: 2.27827
Timestep Consumption Time: 2.52275
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.80102

Cumulative Model Updates: 302,218
Cumulative Timesteps: 2,520,494,744

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2520494744...
Checkpoint 2520494744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.63677
Policy Entropy: 2.50608
Value Function Loss: 0.02158

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.11516
Policy Update Magnitude: 0.49286
Value Function Update Magnitude: 0.69189

Collected Steps per Second: 21,659.12858
Overall Steps per Second: 10,257.43869

Timestep Collection Time: 2.30859
Timestep Consumption Time: 2.56612
PPO Batch Consumption Time: 0.29960
Total Iteration Time: 4.87471

Cumulative Model Updates: 302,224
Cumulative Timesteps: 2,520,544,746

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.90251
Policy Entropy: 2.53123
Value Function Loss: 0.02192

Mean KL Divergence: 0.02184
SB3 Clip Fraction: 0.13994
Policy Update Magnitude: 0.47224
Value Function Update Magnitude: 0.68013

Collected Steps per Second: 21,747.97856
Overall Steps per Second: 10,377.91245

Timestep Collection Time: 2.29943
Timestep Consumption Time: 2.51926
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.81870

Cumulative Model Updates: 302,230
Cumulative Timesteps: 2,520,594,754

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2520594754...
Checkpoint 2520594754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.53386
Policy Entropy: 2.53236
Value Function Loss: 0.02068

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.49647
Value Function Update Magnitude: 0.67719

Collected Steps per Second: 21,723.61591
Overall Steps per Second: 10,609.93058

Timestep Collection Time: 2.30247
Timestep Consumption Time: 2.41179
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.71426

Cumulative Model Updates: 302,236
Cumulative Timesteps: 2,520,644,772

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.64815
Policy Entropy: 2.55975
Value Function Loss: 0.01843

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.11576
Policy Update Magnitude: 0.49874
Value Function Update Magnitude: 0.64787

Collected Steps per Second: 21,667.16223
Overall Steps per Second: 10,312.33814

Timestep Collection Time: 2.30884
Timestep Consumption Time: 2.54224
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.85108

Cumulative Model Updates: 302,242
Cumulative Timesteps: 2,520,694,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2520694798...
Checkpoint 2520694798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.10947
Policy Entropy: 2.54621
Value Function Loss: 0.01891

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.11267
Policy Update Magnitude: 0.49709
Value Function Update Magnitude: 0.63320

Collected Steps per Second: 21,580.41725
Overall Steps per Second: 10,409.39378

Timestep Collection Time: 2.31831
Timestep Consumption Time: 2.48793
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.80624

Cumulative Model Updates: 302,248
Cumulative Timesteps: 2,520,744,828

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.78326
Policy Entropy: 2.55023
Value Function Loss: 0.01916

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 0.49479
Value Function Update Magnitude: 0.62884

Collected Steps per Second: 21,950.51099
Overall Steps per Second: 10,533.72177

Timestep Collection Time: 2.27785
Timestep Consumption Time: 2.46881
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.74666

Cumulative Model Updates: 302,254
Cumulative Timesteps: 2,520,794,828

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2520794828...
Checkpoint 2520794828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.12486
Policy Entropy: 2.55208
Value Function Loss: 0.01869

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.49770
Value Function Update Magnitude: 0.61660

Collected Steps per Second: 22,588.70089
Overall Steps per Second: 10,621.87062

Timestep Collection Time: 2.21429
Timestep Consumption Time: 2.49467
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.70896

Cumulative Model Updates: 302,260
Cumulative Timesteps: 2,520,844,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.60068
Policy Entropy: 2.54843
Value Function Loss: 0.01932

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.09297
Policy Update Magnitude: 0.48683
Value Function Update Magnitude: 0.59532

Collected Steps per Second: 21,647.58187
Overall Steps per Second: 10,385.46527

Timestep Collection Time: 2.30973
Timestep Consumption Time: 2.50469
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.81442

Cumulative Model Updates: 302,266
Cumulative Timesteps: 2,520,894,846

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2520894846...
Checkpoint 2520894846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.19937
Policy Entropy: 2.54279
Value Function Loss: 0.01972

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.09361
Policy Update Magnitude: 0.48574
Value Function Update Magnitude: 0.59915

Collected Steps per Second: 21,576.97284
Overall Steps per Second: 10,221.06315

Timestep Collection Time: 2.31738
Timestep Consumption Time: 2.57468
PPO Batch Consumption Time: 0.30837
Total Iteration Time: 4.89205

Cumulative Model Updates: 302,272
Cumulative Timesteps: 2,520,944,848

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.72768
Policy Entropy: 2.54118
Value Function Loss: 0.01949

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.10214
Policy Update Magnitude: 0.48461
Value Function Update Magnitude: 0.62468

Collected Steps per Second: 21,697.18664
Overall Steps per Second: 10,398.19734

Timestep Collection Time: 2.30583
Timestep Consumption Time: 2.50558
PPO Batch Consumption Time: 0.29797
Total Iteration Time: 4.81141

Cumulative Model Updates: 302,278
Cumulative Timesteps: 2,520,994,878

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2520994878...
Checkpoint 2520994878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.71186
Policy Entropy: 2.53222
Value Function Loss: 0.01843

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.09840
Policy Update Magnitude: 0.47495
Value Function Update Magnitude: 0.63991

Collected Steps per Second: 21,782.48345
Overall Steps per Second: 10,298.33892

Timestep Collection Time: 2.29662
Timestep Consumption Time: 2.56106
PPO Batch Consumption Time: 0.29916
Total Iteration Time: 4.85768

Cumulative Model Updates: 302,284
Cumulative Timesteps: 2,521,044,904

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.12331
Policy Entropy: 2.53391
Value Function Loss: 0.01840

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.46930
Value Function Update Magnitude: 0.63577

Collected Steps per Second: 21,853.56400
Overall Steps per Second: 10,423.06259

Timestep Collection Time: 2.28933
Timestep Consumption Time: 2.51060
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.79993

Cumulative Model Updates: 302,290
Cumulative Timesteps: 2,521,094,934

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2521094934...
Checkpoint 2521094934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.44023
Policy Entropy: 2.53912
Value Function Loss: 0.02011

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.09630
Policy Update Magnitude: 0.48295
Value Function Update Magnitude: 0.63966

Collected Steps per Second: 21,506.42484
Overall Steps per Second: 10,219.97985

Timestep Collection Time: 2.32591
Timestep Consumption Time: 2.56862
PPO Batch Consumption Time: 0.29827
Total Iteration Time: 4.89453

Cumulative Model Updates: 302,296
Cumulative Timesteps: 2,521,144,956

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.44704
Policy Entropy: 2.52342
Value Function Loss: 0.01951

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.48958
Value Function Update Magnitude: 0.64601

Collected Steps per Second: 20,369.10088
Overall Steps per Second: 10,122.62763

Timestep Collection Time: 2.45578
Timestep Consumption Time: 2.48582
PPO Batch Consumption Time: 0.28165
Total Iteration Time: 4.94160

Cumulative Model Updates: 302,302
Cumulative Timesteps: 2,521,194,978

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2521194978...
Checkpoint 2521194978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.43859
Policy Entropy: 2.52532
Value Function Loss: 0.01882

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.47884
Value Function Update Magnitude: 0.64067

Collected Steps per Second: 22,614.80711
Overall Steps per Second: 10,632.48533

Timestep Collection Time: 2.21138
Timestep Consumption Time: 2.49213
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.70351

Cumulative Model Updates: 302,308
Cumulative Timesteps: 2,521,244,988

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.87692
Policy Entropy: 2.53590
Value Function Loss: 0.01772

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.08320
Policy Update Magnitude: 0.47402
Value Function Update Magnitude: 0.63180

Collected Steps per Second: 22,309.11568
Overall Steps per Second: 10,481.33136

Timestep Collection Time: 2.24213
Timestep Consumption Time: 2.53016
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.77229

Cumulative Model Updates: 302,314
Cumulative Timesteps: 2,521,295,008

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2521295008...
Checkpoint 2521295008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.55130
Policy Entropy: 2.56630
Value Function Loss: 0.01856

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.08637
Policy Update Magnitude: 0.47739
Value Function Update Magnitude: 0.63037

Collected Steps per Second: 22,034.37059
Overall Steps per Second: 10,675.95457

Timestep Collection Time: 2.26955
Timestep Consumption Time: 2.41463
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.68417

Cumulative Model Updates: 302,320
Cumulative Timesteps: 2,521,345,016

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.86807
Policy Entropy: 2.56822
Value Function Loss: 0.01854

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.09372
Policy Update Magnitude: 0.47852
Value Function Update Magnitude: 0.64471

Collected Steps per Second: 22,281.60520
Overall Steps per Second: 10,811.04723

Timestep Collection Time: 2.24535
Timestep Consumption Time: 2.38232
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.62767

Cumulative Model Updates: 302,326
Cumulative Timesteps: 2,521,395,046

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2521395046...
Checkpoint 2521395046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.87852
Policy Entropy: 2.54517
Value Function Loss: 0.01891

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.48607
Value Function Update Magnitude: 0.65268

Collected Steps per Second: 22,239.77117
Overall Steps per Second: 10,671.00638

Timestep Collection Time: 2.24831
Timestep Consumption Time: 2.43747
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.68578

Cumulative Model Updates: 302,332
Cumulative Timesteps: 2,521,445,048

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.86261
Policy Entropy: 2.51967
Value Function Loss: 0.02013

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.09704
Policy Update Magnitude: 0.48602
Value Function Update Magnitude: 0.66212

Collected Steps per Second: 22,352.51857
Overall Steps per Second: 10,480.21526

Timestep Collection Time: 2.23796
Timestep Consumption Time: 2.53523
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.77318

Cumulative Model Updates: 302,338
Cumulative Timesteps: 2,521,495,072

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2521495072...
Checkpoint 2521495072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.30479
Policy Entropy: 2.51188
Value Function Loss: 0.02125

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.10159
Policy Update Magnitude: 0.50322
Value Function Update Magnitude: 0.67167

Collected Steps per Second: 21,664.10820
Overall Steps per Second: 10,573.60385

Timestep Collection Time: 2.30926
Timestep Consumption Time: 2.42215
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.73140

Cumulative Model Updates: 302,344
Cumulative Timesteps: 2,521,545,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.26328
Policy Entropy: 2.53802
Value Function Loss: 0.02036

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.49723
Value Function Update Magnitude: 0.66462

Collected Steps per Second: 22,034.73104
Overall Steps per Second: 10,500.30697

Timestep Collection Time: 2.27023
Timestep Consumption Time: 2.49382
PPO Batch Consumption Time: 0.30090
Total Iteration Time: 4.76405

Cumulative Model Updates: 302,350
Cumulative Timesteps: 2,521,595,124

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2521595124...
Checkpoint 2521595124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.37772
Policy Entropy: 2.55384
Value Function Loss: 0.01900

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.09566
Policy Update Magnitude: 0.49174
Value Function Update Magnitude: 0.66291

Collected Steps per Second: 22,091.23791
Overall Steps per Second: 10,460.68808

Timestep Collection Time: 2.26443
Timestep Consumption Time: 2.51767
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.78209

Cumulative Model Updates: 302,356
Cumulative Timesteps: 2,521,645,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.81774
Policy Entropy: 2.56268
Value Function Loss: 0.01803

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.09292
Policy Update Magnitude: 0.48441
Value Function Update Magnitude: 0.65597

Collected Steps per Second: 22,277.34118
Overall Steps per Second: 10,643.35268

Timestep Collection Time: 2.24488
Timestep Consumption Time: 2.45383
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.69871

Cumulative Model Updates: 302,362
Cumulative Timesteps: 2,521,695,158

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2521695158...
Checkpoint 2521695158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.21282
Policy Entropy: 2.54128
Value Function Loss: 0.01938

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.10408
Policy Update Magnitude: 0.48863
Value Function Update Magnitude: 0.64314

Collected Steps per Second: 21,930.08607
Overall Steps per Second: 10,654.34714

Timestep Collection Time: 2.28098
Timestep Consumption Time: 2.41401
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.69499

Cumulative Model Updates: 302,368
Cumulative Timesteps: 2,521,745,180

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.88931
Policy Entropy: 2.52735
Value Function Loss: 0.01954

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.09728
Policy Update Magnitude: 0.48904
Value Function Update Magnitude: 0.64881

Collected Steps per Second: 22,151.06862
Overall Steps per Second: 10,673.07746

Timestep Collection Time: 2.25759
Timestep Consumption Time: 2.42785
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.68543

Cumulative Model Updates: 302,374
Cumulative Timesteps: 2,521,795,188

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2521795188...
Checkpoint 2521795188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.98655
Policy Entropy: 2.52483
Value Function Loss: 0.01977

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.09018
Policy Update Magnitude: 0.49519
Value Function Update Magnitude: 0.65922

Collected Steps per Second: 22,233.16798
Overall Steps per Second: 10,467.52146

Timestep Collection Time: 2.24988
Timestep Consumption Time: 2.52890
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.77878

Cumulative Model Updates: 302,380
Cumulative Timesteps: 2,521,845,210

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.68827
Policy Entropy: 2.54110
Value Function Loss: 0.01982

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.09121
Policy Update Magnitude: 0.49350
Value Function Update Magnitude: 0.65130

Collected Steps per Second: 22,260.53399
Overall Steps per Second: 10,486.21464

Timestep Collection Time: 2.24631
Timestep Consumption Time: 2.52224
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.76855

Cumulative Model Updates: 302,386
Cumulative Timesteps: 2,521,895,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2521895214...
Checkpoint 2521895214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.51867
Policy Entropy: 2.54542
Value Function Loss: 0.01933

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.09345
Policy Update Magnitude: 0.48362
Value Function Update Magnitude: 0.65650

Collected Steps per Second: 21,690.34057
Overall Steps per Second: 10,621.08361

Timestep Collection Time: 2.30545
Timestep Consumption Time: 2.40273
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.70818

Cumulative Model Updates: 302,392
Cumulative Timesteps: 2,521,945,220

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.30298
Policy Entropy: 2.54746
Value Function Loss: 0.01944

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.10391
Policy Update Magnitude: 0.48137
Value Function Update Magnitude: 0.64623

Collected Steps per Second: 22,219.57041
Overall Steps per Second: 10,798.06022

Timestep Collection Time: 2.25171
Timestep Consumption Time: 2.38172
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.63342

Cumulative Model Updates: 302,398
Cumulative Timesteps: 2,521,995,252

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2521995252...
Checkpoint 2521995252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.54023
Policy Entropy: 2.52935
Value Function Loss: 0.02043

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.09524
Policy Update Magnitude: 0.48814
Value Function Update Magnitude: 0.65071

Collected Steps per Second: 22,311.09774
Overall Steps per Second: 10,658.26193

Timestep Collection Time: 2.24104
Timestep Consumption Time: 2.45016
PPO Batch Consumption Time: 0.28153
Total Iteration Time: 4.69120

Cumulative Model Updates: 302,404
Cumulative Timesteps: 2,522,045,252

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.39203
Policy Entropy: 2.54135
Value Function Loss: 0.02172

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.09342
Policy Update Magnitude: 0.48967
Value Function Update Magnitude: 0.66408

Collected Steps per Second: 22,059.95041
Overall Steps per Second: 10,507.09483

Timestep Collection Time: 2.26746
Timestep Consumption Time: 2.49314
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.76059

Cumulative Model Updates: 302,410
Cumulative Timesteps: 2,522,095,272

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2522095272...
Checkpoint 2522095272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.06716
Policy Entropy: 2.52970
Value Function Loss: 0.02141

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.09467
Policy Update Magnitude: 0.49538
Value Function Update Magnitude: 0.64429

Collected Steps per Second: 22,131.95112
Overall Steps per Second: 10,697.66986

Timestep Collection Time: 2.26008
Timestep Consumption Time: 2.41570
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.67578

Cumulative Model Updates: 302,416
Cumulative Timesteps: 2,522,145,292

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.75793
Policy Entropy: 2.54245
Value Function Loss: 0.02068

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.09761
Policy Update Magnitude: 0.49910
Value Function Update Magnitude: 0.65213

Collected Steps per Second: 22,176.21666
Overall Steps per Second: 10,793.81023

Timestep Collection Time: 2.25485
Timestep Consumption Time: 2.37781
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.63266

Cumulative Model Updates: 302,422
Cumulative Timesteps: 2,522,195,296

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2522195296...
Checkpoint 2522195296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.85344
Policy Entropy: 2.52973
Value Function Loss: 0.01906

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.09433
Policy Update Magnitude: 0.49520
Value Function Update Magnitude: 0.63615

Collected Steps per Second: 22,064.52990
Overall Steps per Second: 10,602.28718

Timestep Collection Time: 2.26617
Timestep Consumption Time: 2.44998
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.71615

Cumulative Model Updates: 302,428
Cumulative Timesteps: 2,522,245,298

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.40785
Policy Entropy: 2.53772
Value Function Loss: 0.01856

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.49252
Value Function Update Magnitude: 0.60971

Collected Steps per Second: 21,767.50561
Overall Steps per Second: 10,407.35822

Timestep Collection Time: 2.29755
Timestep Consumption Time: 2.50789
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.80545

Cumulative Model Updates: 302,434
Cumulative Timesteps: 2,522,295,310

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2522295310...
Checkpoint 2522295310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.91859
Policy Entropy: 2.53139
Value Function Loss: 0.01987

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.09234
Policy Update Magnitude: 0.49154
Value Function Update Magnitude: 0.60675

Collected Steps per Second: 21,928.47327
Overall Steps per Second: 10,556.30280

Timestep Collection Time: 2.28014
Timestep Consumption Time: 2.45637
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.73651

Cumulative Model Updates: 302,440
Cumulative Timesteps: 2,522,345,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.51275
Policy Entropy: 2.53624
Value Function Loss: 0.01940

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.09250
Policy Update Magnitude: 0.49876
Value Function Update Magnitude: 0.62222

Collected Steps per Second: 22,391.13344
Overall Steps per Second: 10,649.94905

Timestep Collection Time: 2.23365
Timestep Consumption Time: 2.46252
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.69617

Cumulative Model Updates: 302,446
Cumulative Timesteps: 2,522,395,324

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2522395324...
Checkpoint 2522395324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.13330
Policy Entropy: 2.54694
Value Function Loss: 0.01936

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.08920
Policy Update Magnitude: 0.48479
Value Function Update Magnitude: 0.62393

Collected Steps per Second: 22,246.68284
Overall Steps per Second: 10,646.13969

Timestep Collection Time: 2.24878
Timestep Consumption Time: 2.45038
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.69917

Cumulative Model Updates: 302,452
Cumulative Timesteps: 2,522,445,352

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.88728
Policy Entropy: 2.53352
Value Function Loss: 0.01917

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.09244
Policy Update Magnitude: 0.47643
Value Function Update Magnitude: 0.59484

Collected Steps per Second: 22,189.39800
Overall Steps per Second: 10,474.26079

Timestep Collection Time: 2.25423
Timestep Consumption Time: 2.52129
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.77552

Cumulative Model Updates: 302,458
Cumulative Timesteps: 2,522,495,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2522495372...
Checkpoint 2522495372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.02121
Policy Entropy: 2.53921
Value Function Loss: 0.01921

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.09342
Policy Update Magnitude: 0.46847
Value Function Update Magnitude: 0.58581

Collected Steps per Second: 21,985.73283
Overall Steps per Second: 10,687.95782

Timestep Collection Time: 2.27566
Timestep Consumption Time: 2.40550
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.68116

Cumulative Model Updates: 302,464
Cumulative Timesteps: 2,522,545,404

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.17976
Policy Entropy: 2.52497
Value Function Loss: 0.01867

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.11073
Policy Update Magnitude: 0.46796
Value Function Update Magnitude: 0.59023

Collected Steps per Second: 22,190.41821
Overall Steps per Second: 10,823.61633

Timestep Collection Time: 2.25331
Timestep Consumption Time: 2.36640
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.61971

Cumulative Model Updates: 302,470
Cumulative Timesteps: 2,522,595,406

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2522595406...
Checkpoint 2522595406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.36099
Policy Entropy: 2.55753
Value Function Loss: 0.01971

Mean KL Divergence: 0.02576
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.54518
Value Function Update Magnitude: 0.60631

Collected Steps per Second: 21,992.90174
Overall Steps per Second: 10,596.26675

Timestep Collection Time: 2.27464
Timestep Consumption Time: 2.44645
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.72110

Cumulative Model Updates: 302,476
Cumulative Timesteps: 2,522,645,432

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.35088
Policy Entropy: 2.54218
Value Function Loss: 0.02086

Mean KL Divergence: 0.03840
SB3 Clip Fraction: 0.15884
Policy Update Magnitude: 0.56343
Value Function Update Magnitude: 0.61807

Collected Steps per Second: 21,941.63803
Overall Steps per Second: 10,605.67890

Timestep Collection Time: 2.27996
Timestep Consumption Time: 2.43695
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.71691

Cumulative Model Updates: 302,482
Cumulative Timesteps: 2,522,695,458

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2522695458...
Checkpoint 2522695458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.68993
Policy Entropy: 2.54195
Value Function Loss: 0.02102

Mean KL Divergence: 0.03164
SB3 Clip Fraction: 0.14613
Policy Update Magnitude: 0.54013
Value Function Update Magnitude: 0.64469

Collected Steps per Second: 21,816.15905
Overall Steps per Second: 10,550.17336

Timestep Collection Time: 2.29316
Timestep Consumption Time: 2.44875
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.74191

Cumulative Model Updates: 302,488
Cumulative Timesteps: 2,522,745,486

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.48441
Policy Entropy: 2.52553
Value Function Loss: 0.02044

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.12301
Policy Update Magnitude: 0.51583
Value Function Update Magnitude: 0.65970

Collected Steps per Second: 22,078.94678
Overall Steps per Second: 10,654.61061

Timestep Collection Time: 2.26560
Timestep Consumption Time: 2.42927
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.69487

Cumulative Model Updates: 302,494
Cumulative Timesteps: 2,522,795,508

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2522795508...
Checkpoint 2522795508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.36589
Policy Entropy: 2.53007
Value Function Loss: 0.01930

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.10644
Policy Update Magnitude: 0.50344
Value Function Update Magnitude: 0.63933

Collected Steps per Second: 22,502.41481
Overall Steps per Second: 10,560.84741

Timestep Collection Time: 2.22305
Timestep Consumption Time: 2.51369
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.73674

Cumulative Model Updates: 302,500
Cumulative Timesteps: 2,522,845,532

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.38720
Policy Entropy: 2.53016
Value Function Loss: 0.02053

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.10276
Policy Update Magnitude: 0.50011
Value Function Update Magnitude: 0.61823

Collected Steps per Second: 22,274.83352
Overall Steps per Second: 10,524.40686

Timestep Collection Time: 2.24531
Timestep Consumption Time: 2.50688
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.75219

Cumulative Model Updates: 302,506
Cumulative Timesteps: 2,522,895,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2522895546...
Checkpoint 2522895546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.63742
Policy Entropy: 2.52129
Value Function Loss: 0.02067

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.09568
Policy Update Magnitude: 0.49719
Value Function Update Magnitude: 0.62993

Collected Steps per Second: 21,852.41739
Overall Steps per Second: 10,511.67328

Timestep Collection Time: 2.28817
Timestep Consumption Time: 2.46864
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.75681

Cumulative Model Updates: 302,512
Cumulative Timesteps: 2,522,945,548

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.01862
Policy Entropy: 2.50949
Value Function Loss: 0.02125

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 0.48944
Value Function Update Magnitude: 0.64140

Collected Steps per Second: 22,184.00466
Overall Steps per Second: 10,806.28234

Timestep Collection Time: 2.25487
Timestep Consumption Time: 2.37411
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.62897

Cumulative Model Updates: 302,518
Cumulative Timesteps: 2,522,995,570

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2522995570...
Checkpoint 2522995570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.20086
Policy Entropy: 2.51390
Value Function Loss: 0.01999

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.47370
Value Function Update Magnitude: 0.62711

Collected Steps per Second: 22,076.46234
Overall Steps per Second: 10,640.20616

Timestep Collection Time: 2.26531
Timestep Consumption Time: 2.43479
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.70010

Cumulative Model Updates: 302,524
Cumulative Timesteps: 2,523,045,580

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.84153
Policy Entropy: 2.52663
Value Function Loss: 0.01994

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.09870
Policy Update Magnitude: 0.47885
Value Function Update Magnitude: 0.62166

Collected Steps per Second: 22,195.64012
Overall Steps per Second: 10,558.14144

Timestep Collection Time: 2.25315
Timestep Consumption Time: 2.48348
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.73663

Cumulative Model Updates: 302,530
Cumulative Timesteps: 2,523,095,590

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2523095590...
Checkpoint 2523095590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175.97341
Policy Entropy: 2.53085
Value Function Loss: 0.01938

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.09160
Policy Update Magnitude: 0.49512
Value Function Update Magnitude: 0.61189

Collected Steps per Second: 21,845.00355
Overall Steps per Second: 10,275.41852

Timestep Collection Time: 2.28968
Timestep Consumption Time: 2.57806
PPO Batch Consumption Time: 0.30611
Total Iteration Time: 4.86773

Cumulative Model Updates: 302,536
Cumulative Timesteps: 2,523,145,608

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.25779
Policy Entropy: 2.52240
Value Function Loss: 0.02010

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.09364
Policy Update Magnitude: 0.49292
Value Function Update Magnitude: 0.62117

Collected Steps per Second: 23,020.64763
Overall Steps per Second: 10,706.64659

Timestep Collection Time: 2.17327
Timestep Consumption Time: 2.49953
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.67280

Cumulative Model Updates: 302,542
Cumulative Timesteps: 2,523,195,638

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2523195638...
Checkpoint 2523195638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.95226
Policy Entropy: 2.50587
Value Function Loss: 0.02131

Mean KL Divergence: 0.02975
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.50308
Value Function Update Magnitude: 0.65039

Collected Steps per Second: 22,424.30597
Overall Steps per Second: 10,583.13112

Timestep Collection Time: 2.22981
Timestep Consumption Time: 2.49488
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.72469

Cumulative Model Updates: 302,548
Cumulative Timesteps: 2,523,245,640

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.76030
Policy Entropy: 2.50287
Value Function Loss: 0.01996

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.49659
Value Function Update Magnitude: 0.66097

Collected Steps per Second: 22,134.50515
Overall Steps per Second: 10,509.94117

Timestep Collection Time: 2.26027
Timestep Consumption Time: 2.49998
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.76025

Cumulative Model Updates: 302,554
Cumulative Timesteps: 2,523,295,670

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2523295670...
Checkpoint 2523295670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.22092
Policy Entropy: 2.50369
Value Function Loss: 0.02042

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.09009
Policy Update Magnitude: 0.49757
Value Function Update Magnitude: 0.65270

Collected Steps per Second: 22,171.00231
Overall Steps per Second: 10,831.19940

Timestep Collection Time: 2.25637
Timestep Consumption Time: 2.36232
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.61869

Cumulative Model Updates: 302,560
Cumulative Timesteps: 2,523,345,696

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.01369
Policy Entropy: 2.51744
Value Function Loss: 0.01933

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.09337
Policy Update Magnitude: 0.49773
Value Function Update Magnitude: 0.66083

Collected Steps per Second: 22,316.71804
Overall Steps per Second: 10,496.58434

Timestep Collection Time: 2.24137
Timestep Consumption Time: 2.52399
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.76536

Cumulative Model Updates: 302,566
Cumulative Timesteps: 2,523,395,716

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2523395716...
Checkpoint 2523395716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.91564
Policy Entropy: 2.53403
Value Function Loss: 0.01962

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.09542
Policy Update Magnitude: 0.49243
Value Function Update Magnitude: 0.67391

Collected Steps per Second: 21,910.45746
Overall Steps per Second: 10,542.61537

Timestep Collection Time: 2.28220
Timestep Consumption Time: 2.46084
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.74304

Cumulative Model Updates: 302,572
Cumulative Timesteps: 2,523,445,720

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.34335
Policy Entropy: 2.53617
Value Function Loss: 0.01932

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.09503
Policy Update Magnitude: 0.49363
Value Function Update Magnitude: 0.66784

Collected Steps per Second: 22,005.37075
Overall Steps per Second: 10,522.10397

Timestep Collection Time: 2.27272
Timestep Consumption Time: 2.48032
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.75304

Cumulative Model Updates: 302,578
Cumulative Timesteps: 2,523,495,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2523495732...
Checkpoint 2523495732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.09366
Policy Entropy: 2.54259
Value Function Loss: 0.01964

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.10167
Policy Update Magnitude: 0.49102
Value Function Update Magnitude: 0.66509

Collected Steps per Second: 21,918.23610
Overall Steps per Second: 10,697.75553

Timestep Collection Time: 2.28203
Timestep Consumption Time: 2.39353
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.67556

Cumulative Model Updates: 302,584
Cumulative Timesteps: 2,523,545,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.79818
Policy Entropy: 2.51512
Value Function Loss: 0.01959

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.49270
Value Function Update Magnitude: 0.65815

Collected Steps per Second: 22,407.21088
Overall Steps per Second: 10,521.04121

Timestep Collection Time: 2.23232
Timestep Consumption Time: 2.52197
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.75428

Cumulative Model Updates: 302,590
Cumulative Timesteps: 2,523,595,770

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2523595770...
Checkpoint 2523595770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.09830
Policy Entropy: 2.50496
Value Function Loss: 0.02013

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.49799
Value Function Update Magnitude: 0.65202

Collected Steps per Second: 22,062.12893
Overall Steps per Second: 10,619.16459

Timestep Collection Time: 2.26723
Timestep Consumption Time: 2.44312
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.71035

Cumulative Model Updates: 302,596
Cumulative Timesteps: 2,523,645,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.64823
Policy Entropy: 2.49197
Value Function Loss: 0.02101

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.50193
Value Function Update Magnitude: 0.65498

Collected Steps per Second: 21,831.82909
Overall Steps per Second: 10,392.35331

Timestep Collection Time: 2.29097
Timestep Consumption Time: 2.52180
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.81277

Cumulative Model Updates: 302,602
Cumulative Timesteps: 2,523,695,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2523695806...
Checkpoint 2523695806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150.53470
Policy Entropy: 2.50984
Value Function Loss: 0.02133

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.49939
Value Function Update Magnitude: 0.66689

Collected Steps per Second: 21,915.11570
Overall Steps per Second: 10,661.80777

Timestep Collection Time: 2.28171
Timestep Consumption Time: 2.40830
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.69001

Cumulative Model Updates: 302,608
Cumulative Timesteps: 2,523,745,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.45624
Policy Entropy: 2.52759
Value Function Loss: 0.02113

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.10139
Policy Update Magnitude: 0.49756
Value Function Update Magnitude: 0.66632

Collected Steps per Second: 21,856.96170
Overall Steps per Second: 10,371.72709

Timestep Collection Time: 2.28852
Timestep Consumption Time: 2.53421
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.82273

Cumulative Model Updates: 302,614
Cumulative Timesteps: 2,523,795,830

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2523795830...
Checkpoint 2523795830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.33646
Policy Entropy: 2.54682
Value Function Loss: 0.02137

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.10032
Policy Update Magnitude: 0.50470
Value Function Update Magnitude: 0.66729

Collected Steps per Second: 21,763.02419
Overall Steps per Second: 10,364.33586

Timestep Collection Time: 2.29895
Timestep Consumption Time: 2.52838
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.82732

Cumulative Model Updates: 302,620
Cumulative Timesteps: 2,523,845,862

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.26131
Policy Entropy: 2.56002
Value Function Loss: 0.02056

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.12218
Policy Update Magnitude: 0.47906
Value Function Update Magnitude: 0.67711

Collected Steps per Second: 22,278.66753
Overall Steps per Second: 10,823.19029

Timestep Collection Time: 2.24556
Timestep Consumption Time: 2.37674
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.62230

Cumulative Model Updates: 302,626
Cumulative Timesteps: 2,523,895,890

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2523895890...
Checkpoint 2523895890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.30157
Policy Entropy: 2.53364
Value Function Loss: 0.02050

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.12406
Policy Update Magnitude: 0.46195
Value Function Update Magnitude: 0.67094

Collected Steps per Second: 22,234.09882
Overall Steps per Second: 10,670.01253

Timestep Collection Time: 2.24943
Timestep Consumption Time: 2.43791
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.68734

Cumulative Model Updates: 302,632
Cumulative Timesteps: 2,523,945,904

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.29581
Policy Entropy: 2.50854
Value Function Loss: 0.02042

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.49280
Value Function Update Magnitude: 0.66819

Collected Steps per Second: 22,058.90297
Overall Steps per Second: 10,470.03079

Timestep Collection Time: 2.26775
Timestep Consumption Time: 2.51008
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.77783

Cumulative Model Updates: 302,638
Cumulative Timesteps: 2,523,995,928

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2523995928...
Checkpoint 2523995928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.04301
Policy Entropy: 2.50063
Value Function Loss: 0.02106

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.13136
Policy Update Magnitude: 0.49875
Value Function Update Magnitude: 0.68005

Collected Steps per Second: 21,959.04454
Overall Steps per Second: 10,626.85004

Timestep Collection Time: 2.27697
Timestep Consumption Time: 2.42810
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.70506

Cumulative Model Updates: 302,644
Cumulative Timesteps: 2,524,045,928

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.36884
Policy Entropy: 2.51424
Value Function Loss: 0.02099

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.10710
Policy Update Magnitude: 0.50769
Value Function Update Magnitude: 0.69675

Collected Steps per Second: 22,271.19041
Overall Steps per Second: 10,549.78341

Timestep Collection Time: 2.24622
Timestep Consumption Time: 2.49568
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.74190

Cumulative Model Updates: 302,650
Cumulative Timesteps: 2,524,095,954

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2524095954...
Checkpoint 2524095954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.60963
Policy Entropy: 2.52221
Value Function Loss: 0.01993

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.10312
Policy Update Magnitude: 0.50746
Value Function Update Magnitude: 0.67418

Collected Steps per Second: 22,915.88113
Overall Steps per Second: 10,645.09973

Timestep Collection Time: 2.18215
Timestep Consumption Time: 2.51541
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.69756

Cumulative Model Updates: 302,656
Cumulative Timesteps: 2,524,145,960

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.07284
Policy Entropy: 2.55566
Value Function Loss: 0.01944

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.09247
Policy Update Magnitude: 0.50361
Value Function Update Magnitude: 0.64791

Collected Steps per Second: 22,415.42215
Overall Steps per Second: 10,571.59099

Timestep Collection Time: 2.23168
Timestep Consumption Time: 2.50025
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.73193

Cumulative Model Updates: 302,662
Cumulative Timesteps: 2,524,195,984

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2524195984...
Checkpoint 2524195984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.74780
Policy Entropy: 2.56657
Value Function Loss: 0.01980

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.08689
Policy Update Magnitude: 0.49666
Value Function Update Magnitude: 0.64657

Collected Steps per Second: 21,942.12740
Overall Steps per Second: 10,481.94200

Timestep Collection Time: 2.28000
Timestep Consumption Time: 2.49278
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.77278

Cumulative Model Updates: 302,668
Cumulative Timesteps: 2,524,246,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.18574
Policy Entropy: 2.56744
Value Function Loss: 0.02022

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.08150
Policy Update Magnitude: 0.50015
Value Function Update Magnitude: 0.65511

Collected Steps per Second: 22,208.47667
Overall Steps per Second: 10,838.77063

Timestep Collection Time: 2.25220
Timestep Consumption Time: 2.36253
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.61473

Cumulative Model Updates: 302,674
Cumulative Timesteps: 2,524,296,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2524296030...
Checkpoint 2524296030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.08198
Policy Entropy: 2.54589
Value Function Loss: 0.02185

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.08593
Policy Update Magnitude: 0.50534
Value Function Update Magnitude: 0.64302

Collected Steps per Second: 22,147.24664
Overall Steps per Second: 10,630.82996

Timestep Collection Time: 2.25807
Timestep Consumption Time: 2.44617
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.70424

Cumulative Model Updates: 302,680
Cumulative Timesteps: 2,524,346,040

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.90254
Policy Entropy: 2.55566
Value Function Loss: 0.02181

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.09828
Policy Update Magnitude: 0.50217
Value Function Update Magnitude: 0.63171

Collected Steps per Second: 22,296.52615
Overall Steps per Second: 10,495.55425

Timestep Collection Time: 2.24340
Timestep Consumption Time: 2.52243
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.76583

Cumulative Model Updates: 302,686
Cumulative Timesteps: 2,524,396,060

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2524396060...
Checkpoint 2524396060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.22993
Policy Entropy: 2.56969
Value Function Loss: 0.01986

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.48856
Value Function Update Magnitude: 0.61492

Collected Steps per Second: 21,671.10097
Overall Steps per Second: 10,441.84668

Timestep Collection Time: 2.30814
Timestep Consumption Time: 2.48220
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.79034

Cumulative Model Updates: 302,692
Cumulative Timesteps: 2,524,446,080

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.79530
Policy Entropy: 2.58036
Value Function Loss: 0.01874

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.08499
Policy Update Magnitude: 0.48335
Value Function Update Magnitude: 0.58999

Collected Steps per Second: 21,899.64630
Overall Steps per Second: 10,706.74585

Timestep Collection Time: 2.28351
Timestep Consumption Time: 2.38719
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.67070

Cumulative Model Updates: 302,698
Cumulative Timesteps: 2,524,496,088

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2524496088...
Checkpoint 2524496088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.93277
Policy Entropy: 2.56945
Value Function Loss: 0.01900

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.09180
Policy Update Magnitude: 0.48147
Value Function Update Magnitude: 0.60340

Collected Steps per Second: 22,083.13122
Overall Steps per Second: 10,648.92473

Timestep Collection Time: 2.26462
Timestep Consumption Time: 2.43162
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.69625

Cumulative Model Updates: 302,704
Cumulative Timesteps: 2,524,546,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.37995
Policy Entropy: 2.54719
Value Function Loss: 0.01963

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.09888
Policy Update Magnitude: 0.48053
Value Function Update Magnitude: 0.60898

Collected Steps per Second: 22,473.66561
Overall Steps per Second: 10,527.97651

Timestep Collection Time: 2.22607
Timestep Consumption Time: 2.52584
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.75191

Cumulative Model Updates: 302,710
Cumulative Timesteps: 2,524,596,126

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2524596126...
Checkpoint 2524596126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.58879
Policy Entropy: 2.53997
Value Function Loss: 0.01967

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.08886
Policy Update Magnitude: 0.48555
Value Function Update Magnitude: 0.62343

Collected Steps per Second: 21,846.47489
Overall Steps per Second: 10,507.68221

Timestep Collection Time: 2.28916
Timestep Consumption Time: 2.47022
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.75938

Cumulative Model Updates: 302,716
Cumulative Timesteps: 2,524,646,136

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.84724
Policy Entropy: 2.53054
Value Function Loss: 0.01982

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.49218
Value Function Update Magnitude: 0.64206

Collected Steps per Second: 22,130.52229
Overall Steps per Second: 10,474.02667

Timestep Collection Time: 2.25996
Timestep Consumption Time: 2.51509
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.77505

Cumulative Model Updates: 302,722
Cumulative Timesteps: 2,524,696,150

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2524696150...
Checkpoint 2524696150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.42712
Policy Entropy: 2.53212
Value Function Loss: 0.02062

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.49029
Value Function Update Magnitude: 0.64648

Collected Steps per Second: 22,778.31600
Overall Steps per Second: 10,656.94759

Timestep Collection Time: 2.19560
Timestep Consumption Time: 2.49730
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.69290

Cumulative Model Updates: 302,728
Cumulative Timesteps: 2,524,746,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.68916
Policy Entropy: 2.51994
Value Function Loss: 0.02160

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.10338
Policy Update Magnitude: 0.49461
Value Function Update Magnitude: 0.64299

Collected Steps per Second: 22,256.81287
Overall Steps per Second: 10,488.96310

Timestep Collection Time: 2.24659
Timestep Consumption Time: 2.52051
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.76711

Cumulative Model Updates: 302,734
Cumulative Timesteps: 2,524,796,164

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2524796164...
Checkpoint 2524796164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.36668
Policy Entropy: 2.54107
Value Function Loss: 0.02064

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.11192
Policy Update Magnitude: 0.49431
Value Function Update Magnitude: 0.63083

Collected Steps per Second: 21,660.09738
Overall Steps per Second: 10,531.34024

Timestep Collection Time: 2.30941
Timestep Consumption Time: 2.44041
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.74982

Cumulative Model Updates: 302,740
Cumulative Timesteps: 2,524,846,186

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.39503
Policy Entropy: 2.54366
Value Function Loss: 0.01976

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.49660
Value Function Update Magnitude: 0.62076

Collected Steps per Second: 22,091.32897
Overall Steps per Second: 10,660.77924

Timestep Collection Time: 2.26397
Timestep Consumption Time: 2.42744
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.69140

Cumulative Model Updates: 302,746
Cumulative Timesteps: 2,524,896,200

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2524896200...
Checkpoint 2524896200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.19922
Policy Entropy: 2.54255
Value Function Loss: 0.01870

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.09696
Policy Update Magnitude: 0.48523
Value Function Update Magnitude: 0.61678

Collected Steps per Second: 22,183.57939
Overall Steps per Second: 10,532.95013

Timestep Collection Time: 2.25455
Timestep Consumption Time: 2.49379
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.74834

Cumulative Model Updates: 302,752
Cumulative Timesteps: 2,524,946,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.78244
Policy Entropy: 2.56298
Value Function Loss: 0.01816

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.08953
Policy Update Magnitude: 0.48245
Value Function Update Magnitude: 0.62222

Collected Steps per Second: 22,127.60310
Overall Steps per Second: 10,436.52683

Timestep Collection Time: 2.26052
Timestep Consumption Time: 2.53226
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.79278

Cumulative Model Updates: 302,758
Cumulative Timesteps: 2,524,996,234

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2524996234...
Checkpoint 2524996234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.76932
Policy Entropy: 2.55335
Value Function Loss: 0.01862

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.09314
Policy Update Magnitude: 0.48245
Value Function Update Magnitude: 0.63592

Collected Steps per Second: 21,968.33391
Overall Steps per Second: 10,674.73838

Timestep Collection Time: 2.27719
Timestep Consumption Time: 2.40920
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.68639

Cumulative Model Updates: 302,764
Cumulative Timesteps: 2,525,046,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.57287
Policy Entropy: 2.58860
Value Function Loss: 0.01755

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.09835
Policy Update Magnitude: 0.47665
Value Function Update Magnitude: 0.64252

Collected Steps per Second: 22,266.97187
Overall Steps per Second: 10,486.04749

Timestep Collection Time: 2.24593
Timestep Consumption Time: 2.52327
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.76919

Cumulative Model Updates: 302,770
Cumulative Timesteps: 2,525,096,270

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2525096270...
Checkpoint 2525096270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.90175
Policy Entropy: 2.55669
Value Function Loss: 0.01850

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.11295
Policy Update Magnitude: 0.48029
Value Function Update Magnitude: 0.63715

Collected Steps per Second: 22,639.04909
Overall Steps per Second: 10,604.92050

Timestep Collection Time: 2.20893
Timestep Consumption Time: 2.50662
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.71555

Cumulative Model Updates: 302,776
Cumulative Timesteps: 2,525,146,278

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.88382
Policy Entropy: 2.56745
Value Function Loss: 0.01828

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.10786
Policy Update Magnitude: 0.48144
Value Function Update Magnitude: 0.63424

Collected Steps per Second: 22,484.08146
Overall Steps per Second: 10,565.14885

Timestep Collection Time: 2.22442
Timestep Consumption Time: 2.50945
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.73387

Cumulative Model Updates: 302,782
Cumulative Timesteps: 2,525,196,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2525196292...
Checkpoint 2525196292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.35625
Policy Entropy: 2.54230
Value Function Loss: 0.01969

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.10268
Policy Update Magnitude: 0.49436
Value Function Update Magnitude: 0.64607

Collected Steps per Second: 21,720.38793
Overall Steps per Second: 10,569.13523

Timestep Collection Time: 2.30318
Timestep Consumption Time: 2.43003
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.73322

Cumulative Model Updates: 302,788
Cumulative Timesteps: 2,525,246,318

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.52922
Policy Entropy: 2.54275
Value Function Loss: 0.02001

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.10005
Policy Update Magnitude: 0.49511
Value Function Update Magnitude: 0.65125

Collected Steps per Second: 22,411.32302
Overall Steps per Second: 10,849.13260

Timestep Collection Time: 2.23146
Timestep Consumption Time: 2.37812
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.60959

Cumulative Model Updates: 302,794
Cumulative Timesteps: 2,525,296,328

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2525296328...
Checkpoint 2525296328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.88615
Policy Entropy: 2.53228
Value Function Loss: 0.02055

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.48891
Value Function Update Magnitude: 0.66641

Collected Steps per Second: 22,129.07120
Overall Steps per Second: 10,629.94069

Timestep Collection Time: 2.25965
Timestep Consumption Time: 2.44442
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.70407

Cumulative Model Updates: 302,800
Cumulative Timesteps: 2,525,346,332

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.72303
Policy Entropy: 2.53349
Value Function Loss: 0.01984

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.11653
Policy Update Magnitude: 0.48194
Value Function Update Magnitude: 0.66380

Collected Steps per Second: 22,275.14500
Overall Steps per Second: 10,490.98304

Timestep Collection Time: 2.24465
Timestep Consumption Time: 2.52134
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.76600

Cumulative Model Updates: 302,806
Cumulative Timesteps: 2,525,396,332

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2525396332...
Checkpoint 2525396332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.81619
Policy Entropy: 2.55094
Value Function Loss: 0.01990

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.11849
Policy Update Magnitude: 0.50002
Value Function Update Magnitude: 0.67661

Collected Steps per Second: 21,756.04014
Overall Steps per Second: 10,590.25098

Timestep Collection Time: 2.29904
Timestep Consumption Time: 2.42398
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.72302

Cumulative Model Updates: 302,812
Cumulative Timesteps: 2,525,446,350

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.47311
Policy Entropy: 2.55770
Value Function Loss: 0.01927

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.10819
Policy Update Magnitude: 0.49446
Value Function Update Magnitude: 0.68111

Collected Steps per Second: 22,086.05037
Overall Steps per Second: 10,655.80382

Timestep Collection Time: 2.26469
Timestep Consumption Time: 2.42928
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.69397

Cumulative Model Updates: 302,818
Cumulative Timesteps: 2,525,496,368

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2525496368...
Checkpoint 2525496368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.14228
Policy Entropy: 2.55404
Value Function Loss: 0.01943

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.09987
Policy Update Magnitude: 0.48886
Value Function Update Magnitude: 0.65611

Collected Steps per Second: 22,337.53089
Overall Steps per Second: 10,513.96072

Timestep Collection Time: 2.23847
Timestep Consumption Time: 2.51730
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.75577

Cumulative Model Updates: 302,824
Cumulative Timesteps: 2,525,546,370

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.99842
Policy Entropy: 2.53730
Value Function Loss: 0.01953

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.48934
Value Function Update Magnitude: 0.63748

Collected Steps per Second: 22,202.27855
Overall Steps per Second: 10,439.42199

Timestep Collection Time: 2.25301
Timestep Consumption Time: 2.53863
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.79164

Cumulative Model Updates: 302,830
Cumulative Timesteps: 2,525,596,392

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2525596392...
Checkpoint 2525596392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.62230
Policy Entropy: 2.51553
Value Function Loss: 0.02092

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.10425
Policy Update Magnitude: 0.48923
Value Function Update Magnitude: 0.62871

Collected Steps per Second: 21,797.82204
Overall Steps per Second: 10,577.22226

Timestep Collection Time: 2.29390
Timestep Consumption Time: 2.43343
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.72733

Cumulative Model Updates: 302,836
Cumulative Timesteps: 2,525,646,394

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.97320
Policy Entropy: 2.51572
Value Function Loss: 0.02231

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.49965
Value Function Update Magnitude: 0.66431

Collected Steps per Second: 22,037.19123
Overall Steps per Second: 10,501.53754

Timestep Collection Time: 2.26989
Timestep Consumption Time: 2.49341
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.76330

Cumulative Model Updates: 302,842
Cumulative Timesteps: 2,525,696,416

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2525696416...
Checkpoint 2525696416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.62235
Policy Entropy: 2.52661
Value Function Loss: 0.02132

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.10197
Policy Update Magnitude: 0.50192
Value Function Update Magnitude: 0.69794

Collected Steps per Second: 22,722.27230
Overall Steps per Second: 10,542.39024

Timestep Collection Time: 2.20163
Timestep Consumption Time: 2.54360
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.74522

Cumulative Model Updates: 302,848
Cumulative Timesteps: 2,525,746,442

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.59947
Policy Entropy: 2.52486
Value Function Loss: 0.02030

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.08755
Policy Update Magnitude: 0.49686
Value Function Update Magnitude: 0.68500

Collected Steps per Second: 22,094.45233
Overall Steps per Second: 10,604.73531

Timestep Collection Time: 2.26428
Timestep Consumption Time: 2.45324
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.71752

Cumulative Model Updates: 302,854
Cumulative Timesteps: 2,525,796,470

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2525796470...
Checkpoint 2525796470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.91062
Policy Entropy: 2.52557
Value Function Loss: 0.01998

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.09160
Policy Update Magnitude: 0.52104
Value Function Update Magnitude: 0.66465

Collected Steps per Second: 22,056.53557
Overall Steps per Second: 10,580.73906

Timestep Collection Time: 2.26763
Timestep Consumption Time: 2.45945
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.72708

Cumulative Model Updates: 302,860
Cumulative Timesteps: 2,525,846,486

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.98701
Policy Entropy: 2.49956
Value Function Loss: 0.02068

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.10009
Policy Update Magnitude: 0.52605
Value Function Update Magnitude: 0.67740

Collected Steps per Second: 22,073.27910
Overall Steps per Second: 10,617.45532

Timestep Collection Time: 2.26582
Timestep Consumption Time: 2.44473
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.71054

Cumulative Model Updates: 302,866
Cumulative Timesteps: 2,525,896,500

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2525896500...
Checkpoint 2525896500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.53230
Policy Entropy: 2.50989
Value Function Loss: 0.02049

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.10948
Policy Update Magnitude: 0.50593
Value Function Update Magnitude: 0.69175

Collected Steps per Second: 22,126.24628
Overall Steps per Second: 10,547.13628

Timestep Collection Time: 2.26084
Timestep Consumption Time: 2.48205
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.74290

Cumulative Model Updates: 302,872
Cumulative Timesteps: 2,525,946,524

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.62601
Policy Entropy: 2.51480
Value Function Loss: 0.02084

Mean KL Divergence: 0.02387
SB3 Clip Fraction: 0.14314
Policy Update Magnitude: 0.48353
Value Function Update Magnitude: 0.67971

Collected Steps per Second: 22,438.42321
Overall Steps per Second: 10,519.81791

Timestep Collection Time: 2.22894
Timestep Consumption Time: 2.52532
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.75426

Cumulative Model Updates: 302,878
Cumulative Timesteps: 2,525,996,538

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2525996538...
Checkpoint 2525996538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.18850
Policy Entropy: 2.50493
Value Function Loss: 0.02051

Mean KL Divergence: 0.02316
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.48654
Value Function Update Magnitude: 0.64866

Collected Steps per Second: 21,636.87127
Overall Steps per Second: 10,547.36413

Timestep Collection Time: 2.31179
Timestep Consumption Time: 2.43062
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.74242

Cumulative Model Updates: 302,884
Cumulative Timesteps: 2,526,046,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.48008
Policy Entropy: 2.50095
Value Function Loss: 0.02035

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.12194
Policy Update Magnitude: 0.49402
Value Function Update Magnitude: 0.63780

Collected Steps per Second: 22,343.98099
Overall Steps per Second: 10,871.31385

Timestep Collection Time: 2.23863
Timestep Consumption Time: 2.36247
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.60110

Cumulative Model Updates: 302,890
Cumulative Timesteps: 2,526,096,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2526096578...
Checkpoint 2526096578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.65746
Policy Entropy: 2.51189
Value Function Loss: 0.01923

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.09360
Policy Update Magnitude: 0.49801
Value Function Update Magnitude: 0.63662

Collected Steps per Second: 22,011.44523
Overall Steps per Second: 10,586.51790

Timestep Collection Time: 2.27209
Timestep Consumption Time: 2.45203
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.72412

Cumulative Model Updates: 302,896
Cumulative Timesteps: 2,526,146,590

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.57621
Policy Entropy: 2.53190
Value Function Loss: 0.01837

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.08900
Policy Update Magnitude: 0.49064
Value Function Update Magnitude: 0.63738

Collected Steps per Second: 22,305.88976
Overall Steps per Second: 10,563.52214

Timestep Collection Time: 2.24165
Timestep Consumption Time: 2.49181
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.73346

Cumulative Model Updates: 302,902
Cumulative Timesteps: 2,526,196,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2526196592...
Checkpoint 2526196592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.87829
Policy Entropy: 2.53397
Value Function Loss: 0.01897

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.08542
Policy Update Magnitude: 0.49113
Value Function Update Magnitude: 0.65518

Collected Steps per Second: 21,933.43362
Overall Steps per Second: 10,593.88671

Timestep Collection Time: 2.28045
Timestep Consumption Time: 2.44096
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.72140

Cumulative Model Updates: 302,908
Cumulative Timesteps: 2,526,246,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.80018
Policy Entropy: 2.52959
Value Function Loss: 0.01875

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.08628
Policy Update Magnitude: 0.49213
Value Function Update Magnitude: 0.67403

Collected Steps per Second: 22,129.54249
Overall Steps per Second: 10,483.71784

Timestep Collection Time: 2.25951
Timestep Consumption Time: 2.50998
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.76949

Cumulative Model Updates: 302,914
Cumulative Timesteps: 2,526,296,612

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2526296612...
Checkpoint 2526296612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.52811
Policy Entropy: 2.53740
Value Function Loss: 0.01971

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.48397
Value Function Update Magnitude: 0.69106

Collected Steps per Second: 22,899.99746
Overall Steps per Second: 10,664.71122

Timestep Collection Time: 2.18472
Timestep Consumption Time: 2.50646
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.69117

Cumulative Model Updates: 302,920
Cumulative Timesteps: 2,526,346,642

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.84278
Policy Entropy: 2.55023
Value Function Loss: 0.02015

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.10222
Policy Update Magnitude: 0.48764
Value Function Update Magnitude: 0.67867

Collected Steps per Second: 22,279.46981
Overall Steps per Second: 10,321.90162

Timestep Collection Time: 2.24530
Timestep Consumption Time: 2.60110
PPO Batch Consumption Time: 0.30724
Total Iteration Time: 4.84639

Cumulative Model Updates: 302,926
Cumulative Timesteps: 2,526,396,666

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2526396666...
Checkpoint 2526396666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.98876
Policy Entropy: 2.54701
Value Function Loss: 0.01998

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.10368
Policy Update Magnitude: 0.48473
Value Function Update Magnitude: 0.70706

Collected Steps per Second: 21,929.33714
Overall Steps per Second: 10,352.80566

Timestep Collection Time: 2.28105
Timestep Consumption Time: 2.55068
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.83173

Cumulative Model Updates: 302,932
Cumulative Timesteps: 2,526,446,688

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.06650
Policy Entropy: 2.54281
Value Function Loss: 0.01972

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.10752
Policy Update Magnitude: 0.48870
Value Function Update Magnitude: 0.71998

Collected Steps per Second: 22,252.66600
Overall Steps per Second: 10,538.00302

Timestep Collection Time: 2.24764
Timestep Consumption Time: 2.49861
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.74625

Cumulative Model Updates: 302,938
Cumulative Timesteps: 2,526,496,704

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2526496704...
Checkpoint 2526496704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.78102
Policy Entropy: 2.52902
Value Function Loss: 0.01853

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.10316
Policy Update Magnitude: 0.49346
Value Function Update Magnitude: 0.69833

Collected Steps per Second: 23,029.09745
Overall Steps per Second: 10,745.33213

Timestep Collection Time: 2.17212
Timestep Consumption Time: 2.48311
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.65523

Cumulative Model Updates: 302,944
Cumulative Timesteps: 2,526,546,726

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.44821
Policy Entropy: 2.52439
Value Function Loss: 0.01966

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.10198
Policy Update Magnitude: 0.49624
Value Function Update Magnitude: 0.67869

Collected Steps per Second: 22,560.10828
Overall Steps per Second: 10,744.93844

Timestep Collection Time: 2.21763
Timestep Consumption Time: 2.43851
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.65615

Cumulative Model Updates: 302,950
Cumulative Timesteps: 2,526,596,756

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2526596756...
Checkpoint 2526596756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.94499
Policy Entropy: 2.51467
Value Function Loss: 0.02010

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.09865
Policy Update Magnitude: 0.50007
Value Function Update Magnitude: 0.66963

Collected Steps per Second: 21,555.19007
Overall Steps per Second: 10,546.28971

Timestep Collection Time: 2.32000
Timestep Consumption Time: 2.42176
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.74176

Cumulative Model Updates: 302,956
Cumulative Timesteps: 2,526,646,764

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.94249
Policy Entropy: 2.51408
Value Function Loss: 0.02091

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.10215
Policy Update Magnitude: 0.49180
Value Function Update Magnitude: 0.67230

Collected Steps per Second: 22,213.75535
Overall Steps per Second: 10,699.64936

Timestep Collection Time: 2.25113
Timestep Consumption Time: 2.42248
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.67361

Cumulative Model Updates: 302,962
Cumulative Timesteps: 2,526,696,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2526696770...
Checkpoint 2526696770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.32202
Policy Entropy: 2.50396
Value Function Loss: 0.02025

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.09765
Policy Update Magnitude: 0.48002
Value Function Update Magnitude: 0.68211

Collected Steps per Second: 21,969.60371
Overall Steps per Second: 10,525.79087

Timestep Collection Time: 2.27605
Timestep Consumption Time: 2.47456
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.75062

Cumulative Model Updates: 302,968
Cumulative Timesteps: 2,526,746,774

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.98901
Policy Entropy: 2.50524
Value Function Loss: 0.02065

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.49991
Value Function Update Magnitude: 0.70964

Collected Steps per Second: 22,115.11137
Overall Steps per Second: 10,427.02787

Timestep Collection Time: 2.26090
Timestep Consumption Time: 2.53433
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.79523

Cumulative Model Updates: 302,974
Cumulative Timesteps: 2,526,796,774

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2526796774...
Checkpoint 2526796774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.02382
Policy Entropy: 2.49499
Value Function Loss: 0.02059

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.09873
Policy Update Magnitude: 0.51076
Value Function Update Magnitude: 0.71156

Collected Steps per Second: 21,956.61452
Overall Steps per Second: 10,649.19903

Timestep Collection Time: 2.27722
Timestep Consumption Time: 2.41797
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.69519

Cumulative Model Updates: 302,980
Cumulative Timesteps: 2,526,846,774

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.28942
Policy Entropy: 2.49393
Value Function Loss: 0.02113

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.09332
Policy Update Magnitude: 0.51721
Value Function Update Magnitude: 0.69877

Collected Steps per Second: 22,266.34339
Overall Steps per Second: 10,849.41930

Timestep Collection Time: 2.24644
Timestep Consumption Time: 2.36395
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.61038

Cumulative Model Updates: 302,986
Cumulative Timesteps: 2,526,896,794

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2526896794...
Checkpoint 2526896794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.43018
Policy Entropy: 2.49530
Value Function Loss: 0.02040

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.09340
Policy Update Magnitude: 0.51590
Value Function Update Magnitude: 0.68748

Collected Steps per Second: 22,061.60186
Overall Steps per Second: 10,632.36373

Timestep Collection Time: 2.26702
Timestep Consumption Time: 2.43692
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.70394

Cumulative Model Updates: 302,992
Cumulative Timesteps: 2,526,946,808

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.49470
Policy Entropy: 2.49198
Value Function Loss: 0.02170

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.09797
Policy Update Magnitude: 0.51806
Value Function Update Magnitude: 0.69844

Collected Steps per Second: 21,947.22046
Overall Steps per Second: 10,422.08832

Timestep Collection Time: 2.27847
Timestep Consumption Time: 2.51961
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.79808

Cumulative Model Updates: 302,998
Cumulative Timesteps: 2,526,996,814

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2526996814...
Checkpoint 2526996814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.90922
Policy Entropy: 2.49314
Value Function Loss: 0.02192

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.10566
Policy Update Magnitude: 0.53477
Value Function Update Magnitude: 0.69479

Collected Steps per Second: 21,968.67458
Overall Steps per Second: 10,617.03766

Timestep Collection Time: 2.27624
Timestep Consumption Time: 2.43374
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.70998

Cumulative Model Updates: 303,004
Cumulative Timesteps: 2,527,046,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.87874
Policy Entropy: 2.48626
Value Function Loss: 0.02228

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.10887
Policy Update Magnitude: 0.52052
Value Function Update Magnitude: 0.69202

Collected Steps per Second: 22,020.36375
Overall Steps per Second: 10,441.52592

Timestep Collection Time: 2.27162
Timestep Consumption Time: 2.51905
PPO Batch Consumption Time: 0.29710
Total Iteration Time: 4.79068

Cumulative Model Updates: 303,010
Cumulative Timesteps: 2,527,096,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2527096842...
Checkpoint 2527096842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.28603
Policy Entropy: 2.51125
Value Function Loss: 0.02108

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.10454
Policy Update Magnitude: 0.50836
Value Function Update Magnitude: 0.66203

Collected Steps per Second: 21,913.74681
Overall Steps per Second: 10,810.85919

Timestep Collection Time: 2.28222
Timestep Consumption Time: 2.34387
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.62609

Cumulative Model Updates: 303,016
Cumulative Timesteps: 2,527,146,854

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.60088
Policy Entropy: 2.51592
Value Function Loss: 0.01991

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.09341
Policy Update Magnitude: 0.50075
Value Function Update Magnitude: 0.65654

Collected Steps per Second: 22,082.66115
Overall Steps per Second: 10,405.16554

Timestep Collection Time: 2.26440
Timestep Consumption Time: 2.54129
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.80569

Cumulative Model Updates: 303,022
Cumulative Timesteps: 2,527,196,858

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2527196858...
Checkpoint 2527196858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.31745
Policy Entropy: 2.50492
Value Function Loss: 0.01973

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.10444
Policy Update Magnitude: 0.49425
Value Function Update Magnitude: 0.65509

Collected Steps per Second: 21,867.27943
Overall Steps per Second: 10,574.97863

Timestep Collection Time: 2.28744
Timestep Consumption Time: 2.44260
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.73003

Cumulative Model Updates: 303,028
Cumulative Timesteps: 2,527,246,878

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.01842
Policy Entropy: 2.48284
Value Function Loss: 0.02076

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.10806
Policy Update Magnitude: 0.49532
Value Function Update Magnitude: 0.64094

Collected Steps per Second: 22,097.18972
Overall Steps per Second: 10,536.87425

Timestep Collection Time: 2.26300
Timestep Consumption Time: 2.48281
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.74581

Cumulative Model Updates: 303,034
Cumulative Timesteps: 2,527,296,884

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2527296884...
Checkpoint 2527296884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.05240
Policy Entropy: 2.49410
Value Function Loss: 0.02089

Mean KL Divergence: 0.02439
SB3 Clip Fraction: 0.14059
Policy Update Magnitude: 0.47154
Value Function Update Magnitude: 0.66764

Collected Steps per Second: 22,002.90290
Overall Steps per Second: 10,663.11858

Timestep Collection Time: 2.27325
Timestep Consumption Time: 2.41750
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.69075

Cumulative Model Updates: 303,040
Cumulative Timesteps: 2,527,346,902

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.19488
Policy Entropy: 2.49924
Value Function Loss: 0.01993

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.13946
Policy Update Magnitude: 0.46601
Value Function Update Magnitude: 0.68072

Collected Steps per Second: 22,049.24947
Overall Steps per Second: 10,417.62259

Timestep Collection Time: 2.26792
Timestep Consumption Time: 2.53221
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.80014

Cumulative Model Updates: 303,046
Cumulative Timesteps: 2,527,396,908

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2527396908...
Checkpoint 2527396908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.27851
Policy Entropy: 2.50415
Value Function Loss: 0.02002

Mean KL Divergence: 0.02322
SB3 Clip Fraction: 0.14101
Policy Update Magnitude: 0.45748
Value Function Update Magnitude: 0.68895

Collected Steps per Second: 21,912.28748
Overall Steps per Second: 10,564.46357

Timestep Collection Time: 2.28201
Timestep Consumption Time: 2.45122
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.73323

Cumulative Model Updates: 303,052
Cumulative Timesteps: 2,527,446,912

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.73854
Policy Entropy: 2.49509
Value Function Loss: 0.02035

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.11522
Policy Update Magnitude: 0.47603
Value Function Update Magnitude: 0.67972

Collected Steps per Second: 22,298.64321
Overall Steps per Second: 10,517.30255

Timestep Collection Time: 2.24328
Timestep Consumption Time: 2.51289
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.75616

Cumulative Model Updates: 303,058
Cumulative Timesteps: 2,527,496,934

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2527496934...
Checkpoint 2527496934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.14167
Policy Entropy: 2.47265
Value Function Loss: 0.02104

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.10483
Policy Update Magnitude: 0.49680
Value Function Update Magnitude: 0.67877

Collected Steps per Second: 21,753.63730
Overall Steps per Second: 10,722.56788

Timestep Collection Time: 2.29966
Timestep Consumption Time: 2.36583
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.66549

Cumulative Model Updates: 303,064
Cumulative Timesteps: 2,527,546,960

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.06231
Policy Entropy: 2.48029
Value Function Loss: 0.02071

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.10090
Policy Update Magnitude: 0.49165
Value Function Update Magnitude: 0.67329

Collected Steps per Second: 21,968.29702
Overall Steps per Second: 10,401.86481

Timestep Collection Time: 2.27601
Timestep Consumption Time: 2.53082
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.80683

Cumulative Model Updates: 303,070
Cumulative Timesteps: 2,527,596,960

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2527596960...
Checkpoint 2527596960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.20249
Policy Entropy: 2.48506
Value Function Loss: 0.02016

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.09062
Policy Update Magnitude: 0.49334
Value Function Update Magnitude: 0.64338

Collected Steps per Second: 22,100.42722
Overall Steps per Second: 10,592.91827

Timestep Collection Time: 2.26249
Timestep Consumption Time: 2.45783
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.72032

Cumulative Model Updates: 303,076
Cumulative Timesteps: 2,527,646,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.62646
Policy Entropy: 2.50802
Value Function Loss: 0.02005

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.09750
Policy Update Magnitude: 0.49064
Value Function Update Magnitude: 0.62520

Collected Steps per Second: 22,119.55597
Overall Steps per Second: 10,658.74141

Timestep Collection Time: 2.26144
Timestep Consumption Time: 2.43161
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.69305

Cumulative Model Updates: 303,082
Cumulative Timesteps: 2,527,696,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2527696984...
Checkpoint 2527696984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.33906
Policy Entropy: 2.51048
Value Function Loss: 0.02061

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.09342
Policy Update Magnitude: 0.49812
Value Function Update Magnitude: 0.63775

Collected Steps per Second: 21,957.14927
Overall Steps per Second: 10,403.83118

Timestep Collection Time: 2.27744
Timestep Consumption Time: 2.52906
PPO Batch Consumption Time: 0.29896
Total Iteration Time: 4.80650

Cumulative Model Updates: 303,088
Cumulative Timesteps: 2,527,746,990

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.37315
Policy Entropy: 2.49414
Value Function Loss: 0.02013

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.09380
Policy Update Magnitude: 0.49841
Value Function Update Magnitude: 0.66599

Collected Steps per Second: 21,933.43434
Overall Steps per Second: 10,563.69194

Timestep Collection Time: 2.27999
Timestep Consumption Time: 2.45396
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.73395

Cumulative Model Updates: 303,094
Cumulative Timesteps: 2,527,796,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2527796998...
Checkpoint 2527796998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.70648
Policy Entropy: 2.49238
Value Function Loss: 0.01907

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.48723
Value Function Update Magnitude: 0.64960

Collected Steps per Second: 21,908.96590
Overall Steps per Second: 10,612.25724

Timestep Collection Time: 2.28354
Timestep Consumption Time: 2.43082
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.71436

Cumulative Model Updates: 303,100
Cumulative Timesteps: 2,527,847,028

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.75112
Policy Entropy: 2.48686
Value Function Loss: 0.01937

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.08547
Policy Update Magnitude: 0.48550
Value Function Update Magnitude: 0.63553

Collected Steps per Second: 22,203.54889
Overall Steps per Second: 10,695.30194

Timestep Collection Time: 2.25324
Timestep Consumption Time: 2.42451
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.67775

Cumulative Model Updates: 303,106
Cumulative Timesteps: 2,527,897,058

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2527897058...
Checkpoint 2527897058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.18376
Policy Entropy: 2.50759
Value Function Loss: 0.02017

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.09748
Policy Update Magnitude: 0.48771
Value Function Update Magnitude: 0.63190

Collected Steps per Second: 22,423.01176
Overall Steps per Second: 10,607.00350

Timestep Collection Time: 2.22994
Timestep Consumption Time: 2.48411
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.71406

Cumulative Model Updates: 303,112
Cumulative Timesteps: 2,527,947,060

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.56353
Policy Entropy: 2.50362
Value Function Loss: 0.02037

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.09804
Policy Update Magnitude: 0.47765
Value Function Update Magnitude: 0.63832

Collected Steps per Second: 22,414.75879
Overall Steps per Second: 10,671.30777

Timestep Collection Time: 2.23192
Timestep Consumption Time: 2.45616
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.68809

Cumulative Model Updates: 303,118
Cumulative Timesteps: 2,527,997,088

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2527997088...
Checkpoint 2527997088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.93128
Policy Entropy: 2.50319
Value Function Loss: 0.02081

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.08946
Policy Update Magnitude: 0.48835
Value Function Update Magnitude: 0.64308

Collected Steps per Second: 21,658.91342
Overall Steps per Second: 10,358.64842

Timestep Collection Time: 2.30944
Timestep Consumption Time: 2.51937
PPO Batch Consumption Time: 0.29517
Total Iteration Time: 4.82882

Cumulative Model Updates: 303,124
Cumulative Timesteps: 2,528,047,108

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.47214
Policy Entropy: 2.48567
Value Function Loss: 0.02023

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.08730
Policy Update Magnitude: 0.49527
Value Function Update Magnitude: 0.65393

Collected Steps per Second: 22,765.81375
Overall Steps per Second: 10,646.22002

Timestep Collection Time: 2.19671
Timestep Consumption Time: 2.50073
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.69744

Cumulative Model Updates: 303,130
Cumulative Timesteps: 2,528,097,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2528097118...
Checkpoint 2528097118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.06700
Policy Entropy: 2.50173
Value Function Loss: 0.02023

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.49605
Value Function Update Magnitude: 0.66583

Collected Steps per Second: 21,651.50304
Overall Steps per Second: 10,278.32998

Timestep Collection Time: 2.30931
Timestep Consumption Time: 2.55530
PPO Batch Consumption Time: 0.29809
Total Iteration Time: 4.86460

Cumulative Model Updates: 303,136
Cumulative Timesteps: 2,528,147,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.02093
Policy Entropy: 2.48794
Value Function Loss: 0.01938

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.08955
Policy Update Magnitude: 0.49344
Value Function Update Magnitude: 0.66116

Collected Steps per Second: 21,735.62026
Overall Steps per Second: 10,470.42369

Timestep Collection Time: 2.30138
Timestep Consumption Time: 2.47607
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.77746

Cumulative Model Updates: 303,142
Cumulative Timesteps: 2,528,197,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2528197140...
Checkpoint 2528197140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.18461
Policy Entropy: 2.50886
Value Function Loss: 0.01919

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.48833
Value Function Update Magnitude: 0.64565

Collected Steps per Second: 21,844.46899
Overall Steps per Second: 10,627.20094

Timestep Collection Time: 2.29001
Timestep Consumption Time: 2.41716
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.70717

Cumulative Model Updates: 303,148
Cumulative Timesteps: 2,528,247,164

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.29192
Policy Entropy: 2.50920
Value Function Loss: 0.01978

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.09840
Policy Update Magnitude: 0.48194
Value Function Update Magnitude: 0.64376

Collected Steps per Second: 21,808.71084
Overall Steps per Second: 10,422.61488

Timestep Collection Time: 2.29294
Timestep Consumption Time: 2.50490
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.79784

Cumulative Model Updates: 303,154
Cumulative Timesteps: 2,528,297,170

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2528297170...
Checkpoint 2528297170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.94612
Policy Entropy: 2.52012
Value Function Loss: 0.02081

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.10101
Policy Update Magnitude: 0.49148
Value Function Update Magnitude: 0.66672

Collected Steps per Second: 21,864.26349
Overall Steps per Second: 10,310.97583

Timestep Collection Time: 2.28784
Timestep Consumption Time: 2.56349
PPO Batch Consumption Time: 0.29948
Total Iteration Time: 4.85134

Cumulative Model Updates: 303,160
Cumulative Timesteps: 2,528,347,192

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.68872
Policy Entropy: 2.50449
Value Function Loss: 0.01952

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.10431
Policy Update Magnitude: 0.49491
Value Function Update Magnitude: 0.67021

Collected Steps per Second: 21,571.29108
Overall Steps per Second: 10,328.75085

Timestep Collection Time: 2.31808
Timestep Consumption Time: 2.52316
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.84124

Cumulative Model Updates: 303,166
Cumulative Timesteps: 2,528,397,196

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2528397196...
Checkpoint 2528397196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.63018
Policy Entropy: 2.49311
Value Function Loss: 0.01983

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.10579
Policy Update Magnitude: 0.49699
Value Function Update Magnitude: 0.66920

Collected Steps per Second: 21,768.99501
Overall Steps per Second: 10,642.57923

Timestep Collection Time: 2.29776
Timestep Consumption Time: 2.40223
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.69999

Cumulative Model Updates: 303,172
Cumulative Timesteps: 2,528,447,216

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.80261
Policy Entropy: 2.49357
Value Function Loss: 0.01841

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.11040
Policy Update Magnitude: 0.49657
Value Function Update Magnitude: 0.67618

Collected Steps per Second: 21,958.55470
Overall Steps per Second: 10,520.95490

Timestep Collection Time: 2.27793
Timestep Consumption Time: 2.47639
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.75432

Cumulative Model Updates: 303,178
Cumulative Timesteps: 2,528,497,236

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2528497236...
Checkpoint 2528497236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.15154
Policy Entropy: 2.50253
Value Function Loss: 0.01984

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.12310
Policy Update Magnitude: 0.47673
Value Function Update Magnitude: 0.67502

Collected Steps per Second: 21,697.19688
Overall Steps per Second: 10,324.17863

Timestep Collection Time: 2.30546
Timestep Consumption Time: 2.53967
PPO Batch Consumption Time: 0.29747
Total Iteration Time: 4.84513

Cumulative Model Updates: 303,184
Cumulative Timesteps: 2,528,547,258

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.90502
Policy Entropy: 2.50806
Value Function Loss: 0.01865

Mean KL Divergence: 0.02241
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.45722
Value Function Update Magnitude: 0.67740

Collected Steps per Second: 21,855.30190
Overall Steps per Second: 10,364.50784

Timestep Collection Time: 2.28951
Timestep Consumption Time: 2.53831
PPO Batch Consumption Time: 0.29963
Total Iteration Time: 4.82782

Cumulative Model Updates: 303,190
Cumulative Timesteps: 2,528,597,296

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2528597296...
Checkpoint 2528597296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.45611
Policy Entropy: 2.51191
Value Function Loss: 0.01952

Mean KL Divergence: 0.02350
SB3 Clip Fraction: 0.14120
Policy Update Magnitude: 0.46801
Value Function Update Magnitude: 0.67213

Collected Steps per Second: 21,697.78157
Overall Steps per Second: 10,618.71756

Timestep Collection Time: 2.30530
Timestep Consumption Time: 2.40525
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.71055

Cumulative Model Updates: 303,196
Cumulative Timesteps: 2,528,647,316

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.20504
Policy Entropy: 2.51782
Value Function Loss: 0.01979

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.48953
Value Function Update Magnitude: 0.63504

Collected Steps per Second: 21,873.18748
Overall Steps per Second: 10,487.75638

Timestep Collection Time: 2.28618
Timestep Consumption Time: 2.48186
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.76804

Cumulative Model Updates: 303,202
Cumulative Timesteps: 2,528,697,322

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2528697322...
Checkpoint 2528697322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.91128
Policy Entropy: 2.49228
Value Function Loss: 0.02133

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.11098
Policy Update Magnitude: 0.51223
Value Function Update Magnitude: 0.62761

Collected Steps per Second: 21,575.67198
Overall Steps per Second: 10,281.18769

Timestep Collection Time: 2.31817
Timestep Consumption Time: 2.54664
PPO Batch Consumption Time: 0.29779
Total Iteration Time: 4.86481

Cumulative Model Updates: 303,208
Cumulative Timesteps: 2,528,747,338

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.14386
Policy Entropy: 2.48789
Value Function Loss: 0.02091

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.11166
Policy Update Magnitude: 0.49948
Value Function Update Magnitude: 0.64877

Collected Steps per Second: 21,848.78684
Overall Steps per Second: 10,361.32077

Timestep Collection Time: 2.28946
Timestep Consumption Time: 2.53830
PPO Batch Consumption Time: 0.30023
Total Iteration Time: 4.82776

Cumulative Model Updates: 303,214
Cumulative Timesteps: 2,528,797,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2528797360...
Checkpoint 2528797360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.65351
Policy Entropy: 2.46123
Value Function Loss: 0.02215

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.12467
Policy Update Magnitude: 0.48869
Value Function Update Magnitude: 0.67336

Collected Steps per Second: 21,673.18740
Overall Steps per Second: 10,529.90112

Timestep Collection Time: 2.30838
Timestep Consumption Time: 2.44285
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.75123

Cumulative Model Updates: 303,220
Cumulative Timesteps: 2,528,847,390

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.71964
Policy Entropy: 2.47080
Value Function Loss: 0.02210

Mean KL Divergence: 0.02307
SB3 Clip Fraction: 0.13772
Policy Update Magnitude: 0.48303
Value Function Update Magnitude: 0.68784

Collected Steps per Second: 22,622.73212
Overall Steps per Second: 10,611.76320

Timestep Collection Time: 2.21025
Timestep Consumption Time: 2.50169
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.71194

Cumulative Model Updates: 303,226
Cumulative Timesteps: 2,528,897,392

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2528897392...
Checkpoint 2528897392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.53160
Policy Entropy: 2.48839
Value Function Loss: 0.02315

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.12473
Policy Update Magnitude: 0.51324
Value Function Update Magnitude: 0.69895

Collected Steps per Second: 22,344.30571
Overall Steps per Second: 10,491.01881

Timestep Collection Time: 2.23896
Timestep Consumption Time: 2.52969
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.76865

Cumulative Model Updates: 303,232
Cumulative Timesteps: 2,528,947,420

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.28442
Policy Entropy: 2.49722
Value Function Loss: 0.02189

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.11165
Policy Update Magnitude: 0.52724
Value Function Update Magnitude: 0.72370

Collected Steps per Second: 21,489.49826
Overall Steps per Second: 10,416.47791

Timestep Collection Time: 2.32728
Timestep Consumption Time: 2.47396
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.80124

Cumulative Model Updates: 303,238
Cumulative Timesteps: 2,528,997,432

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2528997432...
Checkpoint 2528997432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.81512
Policy Entropy: 2.52188
Value Function Loss: 0.02059

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.51025
Value Function Update Magnitude: 0.70824

Collected Steps per Second: 21,526.56845
Overall Steps per Second: 10,447.79380

Timestep Collection Time: 2.32355
Timestep Consumption Time: 2.46387
PPO Batch Consumption Time: 0.29861
Total Iteration Time: 4.78742

Cumulative Model Updates: 303,244
Cumulative Timesteps: 2,529,047,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.51165
Policy Entropy: 2.51518
Value Function Loss: 0.02056

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.50856
Value Function Update Magnitude: 0.68973

Collected Steps per Second: 21,720.50552
Overall Steps per Second: 10,328.01879

Timestep Collection Time: 2.30243
Timestep Consumption Time: 2.53974
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.84217

Cumulative Model Updates: 303,250
Cumulative Timesteps: 2,529,097,460

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2529097460...
Checkpoint 2529097460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.42636
Policy Entropy: 2.52050
Value Function Loss: 0.02147

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.11481
Policy Update Magnitude: 0.51987
Value Function Update Magnitude: 0.69574

Collected Steps per Second: 21,693.95670
Overall Steps per Second: 10,258.71647

Timestep Collection Time: 2.30516
Timestep Consumption Time: 2.56953
PPO Batch Consumption Time: 0.30039
Total Iteration Time: 4.87468

Cumulative Model Updates: 303,256
Cumulative Timesteps: 2,529,147,468

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.80266
Policy Entropy: 2.50887
Value Function Loss: 0.02185

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.11444
Policy Update Magnitude: 0.53411
Value Function Update Magnitude: 0.70672

Collected Steps per Second: 21,626.31609
Overall Steps per Second: 10,480.68897

Timestep Collection Time: 2.31255
Timestep Consumption Time: 2.45927
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.77182

Cumulative Model Updates: 303,262
Cumulative Timesteps: 2,529,197,480

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2529197480...
Checkpoint 2529197480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.72742
Policy Entropy: 2.50634
Value Function Loss: 0.02058

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.12356
Policy Update Magnitude: 0.52033
Value Function Update Magnitude: 0.68325

Collected Steps per Second: 21,791.94063
Overall Steps per Second: 10,639.41733

Timestep Collection Time: 2.29571
Timestep Consumption Time: 2.40643
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.70214

Cumulative Model Updates: 303,268
Cumulative Timesteps: 2,529,247,508

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.28671
Policy Entropy: 2.51233
Value Function Loss: 0.02028

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.11511
Policy Update Magnitude: 0.50983
Value Function Update Magnitude: 0.66383

Collected Steps per Second: 21,656.02464
Overall Steps per Second: 10,373.35834

Timestep Collection Time: 2.30929
Timestep Consumption Time: 2.51172
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.82100

Cumulative Model Updates: 303,274
Cumulative Timesteps: 2,529,297,518

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2529297518...
Checkpoint 2529297518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.20009
Policy Entropy: 2.51198
Value Function Loss: 0.02039

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.11191
Policy Update Magnitude: 0.51899
Value Function Update Magnitude: 0.66417

Collected Steps per Second: 21,588.29555
Overall Steps per Second: 10,231.84847

Timestep Collection Time: 2.31709
Timestep Consumption Time: 2.57176
PPO Batch Consumption Time: 0.29856
Total Iteration Time: 4.88885

Cumulative Model Updates: 303,280
Cumulative Timesteps: 2,529,347,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.17662
Policy Entropy: 2.50752
Value Function Loss: 0.02074

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.12188
Policy Update Magnitude: 0.50577
Value Function Update Magnitude: 0.67866

Collected Steps per Second: 21,672.77482
Overall Steps per Second: 10,405.24433

Timestep Collection Time: 2.30713
Timestep Consumption Time: 2.49833
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.80546

Cumulative Model Updates: 303,286
Cumulative Timesteps: 2,529,397,542

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2529397542...
Checkpoint 2529397542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.05156
Policy Entropy: 2.50851
Value Function Loss: 0.02089

Mean KL Divergence: 0.02710
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.49234
Value Function Update Magnitude: 0.72039

Collected Steps per Second: 21,640.00022
Overall Steps per Second: 10,625.16431

Timestep Collection Time: 2.31174
Timestep Consumption Time: 2.39652
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.70826

Cumulative Model Updates: 303,292
Cumulative Timesteps: 2,529,447,568

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.49208
Policy Entropy: 2.51113
Value Function Loss: 0.02023

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.12938
Policy Update Magnitude: 0.51431
Value Function Update Magnitude: 0.73089

Collected Steps per Second: 21,822.09141
Overall Steps per Second: 10,453.36825

Timestep Collection Time: 2.29236
Timestep Consumption Time: 2.49309
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.78544

Cumulative Model Updates: 303,298
Cumulative Timesteps: 2,529,497,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2529497592...
Checkpoint 2529497592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.33880
Policy Entropy: 2.50707
Value Function Loss: 0.01979

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.12038
Policy Update Magnitude: 0.51817
Value Function Update Magnitude: 0.71690

Collected Steps per Second: 21,458.89409
Overall Steps per Second: 10,290.50222

Timestep Collection Time: 2.33013
Timestep Consumption Time: 2.52891
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.85904

Cumulative Model Updates: 303,304
Cumulative Timesteps: 2,529,547,594

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.98533
Policy Entropy: 2.48927
Value Function Loss: 0.01994

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.10004
Policy Update Magnitude: 0.52326
Value Function Update Magnitude: 0.69946

Collected Steps per Second: 21,803.74096
Overall Steps per Second: 10,391.69457

Timestep Collection Time: 2.29364
Timestep Consumption Time: 2.51885
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.81250

Cumulative Model Updates: 303,310
Cumulative Timesteps: 2,529,597,604

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2529597604...
Checkpoint 2529597604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.68792
Policy Entropy: 2.48115
Value Function Loss: 0.02026

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.08801
Policy Update Magnitude: 0.51339
Value Function Update Magnitude: 0.66930

Collected Steps per Second: 22,090.44017
Overall Steps per Second: 10,809.64314

Timestep Collection Time: 2.26433
Timestep Consumption Time: 2.36302
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.62735

Cumulative Model Updates: 303,316
Cumulative Timesteps: 2,529,647,624

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.01177
Policy Entropy: 2.48384
Value Function Loss: 0.02077

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.09199
Policy Update Magnitude: 0.51567
Value Function Update Magnitude: 0.65505

Collected Steps per Second: 22,400.48230
Overall Steps per Second: 10,487.73372

Timestep Collection Time: 2.23263
Timestep Consumption Time: 2.53599
PPO Batch Consumption Time: 0.29775
Total Iteration Time: 4.76862

Cumulative Model Updates: 303,322
Cumulative Timesteps: 2,529,697,636

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2529697636...
Checkpoint 2529697636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.70057
Policy Entropy: 2.50188
Value Function Loss: 0.02033

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.09599
Policy Update Magnitude: 0.51315
Value Function Update Magnitude: 0.66020

Collected Steps per Second: 21,903.86230
Overall Steps per Second: 10,561.99266

Timestep Collection Time: 2.28334
Timestep Consumption Time: 2.45194
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.73528

Cumulative Model Updates: 303,328
Cumulative Timesteps: 2,529,747,650

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.24913
Policy Entropy: 2.52122
Value Function Loss: 0.01965

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.09908
Policy Update Magnitude: 0.50169
Value Function Update Magnitude: 0.66444

Collected Steps per Second: 22,189.94742
Overall Steps per Second: 10,499.00066

Timestep Collection Time: 2.25363
Timestep Consumption Time: 2.50949
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.76312

Cumulative Model Updates: 303,334
Cumulative Timesteps: 2,529,797,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2529797658...
Checkpoint 2529797658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.32014
Policy Entropy: 2.50646
Value Function Loss: 0.01886

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.13333
Policy Update Magnitude: 0.49896
Value Function Update Magnitude: 0.66161

Collected Steps per Second: 22,191.85982
Overall Steps per Second: 10,644.65033

Timestep Collection Time: 2.25425
Timestep Consumption Time: 2.44539
PPO Batch Consumption Time: 0.29492
Total Iteration Time: 4.69964

Cumulative Model Updates: 303,340
Cumulative Timesteps: 2,529,847,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.75865
Policy Entropy: 2.50313
Value Function Loss: 0.01964

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.11988
Policy Update Magnitude: 0.48456
Value Function Update Magnitude: 0.67067

Collected Steps per Second: 22,409.61161
Overall Steps per Second: 10,509.52939

Timestep Collection Time: 2.23217
Timestep Consumption Time: 2.52751
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.75968

Cumulative Model Updates: 303,346
Cumulative Timesteps: 2,529,897,706

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2529897706...
Checkpoint 2529897706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.56608
Policy Entropy: 2.49414
Value Function Loss: 0.01985

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.10961
Policy Update Magnitude: 0.51688
Value Function Update Magnitude: 0.68335

Collected Steps per Second: 21,874.22491
Overall Steps per Second: 10,564.47623

Timestep Collection Time: 2.28644
Timestep Consumption Time: 2.44773
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.73417

Cumulative Model Updates: 303,352
Cumulative Timesteps: 2,529,947,720

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.55319
Policy Entropy: 2.50527
Value Function Loss: 0.02028

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.10125
Policy Update Magnitude: 0.51526
Value Function Update Magnitude: 0.68494

Collected Steps per Second: 22,268.12328
Overall Steps per Second: 10,839.33287

Timestep Collection Time: 2.24662
Timestep Consumption Time: 2.36879
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.61541

Cumulative Model Updates: 303,358
Cumulative Timesteps: 2,529,997,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2529997748...
Checkpoint 2529997748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.26043
Policy Entropy: 2.48336
Value Function Loss: 0.02152

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.09644
Policy Update Magnitude: 0.51856
Value Function Update Magnitude: 0.65427

Collected Steps per Second: 21,879.49825
Overall Steps per Second: 10,429.06789

Timestep Collection Time: 2.28561
Timestep Consumption Time: 2.50945
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.79506

Cumulative Model Updates: 303,364
Cumulative Timesteps: 2,530,047,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.01963
Policy Entropy: 2.48301
Value Function Loss: 0.02095

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.09151
Policy Update Magnitude: 0.50503
Value Function Update Magnitude: 0.64795

Collected Steps per Second: 22,511.16735
Overall Steps per Second: 10,691.42484

Timestep Collection Time: 2.22148
Timestep Consumption Time: 2.45592
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.67739

Cumulative Model Updates: 303,370
Cumulative Timesteps: 2,530,097,764

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2530097764...
Checkpoint 2530097764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.99250
Policy Entropy: 2.48539
Value Function Loss: 0.02116

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.10424
Policy Update Magnitude: 0.49920
Value Function Update Magnitude: 0.64369

Collected Steps per Second: 21,748.22890
Overall Steps per Second: 10,475.38872

Timestep Collection Time: 2.29996
Timestep Consumption Time: 2.47504
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.77500

Cumulative Model Updates: 303,376
Cumulative Timesteps: 2,530,147,784

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.32248
Policy Entropy: 2.48615
Value Function Loss: 0.02064

Mean KL Divergence: 0.02408
SB3 Clip Fraction: 0.13881
Policy Update Magnitude: 0.47242
Value Function Update Magnitude: 0.64215

Collected Steps per Second: 22,530.19860
Overall Steps per Second: 10,695.70451

Timestep Collection Time: 2.21995
Timestep Consumption Time: 2.45632
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.67627

Cumulative Model Updates: 303,382
Cumulative Timesteps: 2,530,197,800

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2530197800...
Checkpoint 2530197800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.39581
Policy Entropy: 2.50589
Value Function Loss: 0.02093

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.12192
Policy Update Magnitude: 0.46256
Value Function Update Magnitude: 0.64155

Collected Steps per Second: 22,057.50521
Overall Steps per Second: 10,619.20136

Timestep Collection Time: 2.26726
Timestep Consumption Time: 2.44214
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.70939

Cumulative Model Updates: 303,388
Cumulative Timesteps: 2,530,247,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.07306
Policy Entropy: 2.50798
Value Function Loss: 0.01877

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.46486
Value Function Update Magnitude: 0.64747

Collected Steps per Second: 22,444.32053
Overall Steps per Second: 10,519.30568

Timestep Collection Time: 2.22800
Timestep Consumption Time: 2.52573
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.75374

Cumulative Model Updates: 303,394
Cumulative Timesteps: 2,530,297,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2530297816...
Checkpoint 2530297816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.39095
Policy Entropy: 2.51645
Value Function Loss: 0.01874

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.11491
Policy Update Magnitude: 0.48831
Value Function Update Magnitude: 0.63518

Collected Steps per Second: 20,652.34049
Overall Steps per Second: 10,069.27437

Timestep Collection Time: 2.42220
Timestep Consumption Time: 2.54579
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.96798

Cumulative Model Updates: 303,400
Cumulative Timesteps: 2,530,347,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.79558
Policy Entropy: 2.48979
Value Function Loss: 0.01950

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.11255
Policy Update Magnitude: 0.50547
Value Function Update Magnitude: 0.62645

Collected Steps per Second: 20,564.21973
Overall Steps per Second: 10,193.20731

Timestep Collection Time: 2.43228
Timestep Consumption Time: 2.47471
PPO Batch Consumption Time: 0.29492
Total Iteration Time: 4.90699

Cumulative Model Updates: 303,406
Cumulative Timesteps: 2,530,397,858

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2530397858...
Checkpoint 2530397858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.35733
Policy Entropy: 2.48923
Value Function Loss: 0.02076

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.10504
Policy Update Magnitude: 0.50141
Value Function Update Magnitude: 0.64867

Collected Steps per Second: 20,767.69709
Overall Steps per Second: 10,161.71482

Timestep Collection Time: 2.40778
Timestep Consumption Time: 2.51305
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.92082

Cumulative Model Updates: 303,412
Cumulative Timesteps: 2,530,447,862

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.47405
Policy Entropy: 2.47496
Value Function Loss: 0.02127

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.11126
Policy Update Magnitude: 0.51134
Value Function Update Magnitude: 0.66234

Collected Steps per Second: 22,208.01953
Overall Steps per Second: 10,450.84260

Timestep Collection Time: 2.25153
Timestep Consumption Time: 2.53297
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.78449

Cumulative Model Updates: 303,418
Cumulative Timesteps: 2,530,497,864

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2530497864...
Checkpoint 2530497864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.72567
Policy Entropy: 2.49270
Value Function Loss: 0.02140

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.12763
Policy Update Magnitude: 0.47401
Value Function Update Magnitude: 0.66844

Collected Steps per Second: 21,852.47916
Overall Steps per Second: 10,578.05044

Timestep Collection Time: 2.28844
Timestep Consumption Time: 2.43909
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.72753

Cumulative Model Updates: 303,424
Cumulative Timesteps: 2,530,547,872

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.97197
Policy Entropy: 2.48178
Value Function Loss: 0.02120

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.11114
Policy Update Magnitude: 0.49150
Value Function Update Magnitude: 0.69083

Collected Steps per Second: 23,027.00044
Overall Steps per Second: 10,688.55373

Timestep Collection Time: 2.17215
Timestep Consumption Time: 2.50744
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.67959

Cumulative Model Updates: 303,430
Cumulative Timesteps: 2,530,597,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2530597890...
Checkpoint 2530597890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.80701
Policy Entropy: 2.51262
Value Function Loss: 0.01971

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.11038
Policy Update Magnitude: 0.52384
Value Function Update Magnitude: 0.69435

Collected Steps per Second: 21,308.87247
Overall Steps per Second: 10,429.75533

Timestep Collection Time: 2.34785
Timestep Consumption Time: 2.44900
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.79685

Cumulative Model Updates: 303,436
Cumulative Timesteps: 2,530,647,920

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.66329
Policy Entropy: 2.49802
Value Function Loss: 0.01982

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.11855
Policy Update Magnitude: 0.51151
Value Function Update Magnitude: 0.68946

Collected Steps per Second: 22,427.97011
Overall Steps per Second: 10,500.85881

Timestep Collection Time: 2.23052
Timestep Consumption Time: 2.53347
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.76399

Cumulative Model Updates: 303,442
Cumulative Timesteps: 2,530,697,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2530697946...
Checkpoint 2530697946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.95005
Policy Entropy: 2.50828
Value Function Loss: 0.01949

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.49337
Value Function Update Magnitude: 0.68219

Collected Steps per Second: 21,960.51068
Overall Steps per Second: 10,656.64628

Timestep Collection Time: 2.27809
Timestep Consumption Time: 2.41645
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.69454

Cumulative Model Updates: 303,448
Cumulative Timesteps: 2,530,747,974

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.86083
Policy Entropy: 2.49344
Value Function Loss: 0.02018

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.12239
Policy Update Magnitude: 0.50614
Value Function Update Magnitude: 0.66195

Collected Steps per Second: 22,412.60054
Overall Steps per Second: 10,535.63587

Timestep Collection Time: 2.23107
Timestep Consumption Time: 2.51511
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.74618

Cumulative Model Updates: 303,454
Cumulative Timesteps: 2,530,797,978

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2530797978...
Checkpoint 2530797978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161.15181
Policy Entropy: 2.48644
Value Function Loss: 0.02043

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.11048
Policy Update Magnitude: 0.49993
Value Function Update Magnitude: 0.65768

Collected Steps per Second: 22,074.04472
Overall Steps per Second: 10,526.75917

Timestep Collection Time: 2.26547
Timestep Consumption Time: 2.48509
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.75056

Cumulative Model Updates: 303,460
Cumulative Timesteps: 2,530,847,986

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.18821
Policy Entropy: 2.48429
Value Function Loss: 0.01982

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.10486
Policy Update Magnitude: 0.50598
Value Function Update Magnitude: 0.65497

Collected Steps per Second: 22,106.49910
Overall Steps per Second: 10,665.72334

Timestep Collection Time: 2.26241
Timestep Consumption Time: 2.42682
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.68923

Cumulative Model Updates: 303,466
Cumulative Timesteps: 2,530,898,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2530898000...
Checkpoint 2530898000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.29293
Policy Entropy: 2.46368
Value Function Loss: 0.02064

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.10092
Policy Update Magnitude: 0.50795
Value Function Update Magnitude: 0.65906

Collected Steps per Second: 21,659.73092
Overall Steps per Second: 10,459.08418

Timestep Collection Time: 2.30852
Timestep Consumption Time: 2.47220
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.78072

Cumulative Model Updates: 303,472
Cumulative Timesteps: 2,530,948,002

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.40558
Policy Entropy: 2.45401
Value Function Loss: 0.02106

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.51348
Value Function Update Magnitude: 0.65247

Collected Steps per Second: 22,050.10503
Overall Steps per Second: 10,496.93798

Timestep Collection Time: 2.26774
Timestep Consumption Time: 2.49593
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.76367

Cumulative Model Updates: 303,478
Cumulative Timesteps: 2,530,998,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2530998006...
Checkpoint 2530998006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.30144
Policy Entropy: 2.47364
Value Function Loss: 0.02049

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.10133
Policy Update Magnitude: 0.50658
Value Function Update Magnitude: 0.63966

Collected Steps per Second: 21,682.57737
Overall Steps per Second: 10,629.78953

Timestep Collection Time: 2.30711
Timestep Consumption Time: 2.39891
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.70602

Cumulative Model Updates: 303,484
Cumulative Timesteps: 2,531,048,030

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.78762
Policy Entropy: 2.49165
Value Function Loss: 0.01992

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.10475
Policy Update Magnitude: 0.50118
Value Function Update Magnitude: 0.66085

Collected Steps per Second: 22,329.81783
Overall Steps per Second: 10,827.53059

Timestep Collection Time: 2.24032
Timestep Consumption Time: 2.37994
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.62026

Cumulative Model Updates: 303,490
Cumulative Timesteps: 2,531,098,056

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2531098056...
Checkpoint 2531098056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.17817
Policy Entropy: 2.48610
Value Function Loss: 0.01897

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.11474
Policy Update Magnitude: 0.49058
Value Function Update Magnitude: 0.66857

Collected Steps per Second: 21,969.38053
Overall Steps per Second: 10,591.17269

Timestep Collection Time: 2.27653
Timestep Consumption Time: 2.44570
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.72223

Cumulative Model Updates: 303,496
Cumulative Timesteps: 2,531,148,070

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.70745
Policy Entropy: 2.48853
Value Function Loss: 0.01917

Mean KL Divergence: 0.02341
SB3 Clip Fraction: 0.14310
Policy Update Magnitude: 0.49405
Value Function Update Magnitude: 0.66651

Collected Steps per Second: 22,127.03379
Overall Steps per Second: 10,630.15429

Timestep Collection Time: 2.26031
Timestep Consumption Time: 2.44461
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.70492

Cumulative Model Updates: 303,502
Cumulative Timesteps: 2,531,198,084

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2531198084...
Checkpoint 2531198084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.74250
Policy Entropy: 2.46168
Value Function Loss: 0.01981

Mean KL Divergence: 0.02703
SB3 Clip Fraction: 0.15204
Policy Update Magnitude: 0.48762
Value Function Update Magnitude: 0.65613

Collected Steps per Second: 22,096.47800
Overall Steps per Second: 10,595.25132

Timestep Collection Time: 2.26389
Timestep Consumption Time: 2.45747
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.72136

Cumulative Model Updates: 303,508
Cumulative Timesteps: 2,531,248,108

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.07007
Policy Entropy: 2.49785
Value Function Loss: 0.02064

Mean KL Divergence: 0.02692
SB3 Clip Fraction: 0.15254
Policy Update Magnitude: 0.49124
Value Function Update Magnitude: 0.66392

Collected Steps per Second: 22,325.17705
Overall Steps per Second: 10,576.48056

Timestep Collection Time: 2.24079
Timestep Consumption Time: 2.48914
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.72993

Cumulative Model Updates: 303,514
Cumulative Timesteps: 2,531,298,134

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2531298134...
Checkpoint 2531298134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.12433
Policy Entropy: 2.51232
Value Function Loss: 0.02120

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.51787
Value Function Update Magnitude: 0.67009

Collected Steps per Second: 22,270.54293
Overall Steps per Second: 10,850.35680

Timestep Collection Time: 2.24620
Timestep Consumption Time: 2.36416
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.61036

Cumulative Model Updates: 303,520
Cumulative Timesteps: 2,531,348,158

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.63778
Policy Entropy: 2.51162
Value Function Loss: 0.02100

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.12010
Policy Update Magnitude: 0.51722
Value Function Update Magnitude: 0.66033

Collected Steps per Second: 22,238.96566
Overall Steps per Second: 10,562.54564

Timestep Collection Time: 2.24858
Timestep Consumption Time: 2.48570
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.73428

Cumulative Model Updates: 303,526
Cumulative Timesteps: 2,531,398,164

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2531398164...
Checkpoint 2531398164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.40027
Policy Entropy: 2.47789
Value Function Loss: 0.02153

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.10029
Policy Update Magnitude: 0.51376
Value Function Update Magnitude: 0.65579

Collected Steps per Second: 21,996.94019
Overall Steps per Second: 10,589.42939

Timestep Collection Time: 2.27341
Timestep Consumption Time: 2.44904
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.72245

Cumulative Model Updates: 303,532
Cumulative Timesteps: 2,531,448,172

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.42915
Policy Entropy: 2.43691
Value Function Loss: 0.02220

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.09869
Policy Update Magnitude: 0.51664
Value Function Update Magnitude: 0.67567

Collected Steps per Second: 22,257.87608
Overall Steps per Second: 10,697.18492

Timestep Collection Time: 2.24747
Timestep Consumption Time: 2.42890
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.67637

Cumulative Model Updates: 303,538
Cumulative Timesteps: 2,531,498,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2531498196...
Checkpoint 2531498196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.14120
Policy Entropy: 2.43406
Value Function Loss: 0.02122

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.52245
Value Function Update Magnitude: 0.67155

Collected Steps per Second: 22,163.35724
Overall Steps per Second: 10,493.13189

Timestep Collection Time: 2.25688
Timestep Consumption Time: 2.51005
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.76693

Cumulative Model Updates: 303,544
Cumulative Timesteps: 2,531,548,216

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.04594
Policy Entropy: 2.44994
Value Function Loss: 0.01939

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.52409
Value Function Update Magnitude: 0.66577

Collected Steps per Second: 22,294.03806
Overall Steps per Second: 10,533.91415

Timestep Collection Time: 2.24302
Timestep Consumption Time: 2.50412
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.74714

Cumulative Model Updates: 303,550
Cumulative Timesteps: 2,531,598,222

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2531598222...
Checkpoint 2531598222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.64177
Policy Entropy: 2.47090
Value Function Loss: 0.01951

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.51442
Value Function Update Magnitude: 0.66997

Collected Steps per Second: 22,029.21538
Overall Steps per Second: 10,432.95839

Timestep Collection Time: 2.27017
Timestep Consumption Time: 2.52330
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.79346

Cumulative Model Updates: 303,556
Cumulative Timesteps: 2,531,648,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.43648
Policy Entropy: 2.48815
Value Function Loss: 0.01978

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.50467
Value Function Update Magnitude: 0.68006

Collected Steps per Second: 22,129.45866
Overall Steps per Second: 10,641.35776

Timestep Collection Time: 2.26015
Timestep Consumption Time: 2.44000
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.70015

Cumulative Model Updates: 303,562
Cumulative Timesteps: 2,531,698,248

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2531698248...
Checkpoint 2531698248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.35411
Policy Entropy: 2.46676
Value Function Loss: 0.02078

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.51312
Value Function Update Magnitude: 0.67131

Collected Steps per Second: 22,194.51261
Overall Steps per Second: 10,526.13856

Timestep Collection Time: 2.25353
Timestep Consumption Time: 2.49807
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.75160

Cumulative Model Updates: 303,568
Cumulative Timesteps: 2,531,748,264

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.10403
Policy Entropy: 2.45750
Value Function Loss: 0.02039

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.09646
Policy Update Magnitude: 0.51820
Value Function Update Magnitude: 0.67129

Collected Steps per Second: 22,260.51810
Overall Steps per Second: 10,489.50220

Timestep Collection Time: 2.24730
Timestep Consumption Time: 2.52185
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.76915

Cumulative Model Updates: 303,574
Cumulative Timesteps: 2,531,798,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2531798290...
Checkpoint 2531798290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.93988
Policy Entropy: 2.44523
Value Function Loss: 0.01978

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.10088
Policy Update Magnitude: 0.51192
Value Function Update Magnitude: 0.66454

Collected Steps per Second: 21,396.52309
Overall Steps per Second: 10,266.59212

Timestep Collection Time: 2.33776
Timestep Consumption Time: 2.53435
PPO Batch Consumption Time: 0.29982
Total Iteration Time: 4.87211

Cumulative Model Updates: 303,580
Cumulative Timesteps: 2,531,848,310

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.69134
Policy Entropy: 2.44792
Value Function Loss: 0.01965

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.12656
Policy Update Magnitude: 0.47339
Value Function Update Magnitude: 0.66880

Collected Steps per Second: 21,780.55397
Overall Steps per Second: 10,303.74728

Timestep Collection Time: 2.29590
Timestep Consumption Time: 2.55728
PPO Batch Consumption Time: 0.29965
Total Iteration Time: 4.85319

Cumulative Model Updates: 303,586
Cumulative Timesteps: 2,531,898,316

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2531898316...
Checkpoint 2531898316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.25167
Policy Entropy: 2.46016
Value Function Loss: 0.01978

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.46823
Value Function Update Magnitude: 0.69389

Collected Steps per Second: 21,411.88479
Overall Steps per Second: 10,536.19656

Timestep Collection Time: 2.33609
Timestep Consumption Time: 2.41136
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.74744

Cumulative Model Updates: 303,592
Cumulative Timesteps: 2,531,948,336

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.63031
Policy Entropy: 2.46689
Value Function Loss: 0.02006

Mean KL Divergence: 0.02332
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.50192
Value Function Update Magnitude: 0.68449

Collected Steps per Second: 21,997.69553
Overall Steps per Second: 10,487.72955

Timestep Collection Time: 2.27315
Timestep Consumption Time: 2.49471
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.76786

Cumulative Model Updates: 303,598
Cumulative Timesteps: 2,531,998,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2531998340...
Checkpoint 2531998340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.76344
Policy Entropy: 2.46563
Value Function Loss: 0.02062

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.12348
Policy Update Magnitude: 0.51100
Value Function Update Magnitude: 0.68085

Collected Steps per Second: 21,643.09555
Overall Steps per Second: 10,306.11762

Timestep Collection Time: 2.31048
Timestep Consumption Time: 2.54159
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.85207

Cumulative Model Updates: 303,604
Cumulative Timesteps: 2,532,048,346

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.93352
Policy Entropy: 2.46764
Value Function Loss: 0.02034

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.10407
Policy Update Magnitude: 0.51879
Value Function Update Magnitude: 0.68758

Collected Steps per Second: 21,855.66183
Overall Steps per Second: 10,430.03772

Timestep Collection Time: 2.28856
Timestep Consumption Time: 2.50701
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.79557

Cumulative Model Updates: 303,610
Cumulative Timesteps: 2,532,098,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2532098364...
Checkpoint 2532098364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.85455
Policy Entropy: 2.45688
Value Function Loss: 0.02058

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.10008
Policy Update Magnitude: 0.52363
Value Function Update Magnitude: 0.68804

Collected Steps per Second: 22,375.39329
Overall Steps per Second: 10,585.60326

Timestep Collection Time: 2.23567
Timestep Consumption Time: 2.48999
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.72566

Cumulative Model Updates: 303,616
Cumulative Timesteps: 2,532,148,388

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.89686
Policy Entropy: 2.46392
Value Function Loss: 0.01982

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.10750
Policy Update Magnitude: 0.51892
Value Function Update Magnitude: 0.66766

Collected Steps per Second: 21,954.85379
Overall Steps per Second: 10,453.82527

Timestep Collection Time: 2.27804
Timestep Consumption Time: 2.50624
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.78428

Cumulative Model Updates: 303,622
Cumulative Timesteps: 2,532,198,402

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2532198402...
Checkpoint 2532198402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.31525
Policy Entropy: 2.45708
Value Function Loss: 0.01904

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.10940
Policy Update Magnitude: 0.52647
Value Function Update Magnitude: 0.65759

Collected Steps per Second: 21,835.52443
Overall Steps per Second: 10,317.51996

Timestep Collection Time: 2.29040
Timestep Consumption Time: 2.55689
PPO Batch Consumption Time: 0.29904
Total Iteration Time: 4.84729

Cumulative Model Updates: 303,628
Cumulative Timesteps: 2,532,248,414

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.88025
Policy Entropy: 2.48501
Value Function Loss: 0.01838

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.13208
Policy Update Magnitude: 0.51276
Value Function Update Magnitude: 0.63448

Collected Steps per Second: 21,424.05827
Overall Steps per Second: 10,260.44610

Timestep Collection Time: 2.33476
Timestep Consumption Time: 2.54027
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.87503

Cumulative Model Updates: 303,634
Cumulative Timesteps: 2,532,298,434

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2532298434...
Checkpoint 2532298434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.19461
Policy Entropy: 2.47784
Value Function Loss: 0.02085

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.12008
Policy Update Magnitude: 0.51609
Value Function Update Magnitude: 0.65046

Collected Steps per Second: 22,530.37751
Overall Steps per Second: 10,557.08965

Timestep Collection Time: 2.22100
Timestep Consumption Time: 2.51894
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.73994

Cumulative Model Updates: 303,640
Cumulative Timesteps: 2,532,348,474

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.42783
Policy Entropy: 2.46863
Value Function Loss: 0.02129

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.11123
Policy Update Magnitude: 0.53234
Value Function Update Magnitude: 0.67225

Collected Steps per Second: 21,814.18340
Overall Steps per Second: 10,280.97437

Timestep Collection Time: 2.29218
Timestep Consumption Time: 2.57137
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.86355

Cumulative Model Updates: 303,646
Cumulative Timesteps: 2,532,398,476

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2532398476...
Checkpoint 2532398476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.95763
Policy Entropy: 2.46036
Value Function Loss: 0.02155

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.54198
Value Function Update Magnitude: 0.68615

Collected Steps per Second: 21,973.79294
Overall Steps per Second: 10,522.89520

Timestep Collection Time: 2.27626
Timestep Consumption Time: 2.47700
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.75325

Cumulative Model Updates: 303,652
Cumulative Timesteps: 2,532,448,494

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.37682
Policy Entropy: 2.43651
Value Function Loss: 0.02092

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.53021
Value Function Update Magnitude: 0.67485

Collected Steps per Second: 21,913.51698
Overall Steps per Second: 10,565.05130

Timestep Collection Time: 2.28206
Timestep Consumption Time: 2.45128
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.73334

Cumulative Model Updates: 303,658
Cumulative Timesteps: 2,532,498,502

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2532498502...
Checkpoint 2532498502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.93441
Policy Entropy: 2.44637
Value Function Loss: 0.02125

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.09156
Policy Update Magnitude: 0.52265
Value Function Update Magnitude: 0.66532

Collected Steps per Second: 21,604.14070
Overall Steps per Second: 10,276.99058

Timestep Collection Time: 2.31530
Timestep Consumption Time: 2.55189
PPO Batch Consumption Time: 0.29907
Total Iteration Time: 4.86718

Cumulative Model Updates: 303,664
Cumulative Timesteps: 2,532,548,522

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.66377
Policy Entropy: 2.44642
Value Function Loss: 0.02126

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.09659
Policy Update Magnitude: 0.52454
Value Function Update Magnitude: 0.67386

Collected Steps per Second: 21,968.38755
Overall Steps per Second: 10,399.49148

Timestep Collection Time: 2.27709
Timestep Consumption Time: 2.53315
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.81024

Cumulative Model Updates: 303,670
Cumulative Timesteps: 2,532,598,546

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2532598546...
Checkpoint 2532598546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.56862
Policy Entropy: 2.48525
Value Function Loss: 0.01933

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.09259
Policy Update Magnitude: 0.51041
Value Function Update Magnitude: 0.69254

Collected Steps per Second: 21,695.54286
Overall Steps per Second: 10,376.43310

Timestep Collection Time: 2.30481
Timestep Consumption Time: 2.51419
PPO Batch Consumption Time: 0.29593
Total Iteration Time: 4.81900

Cumulative Model Updates: 303,676
Cumulative Timesteps: 2,532,648,550

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.00223
Policy Entropy: 2.49417
Value Function Loss: 0.01933

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.09153
Policy Update Magnitude: 0.51046
Value Function Update Magnitude: 0.68278

Collected Steps per Second: 21,881.32971
Overall Steps per Second: 10,613.31043

Timestep Collection Time: 2.28560
Timestep Consumption Time: 2.42659
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.71220

Cumulative Model Updates: 303,682
Cumulative Timesteps: 2,532,698,562

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2532698562...
Checkpoint 2532698562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.28864
Policy Entropy: 2.50110
Value Function Loss: 0.02026

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.09126
Policy Update Magnitude: 0.52145
Value Function Update Magnitude: 0.69105

Collected Steps per Second: 21,720.36760
Overall Steps per Second: 10,308.74285

Timestep Collection Time: 2.30254
Timestep Consumption Time: 2.54888
PPO Batch Consumption Time: 0.29646
Total Iteration Time: 4.85142

Cumulative Model Updates: 303,688
Cumulative Timesteps: 2,532,748,574

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.76363
Policy Entropy: 2.48398
Value Function Loss: 0.01997

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.09107
Policy Update Magnitude: 0.51632
Value Function Update Magnitude: 0.69016

Collected Steps per Second: 21,845.55893
Overall Steps per Second: 10,417.19741

Timestep Collection Time: 2.29017
Timestep Consumption Time: 2.51247
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.80264

Cumulative Model Updates: 303,694
Cumulative Timesteps: 2,532,798,604

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2532798604...
Checkpoint 2532798604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.03093
Policy Entropy: 2.47816
Value Function Loss: 0.02025

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.51527
Value Function Update Magnitude: 0.68188

Collected Steps per Second: 21,860.11449
Overall Steps per Second: 10,616.12733

Timestep Collection Time: 2.28855
Timestep Consumption Time: 2.42390
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.71245

Cumulative Model Updates: 303,700
Cumulative Timesteps: 2,532,848,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.89780
Policy Entropy: 2.47586
Value Function Loss: 0.02023

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.09520
Policy Update Magnitude: 0.50257
Value Function Update Magnitude: 0.67284

Collected Steps per Second: 21,530.69920
Overall Steps per Second: 10,262.12022

Timestep Collection Time: 2.32329
Timestep Consumption Time: 2.55114
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.87443

Cumulative Model Updates: 303,706
Cumulative Timesteps: 2,532,898,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2532898654...
Checkpoint 2532898654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.78217
Policy Entropy: 2.48251
Value Function Loss: 0.02070

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.09778
Policy Update Magnitude: 0.50853
Value Function Update Magnitude: 0.68930

Collected Steps per Second: 21,489.99505
Overall Steps per Second: 10,351.31244

Timestep Collection Time: 2.32694
Timestep Consumption Time: 2.50394
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.83089

Cumulative Model Updates: 303,712
Cumulative Timesteps: 2,532,948,660

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.77435
Policy Entropy: 2.47213
Value Function Loss: 0.02049

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.09413
Policy Update Magnitude: 0.51124
Value Function Update Magnitude: 0.69517

Collected Steps per Second: 22,009.81440
Overall Steps per Second: 10,510.75023

Timestep Collection Time: 2.27299
Timestep Consumption Time: 2.48671
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.75970

Cumulative Model Updates: 303,718
Cumulative Timesteps: 2,532,998,688

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2532998688...
Checkpoint 2532998688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.24163
Policy Entropy: 2.46004
Value Function Loss: 0.01974

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.09579
Policy Update Magnitude: 0.51451
Value Function Update Magnitude: 0.68643

Collected Steps per Second: 21,509.28376
Overall Steps per Second: 10,462.91825

Timestep Collection Time: 2.32588
Timestep Consumption Time: 2.45558
PPO Batch Consumption Time: 0.29674
Total Iteration Time: 4.78146

Cumulative Model Updates: 303,724
Cumulative Timesteps: 2,533,048,716

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.80924
Policy Entropy: 2.45035
Value Function Loss: 0.02042

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.09952
Policy Update Magnitude: 0.51472
Value Function Update Magnitude: 0.67657

Collected Steps per Second: 21,899.20889
Overall Steps per Second: 10,285.32796

Timestep Collection Time: 2.28319
Timestep Consumption Time: 2.57811
PPO Batch Consumption Time: 0.29983
Total Iteration Time: 4.86129

Cumulative Model Updates: 303,730
Cumulative Timesteps: 2,533,098,716

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2533098716...
Checkpoint 2533098716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.65883
Policy Entropy: 2.44020
Value Function Loss: 0.01955

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.10138
Policy Update Magnitude: 0.50924
Value Function Update Magnitude: 0.66506

Collected Steps per Second: 21,435.88454
Overall Steps per Second: 10,164.22015

Timestep Collection Time: 2.33328
Timestep Consumption Time: 2.58751
PPO Batch Consumption Time: 0.30161
Total Iteration Time: 4.92079

Cumulative Model Updates: 303,736
Cumulative Timesteps: 2,533,148,732

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.68174
Policy Entropy: 2.44630
Value Function Loss: 0.01924

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.09684
Policy Update Magnitude: 0.50251
Value Function Update Magnitude: 0.64574

Collected Steps per Second: 21,726.53754
Overall Steps per Second: 10,467.54833

Timestep Collection Time: 2.30133
Timestep Consumption Time: 2.47533
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.77667

Cumulative Model Updates: 303,742
Cumulative Timesteps: 2,533,198,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2533198732...
Checkpoint 2533198732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.83208
Policy Entropy: 2.42803
Value Function Loss: 0.01863

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.09783
Policy Update Magnitude: 0.49551
Value Function Update Magnitude: 0.62359

Collected Steps per Second: 22,626.77357
Overall Steps per Second: 10,656.68827

Timestep Collection Time: 2.21101
Timestep Consumption Time: 2.48351
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.69452

Cumulative Model Updates: 303,748
Cumulative Timesteps: 2,533,248,760

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.47798
Policy Entropy: 2.44056
Value Function Loss: 0.02077

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.09876
Policy Update Magnitude: 0.50374
Value Function Update Magnitude: 0.63603

Collected Steps per Second: 21,972.97283
Overall Steps per Second: 10,443.95538

Timestep Collection Time: 2.27652
Timestep Consumption Time: 2.51304
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.78956

Cumulative Model Updates: 303,754
Cumulative Timesteps: 2,533,298,782

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2533298782...
Checkpoint 2533298782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.68526
Policy Entropy: 2.43260
Value Function Loss: 0.02121

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.10164
Policy Update Magnitude: 0.50655
Value Function Update Magnitude: 0.66573

Collected Steps per Second: 21,445.99814
Overall Steps per Second: 10,276.19451

Timestep Collection Time: 2.33144
Timestep Consumption Time: 2.53418
PPO Batch Consumption Time: 0.29964
Total Iteration Time: 4.86561

Cumulative Model Updates: 303,760
Cumulative Timesteps: 2,533,348,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.78573
Policy Entropy: 2.43779
Value Function Loss: 0.02167

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.51384
Value Function Update Magnitude: 0.67564

Collected Steps per Second: 21,817.09620
Overall Steps per Second: 10,460.55064

Timestep Collection Time: 2.29178
Timestep Consumption Time: 2.48808
PPO Batch Consumption Time: 0.30001
Total Iteration Time: 4.77986

Cumulative Model Updates: 303,766
Cumulative Timesteps: 2,533,398,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2533398782...
Checkpoint 2533398782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.60968
Policy Entropy: 2.44281
Value Function Loss: 0.02033

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.09665
Policy Update Magnitude: 0.51709
Value Function Update Magnitude: 0.66438

Collected Steps per Second: 21,900.12108
Overall Steps per Second: 10,291.60268

Timestep Collection Time: 2.28309
Timestep Consumption Time: 2.57524
PPO Batch Consumption Time: 0.29710
Total Iteration Time: 4.85833

Cumulative Model Updates: 303,772
Cumulative Timesteps: 2,533,448,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.53504
Policy Entropy: 2.44422
Value Function Loss: 0.02164

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.52092
Value Function Update Magnitude: 0.67568

Collected Steps per Second: 21,636.12403
Overall Steps per Second: 10,304.48749

Timestep Collection Time: 2.31104
Timestep Consumption Time: 2.54141
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.85245

Cumulative Model Updates: 303,778
Cumulative Timesteps: 2,533,498,784

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2533498784...
Checkpoint 2533498784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.66973
Policy Entropy: 2.43617
Value Function Loss: 0.02198

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.10643
Policy Update Magnitude: 0.50867
Value Function Update Magnitude: 0.67717

Collected Steps per Second: 21,385.00584
Overall Steps per Second: 10,240.06070

Timestep Collection Time: 2.33846
Timestep Consumption Time: 2.54510
PPO Batch Consumption Time: 0.30088
Total Iteration Time: 4.88356

Cumulative Model Updates: 303,784
Cumulative Timesteps: 2,533,548,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.18343
Policy Entropy: 2.43406
Value Function Loss: 0.02192

Mean KL Divergence: 0.02649
SB3 Clip Fraction: 0.14601
Policy Update Magnitude: 0.47118
Value Function Update Magnitude: 0.66381

Collected Steps per Second: 22,024.39350
Overall Steps per Second: 10,516.72188

Timestep Collection Time: 2.27157
Timestep Consumption Time: 2.48561
PPO Batch Consumption Time: 0.29938
Total Iteration Time: 4.75719

Cumulative Model Updates: 303,790
Cumulative Timesteps: 2,533,598,822

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2533598822...
Checkpoint 2533598822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.18166
Policy Entropy: 2.45999
Value Function Loss: 0.02064

Mean KL Divergence: 0.02154
SB3 Clip Fraction: 0.12923
Policy Update Magnitude: 0.47444
Value Function Update Magnitude: 0.66727

Collected Steps per Second: 21,974.31862
Overall Steps per Second: 10,487.88856

Timestep Collection Time: 2.27593
Timestep Consumption Time: 2.49262
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.76855

Cumulative Model Updates: 303,796
Cumulative Timesteps: 2,533,648,834

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.07360
Policy Entropy: 2.48500
Value Function Loss: 0.01982

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.47905
Value Function Update Magnitude: 0.65851

Collected Steps per Second: 21,681.72968
Overall Steps per Second: 10,309.14981

Timestep Collection Time: 2.30720
Timestep Consumption Time: 2.54519
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.85239

Cumulative Model Updates: 303,802
Cumulative Timesteps: 2,533,698,858

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2533698858...
Checkpoint 2533698858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.21350
Policy Entropy: 2.49781
Value Function Loss: 0.01938

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.12520
Policy Update Magnitude: 0.49838
Value Function Update Magnitude: 0.65887

Collected Steps per Second: 21,836.24796
Overall Steps per Second: 10,508.32637

Timestep Collection Time: 2.29041
Timestep Consumption Time: 2.46905
PPO Batch Consumption Time: 0.29897
Total Iteration Time: 4.75946

Cumulative Model Updates: 303,808
Cumulative Timesteps: 2,533,748,872

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.25101
Policy Entropy: 2.49850
Value Function Loss: 0.01926

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.10882
Policy Update Magnitude: 0.49718
Value Function Update Magnitude: 0.63636

Collected Steps per Second: 21,861.58669
Overall Steps per Second: 10,319.80227

Timestep Collection Time: 2.28831
Timestep Consumption Time: 2.55927
PPO Batch Consumption Time: 0.29957
Total Iteration Time: 4.84757

Cumulative Model Updates: 303,814
Cumulative Timesteps: 2,533,798,898

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2533798898...
Checkpoint 2533798898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.89892
Policy Entropy: 2.49030
Value Function Loss: 0.01982

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.49528
Value Function Update Magnitude: 0.60858

Collected Steps per Second: 21,685.43202
Overall Steps per Second: 10,286.74132

Timestep Collection Time: 2.30616
Timestep Consumption Time: 2.55544
PPO Batch Consumption Time: 0.29906
Total Iteration Time: 4.86160

Cumulative Model Updates: 303,820
Cumulative Timesteps: 2,533,848,908

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.57184
Policy Entropy: 2.48958
Value Function Loss: 0.02062

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.10210
Policy Update Magnitude: 0.51028
Value Function Update Magnitude: 0.60734

Collected Steps per Second: 21,806.83321
Overall Steps per Second: 10,445.23923

Timestep Collection Time: 2.29423
Timestep Consumption Time: 2.49551
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.78974

Cumulative Model Updates: 303,826
Cumulative Timesteps: 2,533,898,938

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2533898938...
Checkpoint 2533898938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.06743
Policy Entropy: 2.47422
Value Function Loss: 0.02132

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.09220
Policy Update Magnitude: 0.51146
Value Function Update Magnitude: 0.63189

Collected Steps per Second: 21,762.14084
Overall Steps per Second: 10,610.20899

Timestep Collection Time: 2.29849
Timestep Consumption Time: 2.41584
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.71433

Cumulative Model Updates: 303,832
Cumulative Timesteps: 2,533,948,958

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.88914
Policy Entropy: 2.47764
Value Function Loss: 0.02116

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.08997
Policy Update Magnitude: 0.49911
Value Function Update Magnitude: 0.65192

Collected Steps per Second: 21,723.12963
Overall Steps per Second: 10,409.70307

Timestep Collection Time: 2.30179
Timestep Consumption Time: 2.50162
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.80340

Cumulative Model Updates: 303,838
Cumulative Timesteps: 2,533,998,960

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2533998960...
Checkpoint 2533998960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.31633
Policy Entropy: 2.47837
Value Function Loss: 0.02089

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.08808
Policy Update Magnitude: 0.49550
Value Function Update Magnitude: 0.65544

Collected Steps per Second: 21,775.10712
Overall Steps per Second: 10,282.41500

Timestep Collection Time: 2.29648
Timestep Consumption Time: 2.56678
PPO Batch Consumption Time: 0.29981
Total Iteration Time: 4.86325

Cumulative Model Updates: 303,844
Cumulative Timesteps: 2,534,048,966

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.64995
Policy Entropy: 2.45200
Value Function Loss: 0.02190

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.09478
Policy Update Magnitude: 0.50838
Value Function Update Magnitude: 0.66723

Collected Steps per Second: 21,669.78419
Overall Steps per Second: 10,457.07895

Timestep Collection Time: 2.30754
Timestep Consumption Time: 2.47429
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.78183

Cumulative Model Updates: 303,850
Cumulative Timesteps: 2,534,098,970

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2534098970...
Checkpoint 2534098970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.41270
Policy Entropy: 2.44919
Value Function Loss: 0.02128

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.51317
Value Function Update Magnitude: 0.68632

Collected Steps per Second: 21,645.16966
Overall Steps per Second: 10,582.86149

Timestep Collection Time: 2.31054
Timestep Consumption Time: 2.41522
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.72575

Cumulative Model Updates: 303,856
Cumulative Timesteps: 2,534,148,982

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.94212
Policy Entropy: 2.45566
Value Function Loss: 0.01952

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.10109
Policy Update Magnitude: 0.49869
Value Function Update Magnitude: 0.68093

Collected Steps per Second: 21,964.72049
Overall Steps per Second: 10,474.09027

Timestep Collection Time: 2.27720
Timestep Consumption Time: 2.49821
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.77540

Cumulative Model Updates: 303,862
Cumulative Timesteps: 2,534,199,000

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2534199000...
Checkpoint 2534199000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.47145
Policy Entropy: 2.46561
Value Function Loss: 0.01934

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.09830
Policy Update Magnitude: 0.51123
Value Function Update Magnitude: 0.66421

Collected Steps per Second: 21,537.06467
Overall Steps per Second: 10,236.31052

Timestep Collection Time: 2.32167
Timestep Consumption Time: 2.56310
PPO Batch Consumption Time: 0.29886
Total Iteration Time: 4.88477

Cumulative Model Updates: 303,868
Cumulative Timesteps: 2,534,249,002

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.55282
Policy Entropy: 2.47436
Value Function Loss: 0.01933

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.09698
Policy Update Magnitude: 0.51003
Value Function Update Magnitude: 0.65675

Collected Steps per Second: 21,583.49085
Overall Steps per Second: 10,376.04005

Timestep Collection Time: 2.31686
Timestep Consumption Time: 2.50251
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.81937

Cumulative Model Updates: 303,874
Cumulative Timesteps: 2,534,299,008

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2534299008...
Checkpoint 2534299008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.88677
Policy Entropy: 2.47912
Value Function Loss: 0.01920

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.09843
Policy Update Magnitude: 0.50133
Value Function Update Magnitude: 0.65659

Collected Steps per Second: 21,300.81745
Overall Steps per Second: 10,365.52485

Timestep Collection Time: 2.34808
Timestep Consumption Time: 2.47715
PPO Batch Consumption Time: 0.29788
Total Iteration Time: 4.82523

Cumulative Model Updates: 303,880
Cumulative Timesteps: 2,534,349,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.38053
Policy Entropy: 2.49032
Value Function Loss: 0.01816

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.09804
Policy Update Magnitude: 0.49488
Value Function Update Magnitude: 0.64250

Collected Steps per Second: 22,083.10133
Overall Steps per Second: 10,395.01666

Timestep Collection Time: 2.26508
Timestep Consumption Time: 2.54684
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.81192

Cumulative Model Updates: 303,886
Cumulative Timesteps: 2,534,399,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2534399044...
Checkpoint 2534399044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.92668
Policy Entropy: 2.47791
Value Function Loss: 0.01809

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.10579
Policy Update Magnitude: 0.49204
Value Function Update Magnitude: 0.62966

Collected Steps per Second: 21,212.58669
Overall Steps per Second: 10,102.17206

Timestep Collection Time: 2.35728
Timestep Consumption Time: 2.59255
PPO Batch Consumption Time: 0.30477
Total Iteration Time: 4.94983

Cumulative Model Updates: 303,892
Cumulative Timesteps: 2,534,449,048

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.02918
Policy Entropy: 2.45478
Value Function Loss: 0.01930

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.11623
Policy Update Magnitude: 0.48918
Value Function Update Magnitude: 0.62213

Collected Steps per Second: 21,697.73735
Overall Steps per Second: 10,460.21387

Timestep Collection Time: 2.30568
Timestep Consumption Time: 2.47702
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.78269

Cumulative Model Updates: 303,898
Cumulative Timesteps: 2,534,499,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2534499076...
Checkpoint 2534499076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.33391
Policy Entropy: 2.46724
Value Function Loss: 0.01968

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.11599
Policy Update Magnitude: 0.49682
Value Function Update Magnitude: 0.62803

Collected Steps per Second: 22,142.59445
Overall Steps per Second: 10,407.13850

Timestep Collection Time: 2.25845
Timestep Consumption Time: 2.54671
PPO Batch Consumption Time: 0.29756
Total Iteration Time: 4.80516

Cumulative Model Updates: 303,904
Cumulative Timesteps: 2,534,549,084

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.10009
Policy Entropy: 2.47963
Value Function Loss: 0.02039

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.11140
Policy Update Magnitude: 0.51285
Value Function Update Magnitude: 0.64293

Collected Steps per Second: 21,953.32445
Overall Steps per Second: 10,359.23052

Timestep Collection Time: 2.27838
Timestep Consumption Time: 2.54997
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.82835

Cumulative Model Updates: 303,910
Cumulative Timesteps: 2,534,599,102

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2534599102...
Checkpoint 2534599102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.63960
Policy Entropy: 2.47860
Value Function Loss: 0.01972

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.09870
Policy Update Magnitude: 0.51447
Value Function Update Magnitude: 0.65178

Collected Steps per Second: 21,363.32517
Overall Steps per Second: 10,203.77404

Timestep Collection Time: 2.34186
Timestep Consumption Time: 2.56122
PPO Batch Consumption Time: 0.29780
Total Iteration Time: 4.90309

Cumulative Model Updates: 303,916
Cumulative Timesteps: 2,534,649,132

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.44354
Policy Entropy: 2.46073
Value Function Loss: 0.02096

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.50716
Value Function Update Magnitude: 0.65678

Collected Steps per Second: 21,750.30607
Overall Steps per Second: 10,480.47415

Timestep Collection Time: 2.29965
Timestep Consumption Time: 2.47285
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.77249

Cumulative Model Updates: 303,922
Cumulative Timesteps: 2,534,699,150

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2534699150...
Checkpoint 2534699150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.57181
Policy Entropy: 2.43756
Value Function Loss: 0.02094

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.09515
Policy Update Magnitude: 0.51259
Value Function Update Magnitude: 0.67119

Collected Steps per Second: 22,490.78875
Overall Steps per Second: 10,629.88103

Timestep Collection Time: 2.22367
Timestep Consumption Time: 2.48118
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.70485

Cumulative Model Updates: 303,928
Cumulative Timesteps: 2,534,749,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.84058
Policy Entropy: 2.44047
Value Function Loss: 0.02159

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.52147
Value Function Update Magnitude: 0.68592

Collected Steps per Second: 22,101.09863
Overall Steps per Second: 10,446.91786

Timestep Collection Time: 2.26333
Timestep Consumption Time: 2.52488
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.78821

Cumulative Model Updates: 303,934
Cumulative Timesteps: 2,534,799,184

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2534799184...
Checkpoint 2534799184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.04018
Policy Entropy: 2.44975
Value Function Loss: 0.02186

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.10200
Policy Update Magnitude: 0.51108
Value Function Update Magnitude: 0.67211

Collected Steps per Second: 21,606.17132
Overall Steps per Second: 10,219.85664

Timestep Collection Time: 2.31536
Timestep Consumption Time: 2.57962
PPO Batch Consumption Time: 0.29974
Total Iteration Time: 4.89498

Cumulative Model Updates: 303,940
Cumulative Timesteps: 2,534,849,210

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.90310
Policy Entropy: 2.47988
Value Function Loss: 0.02184

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.50883
Value Function Update Magnitude: 0.65970

Collected Steps per Second: 21,841.91152
Overall Steps per Second: 10,378.18425

Timestep Collection Time: 2.28954
Timestep Consumption Time: 2.52903
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.81857

Cumulative Model Updates: 303,946
Cumulative Timesteps: 2,534,899,218

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2534899218...
Checkpoint 2534899218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.47423
Policy Entropy: 2.46757
Value Function Loss: 0.02068

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.09916
Policy Update Magnitude: 0.49822
Value Function Update Magnitude: 0.64157

Collected Steps per Second: 22,283.30594
Overall Steps per Second: 10,578.85706

Timestep Collection Time: 2.24446
Timestep Consumption Time: 2.48327
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.72773

Cumulative Model Updates: 303,952
Cumulative Timesteps: 2,534,949,232

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.65213
Policy Entropy: 2.45940
Value Function Loss: 0.01971

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.09227
Policy Update Magnitude: 0.48792
Value Function Update Magnitude: 0.61476

Collected Steps per Second: 22,076.67187
Overall Steps per Second: 10,511.80620

Timestep Collection Time: 2.26529
Timestep Consumption Time: 2.49222
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.75751

Cumulative Model Updates: 303,958
Cumulative Timesteps: 2,534,999,242

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2534999242...
Checkpoint 2534999242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.14441
Policy Entropy: 2.42468
Value Function Loss: 0.02031

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.09960
Policy Update Magnitude: 0.47937
Value Function Update Magnitude: 0.59496

Collected Steps per Second: 21,404.76519
Overall Steps per Second: 10,255.57290

Timestep Collection Time: 2.33630
Timestep Consumption Time: 2.53988
PPO Batch Consumption Time: 0.29939
Total Iteration Time: 4.87618

Cumulative Model Updates: 303,964
Cumulative Timesteps: 2,535,049,250

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.69124
Policy Entropy: 2.41603
Value Function Loss: 0.01940

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.48800
Value Function Update Magnitude: 0.60369

Collected Steps per Second: 21,612.32358
Overall Steps per Second: 10,330.55889

Timestep Collection Time: 2.31470
Timestep Consumption Time: 2.52783
PPO Batch Consumption Time: 0.30619
Total Iteration Time: 4.84253

Cumulative Model Updates: 303,970
Cumulative Timesteps: 2,535,099,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2535099276...
Checkpoint 2535099276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.05429
Policy Entropy: 2.41163
Value Function Loss: 0.02098

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.10217
Policy Update Magnitude: 0.48825
Value Function Update Magnitude: 0.62735

Collected Steps per Second: 22,139.99661
Overall Steps per Second: 10,382.90405

Timestep Collection Time: 2.25872
Timestep Consumption Time: 2.55766
PPO Batch Consumption Time: 0.29985
Total Iteration Time: 4.81638

Cumulative Model Updates: 303,976
Cumulative Timesteps: 2,535,149,284

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.06476
Policy Entropy: 2.43391
Value Function Loss: 0.02127

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.12590
Policy Update Magnitude: 0.47240
Value Function Update Magnitude: 0.62788

Collected Steps per Second: 22,143.33828
Overall Steps per Second: 10,421.94437

Timestep Collection Time: 2.25910
Timestep Consumption Time: 2.54077
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.79987

Cumulative Model Updates: 303,982
Cumulative Timesteps: 2,535,199,308

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2535199308...
Checkpoint 2535199308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.44150
Policy Entropy: 2.43911
Value Function Loss: 0.02160

Mean KL Divergence: 0.02438
SB3 Clip Fraction: 0.13940
Policy Update Magnitude: 0.46315
Value Function Update Magnitude: 0.61923

Collected Steps per Second: 21,632.62060
Overall Steps per Second: 10,365.15334

Timestep Collection Time: 2.31216
Timestep Consumption Time: 2.51344
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.82559

Cumulative Model Updates: 303,988
Cumulative Timesteps: 2,535,249,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.70172
Policy Entropy: 2.43792
Value Function Loss: 0.01995

Mean KL Divergence: 0.02268
SB3 Clip Fraction: 0.12954
Policy Update Magnitude: 0.49505
Value Function Update Magnitude: 0.61971

Collected Steps per Second: 22,128.51862
Overall Steps per Second: 10,698.12127

Timestep Collection Time: 2.26079
Timestep Consumption Time: 2.41554
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.67634

Cumulative Model Updates: 303,994
Cumulative Timesteps: 2,535,299,354

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2535299354...
Checkpoint 2535299354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.96240
Policy Entropy: 2.42979
Value Function Loss: 0.02010

Mean KL Divergence: 0.02471
SB3 Clip Fraction: 0.14130
Policy Update Magnitude: 0.48056
Value Function Update Magnitude: 0.62663

Collected Steps per Second: 21,635.72706
Overall Steps per Second: 10,266.17283

Timestep Collection Time: 2.31201
Timestep Consumption Time: 2.56050
PPO Batch Consumption Time: 0.30089
Total Iteration Time: 4.87251

Cumulative Model Updates: 304,000
Cumulative Timesteps: 2,535,349,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.08347
Policy Entropy: 2.44036
Value Function Loss: 0.02062

Mean KL Divergence: 0.02389
SB3 Clip Fraction: 0.14783
Policy Update Magnitude: 0.47301
Value Function Update Magnitude: 0.62874

Collected Steps per Second: 21,990.22725
Overall Steps per Second: 10,436.99283

Timestep Collection Time: 2.27428
Timestep Consumption Time: 2.51752
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.79180

Cumulative Model Updates: 304,006
Cumulative Timesteps: 2,535,399,388

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2535399388...
Checkpoint 2535399388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.55285
Policy Entropy: 2.44794
Value Function Loss: 0.02124

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.13981
Policy Update Magnitude: 0.49216
Value Function Update Magnitude: 0.63542

Collected Steps per Second: 21,471.34930
Overall Steps per Second: 10,302.42569

Timestep Collection Time: 2.32971
Timestep Consumption Time: 2.52565
PPO Batch Consumption Time: 0.29945
Total Iteration Time: 4.85536

Cumulative Model Updates: 304,012
Cumulative Timesteps: 2,535,449,410

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.43738
Policy Entropy: 2.45608
Value Function Loss: 0.02073

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.50943
Value Function Update Magnitude: 0.66071

Collected Steps per Second: 21,929.80629
Overall Steps per Second: 10,502.67835

Timestep Collection Time: 2.28000
Timestep Consumption Time: 2.48069
PPO Batch Consumption Time: 0.29832
Total Iteration Time: 4.76069

Cumulative Model Updates: 304,018
Cumulative Timesteps: 2,535,499,410

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2535499410...
Checkpoint 2535499410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.25811
Policy Entropy: 2.45928
Value Function Loss: 0.02052

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.11347
Policy Update Magnitude: 0.50234
Value Function Update Magnitude: 0.66677

Collected Steps per Second: 21,593.07208
Overall Steps per Second: 10,392.45722

Timestep Collection Time: 2.31556
Timestep Consumption Time: 2.49562
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.81118

Cumulative Model Updates: 304,024
Cumulative Timesteps: 2,535,549,410

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.91644
Policy Entropy: 2.47954
Value Function Loss: 0.02094

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.09992
Policy Update Magnitude: 0.50242
Value Function Update Magnitude: 0.65466

Collected Steps per Second: 21,925.72585
Overall Steps per Second: 10,469.94783

Timestep Collection Time: 2.28088
Timestep Consumption Time: 2.49565
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.77653

Cumulative Model Updates: 304,030
Cumulative Timesteps: 2,535,599,420

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2535599420...
Checkpoint 2535599420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.63655
Policy Entropy: 2.46733
Value Function Loss: 0.02166

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.09220
Policy Update Magnitude: 0.50399
Value Function Update Magnitude: 0.66932

Collected Steps per Second: 21,433.49472
Overall Steps per Second: 10,296.01655

Timestep Collection Time: 2.33308
Timestep Consumption Time: 2.52375
PPO Batch Consumption Time: 0.29620
Total Iteration Time: 4.85683

Cumulative Model Updates: 304,036
Cumulative Timesteps: 2,535,649,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.30046
Policy Entropy: 2.45167
Value Function Loss: 0.02105

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.08826
Policy Update Magnitude: 0.50350
Value Function Update Magnitude: 0.66820

Collected Steps per Second: 21,651.63473
Overall Steps per Second: 10,418.77745

Timestep Collection Time: 2.31013
Timestep Consumption Time: 2.49063
PPO Batch Consumption Time: 0.29869
Total Iteration Time: 4.80076

Cumulative Model Updates: 304,042
Cumulative Timesteps: 2,535,699,444

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2535699444...
Checkpoint 2535699444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.64137
Policy Entropy: 2.44396
Value Function Loss: 0.02092

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.09220
Policy Update Magnitude: 0.49928
Value Function Update Magnitude: 0.64624

Collected Steps per Second: 21,424.53225
Overall Steps per Second: 10,079.97954

Timestep Collection Time: 2.33499
Timestep Consumption Time: 2.62792
PPO Batch Consumption Time: 0.30955
Total Iteration Time: 4.96291

Cumulative Model Updates: 304,048
Cumulative Timesteps: 2,535,749,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.58889
Policy Entropy: 2.45394
Value Function Loss: 0.02041

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.09836
Policy Update Magnitude: 0.50677
Value Function Update Magnitude: 0.63826

Collected Steps per Second: 22,117.41352
Overall Steps per Second: 10,411.18497

Timestep Collection Time: 2.26111
Timestep Consumption Time: 2.54237
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.80349

Cumulative Model Updates: 304,054
Cumulative Timesteps: 2,535,799,480

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2535799480...
Checkpoint 2535799480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.61601
Policy Entropy: 2.43099
Value Function Loss: 0.02177

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.12295
Policy Update Magnitude: 0.50536
Value Function Update Magnitude: 0.66126

Collected Steps per Second: 21,246.80915
Overall Steps per Second: 10,369.33214

Timestep Collection Time: 2.35377
Timestep Consumption Time: 2.46911
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.82288

Cumulative Model Updates: 304,060
Cumulative Timesteps: 2,535,849,490

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.92222
Policy Entropy: 2.42807
Value Function Loss: 0.02074

Mean KL Divergence: 0.02230
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.47947
Value Function Update Magnitude: 0.65954

Collected Steps per Second: 21,929.50927
Overall Steps per Second: 10,474.44504

Timestep Collection Time: 2.28140
Timestep Consumption Time: 2.49499
PPO Batch Consumption Time: 0.29882
Total Iteration Time: 4.77639

Cumulative Model Updates: 304,066
Cumulative Timesteps: 2,535,899,520

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2535899520...
Checkpoint 2535899520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.96265
Policy Entropy: 2.43772
Value Function Loss: 0.02060

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.11826
Policy Update Magnitude: 0.49663
Value Function Update Magnitude: 0.63960

Collected Steps per Second: 21,747.30815
Overall Steps per Second: 10,331.50661

Timestep Collection Time: 2.30079
Timestep Consumption Time: 2.54226
PPO Batch Consumption Time: 0.29812
Total Iteration Time: 4.84305

Cumulative Model Updates: 304,072
Cumulative Timesteps: 2,535,949,556

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.08050
Policy Entropy: 2.46578
Value Function Loss: 0.02005

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.10540
Policy Update Magnitude: 0.51859
Value Function Update Magnitude: 0.63996

Collected Steps per Second: 21,832.85718
Overall Steps per Second: 10,354.33277

Timestep Collection Time: 2.29049
Timestep Consumption Time: 2.53918
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.82967

Cumulative Model Updates: 304,078
Cumulative Timesteps: 2,535,999,564

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2535999564...
Checkpoint 2535999564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.15815
Policy Entropy: 2.47814
Value Function Loss: 0.01908

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.09764
Policy Update Magnitude: 0.51048
Value Function Update Magnitude: 0.64129

Collected Steps per Second: 21,453.07458
Overall Steps per Second: 10,273.09872

Timestep Collection Time: 2.33151
Timestep Consumption Time: 2.53733
PPO Batch Consumption Time: 0.29875
Total Iteration Time: 4.86883

Cumulative Model Updates: 304,084
Cumulative Timesteps: 2,536,049,582

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.61413
Policy Entropy: 2.46074
Value Function Loss: 0.01970

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.09954
Policy Update Magnitude: 0.49928
Value Function Update Magnitude: 0.64466

Collected Steps per Second: 21,672.89095
Overall Steps per Second: 10,420.27187

Timestep Collection Time: 2.30731
Timestep Consumption Time: 2.49161
PPO Batch Consumption Time: 0.29950
Total Iteration Time: 4.79892

Cumulative Model Updates: 304,090
Cumulative Timesteps: 2,536,099,588

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2536099588...
Checkpoint 2536099588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.43739
Policy Entropy: 2.44329
Value Function Loss: 0.01965

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.09716
Policy Update Magnitude: 0.50261
Value Function Update Magnitude: 0.65165

Collected Steps per Second: 21,306.92015
Overall Steps per Second: 10,156.11076

Timestep Collection Time: 2.34731
Timestep Consumption Time: 2.57721
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.92452

Cumulative Model Updates: 304,096
Cumulative Timesteps: 2,536,149,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.04253
Policy Entropy: 2.43208
Value Function Loss: 0.02095

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.50569
Value Function Update Magnitude: 0.65330

Collected Steps per Second: 21,531.17298
Overall Steps per Second: 10,242.52115

Timestep Collection Time: 2.32305
Timestep Consumption Time: 2.56032
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.88337

Cumulative Model Updates: 304,102
Cumulative Timesteps: 2,536,199,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2536199620...
Checkpoint 2536199620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.76037
Policy Entropy: 2.46744
Value Function Loss: 0.02121

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.09172
Policy Update Magnitude: 0.50213
Value Function Update Magnitude: 0.65276

Collected Steps per Second: 21,658.93476
Overall Steps per Second: 10,470.95049

Timestep Collection Time: 2.30870
Timestep Consumption Time: 2.46680
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.77550

Cumulative Model Updates: 304,108
Cumulative Timesteps: 2,536,249,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.67693
Policy Entropy: 2.48656
Value Function Loss: 0.02073

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.49838
Value Function Update Magnitude: 0.65430

Collected Steps per Second: 21,937.93641
Overall Steps per Second: 10,496.66875

Timestep Collection Time: 2.28062
Timestep Consumption Time: 2.48585
PPO Batch Consumption Time: 0.29879
Total Iteration Time: 4.76646

Cumulative Model Updates: 304,114
Cumulative Timesteps: 2,536,299,656

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2536299656...
Checkpoint 2536299656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.12358
Policy Entropy: 2.49181
Value Function Loss: 0.02018

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.08253
Policy Update Magnitude: 0.50161
Value Function Update Magnitude: 0.64066

Collected Steps per Second: 21,926.81035
Overall Steps per Second: 10,402.50487

Timestep Collection Time: 2.28159
Timestep Consumption Time: 2.52764
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.80923

Cumulative Model Updates: 304,120
Cumulative Timesteps: 2,536,349,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.18643
Policy Entropy: 2.48862
Value Function Loss: 0.01971

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.08645
Policy Update Magnitude: 0.49746
Value Function Update Magnitude: 0.64551

Collected Steps per Second: 21,760.12233
Overall Steps per Second: 10,191.37341

Timestep Collection Time: 2.29778
Timestep Consumption Time: 2.60833
PPO Batch Consumption Time: 0.30622
Total Iteration Time: 4.90611

Cumulative Model Updates: 304,126
Cumulative Timesteps: 2,536,399,684

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2536399684...
Checkpoint 2536399684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.65178
Policy Entropy: 2.48180
Value Function Loss: 0.01934

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.08526
Policy Update Magnitude: 0.49356
Value Function Update Magnitude: 0.66966

Collected Steps per Second: 21,723.49075
Overall Steps per Second: 10,408.27248

Timestep Collection Time: 2.30239
Timestep Consumption Time: 2.50302
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.80541

Cumulative Model Updates: 304,132
Cumulative Timesteps: 2,536,449,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.24079
Policy Entropy: 2.49022
Value Function Loss: 0.01945

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.08638
Policy Update Magnitude: 0.49069
Value Function Update Magnitude: 0.66306

Collected Steps per Second: 21,928.78499
Overall Steps per Second: 10,619.68064

Timestep Collection Time: 2.28038
Timestep Consumption Time: 2.42842
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.70880

Cumulative Model Updates: 304,138
Cumulative Timesteps: 2,536,499,706

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2536499706...
Checkpoint 2536499706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.26745
Policy Entropy: 2.48739
Value Function Loss: 0.01892

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.08703
Policy Update Magnitude: 0.48705
Value Function Update Magnitude: 0.66026

Collected Steps per Second: 21,798.32616
Overall Steps per Second: 10,295.21148

Timestep Collection Time: 2.29375
Timestep Consumption Time: 2.56287
PPO Batch Consumption Time: 0.29958
Total Iteration Time: 4.85663

Cumulative Model Updates: 304,144
Cumulative Timesteps: 2,536,549,706

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.48005
Policy Entropy: 2.48606
Value Function Loss: 0.02017

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.08378
Policy Update Magnitude: 0.49020
Value Function Update Magnitude: 0.65935

Collected Steps per Second: 21,875.52176
Overall Steps per Second: 10,421.81184

Timestep Collection Time: 2.28612
Timestep Consumption Time: 2.51247
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.79859

Cumulative Model Updates: 304,150
Cumulative Timesteps: 2,536,599,716

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2536599716...
Checkpoint 2536599716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.98474
Policy Entropy: 2.48404
Value Function Loss: 0.02044

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.09201
Policy Update Magnitude: 0.50358
Value Function Update Magnitude: 0.67516

Collected Steps per Second: 21,691.98244
Overall Steps per Second: 10,354.67012

Timestep Collection Time: 2.30564
Timestep Consumption Time: 2.52445
PPO Batch Consumption Time: 0.29705
Total Iteration Time: 4.83009

Cumulative Model Updates: 304,156
Cumulative Timesteps: 2,536,649,730

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.80168
Policy Entropy: 2.46391
Value Function Loss: 0.02056

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.10363
Policy Update Magnitude: 0.49989
Value Function Update Magnitude: 0.68625

Collected Steps per Second: 21,915.13950
Overall Steps per Second: 10,661.32315

Timestep Collection Time: 2.28153
Timestep Consumption Time: 2.40832
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.68985

Cumulative Model Updates: 304,162
Cumulative Timesteps: 2,536,699,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2536699730...
Checkpoint 2536699730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.96684
Policy Entropy: 2.47983
Value Function Loss: 0.01967

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.08965
Policy Update Magnitude: 0.49768
Value Function Update Magnitude: 0.67807

Collected Steps per Second: 21,988.71048
Overall Steps per Second: 10,353.61224

Timestep Collection Time: 2.27399
Timestep Consumption Time: 2.55544
PPO Batch Consumption Time: 0.29899
Total Iteration Time: 4.82943

Cumulative Model Updates: 304,168
Cumulative Timesteps: 2,536,749,732

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.28538
Policy Entropy: 2.49015
Value Function Loss: 0.01903

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.09494
Policy Update Magnitude: 0.49400
Value Function Update Magnitude: 0.67720

Collected Steps per Second: 21,848.67651
Overall Steps per Second: 10,395.79219

Timestep Collection Time: 2.28957
Timestep Consumption Time: 2.52238
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.81195

Cumulative Model Updates: 304,174
Cumulative Timesteps: 2,536,799,756

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2536799756...
Checkpoint 2536799756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.13772
Policy Entropy: 2.51073
Value Function Loss: 0.02011

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.09486
Policy Update Magnitude: 0.49685
Value Function Update Magnitude: 0.67958

Collected Steps per Second: 21,157.79612
Overall Steps per Second: 10,226.11820

Timestep Collection Time: 2.36423
Timestep Consumption Time: 2.52736
PPO Batch Consumption Time: 0.29766
Total Iteration Time: 4.89159

Cumulative Model Updates: 304,180
Cumulative Timesteps: 2,536,849,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.99830
Policy Entropy: 2.49546
Value Function Loss: 0.01888

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.50206
Value Function Update Magnitude: 0.69158

Collected Steps per Second: 21,676.39671
Overall Steps per Second: 10,438.12409

Timestep Collection Time: 2.30758
Timestep Consumption Time: 2.48447
PPO Batch Consumption Time: 0.29734
Total Iteration Time: 4.79205

Cumulative Model Updates: 304,186
Cumulative Timesteps: 2,536,899,798

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2536899798...
Checkpoint 2536899798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.19213
Policy Entropy: 2.48389
Value Function Loss: 0.01811

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.08724
Policy Update Magnitude: 0.49917
Value Function Update Magnitude: 0.67806

Collected Steps per Second: 21,936.96562
Overall Steps per Second: 10,397.21759

Timestep Collection Time: 2.27926
Timestep Consumption Time: 2.52972
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.80898

Cumulative Model Updates: 304,192
Cumulative Timesteps: 2,536,949,798

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.78150
Policy Entropy: 2.49103
Value Function Loss: 0.01712

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.48229
Value Function Update Magnitude: 0.64240

Collected Steps per Second: 21,860.83294
Overall Steps per Second: 10,152.05578

Timestep Collection Time: 2.28838
Timestep Consumption Time: 2.63929
PPO Batch Consumption Time: 0.31046
Total Iteration Time: 4.92767

Cumulative Model Updates: 304,198
Cumulative Timesteps: 2,536,999,824

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2536999824...
Checkpoint 2536999824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.60508
Policy Entropy: 2.48584
Value Function Loss: 0.01811

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.48571
Value Function Update Magnitude: 0.61059

Collected Steps per Second: 21,945.24179
Overall Steps per Second: 10,297.10348

Timestep Collection Time: 2.27858
Timestep Consumption Time: 2.57754
PPO Batch Consumption Time: 0.30403
Total Iteration Time: 4.85612

Cumulative Model Updates: 304,204
Cumulative Timesteps: 2,537,049,828

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.94653
Policy Entropy: 2.48727
Value Function Loss: 0.01950

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.09950
Policy Update Magnitude: 0.49546
Value Function Update Magnitude: 0.59935

Collected Steps per Second: 21,104.25219
Overall Steps per Second: 10,428.61021

Timestep Collection Time: 2.36976
Timestep Consumption Time: 2.42589
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.79565

Cumulative Model Updates: 304,210
Cumulative Timesteps: 2,537,099,840

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2537099840...
Checkpoint 2537099840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.62347
Policy Entropy: 2.45578
Value Function Loss: 0.02130

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.10066
Policy Update Magnitude: 0.49441
Value Function Update Magnitude: 0.60834

Collected Steps per Second: 21,804.87372
Overall Steps per Second: 10,292.44977

Timestep Collection Time: 2.29334
Timestep Consumption Time: 2.56517
PPO Batch Consumption Time: 0.29984
Total Iteration Time: 4.85851

Cumulative Model Updates: 304,216
Cumulative Timesteps: 2,537,149,846

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.03065
Policy Entropy: 2.46661
Value Function Loss: 0.02081

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.10383
Policy Update Magnitude: 0.50554
Value Function Update Magnitude: 0.63531

Collected Steps per Second: 21,632.11748
Overall Steps per Second: 10,383.62175

Timestep Collection Time: 2.31175
Timestep Consumption Time: 2.50430
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.81605

Cumulative Model Updates: 304,222
Cumulative Timesteps: 2,537,199,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2537199854...
Checkpoint 2537199854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.29195
Policy Entropy: 2.46934
Value Function Loss: 0.01982

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.10894
Policy Update Magnitude: 0.49986
Value Function Update Magnitude: 0.64764

Collected Steps per Second: 21,537.13506
Overall Steps per Second: 10,301.11310

Timestep Collection Time: 2.32194
Timestep Consumption Time: 2.53268
PPO Batch Consumption Time: 0.29968
Total Iteration Time: 4.85462

Cumulative Model Updates: 304,228
Cumulative Timesteps: 2,537,249,862

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.66146
Policy Entropy: 2.48232
Value Function Loss: 0.01864

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.49952
Value Function Update Magnitude: 0.64955

Collected Steps per Second: 21,704.71321
Overall Steps per Second: 10,414.98166

Timestep Collection Time: 2.30402
Timestep Consumption Time: 2.49753
PPO Batch Consumption Time: 0.29937
Total Iteration Time: 4.80154

Cumulative Model Updates: 304,234
Cumulative Timesteps: 2,537,299,870

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2537299870...
Checkpoint 2537299870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.18480
Policy Entropy: 2.48347
Value Function Loss: 0.01889

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.09531
Policy Update Magnitude: 0.49799
Value Function Update Magnitude: 0.64502

Collected Steps per Second: 21,782.83058
Overall Steps per Second: 10,324.99278

Timestep Collection Time: 2.29539
Timestep Consumption Time: 2.54723
PPO Batch Consumption Time: 0.29780
Total Iteration Time: 4.84262

Cumulative Model Updates: 304,240
Cumulative Timesteps: 2,537,349,870

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.58897
Policy Entropy: 2.48149
Value Function Loss: 0.01961

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.09012
Policy Update Magnitude: 0.49503
Value Function Update Magnitude: 0.65183

Collected Steps per Second: 21,236.93695
Overall Steps per Second: 10,288.29309

Timestep Collection Time: 2.35552
Timestep Consumption Time: 2.50671
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.86223

Cumulative Model Updates: 304,246
Cumulative Timesteps: 2,537,399,894

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2537399894...
Checkpoint 2537399894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.19710
Policy Entropy: 2.48544
Value Function Loss: 0.01973

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.09802
Policy Update Magnitude: 0.49243
Value Function Update Magnitude: 0.66346

Collected Steps per Second: 21,721.25670
Overall Steps per Second: 10,601.80283

Timestep Collection Time: 2.30226
Timestep Consumption Time: 2.41467
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.71693

Cumulative Model Updates: 304,252
Cumulative Timesteps: 2,537,449,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.27483
Policy Entropy: 2.47795
Value Function Loss: 0.02111

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.10096
Policy Update Magnitude: 0.49050
Value Function Update Magnitude: 0.66758

Collected Steps per Second: 22,029.79711
Overall Steps per Second: 10,463.52789

Timestep Collection Time: 2.27111
Timestep Consumption Time: 2.51046
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.78156

Cumulative Model Updates: 304,258
Cumulative Timesteps: 2,537,499,934

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2537499934...
Checkpoint 2537499934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.81324
Policy Entropy: 2.47434
Value Function Loss: 0.02158

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.11345
Policy Update Magnitude: 0.49294
Value Function Update Magnitude: 0.67576

Collected Steps per Second: 21,640.84253
Overall Steps per Second: 10,247.55086

Timestep Collection Time: 2.31257
Timestep Consumption Time: 2.57113
PPO Batch Consumption Time: 0.29903
Total Iteration Time: 4.88370

Cumulative Model Updates: 304,264
Cumulative Timesteps: 2,537,549,980

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.20289
Policy Entropy: 2.45660
Value Function Loss: 0.02268

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.11202
Policy Update Magnitude: 0.50341
Value Function Update Magnitude: 0.69436

Collected Steps per Second: 21,600.37942
Overall Steps per Second: 10,439.77958

Timestep Collection Time: 2.31533
Timestep Consumption Time: 2.47519
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.79052

Cumulative Model Updates: 304,270
Cumulative Timesteps: 2,537,599,992

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2537599992...
Checkpoint 2537599992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.35758
Policy Entropy: 2.46246
Value Function Loss: 0.02002

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.09909
Policy Update Magnitude: 0.50512
Value Function Update Magnitude: 0.69285

Collected Steps per Second: 21,658.93968
Overall Steps per Second: 10,439.14729

Timestep Collection Time: 2.30944
Timestep Consumption Time: 2.48214
PPO Batch Consumption Time: 0.29849
Total Iteration Time: 4.79158

Cumulative Model Updates: 304,276
Cumulative Timesteps: 2,537,650,012

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.12809
Policy Entropy: 2.45473
Value Function Loss: 0.01994

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.09814
Policy Update Magnitude: 0.50591
Value Function Update Magnitude: 0.67053

Collected Steps per Second: 22,005.50138
Overall Steps per Second: 10,270.69949

Timestep Collection Time: 2.27343
Timestep Consumption Time: 2.59751
PPO Batch Consumption Time: 0.29929
Total Iteration Time: 4.87094

Cumulative Model Updates: 304,282
Cumulative Timesteps: 2,537,700,040

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2537700040...
Checkpoint 2537700040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.38634
Policy Entropy: 2.48440
Value Function Loss: 0.01844

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.09959
Policy Update Magnitude: 0.48469
Value Function Update Magnitude: 0.64299

Collected Steps per Second: 21,518.22753
Overall Steps per Second: 10,221.11947

Timestep Collection Time: 2.32454
Timestep Consumption Time: 2.56925
PPO Batch Consumption Time: 0.29948
Total Iteration Time: 4.89379

Cumulative Model Updates: 304,288
Cumulative Timesteps: 2,537,750,060

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.96285
Policy Entropy: 2.47179
Value Function Loss: 0.01897

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.08746
Policy Update Magnitude: 0.48876
Value Function Update Magnitude: 0.62086

Collected Steps per Second: 21,875.58022
Overall Steps per Second: 10,442.71553

Timestep Collection Time: 2.28684
Timestep Consumption Time: 2.50367
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.79052

Cumulative Model Updates: 304,294
Cumulative Timesteps: 2,537,800,086

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2537800086...
Checkpoint 2537800086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.95490
Policy Entropy: 2.48691
Value Function Loss: 0.01926

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.08321
Policy Update Magnitude: 0.48636
Value Function Update Magnitude: 0.59726

Collected Steps per Second: 21,860.09930
Overall Steps per Second: 10,544.90864

Timestep Collection Time: 2.28746
Timestep Consumption Time: 2.45455
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.74200

Cumulative Model Updates: 304,300
Cumulative Timesteps: 2,537,850,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.40344
Policy Entropy: 2.48113
Value Function Loss: 0.01942

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.09136
Policy Update Magnitude: 0.47920
Value Function Update Magnitude: 0.58537

Collected Steps per Second: 22,397.83167
Overall Steps per Second: 10,682.22441

Timestep Collection Time: 2.23316
Timestep Consumption Time: 2.44920
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.68236

Cumulative Model Updates: 304,306
Cumulative Timesteps: 2,537,900,108

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2537900108...
Checkpoint 2537900108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.76670
Policy Entropy: 2.48125
Value Function Loss: 0.01958

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.09865
Policy Update Magnitude: 0.48066
Value Function Update Magnitude: 0.59608

Collected Steps per Second: 22,180.60236
Overall Steps per Second: 10,647.20550

Timestep Collection Time: 2.25485
Timestep Consumption Time: 2.44253
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.69738

Cumulative Model Updates: 304,312
Cumulative Timesteps: 2,537,950,122

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.00150
Policy Entropy: 2.46894
Value Function Loss: 0.01996

Mean KL Divergence: 0.02266
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.47065
Value Function Update Magnitude: 0.62034

Collected Steps per Second: 22,608.58690
Overall Steps per Second: 10,785.48463

Timestep Collection Time: 2.21155
Timestep Consumption Time: 2.42431
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.63586

Cumulative Model Updates: 304,318
Cumulative Timesteps: 2,538,000,122

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2538000122...
Checkpoint 2538000122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.44377
Policy Entropy: 2.46713
Value Function Loss: 0.02024

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.12142
Policy Update Magnitude: 0.47274
Value Function Update Magnitude: 0.64128

Collected Steps per Second: 21,850.90643
Overall Steps per Second: 10,764.21168

Timestep Collection Time: 2.28888
Timestep Consumption Time: 2.35745
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.64632

Cumulative Model Updates: 304,324
Cumulative Timesteps: 2,538,050,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.43014
Policy Entropy: 2.46721
Value Function Loss: 0.02029

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.10926
Policy Update Magnitude: 0.49362
Value Function Update Magnitude: 0.64481

Collected Steps per Second: 22,222.11758
Overall Steps per Second: 10,494.33760

Timestep Collection Time: 2.25100
Timestep Consumption Time: 2.51557
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.76657

Cumulative Model Updates: 304,330
Cumulative Timesteps: 2,538,100,158

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2538100158...
Checkpoint 2538100158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.19536
Policy Entropy: 2.47264
Value Function Loss: 0.01993

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.09508
Policy Update Magnitude: 0.50725
Value Function Update Magnitude: 0.63711

Collected Steps per Second: 22,132.70032
Overall Steps per Second: 10,545.21181

Timestep Collection Time: 2.26100
Timestep Consumption Time: 2.48447
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.74547

Cumulative Model Updates: 304,336
Cumulative Timesteps: 2,538,150,200

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.19748
Policy Entropy: 2.46156
Value Function Loss: 0.01892

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.50544
Value Function Update Magnitude: 0.62748

Collected Steps per Second: 22,137.11503
Overall Steps per Second: 10,687.14341

Timestep Collection Time: 2.25937
Timestep Consumption Time: 2.42064
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.68002

Cumulative Model Updates: 304,342
Cumulative Timesteps: 2,538,200,216

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2538200216...
Checkpoint 2538200216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.89324
Policy Entropy: 2.46878
Value Function Loss: 0.01826

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.08884
Policy Update Magnitude: 0.49416
Value Function Update Magnitude: 0.63796

Collected Steps per Second: 21,782.61278
Overall Steps per Second: 10,414.74429

Timestep Collection Time: 2.29568
Timestep Consumption Time: 2.50578
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.80146

Cumulative Model Updates: 304,348
Cumulative Timesteps: 2,538,250,222

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.85556
Policy Entropy: 2.46910
Value Function Loss: 0.01851

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.08224
Policy Update Magnitude: 0.49594
Value Function Update Magnitude: 0.63760

Collected Steps per Second: 22,384.20175
Overall Steps per Second: 10,369.96803

Timestep Collection Time: 2.23381
Timestep Consumption Time: 2.58800
PPO Batch Consumption Time: 0.30487
Total Iteration Time: 4.82181

Cumulative Model Updates: 304,354
Cumulative Timesteps: 2,538,300,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2538300224...
Checkpoint 2538300224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.74101
Policy Entropy: 2.43060
Value Function Loss: 0.01967

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.09478
Policy Update Magnitude: 0.49549
Value Function Update Magnitude: 0.63668

Collected Steps per Second: 21,821.55833
Overall Steps per Second: 10,383.31848

Timestep Collection Time: 2.29241
Timestep Consumption Time: 2.52532
PPO Batch Consumption Time: 0.29671
Total Iteration Time: 4.81773

Cumulative Model Updates: 304,360
Cumulative Timesteps: 2,538,350,248

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.36194
Policy Entropy: 2.41359
Value Function Loss: 0.02153

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.09464
Policy Update Magnitude: 0.50657
Value Function Update Magnitude: 0.65562

Collected Steps per Second: 22,782.50809
Overall Steps per Second: 10,764.90978

Timestep Collection Time: 2.19519
Timestep Consumption Time: 2.45064
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.64584

Cumulative Model Updates: 304,366
Cumulative Timesteps: 2,538,400,260

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2538400260...
Checkpoint 2538400260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.55613
Policy Entropy: 2.42015
Value Function Loss: 0.02198

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.09716
Policy Update Magnitude: 0.51460
Value Function Update Magnitude: 0.67465

Collected Steps per Second: 22,052.74637
Overall Steps per Second: 10,631.33159

Timestep Collection Time: 2.26838
Timestep Consumption Time: 2.43696
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.70534

Cumulative Model Updates: 304,372
Cumulative Timesteps: 2,538,450,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.69942
Policy Entropy: 2.44614
Value Function Loss: 0.02117

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.10309
Policy Update Magnitude: 0.51154
Value Function Update Magnitude: 0.67801

Collected Steps per Second: 22,102.66631
Overall Steps per Second: 10,499.59947

Timestep Collection Time: 2.26226
Timestep Consumption Time: 2.50002
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.76228

Cumulative Model Updates: 304,378
Cumulative Timesteps: 2,538,500,286

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2538500286...
Checkpoint 2538500286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.57707
Policy Entropy: 2.46016
Value Function Loss: 0.02073

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.11555
Policy Update Magnitude: 0.50307
Value Function Update Magnitude: 0.67115

Collected Steps per Second: 21,610.19692
Overall Steps per Second: 10,564.62631

Timestep Collection Time: 2.31400
Timestep Consumption Time: 2.41934
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.73334

Cumulative Model Updates: 304,384
Cumulative Timesteps: 2,538,550,292

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.54744
Policy Entropy: 2.44360
Value Function Loss: 0.02135

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.11756
Policy Update Magnitude: 0.50977
Value Function Update Magnitude: 0.67873

Collected Steps per Second: 23,176.09327
Overall Steps per Second: 10,757.19846

Timestep Collection Time: 2.15800
Timestep Consumption Time: 2.49135
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.64935

Cumulative Model Updates: 304,390
Cumulative Timesteps: 2,538,600,306

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2538600306...
Checkpoint 2538600306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.04870
Policy Entropy: 2.45412
Value Function Loss: 0.02123

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.11341
Policy Update Magnitude: 0.51643
Value Function Update Magnitude: 0.68799

Collected Steps per Second: 22,100.67665
Overall Steps per Second: 10,435.50111

Timestep Collection Time: 2.26364
Timestep Consumption Time: 2.53038
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.79402

Cumulative Model Updates: 304,396
Cumulative Timesteps: 2,538,650,334

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.85479
Policy Entropy: 2.45829
Value Function Loss: 0.02124

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.11275
Policy Update Magnitude: 0.50773
Value Function Update Magnitude: 0.67733

Collected Steps per Second: 22,415.14038
Overall Steps per Second: 10,642.27346

Timestep Collection Time: 2.23081
Timestep Consumption Time: 2.46781
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.69862

Cumulative Model Updates: 304,402
Cumulative Timesteps: 2,538,700,338

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2538700338...
Checkpoint 2538700338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.10945
Policy Entropy: 2.46967
Value Function Loss: 0.02057

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.10627
Policy Update Magnitude: 0.49940
Value Function Update Magnitude: 0.66300

Collected Steps per Second: 21,977.85683
Overall Steps per Second: 10,651.64586

Timestep Collection Time: 2.27565
Timestep Consumption Time: 2.41977
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.69542

Cumulative Model Updates: 304,408
Cumulative Timesteps: 2,538,750,352

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.47978
Policy Entropy: 2.46970
Value Function Loss: 0.01962

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.09475
Policy Update Magnitude: 0.50608
Value Function Update Magnitude: 0.65095

Collected Steps per Second: 21,937.76421
Overall Steps per Second: 10,618.20422

Timestep Collection Time: 2.28036
Timestep Consumption Time: 2.43098
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.71134

Cumulative Model Updates: 304,414
Cumulative Timesteps: 2,538,800,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2538800378...
Checkpoint 2538800378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.00341
Policy Entropy: 2.47719
Value Function Loss: 0.01947

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.09211
Policy Update Magnitude: 0.51233
Value Function Update Magnitude: 0.64977

Collected Steps per Second: 21,174.51253
Overall Steps per Second: 10,242.76869

Timestep Collection Time: 2.36284
Timestep Consumption Time: 2.52178
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.88462

Cumulative Model Updates: 304,420
Cumulative Timesteps: 2,538,850,410

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.16723
Policy Entropy: 2.46972
Value Function Loss: 0.01943

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.09500
Policy Update Magnitude: 0.50336
Value Function Update Magnitude: 0.65486

Collected Steps per Second: 21,914.18178
Overall Steps per Second: 10,458.04139

Timestep Collection Time: 2.28218
Timestep Consumption Time: 2.49998
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.78216

Cumulative Model Updates: 304,426
Cumulative Timesteps: 2,538,900,422

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2538900422...
Checkpoint 2538900422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.03233
Policy Entropy: 2.45467
Value Function Loss: 0.02007

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.09490
Policy Update Magnitude: 0.49825
Value Function Update Magnitude: 0.65858

Collected Steps per Second: 21,313.38175
Overall Steps per Second: 10,337.97015

Timestep Collection Time: 2.34669
Timestep Consumption Time: 2.49139
PPO Batch Consumption Time: 0.29898
Total Iteration Time: 4.83809

Cumulative Model Updates: 304,432
Cumulative Timesteps: 2,538,950,438

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.30131
Policy Entropy: 2.45492
Value Function Loss: 0.02118

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.09588
Policy Update Magnitude: 0.48732
Value Function Update Magnitude: 0.64829

Collected Steps per Second: 21,918.24250
Overall Steps per Second: 10,188.57379

Timestep Collection Time: 2.28120
Timestep Consumption Time: 2.62625
PPO Batch Consumption Time: 0.30788
Total Iteration Time: 4.90746

Cumulative Model Updates: 304,438
Cumulative Timesteps: 2,539,000,438

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2539000438...
Checkpoint 2539000438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.85339
Policy Entropy: 2.46696
Value Function Loss: 0.02138

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.09330
Policy Update Magnitude: 0.48811
Value Function Update Magnitude: 0.65068

Collected Steps per Second: 21,649.93365
Overall Steps per Second: 10,338.85344

Timestep Collection Time: 2.30948
Timestep Consumption Time: 2.52665
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.83613

Cumulative Model Updates: 304,444
Cumulative Timesteps: 2,539,050,438

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.47763
Policy Entropy: 2.48640
Value Function Loss: 0.02072

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.11033
Policy Update Magnitude: 0.50546
Value Function Update Magnitude: 0.63907

Collected Steps per Second: 21,676.35851
Overall Steps per Second: 10,467.53431

Timestep Collection Time: 2.30721
Timestep Consumption Time: 2.47061
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.77782

Cumulative Model Updates: 304,450
Cumulative Timesteps: 2,539,100,450

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2539100450...
Checkpoint 2539100450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.57516
Policy Entropy: 2.48854
Value Function Loss: 0.02000

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.10755
Policy Update Magnitude: 0.50849
Value Function Update Magnitude: 0.63323

Collected Steps per Second: 21,683.73331
Overall Steps per Second: 10,604.27736

Timestep Collection Time: 2.30643
Timestep Consumption Time: 2.40978
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.71621

Cumulative Model Updates: 304,456
Cumulative Timesteps: 2,539,150,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.73631
Policy Entropy: 2.48247
Value Function Loss: 0.02048

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.10844
Policy Update Magnitude: 0.51008
Value Function Update Magnitude: 0.63523

Collected Steps per Second: 21,992.54458
Overall Steps per Second: 10,477.46162

Timestep Collection Time: 2.27504
Timestep Consumption Time: 2.50035
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.77539

Cumulative Model Updates: 304,462
Cumulative Timesteps: 2,539,200,496

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2539200496...
Checkpoint 2539200496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.44682
Policy Entropy: 2.47987
Value Function Loss: 0.02120

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.10521
Policy Update Magnitude: 0.50583
Value Function Update Magnitude: 0.62605

Collected Steps per Second: 21,641.21629
Overall Steps per Second: 10,261.14021

Timestep Collection Time: 2.31105
Timestep Consumption Time: 2.56306
PPO Batch Consumption Time: 0.29972
Total Iteration Time: 4.87412

Cumulative Model Updates: 304,468
Cumulative Timesteps: 2,539,250,510

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.37956
Policy Entropy: 2.48460
Value Function Loss: 0.02120

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.10400
Policy Update Magnitude: 0.49657
Value Function Update Magnitude: 0.61697

Collected Steps per Second: 21,895.60193
Overall Steps per Second: 10,508.30524

Timestep Collection Time: 2.28503
Timestep Consumption Time: 2.47616
PPO Batch Consumption Time: 0.29819
Total Iteration Time: 4.76119

Cumulative Model Updates: 304,474
Cumulative Timesteps: 2,539,300,542

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2539300542...
Checkpoint 2539300542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.65135
Policy Entropy: 2.48085
Value Function Loss: 0.02030

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.09551
Policy Update Magnitude: 0.48618
Value Function Update Magnitude: 0.60466

Collected Steps per Second: 21,705.32922
Overall Steps per Second: 10,431.53017

Timestep Collection Time: 2.30478
Timestep Consumption Time: 2.49087
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.79565

Cumulative Model Updates: 304,480
Cumulative Timesteps: 2,539,350,568

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.98705
Policy Entropy: 2.48653
Value Function Loss: 0.01978

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.10127
Policy Update Magnitude: 0.48286
Value Function Update Magnitude: 0.57994

Collected Steps per Second: 21,880.65981
Overall Steps per Second: 10,462.85423

Timestep Collection Time: 2.28613
Timestep Consumption Time: 2.49478
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.78091

Cumulative Model Updates: 304,486
Cumulative Timesteps: 2,539,400,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2539400590...
Checkpoint 2539400590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.12076
Policy Entropy: 2.46207
Value Function Loss: 0.02044

Mean KL Divergence: 0.02112
SB3 Clip Fraction: 0.12608
Policy Update Magnitude: 0.44475
Value Function Update Magnitude: 0.58431

Collected Steps per Second: 21,727.99043
Overall Steps per Second: 10,333.61040

Timestep Collection Time: 2.30173
Timestep Consumption Time: 2.53801
PPO Batch Consumption Time: 0.29985
Total Iteration Time: 4.83974

Cumulative Model Updates: 304,492
Cumulative Timesteps: 2,539,450,602

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.50896
Policy Entropy: 2.45360
Value Function Loss: 0.02060

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.11154
Policy Update Magnitude: 0.45522
Value Function Update Magnitude: 0.62333

Collected Steps per Second: 22,045.38490
Overall Steps per Second: 10,534.89343

Timestep Collection Time: 2.26886
Timestep Consumption Time: 2.47898
PPO Batch Consumption Time: 0.29782
Total Iteration Time: 4.74784

Cumulative Model Updates: 304,498
Cumulative Timesteps: 2,539,500,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2539500620...
Checkpoint 2539500620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.26450
Policy Entropy: 2.45706
Value Function Loss: 0.02016

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.10429
Policy Update Magnitude: 0.49368
Value Function Update Magnitude: 0.64872

Collected Steps per Second: 21,049.24767
Overall Steps per Second: 10,141.70401

Timestep Collection Time: 2.37595
Timestep Consumption Time: 2.55537
PPO Batch Consumption Time: 0.29996
Total Iteration Time: 4.93132

Cumulative Model Updates: 304,504
Cumulative Timesteps: 2,539,550,632

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.61680
Policy Entropy: 2.45501
Value Function Loss: 0.01984

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.10649
Policy Update Magnitude: 0.49911
Value Function Update Magnitude: 0.64692

Collected Steps per Second: 21,817.08572
Overall Steps per Second: 10,331.96760

Timestep Collection Time: 2.29242
Timestep Consumption Time: 2.54828
PPO Batch Consumption Time: 0.29818
Total Iteration Time: 4.84070

Cumulative Model Updates: 304,510
Cumulative Timesteps: 2,539,600,646

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2539600646...
Checkpoint 2539600646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.71494
Policy Entropy: 2.46166
Value Function Loss: 0.02000

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.10206
Policy Update Magnitude: 0.51200
Value Function Update Magnitude: 0.66652

Collected Steps per Second: 21,338.09486
Overall Steps per Second: 10,311.96712

Timestep Collection Time: 2.34323
Timestep Consumption Time: 2.50551
PPO Batch Consumption Time: 0.30548
Total Iteration Time: 4.84874

Cumulative Model Updates: 304,516
Cumulative Timesteps: 2,539,650,646

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.49630
Policy Entropy: 2.46173
Value Function Loss: 0.01982

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.50803
Value Function Update Magnitude: 0.67252

Collected Steps per Second: 21,862.11698
Overall Steps per Second: 10,424.76183

Timestep Collection Time: 2.28770
Timestep Consumption Time: 2.50991
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.79762

Cumulative Model Updates: 304,522
Cumulative Timesteps: 2,539,700,660

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2539700660...
Checkpoint 2539700660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.77275
Policy Entropy: 2.46637
Value Function Loss: 0.01989

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.10451
Policy Update Magnitude: 0.49890
Value Function Update Magnitude: 0.65951

Collected Steps per Second: 21,713.19316
Overall Steps per Second: 10,290.69612

Timestep Collection Time: 2.30422
Timestep Consumption Time: 2.55765
PPO Batch Consumption Time: 0.29950
Total Iteration Time: 4.86187

Cumulative Model Updates: 304,528
Cumulative Timesteps: 2,539,750,692

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.41227
Policy Entropy: 2.47130
Value Function Loss: 0.02118

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.50319
Value Function Update Magnitude: 0.65327

Collected Steps per Second: 21,711.75689
Overall Steps per Second: 10,428.04741

Timestep Collection Time: 2.30364
Timestep Consumption Time: 2.49266
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.79630

Cumulative Model Updates: 304,534
Cumulative Timesteps: 2,539,800,708

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2539800708...
Checkpoint 2539800708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.00079
Policy Entropy: 2.44739
Value Function Loss: 0.02189

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.49927
Value Function Update Magnitude: 0.63932

Collected Steps per Second: 20,939.56445
Overall Steps per Second: 10,309.11661

Timestep Collection Time: 2.38811
Timestep Consumption Time: 2.46255
PPO Batch Consumption Time: 0.29811
Total Iteration Time: 4.85066

Cumulative Model Updates: 304,540
Cumulative Timesteps: 2,539,850,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.78823
Policy Entropy: 2.43320
Value Function Loss: 0.02200

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.09173
Policy Update Magnitude: 0.49338
Value Function Update Magnitude: 0.62489

Collected Steps per Second: 21,827.43030
Overall Steps per Second: 10,330.40123

Timestep Collection Time: 2.29180
Timestep Consumption Time: 2.55061
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.84241

Cumulative Model Updates: 304,546
Cumulative Timesteps: 2,539,900,738

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2539900738...
Checkpoint 2539900738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.88397
Policy Entropy: 2.45267
Value Function Loss: 0.02012

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.08902
Policy Update Magnitude: 0.49625
Value Function Update Magnitude: 0.62507

Collected Steps per Second: 21,796.87403
Overall Steps per Second: 10,304.37621

Timestep Collection Time: 2.29519
Timestep Consumption Time: 2.55983
PPO Batch Consumption Time: 0.29766
Total Iteration Time: 4.85502

Cumulative Model Updates: 304,552
Cumulative Timesteps: 2,539,950,766

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.78853
Policy Entropy: 2.46551
Value Function Loss: 0.02026

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.49440
Value Function Update Magnitude: 0.63870

Collected Steps per Second: 21,854.39381
Overall Steps per Second: 10,379.01003

Timestep Collection Time: 2.28878
Timestep Consumption Time: 2.53056
PPO Batch Consumption Time: 0.29909
Total Iteration Time: 4.81934

Cumulative Model Updates: 304,558
Cumulative Timesteps: 2,540,000,786

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2540000786...
Checkpoint 2540000786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.36980
Policy Entropy: 2.47643
Value Function Loss: 0.02050

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.10546
Policy Update Magnitude: 0.48905
Value Function Update Magnitude: 0.63472

Collected Steps per Second: 21,734.62453
Overall Steps per Second: 10,378.59994

Timestep Collection Time: 2.30084
Timestep Consumption Time: 2.51753
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 4.81838

Cumulative Model Updates: 304,564
Cumulative Timesteps: 2,540,050,794

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.69450
Policy Entropy: 2.47654
Value Function Loss: 0.02020

Mean KL Divergence: 0.02786
SB3 Clip Fraction: 0.14305
Policy Update Magnitude: 0.45603
Value Function Update Magnitude: 0.62716

Collected Steps per Second: 22,583.72352
Overall Steps per Second: 10,626.34851

Timestep Collection Time: 2.21505
Timestep Consumption Time: 2.49250
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.70754

Cumulative Model Updates: 304,570
Cumulative Timesteps: 2,540,100,818

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2540100818...
Checkpoint 2540100818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.83605
Policy Entropy: 2.47439
Value Function Loss: 0.01991

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.11723
Policy Update Magnitude: 0.46705
Value Function Update Magnitude: 0.61408

Collected Steps per Second: 21,722.33691
Overall Steps per Second: 10,283.51631

Timestep Collection Time: 2.30187
Timestep Consumption Time: 2.56047
PPO Batch Consumption Time: 0.29927
Total Iteration Time: 4.86234

Cumulative Model Updates: 304,576
Cumulative Timesteps: 2,540,150,820

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.16999
Policy Entropy: 2.46415
Value Function Loss: 0.01989

Mean KL Divergence: 0.02365
SB3 Clip Fraction: 0.13090
Policy Update Magnitude: 0.46737
Value Function Update Magnitude: 0.61517

Collected Steps per Second: 21,296.20355
Overall Steps per Second: 10,376.95726

Timestep Collection Time: 2.34915
Timestep Consumption Time: 2.47192
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.82107

Cumulative Model Updates: 304,582
Cumulative Timesteps: 2,540,200,848

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2540200848...
Checkpoint 2540200848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.30750
Policy Entropy: 2.44941
Value Function Loss: 0.02242

Mean KL Divergence: 0.02629
SB3 Clip Fraction: 0.14240
Policy Update Magnitude: 0.47668
Value Function Update Magnitude: 0.63843

Collected Steps per Second: 21,735.71133
Overall Steps per Second: 10,181.52092

Timestep Collection Time: 2.30101
Timestep Consumption Time: 2.61123
PPO Batch Consumption Time: 0.31142
Total Iteration Time: 4.91223

Cumulative Model Updates: 304,588
Cumulative Timesteps: 2,540,250,862

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.27019
Policy Entropy: 2.42208
Value Function Loss: 0.02264

Mean KL Divergence: 0.02365
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.52432
Value Function Update Magnitude: 0.66793

Collected Steps per Second: 22,451.35678
Overall Steps per Second: 10,510.16885

Timestep Collection Time: 2.22704
Timestep Consumption Time: 2.53026
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.75730

Cumulative Model Updates: 304,594
Cumulative Timesteps: 2,540,300,862

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2540300862...
Checkpoint 2540300862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.41704
Policy Entropy: 2.42130
Value Function Loss: 0.02218

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.11862
Policy Update Magnitude: 0.52989
Value Function Update Magnitude: 0.66212

Collected Steps per Second: 21,574.27982
Overall Steps per Second: 10,253.28172

Timestep Collection Time: 2.31869
Timestep Consumption Time: 2.56014
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.87883

Cumulative Model Updates: 304,600
Cumulative Timesteps: 2,540,350,886

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.01683
Policy Entropy: 2.40294
Value Function Loss: 0.02179

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.10409
Policy Update Magnitude: 0.52009
Value Function Update Magnitude: 0.64935

Collected Steps per Second: 21,679.36034
Overall Steps per Second: 10,477.14777

Timestep Collection Time: 2.30736
Timestep Consumption Time: 2.46704
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.77439

Cumulative Model Updates: 304,606
Cumulative Timesteps: 2,540,400,908

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2540400908...
Checkpoint 2540400908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.08670
Policy Entropy: 2.41921
Value Function Loss: 0.02138

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.11262
Policy Update Magnitude: 0.50735
Value Function Update Magnitude: 0.63579

Collected Steps per Second: 21,662.61267
Overall Steps per Second: 10,590.22903

Timestep Collection Time: 2.30932
Timestep Consumption Time: 2.41446
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.72379

Cumulative Model Updates: 304,612
Cumulative Timesteps: 2,540,450,934

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.95682
Policy Entropy: 2.45276
Value Function Loss: 0.02109

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.11784
Policy Update Magnitude: 0.48560
Value Function Update Magnitude: 0.64526

Collected Steps per Second: 21,811.12584
Overall Steps per Second: 10,426.50636

Timestep Collection Time: 2.29314
Timestep Consumption Time: 2.50386
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.79700

Cumulative Model Updates: 304,618
Cumulative Timesteps: 2,540,500,950

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2540500950...
Checkpoint 2540500950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.51005
Policy Entropy: 2.49216
Value Function Loss: 0.01938

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.11377
Policy Update Magnitude: 0.49385
Value Function Update Magnitude: 0.65933

Collected Steps per Second: 21,761.13884
Overall Steps per Second: 10,283.92411

Timestep Collection Time: 2.29813
Timestep Consumption Time: 2.56480
PPO Batch Consumption Time: 0.29901
Total Iteration Time: 4.86293

Cumulative Model Updates: 304,624
Cumulative Timesteps: 2,540,550,960

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.67476
Policy Entropy: 2.50531
Value Function Loss: 0.01975

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.12350
Policy Update Magnitude: 0.47655
Value Function Update Magnitude: 0.64833

Collected Steps per Second: 21,601.50275
Overall Steps per Second: 10,403.07670

Timestep Collection Time: 2.31586
Timestep Consumption Time: 2.49291
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.80877

Cumulative Model Updates: 304,630
Cumulative Timesteps: 2,540,600,986

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2540600986...
Checkpoint 2540600986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.15424
Policy Entropy: 2.48977
Value Function Loss: 0.01945

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.11300
Policy Update Magnitude: 0.46758
Value Function Update Magnitude: 0.62980

Collected Steps per Second: 21,742.15943
Overall Steps per Second: 10,629.47775

Timestep Collection Time: 2.30023
Timestep Consumption Time: 2.40480
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.70503

Cumulative Model Updates: 304,636
Cumulative Timesteps: 2,540,650,998

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.21628
Policy Entropy: 2.46571
Value Function Loss: 0.02066

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.10351
Policy Update Magnitude: 0.47957
Value Function Update Magnitude: 0.63107

Collected Steps per Second: 21,872.75807
Overall Steps per Second: 10,441.20912

Timestep Collection Time: 2.28723
Timestep Consumption Time: 2.50417
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.79140

Cumulative Model Updates: 304,642
Cumulative Timesteps: 2,540,701,026

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2540701026...
Checkpoint 2540701026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.11843
Policy Entropy: 2.46833
Value Function Loss: 0.02027

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.10295
Policy Update Magnitude: 0.50010
Value Function Update Magnitude: 0.61864

Collected Steps per Second: 21,653.74669
Overall Steps per Second: 10,270.39144

Timestep Collection Time: 2.31036
Timestep Consumption Time: 2.56073
PPO Batch Consumption Time: 0.29771
Total Iteration Time: 4.87109

Cumulative Model Updates: 304,648
Cumulative Timesteps: 2,540,751,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.87248
Policy Entropy: 2.45336
Value Function Loss: 0.02026

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.50295
Value Function Update Magnitude: 0.61511

Collected Steps per Second: 21,787.42740
Overall Steps per Second: 10,487.49089

Timestep Collection Time: 2.29509
Timestep Consumption Time: 2.47288
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.76797

Cumulative Model Updates: 304,654
Cumulative Timesteps: 2,540,801,058

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2540801058...
Checkpoint 2540801058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.51637
Policy Entropy: 2.44922
Value Function Loss: 0.01988

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.09396
Policy Update Magnitude: 0.49208
Value Function Update Magnitude: 0.60570

Collected Steps per Second: 21,483.19781
Overall Steps per Second: 10,557.27785

Timestep Collection Time: 2.32861
Timestep Consumption Time: 2.40992
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.73853

Cumulative Model Updates: 304,660
Cumulative Timesteps: 2,540,851,084

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.97954
Policy Entropy: 2.42976
Value Function Loss: 0.02154

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.08767
Policy Update Magnitude: 0.49570
Value Function Update Magnitude: 0.60023

Collected Steps per Second: 21,751.93306
Overall Steps per Second: 10,264.37423

Timestep Collection Time: 2.29929
Timestep Consumption Time: 2.57329
PPO Batch Consumption Time: 0.29839
Total Iteration Time: 4.87258

Cumulative Model Updates: 304,666
Cumulative Timesteps: 2,540,901,098

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2540901098...
Checkpoint 2540901098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.42635
Policy Entropy: 2.43618
Value Function Loss: 0.02195

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.09579
Policy Update Magnitude: 0.50145
Value Function Update Magnitude: 0.63477

Collected Steps per Second: 21,782.77679
Overall Steps per Second: 10,365.62781

Timestep Collection Time: 2.29558
Timestep Consumption Time: 2.52845
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.82402

Cumulative Model Updates: 304,672
Cumulative Timesteps: 2,540,951,102

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.30791
Policy Entropy: 2.45371
Value Function Loss: 0.02227

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.10068
Policy Update Magnitude: 0.49822
Value Function Update Magnitude: 0.64337

Collected Steps per Second: 21,736.07239
Overall Steps per Second: 10,479.60597

Timestep Collection Time: 2.30042
Timestep Consumption Time: 2.47095
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.77136

Cumulative Model Updates: 304,678
Cumulative Timesteps: 2,541,001,104

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2541001104...
Checkpoint 2541001104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.36570
Policy Entropy: 2.47966
Value Function Loss: 0.02103

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.10955
Policy Update Magnitude: 0.49164
Value Function Update Magnitude: 0.65509

Collected Steps per Second: 21,839.40250
Overall Steps per Second: 10,631.89935

Timestep Collection Time: 2.29036
Timestep Consumption Time: 2.41435
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.70471

Cumulative Model Updates: 304,684
Cumulative Timesteps: 2,541,051,124

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.34490
Policy Entropy: 2.48453
Value Function Loss: 0.02028

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.49613
Value Function Update Magnitude: 0.65267

Collected Steps per Second: 21,700.60591
Overall Steps per Second: 10,400.25901

Timestep Collection Time: 2.30491
Timestep Consumption Time: 2.50439
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.80930

Cumulative Model Updates: 304,690
Cumulative Timesteps: 2,541,101,142

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2541101142...
Checkpoint 2541101142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.04465
Policy Entropy: 2.48522
Value Function Loss: 0.02078

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.09828
Policy Update Magnitude: 0.49807
Value Function Update Magnitude: 0.63355

Collected Steps per Second: 21,467.06668
Overall Steps per Second: 10,386.23047

Timestep Collection Time: 2.33064
Timestep Consumption Time: 2.48651
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.81715

Cumulative Model Updates: 304,696
Cumulative Timesteps: 2,541,151,174

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.09272
Policy Entropy: 2.47587
Value Function Loss: 0.02097

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.09052
Policy Update Magnitude: 0.49524
Value Function Update Magnitude: 0.62900

Collected Steps per Second: 21,971.86868
Overall Steps per Second: 10,505.08929

Timestep Collection Time: 2.27627
Timestep Consumption Time: 2.48466
PPO Batch Consumption Time: 0.29990
Total Iteration Time: 4.76093

Cumulative Model Updates: 304,702
Cumulative Timesteps: 2,541,201,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2541201188...
Checkpoint 2541201188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.18342
Policy Entropy: 2.47722
Value Function Loss: 0.02039

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.09342
Policy Update Magnitude: 0.48404
Value Function Update Magnitude: 0.62070

Collected Steps per Second: 21,990.77091
Overall Steps per Second: 10,511.70797

Timestep Collection Time: 2.27505
Timestep Consumption Time: 2.48441
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.75945

Cumulative Model Updates: 304,708
Cumulative Timesteps: 2,541,251,218

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.66306
Policy Entropy: 2.47503
Value Function Loss: 0.01969

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.09054
Policy Update Magnitude: 0.49139
Value Function Update Magnitude: 0.62248

Collected Steps per Second: 21,711.17529
Overall Steps per Second: 10,305.05786

Timestep Collection Time: 2.30315
Timestep Consumption Time: 2.54923
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.85237

Cumulative Model Updates: 304,714
Cumulative Timesteps: 2,541,301,222

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2541301222...
Checkpoint 2541301222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.98319
Policy Entropy: 2.47806
Value Function Loss: 0.01980

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.09727
Policy Update Magnitude: 0.49052
Value Function Update Magnitude: 0.62879

Collected Steps per Second: 21,674.26855
Overall Steps per Second: 10,436.48659

Timestep Collection Time: 2.30734
Timestep Consumption Time: 2.48450
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.79184

Cumulative Model Updates: 304,720
Cumulative Timesteps: 2,541,351,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.99127
Policy Entropy: 2.47549
Value Function Loss: 0.02050

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.10015
Policy Update Magnitude: 0.48631
Value Function Update Magnitude: 0.62331

Collected Steps per Second: 21,717.93467
Overall Steps per Second: 10,463.70035

Timestep Collection Time: 2.30224
Timestep Consumption Time: 2.47618
PPO Batch Consumption Time: 0.29818
Total Iteration Time: 4.77842

Cumulative Model Updates: 304,726
Cumulative Timesteps: 2,541,401,232

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2541401232...
Checkpoint 2541401232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.72739
Policy Entropy: 2.46785
Value Function Loss: 0.02089

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.10186
Policy Update Magnitude: 0.49162
Value Function Update Magnitude: 0.61348

Collected Steps per Second: 21,917.41406
Overall Steps per Second: 10,374.59139

Timestep Collection Time: 2.28266
Timestep Consumption Time: 2.53970
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.82236

Cumulative Model Updates: 304,732
Cumulative Timesteps: 2,541,451,262

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.44909
Policy Entropy: 2.45194
Value Function Loss: 0.02147

Mean KL Divergence: 0.02138
SB3 Clip Fraction: 0.13117
Policy Update Magnitude: 0.47851
Value Function Update Magnitude: 0.63195

Collected Steps per Second: 21,888.80114
Overall Steps per Second: 10,302.65979

Timestep Collection Time: 2.28464
Timestep Consumption Time: 2.56925
PPO Batch Consumption Time: 0.29966
Total Iteration Time: 4.85389

Cumulative Model Updates: 304,738
Cumulative Timesteps: 2,541,501,270

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2541501270...
Checkpoint 2541501270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.64902
Policy Entropy: 2.43425
Value Function Loss: 0.02153

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.12048
Policy Update Magnitude: 0.47556
Value Function Update Magnitude: 0.63510

Collected Steps per Second: 21,226.61204
Overall Steps per Second: 10,073.12586

Timestep Collection Time: 2.35553
Timestep Consumption Time: 2.60817
PPO Batch Consumption Time: 0.30922
Total Iteration Time: 4.96370

Cumulative Model Updates: 304,744
Cumulative Timesteps: 2,541,551,270

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.10612
Policy Entropy: 2.43838
Value Function Loss: 0.02184

Mean KL Divergence: 0.02091
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.49702
Value Function Update Magnitude: 0.64097

Collected Steps per Second: 21,726.60885
Overall Steps per Second: 10,561.90599

Timestep Collection Time: 2.30142
Timestep Consumption Time: 2.43277
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.73418

Cumulative Model Updates: 304,750
Cumulative Timesteps: 2,541,601,272

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2541601272...
Checkpoint 2541601272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.75594
Policy Entropy: 2.46129
Value Function Loss: 0.02056

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.12446
Policy Update Magnitude: 0.49827
Value Function Update Magnitude: 0.65935

Collected Steps per Second: 21,603.55269
Overall Steps per Second: 10,262.20399

Timestep Collection Time: 2.31462
Timestep Consumption Time: 2.55802
PPO Batch Consumption Time: 0.30020
Total Iteration Time: 4.87264

Cumulative Model Updates: 304,756
Cumulative Timesteps: 2,541,651,276

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.21901
Policy Entropy: 2.47623
Value Function Loss: 0.02076

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.11087
Policy Update Magnitude: 0.50485
Value Function Update Magnitude: 0.65269

Collected Steps per Second: 21,930.86109
Overall Steps per Second: 10,409.00471

Timestep Collection Time: 2.28071
Timestep Consumption Time: 2.52455
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.80526

Cumulative Model Updates: 304,762
Cumulative Timesteps: 2,541,701,294

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2541701294...
Checkpoint 2541701294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.73159
Policy Entropy: 2.50101
Value Function Loss: 0.02021

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.09550
Policy Update Magnitude: 0.49650
Value Function Update Magnitude: 0.65074

Collected Steps per Second: 21,327.05909
Overall Steps per Second: 10,251.31296

Timestep Collection Time: 2.34491
Timestep Consumption Time: 2.53349
PPO Batch Consumption Time: 0.30012
Total Iteration Time: 4.87840

Cumulative Model Updates: 304,768
Cumulative Timesteps: 2,541,751,304

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.98872
Policy Entropy: 2.49376
Value Function Loss: 0.02189

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.09802
Policy Update Magnitude: 0.50580
Value Function Update Magnitude: 0.66748

Collected Steps per Second: 21,962.08334
Overall Steps per Second: 10,417.23007

Timestep Collection Time: 2.27838
Timestep Consumption Time: 2.52501
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.80339

Cumulative Model Updates: 304,774
Cumulative Timesteps: 2,541,801,342

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2541801342...
Checkpoint 2541801342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.77745
Policy Entropy: 2.47269
Value Function Loss: 0.01960

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.10301
Policy Update Magnitude: 0.49812
Value Function Update Magnitude: 0.66734

Collected Steps per Second: 22,277.85750
Overall Steps per Second: 10,570.28139

Timestep Collection Time: 2.24582
Timestep Consumption Time: 2.48745
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.73327

Cumulative Model Updates: 304,780
Cumulative Timesteps: 2,541,851,374

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.60301
Policy Entropy: 2.46257
Value Function Loss: 0.01968

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.48449
Value Function Update Magnitude: 0.64417

Collected Steps per Second: 21,960.51578
Overall Steps per Second: 10,430.09499

Timestep Collection Time: 2.27700
Timestep Consumption Time: 2.51721
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.79420

Cumulative Model Updates: 304,786
Cumulative Timesteps: 2,541,901,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2541901378...
Checkpoint 2541901378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.72709
Policy Entropy: 2.47126
Value Function Loss: 0.01818

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.12235
Policy Update Magnitude: 0.47924
Value Function Update Magnitude: 0.62327

Collected Steps per Second: 20,997.25988
Overall Steps per Second: 10,338.05959

Timestep Collection Time: 2.38260
Timestep Consumption Time: 2.45661
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.83921

Cumulative Model Updates: 304,792
Cumulative Timesteps: 2,541,951,406

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.41298
Policy Entropy: 2.48750
Value Function Loss: 0.01867

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.10887
Policy Update Magnitude: 0.49417
Value Function Update Magnitude: 0.63696

Collected Steps per Second: 22,009.61693
Overall Steps per Second: 10,554.59001

Timestep Collection Time: 2.27210
Timestep Consumption Time: 2.46594
PPO Batch Consumption Time: 0.29704
Total Iteration Time: 4.73803

Cumulative Model Updates: 304,798
Cumulative Timesteps: 2,542,001,414

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2542001414...
Checkpoint 2542001414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.12187
Policy Entropy: 2.47320
Value Function Loss: 0.01895

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.10941
Policy Update Magnitude: 0.51093
Value Function Update Magnitude: 0.64160

Collected Steps per Second: 21,672.73708
Overall Steps per Second: 10,409.70227

Timestep Collection Time: 2.30723
Timestep Consumption Time: 2.49637
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.80360

Cumulative Model Updates: 304,804
Cumulative Timesteps: 2,542,051,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.61717
Policy Entropy: 2.48001
Value Function Loss: 0.01935

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.10360
Policy Update Magnitude: 0.50290
Value Function Update Magnitude: 0.64315

Collected Steps per Second: 21,938.30709
Overall Steps per Second: 10,468.75695

Timestep Collection Time: 2.28049
Timestep Consumption Time: 2.49850
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.77898

Cumulative Model Updates: 304,810
Cumulative Timesteps: 2,542,101,448

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2542101448...
Checkpoint 2542101448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.54829
Policy Entropy: 2.48136
Value Function Loss: 0.02026

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.09989
Policy Update Magnitude: 0.50040
Value Function Update Magnitude: 0.64059

Collected Steps per Second: 21,625.37367
Overall Steps per Second: 10,295.69846

Timestep Collection Time: 2.31312
Timestep Consumption Time: 2.54542
PPO Batch Consumption Time: 0.29937
Total Iteration Time: 4.85853

Cumulative Model Updates: 304,816
Cumulative Timesteps: 2,542,151,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.97820
Policy Entropy: 2.47993
Value Function Loss: 0.02076

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.10098
Policy Update Magnitude: 0.49955
Value Function Update Magnitude: 0.63805

Collected Steps per Second: 21,811.10005
Overall Steps per Second: 10,467.69100

Timestep Collection Time: 2.29342
Timestep Consumption Time: 2.48528
PPO Batch Consumption Time: 0.29918
Total Iteration Time: 4.77870

Cumulative Model Updates: 304,822
Cumulative Timesteps: 2,542,201,492

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2542201492...
Checkpoint 2542201492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.40645
Policy Entropy: 2.45418
Value Function Loss: 0.02151

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.48344
Value Function Update Magnitude: 0.63773

Collected Steps per Second: 21,732.20952
Overall Steps per Second: 10,303.53124

Timestep Collection Time: 2.30147
Timestep Consumption Time: 2.55279
PPO Batch Consumption Time: 0.29815
Total Iteration Time: 4.85426

Cumulative Model Updates: 304,828
Cumulative Timesteps: 2,542,251,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.72874
Policy Entropy: 2.45535
Value Function Loss: 0.02166

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.10523
Policy Update Magnitude: 0.48105
Value Function Update Magnitude: 0.63877

Collected Steps per Second: 22,030.33304
Overall Steps per Second: 10,316.00748

Timestep Collection Time: 2.27078
Timestep Consumption Time: 2.57858
PPO Batch Consumption Time: 0.29894
Total Iteration Time: 4.84936

Cumulative Model Updates: 304,834
Cumulative Timesteps: 2,542,301,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2542301534...
Checkpoint 2542301534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.26101
Policy Entropy: 2.44323
Value Function Loss: 0.02179

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.09857
Policy Update Magnitude: 0.50310
Value Function Update Magnitude: 0.64318

Collected Steps per Second: 21,678.86739
Overall Steps per Second: 10,343.51552

Timestep Collection Time: 2.30713
Timestep Consumption Time: 2.52836
PPO Batch Consumption Time: 0.29721
Total Iteration Time: 4.83549

Cumulative Model Updates: 304,840
Cumulative Timesteps: 2,542,351,550

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.08071
Policy Entropy: 2.45952
Value Function Loss: 0.02019

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.10649
Policy Update Magnitude: 0.50248
Value Function Update Magnitude: 0.66051

Collected Steps per Second: 22,673.42157
Overall Steps per Second: 10,671.99622

Timestep Collection Time: 2.20549
Timestep Consumption Time: 2.48023
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.68572

Cumulative Model Updates: 304,846
Cumulative Timesteps: 2,542,401,556

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2542401556...
Checkpoint 2542401556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.84034
Policy Entropy: 2.45602
Value Function Loss: 0.02105

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.11664
Policy Update Magnitude: 0.49602
Value Function Update Magnitude: 0.65497

Collected Steps per Second: 21,650.06488
Overall Steps per Second: 10,331.56736

Timestep Collection Time: 2.31076
Timestep Consumption Time: 2.53149
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.84225

Cumulative Model Updates: 304,852
Cumulative Timesteps: 2,542,451,584

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.10967
Policy Entropy: 2.45884
Value Function Loss: 0.02056

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.11831
Policy Update Magnitude: 0.49600
Value Function Update Magnitude: 0.64707

Collected Steps per Second: 22,141.22475
Overall Steps per Second: 10,431.46086

Timestep Collection Time: 2.25886
Timestep Consumption Time: 2.53567
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.79453

Cumulative Model Updates: 304,858
Cumulative Timesteps: 2,542,501,598

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2542501598...
Checkpoint 2542501598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.05170
Policy Entropy: 2.44800
Value Function Loss: 0.02035

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.11058
Policy Update Magnitude: 0.50614
Value Function Update Magnitude: 0.66037

Collected Steps per Second: 21,421.88007
Overall Steps per Second: 10,541.25810

Timestep Collection Time: 2.33425
Timestep Consumption Time: 2.40940
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.74365

Cumulative Model Updates: 304,864
Cumulative Timesteps: 2,542,551,602

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.10528
Policy Entropy: 2.46518
Value Function Loss: 0.01925

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.10681
Policy Update Magnitude: 0.50942
Value Function Update Magnitude: 0.67093

Collected Steps per Second: 21,957.59203
Overall Steps per Second: 10,518.83630

Timestep Collection Time: 2.27785
Timestep Consumption Time: 2.47705
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.75490

Cumulative Model Updates: 304,870
Cumulative Timesteps: 2,542,601,618

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2542601618...
Checkpoint 2542601618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.27704
Policy Entropy: 2.47753
Value Function Loss: 0.01943

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.09223
Policy Update Magnitude: 0.50564
Value Function Update Magnitude: 0.66408

Collected Steps per Second: 21,681.46060
Overall Steps per Second: 10,274.35051

Timestep Collection Time: 2.30695
Timestep Consumption Time: 2.56129
PPO Batch Consumption Time: 0.29882
Total Iteration Time: 4.86824

Cumulative Model Updates: 304,876
Cumulative Timesteps: 2,542,651,636

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.66222
Policy Entropy: 2.48382
Value Function Loss: 0.02055

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.09092
Policy Update Magnitude: 0.50272
Value Function Update Magnitude: 0.66080

Collected Steps per Second: 21,824.75857
Overall Steps per Second: 10,419.70695

Timestep Collection Time: 2.29171
Timestep Consumption Time: 2.50843
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.80014

Cumulative Model Updates: 304,882
Cumulative Timesteps: 2,542,701,652

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2542701652...
Checkpoint 2542701652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.28537
Policy Entropy: 2.45626
Value Function Loss: 0.02139

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.09860
Policy Update Magnitude: 0.49853
Value Function Update Magnitude: 0.66500

Collected Steps per Second: 21,590.75964
Overall Steps per Second: 10,574.38854

Timestep Collection Time: 2.31608
Timestep Consumption Time: 2.41289
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.72897

Cumulative Model Updates: 304,888
Cumulative Timesteps: 2,542,751,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.37663
Policy Entropy: 2.45534
Value Function Loss: 0.02177

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.10090
Policy Update Magnitude: 0.50562
Value Function Update Magnitude: 0.67090

Collected Steps per Second: 21,744.20919
Overall Steps per Second: 10,436.58903

Timestep Collection Time: 2.30029
Timestep Consumption Time: 2.49227
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.79256

Cumulative Model Updates: 304,894
Cumulative Timesteps: 2,542,801,676

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2542801676...
Checkpoint 2542801676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.11514
Policy Entropy: 2.45846
Value Function Loss: 0.02036

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.09873
Policy Update Magnitude: 0.50882
Value Function Update Magnitude: 0.65789

Collected Steps per Second: 21,281.67152
Overall Steps per Second: 10,288.40542

Timestep Collection Time: 2.35076
Timestep Consumption Time: 2.51181
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.86256

Cumulative Model Updates: 304,900
Cumulative Timesteps: 2,542,851,704

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.08267
Policy Entropy: 2.45463
Value Function Loss: 0.02065

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.10696
Policy Update Magnitude: 0.50521
Value Function Update Magnitude: 0.65818

Collected Steps per Second: 21,812.44688
Overall Steps per Second: 10,506.48858

Timestep Collection Time: 2.29319
Timestep Consumption Time: 2.46768
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.76087

Cumulative Model Updates: 304,906
Cumulative Timesteps: 2,542,901,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2542901724...
Checkpoint 2542901724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.23234
Policy Entropy: 2.46233
Value Function Loss: 0.02068

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.09854
Policy Update Magnitude: 0.50869
Value Function Update Magnitude: 0.64816

Collected Steps per Second: 21,787.51338
Overall Steps per Second: 10,646.98663

Timestep Collection Time: 2.29599
Timestep Consumption Time: 2.40242
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.69842

Cumulative Model Updates: 304,912
Cumulative Timesteps: 2,542,951,748

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.11160
Policy Entropy: 2.46325
Value Function Loss: 0.02201

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.11538
Policy Update Magnitude: 0.50672
Value Function Update Magnitude: 0.63949

Collected Steps per Second: 21,874.41892
Overall Steps per Second: 10,424.60231

Timestep Collection Time: 2.28724
Timestep Consumption Time: 2.51218
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.79942

Cumulative Model Updates: 304,918
Cumulative Timesteps: 2,543,001,780

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2543001780...
Checkpoint 2543001780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.24936
Policy Entropy: 2.47538
Value Function Loss: 0.02126

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.11125
Policy Update Magnitude: 0.50685
Value Function Update Magnitude: 0.64882

Collected Steps per Second: 21,574.01159
Overall Steps per Second: 10,240.97793

Timestep Collection Time: 2.31807
Timestep Consumption Time: 2.56526
PPO Batch Consumption Time: 0.29969
Total Iteration Time: 4.88332

Cumulative Model Updates: 304,924
Cumulative Timesteps: 2,543,051,790

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.99450
Policy Entropy: 2.47531
Value Function Loss: 0.02151

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.10763
Policy Update Magnitude: 0.51599
Value Function Update Magnitude: 0.65680

Collected Steps per Second: 21,707.90783
Overall Steps per Second: 10,348.49487

Timestep Collection Time: 2.30358
Timestep Consumption Time: 2.52862
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.83220

Cumulative Model Updates: 304,930
Cumulative Timesteps: 2,543,101,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2543101796...
Checkpoint 2543101796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.88917
Policy Entropy: 2.47238
Value Function Loss: 0.02156

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.09533
Policy Update Magnitude: 0.50884
Value Function Update Magnitude: 0.67615

Collected Steps per Second: 22,456.19405
Overall Steps per Second: 10,583.64179

Timestep Collection Time: 2.22674
Timestep Consumption Time: 2.49791
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.72465

Cumulative Model Updates: 304,936
Cumulative Timesteps: 2,543,151,800

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.03686
Policy Entropy: 2.46919
Value Function Loss: 0.02121

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.08801
Policy Update Magnitude: 0.50490
Value Function Update Magnitude: 0.69895

Collected Steps per Second: 21,867.12442
Overall Steps per Second: 10,472.08121

Timestep Collection Time: 2.28654
Timestep Consumption Time: 2.48806
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.77460

Cumulative Model Updates: 304,942
Cumulative Timesteps: 2,543,201,800

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2543201800...
Checkpoint 2543201800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.67084
Policy Entropy: 2.45876
Value Function Loss: 0.02036

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.09019
Policy Update Magnitude: 0.50325
Value Function Update Magnitude: 0.69870

Collected Steps per Second: 21,130.79006
Overall Steps per Second: 10,309.01230

Timestep Collection Time: 2.36688
Timestep Consumption Time: 2.48461
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.85148

Cumulative Model Updates: 304,948
Cumulative Timesteps: 2,543,251,814

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.45010
Policy Entropy: 2.43803
Value Function Loss: 0.02090

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.08786
Policy Update Magnitude: 0.51055
Value Function Update Magnitude: 0.68331

Collected Steps per Second: 21,893.88400
Overall Steps per Second: 10,461.58305

Timestep Collection Time: 2.28447
Timestep Consumption Time: 2.49645
PPO Batch Consumption Time: 0.29890
Total Iteration Time: 4.78092

Cumulative Model Updates: 304,954
Cumulative Timesteps: 2,543,301,830

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2543301830...
Checkpoint 2543301830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.63719
Policy Entropy: 2.41793
Value Function Loss: 0.02139

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.09363
Policy Update Magnitude: 0.51380
Value Function Update Magnitude: 0.68977

Collected Steps per Second: 21,533.18332
Overall Steps per Second: 10,249.65032

Timestep Collection Time: 2.32200
Timestep Consumption Time: 2.55622
PPO Batch Consumption Time: 0.29929
Total Iteration Time: 4.87822

Cumulative Model Updates: 304,960
Cumulative Timesteps: 2,543,351,830

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.88885
Policy Entropy: 2.43577
Value Function Loss: 0.02128

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.10116
Policy Update Magnitude: 0.51544
Value Function Update Magnitude: 0.70574

Collected Steps per Second: 22,018.26008
Overall Steps per Second: 10,411.68439

Timestep Collection Time: 2.27121
Timestep Consumption Time: 2.53186
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.80307

Cumulative Model Updates: 304,966
Cumulative Timesteps: 2,543,401,838

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2543401838...
Checkpoint 2543401838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.65338
Policy Entropy: 2.46121
Value Function Loss: 0.02067

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.10329
Policy Update Magnitude: 0.52211
Value Function Update Magnitude: 0.70455

Collected Steps per Second: 21,473.49613
Overall Steps per Second: 10,295.54160

Timestep Collection Time: 2.32976
Timestep Consumption Time: 2.52943
PPO Batch Consumption Time: 0.29916
Total Iteration Time: 4.85919

Cumulative Model Updates: 304,972
Cumulative Timesteps: 2,543,451,866

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.02402
Policy Entropy: 2.46496
Value Function Loss: 0.02090

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.11744
Policy Update Magnitude: 0.52626
Value Function Update Magnitude: 0.70247

Collected Steps per Second: 21,955.54739
Overall Steps per Second: 10,519.65307

Timestep Collection Time: 2.27842
Timestep Consumption Time: 2.47687
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.75529

Cumulative Model Updates: 304,978
Cumulative Timesteps: 2,543,501,890

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2543501890...
Checkpoint 2543501890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.45996
Policy Entropy: 2.43378
Value Function Loss: 0.02105

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.10111
Policy Update Magnitude: 0.51413
Value Function Update Magnitude: 0.71202

Collected Steps per Second: 21,777.06283
Overall Steps per Second: 10,429.91697

Timestep Collection Time: 2.29728
Timestep Consumption Time: 2.49931
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.79659

Cumulative Model Updates: 304,984
Cumulative Timesteps: 2,543,551,918

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.74063
Policy Entropy: 2.44487
Value Function Loss: 0.02082

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.50834
Value Function Update Magnitude: 0.71656

Collected Steps per Second: 21,779.61773
Overall Steps per Second: 10,423.14111

Timestep Collection Time: 2.29729
Timestep Consumption Time: 2.50299
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.80028

Cumulative Model Updates: 304,990
Cumulative Timesteps: 2,543,601,952

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2543601952...
Checkpoint 2543601952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.45074
Policy Entropy: 2.47136
Value Function Loss: 0.01945

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.09484
Policy Update Magnitude: 0.50072
Value Function Update Magnitude: 0.69257

Collected Steps per Second: 21,471.09172
Overall Steps per Second: 10,306.74582

Timestep Collection Time: 2.32964
Timestep Consumption Time: 2.52349
PPO Batch Consumption Time: 0.29952
Total Iteration Time: 4.85313

Cumulative Model Updates: 304,996
Cumulative Timesteps: 2,543,651,972

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.89985
Policy Entropy: 2.47833
Value Function Loss: 0.01842

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.09457
Policy Update Magnitude: 0.48185
Value Function Update Magnitude: 0.66991

Collected Steps per Second: 21,848.95373
Overall Steps per Second: 10,449.07207

Timestep Collection Time: 2.28844
Timestep Consumption Time: 2.49667
PPO Batch Consumption Time: 0.29933
Total Iteration Time: 4.78511

Cumulative Model Updates: 305,002
Cumulative Timesteps: 2,543,701,972

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2543701972...
Checkpoint 2543701972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.69083
Policy Entropy: 2.46459
Value Function Loss: 0.01880

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.08498
Policy Update Magnitude: 0.47754
Value Function Update Magnitude: 0.67233

Collected Steps per Second: 21,660.70049
Overall Steps per Second: 10,296.91879

Timestep Collection Time: 2.30851
Timestep Consumption Time: 2.54770
PPO Batch Consumption Time: 0.29653
Total Iteration Time: 4.85621

Cumulative Model Updates: 305,008
Cumulative Timesteps: 2,543,751,976

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.09114
Policy Entropy: 2.44094
Value Function Loss: 0.01912

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.09669
Policy Update Magnitude: 0.48270
Value Function Update Magnitude: 0.66460

Collected Steps per Second: 21,781.77175
Overall Steps per Second: 10,333.27273

Timestep Collection Time: 2.29651
Timestep Consumption Time: 2.54436
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.84087

Cumulative Model Updates: 305,014
Cumulative Timesteps: 2,543,801,998

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2543801998...
Checkpoint 2543801998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.20108
Policy Entropy: 2.44298
Value Function Loss: 0.02032

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.08939
Policy Update Magnitude: 0.49080
Value Function Update Magnitude: 0.66231

Collected Steps per Second: 21,224.01640
Overall Steps per Second: 10,192.86449

Timestep Collection Time: 2.35761
Timestep Consumption Time: 2.55151
PPO Batch Consumption Time: 0.29942
Total Iteration Time: 4.90912

Cumulative Model Updates: 305,020
Cumulative Timesteps: 2,543,852,036

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.93576
Policy Entropy: 2.43929
Value Function Loss: 0.01923

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.08570
Policy Update Magnitude: 0.48959
Value Function Update Magnitude: 0.66300

Collected Steps per Second: 22,113.05307
Overall Steps per Second: 10,530.81999

Timestep Collection Time: 2.26183
Timestep Consumption Time: 2.48766
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.74949

Cumulative Model Updates: 305,026
Cumulative Timesteps: 2,543,902,052

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2543902052...
Checkpoint 2543902052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.61187
Policy Entropy: 2.43506
Value Function Loss: 0.01941

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.08557
Policy Update Magnitude: 0.49576
Value Function Update Magnitude: 0.66817

Collected Steps per Second: 21,826.33995
Overall Steps per Second: 10,358.50174

Timestep Collection Time: 2.29081
Timestep Consumption Time: 2.53614
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.82695

Cumulative Model Updates: 305,032
Cumulative Timesteps: 2,543,952,052

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.94086
Policy Entropy: 2.44179
Value Function Loss: 0.02012

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.09085
Policy Update Magnitude: 0.49869
Value Function Update Magnitude: 0.68482

Collected Steps per Second: 21,794.17435
Overall Steps per Second: 10,274.23792

Timestep Collection Time: 2.29465
Timestep Consumption Time: 2.57286
PPO Batch Consumption Time: 0.29959
Total Iteration Time: 4.86751

Cumulative Model Updates: 305,038
Cumulative Timesteps: 2,544,002,062

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2544002062...
Checkpoint 2544002062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.25981
Policy Entropy: 2.45043
Value Function Loss: 0.02092

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.50290
Value Function Update Magnitude: 0.70654

Collected Steps per Second: 21,686.14388
Overall Steps per Second: 10,360.04481

Timestep Collection Time: 2.30571
Timestep Consumption Time: 2.52072
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 4.82643

Cumulative Model Updates: 305,044
Cumulative Timesteps: 2,544,052,064

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.36964
Policy Entropy: 2.46617
Value Function Loss: 0.02110

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.49473
Value Function Update Magnitude: 0.71389

Collected Steps per Second: 21,923.02840
Overall Steps per Second: 10,634.15714

Timestep Collection Time: 2.28135
Timestep Consumption Time: 2.42180
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.70315

Cumulative Model Updates: 305,050
Cumulative Timesteps: 2,544,102,078

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2544102078...
Checkpoint 2544102078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.73594
Policy Entropy: 2.45048
Value Function Loss: 0.02056

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.11206
Policy Update Magnitude: 0.48719
Value Function Update Magnitude: 0.70119

Collected Steps per Second: 21,755.37189
Overall Steps per Second: 10,315.27243

Timestep Collection Time: 2.29847
Timestep Consumption Time: 2.54910
PPO Batch Consumption Time: 0.29714
Total Iteration Time: 4.84757

Cumulative Model Updates: 305,056
Cumulative Timesteps: 2,544,152,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.88547
Policy Entropy: 2.43146
Value Function Loss: 0.02017

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.10861
Policy Update Magnitude: 0.48958
Value Function Update Magnitude: 0.67240

Collected Steps per Second: 21,603.21988
Overall Steps per Second: 10,373.67793

Timestep Collection Time: 2.31447
Timestep Consumption Time: 2.50542
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.81989

Cumulative Model Updates: 305,062
Cumulative Timesteps: 2,544,202,082

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2544202082...
Checkpoint 2544202082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.01619
Policy Entropy: 2.43212
Value Function Loss: 0.02065

Mean KL Divergence: 0.02319
SB3 Clip Fraction: 0.13603
Policy Update Magnitude: 0.46537
Value Function Update Magnitude: 0.64392

Collected Steps per Second: 21,700.47743
Overall Steps per Second: 10,335.35311

Timestep Collection Time: 2.30428
Timestep Consumption Time: 2.53387
PPO Batch Consumption Time: 0.29945
Total Iteration Time: 4.83815

Cumulative Model Updates: 305,068
Cumulative Timesteps: 2,544,252,086

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.70369
Policy Entropy: 2.44629
Value Function Loss: 0.01824

Mean KL Divergence: 0.02178
SB3 Clip Fraction: 0.13235
Policy Update Magnitude: 0.45540
Value Function Update Magnitude: 0.64613

Collected Steps per Second: 21,754.11293
Overall Steps per Second: 10,444.22605

Timestep Collection Time: 2.29906
Timestep Consumption Time: 2.48962
PPO Batch Consumption Time: 0.29937
Total Iteration Time: 4.78867

Cumulative Model Updates: 305,074
Cumulative Timesteps: 2,544,302,100

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2544302100...
Checkpoint 2544302100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.58775
Policy Entropy: 2.42980
Value Function Loss: 0.01947

Mean KL Divergence: 0.02294
SB3 Clip Fraction: 0.13250
Policy Update Magnitude: 0.47763
Value Function Update Magnitude: 0.65967

Collected Steps per Second: 21,703.88421
Overall Steps per Second: 10,345.71482

Timestep Collection Time: 2.30466
Timestep Consumption Time: 2.53020
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.83485

Cumulative Model Updates: 305,080
Cumulative Timesteps: 2,544,352,120

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.36161
Policy Entropy: 2.42414
Value Function Loss: 0.01868

Mean KL Divergence: 0.02497
SB3 Clip Fraction: 0.14096
Policy Update Magnitude: 0.46955
Value Function Update Magnitude: 0.67293

Collected Steps per Second: 21,475.31368
Overall Steps per Second: 10,278.86689

Timestep Collection Time: 2.32825
Timestep Consumption Time: 2.53609
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.86435

Cumulative Model Updates: 305,086
Cumulative Timesteps: 2,544,402,120

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2544402120...
Checkpoint 2544402120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.62894
Policy Entropy: 2.42482
Value Function Loss: 0.02117

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.50266
Value Function Update Magnitude: 0.69799

Collected Steps per Second: 21,668.08003
Overall Steps per Second: 10,350.10617

Timestep Collection Time: 2.30856
Timestep Consumption Time: 2.52444
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 4.83299

Cumulative Model Updates: 305,092
Cumulative Timesteps: 2,544,452,142

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.36279
Policy Entropy: 2.43518
Value Function Loss: 0.02013

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.51300
Value Function Update Magnitude: 0.69726

Collected Steps per Second: 21,828.71869
Overall Steps per Second: 10,575.32316

Timestep Collection Time: 2.29193
Timestep Consumption Time: 2.43889
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.73082

Cumulative Model Updates: 305,098
Cumulative Timesteps: 2,544,502,172

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2544502172...
Checkpoint 2544502172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.94007
Policy Entropy: 2.42152
Value Function Loss: 0.02165

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.10604
Policy Update Magnitude: 0.50530
Value Function Update Magnitude: 0.69478

Collected Steps per Second: 21,911.37398
Overall Steps per Second: 10,348.51312

Timestep Collection Time: 2.28265
Timestep Consumption Time: 2.55051
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.83316

Cumulative Model Updates: 305,104
Cumulative Timesteps: 2,544,552,188

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.53918
Policy Entropy: 2.41557
Value Function Loss: 0.02104

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.09347
Policy Update Magnitude: 0.51337
Value Function Update Magnitude: 0.67795

Collected Steps per Second: 21,395.16006
Overall Steps per Second: 10,238.85732

Timestep Collection Time: 2.33716
Timestep Consumption Time: 2.54658
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.88375

Cumulative Model Updates: 305,110
Cumulative Timesteps: 2,544,602,192

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2544602192...
Checkpoint 2544602192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.49390
Policy Entropy: 2.42597
Value Function Loss: 0.02156

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.09577
Policy Update Magnitude: 0.51527
Value Function Update Magnitude: 0.67000

Collected Steps per Second: 21,622.03007
Overall Steps per Second: 10,469.33814

Timestep Collection Time: 2.31329
Timestep Consumption Time: 2.46428
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.77757

Cumulative Model Updates: 305,116
Cumulative Timesteps: 2,544,652,210

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.48385
Policy Entropy: 2.44581
Value Function Loss: 0.01973

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.08998
Policy Update Magnitude: 0.50323
Value Function Update Magnitude: 0.66731

Collected Steps per Second: 22,816.58282
Overall Steps per Second: 10,554.99910

Timestep Collection Time: 2.19262
Timestep Consumption Time: 2.54713
PPO Batch Consumption Time: 0.29710
Total Iteration Time: 4.73974

Cumulative Model Updates: 305,122
Cumulative Timesteps: 2,544,702,238

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2544702238...
Checkpoint 2544702238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.28156
Policy Entropy: 2.44331
Value Function Loss: 0.02020

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.09913
Policy Update Magnitude: 0.50224
Value Function Update Magnitude: 0.65800

Collected Steps per Second: 21,846.02109
Overall Steps per Second: 10,448.14267

Timestep Collection Time: 2.29021
Timestep Consumption Time: 2.49839
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.78860

Cumulative Model Updates: 305,128
Cumulative Timesteps: 2,544,752,270

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.57769
Policy Entropy: 2.45156
Value Function Loss: 0.01964

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.49986
Value Function Update Magnitude: 0.65752

Collected Steps per Second: 21,772.77325
Overall Steps per Second: 10,434.20500

Timestep Collection Time: 2.29773
Timestep Consumption Time: 2.49688
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.79462

Cumulative Model Updates: 305,134
Cumulative Timesteps: 2,544,802,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2544802298...
Checkpoint 2544802298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.15583
Policy Entropy: 2.43433
Value Function Loss: 0.02070

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.09657
Policy Update Magnitude: 0.50054
Value Function Update Magnitude: 0.67997

Collected Steps per Second: 21,462.91570
Overall Steps per Second: 10,378.86294

Timestep Collection Time: 2.33081
Timestep Consumption Time: 2.48918
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.81999

Cumulative Model Updates: 305,140
Cumulative Timesteps: 2,544,852,324

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.36857
Policy Entropy: 2.41762
Value Function Loss: 0.02029

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.09458
Policy Update Magnitude: 0.50062
Value Function Update Magnitude: 0.67471

Collected Steps per Second: 22,488.71383
Overall Steps per Second: 10,413.96435

Timestep Collection Time: 2.22396
Timestep Consumption Time: 2.57863
PPO Batch Consumption Time: 0.29877
Total Iteration Time: 4.80259

Cumulative Model Updates: 305,146
Cumulative Timesteps: 2,544,902,338

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2544902338...
Checkpoint 2544902338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.14972
Policy Entropy: 2.40817
Value Function Loss: 0.02091

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.50589
Value Function Update Magnitude: 0.66432

Collected Steps per Second: 21,685.00324
Overall Steps per Second: 10,275.66458

Timestep Collection Time: 2.30620
Timestep Consumption Time: 2.56064
PPO Batch Consumption Time: 0.29951
Total Iteration Time: 4.86684

Cumulative Model Updates: 305,152
Cumulative Timesteps: 2,544,952,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.65388
Policy Entropy: 2.40284
Value Function Loss: 0.02168

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.09548
Policy Update Magnitude: 0.50583
Value Function Update Magnitude: 0.66633

Collected Steps per Second: 21,886.21792
Overall Steps per Second: 10,408.66551

Timestep Collection Time: 2.28518
Timestep Consumption Time: 2.51985
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.80503

Cumulative Model Updates: 305,158
Cumulative Timesteps: 2,545,002,362

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2545002362...
Checkpoint 2545002362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.76009
Policy Entropy: 2.43513
Value Function Loss: 0.02133

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.09983
Policy Update Magnitude: 0.51313
Value Function Update Magnitude: 0.67938

Collected Steps per Second: 21,680.44570
Overall Steps per Second: 10,594.90670

Timestep Collection Time: 2.30632
Timestep Consumption Time: 2.41312
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.71944

Cumulative Model Updates: 305,164
Cumulative Timesteps: 2,545,052,364

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.81972
Policy Entropy: 2.44524
Value Function Loss: 0.02188

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.10401
Policy Update Magnitude: 0.50600
Value Function Update Magnitude: 0.69946

Collected Steps per Second: 21,770.10863
Overall Steps per Second: 10,425.32878

Timestep Collection Time: 2.29783
Timestep Consumption Time: 2.50048
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.79831

Cumulative Model Updates: 305,170
Cumulative Timesteps: 2,545,102,388

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2545102388...
Checkpoint 2545102388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.36571
Policy Entropy: 2.45596
Value Function Loss: 0.02199

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.10431
Policy Update Magnitude: 0.50554
Value Function Update Magnitude: 0.71261

Collected Steps per Second: 21,453.48359
Overall Steps per Second: 10,183.22061

Timestep Collection Time: 2.33165
Timestep Consumption Time: 2.58055
PPO Batch Consumption Time: 0.30318
Total Iteration Time: 4.91220

Cumulative Model Updates: 305,176
Cumulative Timesteps: 2,545,152,410

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.22420
Policy Entropy: 2.43345
Value Function Loss: 0.02225

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.10140
Policy Update Magnitude: 0.50580
Value Function Update Magnitude: 0.70742

Collected Steps per Second: 21,565.57409
Overall Steps per Second: 10,455.24602

Timestep Collection Time: 2.31888
Timestep Consumption Time: 2.46417
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.78305

Cumulative Model Updates: 305,182
Cumulative Timesteps: 2,545,202,418

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2545202418...
Checkpoint 2545202418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.73667
Policy Entropy: 2.41445
Value Function Loss: 0.02314

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.09603
Policy Update Magnitude: 0.51605
Value Function Update Magnitude: 0.69258

Collected Steps per Second: 21,400.57701
Overall Steps per Second: 10,377.17471

Timestep Collection Time: 2.33807
Timestep Consumption Time: 2.48367
PPO Batch Consumption Time: 0.29898
Total Iteration Time: 4.82174

Cumulative Model Updates: 305,188
Cumulative Timesteps: 2,545,252,454

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.34295
Policy Entropy: 2.39887
Value Function Loss: 0.02248

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.51534
Value Function Update Magnitude: 0.69042

Collected Steps per Second: 22,167.39534
Overall Steps per Second: 10,470.38775

Timestep Collection Time: 2.25656
Timestep Consumption Time: 2.52092
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.77747

Cumulative Model Updates: 305,194
Cumulative Timesteps: 2,545,302,476

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2545302476...
Checkpoint 2545302476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.12849
Policy Entropy: 2.38206
Value Function Loss: 0.02127

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.10122
Policy Update Magnitude: 0.51279
Value Function Update Magnitude: 0.69271

Collected Steps per Second: 22,025.71767
Overall Steps per Second: 10,592.10853

Timestep Collection Time: 2.27035
Timestep Consumption Time: 2.45072
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.72106

Cumulative Model Updates: 305,200
Cumulative Timesteps: 2,545,352,482

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.47027
Policy Entropy: 2.37191
Value Function Loss: 0.02128

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.09894
Policy Update Magnitude: 0.51286
Value Function Update Magnitude: 0.67967

Collected Steps per Second: 22,367.57589
Overall Steps per Second: 10,552.33174

Timestep Collection Time: 2.23609
Timestep Consumption Time: 2.50371
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.73981

Cumulative Model Updates: 305,206
Cumulative Timesteps: 2,545,402,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2545402498...
Checkpoint 2545402498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.95841
Policy Entropy: 2.36548
Value Function Loss: 0.02017

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.49727
Value Function Update Magnitude: 0.64676

Collected Steps per Second: 22,711.46568
Overall Steps per Second: 10,627.36014

Timestep Collection Time: 2.20241
Timestep Consumption Time: 2.50431
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.70672

Cumulative Model Updates: 305,212
Cumulative Timesteps: 2,545,452,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.81801
Policy Entropy: 2.38269
Value Function Loss: 0.02006

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.08495
Policy Update Magnitude: 0.49637
Value Function Update Magnitude: 0.63930

Collected Steps per Second: 22,183.94291
Overall Steps per Second: 10,490.32472

Timestep Collection Time: 2.25442
Timestep Consumption Time: 2.51302
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.76744

Cumulative Model Updates: 305,218
Cumulative Timesteps: 2,545,502,530

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2545502530...
Checkpoint 2545502530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.96336
Policy Entropy: 2.42279
Value Function Loss: 0.01940

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.08884
Policy Update Magnitude: 0.50119
Value Function Update Magnitude: 0.64507

Collected Steps per Second: 21,944.61423
Overall Steps per Second: 10,533.05991

Timestep Collection Time: 2.27874
Timestep Consumption Time: 2.46879
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.74753

Cumulative Model Updates: 305,224
Cumulative Timesteps: 2,545,552,536

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.07661
Policy Entropy: 2.43390
Value Function Loss: 0.02100

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.09946
Policy Update Magnitude: 0.51056
Value Function Update Magnitude: 0.66202

Collected Steps per Second: 22,088.91083
Overall Steps per Second: 10,462.59143

Timestep Collection Time: 2.26412
Timestep Consumption Time: 2.51596
PPO Batch Consumption Time: 0.29550
Total Iteration Time: 4.78008

Cumulative Model Updates: 305,230
Cumulative Timesteps: 2,545,602,548

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2545602548...
Checkpoint 2545602548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.53511
Policy Entropy: 2.41355
Value Function Loss: 0.02189

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.11763
Policy Update Magnitude: 0.50664
Value Function Update Magnitude: 0.65486

Collected Steps per Second: 21,993.29308
Overall Steps per Second: 10,632.54550

Timestep Collection Time: 2.27478
Timestep Consumption Time: 2.43058
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.70536

Cumulative Model Updates: 305,236
Cumulative Timesteps: 2,545,652,578

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.51344
Policy Entropy: 2.40388
Value Function Loss: 0.02219

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.10613
Policy Update Magnitude: 0.51427
Value Function Update Magnitude: 0.65329

Collected Steps per Second: 22,280.29812
Overall Steps per Second: 10,456.24248

Timestep Collection Time: 2.24476
Timestep Consumption Time: 2.53841
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.78317

Cumulative Model Updates: 305,242
Cumulative Timesteps: 2,545,702,592

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2545702592...
Checkpoint 2545702592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.61467
Policy Entropy: 2.40538
Value Function Loss: 0.02217

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.10525
Policy Update Magnitude: 0.51265
Value Function Update Magnitude: 0.65856

Collected Steps per Second: 21,903.06623
Overall Steps per Second: 10,569.45719

Timestep Collection Time: 2.28352
Timestep Consumption Time: 2.44861
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.73213

Cumulative Model Updates: 305,248
Cumulative Timesteps: 2,545,752,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.41551
Policy Entropy: 2.43898
Value Function Loss: 0.02128

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.10217
Policy Update Magnitude: 0.50498
Value Function Update Magnitude: 0.68651

Collected Steps per Second: 21,836.39536
Overall Steps per Second: 10,571.79188

Timestep Collection Time: 2.29076
Timestep Consumption Time: 2.44089
PPO Batch Consumption Time: 0.29679
Total Iteration Time: 4.73165

Cumulative Model Updates: 305,254
Cumulative Timesteps: 2,545,802,630

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2545802630...
Checkpoint 2545802630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.80343
Policy Entropy: 2.43863
Value Function Loss: 0.02130

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.10559
Policy Update Magnitude: 0.49863
Value Function Update Magnitude: 0.68003

Collected Steps per Second: 21,800.69790
Overall Steps per Second: 10,564.08033

Timestep Collection Time: 2.29451
Timestep Consumption Time: 2.44059
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.73510

Cumulative Model Updates: 305,260
Cumulative Timesteps: 2,545,852,652

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.98409
Policy Entropy: 2.45039
Value Function Loss: 0.02106

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.11062
Policy Update Magnitude: 0.49134
Value Function Update Magnitude: 0.65104

Collected Steps per Second: 22,183.05246
Overall Steps per Second: 10,311.49215

Timestep Collection Time: 2.25406
Timestep Consumption Time: 2.59509
PPO Batch Consumption Time: 0.30193
Total Iteration Time: 4.84915

Cumulative Model Updates: 305,266
Cumulative Timesteps: 2,545,902,654

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2545902654...
Checkpoint 2545902654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.54647
Policy Entropy: 2.46021
Value Function Loss: 0.02079

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.10240
Policy Update Magnitude: 0.49730
Value Function Update Magnitude: 0.63601

Collected Steps per Second: 21,440.36339
Overall Steps per Second: 10,327.90404

Timestep Collection Time: 2.33270
Timestep Consumption Time: 2.50991
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.84261

Cumulative Model Updates: 305,272
Cumulative Timesteps: 2,545,952,668

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.39118
Policy Entropy: 2.44808
Value Function Loss: 0.02030

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.09748
Policy Update Magnitude: 0.49948
Value Function Update Magnitude: 0.63082

Collected Steps per Second: 22,000.43674
Overall Steps per Second: 10,477.76751

Timestep Collection Time: 2.27323
Timestep Consumption Time: 2.49993
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.77315

Cumulative Model Updates: 305,278
Cumulative Timesteps: 2,546,002,680

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2546002680...
Checkpoint 2546002680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.26166
Policy Entropy: 2.42614
Value Function Loss: 0.02056

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.50364
Value Function Update Magnitude: 0.62939

Collected Steps per Second: 22,413.17516
Overall Steps per Second: 10,594.85579

Timestep Collection Time: 2.23208
Timestep Consumption Time: 2.48983
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.72191

Cumulative Model Updates: 305,284
Cumulative Timesteps: 2,546,052,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.45214
Policy Entropy: 2.40905
Value Function Loss: 0.02131

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.50496
Value Function Update Magnitude: 0.65233

Collected Steps per Second: 21,845.21490
Overall Steps per Second: 10,420.33728

Timestep Collection Time: 2.28975
Timestep Consumption Time: 2.51048
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.80023

Cumulative Model Updates: 305,290
Cumulative Timesteps: 2,546,102,728

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2546102728...
Checkpoint 2546102728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.50424
Policy Entropy: 2.41236
Value Function Loss: 0.02031

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.09840
Policy Update Magnitude: 0.50994
Value Function Update Magnitude: 0.69004

Collected Steps per Second: 21,325.44512
Overall Steps per Second: 10,251.30953

Timestep Collection Time: 2.34612
Timestep Consumption Time: 2.53443
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.88055

Cumulative Model Updates: 305,296
Cumulative Timesteps: 2,546,152,760

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.29356
Policy Entropy: 2.42101
Value Function Loss: 0.02033

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.09354
Policy Update Magnitude: 0.51202
Value Function Update Magnitude: 0.69289

Collected Steps per Second: 21,901.66608
Overall Steps per Second: 10,470.21147

Timestep Collection Time: 2.28375
Timestep Consumption Time: 2.49342
PPO Batch Consumption Time: 0.29871
Total Iteration Time: 4.77717

Cumulative Model Updates: 305,302
Cumulative Timesteps: 2,546,202,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2546202778...
Checkpoint 2546202778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.25160
Policy Entropy: 2.43234
Value Function Loss: 0.02012

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.09482
Policy Update Magnitude: 0.51091
Value Function Update Magnitude: 0.67697

Collected Steps per Second: 21,507.75549
Overall Steps per Second: 10,242.92536

Timestep Collection Time: 2.32577
Timestep Consumption Time: 2.55780
PPO Batch Consumption Time: 0.29960
Total Iteration Time: 4.88357

Cumulative Model Updates: 305,308
Cumulative Timesteps: 2,546,252,800

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.89931
Policy Entropy: 2.43245
Value Function Loss: 0.02121

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.09715
Policy Update Magnitude: 0.51020
Value Function Update Magnitude: 0.66474

Collected Steps per Second: 21,937.92775
Overall Steps per Second: 10,465.27094

Timestep Collection Time: 2.28062
Timestep Consumption Time: 2.50015
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.78076

Cumulative Model Updates: 305,314
Cumulative Timesteps: 2,546,302,832

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2546302832...
Checkpoint 2546302832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.41117
Policy Entropy: 2.42969
Value Function Loss: 0.02013

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.11070
Policy Update Magnitude: 0.49765
Value Function Update Magnitude: 0.64712

Collected Steps per Second: 21,347.97103
Overall Steps per Second: 10,247.22774

Timestep Collection Time: 2.34317
Timestep Consumption Time: 2.53834
PPO Batch Consumption Time: 0.29912
Total Iteration Time: 4.88152

Cumulative Model Updates: 305,320
Cumulative Timesteps: 2,546,352,854

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.19117
Policy Entropy: 2.43234
Value Function Loss: 0.02098

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.10439
Policy Update Magnitude: 0.48926
Value Function Update Magnitude: 0.63035

Collected Steps per Second: 22,047.90949
Overall Steps per Second: 10,576.16068

Timestep Collection Time: 2.26779
Timestep Consumption Time: 2.45982
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.72761

Cumulative Model Updates: 305,326
Cumulative Timesteps: 2,546,402,854

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2546402854...
Checkpoint 2546402854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.88971
Policy Entropy: 2.43036
Value Function Loss: 0.02044

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.09733
Policy Update Magnitude: 0.49160
Value Function Update Magnitude: 0.62666

Collected Steps per Second: 22,239.31502
Overall Steps per Second: 10,526.20014

Timestep Collection Time: 2.24890
Timestep Consumption Time: 2.50248
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.75138

Cumulative Model Updates: 305,332
Cumulative Timesteps: 2,546,452,868

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.41770
Policy Entropy: 2.44047
Value Function Loss: 0.02178

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.09693
Policy Update Magnitude: 0.49531
Value Function Update Magnitude: 0.63826

Collected Steps per Second: 22,464.07820
Overall Steps per Second: 10,520.94338

Timestep Collection Time: 2.22684
Timestep Consumption Time: 2.52786
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.75471

Cumulative Model Updates: 305,338
Cumulative Timesteps: 2,546,502,892

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2546502892...
Checkpoint 2546502892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.21801
Policy Entropy: 2.42080
Value Function Loss: 0.02022

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.09207
Policy Update Magnitude: 0.49322
Value Function Update Magnitude: 0.64983

Collected Steps per Second: 22,118.86090
Overall Steps per Second: 10,563.63765

Timestep Collection Time: 2.26079
Timestep Consumption Time: 2.47300
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.73379

Cumulative Model Updates: 305,344
Cumulative Timesteps: 2,546,552,898

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.68819
Policy Entropy: 2.41392
Value Function Loss: 0.02059

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.09106
Policy Update Magnitude: 0.50169
Value Function Update Magnitude: 0.64995

Collected Steps per Second: 23,123.37485
Overall Steps per Second: 10,873.79272

Timestep Collection Time: 2.16257
Timestep Consumption Time: 2.43619
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.59876

Cumulative Model Updates: 305,350
Cumulative Timesteps: 2,546,602,904

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2546602904...
Checkpoint 2546602904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.80387
Policy Entropy: 2.39627
Value Function Loss: 0.02068

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.09594
Policy Update Magnitude: 0.50466
Value Function Update Magnitude: 0.65298

Collected Steps per Second: 22,240.80293
Overall Steps per Second: 10,648.56494

Timestep Collection Time: 2.24821
Timestep Consumption Time: 2.44745
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.69566

Cumulative Model Updates: 305,356
Cumulative Timesteps: 2,546,652,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.54184
Policy Entropy: 2.38840
Value Function Loss: 0.02143

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.10642
Policy Update Magnitude: 0.48818
Value Function Update Magnitude: 0.66491

Collected Steps per Second: 22,177.48973
Overall Steps per Second: 10,473.53337

Timestep Collection Time: 2.25454
Timestep Consumption Time: 2.51940
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.77394

Cumulative Model Updates: 305,362
Cumulative Timesteps: 2,546,702,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2546702906...
Checkpoint 2546702906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.21642
Policy Entropy: 2.40090
Value Function Loss: 0.02071

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.12580
Policy Update Magnitude: 0.46378
Value Function Update Magnitude: 0.67936

Collected Steps per Second: 22,004.58350
Overall Steps per Second: 10,640.51071

Timestep Collection Time: 2.27289
Timestep Consumption Time: 2.42745
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.70034

Cumulative Model Updates: 305,368
Cumulative Timesteps: 2,546,752,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.15633
Policy Entropy: 2.39470
Value Function Loss: 0.02112

Mean KL Divergence: 0.02220
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.49875
Value Function Update Magnitude: 0.67993

Collected Steps per Second: 22,957.37333
Overall Steps per Second: 10,850.00445

Timestep Collection Time: 2.17839
Timestep Consumption Time: 2.43083
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.60921

Cumulative Model Updates: 305,374
Cumulative Timesteps: 2,546,802,930

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2546802930...
Checkpoint 2546802930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.34703
Policy Entropy: 2.42610
Value Function Loss: 0.02005

Mean KL Divergence: 0.02176
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.48177
Value Function Update Magnitude: 0.67552

Collected Steps per Second: 21,842.80706
Overall Steps per Second: 10,472.91976

Timestep Collection Time: 2.29027
Timestep Consumption Time: 2.48643
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.77670

Cumulative Model Updates: 305,380
Cumulative Timesteps: 2,546,852,956

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.14547
Policy Entropy: 2.41189
Value Function Loss: 0.02017

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.11044
Policy Update Magnitude: 0.48384
Value Function Update Magnitude: 0.66223

Collected Steps per Second: 22,402.05986
Overall Steps per Second: 10,674.67056

Timestep Collection Time: 2.23238
Timestep Consumption Time: 2.45254
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.68492

Cumulative Model Updates: 305,386
Cumulative Timesteps: 2,546,902,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2546902966...
Checkpoint 2546902966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.26721
Policy Entropy: 2.43004
Value Function Loss: 0.01971

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.48220
Value Function Update Magnitude: 0.66203

Collected Steps per Second: 21,761.35457
Overall Steps per Second: 10,631.24766

Timestep Collection Time: 2.29783
Timestep Consumption Time: 2.40566
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.70349

Cumulative Model Updates: 305,392
Cumulative Timesteps: 2,546,952,970

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.83658
Policy Entropy: 2.42481
Value Function Loss: 0.02089

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.09439
Policy Update Magnitude: 0.49063
Value Function Update Magnitude: 0.66328

Collected Steps per Second: 21,912.86431
Overall Steps per Second: 10,549.44477

Timestep Collection Time: 2.28359
Timestep Consumption Time: 2.45979
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.74338

Cumulative Model Updates: 305,398
Cumulative Timesteps: 2,547,003,010

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2547003010...
Checkpoint 2547003010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.99713
Policy Entropy: 2.44243
Value Function Loss: 0.02256

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.50834
Value Function Update Magnitude: 0.67227

Collected Steps per Second: 21,796.78248
Overall Steps per Second: 10,524.38103

Timestep Collection Time: 2.29465
Timestep Consumption Time: 2.45774
PPO Batch Consumption Time: 0.28193
Total Iteration Time: 4.75239

Cumulative Model Updates: 305,404
Cumulative Timesteps: 2,547,053,026

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.53345
Policy Entropy: 2.42586
Value Function Loss: 0.02223

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.09675
Policy Update Magnitude: 0.50309
Value Function Update Magnitude: 0.68245

Collected Steps per Second: 21,677.08750
Overall Steps per Second: 10,475.21887

Timestep Collection Time: 2.30741
Timestep Consumption Time: 2.46748
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.77489

Cumulative Model Updates: 305,410
Cumulative Timesteps: 2,547,103,044

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2547103044...
Checkpoint 2547103044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.43960
Policy Entropy: 2.44016
Value Function Loss: 0.02197

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.10094
Policy Update Magnitude: 0.50475
Value Function Update Magnitude: 0.68345

Collected Steps per Second: 21,623.17456
Overall Steps per Second: 10,400.89863

Timestep Collection Time: 2.31261
Timestep Consumption Time: 2.49524
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.80785

Cumulative Model Updates: 305,416
Cumulative Timesteps: 2,547,153,050

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.14851
Policy Entropy: 2.44568
Value Function Loss: 0.02083

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.10651
Policy Update Magnitude: 0.48565
Value Function Update Magnitude: 0.67409

Collected Steps per Second: 22,246.91630
Overall Steps per Second: 10,818.48653

Timestep Collection Time: 2.24768
Timestep Consumption Time: 2.37441
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.62209

Cumulative Model Updates: 305,422
Cumulative Timesteps: 2,547,203,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2547203054...
Checkpoint 2547203054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.33840
Policy Entropy: 2.46376
Value Function Loss: 0.02066

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.08977
Policy Update Magnitude: 0.47462
Value Function Update Magnitude: 0.64247

Collected Steps per Second: 22,092.28326
Overall Steps per Second: 10,561.84480

Timestep Collection Time: 2.26477
Timestep Consumption Time: 2.47247
PPO Batch Consumption Time: 0.28189
Total Iteration Time: 4.73724

Cumulative Model Updates: 305,428
Cumulative Timesteps: 2,547,253,088

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.18629
Policy Entropy: 2.45477
Value Function Loss: 0.02072

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.08710
Policy Update Magnitude: 0.47469
Value Function Update Magnitude: 0.62247

Collected Steps per Second: 21,758.19437
Overall Steps per Second: 10,480.41721

Timestep Collection Time: 2.29844
Timestep Consumption Time: 2.47331
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.77176

Cumulative Model Updates: 305,434
Cumulative Timesteps: 2,547,303,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2547303098...
Checkpoint 2547303098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.37031
Policy Entropy: 2.43992
Value Function Loss: 0.02062

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.09568
Policy Update Magnitude: 0.47021
Value Function Update Magnitude: 0.63581

Collected Steps per Second: 21,681.66760
Overall Steps per Second: 10,654.89057

Timestep Collection Time: 2.30656
Timestep Consumption Time: 2.38706
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.69362

Cumulative Model Updates: 305,440
Cumulative Timesteps: 2,547,353,108

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.74173
Policy Entropy: 2.42030
Value Function Loss: 0.02141

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.10119
Policy Update Magnitude: 0.48794
Value Function Update Magnitude: 0.65168

Collected Steps per Second: 22,410.08383
Overall Steps per Second: 10,469.48806

Timestep Collection Time: 2.23141
Timestep Consumption Time: 2.54495
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 4.77636

Cumulative Model Updates: 305,446
Cumulative Timesteps: 2,547,403,114

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2547403114...
Checkpoint 2547403114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.74841
Policy Entropy: 2.40924
Value Function Loss: 0.02301

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.10636
Policy Update Magnitude: 0.48965
Value Function Update Magnitude: 0.66912

Collected Steps per Second: 21,934.40582
Overall Steps per Second: 10,531.44103

Timestep Collection Time: 2.27998
Timestep Consumption Time: 2.46866
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.74864

Cumulative Model Updates: 305,452
Cumulative Timesteps: 2,547,453,124

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.40545
Policy Entropy: 2.41522
Value Function Loss: 0.02309

Mean KL Divergence: 0.02425
SB3 Clip Fraction: 0.13432
Policy Update Magnitude: 0.47278
Value Function Update Magnitude: 0.68615

Collected Steps per Second: 22,195.61718
Overall Steps per Second: 10,546.88513

Timestep Collection Time: 2.25396
Timestep Consumption Time: 2.48943
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.74339

Cumulative Model Updates: 305,458
Cumulative Timesteps: 2,547,503,152

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2547503152...
Checkpoint 2547503152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.94925
Policy Entropy: 2.43098
Value Function Loss: 0.02299

Mean KL Divergence: 0.02074
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.48493
Value Function Update Magnitude: 0.69340

Collected Steps per Second: 21,734.30527
Overall Steps per Second: 10,619.24702

Timestep Collection Time: 2.30134
Timestep Consumption Time: 2.40879
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.71013

Cumulative Model Updates: 305,464
Cumulative Timesteps: 2,547,553,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.80957
Policy Entropy: 2.44856
Value Function Loss: 0.02116

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.11483
Policy Update Magnitude: 0.50351
Value Function Update Magnitude: 0.70314

Collected Steps per Second: 22,209.30050
Overall Steps per Second: 10,438.84585

Timestep Collection Time: 2.25185
Timestep Consumption Time: 2.53910
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.79095

Cumulative Model Updates: 305,470
Cumulative Timesteps: 2,547,603,182

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2547603182...
Checkpoint 2547603182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.86475
Policy Entropy: 2.43407
Value Function Loss: 0.02081

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.11039
Policy Update Magnitude: 0.50591
Value Function Update Magnitude: 0.69214

Collected Steps per Second: 21,814.88203
Overall Steps per Second: 10,398.41526

Timestep Collection Time: 2.29348
Timestep Consumption Time: 2.51802
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.81150

Cumulative Model Updates: 305,476
Cumulative Timesteps: 2,547,653,214

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.61609
Policy Entropy: 2.43569
Value Function Loss: 0.02005

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.10762
Policy Update Magnitude: 0.54023
Value Function Update Magnitude: 0.66772

Collected Steps per Second: 22,019.76300
Overall Steps per Second: 10,611.78798

Timestep Collection Time: 2.27078
Timestep Consumption Time: 2.44115
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.71193

Cumulative Model Updates: 305,482
Cumulative Timesteps: 2,547,703,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2547703216...
Checkpoint 2547703216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.96768
Policy Entropy: 2.43141
Value Function Loss: 0.02032

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.10486
Policy Update Magnitude: 0.50540
Value Function Update Magnitude: 0.64094

Collected Steps per Second: 21,626.18314
Overall Steps per Second: 10,661.13304

Timestep Collection Time: 2.31312
Timestep Consumption Time: 2.37906
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.69218

Cumulative Model Updates: 305,488
Cumulative Timesteps: 2,547,753,240

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.41991
Policy Entropy: 2.44192
Value Function Loss: 0.02154

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.48508
Value Function Update Magnitude: 0.64798

Collected Steps per Second: 22,164.15538
Overall Steps per Second: 10,584.24978

Timestep Collection Time: 2.25698
Timestep Consumption Time: 2.46929
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.72627

Cumulative Model Updates: 305,494
Cumulative Timesteps: 2,547,803,264

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2547803264...
Checkpoint 2547803264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.23910
Policy Entropy: 2.44311
Value Function Loss: 0.02105

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.09567
Policy Update Magnitude: 0.47291
Value Function Update Magnitude: 0.65438

Collected Steps per Second: 21,642.03826
Overall Steps per Second: 10,322.24369

Timestep Collection Time: 2.31078
Timestep Consumption Time: 2.53410
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.84488

Cumulative Model Updates: 305,500
Cumulative Timesteps: 2,547,853,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.96578
Policy Entropy: 2.46919
Value Function Loss: 0.02074

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.48809
Value Function Update Magnitude: 0.65477

Collected Steps per Second: 22,023.56694
Overall Steps per Second: 10,636.70001

Timestep Collection Time: 2.27048
Timestep Consumption Time: 2.43061
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.70108

Cumulative Model Updates: 305,506
Cumulative Timesteps: 2,547,903,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2547903278...
Checkpoint 2547903278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.98510
Policy Entropy: 2.45679
Value Function Loss: 0.01943

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.09905
Policy Update Magnitude: 0.49052
Value Function Update Magnitude: 0.65145

Collected Steps per Second: 21,698.41100
Overall Steps per Second: 10,684.36769

Timestep Collection Time: 2.30533
Timestep Consumption Time: 2.37646
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.68179

Cumulative Model Updates: 305,512
Cumulative Timesteps: 2,547,953,300

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.72918
Policy Entropy: 2.43370
Value Function Loss: 0.01970

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.09979
Policy Update Magnitude: 0.48359
Value Function Update Magnitude: 0.64728

Collected Steps per Second: 21,673.50743
Overall Steps per Second: 10,460.80011

Timestep Collection Time: 2.30798
Timestep Consumption Time: 2.47387
PPO Batch Consumption Time: 0.28228
Total Iteration Time: 4.78185

Cumulative Model Updates: 305,518
Cumulative Timesteps: 2,548,003,322

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2548003322...
Checkpoint 2548003322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.61282
Policy Entropy: 2.42115
Value Function Loss: 0.02006

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.10648
Policy Update Magnitude: 0.48428
Value Function Update Magnitude: 0.66557

Collected Steps per Second: 21,753.33573
Overall Steps per Second: 10,443.53838

Timestep Collection Time: 2.30043
Timestep Consumption Time: 2.49124
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.79167

Cumulative Model Updates: 305,524
Cumulative Timesteps: 2,548,053,364

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.82072
Policy Entropy: 2.41605
Value Function Loss: 0.02017

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.10412
Policy Update Magnitude: 0.49728
Value Function Update Magnitude: 0.68374

Collected Steps per Second: 22,136.71692
Overall Steps per Second: 10,641.41659

Timestep Collection Time: 2.25878
Timestep Consumption Time: 2.44003
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.69881

Cumulative Model Updates: 305,530
Cumulative Timesteps: 2,548,103,366

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2548103366...
Checkpoint 2548103366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.42462
Policy Entropy: 2.44272
Value Function Loss: 0.02015

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.10410
Policy Update Magnitude: 0.50354
Value Function Update Magnitude: 0.67454

Collected Steps per Second: 22,123.93588
Overall Steps per Second: 10,635.94668

Timestep Collection Time: 2.26090
Timestep Consumption Time: 2.44202
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.70292

Cumulative Model Updates: 305,536
Cumulative Timesteps: 2,548,153,386

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.81373
Policy Entropy: 2.43432
Value Function Loss: 0.02115

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.10406
Policy Update Magnitude: 0.50819
Value Function Update Magnitude: 0.67569

Collected Steps per Second: 22,077.37553
Overall Steps per Second: 10,536.86986

Timestep Collection Time: 2.26712
Timestep Consumption Time: 2.48306
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.75018

Cumulative Model Updates: 305,542
Cumulative Timesteps: 2,548,203,438

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 2548203438...
Checkpoint 2548203438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.66743
Policy Entropy: 2.42614
Value Function Loss: 0.02201

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.11133
Policy Update Magnitude: 0.51261
Value Function Update Magnitude: 0.68351

Collected Steps per Second: 21,607.43937
Overall Steps per Second: 10,404.82468

Timestep Collection Time: 2.31504
Timestep Consumption Time: 2.49254
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.80758

Cumulative Model Updates: 305,548
Cumulative Timesteps: 2,548,253,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.60342
Policy Entropy: 2.41112
Value Function Loss: 0.02201

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.10937
Policy Update Magnitude: 0.51656
Value Function Update Magnitude: 0.65953

Collected Steps per Second: 22,221.45996
Overall Steps per Second: 10,725.72832

Timestep Collection Time: 2.25062
Timestep Consumption Time: 2.41219
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.66281

Cumulative Model Updates: 305,554
Cumulative Timesteps: 2,548,303,472

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2548303472...
Checkpoint 2548303472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.41648
Policy Entropy: 2.40682
Value Function Loss: 0.02144

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.09967
Policy Update Magnitude: 0.50746
Value Function Update Magnitude: 0.63857

Collected Steps per Second: 21,918.86560
Overall Steps per Second: 10,350.61268

Timestep Collection Time: 2.28324
Timestep Consumption Time: 2.55184
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.83508

Cumulative Model Updates: 305,560
Cumulative Timesteps: 2,548,353,518

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.74159
Policy Entropy: 2.41578
Value Function Loss: 0.02099

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.09838
Policy Update Magnitude: 0.50700
Value Function Update Magnitude: 0.64847

Collected Steps per Second: 22,394.45588
Overall Steps per Second: 10,499.72387

Timestep Collection Time: 2.23314
Timestep Consumption Time: 2.52984
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.76298

Cumulative Model Updates: 305,566
Cumulative Timesteps: 2,548,403,528

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2548403528...
Checkpoint 2548403528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.49709
Policy Entropy: 2.42200
Value Function Loss: 0.02118

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.09755
Policy Update Magnitude: 0.51049
Value Function Update Magnitude: 0.65552

Collected Steps per Second: 21,729.45555
Overall Steps per Second: 10,435.63180

Timestep Collection Time: 2.30112
Timestep Consumption Time: 2.49035
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.79147

Cumulative Model Updates: 305,572
Cumulative Timesteps: 2,548,453,530

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.98023
Policy Entropy: 2.42467
Value Function Loss: 0.02147

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.10086
Policy Update Magnitude: 0.49834
Value Function Update Magnitude: 0.66027

Collected Steps per Second: 22,127.10283
Overall Steps per Second: 10,637.63910

Timestep Collection Time: 2.25994
Timestep Consumption Time: 2.44091
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.70086

Cumulative Model Updates: 305,578
Cumulative Timesteps: 2,548,503,536

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2548503536...
Checkpoint 2548503536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.64278
Policy Entropy: 2.44928
Value Function Loss: 0.02087

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.09058
Policy Update Magnitude: 0.49645
Value Function Update Magnitude: 0.66596

Collected Steps per Second: 21,910.82336
Overall Steps per Second: 10,472.67761

Timestep Collection Time: 2.28298
Timestep Consumption Time: 2.49345
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.77643

Cumulative Model Updates: 305,584
Cumulative Timesteps: 2,548,553,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.52289
Policy Entropy: 2.43793
Value Function Loss: 0.01973

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.08299
Policy Update Magnitude: 0.50067
Value Function Update Magnitude: 0.65999

Collected Steps per Second: 22,144.28272
Overall Steps per Second: 10,416.47702

Timestep Collection Time: 2.25819
Timestep Consumption Time: 2.54247
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.80066

Cumulative Model Updates: 305,590
Cumulative Timesteps: 2,548,603,564

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2548603564...
Checkpoint 2548603564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.37677
Policy Entropy: 2.43059
Value Function Loss: 0.02011

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.09078
Policy Update Magnitude: 0.49490
Value Function Update Magnitude: 0.66411

Collected Steps per Second: 21,742.78976
Overall Steps per Second: 10,560.36934

Timestep Collection Time: 2.30026
Timestep Consumption Time: 2.43575
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.73601

Cumulative Model Updates: 305,596
Cumulative Timesteps: 2,548,653,578

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.27618
Policy Entropy: 2.41132
Value Function Loss: 0.01978

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.08608
Policy Update Magnitude: 0.48678
Value Function Update Magnitude: 0.66733

Collected Steps per Second: 22,164.35002
Overall Steps per Second: 10,599.94304

Timestep Collection Time: 2.25624
Timestep Consumption Time: 2.46153
PPO Batch Consumption Time: 0.29517
Total Iteration Time: 4.71776

Cumulative Model Updates: 305,602
Cumulative Timesteps: 2,548,703,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2548703586...
Checkpoint 2548703586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.66713
Policy Entropy: 2.38928
Value Function Loss: 0.02012

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.08834
Policy Update Magnitude: 0.48786
Value Function Update Magnitude: 0.65653

Collected Steps per Second: 22,025.43532
Overall Steps per Second: 10,555.71031

Timestep Collection Time: 2.27028
Timestep Consumption Time: 2.46687
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.73715

Cumulative Model Updates: 305,608
Cumulative Timesteps: 2,548,753,590

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.43126
Policy Entropy: 2.39367
Value Function Loss: 0.01956

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.08456
Policy Update Magnitude: 0.48631
Value Function Update Magnitude: 0.65918

Collected Steps per Second: 22,014.52096
Overall Steps per Second: 10,436.21784

Timestep Collection Time: 2.27259
Timestep Consumption Time: 2.52129
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.79388

Cumulative Model Updates: 305,614
Cumulative Timesteps: 2,548,803,620

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2548803620...
Checkpoint 2548803620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.94033
Policy Entropy: 2.41006
Value Function Loss: 0.02003

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.09239
Policy Update Magnitude: 0.49451
Value Function Update Magnitude: 0.67479

Collected Steps per Second: 21,808.69492
Overall Steps per Second: 10,704.61145

Timestep Collection Time: 2.29331
Timestep Consumption Time: 2.37889
PPO Batch Consumption Time: 0.28150
Total Iteration Time: 4.67219

Cumulative Model Updates: 305,620
Cumulative Timesteps: 2,548,853,634

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.98553
Policy Entropy: 2.45174
Value Function Loss: 0.02080

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.49165
Value Function Update Magnitude: 0.68312

Collected Steps per Second: 22,229.97090
Overall Steps per Second: 10,498.26410

Timestep Collection Time: 2.24985
Timestep Consumption Time: 2.51418
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.76403

Cumulative Model Updates: 305,626
Cumulative Timesteps: 2,548,903,648

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2548903648...
Checkpoint 2548903648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.10452
Policy Entropy: 2.45571
Value Function Loss: 0.02026

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.09746
Policy Update Magnitude: 0.49592
Value Function Update Magnitude: 0.69495

Collected Steps per Second: 21,690.71434
Overall Steps per Second: 10,376.15017

Timestep Collection Time: 2.30587
Timestep Consumption Time: 2.51441
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.82028

Cumulative Model Updates: 305,632
Cumulative Timesteps: 2,548,953,664

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.03420
Policy Entropy: 2.41824
Value Function Loss: 0.02087

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.09275
Policy Update Magnitude: 0.49478
Value Function Update Magnitude: 0.70795

Collected Steps per Second: 21,963.60318
Overall Steps per Second: 10,607.36356

Timestep Collection Time: 2.27831
Timestep Consumption Time: 2.43916
PPO Batch Consumption Time: 0.28178
Total Iteration Time: 4.71748

Cumulative Model Updates: 305,638
Cumulative Timesteps: 2,549,003,704

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2549003704...
Checkpoint 2549003704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.73621
Policy Entropy: 2.39820
Value Function Loss: 0.02031

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.50314
Value Function Update Magnitude: 0.69747

Collected Steps per Second: 21,774.32204
Overall Steps per Second: 10,424.50169

Timestep Collection Time: 2.29656
Timestep Consumption Time: 2.50041
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.79697

Cumulative Model Updates: 305,644
Cumulative Timesteps: 2,549,053,710

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.07618
Policy Entropy: 2.39906
Value Function Loss: 0.02170

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.09135
Policy Update Magnitude: 0.49643
Value Function Update Magnitude: 0.69524

Collected Steps per Second: 22,888.80014
Overall Steps per Second: 10,748.80497

Timestep Collection Time: 2.18526
Timestep Consumption Time: 2.46809
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.65335

Cumulative Model Updates: 305,650
Cumulative Timesteps: 2,549,103,728

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2549103728...
Checkpoint 2549103728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.50761
Policy Entropy: 2.40343
Value Function Loss: 0.02063

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.09347
Policy Update Magnitude: 0.49661
Value Function Update Magnitude: 0.69291

Collected Steps per Second: 21,900.74637
Overall Steps per Second: 10,439.01716

Timestep Collection Time: 2.28339
Timestep Consumption Time: 2.50710
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.79049

Cumulative Model Updates: 305,656
Cumulative Timesteps: 2,549,153,736

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.67142
Policy Entropy: 2.40777
Value Function Loss: 0.02107

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.49987
Value Function Update Magnitude: 0.68845

Collected Steps per Second: 22,000.61029
Overall Steps per Second: 10,576.08387

Timestep Collection Time: 2.27366
Timestep Consumption Time: 2.45606
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.72973

Cumulative Model Updates: 305,662
Cumulative Timesteps: 2,549,203,758

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2549203758...
Checkpoint 2549203758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.55927
Policy Entropy: 2.41831
Value Function Loss: 0.02190

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.10263
Policy Update Magnitude: 0.51218
Value Function Update Magnitude: 0.68710

Collected Steps per Second: 20,872.52216
Overall Steps per Second: 10,273.04011

Timestep Collection Time: 2.39684
Timestep Consumption Time: 2.47300
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.86983

Cumulative Model Updates: 305,668
Cumulative Timesteps: 2,549,253,786

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.21236
Policy Entropy: 2.42348
Value Function Loss: 0.02172

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.11331
Policy Update Magnitude: 0.48948
Value Function Update Magnitude: 0.68396

Collected Steps per Second: 21,992.88761
Overall Steps per Second: 10,553.61971

Timestep Collection Time: 2.27474
Timestep Consumption Time: 2.46563
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.74036

Cumulative Model Updates: 305,674
Cumulative Timesteps: 2,549,303,814

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2549303814...
Checkpoint 2549303814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.64375
Policy Entropy: 2.40634
Value Function Loss: 0.02256

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.12467
Policy Update Magnitude: 0.45970
Value Function Update Magnitude: 0.68206

Collected Steps per Second: 21,834.66278
Overall Steps per Second: 10,532.45721

Timestep Collection Time: 2.28994
Timestep Consumption Time: 2.45729
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.74723

Cumulative Model Updates: 305,680
Cumulative Timesteps: 2,549,353,814

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.69138
Policy Entropy: 2.39840
Value Function Loss: 0.02247

Mean KL Divergence: 0.02398
SB3 Clip Fraction: 0.12966
Policy Update Magnitude: 0.44791
Value Function Update Magnitude: 0.68271

Collected Steps per Second: 21,940.84751
Overall Steps per Second: 10,501.76315

Timestep Collection Time: 2.28013
Timestep Consumption Time: 2.48364
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.76377

Cumulative Model Updates: 305,686
Cumulative Timesteps: 2,549,403,842

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2549403842...
Checkpoint 2549403842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.14387
Policy Entropy: 2.40283
Value Function Loss: 0.02299

Mean KL Divergence: 0.02320
SB3 Clip Fraction: 0.12089
Policy Update Magnitude: 0.46883
Value Function Update Magnitude: 0.67230

Collected Steps per Second: 22,565.11119
Overall Steps per Second: 10,677.75367

Timestep Collection Time: 2.21679
Timestep Consumption Time: 2.46791
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.68469

Cumulative Model Updates: 305,692
Cumulative Timesteps: 2,549,453,864

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.81726
Policy Entropy: 2.37973
Value Function Loss: 0.02217

Mean KL Divergence: 0.02282
SB3 Clip Fraction: 0.12813
Policy Update Magnitude: 0.48959
Value Function Update Magnitude: 0.66237

Collected Steps per Second: 21,628.08755
Overall Steps per Second: 10,430.10500

Timestep Collection Time: 2.31199
Timestep Consumption Time: 2.48221
PPO Batch Consumption Time: 0.28183
Total Iteration Time: 4.79420

Cumulative Model Updates: 305,698
Cumulative Timesteps: 2,549,503,868

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2549503868...
Checkpoint 2549503868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.23882
Policy Entropy: 2.37797
Value Function Loss: 0.02175

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.11824
Policy Update Magnitude: 0.50211
Value Function Update Magnitude: 0.66474

Collected Steps per Second: 21,602.63816
Overall Steps per Second: 10,387.67365

Timestep Collection Time: 2.31564
Timestep Consumption Time: 2.50006
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.81571

Cumulative Model Updates: 305,704
Cumulative Timesteps: 2,549,553,892

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.38309
Policy Entropy: 2.37741
Value Function Loss: 0.02208

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.11662
Policy Update Magnitude: 0.50627
Value Function Update Magnitude: 0.68891

Collected Steps per Second: 22,094.33432
Overall Steps per Second: 10,734.64981

Timestep Collection Time: 2.26302
Timestep Consumption Time: 2.39479
PPO Batch Consumption Time: 0.28153
Total Iteration Time: 4.65781

Cumulative Model Updates: 305,710
Cumulative Timesteps: 2,549,603,892

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2549603892...
Checkpoint 2549603892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.75699
Policy Entropy: 2.41593
Value Function Loss: 0.02263

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.11668
Policy Update Magnitude: 0.50539
Value Function Update Magnitude: 0.70122

Collected Steps per Second: 22,138.50367
Overall Steps per Second: 10,583.53425

Timestep Collection Time: 2.25905
Timestep Consumption Time: 2.46640
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.72545

Cumulative Model Updates: 305,716
Cumulative Timesteps: 2,549,653,904

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.39300
Policy Entropy: 2.42612
Value Function Loss: 0.02299

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.10605
Policy Update Magnitude: 0.50418
Value Function Update Magnitude: 0.70963

Collected Steps per Second: 22,008.40005
Overall Steps per Second: 10,566.14583

Timestep Collection Time: 2.27268
Timestep Consumption Time: 2.46112
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.73380

Cumulative Model Updates: 305,722
Cumulative Timesteps: 2,549,703,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2549703922...
Checkpoint 2549703922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.77274
Policy Entropy: 2.43931
Value Function Loss: 0.02323

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.11565
Policy Update Magnitude: 0.50045
Value Function Update Magnitude: 0.71294

Collected Steps per Second: 22,091.05950
Overall Steps per Second: 10,653.82304

Timestep Collection Time: 2.26553
Timestep Consumption Time: 2.43212
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.69766

Cumulative Model Updates: 305,728
Cumulative Timesteps: 2,549,753,970

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.00052
Policy Entropy: 2.43521
Value Function Loss: 0.02275

Mean KL Divergence: 0.02162
SB3 Clip Fraction: 0.13372
Policy Update Magnitude: 0.47014
Value Function Update Magnitude: 0.69073

Collected Steps per Second: 22,031.01296
Overall Steps per Second: 10,614.12701

Timestep Collection Time: 2.27080
Timestep Consumption Time: 2.44254
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.71334

Cumulative Model Updates: 305,734
Cumulative Timesteps: 2,549,803,998

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2549803998...
Checkpoint 2549803998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.89741
Policy Entropy: 2.44512
Value Function Loss: 0.02251

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.12573
Policy Update Magnitude: 0.46464
Value Function Update Magnitude: 0.67203

Collected Steps per Second: 22,299.24184
Overall Steps per Second: 10,467.65501

Timestep Collection Time: 2.24304
Timestep Consumption Time: 2.53530
PPO Batch Consumption Time: 0.29566
Total Iteration Time: 4.77834

Cumulative Model Updates: 305,740
Cumulative Timesteps: 2,549,854,016

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.00413
Policy Entropy: 2.44188
Value Function Loss: 0.02114

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.11025
Policy Update Magnitude: 0.47532
Value Function Update Magnitude: 0.65982

Collected Steps per Second: 21,907.00376
Overall Steps per Second: 10,442.47639

Timestep Collection Time: 2.28247
Timestep Consumption Time: 2.50586
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.78833

Cumulative Model Updates: 305,746
Cumulative Timesteps: 2,549,904,018

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2549904018...
Checkpoint 2549904018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.53682
Policy Entropy: 2.43777
Value Function Loss: 0.02163

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.09700
Policy Update Magnitude: 0.48335
Value Function Update Magnitude: 0.64661

Collected Steps per Second: 21,772.05456
Overall Steps per Second: 10,552.79601

Timestep Collection Time: 2.29698
Timestep Consumption Time: 2.44205
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.73903

Cumulative Model Updates: 305,752
Cumulative Timesteps: 2,549,954,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.67876
Policy Entropy: 2.45003
Value Function Loss: 0.02108

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.10177
Policy Update Magnitude: 0.49208
Value Function Update Magnitude: 0.63751

Collected Steps per Second: 21,832.39476
Overall Steps per Second: 10,506.45112

Timestep Collection Time: 2.29036
Timestep Consumption Time: 2.46900
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.75936

Cumulative Model Updates: 305,758
Cumulative Timesteps: 2,550,004,032

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2550004032...
Checkpoint 2550004032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.26222
Policy Entropy: 2.43452
Value Function Loss: 0.02183

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.09438
Policy Update Magnitude: 0.49507
Value Function Update Magnitude: 0.64444

Collected Steps per Second: 22,196.13493
Overall Steps per Second: 10,492.19292

Timestep Collection Time: 2.25355
Timestep Consumption Time: 2.51381
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.76735

Cumulative Model Updates: 305,764
Cumulative Timesteps: 2,550,054,052

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.45001
Policy Entropy: 2.42078
Value Function Loss: 0.02088

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.10132
Policy Update Magnitude: 0.47634
Value Function Update Magnitude: 0.66308

Collected Steps per Second: 22,073.13469
Overall Steps per Second: 10,457.76412

Timestep Collection Time: 2.26556
Timestep Consumption Time: 2.51634
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.78190

Cumulative Model Updates: 305,770
Cumulative Timesteps: 2,550,104,060

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2550104060...
Checkpoint 2550104060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.32742
Policy Entropy: 2.39530
Value Function Loss: 0.02167

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.09519
Policy Update Magnitude: 0.47331
Value Function Update Magnitude: 0.66297

Collected Steps per Second: 22,089.23432
Overall Steps per Second: 10,477.78819

Timestep Collection Time: 2.26400
Timestep Consumption Time: 2.50896
PPO Batch Consumption Time: 0.29610
Total Iteration Time: 4.77295

Cumulative Model Updates: 305,776
Cumulative Timesteps: 2,550,154,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.71424
Policy Entropy: 2.40381
Value Function Loss: 0.02207

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.09084
Policy Update Magnitude: 0.49603
Value Function Update Magnitude: 0.66411

Collected Steps per Second: 22,511.42304
Overall Steps per Second: 10,527.37554

Timestep Collection Time: 2.22172
Timestep Consumption Time: 2.52914
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.75085

Cumulative Model Updates: 305,782
Cumulative Timesteps: 2,550,204,084

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2550204084...
Checkpoint 2550204084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.66357
Policy Entropy: 2.40613
Value Function Loss: 0.02250

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.49909
Value Function Update Magnitude: 0.67951

Collected Steps per Second: 22,029.20177
Overall Steps per Second: 10,495.41030

Timestep Collection Time: 2.27099
Timestep Consumption Time: 2.49567
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.76665

Cumulative Model Updates: 305,788
Cumulative Timesteps: 2,550,254,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.51982
Policy Entropy: 2.40334
Value Function Loss: 0.02204

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.09723
Policy Update Magnitude: 0.49511
Value Function Update Magnitude: 0.68767

Collected Steps per Second: 21,672.17561
Overall Steps per Second: 10,478.01454

Timestep Collection Time: 2.30831
Timestep Consumption Time: 2.46607
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.77438

Cumulative Model Updates: 305,794
Cumulative Timesteps: 2,550,304,138

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2550304138...
Checkpoint 2550304138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.16506
Policy Entropy: 2.40610
Value Function Loss: 0.02141

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.09258
Policy Update Magnitude: 0.48872
Value Function Update Magnitude: 0.66418

Collected Steps per Second: 21,946.55019
Overall Steps per Second: 10,666.10600

Timestep Collection Time: 2.27917
Timestep Consumption Time: 2.41045
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.68962

Cumulative Model Updates: 305,800
Cumulative Timesteps: 2,550,354,158

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.97949
Policy Entropy: 2.41920
Value Function Loss: 0.02160

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.48719
Value Function Update Magnitude: 0.66115

Collected Steps per Second: 22,037.15194
Overall Steps per Second: 10,440.68628

Timestep Collection Time: 2.26917
Timestep Consumption Time: 2.52036
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.78953

Cumulative Model Updates: 305,806
Cumulative Timesteps: 2,550,404,164

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2550404164...
Checkpoint 2550404164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.48337
Policy Entropy: 2.41219
Value Function Loss: 0.02113

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.09255
Policy Update Magnitude: 0.49009
Value Function Update Magnitude: 0.69829

Collected Steps per Second: 21,842.53471
Overall Steps per Second: 10,539.99333

Timestep Collection Time: 2.28994
Timestep Consumption Time: 2.45561
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.74554

Cumulative Model Updates: 305,812
Cumulative Timesteps: 2,550,454,182

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.59082
Policy Entropy: 2.39558
Value Function Loss: 0.02061

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.09258
Policy Update Magnitude: 0.49169
Value Function Update Magnitude: 0.70555

Collected Steps per Second: 21,319.58720
Overall Steps per Second: 10,477.83460

Timestep Collection Time: 2.34554
Timestep Consumption Time: 2.42701
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.77255

Cumulative Model Updates: 305,818
Cumulative Timesteps: 2,550,504,188

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2550504188...
Checkpoint 2550504188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.29996
Policy Entropy: 2.39669
Value Function Loss: 0.01994

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.10341
Policy Update Magnitude: 0.49241
Value Function Update Magnitude: 0.68053

Collected Steps per Second: 21,941.23988
Overall Steps per Second: 10,768.65820

Timestep Collection Time: 2.27918
Timestep Consumption Time: 2.36467
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.64385

Cumulative Model Updates: 305,824
Cumulative Timesteps: 2,550,554,196

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.65702
Policy Entropy: 2.41657
Value Function Loss: 0.02089

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.12053
Policy Update Magnitude: 0.49398
Value Function Update Magnitude: 0.67588

Collected Steps per Second: 22,157.10096
Overall Steps per Second: 10,427.00293

Timestep Collection Time: 2.25688
Timestep Consumption Time: 2.53893
PPO Batch Consumption Time: 0.29564
Total Iteration Time: 4.79582

Cumulative Model Updates: 305,830
Cumulative Timesteps: 2,550,604,202

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2550604202...
Checkpoint 2550604202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.15649
Policy Entropy: 2.41433
Value Function Loss: 0.02242

Mean KL Divergence: 0.02439
SB3 Clip Fraction: 0.13752
Policy Update Magnitude: 0.50530
Value Function Update Magnitude: 0.69376

Collected Steps per Second: 22,140.61379
Overall Steps per Second: 10,581.25541

Timestep Collection Time: 2.25884
Timestep Consumption Time: 2.46764
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.72647

Cumulative Model Updates: 305,836
Cumulative Timesteps: 2,550,654,214

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.30544
Policy Entropy: 2.40688
Value Function Loss: 0.02186

Mean KL Divergence: 0.02398
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.49235
Value Function Update Magnitude: 0.70414

Collected Steps per Second: 21,811.65564
Overall Steps per Second: 10,544.20747

Timestep Collection Time: 2.29309
Timestep Consumption Time: 2.45037
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.74346

Cumulative Model Updates: 305,842
Cumulative Timesteps: 2,550,704,230

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2550704230...
Checkpoint 2550704230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.56641
Policy Entropy: 2.40535
Value Function Loss: 0.02077

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.11940
Policy Update Magnitude: 0.49752
Value Function Update Magnitude: 0.70292

Collected Steps per Second: 21,821.68204
Overall Steps per Second: 10,599.49915

Timestep Collection Time: 2.29222
Timestep Consumption Time: 2.42688
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.71909

Cumulative Model Updates: 305,848
Cumulative Timesteps: 2,550,754,250

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.10510
Policy Entropy: 2.43676
Value Function Loss: 0.01984

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.11431
Policy Update Magnitude: 0.47643
Value Function Update Magnitude: 0.66927

Collected Steps per Second: 21,889.92377
Overall Steps per Second: 10,398.67277

Timestep Collection Time: 2.28434
Timestep Consumption Time: 2.52435
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.80869

Cumulative Model Updates: 305,854
Cumulative Timesteps: 2,550,804,254

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2550804254...
Checkpoint 2550804254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.36599
Policy Entropy: 2.44275
Value Function Loss: 0.02080

Mean KL Divergence: 0.02185
SB3 Clip Fraction: 0.13735
Policy Update Magnitude: 0.45606
Value Function Update Magnitude: 0.63984

Collected Steps per Second: 21,871.25307
Overall Steps per Second: 10,417.84223

Timestep Collection Time: 2.28720
Timestep Consumption Time: 2.51456
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.80176

Cumulative Model Updates: 305,860
Cumulative Timesteps: 2,550,854,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.73998
Policy Entropy: 2.44416
Value Function Loss: 0.02176

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.11827
Policy Update Magnitude: 0.48126
Value Function Update Magnitude: 0.64384

Collected Steps per Second: 21,833.95249
Overall Steps per Second: 10,409.18930

Timestep Collection Time: 2.29111
Timestep Consumption Time: 2.51464
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.80575

Cumulative Model Updates: 305,866
Cumulative Timesteps: 2,550,904,302

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2550904302...
Checkpoint 2550904302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.96235
Policy Entropy: 2.43154
Value Function Loss: 0.02134

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.11016
Policy Update Magnitude: 0.50405
Value Function Update Magnitude: 0.67286

Collected Steps per Second: 22,595.49946
Overall Steps per Second: 10,537.86618

Timestep Collection Time: 2.21389
Timestep Consumption Time: 2.53318
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.74707

Cumulative Model Updates: 305,872
Cumulative Timesteps: 2,550,954,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.89604
Policy Entropy: 2.44260
Value Function Loss: 0.02108

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.10105
Policy Update Magnitude: 0.50238
Value Function Update Magnitude: 0.67495

Collected Steps per Second: 21,987.11328
Overall Steps per Second: 10,462.14385

Timestep Collection Time: 2.27461
Timestep Consumption Time: 2.50568
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.78028

Cumulative Model Updates: 305,878
Cumulative Timesteps: 2,551,004,338

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2551004338...
Checkpoint 2551004338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.74603
Policy Entropy: 2.42183
Value Function Loss: 0.02137

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.08944
Policy Update Magnitude: 0.50251
Value Function Update Magnitude: 0.66108

Collected Steps per Second: 21,909.27116
Overall Steps per Second: 10,528.86129

Timestep Collection Time: 2.28278
Timestep Consumption Time: 2.46740
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.75018

Cumulative Model Updates: 305,884
Cumulative Timesteps: 2,551,054,352

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.62568
Policy Entropy: 2.43466
Value Function Loss: 0.02206

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.09427
Policy Update Magnitude: 0.50005
Value Function Update Magnitude: 0.66190

Collected Steps per Second: 21,845.28214
Overall Steps per Second: 10,529.77740

Timestep Collection Time: 2.28965
Timestep Consumption Time: 2.46050
PPO Batch Consumption Time: 0.28153
Total Iteration Time: 4.75015

Cumulative Model Updates: 305,890
Cumulative Timesteps: 2,551,104,370

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2551104370...
Checkpoint 2551104370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.76270
Policy Entropy: 2.44216
Value Function Loss: 0.02143

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.48872
Value Function Update Magnitude: 0.66221

Collected Steps per Second: 22,732.79968
Overall Steps per Second: 10,653.73335

Timestep Collection Time: 2.20078
Timestep Consumption Time: 2.49522
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.69601

Cumulative Model Updates: 305,896
Cumulative Timesteps: 2,551,154,400

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.22609
Policy Entropy: 2.43530
Value Function Loss: 0.02200

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.11388
Policy Update Magnitude: 0.49143
Value Function Update Magnitude: 0.66561

Collected Steps per Second: 22,003.60659
Overall Steps per Second: 10,476.60751

Timestep Collection Time: 2.27317
Timestep Consumption Time: 2.50108
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.77426

Cumulative Model Updates: 305,902
Cumulative Timesteps: 2,551,204,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2551204418...
Checkpoint 2551204418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.15585
Policy Entropy: 2.42782
Value Function Loss: 0.02223

Mean KL Divergence: 0.02951
SB3 Clip Fraction: 0.14476
Policy Update Magnitude: 0.50061
Value Function Update Magnitude: 0.69951

Collected Steps per Second: 21,973.26375
Overall Steps per Second: 10,559.21734

Timestep Collection Time: 2.27622
Timestep Consumption Time: 2.46049
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.73671

Cumulative Model Updates: 305,908
Cumulative Timesteps: 2,551,254,434

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.37469
Policy Entropy: 2.41783
Value Function Loss: 0.02237

Mean KL Divergence: 0.03115
SB3 Clip Fraction: 0.15062
Policy Update Magnitude: 0.47137
Value Function Update Magnitude: 0.69085

Collected Steps per Second: 21,888.53867
Overall Steps per Second: 10,549.63800

Timestep Collection Time: 2.28531
Timestep Consumption Time: 2.45628
PPO Batch Consumption Time: 0.29584
Total Iteration Time: 4.74158

Cumulative Model Updates: 305,914
Cumulative Timesteps: 2,551,304,456

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2551304456...
Checkpoint 2551304456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.26673
Policy Entropy: 2.44629
Value Function Loss: 0.02149

Mean KL Divergence: 0.02679
SB3 Clip Fraction: 0.14481
Policy Update Magnitude: 0.47982
Value Function Update Magnitude: 0.66450

Collected Steps per Second: 22,056.25500
Overall Steps per Second: 10,602.87363

Timestep Collection Time: 2.26784
Timestep Consumption Time: 2.44975
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.71759

Cumulative Model Updates: 305,920
Cumulative Timesteps: 2,551,354,476

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.53695
Policy Entropy: 2.44806
Value Function Loss: 0.02047

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.11783
Policy Update Magnitude: 0.49771
Value Function Update Magnitude: 0.65745

Collected Steps per Second: 22,051.08899
Overall Steps per Second: 10,463.71347

Timestep Collection Time: 2.26819
Timestep Consumption Time: 2.51176
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.77995

Cumulative Model Updates: 305,926
Cumulative Timesteps: 2,551,404,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2551404492...
Checkpoint 2551404492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.20326
Policy Entropy: 2.45259
Value Function Loss: 0.02007

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.11641
Policy Update Magnitude: 0.49822
Value Function Update Magnitude: 0.66108

Collected Steps per Second: 21,650.89831
Overall Steps per Second: 10,540.52253

Timestep Collection Time: 2.31011
Timestep Consumption Time: 2.43500
PPO Batch Consumption Time: 0.28197
Total Iteration Time: 4.74512

Cumulative Model Updates: 305,932
Cumulative Timesteps: 2,551,454,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.23610
Policy Entropy: 2.44270
Value Function Loss: 0.02011

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.10505
Policy Update Magnitude: 0.49744
Value Function Update Magnitude: 0.67294

Collected Steps per Second: 21,832.50488
Overall Steps per Second: 10,549.25402

Timestep Collection Time: 2.29108
Timestep Consumption Time: 2.45049
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.74157

Cumulative Model Updates: 305,938
Cumulative Timesteps: 2,551,504,528

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2551504528...
Checkpoint 2551504528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.90173
Policy Entropy: 2.44257
Value Function Loss: 0.02084

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.09694
Policy Update Magnitude: 0.50215
Value Function Update Magnitude: 0.69452

Collected Steps per Second: 22,072.14567
Overall Steps per Second: 10,566.40466

Timestep Collection Time: 2.26630
Timestep Consumption Time: 2.46777
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.73406

Cumulative Model Updates: 305,944
Cumulative Timesteps: 2,551,554,550

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.41777
Policy Entropy: 2.42889
Value Function Loss: 0.02196

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.09765
Policy Update Magnitude: 0.50333
Value Function Update Magnitude: 0.70689

Collected Steps per Second: 22,057.08304
Overall Steps per Second: 10,568.03517

Timestep Collection Time: 2.26694
Timestep Consumption Time: 2.46450
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.73144

Cumulative Model Updates: 305,950
Cumulative Timesteps: 2,551,604,552

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2551604552...
Checkpoint 2551604552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.17278
Policy Entropy: 2.42312
Value Function Loss: 0.02199

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.10820
Policy Update Magnitude: 0.48905
Value Function Update Magnitude: 0.69989

Collected Steps per Second: 21,713.39585
Overall Steps per Second: 10,489.51262

Timestep Collection Time: 2.30328
Timestep Consumption Time: 2.46453
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.76781

Cumulative Model Updates: 305,956
Cumulative Timesteps: 2,551,654,564

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.47967
Policy Entropy: 2.40857
Value Function Loss: 0.02183

Mean KL Divergence: 0.02297
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.45503
Value Function Update Magnitude: 0.69219

Collected Steps per Second: 21,911.08580
Overall Steps per Second: 10,584.28051

Timestep Collection Time: 2.28277
Timestep Consumption Time: 2.44292
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.72569

Cumulative Model Updates: 305,962
Cumulative Timesteps: 2,551,704,582

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2551704582...
Checkpoint 2551704582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.60272
Policy Entropy: 2.39352
Value Function Loss: 0.02140

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.48563
Value Function Update Magnitude: 0.68935

Collected Steps per Second: 21,852.09786
Overall Steps per Second: 10,641.89268

Timestep Collection Time: 2.28948
Timestep Consumption Time: 2.41175
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.70123

Cumulative Model Updates: 305,968
Cumulative Timesteps: 2,551,754,612

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.42024
Policy Entropy: 2.39012
Value Function Loss: 0.02076

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.10435
Policy Update Magnitude: 0.50695
Value Function Update Magnitude: 0.69850

Collected Steps per Second: 21,747.21440
Overall Steps per Second: 10,392.04349

Timestep Collection Time: 2.29924
Timestep Consumption Time: 2.51233
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.81157

Cumulative Model Updates: 305,974
Cumulative Timesteps: 2,551,804,614

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2551804614...
Checkpoint 2551804614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.46843
Policy Entropy: 2.39964
Value Function Loss: 0.02108

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.10180
Policy Update Magnitude: 0.51249
Value Function Update Magnitude: 0.71550

Collected Steps per Second: 22,071.60405
Overall Steps per Second: 10,431.55788

Timestep Collection Time: 2.26563
Timestep Consumption Time: 2.52810
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.79372

Cumulative Model Updates: 305,980
Cumulative Timesteps: 2,551,854,620

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.29866
Policy Entropy: 2.41941
Value Function Loss: 0.01966

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.09490
Policy Update Magnitude: 0.50875
Value Function Update Magnitude: 0.70951

Collected Steps per Second: 22,032.94317
Overall Steps per Second: 10,639.00998

Timestep Collection Time: 2.27015
Timestep Consumption Time: 2.43123
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.70138

Cumulative Model Updates: 305,986
Cumulative Timesteps: 2,551,904,638

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2551904638...
Checkpoint 2551904638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.25247
Policy Entropy: 2.42077
Value Function Loss: 0.02007

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.50246
Value Function Update Magnitude: 0.68188

Collected Steps per Second: 21,780.33395
Overall Steps per Second: 10,657.96337

Timestep Collection Time: 2.29666
Timestep Consumption Time: 2.39673
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.69339

Cumulative Model Updates: 305,992
Cumulative Timesteps: 2,551,954,660

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.80982
Policy Entropy: 2.42760
Value Function Loss: 0.02007

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.08481
Policy Update Magnitude: 0.49447
Value Function Update Magnitude: 0.66536

Collected Steps per Second: 22,045.90106
Overall Steps per Second: 10,468.26555

Timestep Collection Time: 2.26845
Timestep Consumption Time: 2.50885
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.77730

Cumulative Model Updates: 305,998
Cumulative Timesteps: 2,552,004,670

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2552004670...
Checkpoint 2552004670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.07742
Policy Entropy: 2.43603
Value Function Loss: 0.02107

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.08478
Policy Update Magnitude: 0.48943
Value Function Update Magnitude: 0.67211

Collected Steps per Second: 21,954.79668
Overall Steps per Second: 10,442.43265

Timestep Collection Time: 2.27868
Timestep Consumption Time: 2.51216
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.79084

Cumulative Model Updates: 306,004
Cumulative Timesteps: 2,552,054,698

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.70874
Policy Entropy: 2.42381
Value Function Loss: 0.02027

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.49596
Value Function Update Magnitude: 0.67343

Collected Steps per Second: 21,995.29764
Overall Steps per Second: 10,432.85724

Timestep Collection Time: 2.27494
Timestep Consumption Time: 2.52125
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.79619

Cumulative Model Updates: 306,010
Cumulative Timesteps: 2,552,104,736

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2552104736...
Checkpoint 2552104736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.88465
Policy Entropy: 2.41967
Value Function Loss: 0.02043

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.09019
Policy Update Magnitude: 0.49282
Value Function Update Magnitude: 0.66394

Collected Steps per Second: 21,967.83313
Overall Steps per Second: 10,608.27635

Timestep Collection Time: 2.27678
Timestep Consumption Time: 2.43803
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.71481

Cumulative Model Updates: 306,016
Cumulative Timesteps: 2,552,154,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.75516
Policy Entropy: 2.39379
Value Function Loss: 0.02181

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.09744
Policy Update Magnitude: 0.49564
Value Function Update Magnitude: 0.66332

Collected Steps per Second: 22,296.77859
Overall Steps per Second: 10,423.37512

Timestep Collection Time: 2.24337
Timestep Consumption Time: 2.55546
PPO Batch Consumption Time: 0.29508
Total Iteration Time: 4.79883

Cumulative Model Updates: 306,022
Cumulative Timesteps: 2,552,204,772

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2552204772...
Checkpoint 2552204772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.35946
Policy Entropy: 2.38736
Value Function Loss: 0.02236

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.48550
Value Function Update Magnitude: 0.66445

Collected Steps per Second: 22,343.98327
Overall Steps per Second: 10,555.77018

Timestep Collection Time: 2.23890
Timestep Consumption Time: 2.50031
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.73921

Cumulative Model Updates: 306,028
Cumulative Timesteps: 2,552,254,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.71098
Policy Entropy: 2.39382
Value Function Loss: 0.02187

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.48070
Value Function Update Magnitude: 0.65095

Collected Steps per Second: 21,941.01166
Overall Steps per Second: 10,453.57726

Timestep Collection Time: 2.27902
Timestep Consumption Time: 2.50441
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.78343

Cumulative Model Updates: 306,034
Cumulative Timesteps: 2,552,304,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2552304802...
Checkpoint 2552304802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.60318
Policy Entropy: 2.37847
Value Function Loss: 0.02070

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.09569
Policy Update Magnitude: 0.48896
Value Function Update Magnitude: 0.63814

Collected Steps per Second: 21,912.39981
Overall Steps per Second: 10,651.28161

Timestep Collection Time: 2.28300
Timestep Consumption Time: 2.41371
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.69671

Cumulative Model Updates: 306,040
Cumulative Timesteps: 2,552,354,828

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.62727
Policy Entropy: 2.39683
Value Function Loss: 0.02039

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.09570
Policy Update Magnitude: 0.48944
Value Function Update Magnitude: 0.63817

Collected Steps per Second: 22,328.00520
Overall Steps per Second: 10,464.87855

Timestep Collection Time: 2.24042
Timestep Consumption Time: 2.53976
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 4.78018

Cumulative Model Updates: 306,046
Cumulative Timesteps: 2,552,404,852

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2552404852...
Checkpoint 2552404852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.38528
Policy Entropy: 2.40689
Value Function Loss: 0.02113

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.08683
Policy Update Magnitude: 0.48535
Value Function Update Magnitude: 0.67738

Collected Steps per Second: 21,975.74348
Overall Steps per Second: 10,537.73076

Timestep Collection Time: 2.27642
Timestep Consumption Time: 2.47090
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.74732

Cumulative Model Updates: 306,052
Cumulative Timesteps: 2,552,454,878

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.17956
Policy Entropy: 2.42173
Value Function Loss: 0.02030

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.08984
Policy Update Magnitude: 0.49526
Value Function Update Magnitude: 0.67744

Collected Steps per Second: 21,815.73951
Overall Steps per Second: 10,506.80816

Timestep Collection Time: 2.29321
Timestep Consumption Time: 2.46828
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.76148

Cumulative Model Updates: 306,058
Cumulative Timesteps: 2,552,504,906

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2552504906...
Checkpoint 2552504906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.52356
Policy Entropy: 2.41879
Value Function Loss: 0.02030

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.08828
Policy Update Magnitude: 0.49530
Value Function Update Magnitude: 0.68128

Collected Steps per Second: 21,824.70578
Overall Steps per Second: 10,607.52149

Timestep Collection Time: 2.29208
Timestep Consumption Time: 2.42382
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.71590

Cumulative Model Updates: 306,064
Cumulative Timesteps: 2,552,554,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.40941
Policy Entropy: 2.41268
Value Function Loss: 0.01846

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.48399
Value Function Update Magnitude: 0.66264

Collected Steps per Second: 21,986.61002
Overall Steps per Second: 10,518.66748

Timestep Collection Time: 2.27457
Timestep Consumption Time: 2.47984
PPO Batch Consumption Time: 0.29524
Total Iteration Time: 4.75440

Cumulative Model Updates: 306,070
Cumulative Timesteps: 2,552,604,940

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2552604940...
Checkpoint 2552604940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166.93737
Policy Entropy: 2.39626
Value Function Loss: 0.01889

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.08440
Policy Update Magnitude: 0.47765
Value Function Update Magnitude: 0.63456

Collected Steps per Second: 21,834.49763
Overall Steps per Second: 10,540.31516

Timestep Collection Time: 2.29096
Timestep Consumption Time: 2.45482
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.74578

Cumulative Model Updates: 306,076
Cumulative Timesteps: 2,552,654,962

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.08341
Policy Entropy: 2.37733
Value Function Loss: 0.01941

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.08436
Policy Update Magnitude: 0.48293
Value Function Update Magnitude: 0.61372

Collected Steps per Second: 21,684.62736
Overall Steps per Second: 10,474.48048

Timestep Collection Time: 2.30661
Timestep Consumption Time: 2.46861
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.77522

Cumulative Model Updates: 306,082
Cumulative Timesteps: 2,552,704,980

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2552704980...
Checkpoint 2552704980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.57112
Policy Entropy: 2.35099
Value Function Loss: 0.02154

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.09146
Policy Update Magnitude: 0.49539
Value Function Update Magnitude: 0.60372

Collected Steps per Second: 21,089.27883
Overall Steps per Second: 10,303.03724

Timestep Collection Time: 2.37192
Timestep Consumption Time: 2.48316
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.85507

Cumulative Model Updates: 306,088
Cumulative Timesteps: 2,552,755,002

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.51728
Policy Entropy: 2.38290
Value Function Loss: 0.02156

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.09479
Policy Update Magnitude: 0.49801
Value Function Update Magnitude: 0.61759

Collected Steps per Second: 21,604.51850
Overall Steps per Second: 10,438.20549

Timestep Collection Time: 2.31461
Timestep Consumption Time: 2.47606
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 4.79067

Cumulative Model Updates: 306,094
Cumulative Timesteps: 2,552,805,008

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2552805008...
Checkpoint 2552805008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.09181
Policy Entropy: 2.38109
Value Function Loss: 0.02047

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.49378
Value Function Update Magnitude: 0.62694

Collected Steps per Second: 21,670.32986
Overall Steps per Second: 10,391.31027

Timestep Collection Time: 2.30859
Timestep Consumption Time: 2.50581
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.81441

Cumulative Model Updates: 306,100
Cumulative Timesteps: 2,552,855,036

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.29897
Policy Entropy: 2.40049
Value Function Loss: 0.01970

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.08555
Policy Update Magnitude: 0.49097
Value Function Update Magnitude: 0.61869

Collected Steps per Second: 22,277.08762
Overall Steps per Second: 10,635.01775

Timestep Collection Time: 2.24554
Timestep Consumption Time: 2.45817
PPO Batch Consumption Time: 0.28142
Total Iteration Time: 4.70371

Cumulative Model Updates: 306,106
Cumulative Timesteps: 2,552,905,060

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2552905060...
Checkpoint 2552905060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.49203
Policy Entropy: 2.37216
Value Function Loss: 0.02018

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.09128
Policy Update Magnitude: 0.49633
Value Function Update Magnitude: 0.62649

Collected Steps per Second: 21,818.81666
Overall Steps per Second: 10,478.23827

Timestep Collection Time: 2.29233
Timestep Consumption Time: 2.48099
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.77332

Cumulative Model Updates: 306,112
Cumulative Timesteps: 2,552,955,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.82651
Policy Entropy: 2.35959
Value Function Loss: 0.02200

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.09495
Policy Update Magnitude: 0.49779
Value Function Update Magnitude: 0.63793

Collected Steps per Second: 22,522.17564
Overall Steps per Second: 10,701.85047

Timestep Collection Time: 2.22057
Timestep Consumption Time: 2.45264
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.67321

Cumulative Model Updates: 306,118
Cumulative Timesteps: 2,553,005,088

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2553005088...
Checkpoint 2553005088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.56774
Policy Entropy: 2.36742
Value Function Loss: 0.02170

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.10467
Policy Update Magnitude: 0.50119
Value Function Update Magnitude: 0.65279

Collected Steps per Second: 22,036.77014
Overall Steps per Second: 10,553.71525

Timestep Collection Time: 2.26903
Timestep Consumption Time: 2.46883
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.73786

Cumulative Model Updates: 306,124
Cumulative Timesteps: 2,553,055,090

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.51929
Policy Entropy: 2.42031
Value Function Loss: 0.02085

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.10043
Policy Update Magnitude: 0.48539
Value Function Update Magnitude: 0.64200

Collected Steps per Second: 22,084.41945
Overall Steps per Second: 10,548.88589

Timestep Collection Time: 2.26449
Timestep Consumption Time: 2.47629
PPO Batch Consumption Time: 0.28142
Total Iteration Time: 4.74078

Cumulative Model Updates: 306,130
Cumulative Timesteps: 2,553,105,100

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2553105100...
Checkpoint 2553105100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.76947
Policy Entropy: 2.44458
Value Function Loss: 0.01950

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.09923
Policy Update Magnitude: 0.48128
Value Function Update Magnitude: 0.62804

Collected Steps per Second: 21,778.63056
Overall Steps per Second: 10,555.49846

Timestep Collection Time: 2.29592
Timestep Consumption Time: 2.44114
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.73706

Cumulative Model Updates: 306,136
Cumulative Timesteps: 2,553,155,102

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.98357
Policy Entropy: 2.42505
Value Function Loss: 0.01909

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.09229
Policy Update Magnitude: 0.47872
Value Function Update Magnitude: 0.61512

Collected Steps per Second: 22,013.89857
Overall Steps per Second: 10,563.51166

Timestep Collection Time: 2.27256
Timestep Consumption Time: 2.46336
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.73593

Cumulative Model Updates: 306,142
Cumulative Timesteps: 2,553,205,130

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2553205130...
Checkpoint 2553205130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.37308
Policy Entropy: 2.39494
Value Function Loss: 0.01974

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.09416
Policy Update Magnitude: 0.48792
Value Function Update Magnitude: 0.62502

Collected Steps per Second: 21,766.81763
Overall Steps per Second: 10,507.66189

Timestep Collection Time: 2.29827
Timestep Consumption Time: 2.46264
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.76091

Cumulative Model Updates: 306,148
Cumulative Timesteps: 2,553,255,156

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.53332
Policy Entropy: 2.40929
Value Function Loss: 0.02054

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.09617
Policy Update Magnitude: 0.49402
Value Function Update Magnitude: 0.63888

Collected Steps per Second: 22,180.26430
Overall Steps per Second: 10,595.51285

Timestep Collection Time: 2.25570
Timestep Consumption Time: 2.46630
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.72200

Cumulative Model Updates: 306,154
Cumulative Timesteps: 2,553,305,188

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2553305188...
Checkpoint 2553305188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.85133
Policy Entropy: 2.41214
Value Function Loss: 0.02067

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.09689
Policy Update Magnitude: 0.49269
Value Function Update Magnitude: 0.64178

Collected Steps per Second: 20,373.24976
Overall Steps per Second: 10,230.28258

Timestep Collection Time: 2.45557
Timestep Consumption Time: 2.43461
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.89019

Cumulative Model Updates: 306,160
Cumulative Timesteps: 2,553,355,216

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.67583
Policy Entropy: 2.41451
Value Function Loss: 0.02117

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.08918
Policy Update Magnitude: 0.49047
Value Function Update Magnitude: 0.65081

Collected Steps per Second: 22,637.63430
Overall Steps per Second: 10,547.96988

Timestep Collection Time: 2.20915
Timestep Consumption Time: 2.53204
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.74120

Cumulative Model Updates: 306,166
Cumulative Timesteps: 2,553,405,226

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2553405226...
Checkpoint 2553405226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.49611
Policy Entropy: 2.42681
Value Function Loss: 0.02062

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.49545
Value Function Update Magnitude: 0.65868

Collected Steps per Second: 22,381.98741
Overall Steps per Second: 10,476.33794

Timestep Collection Time: 2.23403
Timestep Consumption Time: 2.53882
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.77285

Cumulative Model Updates: 306,172
Cumulative Timesteps: 2,553,455,228

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.38927
Policy Entropy: 2.45817
Value Function Loss: 0.02011

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.49519
Value Function Update Magnitude: 0.66630

Collected Steps per Second: 22,323.72643
Overall Steps per Second: 10,468.90823

Timestep Collection Time: 2.24102
Timestep Consumption Time: 2.53770
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.77872

Cumulative Model Updates: 306,178
Cumulative Timesteps: 2,553,505,256

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2553505256...
Checkpoint 2553505256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.79663
Policy Entropy: 2.45696
Value Function Loss: 0.02111

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.09189
Policy Update Magnitude: 0.49301
Value Function Update Magnitude: 0.67190

Collected Steps per Second: 21,923.42234
Overall Steps per Second: 10,672.27910

Timestep Collection Time: 2.28094
Timestep Consumption Time: 2.40466
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.68560

Cumulative Model Updates: 306,184
Cumulative Timesteps: 2,553,555,262

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.57244
Policy Entropy: 2.44539
Value Function Loss: 0.02078

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.49465
Value Function Update Magnitude: 0.67563

Collected Steps per Second: 22,608.21708
Overall Steps per Second: 10,622.84312

Timestep Collection Time: 2.21274
Timestep Consumption Time: 2.49655
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.70929

Cumulative Model Updates: 306,190
Cumulative Timesteps: 2,553,605,288

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2553605288...
Checkpoint 2553605288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.78604
Policy Entropy: 2.41155
Value Function Loss: 0.02099

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.10875
Policy Update Magnitude: 0.49200
Value Function Update Magnitude: 0.68707

Collected Steps per Second: 22,103.51001
Overall Steps per Second: 10,443.84657

Timestep Collection Time: 2.26353
Timestep Consumption Time: 2.52704
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.79057

Cumulative Model Updates: 306,196
Cumulative Timesteps: 2,553,655,320

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.92207
Policy Entropy: 2.44185
Value Function Loss: 0.01941

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.12262
Policy Update Magnitude: 0.46314
Value Function Update Magnitude: 0.67593

Collected Steps per Second: 22,364.89112
Overall Steps per Second: 10,621.69251

Timestep Collection Time: 2.23592
Timestep Consumption Time: 2.47200
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.70791

Cumulative Model Updates: 306,202
Cumulative Timesteps: 2,553,705,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2553705326...
Checkpoint 2553705326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.36747
Policy Entropy: 2.42566
Value Function Loss: 0.01940

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.11954
Policy Update Magnitude: 0.45705
Value Function Update Magnitude: 0.66988

Collected Steps per Second: 21,985.09763
Overall Steps per Second: 10,664.62553

Timestep Collection Time: 2.27463
Timestep Consumption Time: 2.41452
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.68915

Cumulative Model Updates: 306,208
Cumulative Timesteps: 2,553,755,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.03179
Policy Entropy: 2.42176
Value Function Loss: 0.02076

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.11209
Policy Update Magnitude: 0.49006
Value Function Update Magnitude: 0.68967

Collected Steps per Second: 22,693.18613
Overall Steps per Second: 10,756.80408

Timestep Collection Time: 2.20375
Timestep Consumption Time: 2.44541
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.64915

Cumulative Model Updates: 306,214
Cumulative Timesteps: 2,553,805,344

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2553805344...
Checkpoint 2553805344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.47944
Policy Entropy: 2.38498
Value Function Loss: 0.02219

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.11545
Policy Update Magnitude: 0.51311
Value Function Update Magnitude: 0.69619

Collected Steps per Second: 21,637.50401
Overall Steps per Second: 10,517.24295

Timestep Collection Time: 2.31145
Timestep Consumption Time: 2.44398
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.75543

Cumulative Model Updates: 306,220
Cumulative Timesteps: 2,553,855,358

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.55334
Policy Entropy: 2.42095
Value Function Loss: 0.02159

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.10512
Policy Update Magnitude: 0.51762
Value Function Update Magnitude: 0.70450

Collected Steps per Second: 22,344.11301
Overall Steps per Second: 10,551.19991

Timestep Collection Time: 2.23889
Timestep Consumption Time: 2.50237
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.74126

Cumulative Model Updates: 306,226
Cumulative Timesteps: 2,553,905,384

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2553905384...
Checkpoint 2553905384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.38580
Policy Entropy: 2.43485
Value Function Loss: 0.02089

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.50351
Value Function Update Magnitude: 0.69922

Collected Steps per Second: 21,964.90552
Overall Steps per Second: 10,647.72987

Timestep Collection Time: 2.27681
Timestep Consumption Time: 2.41996
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.69678

Cumulative Model Updates: 306,232
Cumulative Timesteps: 2,553,955,394

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.55332
Policy Entropy: 2.44880
Value Function Loss: 0.01956

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.49683
Value Function Update Magnitude: 0.67100

Collected Steps per Second: 22,457.64702
Overall Steps per Second: 10,546.95482

Timestep Collection Time: 2.22748
Timestep Consumption Time: 2.51550
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.74298

Cumulative Model Updates: 306,238
Cumulative Timesteps: 2,554,005,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2554005418...
Checkpoint 2554005418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.10377
Policy Entropy: 2.40917
Value Function Loss: 0.02040

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.08984
Policy Update Magnitude: 0.48885
Value Function Update Magnitude: 0.66366

Collected Steps per Second: 21,830.49542
Overall Steps per Second: 10,509.11766

Timestep Collection Time: 2.29074
Timestep Consumption Time: 2.46779
PPO Batch Consumption Time: 0.28168
Total Iteration Time: 4.75853

Cumulative Model Updates: 306,244
Cumulative Timesteps: 2,554,055,426

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.08981
Policy Entropy: 2.41885
Value Function Loss: 0.02080

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.09650
Policy Update Magnitude: 0.49027
Value Function Update Magnitude: 0.67347

Collected Steps per Second: 22,227.56381
Overall Steps per Second: 10,708.48014

Timestep Collection Time: 2.25027
Timestep Consumption Time: 2.42061
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.67088

Cumulative Model Updates: 306,250
Cumulative Timesteps: 2,554,105,444

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2554105444...
Checkpoint 2554105444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.73892
Policy Entropy: 2.42519
Value Function Loss: 0.02181

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.09872
Policy Update Magnitude: 0.48714
Value Function Update Magnitude: 0.69607

Collected Steps per Second: 22,266.92034
Overall Steps per Second: 10,561.81527

Timestep Collection Time: 2.24548
Timestep Consumption Time: 2.48855
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.73403

Cumulative Model Updates: 306,256
Cumulative Timesteps: 2,554,155,444

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.51796
Policy Entropy: 2.41962
Value Function Loss: 0.02241

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.09550
Policy Update Magnitude: 0.49861
Value Function Update Magnitude: 0.69888

Collected Steps per Second: 22,487.91089
Overall Steps per Second: 10,726.74111

Timestep Collection Time: 2.22475
Timestep Consumption Time: 2.43929
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.66404

Cumulative Model Updates: 306,262
Cumulative Timesteps: 2,554,205,474

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2554205474...
Checkpoint 2554205474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.93434
Policy Entropy: 2.42220
Value Function Loss: 0.02142

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.10165
Policy Update Magnitude: 0.49892
Value Function Update Magnitude: 0.68575

Collected Steps per Second: 21,842.84998
Overall Steps per Second: 10,583.51255

Timestep Collection Time: 2.29027
Timestep Consumption Time: 2.43652
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.72679

Cumulative Model Updates: 306,268
Cumulative Timesteps: 2,554,255,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.84166
Policy Entropy: 2.41466
Value Function Loss: 0.02067

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.09134
Policy Update Magnitude: 0.49668
Value Function Update Magnitude: 0.65595

Collected Steps per Second: 22,395.96319
Overall Steps per Second: 10,777.74632

Timestep Collection Time: 2.23281
Timestep Consumption Time: 2.40693
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.63975

Cumulative Model Updates: 306,274
Cumulative Timesteps: 2,554,305,506

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2554305506...
Checkpoint 2554305506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.83305
Policy Entropy: 2.44406
Value Function Loss: 0.01925

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.48637
Value Function Update Magnitude: 0.62916

Collected Steps per Second: 22,330.03086
Overall Steps per Second: 10,541.37248

Timestep Collection Time: 2.23985
Timestep Consumption Time: 2.50488
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.74473

Cumulative Model Updates: 306,280
Cumulative Timesteps: 2,554,355,522

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.59896
Policy Entropy: 2.44000
Value Function Loss: 0.01853

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.47171
Value Function Update Magnitude: 0.62180

Collected Steps per Second: 22,324.92883
Overall Steps per Second: 10,666.01308

Timestep Collection Time: 2.24090
Timestep Consumption Time: 2.44951
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.69041

Cumulative Model Updates: 306,286
Cumulative Timesteps: 2,554,405,550

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2554405550...
Checkpoint 2554405550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.94489
Policy Entropy: 2.41590
Value Function Loss: 0.01868

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.08906
Policy Update Magnitude: 0.48208
Value Function Update Magnitude: 0.63973

Collected Steps per Second: 21,936.25439
Overall Steps per Second: 10,647.25108

Timestep Collection Time: 2.27933
Timestep Consumption Time: 2.41672
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.69605

Cumulative Model Updates: 306,292
Cumulative Timesteps: 2,554,455,550

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.36597
Policy Entropy: 2.40917
Value Function Loss: 0.01868

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.09030
Policy Update Magnitude: 0.48387
Value Function Update Magnitude: 0.64986

Collected Steps per Second: 22,184.09087
Overall Steps per Second: 10,652.44806

Timestep Collection Time: 2.25414
Timestep Consumption Time: 2.44018
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.69432

Cumulative Model Updates: 306,298
Cumulative Timesteps: 2,554,505,556

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2554505556...
Checkpoint 2554505556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.04558
Policy Entropy: 2.41041
Value Function Loss: 0.02019

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.08710
Policy Update Magnitude: 0.48676
Value Function Update Magnitude: 0.65893

Collected Steps per Second: 21,986.47624
Overall Steps per Second: 10,560.27118

Timestep Collection Time: 2.27494
Timestep Consumption Time: 2.46149
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.73643

Cumulative Model Updates: 306,304
Cumulative Timesteps: 2,554,555,574

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.40212
Policy Entropy: 2.45743
Value Function Loss: 0.02055

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.49046
Value Function Update Magnitude: 0.66143

Collected Steps per Second: 22,146.93959
Overall Steps per Second: 10,408.22045

Timestep Collection Time: 2.25801
Timestep Consumption Time: 2.54665
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.80466

Cumulative Model Updates: 306,310
Cumulative Timesteps: 2,554,605,582

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2554605582...
Checkpoint 2554605582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.83983
Policy Entropy: 2.45474
Value Function Loss: 0.02063

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.09092
Policy Update Magnitude: 0.49516
Value Function Update Magnitude: 0.67475

Collected Steps per Second: 21,856.12002
Overall Steps per Second: 10,638.70272

Timestep Collection Time: 2.28824
Timestep Consumption Time: 2.41271
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.70095

Cumulative Model Updates: 306,316
Cumulative Timesteps: 2,554,655,594

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.78421
Policy Entropy: 2.43128
Value Function Loss: 0.02168

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.09284
Policy Update Magnitude: 0.50588
Value Function Update Magnitude: 0.68198

Collected Steps per Second: 22,395.96932
Overall Steps per Second: 10,864.45037

Timestep Collection Time: 2.23335
Timestep Consumption Time: 2.37047
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.60382

Cumulative Model Updates: 306,322
Cumulative Timesteps: 2,554,705,612

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2554705612...
Checkpoint 2554705612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.72874
Policy Entropy: 2.40762
Value Function Loss: 0.02110

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.10524
Policy Update Magnitude: 0.50126
Value Function Update Magnitude: 0.69490

Collected Steps per Second: 22,027.13885
Overall Steps per Second: 10,617.76959

Timestep Collection Time: 2.27074
Timestep Consumption Time: 2.44004
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.71078

Cumulative Model Updates: 306,328
Cumulative Timesteps: 2,554,755,630

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.90765
Policy Entropy: 2.39417
Value Function Loss: 0.02170

Mean KL Divergence: 0.02372
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.47220
Value Function Update Magnitude: 0.70478

Collected Steps per Second: 22,149.52978
Overall Steps per Second: 10,523.45922

Timestep Collection Time: 2.25865
Timestep Consumption Time: 2.49530
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.75395

Cumulative Model Updates: 306,334
Cumulative Timesteps: 2,554,805,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2554805658...
Checkpoint 2554805658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.33490
Policy Entropy: 2.39867
Value Function Loss: 0.02057

Mean KL Divergence: 0.02073
SB3 Clip Fraction: 0.12439
Policy Update Magnitude: 0.48584
Value Function Update Magnitude: 0.66971

Collected Steps per Second: 21,604.31354
Overall Steps per Second: 10,357.22252

Timestep Collection Time: 2.31556
Timestep Consumption Time: 2.51450
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.83006

Cumulative Model Updates: 306,340
Cumulative Timesteps: 2,554,855,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.56269
Policy Entropy: 2.37819
Value Function Loss: 0.02188

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.10968
Policy Update Magnitude: 0.50253
Value Function Update Magnitude: 0.64342

Collected Steps per Second: 22,212.29719
Overall Steps per Second: 10,797.74925

Timestep Collection Time: 2.25155
Timestep Consumption Time: 2.38016
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.63171

Cumulative Model Updates: 306,346
Cumulative Timesteps: 2,554,905,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2554905696...
Checkpoint 2554905696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.00230
Policy Entropy: 2.36859
Value Function Loss: 0.02124

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.10003
Policy Update Magnitude: 0.49994
Value Function Update Magnitude: 0.63918

Collected Steps per Second: 22,210.85686
Overall Steps per Second: 10,694.22419

Timestep Collection Time: 2.25187
Timestep Consumption Time: 2.42505
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.67692

Cumulative Model Updates: 306,352
Cumulative Timesteps: 2,554,955,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.89061
Policy Entropy: 2.37829
Value Function Loss: 0.02177

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.09302
Policy Update Magnitude: 0.49183
Value Function Update Magnitude: 0.64107

Collected Steps per Second: 22,285.16530
Overall Steps per Second: 10,512.75605

Timestep Collection Time: 2.24499
Timestep Consumption Time: 2.51399
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.75898

Cumulative Model Updates: 306,358
Cumulative Timesteps: 2,555,005,742

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2555005742...
Checkpoint 2555005742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.22491
Policy Entropy: 2.35156
Value Function Loss: 0.02269

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.50224
Value Function Update Magnitude: 0.64199

Collected Steps per Second: 21,990.33463
Overall Steps per Second: 10,468.54244

Timestep Collection Time: 2.27373
Timestep Consumption Time: 2.50249
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.77621

Cumulative Model Updates: 306,364
Cumulative Timesteps: 2,555,055,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.02634
Policy Entropy: 2.35818
Value Function Loss: 0.02179

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.09177
Policy Update Magnitude: 0.50852
Value Function Update Magnitude: 0.64458

Collected Steps per Second: 22,303.99551
Overall Steps per Second: 10,836.21104

Timestep Collection Time: 2.24238
Timestep Consumption Time: 2.37307
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.61545

Cumulative Model Updates: 306,370
Cumulative Timesteps: 2,555,105,756

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2555105756...
Checkpoint 2555105756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.30639
Policy Entropy: 2.33409
Value Function Loss: 0.02209

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.50939
Value Function Update Magnitude: 0.64445

Collected Steps per Second: 22,185.35357
Overall Steps per Second: 10,669.46920

Timestep Collection Time: 2.25473
Timestep Consumption Time: 2.43360
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.68833

Cumulative Model Updates: 306,376
Cumulative Timesteps: 2,555,155,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.24984
Policy Entropy: 2.37329
Value Function Loss: 0.02093

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.10039
Policy Update Magnitude: 0.49947
Value Function Update Magnitude: 0.64740

Collected Steps per Second: 22,133.76680
Overall Steps per Second: 10,523.02019

Timestep Collection Time: 2.25990
Timestep Consumption Time: 2.49349
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.75339

Cumulative Model Updates: 306,382
Cumulative Timesteps: 2,555,205,798

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2555205798...
Checkpoint 2555205798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.31059
Policy Entropy: 2.35236
Value Function Loss: 0.02147

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.10384
Policy Update Magnitude: 0.48823
Value Function Update Magnitude: 0.64878

Collected Steps per Second: 21,902.37633
Overall Steps per Second: 10,634.73415

Timestep Collection Time: 2.28404
Timestep Consumption Time: 2.41998
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.70402

Cumulative Model Updates: 306,388
Cumulative Timesteps: 2,555,255,824

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.30375
Policy Entropy: 2.37581
Value Function Loss: 0.01924

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.09327
Policy Update Magnitude: 0.48671
Value Function Update Magnitude: 0.63400

Collected Steps per Second: 22,231.09949
Overall Steps per Second: 10,849.00835

Timestep Collection Time: 2.24919
Timestep Consumption Time: 2.35971
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.60890

Cumulative Model Updates: 306,394
Cumulative Timesteps: 2,555,305,826

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2555305826...
Checkpoint 2555305826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.69094
Policy Entropy: 2.36807
Value Function Loss: 0.01978

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.09407
Policy Update Magnitude: 0.48066
Value Function Update Magnitude: 0.62722

Collected Steps per Second: 22,109.19999
Overall Steps per Second: 10,665.17752

Timestep Collection Time: 2.26150
Timestep Consumption Time: 2.42665
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.68815

Cumulative Model Updates: 306,400
Cumulative Timesteps: 2,555,355,826

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.05544
Policy Entropy: 2.41582
Value Function Loss: 0.01963

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.09938
Policy Update Magnitude: 0.47616
Value Function Update Magnitude: 0.64606

Collected Steps per Second: 22,359.95996
Overall Steps per Second: 10,505.66989

Timestep Collection Time: 2.23739
Timestep Consumption Time: 2.52461
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.76200

Cumulative Model Updates: 306,406
Cumulative Timesteps: 2,555,405,854

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2555405854...
Checkpoint 2555405854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.41470
Policy Entropy: 2.41700
Value Function Loss: 0.01985

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.11593
Policy Update Magnitude: 0.46841
Value Function Update Magnitude: 0.66500

Collected Steps per Second: 21,804.24219
Overall Steps per Second: 10,590.22935

Timestep Collection Time: 2.29405
Timestep Consumption Time: 2.42917
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.72322

Cumulative Model Updates: 306,412
Cumulative Timesteps: 2,555,455,874

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.98349
Policy Entropy: 2.43496
Value Function Loss: 0.01988

Mean KL Divergence: 0.02293
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.45669
Value Function Update Magnitude: 0.67191

Collected Steps per Second: 22,380.55774
Overall Steps per Second: 10,733.75524

Timestep Collection Time: 2.23444
Timestep Consumption Time: 2.42451
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.65895

Cumulative Model Updates: 306,418
Cumulative Timesteps: 2,555,505,882

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2555505882...
Checkpoint 2555505882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.60733
Policy Entropy: 2.43449
Value Function Loss: 0.01979

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.10969
Policy Update Magnitude: 0.46810
Value Function Update Magnitude: 0.65324

Collected Steps per Second: 22,305.25367
Overall Steps per Second: 10,561.00728

Timestep Collection Time: 2.24306
Timestep Consumption Time: 2.49437
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.73743

Cumulative Model Updates: 306,424
Cumulative Timesteps: 2,555,555,914

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.98356
Policy Entropy: 2.43276
Value Function Loss: 0.01951

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.47216
Value Function Update Magnitude: 0.66285

Collected Steps per Second: 22,562.51215
Overall Steps per Second: 10,690.04241

Timestep Collection Time: 2.21713
Timestep Consumption Time: 2.46237
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.67950

Cumulative Model Updates: 306,430
Cumulative Timesteps: 2,555,605,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2555605938...
Checkpoint 2555605938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.82969
Policy Entropy: 2.41947
Value Function Loss: 0.02041

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.48214
Value Function Update Magnitude: 0.67298

Collected Steps per Second: 21,574.43612
Overall Steps per Second: 10,333.89372

Timestep Collection Time: 2.31858
Timestep Consumption Time: 2.52200
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.84058

Cumulative Model Updates: 306,436
Cumulative Timesteps: 2,555,655,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.94074
Policy Entropy: 2.39396
Value Function Loss: 0.02073

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.48251
Value Function Update Magnitude: 0.66491

Collected Steps per Second: 22,251.89200
Overall Steps per Second: 10,801.02910

Timestep Collection Time: 2.24763
Timestep Consumption Time: 2.38286
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.63048

Cumulative Model Updates: 306,442
Cumulative Timesteps: 2,555,705,974

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2555705974...
Checkpoint 2555705974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.09121
Policy Entropy: 2.39826
Value Function Loss: 0.02088

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.08516
Policy Update Magnitude: 0.47927
Value Function Update Magnitude: 0.64769

Collected Steps per Second: 21,651.30889
Overall Steps per Second: 10,273.95241

Timestep Collection Time: 2.30970
Timestep Consumption Time: 2.55776
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 4.86745

Cumulative Model Updates: 306,448
Cumulative Timesteps: 2,555,755,982

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.65163
Policy Entropy: 2.40749
Value Function Loss: 0.02098

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.08447
Policy Update Magnitude: 0.48285
Value Function Update Magnitude: 0.64771

Collected Steps per Second: 22,479.46251
Overall Steps per Second: 10,506.17860

Timestep Collection Time: 2.22505
Timestep Consumption Time: 2.53576
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.76082

Cumulative Model Updates: 306,454
Cumulative Timesteps: 2,555,806,000

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2555806000...
Checkpoint 2555806000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.21219
Policy Entropy: 2.42432
Value Function Loss: 0.02035

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.08530
Policy Update Magnitude: 0.48198
Value Function Update Magnitude: 0.66004

Collected Steps per Second: 21,799.22355
Overall Steps per Second: 10,601.41640

Timestep Collection Time: 2.29430
Timestep Consumption Time: 2.42337
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.71767

Cumulative Model Updates: 306,460
Cumulative Timesteps: 2,555,856,014

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.67000
Policy Entropy: 2.42341
Value Function Loss: 0.01952

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.08667
Policy Update Magnitude: 0.48064
Value Function Update Magnitude: 0.66036

Collected Steps per Second: 21,875.36499
Overall Steps per Second: 10,602.03364

Timestep Collection Time: 2.28686
Timestep Consumption Time: 2.43166
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.71853

Cumulative Model Updates: 306,466
Cumulative Timesteps: 2,555,906,040

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2555906040...
Checkpoint 2555906040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.18766
Policy Entropy: 2.39194
Value Function Loss: 0.02015

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.09002
Policy Update Magnitude: 0.49675
Value Function Update Magnitude: 0.64697

Collected Steps per Second: 22,203.82681
Overall Steps per Second: 10,487.15799

Timestep Collection Time: 2.25249
Timestep Consumption Time: 2.51658
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.76907

Cumulative Model Updates: 306,472
Cumulative Timesteps: 2,555,956,054

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.74644
Policy Entropy: 2.40034
Value Function Loss: 0.02003

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.10515
Policy Update Magnitude: 0.49741
Value Function Update Magnitude: 0.66071

Collected Steps per Second: 22,388.98812
Overall Steps per Second: 10,485.70392

Timestep Collection Time: 2.23378
Timestep Consumption Time: 2.53576
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.76954

Cumulative Model Updates: 306,478
Cumulative Timesteps: 2,556,006,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2556006066...
Checkpoint 2556006066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.88680
Policy Entropy: 2.39370
Value Function Loss: 0.02138

Mean KL Divergence: 0.02599
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.48683
Value Function Update Magnitude: 0.66822

Collected Steps per Second: 22,141.49109
Overall Steps per Second: 10,577.47958

Timestep Collection Time: 2.25875
Timestep Consumption Time: 2.46941
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.72816

Cumulative Model Updates: 306,484
Cumulative Timesteps: 2,556,056,078

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.42258
Policy Entropy: 2.41755
Value Function Loss: 0.02199

Mean KL Divergence: 0.02791
SB3 Clip Fraction: 0.13860
Policy Update Magnitude: 0.46855
Value Function Update Magnitude: 0.67701

Collected Steps per Second: 23,080.67743
Overall Steps per Second: 10,853.12403

Timestep Collection Time: 2.16692
Timestep Consumption Time: 2.44134
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.60826

Cumulative Model Updates: 306,490
Cumulative Timesteps: 2,556,106,092

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2556106092...
Checkpoint 2556106092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.46316
Policy Entropy: 2.39081
Value Function Loss: 0.02312

Mean KL Divergence: 0.03209
SB3 Clip Fraction: 0.12962
Policy Update Magnitude: 0.49794
Value Function Update Magnitude: 0.70123

Collected Steps per Second: 21,959.95038
Overall Steps per Second: 10,486.79789

Timestep Collection Time: 2.27715
Timestep Consumption Time: 2.49133
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.76847

Cumulative Model Updates: 306,496
Cumulative Timesteps: 2,556,156,098

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.29326
Policy Entropy: 2.38393
Value Function Loss: 0.02147

Mean KL Divergence: 0.03047
SB3 Clip Fraction: 0.13840
Policy Update Magnitude: 0.50705
Value Function Update Magnitude: 0.69965

Collected Steps per Second: 22,469.60293
Overall Steps per Second: 10,654.37429

Timestep Collection Time: 2.22656
Timestep Consumption Time: 2.46916
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.69572

Cumulative Model Updates: 306,502
Cumulative Timesteps: 2,556,206,128

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2556206128...
Checkpoint 2556206128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.57444
Policy Entropy: 2.39212
Value Function Loss: 0.02094

Mean KL Divergence: 0.02348
SB3 Clip Fraction: 0.12960
Policy Update Magnitude: 0.49603
Value Function Update Magnitude: 0.67517

Collected Steps per Second: 22,044.51893
Overall Steps per Second: 10,715.83873

Timestep Collection Time: 2.26850
Timestep Consumption Time: 2.39824
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.66674

Cumulative Model Updates: 306,508
Cumulative Timesteps: 2,556,256,136

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.50687
Policy Entropy: 2.43013
Value Function Loss: 0.01980

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.11731
Policy Update Magnitude: 0.49615
Value Function Update Magnitude: 0.66100

Collected Steps per Second: 22,398.07974
Overall Steps per Second: 10,553.35493

Timestep Collection Time: 2.23403
Timestep Consumption Time: 2.50740
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.74143

Cumulative Model Updates: 306,514
Cumulative Timesteps: 2,556,306,174

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2556306174...
Checkpoint 2556306174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.94952
Policy Entropy: 2.42516
Value Function Loss: 0.02121

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.09894
Policy Update Magnitude: 0.50569
Value Function Update Magnitude: 0.66860

Collected Steps per Second: 22,262.83076
Overall Steps per Second: 10,525.22763

Timestep Collection Time: 2.24643
Timestep Consumption Time: 2.50520
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.75163

Cumulative Model Updates: 306,520
Cumulative Timesteps: 2,556,356,186

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.16466
Policy Entropy: 2.44527
Value Function Loss: 0.02148

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.09135
Policy Update Magnitude: 0.49791
Value Function Update Magnitude: 0.69437

Collected Steps per Second: 21,984.64309
Overall Steps per Second: 10,448.10208

Timestep Collection Time: 2.27577
Timestep Consumption Time: 2.51285
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.78862

Cumulative Model Updates: 306,526
Cumulative Timesteps: 2,556,406,218

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2556406218...
Checkpoint 2556406218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.14416
Policy Entropy: 2.42291
Value Function Loss: 0.02257

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.08656
Policy Update Magnitude: 0.49839
Value Function Update Magnitude: 0.69349

Collected Steps per Second: 21,860.67976
Overall Steps per Second: 10,623.94980

Timestep Collection Time: 2.28868
Timestep Consumption Time: 2.42068
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.70936

Cumulative Model Updates: 306,532
Cumulative Timesteps: 2,556,456,250

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.86372
Policy Entropy: 2.43814
Value Function Loss: 0.02244

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.50548
Value Function Update Magnitude: 0.67358

Collected Steps per Second: 22,040.32626
Overall Steps per Second: 10,514.38701

Timestep Collection Time: 2.26993
Timestep Consumption Time: 2.48831
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.75824

Cumulative Model Updates: 306,538
Cumulative Timesteps: 2,556,506,280

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2556506280...
Checkpoint 2556506280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.70569
Policy Entropy: 2.42022
Value Function Loss: 0.02296

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.09051
Policy Update Magnitude: 0.49688
Value Function Update Magnitude: 0.65595

Collected Steps per Second: 21,835.78940
Overall Steps per Second: 10,556.96798

Timestep Collection Time: 2.29046
Timestep Consumption Time: 2.44707
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.73753

Cumulative Model Updates: 306,544
Cumulative Timesteps: 2,556,556,294

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.46865
Policy Entropy: 2.41977
Value Function Loss: 0.02200

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.09050
Policy Update Magnitude: 0.49064
Value Function Update Magnitude: 0.64156

Collected Steps per Second: 21,854.70203
Overall Steps per Second: 10,528.53046

Timestep Collection Time: 2.28793
Timestep Consumption Time: 2.46126
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.74919

Cumulative Model Updates: 306,550
Cumulative Timesteps: 2,556,606,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2556606296...
Checkpoint 2556606296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.60649
Policy Entropy: 2.41829
Value Function Loss: 0.02177

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.09146
Policy Update Magnitude: 0.49377
Value Function Update Magnitude: 0.64109

Collected Steps per Second: 23,017.87904
Overall Steps per Second: 10,604.18675

Timestep Collection Time: 2.17275
Timestep Consumption Time: 2.54350
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.71625

Cumulative Model Updates: 306,556
Cumulative Timesteps: 2,556,656,308

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.56339
Policy Entropy: 2.38894
Value Function Loss: 0.02195

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.09539
Policy Update Magnitude: 0.49286
Value Function Update Magnitude: 0.63942

Collected Steps per Second: 22,063.01842
Overall Steps per Second: 10,464.58093

Timestep Collection Time: 2.26624
Timestep Consumption Time: 2.51179
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.77802

Cumulative Model Updates: 306,562
Cumulative Timesteps: 2,556,706,308

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2556706308...
Checkpoint 2556706308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.92383
Policy Entropy: 2.39577
Value Function Loss: 0.02189

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.10677
Policy Update Magnitude: 0.48556
Value Function Update Magnitude: 0.64655

Collected Steps per Second: 22,105.20513
Overall Steps per Second: 10,709.40169

Timestep Collection Time: 2.26191
Timestep Consumption Time: 2.40688
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.66879

Cumulative Model Updates: 306,568
Cumulative Timesteps: 2,556,756,308

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.85520
Policy Entropy: 2.37727
Value Function Loss: 0.02247

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.10105
Policy Update Magnitude: 0.48939
Value Function Update Magnitude: 0.64562

Collected Steps per Second: 22,284.77922
Overall Steps per Second: 10,828.12939

Timestep Collection Time: 2.24485
Timestep Consumption Time: 2.37515
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.62000

Cumulative Model Updates: 306,574
Cumulative Timesteps: 2,556,806,334

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2556806334...
Checkpoint 2556806334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.43732
Policy Entropy: 2.38061
Value Function Loss: 0.02185

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.09258
Policy Update Magnitude: 0.48728
Value Function Update Magnitude: 0.64071

Collected Steps per Second: 22,180.42500
Overall Steps per Second: 10,641.15739

Timestep Collection Time: 2.25496
Timestep Consumption Time: 2.44528
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.70024

Cumulative Model Updates: 306,580
Cumulative Timesteps: 2,556,856,350

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.36676
Policy Entropy: 2.38007
Value Function Loss: 0.02208

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.09542
Policy Update Magnitude: 0.48333
Value Function Update Magnitude: 0.62661

Collected Steps per Second: 21,986.66138
Overall Steps per Second: 10,473.32341

Timestep Collection Time: 2.27529
Timestep Consumption Time: 2.50123
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.77652

Cumulative Model Updates: 306,586
Cumulative Timesteps: 2,556,906,376

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2556906376...
Checkpoint 2556906376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.62695
Policy Entropy: 2.37938
Value Function Loss: 0.02245

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.10052
Policy Update Magnitude: 0.48536
Value Function Update Magnitude: 0.62364

Collected Steps per Second: 21,922.05145
Overall Steps per Second: 10,658.78021

Timestep Collection Time: 2.28154
Timestep Consumption Time: 2.41093
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.69247

Cumulative Model Updates: 306,592
Cumulative Timesteps: 2,556,956,392

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.07136
Policy Entropy: 2.39854
Value Function Loss: 0.02182

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.48998
Value Function Update Magnitude: 0.63097

Collected Steps per Second: 21,999.59778
Overall Steps per Second: 10,638.11775

Timestep Collection Time: 2.27341
Timestep Consumption Time: 2.42799
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.70140

Cumulative Model Updates: 306,598
Cumulative Timesteps: 2,557,006,406

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2557006406...
Checkpoint 2557006406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.69761
Policy Entropy: 2.40900
Value Function Loss: 0.02051

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.09605
Policy Update Magnitude: 0.48346
Value Function Update Magnitude: 0.62790

Collected Steps per Second: 22,079.90712
Overall Steps per Second: 10,447.14874

Timestep Collection Time: 2.26532
Timestep Consumption Time: 2.52240
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.78772

Cumulative Model Updates: 306,604
Cumulative Timesteps: 2,557,056,424

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.08447
Policy Entropy: 2.40941
Value Function Loss: 0.02019

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.09257
Policy Update Magnitude: 0.47896
Value Function Update Magnitude: 0.59943

Collected Steps per Second: 22,224.51515
Overall Steps per Second: 10,481.78333

Timestep Collection Time: 2.25040
Timestep Consumption Time: 2.52112
PPO Batch Consumption Time: 0.29485
Total Iteration Time: 4.77152

Cumulative Model Updates: 306,610
Cumulative Timesteps: 2,557,106,438

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2557106438...
Checkpoint 2557106438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.60453
Policy Entropy: 2.40271
Value Function Loss: 0.01957

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.09268
Policy Update Magnitude: 0.48061
Value Function Update Magnitude: 0.59763

Collected Steps per Second: 22,091.26100
Overall Steps per Second: 10,702.78681

Timestep Collection Time: 2.26461
Timestep Consumption Time: 2.40969
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.67430

Cumulative Model Updates: 306,616
Cumulative Timesteps: 2,557,156,466

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.87109
Policy Entropy: 2.39126
Value Function Loss: 0.01950

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.08968
Policy Update Magnitude: 0.48240
Value Function Update Magnitude: 0.60651

Collected Steps per Second: 22,047.82491
Overall Steps per Second: 10,781.10694

Timestep Collection Time: 2.26780
Timestep Consumption Time: 2.36995
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.63774

Cumulative Model Updates: 306,622
Cumulative Timesteps: 2,557,206,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2557206466...
Checkpoint 2557206466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.94678
Policy Entropy: 2.38245
Value Function Loss: 0.01955

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.08430
Policy Update Magnitude: 0.48107
Value Function Update Magnitude: 0.61218

Collected Steps per Second: 22,134.01375
Overall Steps per Second: 10,628.39334

Timestep Collection Time: 2.25897
Timestep Consumption Time: 2.44541
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.70438

Cumulative Model Updates: 306,628
Cumulative Timesteps: 2,557,256,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.56947
Policy Entropy: 2.36850
Value Function Loss: 0.02096

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.08790
Policy Update Magnitude: 0.49134
Value Function Update Magnitude: 0.62194

Collected Steps per Second: 22,358.64790
Overall Steps per Second: 10,548.30463

Timestep Collection Time: 2.23806
Timestep Consumption Time: 2.50583
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.74389

Cumulative Model Updates: 306,634
Cumulative Timesteps: 2,557,306,506

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2557306506...
Checkpoint 2557306506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.95505
Policy Entropy: 2.37533
Value Function Loss: 0.02116

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.49704
Value Function Update Magnitude: 0.64936

Collected Steps per Second: 22,024.82775
Overall Steps per Second: 10,691.52696

Timestep Collection Time: 2.27135
Timestep Consumption Time: 2.40769
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.67903

Cumulative Model Updates: 306,640
Cumulative Timesteps: 2,557,356,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.71912
Policy Entropy: 2.40086
Value Function Loss: 0.02078

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.49329
Value Function Update Magnitude: 0.64753

Collected Steps per Second: 21,933.82300
Overall Steps per Second: 10,740.96562

Timestep Collection Time: 2.28104
Timestep Consumption Time: 2.37701
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.65805

Cumulative Model Updates: 306,646
Cumulative Timesteps: 2,557,406,564

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2557406564...
Checkpoint 2557406564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.50972
Policy Entropy: 2.44243
Value Function Loss: 0.02028

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.48695
Value Function Update Magnitude: 0.63393

Collected Steps per Second: 21,983.67862
Overall Steps per Second: 10,482.47229

Timestep Collection Time: 2.27487
Timestep Consumption Time: 2.49595
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.77082

Cumulative Model Updates: 306,652
Cumulative Timesteps: 2,557,456,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.20306
Policy Entropy: 2.42462
Value Function Loss: 0.02083

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.09894
Policy Update Magnitude: 0.48241
Value Function Update Magnitude: 0.63558

Collected Steps per Second: 22,166.84525
Overall Steps per Second: 10,623.79113

Timestep Collection Time: 2.25589
Timestep Consumption Time: 2.45109
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.70698

Cumulative Model Updates: 306,658
Cumulative Timesteps: 2,557,506,580

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2557506580...
Checkpoint 2557506580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.50485
Policy Entropy: 2.41963
Value Function Loss: 0.02053

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.47816
Value Function Update Magnitude: 0.64188

Collected Steps per Second: 21,690.64535
Overall Steps per Second: 10,450.93231

Timestep Collection Time: 2.30533
Timestep Consumption Time: 2.47932
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.78464

Cumulative Model Updates: 306,664
Cumulative Timesteps: 2,557,556,584

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.94088
Policy Entropy: 2.39852
Value Function Loss: 0.01929

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.08545
Policy Update Magnitude: 0.48055
Value Function Update Magnitude: 0.65233

Collected Steps per Second: 22,210.72483
Overall Steps per Second: 10,744.58689

Timestep Collection Time: 2.25152
Timestep Consumption Time: 2.40273
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.65425

Cumulative Model Updates: 306,670
Cumulative Timesteps: 2,557,606,592

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2557606592...
Checkpoint 2557606592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.14398
Policy Entropy: 2.39962
Value Function Loss: 0.01864

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.09531
Policy Update Magnitude: 0.48800
Value Function Update Magnitude: 0.65158

Collected Steps per Second: 22,158.52742
Overall Steps per Second: 10,673.05397

Timestep Collection Time: 2.25764
Timestep Consumption Time: 2.42949
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.68713

Cumulative Model Updates: 306,676
Cumulative Timesteps: 2,557,656,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.53488
Policy Entropy: 2.38137
Value Function Loss: 0.01917

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.09689
Policy Update Magnitude: 0.49071
Value Function Update Magnitude: 0.65262

Collected Steps per Second: 22,114.43708
Overall Steps per Second: 10,428.37037

Timestep Collection Time: 2.26205
Timestep Consumption Time: 2.53486
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.79691

Cumulative Model Updates: 306,682
Cumulative Timesteps: 2,557,706,642

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2557706642...
Checkpoint 2557706642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.81189
Policy Entropy: 2.38887
Value Function Loss: 0.01876

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.47624
Value Function Update Magnitude: 0.65929

Collected Steps per Second: 21,817.53419
Overall Steps per Second: 10,614.48702

Timestep Collection Time: 2.29201
Timestep Consumption Time: 2.41910
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.71111

Cumulative Model Updates: 306,688
Cumulative Timesteps: 2,557,756,648

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.31399
Policy Entropy: 2.39754
Value Function Loss: 0.02011

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.09711
Policy Update Magnitude: 0.49250
Value Function Update Magnitude: 0.64825

Collected Steps per Second: 22,001.63301
Overall Steps per Second: 10,634.48621

Timestep Collection Time: 2.27310
Timestep Consumption Time: 2.42971
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.70281

Cumulative Model Updates: 306,694
Cumulative Timesteps: 2,557,806,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2557806660...
Checkpoint 2557806660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.99665
Policy Entropy: 2.39166
Value Function Loss: 0.01978

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.11127
Policy Update Magnitude: 0.48040
Value Function Update Magnitude: 0.63477

Collected Steps per Second: 22,151.95690
Overall Steps per Second: 10,472.77377

Timestep Collection Time: 2.25795
Timestep Consumption Time: 2.51805
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.77600

Cumulative Model Updates: 306,700
Cumulative Timesteps: 2,557,856,678

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.20154
Policy Entropy: 2.38994
Value Function Loss: 0.02069

Mean KL Divergence: 0.02478
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.47551
Value Function Update Magnitude: 0.64491

Collected Steps per Second: 22,345.31021
Overall Steps per Second: 10,504.08981

Timestep Collection Time: 2.23779
Timestep Consumption Time: 2.52265
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.76043

Cumulative Model Updates: 306,706
Cumulative Timesteps: 2,557,906,682

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2557906682...
Checkpoint 2557906682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.46996
Policy Entropy: 2.37288
Value Function Loss: 0.02099

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.13109
Policy Update Magnitude: 0.50957
Value Function Update Magnitude: 0.65369

Collected Steps per Second: 22,107.04832
Overall Steps per Second: 10,596.19798

Timestep Collection Time: 2.26263
Timestep Consumption Time: 2.45793
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.72056

Cumulative Model Updates: 306,712
Cumulative Timesteps: 2,557,956,702

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.33004
Policy Entropy: 2.35806
Value Function Loss: 0.02210

Mean KL Divergence: 0.02112
SB3 Clip Fraction: 0.12755
Policy Update Magnitude: 0.52084
Value Function Update Magnitude: 0.66371

Collected Steps per Second: 21,376.76338
Overall Steps per Second: 10,444.52644

Timestep Collection Time: 2.34020
Timestep Consumption Time: 2.44948
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.78969

Cumulative Model Updates: 306,718
Cumulative Timesteps: 2,558,006,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2558006728...
Checkpoint 2558006728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.08051
Policy Entropy: 2.36591
Value Function Loss: 0.02187

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.10751
Policy Update Magnitude: 0.50301
Value Function Update Magnitude: 0.67346

Collected Steps per Second: 22,191.66184
Overall Steps per Second: 10,640.78850

Timestep Collection Time: 2.25310
Timestep Consumption Time: 2.44580
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.69890

Cumulative Model Updates: 306,724
Cumulative Timesteps: 2,558,056,728

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.41921
Policy Entropy: 2.38470
Value Function Loss: 0.02033

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.09819
Policy Update Magnitude: 0.49649
Value Function Update Magnitude: 0.67271

Collected Steps per Second: 21,934.25774
Overall Steps per Second: 10,481.37221

Timestep Collection Time: 2.28045
Timestep Consumption Time: 2.49182
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.77228

Cumulative Model Updates: 306,730
Cumulative Timesteps: 2,558,106,748

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2558106748...
Checkpoint 2558106748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.75224
Policy Entropy: 2.42289
Value Function Loss: 0.02055

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.08776
Policy Update Magnitude: 0.49132
Value Function Update Magnitude: 0.65731

Collected Steps per Second: 22,047.06850
Overall Steps per Second: 10,640.94768

Timestep Collection Time: 2.26905
Timestep Consumption Time: 2.43222
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.70127

Cumulative Model Updates: 306,736
Cumulative Timesteps: 2,558,156,774

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.62511
Policy Entropy: 2.41280
Value Function Loss: 0.02117

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.09035
Policy Update Magnitude: 0.50412
Value Function Update Magnitude: 0.66934

Collected Steps per Second: 22,277.52600
Overall Steps per Second: 10,504.09666

Timestep Collection Time: 2.24477
Timestep Consumption Time: 2.51604
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.76081

Cumulative Model Updates: 306,742
Cumulative Timesteps: 2,558,206,782

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2558206782...
Checkpoint 2558206782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.35818
Policy Entropy: 2.43004
Value Function Loss: 0.02119

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.09521
Policy Update Magnitude: 0.50760
Value Function Update Magnitude: 0.69539

Collected Steps per Second: 22,095.23167
Overall Steps per Second: 10,559.00300

Timestep Collection Time: 2.26402
Timestep Consumption Time: 2.47355
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.73757

Cumulative Model Updates: 306,748
Cumulative Timesteps: 2,558,256,806

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.13709
Policy Entropy: 2.42869
Value Function Loss: 0.01967

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.09047
Policy Update Magnitude: 0.49842
Value Function Update Magnitude: 0.69305

Collected Steps per Second: 22,160.38494
Overall Steps per Second: 10,728.44231

Timestep Collection Time: 2.25664
Timestep Consumption Time: 2.40461
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.66125

Cumulative Model Updates: 306,754
Cumulative Timesteps: 2,558,306,814

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2558306814...
Checkpoint 2558306814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.55189
Policy Entropy: 2.43602
Value Function Loss: 0.01965

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.07888
Policy Update Magnitude: 0.49182
Value Function Update Magnitude: 0.67651

Collected Steps per Second: 22,472.94025
Overall Steps per Second: 10,583.42294

Timestep Collection Time: 2.22508
Timestep Consumption Time: 2.49967
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.72475

Cumulative Model Updates: 306,760
Cumulative Timesteps: 2,558,356,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.33506
Policy Entropy: 2.42276
Value Function Loss: 0.01970

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.08419
Policy Update Magnitude: 0.48797
Value Function Update Magnitude: 0.67016

Collected Steps per Second: 22,153.58683
Overall Steps per Second: 10,617.29622

Timestep Collection Time: 2.25724
Timestep Consumption Time: 2.45262
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.70986

Cumulative Model Updates: 306,766
Cumulative Timesteps: 2,558,406,824

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2558406824...
Checkpoint 2558406824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.85213
Policy Entropy: 2.41223
Value Function Loss: 0.01932

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.08985
Policy Update Magnitude: 0.48256
Value Function Update Magnitude: 0.65487

Collected Steps per Second: 21,946.21764
Overall Steps per Second: 10,652.15852

Timestep Collection Time: 2.27939
Timestep Consumption Time: 2.41675
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.69614

Cumulative Model Updates: 306,772
Cumulative Timesteps: 2,558,456,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.02170
Policy Entropy: 2.41552
Value Function Loss: 0.01914

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.48139
Value Function Update Magnitude: 0.64826

Collected Steps per Second: 21,826.10494
Overall Steps per Second: 10,577.97831

Timestep Collection Time: 2.29230
Timestep Consumption Time: 2.43753
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.72983

Cumulative Model Updates: 306,778
Cumulative Timesteps: 2,558,506,880

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2558506880...
Checkpoint 2558506880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.59143
Policy Entropy: 2.40263
Value Function Loss: 0.01916

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.48891
Value Function Update Magnitude: 0.64368

Collected Steps per Second: 22,299.00006
Overall Steps per Second: 10,639.71833

Timestep Collection Time: 2.24234
Timestep Consumption Time: 2.45722
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.69956

Cumulative Model Updates: 306,784
Cumulative Timesteps: 2,558,556,882

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.97987
Policy Entropy: 2.38447
Value Function Loss: 0.02035

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.09515
Policy Update Magnitude: 0.49243
Value Function Update Magnitude: 0.65365

Collected Steps per Second: 21,959.48779
Overall Steps per Second: 10,416.02276

Timestep Collection Time: 2.27747
Timestep Consumption Time: 2.52398
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.80145

Cumulative Model Updates: 306,790
Cumulative Timesteps: 2,558,606,894

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2558606894...
Checkpoint 2558606894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.07888
Policy Entropy: 2.38261
Value Function Loss: 0.02100

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.10227
Policy Update Magnitude: 0.49581
Value Function Update Magnitude: 0.68673

Collected Steps per Second: 21,929.39297
Overall Steps per Second: 10,652.30654

Timestep Collection Time: 2.28141
Timestep Consumption Time: 2.41522
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.69664

Cumulative Model Updates: 306,796
Cumulative Timesteps: 2,558,656,924

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.01933
Policy Entropy: 2.38548
Value Function Loss: 0.02164

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.48260
Value Function Update Magnitude: 0.69094

Collected Steps per Second: 22,102.44954
Overall Steps per Second: 10,681.44021

Timestep Collection Time: 2.26219
Timestep Consumption Time: 2.41882
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.68102

Cumulative Model Updates: 306,802
Cumulative Timesteps: 2,558,706,924

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2558706924...
Checkpoint 2558706924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.64364
Policy Entropy: 2.38121
Value Function Loss: 0.02212

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.11226
Policy Update Magnitude: 0.49281
Value Function Update Magnitude: 0.67905

Collected Steps per Second: 22,355.88891
Overall Steps per Second: 10,572.53532

Timestep Collection Time: 2.23717
Timestep Consumption Time: 2.49339
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.73056

Cumulative Model Updates: 306,808
Cumulative Timesteps: 2,558,756,938

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.99924
Policy Entropy: 2.35920
Value Function Loss: 0.02209

Mean KL Divergence: 0.02359
SB3 Clip Fraction: 0.13797
Policy Update Magnitude: 0.46843
Value Function Update Magnitude: 0.68098

Collected Steps per Second: 22,183.58165
Overall Steps per Second: 10,643.09578

Timestep Collection Time: 2.25428
Timestep Consumption Time: 2.44435
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.69863

Cumulative Model Updates: 306,814
Cumulative Timesteps: 2,558,806,946

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2558806946...
Checkpoint 2558806946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.66802
Policy Entropy: 2.34627
Value Function Loss: 0.02067

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.46917
Value Function Update Magnitude: 0.67338

Collected Steps per Second: 22,049.98847
Overall Steps per Second: 10,636.84188

Timestep Collection Time: 2.26812
Timestep Consumption Time: 2.43365
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.70177

Cumulative Model Updates: 306,820
Cumulative Timesteps: 2,558,856,958

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.26702
Policy Entropy: 2.34370
Value Function Loss: 0.02056

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.10308
Policy Update Magnitude: 0.49298
Value Function Update Magnitude: 0.65847

Collected Steps per Second: 21,974.30444
Overall Steps per Second: 10,601.02150

Timestep Collection Time: 2.27611
Timestep Consumption Time: 2.44192
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.71804

Cumulative Model Updates: 306,826
Cumulative Timesteps: 2,558,906,974

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2558906974...
Checkpoint 2558906974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.40958
Policy Entropy: 2.36580
Value Function Loss: 0.02040

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.49306
Value Function Update Magnitude: 0.67094

Collected Steps per Second: 22,305.60001
Overall Steps per Second: 10,594.58984

Timestep Collection Time: 2.24222
Timestep Consumption Time: 2.47849
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.72071

Cumulative Model Updates: 306,832
Cumulative Timesteps: 2,558,956,988

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.58289
Policy Entropy: 2.36992
Value Function Loss: 0.02037

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.09929
Policy Update Magnitude: 0.49390
Value Function Update Magnitude: 0.67949

Collected Steps per Second: 21,872.67298
Overall Steps per Second: 10,448.94194

Timestep Collection Time: 2.28605
Timestep Consumption Time: 2.49932
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.78536

Cumulative Model Updates: 306,838
Cumulative Timesteps: 2,559,006,990

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2559006990...
Checkpoint 2559006990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.07076
Policy Entropy: 2.40003
Value Function Loss: 0.02047

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.09680
Policy Update Magnitude: 0.49307
Value Function Update Magnitude: 0.70807

Collected Steps per Second: 22,071.86078
Overall Steps per Second: 10,643.96182

Timestep Collection Time: 2.26596
Timestep Consumption Time: 2.43285
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.69881

Cumulative Model Updates: 306,844
Cumulative Timesteps: 2,559,057,004

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.07653
Policy Entropy: 2.37567
Value Function Loss: 0.02065

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.09785
Policy Update Magnitude: 0.50183
Value Function Update Magnitude: 0.72004

Collected Steps per Second: 22,104.58591
Overall Steps per Second: 10,673.60009

Timestep Collection Time: 2.26225
Timestep Consumption Time: 2.42277
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.68502

Cumulative Model Updates: 306,850
Cumulative Timesteps: 2,559,107,010

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2559107010...
Checkpoint 2559107010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.70460
Policy Entropy: 2.37688
Value Function Loss: 0.02053

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.10513
Policy Update Magnitude: 0.50134
Value Function Update Magnitude: 0.68901

Collected Steps per Second: 22,327.36288
Overall Steps per Second: 10,543.89086

Timestep Collection Time: 2.24030
Timestep Consumption Time: 2.50368
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.74398

Cumulative Model Updates: 306,856
Cumulative Timesteps: 2,559,157,030

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.17252
Policy Entropy: 2.34622
Value Function Loss: 0.02058

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.11767
Policy Update Magnitude: 0.46865
Value Function Update Magnitude: 0.66975

Collected Steps per Second: 22,075.69445
Overall Steps per Second: 10,429.64276

Timestep Collection Time: 2.26530
Timestep Consumption Time: 2.52950
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.79480

Cumulative Model Updates: 306,862
Cumulative Timesteps: 2,559,207,038

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2559207038...
Checkpoint 2559207038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.41361
Policy Entropy: 2.35563
Value Function Loss: 0.02125

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.12693
Policy Update Magnitude: 0.44496
Value Function Update Magnitude: 0.64842

Collected Steps per Second: 21,989.19092
Overall Steps per Second: 10,543.54482

Timestep Collection Time: 2.27475
Timestep Consumption Time: 2.46938
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.74413

Cumulative Model Updates: 306,868
Cumulative Timesteps: 2,559,257,058

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.68521
Policy Entropy: 2.35895
Value Function Loss: 0.02176

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.10554
Policy Update Magnitude: 0.46819
Value Function Update Magnitude: 0.66093

Collected Steps per Second: 22,289.08492
Overall Steps per Second: 10,843.52528

Timestep Collection Time: 2.24397
Timestep Consumption Time: 2.36855
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.61252

Cumulative Model Updates: 306,874
Cumulative Timesteps: 2,559,307,074

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2559307074...
Checkpoint 2559307074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.33426
Policy Entropy: 2.33892
Value Function Loss: 0.02229

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.10783
Policy Update Magnitude: 0.48657
Value Function Update Magnitude: 0.65220

Collected Steps per Second: 21,887.14825
Overall Steps per Second: 10,639.48766

Timestep Collection Time: 2.28536
Timestep Consumption Time: 2.41599
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.70135

Cumulative Model Updates: 306,880
Cumulative Timesteps: 2,559,357,094

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.02020
Policy Entropy: 2.35366
Value Function Loss: 0.02277

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.11806
Policy Update Magnitude: 0.49395
Value Function Update Magnitude: 0.65068

Collected Steps per Second: 22,074.74740
Overall Steps per Second: 10,533.56496

Timestep Collection Time: 2.26639
Timestep Consumption Time: 2.48319
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.74958

Cumulative Model Updates: 306,886
Cumulative Timesteps: 2,559,407,124

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2559407124...
Checkpoint 2559407124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.90170
Policy Entropy: 2.35022
Value Function Loss: 0.02250

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.11500
Policy Update Magnitude: 0.50021
Value Function Update Magnitude: 0.65912

Collected Steps per Second: 21,844.09115
Overall Steps per Second: 10,614.67370

Timestep Collection Time: 2.29050
Timestep Consumption Time: 2.42316
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.71366

Cumulative Model Updates: 306,892
Cumulative Timesteps: 2,559,457,158

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.76741
Policy Entropy: 2.37593
Value Function Loss: 0.02214

Mean KL Divergence: 0.02093
SB3 Clip Fraction: 0.12236
Policy Update Magnitude: 0.49873
Value Function Update Magnitude: 0.66366

Collected Steps per Second: 22,313.49117
Overall Steps per Second: 10,882.16971

Timestep Collection Time: 2.24187
Timestep Consumption Time: 2.35500
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.59688

Cumulative Model Updates: 306,898
Cumulative Timesteps: 2,559,507,182

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2559507182...
Checkpoint 2559507182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.88985
Policy Entropy: 2.39032
Value Function Loss: 0.02079

Mean KL Divergence: 0.02625
SB3 Clip Fraction: 0.14209
Policy Update Magnitude: 0.47876
Value Function Update Magnitude: 0.64715

Collected Steps per Second: 22,109.94552
Overall Steps per Second: 10,647.88674

Timestep Collection Time: 2.26215
Timestep Consumption Time: 2.43512
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.69727

Cumulative Model Updates: 306,904
Cumulative Timesteps: 2,559,557,198

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.14091
Policy Entropy: 2.38132
Value Function Loss: 0.02038

Mean KL Divergence: 0.02400
SB3 Clip Fraction: 0.12982
Policy Update Magnitude: 0.47248
Value Function Update Magnitude: 0.62422

Collected Steps per Second: 22,167.93822
Overall Steps per Second: 10,519.39657

Timestep Collection Time: 2.25677
Timestep Consumption Time: 2.49901
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.75579

Cumulative Model Updates: 306,910
Cumulative Timesteps: 2,559,607,226

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2559607226...
Checkpoint 2559607226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.95259
Policy Entropy: 2.38087
Value Function Loss: 0.02008

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.11516
Policy Update Magnitude: 0.49685
Value Function Update Magnitude: 0.61304

Collected Steps per Second: 22,160.70067
Overall Steps per Second: 10,619.83276

Timestep Collection Time: 2.25634
Timestep Consumption Time: 2.45202
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.70836

Cumulative Model Updates: 306,916
Cumulative Timesteps: 2,559,657,228

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.86674
Policy Entropy: 2.36221
Value Function Loss: 0.01959

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.09825
Policy Update Magnitude: 0.50511
Value Function Update Magnitude: 0.61058

Collected Steps per Second: 22,388.76461
Overall Steps per Second: 10,884.55699

Timestep Collection Time: 2.23380
Timestep Consumption Time: 2.36097
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.59477

Cumulative Model Updates: 306,922
Cumulative Timesteps: 2,559,707,240

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2559707240...
Checkpoint 2559707240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.89939
Policy Entropy: 2.35882
Value Function Loss: 0.01980

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.09760
Policy Update Magnitude: 0.49865
Value Function Update Magnitude: 0.59652

Collected Steps per Second: 21,335.16125
Overall Steps per Second: 10,621.56677

Timestep Collection Time: 2.34467
Timestep Consumption Time: 2.36499
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.70966

Cumulative Model Updates: 306,928
Cumulative Timesteps: 2,559,757,264

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.65972
Policy Entropy: 2.34685
Value Function Loss: 0.02022

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.50166
Value Function Update Magnitude: 0.60546

Collected Steps per Second: 22,099.63010
Overall Steps per Second: 10,528.27615

Timestep Collection Time: 2.26339
Timestep Consumption Time: 2.48763
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.75102

Cumulative Model Updates: 306,934
Cumulative Timesteps: 2,559,807,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2559807284...
Checkpoint 2559807284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.32156
Policy Entropy: 2.35731
Value Function Loss: 0.01973

Mean KL Divergence: 0.02391
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.47052
Value Function Update Magnitude: 0.60531

Collected Steps per Second: 21,909.49774
Overall Steps per Second: 10,549.23116

Timestep Collection Time: 2.28212
Timestep Consumption Time: 2.45757
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.73968

Cumulative Model Updates: 306,940
Cumulative Timesteps: 2,559,857,284

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.47915
Policy Entropy: 2.36512
Value Function Loss: 0.02033

Mean KL Divergence: 0.02592
SB3 Clip Fraction: 0.13684
Policy Update Magnitude: 0.47899
Value Function Update Magnitude: 0.61777

Collected Steps per Second: 22,095.41287
Overall Steps per Second: 10,528.33797

Timestep Collection Time: 2.26382
Timestep Consumption Time: 2.48717
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.75099

Cumulative Model Updates: 306,946
Cumulative Timesteps: 2,559,907,304

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2559907304...
Checkpoint 2559907304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.24818
Policy Entropy: 2.37602
Value Function Loss: 0.01945

Mean KL Divergence: 0.02717
SB3 Clip Fraction: 0.14470
Policy Update Magnitude: 0.48373
Value Function Update Magnitude: 0.63733

Collected Steps per Second: 22,153.13348
Overall Steps per Second: 10,650.37070

Timestep Collection Time: 2.25819
Timestep Consumption Time: 2.43892
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.69711

Cumulative Model Updates: 306,952
Cumulative Timesteps: 2,559,957,330

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.60970
Policy Entropy: 2.35342
Value Function Loss: 0.02092

Mean KL Divergence: 0.02647
SB3 Clip Fraction: 0.13925
Policy Update Magnitude: 0.48349
Value Function Update Magnitude: 0.64965

Collected Steps per Second: 21,741.47060
Overall Steps per Second: 10,450.88180

Timestep Collection Time: 2.30196
Timestep Consumption Time: 2.48692
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.78888

Cumulative Model Updates: 306,958
Cumulative Timesteps: 2,560,007,378

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2560007378...
Checkpoint 2560007378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.57020
Policy Entropy: 2.36167
Value Function Loss: 0.02018

Mean KL Divergence: 0.02416
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.47745
Value Function Update Magnitude: 0.65050

Collected Steps per Second: 21,967.41759
Overall Steps per Second: 10,579.38559

Timestep Collection Time: 2.27710
Timestep Consumption Time: 2.45115
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.72825

Cumulative Model Updates: 306,964
Cumulative Timesteps: 2,560,057,400

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.31599
Policy Entropy: 2.35286
Value Function Loss: 0.02120

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.12145
Policy Update Magnitude: 0.49701
Value Function Update Magnitude: 0.65631

Collected Steps per Second: 22,370.69127
Overall Steps per Second: 10,542.71902

Timestep Collection Time: 2.23587
Timestep Consumption Time: 2.50844
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.74432

Cumulative Model Updates: 306,970
Cumulative Timesteps: 2,560,107,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2560107418...
Checkpoint 2560107418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.46304
Policy Entropy: 2.35253
Value Function Loss: 0.02057

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.11548
Policy Update Magnitude: 0.51592
Value Function Update Magnitude: 0.64102

Collected Steps per Second: 22,208.05999
Overall Steps per Second: 10,634.08970

Timestep Collection Time: 2.25216
Timestep Consumption Time: 2.45121
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.70336

Cumulative Model Updates: 306,976
Cumulative Timesteps: 2,560,157,434

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.24774
Policy Entropy: 2.36117
Value Function Loss: 0.02074

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.10131
Policy Update Magnitude: 0.50477
Value Function Update Magnitude: 0.62251

Collected Steps per Second: 22,301.35943
Overall Steps per Second: 10,493.21729

Timestep Collection Time: 2.24336
Timestep Consumption Time: 2.52448
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.76784

Cumulative Model Updates: 306,982
Cumulative Timesteps: 2,560,207,464

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2560207464...
Checkpoint 2560207464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.69116
Policy Entropy: 2.35204
Value Function Loss: 0.02115

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.50333
Value Function Update Magnitude: 0.61334

Collected Steps per Second: 22,041.21693
Overall Steps per Second: 10,600.63010

Timestep Collection Time: 2.26920
Timestep Consumption Time: 2.44901
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.71821

Cumulative Model Updates: 306,988
Cumulative Timesteps: 2,560,257,480

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.91645
Policy Entropy: 2.38674
Value Function Loss: 0.02163

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.49557
Value Function Update Magnitude: 0.63324

Collected Steps per Second: 22,172.63244
Overall Steps per Second: 10,511.84584

Timestep Collection Time: 2.25539
Timestep Consumption Time: 2.50191
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.75730

Cumulative Model Updates: 306,994
Cumulative Timesteps: 2,560,307,488

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2560307488...
Checkpoint 2560307488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.86217
Policy Entropy: 2.39203
Value Function Loss: 0.02111

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.09444
Policy Update Magnitude: 0.48607
Value Function Update Magnitude: 0.64175

Collected Steps per Second: 22,848.54933
Overall Steps per Second: 10,662.85019

Timestep Collection Time: 2.18902
Timestep Consumption Time: 2.50166
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.69068

Cumulative Model Updates: 307,000
Cumulative Timesteps: 2,560,357,504

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.91472
Policy Entropy: 2.42142
Value Function Loss: 0.02112

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.09438
Policy Update Magnitude: 0.49493
Value Function Update Magnitude: 0.65089

Collected Steps per Second: 22,426.31780
Overall Steps per Second: 10,588.55027

Timestep Collection Time: 2.23086
Timestep Consumption Time: 2.49405
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.72491

Cumulative Model Updates: 307,006
Cumulative Timesteps: 2,560,407,534

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2560407534...
Checkpoint 2560407534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.11398
Policy Entropy: 2.41362
Value Function Loss: 0.02029

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.09958
Policy Update Magnitude: 0.49597
Value Function Update Magnitude: 0.65619

Collected Steps per Second: 22,112.00264
Overall Steps per Second: 10,428.28965

Timestep Collection Time: 2.26185
Timestep Consumption Time: 2.53414
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.79599

Cumulative Model Updates: 307,012
Cumulative Timesteps: 2,560,457,548

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.94675
Policy Entropy: 2.41518
Value Function Loss: 0.01958

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.09331
Policy Update Magnitude: 0.49801
Value Function Update Magnitude: 0.64558

Collected Steps per Second: 22,091.23041
Overall Steps per Second: 10,503.31136

Timestep Collection Time: 2.26398
Timestep Consumption Time: 2.49776
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.76174

Cumulative Model Updates: 307,018
Cumulative Timesteps: 2,560,507,562

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2560507562...
Checkpoint 2560507562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.53502
Policy Entropy: 2.40816
Value Function Loss: 0.01867

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.08968
Policy Update Magnitude: 0.49019
Value Function Update Magnitude: 0.61444

Collected Steps per Second: 21,831.32140
Overall Steps per Second: 10,601.70190

Timestep Collection Time: 2.29120
Timestep Consumption Time: 2.42691
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.71811

Cumulative Model Updates: 307,024
Cumulative Timesteps: 2,560,557,582

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.79892
Policy Entropy: 2.40699
Value Function Loss: 0.01987

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.08794
Policy Update Magnitude: 0.48716
Value Function Update Magnitude: 0.60593

Collected Steps per Second: 22,529.75264
Overall Steps per Second: 10,568.48436

Timestep Collection Time: 2.22044
Timestep Consumption Time: 2.51307
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.73351

Cumulative Model Updates: 307,030
Cumulative Timesteps: 2,560,607,608

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2560607608...
Checkpoint 2560607608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.45499
Policy Entropy: 2.38919
Value Function Loss: 0.02083

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.09309
Policy Update Magnitude: 0.49095
Value Function Update Magnitude: 0.64592

Collected Steps per Second: 22,100.52558
Overall Steps per Second: 10,528.83171

Timestep Collection Time: 2.26311
Timestep Consumption Time: 2.48727
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.75038

Cumulative Model Updates: 307,036
Cumulative Timesteps: 2,560,657,624

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.14260
Policy Entropy: 2.37813
Value Function Loss: 0.02002

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.09851
Policy Update Magnitude: 0.48722
Value Function Update Magnitude: 0.65249

Collected Steps per Second: 22,296.04325
Overall Steps per Second: 10,538.49116

Timestep Collection Time: 2.24399
Timestep Consumption Time: 2.50356
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.74755

Cumulative Model Updates: 307,042
Cumulative Timesteps: 2,560,707,656

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2560707656...
Checkpoint 2560707656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.89970
Policy Entropy: 2.36801
Value Function Loss: 0.01951

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.11517
Policy Update Magnitude: 0.48142
Value Function Update Magnitude: 0.62488

Collected Steps per Second: 21,743.16422
Overall Steps per Second: 10,580.67593

Timestep Collection Time: 2.30068
Timestep Consumption Time: 2.42719
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.72786

Cumulative Model Updates: 307,048
Cumulative Timesteps: 2,560,757,680

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.31879
Policy Entropy: 2.37819
Value Function Loss: 0.01942

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.46891
Value Function Update Magnitude: 0.60456

Collected Steps per Second: 22,297.61332
Overall Steps per Second: 10,482.44188

Timestep Collection Time: 2.24365
Timestep Consumption Time: 2.52890
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.77255

Cumulative Model Updates: 307,054
Cumulative Timesteps: 2,560,807,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2560807708...
Checkpoint 2560807708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.85406
Policy Entropy: 2.39930
Value Function Loss: 0.02085

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.11556
Policy Update Magnitude: 0.48967
Value Function Update Magnitude: 0.60945

Collected Steps per Second: 21,962.20227
Overall Steps per Second: 10,589.74374

Timestep Collection Time: 2.27800
Timestep Consumption Time: 2.44638
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.72438

Cumulative Model Updates: 307,060
Cumulative Timesteps: 2,560,857,738

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.22570
Policy Entropy: 2.39605
Value Function Loss: 0.02049

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.10636
Policy Update Magnitude: 0.49430
Value Function Update Magnitude: 0.62395

Collected Steps per Second: 22,178.91297
Overall Steps per Second: 10,529.46586

Timestep Collection Time: 2.25448
Timestep Consumption Time: 2.49429
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.74877

Cumulative Model Updates: 307,066
Cumulative Timesteps: 2,560,907,740

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2560907740...
Checkpoint 2560907740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.10477
Policy Entropy: 2.39715
Value Function Loss: 0.02051

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.09763
Policy Update Magnitude: 0.49155
Value Function Update Magnitude: 0.62224

Collected Steps per Second: 21,620.41112
Overall Steps per Second: 10,589.67418

Timestep Collection Time: 2.31309
Timestep Consumption Time: 2.40943
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.72252

Cumulative Model Updates: 307,072
Cumulative Timesteps: 2,560,957,750

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.42574
Policy Entropy: 2.36334
Value Function Loss: 0.02106

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.09957
Policy Update Magnitude: 0.49602
Value Function Update Magnitude: 0.62326

Collected Steps per Second: 22,445.84183
Overall Steps per Second: 10,502.42302

Timestep Collection Time: 2.22803
Timestep Consumption Time: 2.53373
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.76176

Cumulative Model Updates: 307,078
Cumulative Timesteps: 2,561,007,760

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2561007760...
Checkpoint 2561007760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.21084
Policy Entropy: 2.37781
Value Function Loss: 0.02097

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.49661
Value Function Update Magnitude: 0.66012

Collected Steps per Second: 22,015.44356
Overall Steps per Second: 10,561.82828

Timestep Collection Time: 2.27177
Timestep Consumption Time: 2.46359
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.73535

Cumulative Model Updates: 307,084
Cumulative Timesteps: 2,561,057,774

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.92139
Policy Entropy: 2.36278
Value Function Loss: 0.02093

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.09420
Policy Update Magnitude: 0.49369
Value Function Update Magnitude: 0.67623

Collected Steps per Second: 22,381.59483
Overall Steps per Second: 10,583.10886

Timestep Collection Time: 2.23469
Timestep Consumption Time: 2.49133
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.72602

Cumulative Model Updates: 307,090
Cumulative Timesteps: 2,561,107,790

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2561107790...
Checkpoint 2561107790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.58456
Policy Entropy: 2.37468
Value Function Loss: 0.02022

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.10062
Policy Update Magnitude: 0.50251
Value Function Update Magnitude: 0.67326

Collected Steps per Second: 22,922.18749
Overall Steps per Second: 10,699.96061

Timestep Collection Time: 2.18182
Timestep Consumption Time: 2.49222
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.67404

Cumulative Model Updates: 307,096
Cumulative Timesteps: 2,561,157,802

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.77823
Policy Entropy: 2.36827
Value Function Loss: 0.02030

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.09667
Policy Update Magnitude: 0.49801
Value Function Update Magnitude: 0.67811

Collected Steps per Second: 22,566.23185
Overall Steps per Second: 10,715.44205

Timestep Collection Time: 2.21632
Timestep Consumption Time: 2.45115
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.66747

Cumulative Model Updates: 307,102
Cumulative Timesteps: 2,561,207,816

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2561207816...
Checkpoint 2561207816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.19878
Policy Entropy: 2.37756
Value Function Loss: 0.02097

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.08935
Policy Update Magnitude: 0.50021
Value Function Update Magnitude: 0.68863

Collected Steps per Second: 22,080.68151
Overall Steps per Second: 10,718.27578

Timestep Collection Time: 2.26506
Timestep Consumption Time: 2.40118
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.66624

Cumulative Model Updates: 307,108
Cumulative Timesteps: 2,561,257,830

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.89696
Policy Entropy: 2.37682
Value Function Loss: 0.02192

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.08826
Policy Update Magnitude: 0.50969
Value Function Update Magnitude: 0.69358

Collected Steps per Second: 22,580.71420
Overall Steps per Second: 10,866.12371

Timestep Collection Time: 2.21472
Timestep Consumption Time: 2.38766
PPO Batch Consumption Time: 0.28426
Total Iteration Time: 4.60238

Cumulative Model Updates: 307,114
Cumulative Timesteps: 2,561,307,840

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2561307840...
Checkpoint 2561307840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.48714
Policy Entropy: 2.35347
Value Function Loss: 0.02263

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.50824
Value Function Update Magnitude: 0.71073

Collected Steps per Second: 21,706.71452
Overall Steps per Second: 10,562.09798

Timestep Collection Time: 2.30362
Timestep Consumption Time: 2.43067
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.73429

Cumulative Model Updates: 307,120
Cumulative Timesteps: 2,561,357,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.74276
Policy Entropy: 2.35778
Value Function Loss: 0.02136

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.09904
Policy Update Magnitude: 0.50648
Value Function Update Magnitude: 0.71934

Collected Steps per Second: 22,433.45363
Overall Steps per Second: 10,502.86257

Timestep Collection Time: 2.22881
Timestep Consumption Time: 2.53179
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 4.76061

Cumulative Model Updates: 307,126
Cumulative Timesteps: 2,561,407,844

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2561407844...
Checkpoint 2561407844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.05467
Policy Entropy: 2.34167
Value Function Loss: 0.02214

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.09744
Policy Update Magnitude: 0.50403
Value Function Update Magnitude: 0.70834

Collected Steps per Second: 22,040.79212
Overall Steps per Second: 10,691.16830

Timestep Collection Time: 2.26961
Timestep Consumption Time: 2.40939
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.67900

Cumulative Model Updates: 307,132
Cumulative Timesteps: 2,561,457,868

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.87450
Policy Entropy: 2.35222
Value Function Loss: 0.02123

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.09995
Policy Update Magnitude: 0.50091
Value Function Update Magnitude: 0.69585

Collected Steps per Second: 22,209.69497
Overall Steps per Second: 10,848.58335

Timestep Collection Time: 2.25127
Timestep Consumption Time: 2.35763
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.60890

Cumulative Model Updates: 307,138
Cumulative Timesteps: 2,561,507,868

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2561507868...
Checkpoint 2561507868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.80482
Policy Entropy: 2.34425
Value Function Loss: 0.02118

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.10306
Policy Update Magnitude: 0.48917
Value Function Update Magnitude: 0.69143

Collected Steps per Second: 22,042.36962
Overall Steps per Second: 10,629.89401

Timestep Collection Time: 2.26899
Timestep Consumption Time: 2.43604
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.70503

Cumulative Model Updates: 307,144
Cumulative Timesteps: 2,561,557,882

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.97149
Policy Entropy: 2.36209
Value Function Loss: 0.02015

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.49127
Value Function Update Magnitude: 0.66976

Collected Steps per Second: 22,355.90552
Overall Steps per Second: 10,521.38029

Timestep Collection Time: 2.23726
Timestep Consumption Time: 2.51649
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.75375

Cumulative Model Updates: 307,150
Cumulative Timesteps: 2,561,607,898

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2561607898...
Checkpoint 2561607898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.76247
Policy Entropy: 2.38343
Value Function Loss: 0.02156

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.10180
Policy Update Magnitude: 0.48771
Value Function Update Magnitude: 0.65522

Collected Steps per Second: 21,729.81722
Overall Steps per Second: 10,589.96540

Timestep Collection Time: 2.30108
Timestep Consumption Time: 2.42056
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.72164

Cumulative Model Updates: 307,156
Cumulative Timesteps: 2,561,657,900

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.13409
Policy Entropy: 2.39617
Value Function Loss: 0.02106

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.10534
Policy Update Magnitude: 0.49880
Value Function Update Magnitude: 0.66139

Collected Steps per Second: 22,257.60814
Overall Steps per Second: 10,550.46138

Timestep Collection Time: 2.24678
Timestep Consumption Time: 2.49311
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.73989

Cumulative Model Updates: 307,162
Cumulative Timesteps: 2,561,707,908

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2561707908...
Checkpoint 2561707908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.83838
Policy Entropy: 2.40823
Value Function Loss: 0.02181

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.12070
Policy Update Magnitude: 0.49015
Value Function Update Magnitude: 0.67279

Collected Steps per Second: 21,829.23508
Overall Steps per Second: 10,574.76329

Timestep Collection Time: 2.29106
Timestep Consumption Time: 2.43832
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.72937

Cumulative Model Updates: 307,168
Cumulative Timesteps: 2,561,757,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.82889
Policy Entropy: 2.39586
Value Function Loss: 0.02097

Mean KL Divergence: 0.02312
SB3 Clip Fraction: 0.13139
Policy Update Magnitude: 0.48462
Value Function Update Magnitude: 0.67970

Collected Steps per Second: 22,323.49831
Overall Steps per Second: 10,493.39347

Timestep Collection Time: 2.23997
Timestep Consumption Time: 2.52531
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.76528

Cumulative Model Updates: 307,174
Cumulative Timesteps: 2,561,807,924

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2561807924...
Checkpoint 2561807924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.73913
Policy Entropy: 2.38416
Value Function Loss: 0.02023

Mean KL Divergence: 0.02465
SB3 Clip Fraction: 0.13876
Policy Update Magnitude: 0.48172
Value Function Update Magnitude: 0.69044

Collected Steps per Second: 21,848.21251
Overall Steps per Second: 10,546.43272

Timestep Collection Time: 2.28888
Timestep Consumption Time: 2.45282
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.74170

Cumulative Model Updates: 307,180
Cumulative Timesteps: 2,561,857,932

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.56438
Policy Entropy: 2.39189
Value Function Loss: 0.02005

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.12092
Policy Update Magnitude: 0.49381
Value Function Update Magnitude: 0.66587

Collected Steps per Second: 22,415.96479
Overall Steps per Second: 10,590.81961

Timestep Collection Time: 2.23091
Timestep Consumption Time: 2.49092
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.72183

Cumulative Model Updates: 307,186
Cumulative Timesteps: 2,561,907,940

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2561907940...
Checkpoint 2561907940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.81698
Policy Entropy: 2.36452
Value Function Loss: 0.02089

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.10568
Policy Update Magnitude: 0.49985
Value Function Update Magnitude: 0.64397

Collected Steps per Second: 21,983.83854
Overall Steps per Second: 10,596.92904

Timestep Collection Time: 2.27467
Timestep Consumption Time: 2.44424
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.71891

Cumulative Model Updates: 307,192
Cumulative Timesteps: 2,561,957,946

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.94913
Policy Entropy: 2.36234
Value Function Loss: 0.02155

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.10024
Policy Update Magnitude: 0.50790
Value Function Update Magnitude: 0.65472

Collected Steps per Second: 22,191.77163
Overall Steps per Second: 10,495.61823

Timestep Collection Time: 2.25327
Timestep Consumption Time: 2.51101
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.76427

Cumulative Model Updates: 307,198
Cumulative Timesteps: 2,562,007,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2562007950...
Checkpoint 2562007950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.67950
Policy Entropy: 2.32264
Value Function Loss: 0.02076

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.09719
Policy Update Magnitude: 0.50751
Value Function Update Magnitude: 0.65176

Collected Steps per Second: 21,893.87200
Overall Steps per Second: 10,583.72692

Timestep Collection Time: 2.28511
Timestep Consumption Time: 2.44195
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.72707

Cumulative Model Updates: 307,204
Cumulative Timesteps: 2,562,057,980

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.27094
Policy Entropy: 2.34775
Value Function Loss: 0.01986

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.09710
Policy Update Magnitude: 0.49749
Value Function Update Magnitude: 0.63018

Collected Steps per Second: 22,370.46104
Overall Steps per Second: 10,863.06476

Timestep Collection Time: 2.23563
Timestep Consumption Time: 2.36823
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.60386

Cumulative Model Updates: 307,210
Cumulative Timesteps: 2,562,107,992

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2562107992...
Checkpoint 2562107992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.03589
Policy Entropy: 2.37624
Value Function Loss: 0.01952

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.10819
Policy Update Magnitude: 0.48897
Value Function Update Magnitude: 0.63233

Collected Steps per Second: 22,032.15682
Overall Steps per Second: 10,620.28336

Timestep Collection Time: 2.27032
Timestep Consumption Time: 2.43954
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.70986

Cumulative Model Updates: 307,216
Cumulative Timesteps: 2,562,158,012

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.59485
Policy Entropy: 2.41123
Value Function Loss: 0.01860

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.10329
Policy Update Magnitude: 0.48420
Value Function Update Magnitude: 0.63780

Collected Steps per Second: 22,329.77231
Overall Steps per Second: 10,510.24835

Timestep Collection Time: 2.24024
Timestep Consumption Time: 2.51931
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.75955

Cumulative Model Updates: 307,222
Cumulative Timesteps: 2,562,208,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2562208036...
Checkpoint 2562208036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.58826
Policy Entropy: 2.39485
Value Function Loss: 0.02075

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.10167
Policy Update Magnitude: 0.49637
Value Function Update Magnitude: 0.63117

Collected Steps per Second: 21,871.57573
Overall Steps per Second: 10,566.87751

Timestep Collection Time: 2.28726
Timestep Consumption Time: 2.44697
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.73423

Cumulative Model Updates: 307,228
Cumulative Timesteps: 2,562,258,062

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.74618
Policy Entropy: 2.36212
Value Function Loss: 0.02219

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.10145
Policy Update Magnitude: 0.51416
Value Function Update Magnitude: 0.61968

Collected Steps per Second: 22,157.05632
Overall Steps per Second: 10,517.54987

Timestep Collection Time: 2.25752
Timestep Consumption Time: 2.49834
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.75586

Cumulative Model Updates: 307,234
Cumulative Timesteps: 2,562,308,082

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2562308082...
Checkpoint 2562308082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.04408
Policy Entropy: 2.35723
Value Function Loss: 0.02340

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.11202
Policy Update Magnitude: 0.51240
Value Function Update Magnitude: 0.65295

Collected Steps per Second: 21,867.60526
Overall Steps per Second: 10,656.26649

Timestep Collection Time: 2.28676
Timestep Consumption Time: 2.40588
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.69264

Cumulative Model Updates: 307,240
Cumulative Timesteps: 2,562,358,088

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.27916
Policy Entropy: 2.37322
Value Function Loss: 0.02235

Mean KL Divergence: 0.02551
SB3 Clip Fraction: 0.14023
Policy Update Magnitude: 0.46141
Value Function Update Magnitude: 0.66807

Collected Steps per Second: 22,282.70599
Overall Steps per Second: 10,526.48231

Timestep Collection Time: 2.24560
Timestep Consumption Time: 2.50794
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.75353

Cumulative Model Updates: 307,246
Cumulative Timesteps: 2,562,408,126

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2562408126...
Checkpoint 2562408126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.84811
Policy Entropy: 2.41209
Value Function Loss: 0.02018

Mean KL Divergence: 0.02336
SB3 Clip Fraction: 0.12929
Policy Update Magnitude: 0.44351
Value Function Update Magnitude: 0.63431

Collected Steps per Second: 22,132.67921
Overall Steps per Second: 10,573.16200

Timestep Collection Time: 2.26064
Timestep Consumption Time: 2.47153
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.73217

Cumulative Model Updates: 307,252
Cumulative Timesteps: 2,562,458,160

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.70362
Policy Entropy: 2.41747
Value Function Loss: 0.01984

Mean KL Divergence: 0.02533
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.46198
Value Function Update Magnitude: 0.60575

Collected Steps per Second: 22,308.01718
Overall Steps per Second: 10,883.27257

Timestep Collection Time: 2.24206
Timestep Consumption Time: 2.35361
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.59568

Cumulative Model Updates: 307,258
Cumulative Timesteps: 2,562,508,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2562508176...
Checkpoint 2562508176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.93751
Policy Entropy: 2.40745
Value Function Loss: 0.02038

Mean KL Divergence: 0.02172
SB3 Clip Fraction: 0.12674
Policy Update Magnitude: 0.48141
Value Function Update Magnitude: 0.60665

Collected Steps per Second: 22,112.30272
Overall Steps per Second: 10,634.22914

Timestep Collection Time: 2.26200
Timestep Consumption Time: 2.44149
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.70349

Cumulative Model Updates: 307,264
Cumulative Timesteps: 2,562,558,194

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.93508
Policy Entropy: 2.40168
Value Function Loss: 0.02091

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.49363
Value Function Update Magnitude: 0.61863

Collected Steps per Second: 22,179.39819
Overall Steps per Second: 10,456.85114

Timestep Collection Time: 2.25471
Timestep Consumption Time: 2.52761
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.78232

Cumulative Model Updates: 307,270
Cumulative Timesteps: 2,562,608,202

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2562608202...
Checkpoint 2562608202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.52732
Policy Entropy: 2.38661
Value Function Loss: 0.02073

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.50069
Value Function Update Magnitude: 0.63831

Collected Steps per Second: 21,855.54418
Overall Steps per Second: 10,638.13563

Timestep Collection Time: 2.28839
Timestep Consumption Time: 2.41300
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.70139

Cumulative Model Updates: 307,276
Cumulative Timesteps: 2,562,658,216

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.66660
Policy Entropy: 2.40982
Value Function Loss: 0.02023

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.09824
Policy Update Magnitude: 0.49576
Value Function Update Magnitude: 0.64734

Collected Steps per Second: 22,178.30951
Overall Steps per Second: 10,813.64283

Timestep Collection Time: 2.25473
Timestep Consumption Time: 2.36962
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.62434

Cumulative Model Updates: 307,282
Cumulative Timesteps: 2,562,708,222

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2562708222...
Checkpoint 2562708222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172.49529
Policy Entropy: 2.38662
Value Function Loss: 0.02061

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.48968
Value Function Update Magnitude: 0.63638

Collected Steps per Second: 21,922.85652
Overall Steps per Second: 10,471.52870

Timestep Collection Time: 2.28109
Timestep Consumption Time: 2.49453
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.77562

Cumulative Model Updates: 307,288
Cumulative Timesteps: 2,562,758,230

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.86461
Policy Entropy: 2.40502
Value Function Loss: 0.02108

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.10015
Policy Update Magnitude: 0.48683
Value Function Update Magnitude: 0.64884

Collected Steps per Second: 22,215.26101
Overall Steps per Second: 10,499.91074

Timestep Collection Time: 2.25089
Timestep Consumption Time: 2.51144
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.76233

Cumulative Model Updates: 307,294
Cumulative Timesteps: 2,562,808,234

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2562808234...
Checkpoint 2562808234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.17171
Policy Entropy: 2.39917
Value Function Loss: 0.02207

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.09780
Policy Update Magnitude: 0.48871
Value Function Update Magnitude: 0.66213

Collected Steps per Second: 21,961.67651
Overall Steps per Second: 10,536.29990

Timestep Collection Time: 2.27788
Timestep Consumption Time: 2.47009
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.74797

Cumulative Model Updates: 307,300
Cumulative Timesteps: 2,562,858,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.32987
Policy Entropy: 2.41190
Value Function Loss: 0.02142

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.09750
Policy Update Magnitude: 0.47586
Value Function Update Magnitude: 0.66385

Collected Steps per Second: 22,546.53305
Overall Steps per Second: 10,764.56891

Timestep Collection Time: 2.21843
Timestep Consumption Time: 2.42811
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.64654

Cumulative Model Updates: 307,306
Cumulative Timesteps: 2,562,908,278

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2562908278...
Checkpoint 2562908278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.51276
Policy Entropy: 2.39934
Value Function Loss: 0.02112

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.09958
Policy Update Magnitude: 0.48490
Value Function Update Magnitude: 0.66974

Collected Steps per Second: 21,770.00099
Overall Steps per Second: 10,581.09608

Timestep Collection Time: 2.29802
Timestep Consumption Time: 2.43003
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.72805

Cumulative Model Updates: 307,312
Cumulative Timesteps: 2,562,958,306

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.41473
Policy Entropy: 2.37889
Value Function Loss: 0.02235

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.09496
Policy Update Magnitude: 0.50175
Value Function Update Magnitude: 0.65676

Collected Steps per Second: 22,392.30988
Overall Steps per Second: 10,547.33093

Timestep Collection Time: 2.23327
Timestep Consumption Time: 2.50803
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.74129

Cumulative Model Updates: 307,318
Cumulative Timesteps: 2,563,008,314

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2563008314...
Checkpoint 2563008314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.83238
Policy Entropy: 2.35056
Value Function Loss: 0.02213

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.09790
Policy Update Magnitude: 0.51237
Value Function Update Magnitude: 0.64730

Collected Steps per Second: 22,018.30532
Overall Steps per Second: 10,639.02599

Timestep Collection Time: 2.27111
Timestep Consumption Time: 2.42913
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.70024

Cumulative Model Updates: 307,324
Cumulative Timesteps: 2,563,058,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.87336
Policy Entropy: 2.36317
Value Function Loss: 0.02221

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.50265
Value Function Update Magnitude: 0.64518

Collected Steps per Second: 22,533.35014
Overall Steps per Second: 10,890.83014

Timestep Collection Time: 2.21947
Timestep Consumption Time: 2.37265
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.59212

Cumulative Model Updates: 307,330
Cumulative Timesteps: 2,563,108,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2563108332...
Checkpoint 2563108332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.18492
Policy Entropy: 2.39078
Value Function Loss: 0.02036

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.49876
Value Function Update Magnitude: 0.62723

Collected Steps per Second: 21,952.96602
Overall Steps per Second: 10,604.16902

Timestep Collection Time: 2.27842
Timestep Consumption Time: 2.43841
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.71682

Cumulative Model Updates: 307,336
Cumulative Timesteps: 2,563,158,350

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.58092
Policy Entropy: 2.41488
Value Function Loss: 0.02044

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.50356
Value Function Update Magnitude: 0.62360

Collected Steps per Second: 22,295.35992
Overall Steps per Second: 10,507.22207

Timestep Collection Time: 2.24262
Timestep Consumption Time: 2.51601
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.75863

Cumulative Model Updates: 307,342
Cumulative Timesteps: 2,563,208,350

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2563208350...
Checkpoint 2563208350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.62011
Policy Entropy: 2.39476
Value Function Loss: 0.02057

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.49899
Value Function Update Magnitude: 0.64294

Collected Steps per Second: 21,955.14475
Overall Steps per Second: 10,659.11034

Timestep Collection Time: 2.27819
Timestep Consumption Time: 2.41432
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.69251

Cumulative Model Updates: 307,348
Cumulative Timesteps: 2,563,258,368

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.91721
Policy Entropy: 2.38609
Value Function Loss: 0.02010

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.11374
Policy Update Magnitude: 0.48319
Value Function Update Magnitude: 0.64346

Collected Steps per Second: 22,315.19875
Overall Steps per Second: 10,846.40790

Timestep Collection Time: 2.24188
Timestep Consumption Time: 2.37052
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.61240

Cumulative Model Updates: 307,354
Cumulative Timesteps: 2,563,308,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2563308396...
Checkpoint 2563308396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.67139
Policy Entropy: 2.39808
Value Function Loss: 0.02009

Mean KL Divergence: 0.02183
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.47601
Value Function Update Magnitude: 0.64130

Collected Steps per Second: 21,641.74711
Overall Steps per Second: 10,370.54798

Timestep Collection Time: 2.31155
Timestep Consumption Time: 2.51230
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.82385

Cumulative Model Updates: 307,360
Cumulative Timesteps: 2,563,358,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.89480
Policy Entropy: 2.40107
Value Function Loss: 0.02088

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.47918
Value Function Update Magnitude: 0.66926

Collected Steps per Second: 22,483.03425
Overall Steps per Second: 10,722.95726

Timestep Collection Time: 2.22514
Timestep Consumption Time: 2.44036
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.66550

Cumulative Model Updates: 307,366
Cumulative Timesteps: 2,563,408,450

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2563408450...
Checkpoint 2563408450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.83206
Policy Entropy: 2.39543
Value Function Loss: 0.02222

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.11272
Policy Update Magnitude: 0.49706
Value Function Update Magnitude: 0.67684

Collected Steps per Second: 21,830.27388
Overall Steps per Second: 10,620.97372

Timestep Collection Time: 2.29049
Timestep Consumption Time: 2.41737
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.70785

Cumulative Model Updates: 307,372
Cumulative Timesteps: 2,563,458,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.65724
Policy Entropy: 2.38913
Value Function Loss: 0.02377

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.09714
Policy Update Magnitude: 0.51468
Value Function Update Magnitude: 0.66289

Collected Steps per Second: 22,372.96059
Overall Steps per Second: 10,733.30957

Timestep Collection Time: 2.23582
Timestep Consumption Time: 2.42462
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.66045

Cumulative Model Updates: 307,378
Cumulative Timesteps: 2,563,508,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2563508474...
Checkpoint 2563508474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.68305
Policy Entropy: 2.39070
Value Function Loss: 0.02405

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.10024
Policy Update Magnitude: 0.50844
Value Function Update Magnitude: 0.64926

Collected Steps per Second: 21,914.24269
Overall Steps per Second: 10,437.89992

Timestep Collection Time: 2.28336
Timestep Consumption Time: 2.51052
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.79388

Cumulative Model Updates: 307,384
Cumulative Timesteps: 2,563,558,512

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.17934
Policy Entropy: 2.38351
Value Function Loss: 0.02288

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.08940
Policy Update Magnitude: 0.50762
Value Function Update Magnitude: 0.64873

Collected Steps per Second: 22,095.88359
Overall Steps per Second: 10,477.59391

Timestep Collection Time: 2.26332
Timestep Consumption Time: 2.50972
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.77304

Cumulative Model Updates: 307,390
Cumulative Timesteps: 2,563,608,522

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2563608522...
Checkpoint 2563608522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.83706
Policy Entropy: 2.37554
Value Function Loss: 0.02077

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.08886
Policy Update Magnitude: 0.50329
Value Function Update Magnitude: 0.67148

Collected Steps per Second: 22,109.62356
Overall Steps per Second: 10,644.25266

Timestep Collection Time: 2.26227
Timestep Consumption Time: 2.43679
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.69906

Cumulative Model Updates: 307,396
Cumulative Timesteps: 2,563,658,540

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.98914
Policy Entropy: 2.39573
Value Function Loss: 0.02030

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.08708
Policy Update Magnitude: 0.49384
Value Function Update Magnitude: 0.66996

Collected Steps per Second: 23,005.58975
Overall Steps per Second: 10,834.61186

Timestep Collection Time: 2.17451
Timestep Consumption Time: 2.44272
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.61724

Cumulative Model Updates: 307,402
Cumulative Timesteps: 2,563,708,566

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2563708566...
Checkpoint 2563708566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.51191
Policy Entropy: 2.40958
Value Function Loss: 0.02080

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.08588
Policy Update Magnitude: 0.49831
Value Function Update Magnitude: 0.66327

Collected Steps per Second: 22,048.67620
Overall Steps per Second: 10,598.03077

Timestep Collection Time: 2.26834
Timestep Consumption Time: 2.45083
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.71918

Cumulative Model Updates: 307,408
Cumulative Timesteps: 2,563,758,580

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.73566
Policy Entropy: 2.39874
Value Function Loss: 0.02264

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.50313
Value Function Update Magnitude: 0.65858

Collected Steps per Second: 22,203.48031
Overall Steps per Second: 10,575.91202

Timestep Collection Time: 2.25235
Timestep Consumption Time: 2.47632
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.72867

Cumulative Model Updates: 307,414
Cumulative Timesteps: 2,563,808,590

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2563808590...
Checkpoint 2563808590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.58069
Policy Entropy: 2.38498
Value Function Loss: 0.02343

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.51149
Value Function Update Magnitude: 0.68872

Collected Steps per Second: 21,979.12107
Overall Steps per Second: 10,659.72432

Timestep Collection Time: 2.27561
Timestep Consumption Time: 2.41644
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.69205

Cumulative Model Updates: 307,420
Cumulative Timesteps: 2,563,858,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.84808
Policy Entropy: 2.36666
Value Function Loss: 0.02265

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.10600
Policy Update Magnitude: 0.49766
Value Function Update Magnitude: 0.68196

Collected Steps per Second: 22,381.10280
Overall Steps per Second: 10,855.69998

Timestep Collection Time: 2.23412
Timestep Consumption Time: 2.37194
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.60606

Cumulative Model Updates: 307,426
Cumulative Timesteps: 2,563,908,608

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2563908608...
Checkpoint 2563908608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.67847
Policy Entropy: 2.38859
Value Function Loss: 0.02183

Mean KL Divergence: 0.03010
SB3 Clip Fraction: 0.15187
Policy Update Magnitude: 0.45521
Value Function Update Magnitude: 0.65295

Collected Steps per Second: 22,290.35343
Overall Steps per Second: 10,693.27503

Timestep Collection Time: 2.24348
Timestep Consumption Time: 2.43310
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.67658

Cumulative Model Updates: 307,432
Cumulative Timesteps: 2,563,958,616

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.51338
Policy Entropy: 2.40848
Value Function Loss: 0.01987

Mean KL Divergence: 0.02192
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.46583
Value Function Update Magnitude: 0.64374

Collected Steps per Second: 22,327.24382
Overall Steps per Second: 10,550.86175

Timestep Collection Time: 2.24049
Timestep Consumption Time: 2.50073
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.74122

Cumulative Model Updates: 307,438
Cumulative Timesteps: 2,564,008,640

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2564008640...
Checkpoint 2564008640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.80511
Policy Entropy: 2.44058
Value Function Loss: 0.01971

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.11894
Policy Update Magnitude: 0.48592
Value Function Update Magnitude: 0.64999

Collected Steps per Second: 21,938.80445
Overall Steps per Second: 10,530.95853

Timestep Collection Time: 2.27970
Timestep Consumption Time: 2.46953
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.74924

Cumulative Model Updates: 307,444
Cumulative Timesteps: 2,564,058,654

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.60385
Policy Entropy: 2.43419
Value Function Loss: 0.02030

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.46885
Value Function Update Magnitude: 0.65423

Collected Steps per Second: 22,395.16510
Overall Steps per Second: 10,874.56879

Timestep Collection Time: 2.23343
Timestep Consumption Time: 2.36611
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.59954

Cumulative Model Updates: 307,450
Cumulative Timesteps: 2,564,108,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2564108672...
Checkpoint 2564108672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.55743
Policy Entropy: 2.42548
Value Function Loss: 0.01999

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.12085
Policy Update Magnitude: 0.46022
Value Function Update Magnitude: 0.65209

Collected Steps per Second: 22,188.36485
Overall Steps per Second: 10,688.75342

Timestep Collection Time: 2.25442
Timestep Consumption Time: 2.42545
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.67987

Cumulative Model Updates: 307,456
Cumulative Timesteps: 2,564,158,694

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.57386
Policy Entropy: 2.41097
Value Function Loss: 0.01942

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.10894
Policy Update Magnitude: 0.47666
Value Function Update Magnitude: 0.65309

Collected Steps per Second: 22,225.45124
Overall Steps per Second: 10,459.78022

Timestep Collection Time: 2.25111
Timestep Consumption Time: 2.53216
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.78327

Cumulative Model Updates: 307,462
Cumulative Timesteps: 2,564,208,726

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2564208726...
Checkpoint 2564208726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.63921
Policy Entropy: 2.38724
Value Function Loss: 0.02029

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.09973
Policy Update Magnitude: 0.49794
Value Function Update Magnitude: 0.68758

Collected Steps per Second: 22,118.29961
Overall Steps per Second: 10,613.01884

Timestep Collection Time: 2.26175
Timestep Consumption Time: 2.45190
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.71364

Cumulative Model Updates: 307,468
Cumulative Timesteps: 2,564,258,752

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.39138
Policy Entropy: 2.37759
Value Function Loss: 0.02100

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.09314
Policy Update Magnitude: 0.50485
Value Function Update Magnitude: 0.72768

Collected Steps per Second: 21,978.57434
Overall Steps per Second: 10,666.21178

Timestep Collection Time: 2.27594
Timestep Consumption Time: 2.41382
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.68976

Cumulative Model Updates: 307,474
Cumulative Timesteps: 2,564,308,774

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2564308774...
Checkpoint 2564308774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.93000
Policy Entropy: 2.35038
Value Function Loss: 0.02162

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.10380
Policy Update Magnitude: 0.50894
Value Function Update Magnitude: 0.73410

Collected Steps per Second: 22,545.54456
Overall Steps per Second: 10,648.04186

Timestep Collection Time: 2.21791
Timestep Consumption Time: 2.47816
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.69607

Cumulative Model Updates: 307,480
Cumulative Timesteps: 2,564,358,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.31488
Policy Entropy: 2.36598
Value Function Loss: 0.02162

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.11243
Policy Update Magnitude: 0.50821
Value Function Update Magnitude: 0.70822

Collected Steps per Second: 22,431.72576
Overall Steps per Second: 10,733.86041

Timestep Collection Time: 2.22916
Timestep Consumption Time: 2.42936
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.65853

Cumulative Model Updates: 307,486
Cumulative Timesteps: 2,564,408,782

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2564408782...
Checkpoint 2564408782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.07120
Policy Entropy: 2.36743
Value Function Loss: 0.02160

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.13309
Policy Update Magnitude: 0.47449
Value Function Update Magnitude: 0.70435

Collected Steps per Second: 22,286.17886
Overall Steps per Second: 10,589.86276

Timestep Collection Time: 2.24489
Timestep Consumption Time: 2.47944
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.72433

Cumulative Model Updates: 307,492
Cumulative Timesteps: 2,564,458,812

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.69464
Policy Entropy: 2.39185
Value Function Loss: 0.02181

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.10591
Policy Update Magnitude: 0.47945
Value Function Update Magnitude: 0.69366

Collected Steps per Second: 22,283.07624
Overall Steps per Second: 10,850.34280

Timestep Collection Time: 2.24475
Timestep Consumption Time: 2.36524
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.60999

Cumulative Model Updates: 307,498
Cumulative Timesteps: 2,564,508,832

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2564508832...
Checkpoint 2564508832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.72175
Policy Entropy: 2.39598
Value Function Loss: 0.02120

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.10345
Policy Update Magnitude: 0.49892
Value Function Update Magnitude: 0.68214

Collected Steps per Second: 22,089.72587
Overall Steps per Second: 10,650.68954

Timestep Collection Time: 2.26413
Timestep Consumption Time: 2.43172
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.69585

Cumulative Model Updates: 307,504
Cumulative Timesteps: 2,564,558,846

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.89888
Policy Entropy: 2.38517
Value Function Loss: 0.02138

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.12302
Policy Update Magnitude: 0.49828
Value Function Update Magnitude: 0.68675

Collected Steps per Second: 22,190.91312
Overall Steps per Second: 10,501.30226

Timestep Collection Time: 2.25344
Timestep Consumption Time: 2.50844
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.76189

Cumulative Model Updates: 307,510
Cumulative Timesteps: 2,564,608,852

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2564608852...
Checkpoint 2564608852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.60006
Policy Entropy: 2.38684
Value Function Loss: 0.02053

Mean KL Divergence: 0.02379
SB3 Clip Fraction: 0.13780
Policy Update Magnitude: 0.48983
Value Function Update Magnitude: 0.68662

Collected Steps per Second: 22,109.98755
Overall Steps per Second: 10,640.33745

Timestep Collection Time: 2.26215
Timestep Consumption Time: 2.43846
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.70060

Cumulative Model Updates: 307,516
Cumulative Timesteps: 2,564,658,868

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.46567
Policy Entropy: 2.36454
Value Function Loss: 0.02104

Mean KL Divergence: 0.02241
SB3 Clip Fraction: 0.13431
Policy Update Magnitude: 0.49276
Value Function Update Magnitude: 0.66815

Collected Steps per Second: 21,905.91252
Overall Steps per Second: 10,630.67026

Timestep Collection Time: 2.28276
Timestep Consumption Time: 2.42117
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.70394

Cumulative Model Updates: 307,522
Cumulative Timesteps: 2,564,708,874

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2564708874...
Checkpoint 2564708874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.17576
Policy Entropy: 2.40075
Value Function Loss: 0.02051

Mean KL Divergence: 0.02093
SB3 Clip Fraction: 0.12844
Policy Update Magnitude: 0.48827
Value Function Update Magnitude: 0.67268

Collected Steps per Second: 22,460.40270
Overall Steps per Second: 10,616.33008

Timestep Collection Time: 2.22739
Timestep Consumption Time: 2.48498
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.71236

Cumulative Model Updates: 307,528
Cumulative Timesteps: 2,564,758,902

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.03463
Policy Entropy: 2.37681
Value Function Loss: 0.02061

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.11327
Policy Update Magnitude: 0.48774
Value Function Update Magnitude: 0.68240

Collected Steps per Second: 22,209.90805
Overall Steps per Second: 10,650.25912

Timestep Collection Time: 2.25251
Timestep Consumption Time: 2.44484
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.69735

Cumulative Model Updates: 307,534
Cumulative Timesteps: 2,564,808,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2564808930...
Checkpoint 2564808930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.95530
Policy Entropy: 2.39670
Value Function Loss: 0.02023

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.50326
Value Function Update Magnitude: 0.67936

Collected Steps per Second: 21,873.08980
Overall Steps per Second: 10,473.00533

Timestep Collection Time: 2.28591
Timestep Consumption Time: 2.48826
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.77418

Cumulative Model Updates: 307,540
Cumulative Timesteps: 2,564,858,930

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.11455
Policy Entropy: 2.37576
Value Function Loss: 0.02106

Mean KL Divergence: 0.03195
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.54088
Value Function Update Magnitude: 0.67776

Collected Steps per Second: 22,178.38712
Overall Steps per Second: 10,687.76587

Timestep Collection Time: 2.25598
Timestep Consumption Time: 2.42545
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.68143

Cumulative Model Updates: 307,546
Cumulative Timesteps: 2,564,908,964

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2564908964...
Checkpoint 2564908964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.44604
Policy Entropy: 2.41049
Value Function Loss: 0.02092

Mean KL Divergence: 0.02813
SB3 Clip Fraction: 0.14055
Policy Update Magnitude: 0.52930
Value Function Update Magnitude: 0.68884

Collected Steps per Second: 22,101.38896
Overall Steps per Second: 10,644.55376

Timestep Collection Time: 2.26293
Timestep Consumption Time: 2.43562
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.69855

Cumulative Model Updates: 307,552
Cumulative Timesteps: 2,564,958,978

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.38302
Policy Entropy: 2.41921
Value Function Loss: 0.02048

Mean KL Divergence: 0.02313
SB3 Clip Fraction: 0.13146
Policy Update Magnitude: 0.52337
Value Function Update Magnitude: 0.69268

Collected Steps per Second: 22,247.21023
Overall Steps per Second: 10,504.86781

Timestep Collection Time: 2.24792
Timestep Consumption Time: 2.51273
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.76065

Cumulative Model Updates: 307,558
Cumulative Timesteps: 2,565,008,988

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2565008988...
Checkpoint 2565008988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.54420
Policy Entropy: 2.41883
Value Function Loss: 0.02008

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.11879
Policy Update Magnitude: 0.50750
Value Function Update Magnitude: 0.68605

Collected Steps per Second: 22,211.42001
Overall Steps per Second: 10,682.84834

Timestep Collection Time: 2.25118
Timestep Consumption Time: 2.42940
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.68059

Cumulative Model Updates: 307,564
Cumulative Timesteps: 2,565,058,990

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.82552
Policy Entropy: 2.38558
Value Function Loss: 0.01971

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.10331
Policy Update Magnitude: 0.51007
Value Function Update Magnitude: 0.68651

Collected Steps per Second: 22,123.24503
Overall Steps per Second: 10,549.14458

Timestep Collection Time: 2.26088
Timestep Consumption Time: 2.48055
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.74143

Cumulative Model Updates: 307,570
Cumulative Timesteps: 2,565,109,008

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2565109008...
Checkpoint 2565109008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.10437
Policy Entropy: 2.38765
Value Function Loss: 0.02058

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.09760
Policy Update Magnitude: 0.50544
Value Function Update Magnitude: 0.67867

Collected Steps per Second: 22,982.35179
Overall Steps per Second: 10,807.90926

Timestep Collection Time: 2.17671
Timestep Consumption Time: 2.45193
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.62865

Cumulative Model Updates: 307,576
Cumulative Timesteps: 2,565,159,034

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.97979
Policy Entropy: 2.38525
Value Function Loss: 0.02062

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.09556
Policy Update Magnitude: 0.50087
Value Function Update Magnitude: 0.67843

Collected Steps per Second: 22,298.44953
Overall Steps per Second: 10,594.28657

Timestep Collection Time: 2.24312
Timestep Consumption Time: 2.47811
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.72122

Cumulative Model Updates: 307,582
Cumulative Timesteps: 2,565,209,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2565209052...
Checkpoint 2565209052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.30878
Policy Entropy: 2.37659
Value Function Loss: 0.02149

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.09420
Policy Update Magnitude: 0.50415
Value Function Update Magnitude: 0.67625

Collected Steps per Second: 22,126.22568
Overall Steps per Second: 10,656.84815

Timestep Collection Time: 2.25994
Timestep Consumption Time: 2.43225
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.69219

Cumulative Model Updates: 307,588
Cumulative Timesteps: 2,565,259,056

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.69825
Policy Entropy: 2.39203
Value Function Loss: 0.02143

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.51726
Value Function Update Magnitude: 0.68800

Collected Steps per Second: 22,147.24949
Overall Steps per Second: 10,515.98679

Timestep Collection Time: 2.25789
Timestep Consumption Time: 2.49735
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.75524

Cumulative Model Updates: 307,594
Cumulative Timesteps: 2,565,309,062

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2565309062...
Checkpoint 2565309062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.82064
Policy Entropy: 2.40398
Value Function Loss: 0.02159

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.09962
Policy Update Magnitude: 0.50832
Value Function Update Magnitude: 0.69913

Collected Steps per Second: 22,204.32909
Overall Steps per Second: 10,724.51020

Timestep Collection Time: 2.25325
Timestep Consumption Time: 2.41195
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.66520

Cumulative Model Updates: 307,600
Cumulative Timesteps: 2,565,359,094

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.67800
Policy Entropy: 2.43337
Value Function Loss: 0.02055

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.09315
Policy Update Magnitude: 0.50359
Value Function Update Magnitude: 0.70819

Collected Steps per Second: 22,681.36808
Overall Steps per Second: 10,714.28059

Timestep Collection Time: 2.20551
Timestep Consumption Time: 2.46340
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.66891

Cumulative Model Updates: 307,606
Cumulative Timesteps: 2,565,409,118

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2565409118...
Checkpoint 2565409118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.46698
Policy Entropy: 2.42200
Value Function Loss: 0.02164

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.49973
Value Function Update Magnitude: 0.70643

Collected Steps per Second: 21,988.16350
Overall Steps per Second: 10,609.95442

Timestep Collection Time: 2.27441
Timestep Consumption Time: 2.43909
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.71350

Cumulative Model Updates: 307,612
Cumulative Timesteps: 2,565,459,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.19361
Policy Entropy: 2.41422
Value Function Loss: 0.02102

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.09165
Policy Update Magnitude: 0.50163
Value Function Update Magnitude: 0.70734

Collected Steps per Second: 22,085.37231
Overall Steps per Second: 10,660.42971

Timestep Collection Time: 2.26439
Timestep Consumption Time: 2.42679
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.69118

Cumulative Model Updates: 307,618
Cumulative Timesteps: 2,565,509,138

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2565509138...
Checkpoint 2565509138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.93213
Policy Entropy: 2.40382
Value Function Loss: 0.02104

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.49571
Value Function Update Magnitude: 0.68118

Collected Steps per Second: 22,368.10884
Overall Steps per Second: 10,531.09179

Timestep Collection Time: 2.23658
Timestep Consumption Time: 2.51393
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.75050

Cumulative Model Updates: 307,624
Cumulative Timesteps: 2,565,559,166

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.11788
Policy Entropy: 2.39456
Value Function Loss: 0.02029

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.49968
Value Function Update Magnitude: 0.67386

Collected Steps per Second: 22,129.69775
Overall Steps per Second: 10,449.40202

Timestep Collection Time: 2.25968
Timestep Consumption Time: 2.52586
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.78554

Cumulative Model Updates: 307,630
Cumulative Timesteps: 2,565,609,172

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2565609172...
Checkpoint 2565609172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.63229
Policy Entropy: 2.40916
Value Function Loss: 0.02086

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.08510
Policy Update Magnitude: 0.49632
Value Function Update Magnitude: 0.67999

Collected Steps per Second: 21,890.57382
Overall Steps per Second: 10,567.36576

Timestep Collection Time: 2.28518
Timestep Consumption Time: 2.44863
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.73382

Cumulative Model Updates: 307,636
Cumulative Timesteps: 2,565,659,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.25983
Policy Entropy: 2.42318
Value Function Loss: 0.02154

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.08632
Policy Update Magnitude: 0.49604
Value Function Update Magnitude: 0.69118

Collected Steps per Second: 22,371.38866
Overall Steps per Second: 10,553.64620

Timestep Collection Time: 2.23625
Timestep Consumption Time: 2.50410
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.74035

Cumulative Model Updates: 307,642
Cumulative Timesteps: 2,565,709,224

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2565709224...
Checkpoint 2565709224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.96807
Policy Entropy: 2.42834
Value Function Loss: 0.02115

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.08543
Policy Update Magnitude: 0.49387
Value Function Update Magnitude: 0.70741

Collected Steps per Second: 22,870.28791
Overall Steps per Second: 10,681.62909

Timestep Collection Time: 2.18642
Timestep Consumption Time: 2.49489
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.68131

Cumulative Model Updates: 307,648
Cumulative Timesteps: 2,565,759,228

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.94934
Policy Entropy: 2.43456
Value Function Loss: 0.01966

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.48467
Value Function Update Magnitude: 0.71863

Collected Steps per Second: 22,129.68680
Overall Steps per Second: 10,472.50543

Timestep Collection Time: 2.26013
Timestep Consumption Time: 2.51580
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.77593

Cumulative Model Updates: 307,654
Cumulative Timesteps: 2,565,809,244

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2565809244...
Checkpoint 2565809244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.19684
Policy Entropy: 2.43945
Value Function Loss: 0.01794

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.08241
Policy Update Magnitude: 0.47703
Value Function Update Magnitude: 0.71069

Collected Steps per Second: 22,188.85726
Overall Steps per Second: 10,522.36014

Timestep Collection Time: 2.25419
Timestep Consumption Time: 2.49930
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.75350

Cumulative Model Updates: 307,660
Cumulative Timesteps: 2,565,859,262

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.53492
Policy Entropy: 2.43773
Value Function Loss: 0.01926

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.08494
Policy Update Magnitude: 0.48639
Value Function Update Magnitude: 0.70532

Collected Steps per Second: 21,591.57031
Overall Steps per Second: 10,422.75085

Timestep Collection Time: 2.31683
Timestep Consumption Time: 2.48267
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.79950

Cumulative Model Updates: 307,666
Cumulative Timesteps: 2,565,909,286

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2565909286...
Checkpoint 2565909286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.10744
Policy Entropy: 2.39504
Value Function Loss: 0.02062

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.09160
Policy Update Magnitude: 0.49333
Value Function Update Magnitude: 0.71654

Collected Steps per Second: 22,081.23964
Overall Steps per Second: 10,653.25626

Timestep Collection Time: 2.26446
Timestep Consumption Time: 2.42913
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.69359

Cumulative Model Updates: 307,672
Cumulative Timesteps: 2,565,959,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.71812
Policy Entropy: 2.36112
Value Function Loss: 0.02193

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.09120
Policy Update Magnitude: 0.49535
Value Function Update Magnitude: 0.70748

Collected Steps per Second: 22,418.37479
Overall Steps per Second: 10,543.79489

Timestep Collection Time: 2.23228
Timestep Consumption Time: 2.51402
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.74630

Cumulative Model Updates: 307,678
Cumulative Timesteps: 2,566,009,332

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2566009332...
Checkpoint 2566009332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.15434
Policy Entropy: 2.35202
Value Function Loss: 0.02222

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.08934
Policy Update Magnitude: 0.50367
Value Function Update Magnitude: 0.68536

Collected Steps per Second: 21,857.84706
Overall Steps per Second: 10,538.39208

Timestep Collection Time: 2.28760
Timestep Consumption Time: 2.45715
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.74475

Cumulative Model Updates: 307,684
Cumulative Timesteps: 2,566,059,334

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.58180
Policy Entropy: 2.37033
Value Function Loss: 0.02137

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.08840
Policy Update Magnitude: 0.49728
Value Function Update Magnitude: 0.67499

Collected Steps per Second: 21,831.99052
Overall Steps per Second: 10,439.03074

Timestep Collection Time: 2.29031
Timestep Consumption Time: 2.49960
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.78991

Cumulative Model Updates: 307,690
Cumulative Timesteps: 2,566,109,336

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2566109336...
Checkpoint 2566109336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.48855
Policy Entropy: 2.39256
Value Function Loss: 0.02160

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.09053
Policy Update Magnitude: 0.49821
Value Function Update Magnitude: 0.67600

Collected Steps per Second: 22,246.29274
Overall Steps per Second: 10,680.56463

Timestep Collection Time: 2.24766
Timestep Consumption Time: 2.43393
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.68159

Cumulative Model Updates: 307,696
Cumulative Timesteps: 2,566,159,338

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.18907
Policy Entropy: 2.39439
Value Function Loss: 0.02077

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.08636
Policy Update Magnitude: 0.50288
Value Function Update Magnitude: 0.66381

Collected Steps per Second: 22,493.88643
Overall Steps per Second: 10,579.30785

Timestep Collection Time: 2.22354
Timestep Consumption Time: 2.50418
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.72772

Cumulative Model Updates: 307,702
Cumulative Timesteps: 2,566,209,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2566209354...
Checkpoint 2566209354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.01580
Policy Entropy: 2.41541
Value Function Loss: 0.02046

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.08748
Policy Update Magnitude: 0.49962
Value Function Update Magnitude: 0.66806

Collected Steps per Second: 22,442.61582
Overall Steps per Second: 10,549.73097

Timestep Collection Time: 2.22853
Timestep Consumption Time: 2.51226
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.74078

Cumulative Model Updates: 307,708
Cumulative Timesteps: 2,566,259,368

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.85358
Policy Entropy: 2.40496
Value Function Loss: 0.02000

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.49359
Value Function Update Magnitude: 0.68201

Collected Steps per Second: 22,052.30501
Overall Steps per Second: 10,524.31912

Timestep Collection Time: 2.26843
Timestep Consumption Time: 2.48476
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.75318

Cumulative Model Updates: 307,714
Cumulative Timesteps: 2,566,309,392

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2566309392...
Checkpoint 2566309392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.78593
Policy Entropy: 2.43608
Value Function Loss: 0.02010

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.09354
Policy Update Magnitude: 0.49693
Value Function Update Magnitude: 0.68483

Collected Steps per Second: 22,215.02743
Overall Steps per Second: 10,705.06233

Timestep Collection Time: 2.25163
Timestep Consumption Time: 2.42093
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.67256

Cumulative Model Updates: 307,720
Cumulative Timesteps: 2,566,359,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.11105
Policy Entropy: 2.42406
Value Function Loss: 0.02050

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.48934
Value Function Update Magnitude: 0.66953

Collected Steps per Second: 22,339.17625
Overall Steps per Second: 10,695.43333

Timestep Collection Time: 2.23822
Timestep Consumption Time: 2.43667
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.67489

Cumulative Model Updates: 307,726
Cumulative Timesteps: 2,566,409,412

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2566409412...
Checkpoint 2566409412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.72795
Policy Entropy: 2.42609
Value Function Loss: 0.02158

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.49114
Value Function Update Magnitude: 0.66544

Collected Steps per Second: 22,071.35676
Overall Steps per Second: 10,626.70554

Timestep Collection Time: 2.26574
Timestep Consumption Time: 2.44014
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.70588

Cumulative Model Updates: 307,732
Cumulative Timesteps: 2,566,459,420

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.95900
Policy Entropy: 2.40451
Value Function Loss: 0.02190

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.09085
Policy Update Magnitude: 0.49334
Value Function Update Magnitude: 0.66777

Collected Steps per Second: 21,743.83127
Overall Steps per Second: 10,523.61906

Timestep Collection Time: 2.30024
Timestep Consumption Time: 2.45250
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.75274

Cumulative Model Updates: 307,738
Cumulative Timesteps: 2,566,509,436

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2566509436...
Checkpoint 2566509436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.74212
Policy Entropy: 2.39950
Value Function Loss: 0.02019

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.09337
Policy Update Magnitude: 0.48922
Value Function Update Magnitude: 0.66564

Collected Steps per Second: 22,369.77927
Overall Steps per Second: 10,652.11525

Timestep Collection Time: 2.23659
Timestep Consumption Time: 2.46032
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.69691

Cumulative Model Updates: 307,744
Cumulative Timesteps: 2,566,559,468

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.14557
Policy Entropy: 2.40236
Value Function Loss: 0.02017

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.49004
Value Function Update Magnitude: 0.65003

Collected Steps per Second: 22,073.37017
Overall Steps per Second: 10,454.50735

Timestep Collection Time: 2.26644
Timestep Consumption Time: 2.51886
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.78530

Cumulative Model Updates: 307,750
Cumulative Timesteps: 2,566,609,496

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2566609496...
Checkpoint 2566609496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.66285
Policy Entropy: 2.37729
Value Function Loss: 0.02192

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.10247
Policy Update Magnitude: 0.48177
Value Function Update Magnitude: 0.64560

Collected Steps per Second: 21,958.11116
Overall Steps per Second: 10,593.42319

Timestep Collection Time: 2.27752
Timestep Consumption Time: 2.44334
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.72085

Cumulative Model Updates: 307,756
Cumulative Timesteps: 2,566,659,506

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.34855
Policy Entropy: 2.36803
Value Function Loss: 0.02297

Mean KL Divergence: 0.02164
SB3 Clip Fraction: 0.12788
Policy Update Magnitude: 0.45772
Value Function Update Magnitude: 0.64462

Collected Steps per Second: 22,220.31994
Overall Steps per Second: 10,500.53237

Timestep Collection Time: 2.25109
Timestep Consumption Time: 2.51248
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.76357

Cumulative Model Updates: 307,762
Cumulative Timesteps: 2,566,709,526

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2566709526...
Checkpoint 2566709526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.94545
Policy Entropy: 2.36110
Value Function Loss: 0.02264

Mean KL Divergence: 0.02327
SB3 Clip Fraction: 0.13131
Policy Update Magnitude: 0.45929
Value Function Update Magnitude: 0.65191

Collected Steps per Second: 22,068.36896
Overall Steps per Second: 10,609.24846

Timestep Collection Time: 2.26587
Timestep Consumption Time: 2.44738
PPO Batch Consumption Time: 0.28561
Total Iteration Time: 4.71325

Cumulative Model Updates: 307,768
Cumulative Timesteps: 2,566,759,530

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.36741
Policy Entropy: 2.37298
Value Function Loss: 0.02097

Mean KL Divergence: 0.02371
SB3 Clip Fraction: 0.13286
Policy Update Magnitude: 0.49606
Value Function Update Magnitude: 0.65509

Collected Steps per Second: 22,257.74553
Overall Steps per Second: 10,853.06657

Timestep Collection Time: 2.24704
Timestep Consumption Time: 2.36124
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.60828

Cumulative Model Updates: 307,774
Cumulative Timesteps: 2,566,809,544

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2566809544...
Checkpoint 2566809544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.25838
Policy Entropy: 2.39751
Value Function Loss: 0.02114

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.50904
Value Function Update Magnitude: 0.65173

Collected Steps per Second: 22,022.88203
Overall Steps per Second: 10,646.76954

Timestep Collection Time: 2.27109
Timestep Consumption Time: 2.42667
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.69776

Cumulative Model Updates: 307,780
Cumulative Timesteps: 2,566,859,560

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.77952
Policy Entropy: 2.42075
Value Function Loss: 0.02206

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.49516
Value Function Update Magnitude: 0.66551

Collected Steps per Second: 22,151.48440
Overall Steps per Second: 10,509.72282

Timestep Collection Time: 2.25773
Timestep Consumption Time: 2.50091
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.75864

Cumulative Model Updates: 307,786
Cumulative Timesteps: 2,566,909,572

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2566909572...
Checkpoint 2566909572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.97562
Policy Entropy: 2.42051
Value Function Loss: 0.02207

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.13002
Policy Update Magnitude: 0.49323
Value Function Update Magnitude: 0.68159

Collected Steps per Second: 21,965.80083
Overall Steps per Second: 10,630.35289

Timestep Collection Time: 2.27690
Timestep Consumption Time: 2.42793
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.70483

Cumulative Model Updates: 307,792
Cumulative Timesteps: 2,566,959,586

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.52618
Policy Entropy: 2.39274
Value Function Loss: 0.02159

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.11449
Policy Update Magnitude: 0.51596
Value Function Update Magnitude: 0.69247

Collected Steps per Second: 22,116.15043
Overall Steps per Second: 10,702.82169

Timestep Collection Time: 2.26142
Timestep Consumption Time: 2.41155
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.67297

Cumulative Model Updates: 307,798
Cumulative Timesteps: 2,567,009,600

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2567009600...
Checkpoint 2567009600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.61942
Policy Entropy: 2.39993
Value Function Loss: 0.01970

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.10209
Policy Update Magnitude: 0.50600
Value Function Update Magnitude: 0.68308

Collected Steps per Second: 22,383.35978
Overall Steps per Second: 10,577.95731

Timestep Collection Time: 2.23487
Timestep Consumption Time: 2.49420
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.72908

Cumulative Model Updates: 307,804
Cumulative Timesteps: 2,567,059,624

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.82512
Policy Entropy: 2.39680
Value Function Loss: 0.01999

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.51270
Value Function Update Magnitude: 0.65763

Collected Steps per Second: 22,229.58350
Overall Steps per Second: 10,666.92935

Timestep Collection Time: 2.25051
Timestep Consumption Time: 2.43949
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.69001

Cumulative Model Updates: 307,810
Cumulative Timesteps: 2,567,109,652

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2567109652...
Checkpoint 2567109652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.28557
Policy Entropy: 2.41402
Value Function Loss: 0.01952

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.09048
Policy Update Magnitude: 0.50731
Value Function Update Magnitude: 0.66766

Collected Steps per Second: 21,741.77054
Overall Steps per Second: 10,471.34190

Timestep Collection Time: 2.29981
Timestep Consumption Time: 2.47532
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.77513

Cumulative Model Updates: 307,816
Cumulative Timesteps: 2,567,159,654

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.82552
Policy Entropy: 2.37813
Value Function Loss: 0.02041

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.08688
Policy Update Magnitude: 0.50406
Value Function Update Magnitude: 0.67571

Collected Steps per Second: 23,054.59084
Overall Steps per Second: 10,701.73097

Timestep Collection Time: 2.16920
Timestep Consumption Time: 2.50388
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.67308

Cumulative Model Updates: 307,822
Cumulative Timesteps: 2,567,209,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2567209664...
Checkpoint 2567209664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.93633
Policy Entropy: 2.38292
Value Function Loss: 0.02018

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.50078
Value Function Update Magnitude: 0.65509

Collected Steps per Second: 22,071.14927
Overall Steps per Second: 10,587.39170

Timestep Collection Time: 2.26576
Timestep Consumption Time: 2.45759
PPO Batch Consumption Time: 0.28192
Total Iteration Time: 4.72335

Cumulative Model Updates: 307,828
Cumulative Timesteps: 2,567,259,672

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.15856
Policy Entropy: 2.37686
Value Function Loss: 0.02141

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.08990
Policy Update Magnitude: 0.50472
Value Function Update Magnitude: 0.65376

Collected Steps per Second: 22,123.98386
Overall Steps per Second: 10,505.70045

Timestep Collection Time: 2.26008
Timestep Consumption Time: 2.49943
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.75951

Cumulative Model Updates: 307,834
Cumulative Timesteps: 2,567,309,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2567309674...
Checkpoint 2567309674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.32591
Policy Entropy: 2.39779
Value Function Loss: 0.02106

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.08823
Policy Update Magnitude: 0.49586
Value Function Update Magnitude: 0.64578

Collected Steps per Second: 22,002.49646
Overall Steps per Second: 10,624.08636

Timestep Collection Time: 2.27274
Timestep Consumption Time: 2.43411
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.70685

Cumulative Model Updates: 307,840
Cumulative Timesteps: 2,567,359,680

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.89550
Policy Entropy: 2.36632
Value Function Loss: 0.02147

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.09042
Policy Update Magnitude: 0.49197
Value Function Update Magnitude: 0.63444

Collected Steps per Second: 22,251.34571
Overall Steps per Second: 10,540.26309

Timestep Collection Time: 2.24759
Timestep Consumption Time: 2.49726
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.74485

Cumulative Model Updates: 307,846
Cumulative Timesteps: 2,567,409,692

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2567409692...
Checkpoint 2567409692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.25514
Policy Entropy: 2.34954
Value Function Loss: 0.02128

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.08576
Policy Update Magnitude: 0.49601
Value Function Update Magnitude: 0.62977

Collected Steps per Second: 22,059.85457
Overall Steps per Second: 10,591.86211

Timestep Collection Time: 2.26783
Timestep Consumption Time: 2.45542
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.72325

Cumulative Model Updates: 307,852
Cumulative Timesteps: 2,567,459,720

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.53078
Policy Entropy: 2.35034
Value Function Loss: 0.02164

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.08625
Policy Update Magnitude: 0.49847
Value Function Update Magnitude: 0.62342

Collected Steps per Second: 21,966.64596
Overall Steps per Second: 10,453.14949

Timestep Collection Time: 2.27682
Timestep Consumption Time: 2.50777
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.78459

Cumulative Model Updates: 307,858
Cumulative Timesteps: 2,567,509,734

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2567509734...
Checkpoint 2567509734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.13646
Policy Entropy: 2.38227
Value Function Loss: 0.02083

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.49907
Value Function Update Magnitude: 0.62458

Collected Steps per Second: 21,960.06801
Overall Steps per Second: 10,596.98548

Timestep Collection Time: 2.27750
Timestep Consumption Time: 2.44215
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.71964

Cumulative Model Updates: 307,864
Cumulative Timesteps: 2,567,559,748

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.56587
Policy Entropy: 2.40397
Value Function Loss: 0.02127

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.50073
Value Function Update Magnitude: 0.63822

Collected Steps per Second: 22,480.90551
Overall Steps per Second: 10,560.97803

Timestep Collection Time: 2.22411
Timestep Consumption Time: 2.51030
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.73441

Cumulative Model Updates: 307,870
Cumulative Timesteps: 2,567,609,748

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2567609748...
Checkpoint 2567609748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.13149
Policy Entropy: 2.39889
Value Function Loss: 0.02030

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.50233
Value Function Update Magnitude: 0.65442

Collected Steps per Second: 22,138.22282
Overall Steps per Second: 10,568.47465

Timestep Collection Time: 2.25917
Timestep Consumption Time: 2.47321
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.73238

Cumulative Model Updates: 307,876
Cumulative Timesteps: 2,567,659,762

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.79562
Policy Entropy: 2.39979
Value Function Loss: 0.02099

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.09707
Policy Update Magnitude: 0.49914
Value Function Update Magnitude: 0.64825

Collected Steps per Second: 21,974.51185
Overall Steps per Second: 10,498.66319

Timestep Collection Time: 2.27536
Timestep Consumption Time: 2.48715
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.76251

Cumulative Model Updates: 307,882
Cumulative Timesteps: 2,567,709,762

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2567709762...
Checkpoint 2567709762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.61675
Policy Entropy: 2.39108
Value Function Loss: 0.02037

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.49456
Value Function Update Magnitude: 0.64182

Collected Steps per Second: 22,167.15085
Overall Steps per Second: 10,564.69015

Timestep Collection Time: 2.25586
Timestep Consumption Time: 2.47745
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.73331

Cumulative Model Updates: 307,888
Cumulative Timesteps: 2,567,759,768

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.46353
Policy Entropy: 2.37965
Value Function Loss: 0.02057

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.09937
Policy Update Magnitude: 0.50016
Value Function Update Magnitude: 0.65089

Collected Steps per Second: 22,391.89094
Overall Steps per Second: 10,872.75457

Timestep Collection Time: 2.23438
Timestep Consumption Time: 2.36721
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.60159

Cumulative Model Updates: 307,894
Cumulative Timesteps: 2,567,809,800

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2567809800...
Checkpoint 2567809800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.84282
Policy Entropy: 2.38272
Value Function Loss: 0.02158

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.10626
Policy Update Magnitude: 0.51680
Value Function Update Magnitude: 0.67341

Collected Steps per Second: 22,137.82300
Overall Steps per Second: 10,620.99920

Timestep Collection Time: 2.25858
Timestep Consumption Time: 2.44908
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.70766

Cumulative Model Updates: 307,900
Cumulative Timesteps: 2,567,859,800

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.58355
Policy Entropy: 2.38328
Value Function Loss: 0.02141

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.11154
Policy Update Magnitude: 0.51484
Value Function Update Magnitude: 0.69383

Collected Steps per Second: 22,318.51468
Overall Steps per Second: 10,516.95985

Timestep Collection Time: 2.24065
Timestep Consumption Time: 2.51434
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.75499

Cumulative Model Updates: 307,906
Cumulative Timesteps: 2,567,909,808

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2567909808...
Checkpoint 2567909808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.06735
Policy Entropy: 2.37394
Value Function Loss: 0.02091

Mean KL Divergence: 0.02711
SB3 Clip Fraction: 0.14095
Policy Update Magnitude: 0.48432
Value Function Update Magnitude: 0.69907

Collected Steps per Second: 21,769.72615
Overall Steps per Second: 10,615.73648

Timestep Collection Time: 2.29778
Timestep Consumption Time: 2.41428
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.71206

Cumulative Model Updates: 307,912
Cumulative Timesteps: 2,567,959,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.16478
Policy Entropy: 2.38116
Value Function Loss: 0.02008

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.13154
Policy Update Magnitude: 0.48534
Value Function Update Magnitude: 0.68803

Collected Steps per Second: 19,868.42255
Overall Steps per Second: 10,060.78977

Timestep Collection Time: 2.51736
Timestep Consumption Time: 2.45402
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.97138

Cumulative Model Updates: 307,918
Cumulative Timesteps: 2,568,009,846

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2568009846...
Checkpoint 2568009846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.13073
Policy Entropy: 2.39574
Value Function Loss: 0.02071

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.48917
Value Function Update Magnitude: 0.67100

Collected Steps per Second: 20,001.02856
Overall Steps per Second: 10,141.39556

Timestep Collection Time: 2.50057
Timestep Consumption Time: 2.43110
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.93167

Cumulative Model Updates: 307,924
Cumulative Timesteps: 2,568,059,860

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.93072
Policy Entropy: 2.41632
Value Function Loss: 0.02084

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.11004
Policy Update Magnitude: 0.49138
Value Function Update Magnitude: 0.66476

Collected Steps per Second: 22,533.66272
Overall Steps per Second: 10,546.90316

Timestep Collection Time: 2.21926
Timestep Consumption Time: 2.52223
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.74149

Cumulative Model Updates: 307,930
Cumulative Timesteps: 2,568,109,868

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2568109868...
Checkpoint 2568109868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.75914
Policy Entropy: 2.38568
Value Function Loss: 0.02140

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.11815
Policy Update Magnitude: 0.48336
Value Function Update Magnitude: 0.65149

Collected Steps per Second: 22,221.62198
Overall Steps per Second: 10,676.22305

Timestep Collection Time: 2.25096
Timestep Consumption Time: 2.43422
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.68518

Cumulative Model Updates: 307,936
Cumulative Timesteps: 2,568,159,888

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.75933
Policy Entropy: 2.39991
Value Function Loss: 0.02031

Mean KL Divergence: 0.02285
SB3 Clip Fraction: 0.13114
Policy Update Magnitude: 0.47538
Value Function Update Magnitude: 0.64021

Collected Steps per Second: 22,896.23508
Overall Steps per Second: 10,812.67821

Timestep Collection Time: 2.18525
Timestep Consumption Time: 2.44210
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.62735

Cumulative Model Updates: 307,942
Cumulative Timesteps: 2,568,209,922

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2568209922...
Checkpoint 2568209922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.93464
Policy Entropy: 2.39272
Value Function Loss: 0.02097

Mean KL Divergence: 0.02484
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.49042
Value Function Update Magnitude: 0.65270

Collected Steps per Second: 22,218.52807
Overall Steps per Second: 10,671.01353

Timestep Collection Time: 2.25100
Timestep Consumption Time: 2.43590
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.68690

Cumulative Model Updates: 307,948
Cumulative Timesteps: 2,568,259,936

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.16581
Policy Entropy: 2.39903
Value Function Loss: 0.02204

Mean KL Divergence: 0.02427
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.50515
Value Function Update Magnitude: 0.67114

Collected Steps per Second: 22,061.59592
Overall Steps per Second: 10,504.52977

Timestep Collection Time: 2.26684
Timestep Consumption Time: 2.49397
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.76080

Cumulative Model Updates: 307,954
Cumulative Timesteps: 2,568,309,946

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2568309946...
Checkpoint 2568309946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.29551
Policy Entropy: 2.38083
Value Function Loss: 0.02186

Mean KL Divergence: 0.02501
SB3 Clip Fraction: 0.14549
Policy Update Magnitude: 0.49146
Value Function Update Magnitude: 0.67821

Collected Steps per Second: 22,063.48550
Overall Steps per Second: 10,622.80359

Timestep Collection Time: 2.26709
Timestep Consumption Time: 2.44164
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.70874

Cumulative Model Updates: 307,960
Cumulative Timesteps: 2,568,359,966

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.05180
Policy Entropy: 2.38612
Value Function Loss: 0.02188

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.12121
Policy Update Magnitude: 0.48948
Value Function Update Magnitude: 0.65632

Collected Steps per Second: 22,476.85827
Overall Steps per Second: 10,900.51655

Timestep Collection Time: 2.22487
Timestep Consumption Time: 2.36281
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.58767

Cumulative Model Updates: 307,966
Cumulative Timesteps: 2,568,409,974

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2568409974...
Checkpoint 2568409974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.12094
Policy Entropy: 2.39755
Value Function Loss: 0.02057

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.10534
Policy Update Magnitude: 0.49769
Value Function Update Magnitude: 0.62876

Collected Steps per Second: 22,140.63283
Overall Steps per Second: 10,723.82241

Timestep Collection Time: 2.25838
Timestep Consumption Time: 2.40432
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.66270

Cumulative Model Updates: 307,972
Cumulative Timesteps: 2,568,459,976

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.09935
Policy Entropy: 2.39450
Value Function Loss: 0.02147

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.09926
Policy Update Magnitude: 0.50006
Value Function Update Magnitude: 0.62256

Collected Steps per Second: 22,183.74076
Overall Steps per Second: 10,523.08046

Timestep Collection Time: 2.25453
Timestep Consumption Time: 2.49826
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.75279

Cumulative Model Updates: 307,978
Cumulative Timesteps: 2,568,509,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2568509990...
Checkpoint 2568509990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.08317
Policy Entropy: 2.38095
Value Function Loss: 0.02081

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.09305
Policy Update Magnitude: 0.49843
Value Function Update Magnitude: 0.62822

Collected Steps per Second: 22,125.78925
Overall Steps per Second: 10,557.90767

Timestep Collection Time: 2.26089
Timestep Consumption Time: 2.47717
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.73806

Cumulative Model Updates: 307,984
Cumulative Timesteps: 2,568,560,014

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.24102
Policy Entropy: 2.37321
Value Function Loss: 0.02118

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.49320
Value Function Update Magnitude: 0.63884

Collected Steps per Second: 22,640.82655
Overall Steps per Second: 10,827.86988

Timestep Collection Time: 2.20928
Timestep Consumption Time: 2.41028
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.61956

Cumulative Model Updates: 307,990
Cumulative Timesteps: 2,568,610,034

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2568610034...
Checkpoint 2568610034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.65277
Policy Entropy: 2.37351
Value Function Loss: 0.02156

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.10135
Policy Update Magnitude: 0.49891
Value Function Update Magnitude: 0.64035

Collected Steps per Second: 21,997.31659
Overall Steps per Second: 10,713.89457

Timestep Collection Time: 2.27382
Timestep Consumption Time: 2.39469
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.66852

Cumulative Model Updates: 307,996
Cumulative Timesteps: 2,568,660,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.48364
Policy Entropy: 2.38876
Value Function Loss: 0.02233

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.10288
Policy Update Magnitude: 0.49907
Value Function Update Magnitude: 0.64160

Collected Steps per Second: 22,730.35382
Overall Steps per Second: 10,786.38066

Timestep Collection Time: 2.20111
Timestep Consumption Time: 2.43733
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.63844

Cumulative Model Updates: 308,002
Cumulative Timesteps: 2,568,710,084

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2568710084...
Checkpoint 2568710084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.80923
Policy Entropy: 2.40362
Value Function Loss: 0.02097

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.09250
Policy Update Magnitude: 0.49867
Value Function Update Magnitude: 0.63760

Collected Steps per Second: 22,370.01466
Overall Steps per Second: 10,646.70584

Timestep Collection Time: 2.23549
Timestep Consumption Time: 2.46155
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.69704

Cumulative Model Updates: 308,008
Cumulative Timesteps: 2,568,760,092

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.09691
Policy Entropy: 2.41835
Value Function Loss: 0.02125

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.09191
Policy Update Magnitude: 0.49949
Value Function Update Magnitude: 0.61979

Collected Steps per Second: 22,562.49878
Overall Steps per Second: 10,647.74635

Timestep Collection Time: 2.21669
Timestep Consumption Time: 2.48046
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.69714

Cumulative Model Updates: 308,014
Cumulative Timesteps: 2,568,810,106

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2568810106...
Checkpoint 2568810106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.87961
Policy Entropy: 2.41589
Value Function Loss: 0.02099

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.09130
Policy Update Magnitude: 0.49028
Value Function Update Magnitude: 0.61464

Collected Steps per Second: 22,235.00471
Overall Steps per Second: 10,705.57188

Timestep Collection Time: 2.24961
Timestep Consumption Time: 2.42273
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.67233

Cumulative Model Updates: 308,020
Cumulative Timesteps: 2,568,860,126

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.28411
Policy Entropy: 2.40595
Value Function Loss: 0.02137

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.09537
Policy Update Magnitude: 0.49416
Value Function Update Magnitude: 0.62722

Collected Steps per Second: 22,598.54852
Overall Steps per Second: 10,758.67704

Timestep Collection Time: 2.21395
Timestep Consumption Time: 2.43644
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.65039

Cumulative Model Updates: 308,026
Cumulative Timesteps: 2,568,910,158

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2568910158...
Checkpoint 2568910158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.34206
Policy Entropy: 2.42730
Value Function Loss: 0.02067

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.09028
Policy Update Magnitude: 0.50467
Value Function Update Magnitude: 0.64579

Collected Steps per Second: 22,257.97346
Overall Steps per Second: 10,707.21477

Timestep Collection Time: 2.24719
Timestep Consumption Time: 2.42423
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.67143

Cumulative Model Updates: 308,032
Cumulative Timesteps: 2,568,960,176

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.47656
Policy Entropy: 2.40499
Value Function Loss: 0.02018

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.09407
Policy Update Magnitude: 0.50286
Value Function Update Magnitude: 0.67010

Collected Steps per Second: 22,577.34807
Overall Steps per Second: 10,822.26655

Timestep Collection Time: 2.21505
Timestep Consumption Time: 2.40598
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.62103

Cumulative Model Updates: 308,038
Cumulative Timesteps: 2,569,010,186

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2569010186...
Checkpoint 2569010186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.51633
Policy Entropy: 2.40494
Value Function Loss: 0.01958

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.09541
Policy Update Magnitude: 0.48746
Value Function Update Magnitude: 0.68387

Collected Steps per Second: 22,080.57756
Overall Steps per Second: 10,707.82245

Timestep Collection Time: 2.26652
Timestep Consumption Time: 2.40726
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.67378

Cumulative Model Updates: 308,044
Cumulative Timesteps: 2,569,060,232

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.21364
Policy Entropy: 2.36612
Value Function Loss: 0.02042

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.49191
Value Function Update Magnitude: 0.65734

Collected Steps per Second: 22,596.69082
Overall Steps per Second: 10,655.70267

Timestep Collection Time: 2.21298
Timestep Consumption Time: 2.47991
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.69289

Cumulative Model Updates: 308,050
Cumulative Timesteps: 2,569,110,238

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2569110238...
Checkpoint 2569110238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.52007
Policy Entropy: 2.39581
Value Function Loss: 0.02038

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.09406
Policy Update Magnitude: 0.49641
Value Function Update Magnitude: 0.65176

Collected Steps per Second: 22,379.87397
Overall Steps per Second: 10,592.25089

Timestep Collection Time: 2.23469
Timestep Consumption Time: 2.48688
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.72156

Cumulative Model Updates: 308,056
Cumulative Timesteps: 2,569,160,250

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.59488
Policy Entropy: 2.39492
Value Function Loss: 0.02042

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.49843
Value Function Update Magnitude: 0.65230

Collected Steps per Second: 22,851.12036
Overall Steps per Second: 10,885.61214

Timestep Collection Time: 2.18913
Timestep Consumption Time: 2.40630
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.59542

Cumulative Model Updates: 308,062
Cumulative Timesteps: 2,569,210,274

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2569210274...
Checkpoint 2569210274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.92923
Policy Entropy: 2.40407
Value Function Loss: 0.01888

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.09028
Policy Update Magnitude: 0.49346
Value Function Update Magnitude: 0.65012

Collected Steps per Second: 22,035.50608
Overall Steps per Second: 10,585.74431

Timestep Collection Time: 2.26979
Timestep Consumption Time: 2.45505
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.72484

Cumulative Model Updates: 308,068
Cumulative Timesteps: 2,569,260,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.80379
Policy Entropy: 2.38982
Value Function Loss: 0.01991

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.49757
Value Function Update Magnitude: 0.65677

Collected Steps per Second: 22,338.25436
Overall Steps per Second: 10,583.43156

Timestep Collection Time: 2.23867
Timestep Consumption Time: 2.48645
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.72512

Cumulative Model Updates: 308,074
Cumulative Timesteps: 2,569,310,298

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2569310298...
Checkpoint 2569310298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.73348
Policy Entropy: 2.38620
Value Function Loss: 0.02031

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.50489
Value Function Update Magnitude: 0.66606

Collected Steps per Second: 22,228.01407
Overall Steps per Second: 10,486.86554

Timestep Collection Time: 2.25067
Timestep Consumption Time: 2.51987
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.77054

Cumulative Model Updates: 308,080
Cumulative Timesteps: 2,569,360,326

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.19250
Policy Entropy: 2.37867
Value Function Loss: 0.02137

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.08518
Policy Update Magnitude: 0.51107
Value Function Update Magnitude: 0.68719

Collected Steps per Second: 22,576.04734
Overall Steps per Second: 10,934.22902

Timestep Collection Time: 2.21536
Timestep Consumption Time: 2.35872
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.57408

Cumulative Model Updates: 308,086
Cumulative Timesteps: 2,569,410,340

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2569410340...
Checkpoint 2569410340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.28058
Policy Entropy: 2.37570
Value Function Loss: 0.02160

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.51312
Value Function Update Magnitude: 0.68226

Collected Steps per Second: 22,353.23201
Overall Steps per Second: 10,626.36000

Timestep Collection Time: 2.23780
Timestep Consumption Time: 2.46955
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.70735

Cumulative Model Updates: 308,092
Cumulative Timesteps: 2,569,460,362

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.77044
Policy Entropy: 2.38106
Value Function Loss: 0.02187

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.50632
Value Function Update Magnitude: 0.66458

Collected Steps per Second: 22,704.32233
Overall Steps per Second: 10,652.69257

Timestep Collection Time: 2.20258
Timestep Consumption Time: 2.49182
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.69440

Cumulative Model Updates: 308,098
Cumulative Timesteps: 2,569,510,370

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2569510370...
Checkpoint 2569510370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.12656
Policy Entropy: 2.39102
Value Function Loss: 0.02078

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.08842
Policy Update Magnitude: 0.50342
Value Function Update Magnitude: 0.66337

Collected Steps per Second: 22,456.21005
Overall Steps per Second: 10,607.02379

Timestep Collection Time: 2.22700
Timestep Consumption Time: 2.48780
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.71480

Cumulative Model Updates: 308,104
Cumulative Timesteps: 2,569,560,380

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.37988
Policy Entropy: 2.39604
Value Function Loss: 0.01959

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.08338
Policy Update Magnitude: 0.48886
Value Function Update Magnitude: 0.66879

Collected Steps per Second: 22,821.13055
Overall Steps per Second: 10,841.44101

Timestep Collection Time: 2.19227
Timestep Consumption Time: 2.42243
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.61470

Cumulative Model Updates: 308,110
Cumulative Timesteps: 2,569,610,410

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2569610410...
Checkpoint 2569610410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.72353
Policy Entropy: 2.38647
Value Function Loss: 0.01983

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.08390
Policy Update Magnitude: 0.49233
Value Function Update Magnitude: 0.64667

Collected Steps per Second: 22,419.86069
Overall Steps per Second: 10,542.59354

Timestep Collection Time: 2.23141
Timestep Consumption Time: 2.51391
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.74532

Cumulative Model Updates: 308,116
Cumulative Timesteps: 2,569,660,438

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.61369
Policy Entropy: 2.38499
Value Function Loss: 0.02167

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.09422
Policy Update Magnitude: 0.50156
Value Function Update Magnitude: 0.64901

Collected Steps per Second: 22,572.08085
Overall Steps per Second: 10,655.05382

Timestep Collection Time: 2.21583
Timestep Consumption Time: 2.47828
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.69411

Cumulative Model Updates: 308,122
Cumulative Timesteps: 2,569,710,454

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2569710454...
Checkpoint 2569710454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.19931
Policy Entropy: 2.39372
Value Function Loss: 0.02196

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.50413
Value Function Update Magnitude: 0.67479

Collected Steps per Second: 22,439.59546
Overall Steps per Second: 10,813.87113

Timestep Collection Time: 2.22927
Timestep Consumption Time: 2.39664
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.62591

Cumulative Model Updates: 308,128
Cumulative Timesteps: 2,569,760,478

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.53140
Policy Entropy: 2.40230
Value Function Loss: 0.02187

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.49335
Value Function Update Magnitude: 0.67337

Collected Steps per Second: 22,308.26721
Overall Steps per Second: 10,770.37823

Timestep Collection Time: 2.24294
Timestep Consumption Time: 2.40277
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.64570

Cumulative Model Updates: 308,134
Cumulative Timesteps: 2,569,810,514

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2569810514...
Checkpoint 2569810514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.53459
Policy Entropy: 2.40548
Value Function Loss: 0.02090

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.09360
Policy Update Magnitude: 0.49117
Value Function Update Magnitude: 0.64912

Collected Steps per Second: 22,572.62867
Overall Steps per Second: 10,781.69185

Timestep Collection Time: 2.21507
Timestep Consumption Time: 2.42242
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.63749

Cumulative Model Updates: 308,140
Cumulative Timesteps: 2,569,860,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.03788
Policy Entropy: 2.38303
Value Function Loss: 0.02123

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.09451
Policy Update Magnitude: 0.50125
Value Function Update Magnitude: 0.64831

Collected Steps per Second: 22,109.18065
Overall Steps per Second: 10,525.49364

Timestep Collection Time: 2.26259
Timestep Consumption Time: 2.49006
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.75265

Cumulative Model Updates: 308,146
Cumulative Timesteps: 2,569,910,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2569910538...
Checkpoint 2569910538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.53627
Policy Entropy: 2.37919
Value Function Loss: 0.02002

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.09371
Policy Update Magnitude: 0.49537
Value Function Update Magnitude: 0.64080

Collected Steps per Second: 22,070.61998
Overall Steps per Second: 10,677.14526

Timestep Collection Time: 2.26564
Timestep Consumption Time: 2.41764
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.68327

Cumulative Model Updates: 308,152
Cumulative Timesteps: 2,569,960,542

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.80848
Policy Entropy: 2.38278
Value Function Loss: 0.01945

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.08789
Policy Update Magnitude: 0.50230
Value Function Update Magnitude: 0.62226

Collected Steps per Second: 22,204.91425
Overall Steps per Second: 10,868.65592

Timestep Collection Time: 2.25265
Timestep Consumption Time: 2.34957
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.60222

Cumulative Model Updates: 308,158
Cumulative Timesteps: 2,570,010,562

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2570010562...
Checkpoint 2570010562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269.52922
Policy Entropy: 2.40498
Value Function Loss: 0.01900

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.08687
Policy Update Magnitude: 0.49542
Value Function Update Magnitude: 0.60624

Collected Steps per Second: 22,210.72299
Overall Steps per Second: 10,713.92886

Timestep Collection Time: 2.25116
Timestep Consumption Time: 2.41566
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.66682

Cumulative Model Updates: 308,164
Cumulative Timesteps: 2,570,060,562

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.57025
Policy Entropy: 2.39631
Value Function Loss: 0.02050

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.08571
Policy Update Magnitude: 0.50393
Value Function Update Magnitude: 0.61539

Collected Steps per Second: 22,441.61122
Overall Steps per Second: 10,584.97547

Timestep Collection Time: 2.22836
Timestep Consumption Time: 2.49607
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.72443

Cumulative Model Updates: 308,170
Cumulative Timesteps: 2,570,110,570

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2570110570...
Checkpoint 2570110570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.31988
Policy Entropy: 2.38861
Value Function Loss: 0.02192

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.09341
Policy Update Magnitude: 0.50490
Value Function Update Magnitude: 0.64109

Collected Steps per Second: 21,987.66177
Overall Steps per Second: 10,489.84516

Timestep Collection Time: 2.27537
Timestep Consumption Time: 2.49401
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.76937

Cumulative Model Updates: 308,176
Cumulative Timesteps: 2,570,160,600

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.88344
Policy Entropy: 2.37629
Value Function Loss: 0.02108

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.09890
Policy Update Magnitude: 0.50297
Value Function Update Magnitude: 0.64122

Collected Steps per Second: 22,597.90438
Overall Steps per Second: 10,896.48388

Timestep Collection Time: 2.21383
Timestep Consumption Time: 2.37737
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.59121

Cumulative Model Updates: 308,182
Cumulative Timesteps: 2,570,210,628

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2570210628...
Checkpoint 2570210628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.54088
Policy Entropy: 2.38013
Value Function Loss: 0.02085

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.10792
Policy Update Magnitude: 0.49703
Value Function Update Magnitude: 0.62764

Collected Steps per Second: 22,201.83403
Overall Steps per Second: 10,637.28167

Timestep Collection Time: 2.25207
Timestep Consumption Time: 2.44838
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.70045

Cumulative Model Updates: 308,188
Cumulative Timesteps: 2,570,260,628

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.39363
Policy Entropy: 2.40224
Value Function Loss: 0.02058

Mean KL Divergence: 0.02475
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.50055
Value Function Update Magnitude: 0.62684

Collected Steps per Second: 22,537.14019
Overall Steps per Second: 10,631.18764

Timestep Collection Time: 2.21856
Timestep Consumption Time: 2.48458
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.70314

Cumulative Model Updates: 308,194
Cumulative Timesteps: 2,570,310,628

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2570310628...
Checkpoint 2570310628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.71917
Policy Entropy: 2.40980
Value Function Loss: 0.02206

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.11204
Policy Update Magnitude: 0.50383
Value Function Update Magnitude: 0.65183

Collected Steps per Second: 22,069.89376
Overall Steps per Second: 10,571.14065

Timestep Collection Time: 2.26635
Timestep Consumption Time: 2.46522
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.73156

Cumulative Model Updates: 308,200
Cumulative Timesteps: 2,570,360,646

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.87340
Policy Entropy: 2.41682
Value Function Loss: 0.02123

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.10955
Policy Update Magnitude: 0.51121
Value Function Update Magnitude: 0.67129

Collected Steps per Second: 22,711.30250
Overall Steps per Second: 10,798.20488

Timestep Collection Time: 2.20225
Timestep Consumption Time: 2.42963
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.63188

Cumulative Model Updates: 308,206
Cumulative Timesteps: 2,570,410,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2570410662...
Checkpoint 2570410662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.19239
Policy Entropy: 2.42643
Value Function Loss: 0.02085

Mean KL Divergence: 0.02154
SB3 Clip Fraction: 0.12963
Policy Update Magnitude: 0.50814
Value Function Update Magnitude: 0.67413

Collected Steps per Second: 22,295.86911
Overall Steps per Second: 10,637.50998

Timestep Collection Time: 2.24311
Timestep Consumption Time: 2.45837
PPO Batch Consumption Time: 0.28585
Total Iteration Time: 4.70148

Cumulative Model Updates: 308,212
Cumulative Timesteps: 2,570,460,674

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.19118
Policy Entropy: 2.44285
Value Function Loss: 0.01974

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.11339
Policy Update Magnitude: 0.49456
Value Function Update Magnitude: 0.66454

Collected Steps per Second: 22,527.66329
Overall Steps per Second: 10,641.15763

Timestep Collection Time: 2.21949
Timestep Consumption Time: 2.47924
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.69874

Cumulative Model Updates: 308,218
Cumulative Timesteps: 2,570,510,674

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2570510674...
Checkpoint 2570510674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.64363
Policy Entropy: 2.44011
Value Function Loss: 0.01916

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.11359
Policy Update Magnitude: 0.50221
Value Function Update Magnitude: 0.64627

Collected Steps per Second: 22,367.98621
Overall Steps per Second: 10,578.65165

Timestep Collection Time: 2.23552
Timestep Consumption Time: 2.49136
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.72688

Cumulative Model Updates: 308,224
Cumulative Timesteps: 2,570,560,678

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.21835
Policy Entropy: 2.42990
Value Function Loss: 0.01955

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.48932
Value Function Update Magnitude: 0.63095

Collected Steps per Second: 22,796.98863
Overall Steps per Second: 10,784.21359

Timestep Collection Time: 2.19345
Timestep Consumption Time: 2.44333
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.63678

Cumulative Model Updates: 308,230
Cumulative Timesteps: 2,570,610,682

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2570610682...
Checkpoint 2570610682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.94383
Policy Entropy: 2.40359
Value Function Loss: 0.02004

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.11390
Policy Update Magnitude: 0.49129
Value Function Update Magnitude: 0.62871

Collected Steps per Second: 22,171.50975
Overall Steps per Second: 10,711.10735

Timestep Collection Time: 2.25542
Timestep Consumption Time: 2.41319
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.66861

Cumulative Model Updates: 308,236
Cumulative Timesteps: 2,570,660,688

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.87002
Policy Entropy: 2.40449
Value Function Loss: 0.02010

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.11109
Policy Update Magnitude: 0.50558
Value Function Update Magnitude: 0.63880

Collected Steps per Second: 22,715.73074
Overall Steps per Second: 10,772.93504

Timestep Collection Time: 2.20165
Timestep Consumption Time: 2.44073
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.64237

Cumulative Model Updates: 308,242
Cumulative Timesteps: 2,570,710,700

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2570710700...
Checkpoint 2570710700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.99309
Policy Entropy: 2.39017
Value Function Loss: 0.02072

Mean KL Divergence: 0.03302
SB3 Clip Fraction: 0.13929
Policy Update Magnitude: 0.50171
Value Function Update Magnitude: 0.64239

Collected Steps per Second: 22,273.13255
Overall Steps per Second: 10,675.90927

Timestep Collection Time: 2.24504
Timestep Consumption Time: 2.43878
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.68382

Cumulative Model Updates: 308,248
Cumulative Timesteps: 2,570,760,704

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.47022
Policy Entropy: 2.43518
Value Function Loss: 0.02000

Mean KL Divergence: 0.02486
SB3 Clip Fraction: 0.11888
Policy Update Magnitude: 0.49521
Value Function Update Magnitude: 0.63913

Collected Steps per Second: 22,438.53128
Overall Steps per Second: 10,672.41872

Timestep Collection Time: 2.22876
Timestep Consumption Time: 2.45716
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.68591

Cumulative Model Updates: 308,254
Cumulative Timesteps: 2,570,810,714

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2570810714...
Checkpoint 2570810714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.37032
Policy Entropy: 2.42620
Value Function Loss: 0.02117

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.10912
Policy Update Magnitude: 0.50598
Value Function Update Magnitude: 0.65518

Collected Steps per Second: 22,955.57398
Overall Steps per Second: 10,858.84894

Timestep Collection Time: 2.17908
Timestep Consumption Time: 2.42749
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.60657

Cumulative Model Updates: 308,260
Cumulative Timesteps: 2,570,860,736

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.78567
Policy Entropy: 2.43811
Value Function Loss: 0.02061

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.09708
Policy Update Magnitude: 0.49891
Value Function Update Magnitude: 0.67641

Collected Steps per Second: 22,571.20500
Overall Steps per Second: 10,618.91977

Timestep Collection Time: 2.21610
Timestep Consumption Time: 2.49436
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.71046

Cumulative Model Updates: 308,266
Cumulative Timesteps: 2,570,910,756

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2570910756...
Checkpoint 2570910756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.65953
Policy Entropy: 2.43603
Value Function Loss: 0.02184

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.09924
Policy Update Magnitude: 0.50152
Value Function Update Magnitude: 0.69561

Collected Steps per Second: 22,162.78310
Overall Steps per Second: 10,480.88093

Timestep Collection Time: 2.25658
Timestep Consumption Time: 2.51516
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.77174

Cumulative Model Updates: 308,272
Cumulative Timesteps: 2,570,960,768

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.08422
Policy Entropy: 2.41605
Value Function Loss: 0.02068

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.51044
Value Function Update Magnitude: 0.70969

Collected Steps per Second: 22,557.31035
Overall Steps per Second: 10,701.45706

Timestep Collection Time: 2.21711
Timestep Consumption Time: 2.45627
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.67338

Cumulative Model Updates: 308,278
Cumulative Timesteps: 2,571,010,780

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2571010780...
Checkpoint 2571010780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.47247
Policy Entropy: 2.41769
Value Function Loss: 0.02177

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.09877
Policy Update Magnitude: 0.51599
Value Function Update Magnitude: 0.71199

Collected Steps per Second: 22,899.25687
Overall Steps per Second: 10,894.50598

Timestep Collection Time: 2.18444
Timestep Consumption Time: 2.40705
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.59149

Cumulative Model Updates: 308,284
Cumulative Timesteps: 2,571,060,802

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.25237
Policy Entropy: 2.38380
Value Function Loss: 0.02134

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.10003
Policy Update Magnitude: 0.52092
Value Function Update Magnitude: 0.71719

Collected Steps per Second: 22,633.52321
Overall Steps per Second: 10,583.87573

Timestep Collection Time: 2.20947
Timestep Consumption Time: 2.51546
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.72492

Cumulative Model Updates: 308,290
Cumulative Timesteps: 2,571,110,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2571110810...
Checkpoint 2571110810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.24743
Policy Entropy: 2.39240
Value Function Loss: 0.02078

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.09389
Policy Update Magnitude: 0.51254
Value Function Update Magnitude: 0.70370

Collected Steps per Second: 22,253.97490
Overall Steps per Second: 10,639.27778

Timestep Collection Time: 2.24688
Timestep Consumption Time: 2.45288
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.69976

Cumulative Model Updates: 308,296
Cumulative Timesteps: 2,571,160,812

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.24386
Policy Entropy: 2.38021
Value Function Loss: 0.02079

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.50777
Value Function Update Magnitude: 0.67452

Collected Steps per Second: 22,492.58022
Overall Steps per Second: 10,717.09593

Timestep Collection Time: 2.22304
Timestep Consumption Time: 2.44259
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.66563

Cumulative Model Updates: 308,302
Cumulative Timesteps: 2,571,210,814

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2571210814...
Checkpoint 2571210814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.53308
Policy Entropy: 2.39909
Value Function Loss: 0.02127

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.10131
Policy Update Magnitude: 0.50955
Value Function Update Magnitude: 0.65778

Collected Steps per Second: 23,011.57646
Overall Steps per Second: 10,666.93375

Timestep Collection Time: 2.17343
Timestep Consumption Time: 2.51527
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.68870

Cumulative Model Updates: 308,308
Cumulative Timesteps: 2,571,260,828

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.72512
Policy Entropy: 2.39879
Value Function Loss: 0.02164

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.51164
Value Function Update Magnitude: 0.67480

Collected Steps per Second: 22,605.53051
Overall Steps per Second: 10,658.77807

Timestep Collection Time: 2.21291
Timestep Consumption Time: 2.48031
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.69322

Cumulative Model Updates: 308,314
Cumulative Timesteps: 2,571,310,852

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2571310852...
Checkpoint 2571310852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.15683
Policy Entropy: 2.40560
Value Function Loss: 0.02128

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.11300
Policy Update Magnitude: 0.50535
Value Function Update Magnitude: 0.71007

Collected Steps per Second: 22,350.86568
Overall Steps per Second: 10,605.56927

Timestep Collection Time: 2.23714
Timestep Consumption Time: 2.47755
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.71469

Cumulative Model Updates: 308,320
Cumulative Timesteps: 2,571,360,854

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.59114
Policy Entropy: 2.40582
Value Function Loss: 0.02140

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.10398
Policy Update Magnitude: 0.50970
Value Function Update Magnitude: 0.72663

Collected Steps per Second: 22,563.16020
Overall Steps per Second: 10,800.40344

Timestep Collection Time: 2.21680
Timestep Consumption Time: 2.41432
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.63112

Cumulative Model Updates: 308,326
Cumulative Timesteps: 2,571,410,872

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2571410872...
Checkpoint 2571410872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.66363
Policy Entropy: 2.39667
Value Function Loss: 0.02286

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.12693
Policy Update Magnitude: 0.51404
Value Function Update Magnitude: 0.74387

Collected Steps per Second: 22,501.69384
Overall Steps per Second: 10,622.57539

Timestep Collection Time: 2.22277
Timestep Consumption Time: 2.48570
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.70846

Cumulative Model Updates: 308,332
Cumulative Timesteps: 2,571,460,888

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.39913
Policy Entropy: 2.40975
Value Function Loss: 0.02305

Mean KL Divergence: 0.02453
SB3 Clip Fraction: 0.13227
Policy Update Magnitude: 0.50586
Value Function Update Magnitude: 0.75649

Collected Steps per Second: 22,600.63792
Overall Steps per Second: 10,768.98731

Timestep Collection Time: 2.21277
Timestep Consumption Time: 2.43112
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.64389

Cumulative Model Updates: 308,338
Cumulative Timesteps: 2,571,510,898

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2571510898...
Checkpoint 2571510898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.01966
Policy Entropy: 2.42357
Value Function Loss: 0.02259

Mean KL Divergence: 0.02402
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.50497
Value Function Update Magnitude: 0.76631

Collected Steps per Second: 21,809.39020
Overall Steps per Second: 10,473.23266

Timestep Collection Time: 2.29351
Timestep Consumption Time: 2.48248
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.77598

Cumulative Model Updates: 308,344
Cumulative Timesteps: 2,571,560,918

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.30275
Policy Entropy: 2.41786
Value Function Loss: 0.02232

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.12117
Policy Update Magnitude: 0.51342
Value Function Update Magnitude: 0.74979

Collected Steps per Second: 22,077.85787
Overall Steps per Second: 10,687.51982

Timestep Collection Time: 2.26526
Timestep Consumption Time: 2.41422
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.67948

Cumulative Model Updates: 308,350
Cumulative Timesteps: 2,571,610,930

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2571610930...
Checkpoint 2571610930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.69964
Policy Entropy: 2.40850
Value Function Loss: 0.02306

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.10552
Policy Update Magnitude: 0.51878
Value Function Update Magnitude: 0.73152

Collected Steps per Second: 22,336.00114
Overall Steps per Second: 10,751.80842

Timestep Collection Time: 2.23925
Timestep Consumption Time: 2.41261
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.65187

Cumulative Model Updates: 308,356
Cumulative Timesteps: 2,571,660,946

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.98958
Policy Entropy: 2.40894
Value Function Loss: 0.02227

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.50945
Value Function Update Magnitude: 0.72589

Collected Steps per Second: 22,596.31629
Overall Steps per Second: 10,756.39665

Timestep Collection Time: 2.21319
Timestep Consumption Time: 2.43613
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.64933

Cumulative Model Updates: 308,362
Cumulative Timesteps: 2,571,710,956

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2571710956...
Checkpoint 2571710956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.20266
Policy Entropy: 2.41202
Value Function Loss: 0.02172

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.51139
Value Function Update Magnitude: 0.70254

Collected Steps per Second: 22,411.52789
Overall Steps per Second: 10,727.31289

Timestep Collection Time: 2.23189
Timestep Consumption Time: 2.43098
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.66286

Cumulative Model Updates: 308,368
Cumulative Timesteps: 2,571,760,976

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.41757
Policy Entropy: 2.40901
Value Function Loss: 0.02149

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.51318
Value Function Update Magnitude: 0.68207

Collected Steps per Second: 22,125.44411
Overall Steps per Second: 10,571.00327

Timestep Collection Time: 2.26047
Timestep Consumption Time: 2.47077
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.73124

Cumulative Model Updates: 308,374
Cumulative Timesteps: 2,571,810,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2571810990...
Checkpoint 2571810990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.20579
Policy Entropy: 2.40761
Value Function Loss: 0.02027

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.50406
Value Function Update Magnitude: 0.68810

Collected Steps per Second: 22,145.10660
Overall Steps per Second: 10,864.04008

Timestep Collection Time: 2.25820
Timestep Consumption Time: 2.34488
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.60308

Cumulative Model Updates: 308,380
Cumulative Timesteps: 2,571,860,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.96248
Policy Entropy: 2.39949
Value Function Loss: 0.02018

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.09180
Policy Update Magnitude: 0.50118
Value Function Update Magnitude: 0.66988

Collected Steps per Second: 22,219.95597
Overall Steps per Second: 10,533.34929

Timestep Collection Time: 2.25041
Timestep Consumption Time: 2.49680
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.74721

Cumulative Model Updates: 308,386
Cumulative Timesteps: 2,571,911,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2571911002...
Checkpoint 2571911002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.91862
Policy Entropy: 2.42841
Value Function Loss: 0.01887

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.48851
Value Function Update Magnitude: 0.64909

Collected Steps per Second: 22,333.16504
Overall Steps per Second: 10,721.25538

Timestep Collection Time: 2.23909
Timestep Consumption Time: 2.42510
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.66419

Cumulative Model Updates: 308,392
Cumulative Timesteps: 2,571,961,008

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.72789
Policy Entropy: 2.41920
Value Function Loss: 0.02016

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.08610
Policy Update Magnitude: 0.48515
Value Function Update Magnitude: 0.64430

Collected Steps per Second: 22,508.62333
Overall Steps per Second: 10,799.37204

Timestep Collection Time: 2.22208
Timestep Consumption Time: 2.40930
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.63138

Cumulative Model Updates: 308,398
Cumulative Timesteps: 2,572,011,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2572011024...
Checkpoint 2572011024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.31484
Policy Entropy: 2.44210
Value Function Loss: 0.02012

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.09198
Policy Update Magnitude: 0.49136
Value Function Update Magnitude: 0.65939

Collected Steps per Second: 22,862.73025
Overall Steps per Second: 10,673.93040

Timestep Collection Time: 2.18697
Timestep Consumption Time: 2.49734
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.68431

Cumulative Model Updates: 308,404
Cumulative Timesteps: 2,572,061,024

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.13053
Policy Entropy: 2.42283
Value Function Loss: 0.02108

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.08854
Policy Update Magnitude: 0.49038
Value Function Update Magnitude: 0.68021

Collected Steps per Second: 22,729.90027
Overall Steps per Second: 10,660.19584

Timestep Collection Time: 2.20133
Timestep Consumption Time: 2.49239
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.69372

Cumulative Model Updates: 308,410
Cumulative Timesteps: 2,572,111,060

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2572111060...
Checkpoint 2572111060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.68443
Policy Entropy: 2.41736
Value Function Loss: 0.02091

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.08852
Policy Update Magnitude: 0.50211
Value Function Update Magnitude: 0.67783

Collected Steps per Second: 22,334.03330
Overall Steps per Second: 10,602.77483

Timestep Collection Time: 2.23945
Timestep Consumption Time: 2.47780
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.71726

Cumulative Model Updates: 308,416
Cumulative Timesteps: 2,572,161,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.90484
Policy Entropy: 2.40605
Value Function Loss: 0.02119

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.08738
Policy Update Magnitude: 0.50431
Value Function Update Magnitude: 0.64466

Collected Steps per Second: 22,524.35504
Overall Steps per Second: 10,707.08911

Timestep Collection Time: 2.22088
Timestep Consumption Time: 2.45116
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.67204

Cumulative Model Updates: 308,422
Cumulative Timesteps: 2,572,211,100

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2572211100...
Checkpoint 2572211100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.11712
Policy Entropy: 2.41343
Value Function Loss: 0.02170

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.50451
Value Function Update Magnitude: 0.65211

Collected Steps per Second: 22,325.99778
Overall Steps per Second: 10,624.77176

Timestep Collection Time: 2.24035
Timestep Consumption Time: 2.46733
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.70768

Cumulative Model Updates: 308,428
Cumulative Timesteps: 2,572,261,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.20400
Policy Entropy: 2.41103
Value Function Loss: 0.02167

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.09454
Policy Update Magnitude: 0.50516
Value Function Update Magnitude: 0.66900

Collected Steps per Second: 22,579.44723
Overall Steps per Second: 10,591.42531

Timestep Collection Time: 2.21511
Timestep Consumption Time: 2.50720
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.72231

Cumulative Model Updates: 308,434
Cumulative Timesteps: 2,572,311,134

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2572311134...
Checkpoint 2572311134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.07510
Policy Entropy: 2.39436
Value Function Loss: 0.02174

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.08750
Policy Update Magnitude: 0.50630
Value Function Update Magnitude: 0.64399

Collected Steps per Second: 22,346.25790
Overall Steps per Second: 10,638.20737

Timestep Collection Time: 2.23841
Timestep Consumption Time: 2.46351
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.70192

Cumulative Model Updates: 308,440
Cumulative Timesteps: 2,572,361,154

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.62119
Policy Entropy: 2.40460
Value Function Loss: 0.02149

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.50247
Value Function Update Magnitude: 0.61501

Collected Steps per Second: 22,357.59723
Overall Steps per Second: 10,800.75498

Timestep Collection Time: 2.23772
Timestep Consumption Time: 2.39437
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.63208

Cumulative Model Updates: 308,446
Cumulative Timesteps: 2,572,411,184

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2572411184...
Checkpoint 2572411184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.14101
Policy Entropy: 2.40987
Value Function Loss: 0.02094

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.49797
Value Function Update Magnitude: 0.62331

Collected Steps per Second: 22,510.91165
Overall Steps per Second: 10,643.87712

Timestep Collection Time: 2.22221
Timestep Consumption Time: 2.47758
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.69979

Cumulative Model Updates: 308,452
Cumulative Timesteps: 2,572,461,208

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.08748
Policy Entropy: 2.42186
Value Function Loss: 0.02238

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.08934
Policy Update Magnitude: 0.50330
Value Function Update Magnitude: 0.65646

Collected Steps per Second: 22,419.66079
Overall Steps per Second: 10,587.48695

Timestep Collection Time: 2.23027
Timestep Consumption Time: 2.49247
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.72274

Cumulative Model Updates: 308,458
Cumulative Timesteps: 2,572,511,210

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2572511210...
Checkpoint 2572511210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.04432
Policy Entropy: 2.42093
Value Function Loss: 0.02079

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.08966
Policy Update Magnitude: 0.49807
Value Function Update Magnitude: 0.66161

Collected Steps per Second: 22,428.65200
Overall Steps per Second: 10,645.25329

Timestep Collection Time: 2.23009
Timestep Consumption Time: 2.46853
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.69862

Cumulative Model Updates: 308,464
Cumulative Timesteps: 2,572,561,228

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.08880
Policy Entropy: 2.42293
Value Function Loss: 0.02080

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.49190
Value Function Update Magnitude: 0.62512

Collected Steps per Second: 22,077.90150
Overall Steps per Second: 10,725.52990

Timestep Collection Time: 2.26543
Timestep Consumption Time: 2.39783
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.66327

Cumulative Model Updates: 308,470
Cumulative Timesteps: 2,572,611,244

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2572611244...
Checkpoint 2572611244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.90737
Policy Entropy: 2.42297
Value Function Loss: 0.01898

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.08957
Policy Update Magnitude: 0.48780
Value Function Update Magnitude: 0.63076

Collected Steps per Second: 22,108.38163
Overall Steps per Second: 10,665.65539

Timestep Collection Time: 2.26285
Timestep Consumption Time: 2.42772
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.69057

Cumulative Model Updates: 308,476
Cumulative Timesteps: 2,572,661,272

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.49756
Policy Entropy: 2.41536
Value Function Loss: 0.01905

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.09390
Policy Update Magnitude: 0.49386
Value Function Update Magnitude: 0.66673

Collected Steps per Second: 22,653.88033
Overall Steps per Second: 10,669.85818

Timestep Collection Time: 2.20713
Timestep Consumption Time: 2.47897
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.68610

Cumulative Model Updates: 308,482
Cumulative Timesteps: 2,572,711,272

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2572711272...
Checkpoint 2572711272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.30398
Policy Entropy: 2.41628
Value Function Loss: 0.01950

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.08907
Policy Update Magnitude: 0.49734
Value Function Update Magnitude: 0.68693

Collected Steps per Second: 22,387.32772
Overall Steps per Second: 10,815.92119

Timestep Collection Time: 2.23376
Timestep Consumption Time: 2.38979
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.62355

Cumulative Model Updates: 308,488
Cumulative Timesteps: 2,572,761,280

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.78811
Policy Entropy: 2.40556
Value Function Loss: 0.02122

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.09190
Policy Update Magnitude: 0.49764
Value Function Update Magnitude: 0.70671

Collected Steps per Second: 22,519.16175
Overall Steps per Second: 10,903.16988

Timestep Collection Time: 2.22157
Timestep Consumption Time: 2.36682
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.58839

Cumulative Model Updates: 308,494
Cumulative Timesteps: 2,572,811,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2572811308...
Checkpoint 2572811308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.00251
Policy Entropy: 2.40645
Value Function Loss: 0.02159

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.10216
Policy Update Magnitude: 0.48512
Value Function Update Magnitude: 0.70965

Collected Steps per Second: 22,173.28817
Overall Steps per Second: 10,678.33248

Timestep Collection Time: 2.25542
Timestep Consumption Time: 2.42790
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.68332

Cumulative Model Updates: 308,500
Cumulative Timesteps: 2,572,861,318

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.48454
Policy Entropy: 2.39547
Value Function Loss: 0.02183

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.11067
Policy Update Magnitude: 0.49259
Value Function Update Magnitude: 0.69565

Collected Steps per Second: 22,387.73174
Overall Steps per Second: 10,574.17410

Timestep Collection Time: 2.23453
Timestep Consumption Time: 2.49643
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.73096

Cumulative Model Updates: 308,506
Cumulative Timesteps: 2,572,911,344

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2572911344...
Checkpoint 2572911344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.34718
Policy Entropy: 2.40643
Value Function Loss: 0.02086

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.10450
Policy Update Magnitude: 0.49500
Value Function Update Magnitude: 0.67972

Collected Steps per Second: 22,218.68205
Overall Steps per Second: 10,572.42402

Timestep Collection Time: 2.25036
Timestep Consumption Time: 2.47893
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.72928

Cumulative Model Updates: 308,512
Cumulative Timesteps: 2,572,961,344

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.06647
Policy Entropy: 2.40705
Value Function Loss: 0.01961

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.09189
Policy Update Magnitude: 0.49066
Value Function Update Magnitude: 0.67388

Collected Steps per Second: 22,228.61122
Overall Steps per Second: 10,850.34807

Timestep Collection Time: 2.24935
Timestep Consumption Time: 2.35879
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.60815

Cumulative Model Updates: 308,518
Cumulative Timesteps: 2,573,011,344

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2573011344...
Checkpoint 2573011344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.83086
Policy Entropy: 2.41071
Value Function Loss: 0.02010

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.08694
Policy Update Magnitude: 0.48918
Value Function Update Magnitude: 0.64278

Collected Steps per Second: 22,368.69874
Overall Steps per Second: 10,732.58004

Timestep Collection Time: 2.23553
Timestep Consumption Time: 2.42374
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.65927

Cumulative Model Updates: 308,524
Cumulative Timesteps: 2,573,061,350

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.20501
Policy Entropy: 2.41167
Value Function Loss: 0.02052

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.49603
Value Function Update Magnitude: 0.66488

Collected Steps per Second: 22,497.39632
Overall Steps per Second: 10,779.85484

Timestep Collection Time: 2.22310
Timestep Consumption Time: 2.41648
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.63958

Cumulative Model Updates: 308,530
Cumulative Timesteps: 2,573,111,364

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2573111364...
Checkpoint 2573111364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.59445
Policy Entropy: 2.39900
Value Function Loss: 0.02120

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.09406
Policy Update Magnitude: 0.49316
Value Function Update Magnitude: 0.68516

Collected Steps per Second: 22,052.17978
Overall Steps per Second: 10,696.26190

Timestep Collection Time: 2.26817
Timestep Consumption Time: 2.40805
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.67621

Cumulative Model Updates: 308,536
Cumulative Timesteps: 2,573,161,382

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.89564
Policy Entropy: 2.42699
Value Function Loss: 0.02027

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.49076
Value Function Update Magnitude: 0.65726

Collected Steps per Second: 22,261.57822
Overall Steps per Second: 10,845.78851

Timestep Collection Time: 2.24701
Timestep Consumption Time: 2.36510
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.61211

Cumulative Model Updates: 308,542
Cumulative Timesteps: 2,573,211,404

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2573211404...
Checkpoint 2573211404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.33794
Policy Entropy: 2.42114
Value Function Loss: 0.02154

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.49069
Value Function Update Magnitude: 0.65232

Collected Steps per Second: 22,165.25513
Overall Steps per Second: 10,661.94435

Timestep Collection Time: 2.25768
Timestep Consumption Time: 2.43584
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.69352

Cumulative Model Updates: 308,548
Cumulative Timesteps: 2,573,261,446

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.18174
Policy Entropy: 2.40964
Value Function Loss: 0.02144

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.08593
Policy Update Magnitude: 0.49792
Value Function Update Magnitude: 0.65200

Collected Steps per Second: 22,413.23410
Overall Steps per Second: 10,567.51472

Timestep Collection Time: 2.23118
Timestep Consumption Time: 2.50106
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.73224

Cumulative Model Updates: 308,554
Cumulative Timesteps: 2,573,311,454

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2573311454...
Checkpoint 2573311454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.44170
Policy Entropy: 2.37930
Value Function Loss: 0.02240

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.10189
Policy Update Magnitude: 0.49758
Value Function Update Magnitude: 0.65972

Collected Steps per Second: 22,442.97173
Overall Steps per Second: 10,628.80478

Timestep Collection Time: 2.22814
Timestep Consumption Time: 2.47663
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.70476

Cumulative Model Updates: 308,560
Cumulative Timesteps: 2,573,361,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.89727
Policy Entropy: 2.38621
Value Function Loss: 0.02010

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.09684
Policy Update Magnitude: 0.49258
Value Function Update Magnitude: 0.66178

Collected Steps per Second: 22,421.46839
Overall Steps per Second: 10,776.08488

Timestep Collection Time: 2.23143
Timestep Consumption Time: 2.41144
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.64287

Cumulative Model Updates: 308,566
Cumulative Timesteps: 2,573,411,492

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2573411492...
Checkpoint 2573411492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.91222
Policy Entropy: 2.39971
Value Function Loss: 0.01921

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.09919
Policy Update Magnitude: 0.48633
Value Function Update Magnitude: 0.63178

Collected Steps per Second: 23,047.93215
Overall Steps per Second: 10,755.79533

Timestep Collection Time: 2.17052
Timestep Consumption Time: 2.48055
PPO Batch Consumption Time: 0.28585
Total Iteration Time: 4.65107

Cumulative Model Updates: 308,572
Cumulative Timesteps: 2,573,461,518

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.15559
Policy Entropy: 2.39715
Value Function Loss: 0.01954

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.49889
Value Function Update Magnitude: 0.62425

Collected Steps per Second: 22,409.57356
Overall Steps per Second: 10,593.49901

Timestep Collection Time: 2.23181
Timestep Consumption Time: 2.48938
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.72120

Cumulative Model Updates: 308,578
Cumulative Timesteps: 2,573,511,532

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2573511532...
Checkpoint 2573511532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.35231
Policy Entropy: 2.38440
Value Function Loss: 0.02076

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.09457
Policy Update Magnitude: 0.50707
Value Function Update Magnitude: 0.64400

Collected Steps per Second: 22,279.38625
Overall Steps per Second: 10,606.23164

Timestep Collection Time: 2.24450
Timestep Consumption Time: 2.47028
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.71478

Cumulative Model Updates: 308,584
Cumulative Timesteps: 2,573,561,538

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.55702
Policy Entropy: 2.37723
Value Function Loss: 0.02288

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.09482
Policy Update Magnitude: 0.51325
Value Function Update Magnitude: 0.67255

Collected Steps per Second: 22,363.76232
Overall Steps per Second: 10,737.64177

Timestep Collection Time: 2.23674
Timestep Consumption Time: 2.42182
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.65856

Cumulative Model Updates: 308,590
Cumulative Timesteps: 2,573,611,560

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2573611560...
Checkpoint 2573611560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.70375
Policy Entropy: 2.38608
Value Function Loss: 0.02219

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.09373
Policy Update Magnitude: 0.51666
Value Function Update Magnitude: 0.67093

Collected Steps per Second: 23,115.06246
Overall Steps per Second: 10,721.58064

Timestep Collection Time: 2.16378
Timestep Consumption Time: 2.50120
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.66498

Cumulative Model Updates: 308,596
Cumulative Timesteps: 2,573,661,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.00953
Policy Entropy: 2.39703
Value Function Loss: 0.02172

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.08825
Policy Update Magnitude: 0.51389
Value Function Update Magnitude: 0.66476

Collected Steps per Second: 22,194.75444
Overall Steps per Second: 10,551.89037

Timestep Collection Time: 2.25314
Timestep Consumption Time: 2.48610
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.73925

Cumulative Model Updates: 308,602
Cumulative Timesteps: 2,573,711,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2573711584...
Checkpoint 2573711584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.51245
Policy Entropy: 2.39231
Value Function Loss: 0.02076

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.09100
Policy Update Magnitude: 0.50815
Value Function Update Magnitude: 0.65913

Collected Steps per Second: 22,568.14863
Overall Steps per Second: 10,736.93603

Timestep Collection Time: 2.21587
Timestep Consumption Time: 2.44170
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.65757

Cumulative Model Updates: 308,608
Cumulative Timesteps: 2,573,761,592

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.19246
Policy Entropy: 2.38807
Value Function Loss: 0.02083

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.08817
Policy Update Magnitude: 0.51228
Value Function Update Magnitude: 0.65343

Collected Steps per Second: 22,378.45811
Overall Steps per Second: 10,738.40124

Timestep Collection Time: 2.23447
Timestep Consumption Time: 2.42209
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.65656

Cumulative Model Updates: 308,614
Cumulative Timesteps: 2,573,811,596

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2573811596...
Checkpoint 2573811596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.79866
Policy Entropy: 2.38870
Value Function Loss: 0.02227

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.09346
Policy Update Magnitude: 0.50791
Value Function Update Magnitude: 0.66245

Collected Steps per Second: 22,416.60162
Overall Steps per Second: 10,558.43650

Timestep Collection Time: 2.23120
Timestep Consumption Time: 2.50586
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.73707

Cumulative Model Updates: 308,620
Cumulative Timesteps: 2,573,861,612

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.46722
Policy Entropy: 2.39742
Value Function Loss: 0.02110

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.08842
Policy Update Magnitude: 0.50761
Value Function Update Magnitude: 0.66154

Collected Steps per Second: 22,755.81037
Overall Steps per Second: 10,687.45350

Timestep Collection Time: 2.19742
Timestep Consumption Time: 2.48134
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.67876

Cumulative Model Updates: 308,626
Cumulative Timesteps: 2,573,911,616

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2573911616...
Checkpoint 2573911616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.84429
Policy Entropy: 2.42506
Value Function Loss: 0.02099

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.09768
Policy Update Magnitude: 0.49661
Value Function Update Magnitude: 0.66585

Collected Steps per Second: 22,469.60880
Overall Steps per Second: 10,763.78324

Timestep Collection Time: 2.22541
Timestep Consumption Time: 2.42017
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.64558

Cumulative Model Updates: 308,632
Cumulative Timesteps: 2,573,961,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.41472
Policy Entropy: 2.40276
Value Function Loss: 0.02081

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.09028
Policy Update Magnitude: 0.49535
Value Function Update Magnitude: 0.65653

Collected Steps per Second: 22,278.97340
Overall Steps per Second: 10,536.60570

Timestep Collection Time: 2.24544
Timestep Consumption Time: 2.50239
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.74783

Cumulative Model Updates: 308,638
Cumulative Timesteps: 2,574,011,646

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2574011646...
Checkpoint 2574011646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.91101
Policy Entropy: 2.38794
Value Function Loss: 0.02057

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.08986
Policy Update Magnitude: 0.50524
Value Function Update Magnitude: 0.65925

Collected Steps per Second: 22,383.83300
Overall Steps per Second: 10,745.51508

Timestep Collection Time: 2.23384
Timestep Consumption Time: 2.41945
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.65329

Cumulative Model Updates: 308,644
Cumulative Timesteps: 2,574,061,648

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.30094
Policy Entropy: 2.38430
Value Function Loss: 0.02000

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.49816
Value Function Update Magnitude: 0.67043

Collected Steps per Second: 22,655.58171
Overall Steps per Second: 10,762.84661

Timestep Collection Time: 2.20758
Timestep Consumption Time: 2.43933
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.64691

Cumulative Model Updates: 308,650
Cumulative Timesteps: 2,574,111,662

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2574111662...
Checkpoint 2574111662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.58163
Policy Entropy: 2.38538
Value Function Loss: 0.02094

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.08307
Policy Update Magnitude: 0.49291
Value Function Update Magnitude: 0.65062

Collected Steps per Second: 22,426.13238
Overall Steps per Second: 10,681.76155

Timestep Collection Time: 2.23061
Timestep Consumption Time: 2.45251
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.68312

Cumulative Model Updates: 308,656
Cumulative Timesteps: 2,574,161,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.24962
Policy Entropy: 2.40220
Value Function Loss: 0.02131

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.49711
Value Function Update Magnitude: 0.63750

Collected Steps per Second: 22,368.42482
Overall Steps per Second: 10,884.86746

Timestep Collection Time: 2.23574
Timestep Consumption Time: 2.35871
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.59445

Cumulative Model Updates: 308,662
Cumulative Timesteps: 2,574,211,696

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2574211696...
Checkpoint 2574211696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.12127
Policy Entropy: 2.39596
Value Function Loss: 0.02110

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.08766
Policy Update Magnitude: 0.49303
Value Function Update Magnitude: 0.63765

Collected Steps per Second: 22,338.97471
Overall Steps per Second: 10,640.87360

Timestep Collection Time: 2.23887
Timestep Consumption Time: 2.46131
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.70018

Cumulative Model Updates: 308,668
Cumulative Timesteps: 2,574,261,710

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.45514
Policy Entropy: 2.42258
Value Function Loss: 0.02062

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.49559
Value Function Update Magnitude: 0.64649

Collected Steps per Second: 22,416.07689
Overall Steps per Second: 10,515.92821

Timestep Collection Time: 2.23072
Timestep Consumption Time: 2.52435
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.75507

Cumulative Model Updates: 308,674
Cumulative Timesteps: 2,574,311,714

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2574311714...
Checkpoint 2574311714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.66113
Policy Entropy: 2.42515
Value Function Loss: 0.02028

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.09698
Policy Update Magnitude: 0.49128
Value Function Update Magnitude: 0.64101

Collected Steps per Second: 22,210.84731
Overall Steps per Second: 10,615.16021

Timestep Collection Time: 2.25115
Timestep Consumption Time: 2.45909
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.71024

Cumulative Model Updates: 308,680
Cumulative Timesteps: 2,574,361,714

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.30951
Policy Entropy: 2.40286
Value Function Loss: 0.02013

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.48970
Value Function Update Magnitude: 0.64967

Collected Steps per Second: 22,360.50176
Overall Steps per Second: 10,884.91433

Timestep Collection Time: 2.23716
Timestep Consumption Time: 2.35856
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.59572

Cumulative Model Updates: 308,686
Cumulative Timesteps: 2,574,411,738

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2574411738...
Checkpoint 2574411738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.97689
Policy Entropy: 2.39297
Value Function Loss: 0.02106

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.10114
Policy Update Magnitude: 0.49087
Value Function Update Magnitude: 0.65145

Collected Steps per Second: 22,398.54279
Overall Steps per Second: 10,668.75756

Timestep Collection Time: 2.23309
Timestep Consumption Time: 2.45518
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.68827

Cumulative Model Updates: 308,692
Cumulative Timesteps: 2,574,461,756

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.83644
Policy Entropy: 2.40442
Value Function Loss: 0.02065

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.09144
Policy Update Magnitude: 0.49604
Value Function Update Magnitude: 0.65581

Collected Steps per Second: 22,564.41470
Overall Steps per Second: 10,639.47290

Timestep Collection Time: 2.21730
Timestep Consumption Time: 2.48519
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.70249

Cumulative Model Updates: 308,698
Cumulative Timesteps: 2,574,511,788

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2574511788...
Checkpoint 2574511788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.85143
Policy Entropy: 2.43763
Value Function Loss: 0.02078

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.09029
Policy Update Magnitude: 0.48971
Value Function Update Magnitude: 0.65657

Collected Steps per Second: 22,253.03134
Overall Steps per Second: 10,643.39406

Timestep Collection Time: 2.24796
Timestep Consumption Time: 2.45204
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.70000

Cumulative Model Updates: 308,704
Cumulative Timesteps: 2,574,561,812

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.71694
Policy Entropy: 2.44979
Value Function Loss: 0.02010

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.08304
Policy Update Magnitude: 0.48868
Value Function Update Magnitude: 0.66108

Collected Steps per Second: 22,501.44313
Overall Steps per Second: 10,737.37368

Timestep Collection Time: 2.22208
Timestep Consumption Time: 2.43455
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.65663

Cumulative Model Updates: 308,710
Cumulative Timesteps: 2,574,611,812

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2574611812...
Checkpoint 2574611812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.76618
Policy Entropy: 2.42804
Value Function Loss: 0.02058

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.08590
Policy Update Magnitude: 0.49352
Value Function Update Magnitude: 0.66559

Collected Steps per Second: 22,324.59136
Overall Steps per Second: 10,607.29274

Timestep Collection Time: 2.24076
Timestep Consumption Time: 2.47524
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.71600

Cumulative Model Updates: 308,716
Cumulative Timesteps: 2,574,661,836

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.19487
Policy Entropy: 2.40749
Value Function Loss: 0.02095

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.09323
Policy Update Magnitude: 0.49405
Value Function Update Magnitude: 0.68021

Collected Steps per Second: 22,604.72430
Overall Steps per Second: 10,600.42548

Timestep Collection Time: 2.21193
Timestep Consumption Time: 2.50486
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.71679

Cumulative Model Updates: 308,722
Cumulative Timesteps: 2,574,711,836

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2574711836...
Checkpoint 2574711836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.75059
Policy Entropy: 2.38896
Value Function Loss: 0.02080

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.08376
Policy Update Magnitude: 0.49054
Value Function Update Magnitude: 0.67536

Collected Steps per Second: 21,793.63280
Overall Steps per Second: 10,496.16597

Timestep Collection Time: 2.29507
Timestep Consumption Time: 2.47029
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.76536

Cumulative Model Updates: 308,728
Cumulative Timesteps: 2,574,761,854

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.46959
Policy Entropy: 2.38240
Value Function Loss: 0.02010

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.49572
Value Function Update Magnitude: 0.67272

Collected Steps per Second: 22,440.42920
Overall Steps per Second: 10,888.45894

Timestep Collection Time: 2.22928
Timestep Consumption Time: 2.36513
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.59441

Cumulative Model Updates: 308,734
Cumulative Timesteps: 2,574,811,880

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2574811880...
Checkpoint 2574811880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.30077
Policy Entropy: 2.37829
Value Function Loss: 0.02098

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.09038
Policy Update Magnitude: 0.50002
Value Function Update Magnitude: 0.67893

Collected Steps per Second: 22,278.28887
Overall Steps per Second: 10,715.17529

Timestep Collection Time: 2.24515
Timestep Consumption Time: 2.42281
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.66796

Cumulative Model Updates: 308,740
Cumulative Timesteps: 2,574,861,898

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.17434
Policy Entropy: 2.39955
Value Function Loss: 0.02175

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 0.50232
Value Function Update Magnitude: 0.70644

Collected Steps per Second: 22,593.38813
Overall Steps per Second: 10,771.96985

Timestep Collection Time: 2.21375
Timestep Consumption Time: 2.42942
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.64316

Cumulative Model Updates: 308,746
Cumulative Timesteps: 2,574,911,914

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2574911914...
Checkpoint 2574911914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.88296
Policy Entropy: 2.42453
Value Function Loss: 0.02250

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.09931
Policy Update Magnitude: 0.50565
Value Function Update Magnitude: 0.73267

Collected Steps per Second: 22,367.55827
Overall Steps per Second: 10,780.53413

Timestep Collection Time: 2.23574
Timestep Consumption Time: 2.40299
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.63873

Cumulative Model Updates: 308,752
Cumulative Timesteps: 2,574,961,922

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.19105
Policy Entropy: 2.43453
Value Function Loss: 0.02171

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.11682
Policy Update Magnitude: 0.47439
Value Function Update Magnitude: 0.71314

Collected Steps per Second: 22,686.22254
Overall Steps per Second: 10,853.79075

Timestep Collection Time: 2.20495
Timestep Consumption Time: 2.40376
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.60871

Cumulative Model Updates: 308,758
Cumulative Timesteps: 2,575,011,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2575011944...
Checkpoint 2575011944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.09061
Policy Entropy: 2.42170
Value Function Loss: 0.02189

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.12883
Policy Update Magnitude: 0.46708
Value Function Update Magnitude: 0.67923

Collected Steps per Second: 22,465.56246
Overall Steps per Second: 10,607.44585

Timestep Collection Time: 2.22607
Timestep Consumption Time: 2.48854
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.71461

Cumulative Model Updates: 308,764
Cumulative Timesteps: 2,575,061,954

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.72639
Policy Entropy: 2.40447
Value Function Loss: 0.02234

Mean KL Divergence: 0.02346
SB3 Clip Fraction: 0.13600
Policy Update Magnitude: 0.47941
Value Function Update Magnitude: 0.66475

Collected Steps per Second: 22,315.93758
Overall Steps per Second: 10,534.88758

Timestep Collection Time: 2.24109
Timestep Consumption Time: 2.50619
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.74727

Cumulative Model Updates: 308,770
Cumulative Timesteps: 2,575,111,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2575111966...
Checkpoint 2575111966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.54422
Policy Entropy: 2.43386
Value Function Loss: 0.02258

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.12169
Policy Update Magnitude: 0.48936
Value Function Update Magnitude: 0.69602

Collected Steps per Second: 22,269.09844
Overall Steps per Second: 10,584.94697

Timestep Collection Time: 2.24634
Timestep Consumption Time: 2.47962
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.72596

Cumulative Model Updates: 308,776
Cumulative Timesteps: 2,575,161,990

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.88395
Policy Entropy: 2.42475
Value Function Loss: 0.02104

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.10325
Policy Update Magnitude: 0.49326
Value Function Update Magnitude: 0.71286

Collected Steps per Second: 22,284.79432
Overall Steps per Second: 10,874.84579

Timestep Collection Time: 2.24413
Timestep Consumption Time: 2.35455
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.59869

Cumulative Model Updates: 308,782
Cumulative Timesteps: 2,575,212,000

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2575212000...
Checkpoint 2575212000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.43290
Policy Entropy: 2.42666
Value Function Loss: 0.02012

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.48901
Value Function Update Magnitude: 0.67131

Collected Steps per Second: 22,024.78436
Overall Steps per Second: 10,644.43174

Timestep Collection Time: 2.27035
Timestep Consumption Time: 2.42732
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.69767

Cumulative Model Updates: 308,788
Cumulative Timesteps: 2,575,262,004

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.64448
Policy Entropy: 2.41011
Value Function Loss: 0.02047

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.09374
Policy Update Magnitude: 0.49015
Value Function Update Magnitude: 0.64855

Collected Steps per Second: 22,471.15281
Overall Steps per Second: 10,697.74015

Timestep Collection Time: 2.22552
Timestep Consumption Time: 2.44930
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.67482

Cumulative Model Updates: 308,794
Cumulative Timesteps: 2,575,312,014

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2575312014...
Checkpoint 2575312014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.70145
Policy Entropy: 2.40129
Value Function Loss: 0.02141

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.11196
Policy Update Magnitude: 0.46916
Value Function Update Magnitude: 0.66197

Collected Steps per Second: 22,534.56697
Overall Steps per Second: 10,884.97076

Timestep Collection Time: 2.21926
Timestep Consumption Time: 2.37515
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.59441

Cumulative Model Updates: 308,800
Cumulative Timesteps: 2,575,362,024

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.10907
Policy Entropy: 2.42079
Value Function Loss: 0.02138

Mean KL Divergence: 0.02282
SB3 Clip Fraction: 0.12899
Policy Update Magnitude: 0.44763
Value Function Update Magnitude: 0.68219

Collected Steps per Second: 22,517.67809
Overall Steps per Second: 10,590.82198

Timestep Collection Time: 2.22137
Timestep Consumption Time: 2.50159
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.72296

Cumulative Model Updates: 308,806
Cumulative Timesteps: 2,575,412,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2575412044...
Checkpoint 2575412044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.23658
Policy Entropy: 2.41499
Value Function Loss: 0.02108

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.11993
Policy Update Magnitude: 0.47379
Value Function Update Magnitude: 0.68977

Collected Steps per Second: 22,432.98824
Overall Steps per Second: 10,536.48057

Timestep Collection Time: 2.23011
Timestep Consumption Time: 2.51797
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.74807

Cumulative Model Updates: 308,812
Cumulative Timesteps: 2,575,462,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.17784
Policy Entropy: 2.42385
Value Function Loss: 0.02074

Mean KL Divergence: 0.02077
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.50162
Value Function Update Magnitude: 0.66333

Collected Steps per Second: 22,496.61622
Overall Steps per Second: 10,935.71881

Timestep Collection Time: 2.22362
Timestep Consumption Time: 2.35074
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.57437

Cumulative Model Updates: 308,818
Cumulative Timesteps: 2,575,512,096

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2575512096...
Checkpoint 2575512096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.03919
Policy Entropy: 2.41120
Value Function Loss: 0.02109

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.11961
Policy Update Magnitude: 0.50455
Value Function Update Magnitude: 0.66159

Collected Steps per Second: 22,643.80270
Overall Steps per Second: 10,619.54898

Timestep Collection Time: 2.20926
Timestep Consumption Time: 2.50149
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.71075

Cumulative Model Updates: 308,824
Cumulative Timesteps: 2,575,562,122

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.09538
Policy Entropy: 2.41654
Value Function Loss: 0.02103

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.11699
Policy Update Magnitude: 0.48025
Value Function Update Magnitude: 0.65802

Collected Steps per Second: 22,497.56017
Overall Steps per Second: 10,622.99809

Timestep Collection Time: 2.22362
Timestep Consumption Time: 2.48560
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.70922

Cumulative Model Updates: 308,830
Cumulative Timesteps: 2,575,612,148

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2575612148...
Checkpoint 2575612148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.22380
Policy Entropy: 2.42150
Value Function Loss: 0.02008

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.12537
Policy Update Magnitude: 0.45402
Value Function Update Magnitude: 0.64810

Collected Steps per Second: 22,471.46490
Overall Steps per Second: 10,802.99514

Timestep Collection Time: 2.22593
Timestep Consumption Time: 2.40426
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.63020

Cumulative Model Updates: 308,836
Cumulative Timesteps: 2,575,662,168

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.25831
Policy Entropy: 2.42747
Value Function Loss: 0.02002

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.11044
Policy Update Magnitude: 0.47855
Value Function Update Magnitude: 0.65190

Collected Steps per Second: 22,133.17036
Overall Steps per Second: 10,560.80024

Timestep Collection Time: 2.25996
Timestep Consumption Time: 2.47643
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.73638

Cumulative Model Updates: 308,842
Cumulative Timesteps: 2,575,712,188

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2575712188...
Checkpoint 2575712188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.13377
Policy Entropy: 2.41444
Value Function Loss: 0.01968

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.11574
Policy Update Magnitude: 0.49857
Value Function Update Magnitude: 0.64853

Collected Steps per Second: 23,172.27639
Overall Steps per Second: 10,771.28002

Timestep Collection Time: 2.15870
Timestep Consumption Time: 2.48532
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.64402

Cumulative Model Updates: 308,848
Cumulative Timesteps: 2,575,762,210

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.46835
Policy Entropy: 2.42035
Value Function Loss: 0.02011

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.10292
Policy Update Magnitude: 0.50801
Value Function Update Magnitude: 0.64452

Collected Steps per Second: 22,136.63165
Overall Steps per Second: 10,655.08440

Timestep Collection Time: 2.25879
Timestep Consumption Time: 2.43399
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.69278

Cumulative Model Updates: 308,854
Cumulative Timesteps: 2,575,812,212

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2575812212...
Checkpoint 2575812212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.10991
Policy Entropy: 2.40100
Value Function Loss: 0.02211

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.10734
Policy Update Magnitude: 0.51279
Value Function Update Magnitude: 0.65422

Collected Steps per Second: 22,331.95523
Overall Steps per Second: 10,664.92067

Timestep Collection Time: 2.23921
Timestep Consumption Time: 2.44962
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.68883

Cumulative Model Updates: 308,860
Cumulative Timesteps: 2,575,862,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.97872
Policy Entropy: 2.41130
Value Function Loss: 0.02275

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.10103
Policy Update Magnitude: 0.52799
Value Function Update Magnitude: 0.68422

Collected Steps per Second: 22,297.89656
Overall Steps per Second: 10,540.26307

Timestep Collection Time: 2.24362
Timestep Consumption Time: 2.50275
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.74637

Cumulative Model Updates: 308,866
Cumulative Timesteps: 2,575,912,246

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2575912246...
Checkpoint 2575912246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.25416
Policy Entropy: 2.41130
Value Function Loss: 0.02318

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.10442
Policy Update Magnitude: 0.51561
Value Function Update Magnitude: 0.70417

Collected Steps per Second: 22,902.85413
Overall Steps per Second: 10,652.74362

Timestep Collection Time: 2.18444
Timestep Consumption Time: 2.51200
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.69644

Cumulative Model Updates: 308,872
Cumulative Timesteps: 2,575,962,276

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.21501
Policy Entropy: 2.41779
Value Function Loss: 0.02175

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.10370
Policy Update Magnitude: 0.51679
Value Function Update Magnitude: 0.68877

Collected Steps per Second: 22,470.44241
Overall Steps per Second: 10,578.23691

Timestep Collection Time: 2.22621
Timestep Consumption Time: 2.50274
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.72895

Cumulative Model Updates: 308,878
Cumulative Timesteps: 2,576,012,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2576012300...
Checkpoint 2576012300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.34944
Policy Entropy: 2.41679
Value Function Loss: 0.02172

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.11279
Policy Update Magnitude: 0.51608
Value Function Update Magnitude: 0.68474

Collected Steps per Second: 22,342.47616
Overall Steps per Second: 10,525.01228

Timestep Collection Time: 2.23834
Timestep Consumption Time: 2.51320
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.75154

Cumulative Model Updates: 308,884
Cumulative Timesteps: 2,576,062,310

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.65346
Policy Entropy: 2.41641
Value Function Loss: 0.02196

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.52276
Value Function Update Magnitude: 0.70533

Collected Steps per Second: 22,438.94623
Overall Steps per Second: 10,923.03080

Timestep Collection Time: 2.23050
Timestep Consumption Time: 2.35156
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.58206

Cumulative Model Updates: 308,890
Cumulative Timesteps: 2,576,112,360

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2576112360...
Checkpoint 2576112360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.94378
Policy Entropy: 2.41191
Value Function Loss: 0.02149

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.10000
Policy Update Magnitude: 0.51680
Value Function Update Magnitude: 0.69714

Collected Steps per Second: 22,262.53728
Overall Steps per Second: 10,636.55040

Timestep Collection Time: 2.24691
Timestep Consumption Time: 2.45593
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.70284

Cumulative Model Updates: 308,896
Cumulative Timesteps: 2,576,162,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.97134
Policy Entropy: 2.40750
Value Function Loss: 0.02051

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.09607
Policy Update Magnitude: 0.51885
Value Function Update Magnitude: 0.67929

Collected Steps per Second: 22,318.10298
Overall Steps per Second: 10,513.29417

Timestep Collection Time: 2.24114
Timestep Consumption Time: 2.51646
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.75760

Cumulative Model Updates: 308,902
Cumulative Timesteps: 2,576,212,400

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2576212400...
Checkpoint 2576212400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.62031
Policy Entropy: 2.42850
Value Function Loss: 0.01906

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.09060
Policy Update Magnitude: 0.50691
Value Function Update Magnitude: 0.66987

Collected Steps per Second: 22,186.00034
Overall Steps per Second: 10,546.31413

Timestep Collection Time: 2.25376
Timestep Consumption Time: 2.48742
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.74118

Cumulative Model Updates: 308,908
Cumulative Timesteps: 2,576,262,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.12971
Policy Entropy: 2.44012
Value Function Loss: 0.01931

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.08607
Policy Update Magnitude: 0.49842
Value Function Update Magnitude: 0.67109

Collected Steps per Second: 22,349.65294
Overall Steps per Second: 10,873.01630

Timestep Collection Time: 2.23789
Timestep Consumption Time: 2.36212
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.60001

Cumulative Model Updates: 308,914
Cumulative Timesteps: 2,576,312,418

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2576312418...
Checkpoint 2576312418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.09335
Policy Entropy: 2.43361
Value Function Loss: 0.01947

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.49414
Value Function Update Magnitude: 0.68369

Collected Steps per Second: 22,311.96268
Overall Steps per Second: 10,751.46769

Timestep Collection Time: 2.24113
Timestep Consumption Time: 2.40977
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.65090

Cumulative Model Updates: 308,920
Cumulative Timesteps: 2,576,362,422

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.58464
Policy Entropy: 2.41588
Value Function Loss: 0.02070

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.08849
Policy Update Magnitude: 0.51053
Value Function Update Magnitude: 0.69957

Collected Steps per Second: 22,444.99663
Overall Steps per Second: 10,743.60944

Timestep Collection Time: 2.22811
Timestep Consumption Time: 2.42675
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.65486

Cumulative Model Updates: 308,926
Cumulative Timesteps: 2,576,412,432

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2576412432...
Checkpoint 2576412432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.18783
Policy Entropy: 2.41227
Value Function Loss: 0.01897

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.08568
Policy Update Magnitude: 0.50177
Value Function Update Magnitude: 0.70289

Collected Steps per Second: 22,441.01965
Overall Steps per Second: 10,717.73768

Timestep Collection Time: 2.22904
Timestep Consumption Time: 2.43817
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 4.66722

Cumulative Model Updates: 308,932
Cumulative Timesteps: 2,576,462,454

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.85342
Policy Entropy: 2.41348
Value Function Loss: 0.01928

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.09132
Policy Update Magnitude: 0.48401
Value Function Update Magnitude: 0.68288

Collected Steps per Second: 22,547.81473
Overall Steps per Second: 10,957.02483

Timestep Collection Time: 2.21884
Timestep Consumption Time: 2.34718
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.56602

Cumulative Model Updates: 308,938
Cumulative Timesteps: 2,576,512,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2576512484...
Checkpoint 2576512484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.62348
Policy Entropy: 2.41741
Value Function Loss: 0.02000

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.08874
Policy Update Magnitude: 0.48674
Value Function Update Magnitude: 0.65832

Collected Steps per Second: 22,607.50909
Overall Steps per Second: 10,619.81377

Timestep Collection Time: 2.21201
Timestep Consumption Time: 2.49693
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.70893

Cumulative Model Updates: 308,944
Cumulative Timesteps: 2,576,562,492

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.39593
Policy Entropy: 2.40306
Value Function Loss: 0.02119

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.08808
Policy Update Magnitude: 0.49781
Value Function Update Magnitude: 0.66148

Collected Steps per Second: 22,122.55257
Overall Steps per Second: 10,467.98593

Timestep Collection Time: 2.26149
Timestep Consumption Time: 2.51784
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.77933

Cumulative Model Updates: 308,950
Cumulative Timesteps: 2,576,612,522

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2576612522...
Checkpoint 2576612522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.41403
Policy Entropy: 2.43352
Value Function Loss: 0.02109

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.08685
Policy Update Magnitude: 0.49588
Value Function Update Magnitude: 0.66663

Collected Steps per Second: 22,214.76114
Overall Steps per Second: 10,632.18359

Timestep Collection Time: 2.25139
Timestep Consumption Time: 2.45263
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.70402

Cumulative Model Updates: 308,956
Cumulative Timesteps: 2,576,662,536

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.57741
Policy Entropy: 2.42998
Value Function Loss: 0.02167

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.50232
Value Function Update Magnitude: 0.66544

Collected Steps per Second: 22,426.56309
Overall Steps per Second: 10,598.66483

Timestep Collection Time: 2.23084
Timestep Consumption Time: 2.48957
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.72041

Cumulative Model Updates: 308,962
Cumulative Timesteps: 2,576,712,566

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2576712566...
Checkpoint 2576712566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.10107
Policy Entropy: 2.43751
Value Function Loss: 0.02070

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.50874
Value Function Update Magnitude: 0.66776

Collected Steps per Second: 22,307.28719
Overall Steps per Second: 10,565.83233

Timestep Collection Time: 2.24187
Timestep Consumption Time: 2.49131
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.73318

Cumulative Model Updates: 308,968
Cumulative Timesteps: 2,576,762,576

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.97104
Policy Entropy: 2.40786
Value Function Loss: 0.01991

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.08706
Policy Update Magnitude: 0.50053
Value Function Update Magnitude: 0.67472

Collected Steps per Second: 22,442.02716
Overall Steps per Second: 10,751.75535

Timestep Collection Time: 2.22832
Timestep Consumption Time: 2.42283
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.65115

Cumulative Model Updates: 308,974
Cumulative Timesteps: 2,576,812,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2576812584...
Checkpoint 2576812584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.28237
Policy Entropy: 2.39817
Value Function Loss: 0.02074

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.09206
Policy Update Magnitude: 0.49592
Value Function Update Magnitude: 0.67628

Collected Steps per Second: 22,388.32834
Overall Steps per Second: 10,707.74870

Timestep Collection Time: 2.23349
Timestep Consumption Time: 2.43640
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.66989

Cumulative Model Updates: 308,980
Cumulative Timesteps: 2,576,862,588

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.66247
Policy Entropy: 2.38349
Value Function Loss: 0.02186

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.50057
Value Function Update Magnitude: 0.68955

Collected Steps per Second: 22,447.98203
Overall Steps per Second: 10,592.80944

Timestep Collection Time: 2.22746
Timestep Consumption Time: 2.49291
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.72037

Cumulative Model Updates: 308,986
Cumulative Timesteps: 2,576,912,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2576912590...
Checkpoint 2576912590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.56521
Policy Entropy: 2.39030
Value Function Loss: 0.02298

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.09198
Policy Update Magnitude: 0.50719
Value Function Update Magnitude: 0.70694

Collected Steps per Second: 22,408.72060
Overall Steps per Second: 10,562.70458

Timestep Collection Time: 2.23181
Timestep Consumption Time: 2.50296
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.73477

Cumulative Model Updates: 308,992
Cumulative Timesteps: 2,576,962,602

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.64506
Policy Entropy: 2.40235
Value Function Loss: 0.02154

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.10615
Policy Update Magnitude: 0.49442
Value Function Update Magnitude: 0.70151

Collected Steps per Second: 22,222.23901
Overall Steps per Second: 10,587.02134

Timestep Collection Time: 2.25090
Timestep Consumption Time: 2.47375
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.72465

Cumulative Model Updates: 308,998
Cumulative Timesteps: 2,577,012,622

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2577012622...
Checkpoint 2577012622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.34856
Policy Entropy: 2.40633
Value Function Loss: 0.02134

Mean KL Divergence: 0.02184
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.47910
Value Function Update Magnitude: 0.68629

Collected Steps per Second: 23,498.56685
Overall Steps per Second: 10,977.67559

Timestep Collection Time: 2.12898
Timestep Consumption Time: 2.42827
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.55725

Cumulative Model Updates: 309,004
Cumulative Timesteps: 2,577,062,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.37867
Policy Entropy: 2.40783
Value Function Loss: 0.02178

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.12046
Policy Update Magnitude: 0.48995
Value Function Update Magnitude: 0.67531

Collected Steps per Second: 22,617.99186
Overall Steps per Second: 10,771.12777

Timestep Collection Time: 2.21134
Timestep Consumption Time: 2.43219
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.64352

Cumulative Model Updates: 309,010
Cumulative Timesteps: 2,577,112,666

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2577112666...
Checkpoint 2577112666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.67048
Policy Entropy: 2.39898
Value Function Loss: 0.02252

Mean KL Divergence: 0.02269
SB3 Clip Fraction: 0.12405
Policy Update Magnitude: 0.50047
Value Function Update Magnitude: 0.68005

Collected Steps per Second: 22,274.97901
Overall Steps per Second: 10,693.16763

Timestep Collection Time: 2.24485
Timestep Consumption Time: 2.43141
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.67626

Cumulative Model Updates: 309,016
Cumulative Timesteps: 2,577,162,670

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.94496
Policy Entropy: 2.40277
Value Function Loss: 0.02075

Mean KL Divergence: 0.02494
SB3 Clip Fraction: 0.11662
Policy Update Magnitude: 0.50645
Value Function Update Magnitude: 0.67508

Collected Steps per Second: 22,359.04664
Overall Steps per Second: 10,895.68937

Timestep Collection Time: 2.23659
Timestep Consumption Time: 2.35312
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.58970

Cumulative Model Updates: 309,022
Cumulative Timesteps: 2,577,212,678

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2577212678...
Checkpoint 2577212678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.14327
Policy Entropy: 2.39842
Value Function Loss: 0.02035

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.11313
Policy Update Magnitude: 0.50553
Value Function Update Magnitude: 0.67030

Collected Steps per Second: 22,292.30383
Overall Steps per Second: 10,708.67498

Timestep Collection Time: 2.24427
Timestep Consumption Time: 2.42764
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.67191

Cumulative Model Updates: 309,028
Cumulative Timesteps: 2,577,262,708

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.75777
Policy Entropy: 2.40280
Value Function Loss: 0.01972

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.10468
Policy Update Magnitude: 0.50296
Value Function Update Magnitude: 0.65316

Collected Steps per Second: 22,550.12081
Overall Steps per Second: 10,616.65045

Timestep Collection Time: 2.21852
Timestep Consumption Time: 2.49370
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.71222

Cumulative Model Updates: 309,034
Cumulative Timesteps: 2,577,312,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2577312736...
Checkpoint 2577312736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.31712
Policy Entropy: 2.38183
Value Function Loss: 0.02087

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.09760
Policy Update Magnitude: 0.50302
Value Function Update Magnitude: 0.64013

Collected Steps per Second: 22,457.11167
Overall Steps per Second: 10,628.31996

Timestep Collection Time: 2.22753
Timestep Consumption Time: 2.47914
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.70667

Cumulative Model Updates: 309,040
Cumulative Timesteps: 2,577,362,760

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.01094
Policy Entropy: 2.37094
Value Function Loss: 0.02094

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.09229
Policy Update Magnitude: 0.50547
Value Function Update Magnitude: 0.63753

Collected Steps per Second: 22,574.22648
Overall Steps per Second: 10,771.17499

Timestep Collection Time: 2.21536
Timestep Consumption Time: 2.42759
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.64295

Cumulative Model Updates: 309,046
Cumulative Timesteps: 2,577,412,770

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2577412770...
Checkpoint 2577412770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.00368
Policy Entropy: 2.35802
Value Function Loss: 0.02030

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.10621
Policy Update Magnitude: 0.48668
Value Function Update Magnitude: 0.64931

Collected Steps per Second: 22,286.64171
Overall Steps per Second: 10,565.91051

Timestep Collection Time: 2.24377
Timestep Consumption Time: 2.48900
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.73277

Cumulative Model Updates: 309,052
Cumulative Timesteps: 2,577,462,776

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.12365
Policy Entropy: 2.37466
Value Function Loss: 0.02055

Mean KL Divergence: 0.02336
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.48299
Value Function Update Magnitude: 0.65503

Collected Steps per Second: 22,645.03132
Overall Steps per Second: 10,645.42413

Timestep Collection Time: 2.20808
Timestep Consumption Time: 2.48896
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.69704

Cumulative Model Updates: 309,058
Cumulative Timesteps: 2,577,512,778

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2577512778...
Checkpoint 2577512778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.98071
Policy Entropy: 2.38299
Value Function Loss: 0.02039

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.12626
Policy Update Magnitude: 0.47351
Value Function Update Magnitude: 0.66734

Collected Steps per Second: 22,432.80163
Overall Steps per Second: 10,664.75517

Timestep Collection Time: 2.22924
Timestep Consumption Time: 2.45985
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.68909

Cumulative Model Updates: 309,064
Cumulative Timesteps: 2,577,562,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.93864
Policy Entropy: 2.39948
Value Function Loss: 0.02105

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.11850
Policy Update Magnitude: 0.50317
Value Function Update Magnitude: 0.67870

Collected Steps per Second: 22,497.52695
Overall Steps per Second: 10,691.06207

Timestep Collection Time: 2.22256
Timestep Consumption Time: 2.45444
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.67699

Cumulative Model Updates: 309,070
Cumulative Timesteps: 2,577,612,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2577612788...
Checkpoint 2577612788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.88097
Policy Entropy: 2.38962
Value Function Loss: 0.02082

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.11656
Policy Update Magnitude: 0.50614
Value Function Update Magnitude: 0.68419

Collected Steps per Second: 23,044.09181
Overall Steps per Second: 10,735.86601

Timestep Collection Time: 2.17019
Timestep Consumption Time: 2.48803
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.65822

Cumulative Model Updates: 309,076
Cumulative Timesteps: 2,577,662,798

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.68198
Policy Entropy: 2.39923
Value Function Loss: 0.02056

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.10896
Policy Update Magnitude: 0.50291
Value Function Update Magnitude: 0.66287

Collected Steps per Second: 22,498.98748
Overall Steps per Second: 10,741.51094

Timestep Collection Time: 2.22268
Timestep Consumption Time: 2.43291
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.65558

Cumulative Model Updates: 309,082
Cumulative Timesteps: 2,577,712,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2577712806...
Checkpoint 2577712806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.13086
Policy Entropy: 2.38918
Value Function Loss: 0.01973

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.49909
Value Function Update Magnitude: 0.65155

Collected Steps per Second: 22,048.57865
Overall Steps per Second: 10,707.79084

Timestep Collection Time: 2.26799
Timestep Consumption Time: 2.40207
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.67006

Cumulative Model Updates: 309,088
Cumulative Timesteps: 2,577,762,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.72008
Policy Entropy: 2.39124
Value Function Loss: 0.02049

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.09208
Policy Update Magnitude: 0.49235
Value Function Update Magnitude: 0.64922

Collected Steps per Second: 22,055.21051
Overall Steps per Second: 10,706.90740

Timestep Collection Time: 2.26794
Timestep Consumption Time: 2.40381
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.67175

Cumulative Model Updates: 309,094
Cumulative Timesteps: 2,577,812,832

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2577812832...
Checkpoint 2577812832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.41816
Policy Entropy: 2.38240
Value Function Loss: 0.02058

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.09327
Policy Update Magnitude: 0.49193
Value Function Update Magnitude: 0.63811

Collected Steps per Second: 22,414.88903
Overall Steps per Second: 10,616.07671

Timestep Collection Time: 2.23146
Timestep Consumption Time: 2.48007
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.71153

Cumulative Model Updates: 309,100
Cumulative Timesteps: 2,577,862,850

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.40883
Policy Entropy: 2.38625
Value Function Loss: 0.02026

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.09545
Policy Update Magnitude: 0.49763
Value Function Update Magnitude: 0.64388

Collected Steps per Second: 22,723.53885
Overall Steps per Second: 10,687.70307

Timestep Collection Time: 2.20098
Timestep Consumption Time: 2.47861
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.67958

Cumulative Model Updates: 309,106
Cumulative Timesteps: 2,577,912,864

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2577912864...
Checkpoint 2577912864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.00297
Policy Entropy: 2.40245
Value Function Loss: 0.01902

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.09083
Policy Update Magnitude: 0.48914
Value Function Update Magnitude: 0.66174

Collected Steps per Second: 21,954.52888
Overall Steps per Second: 10,607.25900

Timestep Collection Time: 2.27853
Timestep Consumption Time: 2.43749
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.71602

Cumulative Model Updates: 309,112
Cumulative Timesteps: 2,577,962,888

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.59604
Policy Entropy: 2.38057
Value Function Loss: 0.01928

Mean KL Divergence: 0.02307
SB3 Clip Fraction: 0.09828
Policy Update Magnitude: 0.48283
Value Function Update Magnitude: 0.66664

Collected Steps per Second: 22,494.41823
Overall Steps per Second: 10,645.01421

Timestep Collection Time: 2.22322
Timestep Consumption Time: 2.47476
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.69797

Cumulative Model Updates: 309,118
Cumulative Timesteps: 2,578,012,898

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2578012898...
Checkpoint 2578012898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.63942
Policy Entropy: 2.38558
Value Function Loss: 0.02058

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.09854
Policy Update Magnitude: 0.49771
Value Function Update Magnitude: 0.67647

Collected Steps per Second: 23,386.75302
Overall Steps per Second: 10,965.69462

Timestep Collection Time: 2.13907
Timestep Consumption Time: 2.42297
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.56205

Cumulative Model Updates: 309,124
Cumulative Timesteps: 2,578,062,924

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.72847
Policy Entropy: 2.37241
Value Function Loss: 0.02028

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.49336
Value Function Update Magnitude: 0.66585

Collected Steps per Second: 22,518.80509
Overall Steps per Second: 10,598.85546

Timestep Collection Time: 2.22170
Timestep Consumption Time: 2.49862
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.72032

Cumulative Model Updates: 309,130
Cumulative Timesteps: 2,578,112,954

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2578112954...
Checkpoint 2578112954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.80779
Policy Entropy: 2.39951
Value Function Loss: 0.02073

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.09687
Policy Update Magnitude: 0.48689
Value Function Update Magnitude: 0.64699

Collected Steps per Second: 22,416.71210
Overall Steps per Second: 10,555.55570

Timestep Collection Time: 2.23164
Timestep Consumption Time: 2.50767
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.73931

Cumulative Model Updates: 309,136
Cumulative Timesteps: 2,578,162,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.68193
Policy Entropy: 2.40047
Value Function Loss: 0.02083

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.09631
Policy Update Magnitude: 0.48792
Value Function Update Magnitude: 0.65380

Collected Steps per Second: 22,437.32233
Overall Steps per Second: 10,767.05076

Timestep Collection Time: 2.22914
Timestep Consumption Time: 2.41614
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.64528

Cumulative Model Updates: 309,142
Cumulative Timesteps: 2,578,212,996

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2578212996...
Checkpoint 2578212996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.88087
Policy Entropy: 2.38306
Value Function Loss: 0.02086

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.09966
Policy Update Magnitude: 0.47846
Value Function Update Magnitude: 0.66359

Collected Steps per Second: 22,940.96974
Overall Steps per Second: 10,714.27592

Timestep Collection Time: 2.17959
Timestep Consumption Time: 2.48726
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.66686

Cumulative Model Updates: 309,148
Cumulative Timesteps: 2,578,262,998

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.69797
Policy Entropy: 2.35930
Value Function Loss: 0.02180

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.09659
Policy Update Magnitude: 0.49550
Value Function Update Magnitude: 0.65126

Collected Steps per Second: 22,230.35759
Overall Steps per Second: 10,521.47624

Timestep Collection Time: 2.25026
Timestep Consumption Time: 2.50421
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.75447

Cumulative Model Updates: 309,154
Cumulative Timesteps: 2,578,313,022

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2578313022...
Checkpoint 2578313022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.50684
Policy Entropy: 2.35278
Value Function Loss: 0.02171

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.10098
Policy Update Magnitude: 0.49814
Value Function Update Magnitude: 0.65703

Collected Steps per Second: 22,088.44509
Overall Steps per Second: 10,592.26151

Timestep Collection Time: 2.26489
Timestep Consumption Time: 2.45818
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.72307

Cumulative Model Updates: 309,160
Cumulative Timesteps: 2,578,363,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.92379
Policy Entropy: 2.36142
Value Function Loss: 0.02139

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.09554
Policy Update Magnitude: 0.50458
Value Function Update Magnitude: 0.66144

Collected Steps per Second: 22,404.75359
Overall Steps per Second: 10,645.51341

Timestep Collection Time: 2.23212
Timestep Consumption Time: 2.46564
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.69775

Cumulative Model Updates: 309,166
Cumulative Timesteps: 2,578,413,060

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2578413060...
Checkpoint 2578413060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.51765
Policy Entropy: 2.34919
Value Function Loss: 0.02098

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.09386
Policy Update Magnitude: 0.51478
Value Function Update Magnitude: 0.66772

Collected Steps per Second: 23,099.45577
Overall Steps per Second: 10,875.84163

Timestep Collection Time: 2.16533
Timestep Consumption Time: 2.43367
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.59900

Cumulative Model Updates: 309,172
Cumulative Timesteps: 2,578,463,078

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.92144
Policy Entropy: 2.34648
Value Function Loss: 0.02102

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.10866
Policy Update Magnitude: 0.50050
Value Function Update Magnitude: 0.67868

Collected Steps per Second: 22,233.11953
Overall Steps per Second: 10,516.65541

Timestep Collection Time: 2.24908
Timestep Consumption Time: 2.50567
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.75474

Cumulative Model Updates: 309,178
Cumulative Timesteps: 2,578,513,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2578513082...
Checkpoint 2578513082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.61984
Policy Entropy: 2.35196
Value Function Loss: 0.02150

Mean KL Divergence: 0.02448
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.47944
Value Function Update Magnitude: 0.69043

Collected Steps per Second: 22,136.36644
Overall Steps per Second: 10,606.49147

Timestep Collection Time: 2.25999
Timestep Consumption Time: 2.45674
PPO Batch Consumption Time: 0.28438
Total Iteration Time: 4.71673

Cumulative Model Updates: 309,184
Cumulative Timesteps: 2,578,563,110

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.92845
Policy Entropy: 2.38269
Value Function Loss: 0.02212

Mean KL Divergence: 0.02484
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.48303
Value Function Update Magnitude: 0.70429

Collected Steps per Second: 22,394.84072
Overall Steps per Second: 10,640.94351

Timestep Collection Time: 2.23275
Timestep Consumption Time: 2.46627
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.69902

Cumulative Model Updates: 309,190
Cumulative Timesteps: 2,578,613,112

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2578613112...
Checkpoint 2578613112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.93057
Policy Entropy: 2.38601
Value Function Loss: 0.02235

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.11971
Policy Update Magnitude: 0.49654
Value Function Update Magnitude: 0.70255

Collected Steps per Second: 23,175.57453
Overall Steps per Second: 10,331.48073

Timestep Collection Time: 2.15813
Timestep Consumption Time: 2.68299
PPO Batch Consumption Time: 0.32166
Total Iteration Time: 4.84113

Cumulative Model Updates: 309,196
Cumulative Timesteps: 2,578,663,128

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.84443
Policy Entropy: 2.41785
Value Function Loss: 0.02242

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.10295
Policy Update Magnitude: 0.49979
Value Function Update Magnitude: 0.69115

Collected Steps per Second: 11,434.92700
Overall Steps per Second: 7,131.80621

Timestep Collection Time: 4.37519
Timestep Consumption Time: 2.63986
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 7.01505

Cumulative Model Updates: 309,202
Cumulative Timesteps: 2,578,713,158

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2578713158...
Checkpoint 2578713158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.39553
Policy Entropy: 2.40967
Value Function Loss: 0.02237

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.09602
Policy Update Magnitude: 0.49782
Value Function Update Magnitude: 0.68304

Collected Steps per Second: 20,080.63240
Overall Steps per Second: 10,002.21425

Timestep Collection Time: 2.49136
Timestep Consumption Time: 2.51034
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 5.00169

Cumulative Model Updates: 309,208
Cumulative Timesteps: 2,578,763,186

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.91531
Policy Entropy: 2.40655
Value Function Loss: 0.02221

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.11383
Policy Update Magnitude: 0.48543
Value Function Update Magnitude: 0.67397

Collected Steps per Second: 22,204.09947
Overall Steps per Second: 10,842.45098

Timestep Collection Time: 2.25193
Timestep Consumption Time: 2.35976
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.61169

Cumulative Model Updates: 309,214
Cumulative Timesteps: 2,578,813,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2578813188...
Checkpoint 2578813188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.31994
Policy Entropy: 2.38779
Value Function Loss: 0.02143

Mean KL Divergence: 0.02235
SB3 Clip Fraction: 0.13039
Policy Update Magnitude: 0.45932
Value Function Update Magnitude: 0.66555

Collected Steps per Second: 22,236.95342
Overall Steps per Second: 10,618.71008

Timestep Collection Time: 2.24995
Timestep Consumption Time: 2.46173
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.71168

Cumulative Model Updates: 309,220
Cumulative Timesteps: 2,578,863,220

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.09566
Policy Entropy: 2.38514
Value Function Loss: 0.02084

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.11252
Policy Update Magnitude: 0.48042
Value Function Update Magnitude: 0.67961

Collected Steps per Second: 22,035.11298
Overall Steps per Second: 10,514.47266

Timestep Collection Time: 2.26956
Timestep Consumption Time: 2.48674
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.75630

Cumulative Model Updates: 309,226
Cumulative Timesteps: 2,578,913,230

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2578913230...
Checkpoint 2578913230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.16216
Policy Entropy: 2.40304
Value Function Loss: 0.02210

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.50394
Value Function Update Magnitude: 0.67492

Collected Steps per Second: 21,936.87618
Overall Steps per Second: 10,650.50980

Timestep Collection Time: 2.28018
Timestep Consumption Time: 2.41631
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.69649

Cumulative Model Updates: 309,232
Cumulative Timesteps: 2,578,963,250

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.50823
Policy Entropy: 2.41065
Value Function Loss: 0.02190

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.10491
Policy Update Magnitude: 0.50943
Value Function Update Magnitude: 0.67179

Collected Steps per Second: 22,539.78979
Overall Steps per Second: 10,903.52016

Timestep Collection Time: 2.21857
Timestep Consumption Time: 2.36766
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.58623

Cumulative Model Updates: 309,238
Cumulative Timesteps: 2,579,013,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2579013256...
Checkpoint 2579013256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.87358
Policy Entropy: 2.42390
Value Function Loss: 0.02213

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.10008
Policy Update Magnitude: 0.50435
Value Function Update Magnitude: 0.67996

Collected Steps per Second: 21,696.97652
Overall Steps per Second: 10,564.08929

Timestep Collection Time: 2.30511
Timestep Consumption Time: 2.42923
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.73434

Cumulative Model Updates: 309,244
Cumulative Timesteps: 2,579,063,270

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.09420
Policy Entropy: 2.42365
Value Function Loss: 0.02079

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.08791
Policy Update Magnitude: 0.49238
Value Function Update Magnitude: 0.67057

Collected Steps per Second: 22,448.54133
Overall Steps per Second: 10,552.20826

Timestep Collection Time: 2.22865
Timestep Consumption Time: 2.51254
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.74119

Cumulative Model Updates: 309,250
Cumulative Timesteps: 2,579,113,300

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2579113300...
Checkpoint 2579113300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.68189
Policy Entropy: 2.42394
Value Function Loss: 0.01980

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.08469
Policy Update Magnitude: 0.49302
Value Function Update Magnitude: 0.66599

Collected Steps per Second: 21,929.60434
Overall Steps per Second: 10,688.61112

Timestep Collection Time: 2.28039
Timestep Consumption Time: 2.39824
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.67862

Cumulative Model Updates: 309,256
Cumulative Timesteps: 2,579,163,308

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.69919
Policy Entropy: 2.41430
Value Function Loss: 0.01980

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.09372
Policy Update Magnitude: 0.48763
Value Function Update Magnitude: 0.65238

Collected Steps per Second: 21,926.61296
Overall Steps per Second: 10,782.23496

Timestep Collection Time: 2.28134
Timestep Consumption Time: 2.35796
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.63930

Cumulative Model Updates: 309,262
Cumulative Timesteps: 2,579,213,330

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2579213330...
Checkpoint 2579213330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.27481
Policy Entropy: 2.40566
Value Function Loss: 0.02016

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.09737
Policy Update Magnitude: 0.48144
Value Function Update Magnitude: 0.64586

Collected Steps per Second: 21,890.41441
Overall Steps per Second: 10,643.43734

Timestep Collection Time: 2.28429
Timestep Consumption Time: 2.41382
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.69811

Cumulative Model Updates: 309,268
Cumulative Timesteps: 2,579,263,334

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.74506
Policy Entropy: 2.40329
Value Function Loss: 0.02164

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.09795
Policy Update Magnitude: 0.49354
Value Function Update Magnitude: 0.65581

Collected Steps per Second: 21,625.55115
Overall Steps per Second: 10,519.89798

Timestep Collection Time: 2.31263
Timestep Consumption Time: 2.44140
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.75404

Cumulative Model Updates: 309,274
Cumulative Timesteps: 2,579,313,346

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2579313346...
Checkpoint 2579313346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.83563
Policy Entropy: 2.42409
Value Function Loss: 0.02130

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.09201
Policy Update Magnitude: 0.50069
Value Function Update Magnitude: 0.65749

Collected Steps per Second: 21,710.89021
Overall Steps per Second: 10,420.65307

Timestep Collection Time: 2.30345
Timestep Consumption Time: 2.49567
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.79912

Cumulative Model Updates: 309,280
Cumulative Timesteps: 2,579,363,356

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.99143
Policy Entropy: 2.40079
Value Function Loss: 0.02050

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.49695
Value Function Update Magnitude: 0.65018

Collected Steps per Second: 21,769.48512
Overall Steps per Second: 10,608.83658

Timestep Collection Time: 2.29826
Timestep Consumption Time: 2.41781
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.71607

Cumulative Model Updates: 309,286
Cumulative Timesteps: 2,579,413,388

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2579413388...
Checkpoint 2579413388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.45932
Policy Entropy: 2.39312
Value Function Loss: 0.02096

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.09043
Policy Update Magnitude: 0.50349
Value Function Update Magnitude: 0.64906

Collected Steps per Second: 22,795.07650
Overall Steps per Second: 10,768.94973

Timestep Collection Time: 2.19433
Timestep Consumption Time: 2.45050
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.64484

Cumulative Model Updates: 309,292
Cumulative Timesteps: 2,579,463,408

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.98043
Policy Entropy: 2.38255
Value Function Loss: 0.02155

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.09547
Policy Update Magnitude: 0.50628
Value Function Update Magnitude: 0.66709

Collected Steps per Second: 22,623.67180
Overall Steps per Second: 10,707.95346

Timestep Collection Time: 2.21025
Timestep Consumption Time: 2.45955
PPO Batch Consumption Time: 0.28468
Total Iteration Time: 4.66980

Cumulative Model Updates: 309,298
Cumulative Timesteps: 2,579,513,412

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2579513412...
Checkpoint 2579513412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.29610
Policy Entropy: 2.38761
Value Function Loss: 0.02294

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.09094
Policy Update Magnitude: 0.50212
Value Function Update Magnitude: 0.66232

Collected Steps per Second: 21,978.55226
Overall Steps per Second: 10,499.99480

Timestep Collection Time: 2.27540
Timestep Consumption Time: 2.48746
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.76286

Cumulative Model Updates: 309,304
Cumulative Timesteps: 2,579,563,422

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.68746
Policy Entropy: 2.42110
Value Function Loss: 0.02249

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.08974
Policy Update Magnitude: 0.50779
Value Function Update Magnitude: 0.65075

Collected Steps per Second: 22,622.18171
Overall Steps per Second: 10,757.41628

Timestep Collection Time: 2.21155
Timestep Consumption Time: 2.43920
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.65074

Cumulative Model Updates: 309,310
Cumulative Timesteps: 2,579,613,452

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2579613452...
Checkpoint 2579613452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.09768
Policy Entropy: 2.41147
Value Function Loss: 0.02227

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.09049
Policy Update Magnitude: 0.50150
Value Function Update Magnitude: 0.67629

Collected Steps per Second: 22,447.94983
Overall Steps per Second: 10,635.36319

Timestep Collection Time: 2.22737
Timestep Consumption Time: 2.47392
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.70130

Cumulative Model Updates: 309,316
Cumulative Timesteps: 2,579,663,452

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.43491
Policy Entropy: 2.40575
Value Function Loss: 0.02098

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.08846
Policy Update Magnitude: 0.49454
Value Function Update Magnitude: 0.68706

Collected Steps per Second: 22,560.30762
Overall Steps per Second: 10,613.22556

Timestep Collection Time: 2.21726
Timestep Consumption Time: 2.49592
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.71318

Cumulative Model Updates: 309,322
Cumulative Timesteps: 2,579,713,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2579713474...
Checkpoint 2579713474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.70674
Policy Entropy: 2.37192
Value Function Loss: 0.02111

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.49830
Value Function Update Magnitude: 0.67192

Collected Steps per Second: 21,825.04973
Overall Steps per Second: 10,498.02091

Timestep Collection Time: 2.29113
Timestep Consumption Time: 2.47205
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.76318

Cumulative Model Updates: 309,328
Cumulative Timesteps: 2,579,763,478

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.97649
Policy Entropy: 2.36235
Value Function Loss: 0.02187

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.10475
Policy Update Magnitude: 0.49511
Value Function Update Magnitude: 0.65887

Collected Steps per Second: 22,198.26337
Overall Steps per Second: 10,829.73881

Timestep Collection Time: 2.25405
Timestep Consumption Time: 2.36619
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.62024

Cumulative Model Updates: 309,334
Cumulative Timesteps: 2,579,813,514

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2579813514...
Checkpoint 2579813514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.21963
Policy Entropy: 2.39239
Value Function Loss: 0.02328

Mean KL Divergence: 0.02409
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.50285
Value Function Update Magnitude: 0.68499

Collected Steps per Second: 21,815.63606
Overall Steps per Second: 10,459.12917

Timestep Collection Time: 2.29230
Timestep Consumption Time: 2.48898
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.78128

Cumulative Model Updates: 309,340
Cumulative Timesteps: 2,579,863,522

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.17912
Policy Entropy: 2.41406
Value Function Loss: 0.02277

Mean KL Divergence: 0.02244
SB3 Clip Fraction: 0.12361
Policy Update Magnitude: 0.48058
Value Function Update Magnitude: 0.70338

Collected Steps per Second: 22,334.34601
Overall Steps per Second: 10,696.15798

Timestep Collection Time: 2.23915
Timestep Consumption Time: 2.43636
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.67551

Cumulative Model Updates: 309,346
Cumulative Timesteps: 2,579,913,532

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2579913532...
Checkpoint 2579913532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.34761
Policy Entropy: 2.43533
Value Function Loss: 0.02203

Mean KL Divergence: 0.02337
SB3 Clip Fraction: 0.13185
Policy Update Magnitude: 0.47770
Value Function Update Magnitude: 0.69013

Collected Steps per Second: 21,385.23659
Overall Steps per Second: 10,576.80588

Timestep Collection Time: 2.33816
Timestep Consumption Time: 2.38936
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.72751

Cumulative Model Updates: 309,352
Cumulative Timesteps: 2,579,963,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.43935
Policy Entropy: 2.41698
Value Function Loss: 0.02136

Mean KL Divergence: 0.02245
SB3 Clip Fraction: 0.12830
Policy Update Magnitude: 0.46762
Value Function Update Magnitude: 0.65315

Collected Steps per Second: 22,330.86433
Overall Steps per Second: 10,665.45842

Timestep Collection Time: 2.23977
Timestep Consumption Time: 2.44976
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.68953

Cumulative Model Updates: 309,358
Cumulative Timesteps: 2,580,013,550

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2580013550...
Checkpoint 2580013550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.37344
Policy Entropy: 2.40547
Value Function Loss: 0.02138

Mean KL Divergence: 0.02312
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.48235
Value Function Update Magnitude: 0.64441

Collected Steps per Second: 22,331.46395
Overall Steps per Second: 10,484.70383

Timestep Collection Time: 2.23962
Timestep Consumption Time: 2.53057
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.77019

Cumulative Model Updates: 309,364
Cumulative Timesteps: 2,580,063,564

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.88479
Policy Entropy: 2.42077
Value Function Loss: 0.02159

Mean KL Divergence: 0.02302
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.48721
Value Function Update Magnitude: 0.64471

Collected Steps per Second: 22,431.56375
Overall Steps per Second: 10,564.99615

Timestep Collection Time: 2.22918
Timestep Consumption Time: 2.50381
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.73299

Cumulative Model Updates: 309,370
Cumulative Timesteps: 2,580,113,568

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2580113568...
Checkpoint 2580113568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.16251
Policy Entropy: 2.43827
Value Function Loss: 0.02156

Mean KL Divergence: 0.02105
SB3 Clip Fraction: 0.11968
Policy Update Magnitude: 0.50023
Value Function Update Magnitude: 0.65738

Collected Steps per Second: 21,665.19130
Overall Steps per Second: 10,535.12831

Timestep Collection Time: 2.30813
Timestep Consumption Time: 2.43847
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.74660

Cumulative Model Updates: 309,376
Cumulative Timesteps: 2,580,163,574

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.38359
Policy Entropy: 2.45007
Value Function Loss: 0.02183

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.11395
Policy Update Magnitude: 0.50258
Value Function Update Magnitude: 0.67349

Collected Steps per Second: 22,440.53163
Overall Steps per Second: 10,872.17849

Timestep Collection Time: 2.22918
Timestep Consumption Time: 2.37192
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.60110

Cumulative Model Updates: 309,382
Cumulative Timesteps: 2,580,213,598

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2580213598...
Checkpoint 2580213598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.15427
Policy Entropy: 2.43856
Value Function Loss: 0.02102

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.09654
Policy Update Magnitude: 0.49845
Value Function Update Magnitude: 0.69194

Collected Steps per Second: 22,223.03384
Overall Steps per Second: 10,696.88943

Timestep Collection Time: 2.25064
Timestep Consumption Time: 2.42511
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.67575

Cumulative Model Updates: 309,388
Cumulative Timesteps: 2,580,263,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.08355
Policy Entropy: 2.43938
Value Function Loss: 0.01994

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.09402
Policy Update Magnitude: 0.49785
Value Function Update Magnitude: 0.67663

Collected Steps per Second: 22,500.59559
Overall Steps per Second: 10,624.51855

Timestep Collection Time: 2.22216
Timestep Consumption Time: 2.48393
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.70610

Cumulative Model Updates: 309,394
Cumulative Timesteps: 2,580,313,614

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2580313614...
Checkpoint 2580313614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.16018
Policy Entropy: 2.45615
Value Function Loss: 0.01961

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.09388
Policy Update Magnitude: 0.49548
Value Function Update Magnitude: 0.65584

Collected Steps per Second: 22,144.69675
Overall Steps per Second: 10,578.38083

Timestep Collection Time: 2.25887
Timestep Consumption Time: 2.46983
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.72870

Cumulative Model Updates: 309,400
Cumulative Timesteps: 2,580,363,636

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.51851
Policy Entropy: 2.45557
Value Function Loss: 0.02099

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.09751
Policy Update Magnitude: 0.49885
Value Function Update Magnitude: 0.66116

Collected Steps per Second: 21,550.41006
Overall Steps per Second: 10,526.29718

Timestep Collection Time: 2.32070
Timestep Consumption Time: 2.43045
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.75115

Cumulative Model Updates: 309,406
Cumulative Timesteps: 2,580,413,648

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2580413648...
Checkpoint 2580413648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.14600
Policy Entropy: 2.44427
Value Function Loss: 0.02138

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.10033
Policy Update Magnitude: 0.48611
Value Function Update Magnitude: 0.65321

Collected Steps per Second: 22,160.34856
Overall Steps per Second: 10,446.94409

Timestep Collection Time: 2.25628
Timestep Consumption Time: 2.52981
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.78609

Cumulative Model Updates: 309,412
Cumulative Timesteps: 2,580,463,648

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.75551
Policy Entropy: 2.43339
Value Function Loss: 0.02178

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.10371
Policy Update Magnitude: 0.49182
Value Function Update Magnitude: 0.64841

Collected Steps per Second: 21,817.30197
Overall Steps per Second: 10,461.84116

Timestep Collection Time: 2.29295
Timestep Consumption Time: 2.48881
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.78176

Cumulative Model Updates: 309,418
Cumulative Timesteps: 2,580,513,674

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2580513674...
Checkpoint 2580513674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.77561
Policy Entropy: 2.43748
Value Function Loss: 0.02150

Mean KL Divergence: 0.02344
SB3 Clip Fraction: 0.12764
Policy Update Magnitude: 0.46902
Value Function Update Magnitude: 0.64910

Collected Steps per Second: 21,805.33607
Overall Steps per Second: 10,623.69215

Timestep Collection Time: 2.29430
Timestep Consumption Time: 2.41480
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.70910

Cumulative Model Updates: 309,424
Cumulative Timesteps: 2,580,563,702

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.85019
Policy Entropy: 2.43488
Value Function Loss: 0.02201

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.10766
Policy Update Magnitude: 0.49028
Value Function Update Magnitude: 0.67158

Collected Steps per Second: 22,019.37266
Overall Steps per Second: 10,524.74587

Timestep Collection Time: 2.27127
Timestep Consumption Time: 2.48058
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.75185

Cumulative Model Updates: 309,430
Cumulative Timesteps: 2,580,613,714

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2580613714...
Checkpoint 2580613714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.17367
Policy Entropy: 2.44765
Value Function Loss: 0.02090

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.09687
Policy Update Magnitude: 0.49936
Value Function Update Magnitude: 0.68648

Collected Steps per Second: 22,530.93241
Overall Steps per Second: 10,593.25219

Timestep Collection Time: 2.22068
Timestep Consumption Time: 2.50251
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.72320

Cumulative Model Updates: 309,436
Cumulative Timesteps: 2,580,663,748

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.54742
Policy Entropy: 2.44774
Value Function Loss: 0.02096

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.49416
Value Function Update Magnitude: 0.68882

Collected Steps per Second: 22,437.66729
Overall Steps per Second: 10,550.38970

Timestep Collection Time: 2.22929
Timestep Consumption Time: 2.51177
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.74106

Cumulative Model Updates: 309,442
Cumulative Timesteps: 2,580,713,768

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2580713768...
Checkpoint 2580713768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.89117
Policy Entropy: 2.46452
Value Function Loss: 0.02118

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.09967
Policy Update Magnitude: 0.48704
Value Function Update Magnitude: 0.68958

Collected Steps per Second: 22,042.32359
Overall Steps per Second: 10,542.18842

Timestep Collection Time: 2.26864
Timestep Consumption Time: 2.47478
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.74342

Cumulative Model Updates: 309,448
Cumulative Timesteps: 2,580,763,774

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.66056
Policy Entropy: 2.45970
Value Function Loss: 0.02114

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.10404
Policy Update Magnitude: 0.48341
Value Function Update Magnitude: 0.67689

Collected Steps per Second: 22,468.02122
Overall Steps per Second: 10,883.78492

Timestep Collection Time: 2.22645
Timestep Consumption Time: 2.36974
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.59620

Cumulative Model Updates: 309,454
Cumulative Timesteps: 2,580,813,798

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2580813798...
Checkpoint 2580813798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.22428
Policy Entropy: 2.45548
Value Function Loss: 0.02168

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.10166
Policy Update Magnitude: 0.49321
Value Function Update Magnitude: 0.66215

Collected Steps per Second: 22,238.40653
Overall Steps per Second: 10,660.62124

Timestep Collection Time: 2.24854
Timestep Consumption Time: 2.44199
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.69053

Cumulative Model Updates: 309,460
Cumulative Timesteps: 2,580,863,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.20160
Policy Entropy: 2.43615
Value Function Loss: 0.02079

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.09631
Policy Update Magnitude: 0.49243
Value Function Update Magnitude: 0.64299

Collected Steps per Second: 21,806.77809
Overall Steps per Second: 10,497.47564

Timestep Collection Time: 2.29424
Timestep Consumption Time: 2.47167
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.76591

Cumulative Model Updates: 309,466
Cumulative Timesteps: 2,580,913,832

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2580913832...
Checkpoint 2580913832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.67542
Policy Entropy: 2.44021
Value Function Loss: 0.02083

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.09188
Policy Update Magnitude: 0.48303
Value Function Update Magnitude: 0.63604

Collected Steps per Second: 21,795.69766
Overall Steps per Second: 10,614.55769

Timestep Collection Time: 2.29550
Timestep Consumption Time: 2.41803
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.71353

Cumulative Model Updates: 309,472
Cumulative Timesteps: 2,580,963,864

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.56642
Policy Entropy: 2.44068
Value Function Loss: 0.02055

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.48618
Value Function Update Magnitude: 0.61315

Collected Steps per Second: 22,457.22477
Overall Steps per Second: 10,573.80194

Timestep Collection Time: 2.22663
Timestep Consumption Time: 2.50241
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.72905

Cumulative Model Updates: 309,478
Cumulative Timesteps: 2,581,013,868

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2581013868...
Checkpoint 2581013868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.20602
Policy Entropy: 2.45591
Value Function Loss: 0.02114

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.09466
Policy Update Magnitude: 0.48839
Value Function Update Magnitude: 0.61530

Collected Steps per Second: 21,931.97100
Overall Steps per Second: 10,564.41009

Timestep Collection Time: 2.28142
Timestep Consumption Time: 2.45486
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.73628

Cumulative Model Updates: 309,484
Cumulative Timesteps: 2,581,063,904

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.24829
Policy Entropy: 2.43352
Value Function Loss: 0.02067

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.48890
Value Function Update Magnitude: 0.62265

Collected Steps per Second: 21,894.30727
Overall Steps per Second: 10,439.46794

Timestep Collection Time: 2.28379
Timestep Consumption Time: 2.50592
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.78971

Cumulative Model Updates: 309,490
Cumulative Timesteps: 2,581,113,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2581113906...
Checkpoint 2581113906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.28173
Policy Entropy: 2.45080
Value Function Loss: 0.01844

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.10407
Policy Update Magnitude: 0.47574
Value Function Update Magnitude: 0.62385

Collected Steps per Second: 22,213.00295
Overall Steps per Second: 10,655.43926

Timestep Collection Time: 2.25156
Timestep Consumption Time: 2.44219
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.69375

Cumulative Model Updates: 309,496
Cumulative Timesteps: 2,581,163,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.56602
Policy Entropy: 2.44374
Value Function Loss: 0.02001

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.10034
Policy Update Magnitude: 0.48555
Value Function Update Magnitude: 0.60921

Collected Steps per Second: 22,580.67502
Overall Steps per Second: 10,618.29946

Timestep Collection Time: 2.21455
Timestep Consumption Time: 2.49487
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.70942

Cumulative Model Updates: 309,502
Cumulative Timesteps: 2,581,213,926

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2581213926...
Checkpoint 2581213926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.01885
Policy Entropy: 2.46676
Value Function Loss: 0.01966

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.10695
Policy Update Magnitude: 0.49123
Value Function Update Magnitude: 0.61347

Collected Steps per Second: 22,137.52470
Overall Steps per Second: 10,479.99101

Timestep Collection Time: 2.25915
Timestep Consumption Time: 2.51299
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.77214

Cumulative Model Updates: 309,508
Cumulative Timesteps: 2,581,263,938

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.13512
Policy Entropy: 2.43759
Value Function Loss: 0.02123

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.49657
Value Function Update Magnitude: 0.62098

Collected Steps per Second: 22,363.05179
Overall Steps per Second: 10,659.04266

Timestep Collection Time: 2.23690
Timestep Consumption Time: 2.45620
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.69310

Cumulative Model Updates: 309,514
Cumulative Timesteps: 2,581,313,962

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2581313962...
Checkpoint 2581313962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.54705
Policy Entropy: 2.44327
Value Function Loss: 0.02045

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.09081
Policy Update Magnitude: 0.48873
Value Function Update Magnitude: 0.63589

Collected Steps per Second: 22,082.05013
Overall Steps per Second: 10,590.36005

Timestep Collection Time: 2.26464
Timestep Consumption Time: 2.45739
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.72203

Cumulative Model Updates: 309,520
Cumulative Timesteps: 2,581,363,970

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.34987
Policy Entropy: 2.42207
Value Function Loss: 0.02112

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.09117
Policy Update Magnitude: 0.48539
Value Function Update Magnitude: 0.64005

Collected Steps per Second: 22,644.77069
Overall Steps per Second: 10,741.51500

Timestep Collection Time: 2.20890
Timestep Consumption Time: 2.44780
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.65670

Cumulative Model Updates: 309,526
Cumulative Timesteps: 2,581,413,990

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2581413990...
Checkpoint 2581413990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.50028
Policy Entropy: 2.43557
Value Function Loss: 0.02106

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.48362
Value Function Update Magnitude: 0.63446

Collected Steps per Second: 21,971.38203
Overall Steps per Second: 10,613.80041

Timestep Collection Time: 2.27660
Timestep Consumption Time: 2.43613
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.71273

Cumulative Model Updates: 309,532
Cumulative Timesteps: 2,581,464,010

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.16315
Policy Entropy: 2.43694
Value Function Loss: 0.02107

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.48735
Value Function Update Magnitude: 0.62679

Collected Steps per Second: 21,535.37995
Overall Steps per Second: 10,498.68899

Timestep Collection Time: 2.32288
Timestep Consumption Time: 2.44191
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.76479

Cumulative Model Updates: 309,538
Cumulative Timesteps: 2,581,514,034

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2581514034...
Checkpoint 2581514034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.39740
Policy Entropy: 2.43071
Value Function Loss: 0.02105

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.09254
Policy Update Magnitude: 0.49812
Value Function Update Magnitude: 0.63563

Collected Steps per Second: 21,933.00094
Overall Steps per Second: 10,610.49913

Timestep Collection Time: 2.28040
Timestep Consumption Time: 2.43342
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.71382

Cumulative Model Updates: 309,544
Cumulative Timesteps: 2,581,564,050

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.93842
Policy Entropy: 2.42955
Value Function Loss: 0.02029

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.09460
Policy Update Magnitude: 0.48914
Value Function Update Magnitude: 0.64176

Collected Steps per Second: 22,171.69471
Overall Steps per Second: 10,474.51751

Timestep Collection Time: 2.25567
Timestep Consumption Time: 2.51897
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.77464

Cumulative Model Updates: 309,550
Cumulative Timesteps: 2,581,614,062

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2581614062...
Checkpoint 2581614062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.35531
Policy Entropy: 2.44226
Value Function Loss: 0.02044

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.09036
Policy Update Magnitude: 0.51432
Value Function Update Magnitude: 0.63961

Collected Steps per Second: 21,983.97991
Overall Steps per Second: 10,621.52506

Timestep Collection Time: 2.27529
Timestep Consumption Time: 2.43401
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.70930

Cumulative Model Updates: 309,556
Cumulative Timesteps: 2,581,664,082

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.97178
Policy Entropy: 2.44475
Value Function Loss: 0.02014

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.09355
Policy Update Magnitude: 0.49166
Value Function Update Magnitude: 0.66067

Collected Steps per Second: 22,397.04650
Overall Steps per Second: 10,446.98222

Timestep Collection Time: 2.23279
Timestep Consumption Time: 2.55404
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.78684

Cumulative Model Updates: 309,562
Cumulative Timesteps: 2,581,714,090

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2581714090...
Checkpoint 2581714090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.54332
Policy Entropy: 2.45504
Value Function Loss: 0.01987

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.48171
Value Function Update Magnitude: 0.68320

Collected Steps per Second: 22,153.73482
Overall Steps per Second: 10,651.32099

Timestep Collection Time: 2.25732
Timestep Consumption Time: 2.43769
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.69500

Cumulative Model Updates: 309,568
Cumulative Timesteps: 2,581,764,098

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.17273
Policy Entropy: 2.45434
Value Function Loss: 0.01889

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.09547
Policy Update Magnitude: 0.47750
Value Function Update Magnitude: 0.66922

Collected Steps per Second: 22,576.25658
Overall Steps per Second: 10,621.72462

Timestep Collection Time: 2.21587
Timestep Consumption Time: 2.49391
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.70978

Cumulative Model Updates: 309,574
Cumulative Timesteps: 2,581,814,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2581814124...
Checkpoint 2581814124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.11468
Policy Entropy: 2.45117
Value Function Loss: 0.01983

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.47682
Value Function Update Magnitude: 0.65247

Collected Steps per Second: 22,489.83289
Overall Steps per Second: 10,606.80701

Timestep Collection Time: 2.22465
Timestep Consumption Time: 2.49232
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.71697

Cumulative Model Updates: 309,580
Cumulative Timesteps: 2,581,864,156

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.98776
Policy Entropy: 2.44609
Value Function Loss: 0.02096

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.08736
Policy Update Magnitude: 0.48246
Value Function Update Magnitude: 0.64480

Collected Steps per Second: 22,393.05015
Overall Steps per Second: 10,689.59036

Timestep Collection Time: 2.23337
Timestep Consumption Time: 2.44520
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.67857

Cumulative Model Updates: 309,586
Cumulative Timesteps: 2,581,914,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2581914168...
Checkpoint 2581914168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.43460
Policy Entropy: 2.42731
Value Function Loss: 0.02264

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.09646
Policy Update Magnitude: 0.48210
Value Function Update Magnitude: 0.65759

Collected Steps per Second: 22,257.33076
Overall Steps per Second: 10,750.65212

Timestep Collection Time: 2.24681
Timestep Consumption Time: 2.40481
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.65162

Cumulative Model Updates: 309,592
Cumulative Timesteps: 2,581,964,176

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.48353
Policy Entropy: 2.46075
Value Function Loss: 0.02132

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.10300
Policy Update Magnitude: 0.47101
Value Function Update Magnitude: 0.65292

Collected Steps per Second: 22,426.91287
Overall Steps per Second: 10,892.21725

Timestep Collection Time: 2.23000
Timestep Consumption Time: 2.36154
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.59154

Cumulative Model Updates: 309,598
Cumulative Timesteps: 2,582,014,188

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2582014188...
Checkpoint 2582014188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.54095
Policy Entropy: 2.45605
Value Function Loss: 0.01984

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.09248
Policy Update Magnitude: 0.47218
Value Function Update Magnitude: 0.64768

Collected Steps per Second: 21,796.77473
Overall Steps per Second: 10,573.86746

Timestep Collection Time: 2.29511
Timestep Consumption Time: 2.43599
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.73110

Cumulative Model Updates: 309,604
Cumulative Timesteps: 2,582,064,214

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.94391
Policy Entropy: 2.47033
Value Function Loss: 0.01949

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.09022
Policy Update Magnitude: 0.48996
Value Function Update Magnitude: 0.64413

Collected Steps per Second: 21,959.01575
Overall Steps per Second: 10,500.02771

Timestep Collection Time: 2.27733
Timestep Consumption Time: 2.48532
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.76265

Cumulative Model Updates: 309,610
Cumulative Timesteps: 2,582,114,222

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2582114222...
Checkpoint 2582114222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.66983
Policy Entropy: 2.45035
Value Function Loss: 0.01904

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.08748
Policy Update Magnitude: 0.48719
Value Function Update Magnitude: 0.65939

Collected Steps per Second: 21,316.99159
Overall Steps per Second: 10,395.61915

Timestep Collection Time: 2.34583
Timestep Consumption Time: 2.46447
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.81030

Cumulative Model Updates: 309,616
Cumulative Timesteps: 2,582,164,228

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.28874
Policy Entropy: 2.44423
Value Function Loss: 0.02093

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.08905
Policy Update Magnitude: 0.49218
Value Function Update Magnitude: 0.64936

Collected Steps per Second: 21,999.98109
Overall Steps per Second: 10,697.64970

Timestep Collection Time: 2.27346
Timestep Consumption Time: 2.40196
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.67542

Cumulative Model Updates: 309,622
Cumulative Timesteps: 2,582,214,244

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2582214244...
Checkpoint 2582214244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.91129
Policy Entropy: 2.44064
Value Function Loss: 0.02037

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.08665
Policy Update Magnitude: 0.48278
Value Function Update Magnitude: 0.63896

Collected Steps per Second: 22,070.18747
Overall Steps per Second: 10,615.16498

Timestep Collection Time: 2.26659
Timestep Consumption Time: 2.44592
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.71250

Cumulative Model Updates: 309,628
Cumulative Timesteps: 2,582,264,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.22425
Policy Entropy: 2.44753
Value Function Loss: 0.02114

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.08949
Policy Update Magnitude: 0.47478
Value Function Update Magnitude: 0.63962

Collected Steps per Second: 22,198.72202
Overall Steps per Second: 10,452.61346

Timestep Collection Time: 2.25265
Timestep Consumption Time: 2.53141
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.78407

Cumulative Model Updates: 309,634
Cumulative Timesteps: 2,582,314,274

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2582314274...
Checkpoint 2582314274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.20131
Policy Entropy: 2.44107
Value Function Loss: 0.02084

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.09312
Policy Update Magnitude: 0.47635
Value Function Update Magnitude: 0.62545

Collected Steps per Second: 21,798.68108
Overall Steps per Second: 10,540.63024

Timestep Collection Time: 2.29399
Timestep Consumption Time: 2.45013
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.74412

Cumulative Model Updates: 309,640
Cumulative Timesteps: 2,582,364,280

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.39191
Policy Entropy: 2.42580
Value Function Loss: 0.02178

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.08891
Policy Update Magnitude: 0.49023
Value Function Update Magnitude: 0.64549

Collected Steps per Second: 22,231.87709
Overall Steps per Second: 10,719.56976

Timestep Collection Time: 2.25010
Timestep Consumption Time: 2.41650
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.66661

Cumulative Model Updates: 309,646
Cumulative Timesteps: 2,582,414,304

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2582414304...
Checkpoint 2582414304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.97447
Policy Entropy: 2.42106
Value Function Loss: 0.02197

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.08261
Policy Update Magnitude: 0.49643
Value Function Update Magnitude: 0.66152

Collected Steps per Second: 22,153.14035
Overall Steps per Second: 10,483.36142

Timestep Collection Time: 2.25819
Timestep Consumption Time: 2.51375
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.77194

Cumulative Model Updates: 309,652
Cumulative Timesteps: 2,582,464,330

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.89301
Policy Entropy: 2.41681
Value Function Loss: 0.02321

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.09633
Policy Update Magnitude: 0.49559
Value Function Update Magnitude: 0.65998

Collected Steps per Second: 21,964.22720
Overall Steps per Second: 10,486.15686

Timestep Collection Time: 2.27670
Timestep Consumption Time: 2.49206
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.76876

Cumulative Model Updates: 309,658
Cumulative Timesteps: 2,582,514,336

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2582514336...
Checkpoint 2582514336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.27429
Policy Entropy: 2.41870
Value Function Loss: 0.02325

Mean KL Divergence: 0.02305
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.48056
Value Function Update Magnitude: 0.69080

Collected Steps per Second: 21,789.76125
Overall Steps per Second: 10,521.51554

Timestep Collection Time: 2.29603
Timestep Consumption Time: 2.45899
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.75502

Cumulative Model Updates: 309,664
Cumulative Timesteps: 2,582,564,366

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.03259
Policy Entropy: 2.41121
Value Function Loss: 0.02204

Mean KL Divergence: 0.02277
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.46865
Value Function Update Magnitude: 0.68696

Collected Steps per Second: 22,147.08404
Overall Steps per Second: 10,456.27975

Timestep Collection Time: 2.25845
Timestep Consumption Time: 2.52509
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.78354

Cumulative Model Updates: 309,670
Cumulative Timesteps: 2,582,614,384

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2582614384...
Checkpoint 2582614384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.89686
Policy Entropy: 2.42445
Value Function Loss: 0.02110

Mean KL Divergence: 0.02380
SB3 Clip Fraction: 0.13848
Policy Update Magnitude: 0.46302
Value Function Update Magnitude: 0.64221

Collected Steps per Second: 21,317.22066
Overall Steps per Second: 10,268.48772

Timestep Collection Time: 2.34674
Timestep Consumption Time: 2.52506
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.87180

Cumulative Model Updates: 309,676
Cumulative Timesteps: 2,582,664,410

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.94955
Policy Entropy: 2.42382
Value Function Loss: 0.02142

Mean KL Divergence: 0.02112
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.48396
Value Function Update Magnitude: 0.63379

Collected Steps per Second: 20,649.44503
Overall Steps per Second: 10,154.94206

Timestep Collection Time: 2.42176
Timestep Consumption Time: 2.50274
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.92450

Cumulative Model Updates: 309,682
Cumulative Timesteps: 2,582,714,418

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2582714418...
Checkpoint 2582714418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.32660
Policy Entropy: 2.44568
Value Function Loss: 0.02104

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.11380
Policy Update Magnitude: 0.49662
Value Function Update Magnitude: 0.64545

Collected Steps per Second: 21,412.15994
Overall Steps per Second: 10,571.26322

Timestep Collection Time: 2.33643
Timestep Consumption Time: 2.39602
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.73245

Cumulative Model Updates: 309,688
Cumulative Timesteps: 2,582,764,446

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.85615
Policy Entropy: 2.44101
Value Function Loss: 0.02018

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.10223
Policy Update Magnitude: 0.48856
Value Function Update Magnitude: 0.65236

Collected Steps per Second: 22,009.73154
Overall Steps per Second: 10,431.79291

Timestep Collection Time: 2.27200
Timestep Consumption Time: 2.52162
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.79362

Cumulative Model Updates: 309,694
Cumulative Timesteps: 2,582,814,452

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2582814452...
Checkpoint 2582814452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.72797
Policy Entropy: 2.46327
Value Function Loss: 0.01942

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.09757
Policy Update Magnitude: 0.48485
Value Function Update Magnitude: 0.66050

Collected Steps per Second: 22,110.88132
Overall Steps per Second: 10,635.81683

Timestep Collection Time: 2.26178
Timestep Consumption Time: 2.44025
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.70204

Cumulative Model Updates: 309,700
Cumulative Timesteps: 2,582,864,462

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.91488
Policy Entropy: 2.43453
Value Function Loss: 0.01963

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.47842
Value Function Update Magnitude: 0.64077

Collected Steps per Second: 22,293.12639
Overall Steps per Second: 10,464.39001

Timestep Collection Time: 2.24293
Timestep Consumption Time: 2.53537
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.77830

Cumulative Model Updates: 309,706
Cumulative Timesteps: 2,582,914,464

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2582914464...
Checkpoint 2582914464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.35062
Policy Entropy: 2.42544
Value Function Loss: 0.02035

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.10851
Policy Update Magnitude: 0.49390
Value Function Update Magnitude: 0.62726

Collected Steps per Second: 21,945.24132
Overall Steps per Second: 10,621.37643

Timestep Collection Time: 2.27922
Timestep Consumption Time: 2.42996
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.70918

Cumulative Model Updates: 309,712
Cumulative Timesteps: 2,582,964,482

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.06860
Policy Entropy: 2.40179
Value Function Loss: 0.02149

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.12395
Policy Update Magnitude: 0.47195
Value Function Update Magnitude: 0.62598

Collected Steps per Second: 22,336.26305
Overall Steps per Second: 10,506.03303

Timestep Collection Time: 2.23869
Timestep Consumption Time: 2.52086
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.75955

Cumulative Model Updates: 309,718
Cumulative Timesteps: 2,583,014,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2583014486...
Checkpoint 2583014486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.31350
Policy Entropy: 2.42844
Value Function Loss: 0.02118

Mean KL Divergence: 0.02221
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.44638
Value Function Update Magnitude: 0.62310

Collected Steps per Second: 22,354.56758
Overall Steps per Second: 10,575.08881

Timestep Collection Time: 2.23713
Timestep Consumption Time: 2.49191
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.72904

Cumulative Model Updates: 309,724
Cumulative Timesteps: 2,583,064,496

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.97281
Policy Entropy: 2.41649
Value Function Loss: 0.02121

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.11449
Policy Update Magnitude: 0.47811
Value Function Update Magnitude: 0.63901

Collected Steps per Second: 22,203.15666
Overall Steps per Second: 10,682.78151

Timestep Collection Time: 2.25211
Timestep Consumption Time: 2.42869
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.68080

Cumulative Model Updates: 309,730
Cumulative Timesteps: 2,583,114,500

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2583114500...
Checkpoint 2583114500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.62502
Policy Entropy: 2.43604
Value Function Loss: 0.02060

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.10664
Policy Update Magnitude: 0.49158
Value Function Update Magnitude: 0.64990

Collected Steps per Second: 22,379.81821
Overall Steps per Second: 10,632.12236

Timestep Collection Time: 2.23487
Timestep Consumption Time: 2.46936
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.70423

Cumulative Model Updates: 309,736
Cumulative Timesteps: 2,583,164,516

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.77997
Policy Entropy: 2.41042
Value Function Loss: 0.02176

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.10969
Policy Update Magnitude: 0.49757
Value Function Update Magnitude: 0.64501

Collected Steps per Second: 22,473.30638
Overall Steps per Second: 10,687.36677

Timestep Collection Time: 2.22584
Timestep Consumption Time: 2.45464
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.68048

Cumulative Model Updates: 309,742
Cumulative Timesteps: 2,583,214,538

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2583214538...
Checkpoint 2583214538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.93720
Policy Entropy: 2.44723
Value Function Loss: 0.02110

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.09963
Policy Update Magnitude: 0.49261
Value Function Update Magnitude: 0.66245

Collected Steps per Second: 21,980.23643
Overall Steps per Second: 10,624.38084

Timestep Collection Time: 2.27477
Timestep Consumption Time: 2.43139
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.70616

Cumulative Model Updates: 309,748
Cumulative Timesteps: 2,583,264,538

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.86502
Policy Entropy: 2.44622
Value Function Loss: 0.02084

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.49887
Value Function Update Magnitude: 0.66824

Collected Steps per Second: 21,963.09268
Overall Steps per Second: 10,512.30098

Timestep Collection Time: 2.27755
Timestep Consumption Time: 2.48088
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.75843

Cumulative Model Updates: 309,754
Cumulative Timesteps: 2,583,314,560

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2583314560...
Checkpoint 2583314560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.14770
Policy Entropy: 2.46169
Value Function Loss: 0.02022

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.09444
Policy Update Magnitude: 0.48415
Value Function Update Magnitude: 0.67024

Collected Steps per Second: 22,759.86717
Overall Steps per Second: 10,622.78124

Timestep Collection Time: 2.19913
Timestep Consumption Time: 2.51263
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.71176

Cumulative Model Updates: 309,760
Cumulative Timesteps: 2,583,364,612

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.33113
Policy Entropy: 2.45731
Value Function Loss: 0.02027

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.09503
Policy Update Magnitude: 0.50330
Value Function Update Magnitude: 0.66507

Collected Steps per Second: 22,140.98371
Overall Steps per Second: 10,452.68543

Timestep Collection Time: 2.25862
Timestep Consumption Time: 2.52561
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.78423

Cumulative Model Updates: 309,766
Cumulative Timesteps: 2,583,414,620

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2583414620...
Checkpoint 2583414620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.61102
Policy Entropy: 2.46173
Value Function Loss: 0.02077

Mean KL Divergence: 0.02622
SB3 Clip Fraction: 0.09909
Policy Update Magnitude: 0.50660
Value Function Update Magnitude: 0.63878

Collected Steps per Second: 22,242.75346
Overall Steps per Second: 10,645.38894

Timestep Collection Time: 2.24882
Timestep Consumption Time: 2.44993
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.69875

Cumulative Model Updates: 309,772
Cumulative Timesteps: 2,583,464,640

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.51724
Policy Entropy: 2.47171
Value Function Loss: 0.02182

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.09568
Policy Update Magnitude: 0.49222
Value Function Update Magnitude: 0.64465

Collected Steps per Second: 22,628.13957
Overall Steps per Second: 10,890.11812

Timestep Collection Time: 2.21043
Timestep Consumption Time: 2.38254
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.59297

Cumulative Model Updates: 309,778
Cumulative Timesteps: 2,583,514,658

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2583514658...
Checkpoint 2583514658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.32138
Policy Entropy: 2.46473
Value Function Loss: 0.02209

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.09676
Policy Update Magnitude: 0.49523
Value Function Update Magnitude: 0.66552

Collected Steps per Second: 22,438.52695
Overall Steps per Second: 10,736.01846

Timestep Collection Time: 2.22840
Timestep Consumption Time: 2.42901
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.65741

Cumulative Model Updates: 309,784
Cumulative Timesteps: 2,583,564,660

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.39921
Policy Entropy: 2.44203
Value Function Loss: 0.02091

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.10702
Policy Update Magnitude: 0.48889
Value Function Update Magnitude: 0.66197

Collected Steps per Second: 22,559.52558
Overall Steps per Second: 10,745.36703

Timestep Collection Time: 2.21707
Timestep Consumption Time: 2.43759
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.65466

Cumulative Model Updates: 309,790
Cumulative Timesteps: 2,583,614,676

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2583614676...
Checkpoint 2583614676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.30502
Policy Entropy: 2.42774
Value Function Loss: 0.01987

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.47534
Value Function Update Magnitude: 0.65201

Collected Steps per Second: 22,138.30370
Overall Steps per Second: 10,711.07099

Timestep Collection Time: 2.25862
Timestep Consumption Time: 2.40963
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.66825

Cumulative Model Updates: 309,796
Cumulative Timesteps: 2,583,664,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.32094
Policy Entropy: 2.41790
Value Function Loss: 0.02020

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.10226
Policy Update Magnitude: 0.48350
Value Function Update Magnitude: 0.64797

Collected Steps per Second: 22,278.71075
Overall Steps per Second: 10,890.06302

Timestep Collection Time: 2.24537
Timestep Consumption Time: 2.34817
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.59355

Cumulative Model Updates: 309,802
Cumulative Timesteps: 2,583,714,702

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2583714702...
Checkpoint 2583714702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.82711
Policy Entropy: 2.44638
Value Function Loss: 0.02059

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.10579
Policy Update Magnitude: 0.47581
Value Function Update Magnitude: 0.65421

Collected Steps per Second: 21,918.07376
Overall Steps per Second: 10,613.55907

Timestep Collection Time: 2.28223
Timestep Consumption Time: 2.43080
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.71303

Cumulative Model Updates: 309,808
Cumulative Timesteps: 2,583,764,724

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.36502
Policy Entropy: 2.44099
Value Function Loss: 0.02046

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.47712
Value Function Update Magnitude: 0.65784

Collected Steps per Second: 22,098.20641
Overall Steps per Second: 10,537.98486

Timestep Collection Time: 2.26317
Timestep Consumption Time: 2.48271
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.74588

Cumulative Model Updates: 309,814
Cumulative Timesteps: 2,583,814,736

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2583814736...
Checkpoint 2583814736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.34715
Policy Entropy: 2.45707
Value Function Loss: 0.01948

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.09566
Policy Update Magnitude: 0.48349
Value Function Update Magnitude: 0.64646

Collected Steps per Second: 21,644.63851
Overall Steps per Second: 10,590.97770

Timestep Collection Time: 2.31060
Timestep Consumption Time: 2.41154
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.72213

Cumulative Model Updates: 309,820
Cumulative Timesteps: 2,583,864,748

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.43065
Policy Entropy: 2.43491
Value Function Loss: 0.02024

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.10162
Policy Update Magnitude: 0.47985
Value Function Update Magnitude: 0.65093

Collected Steps per Second: 22,597.51821
Overall Steps per Second: 10,588.36314

Timestep Collection Time: 2.21334
Timestep Consumption Time: 2.51034
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.72368

Cumulative Model Updates: 309,826
Cumulative Timesteps: 2,583,914,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2583914764...
Checkpoint 2583914764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.63960
Policy Entropy: 2.44645
Value Function Loss: 0.02116

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.48670
Value Function Update Magnitude: 0.66667

Collected Steps per Second: 21,938.24962
Overall Steps per Second: 10,522.63663

Timestep Collection Time: 2.27912
Timestep Consumption Time: 2.47254
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.75166

Cumulative Model Updates: 309,832
Cumulative Timesteps: 2,583,964,764

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.59403
Policy Entropy: 2.41852
Value Function Loss: 0.02167

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.49698
Value Function Update Magnitude: 0.66421

Collected Steps per Second: 22,033.25763
Overall Steps per Second: 10,477.98270

Timestep Collection Time: 2.27011
Timestep Consumption Time: 2.50352
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.77363

Cumulative Model Updates: 309,838
Cumulative Timesteps: 2,584,014,782

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2584014782...
Checkpoint 2584014782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.27679
Policy Entropy: 2.41520
Value Function Loss: 0.02130

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.50198
Value Function Update Magnitude: 0.67339

Collected Steps per Second: 22,033.25572
Overall Steps per Second: 10,647.83449

Timestep Collection Time: 2.27075
Timestep Consumption Time: 2.42805
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.69880

Cumulative Model Updates: 309,844
Cumulative Timesteps: 2,584,064,814

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.52968
Policy Entropy: 2.39825
Value Function Loss: 0.02160

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.09892
Policy Update Magnitude: 0.50266
Value Function Update Magnitude: 0.68834

Collected Steps per Second: 22,442.36740
Overall Steps per Second: 10,585.03407

Timestep Collection Time: 2.22820
Timestep Consumption Time: 2.49602
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.72422

Cumulative Model Updates: 309,850
Cumulative Timesteps: 2,584,114,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2584114820...
Checkpoint 2584114820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.00528
Policy Entropy: 2.42256
Value Function Loss: 0.02145

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.09022
Policy Update Magnitude: 0.49535
Value Function Update Magnitude: 0.68466

Collected Steps per Second: 22,392.42214
Overall Steps per Second: 10,531.77793

Timestep Collection Time: 2.23379
Timestep Consumption Time: 2.51564
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.74944

Cumulative Model Updates: 309,856
Cumulative Timesteps: 2,584,164,840

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.76623
Policy Entropy: 2.43378
Value Function Loss: 0.02220

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.09139
Policy Update Magnitude: 0.49681
Value Function Update Magnitude: 0.67636

Collected Steps per Second: 22,578.78082
Overall Steps per Second: 10,804.36737

Timestep Collection Time: 2.21509
Timestep Consumption Time: 2.41397
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.62905

Cumulative Model Updates: 309,862
Cumulative Timesteps: 2,584,214,854

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2584214854...
Checkpoint 2584214854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.84978
Policy Entropy: 2.44831
Value Function Loss: 0.02206

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.09416
Policy Update Magnitude: 0.49476
Value Function Update Magnitude: 0.69366

Collected Steps per Second: 22,271.22591
Overall Steps per Second: 10,734.42199

Timestep Collection Time: 2.24532
Timestep Consumption Time: 2.41315
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.65847

Cumulative Model Updates: 309,868
Cumulative Timesteps: 2,584,264,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.93614
Policy Entropy: 2.46085
Value Function Loss: 0.02141

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.08379
Policy Update Magnitude: 0.49096
Value Function Update Magnitude: 0.69713

Collected Steps per Second: 22,379.09199
Overall Steps per Second: 10,530.34953

Timestep Collection Time: 2.23530
Timestep Consumption Time: 2.51516
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.75046

Cumulative Model Updates: 309,874
Cumulative Timesteps: 2,584,314,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2584314884...
Checkpoint 2584314884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.40483
Policy Entropy: 2.46947
Value Function Loss: 0.02093

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 0.48442
Value Function Update Magnitude: 0.69304

Collected Steps per Second: 22,292.47369
Overall Steps per Second: 10,608.75442

Timestep Collection Time: 2.24426
Timestep Consumption Time: 2.47166
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.71592

Cumulative Model Updates: 309,880
Cumulative Timesteps: 2,584,364,914

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.20504
Policy Entropy: 2.47502
Value Function Loss: 0.02057

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.09768
Policy Update Magnitude: 0.49817
Value Function Update Magnitude: 0.68405

Collected Steps per Second: 20,814.49004
Overall Steps per Second: 10,327.04122

Timestep Collection Time: 2.40227
Timestep Consumption Time: 2.43958
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.84185

Cumulative Model Updates: 309,886
Cumulative Timesteps: 2,584,414,916

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2584414916...
Checkpoint 2584414916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.91998
Policy Entropy: 2.46370
Value Function Loss: 0.02158

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.11655
Policy Update Magnitude: 0.49090
Value Function Update Magnitude: 0.67878

Collected Steps per Second: 21,246.42192
Overall Steps per Second: 10,487.71877

Timestep Collection Time: 2.35381
Timestep Consumption Time: 2.41463
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.76843

Cumulative Model Updates: 309,892
Cumulative Timesteps: 2,584,464,926

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.98828
Policy Entropy: 2.48308
Value Function Loss: 0.02121

Mean KL Divergence: 0.02178
SB3 Clip Fraction: 0.12811
Policy Update Magnitude: 0.46992
Value Function Update Magnitude: 0.67721

Collected Steps per Second: 21,801.12978
Overall Steps per Second: 10,454.03205

Timestep Collection Time: 2.29364
Timestep Consumption Time: 2.48958
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.78323

Cumulative Model Updates: 309,898
Cumulative Timesteps: 2,584,514,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2584514930...
Checkpoint 2584514930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.88721
Policy Entropy: 2.47408
Value Function Loss: 0.02137

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.12131
Policy Update Magnitude: 0.47336
Value Function Update Magnitude: 0.66946

Collected Steps per Second: 21,943.41810
Overall Steps per Second: 10,438.12381

Timestep Collection Time: 2.27904
Timestep Consumption Time: 2.51205
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.79109

Cumulative Model Updates: 309,904
Cumulative Timesteps: 2,584,564,940

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.35500
Policy Entropy: 2.46168
Value Function Loss: 0.02124

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.11113
Policy Update Magnitude: 0.49221
Value Function Update Magnitude: 0.65355

Collected Steps per Second: 22,083.61026
Overall Steps per Second: 10,818.29174

Timestep Collection Time: 2.26503
Timestep Consumption Time: 2.35862
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.62365

Cumulative Model Updates: 309,910
Cumulative Timesteps: 2,584,614,960

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2584614960...
Checkpoint 2584614960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.19332
Policy Entropy: 2.42811
Value Function Loss: 0.02081

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.10343
Policy Update Magnitude: 0.49402
Value Function Update Magnitude: 0.63990

Collected Steps per Second: 22,110.95877
Overall Steps per Second: 10,389.20065

Timestep Collection Time: 2.26250
Timestep Consumption Time: 2.55269
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.81519

Cumulative Model Updates: 309,916
Cumulative Timesteps: 2,584,664,986

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.36843
Policy Entropy: 2.43795
Value Function Loss: 0.02072

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.48335
Value Function Update Magnitude: 0.61880

Collected Steps per Second: 22,629.01720
Overall Steps per Second: 10,720.76083

Timestep Collection Time: 2.21070
Timestep Consumption Time: 2.45557
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.66627

Cumulative Model Updates: 309,922
Cumulative Timesteps: 2,584,715,012

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2584715012...
Checkpoint 2584715012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.04496
Policy Entropy: 2.44571
Value Function Loss: 0.02015

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.47632
Value Function Update Magnitude: 0.62140

Collected Steps per Second: 22,019.73201
Overall Steps per Second: 10,672.66985

Timestep Collection Time: 2.27178
Timestep Consumption Time: 2.41533
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.68711

Cumulative Model Updates: 309,928
Cumulative Timesteps: 2,584,765,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.95686
Policy Entropy: 2.44544
Value Function Loss: 0.02234

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.09429
Policy Update Magnitude: 0.48448
Value Function Update Magnitude: 0.63307

Collected Steps per Second: 22,297.97905
Overall Steps per Second: 10,577.66196

Timestep Collection Time: 2.24361
Timestep Consumption Time: 2.48598
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.72959

Cumulative Model Updates: 309,934
Cumulative Timesteps: 2,584,815,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2584815064...
Checkpoint 2584815064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.16967
Policy Entropy: 2.43855
Value Function Loss: 0.02211

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.09917
Policy Update Magnitude: 0.49345
Value Function Update Magnitude: 0.63684

Collected Steps per Second: 23,037.28414
Overall Steps per Second: 10,707.34490

Timestep Collection Time: 2.17135
Timestep Consumption Time: 2.50040
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.67175

Cumulative Model Updates: 309,940
Cumulative Timesteps: 2,584,865,086

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.28642
Policy Entropy: 2.45684
Value Function Loss: 0.02231

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.09524
Policy Update Magnitude: 0.48499
Value Function Update Magnitude: 0.62658

Collected Steps per Second: 22,627.95922
Overall Steps per Second: 10,734.25171

Timestep Collection Time: 2.20992
Timestep Consumption Time: 2.44862
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.65855

Cumulative Model Updates: 309,946
Cumulative Timesteps: 2,584,915,092

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2584915092...
Checkpoint 2584915092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.37491
Policy Entropy: 2.45611
Value Function Loss: 0.02208

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.09710
Policy Update Magnitude: 0.48467
Value Function Update Magnitude: 0.61851

Collected Steps per Second: 22,176.93577
Overall Steps per Second: 10,679.53924

Timestep Collection Time: 2.25468
Timestep Consumption Time: 2.42735
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.68204

Cumulative Model Updates: 309,952
Cumulative Timesteps: 2,584,965,094

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.23660
Policy Entropy: 2.45845
Value Function Loss: 0.02267

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.09648
Policy Update Magnitude: 0.47748
Value Function Update Magnitude: 0.63187

Collected Steps per Second: 21,505.13406
Overall Steps per Second: 10,515.23230

Timestep Collection Time: 2.32558
Timestep Consumption Time: 2.43056
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.75615

Cumulative Model Updates: 309,958
Cumulative Timesteps: 2,585,015,106

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2585015106...
Checkpoint 2585015106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.33345
Policy Entropy: 2.43764
Value Function Loss: 0.02208

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.48375
Value Function Update Magnitude: 0.66450

Collected Steps per Second: 21,775.66415
Overall Steps per Second: 10,602.51852

Timestep Collection Time: 2.29651
Timestep Consumption Time: 2.42011
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.71662

Cumulative Model Updates: 309,964
Cumulative Timesteps: 2,585,065,114

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.89875
Policy Entropy: 2.44643
Value Function Loss: 0.02054

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.48440
Value Function Update Magnitude: 0.66894

Collected Steps per Second: 21,876.63805
Overall Steps per Second: 10,416.49184

Timestep Collection Time: 2.28664
Timestep Consumption Time: 2.51574
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.80238

Cumulative Model Updates: 309,970
Cumulative Timesteps: 2,585,115,138

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2585115138...
Checkpoint 2585115138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.65367
Policy Entropy: 2.45896
Value Function Loss: 0.01913

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.09578
Policy Update Magnitude: 0.48736
Value Function Update Magnitude: 0.65721

Collected Steps per Second: 22,015.51828
Overall Steps per Second: 10,686.81929

Timestep Collection Time: 2.27158
Timestep Consumption Time: 2.40802
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.67960

Cumulative Model Updates: 309,976
Cumulative Timesteps: 2,585,165,148

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.06282
Policy Entropy: 2.46773
Value Function Loss: 0.01902

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.09841
Policy Update Magnitude: 0.49152
Value Function Update Magnitude: 0.68106

Collected Steps per Second: 22,301.07133
Overall Steps per Second: 10,499.75041

Timestep Collection Time: 2.24231
Timestep Consumption Time: 2.52028
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.76259

Cumulative Model Updates: 309,982
Cumulative Timesteps: 2,585,215,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2585215154...
Checkpoint 2585215154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.35678
Policy Entropy: 2.46458
Value Function Loss: 0.01939

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.09201
Policy Update Magnitude: 0.48463
Value Function Update Magnitude: 0.67968

Collected Steps per Second: 23,025.75108
Overall Steps per Second: 10,731.19274

Timestep Collection Time: 2.17218
Timestep Consumption Time: 2.48863
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.66081

Cumulative Model Updates: 309,988
Cumulative Timesteps: 2,585,265,170

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.48742
Policy Entropy: 2.44847
Value Function Loss: 0.02075

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.10276
Policy Update Magnitude: 0.48785
Value Function Update Magnitude: 0.67251

Collected Steps per Second: 22,729.41050
Overall Steps per Second: 10,744.33958

Timestep Collection Time: 2.20067
Timestep Consumption Time: 2.45480
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.65547

Cumulative Model Updates: 309,994
Cumulative Timesteps: 2,585,315,190

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2585315190...
Checkpoint 2585315190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.36557
Policy Entropy: 2.46984
Value Function Loss: 0.02030

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.10450
Policy Update Magnitude: 0.48108
Value Function Update Magnitude: 0.68129

Collected Steps per Second: 22,317.60377
Overall Steps per Second: 10,610.42487

Timestep Collection Time: 2.24101
Timestep Consumption Time: 2.47265
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.71367

Cumulative Model Updates: 310,000
Cumulative Timesteps: 2,585,365,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.74562
Policy Entropy: 2.46593
Value Function Loss: 0.02054

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.10041
Policy Update Magnitude: 0.48021
Value Function Update Magnitude: 0.68284

Collected Steps per Second: 22,529.80469
Overall Steps per Second: 10,899.08208

Timestep Collection Time: 2.21973
Timestep Consumption Time: 2.36873
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.58846

Cumulative Model Updates: 310,006
Cumulative Timesteps: 2,585,415,214

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2585415214...
Checkpoint 2585415214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.98162
Policy Entropy: 2.46837
Value Function Loss: 0.02002

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.48191
Value Function Update Magnitude: 0.67167

Collected Steps per Second: 22,291.88355
Overall Steps per Second: 10,713.05859

Timestep Collection Time: 2.24378
Timestep Consumption Time: 2.42511
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.66888

Cumulative Model Updates: 310,012
Cumulative Timesteps: 2,585,465,232

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.38136
Policy Entropy: 2.46114
Value Function Loss: 0.02101

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.10402
Policy Update Magnitude: 0.47444
Value Function Update Magnitude: 0.66909

Collected Steps per Second: 21,982.21366
Overall Steps per Second: 10,459.37639

Timestep Collection Time: 2.27557
Timestep Consumption Time: 2.50694
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.78250

Cumulative Model Updates: 310,018
Cumulative Timesteps: 2,585,515,254

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2585515254...
Checkpoint 2585515254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.41799
Policy Entropy: 2.47725
Value Function Loss: 0.02202

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.47584
Value Function Update Magnitude: 0.64977

Collected Steps per Second: 21,276.38027
Overall Steps per Second: 10,532.90047

Timestep Collection Time: 2.35012
Timestep Consumption Time: 2.39710
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.74722

Cumulative Model Updates: 310,024
Cumulative Timesteps: 2,585,565,256

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.80613
Policy Entropy: 2.48701
Value Function Loss: 0.02291

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.48795
Value Function Update Magnitude: 0.66478

Collected Steps per Second: 21,939.80984
Overall Steps per Second: 10,509.10755

Timestep Collection Time: 2.28033
Timestep Consumption Time: 2.48030
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.76063

Cumulative Model Updates: 310,030
Cumulative Timesteps: 2,585,615,286

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2585615286...
Checkpoint 2585615286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.19971
Policy Entropy: 2.47233
Value Function Loss: 0.02277

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.09412
Policy Update Magnitude: 0.50334
Value Function Update Magnitude: 0.69188

Collected Steps per Second: 22,350.36040
Overall Steps per Second: 10,701.97640

Timestep Collection Time: 2.23817
Timestep Consumption Time: 2.43610
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.67428

Cumulative Model Updates: 310,036
Cumulative Timesteps: 2,585,665,310

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.36144
Policy Entropy: 2.45257
Value Function Loss: 0.02193

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.09048
Policy Update Magnitude: 0.49616
Value Function Update Magnitude: 0.69449

Collected Steps per Second: 22,551.76058
Overall Steps per Second: 10,572.66725

Timestep Collection Time: 2.21712
Timestep Consumption Time: 2.51205
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.72918

Cumulative Model Updates: 310,042
Cumulative Timesteps: 2,585,715,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2585715310...
Checkpoint 2585715310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.28979
Policy Entropy: 2.46623
Value Function Loss: 0.02205

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.09454
Policy Update Magnitude: 0.49451
Value Function Update Magnitude: 0.69088

Collected Steps per Second: 22,272.12366
Overall Steps per Second: 10,530.08578

Timestep Collection Time: 2.24496
Timestep Consumption Time: 2.50334
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.74830

Cumulative Model Updates: 310,048
Cumulative Timesteps: 2,585,765,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.27721
Policy Entropy: 2.49002
Value Function Loss: 0.02093

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.08931
Policy Update Magnitude: 0.48446
Value Function Update Magnitude: 0.67002

Collected Steps per Second: 22,575.34241
Overall Steps per Second: 10,780.93666

Timestep Collection Time: 2.21516
Timestep Consumption Time: 2.42340
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.63856

Cumulative Model Updates: 310,054
Cumulative Timesteps: 2,585,815,318

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2585815318...
Checkpoint 2585815318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.29876
Policy Entropy: 2.49622
Value Function Loss: 0.02204

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.09003
Policy Update Magnitude: 0.48914
Value Function Update Magnitude: 0.64858

Collected Steps per Second: 22,679.02437
Overall Steps per Second: 10,686.64607

Timestep Collection Time: 2.20521
Timestep Consumption Time: 2.47465
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.67986

Cumulative Model Updates: 310,060
Cumulative Timesteps: 2,585,865,330

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.27317
Policy Entropy: 2.49210
Value Function Loss: 0.02013

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.09446
Policy Update Magnitude: 0.47901
Value Function Update Magnitude: 0.64466

Collected Steps per Second: 22,527.59955
Overall Steps per Second: 10,621.92938

Timestep Collection Time: 2.22074
Timestep Consumption Time: 2.48914
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.70988

Cumulative Model Updates: 310,066
Cumulative Timesteps: 2,585,915,358

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2585915358...
Checkpoint 2585915358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.27757
Policy Entropy: 2.48588
Value Function Loss: 0.01956

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.09218
Policy Update Magnitude: 0.48594
Value Function Update Magnitude: 0.62290

Collected Steps per Second: 22,256.98228
Overall Steps per Second: 10,534.32200

Timestep Collection Time: 2.24658
Timestep Consumption Time: 2.50000
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.74658

Cumulative Model Updates: 310,072
Cumulative Timesteps: 2,585,965,360

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.19380
Policy Entropy: 2.49374
Value Function Loss: 0.01836

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.09557
Policy Update Magnitude: 0.47825
Value Function Update Magnitude: 0.58726

Collected Steps per Second: 22,051.60037
Overall Steps per Second: 10,570.88284

Timestep Collection Time: 2.26813
Timestep Consumption Time: 2.46335
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.73149

Cumulative Model Updates: 310,078
Cumulative Timesteps: 2,586,015,376

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2586015376...
Checkpoint 2586015376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.67502
Policy Entropy: 2.48898
Value Function Loss: 0.01929

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.08442
Policy Update Magnitude: 0.47762
Value Function Update Magnitude: 0.58863

Collected Steps per Second: 21,858.87663
Overall Steps per Second: 10,657.84430

Timestep Collection Time: 2.28868
Timestep Consumption Time: 2.40533
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.69401

Cumulative Model Updates: 310,084
Cumulative Timesteps: 2,586,065,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.62212
Policy Entropy: 2.47038
Value Function Loss: 0.02108

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.48358
Value Function Update Magnitude: 0.60819

Collected Steps per Second: 22,305.92357
Overall Steps per Second: 10,708.30361

Timestep Collection Time: 2.24236
Timestep Consumption Time: 2.42859
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.67095

Cumulative Model Updates: 310,090
Cumulative Timesteps: 2,586,115,422

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2586115422...
Checkpoint 2586115422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.54706
Policy Entropy: 2.46347
Value Function Loss: 0.02047

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.09569
Policy Update Magnitude: 0.47048
Value Function Update Magnitude: 0.61640

Collected Steps per Second: 21,792.16701
Overall Steps per Second: 10,582.19347

Timestep Collection Time: 2.29550
Timestep Consumption Time: 2.43168
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.72719

Cumulative Model Updates: 310,096
Cumulative Timesteps: 2,586,165,446

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.64269
Policy Entropy: 2.46040
Value Function Loss: 0.02166

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.08860
Policy Update Magnitude: 0.48297
Value Function Update Magnitude: 0.61308

Collected Steps per Second: 21,620.89352
Overall Steps per Second: 10,512.08676

Timestep Collection Time: 2.31332
Timestep Consumption Time: 2.44463
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.75795

Cumulative Model Updates: 310,102
Cumulative Timesteps: 2,586,215,462

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2586215462...
Checkpoint 2586215462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.63789
Policy Entropy: 2.45094
Value Function Loss: 0.02106

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.09127
Policy Update Magnitude: 0.49329
Value Function Update Magnitude: 0.61932

Collected Steps per Second: 21,576.04144
Overall Steps per Second: 10,621.63514

Timestep Collection Time: 2.31822
Timestep Consumption Time: 2.39085
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.70907

Cumulative Model Updates: 310,108
Cumulative Timesteps: 2,586,265,480

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.41716
Policy Entropy: 2.44866
Value Function Loss: 0.02198

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.09254
Policy Update Magnitude: 0.49605
Value Function Update Magnitude: 0.65442

Collected Steps per Second: 21,645.19776
Overall Steps per Second: 10,437.38795

Timestep Collection Time: 2.31054
Timestep Consumption Time: 2.48108
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.79162

Cumulative Model Updates: 310,114
Cumulative Timesteps: 2,586,315,492

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2586315492...
Checkpoint 2586315492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.84222
Policy Entropy: 2.40901
Value Function Loss: 0.02137

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.09039
Policy Update Magnitude: 0.50464
Value Function Update Magnitude: 0.68046

Collected Steps per Second: 22,263.59788
Overall Steps per Second: 10,624.64249

Timestep Collection Time: 2.24582
Timestep Consumption Time: 2.46022
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.70604

Cumulative Model Updates: 310,120
Cumulative Timesteps: 2,586,365,492

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.35751
Policy Entropy: 2.43074
Value Function Loss: 0.02029

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.10151
Policy Update Magnitude: 0.49954
Value Function Update Magnitude: 0.68585

Collected Steps per Second: 22,375.96160
Overall Steps per Second: 10,632.44470

Timestep Collection Time: 2.23570
Timestep Consumption Time: 2.46933
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.70503

Cumulative Model Updates: 310,126
Cumulative Timesteps: 2,586,415,518

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2586415518...
Checkpoint 2586415518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.47320
Policy Entropy: 2.44761
Value Function Loss: 0.01964

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.48933
Value Function Update Magnitude: 0.66391

Collected Steps per Second: 22,095.87325
Overall Steps per Second: 10,544.42684

Timestep Collection Time: 2.26296
Timestep Consumption Time: 2.47907
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.74203

Cumulative Model Updates: 310,132
Cumulative Timesteps: 2,586,465,520

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.58221
Policy Entropy: 2.47601
Value Function Loss: 0.01949

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.09473
Policy Update Magnitude: 0.48321
Value Function Update Magnitude: 0.67083

Collected Steps per Second: 23,237.17316
Overall Steps per Second: 10,845.18161

Timestep Collection Time: 2.15207
Timestep Consumption Time: 2.45901
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.61108

Cumulative Model Updates: 310,138
Cumulative Timesteps: 2,586,515,528

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2586515528...
Checkpoint 2586515528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.48457
Policy Entropy: 2.46674
Value Function Loss: 0.02005

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.10417
Policy Update Magnitude: 0.47679
Value Function Update Magnitude: 0.68560

Collected Steps per Second: 22,438.43928
Overall Steps per Second: 10,656.16486

Timestep Collection Time: 2.22948
Timestep Consumption Time: 2.46508
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.69456

Cumulative Model Updates: 310,144
Cumulative Timesteps: 2,586,565,554

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.21248
Policy Entropy: 2.44566
Value Function Loss: 0.02084

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.10042
Policy Update Magnitude: 0.49313
Value Function Update Magnitude: 0.67569

Collected Steps per Second: 22,378.55510
Overall Steps per Second: 10,647.47470

Timestep Collection Time: 2.23482
Timestep Consumption Time: 2.46226
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.69708

Cumulative Model Updates: 310,150
Cumulative Timesteps: 2,586,615,566

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2586615566...
Checkpoint 2586615566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.30274
Policy Entropy: 2.42645
Value Function Loss: 0.02111

Mean KL Divergence: 0.02984
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.49895
Value Function Update Magnitude: 0.66975

Collected Steps per Second: 21,709.15975
Overall Steps per Second: 10,620.92789

Timestep Collection Time: 2.30428
Timestep Consumption Time: 2.40567
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.70995

Cumulative Model Updates: 310,156
Cumulative Timesteps: 2,586,665,590

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.00159
Policy Entropy: 2.42655
Value Function Loss: 0.02168

Mean KL Divergence: 0.04280
SB3 Clip Fraction: 0.10263
Policy Update Magnitude: 0.49267
Value Function Update Magnitude: 0.68863

Collected Steps per Second: 22,290.63555
Overall Steps per Second: 10,705.72212

Timestep Collection Time: 2.24381
Timestep Consumption Time: 2.42808
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.67189

Cumulative Model Updates: 310,162
Cumulative Timesteps: 2,586,715,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2586715606...
Checkpoint 2586715606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.16528
Policy Entropy: 2.43109
Value Function Loss: 0.02098

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.10330
Policy Update Magnitude: 0.48403
Value Function Update Magnitude: 0.68899

Collected Steps per Second: 21,775.29062
Overall Steps per Second: 10,587.68961

Timestep Collection Time: 2.29636
Timestep Consumption Time: 2.42648
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.72284

Cumulative Model Updates: 310,168
Cumulative Timesteps: 2,586,765,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.89657
Policy Entropy: 2.43868
Value Function Loss: 0.02052

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.11329
Policy Update Magnitude: 0.48130
Value Function Update Magnitude: 0.66952

Collected Steps per Second: 21,932.62184
Overall Steps per Second: 10,507.69871

Timestep Collection Time: 2.28135
Timestep Consumption Time: 2.48049
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.76184

Cumulative Model Updates: 310,174
Cumulative Timesteps: 2,586,815,646

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2586815646...
Checkpoint 2586815646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.27143
Policy Entropy: 2.42150
Value Function Loss: 0.02065

Mean KL Divergence: 0.02474
SB3 Clip Fraction: 0.14129
Policy Update Magnitude: 0.46541
Value Function Update Magnitude: 0.66459

Collected Steps per Second: 21,623.28683
Overall Steps per Second: 10,686.00205

Timestep Collection Time: 2.31251
Timestep Consumption Time: 2.36689
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.67939

Cumulative Model Updates: 310,180
Cumulative Timesteps: 2,586,865,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.97072
Policy Entropy: 2.43239
Value Function Loss: 0.02056

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.48258
Value Function Update Magnitude: 0.65777

Collected Steps per Second: 22,435.93366
Overall Steps per Second: 10,542.87213

Timestep Collection Time: 2.22955
Timestep Consumption Time: 2.51508
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.74463

Cumulative Model Updates: 310,186
Cumulative Timesteps: 2,586,915,672

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2586915672...
Checkpoint 2586915672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.14656
Policy Entropy: 2.42121
Value Function Loss: 0.02131

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.11666
Policy Update Magnitude: 0.49728
Value Function Update Magnitude: 0.65528

Collected Steps per Second: 20,966.92016
Overall Steps per Second: 10,065.40419

Timestep Collection Time: 2.38509
Timestep Consumption Time: 2.58321
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.96831

Cumulative Model Updates: 310,192
Cumulative Timesteps: 2,586,965,680

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.55566
Policy Entropy: 2.41129
Value Function Loss: 0.02163

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.11727
Policy Update Magnitude: 0.49034
Value Function Update Magnitude: 0.65163

Collected Steps per Second: 21,960.57151
Overall Steps per Second: 10,484.12007

Timestep Collection Time: 2.27772
Timestep Consumption Time: 2.49331
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.77103

Cumulative Model Updates: 310,198
Cumulative Timesteps: 2,587,015,700

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2587015700...
Checkpoint 2587015700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.13406
Policy Entropy: 2.39859
Value Function Loss: 0.02215

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.11490
Policy Update Magnitude: 0.48419
Value Function Update Magnitude: 0.63691

Collected Steps per Second: 22,141.28397
Overall Steps per Second: 10,686.81929

Timestep Collection Time: 2.25868
Timestep Consumption Time: 2.42092
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.67960

Cumulative Model Updates: 310,204
Cumulative Timesteps: 2,587,065,710

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.30940
Policy Entropy: 2.40536
Value Function Loss: 0.02267

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.10981
Policy Update Magnitude: 0.51151
Value Function Update Magnitude: 0.64851

Collected Steps per Second: 23,082.67175
Overall Steps per Second: 10,874.02729

Timestep Collection Time: 2.16639
Timestep Consumption Time: 2.43228
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.59866

Cumulative Model Updates: 310,210
Cumulative Timesteps: 2,587,115,716

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2587115716...
Checkpoint 2587115716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.56493
Policy Entropy: 2.40816
Value Function Loss: 0.02147

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 0.51023
Value Function Update Magnitude: 0.67466

Collected Steps per Second: 22,188.22669
Overall Steps per Second: 10,711.92476

Timestep Collection Time: 2.25435
Timestep Consumption Time: 2.41521
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.66956

Cumulative Model Updates: 310,216
Cumulative Timesteps: 2,587,165,736

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.75612
Policy Entropy: 2.42340
Value Function Loss: 0.02145

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.09043
Policy Update Magnitude: 0.50318
Value Function Update Magnitude: 0.67638

Collected Steps per Second: 22,009.39900
Overall Steps per Second: 10,533.34879

Timestep Collection Time: 2.27303
Timestep Consumption Time: 2.47646
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.74949

Cumulative Model Updates: 310,222
Cumulative Timesteps: 2,587,215,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2587215764...
Checkpoint 2587215764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.93355
Policy Entropy: 2.41808
Value Function Loss: 0.02138

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.08706
Policy Update Magnitude: 0.49788
Value Function Update Magnitude: 0.65884

Collected Steps per Second: 22,077.55601
Overall Steps per Second: 10,693.32738

Timestep Collection Time: 2.26592
Timestep Consumption Time: 2.41232
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.67824

Cumulative Model Updates: 310,228
Cumulative Timesteps: 2,587,265,790

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.69260
Policy Entropy: 2.44631
Value Function Loss: 0.02069

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.09788
Policy Update Magnitude: 0.49003
Value Function Update Magnitude: 0.66428

Collected Steps per Second: 22,106.95415
Overall Steps per Second: 10,666.77927

Timestep Collection Time: 2.26246
Timestep Consumption Time: 2.42649
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.68895

Cumulative Model Updates: 310,234
Cumulative Timesteps: 2,587,315,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2587315806...
Checkpoint 2587315806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.35921
Policy Entropy: 2.45905
Value Function Loss: 0.01983

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.11665
Policy Update Magnitude: 0.45731
Value Function Update Magnitude: 0.66207

Collected Steps per Second: 21,809.84082
Overall Steps per Second: 10,448.08328

Timestep Collection Time: 2.29273
Timestep Consumption Time: 2.49322
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.78595

Cumulative Model Updates: 310,240
Cumulative Timesteps: 2,587,365,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.01104
Policy Entropy: 2.45925
Value Function Loss: 0.01943

Mean KL Divergence: 0.02417
SB3 Clip Fraction: 0.13041
Policy Update Magnitude: 0.45805
Value Function Update Magnitude: 0.64690

Collected Steps per Second: 22,314.00376
Overall Steps per Second: 10,702.63240

Timestep Collection Time: 2.24182
Timestep Consumption Time: 2.43217
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.67399

Cumulative Model Updates: 310,246
Cumulative Timesteps: 2,587,415,834

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2587415834...
Checkpoint 2587415834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.62140
Policy Entropy: 2.43788
Value Function Loss: 0.02094

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.12487
Policy Update Magnitude: 0.46635
Value Function Update Magnitude: 0.64183

Collected Steps per Second: 21,815.97471
Overall Steps per Second: 10,612.47737

Timestep Collection Time: 2.29309
Timestep Consumption Time: 2.42079
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.71389

Cumulative Model Updates: 310,252
Cumulative Timesteps: 2,587,465,860

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.02516
Policy Entropy: 2.43562
Value Function Loss: 0.02042

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.10922
Policy Update Magnitude: 0.47435
Value Function Update Magnitude: 0.63965

Collected Steps per Second: 22,006.17394
Overall Steps per Second: 10,536.82110

Timestep Collection Time: 2.27291
Timestep Consumption Time: 2.47406
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.74697

Cumulative Model Updates: 310,258
Cumulative Timesteps: 2,587,515,878

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2587515878...
Checkpoint 2587515878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.46574
Policy Entropy: 2.44989
Value Function Loss: 0.02044

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.08915
Policy Update Magnitude: 0.46715
Value Function Update Magnitude: 0.62208

Collected Steps per Second: 22,419.71163
Overall Steps per Second: 10,590.66648

Timestep Collection Time: 2.23098
Timestep Consumption Time: 2.49185
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.72284

Cumulative Model Updates: 310,264
Cumulative Timesteps: 2,587,565,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.75218
Policy Entropy: 2.44519
Value Function Loss: 0.02163

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.08807
Policy Update Magnitude: 0.48062
Value Function Update Magnitude: 0.61836

Collected Steps per Second: 22,453.94665
Overall Steps per Second: 10,553.76590

Timestep Collection Time: 2.22749
Timestep Consumption Time: 2.51167
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.73916

Cumulative Model Updates: 310,270
Cumulative Timesteps: 2,587,615,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2587615912...
Checkpoint 2587615912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.56474
Policy Entropy: 2.43131
Value Function Loss: 0.02224

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.08791
Policy Update Magnitude: 0.49178
Value Function Update Magnitude: 0.64277

Collected Steps per Second: 22,212.18892
Overall Steps per Second: 10,524.94875

Timestep Collection Time: 2.25228
Timestep Consumption Time: 2.50100
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.75328

Cumulative Model Updates: 310,276
Cumulative Timesteps: 2,587,665,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.65481
Policy Entropy: 2.41740
Value Function Loss: 0.02158

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.09989
Policy Update Magnitude: 0.50001
Value Function Update Magnitude: 0.66646

Collected Steps per Second: 22,622.22032
Overall Steps per Second: 10,965.04087

Timestep Collection Time: 2.21128
Timestep Consumption Time: 2.35086
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.56214

Cumulative Model Updates: 310,282
Cumulative Timesteps: 2,587,715,964

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2587715964...
Checkpoint 2587715964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.67264
Policy Entropy: 2.43444
Value Function Loss: 0.02216

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.09808
Policy Update Magnitude: 0.50368
Value Function Update Magnitude: 0.68182

Collected Steps per Second: 22,355.45731
Overall Steps per Second: 10,625.23409

Timestep Collection Time: 2.23695
Timestep Consumption Time: 2.46958
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.70653

Cumulative Model Updates: 310,288
Cumulative Timesteps: 2,587,765,972

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.14792
Policy Entropy: 2.42680
Value Function Loss: 0.02070

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.09555
Policy Update Magnitude: 0.50583
Value Function Update Magnitude: 0.69203

Collected Steps per Second: 22,434.16374
Overall Steps per Second: 10,583.47507

Timestep Collection Time: 2.22901
Timestep Consumption Time: 2.49590
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.72491

Cumulative Model Updates: 310,294
Cumulative Timesteps: 2,587,815,978

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2587815978...
Checkpoint 2587815978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.71167
Policy Entropy: 2.42937
Value Function Loss: 0.02075

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.49478
Value Function Update Magnitude: 0.68398

Collected Steps per Second: 21,761.66795
Overall Steps per Second: 10,490.04651

Timestep Collection Time: 2.29762
Timestep Consumption Time: 2.46881
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.76642

Cumulative Model Updates: 310,300
Cumulative Timesteps: 2,587,865,978

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.25726
Policy Entropy: 2.44007
Value Function Loss: 0.02000

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.08796
Policy Update Magnitude: 0.49724
Value Function Update Magnitude: 0.67711

Collected Steps per Second: 22,255.64445
Overall Steps per Second: 10,861.69914

Timestep Collection Time: 2.24734
Timestep Consumption Time: 2.35746
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.60480

Cumulative Model Updates: 310,306
Cumulative Timesteps: 2,587,915,994

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2587915994...
Checkpoint 2587915994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.43465
Policy Entropy: 2.43381
Value Function Loss: 0.01975

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.08989
Policy Update Magnitude: 0.49174
Value Function Update Magnitude: 0.67088

Collected Steps per Second: 21,311.67327
Overall Steps per Second: 10,304.61294

Timestep Collection Time: 2.34641
Timestep Consumption Time: 2.50636
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.85278

Cumulative Model Updates: 310,312
Cumulative Timesteps: 2,587,966,000

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.62896
Policy Entropy: 2.42048
Value Function Loss: 0.01980

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.09345
Policy Update Magnitude: 0.49505
Value Function Update Magnitude: 0.68280

Collected Steps per Second: 22,273.51989
Overall Steps per Second: 10,503.28500

Timestep Collection Time: 2.24572
Timestep Consumption Time: 2.51660
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.76232

Cumulative Model Updates: 310,318
Cumulative Timesteps: 2,588,016,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2588016020...
Checkpoint 2588016020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.93178
Policy Entropy: 2.38969
Value Function Loss: 0.01996

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.08822
Policy Update Magnitude: 0.50085
Value Function Update Magnitude: 0.68664

Collected Steps per Second: 21,765.27267
Overall Steps per Second: 10,576.08314

Timestep Collection Time: 2.29788
Timestep Consumption Time: 2.43109
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.72897

Cumulative Model Updates: 310,324
Cumulative Timesteps: 2,588,066,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.01583
Policy Entropy: 2.38824
Value Function Loss: 0.02105

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.10488
Policy Update Magnitude: 0.49425
Value Function Update Magnitude: 0.67883

Collected Steps per Second: 22,144.24088
Overall Steps per Second: 10,437.31211

Timestep Collection Time: 2.25837
Timestep Consumption Time: 2.53309
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.79146

Cumulative Model Updates: 310,330
Cumulative Timesteps: 2,588,116,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2588116044...
Checkpoint 2588116044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.34950
Policy Entropy: 2.40455
Value Function Loss: 0.02176

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.11464
Policy Update Magnitude: 0.50837
Value Function Update Magnitude: 0.68745

Collected Steps per Second: 22,277.77011
Overall Steps per Second: 10,577.46440

Timestep Collection Time: 2.24439
Timestep Consumption Time: 2.48264
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.72703

Cumulative Model Updates: 310,336
Cumulative Timesteps: 2,588,166,044

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.73219
Policy Entropy: 2.42024
Value Function Loss: 0.02197

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.51014
Value Function Update Magnitude: 0.70586

Collected Steps per Second: 21,419.56976
Overall Steps per Second: 10,479.79289

Timestep Collection Time: 2.33441
Timestep Consumption Time: 2.43687
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.77128

Cumulative Model Updates: 310,342
Cumulative Timesteps: 2,588,216,046

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2588216046...
Checkpoint 2588216046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.61065
Policy Entropy: 2.41916
Value Function Loss: 0.02162

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.10587
Policy Update Magnitude: 0.51504
Value Function Update Magnitude: 0.70825

Collected Steps per Second: 21,950.61117
Overall Steps per Second: 10,688.35790

Timestep Collection Time: 2.27848
Timestep Consumption Time: 2.40082
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.67930

Cumulative Model Updates: 310,348
Cumulative Timesteps: 2,588,266,060

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.48566
Policy Entropy: 2.40151
Value Function Loss: 0.02156

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.10078
Policy Update Magnitude: 0.49490
Value Function Update Magnitude: 0.67603

Collected Steps per Second: 22,555.27556
Overall Steps per Second: 10,597.57425

Timestep Collection Time: 2.21704
Timestep Consumption Time: 2.50158
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.71863

Cumulative Model Updates: 310,354
Cumulative Timesteps: 2,588,316,066

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2588316066...
Checkpoint 2588316066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.24130
Policy Entropy: 2.39658
Value Function Loss: 0.02268

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.10760
Policy Update Magnitude: 0.49632
Value Function Update Magnitude: 0.66049

Collected Steps per Second: 22,352.31568
Overall Steps per Second: 10,483.45369

Timestep Collection Time: 2.23690
Timestep Consumption Time: 2.53252
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.76942

Cumulative Model Updates: 310,360
Cumulative Timesteps: 2,588,366,066

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.34703
Policy Entropy: 2.39090
Value Function Loss: 0.02147

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.10525
Policy Update Magnitude: 0.49784
Value Function Update Magnitude: 0.67493

Collected Steps per Second: 22,168.78496
Overall Steps per Second: 10,515.10695

Timestep Collection Time: 2.25615
Timestep Consumption Time: 2.50044
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.75659

Cumulative Model Updates: 310,366
Cumulative Timesteps: 2,588,416,082

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2588416082...
Checkpoint 2588416082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.65101
Policy Entropy: 2.40465
Value Function Loss: 0.02068

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.49023
Value Function Update Magnitude: 0.65722

Collected Steps per Second: 22,296.71596
Overall Steps per Second: 10,761.78050

Timestep Collection Time: 2.24365
Timestep Consumption Time: 2.40484
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.64849

Cumulative Model Updates: 310,372
Cumulative Timesteps: 2,588,466,108

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.11874
Policy Entropy: 2.42125
Value Function Loss: 0.02018

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.09417
Policy Update Magnitude: 0.48295
Value Function Update Magnitude: 0.64294

Collected Steps per Second: 22,236.53865
Overall Steps per Second: 10,658.89458

Timestep Collection Time: 2.24963
Timestep Consumption Time: 2.44354
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.69317

Cumulative Model Updates: 310,378
Cumulative Timesteps: 2,588,516,132

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2588516132...
Checkpoint 2588516132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.38474
Policy Entropy: 2.42788
Value Function Loss: 0.02104

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.09063
Policy Update Magnitude: 0.48725
Value Function Update Magnitude: 0.64679

Collected Steps per Second: 21,486.71997
Overall Steps per Second: 10,361.09785

Timestep Collection Time: 2.32720
Timestep Consumption Time: 2.49892
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.82613

Cumulative Model Updates: 310,384
Cumulative Timesteps: 2,588,566,136

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.47011
Policy Entropy: 2.43018
Value Function Loss: 0.02119

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.09016
Policy Update Magnitude: 0.48049
Value Function Update Magnitude: 0.66419

Collected Steps per Second: 21,625.12910
Overall Steps per Second: 10,444.91409

Timestep Collection Time: 2.31351
Timestep Consumption Time: 2.47638
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.78989

Cumulative Model Updates: 310,390
Cumulative Timesteps: 2,588,616,166

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2588616166...
Checkpoint 2588616166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.27967
Policy Entropy: 2.39883
Value Function Loss: 0.02142

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.09428
Policy Update Magnitude: 0.48926
Value Function Update Magnitude: 0.66559

Collected Steps per Second: 22,065.10981
Overall Steps per Second: 10,667.34255

Timestep Collection Time: 2.26602
Timestep Consumption Time: 2.42118
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.68720

Cumulative Model Updates: 310,396
Cumulative Timesteps: 2,588,666,166

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.17127
Policy Entropy: 2.37210
Value Function Loss: 0.02172

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.09912
Policy Update Magnitude: 0.50044
Value Function Update Magnitude: 0.66481

Collected Steps per Second: 22,509.45402
Overall Steps per Second: 10,393.56819

Timestep Collection Time: 2.22218
Timestep Consumption Time: 2.59041
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.81259

Cumulative Model Updates: 310,402
Cumulative Timesteps: 2,588,716,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2588716186...
Checkpoint 2588716186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.24149
Policy Entropy: 2.37579
Value Function Loss: 0.02230

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.09719
Policy Update Magnitude: 0.49479
Value Function Update Magnitude: 0.67522

Collected Steps per Second: 22,428.87711
Overall Steps per Second: 10,612.13405

Timestep Collection Time: 2.23043
Timestep Consumption Time: 2.48361
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.71404

Cumulative Model Updates: 310,408
Cumulative Timesteps: 2,588,766,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.01737
Policy Entropy: 2.39852
Value Function Loss: 0.02172

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.09167
Policy Update Magnitude: 0.48828
Value Function Update Magnitude: 0.69372

Collected Steps per Second: 22,179.45953
Overall Steps per Second: 10,544.45186

Timestep Collection Time: 2.25560
Timestep Consumption Time: 2.48889
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.74449

Cumulative Model Updates: 310,414
Cumulative Timesteps: 2,588,816,240

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2588816240...
Checkpoint 2588816240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.12578
Policy Entropy: 2.44499
Value Function Loss: 0.01994

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.09048
Policy Update Magnitude: 0.48534
Value Function Update Magnitude: 0.71736

Collected Steps per Second: 22,430.80197
Overall Steps per Second: 10,926.92884

Timestep Collection Time: 2.23024
Timestep Consumption Time: 2.34799
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.57823

Cumulative Model Updates: 310,420
Cumulative Timesteps: 2,588,866,266

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.16926
Policy Entropy: 2.41822
Value Function Loss: 0.01935

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.09249
Policy Update Magnitude: 0.48928
Value Function Update Magnitude: 0.70975

Collected Steps per Second: 22,219.03619
Overall Steps per Second: 10,571.71338

Timestep Collection Time: 2.25149
Timestep Consumption Time: 2.48057
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.73206

Cumulative Model Updates: 310,426
Cumulative Timesteps: 2,588,916,292

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2588916292...
Checkpoint 2588916292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.23944
Policy Entropy: 2.41007
Value Function Loss: 0.01950

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.09847
Policy Update Magnitude: 0.47880
Value Function Update Magnitude: 0.68580

Collected Steps per Second: 22,359.02611
Overall Steps per Second: 10,632.82710

Timestep Collection Time: 2.23704
Timestep Consumption Time: 2.46707
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.70411

Cumulative Model Updates: 310,432
Cumulative Timesteps: 2,588,966,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.42438
Policy Entropy: 2.38457
Value Function Loss: 0.02079

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.09129
Policy Update Magnitude: 0.47695
Value Function Update Magnitude: 0.66277

Collected Steps per Second: 22,204.17577
Overall Steps per Second: 10,558.23919

Timestep Collection Time: 2.25246
Timestep Consumption Time: 2.48450
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.73696

Cumulative Model Updates: 310,438
Cumulative Timesteps: 2,589,016,324

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2589016324...
Checkpoint 2589016324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.61167
Policy Entropy: 2.40690
Value Function Loss: 0.02070

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.09328
Policy Update Magnitude: 0.47265
Value Function Update Magnitude: 0.65921

Collected Steps per Second: 22,102.81445
Overall Steps per Second: 10,733.74280

Timestep Collection Time: 2.26315
Timestep Consumption Time: 2.39711
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.66026

Cumulative Model Updates: 310,444
Cumulative Timesteps: 2,589,066,346

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.55209
Policy Entropy: 2.40633
Value Function Loss: 0.02048

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.08712
Policy Update Magnitude: 0.47821
Value Function Update Magnitude: 0.66856

Collected Steps per Second: 22,267.65264
Overall Steps per Second: 10,691.66937

Timestep Collection Time: 2.24676
Timestep Consumption Time: 2.43259
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.67934

Cumulative Model Updates: 310,450
Cumulative Timesteps: 2,589,116,376

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2589116376...
Checkpoint 2589116376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.40090
Policy Entropy: 2.41440
Value Function Loss: 0.01998

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.08280
Policy Update Magnitude: 0.48967
Value Function Update Magnitude: 0.68138

Collected Steps per Second: 21,730.77078
Overall Steps per Second: 10,578.75873

Timestep Collection Time: 2.30273
Timestep Consumption Time: 2.42751
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.73023

Cumulative Model Updates: 310,456
Cumulative Timesteps: 2,589,166,416

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.28820
Policy Entropy: 2.40497
Value Function Loss: 0.02138

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.08747
Policy Update Magnitude: 0.50127
Value Function Update Magnitude: 0.68997

Collected Steps per Second: 21,752.17776
Overall Steps per Second: 10,587.56430

Timestep Collection Time: 2.29899
Timestep Consumption Time: 2.42429
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.72328

Cumulative Model Updates: 310,462
Cumulative Timesteps: 2,589,216,424

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2589216424...
Checkpoint 2589216424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.18598
Policy Entropy: 2.38043
Value Function Loss: 0.02276

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.09435
Policy Update Magnitude: 0.51288
Value Function Update Magnitude: 0.69632

Collected Steps per Second: 22,284.85221
Overall Steps per Second: 10,620.58694

Timestep Collection Time: 2.24475
Timestep Consumption Time: 2.46534
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.71010

Cumulative Model Updates: 310,468
Cumulative Timesteps: 2,589,266,448

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.54763
Policy Entropy: 2.38083
Value Function Loss: 0.02284

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.50966
Value Function Update Magnitude: 0.68771

Collected Steps per Second: 22,654.00350
Overall Steps per Second: 10,624.16818

Timestep Collection Time: 2.20712
Timestep Consumption Time: 2.49914
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.70625

Cumulative Model Updates: 310,474
Cumulative Timesteps: 2,589,316,448

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2589316448...
Checkpoint 2589316448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.29172
Policy Entropy: 2.36735
Value Function Loss: 0.02238

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.10347
Policy Update Magnitude: 0.49459
Value Function Update Magnitude: 0.67469

Collected Steps per Second: 22,214.80751
Overall Steps per Second: 10,522.55708

Timestep Collection Time: 2.25138
Timestep Consumption Time: 2.50165
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.75303

Cumulative Model Updates: 310,480
Cumulative Timesteps: 2,589,366,462

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.27861
Policy Entropy: 2.40021
Value Function Loss: 0.02111

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.11166
Policy Update Magnitude: 0.48403
Value Function Update Magnitude: 0.65595

Collected Steps per Second: 22,216.24505
Overall Steps per Second: 10,713.31677

Timestep Collection Time: 2.25079
Timestep Consumption Time: 2.41668
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.66746

Cumulative Model Updates: 310,486
Cumulative Timesteps: 2,589,416,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2589416466...
Checkpoint 2589416466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.64434
Policy Entropy: 2.40946
Value Function Loss: 0.02179

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.10082
Policy Update Magnitude: 0.48914
Value Function Update Magnitude: 0.63942

Collected Steps per Second: 22,156.09796
Overall Steps per Second: 10,739.22226

Timestep Collection Time: 2.25690
Timestep Consumption Time: 2.39931
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.65620

Cumulative Model Updates: 310,492
Cumulative Timesteps: 2,589,466,470

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.79184
Policy Entropy: 2.41918
Value Function Loss: 0.02126

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.10015
Policy Update Magnitude: 0.50869
Value Function Update Magnitude: 0.66415

Collected Steps per Second: 22,335.30803
Overall Steps per Second: 10,521.90673

Timestep Collection Time: 2.23915
Timestep Consumption Time: 2.51399
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.75313

Cumulative Model Updates: 310,498
Cumulative Timesteps: 2,589,516,482

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2589516482...
Checkpoint 2589516482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.99761
Policy Entropy: 2.39981
Value Function Loss: 0.02162

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.51234
Value Function Update Magnitude: 0.68306

Collected Steps per Second: 22,471.84245
Overall Steps per Second: 10,583.42277

Timestep Collection Time: 2.22510
Timestep Consumption Time: 2.49946
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.72456

Cumulative Model Updates: 310,504
Cumulative Timesteps: 2,589,566,484

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.00306
Policy Entropy: 2.41910
Value Function Loss: 0.01991

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.10619
Policy Update Magnitude: 0.50406
Value Function Update Magnitude: 0.68343

Collected Steps per Second: 21,537.37901
Overall Steps per Second: 10,440.17461

Timestep Collection Time: 2.32192
Timestep Consumption Time: 2.46804
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.78996

Cumulative Model Updates: 310,510
Cumulative Timesteps: 2,589,616,492

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2589616492...
Checkpoint 2589616492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.96344
Policy Entropy: 2.44300
Value Function Loss: 0.02035

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.11575
Policy Update Magnitude: 0.46967
Value Function Update Magnitude: 0.66980

Collected Steps per Second: 21,673.24170
Overall Steps per Second: 10,637.64402

Timestep Collection Time: 2.30708
Timestep Consumption Time: 2.39339
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.70048

Cumulative Model Updates: 310,516
Cumulative Timesteps: 2,589,666,494

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.85810
Policy Entropy: 2.46117
Value Function Loss: 0.02108

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.12313
Policy Update Magnitude: 0.44990
Value Function Update Magnitude: 0.64760

Collected Steps per Second: 22,220.01726
Overall Steps per Second: 10,526.76564

Timestep Collection Time: 2.25148
Timestep Consumption Time: 2.50097
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.75246

Cumulative Model Updates: 310,522
Cumulative Timesteps: 2,589,716,522

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2589716522...
Checkpoint 2589716522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.00221
Policy Entropy: 2.43467
Value Function Loss: 0.02168

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.10597
Policy Update Magnitude: 0.47350
Value Function Update Magnitude: 0.63920

Collected Steps per Second: 22,094.56727
Overall Steps per Second: 10,588.52655

Timestep Collection Time: 2.26372
Timestep Consumption Time: 2.45988
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.72360

Cumulative Model Updates: 310,528
Cumulative Timesteps: 2,589,766,538

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.62433
Policy Entropy: 2.42540
Value Function Loss: 0.02164

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.10921
Policy Update Magnitude: 0.50070
Value Function Update Magnitude: 0.65041

Collected Steps per Second: 21,989.20415
Overall Steps per Second: 10,458.58283

Timestep Collection Time: 2.27521
Timestep Consumption Time: 2.50842
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.78363

Cumulative Model Updates: 310,534
Cumulative Timesteps: 2,589,816,568

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2589816568...
Checkpoint 2589816568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.26184
Policy Entropy: 2.45558
Value Function Loss: 0.02057

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.10947
Policy Update Magnitude: 0.50498
Value Function Update Magnitude: 0.65687

Collected Steps per Second: 21,989.06086
Overall Steps per Second: 10,573.75640

Timestep Collection Time: 2.27468
Timestep Consumption Time: 2.45571
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.73039

Cumulative Model Updates: 310,540
Cumulative Timesteps: 2,589,866,586

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.74046
Policy Entropy: 2.46901
Value Function Loss: 0.02000

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.49801
Value Function Update Magnitude: 0.62844

Collected Steps per Second: 23,334.34433
Overall Steps per Second: 10,912.31397

Timestep Collection Time: 2.14276
Timestep Consumption Time: 2.43922
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.58198

Cumulative Model Updates: 310,546
Cumulative Timesteps: 2,589,916,586

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2589916586...
Checkpoint 2589916586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.26850
Policy Entropy: 2.46797
Value Function Loss: 0.02078

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.10889
Policy Update Magnitude: 0.49128
Value Function Update Magnitude: 0.61308

Collected Steps per Second: 22,185.53617
Overall Steps per Second: 10,668.94052

Timestep Collection Time: 2.25408
Timestep Consumption Time: 2.43317
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.68725

Cumulative Model Updates: 310,552
Cumulative Timesteps: 2,589,966,594

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.98985
Policy Entropy: 2.42733
Value Function Loss: 0.01950

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.47939
Value Function Update Magnitude: 0.62336

Collected Steps per Second: 22,232.45494
Overall Steps per Second: 10,474.74137

Timestep Collection Time: 2.24986
Timestep Consumption Time: 2.52543
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.77530

Cumulative Model Updates: 310,558
Cumulative Timesteps: 2,590,016,614

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2590016614...
Checkpoint 2590016614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.63544
Policy Entropy: 2.40994
Value Function Loss: 0.01981

Mean KL Divergence: 0.02485
SB3 Clip Fraction: 0.14072
Policy Update Magnitude: 0.46031
Value Function Update Magnitude: 0.61735

Collected Steps per Second: 22,141.79810
Overall Steps per Second: 10,637.95048

Timestep Collection Time: 2.25844
Timestep Consumption Time: 2.44227
PPO Batch Consumption Time: 0.29507
Total Iteration Time: 4.70072

Cumulative Model Updates: 310,564
Cumulative Timesteps: 2,590,066,620

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.57478
Policy Entropy: 2.41589
Value Function Loss: 0.01958

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.11438
Policy Update Magnitude: 0.47708
Value Function Update Magnitude: 0.62266

Collected Steps per Second: 21,292.31315
Overall Steps per Second: 10,415.76433

Timestep Collection Time: 2.34920
Timestep Consumption Time: 2.45313
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.80234

Cumulative Model Updates: 310,570
Cumulative Timesteps: 2,590,116,640

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2590116640...
Checkpoint 2590116640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.86839
Policy Entropy: 2.41940
Value Function Loss: 0.02137

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.49647
Value Function Update Magnitude: 0.66187

Collected Steps per Second: 22,182.35059
Overall Steps per Second: 10,669.08588

Timestep Collection Time: 2.25513
Timestep Consumption Time: 2.43356
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.68869

Cumulative Model Updates: 310,576
Cumulative Timesteps: 2,590,166,664

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.40324
Policy Entropy: 2.42004
Value Function Loss: 0.02025

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.08892
Policy Update Magnitude: 0.50104
Value Function Update Magnitude: 0.66862

Collected Steps per Second: 22,069.81962
Overall Steps per Second: 10,530.87783

Timestep Collection Time: 2.26672
Timestep Consumption Time: 2.48370
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.75041

Cumulative Model Updates: 310,582
Cumulative Timesteps: 2,590,216,690

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2590216690...
Checkpoint 2590216690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.06617
Policy Entropy: 2.42056
Value Function Loss: 0.02039

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.08978
Policy Update Magnitude: 0.48487
Value Function Update Magnitude: 0.65949

Collected Steps per Second: 21,573.88018
Overall Steps per Second: 10,549.02593

Timestep Collection Time: 2.31771
Timestep Consumption Time: 2.42225
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.73996

Cumulative Model Updates: 310,588
Cumulative Timesteps: 2,590,266,692

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.64350
Policy Entropy: 2.42694
Value Function Loss: 0.02083

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.09123
Policy Update Magnitude: 0.48359
Value Function Update Magnitude: 0.65715

Collected Steps per Second: 22,786.46382
Overall Steps per Second: 10,726.30900

Timestep Collection Time: 2.19455
Timestep Consumption Time: 2.46745
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.66200

Cumulative Model Updates: 310,594
Cumulative Timesteps: 2,590,316,698

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2590316698...
Checkpoint 2590316698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.40687
Policy Entropy: 2.42576
Value Function Loss: 0.02256

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.09574
Policy Update Magnitude: 0.49343
Value Function Update Magnitude: 0.68018

Collected Steps per Second: 21,579.16361
Overall Steps per Second: 10,420.15329

Timestep Collection Time: 2.31835
Timestep Consumption Time: 2.48273
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.80108

Cumulative Model Updates: 310,600
Cumulative Timesteps: 2,590,366,726

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.00945
Policy Entropy: 2.42627
Value Function Loss: 0.02264

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.10039
Policy Update Magnitude: 0.50034
Value Function Update Magnitude: 0.68099

Collected Steps per Second: 22,258.51811
Overall Steps per Second: 10,513.18203

Timestep Collection Time: 2.24678
Timestep Consumption Time: 2.51010
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.75689

Cumulative Model Updates: 310,606
Cumulative Timesteps: 2,590,416,736

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2590416736...
Checkpoint 2590416736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.80497
Policy Entropy: 2.43413
Value Function Loss: 0.02230

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.48401
Value Function Update Magnitude: 0.66647

Collected Steps per Second: 22,344.93117
Overall Steps per Second: 10,746.86801

Timestep Collection Time: 2.23845
Timestep Consumption Time: 2.41574
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.65419

Cumulative Model Updates: 310,612
Cumulative Timesteps: 2,590,466,754

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.90486
Policy Entropy: 2.44589
Value Function Loss: 0.02093

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.12929
Policy Update Magnitude: 0.44885
Value Function Update Magnitude: 0.65979

Collected Steps per Second: 22,843.93933
Overall Steps per Second: 10,736.92907

Timestep Collection Time: 2.18885
Timestep Consumption Time: 2.46816
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.65701

Cumulative Model Updates: 310,618
Cumulative Timesteps: 2,590,516,756

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2590516756...
Checkpoint 2590516756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.43845
Policy Entropy: 2.43379
Value Function Loss: 0.02095

Mean KL Divergence: 0.02830
SB3 Clip Fraction: 0.14303
Policy Update Magnitude: 0.44545
Value Function Update Magnitude: 0.64546

Collected Steps per Second: 22,461.14736
Overall Steps per Second: 10,630.04115

Timestep Collection Time: 2.22616
Timestep Consumption Time: 2.47768
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.70384

Cumulative Model Updates: 310,624
Cumulative Timesteps: 2,590,566,758

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.99889
Policy Entropy: 2.40694
Value Function Loss: 0.01987

Mean KL Divergence: 0.02110
SB3 Clip Fraction: 0.12580
Policy Update Magnitude: 0.48578
Value Function Update Magnitude: 0.64920

Collected Steps per Second: 22,252.61047
Overall Steps per Second: 10,586.63346

Timestep Collection Time: 2.24729
Timestep Consumption Time: 2.47641
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.72369

Cumulative Model Updates: 310,630
Cumulative Timesteps: 2,590,616,766

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2590616766...
Checkpoint 2590616766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.01166
Policy Entropy: 2.41550
Value Function Loss: 0.02025

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.11900
Policy Update Magnitude: 0.48792
Value Function Update Magnitude: 0.65898

Collected Steps per Second: 22,367.27897
Overall Steps per Second: 10,569.94818

Timestep Collection Time: 2.23621
Timestep Consumption Time: 2.49588
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.73210

Cumulative Model Updates: 310,636
Cumulative Timesteps: 2,590,666,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.78306
Policy Entropy: 2.42015
Value Function Loss: 0.02006

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.11220
Policy Update Magnitude: 0.48599
Value Function Update Magnitude: 0.67853

Collected Steps per Second: 21,928.53822
Overall Steps per Second: 10,754.77538

Timestep Collection Time: 2.28105
Timestep Consumption Time: 2.36991
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.65096

Cumulative Model Updates: 310,642
Cumulative Timesteps: 2,590,716,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2590716804...
Checkpoint 2590716804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.60467
Policy Entropy: 2.44045
Value Function Loss: 0.02085

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.11374
Policy Update Magnitude: 0.50145
Value Function Update Magnitude: 0.69510

Collected Steps per Second: 21,998.85465
Overall Steps per Second: 10,644.86190

Timestep Collection Time: 2.27285
Timestep Consumption Time: 2.42426
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.69710

Cumulative Model Updates: 310,648
Cumulative Timesteps: 2,590,766,804

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.12067
Policy Entropy: 2.43353
Value Function Loss: 0.02051

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.10626
Policy Update Magnitude: 0.49681
Value Function Update Magnitude: 0.70310

Collected Steps per Second: 21,971.39844
Overall Steps per Second: 10,515.58511

Timestep Collection Time: 2.27660
Timestep Consumption Time: 2.48015
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.75675

Cumulative Model Updates: 310,654
Cumulative Timesteps: 2,590,816,824

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2590816824...
Checkpoint 2590816824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.09063
Policy Entropy: 2.40408
Value Function Loss: 0.02053

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.10516
Policy Update Magnitude: 0.49617
Value Function Update Magnitude: 0.69546

Collected Steps per Second: 21,929.33618
Overall Steps per Second: 10,632.69578

Timestep Collection Time: 2.28105
Timestep Consumption Time: 2.42349
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.70455

Cumulative Model Updates: 310,660
Cumulative Timesteps: 2,590,866,846

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.17471
Policy Entropy: 2.42126
Value Function Loss: 0.01929

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 0.49370
Value Function Update Magnitude: 0.67946

Collected Steps per Second: 21,752.82097
Overall Steps per Second: 10,579.27237

Timestep Collection Time: 2.29975
Timestep Consumption Time: 2.42893
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.72868

Cumulative Model Updates: 310,666
Cumulative Timesteps: 2,590,916,872

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2590916872...
Checkpoint 2590916872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.74512
Policy Entropy: 2.40388
Value Function Loss: 0.01968

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.09466
Policy Update Magnitude: 0.48484
Value Function Update Magnitude: 0.65758

Collected Steps per Second: 22,030.34916
Overall Steps per Second: 10,404.05218

Timestep Collection Time: 2.26987
Timestep Consumption Time: 2.53653
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.80640

Cumulative Model Updates: 310,672
Cumulative Timesteps: 2,590,966,878

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.58789
Policy Entropy: 2.40889
Value Function Loss: 0.02042

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.48745
Value Function Update Magnitude: 0.65215

Collected Steps per Second: 22,064.36835
Overall Steps per Second: 10,505.01600

Timestep Collection Time: 2.26682
Timestep Consumption Time: 2.49433
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.76115

Cumulative Model Updates: 310,678
Cumulative Timesteps: 2,591,016,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2591016894...
Checkpoint 2591016894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.73054
Policy Entropy: 2.39710
Value Function Loss: 0.02093

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.08996
Policy Update Magnitude: 0.49994
Value Function Update Magnitude: 0.65927

Collected Steps per Second: 20,849.30400
Overall Steps per Second: 10,221.34392

Timestep Collection Time: 2.39893
Timestep Consumption Time: 2.49436
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.89329

Cumulative Model Updates: 310,684
Cumulative Timesteps: 2,591,066,910

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.06952
Policy Entropy: 2.41140
Value Function Loss: 0.02060

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.08582
Policy Update Magnitude: 0.49569
Value Function Update Magnitude: 0.67083

Collected Steps per Second: 20,582.64562
Overall Steps per Second: 10,432.21329

Timestep Collection Time: 2.43069
Timestep Consumption Time: 2.36503
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.79572

Cumulative Model Updates: 310,690
Cumulative Timesteps: 2,591,116,940

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2591116940...
Checkpoint 2591116940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.64092
Policy Entropy: 2.41726
Value Function Loss: 0.01911

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.08332
Policy Update Magnitude: 0.48803
Value Function Update Magnitude: 0.65948

Collected Steps per Second: 22,220.14497
Overall Steps per Second: 10,673.64066

Timestep Collection Time: 2.25084
Timestep Consumption Time: 2.43491
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.68575

Cumulative Model Updates: 310,696
Cumulative Timesteps: 2,591,166,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.22969
Policy Entropy: 2.43004
Value Function Loss: 0.01958

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.08856
Policy Update Magnitude: 0.49235
Value Function Update Magnitude: 0.65293

Collected Steps per Second: 22,274.45963
Overall Steps per Second: 10,541.63077

Timestep Collection Time: 2.24526
Timestep Consumption Time: 2.49898
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.74424

Cumulative Model Updates: 310,702
Cumulative Timesteps: 2,591,216,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2591216966...
Checkpoint 2591216966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.73750
Policy Entropy: 2.43165
Value Function Loss: 0.01955

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.09304
Policy Update Magnitude: 0.49448
Value Function Update Magnitude: 0.66438

Collected Steps per Second: 22,058.84363
Overall Steps per Second: 10,496.27125

Timestep Collection Time: 2.26748
Timestep Consumption Time: 2.49783
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.76531

Cumulative Model Updates: 310,708
Cumulative Timesteps: 2,591,266,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.96758
Policy Entropy: 2.43560
Value Function Loss: 0.01944

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.49540
Value Function Update Magnitude: 0.66236

Collected Steps per Second: 22,044.95331
Overall Steps per Second: 10,644.47113

Timestep Collection Time: 2.26846
Timestep Consumption Time: 2.42957
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.69803

Cumulative Model Updates: 310,714
Cumulative Timesteps: 2,591,316,992

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2591316992...
Checkpoint 2591316992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.98798
Policy Entropy: 2.43403
Value Function Loss: 0.01919

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.10457
Policy Update Magnitude: 0.48624
Value Function Update Magnitude: 0.66236

Collected Steps per Second: 21,706.30255
Overall Steps per Second: 10,568.99770

Timestep Collection Time: 2.30385
Timestep Consumption Time: 2.42773
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.73157

Cumulative Model Updates: 310,720
Cumulative Timesteps: 2,591,367,000

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.95889
Policy Entropy: 2.44392
Value Function Loss: 0.01923

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.10504
Policy Update Magnitude: 0.48355
Value Function Update Magnitude: 0.67655

Collected Steps per Second: 21,667.79467
Overall Steps per Second: 10,470.25052

Timestep Collection Time: 2.30850
Timestep Consumption Time: 2.46885
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.77735

Cumulative Model Updates: 310,726
Cumulative Timesteps: 2,591,417,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2591417020...
Checkpoint 2591417020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.08090
Policy Entropy: 2.43687
Value Function Loss: 0.02004

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.10571
Policy Update Magnitude: 0.47640
Value Function Update Magnitude: 0.68743

Collected Steps per Second: 21,637.78521
Overall Steps per Second: 10,590.08231

Timestep Collection Time: 2.31123
Timestep Consumption Time: 2.41111
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.72234

Cumulative Model Updates: 310,732
Cumulative Timesteps: 2,591,467,030

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.32625
Policy Entropy: 2.40876
Value Function Loss: 0.02098

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.08769
Policy Update Magnitude: 0.50094
Value Function Update Magnitude: 0.68663

Collected Steps per Second: 21,893.00827
Overall Steps per Second: 10,535.74854

Timestep Collection Time: 2.28511
Timestep Consumption Time: 2.46329
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.74840

Cumulative Model Updates: 310,738
Cumulative Timesteps: 2,591,517,058

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2591517058...
Checkpoint 2591517058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.11037
Policy Entropy: 2.40877
Value Function Loss: 0.02134

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.49208
Value Function Update Magnitude: 0.67736

Collected Steps per Second: 21,701.29737
Overall Steps per Second: 10,615.64659

Timestep Collection Time: 2.30475
Timestep Consumption Time: 2.40679
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.71154

Cumulative Model Updates: 310,744
Cumulative Timesteps: 2,591,567,074

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.22740
Policy Entropy: 2.43652
Value Function Loss: 0.02107

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.08971
Policy Update Magnitude: 0.48436
Value Function Update Magnitude: 0.66105

Collected Steps per Second: 22,087.73961
Overall Steps per Second: 10,431.03285

Timestep Collection Time: 2.26451
Timestep Consumption Time: 2.53060
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.79511

Cumulative Model Updates: 310,750
Cumulative Timesteps: 2,591,617,092

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2591617092...
Checkpoint 2591617092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.94916
Policy Entropy: 2.46833
Value Function Loss: 0.02007

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.08571
Policy Update Magnitude: 0.48285
Value Function Update Magnitude: 0.63380

Collected Steps per Second: 21,681.23435
Overall Steps per Second: 10,382.78974

Timestep Collection Time: 2.30642
Timestep Consumption Time: 2.50982
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.81624

Cumulative Model Updates: 310,756
Cumulative Timesteps: 2,591,667,098

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.15821
Policy Entropy: 2.46618
Value Function Loss: 0.02095

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.08705
Policy Update Magnitude: 0.48310
Value Function Update Magnitude: 0.61128

Collected Steps per Second: 22,699.61473
Overall Steps per Second: 10,769.31177

Timestep Collection Time: 2.20321
Timestep Consumption Time: 2.44073
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.64394

Cumulative Model Updates: 310,762
Cumulative Timesteps: 2,591,717,110

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2591717110...
Checkpoint 2591717110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.74214
Policy Entropy: 2.46923
Value Function Loss: 0.02020

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.08249
Policy Update Magnitude: 0.48793
Value Function Update Magnitude: 0.61761

Collected Steps per Second: 22,818.54675
Overall Steps per Second: 10,663.24574

Timestep Collection Time: 2.19190
Timestep Consumption Time: 2.49860
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.69050

Cumulative Model Updates: 310,768
Cumulative Timesteps: 2,591,767,126

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.81112
Policy Entropy: 2.46670
Value Function Loss: 0.02110

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.08260
Policy Update Magnitude: 0.49619
Value Function Update Magnitude: 0.65658

Collected Steps per Second: 22,734.77047
Overall Steps per Second: 10,790.61706

Timestep Collection Time: 2.19945
Timestep Consumption Time: 2.43458
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.63403

Cumulative Model Updates: 310,774
Cumulative Timesteps: 2,591,817,130

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2591817130...
Checkpoint 2591817130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.89802
Policy Entropy: 2.46845
Value Function Loss: 0.02038

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.08783
Policy Update Magnitude: 0.49539
Value Function Update Magnitude: 0.67945

Collected Steps per Second: 21,977.15597
Overall Steps per Second: 10,602.15246

Timestep Collection Time: 2.27645
Timestep Consumption Time: 2.44240
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.71885

Cumulative Model Updates: 310,780
Cumulative Timesteps: 2,591,867,160

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.15536
Policy Entropy: 2.44600
Value Function Loss: 0.02058

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.08728
Policy Update Magnitude: 0.49393
Value Function Update Magnitude: 0.68687

Collected Steps per Second: 22,370.06549
Overall Steps per Second: 10,897.90451

Timestep Collection Time: 2.23513
Timestep Consumption Time: 2.35291
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.58804

Cumulative Model Updates: 310,786
Cumulative Timesteps: 2,591,917,160

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2591917160...
Checkpoint 2591917160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.47323
Policy Entropy: 2.44164
Value Function Loss: 0.02070

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.09388
Policy Update Magnitude: 0.49506
Value Function Update Magnitude: 0.66340

Collected Steps per Second: 22,240.59148
Overall Steps per Second: 10,668.60017

Timestep Collection Time: 2.24832
Timestep Consumption Time: 2.43870
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.68703

Cumulative Model Updates: 310,792
Cumulative Timesteps: 2,591,967,164

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.90054
Policy Entropy: 2.42968
Value Function Loss: 0.02046

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.09127
Policy Update Magnitude: 0.49777
Value Function Update Magnitude: 0.64999

Collected Steps per Second: 20,748.96106
Overall Steps per Second: 10,136.79791

Timestep Collection Time: 2.40986
Timestep Consumption Time: 2.52287
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.93272

Cumulative Model Updates: 310,798
Cumulative Timesteps: 2,592,017,166

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2592017166...
Checkpoint 2592017166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.65413
Policy Entropy: 2.43542
Value Function Loss: 0.02097

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.09053
Policy Update Magnitude: 0.49726
Value Function Update Magnitude: 0.66265

Collected Steps per Second: 21,728.33164
Overall Steps per Second: 10,643.22793

Timestep Collection Time: 2.30179
Timestep Consumption Time: 2.39735
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.69914

Cumulative Model Updates: 310,804
Cumulative Timesteps: 2,592,067,180

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.22390
Policy Entropy: 2.41740
Value Function Loss: 0.02123

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.09027
Policy Update Magnitude: 0.49941
Value Function Update Magnitude: 0.66317

Collected Steps per Second: 22,209.13364
Overall Steps per Second: 10,840.84546

Timestep Collection Time: 2.25133
Timestep Consumption Time: 2.36086
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.61219

Cumulative Model Updates: 310,810
Cumulative Timesteps: 2,592,117,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2592117180...
Checkpoint 2592117180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.56480
Policy Entropy: 2.40342
Value Function Loss: 0.02305

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.09019
Policy Update Magnitude: 0.51474
Value Function Update Magnitude: 0.67856

Collected Steps per Second: 21,426.09945
Overall Steps per Second: 10,353.72423

Timestep Collection Time: 2.33416
Timestep Consumption Time: 2.49618
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.83034

Cumulative Model Updates: 310,816
Cumulative Timesteps: 2,592,167,192

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.67477
Policy Entropy: 2.41074
Value Function Loss: 0.02231

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.09257
Policy Update Magnitude: 0.51132
Value Function Update Magnitude: 0.71079

Collected Steps per Second: 22,247.29621
Overall Steps per Second: 10,665.64857

Timestep Collection Time: 2.24872
Timestep Consumption Time: 2.44185
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.69057

Cumulative Model Updates: 310,822
Cumulative Timesteps: 2,592,217,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2592217220...
Checkpoint 2592217220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.81762
Policy Entropy: 2.43212
Value Function Loss: 0.02084

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.09900
Policy Update Magnitude: 0.48971
Value Function Update Magnitude: 0.68704

Collected Steps per Second: 21,784.78858
Overall Steps per Second: 10,427.16465

Timestep Collection Time: 2.29656
Timestep Consumption Time: 2.50149
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.79804

Cumulative Model Updates: 310,828
Cumulative Timesteps: 2,592,267,250

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.11363
Policy Entropy: 2.44650
Value Function Loss: 0.01997

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.47932
Value Function Update Magnitude: 0.67259

Collected Steps per Second: 22,517.99596
Overall Steps per Second: 10,731.08396

Timestep Collection Time: 2.22062
Timestep Consumption Time: 2.43911
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.65973

Cumulative Model Updates: 310,834
Cumulative Timesteps: 2,592,317,254

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2592317254...
Checkpoint 2592317254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.71505
Policy Entropy: 2.42822
Value Function Loss: 0.01965

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.08960
Policy Update Magnitude: 0.48077
Value Function Update Magnitude: 0.66471

Collected Steps per Second: 22,856.36623
Overall Steps per Second: 10,640.35877

Timestep Collection Time: 2.18967
Timestep Consumption Time: 2.51393
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.70360

Cumulative Model Updates: 310,840
Cumulative Timesteps: 2,592,367,302

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.31492
Policy Entropy: 2.42375
Value Function Loss: 0.02120

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.49305
Value Function Update Magnitude: 0.66416

Collected Steps per Second: 22,197.26770
Overall Steps per Second: 10,486.89911

Timestep Collection Time: 2.25361
Timestep Consumption Time: 2.51653
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.77014

Cumulative Model Updates: 310,846
Cumulative Timesteps: 2,592,417,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2592417326...
Checkpoint 2592417326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.27862
Policy Entropy: 2.42442
Value Function Loss: 0.02099

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.49536
Value Function Update Magnitude: 0.66769

Collected Steps per Second: 22,142.73661
Overall Steps per Second: 10,616.49711

Timestep Collection Time: 2.25844
Timestep Consumption Time: 2.45197
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.71040

Cumulative Model Updates: 310,852
Cumulative Timesteps: 2,592,467,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.42531
Policy Entropy: 2.42932
Value Function Loss: 0.02255

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.09567
Policy Update Magnitude: 0.48639
Value Function Update Magnitude: 0.66911

Collected Steps per Second: 22,003.38958
Overall Steps per Second: 10,504.52437

Timestep Collection Time: 2.27356
Timestep Consumption Time: 2.48877
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.76233

Cumulative Model Updates: 310,858
Cumulative Timesteps: 2,592,517,360

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2592517360...
Checkpoint 2592517360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.71956
Policy Entropy: 2.43397
Value Function Loss: 0.02141

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.09418
Policy Update Magnitude: 0.49174
Value Function Update Magnitude: 0.68457

Collected Steps per Second: 22,127.70475
Overall Steps per Second: 10,668.17946

Timestep Collection Time: 2.26061
Timestep Consumption Time: 2.42829
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.68890

Cumulative Model Updates: 310,864
Cumulative Timesteps: 2,592,567,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.19980
Policy Entropy: 2.44233
Value Function Loss: 0.02092

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.09858
Policy Update Magnitude: 0.49060
Value Function Update Magnitude: 0.68609

Collected Steps per Second: 21,995.76007
Overall Steps per Second: 10,446.53255

Timestep Collection Time: 2.27362
Timestep Consumption Time: 2.51361
PPO Batch Consumption Time: 0.29517
Total Iteration Time: 4.78723

Cumulative Model Updates: 310,870
Cumulative Timesteps: 2,592,617,392

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2592617392...
Checkpoint 2592617392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.72841
Policy Entropy: 2.43847
Value Function Loss: 0.02014

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.49217
Value Function Update Magnitude: 0.66982

Collected Steps per Second: 21,814.33629
Overall Steps per Second: 10,557.90235

Timestep Collection Time: 2.29235
Timestep Consumption Time: 2.44401
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.73636

Cumulative Model Updates: 310,876
Cumulative Timesteps: 2,592,667,398

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.37057
Policy Entropy: 2.43639
Value Function Loss: 0.02038

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.09466
Policy Update Magnitude: 0.49280
Value Function Update Magnitude: 0.66765

Collected Steps per Second: 21,568.59887
Overall Steps per Second: 10,505.96843

Timestep Collection Time: 2.31856
Timestep Consumption Time: 2.44141
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.75996

Cumulative Model Updates: 310,882
Cumulative Timesteps: 2,592,717,406

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2592717406...
Checkpoint 2592717406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.44608
Policy Entropy: 2.44695
Value Function Loss: 0.02008

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.08565
Policy Update Magnitude: 0.49471
Value Function Update Magnitude: 0.65949

Collected Steps per Second: 22,420.41816
Overall Steps per Second: 10,635.64161

Timestep Collection Time: 2.23100
Timestep Consumption Time: 2.47205
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.70305

Cumulative Model Updates: 310,888
Cumulative Timesteps: 2,592,767,426

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.60334
Policy Entropy: 2.44502
Value Function Loss: 0.01959

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.48712
Value Function Update Magnitude: 0.64218

Collected Steps per Second: 21,676.70538
Overall Steps per Second: 10,439.26481

Timestep Collection Time: 2.30792
Timestep Consumption Time: 2.48438
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.79229

Cumulative Model Updates: 310,894
Cumulative Timesteps: 2,592,817,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2592817454...
Checkpoint 2592817454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.53042
Policy Entropy: 2.45655
Value Function Loss: 0.01945

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.08339
Policy Update Magnitude: 0.48423
Value Function Update Magnitude: 0.64481

Collected Steps per Second: 21,588.80701
Overall Steps per Second: 10,572.86816

Timestep Collection Time: 2.31611
Timestep Consumption Time: 2.41317
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.72927

Cumulative Model Updates: 310,900
Cumulative Timesteps: 2,592,867,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.66641
Policy Entropy: 2.44704
Value Function Loss: 0.02047

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.09153
Policy Update Magnitude: 0.48676
Value Function Update Magnitude: 0.66476

Collected Steps per Second: 22,279.61464
Overall Steps per Second: 10,659.01630

Timestep Collection Time: 2.24501
Timestep Consumption Time: 2.44754
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.69255

Cumulative Model Updates: 310,906
Cumulative Timesteps: 2,592,917,474

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2592917474...
Checkpoint 2592917474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.48787
Policy Entropy: 2.45836
Value Function Loss: 0.02049

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.09389
Policy Update Magnitude: 0.49215
Value Function Update Magnitude: 0.66217

Collected Steps per Second: 22,253.41716
Overall Steps per Second: 10,501.30430

Timestep Collection Time: 2.24801
Timestep Consumption Time: 2.51577
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.76379

Cumulative Model Updates: 310,912
Cumulative Timesteps: 2,592,967,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.65322
Policy Entropy: 2.44699
Value Function Loss: 0.02092

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.09642
Policy Update Magnitude: 0.49208
Value Function Update Magnitude: 0.67277

Collected Steps per Second: 22,447.74423
Overall Steps per Second: 10,574.75440

Timestep Collection Time: 2.22740
Timestep Consumption Time: 2.50085
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.72824

Cumulative Model Updates: 310,918
Cumulative Timesteps: 2,593,017,500

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2593017500...
Checkpoint 2593017500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.06325
Policy Entropy: 2.43397
Value Function Loss: 0.02003

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.09329
Policy Update Magnitude: 0.49143
Value Function Update Magnitude: 0.67119

Collected Steps per Second: 22,254.33831
Overall Steps per Second: 10,569.23183

Timestep Collection Time: 2.24747
Timestep Consumption Time: 2.48475
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.73223

Cumulative Model Updates: 310,924
Cumulative Timesteps: 2,593,067,516

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.71391
Policy Entropy: 2.41012
Value Function Loss: 0.02078

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.08146
Policy Update Magnitude: 0.49104
Value Function Update Magnitude: 0.66616

Collected Steps per Second: 22,483.72796
Overall Steps per Second: 10,888.62860

Timestep Collection Time: 2.22383
Timestep Consumption Time: 2.36812
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.59195

Cumulative Model Updates: 310,930
Cumulative Timesteps: 2,593,117,516

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2593117516...
Checkpoint 2593117516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.37120
Policy Entropy: 2.41307
Value Function Loss: 0.02003

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.08063
Policy Update Magnitude: 0.49010
Value Function Update Magnitude: 0.66193

Collected Steps per Second: 22,086.72420
Overall Steps per Second: 10,677.09157

Timestep Collection Time: 2.26426
Timestep Consumption Time: 2.41960
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.68386

Cumulative Model Updates: 310,936
Cumulative Timesteps: 2,593,167,526

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.99099
Policy Entropy: 2.41344
Value Function Loss: 0.02026

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.08749
Policy Update Magnitude: 0.48450
Value Function Update Magnitude: 0.66416

Collected Steps per Second: 22,470.34615
Overall Steps per Second: 10,751.23560

Timestep Collection Time: 2.22569
Timestep Consumption Time: 2.42606
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.65174

Cumulative Model Updates: 310,942
Cumulative Timesteps: 2,593,217,538

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2593217538...
Checkpoint 2593217538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.49907
Policy Entropy: 2.43861
Value Function Loss: 0.02005

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.07885
Policy Update Magnitude: 0.47590
Value Function Update Magnitude: 0.65248

Collected Steps per Second: 21,273.06263
Overall Steps per Second: 10,351.37268

Timestep Collection Time: 2.35161
Timestep Consumption Time: 2.48118
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.83279

Cumulative Model Updates: 310,948
Cumulative Timesteps: 2,593,267,564

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.26563
Policy Entropy: 2.45608
Value Function Loss: 0.02108

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.08090
Policy Update Magnitude: 0.50225
Value Function Update Magnitude: 0.66268

Collected Steps per Second: 21,884.92875
Overall Steps per Second: 10,786.22980

Timestep Collection Time: 2.28541
Timestep Consumption Time: 2.35162
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.63702

Cumulative Model Updates: 310,954
Cumulative Timesteps: 2,593,317,580

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2593317580...
Checkpoint 2593317580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.92592
Policy Entropy: 2.47497
Value Function Loss: 0.01951

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.49962
Value Function Update Magnitude: 0.67622

Collected Steps per Second: 21,851.70688
Overall Steps per Second: 10,619.70848

Timestep Collection Time: 2.28824
Timestep Consumption Time: 2.42017
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.70842

Cumulative Model Updates: 310,960
Cumulative Timesteps: 2,593,367,582

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.14805
Policy Entropy: 2.47307
Value Function Loss: 0.01860

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.08989
Policy Update Magnitude: 0.48368
Value Function Update Magnitude: 0.67303

Collected Steps per Second: 22,191.33240
Overall Steps per Second: 10,519.03903

Timestep Collection Time: 2.25367
Timestep Consumption Time: 2.50075
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.75443

Cumulative Model Updates: 310,966
Cumulative Timesteps: 2,593,417,594

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2593417594...
Checkpoint 2593417594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.25947
Policy Entropy: 2.45862
Value Function Loss: 0.01936

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.09214
Policy Update Magnitude: 0.48496
Value Function Update Magnitude: 0.66007

Collected Steps per Second: 21,925.56719
Overall Steps per Second: 10,564.73594

Timestep Collection Time: 2.28190
Timestep Consumption Time: 2.45385
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.73575

Cumulative Model Updates: 310,972
Cumulative Timesteps: 2,593,467,626

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.10341
Policy Entropy: 2.44555
Value Function Loss: 0.02073

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.09001
Policy Update Magnitude: 0.49258
Value Function Update Magnitude: 0.66879

Collected Steps per Second: 22,530.75878
Overall Steps per Second: 10,666.15883

Timestep Collection Time: 2.21937
Timestep Consumption Time: 2.46873
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.68810

Cumulative Model Updates: 310,978
Cumulative Timesteps: 2,593,517,630

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2593517630...
Checkpoint 2593517630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.85851
Policy Entropy: 2.44363
Value Function Loss: 0.02093

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.08506
Policy Update Magnitude: 0.50241
Value Function Update Magnitude: 0.65636

Collected Steps per Second: 22,449.99733
Overall Steps per Second: 10,560.84429

Timestep Collection Time: 2.22824
Timestep Consumption Time: 2.50850
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.73674

Cumulative Model Updates: 310,984
Cumulative Timesteps: 2,593,567,654

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.70039
Policy Entropy: 2.43870
Value Function Loss: 0.02009

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.49695
Value Function Update Magnitude: 0.66642

Collected Steps per Second: 22,584.16583
Overall Steps per Second: 10,758.33134

Timestep Collection Time: 2.21421
Timestep Consumption Time: 2.43391
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.64812

Cumulative Model Updates: 310,990
Cumulative Timesteps: 2,593,617,660

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2593617660...
Checkpoint 2593617660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.19524
Policy Entropy: 2.44001
Value Function Loss: 0.02109

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.08847
Policy Update Magnitude: 0.51013
Value Function Update Magnitude: 0.67735

Collected Steps per Second: 21,923.08314
Overall Steps per Second: 10,653.54839

Timestep Collection Time: 2.28198
Timestep Consumption Time: 2.41392
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.69590

Cumulative Model Updates: 310,996
Cumulative Timesteps: 2,593,667,688

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.05733
Policy Entropy: 2.43438
Value Function Loss: 0.02088

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.09532
Policy Update Magnitude: 0.50196
Value Function Update Magnitude: 0.67629

Collected Steps per Second: 22,371.06338
Overall Steps per Second: 10,894.57105

Timestep Collection Time: 2.23512
Timestep Consumption Time: 2.35451
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.58963

Cumulative Model Updates: 311,002
Cumulative Timesteps: 2,593,717,690

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2593717690...
Checkpoint 2593717690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.84962
Policy Entropy: 2.43450
Value Function Loss: 0.02209

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.49650
Value Function Update Magnitude: 0.66438

Collected Steps per Second: 22,017.06952
Overall Steps per Second: 10,668.95258

Timestep Collection Time: 2.27224
Timestep Consumption Time: 2.41688
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.68912

Cumulative Model Updates: 311,008
Cumulative Timesteps: 2,593,767,718

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.46798
Policy Entropy: 2.41547
Value Function Loss: 0.02193

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.09787
Policy Update Magnitude: 0.49721
Value Function Update Magnitude: 0.65130

Collected Steps per Second: 22,112.25840
Overall Steps per Second: 10,532.15102

Timestep Collection Time: 2.26137
Timestep Consumption Time: 2.48638
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.74775

Cumulative Model Updates: 311,014
Cumulative Timesteps: 2,593,817,722

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2593817722...
Checkpoint 2593817722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.06148
Policy Entropy: 2.40756
Value Function Loss: 0.02214

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.09728
Policy Update Magnitude: 0.50184
Value Function Update Magnitude: 0.66528

Collected Steps per Second: 21,587.50780
Overall Steps per Second: 10,583.70159

Timestep Collection Time: 2.31727
Timestep Consumption Time: 2.40925
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.72651

Cumulative Model Updates: 311,020
Cumulative Timesteps: 2,593,867,746

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.91618
Policy Entropy: 2.40314
Value Function Loss: 0.02141

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.10653
Policy Update Magnitude: 0.49143
Value Function Update Magnitude: 0.65984

Collected Steps per Second: 21,560.06205
Overall Steps per Second: 10,465.12803

Timestep Collection Time: 2.31984
Timestep Consumption Time: 2.45946
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.77930

Cumulative Model Updates: 311,026
Cumulative Timesteps: 2,593,917,762

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2593917762...
Checkpoint 2593917762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.58774
Policy Entropy: 2.43335
Value Function Loss: 0.02036

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.10458
Policy Update Magnitude: 0.48285
Value Function Update Magnitude: 0.65177

Collected Steps per Second: 21,651.92484
Overall Steps per Second: 10,572.50580

Timestep Collection Time: 2.31056
Timestep Consumption Time: 2.42134
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.73190

Cumulative Model Updates: 311,032
Cumulative Timesteps: 2,593,967,790

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.64380
Policy Entropy: 2.43103
Value Function Loss: 0.02017

Mean KL Divergence: 0.02148
SB3 Clip Fraction: 0.11683
Policy Update Magnitude: 0.47153
Value Function Update Magnitude: 0.64791

Collected Steps per Second: 22,450.92178
Overall Steps per Second: 10,592.90753

Timestep Collection Time: 2.22735
Timestep Consumption Time: 2.49336
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.72071

Cumulative Model Updates: 311,038
Cumulative Timesteps: 2,594,017,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2594017796...
Checkpoint 2594017796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.79276
Policy Entropy: 2.43491
Value Function Loss: 0.01999

Mean KL Divergence: 0.02601
SB3 Clip Fraction: 0.13102
Policy Update Magnitude: 0.44660
Value Function Update Magnitude: 0.63803

Collected Steps per Second: 22,261.58236
Overall Steps per Second: 10,811.09729

Timestep Collection Time: 2.24683
Timestep Consumption Time: 2.37971
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.62654

Cumulative Model Updates: 311,044
Cumulative Timesteps: 2,594,067,814

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.53686
Policy Entropy: 2.42178
Value Function Loss: 0.02027

Mean KL Divergence: 0.02089
SB3 Clip Fraction: 0.12320
Policy Update Magnitude: 0.46307
Value Function Update Magnitude: 0.63141

Collected Steps per Second: 22,644.38478
Overall Steps per Second: 10,574.10480

Timestep Collection Time: 2.20876
Timestep Consumption Time: 2.52129
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.73005

Cumulative Model Updates: 311,050
Cumulative Timesteps: 2,594,117,830

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2594117830...
Checkpoint 2594117830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.90967
Policy Entropy: 2.44013
Value Function Loss: 0.01974

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.11715
Policy Update Magnitude: 0.48656
Value Function Update Magnitude: 0.61849

Collected Steps per Second: 22,149.53281
Overall Steps per Second: 10,603.48799

Timestep Collection Time: 2.25847
Timestep Consumption Time: 2.45923
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.71769

Cumulative Model Updates: 311,056
Cumulative Timesteps: 2,594,167,854

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.72437
Policy Entropy: 2.44830
Value Function Loss: 0.01898

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.10112
Policy Update Magnitude: 0.48052
Value Function Update Magnitude: 0.62283

Collected Steps per Second: 22,276.17855
Overall Steps per Second: 10,628.78128

Timestep Collection Time: 2.24482
Timestep Consumption Time: 2.45995
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.70477

Cumulative Model Updates: 311,062
Cumulative Timesteps: 2,594,217,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2594217860...
Checkpoint 2594217860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.28534
Policy Entropy: 2.45393
Value Function Loss: 0.01977

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.08799
Policy Update Magnitude: 0.48703
Value Function Update Magnitude: 0.63406

Collected Steps per Second: 22,274.34961
Overall Steps per Second: 10,857.82011

Timestep Collection Time: 2.24518
Timestep Consumption Time: 2.36071
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.60590

Cumulative Model Updates: 311,068
Cumulative Timesteps: 2,594,267,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.78074
Policy Entropy: 2.43873
Value Function Loss: 0.02243

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.09547
Policy Update Magnitude: 0.49461
Value Function Update Magnitude: 0.65584

Collected Steps per Second: 22,343.01712
Overall Steps per Second: 10,505.30840

Timestep Collection Time: 2.23891
Timestep Consumption Time: 2.52287
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.76178

Cumulative Model Updates: 311,074
Cumulative Timesteps: 2,594,317,894

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2594317894...
Checkpoint 2594317894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.49816
Policy Entropy: 2.42830
Value Function Loss: 0.02283

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.51881
Value Function Update Magnitude: 0.67469

Collected Steps per Second: 21,281.44397
Overall Steps per Second: 10,293.96372

Timestep Collection Time: 2.35181
Timestep Consumption Time: 2.51026
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.86207

Cumulative Model Updates: 311,080
Cumulative Timesteps: 2,594,367,944

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.68200
Policy Entropy: 2.43370
Value Function Loss: 0.02284

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.09230
Policy Update Magnitude: 0.51983
Value Function Update Magnitude: 0.65874

Collected Steps per Second: 21,936.17805
Overall Steps per Second: 10,525.84344

Timestep Collection Time: 2.27980
Timestep Consumption Time: 2.47137
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.75116

Cumulative Model Updates: 311,086
Cumulative Timesteps: 2,594,417,954

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2594417954...
Checkpoint 2594417954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.56490
Policy Entropy: 2.43388
Value Function Loss: 0.02083

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.09642
Policy Update Magnitude: 0.51252
Value Function Update Magnitude: 0.64992

Collected Steps per Second: 22,020.80451
Overall Steps per Second: 10,697.80579

Timestep Collection Time: 2.27067
Timestep Consumption Time: 2.40337
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.67404

Cumulative Model Updates: 311,092
Cumulative Timesteps: 2,594,467,956

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.79844
Policy Entropy: 2.43475
Value Function Loss: 0.02043

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.08781
Policy Update Magnitude: 0.49164
Value Function Update Magnitude: 0.65826

Collected Steps per Second: 22,287.99599
Overall Steps per Second: 10,674.83327

Timestep Collection Time: 2.24399
Timestep Consumption Time: 2.44124
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.68523

Cumulative Model Updates: 311,098
Cumulative Timesteps: 2,594,517,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2594517970...
Checkpoint 2594517970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.50464
Policy Entropy: 2.43931
Value Function Loss: 0.02038

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.08912
Policy Update Magnitude: 0.48818
Value Function Update Magnitude: 0.65611

Collected Steps per Second: 21,978.07318
Overall Steps per Second: 10,571.95078

Timestep Collection Time: 2.27499
Timestep Consumption Time: 2.45450
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.72950

Cumulative Model Updates: 311,104
Cumulative Timesteps: 2,594,567,970

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.46312
Policy Entropy: 2.44682
Value Function Loss: 0.02093

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.09972
Policy Update Magnitude: 0.48511
Value Function Update Magnitude: 0.63368

Collected Steps per Second: 22,643.55079
Overall Steps per Second: 10,574.46659

Timestep Collection Time: 2.20866
Timestep Consumption Time: 2.52084
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.72951

Cumulative Model Updates: 311,110
Cumulative Timesteps: 2,594,617,982

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2594617982...
Checkpoint 2594617982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.89150
Policy Entropy: 2.44945
Value Function Loss: 0.02133

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.10229
Policy Update Magnitude: 0.49449
Value Function Update Magnitude: 0.61846

Collected Steps per Second: 22,811.02604
Overall Steps per Second: 10,655.38974

Timestep Collection Time: 2.19324
Timestep Consumption Time: 2.50204
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.69528

Cumulative Model Updates: 311,116
Cumulative Timesteps: 2,594,668,012

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.83794
Policy Entropy: 2.44266
Value Function Loss: 0.02152

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.09728
Policy Update Magnitude: 0.49244
Value Function Update Magnitude: 0.61170

Collected Steps per Second: 22,706.88781
Overall Steps per Second: 10,775.70283

Timestep Collection Time: 2.20294
Timestep Consumption Time: 2.43917
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.64211

Cumulative Model Updates: 311,122
Cumulative Timesteps: 2,594,718,034

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2594718034...
Checkpoint 2594718034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.15879
Policy Entropy: 2.43295
Value Function Loss: 0.02125

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.10847
Policy Update Magnitude: 0.48600
Value Function Update Magnitude: 0.62941

Collected Steps per Second: 21,877.71958
Overall Steps per Second: 10,450.00299

Timestep Collection Time: 2.28781
Timestep Consumption Time: 2.50186
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.78966

Cumulative Model Updates: 311,128
Cumulative Timesteps: 2,594,768,086

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.96916
Policy Entropy: 2.43131
Value Function Loss: 0.02222

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.09210
Policy Update Magnitude: 0.48129
Value Function Update Magnitude: 0.64089

Collected Steps per Second: 22,414.83813
Overall Steps per Second: 10,737.19327

Timestep Collection Time: 2.23191
Timestep Consumption Time: 2.42740
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.65932

Cumulative Model Updates: 311,134
Cumulative Timesteps: 2,594,818,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2594818114...
Checkpoint 2594818114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.71066
Policy Entropy: 2.42764
Value Function Loss: 0.02287

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.49900
Value Function Update Magnitude: 0.63422

Collected Steps per Second: 22,102.76300
Overall Steps per Second: 10,674.46889

Timestep Collection Time: 2.26361
Timestep Consumption Time: 2.42346
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.68707

Cumulative Model Updates: 311,140
Cumulative Timesteps: 2,594,868,146

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.96969
Policy Entropy: 2.43657
Value Function Loss: 0.02266

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.09228
Policy Update Magnitude: 0.50517
Value Function Update Magnitude: 0.64434

Collected Steps per Second: 22,511.75754
Overall Steps per Second: 10,612.97370

Timestep Collection Time: 2.22213
Timestep Consumption Time: 2.49135
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.71348

Cumulative Model Updates: 311,146
Cumulative Timesteps: 2,594,918,170

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2594918170...
Checkpoint 2594918170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.02165
Policy Entropy: 2.44099
Value Function Loss: 0.02135

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.09198
Policy Update Magnitude: 0.50166
Value Function Update Magnitude: 0.66139

Collected Steps per Second: 21,650.38488
Overall Steps per Second: 10,479.76732

Timestep Collection Time: 2.31091
Timestep Consumption Time: 2.46325
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.77415

Cumulative Model Updates: 311,152
Cumulative Timesteps: 2,594,968,202

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.89414
Policy Entropy: 2.42813
Value Function Loss: 0.02137

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.09277
Policy Update Magnitude: 0.49514
Value Function Update Magnitude: 0.64298

Collected Steps per Second: 21,772.17417
Overall Steps per Second: 10,446.16253

Timestep Collection Time: 2.29669
Timestep Consumption Time: 2.49014
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.78683

Cumulative Model Updates: 311,158
Cumulative Timesteps: 2,595,018,206

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2595018206...
Checkpoint 2595018206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.98353
Policy Entropy: 2.42239
Value Function Loss: 0.02210

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.09158
Policy Update Magnitude: 0.50052
Value Function Update Magnitude: 0.63896

Collected Steps per Second: 21,839.58904
Overall Steps per Second: 10,671.76255

Timestep Collection Time: 2.28970
Timestep Consumption Time: 2.39613
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.68582

Cumulative Model Updates: 311,164
Cumulative Timesteps: 2,595,068,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.31476
Policy Entropy: 2.42118
Value Function Loss: 0.02096

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.09325
Policy Update Magnitude: 0.49727
Value Function Update Magnitude: 0.64000

Collected Steps per Second: 22,112.38104
Overall Steps per Second: 10,457.25820

Timestep Collection Time: 2.26163
Timestep Consumption Time: 2.52070
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.78232

Cumulative Model Updates: 311,170
Cumulative Timesteps: 2,595,118,222

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2595118222...
Checkpoint 2595118222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.81889
Policy Entropy: 2.44583
Value Function Loss: 0.01963

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.09217
Policy Update Magnitude: 0.48856
Value Function Update Magnitude: 0.64033

Collected Steps per Second: 21,919.81611
Overall Steps per Second: 10,576.61390

Timestep Collection Time: 2.28141
Timestep Consumption Time: 2.44676
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.72817

Cumulative Model Updates: 311,176
Cumulative Timesteps: 2,595,168,230

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.35353
Policy Entropy: 2.45173
Value Function Loss: 0.02031

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.09353
Policy Update Magnitude: 0.48329
Value Function Update Magnitude: 0.64822

Collected Steps per Second: 22,503.22289
Overall Steps per Second: 10,471.94281

Timestep Collection Time: 2.22324
Timestep Consumption Time: 2.55429
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.77753

Cumulative Model Updates: 311,182
Cumulative Timesteps: 2,595,218,260

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2595218260...
Checkpoint 2595218260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.49394
Policy Entropy: 2.46053
Value Function Loss: 0.02016

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.10652
Policy Update Magnitude: 0.48477
Value Function Update Magnitude: 0.67984

Collected Steps per Second: 22,176.82680
Overall Steps per Second: 10,659.01425

Timestep Collection Time: 2.25515
Timestep Consumption Time: 2.43684
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.69199

Cumulative Model Updates: 311,188
Cumulative Timesteps: 2,595,268,272

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.23899
Policy Entropy: 2.44477
Value Function Loss: 0.02194

Mean KL Divergence: 0.02394
SB3 Clip Fraction: 0.14194
Policy Update Magnitude: 0.48657
Value Function Update Magnitude: 0.68754

Collected Steps per Second: 22,582.52882
Overall Steps per Second: 10,596.84777

Timestep Collection Time: 2.21463
Timestep Consumption Time: 2.50488
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.71952

Cumulative Model Updates: 311,194
Cumulative Timesteps: 2,595,318,284

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2595318284...
Checkpoint 2595318284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.96950
Policy Entropy: 2.44486
Value Function Loss: 0.02151

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.13050
Policy Update Magnitude: 0.47271
Value Function Update Magnitude: 0.67055

Collected Steps per Second: 22,321.96537
Overall Steps per Second: 10,609.61922

Timestep Collection Time: 2.24129
Timestep Consumption Time: 2.47424
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.71553

Cumulative Model Updates: 311,200
Cumulative Timesteps: 2,595,368,314

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.80139
Policy Entropy: 2.43640
Value Function Loss: 0.02233

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.11723
Policy Update Magnitude: 0.47430
Value Function Update Magnitude: 0.66550

Collected Steps per Second: 22,660.56125
Overall Steps per Second: 10,801.79571

Timestep Collection Time: 2.20665
Timestep Consumption Time: 2.42258
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.62923

Cumulative Model Updates: 311,206
Cumulative Timesteps: 2,595,418,318

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2595418318...
Checkpoint 2595418318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.08262
Policy Entropy: 2.44510
Value Function Loss: 0.02106

Mean KL Divergence: 0.02253
SB3 Clip Fraction: 0.12737
Policy Update Magnitude: 0.46260
Value Function Update Magnitude: 0.66580

Collected Steps per Second: 22,434.18286
Overall Steps per Second: 10,646.88638

Timestep Collection Time: 2.22919
Timestep Consumption Time: 2.46796
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.69715

Cumulative Model Updates: 311,212
Cumulative Timesteps: 2,595,468,328

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.26151
Policy Entropy: 2.45797
Value Function Loss: 0.02115

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.12439
Policy Update Magnitude: 0.47114
Value Function Update Magnitude: 0.64318

Collected Steps per Second: 22,503.88440
Overall Steps per Second: 10,589.13533

Timestep Collection Time: 2.22299
Timestep Consumption Time: 2.50128
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.72428

Cumulative Model Updates: 311,218
Cumulative Timesteps: 2,595,518,354

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2595518354...
Checkpoint 2595518354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.52391
Policy Entropy: 2.49525
Value Function Loss: 0.01979

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.11036
Policy Update Magnitude: 0.46674
Value Function Update Magnitude: 0.62595

Collected Steps per Second: 21,970.31245
Overall Steps per Second: 10,517.12757

Timestep Collection Time: 2.27662
Timestep Consumption Time: 2.47924
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.75586

Cumulative Model Updates: 311,224
Cumulative Timesteps: 2,595,568,372

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.95779
Policy Entropy: 2.49146
Value Function Loss: 0.02020

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.11270
Policy Update Magnitude: 0.46218
Value Function Update Magnitude: 0.59263

Collected Steps per Second: 22,000.38215
Overall Steps per Second: 10,511.63340

Timestep Collection Time: 2.27396
Timestep Consumption Time: 2.48534
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.75930

Cumulative Model Updates: 311,230
Cumulative Timesteps: 2,595,618,400

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2595618400...
Checkpoint 2595618400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.70367
Policy Entropy: 2.48203
Value Function Loss: 0.02059

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.12003
Policy Update Magnitude: 0.46084
Value Function Update Magnitude: 0.58601

Collected Steps per Second: 21,718.74735
Overall Steps per Second: 10,573.65258

Timestep Collection Time: 2.30253
Timestep Consumption Time: 2.42696
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.72949

Cumulative Model Updates: 311,236
Cumulative Timesteps: 2,595,668,408

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.98054
Policy Entropy: 2.46396
Value Function Loss: 0.02088

Mean KL Divergence: 0.02599
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.47588
Value Function Update Magnitude: 0.59870

Collected Steps per Second: 21,747.32885
Overall Steps per Second: 10,434.87675

Timestep Collection Time: 2.29922
Timestep Consumption Time: 2.49259
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.79182

Cumulative Model Updates: 311,242
Cumulative Timesteps: 2,595,718,410

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2595718410...
Checkpoint 2595718410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.48307
Policy Entropy: 2.44338
Value Function Loss: 0.02193

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.12364
Policy Update Magnitude: 0.49563
Value Function Update Magnitude: 0.63582

Collected Steps per Second: 21,810.99372
Overall Steps per Second: 10,616.83560

Timestep Collection Time: 2.29288
Timestep Consumption Time: 2.41756
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.71044

Cumulative Model Updates: 311,248
Cumulative Timesteps: 2,595,768,420

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.03512
Policy Entropy: 2.43512
Value Function Loss: 0.02128

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.12391
Policy Update Magnitude: 0.47600
Value Function Update Magnitude: 0.65181

Collected Steps per Second: 21,305.69597
Overall Steps per Second: 10,480.66634

Timestep Collection Time: 2.34735
Timestep Consumption Time: 2.42448
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.77183

Cumulative Model Updates: 311,254
Cumulative Timesteps: 2,595,818,432

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2595818432...
Checkpoint 2595818432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.84599
Policy Entropy: 2.43360
Value Function Loss: 0.02136

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.11910
Policy Update Magnitude: 0.47049
Value Function Update Magnitude: 0.64720

Collected Steps per Second: 21,846.96095
Overall Steps per Second: 10,581.69203

Timestep Collection Time: 2.28956
Timestep Consumption Time: 2.43747
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.72703

Cumulative Model Updates: 311,260
Cumulative Timesteps: 2,595,868,452

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.78867
Policy Entropy: 2.45848
Value Function Loss: 0.02034

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.11194
Policy Update Magnitude: 0.48228
Value Function Update Magnitude: 0.63010

Collected Steps per Second: 21,762.43990
Overall Steps per Second: 10,515.42800

Timestep Collection Time: 2.29754
Timestep Consumption Time: 2.45738
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.75492

Cumulative Model Updates: 311,266
Cumulative Timesteps: 2,595,918,452

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2595918452...
Checkpoint 2595918452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.15668
Policy Entropy: 2.44501
Value Function Loss: 0.02016

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.10575
Policy Update Magnitude: 0.47700
Value Function Update Magnitude: 0.62859

Collected Steps per Second: 21,885.50966
Overall Steps per Second: 10,604.64659

Timestep Collection Time: 2.28498
Timestep Consumption Time: 2.43069
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.71567

Cumulative Model Updates: 311,272
Cumulative Timesteps: 2,595,968,460

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.60517
Policy Entropy: 2.43961
Value Function Loss: 0.01913

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.47480
Value Function Update Magnitude: 0.62645

Collected Steps per Second: 22,391.99004
Overall Steps per Second: 10,837.44464

Timestep Collection Time: 2.23330
Timestep Consumption Time: 2.38107
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.61437

Cumulative Model Updates: 311,278
Cumulative Timesteps: 2,596,018,468

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2596018468...
Checkpoint 2596018468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.87735
Policy Entropy: 2.43625
Value Function Loss: 0.02029

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.10162
Policy Update Magnitude: 0.48135
Value Function Update Magnitude: 0.62567

Collected Steps per Second: 22,308.44490
Overall Steps per Second: 10,675.28751

Timestep Collection Time: 2.24148
Timestep Consumption Time: 2.44261
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.68409

Cumulative Model Updates: 311,284
Cumulative Timesteps: 2,596,068,472

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.05517
Policy Entropy: 2.44940
Value Function Loss: 0.02132

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.09839
Policy Update Magnitude: 0.48406
Value Function Update Magnitude: 0.64734

Collected Steps per Second: 21,893.76085
Overall Steps per Second: 10,518.11815

Timestep Collection Time: 2.28458
Timestep Consumption Time: 2.47084
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.75541

Cumulative Model Updates: 311,290
Cumulative Timesteps: 2,596,118,490

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2596118490...
Checkpoint 2596118490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.95290
Policy Entropy: 2.44310
Value Function Loss: 0.02177

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.11888
Policy Update Magnitude: 0.48687
Value Function Update Magnitude: 0.65501

Collected Steps per Second: 22,358.43195
Overall Steps per Second: 10,732.50943

Timestep Collection Time: 2.23719
Timestep Consumption Time: 2.42342
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.66061

Cumulative Model Updates: 311,296
Cumulative Timesteps: 2,596,168,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.34874
Policy Entropy: 2.42386
Value Function Loss: 0.02154

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.11322
Policy Update Magnitude: 0.49907
Value Function Update Magnitude: 0.65404

Collected Steps per Second: 22,546.61190
Overall Steps per Second: 10,765.60522

Timestep Collection Time: 2.21772
Timestep Consumption Time: 2.42689
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.64461

Cumulative Model Updates: 311,302
Cumulative Timesteps: 2,596,218,512

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2596218512...
Checkpoint 2596218512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.75092
Policy Entropy: 2.43178
Value Function Loss: 0.01974

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.10362
Policy Update Magnitude: 0.50547
Value Function Update Magnitude: 0.64891

Collected Steps per Second: 21,983.82196
Overall Steps per Second: 10,630.64341

Timestep Collection Time: 2.27549
Timestep Consumption Time: 2.43015
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.70564

Cumulative Model Updates: 311,308
Cumulative Timesteps: 2,596,268,536

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.74670
Policy Entropy: 2.44183
Value Function Loss: 0.02077

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.10150
Policy Update Magnitude: 0.49617
Value Function Update Magnitude: 0.64873

Collected Steps per Second: 21,323.24071
Overall Steps per Second: 10,479.73231

Timestep Collection Time: 2.34542
Timestep Consumption Time: 2.42684
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.77226

Cumulative Model Updates: 311,314
Cumulative Timesteps: 2,596,318,548

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2596318548...
Checkpoint 2596318548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.57884
Policy Entropy: 2.44872
Value Function Loss: 0.02204

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.09425
Policy Update Magnitude: 0.49713
Value Function Update Magnitude: 0.66648

Collected Steps per Second: 21,799.09332
Overall Steps per Second: 10,655.95705

Timestep Collection Time: 2.29450
Timestep Consumption Time: 2.39940
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.69390

Cumulative Model Updates: 311,320
Cumulative Timesteps: 2,596,368,566

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.49908
Policy Entropy: 2.45692
Value Function Loss: 0.02331

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.10376
Policy Update Magnitude: 0.49886
Value Function Update Magnitude: 0.67976

Collected Steps per Second: 22,277.49331
Overall Steps per Second: 10,509.32422

Timestep Collection Time: 2.24514
Timestep Consumption Time: 2.51407
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.75920

Cumulative Model Updates: 311,326
Cumulative Timesteps: 2,596,418,582

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2596418582...
Checkpoint 2596418582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.27160
Policy Entropy: 2.46407
Value Function Loss: 0.02219

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.10094
Policy Update Magnitude: 0.50243
Value Function Update Magnitude: 0.68689

Collected Steps per Second: 22,066.85104
Overall Steps per Second: 10,587.41037

Timestep Collection Time: 2.26693
Timestep Consumption Time: 2.45793
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.72486

Cumulative Model Updates: 311,332
Cumulative Timesteps: 2,596,468,606

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.99343
Policy Entropy: 2.47620
Value Function Loss: 0.01993

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.09818
Policy Update Magnitude: 0.48951
Value Function Update Magnitude: 0.67863

Collected Steps per Second: 22,329.04653
Overall Steps per Second: 10,504.04879

Timestep Collection Time: 2.23977
Timestep Consumption Time: 2.52144
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.76121

Cumulative Model Updates: 311,338
Cumulative Timesteps: 2,596,518,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2596518618...
Checkpoint 2596518618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.22840
Policy Entropy: 2.47898
Value Function Loss: 0.01997

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.08957
Policy Update Magnitude: 0.48275
Value Function Update Magnitude: 0.65070

Collected Steps per Second: 22,395.33217
Overall Steps per Second: 10,722.14942

Timestep Collection Time: 2.23261
Timestep Consumption Time: 2.43064
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.66324

Cumulative Model Updates: 311,344
Cumulative Timesteps: 2,596,568,618

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.54653
Policy Entropy: 2.48829
Value Function Loss: 0.02039

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.47915
Value Function Update Magnitude: 0.64279

Collected Steps per Second: 22,428.63289
Overall Steps per Second: 10,729.53295

Timestep Collection Time: 2.23010
Timestep Consumption Time: 2.43162
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.66171

Cumulative Model Updates: 311,350
Cumulative Timesteps: 2,596,618,636

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2596618636...
Checkpoint 2596618636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.50038
Policy Entropy: 2.48196
Value Function Loss: 0.02159

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.08361
Policy Update Magnitude: 0.48389
Value Function Update Magnitude: 0.64115

Collected Steps per Second: 22,127.14042
Overall Steps per Second: 10,655.18112

Timestep Collection Time: 2.25967
Timestep Consumption Time: 2.43288
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.69255

Cumulative Model Updates: 311,356
Cumulative Timesteps: 2,596,668,636

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.44303
Policy Entropy: 2.45827
Value Function Loss: 0.01991

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.09257
Policy Update Magnitude: 0.48698
Value Function Update Magnitude: 0.63520

Collected Steps per Second: 22,104.58776
Overall Steps per Second: 10,533.78446

Timestep Collection Time: 2.26315
Timestep Consumption Time: 2.48595
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.74910

Cumulative Model Updates: 311,362
Cumulative Timesteps: 2,596,718,662

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2596718662...
Checkpoint 2596718662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.92291
Policy Entropy: 2.44819
Value Function Loss: 0.01987

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.47555
Value Function Update Magnitude: 0.62827

Collected Steps per Second: 22,313.81122
Overall Steps per Second: 10,761.41648

Timestep Collection Time: 2.24112
Timestep Consumption Time: 2.40585
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.64697

Cumulative Model Updates: 311,368
Cumulative Timesteps: 2,596,768,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.94597
Policy Entropy: 2.45568
Value Function Loss: 0.01909

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.10089
Policy Update Magnitude: 0.47068
Value Function Update Magnitude: 0.63358

Collected Steps per Second: 22,106.03569
Overall Steps per Second: 10,676.27395

Timestep Collection Time: 2.26255
Timestep Consumption Time: 2.42223
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.68478

Cumulative Model Updates: 311,374
Cumulative Timesteps: 2,596,818,686

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2596818686...
Checkpoint 2596818686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.58995
Policy Entropy: 2.46878
Value Function Loss: 0.01937

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.46863
Value Function Update Magnitude: 0.63943

Collected Steps per Second: 21,884.39805
Overall Steps per Second: 10,627.59790

Timestep Collection Time: 2.28565
Timestep Consumption Time: 2.42097
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.70661

Cumulative Model Updates: 311,380
Cumulative Timesteps: 2,596,868,706

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.48543
Policy Entropy: 2.48270
Value Function Loss: 0.01928

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.09942
Policy Update Magnitude: 0.47483
Value Function Update Magnitude: 0.64346

Collected Steps per Second: 21,736.86886
Overall Steps per Second: 10,551.15387

Timestep Collection Time: 2.30024
Timestep Consumption Time: 2.43858
PPO Batch Consumption Time: 0.28383
Total Iteration Time: 4.73882

Cumulative Model Updates: 311,386
Cumulative Timesteps: 2,596,918,706

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2596918706...
Checkpoint 2596918706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.93002
Policy Entropy: 2.46315
Value Function Loss: 0.02024

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.09600
Policy Update Magnitude: 0.47205
Value Function Update Magnitude: 0.63144

Collected Steps per Second: 21,611.71165
Overall Steps per Second: 10,632.54275

Timestep Collection Time: 2.31402
Timestep Consumption Time: 2.38946
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.70348

Cumulative Model Updates: 311,392
Cumulative Timesteps: 2,596,968,716

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.57284
Policy Entropy: 2.47421
Value Function Loss: 0.01988

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.49011
Value Function Update Magnitude: 0.61806

Collected Steps per Second: 22,011.35621
Overall Steps per Second: 10,441.92436

Timestep Collection Time: 2.27255
Timestep Consumption Time: 2.51794
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.79050

Cumulative Model Updates: 311,398
Cumulative Timesteps: 2,597,018,738

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2597018738...
Checkpoint 2597018738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.52981
Policy Entropy: 2.46303
Value Function Loss: 0.02022

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.08687
Policy Update Magnitude: 0.48256
Value Function Update Magnitude: 0.61273

Collected Steps per Second: 21,954.89346
Overall Steps per Second: 10,593.82021

Timestep Collection Time: 2.27767
Timestep Consumption Time: 2.44263
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.72030

Cumulative Model Updates: 311,404
Cumulative Timesteps: 2,597,068,744

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.21421
Policy Entropy: 2.48092
Value Function Loss: 0.02004

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.08181
Policy Update Magnitude: 0.50932
Value Function Update Magnitude: 0.62690

Collected Steps per Second: 22,278.61203
Overall Steps per Second: 10,480.17436

Timestep Collection Time: 2.24457
Timestep Consumption Time: 2.52691
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.77149

Cumulative Model Updates: 311,410
Cumulative Timesteps: 2,597,118,750

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2597118750...
Checkpoint 2597118750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.05524
Policy Entropy: 2.47042
Value Function Loss: 0.01995

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.08321
Policy Update Magnitude: 0.49943
Value Function Update Magnitude: 0.62723

Collected Steps per Second: 22,389.58377
Overall Steps per Second: 10,701.85639

Timestep Collection Time: 2.23381
Timestep Consumption Time: 2.43959
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.67339

Cumulative Model Updates: 311,416
Cumulative Timesteps: 2,597,168,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.14080
Policy Entropy: 2.46513
Value Function Loss: 0.01988

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.08700
Policy Update Magnitude: 0.48568
Value Function Update Magnitude: 0.62851

Collected Steps per Second: 22,474.62056
Overall Steps per Second: 10,625.20601

Timestep Collection Time: 2.22527
Timestep Consumption Time: 2.48165
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.70692

Cumulative Model Updates: 311,422
Cumulative Timesteps: 2,597,218,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2597218776...
Checkpoint 2597218776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.70886
Policy Entropy: 2.46680
Value Function Loss: 0.01993

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.47961
Value Function Update Magnitude: 0.62795

Collected Steps per Second: 22,441.53688
Overall Steps per Second: 10,594.96424

Timestep Collection Time: 2.22801
Timestep Consumption Time: 2.49121
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.71922

Cumulative Model Updates: 311,428
Cumulative Timesteps: 2,597,268,776

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.35651
Policy Entropy: 2.46325
Value Function Loss: 0.02095

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.09651
Policy Update Magnitude: 0.47151
Value Function Update Magnitude: 0.62069

Collected Steps per Second: 22,101.75299
Overall Steps per Second: 10,703.67596

Timestep Collection Time: 2.26317
Timestep Consumption Time: 2.40999
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.67316

Cumulative Model Updates: 311,434
Cumulative Timesteps: 2,597,318,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2597318796...
Checkpoint 2597318796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.38550
Policy Entropy: 2.46121
Value Function Loss: 0.02067

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.10639
Policy Update Magnitude: 0.48553
Value Function Update Magnitude: 0.62759

Collected Steps per Second: 22,469.93890
Overall Steps per Second: 10,738.86123

Timestep Collection Time: 2.22528
Timestep Consumption Time: 2.43089
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.65617

Cumulative Model Updates: 311,440
Cumulative Timesteps: 2,597,368,798

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.89923
Policy Entropy: 2.45702
Value Function Loss: 0.02186

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.12198
Policy Update Magnitude: 0.47925
Value Function Update Magnitude: 0.64562

Collected Steps per Second: 22,122.27372
Overall Steps per Second: 10,480.72457

Timestep Collection Time: 2.26143
Timestep Consumption Time: 2.51190
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.77333

Cumulative Model Updates: 311,446
Cumulative Timesteps: 2,597,418,826

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2597418826...
Checkpoint 2597418826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.22145
Policy Entropy: 2.46944
Value Function Loss: 0.02091

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.11130
Policy Update Magnitude: 0.46454
Value Function Update Magnitude: 0.66659

Collected Steps per Second: 21,985.96463
Overall Steps per Second: 10,537.93390

Timestep Collection Time: 2.27427
Timestep Consumption Time: 2.47068
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.74495

Cumulative Model Updates: 311,452
Cumulative Timesteps: 2,597,468,828

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.19903
Policy Entropy: 2.46596
Value Function Loss: 0.02082

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.09722
Policy Update Magnitude: 0.47863
Value Function Update Magnitude: 0.66856

Collected Steps per Second: 21,770.75259
Overall Steps per Second: 10,480.25682

Timestep Collection Time: 2.29730
Timestep Consumption Time: 2.47491
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.77221

Cumulative Model Updates: 311,458
Cumulative Timesteps: 2,597,518,842

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2597518842...
Checkpoint 2597518842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.23206
Policy Entropy: 2.46609
Value Function Loss: 0.01952

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.09945
Policy Update Magnitude: 0.48819
Value Function Update Magnitude: 0.66310

Collected Steps per Second: 21,788.43649
Overall Steps per Second: 10,608.07211

Timestep Collection Time: 2.29507
Timestep Consumption Time: 2.41889
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.71396

Cumulative Model Updates: 311,464
Cumulative Timesteps: 2,597,568,848

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.89089
Policy Entropy: 2.45027
Value Function Loss: 0.01987

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.10424
Policy Update Magnitude: 0.49028
Value Function Update Magnitude: 0.63968

Collected Steps per Second: 21,488.44363
Overall Steps per Second: 10,509.45843

Timestep Collection Time: 2.32711
Timestep Consumption Time: 2.43108
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.75819

Cumulative Model Updates: 311,470
Cumulative Timesteps: 2,597,618,854

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2597618854...
Checkpoint 2597618854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.57144
Policy Entropy: 2.46158
Value Function Loss: 0.02015

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.49281
Value Function Update Magnitude: 0.61699

Collected Steps per Second: 22,193.39531
Overall Steps per Second: 10,562.44034

Timestep Collection Time: 2.25337
Timestep Consumption Time: 2.48133
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.73470

Cumulative Model Updates: 311,476
Cumulative Timesteps: 2,597,668,864

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.39978
Policy Entropy: 2.48479
Value Function Loss: 0.01985

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.09748
Policy Update Magnitude: 0.48512
Value Function Update Magnitude: 0.61868

Collected Steps per Second: 20,862.22552
Overall Steps per Second: 10,042.92900

Timestep Collection Time: 2.39763
Timestep Consumption Time: 2.58298
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.98062

Cumulative Model Updates: 311,482
Cumulative Timesteps: 2,597,718,884

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2597718884...
Checkpoint 2597718884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.73373
Policy Entropy: 2.48047
Value Function Loss: 0.01950

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.08834
Policy Update Magnitude: 0.48652
Value Function Update Magnitude: 0.62508

Collected Steps per Second: 22,306.65119
Overall Steps per Second: 10,645.23366

Timestep Collection Time: 2.24175
Timestep Consumption Time: 2.45575
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.69750

Cumulative Model Updates: 311,488
Cumulative Timesteps: 2,597,768,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.40713
Policy Entropy: 2.48545
Value Function Loss: 0.01896

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.08905
Policy Update Magnitude: 0.48378
Value Function Update Magnitude: 0.60971

Collected Steps per Second: 22,517.04094
Overall Steps per Second: 10,534.22020

Timestep Collection Time: 2.22161
Timestep Consumption Time: 2.52711
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.74871

Cumulative Model Updates: 311,494
Cumulative Timesteps: 2,597,818,914

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2597818914...
Checkpoint 2597818914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.33048
Policy Entropy: 2.46169
Value Function Loss: 0.02013

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.09874
Policy Update Magnitude: 0.47618
Value Function Update Magnitude: 0.61570

Collected Steps per Second: 22,417.19527
Overall Steps per Second: 10,585.94673

Timestep Collection Time: 2.23159
Timestep Consumption Time: 2.49411
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.72570

Cumulative Model Updates: 311,500
Cumulative Timesteps: 2,597,868,940

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.09583
Policy Entropy: 2.45111
Value Function Loss: 0.02061

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.10227
Policy Update Magnitude: 0.48007
Value Function Update Magnitude: 0.65125

Collected Steps per Second: 22,309.65818
Overall Steps per Second: 10,523.90125

Timestep Collection Time: 2.24136
Timestep Consumption Time: 2.51011
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.75147

Cumulative Model Updates: 311,506
Cumulative Timesteps: 2,597,918,944

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2597918944...
Checkpoint 2597918944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.65031
Policy Entropy: 2.43566
Value Function Loss: 0.02125

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.09958
Policy Update Magnitude: 0.49996
Value Function Update Magnitude: 0.68627

Collected Steps per Second: 22,219.36117
Overall Steps per Second: 10,591.05808

Timestep Collection Time: 2.25092
Timestep Consumption Time: 2.47137
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.72229

Cumulative Model Updates: 311,512
Cumulative Timesteps: 2,597,968,958

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.76710
Policy Entropy: 2.45587
Value Function Loss: 0.02106

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.10124
Policy Update Magnitude: 0.50453
Value Function Update Magnitude: 0.69198

Collected Steps per Second: 23,367.00362
Overall Steps per Second: 10,959.25389

Timestep Collection Time: 2.14097
Timestep Consumption Time: 2.42394
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.56491

Cumulative Model Updates: 311,518
Cumulative Timesteps: 2,598,018,986

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2598018986...
Checkpoint 2598018986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276.61166
Policy Entropy: 2.48012
Value Function Loss: 0.02020

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.09525
Policy Update Magnitude: 0.49156
Value Function Update Magnitude: 0.69576

Collected Steps per Second: 22,174.94811
Overall Steps per Second: 10,590.02618

Timestep Collection Time: 2.25489
Timestep Consumption Time: 2.46673
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.72161

Cumulative Model Updates: 311,524
Cumulative Timesteps: 2,598,068,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.37650
Policy Entropy: 2.48938
Value Function Loss: 0.01915

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.09866
Policy Update Magnitude: 0.48396
Value Function Update Magnitude: 0.68450

Collected Steps per Second: 22,003.80961
Overall Steps per Second: 10,458.27157

Timestep Collection Time: 2.27352
Timestep Consumption Time: 2.50988
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.78339

Cumulative Model Updates: 311,530
Cumulative Timesteps: 2,598,119,014

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2598119014...
Checkpoint 2598119014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.93423
Policy Entropy: 2.47468
Value Function Loss: 0.01974

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.48726
Value Function Update Magnitude: 0.67379

Collected Steps per Second: 21,815.25254
Overall Steps per Second: 10,628.31586

Timestep Collection Time: 2.29234
Timestep Consumption Time: 2.41283
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.70517

Cumulative Model Updates: 311,536
Cumulative Timesteps: 2,598,169,022

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.16712
Policy Entropy: 2.46948
Value Function Loss: 0.02041

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.09902
Policy Update Magnitude: 0.48828
Value Function Update Magnitude: 0.67161

Collected Steps per Second: 21,633.45986
Overall Steps per Second: 10,548.63354

Timestep Collection Time: 2.31225
Timestep Consumption Time: 2.42978
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.74204

Cumulative Model Updates: 311,542
Cumulative Timesteps: 2,598,219,044

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2598219044...
Checkpoint 2598219044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.08968
Policy Entropy: 2.47127
Value Function Loss: 0.01984

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.09167
Policy Update Magnitude: 0.48036
Value Function Update Magnitude: 0.65592

Collected Steps per Second: 21,838.98848
Overall Steps per Second: 10,609.49516

Timestep Collection Time: 2.29049
Timestep Consumption Time: 2.42434
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.71483

Cumulative Model Updates: 311,548
Cumulative Timesteps: 2,598,269,066

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.28635
Policy Entropy: 2.48420
Value Function Loss: 0.01848

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.08704
Policy Update Magnitude: 0.47029
Value Function Update Magnitude: 0.64088

Collected Steps per Second: 22,119.94966
Overall Steps per Second: 10,484.34431

Timestep Collection Time: 2.26167
Timestep Consumption Time: 2.51002
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.77169

Cumulative Model Updates: 311,554
Cumulative Timesteps: 2,598,319,094

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2598319094...
Checkpoint 2598319094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.03028
Policy Entropy: 2.51098
Value Function Loss: 0.01733

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.08999
Policy Update Magnitude: 0.46370
Value Function Update Magnitude: 0.63700

Collected Steps per Second: 22,407.48358
Overall Steps per Second: 10,661.15484

Timestep Collection Time: 2.23256
Timestep Consumption Time: 2.45980
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.69236

Cumulative Model Updates: 311,560
Cumulative Timesteps: 2,598,369,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.99874
Policy Entropy: 2.50648
Value Function Loss: 0.01875

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.09554
Policy Update Magnitude: 0.46172
Value Function Update Magnitude: 0.62950

Collected Steps per Second: 22,751.51654
Overall Steps per Second: 10,774.48229

Timestep Collection Time: 2.19766
Timestep Consumption Time: 2.44294
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.64059

Cumulative Model Updates: 311,566
Cumulative Timesteps: 2,598,419,120

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2598419120...
Checkpoint 2598419120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.70787
Policy Entropy: 2.51315
Value Function Loss: 0.01943

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.46032
Value Function Update Magnitude: 0.63649

Collected Steps per Second: 22,195.30242
Overall Steps per Second: 10,688.72567

Timestep Collection Time: 2.25336
Timestep Consumption Time: 2.42578
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.67914

Cumulative Model Updates: 311,572
Cumulative Timesteps: 2,598,469,134

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.81784
Policy Entropy: 2.50093
Value Function Loss: 0.02055

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.47015
Value Function Update Magnitude: 0.65544

Collected Steps per Second: 22,342.78247
Overall Steps per Second: 10,553.55219

Timestep Collection Time: 2.23884
Timestep Consumption Time: 2.50098
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.73983

Cumulative Model Updates: 311,578
Cumulative Timesteps: 2,598,519,156

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2598519156...
Checkpoint 2598519156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.69884
Policy Entropy: 2.49896
Value Function Loss: 0.01978

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.09159
Policy Update Magnitude: 0.47207
Value Function Update Magnitude: 0.66454

Collected Steps per Second: 22,365.88698
Overall Steps per Second: 10,595.24346

Timestep Collection Time: 2.23564
Timestep Consumption Time: 2.48365
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.71929

Cumulative Model Updates: 311,584
Cumulative Timesteps: 2,598,569,158

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.95551
Policy Entropy: 2.47212
Value Function Loss: 0.02052

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.09630
Policy Update Magnitude: 0.48317
Value Function Update Magnitude: 0.67226

Collected Steps per Second: 22,456.63986
Overall Steps per Second: 10,803.92483

Timestep Collection Time: 2.22758
Timestep Consumption Time: 2.40259
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.63017

Cumulative Model Updates: 311,590
Cumulative Timesteps: 2,598,619,182

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2598619182...
Checkpoint 2598619182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.78279
Policy Entropy: 2.46000
Value Function Loss: 0.01979

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.47754
Value Function Update Magnitude: 0.67367

Collected Steps per Second: 21,905.62561
Overall Steps per Second: 10,581.10717

Timestep Collection Time: 2.28298
Timestep Consumption Time: 2.44337
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.72635

Cumulative Model Updates: 311,596
Cumulative Timesteps: 2,598,669,192

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.71129
Policy Entropy: 2.48203
Value Function Loss: 0.01922

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.47546
Value Function Update Magnitude: 0.66692

Collected Steps per Second: 22,044.76500
Overall Steps per Second: 10,560.95905

Timestep Collection Time: 2.26893
Timestep Consumption Time: 2.46719
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.73612

Cumulative Model Updates: 311,602
Cumulative Timesteps: 2,598,719,210

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2598719210...
Checkpoint 2598719210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.06102
Policy Entropy: 2.49056
Value Function Loss: 0.01923

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.09340
Policy Update Magnitude: 0.47090
Value Function Update Magnitude: 0.64682

Collected Steps per Second: 21,868.82213
Overall Steps per Second: 10,666.54726

Timestep Collection Time: 2.28755
Timestep Consumption Time: 2.40244
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.68999

Cumulative Model Updates: 311,608
Cumulative Timesteps: 2,598,769,236

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.65975
Policy Entropy: 2.48614
Value Function Loss: 0.01944

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.09317
Policy Update Magnitude: 0.46492
Value Function Update Magnitude: 0.62243

Collected Steps per Second: 21,964.40491
Overall Steps per Second: 10,720.88157

Timestep Collection Time: 2.27769
Timestep Consumption Time: 2.38872
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.66641

Cumulative Model Updates: 311,614
Cumulative Timesteps: 2,598,819,264

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2598819264...
Checkpoint 2598819264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.76528
Policy Entropy: 2.48531
Value Function Loss: 0.01980

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.08342
Policy Update Magnitude: 0.46283
Value Function Update Magnitude: 0.59630

Collected Steps per Second: 21,991.41640
Overall Steps per Second: 10,512.11860

Timestep Collection Time: 2.27452
Timestep Consumption Time: 2.48379
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.75832

Cumulative Model Updates: 311,620
Cumulative Timesteps: 2,598,869,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.98793
Policy Entropy: 2.49112
Value Function Loss: 0.01951

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.08869
Policy Update Magnitude: 0.46553
Value Function Update Magnitude: 0.59866

Collected Steps per Second: 22,264.33236
Overall Steps per Second: 10,676.39392

Timestep Collection Time: 2.24691
Timestep Consumption Time: 2.43875
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.68566

Cumulative Model Updates: 311,626
Cumulative Timesteps: 2,598,919,310

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2598919310...
Checkpoint 2598919310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.20185
Policy Entropy: 2.50529
Value Function Loss: 0.01910

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.08739
Policy Update Magnitude: 0.46142
Value Function Update Magnitude: 0.60070

Collected Steps per Second: 22,145.21558
Overall Steps per Second: 10,639.79688

Timestep Collection Time: 2.25828
Timestep Consumption Time: 2.44200
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.70028

Cumulative Model Updates: 311,632
Cumulative Timesteps: 2,598,969,320

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.73843
Policy Entropy: 2.49275
Value Function Loss: 0.01943

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.45622
Value Function Update Magnitude: 0.60985

Collected Steps per Second: 22,113.61180
Overall Steps per Second: 10,673.76897

Timestep Collection Time: 2.26123
Timestep Consumption Time: 2.42352
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.68476

Cumulative Model Updates: 311,638
Cumulative Timesteps: 2,599,019,324

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2599019324...
Checkpoint 2599019324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.99723
Policy Entropy: 2.50191
Value Function Loss: 0.02042

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.09600
Policy Update Magnitude: 0.46724
Value Function Update Magnitude: 0.61351

Collected Steps per Second: 22,536.56956
Overall Steps per Second: 10,618.86651

Timestep Collection Time: 2.21986
Timestep Consumption Time: 2.49138
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.71124

Cumulative Model Updates: 311,644
Cumulative Timesteps: 2,599,069,352

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.03252
Policy Entropy: 2.50364
Value Function Loss: 0.02080

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.10705
Policy Update Magnitude: 0.47716
Value Function Update Magnitude: 0.62088

Collected Steps per Second: 22,441.83236
Overall Steps per Second: 10,736.59103

Timestep Collection Time: 2.22861
Timestep Consumption Time: 2.42967
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.65828

Cumulative Model Updates: 311,650
Cumulative Timesteps: 2,599,119,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2599119366...
Checkpoint 2599119366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.07751
Policy Entropy: 2.51044
Value Function Loss: 0.02008

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.46682
Value Function Update Magnitude: 0.61064

Collected Steps per Second: 22,212.94067
Overall Steps per Second: 10,657.52778

Timestep Collection Time: 2.25130
Timestep Consumption Time: 2.44097
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.69227

Cumulative Model Updates: 311,656
Cumulative Timesteps: 2,599,169,374

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.96020
Policy Entropy: 2.49962
Value Function Loss: 0.01871

Mean KL Divergence: 0.02316
SB3 Clip Fraction: 0.13322
Policy Update Magnitude: 0.49252
Value Function Update Magnitude: 0.61094

Collected Steps per Second: 22,526.52694
Overall Steps per Second: 10,935.49188

Timestep Collection Time: 2.21996
Timestep Consumption Time: 2.35304
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.57300

Cumulative Model Updates: 311,662
Cumulative Timesteps: 2,599,219,382

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2599219382...
Checkpoint 2599219382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.27402
Policy Entropy: 2.48700
Value Function Loss: 0.01943

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.12343
Policy Update Magnitude: 0.48833
Value Function Update Magnitude: 0.61903

Collected Steps per Second: 21,782.13666
Overall Steps per Second: 10,591.65699

Timestep Collection Time: 2.29684
Timestep Consumption Time: 2.42669
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.72353

Cumulative Model Updates: 311,668
Cumulative Timesteps: 2,599,269,412

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.83588
Policy Entropy: 2.49732
Value Function Loss: 0.02006

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.49038
Value Function Update Magnitude: 0.61940

Collected Steps per Second: 21,931.48710
Overall Steps per Second: 10,523.96414

Timestep Collection Time: 2.28065
Timestep Consumption Time: 2.47212
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.75277

Cumulative Model Updates: 311,674
Cumulative Timesteps: 2,599,319,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2599319430...
Checkpoint 2599319430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.14194
Policy Entropy: 2.49046
Value Function Loss: 0.02017

Mean KL Divergence: 0.02250
SB3 Clip Fraction: 0.11917
Policy Update Magnitude: 0.49704
Value Function Update Magnitude: 0.62853

Collected Steps per Second: 21,854.37620
Overall Steps per Second: 10,649.00959

Timestep Collection Time: 2.28851
Timestep Consumption Time: 2.40808
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.69659

Cumulative Model Updates: 311,680
Cumulative Timesteps: 2,599,369,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.18563
Policy Entropy: 2.48838
Value Function Loss: 0.02128

Mean KL Divergence: 0.02834
SB3 Clip Fraction: 0.14391
Policy Update Magnitude: 0.48096
Value Function Update Magnitude: 0.62810

Collected Steps per Second: 22,219.04972
Overall Steps per Second: 10,612.67698

Timestep Collection Time: 2.25059
Timestep Consumption Time: 2.46132
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.71191

Cumulative Model Updates: 311,686
Cumulative Timesteps: 2,599,419,450

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2599419450...
Checkpoint 2599419450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.13491
Policy Entropy: 2.45698
Value Function Loss: 0.02107

Mean KL Divergence: 0.02345
SB3 Clip Fraction: 0.12710
Policy Update Magnitude: 0.49558
Value Function Update Magnitude: 0.66908

Collected Steps per Second: 22,394.67419
Overall Steps per Second: 10,586.43093

Timestep Collection Time: 2.23401
Timestep Consumption Time: 2.49185
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.72586

Cumulative Model Updates: 311,692
Cumulative Timesteps: 2,599,469,480

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.91627
Policy Entropy: 2.46630
Value Function Loss: 0.02100

Mean KL Divergence: 0.02256
SB3 Clip Fraction: 0.11002
Policy Update Magnitude: 0.50333
Value Function Update Magnitude: 0.68560

Collected Steps per Second: 22,427.49647
Overall Steps per Second: 10,548.65157

Timestep Collection Time: 2.23021
Timestep Consumption Time: 2.51144
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.74165

Cumulative Model Updates: 311,698
Cumulative Timesteps: 2,599,519,498

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2599519498...
Checkpoint 2599519498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.36249
Policy Entropy: 2.45496
Value Function Loss: 0.01943

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.10097
Policy Update Magnitude: 0.50971
Value Function Update Magnitude: 0.69179

Collected Steps per Second: 22,297.10380
Overall Steps per Second: 10,498.12580

Timestep Collection Time: 2.24253
Timestep Consumption Time: 2.52041
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.76295

Cumulative Model Updates: 311,704
Cumulative Timesteps: 2,599,569,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.55176
Policy Entropy: 2.47311
Value Function Loss: 0.01992

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.49608
Value Function Update Magnitude: 0.71749

Collected Steps per Second: 21,431.42514
Overall Steps per Second: 10,295.83000

Timestep Collection Time: 2.33330
Timestep Consumption Time: 2.52362
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.85692

Cumulative Model Updates: 311,710
Cumulative Timesteps: 2,599,619,506

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2599619506...
Checkpoint 2599619506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.01099
Policy Entropy: 2.44345
Value Function Loss: 0.01979

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.08822
Policy Update Magnitude: 0.49934
Value Function Update Magnitude: 0.71219

Collected Steps per Second: 21,946.62434
Overall Steps per Second: 10,706.24831

Timestep Collection Time: 2.27917
Timestep Consumption Time: 2.39287
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.67204

Cumulative Model Updates: 311,716
Cumulative Timesteps: 2,599,669,526

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.74458
Policy Entropy: 2.46750
Value Function Loss: 0.01986

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.08076
Policy Update Magnitude: 0.48665
Value Function Update Magnitude: 0.69375

Collected Steps per Second: 22,379.04394
Overall Steps per Second: 10,571.74916

Timestep Collection Time: 2.23531
Timestep Consumption Time: 2.49655
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.73186

Cumulative Model Updates: 311,722
Cumulative Timesteps: 2,599,719,550

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2599719550...
Checkpoint 2599719550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.45495
Policy Entropy: 2.43449
Value Function Loss: 0.02084

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.09366
Policy Update Magnitude: 0.49895
Value Function Update Magnitude: 0.68981

Collected Steps per Second: 22,036.36626
Overall Steps per Second: 10,496.86592

Timestep Collection Time: 2.26970
Timestep Consumption Time: 2.49515
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.76485

Cumulative Model Updates: 311,728
Cumulative Timesteps: 2,599,769,566

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.91084
Policy Entropy: 2.44684
Value Function Loss: 0.02120

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.10090
Policy Update Magnitude: 0.51356
Value Function Update Magnitude: 0.69389

Collected Steps per Second: 22,656.96914
Overall Steps per Second: 10,929.41418

Timestep Collection Time: 2.20815
Timestep Consumption Time: 2.36940
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.57756

Cumulative Model Updates: 311,734
Cumulative Timesteps: 2,599,819,596

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2599819596...
Checkpoint 2599819596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.33731
Policy Entropy: 2.43020
Value Function Loss: 0.02281

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.09781
Policy Update Magnitude: 0.51653
Value Function Update Magnitude: 0.71330

Collected Steps per Second: 21,875.85931
Overall Steps per Second: 10,616.89950

Timestep Collection Time: 2.28672
Timestep Consumption Time: 2.42501
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.71173

Cumulative Model Updates: 311,740
Cumulative Timesteps: 2,599,869,620

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.51737
Policy Entropy: 2.43726
Value Function Loss: 0.02239

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.10204
Policy Update Magnitude: 0.52565
Value Function Update Magnitude: 0.72039

Collected Steps per Second: 21,928.39600
Overall Steps per Second: 10,553.59427

Timestep Collection Time: 2.28115
Timestep Consumption Time: 2.45866
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.73981

Cumulative Model Updates: 311,746
Cumulative Timesteps: 2,599,919,642

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2599919642...
Checkpoint 2599919642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.32650
Policy Entropy: 2.42777
Value Function Loss: 0.02336

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.10147
Policy Update Magnitude: 0.52510
Value Function Update Magnitude: 0.71636

Collected Steps per Second: 21,821.11051
Overall Steps per Second: 10,667.93478

Timestep Collection Time: 2.29255
Timestep Consumption Time: 2.39683
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.68938

Cumulative Model Updates: 311,752
Cumulative Timesteps: 2,599,969,668

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.73268
Policy Entropy: 2.43971
Value Function Loss: 0.02188

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.52687
Value Function Update Magnitude: 0.71243

Collected Steps per Second: 22,364.60521
Overall Steps per Second: 10,625.35036

Timestep Collection Time: 2.23666
Timestep Consumption Time: 2.47114
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.70780

Cumulative Model Updates: 311,758
Cumulative Timesteps: 2,600,019,690

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2600019690...
Checkpoint 2600019690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.18305
Policy Entropy: 2.43832
Value Function Loss: 0.02205

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.10407
Policy Update Magnitude: 0.51516
Value Function Update Magnitude: 0.69116

Collected Steps per Second: 22,172.94704
Overall Steps per Second: 10,509.69124

Timestep Collection Time: 2.25581
Timestep Consumption Time: 2.50341
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.75923

Cumulative Model Updates: 311,764
Cumulative Timesteps: 2,600,069,708

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.31231
Policy Entropy: 2.46833
Value Function Loss: 0.02065

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.09596
Policy Update Magnitude: 0.50261
Value Function Update Magnitude: 0.68222

Collected Steps per Second: 22,330.02814
Overall Steps per Second: 10,553.88108

Timestep Collection Time: 2.24030
Timestep Consumption Time: 2.49976
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.74006

Cumulative Model Updates: 311,770
Cumulative Timesteps: 2,600,119,734

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2600119734...
Checkpoint 2600119734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.33603
Policy Entropy: 2.44467
Value Function Loss: 0.02087

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.09578
Policy Update Magnitude: 0.50249
Value Function Update Magnitude: 0.68919

Collected Steps per Second: 22,200.27323
Overall Steps per Second: 10,469.98653

Timestep Collection Time: 2.25249
Timestep Consumption Time: 2.52363
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.77613

Cumulative Model Updates: 311,776
Cumulative Timesteps: 2,600,169,740

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.02440
Policy Entropy: 2.46842
Value Function Loss: 0.02007

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.09975
Policy Update Magnitude: 0.49732
Value Function Update Magnitude: 0.70490

Collected Steps per Second: 22,435.35012
Overall Steps per Second: 10,868.94544

Timestep Collection Time: 2.22943
Timestep Consumption Time: 2.37249
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.60192

Cumulative Model Updates: 311,782
Cumulative Timesteps: 2,600,219,758

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2600219758...
Checkpoint 2600219758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.04545
Policy Entropy: 2.45564
Value Function Loss: 0.02136

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.11630
Policy Update Magnitude: 0.49980
Value Function Update Magnitude: 0.70121

Collected Steps per Second: 22,344.62708
Overall Steps per Second: 10,642.54832

Timestep Collection Time: 2.23767
Timestep Consumption Time: 2.46045
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.69812

Cumulative Model Updates: 311,788
Cumulative Timesteps: 2,600,269,758

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.80778
Policy Entropy: 2.47378
Value Function Loss: 0.02023

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.11868
Policy Update Magnitude: 0.50438
Value Function Update Magnitude: 0.70035

Collected Steps per Second: 22,459.49774
Overall Steps per Second: 10,561.81031

Timestep Collection Time: 2.22721
Timestep Consumption Time: 2.50891
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.73612

Cumulative Model Updates: 311,794
Cumulative Timesteps: 2,600,319,780

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2600319780...
Checkpoint 2600319780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.27074
Policy Entropy: 2.43927
Value Function Loss: 0.02135

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.11203
Policy Update Magnitude: 0.51601
Value Function Update Magnitude: 0.69581

Collected Steps per Second: 22,306.85586
Overall Steps per Second: 10,613.43949

Timestep Collection Time: 2.24245
Timestep Consumption Time: 2.47063
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.71308

Cumulative Model Updates: 311,800
Cumulative Timesteps: 2,600,369,802

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.57922
Policy Entropy: 2.43481
Value Function Loss: 0.02113

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.10436
Policy Update Magnitude: 0.51744
Value Function Update Magnitude: 0.69651

Collected Steps per Second: 22,630.91516
Overall Steps per Second: 10,844.05144

Timestep Collection Time: 2.20981
Timestep Consumption Time: 2.40194
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.61175

Cumulative Model Updates: 311,806
Cumulative Timesteps: 2,600,419,812

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2600419812...
Checkpoint 2600419812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.49764
Policy Entropy: 2.44659
Value Function Loss: 0.02101

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.10126
Policy Update Magnitude: 0.50820
Value Function Update Magnitude: 0.69523

Collected Steps per Second: 22,166.78212
Overall Steps per Second: 10,690.57909

Timestep Collection Time: 2.25617
Timestep Consumption Time: 2.42197
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.67814

Cumulative Model Updates: 311,812
Cumulative Timesteps: 2,600,469,824

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.53904
Policy Entropy: 2.46864
Value Function Loss: 0.01937

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.09427
Policy Update Magnitude: 0.49473
Value Function Update Magnitude: 0.67424

Collected Steps per Second: 22,016.03555
Overall Steps per Second: 10,470.18917

Timestep Collection Time: 2.27253
Timestep Consumption Time: 2.50599
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.77852

Cumulative Model Updates: 311,818
Cumulative Timesteps: 2,600,519,856

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2600519856...
Checkpoint 2600519856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.10674
Policy Entropy: 2.47624
Value Function Loss: 0.01976

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.09373
Policy Update Magnitude: 0.48804
Value Function Update Magnitude: 0.66836

Collected Steps per Second: 21,948.18109
Overall Steps per Second: 10,645.51347

Timestep Collection Time: 2.27846
Timestep Consumption Time: 2.41911
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.69757

Cumulative Model Updates: 311,824
Cumulative Timesteps: 2,600,569,864

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.98206
Policy Entropy: 2.45622
Value Function Loss: 0.01911

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.08990
Policy Update Magnitude: 0.48142
Value Function Update Magnitude: 0.66756

Collected Steps per Second: 22,047.87346
Overall Steps per Second: 10,557.08396

Timestep Collection Time: 2.26852
Timestep Consumption Time: 2.46915
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.73767

Cumulative Model Updates: 311,830
Cumulative Timesteps: 2,600,619,880

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2600619880...
Checkpoint 2600619880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.98672
Policy Entropy: 2.43689
Value Function Loss: 0.02052

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.08518
Policy Update Magnitude: 0.48431
Value Function Update Magnitude: 0.66260

Collected Steps per Second: 21,961.84522
Overall Steps per Second: 10,668.09602

Timestep Collection Time: 2.27759
Timestep Consumption Time: 2.41116
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.68875

Cumulative Model Updates: 311,836
Cumulative Timesteps: 2,600,669,900

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.80152
Policy Entropy: 2.42416
Value Function Loss: 0.02071

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.48684
Value Function Update Magnitude: 0.66372

Collected Steps per Second: 22,039.90260
Overall Steps per Second: 10,485.32504

Timestep Collection Time: 2.26970
Timestep Consumption Time: 2.50116
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.77086

Cumulative Model Updates: 311,842
Cumulative Timesteps: 2,600,719,924

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2600719924...
Checkpoint 2600719924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.40753
Policy Entropy: 2.42879
Value Function Loss: 0.02182

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.09397
Policy Update Magnitude: 0.49423
Value Function Update Magnitude: 0.67031

Collected Steps per Second: 22,317.08909
Overall Steps per Second: 10,458.38423

Timestep Collection Time: 2.24115
Timestep Consumption Time: 2.54123
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.78238

Cumulative Model Updates: 311,848
Cumulative Timesteps: 2,600,769,940

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.23485
Policy Entropy: 2.44911
Value Function Loss: 0.02079

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.09159
Policy Update Magnitude: 0.49796
Value Function Update Magnitude: 0.68156

Collected Steps per Second: 22,375.18334
Overall Steps per Second: 10,611.64140

Timestep Collection Time: 2.23498
Timestep Consumption Time: 2.47758
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.71256

Cumulative Model Updates: 311,854
Cumulative Timesteps: 2,600,819,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2600819948...
Checkpoint 2600819948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.38095
Policy Entropy: 2.47063
Value Function Loss: 0.01996

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.08982
Policy Update Magnitude: 0.49747
Value Function Update Magnitude: 0.68932

Collected Steps per Second: 22,384.43424
Overall Steps per Second: 10,865.36498

Timestep Collection Time: 2.23378
Timestep Consumption Time: 2.36818
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.60196

Cumulative Model Updates: 311,860
Cumulative Timesteps: 2,600,869,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.87003
Policy Entropy: 2.48122
Value Function Loss: 0.02061

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.50749
Value Function Update Magnitude: 0.70135

Collected Steps per Second: 22,453.16617
Overall Steps per Second: 10,571.05348

Timestep Collection Time: 2.22802
Timestep Consumption Time: 2.50434
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.73236

Cumulative Model Updates: 311,866
Cumulative Timesteps: 2,600,919,976

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2600919976...
Checkpoint 2600919976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.54653
Policy Entropy: 2.48298
Value Function Loss: 0.02104

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.09641
Policy Update Magnitude: 0.50364
Value Function Update Magnitude: 0.69121

Collected Steps per Second: 22,364.23125
Overall Steps per Second: 10,531.67705

Timestep Collection Time: 2.23670
Timestep Consumption Time: 2.51297
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.74967

Cumulative Model Updates: 311,872
Cumulative Timesteps: 2,600,969,998

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.68301
Policy Entropy: 2.44253
Value Function Loss: 0.02238

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.09184
Policy Update Magnitude: 0.49937
Value Function Update Magnitude: 0.66217

Collected Steps per Second: 22,503.23552
Overall Steps per Second: 10,891.52769

Timestep Collection Time: 2.22306
Timestep Consumption Time: 2.37005
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.59311

Cumulative Model Updates: 311,878
Cumulative Timesteps: 2,601,020,024

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2601020024...
Checkpoint 2601020024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.72613
Policy Entropy: 2.44408
Value Function Loss: 0.02188

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.10038
Policy Update Magnitude: 0.50064
Value Function Update Magnitude: 0.66246

Collected Steps per Second: 22,073.40497
Overall Steps per Second: 10,655.51460

Timestep Collection Time: 2.26608
Timestep Consumption Time: 2.42821
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.69428

Cumulative Model Updates: 311,884
Cumulative Timesteps: 2,601,070,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.13028
Policy Entropy: 2.43554
Value Function Loss: 0.02160

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.09904
Policy Update Magnitude: 0.49286
Value Function Update Magnitude: 0.67440

Collected Steps per Second: 21,784.72387
Overall Steps per Second: 10,496.81490

Timestep Collection Time: 2.29629
Timestep Consumption Time: 2.46935
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.76564

Cumulative Model Updates: 311,890
Cumulative Timesteps: 2,601,120,068

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2601120068...
Checkpoint 2601120068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.75620
Policy Entropy: 2.46944
Value Function Loss: 0.02083

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.10231
Policy Update Magnitude: 0.50683
Value Function Update Magnitude: 0.68696

Collected Steps per Second: 21,438.81182
Overall Steps per Second: 10,375.75552

Timestep Collection Time: 2.33306
Timestep Consumption Time: 2.48760
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.82066

Cumulative Model Updates: 311,896
Cumulative Timesteps: 2,601,170,086

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.99865
Policy Entropy: 2.47176
Value Function Loss: 0.02010

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.10031
Policy Update Magnitude: 0.50044
Value Function Update Magnitude: 0.67818

Collected Steps per Second: 21,914.36333
Overall Steps per Second: 10,648.31764

Timestep Collection Time: 2.28188
Timestep Consumption Time: 2.41426
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.69614

Cumulative Model Updates: 311,902
Cumulative Timesteps: 2,601,220,092

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2601220092...
Checkpoint 2601220092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143.92599
Policy Entropy: 2.45174
Value Function Loss: 0.02030

Mean KL Divergence: 0.02478
SB3 Clip Fraction: 0.13285
Policy Update Magnitude: 0.48955
Value Function Update Magnitude: 0.66318

Collected Steps per Second: 21,654.96960
Overall Steps per Second: 10,710.84689

Timestep Collection Time: 2.31051
Timestep Consumption Time: 2.36083
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.67134

Cumulative Model Updates: 311,908
Cumulative Timesteps: 2,601,270,126

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.16469
Policy Entropy: 2.44774
Value Function Loss: 0.02019

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.11845
Policy Update Magnitude: 0.51068
Value Function Update Magnitude: 0.67202

Collected Steps per Second: 22,462.05507
Overall Steps per Second: 10,517.93930

Timestep Collection Time: 2.22598
Timestep Consumption Time: 2.52781
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.75378

Cumulative Model Updates: 311,914
Cumulative Timesteps: 2,601,320,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2601320126...
Checkpoint 2601320126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.58364
Policy Entropy: 2.42736
Value Function Loss: 0.02055

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.11192
Policy Update Magnitude: 0.51906
Value Function Update Magnitude: 0.68642

Collected Steps per Second: 22,208.85192
Overall Steps per Second: 10,551.21002

Timestep Collection Time: 2.25226
Timestep Consumption Time: 2.48843
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.74069

Cumulative Model Updates: 311,920
Cumulative Timesteps: 2,601,370,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.49692
Policy Entropy: 2.45762
Value Function Loss: 0.01940

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.10196
Policy Update Magnitude: 0.50778
Value Function Update Magnitude: 0.67609

Collected Steps per Second: 22,543.38480
Overall Steps per Second: 10,904.12783

Timestep Collection Time: 2.21919
Timestep Consumption Time: 2.36880
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.58799

Cumulative Model Updates: 311,926
Cumulative Timesteps: 2,601,420,174

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2601420174...
Checkpoint 2601420174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.69068
Policy Entropy: 2.46237
Value Function Loss: 0.01941

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.09409
Policy Update Magnitude: 0.49684
Value Function Update Magnitude: 0.65762

Collected Steps per Second: 21,467.93843
Overall Steps per Second: 10,662.28061

Timestep Collection Time: 2.32971
Timestep Consumption Time: 2.36103
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.69074

Cumulative Model Updates: 311,932
Cumulative Timesteps: 2,601,470,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.96227
Policy Entropy: 2.47481
Value Function Loss: 0.01946

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.09403
Policy Update Magnitude: 0.49589
Value Function Update Magnitude: 0.65930

Collected Steps per Second: 21,277.89544
Overall Steps per Second: 10,413.29649

Timestep Collection Time: 2.35080
Timestep Consumption Time: 2.45268
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.80347

Cumulative Model Updates: 311,938
Cumulative Timesteps: 2,601,520,208

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2601520208...
Checkpoint 2601520208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.62150
Policy Entropy: 2.45159
Value Function Loss: 0.01966

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.09996
Policy Update Magnitude: 0.50369
Value Function Update Magnitude: 0.66540

Collected Steps per Second: 22,162.17898
Overall Steps per Second: 10,678.24650

Timestep Collection Time: 2.25682
Timestep Consumption Time: 2.42710
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.68392

Cumulative Model Updates: 311,944
Cumulative Timesteps: 2,601,570,224

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.76507
Policy Entropy: 2.46091
Value Function Loss: 0.02011

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.09959
Policy Update Magnitude: 0.48714
Value Function Update Magnitude: 0.65926

Collected Steps per Second: 22,475.09867
Overall Steps per Second: 10,897.15492

Timestep Collection Time: 2.22495
Timestep Consumption Time: 2.36395
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.58890

Cumulative Model Updates: 311,950
Cumulative Timesteps: 2,601,620,230

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2601620230...
Checkpoint 2601620230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.23995
Policy Entropy: 2.47108
Value Function Loss: 0.02082

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.10265
Policy Update Magnitude: 0.49216
Value Function Update Magnitude: 0.63896

Collected Steps per Second: 21,801.96155
Overall Steps per Second: 10,592.55866

Timestep Collection Time: 2.29383
Timestep Consumption Time: 2.42741
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.72124

Cumulative Model Updates: 311,956
Cumulative Timesteps: 2,601,670,240

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.78458
Policy Entropy: 2.47755
Value Function Loss: 0.02077

Mean KL Divergence: 0.02138
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.46099
Value Function Update Magnitude: 0.63464

Collected Steps per Second: 22,099.21509
Overall Steps per Second: 10,539.10749

Timestep Collection Time: 2.26298
Timestep Consumption Time: 2.48221
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.74518

Cumulative Model Updates: 311,962
Cumulative Timesteps: 2,601,720,250

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2601720250...
Checkpoint 2601720250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.32163
Policy Entropy: 2.47914
Value Function Loss: 0.02103

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.46056
Value Function Update Magnitude: 0.63937

Collected Steps per Second: 21,156.01789
Overall Steps per Second: 10,260.11770

Timestep Collection Time: 2.36358
Timestep Consumption Time: 2.51005
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.87363

Cumulative Model Updates: 311,968
Cumulative Timesteps: 2,601,770,254

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.69418
Policy Entropy: 2.48035
Value Function Loss: 0.01940

Mean KL Divergence: 0.02332
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.47980
Value Function Update Magnitude: 0.64235

Collected Steps per Second: 21,951.13697
Overall Steps per Second: 10,538.51962

Timestep Collection Time: 2.27824
Timestep Consumption Time: 2.46721
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.74545

Cumulative Model Updates: 311,974
Cumulative Timesteps: 2,601,820,264

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2601820264...
Checkpoint 2601820264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.39814
Policy Entropy: 2.47656
Value Function Loss: 0.01980

Mean KL Divergence: 0.02230
SB3 Clip Fraction: 0.13021
Policy Update Magnitude: 0.48008
Value Function Update Magnitude: 0.65076

Collected Steps per Second: 22,041.02305
Overall Steps per Second: 10,706.05935

Timestep Collection Time: 2.26977
Timestep Consumption Time: 2.40310
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.67287

Cumulative Model Updates: 311,980
Cumulative Timesteps: 2,601,870,292

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.99150
Policy Entropy: 2.48110
Value Function Loss: 0.01904

Mean KL Divergence: 0.02002
SB3 Clip Fraction: 0.12574
Policy Update Magnitude: 0.48012
Value Function Update Magnitude: 0.65677

Collected Steps per Second: 22,626.86670
Overall Steps per Second: 10,720.75681

Timestep Collection Time: 2.21100
Timestep Consumption Time: 2.45546
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.66646

Cumulative Model Updates: 311,986
Cumulative Timesteps: 2,601,920,320

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2601920320...
Checkpoint 2601920320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.06425
Policy Entropy: 2.48131
Value Function Loss: 0.02042

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.11121
Policy Update Magnitude: 0.49000
Value Function Update Magnitude: 0.65835

Collected Steps per Second: 22,199.52007
Overall Steps per Second: 10,482.57602

Timestep Collection Time: 2.25392
Timestep Consumption Time: 2.51933
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.77325

Cumulative Model Updates: 311,992
Cumulative Timesteps: 2,601,970,356

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.78104
Policy Entropy: 2.48142
Value Function Loss: 0.01932

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.10167
Policy Update Magnitude: 0.48783
Value Function Update Magnitude: 0.66758

Collected Steps per Second: 22,455.54112
Overall Steps per Second: 10,584.43864

Timestep Collection Time: 2.22742
Timestep Consumption Time: 2.49819
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.72562

Cumulative Model Updates: 311,998
Cumulative Timesteps: 2,602,020,374

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2602020374...
Checkpoint 2602020374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.17664
Policy Entropy: 2.47319
Value Function Loss: 0.02042

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.49553
Value Function Update Magnitude: 0.66430

Collected Steps per Second: 22,725.17512
Overall Steps per Second: 10,625.49462

Timestep Collection Time: 2.20056
Timestep Consumption Time: 2.50586
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.70642

Cumulative Model Updates: 312,004
Cumulative Timesteps: 2,602,070,382

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.93197
Policy Entropy: 2.48616
Value Function Loss: 0.02037

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.08141
Policy Update Magnitude: 0.49594
Value Function Update Magnitude: 0.68380

Collected Steps per Second: 22,461.13526
Overall Steps per Second: 10,593.21069

Timestep Collection Time: 2.22616
Timestep Consumption Time: 2.49404
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.72019

Cumulative Model Updates: 312,010
Cumulative Timesteps: 2,602,120,384

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2602120384...
Checkpoint 2602120384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.78316
Policy Entropy: 2.47936
Value Function Loss: 0.02094

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.49198
Value Function Update Magnitude: 0.68887

Collected Steps per Second: 22,347.61614
Overall Steps per Second: 10,653.05062

Timestep Collection Time: 2.23746
Timestep Consumption Time: 2.45621
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.69368

Cumulative Model Updates: 312,016
Cumulative Timesteps: 2,602,170,386

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.01492
Policy Entropy: 2.48377
Value Function Loss: 0.01946

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.48359
Value Function Update Magnitude: 0.68081

Collected Steps per Second: 22,842.83180
Overall Steps per Second: 10,819.34072

Timestep Collection Time: 2.18940
Timestep Consumption Time: 2.43307
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.62246

Cumulative Model Updates: 312,022
Cumulative Timesteps: 2,602,220,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2602220398...
Checkpoint 2602220398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.83063
Policy Entropy: 2.47885
Value Function Loss: 0.01918

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.08253
Policy Update Magnitude: 0.47808
Value Function Update Magnitude: 0.64530

Collected Steps per Second: 21,764.20748
Overall Steps per Second: 10,589.87232

Timestep Collection Time: 2.29744
Timestep Consumption Time: 2.42424
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.72168

Cumulative Model Updates: 312,028
Cumulative Timesteps: 2,602,270,400

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.59693
Policy Entropy: 2.49179
Value Function Loss: 0.01938

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 0.47543
Value Function Update Magnitude: 0.63003

Collected Steps per Second: 22,040.13781
Overall Steps per Second: 10,475.81402

Timestep Collection Time: 2.26868
Timestep Consumption Time: 2.50441
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.77309

Cumulative Model Updates: 312,034
Cumulative Timesteps: 2,602,320,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2602320402...
Checkpoint 2602320402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.87287
Policy Entropy: 2.48317
Value Function Loss: 0.02122

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.08590
Policy Update Magnitude: 0.49128
Value Function Update Magnitude: 0.66741

Collected Steps per Second: 21,788.17684
Overall Steps per Second: 10,667.57547

Timestep Collection Time: 2.29574
Timestep Consumption Time: 2.39324
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.68898

Cumulative Model Updates: 312,040
Cumulative Timesteps: 2,602,370,422

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.10832
Policy Entropy: 2.46786
Value Function Loss: 0.02057

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.09745
Policy Update Magnitude: 0.49512
Value Function Update Magnitude: 0.70304

Collected Steps per Second: 22,001.95927
Overall Steps per Second: 10,768.05720

Timestep Collection Time: 2.27371
Timestep Consumption Time: 2.37207
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.64578

Cumulative Model Updates: 312,046
Cumulative Timesteps: 2,602,420,448

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2602420448...
Checkpoint 2602420448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.49904
Policy Entropy: 2.46429
Value Function Loss: 0.02019

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.09930
Policy Update Magnitude: 0.49318
Value Function Update Magnitude: 0.70999

Collected Steps per Second: 21,857.60169
Overall Steps per Second: 10,453.40407

Timestep Collection Time: 2.28900
Timestep Consumption Time: 2.49719
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.78619

Cumulative Model Updates: 312,052
Cumulative Timesteps: 2,602,470,480

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.58991
Policy Entropy: 2.46731
Value Function Loss: 0.02023

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.10180
Policy Update Magnitude: 0.49710
Value Function Update Magnitude: 0.72511

Collected Steps per Second: 22,222.70217
Overall Steps per Second: 10,464.52523

Timestep Collection Time: 2.25022
Timestep Consumption Time: 2.52840
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.77862

Cumulative Model Updates: 312,058
Cumulative Timesteps: 2,602,520,486

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2602520486...
Checkpoint 2602520486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.46137
Policy Entropy: 2.48329
Value Function Loss: 0.02111

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.09961
Policy Update Magnitude: 0.49841
Value Function Update Magnitude: 0.71877

Collected Steps per Second: 22,154.81063
Overall Steps per Second: 10,545.29148

Timestep Collection Time: 2.25820
Timestep Consumption Time: 2.48610
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.74430

Cumulative Model Updates: 312,064
Cumulative Timesteps: 2,602,570,516

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.58140
Policy Entropy: 2.47180
Value Function Loss: 0.02054

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.09178
Policy Update Magnitude: 0.49455
Value Function Update Magnitude: 0.70194

Collected Steps per Second: 22,350.45258
Overall Steps per Second: 10,775.58761

Timestep Collection Time: 2.23745
Timestep Consumption Time: 2.40341
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.64086

Cumulative Model Updates: 312,070
Cumulative Timesteps: 2,602,620,524

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2602620524...
Checkpoint 2602620524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.14470
Policy Entropy: 2.47265
Value Function Loss: 0.02139

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.08473
Policy Update Magnitude: 0.48802
Value Function Update Magnitude: 0.67463

Collected Steps per Second: 22,260.52008
Overall Steps per Second: 10,688.31935

Timestep Collection Time: 2.24730
Timestep Consumption Time: 2.43314
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.68044

Cumulative Model Updates: 312,076
Cumulative Timesteps: 2,602,670,550

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.60791
Policy Entropy: 2.45449
Value Function Loss: 0.02245

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.09448
Policy Update Magnitude: 0.48727
Value Function Update Magnitude: 0.68806

Collected Steps per Second: 22,184.23463
Overall Steps per Second: 10,480.75260

Timestep Collection Time: 2.25430
Timestep Consumption Time: 2.51730
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.77160

Cumulative Model Updates: 312,082
Cumulative Timesteps: 2,602,720,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2602720560...
Checkpoint 2602720560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.65642
Policy Entropy: 2.44341
Value Function Loss: 0.02370

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.10132
Policy Update Magnitude: 0.49926
Value Function Update Magnitude: 0.72412

Collected Steps per Second: 22,375.78304
Overall Steps per Second: 10,594.15616

Timestep Collection Time: 2.23492
Timestep Consumption Time: 2.48542
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.72034

Cumulative Model Updates: 312,088
Cumulative Timesteps: 2,602,770,568

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.55575
Policy Entropy: 2.45671
Value Function Loss: 0.02339

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.09606
Policy Update Magnitude: 0.50096
Value Function Update Magnitude: 0.74439

Collected Steps per Second: 23,131.14099
Overall Steps per Second: 10,866.36896

Timestep Collection Time: 2.16358
Timestep Consumption Time: 2.44201
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.60559

Cumulative Model Updates: 312,094
Cumulative Timesteps: 2,602,820,614

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2602820614...
Checkpoint 2602820614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.45545
Policy Entropy: 2.46420
Value Function Loss: 0.02145

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.09020
Policy Update Magnitude: 0.49493
Value Function Update Magnitude: 0.73307

Collected Steps per Second: 21,533.81090
Overall Steps per Second: 10,367.95460

Timestep Collection Time: 2.32286
Timestep Consumption Time: 2.50162
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.82448

Cumulative Model Updates: 312,100
Cumulative Timesteps: 2,602,870,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.25886
Policy Entropy: 2.51097
Value Function Loss: 0.01982

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.08508
Policy Update Magnitude: 0.48821
Value Function Update Magnitude: 0.71149

Collected Steps per Second: 21,774.32542
Overall Steps per Second: 10,332.66316

Timestep Collection Time: 2.29702
Timestep Consumption Time: 2.54355
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.84057

Cumulative Model Updates: 312,106
Cumulative Timesteps: 2,602,920,650

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2602920650...
Checkpoint 2602920650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.51400
Policy Entropy: 2.50074
Value Function Loss: 0.02058

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.48420
Value Function Update Magnitude: 0.69453

Collected Steps per Second: 21,858.91061
Overall Steps per Second: 10,681.47489

Timestep Collection Time: 2.28740
Timestep Consumption Time: 2.39360
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.68100

Cumulative Model Updates: 312,112
Cumulative Timesteps: 2,602,970,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.76409
Policy Entropy: 2.49350
Value Function Loss: 0.02161

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.49421
Value Function Update Magnitude: 0.69848

Collected Steps per Second: 22,789.88585
Overall Steps per Second: 10,774.30611

Timestep Collection Time: 2.19501
Timestep Consumption Time: 2.44789
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.64290

Cumulative Model Updates: 312,118
Cumulative Timesteps: 2,603,020,674

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2603020674...
Checkpoint 2603020674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.69611
Policy Entropy: 2.49140
Value Function Loss: 0.02190

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.09094
Policy Update Magnitude: 0.49534
Value Function Update Magnitude: 0.68738

Collected Steps per Second: 22,066.07427
Overall Steps per Second: 10,374.86974

Timestep Collection Time: 2.26701
Timestep Consumption Time: 2.55464
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.82165

Cumulative Model Updates: 312,124
Cumulative Timesteps: 2,603,070,698

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.17805
Policy Entropy: 2.48776
Value Function Loss: 0.02082

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.08517
Policy Update Magnitude: 0.49456
Value Function Update Magnitude: 0.65665

Collected Steps per Second: 22,388.52971
Overall Steps per Second: 10,563.53088

Timestep Collection Time: 2.23400
Timestep Consumption Time: 2.50078
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.73478

Cumulative Model Updates: 312,130
Cumulative Timesteps: 2,603,120,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2603120714...
Checkpoint 2603120714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.23258
Policy Entropy: 2.50064
Value Function Loss: 0.01975

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.08123
Policy Update Magnitude: 0.48393
Value Function Update Magnitude: 0.63043

Collected Steps per Second: 22,521.15370
Overall Steps per Second: 10,954.20819

Timestep Collection Time: 2.22129
Timestep Consumption Time: 2.34554
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.56683

Cumulative Model Updates: 312,136
Cumulative Timesteps: 2,603,170,740

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.67301
Policy Entropy: 2.47729
Value Function Loss: 0.01973

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.09085
Policy Update Magnitude: 0.47727
Value Function Update Magnitude: 0.60341

Collected Steps per Second: 22,502.12855
Overall Steps per Second: 10,576.45373

Timestep Collection Time: 2.22299
Timestep Consumption Time: 2.50657
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.72956

Cumulative Model Updates: 312,142
Cumulative Timesteps: 2,603,220,762

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2603220762...
Checkpoint 2603220762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.39889
Policy Entropy: 2.49791
Value Function Loss: 0.01992

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.09193
Policy Update Magnitude: 0.47333
Value Function Update Magnitude: 0.58583

Collected Steps per Second: 22,612.57762
Overall Steps per Second: 10,638.73044

Timestep Collection Time: 2.21116
Timestep Consumption Time: 2.48865
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.69981

Cumulative Model Updates: 312,148
Cumulative Timesteps: 2,603,270,762

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.06799
Policy Entropy: 2.48786
Value Function Loss: 0.01984

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.09214
Policy Update Magnitude: 0.47928
Value Function Update Magnitude: 0.57797

Collected Steps per Second: 22,603.11298
Overall Steps per Second: 10,728.22980

Timestep Collection Time: 2.21306
Timestep Consumption Time: 2.44959
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.66265

Cumulative Model Updates: 312,154
Cumulative Timesteps: 2,603,320,784

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2603320784...
Checkpoint 2603320784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.69744
Policy Entropy: 2.50307
Value Function Loss: 0.01978

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.48320
Value Function Update Magnitude: 0.58025

Collected Steps per Second: 22,464.79811
Overall Steps per Second: 10,754.06169

Timestep Collection Time: 2.22570
Timestep Consumption Time: 2.42370
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.64941

Cumulative Model Updates: 312,160
Cumulative Timesteps: 2,603,370,784

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.41059
Policy Entropy: 2.49139
Value Function Loss: 0.01909

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.47798
Value Function Update Magnitude: 0.59805

Collected Steps per Second: 21,056.91610
Overall Steps per Second: 10,355.73093

Timestep Collection Time: 2.37575
Timestep Consumption Time: 2.45500
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.83076

Cumulative Model Updates: 312,166
Cumulative Timesteps: 2,603,420,810

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2603420810...
Checkpoint 2603420810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.52747
Policy Entropy: 2.49820
Value Function Loss: 0.01985

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.08258
Policy Update Magnitude: 0.47842
Value Function Update Magnitude: 0.60298

Collected Steps per Second: 21,458.38703
Overall Steps per Second: 10,364.83842

Timestep Collection Time: 2.33121
Timestep Consumption Time: 2.49511
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.82632

Cumulative Model Updates: 312,172
Cumulative Timesteps: 2,603,470,834

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.80828
Policy Entropy: 2.50264
Value Function Loss: 0.02043

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.09007
Policy Update Magnitude: 0.47269
Value Function Update Magnitude: 0.62309

Collected Steps per Second: 22,217.76978
Overall Steps per Second: 10,732.24429

Timestep Collection Time: 2.25045
Timestep Consumption Time: 2.40841
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.65886

Cumulative Model Updates: 312,178
Cumulative Timesteps: 2,603,520,834

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2603520834...
Checkpoint 2603520834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.76514
Policy Entropy: 2.48720
Value Function Loss: 0.02162

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.09741
Policy Update Magnitude: 0.48079
Value Function Update Magnitude: 0.65491

Collected Steps per Second: 21,983.10243
Overall Steps per Second: 10,673.98984

Timestep Collection Time: 2.27548
Timestep Consumption Time: 2.41087
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.68635

Cumulative Model Updates: 312,184
Cumulative Timesteps: 2,603,570,856

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.03953
Policy Entropy: 2.46098
Value Function Loss: 0.02227

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.09964
Policy Update Magnitude: 0.48300
Value Function Update Magnitude: 0.67774

Collected Steps per Second: 22,082.56656
Overall Steps per Second: 10,465.35239

Timestep Collection Time: 2.26441
Timestep Consumption Time: 2.51364
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.77805

Cumulative Model Updates: 312,190
Cumulative Timesteps: 2,603,620,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2603620860...
Checkpoint 2603620860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.95283
Policy Entropy: 2.45461
Value Function Loss: 0.02209

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.11159
Policy Update Magnitude: 0.49669
Value Function Update Magnitude: 0.67228

Collected Steps per Second: 21,961.91400
Overall Steps per Second: 10,359.59774

Timestep Collection Time: 2.27694
Timestep Consumption Time: 2.55008
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.82702

Cumulative Model Updates: 312,196
Cumulative Timesteps: 2,603,670,866

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.76146
Policy Entropy: 2.47338
Value Function Loss: 0.02224

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.10032
Policy Update Magnitude: 0.50624
Value Function Update Magnitude: 0.67323

Collected Steps per Second: 22,491.12374
Overall Steps per Second: 10,763.44110

Timestep Collection Time: 2.22408
Timestep Consumption Time: 2.42332
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.64740

Cumulative Model Updates: 312,202
Cumulative Timesteps: 2,603,720,888

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2603720888...
Checkpoint 2603720888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.66323
Policy Entropy: 2.49574
Value Function Loss: 0.02194

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.09452
Policy Update Magnitude: 0.50801
Value Function Update Magnitude: 0.68363

Collected Steps per Second: 22,469.76640
Overall Steps per Second: 10,597.85185

Timestep Collection Time: 2.22548
Timestep Consumption Time: 2.49302
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.71850

Cumulative Model Updates: 312,208
Cumulative Timesteps: 2,603,770,894

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.16490
Policy Entropy: 2.49578
Value Function Loss: 0.02141

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.09223
Policy Update Magnitude: 0.50367
Value Function Update Magnitude: 0.69771

Collected Steps per Second: 23,039.86830
Overall Steps per Second: 10,845.77431

Timestep Collection Time: 2.17024
Timestep Consumption Time: 2.44004
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.61027

Cumulative Model Updates: 312,214
Cumulative Timesteps: 2,603,820,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2603820896...
Checkpoint 2603820896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.18362
Policy Entropy: 2.48545
Value Function Loss: 0.02066

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.49890
Value Function Update Magnitude: 0.69921

Collected Steps per Second: 22,037.94131
Overall Steps per Second: 10,570.70369

Timestep Collection Time: 2.27009
Timestep Consumption Time: 2.46262
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.73270

Cumulative Model Updates: 312,220
Cumulative Timesteps: 2,603,870,924

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.91906
Policy Entropy: 2.48437
Value Function Loss: 0.02021

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.09908
Policy Update Magnitude: 0.48298
Value Function Update Magnitude: 0.69597

Collected Steps per Second: 22,305.68766
Overall Steps per Second: 10,616.38802

Timestep Collection Time: 2.24194
Timestep Consumption Time: 2.46851
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.71045

Cumulative Model Updates: 312,226
Cumulative Timesteps: 2,603,920,932

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2603920932...
Checkpoint 2603920932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.26621
Policy Entropy: 2.46007
Value Function Loss: 0.02036

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.09215
Policy Update Magnitude: 0.49676
Value Function Update Magnitude: 0.69323

Collected Steps per Second: 22,149.35365
Overall Steps per Second: 10,660.77808

Timestep Collection Time: 2.25776
Timestep Consumption Time: 2.43308
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.69084

Cumulative Model Updates: 312,232
Cumulative Timesteps: 2,603,970,940

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.58789
Policy Entropy: 2.46659
Value Function Loss: 0.02161

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.08639
Policy Update Magnitude: 0.49058
Value Function Update Magnitude: 0.68825

Collected Steps per Second: 22,190.70293
Overall Steps per Second: 10,501.49809

Timestep Collection Time: 2.25365
Timestep Consumption Time: 2.50853
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.76218

Cumulative Model Updates: 312,238
Cumulative Timesteps: 2,604,020,950

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2604020950...
Checkpoint 2604020950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.72721
Policy Entropy: 2.44469
Value Function Loss: 0.02240

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.08613
Policy Update Magnitude: 0.50549
Value Function Update Magnitude: 0.71050

Collected Steps per Second: 21,795.82042
Overall Steps per Second: 10,583.98604

Timestep Collection Time: 2.29402
Timestep Consumption Time: 2.43010
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.72412

Cumulative Model Updates: 312,244
Cumulative Timesteps: 2,604,070,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.66381
Policy Entropy: 2.45270
Value Function Loss: 0.02253

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.08375
Policy Update Magnitude: 0.50985
Value Function Update Magnitude: 0.72838

Collected Steps per Second: 21,840.42347
Overall Steps per Second: 10,465.54107

Timestep Collection Time: 2.29071
Timestep Consumption Time: 2.48974
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.78045

Cumulative Model Updates: 312,250
Cumulative Timesteps: 2,604,120,980

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2604120980...
Checkpoint 2604120980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.70908
Policy Entropy: 2.45894
Value Function Loss: 0.02244

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.08844
Policy Update Magnitude: 0.50330
Value Function Update Magnitude: 0.72538

Collected Steps per Second: 21,834.16220
Overall Steps per Second: 10,567.73262

Timestep Collection Time: 2.28999
Timestep Consumption Time: 2.44139
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.73138

Cumulative Model Updates: 312,256
Cumulative Timesteps: 2,604,170,980

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.45156
Policy Entropy: 2.46863
Value Function Loss: 0.02218

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.49014
Value Function Update Magnitude: 0.71026

Collected Steps per Second: 22,497.76057
Overall Steps per Second: 10,473.42257

Timestep Collection Time: 2.22333
Timestep Consumption Time: 2.55257
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.77590

Cumulative Model Updates: 312,262
Cumulative Timesteps: 2,604,221,000

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2604221000...
Checkpoint 2604221000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.28094
Policy Entropy: 2.48963
Value Function Loss: 0.02191

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.09143
Policy Update Magnitude: 0.47816
Value Function Update Magnitude: 0.70685

Collected Steps per Second: 22,208.31101
Overall Steps per Second: 10,619.38951

Timestep Collection Time: 2.25222
Timestep Consumption Time: 2.45784
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.71006

Cumulative Model Updates: 312,268
Cumulative Timesteps: 2,604,271,018

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.74134
Policy Entropy: 2.46955
Value Function Loss: 0.02154

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.09781
Policy Update Magnitude: 0.50435
Value Function Update Magnitude: 0.70339

Collected Steps per Second: 22,364.09140
Overall Steps per Second: 10,627.63092

Timestep Collection Time: 2.23644
Timestep Consumption Time: 2.46978
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.70622

Cumulative Model Updates: 312,274
Cumulative Timesteps: 2,604,321,034

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2604321034...
Checkpoint 2604321034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.42022
Policy Entropy: 2.47412
Value Function Loss: 0.02148

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.10375
Policy Update Magnitude: 0.49380
Value Function Update Magnitude: 0.69437

Collected Steps per Second: 22,572.35198
Overall Steps per Second: 10,674.55716

Timestep Collection Time: 2.21616
Timestep Consumption Time: 2.47012
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.68628

Cumulative Model Updates: 312,280
Cumulative Timesteps: 2,604,371,058

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.13583
Policy Entropy: 2.44059
Value Function Loss: 0.02097

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.10203
Policy Update Magnitude: 0.49745
Value Function Update Magnitude: 0.69236

Collected Steps per Second: 22,905.35667
Overall Steps per Second: 10,734.96855

Timestep Collection Time: 2.18290
Timestep Consumption Time: 2.47478
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.65768

Cumulative Model Updates: 312,286
Cumulative Timesteps: 2,604,421,058

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2604421058...
Checkpoint 2604421058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.92127
Policy Entropy: 2.44430
Value Function Loss: 0.02172

Mean KL Divergence: 0.02513
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.46320
Value Function Update Magnitude: 0.68922

Collected Steps per Second: 22,363.61241
Overall Steps per Second: 10,631.58900

Timestep Collection Time: 2.23649
Timestep Consumption Time: 2.46798
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.70447

Cumulative Model Updates: 312,292
Cumulative Timesteps: 2,604,471,074

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.93555
Policy Entropy: 2.45017
Value Function Loss: 0.02146

Mean KL Divergence: 0.02526
SB3 Clip Fraction: 0.13712
Policy Update Magnitude: 0.45559
Value Function Update Magnitude: 0.68168

Collected Steps per Second: 22,380.32214
Overall Steps per Second: 10,564.00970

Timestep Collection Time: 2.23527
Timestep Consumption Time: 2.50025
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.73551

Cumulative Model Updates: 312,298
Cumulative Timesteps: 2,604,521,100

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2604521100...
Checkpoint 2604521100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.97946
Policy Entropy: 2.46461
Value Function Loss: 0.02141

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.11984
Policy Update Magnitude: 0.50413
Value Function Update Magnitude: 0.67255

Collected Steps per Second: 21,595.02307
Overall Steps per Second: 10,544.25909

Timestep Collection Time: 2.31600
Timestep Consumption Time: 2.42725
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.74324

Cumulative Model Updates: 312,304
Cumulative Timesteps: 2,604,571,114

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.63202
Policy Entropy: 2.45774
Value Function Loss: 0.02011

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.11585
Policy Update Magnitude: 0.50329
Value Function Update Magnitude: 0.65149

Collected Steps per Second: 21,744.27273
Overall Steps per Second: 10,589.97797

Timestep Collection Time: 2.30019
Timestep Consumption Time: 2.42276
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.72296

Cumulative Model Updates: 312,310
Cumulative Timesteps: 2,604,621,130

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2604621130...
Checkpoint 2604621130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.67068
Policy Entropy: 2.46108
Value Function Loss: 0.02041

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.10550
Policy Update Magnitude: 0.49757
Value Function Update Magnitude: 0.65078

Collected Steps per Second: 22,054.40973
Overall Steps per Second: 10,477.22415

Timestep Collection Time: 2.26712
Timestep Consumption Time: 2.50514
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.77226

Cumulative Model Updates: 312,316
Cumulative Timesteps: 2,604,671,130

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.68004
Policy Entropy: 2.47603
Value Function Loss: 0.02036

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.09962
Policy Update Magnitude: 0.48693
Value Function Update Magnitude: 0.65207

Collected Steps per Second: 22,092.26587
Overall Steps per Second: 10,477.60119

Timestep Collection Time: 2.26360
Timestep Consumption Time: 2.50925
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.77285

Cumulative Model Updates: 312,322
Cumulative Timesteps: 2,604,721,138

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2604721138...
Checkpoint 2604721138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.05275
Policy Entropy: 2.49395
Value Function Loss: 0.02185

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.09887
Policy Update Magnitude: 0.48369
Value Function Update Magnitude: 0.64954

Collected Steps per Second: 21,772.87095
Overall Steps per Second: 10,650.10654

Timestep Collection Time: 2.29662
Timestep Consumption Time: 2.39854
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.69516

Cumulative Model Updates: 312,328
Cumulative Timesteps: 2,604,771,142

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.90658
Policy Entropy: 2.47449
Value Function Loss: 0.02327

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.48893
Value Function Update Magnitude: 0.65471

Collected Steps per Second: 22,379.49507
Overall Steps per Second: 10,540.10581

Timestep Collection Time: 2.23455
Timestep Consumption Time: 2.51000
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.74454

Cumulative Model Updates: 312,334
Cumulative Timesteps: 2,604,821,150

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2604821150...
Checkpoint 2604821150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.92723
Policy Entropy: 2.46904
Value Function Loss: 0.02340

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.09649
Policy Update Magnitude: 0.49985
Value Function Update Magnitude: 0.67213

Collected Steps per Second: 22,506.94469
Overall Steps per Second: 10,903.32958

Timestep Collection Time: 2.22163
Timestep Consumption Time: 2.36431
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.58594

Cumulative Model Updates: 312,340
Cumulative Timesteps: 2,604,871,152

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.70700
Policy Entropy: 2.47549
Value Function Loss: 0.02323

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.09917
Policy Update Magnitude: 0.50668
Value Function Update Magnitude: 0.68649

Collected Steps per Second: 22,624.10495
Overall Steps per Second: 10,602.74002

Timestep Collection Time: 2.21136
Timestep Consumption Time: 2.50723
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.71859

Cumulative Model Updates: 312,346
Cumulative Timesteps: 2,604,921,182

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2604921182...
Checkpoint 2604921182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.21125
Policy Entropy: 2.50006
Value Function Loss: 0.02025

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.09345
Policy Update Magnitude: 0.49382
Value Function Update Magnitude: 0.68902

Collected Steps per Second: 22,447.17958
Overall Steps per Second: 10,565.15357

Timestep Collection Time: 2.22879
Timestep Consumption Time: 2.50659
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.73538

Cumulative Model Updates: 312,352
Cumulative Timesteps: 2,604,971,212

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.61232
Policy Entropy: 2.47277
Value Function Loss: 0.02020

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.09600
Policy Update Magnitude: 0.48817
Value Function Update Magnitude: 0.65113

Collected Steps per Second: 22,442.26845
Overall Steps per Second: 10,616.04444

Timestep Collection Time: 2.22910
Timestep Consumption Time: 2.48320
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.71230

Cumulative Model Updates: 312,358
Cumulative Timesteps: 2,605,021,238

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2605021238...
Checkpoint 2605021238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.27744
Policy Entropy: 2.45370
Value Function Loss: 0.02004

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.49089
Value Function Update Magnitude: 0.62532

Collected Steps per Second: 22,025.78647
Overall Steps per Second: 10,689.05085

Timestep Collection Time: 2.27007
Timestep Consumption Time: 2.40762
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.67768

Cumulative Model Updates: 312,364
Cumulative Timesteps: 2,605,071,238

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.19283
Policy Entropy: 2.45323
Value Function Loss: 0.02106

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.08734
Policy Update Magnitude: 0.49845
Value Function Update Magnitude: 0.62982

Collected Steps per Second: 22,662.50852
Overall Steps per Second: 10,692.95396

Timestep Collection Time: 2.20682
Timestep Consumption Time: 2.47028
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.67710

Cumulative Model Updates: 312,370
Cumulative Timesteps: 2,605,121,250

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2605121250...
Checkpoint 2605121250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.14576
Policy Entropy: 2.47040
Value Function Loss: 0.02031

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.09139
Policy Update Magnitude: 0.50146
Value Function Update Magnitude: 0.64426

Collected Steps per Second: 21,832.74126
Overall Steps per Second: 10,570.65163

Timestep Collection Time: 2.29115
Timestep Consumption Time: 2.44101
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.73216

Cumulative Model Updates: 312,376
Cumulative Timesteps: 2,605,171,272

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.67920
Policy Entropy: 2.45761
Value Function Loss: 0.02039

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.49844
Value Function Update Magnitude: 0.64592

Collected Steps per Second: 21,656.81990
Overall Steps per Second: 10,515.51438

Timestep Collection Time: 2.30957
Timestep Consumption Time: 2.44702
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.75659

Cumulative Model Updates: 312,382
Cumulative Timesteps: 2,605,221,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2605221290...
Checkpoint 2605221290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.72909
Policy Entropy: 2.46906
Value Function Loss: 0.01899

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.09129
Policy Update Magnitude: 0.49705
Value Function Update Magnitude: 0.64646

Collected Steps per Second: 21,618.05838
Overall Steps per Second: 10,388.47902

Timestep Collection Time: 2.31371
Timestep Consumption Time: 2.50104
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.81476

Cumulative Model Updates: 312,388
Cumulative Timesteps: 2,605,271,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.99124
Policy Entropy: 2.48643
Value Function Loss: 0.01947

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.08870
Policy Update Magnitude: 0.48463
Value Function Update Magnitude: 0.62415

Collected Steps per Second: 21,093.46911
Overall Steps per Second: 10,366.49739

Timestep Collection Time: 2.37078
Timestep Consumption Time: 2.45322
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.82400

Cumulative Model Updates: 312,394
Cumulative Timesteps: 2,605,321,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2605321316...
Checkpoint 2605321316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.65289
Policy Entropy: 2.48623
Value Function Loss: 0.01906

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.08597
Policy Update Magnitude: 0.48023
Value Function Update Magnitude: 0.62041

Collected Steps per Second: 22,389.56810
Overall Steps per Second: 10,592.65529

Timestep Collection Time: 2.23425
Timestep Consumption Time: 2.48826
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.72252

Cumulative Model Updates: 312,400
Cumulative Timesteps: 2,605,371,340

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.38179
Policy Entropy: 2.47156
Value Function Loss: 0.02016

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.48682
Value Function Update Magnitude: 0.62591

Collected Steps per Second: 22,351.77836
Overall Steps per Second: 10,848.86984

Timestep Collection Time: 2.23767
Timestep Consumption Time: 2.37258
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.61025

Cumulative Model Updates: 312,406
Cumulative Timesteps: 2,605,421,356

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2605421356...
Checkpoint 2605421356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.59121
Policy Entropy: 2.44256
Value Function Loss: 0.02044

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.09300
Policy Update Magnitude: 0.49223
Value Function Update Magnitude: 0.62994

Collected Steps per Second: 22,561.58651
Overall Steps per Second: 10,705.86951

Timestep Collection Time: 2.21633
Timestep Consumption Time: 2.45438
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.67071

Cumulative Model Updates: 312,412
Cumulative Timesteps: 2,605,471,360

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.54138
Policy Entropy: 2.47829
Value Function Loss: 0.02155

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.49727
Value Function Update Magnitude: 0.64083

Collected Steps per Second: 22,524.26674
Overall Steps per Second: 10,623.91289

Timestep Collection Time: 2.22098
Timestep Consumption Time: 2.48783
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.70881

Cumulative Model Updates: 312,418
Cumulative Timesteps: 2,605,521,386

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2605521386...
Checkpoint 2605521386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.87827
Policy Entropy: 2.47180
Value Function Loss: 0.02092

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.08957
Policy Update Magnitude: 0.49789
Value Function Update Magnitude: 0.66566

Collected Steps per Second: 22,409.25818
Overall Steps per Second: 10,663.85355

Timestep Collection Time: 2.23256
Timestep Consumption Time: 2.45899
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.69155

Cumulative Model Updates: 312,424
Cumulative Timesteps: 2,605,571,416

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.75900
Policy Entropy: 2.50761
Value Function Loss: 0.02005

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.08251
Policy Update Magnitude: 0.49183
Value Function Update Magnitude: 0.67337

Collected Steps per Second: 22,540.60563
Overall Steps per Second: 10,722.88742

Timestep Collection Time: 2.21849
Timestep Consumption Time: 2.44500
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.66348

Cumulative Model Updates: 312,430
Cumulative Timesteps: 2,605,621,422

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2605621422...
Checkpoint 2605621422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.47835
Policy Entropy: 2.47768
Value Function Loss: 0.02007

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.08996
Policy Update Magnitude: 0.48498
Value Function Update Magnitude: 0.66474

Collected Steps per Second: 22,515.37089
Overall Steps per Second: 10,623.74248

Timestep Collection Time: 2.22150
Timestep Consumption Time: 2.48663
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.70813

Cumulative Model Updates: 312,436
Cumulative Timesteps: 2,605,671,440

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.97827
Policy Entropy: 2.47797
Value Function Loss: 0.02059

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.48352
Value Function Update Magnitude: 0.67885

Collected Steps per Second: 21,867.31818
Overall Steps per Second: 10,489.08082

Timestep Collection Time: 2.28661
Timestep Consumption Time: 2.48044
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.76705

Cumulative Model Updates: 312,442
Cumulative Timesteps: 2,605,721,442

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2605721442...
Checkpoint 2605721442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.07091
Policy Entropy: 2.46946
Value Function Loss: 0.02043

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.09211
Policy Update Magnitude: 0.49036
Value Function Update Magnitude: 0.69289

Collected Steps per Second: 21,856.97144
Overall Steps per Second: 10,595.90160

Timestep Collection Time: 2.28897
Timestep Consumption Time: 2.43266
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.72164

Cumulative Model Updates: 312,448
Cumulative Timesteps: 2,605,771,472

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.13427
Policy Entropy: 2.47765
Value Function Loss: 0.02139

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.08943
Policy Update Magnitude: 0.49950
Value Function Update Magnitude: 0.69228

Collected Steps per Second: 21,619.35831
Overall Steps per Second: 10,477.20965

Timestep Collection Time: 2.31376
Timestep Consumption Time: 2.46060
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.77436

Cumulative Model Updates: 312,454
Cumulative Timesteps: 2,605,821,494

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2605821494...
Checkpoint 2605821494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.46087
Policy Entropy: 2.48421
Value Function Loss: 0.02100

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.09308
Policy Update Magnitude: 0.50345
Value Function Update Magnitude: 0.68472

Collected Steps per Second: 21,812.19055
Overall Steps per Second: 10,630.69207

Timestep Collection Time: 2.29376
Timestep Consumption Time: 2.41261
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.70637

Cumulative Model Updates: 312,460
Cumulative Timesteps: 2,605,871,526

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.26492
Policy Entropy: 2.47180
Value Function Loss: 0.02028

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.08934
Policy Update Magnitude: 0.49595
Value Function Update Magnitude: 0.67962

Collected Steps per Second: 22,288.76006
Overall Steps per Second: 10,462.98817

Timestep Collection Time: 2.24427
Timestep Consumption Time: 2.53658
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.78085

Cumulative Model Updates: 312,466
Cumulative Timesteps: 2,605,921,548

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2605921548...
Checkpoint 2605921548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.06606
Policy Entropy: 2.47849
Value Function Loss: 0.02019

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.08173
Policy Update Magnitude: 0.48983
Value Function Update Magnitude: 0.68378

Collected Steps per Second: 22,177.33596
Overall Steps per Second: 10,580.55268

Timestep Collection Time: 2.25573
Timestep Consumption Time: 2.47238
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.72811

Cumulative Model Updates: 312,472
Cumulative Timesteps: 2,605,971,574

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.82383
Policy Entropy: 2.45843
Value Function Loss: 0.02078

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.08573
Policy Update Magnitude: 0.48514
Value Function Update Magnitude: 0.68413

Collected Steps per Second: 22,264.38312
Overall Steps per Second: 10,565.94880

Timestep Collection Time: 2.24637
Timestep Consumption Time: 2.48714
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.73351

Cumulative Model Updates: 312,478
Cumulative Timesteps: 2,606,021,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2606021588...
Checkpoint 2606021588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.24335
Policy Entropy: 2.45829
Value Function Loss: 0.02120

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.49418
Value Function Update Magnitude: 0.67703

Collected Steps per Second: 22,172.44275
Overall Steps per Second: 10,682.80813

Timestep Collection Time: 2.25559
Timestep Consumption Time: 2.42595
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.68154

Cumulative Model Updates: 312,484
Cumulative Timesteps: 2,606,071,600

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.11381
Policy Entropy: 2.45109
Value Function Loss: 0.02237

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.09295
Policy Update Magnitude: 0.50538
Value Function Update Magnitude: 0.68542

Collected Steps per Second: 22,723.42410
Overall Steps per Second: 10,805.09891

Timestep Collection Time: 2.20090
Timestep Consumption Time: 2.42765
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.62856

Cumulative Model Updates: 312,490
Cumulative Timesteps: 2,606,121,612

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2606121612...
Checkpoint 2606121612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.57217
Policy Entropy: 2.44319
Value Function Loss: 0.02277

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.50386
Value Function Update Magnitude: 0.70002

Collected Steps per Second: 22,383.93068
Overall Steps per Second: 10,657.82679

Timestep Collection Time: 2.23482
Timestep Consumption Time: 2.45882
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.69364

Cumulative Model Updates: 312,496
Cumulative Timesteps: 2,606,171,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.59509
Policy Entropy: 2.44415
Value Function Loss: 0.02300

Mean KL Divergence: 0.02264
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.49343
Value Function Update Magnitude: 0.68922

Collected Steps per Second: 22,225.10103
Overall Steps per Second: 10,603.67140

Timestep Collection Time: 2.25016
Timestep Consumption Time: 2.46613
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.71629

Cumulative Model Updates: 312,502
Cumulative Timesteps: 2,606,221,646

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2606221646...
Checkpoint 2606221646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.01834
Policy Entropy: 2.44290
Value Function Loss: 0.02223

Mean KL Divergence: 0.02311
SB3 Clip Fraction: 0.13270
Policy Update Magnitude: 0.44168
Value Function Update Magnitude: 0.66267

Collected Steps per Second: 22,416.55019
Overall Steps per Second: 10,606.07233

Timestep Collection Time: 2.23112
Timestep Consumption Time: 2.48448
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.71560

Cumulative Model Updates: 312,508
Cumulative Timesteps: 2,606,271,660

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.94784
Policy Entropy: 2.44696
Value Function Loss: 0.02147

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.10907
Policy Update Magnitude: 0.47091
Value Function Update Magnitude: 0.65024

Collected Steps per Second: 22,162.33748
Overall Steps per Second: 10,548.86502

Timestep Collection Time: 2.25626
Timestep Consumption Time: 2.48397
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.74023

Cumulative Model Updates: 312,514
Cumulative Timesteps: 2,606,321,664

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2606321664...
Checkpoint 2606321664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.31629
Policy Entropy: 2.45124
Value Function Loss: 0.02133

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.49395
Value Function Update Magnitude: 0.63441

Collected Steps per Second: 21,970.74749
Overall Steps per Second: 10,476.38452

Timestep Collection Time: 2.27621
Timestep Consumption Time: 2.49738
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.77359

Cumulative Model Updates: 312,520
Cumulative Timesteps: 2,606,371,674

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.27591
Policy Entropy: 2.43275
Value Function Loss: 0.02156

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.09826
Policy Update Magnitude: 0.49501
Value Function Update Magnitude: 0.62609

Collected Steps per Second: 21,962.84553
Overall Steps per Second: 10,466.16770

Timestep Collection Time: 2.27666
Timestep Consumption Time: 2.50083
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.77749

Cumulative Model Updates: 312,526
Cumulative Timesteps: 2,606,421,676

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2606421676...
Checkpoint 2606421676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.89431
Policy Entropy: 2.43740
Value Function Loss: 0.02031

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.49535
Value Function Update Magnitude: 0.62468

Collected Steps per Second: 21,932.27422
Overall Steps per Second: 10,655.68365

Timestep Collection Time: 2.28102
Timestep Consumption Time: 2.41394
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.69496

Cumulative Model Updates: 312,532
Cumulative Timesteps: 2,606,471,704

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.07808
Policy Entropy: 2.41855
Value Function Loss: 0.02154

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.10011
Policy Update Magnitude: 0.48956
Value Function Update Magnitude: 0.62072

Collected Steps per Second: 22,635.40342
Overall Steps per Second: 10,580.48949

Timestep Collection Time: 2.20964
Timestep Consumption Time: 2.51756
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.72719

Cumulative Model Updates: 312,538
Cumulative Timesteps: 2,606,521,720

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2606521720...
Checkpoint 2606521720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.09070
Policy Entropy: 2.41973
Value Function Loss: 0.02140

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.11849
Policy Update Magnitude: 0.48651
Value Function Update Magnitude: 0.63989

Collected Steps per Second: 22,364.50185
Overall Steps per Second: 10,535.78108

Timestep Collection Time: 2.23622
Timestep Consumption Time: 2.51065
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.74687

Cumulative Model Updates: 312,544
Cumulative Timesteps: 2,606,571,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.75509
Policy Entropy: 2.41621
Value Function Loss: 0.02060

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.12099
Policy Update Magnitude: 0.46377
Value Function Update Magnitude: 0.64865

Collected Steps per Second: 22,470.34994
Overall Steps per Second: 10,773.89762

Timestep Collection Time: 2.22533
Timestep Consumption Time: 2.41588
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.64122

Cumulative Model Updates: 312,550
Cumulative Timesteps: 2,606,621,736

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2606621736...
Checkpoint 2606621736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.12663
Policy Entropy: 2.43963
Value Function Loss: 0.01882

Mean KL Divergence: 0.02358
SB3 Clip Fraction: 0.12823
Policy Update Magnitude: 0.47878
Value Function Update Magnitude: 0.63905

Collected Steps per Second: 22,347.77056
Overall Steps per Second: 10,706.37455

Timestep Collection Time: 2.23808
Timestep Consumption Time: 2.43353
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.67161

Cumulative Model Updates: 312,556
Cumulative Timesteps: 2,606,671,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.36189
Policy Entropy: 2.42008
Value Function Loss: 0.01940

Mean KL Divergence: 0.02807
SB3 Clip Fraction: 0.14566
Policy Update Magnitude: 0.46829
Value Function Update Magnitude: 0.64653

Collected Steps per Second: 22,597.16455
Overall Steps per Second: 10,612.07145

Timestep Collection Time: 2.21284
Timestep Consumption Time: 2.49915
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.71199

Cumulative Model Updates: 312,562
Cumulative Timesteps: 2,606,721,756

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2606721756...
Checkpoint 2606721756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.18701
Policy Entropy: 2.41335
Value Function Loss: 0.01968

Mean KL Divergence: 0.02707
SB3 Clip Fraction: 0.14369
Policy Update Magnitude: 0.46757
Value Function Update Magnitude: 0.67639

Collected Steps per Second: 22,393.14763
Overall Steps per Second: 10,564.81799

Timestep Collection Time: 2.23283
Timestep Consumption Time: 2.49986
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.73269

Cumulative Model Updates: 312,568
Cumulative Timesteps: 2,606,771,756

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.10012
Policy Entropy: 2.39660
Value Function Loss: 0.02075

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.12374
Policy Update Magnitude: 0.50377
Value Function Update Magnitude: 0.71245

Collected Steps per Second: 22,070.34637
Overall Steps per Second: 10,556.35868

Timestep Collection Time: 2.26666
Timestep Consumption Time: 2.47228
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.73894

Cumulative Model Updates: 312,574
Cumulative Timesteps: 2,606,821,782

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2606821782...
Checkpoint 2606821782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.36552
Policy Entropy: 2.42761
Value Function Loss: 0.02054

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.11406
Policy Update Magnitude: 0.51108
Value Function Update Magnitude: 0.71923

Collected Steps per Second: 21,997.90809
Overall Steps per Second: 10,828.69982

Timestep Collection Time: 2.27294
Timestep Consumption Time: 2.34442
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.61736

Cumulative Model Updates: 312,580
Cumulative Timesteps: 2,606,871,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.06723
Policy Entropy: 2.44904
Value Function Loss: 0.02115

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.09113
Policy Update Magnitude: 0.50395
Value Function Update Magnitude: 0.72327

Collected Steps per Second: 21,780.86761
Overall Steps per Second: 10,596.68410

Timestep Collection Time: 2.29688
Timestep Consumption Time: 2.42422
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.72110

Cumulative Model Updates: 312,586
Cumulative Timesteps: 2,606,921,810

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2606921810...
Checkpoint 2606921810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.35601
Policy Entropy: 2.44038
Value Function Loss: 0.02067

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.09412
Policy Update Magnitude: 0.50266
Value Function Update Magnitude: 0.72255

Collected Steps per Second: 21,950.40612
Overall Steps per Second: 10,617.76685

Timestep Collection Time: 2.27923
Timestep Consumption Time: 2.43268
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.71191

Cumulative Model Updates: 312,592
Cumulative Timesteps: 2,606,971,840

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.35035
Policy Entropy: 2.44156
Value Function Loss: 0.02144

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.49823
Value Function Update Magnitude: 0.69778

Collected Steps per Second: 22,271.60383
Overall Steps per Second: 10,606.76418

Timestep Collection Time: 2.24546
Timestep Consumption Time: 2.46946
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.71492

Cumulative Model Updates: 312,598
Cumulative Timesteps: 2,607,021,850

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2607021850...
Checkpoint 2607021850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.72755
Policy Entropy: 2.44377
Value Function Loss: 0.02095

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.08852
Policy Update Magnitude: 0.49287
Value Function Update Magnitude: 0.67548

Collected Steps per Second: 21,865.28964
Overall Steps per Second: 10,459.13346

Timestep Collection Time: 2.28783
Timestep Consumption Time: 2.49498
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.78281

Cumulative Model Updates: 312,604
Cumulative Timesteps: 2,607,071,874

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.00120
Policy Entropy: 2.45775
Value Function Loss: 0.02154

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.08454
Policy Update Magnitude: 0.49443
Value Function Update Magnitude: 0.67680

Collected Steps per Second: 23,330.76388
Overall Steps per Second: 10,877.72725

Timestep Collection Time: 2.14404
Timestep Consumption Time: 2.45453
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.59857

Cumulative Model Updates: 312,610
Cumulative Timesteps: 2,607,121,896

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2607121896...
Checkpoint 2607121896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.11213
Policy Entropy: 2.45061
Value Function Loss: 0.02109

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.09063
Policy Update Magnitude: 0.48943
Value Function Update Magnitude: 0.69621

Collected Steps per Second: 21,993.38351
Overall Steps per Second: 10,563.28350

Timestep Collection Time: 2.27341
Timestep Consumption Time: 2.45997
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.73338

Cumulative Model Updates: 312,616
Cumulative Timesteps: 2,607,171,896

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.85362
Policy Entropy: 2.44220
Value Function Loss: 0.02225

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.09151
Policy Update Magnitude: 0.49160
Value Function Update Magnitude: 0.69938

Collected Steps per Second: 21,066.10989
Overall Steps per Second: 10,305.08111

Timestep Collection Time: 2.37481
Timestep Consumption Time: 2.47988
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.85469

Cumulative Model Updates: 312,622
Cumulative Timesteps: 2,607,221,924

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2607221924...
Checkpoint 2607221924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.06298
Policy Entropy: 2.43241
Value Function Loss: 0.02139

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.08973
Policy Update Magnitude: 0.49401
Value Function Update Magnitude: 0.69875

Collected Steps per Second: 22,384.93207
Overall Steps per Second: 10,880.94819

Timestep Collection Time: 2.23525
Timestep Consumption Time: 2.36324
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.59850

Cumulative Model Updates: 312,628
Cumulative Timesteps: 2,607,271,960

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.25709
Policy Entropy: 2.43850
Value Function Loss: 0.02061

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.09276
Policy Update Magnitude: 0.49103
Value Function Update Magnitude: 0.70399

Collected Steps per Second: 22,754.46285
Overall Steps per Second: 10,702.64298

Timestep Collection Time: 2.19807
Timestep Consumption Time: 2.47516
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.67324

Cumulative Model Updates: 312,634
Cumulative Timesteps: 2,607,321,976

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2607321976...
Checkpoint 2607321976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.08576
Policy Entropy: 2.45500
Value Function Loss: 0.02047

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.10294
Policy Update Magnitude: 0.49284
Value Function Update Magnitude: 0.70691

Collected Steps per Second: 22,467.26596
Overall Steps per Second: 10,618.90763

Timestep Collection Time: 2.22680
Timestep Consumption Time: 2.48461
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.71141

Cumulative Model Updates: 312,640
Cumulative Timesteps: 2,607,372,006

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.88492
Policy Entropy: 2.47385
Value Function Loss: 0.02049

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.09959
Policy Update Magnitude: 0.48961
Value Function Update Magnitude: 0.69469

Collected Steps per Second: 22,507.22982
Overall Steps per Second: 10,768.09838

Timestep Collection Time: 2.22284
Timestep Consumption Time: 2.42329
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.64613

Cumulative Model Updates: 312,646
Cumulative Timesteps: 2,607,422,036

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2607422036...
Checkpoint 2607422036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.23903
Policy Entropy: 2.45937
Value Function Loss: 0.02113

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.09326
Policy Update Magnitude: 0.50017
Value Function Update Magnitude: 0.67810

Collected Steps per Second: 21,823.75702
Overall Steps per Second: 10,672.86151

Timestep Collection Time: 2.29145
Timestep Consumption Time: 2.39408
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.68553

Cumulative Model Updates: 312,652
Cumulative Timesteps: 2,607,472,044

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.30984
Policy Entropy: 2.44862
Value Function Loss: 0.02089

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.09304
Policy Update Magnitude: 0.49833
Value Function Update Magnitude: 0.67553

Collected Steps per Second: 22,531.48347
Overall Steps per Second: 10,754.34801

Timestep Collection Time: 2.22009
Timestep Consumption Time: 2.43123
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.65133

Cumulative Model Updates: 312,658
Cumulative Timesteps: 2,607,522,066

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2607522066...
Checkpoint 2607522066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.90157
Policy Entropy: 2.45748
Value Function Loss: 0.02032

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.08640
Policy Update Magnitude: 0.48865
Value Function Update Magnitude: 0.68116

Collected Steps per Second: 21,220.47385
Overall Steps per Second: 10,258.14043

Timestep Collection Time: 2.35669
Timestep Consumption Time: 2.51847
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.87515

Cumulative Model Updates: 312,664
Cumulative Timesteps: 2,607,572,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.80982
Policy Entropy: 2.44707
Value Function Loss: 0.02061

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.08267
Policy Update Magnitude: 0.48410
Value Function Update Magnitude: 0.66021

Collected Steps per Second: 22,137.60302
Overall Steps per Second: 10,479.24914

Timestep Collection Time: 2.26077
Timestep Consumption Time: 2.51515
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.77591

Cumulative Model Updates: 312,670
Cumulative Timesteps: 2,607,622,124

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2607622124...
Checkpoint 2607622124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.64552
Policy Entropy: 2.42291
Value Function Loss: 0.02062

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.47985
Value Function Update Magnitude: 0.63494

Collected Steps per Second: 21,585.96601
Overall Steps per Second: 10,567.53624

Timestep Collection Time: 2.31706
Timestep Consumption Time: 2.41592
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.73299

Cumulative Model Updates: 312,676
Cumulative Timesteps: 2,607,672,140

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.94656
Policy Entropy: 2.40584
Value Function Loss: 0.02100

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.08390
Policy Update Magnitude: 0.48365
Value Function Update Magnitude: 0.67184

Collected Steps per Second: 22,422.05848
Overall Steps per Second: 10,721.51339

Timestep Collection Time: 2.23030
Timestep Consumption Time: 2.43396
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.66427

Cumulative Model Updates: 312,682
Cumulative Timesteps: 2,607,722,148

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2607722148...
Checkpoint 2607722148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.30315
Policy Entropy: 2.42096
Value Function Loss: 0.02076

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.08786
Policy Update Magnitude: 0.48907
Value Function Update Magnitude: 0.68469

Collected Steps per Second: 22,341.80414
Overall Steps per Second: 10,543.06013

Timestep Collection Time: 2.23876
Timestep Consumption Time: 2.50540
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.74416

Cumulative Model Updates: 312,688
Cumulative Timesteps: 2,607,772,166

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.55690
Policy Entropy: 2.42124
Value Function Loss: 0.02084

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.08622
Policy Update Magnitude: 0.49162
Value Function Update Magnitude: 0.67480

Collected Steps per Second: 22,796.52406
Overall Steps per Second: 10,835.55677

Timestep Collection Time: 2.19349
Timestep Consumption Time: 2.42131
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.61481

Cumulative Model Updates: 312,694
Cumulative Timesteps: 2,607,822,170

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2607822170...
Checkpoint 2607822170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.63121
Policy Entropy: 2.41556
Value Function Loss: 0.02100

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.09633
Policy Update Magnitude: 0.49676
Value Function Update Magnitude: 0.68956

Collected Steps per Second: 22,176.62354
Overall Steps per Second: 10,616.00489

Timestep Collection Time: 2.25499
Timestep Consumption Time: 2.45564
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.71062

Cumulative Model Updates: 312,700
Cumulative Timesteps: 2,607,872,178

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.98168
Policy Entropy: 2.40734
Value Function Loss: 0.02099

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.10715
Policy Update Magnitude: 0.49857
Value Function Update Magnitude: 0.68703

Collected Steps per Second: 22,680.57477
Overall Steps per Second: 10,923.35143

Timestep Collection Time: 2.20532
Timestep Consumption Time: 2.37367
PPO Batch Consumption Time: 0.28190
Total Iteration Time: 4.57900

Cumulative Model Updates: 312,706
Cumulative Timesteps: 2,607,922,196

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2607922196...
Checkpoint 2607922196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.00385
Policy Entropy: 2.39971
Value Function Loss: 0.02136

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.11186
Policy Update Magnitude: 0.50039
Value Function Update Magnitude: 0.67926

Collected Steps per Second: 22,048.33533
Overall Steps per Second: 10,638.03283

Timestep Collection Time: 2.26774
Timestep Consumption Time: 2.43237
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.70012

Cumulative Model Updates: 312,712
Cumulative Timesteps: 2,607,972,196

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.21555
Policy Entropy: 2.39886
Value Function Loss: 0.02259

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.51458
Value Function Update Magnitude: 0.67511

Collected Steps per Second: 22,335.01804
Overall Steps per Second: 10,567.11069

Timestep Collection Time: 2.23962
Timestep Consumption Time: 2.49412
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.73374

Cumulative Model Updates: 312,718
Cumulative Timesteps: 2,608,022,218

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2608022218...
Checkpoint 2608022218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.45476
Policy Entropy: 2.39397
Value Function Loss: 0.02244

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.10911
Policy Update Magnitude: 0.51277
Value Function Update Magnitude: 0.66611

Collected Steps per Second: 21,826.25229
Overall Steps per Second: 10,637.67568

Timestep Collection Time: 2.29082
Timestep Consumption Time: 2.40946
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.70027

Cumulative Model Updates: 312,724
Cumulative Timesteps: 2,608,072,218

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.21377
Policy Entropy: 2.40769
Value Function Loss: 0.02208

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.10023
Policy Update Magnitude: 0.50517
Value Function Update Magnitude: 0.66359

Collected Steps per Second: 22,277.60445
Overall Steps per Second: 10,698.97831

Timestep Collection Time: 2.24512
Timestep Consumption Time: 2.42971
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.67484

Cumulative Model Updates: 312,730
Cumulative Timesteps: 2,608,122,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2608122234...
Checkpoint 2608122234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.90054
Policy Entropy: 2.42119
Value Function Loss: 0.02049

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.09884
Policy Update Magnitude: 0.48903
Value Function Update Magnitude: 0.67234

Collected Steps per Second: 21,747.43486
Overall Steps per Second: 10,333.21553

Timestep Collection Time: 2.30050
Timestep Consumption Time: 2.54117
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.84167

Cumulative Model Updates: 312,736
Cumulative Timesteps: 2,608,172,264

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.38115
Policy Entropy: 2.41773
Value Function Loss: 0.02060

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.10149
Policy Update Magnitude: 0.49238
Value Function Update Magnitude: 0.66672

Collected Steps per Second: 22,552.21915
Overall Steps per Second: 10,547.99049

Timestep Collection Time: 2.21717
Timestep Consumption Time: 2.52326
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.74043

Cumulative Model Updates: 312,742
Cumulative Timesteps: 2,608,222,266

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2608222266...
Checkpoint 2608222266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.78750
Policy Entropy: 2.42193
Value Function Loss: 0.02080

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.49866
Value Function Update Magnitude: 0.66573

Collected Steps per Second: 22,112.62983
Overall Steps per Second: 10,820.30794

Timestep Collection Time: 2.26169
Timestep Consumption Time: 2.36036
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.62205

Cumulative Model Updates: 312,748
Cumulative Timesteps: 2,608,272,278

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.29560
Policy Entropy: 2.41831
Value Function Loss: 0.02078

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.48684
Value Function Update Magnitude: 0.66727

Collected Steps per Second: 22,514.09392
Overall Steps per Second: 10,592.40799

Timestep Collection Time: 2.22216
Timestep Consumption Time: 2.50103
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.72319

Cumulative Model Updates: 312,754
Cumulative Timesteps: 2,608,322,308

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2608322308...
Checkpoint 2608322308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.17433
Policy Entropy: 2.42649
Value Function Loss: 0.02022

Mean KL Divergence: 0.02184
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.46715
Value Function Update Magnitude: 0.66251

Collected Steps per Second: 22,191.28363
Overall Steps per Second: 10,569.69471

Timestep Collection Time: 2.25314
Timestep Consumption Time: 2.47737
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.73051

Cumulative Model Updates: 312,760
Cumulative Timesteps: 2,608,372,308

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.90989
Policy Entropy: 2.42777
Value Function Loss: 0.01944

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.11569
Policy Update Magnitude: 0.47380
Value Function Update Magnitude: 0.64162

Collected Steps per Second: 22,342.21032
Overall Steps per Second: 10,614.04943

Timestep Collection Time: 2.23872
Timestep Consumption Time: 2.47371
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.71243

Cumulative Model Updates: 312,766
Cumulative Timesteps: 2,608,422,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2608422326...
Checkpoint 2608422326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.26320
Policy Entropy: 2.39943
Value Function Loss: 0.01968

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.10655
Policy Update Magnitude: 0.49770
Value Function Update Magnitude: 0.64015

Collected Steps per Second: 22,234.54956
Overall Steps per Second: 10,554.38729

Timestep Collection Time: 2.24920
Timestep Consumption Time: 2.48911
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.73831

Cumulative Model Updates: 312,772
Cumulative Timesteps: 2,608,472,336

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.26090
Policy Entropy: 2.41835
Value Function Loss: 0.01863

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.09520
Policy Update Magnitude: 0.48972
Value Function Update Magnitude: 0.65162

Collected Steps per Second: 22,360.97854
Overall Steps per Second: 10,912.38050

Timestep Collection Time: 2.23711
Timestep Consumption Time: 2.34704
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.58415

Cumulative Model Updates: 312,778
Cumulative Timesteps: 2,608,522,360

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2608522360...
Checkpoint 2608522360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.04599
Policy Entropy: 2.41042
Value Function Loss: 0.02005

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.10908
Policy Update Magnitude: 0.48455
Value Function Update Magnitude: 0.67047

Collected Steps per Second: 21,877.79110
Overall Steps per Second: 10,580.48809

Timestep Collection Time: 2.28606
Timestep Consumption Time: 2.44094
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.72700

Cumulative Model Updates: 312,784
Cumulative Timesteps: 2,608,572,374

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.63939
Policy Entropy: 2.43463
Value Function Loss: 0.02040

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.47305
Value Function Update Magnitude: 0.69281

Collected Steps per Second: 21,780.47974
Overall Steps per Second: 10,459.56379

Timestep Collection Time: 2.29582
Timestep Consumption Time: 2.48488
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.78070

Cumulative Model Updates: 312,790
Cumulative Timesteps: 2,608,622,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2608622378...
Checkpoint 2608622378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.86412
Policy Entropy: 2.43533
Value Function Loss: 0.02210

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.12035
Policy Update Magnitude: 0.46534
Value Function Update Magnitude: 0.69532

Collected Steps per Second: 21,960.10966
Overall Steps per Second: 10,681.55577

Timestep Collection Time: 2.27813
Timestep Consumption Time: 2.40546
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.68359

Cumulative Model Updates: 312,796
Cumulative Timesteps: 2,608,672,406

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.42919
Policy Entropy: 2.44430
Value Function Loss: 0.02330

Mean KL Divergence: 0.02156
SB3 Clip Fraction: 0.12626
Policy Update Magnitude: 0.47469
Value Function Update Magnitude: 0.70343

Collected Steps per Second: 22,090.60096
Overall Steps per Second: 10,826.87996

Timestep Collection Time: 2.26476
Timestep Consumption Time: 2.35614
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.62091

Cumulative Model Updates: 312,802
Cumulative Timesteps: 2,608,722,436

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2608722436...
Checkpoint 2608722436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.59657
Policy Entropy: 2.44239
Value Function Loss: 0.02138

Mean KL Divergence: 0.02373
SB3 Clip Fraction: 0.13284
Policy Update Magnitude: 0.48135
Value Function Update Magnitude: 0.71959

Collected Steps per Second: 21,737.45974
Overall Steps per Second: 10,411.16941

Timestep Collection Time: 2.30183
Timestep Consumption Time: 2.50416
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.80599

Cumulative Model Updates: 312,808
Cumulative Timesteps: 2,608,772,472

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.60426
Policy Entropy: 2.43479
Value Function Loss: 0.01910

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.11456
Policy Update Magnitude: 0.47583
Value Function Update Magnitude: 0.67974

Collected Steps per Second: 22,587.82215
Overall Steps per Second: 10,661.01740

Timestep Collection Time: 2.21429
Timestep Consumption Time: 2.47719
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.69148

Cumulative Model Updates: 312,814
Cumulative Timesteps: 2,608,822,488

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2608822488...
Checkpoint 2608822488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.14821
Policy Entropy: 2.43171
Value Function Loss: 0.01933

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.09678
Policy Update Magnitude: 0.48028
Value Function Update Magnitude: 0.64385

Collected Steps per Second: 22,128.80072
Overall Steps per Second: 10,666.15407

Timestep Collection Time: 2.25977
Timestep Consumption Time: 2.42852
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.68829

Cumulative Model Updates: 312,820
Cumulative Timesteps: 2,608,872,494

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.23231
Policy Entropy: 2.42600
Value Function Loss: 0.01991

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.09518
Policy Update Magnitude: 0.48867
Value Function Update Magnitude: 0.67695

Collected Steps per Second: 22,257.78069
Overall Steps per Second: 10,865.69368

Timestep Collection Time: 2.24775
Timestep Consumption Time: 2.35665
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.60440

Cumulative Model Updates: 312,826
Cumulative Timesteps: 2,608,922,524

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2608922524...
Checkpoint 2608922524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.19029
Policy Entropy: 2.41660
Value Function Loss: 0.02043

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.49452
Value Function Update Magnitude: 0.70554

Collected Steps per Second: 21,802.70060
Overall Steps per Second: 10,462.90983

Timestep Collection Time: 2.29449
Timestep Consumption Time: 2.48678
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.78127

Cumulative Model Updates: 312,832
Cumulative Timesteps: 2,608,972,550

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.56834
Policy Entropy: 2.42751
Value Function Loss: 0.02108

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.08053
Policy Update Magnitude: 0.49400
Value Function Update Magnitude: 0.71150

Collected Steps per Second: 22,533.67451
Overall Steps per Second: 10,711.39663

Timestep Collection Time: 2.22014
Timestep Consumption Time: 2.45040
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.67054

Cumulative Model Updates: 312,838
Cumulative Timesteps: 2,609,022,578

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2609022578...
Checkpoint 2609022578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.27483
Policy Entropy: 2.44493
Value Function Loss: 0.02130

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.08555
Policy Update Magnitude: 0.49352
Value Function Update Magnitude: 0.70893

Collected Steps per Second: 22,007.91563
Overall Steps per Second: 10,695.34039

Timestep Collection Time: 2.27282
Timestep Consumption Time: 2.40398
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.67680

Cumulative Model Updates: 312,844
Cumulative Timesteps: 2,609,072,598

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.03058
Policy Entropy: 2.45516
Value Function Loss: 0.02137

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.50086
Value Function Update Magnitude: 0.70496

Collected Steps per Second: 21,831.23564
Overall Steps per Second: 10,502.65514

Timestep Collection Time: 2.29121
Timestep Consumption Time: 2.47139
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.76261

Cumulative Model Updates: 312,850
Cumulative Timesteps: 2,609,122,618

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2609122618...
Checkpoint 2609122618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.92838
Policy Entropy: 2.46786
Value Function Loss: 0.02125

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.51786
Value Function Update Magnitude: 0.70942

Collected Steps per Second: 21,195.36359
Overall Steps per Second: 10,640.93850

Timestep Collection Time: 2.36014
Timestep Consumption Time: 2.34095
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.70109

Cumulative Model Updates: 312,856
Cumulative Timesteps: 2,609,172,642

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.49491
Policy Entropy: 2.44999
Value Function Loss: 0.02102

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.50184
Value Function Update Magnitude: 0.71414

Collected Steps per Second: 21,573.77534
Overall Steps per Second: 10,362.13739

Timestep Collection Time: 2.31837
Timestep Consumption Time: 2.50843
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.82680

Cumulative Model Updates: 312,862
Cumulative Timesteps: 2,609,222,658

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2609222658...
Checkpoint 2609222658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.92289
Policy Entropy: 2.45336
Value Function Loss: 0.02006

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.09727
Policy Update Magnitude: 0.49037
Value Function Update Magnitude: 0.70411

Collected Steps per Second: 21,841.41832
Overall Steps per Second: 10,576.13969

Timestep Collection Time: 2.28959
Timestep Consumption Time: 2.43878
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.72838

Cumulative Model Updates: 312,868
Cumulative Timesteps: 2,609,272,666

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.28011
Policy Entropy: 2.43882
Value Function Loss: 0.01999

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.48298
Value Function Update Magnitude: 0.68683

Collected Steps per Second: 21,540.40643
Overall Steps per Second: 10,570.80107

Timestep Collection Time: 2.32261
Timestep Consumption Time: 2.41024
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.73285

Cumulative Model Updates: 312,874
Cumulative Timesteps: 2,609,322,696

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2609322696...
Checkpoint 2609322696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.90748
Policy Entropy: 2.44317
Value Function Loss: 0.01865

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.08594
Policy Update Magnitude: 0.47352
Value Function Update Magnitude: 0.69486

Collected Steps per Second: 22,486.42238
Overall Steps per Second: 10,600.80354

Timestep Collection Time: 2.22454
Timestep Consumption Time: 2.49416
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.71870

Cumulative Model Updates: 312,880
Cumulative Timesteps: 2,609,372,718

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.86662
Policy Entropy: 2.42608
Value Function Loss: 0.01968

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.08202
Policy Update Magnitude: 0.47716
Value Function Update Magnitude: 0.68014

Collected Steps per Second: 22,526.29603
Overall Steps per Second: 10,482.59804

Timestep Collection Time: 2.21972
Timestep Consumption Time: 2.55028
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.77000

Cumulative Model Updates: 312,886
Cumulative Timesteps: 2,609,422,720

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2609422720...
Checkpoint 2609422720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.98126
Policy Entropy: 2.42959
Value Function Loss: 0.01989

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.07892
Policy Update Magnitude: 0.48400
Value Function Update Magnitude: 0.66657

Collected Steps per Second: 22,185.20106
Overall Steps per Second: 10,610.18355

Timestep Collection Time: 2.25475
Timestep Consumption Time: 2.45978
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.71453

Cumulative Model Updates: 312,892
Cumulative Timesteps: 2,609,472,742

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.26917
Policy Entropy: 2.44312
Value Function Loss: 0.02176

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.10110
Policy Update Magnitude: 0.48356
Value Function Update Magnitude: 0.69314

Collected Steps per Second: 22,646.56062
Overall Steps per Second: 10,946.05345

Timestep Collection Time: 2.20864
Timestep Consumption Time: 2.36087
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.56950

Cumulative Model Updates: 312,898
Cumulative Timesteps: 2,609,522,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2609522760...
Checkpoint 2609522760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.19468
Policy Entropy: 2.43156
Value Function Loss: 0.02106

Mean KL Divergence: 0.02299
SB3 Clip Fraction: 0.13166
Policy Update Magnitude: 0.47009
Value Function Update Magnitude: 0.71698

Collected Steps per Second: 22,125.37399
Overall Steps per Second: 10,691.25409

Timestep Collection Time: 2.25994
Timestep Consumption Time: 2.41697
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.67691

Cumulative Model Updates: 312,904
Cumulative Timesteps: 2,609,572,762

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.74333
Policy Entropy: 2.43978
Value Function Loss: 0.02047

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.11651
Policy Update Magnitude: 0.46553
Value Function Update Magnitude: 0.70929

Collected Steps per Second: 22,682.73312
Overall Steps per Second: 10,744.38380

Timestep Collection Time: 2.20432
Timestep Consumption Time: 2.44927
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.65359

Cumulative Model Updates: 312,910
Cumulative Timesteps: 2,609,622,762

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2609622762...
Checkpoint 2609622762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.88028
Policy Entropy: 2.42201
Value Function Loss: 0.01957

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.10745
Policy Update Magnitude: 0.48444
Value Function Update Magnitude: 0.69173

Collected Steps per Second: 21,970.51089
Overall Steps per Second: 10,663.64782

Timestep Collection Time: 2.27678
Timestep Consumption Time: 2.41411
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.69089

Cumulative Model Updates: 312,916
Cumulative Timesteps: 2,609,672,784

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.08072
Policy Entropy: 2.43646
Value Function Loss: 0.02037

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.09950
Policy Update Magnitude: 0.49460
Value Function Update Magnitude: 0.69617

Collected Steps per Second: 22,250.94013
Overall Steps per Second: 10,515.97283

Timestep Collection Time: 2.24746
Timestep Consumption Time: 2.50798
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.75543

Cumulative Model Updates: 312,922
Cumulative Timesteps: 2,609,722,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2609722792...
Checkpoint 2609722792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.45191
Policy Entropy: 2.41579
Value Function Loss: 0.02129

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.49991
Value Function Update Magnitude: 0.73251

Collected Steps per Second: 22,349.93500
Overall Steps per Second: 10,723.36657

Timestep Collection Time: 2.23822
Timestep Consumption Time: 2.42674
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.66495

Cumulative Model Updates: 312,928
Cumulative Timesteps: 2,609,772,816

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.48609
Policy Entropy: 2.41566
Value Function Loss: 0.02185

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.49766
Value Function Update Magnitude: 0.71665

Collected Steps per Second: 22,238.06061
Overall Steps per Second: 10,552.88649

Timestep Collection Time: 2.24939
Timestep Consumption Time: 2.49074
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.74012

Cumulative Model Updates: 312,934
Cumulative Timesteps: 2,609,822,838

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2609822838...
Checkpoint 2609822838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.47939
Policy Entropy: 2.42272
Value Function Loss: 0.02120

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.08805
Policy Update Magnitude: 0.49849
Value Function Update Magnitude: 0.69599

Collected Steps per Second: 21,746.05949
Overall Steps per Second: 10,470.87064

Timestep Collection Time: 2.30065
Timestep Consumption Time: 2.47737
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.77802

Cumulative Model Updates: 312,940
Cumulative Timesteps: 2,609,872,868

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.88993
Policy Entropy: 2.44809
Value Function Loss: 0.02009

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.49025
Value Function Update Magnitude: 0.68704

Collected Steps per Second: 22,195.72656
Overall Steps per Second: 10,847.98290

Timestep Collection Time: 2.25404
Timestep Consumption Time: 2.35788
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.61192

Cumulative Model Updates: 312,946
Cumulative Timesteps: 2,609,922,898

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2609922898...
Checkpoint 2609922898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.37556
Policy Entropy: 2.45716
Value Function Loss: 0.01956

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.08332
Policy Update Magnitude: 0.48490
Value Function Update Magnitude: 0.67281

Collected Steps per Second: 21,865.25089
Overall Steps per Second: 10,412.48390

Timestep Collection Time: 2.28710
Timestep Consumption Time: 2.51560
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.80270

Cumulative Model Updates: 312,952
Cumulative Timesteps: 2,609,972,906

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.91835
Policy Entropy: 2.46243
Value Function Loss: 0.02014

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.07996
Policy Update Magnitude: 0.48015
Value Function Update Magnitude: 0.66774

Collected Steps per Second: 22,619.64703
Overall Steps per Second: 10,674.11491

Timestep Collection Time: 2.21171
Timestep Consumption Time: 2.47515
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.68685

Cumulative Model Updates: 312,958
Cumulative Timesteps: 2,610,022,934

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2610022934...
Checkpoint 2610022934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.11390
Policy Entropy: 2.46187
Value Function Loss: 0.02042

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.08194
Policy Update Magnitude: 0.48195
Value Function Update Magnitude: 0.64981

Collected Steps per Second: 22,056.76951
Overall Steps per Second: 10,599.92081

Timestep Collection Time: 2.26815
Timestep Consumption Time: 2.45151
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.71966

Cumulative Model Updates: 312,964
Cumulative Timesteps: 2,610,072,962

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.97382
Policy Entropy: 2.46014
Value Function Loss: 0.02002

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.07684
Policy Update Magnitude: 0.47788
Value Function Update Magnitude: 0.65635

Collected Steps per Second: 22,449.83259
Overall Steps per Second: 10,610.18427

Timestep Collection Time: 2.22719
Timestep Consumption Time: 2.48527
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.71245

Cumulative Model Updates: 312,970
Cumulative Timesteps: 2,610,122,962

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2610122962...
Checkpoint 2610122962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.28098
Policy Entropy: 2.44536
Value Function Loss: 0.02004

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.08007
Policy Update Magnitude: 0.47393
Value Function Update Magnitude: 0.63798

Collected Steps per Second: 22,928.56373
Overall Steps per Second: 10,684.60390

Timestep Collection Time: 2.18103
Timestep Consumption Time: 2.49934
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.68038

Cumulative Model Updates: 312,976
Cumulative Timesteps: 2,610,172,970

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.14041
Policy Entropy: 2.41187
Value Function Loss: 0.02100

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.08338
Policy Update Magnitude: 0.48465
Value Function Update Magnitude: 0.64638

Collected Steps per Second: 22,564.07082
Overall Steps per Second: 10,744.96328

Timestep Collection Time: 2.21662
Timestep Consumption Time: 2.43821
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.65483

Cumulative Model Updates: 312,982
Cumulative Timesteps: 2,610,222,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2610222986...
Checkpoint 2610222986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.66187
Policy Entropy: 2.39772
Value Function Loss: 0.02152

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.08595
Policy Update Magnitude: 0.48757
Value Function Update Magnitude: 0.65189

Collected Steps per Second: 22,209.97806
Overall Steps per Second: 10,644.27935

Timestep Collection Time: 2.25232
Timestep Consumption Time: 2.44729
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.69961

Cumulative Model Updates: 312,988
Cumulative Timesteps: 2,610,273,010

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.15396
Policy Entropy: 2.41207
Value Function Loss: 0.02227

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.08795
Policy Update Magnitude: 0.49359
Value Function Update Magnitude: 0.65872

Collected Steps per Second: 21,765.94595
Overall Steps per Second: 10,499.38032

Timestep Collection Time: 2.29726
Timestep Consumption Time: 2.46512
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.76238

Cumulative Model Updates: 312,994
Cumulative Timesteps: 2,610,323,012

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2610323012...
Checkpoint 2610323012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.00749
Policy Entropy: 2.44008
Value Function Loss: 0.02180

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.08372
Policy Update Magnitude: 0.49618
Value Function Update Magnitude: 0.66210

Collected Steps per Second: 21,742.77420
Overall Steps per Second: 10,686.11914

Timestep Collection Time: 2.30053
Timestep Consumption Time: 2.38030
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.68084

Cumulative Model Updates: 313,000
Cumulative Timesteps: 2,610,373,032

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.71206
Policy Entropy: 2.44847
Value Function Loss: 0.02062

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.08956
Policy Update Magnitude: 0.48757
Value Function Update Magnitude: 0.67614

Collected Steps per Second: 22,096.90167
Overall Steps per Second: 10,433.45273

Timestep Collection Time: 2.26303
Timestep Consumption Time: 2.52982
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.79285

Cumulative Model Updates: 313,006
Cumulative Timesteps: 2,610,423,038

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2610423038...
Checkpoint 2610423038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.40681
Policy Entropy: 2.43997
Value Function Loss: 0.01944

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.08973
Policy Update Magnitude: 0.48290
Value Function Update Magnitude: 0.65751

Collected Steps per Second: 21,623.77315
Overall Steps per Second: 10,565.31444

Timestep Collection Time: 2.31338
Timestep Consumption Time: 2.42136
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.73474

Cumulative Model Updates: 313,012
Cumulative Timesteps: 2,610,473,062

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.77944
Policy Entropy: 2.41966
Value Function Loss: 0.02035

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.09827
Policy Update Magnitude: 0.48734
Value Function Update Magnitude: 0.64124

Collected Steps per Second: 21,629.01720
Overall Steps per Second: 10,605.74065

Timestep Collection Time: 2.31226
Timestep Consumption Time: 2.40330
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.71556

Cumulative Model Updates: 313,018
Cumulative Timesteps: 2,610,523,074

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2610523074...
Checkpoint 2610523074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.68271
Policy Entropy: 2.41655
Value Function Loss: 0.02064

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.11461
Policy Update Magnitude: 0.48644
Value Function Update Magnitude: 0.64179

Collected Steps per Second: 21,937.86844
Overall Steps per Second: 10,628.58029

Timestep Collection Time: 2.27998
Timestep Consumption Time: 2.42601
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.70599

Cumulative Model Updates: 313,024
Cumulative Timesteps: 2,610,573,092

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.91813
Policy Entropy: 2.43704
Value Function Loss: 0.02042

Mean KL Divergence: 0.02758
SB3 Clip Fraction: 0.13504
Policy Update Magnitude: 0.47625
Value Function Update Magnitude: 0.64033

Collected Steps per Second: 22,536.73955
Overall Steps per Second: 10,495.31268

Timestep Collection Time: 2.21993
Timestep Consumption Time: 2.54696
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.76689

Cumulative Model Updates: 313,030
Cumulative Timesteps: 2,610,623,122

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2610623122...
Checkpoint 2610623122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.59159
Policy Entropy: 2.46640
Value Function Loss: 0.01900

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.47280
Value Function Update Magnitude: 0.63692

Collected Steps per Second: 22,255.68628
Overall Steps per Second: 10,523.31588

Timestep Collection Time: 2.24779
Timestep Consumption Time: 2.50604
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.75382

Cumulative Model Updates: 313,036
Cumulative Timesteps: 2,610,673,148

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.13058
Policy Entropy: 2.46388
Value Function Loss: 0.01865

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.10754
Policy Update Magnitude: 0.46743
Value Function Update Magnitude: 0.62609

Collected Steps per Second: 21,887.61216
Overall Steps per Second: 10,475.87823

Timestep Collection Time: 2.28668
Timestep Consumption Time: 2.49096
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.77764

Cumulative Model Updates: 313,042
Cumulative Timesteps: 2,610,723,198

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2610723198...
Checkpoint 2610723198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.97993
Policy Entropy: 2.45017
Value Function Loss: 0.01948

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.09721
Policy Update Magnitude: 0.46490
Value Function Update Magnitude: 0.60585

Collected Steps per Second: 22,346.39967
Overall Steps per Second: 10,728.13753

Timestep Collection Time: 2.23812
Timestep Consumption Time: 2.42382
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.66195

Cumulative Model Updates: 313,048
Cumulative Timesteps: 2,610,773,212

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.85697
Policy Entropy: 2.43999
Value Function Loss: 0.02163

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.09472
Policy Update Magnitude: 0.47463
Value Function Update Magnitude: 0.61071

Collected Steps per Second: 22,204.46359
Overall Steps per Second: 10,398.16314

Timestep Collection Time: 2.25180
Timestep Consumption Time: 2.55674
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.80854

Cumulative Model Updates: 313,054
Cumulative Timesteps: 2,610,823,212

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2610823212...
Checkpoint 2610823212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.07021
Policy Entropy: 2.43789
Value Function Loss: 0.02129

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.09775
Policy Update Magnitude: 0.48625
Value Function Update Magnitude: 0.64309

Collected Steps per Second: 20,592.04264
Overall Steps per Second: 10,066.32987

Timestep Collection Time: 2.42812
Timestep Consumption Time: 2.53893
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.96705

Cumulative Model Updates: 313,060
Cumulative Timesteps: 2,610,873,212

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.65706
Policy Entropy: 2.43241
Value Function Loss: 0.02008

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.48118
Value Function Update Magnitude: 0.65792

Collected Steps per Second: 19,676.56567
Overall Steps per Second: 9,734.29004

Timestep Collection Time: 2.54191
Timestep Consumption Time: 2.59622
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 5.13813

Cumulative Model Updates: 313,066
Cumulative Timesteps: 2,610,923,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2610923228...
Checkpoint 2610923228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.46120
Policy Entropy: 2.40195
Value Function Loss: 0.02087

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.08483
Policy Update Magnitude: 0.48111
Value Function Update Magnitude: 0.63805

Collected Steps per Second: 22,068.12839
Overall Steps per Second: 10,622.98053

Timestep Collection Time: 2.26653
Timestep Consumption Time: 2.44194
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.70847

Cumulative Model Updates: 313,072
Cumulative Timesteps: 2,610,973,246

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.36705
Policy Entropy: 2.40401
Value Function Loss: 0.02106

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.08240
Policy Update Magnitude: 0.47797
Value Function Update Magnitude: 0.61367

Collected Steps per Second: 21,290.88338
Overall Steps per Second: 10,420.27491

Timestep Collection Time: 2.34870
Timestep Consumption Time: 2.45021
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.79891

Cumulative Model Updates: 313,078
Cumulative Timesteps: 2,611,023,252

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2611023252...
Checkpoint 2611023252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.16314
Policy Entropy: 2.38991
Value Function Loss: 0.02196

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.08202
Policy Update Magnitude: 0.48017
Value Function Update Magnitude: 0.61859

Collected Steps per Second: 22,189.65358
Overall Steps per Second: 10,695.75840

Timestep Collection Time: 2.25438
Timestep Consumption Time: 2.42261
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.67699

Cumulative Model Updates: 313,084
Cumulative Timesteps: 2,611,073,276

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.85089
Policy Entropy: 2.43352
Value Function Loss: 0.02155

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.08293
Policy Update Magnitude: 0.47978
Value Function Update Magnitude: 0.64886

Collected Steps per Second: 21,719.70312
Overall Steps per Second: 10,519.77394

Timestep Collection Time: 2.30335
Timestep Consumption Time: 2.45227
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.75562

Cumulative Model Updates: 313,090
Cumulative Timesteps: 2,611,123,304

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2611123304...
Checkpoint 2611123304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.02873
Policy Entropy: 2.41628
Value Function Loss: 0.02242

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.09327
Policy Update Magnitude: 0.48639
Value Function Update Magnitude: 0.66686

Collected Steps per Second: 22,086.23888
Overall Steps per Second: 10,699.34128

Timestep Collection Time: 2.26422
Timestep Consumption Time: 2.40972
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.67393

Cumulative Model Updates: 313,096
Cumulative Timesteps: 2,611,173,312

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.93478
Policy Entropy: 2.44405
Value Function Loss: 0.02199

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.09008
Policy Update Magnitude: 0.48929
Value Function Update Magnitude: 0.66321

Collected Steps per Second: 22,250.24969
Overall Steps per Second: 10,512.52390

Timestep Collection Time: 2.24779
Timestep Consumption Time: 2.50977
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.75756

Cumulative Model Updates: 313,102
Cumulative Timesteps: 2,611,223,326

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2611223326...
Checkpoint 2611223326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.73430
Policy Entropy: 2.45602
Value Function Loss: 0.01992

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.46806
Value Function Update Magnitude: 0.63228

Collected Steps per Second: 21,993.53244
Overall Steps per Second: 10,485.28033

Timestep Collection Time: 2.27440
Timestep Consumption Time: 2.49629
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.77069

Cumulative Model Updates: 313,108
Cumulative Timesteps: 2,611,273,348

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.01087
Policy Entropy: 2.46642
Value Function Loss: 0.02048

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.09676
Policy Update Magnitude: 0.45680
Value Function Update Magnitude: 0.59932

Collected Steps per Second: 22,686.85726
Overall Steps per Second: 10,555.19115

Timestep Collection Time: 2.20410
Timestep Consumption Time: 2.53329
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.73738

Cumulative Model Updates: 313,114
Cumulative Timesteps: 2,611,323,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2611323352...
Checkpoint 2611323352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.82496
Policy Entropy: 2.45787
Value Function Loss: 0.02082

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.09371
Policy Update Magnitude: 0.48491
Value Function Update Magnitude: 0.62480

Collected Steps per Second: 22,393.39291
Overall Steps per Second: 10,593.54561

Timestep Collection Time: 2.23396
Timestep Consumption Time: 2.48835
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.72231

Cumulative Model Updates: 313,120
Cumulative Timesteps: 2,611,373,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.78097
Policy Entropy: 2.41907
Value Function Loss: 0.02219

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.08768
Policy Update Magnitude: 0.49015
Value Function Update Magnitude: 0.64589

Collected Steps per Second: 22,228.16854
Overall Steps per Second: 10,582.44367

Timestep Collection Time: 2.24976
Timestep Consumption Time: 2.47580
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.72556

Cumulative Model Updates: 313,126
Cumulative Timesteps: 2,611,423,386

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2611423386...
Checkpoint 2611423386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.66506
Policy Entropy: 2.41825
Value Function Loss: 0.02144

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.08331
Policy Update Magnitude: 0.48971
Value Function Update Magnitude: 0.65831

Collected Steps per Second: 22,418.46319
Overall Steps per Second: 10,919.15218

Timestep Collection Time: 2.23155
Timestep Consumption Time: 2.35012
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.58167

Cumulative Model Updates: 313,132
Cumulative Timesteps: 2,611,473,414

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.85336
Policy Entropy: 2.43109
Value Function Loss: 0.02149

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.08709
Policy Update Magnitude: 0.48629
Value Function Update Magnitude: 0.66038

Collected Steps per Second: 22,331.57327
Overall Steps per Second: 10,537.26502

Timestep Collection Time: 2.23925
Timestep Consumption Time: 2.50638
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.74563

Cumulative Model Updates: 313,138
Cumulative Timesteps: 2,611,523,420

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2611523420...
Checkpoint 2611523420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.39930
Policy Entropy: 2.43855
Value Function Loss: 0.02013

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.08524
Policy Update Magnitude: 0.46961
Value Function Update Magnitude: 0.65160

Collected Steps per Second: 22,367.39773
Overall Steps per Second: 10,585.62075

Timestep Collection Time: 2.23549
Timestep Consumption Time: 2.48809
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.72358

Cumulative Model Updates: 313,144
Cumulative Timesteps: 2,611,573,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.19014
Policy Entropy: 2.45556
Value Function Loss: 0.02017

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.07951
Policy Update Magnitude: 0.46676
Value Function Update Magnitude: 0.64031

Collected Steps per Second: 22,134.40638
Overall Steps per Second: 10,559.46079

Timestep Collection Time: 2.25983
Timestep Consumption Time: 2.47715
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.73698

Cumulative Model Updates: 313,150
Cumulative Timesteps: 2,611,623,442

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2611623442...
Checkpoint 2611623442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.14019
Policy Entropy: 2.42883
Value Function Loss: 0.01996

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.09495
Policy Update Magnitude: 0.46335
Value Function Update Magnitude: 0.64628

Collected Steps per Second: 22,171.84005
Overall Steps per Second: 10,735.41385

Timestep Collection Time: 2.25538
Timestep Consumption Time: 2.40266
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.65804

Cumulative Model Updates: 313,156
Cumulative Timesteps: 2,611,673,448

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.19780
Policy Entropy: 2.44335
Value Function Loss: 0.02190

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.47422
Value Function Update Magnitude: 0.66237

Collected Steps per Second: 22,064.30356
Overall Steps per Second: 10,621.45424

Timestep Collection Time: 2.26692
Timestep Consumption Time: 2.44223
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.70915

Cumulative Model Updates: 313,162
Cumulative Timesteps: 2,611,723,466

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2611723466...
Checkpoint 2611723466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.62016
Policy Entropy: 2.40556
Value Function Loss: 0.02238

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.48826
Value Function Update Magnitude: 0.67241

Collected Steps per Second: 21,544.17189
Overall Steps per Second: 10,350.12172

Timestep Collection Time: 2.32118
Timestep Consumption Time: 2.51045
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.83163

Cumulative Model Updates: 313,168
Cumulative Timesteps: 2,611,773,474

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.05434
Policy Entropy: 2.39611
Value Function Loss: 0.02285

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.48937
Value Function Update Magnitude: 0.68107

Collected Steps per Second: 21,989.15940
Overall Steps per Second: 10,503.28426

Timestep Collection Time: 2.27567
Timestep Consumption Time: 2.48856
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.76422

Cumulative Model Updates: 313,174
Cumulative Timesteps: 2,611,823,514

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2611823514...
Checkpoint 2611823514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.22799
Policy Entropy: 2.39991
Value Function Loss: 0.02166

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.08791
Policy Update Magnitude: 0.48408
Value Function Update Magnitude: 0.67106

Collected Steps per Second: 21,900.59128
Overall Steps per Second: 10,631.35137

Timestep Collection Time: 2.28396
Timestep Consumption Time: 2.42100
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.70495

Cumulative Model Updates: 313,180
Cumulative Timesteps: 2,611,873,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.27154
Policy Entropy: 2.42151
Value Function Loss: 0.02190

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.48666
Value Function Update Magnitude: 0.65095

Collected Steps per Second: 22,082.05960
Overall Steps per Second: 10,517.49548

Timestep Collection Time: 2.26473
Timestep Consumption Time: 2.49020
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.75493

Cumulative Model Updates: 313,186
Cumulative Timesteps: 2,611,923,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2611923544...
Checkpoint 2611923544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.25934
Policy Entropy: 2.46138
Value Function Loss: 0.02001

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.09303
Policy Update Magnitude: 0.48054
Value Function Update Magnitude: 0.65645

Collected Steps per Second: 22,386.35441
Overall Steps per Second: 10,470.80746

Timestep Collection Time: 2.23449
Timestep Consumption Time: 2.54280
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.77728

Cumulative Model Updates: 313,192
Cumulative Timesteps: 2,611,973,566

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.19412
Policy Entropy: 2.45840
Value Function Loss: 0.02010

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.47612
Value Function Update Magnitude: 0.65166

Collected Steps per Second: 22,515.31688
Overall Steps per Second: 10,586.37637

Timestep Collection Time: 2.22142
Timestep Consumption Time: 2.50314
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.72456

Cumulative Model Updates: 313,198
Cumulative Timesteps: 2,612,023,582

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2612023582...
Checkpoint 2612023582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.52341
Policy Entropy: 2.46015
Value Function Loss: 0.02030

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.11996
Policy Update Magnitude: 0.46204
Value Function Update Magnitude: 0.65801

Collected Steps per Second: 23,325.11571
Overall Steps per Second: 10,926.58842

Timestep Collection Time: 2.14421
Timestep Consumption Time: 2.43306
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.57727

Cumulative Model Updates: 313,204
Cumulative Timesteps: 2,612,073,596

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.91410
Policy Entropy: 2.43929
Value Function Loss: 0.02178

Mean KL Divergence: 0.02297
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.46383
Value Function Update Magnitude: 0.68792

Collected Steps per Second: 22,380.81340
Overall Steps per Second: 10,535.93823

Timestep Collection Time: 2.23459
Timestep Consumption Time: 2.51221
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.74680

Cumulative Model Updates: 313,210
Cumulative Timesteps: 2,612,123,608

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2612123608...
Checkpoint 2612123608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.44840
Policy Entropy: 2.42904
Value Function Loss: 0.02246

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.11372
Policy Update Magnitude: 0.50285
Value Function Update Magnitude: 0.69815

Collected Steps per Second: 22,294.52295
Overall Steps per Second: 10,599.62612

Timestep Collection Time: 2.24279
Timestep Consumption Time: 2.47454
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.71734

Cumulative Model Updates: 313,216
Cumulative Timesteps: 2,612,173,610

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.47142
Policy Entropy: 2.44783
Value Function Loss: 0.02191

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.10288
Policy Update Magnitude: 0.50201
Value Function Update Magnitude: 0.68938

Collected Steps per Second: 22,341.23750
Overall Steps per Second: 10,881.54743

Timestep Collection Time: 2.23846
Timestep Consumption Time: 2.35739
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.59585

Cumulative Model Updates: 313,222
Cumulative Timesteps: 2,612,223,620

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2612223620...
Checkpoint 2612223620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.42629
Policy Entropy: 2.43358
Value Function Loss: 0.02125

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.48661
Value Function Update Magnitude: 0.66605

Collected Steps per Second: 22,433.51722
Overall Steps per Second: 10,673.98252

Timestep Collection Time: 2.22952
Timestep Consumption Time: 2.45627
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.68579

Cumulative Model Updates: 313,228
Cumulative Timesteps: 2,612,273,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.71728
Policy Entropy: 2.42279
Value Function Loss: 0.02132

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.09749
Policy Update Magnitude: 0.48332
Value Function Update Magnitude: 0.65163

Collected Steps per Second: 21,799.89028
Overall Steps per Second: 10,433.64645

Timestep Collection Time: 2.29396
Timestep Consumption Time: 2.49900
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.79296

Cumulative Model Updates: 313,234
Cumulative Timesteps: 2,612,323,644

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2612323644...
Checkpoint 2612323644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.99523
Policy Entropy: 2.40300
Value Function Loss: 0.02175

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.09022
Policy Update Magnitude: 0.49922
Value Function Update Magnitude: 0.66614

Collected Steps per Second: 21,854.84226
Overall Steps per Second: 10,679.30042

Timestep Collection Time: 2.28920
Timestep Consumption Time: 2.39557
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.68476

Cumulative Model Updates: 313,240
Cumulative Timesteps: 2,612,373,674

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.98686
Policy Entropy: 2.42538
Value Function Loss: 0.02210

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.50756
Value Function Update Magnitude: 0.68190

Collected Steps per Second: 21,752.85533
Overall Steps per Second: 10,420.87497

Timestep Collection Time: 2.29938
Timestep Consumption Time: 2.50041
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.79979

Cumulative Model Updates: 313,246
Cumulative Timesteps: 2,612,423,692

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2612423692...
Checkpoint 2612423692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.51322
Policy Entropy: 2.44368
Value Function Loss: 0.02129

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.09463
Policy Update Magnitude: 0.51656
Value Function Update Magnitude: 0.68816

Collected Steps per Second: 22,588.79227
Overall Steps per Second: 10,652.46803

Timestep Collection Time: 2.21464
Timestep Consumption Time: 2.48155
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.69619

Cumulative Model Updates: 313,252
Cumulative Timesteps: 2,612,473,718

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.75827
Policy Entropy: 2.43671
Value Function Loss: 0.02246

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.10218
Policy Update Magnitude: 0.49379
Value Function Update Magnitude: 0.69733

Collected Steps per Second: 22,361.72984
Overall Steps per Second: 10,457.24886

Timestep Collection Time: 2.23695
Timestep Consumption Time: 2.54653
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.78348

Cumulative Model Updates: 313,258
Cumulative Timesteps: 2,612,523,740

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2612523740...
Checkpoint 2612523740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.72341
Policy Entropy: 2.42805
Value Function Loss: 0.02162

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.10124
Policy Update Magnitude: 0.48699
Value Function Update Magnitude: 0.72881

Collected Steps per Second: 21,914.26550
Overall Steps per Second: 10,565.55453

Timestep Collection Time: 2.28290
Timestep Consumption Time: 2.45211
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.73501

Cumulative Model Updates: 313,264
Cumulative Timesteps: 2,612,573,768

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.31055
Policy Entropy: 2.43027
Value Function Loss: 0.02159

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.09387
Policy Update Magnitude: 0.49788
Value Function Update Magnitude: 0.72102

Collected Steps per Second: 22,430.28721
Overall Steps per Second: 10,600.65397

Timestep Collection Time: 2.22922
Timestep Consumption Time: 2.48766
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.71688

Cumulative Model Updates: 313,270
Cumulative Timesteps: 2,612,623,770

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2612623770...
Checkpoint 2612623770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.14489
Policy Entropy: 2.45098
Value Function Loss: 0.02042

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.09255
Policy Update Magnitude: 0.48989
Value Function Update Magnitude: 0.70813

Collected Steps per Second: 23,063.87127
Overall Steps per Second: 10,764.12716

Timestep Collection Time: 2.16911
Timestep Consumption Time: 2.47855
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.64766

Cumulative Model Updates: 313,276
Cumulative Timesteps: 2,612,673,798

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.02797
Policy Entropy: 2.44589
Value Function Loss: 0.01965

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.48717
Value Function Update Magnitude: 0.69611

Collected Steps per Second: 22,481.97335
Overall Steps per Second: 10,744.83114

Timestep Collection Time: 2.22436
Timestep Consumption Time: 2.42978
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.65414

Cumulative Model Updates: 313,282
Cumulative Timesteps: 2,612,723,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2612723806...
Checkpoint 2612723806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.89368
Policy Entropy: 2.43883
Value Function Loss: 0.02009

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.47458
Value Function Update Magnitude: 0.67424

Collected Steps per Second: 22,335.85924
Overall Steps per Second: 10,614.22849

Timestep Collection Time: 2.23900
Timestep Consumption Time: 2.47260
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.71160

Cumulative Model Updates: 313,288
Cumulative Timesteps: 2,612,773,816

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.68224
Policy Entropy: 2.43032
Value Function Loss: 0.02074

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.09558
Policy Update Magnitude: 0.47904
Value Function Update Magnitude: 0.68166

Collected Steps per Second: 22,274.73765
Overall Steps per Second: 10,605.66203

Timestep Collection Time: 2.24505
Timestep Consumption Time: 2.47016
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.71522

Cumulative Model Updates: 313,294
Cumulative Timesteps: 2,612,823,824

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2612823824...
Checkpoint 2612823824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146.59337
Policy Entropy: 2.42521
Value Function Loss: 0.02227

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.10074
Policy Update Magnitude: 0.49240
Value Function Update Magnitude: 0.70887

Collected Steps per Second: 21,773.24343
Overall Steps per Second: 10,626.33375

Timestep Collection Time: 2.29640
Timestep Consumption Time: 2.40890
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.70529

Cumulative Model Updates: 313,300
Cumulative Timesteps: 2,612,873,824

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.69958
Policy Entropy: 2.42515
Value Function Loss: 0.02172

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.08907
Policy Update Magnitude: 0.49470
Value Function Update Magnitude: 0.73850

Collected Steps per Second: 20,999.99152
Overall Steps per Second: 10,353.01282

Timestep Collection Time: 2.38210
Timestep Consumption Time: 2.44973
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.83183

Cumulative Model Updates: 313,306
Cumulative Timesteps: 2,612,923,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2612923848...
Checkpoint 2612923848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.58720
Policy Entropy: 2.43582
Value Function Loss: 0.02080

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.09668
Policy Update Magnitude: 0.48403
Value Function Update Magnitude: 0.71984

Collected Steps per Second: 22,261.37917
Overall Steps per Second: 10,565.91619

Timestep Collection Time: 2.24748
Timestep Consumption Time: 2.48775
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.73523

Cumulative Model Updates: 313,312
Cumulative Timesteps: 2,612,973,880

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.86361
Policy Entropy: 2.45263
Value Function Loss: 0.01978

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.09236
Policy Update Magnitude: 0.48544
Value Function Update Magnitude: 0.68572

Collected Steps per Second: 22,299.18450
Overall Steps per Second: 10,564.89687

Timestep Collection Time: 2.24277
Timestep Consumption Time: 2.49102
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.73379

Cumulative Model Updates: 313,318
Cumulative Timesteps: 2,613,023,892

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2613023892...
Checkpoint 2613023892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.29339
Policy Entropy: 2.44947
Value Function Loss: 0.01993

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.10123
Policy Update Magnitude: 0.48141
Value Function Update Magnitude: 0.66992

Collected Steps per Second: 22,354.74277
Overall Steps per Second: 10,887.18620

Timestep Collection Time: 2.23782
Timestep Consumption Time: 2.35712
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.59494

Cumulative Model Updates: 313,324
Cumulative Timesteps: 2,613,073,918

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.28209
Policy Entropy: 2.42997
Value Function Loss: 0.01979

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.09772
Policy Update Magnitude: 0.47453
Value Function Update Magnitude: 0.66325

Collected Steps per Second: 22,290.03921
Overall Steps per Second: 10,588.65812

Timestep Collection Time: 2.24342
Timestep Consumption Time: 2.47918
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.72260

Cumulative Model Updates: 313,330
Cumulative Timesteps: 2,613,123,924

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2613123924...
Checkpoint 2613123924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.87042
Policy Entropy: 2.43381
Value Function Loss: 0.02072

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.47567
Value Function Update Magnitude: 0.66386

Collected Steps per Second: 22,280.26462
Overall Steps per Second: 10,622.85044

Timestep Collection Time: 2.24548
Timestep Consumption Time: 2.46417
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.70966

Cumulative Model Updates: 313,336
Cumulative Timesteps: 2,613,173,954

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.38354
Policy Entropy: 2.44672
Value Function Loss: 0.02181

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.08034
Policy Update Magnitude: 0.48871
Value Function Update Magnitude: 0.68667

Collected Steps per Second: 22,378.72310
Overall Steps per Second: 10,600.55336

Timestep Collection Time: 2.23427
Timestep Consumption Time: 2.48247
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.71673

Cumulative Model Updates: 313,342
Cumulative Timesteps: 2,613,223,954

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2613223954...
Checkpoint 2613223954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.88128
Policy Entropy: 2.44632
Value Function Loss: 0.02264

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.08097
Policy Update Magnitude: 0.50837
Value Function Update Magnitude: 0.72001

Collected Steps per Second: 22,853.51085
Overall Steps per Second: 10,700.86999

Timestep Collection Time: 2.18942
Timestep Consumption Time: 2.48646
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.67588

Cumulative Model Updates: 313,348
Cumulative Timesteps: 2,613,273,990

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.09107
Policy Entropy: 2.46329
Value Function Loss: 0.02238

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.08993
Policy Update Magnitude: 0.51024
Value Function Update Magnitude: 0.72597

Collected Steps per Second: 21,941.56863
Overall Steps per Second: 10,612.47607

Timestep Collection Time: 2.27905
Timestep Consumption Time: 2.43295
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.71200

Cumulative Model Updates: 313,354
Cumulative Timesteps: 2,613,323,996

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2613323996...
Checkpoint 2613323996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.05901
Policy Entropy: 2.46079
Value Function Loss: 0.02323

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.09081
Policy Update Magnitude: 0.49842
Value Function Update Magnitude: 0.72167

Collected Steps per Second: 21,852.26230
Overall Steps per Second: 10,481.89366

Timestep Collection Time: 2.28919
Timestep Consumption Time: 2.48323
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.77242

Cumulative Model Updates: 313,360
Cumulative Timesteps: 2,613,374,020

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.40613
Policy Entropy: 2.45395
Value Function Loss: 0.02280

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.49914
Value Function Update Magnitude: 0.72072

Collected Steps per Second: 22,377.48048
Overall Steps per Second: 10,732.04902

Timestep Collection Time: 2.23537
Timestep Consumption Time: 2.42562
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.66099

Cumulative Model Updates: 313,366
Cumulative Timesteps: 2,613,424,042

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2613424042...
Checkpoint 2613424042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153.92529
Policy Entropy: 2.39455
Value Function Loss: 0.02371

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.49650
Value Function Update Magnitude: 0.70650

Collected Steps per Second: 22,163.85266
Overall Steps per Second: 10,591.92468

Timestep Collection Time: 2.25719
Timestep Consumption Time: 2.46603
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.72322

Cumulative Model Updates: 313,372
Cumulative Timesteps: 2,613,474,070

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.00797
Policy Entropy: 2.38197
Value Function Loss: 0.02254

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.11686
Policy Update Magnitude: 0.48562
Value Function Update Magnitude: 0.66490

Collected Steps per Second: 22,443.29346
Overall Steps per Second: 10,510.88509

Timestep Collection Time: 2.22837
Timestep Consumption Time: 2.52974
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.75811

Cumulative Model Updates: 313,378
Cumulative Timesteps: 2,613,524,082

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2613524082...
Checkpoint 2613524082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.52415
Policy Entropy: 2.40152
Value Function Loss: 0.02192

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.10041
Policy Update Magnitude: 0.45987
Value Function Update Magnitude: 0.65404

Collected Steps per Second: 22,071.65498
Overall Steps per Second: 10,585.10552

Timestep Collection Time: 2.26580
Timestep Consumption Time: 2.45876
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.72456

Cumulative Model Updates: 313,384
Cumulative Timesteps: 2,613,574,092

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.01299
Policy Entropy: 2.41931
Value Function Loss: 0.02195

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.10483
Policy Update Magnitude: 0.47150
Value Function Update Magnitude: 0.66436

Collected Steps per Second: 22,369.54765
Overall Steps per Second: 10,851.98261

Timestep Collection Time: 2.23590
Timestep Consumption Time: 2.37303
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.60893

Cumulative Model Updates: 313,390
Cumulative Timesteps: 2,613,624,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2613624108...
Checkpoint 2613624108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.80019
Policy Entropy: 2.44650
Value Function Loss: 0.02246

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.10803
Policy Update Magnitude: 0.48906
Value Function Update Magnitude: 0.68012

Collected Steps per Second: 21,526.64126
Overall Steps per Second: 10,344.17765

Timestep Collection Time: 2.32307
Timestep Consumption Time: 2.51134
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.83441

Cumulative Model Updates: 313,396
Cumulative Timesteps: 2,613,674,116

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.63614
Policy Entropy: 2.45387
Value Function Loss: 0.02260

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.10651
Policy Update Magnitude: 0.49836
Value Function Update Magnitude: 0.67087

Collected Steps per Second: 22,258.89895
Overall Steps per Second: 10,548.60243

Timestep Collection Time: 2.24629
Timestep Consumption Time: 2.49367
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.73996

Cumulative Model Updates: 313,402
Cumulative Timesteps: 2,613,724,116

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2613724116...
Checkpoint 2613724116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.49211
Policy Entropy: 2.45552
Value Function Loss: 0.02214

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.10204
Policy Update Magnitude: 0.50226
Value Function Update Magnitude: 0.65120

Collected Steps per Second: 22,355.76550
Overall Steps per Second: 10,602.18575

Timestep Collection Time: 2.23683
Timestep Consumption Time: 2.47975
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.71657

Cumulative Model Updates: 313,408
Cumulative Timesteps: 2,613,774,122

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.18800
Policy Entropy: 2.43978
Value Function Loss: 0.02159

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.09459
Policy Update Magnitude: 0.48715
Value Function Update Magnitude: 0.63928

Collected Steps per Second: 22,718.13797
Overall Steps per Second: 10,756.50361

Timestep Collection Time: 2.20088
Timestep Consumption Time: 2.44747
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.64835

Cumulative Model Updates: 313,414
Cumulative Timesteps: 2,613,824,122

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2613824122...
Checkpoint 2613824122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.21986
Policy Entropy: 2.41885
Value Function Loss: 0.02099

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.48618
Value Function Update Magnitude: 0.63585

Collected Steps per Second: 21,582.45974
Overall Steps per Second: 10,376.83571

Timestep Collection Time: 2.31781
Timestep Consumption Time: 2.50293
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.82074

Cumulative Model Updates: 313,420
Cumulative Timesteps: 2,613,874,146

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.52916
Policy Entropy: 2.43666
Value Function Loss: 0.02100

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.07899
Policy Update Magnitude: 0.48368
Value Function Update Magnitude: 0.63533

Collected Steps per Second: 22,122.20646
Overall Steps per Second: 10,552.07041

Timestep Collection Time: 2.26044
Timestep Consumption Time: 2.47853
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.73898

Cumulative Model Updates: 313,426
Cumulative Timesteps: 2,613,924,152

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2613924152...
Checkpoint 2613924152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.89049
Policy Entropy: 2.44369
Value Function Loss: 0.02189

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.08124
Policy Update Magnitude: 0.48845
Value Function Update Magnitude: 0.64220

Collected Steps per Second: 21,872.05347
Overall Steps per Second: 10,801.46531

Timestep Collection Time: 2.28712
Timestep Consumption Time: 2.34410
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.63122

Cumulative Model Updates: 313,432
Cumulative Timesteps: 2,613,974,176

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.53535
Policy Entropy: 2.42847
Value Function Loss: 0.02212

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.08547
Policy Update Magnitude: 0.49280
Value Function Update Magnitude: 0.66309

Collected Steps per Second: 22,388.76180
Overall Steps per Second: 10,557.16122

Timestep Collection Time: 2.23532
Timestep Consumption Time: 2.50516
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.74048

Cumulative Model Updates: 313,438
Cumulative Timesteps: 2,614,024,222

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2614024222...
Checkpoint 2614024222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.80517
Policy Entropy: 2.41463
Value Function Loss: 0.02156

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.09835
Policy Update Magnitude: 0.48878
Value Function Update Magnitude: 0.66880

Collected Steps per Second: 21,899.89490
Overall Steps per Second: 10,605.15842

Timestep Collection Time: 2.28430
Timestep Consumption Time: 2.43284
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.71714

Cumulative Model Updates: 313,444
Cumulative Timesteps: 2,614,074,248

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.03118
Policy Entropy: 2.39546
Value Function Loss: 0.02001

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.09603
Policy Update Magnitude: 0.47130
Value Function Update Magnitude: 0.65371

Collected Steps per Second: 22,352.75079
Overall Steps per Second: 10,429.50646

Timestep Collection Time: 2.23811
Timestep Consumption Time: 2.55866
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.79678

Cumulative Model Updates: 313,450
Cumulative Timesteps: 2,614,124,276

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2614124276...
Checkpoint 2614124276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.96768
Policy Entropy: 2.43977
Value Function Loss: 0.01971

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.08422
Policy Update Magnitude: 0.47667
Value Function Update Magnitude: 0.61875

Collected Steps per Second: 22,083.31132
Overall Steps per Second: 10,634.86598

Timestep Collection Time: 2.26415
Timestep Consumption Time: 2.43736
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.70152

Cumulative Model Updates: 313,456
Cumulative Timesteps: 2,614,174,276

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.84068
Policy Entropy: 2.41988
Value Function Loss: 0.01972

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.08297
Policy Update Magnitude: 0.48123
Value Function Update Magnitude: 0.62380

Collected Steps per Second: 23,283.44545
Overall Steps per Second: 10,879.86443

Timestep Collection Time: 2.14745
Timestep Consumption Time: 2.44820
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.59565

Cumulative Model Updates: 313,462
Cumulative Timesteps: 2,614,224,276

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2614224276...
Checkpoint 2614224276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.47563
Policy Entropy: 2.42752
Value Function Loss: 0.01932

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.08625
Policy Update Magnitude: 0.48225
Value Function Update Magnitude: 0.63313

Collected Steps per Second: 22,054.61394
Overall Steps per Second: 10,588.58419

Timestep Collection Time: 2.26828
Timestep Consumption Time: 2.45624
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.72452

Cumulative Model Updates: 313,468
Cumulative Timesteps: 2,614,274,302

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.81431
Policy Entropy: 2.38582
Value Function Loss: 0.01974

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.09168
Policy Update Magnitude: 0.48645
Value Function Update Magnitude: 0.63036

Collected Steps per Second: 22,267.12914
Overall Steps per Second: 10,559.09886

Timestep Collection Time: 2.24573
Timestep Consumption Time: 2.49009
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.73582

Cumulative Model Updates: 313,474
Cumulative Timesteps: 2,614,324,308

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2614324308...
Checkpoint 2614324308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.26762
Policy Entropy: 2.39814
Value Function Loss: 0.01971

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.08571
Policy Update Magnitude: 0.49134
Value Function Update Magnitude: 0.63417

Collected Steps per Second: 22,284.77452
Overall Steps per Second: 10,723.35789

Timestep Collection Time: 2.24395
Timestep Consumption Time: 2.41932
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.66328

Cumulative Model Updates: 313,480
Cumulative Timesteps: 2,614,374,314

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.45861
Policy Entropy: 2.39134
Value Function Loss: 0.02118

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.09265
Policy Update Magnitude: 0.49512
Value Function Update Magnitude: 0.65365

Collected Steps per Second: 22,458.19137
Overall Steps per Second: 10,728.15128

Timestep Collection Time: 2.22725
Timestep Consumption Time: 2.43525
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.66250

Cumulative Model Updates: 313,486
Cumulative Timesteps: 2,614,424,334

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2614424334...
Checkpoint 2614424334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.97311
Policy Entropy: 2.39742
Value Function Loss: 0.02116

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.09648
Policy Update Magnitude: 0.50044
Value Function Update Magnitude: 0.66849

Collected Steps per Second: 21,623.86448
Overall Steps per Second: 10,422.06488

Timestep Collection Time: 2.31365
Timestep Consumption Time: 2.48674
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.80039

Cumulative Model Updates: 313,492
Cumulative Timesteps: 2,614,474,364

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.22123
Policy Entropy: 2.40302
Value Function Loss: 0.02251

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.12107
Policy Update Magnitude: 0.47473
Value Function Update Magnitude: 0.64860

Collected Steps per Second: 22,260.95960
Overall Steps per Second: 10,745.62800

Timestep Collection Time: 2.24698
Timestep Consumption Time: 2.40793
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.65492

Cumulative Model Updates: 313,498
Cumulative Timesteps: 2,614,524,384

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2614524384...
Checkpoint 2614524384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172.36075
Policy Entropy: 2.42070
Value Function Loss: 0.02294

Mean KL Divergence: 0.02330
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.47252
Value Function Update Magnitude: 0.65213

Collected Steps per Second: 21,429.91192
Overall Steps per Second: 10,690.75941

Timestep Collection Time: 2.33496
Timestep Consumption Time: 2.34553
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.68049

Cumulative Model Updates: 313,504
Cumulative Timesteps: 2,614,574,422

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.20883
Policy Entropy: 2.42745
Value Function Loss: 0.02263

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.12162
Policy Update Magnitude: 0.51628
Value Function Update Magnitude: 0.68189

Collected Steps per Second: 22,018.59124
Overall Steps per Second: 10,414.95206

Timestep Collection Time: 2.27190
Timestep Consumption Time: 2.53120
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.80309

Cumulative Model Updates: 313,510
Cumulative Timesteps: 2,614,624,446

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2614624446...
Checkpoint 2614624446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.52647
Policy Entropy: 2.40130
Value Function Loss: 0.02352

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.11382
Policy Update Magnitude: 0.51385
Value Function Update Magnitude: 0.71030

Collected Steps per Second: 21,910.06530
Overall Steps per Second: 10,590.67079

Timestep Collection Time: 2.28352
Timestep Consumption Time: 2.44064
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.72416

Cumulative Model Updates: 313,516
Cumulative Timesteps: 2,614,674,478

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.12516
Policy Entropy: 2.42131
Value Function Loss: 0.02236

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.10034
Policy Update Magnitude: 0.50387
Value Function Update Magnitude: 0.70846

Collected Steps per Second: 22,640.25877
Overall Steps per Second: 10,497.11493

Timestep Collection Time: 2.20863
Timestep Consumption Time: 2.55496
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.76359

Cumulative Model Updates: 313,522
Cumulative Timesteps: 2,614,724,482

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2614724482...
Checkpoint 2614724482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.24581
Policy Entropy: 2.39900
Value Function Loss: 0.02316

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.51106
Value Function Update Magnitude: 0.68927

Collected Steps per Second: 22,145.81202
Overall Steps per Second: 10,652.40791

Timestep Collection Time: 2.25840
Timestep Consumption Time: 2.43669
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.69509

Cumulative Model Updates: 313,528
Cumulative Timesteps: 2,614,774,496

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.40408
Policy Entropy: 2.43741
Value Function Loss: 0.02264

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.08982
Policy Update Magnitude: 0.50951
Value Function Update Magnitude: 0.68388

Collected Steps per Second: 21,620.19982
Overall Steps per Second: 10,379.75869

Timestep Collection Time: 2.31302
Timestep Consumption Time: 2.50482
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.81784

Cumulative Model Updates: 313,534
Cumulative Timesteps: 2,614,824,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2614824504...
Checkpoint 2614824504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.61695
Policy Entropy: 2.39885
Value Function Loss: 0.02270

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.09524
Policy Update Magnitude: 0.50106
Value Function Update Magnitude: 0.70527

Collected Steps per Second: 22,193.27169
Overall Steps per Second: 10,634.16400

Timestep Collection Time: 2.25312
Timestep Consumption Time: 2.44909
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.70220

Cumulative Model Updates: 313,540
Cumulative Timesteps: 2,614,874,508

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.65335
Policy Entropy: 2.41664
Value Function Loss: 0.02169

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.09311
Policy Update Magnitude: 0.48990
Value Function Update Magnitude: 0.69137

Collected Steps per Second: 22,232.06305
Overall Steps per Second: 10,560.46455

Timestep Collection Time: 2.25026
Timestep Consumption Time: 2.48703
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.73729

Cumulative Model Updates: 313,546
Cumulative Timesteps: 2,614,924,536

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2614924536...
Checkpoint 2614924536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.56477
Policy Entropy: 2.38820
Value Function Loss: 0.02197

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.09245
Policy Update Magnitude: 0.49842
Value Function Update Magnitude: 0.67081

Collected Steps per Second: 22,183.42883
Overall Steps per Second: 10,702.99612

Timestep Collection Time: 2.25393
Timestep Consumption Time: 2.41765
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.67159

Cumulative Model Updates: 313,552
Cumulative Timesteps: 2,614,974,536

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.51947
Policy Entropy: 2.41756
Value Function Loss: 0.02029

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.08487
Policy Update Magnitude: 0.48930
Value Function Update Magnitude: 0.67059

Collected Steps per Second: 22,719.29238
Overall Steps per Second: 10,773.92632

Timestep Collection Time: 2.20086
Timestep Consumption Time: 2.44016
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.64102

Cumulative Model Updates: 313,558
Cumulative Timesteps: 2,615,024,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2615024538...
Checkpoint 2615024538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.16943
Policy Entropy: 2.41285
Value Function Loss: 0.01995

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.09059
Policy Update Magnitude: 0.48401
Value Function Update Magnitude: 0.64918

Collected Steps per Second: 21,926.83666
Overall Steps per Second: 10,604.20162

Timestep Collection Time: 2.28113
Timestep Consumption Time: 2.43568
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.71681

Cumulative Model Updates: 313,564
Cumulative Timesteps: 2,615,074,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.42850
Policy Entropy: 2.40700
Value Function Loss: 0.01965

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.08633
Policy Update Magnitude: 0.49121
Value Function Update Magnitude: 0.64681

Collected Steps per Second: 21,753.60162
Overall Steps per Second: 10,540.10293

Timestep Collection Time: 2.29902
Timestep Consumption Time: 2.44590
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.74493

Cumulative Model Updates: 313,570
Cumulative Timesteps: 2,615,124,568

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2615124568...
Checkpoint 2615124568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.27775
Policy Entropy: 2.40103
Value Function Loss: 0.01998

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.09302
Policy Update Magnitude: 0.48130
Value Function Update Magnitude: 0.66780

Collected Steps per Second: 22,494.54028
Overall Steps per Second: 10,666.62777

Timestep Collection Time: 2.22374
Timestep Consumption Time: 2.46584
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.68958

Cumulative Model Updates: 313,576
Cumulative Timesteps: 2,615,174,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.59091
Policy Entropy: 2.41218
Value Function Loss: 0.02027

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.10182
Policy Update Magnitude: 0.48134
Value Function Update Magnitude: 0.67768

Collected Steps per Second: 22,242.88915
Overall Steps per Second: 10,520.02098

Timestep Collection Time: 2.24836
Timestep Consumption Time: 2.50543
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.75379

Cumulative Model Updates: 313,582
Cumulative Timesteps: 2,615,224,600

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2615224600...
Checkpoint 2615224600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.94348
Policy Entropy: 2.39357
Value Function Loss: 0.02177

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.09624
Policy Update Magnitude: 0.49351
Value Function Update Magnitude: 0.66822

Collected Steps per Second: 21,989.93866
Overall Steps per Second: 10,539.34467

Timestep Collection Time: 2.27477
Timestep Consumption Time: 2.47145
PPO Batch Consumption Time: 0.28447
Total Iteration Time: 4.74622

Cumulative Model Updates: 313,588
Cumulative Timesteps: 2,615,274,622

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.52308
Policy Entropy: 2.38438
Value Function Loss: 0.02259

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.09456
Policy Update Magnitude: 0.50475
Value Function Update Magnitude: 0.66221

Collected Steps per Second: 21,899.60673
Overall Steps per Second: 10,506.94993

Timestep Collection Time: 2.28342
Timestep Consumption Time: 2.47591
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.75933

Cumulative Model Updates: 313,594
Cumulative Timesteps: 2,615,324,628

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2615324628...
Checkpoint 2615324628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.45184
Policy Entropy: 2.37942
Value Function Loss: 0.02351

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.09103
Policy Update Magnitude: 0.51040
Value Function Update Magnitude: 0.67573

Collected Steps per Second: 22,193.09967
Overall Steps per Second: 10,633.43238

Timestep Collection Time: 2.25331
Timestep Consumption Time: 2.44959
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.70290

Cumulative Model Updates: 313,600
Cumulative Timesteps: 2,615,374,636

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.10180
Policy Entropy: 2.39382
Value Function Loss: 0.02217

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.50714
Value Function Update Magnitude: 0.67697

Collected Steps per Second: 22,474.69328
Overall Steps per Second: 10,567.37677

Timestep Collection Time: 2.22526
Timestep Consumption Time: 2.50742
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.73268

Cumulative Model Updates: 313,606
Cumulative Timesteps: 2,615,424,648

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2615424648...
Checkpoint 2615424648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.88318
Policy Entropy: 2.38172
Value Function Loss: 0.02225

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.09311
Policy Update Magnitude: 0.50048
Value Function Update Magnitude: 0.68527

Collected Steps per Second: 21,781.04830
Overall Steps per Second: 10,493.73105

Timestep Collection Time: 2.29668
Timestep Consumption Time: 2.47036
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.76704

Cumulative Model Updates: 313,612
Cumulative Timesteps: 2,615,474,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.94766
Policy Entropy: 2.37816
Value Function Loss: 0.02242

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.09158
Policy Update Magnitude: 0.49276
Value Function Update Magnitude: 0.69032

Collected Steps per Second: 22,501.55414
Overall Steps per Second: 10,906.07181

Timestep Collection Time: 2.22278
Timestep Consumption Time: 2.36329
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.58607

Cumulative Model Updates: 313,618
Cumulative Timesteps: 2,615,524,688

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2615524688...
Checkpoint 2615524688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.28033
Policy Entropy: 2.37624
Value Function Loss: 0.02206

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.08741
Policy Update Magnitude: 0.50058
Value Function Update Magnitude: 0.68923

Collected Steps per Second: 22,036.38232
Overall Steps per Second: 10,622.60284

Timestep Collection Time: 2.27025
Timestep Consumption Time: 2.43933
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.70958

Cumulative Model Updates: 313,624
Cumulative Timesteps: 2,615,574,716

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.16612
Policy Entropy: 2.39449
Value Function Loss: 0.02163

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.09132
Policy Update Magnitude: 0.50240
Value Function Update Magnitude: 0.68293

Collected Steps per Second: 22,489.76035
Overall Steps per Second: 10,555.35050

Timestep Collection Time: 2.22412
Timestep Consumption Time: 2.51471
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.73883

Cumulative Model Updates: 313,630
Cumulative Timesteps: 2,615,624,736

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2615624736...
Checkpoint 2615624736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.68275
Policy Entropy: 2.42281
Value Function Loss: 0.02044

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.08699
Policy Update Magnitude: 0.49925
Value Function Update Magnitude: 0.67262

Collected Steps per Second: 21,950.38668
Overall Steps per Second: 10,523.16704

Timestep Collection Time: 2.27786
Timestep Consumption Time: 2.47356
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.75142

Cumulative Model Updates: 313,636
Cumulative Timesteps: 2,615,674,736

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.76863
Policy Entropy: 2.43248
Value Function Loss: 0.02209

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.08701
Policy Update Magnitude: 0.50628
Value Function Update Magnitude: 0.65516

Collected Steps per Second: 22,055.73281
Overall Steps per Second: 10,645.18825

Timestep Collection Time: 2.26698
Timestep Consumption Time: 2.42997
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.69696

Cumulative Model Updates: 313,642
Cumulative Timesteps: 2,615,724,736

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2615724736...
Checkpoint 2615724736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.20710
Policy Entropy: 2.43978
Value Function Loss: 0.02216

Mean KL Divergence: 0.02256
SB3 Clip Fraction: 0.11704
Policy Update Magnitude: 0.48540
Value Function Update Magnitude: 0.64305

Collected Steps per Second: 21,636.07892
Overall Steps per Second: 10,493.86734

Timestep Collection Time: 2.31197
Timestep Consumption Time: 2.45481
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.76678

Cumulative Model Updates: 313,648
Cumulative Timesteps: 2,615,774,758

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.47571
Policy Entropy: 2.41057
Value Function Loss: 0.02366

Mean KL Divergence: 0.02397
SB3 Clip Fraction: 0.12180
Policy Update Magnitude: 0.47663
Value Function Update Magnitude: 0.64408

Collected Steps per Second: 22,052.67094
Overall Steps per Second: 10,441.86671

Timestep Collection Time: 2.26793
Timestep Consumption Time: 2.52182
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.78976

Cumulative Model Updates: 313,654
Cumulative Timesteps: 2,615,824,772

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2615824772...
Checkpoint 2615824772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.33462
Policy Entropy: 2.40535
Value Function Loss: 0.02346

Mean KL Divergence: 0.02563
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.48653
Value Function Update Magnitude: 0.65631

Collected Steps per Second: 21,708.74374
Overall Steps per Second: 10,576.21423

Timestep Collection Time: 2.30414
Timestep Consumption Time: 2.42534
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.72948

Cumulative Model Updates: 313,660
Cumulative Timesteps: 2,615,874,792

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.69954
Policy Entropy: 2.38764
Value Function Loss: 0.02425

Mean KL Divergence: 0.02299
SB3 Clip Fraction: 0.11929
Policy Update Magnitude: 0.49194
Value Function Update Magnitude: 0.67850

Collected Steps per Second: 21,985.37524
Overall Steps per Second: 10,639.54270

Timestep Collection Time: 2.27424
Timestep Consumption Time: 2.42521
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.69945

Cumulative Model Updates: 313,666
Cumulative Timesteps: 2,615,924,792

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2615924792...
Checkpoint 2615924792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.98660
Policy Entropy: 2.39567
Value Function Loss: 0.02378

Mean KL Divergence: 0.02297
SB3 Clip Fraction: 0.12360
Policy Update Magnitude: 0.48264
Value Function Update Magnitude: 0.68820

Collected Steps per Second: 22,276.61678
Overall Steps per Second: 10,525.45265

Timestep Collection Time: 2.24495
Timestep Consumption Time: 2.50638
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.75134

Cumulative Model Updates: 313,672
Cumulative Timesteps: 2,615,974,802

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.74637
Policy Entropy: 2.40377
Value Function Loss: 0.02231

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.11389
Policy Update Magnitude: 0.49182
Value Function Update Magnitude: 0.68987

Collected Steps per Second: 22,641.05032
Overall Steps per Second: 10,633.61209

Timestep Collection Time: 2.20935
Timestep Consumption Time: 2.49479
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.70414

Cumulative Model Updates: 313,678
Cumulative Timesteps: 2,616,024,824

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2616024824...
Checkpoint 2616024824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.92019
Policy Entropy: 2.40779
Value Function Loss: 0.02121

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.10391
Policy Update Magnitude: 0.49828
Value Function Update Magnitude: 0.66052

Collected Steps per Second: 22,512.29227
Overall Steps per Second: 10,649.90447

Timestep Collection Time: 2.22270
Timestep Consumption Time: 2.47575
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.69845

Cumulative Model Updates: 313,684
Cumulative Timesteps: 2,616,074,862

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.99368
Policy Entropy: 2.41037
Value Function Loss: 0.02007

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.09919
Policy Update Magnitude: 0.49880
Value Function Update Magnitude: 0.65084

Collected Steps per Second: 22,522.82180
Overall Steps per Second: 10,724.11957

Timestep Collection Time: 2.22006
Timestep Consumption Time: 2.44251
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.66257

Cumulative Model Updates: 313,690
Cumulative Timesteps: 2,616,124,864

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2616124864...
Checkpoint 2616124864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.84897
Policy Entropy: 2.41195
Value Function Loss: 0.02073

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.09161
Policy Update Magnitude: 0.49532
Value Function Update Magnitude: 0.64790

Collected Steps per Second: 22,397.19273
Overall Steps per Second: 10,624.49324

Timestep Collection Time: 2.23340
Timestep Consumption Time: 2.47477
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.70818

Cumulative Model Updates: 313,696
Cumulative Timesteps: 2,616,174,886

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.15842
Policy Entropy: 2.42318
Value Function Loss: 0.02025

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.49528
Value Function Update Magnitude: 0.64245

Collected Steps per Second: 22,457.80786
Overall Steps per Second: 10,556.66925

Timestep Collection Time: 2.22675
Timestep Consumption Time: 2.51035
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.73710

Cumulative Model Updates: 313,702
Cumulative Timesteps: 2,616,224,894

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2616224894...
Checkpoint 2616224894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.78147
Policy Entropy: 2.41811
Value Function Loss: 0.02068

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.48991
Value Function Update Magnitude: 0.64835

Collected Steps per Second: 22,219.10231
Overall Steps per Second: 10,560.97623

Timestep Collection Time: 2.25149
Timestep Consumption Time: 2.48539
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.73687

Cumulative Model Updates: 313,708
Cumulative Timesteps: 2,616,274,920

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.84470
Policy Entropy: 2.44755
Value Function Loss: 0.02058

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.09017
Policy Update Magnitude: 0.49025
Value Function Update Magnitude: 0.65144

Collected Steps per Second: 22,737.13788
Overall Steps per Second: 10,809.31802

Timestep Collection Time: 2.19966
Timestep Consumption Time: 2.42727
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.62693

Cumulative Model Updates: 313,714
Cumulative Timesteps: 2,616,324,934

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2616324934...
Checkpoint 2616324934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.12733
Policy Entropy: 2.46500
Value Function Loss: 0.02064

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.49649
Value Function Update Magnitude: 0.65402

Collected Steps per Second: 21,621.30655
Overall Steps per Second: 10,394.91012

Timestep Collection Time: 2.31263
Timestep Consumption Time: 2.49761
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.81024

Cumulative Model Updates: 313,720
Cumulative Timesteps: 2,616,374,936

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.28111
Policy Entropy: 2.44396
Value Function Loss: 0.02089

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.07424
Policy Update Magnitude: 0.49045
Value Function Update Magnitude: 0.64744

Collected Steps per Second: 21,928.86788
Overall Steps per Second: 10,448.70215

Timestep Collection Time: 2.28083
Timestep Consumption Time: 2.50599
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.78681

Cumulative Model Updates: 313,726
Cumulative Timesteps: 2,616,424,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2616424952...
Checkpoint 2616424952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.48025
Policy Entropy: 2.43264
Value Function Loss: 0.02048

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.48636
Value Function Update Magnitude: 0.63381

Collected Steps per Second: 22,014.18136
Overall Steps per Second: 10,638.23993

Timestep Collection Time: 2.27126
Timestep Consumption Time: 2.42876
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.70003

Cumulative Model Updates: 313,732
Cumulative Timesteps: 2,616,474,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.90089
Policy Entropy: 2.40947
Value Function Loss: 0.02189

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.08816
Policy Update Magnitude: 0.48932
Value Function Update Magnitude: 0.64377

Collected Steps per Second: 22,556.73376
Overall Steps per Second: 10,699.59964

Timestep Collection Time: 2.21761
Timestep Consumption Time: 2.45752
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.67513

Cumulative Model Updates: 313,738
Cumulative Timesteps: 2,616,524,974

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2616524974...
Checkpoint 2616524974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.93482
Policy Entropy: 2.42843
Value Function Loss: 0.02080

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.08163
Policy Update Magnitude: 0.49459
Value Function Update Magnitude: 0.65553

Collected Steps per Second: 22,283.83074
Overall Steps per Second: 10,664.45470

Timestep Collection Time: 2.24504
Timestep Consumption Time: 2.44606
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.69110

Cumulative Model Updates: 313,744
Cumulative Timesteps: 2,616,575,002

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.26602
Policy Entropy: 2.41402
Value Function Loss: 0.02138

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.08529
Policy Update Magnitude: 0.50566
Value Function Update Magnitude: 0.64827

Collected Steps per Second: 22,259.48307
Overall Steps per Second: 10,495.12902

Timestep Collection Time: 2.24686
Timestep Consumption Time: 2.51859
PPO Batch Consumption Time: 0.29933
Total Iteration Time: 4.76545

Cumulative Model Updates: 313,750
Cumulative Timesteps: 2,616,625,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2616625016...
Checkpoint 2616625016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.11103
Policy Entropy: 2.43507
Value Function Loss: 0.02012

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.08420
Policy Update Magnitude: 0.49030
Value Function Update Magnitude: 0.63034

Collected Steps per Second: 22,029.40994
Overall Steps per Second: 10,631.17301

Timestep Collection Time: 2.26978
Timestep Consumption Time: 2.43355
PPO Batch Consumption Time: 0.29508
Total Iteration Time: 4.70334

Cumulative Model Updates: 313,756
Cumulative Timesteps: 2,616,675,018

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.67802
Policy Entropy: 2.43856
Value Function Loss: 0.01971

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.08670
Policy Update Magnitude: 0.48189
Value Function Update Magnitude: 0.63670

Collected Steps per Second: 21,473.40148
Overall Steps per Second: 10,502.90530

Timestep Collection Time: 2.33032
Timestep Consumption Time: 2.43407
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.76440

Cumulative Model Updates: 313,762
Cumulative Timesteps: 2,616,725,058

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2616725058...
Checkpoint 2616725058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.16861
Policy Entropy: 2.44955
Value Function Loss: 0.01917

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.08834
Policy Update Magnitude: 0.48135
Value Function Update Magnitude: 0.63480

Collected Steps per Second: 22,153.40076
Overall Steps per Second: 10,600.57711

Timestep Collection Time: 2.25708
Timestep Consumption Time: 2.45983
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.71691

Cumulative Model Updates: 313,768
Cumulative Timesteps: 2,616,775,060

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.62168
Policy Entropy: 2.42796
Value Function Loss: 0.02099

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.09082
Policy Update Magnitude: 0.48245
Value Function Update Magnitude: 0.64599

Collected Steps per Second: 21,881.40255
Overall Steps per Second: 10,446.97677

Timestep Collection Time: 2.28605
Timestep Consumption Time: 2.50213
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.78818

Cumulative Model Updates: 313,774
Cumulative Timesteps: 2,616,825,082

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2616825082...
Checkpoint 2616825082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.86432
Policy Entropy: 2.41568
Value Function Loss: 0.02242

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.09316
Policy Update Magnitude: 0.49423
Value Function Update Magnitude: 0.66437

Collected Steps per Second: 21,646.30127
Overall Steps per Second: 10,585.25412

Timestep Collection Time: 2.31060
Timestep Consumption Time: 2.41446
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.72506

Cumulative Model Updates: 313,780
Cumulative Timesteps: 2,616,875,098

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.00275
Policy Entropy: 2.40157
Value Function Loss: 0.02216

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.08962
Policy Update Magnitude: 0.49725
Value Function Update Magnitude: 0.67190

Collected Steps per Second: 22,031.32383
Overall Steps per Second: 10,618.99115

Timestep Collection Time: 2.26968
Timestep Consumption Time: 2.43924
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.70892

Cumulative Model Updates: 313,786
Cumulative Timesteps: 2,616,925,102

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2616925102...
Checkpoint 2616925102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269.15400
Policy Entropy: 2.42719
Value Function Loss: 0.02104

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.08275
Policy Update Magnitude: 0.48846
Value Function Update Magnitude: 0.65719

Collected Steps per Second: 21,800.33385
Overall Steps per Second: 10,580.56074

Timestep Collection Time: 2.29474
Timestep Consumption Time: 2.43337
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.72810

Cumulative Model Updates: 313,792
Cumulative Timesteps: 2,616,975,128

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.04637
Policy Entropy: 2.44910
Value Function Loss: 0.02017

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.07893
Policy Update Magnitude: 0.48398
Value Function Update Magnitude: 0.65456

Collected Steps per Second: 22,019.21095
Overall Steps per Second: 10,520.44441

Timestep Collection Time: 2.27165
Timestep Consumption Time: 2.48290
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.75455

Cumulative Model Updates: 313,798
Cumulative Timesteps: 2,617,025,148

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2617025148...
Checkpoint 2617025148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.22582
Policy Entropy: 2.46381
Value Function Loss: 0.01951

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.08070
Policy Update Magnitude: 0.47431
Value Function Update Magnitude: 0.65498

Collected Steps per Second: 22,063.89689
Overall Steps per Second: 10,583.76120

Timestep Collection Time: 2.26660
Timestep Consumption Time: 2.45856
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.72516

Cumulative Model Updates: 313,804
Cumulative Timesteps: 2,617,075,158

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.83357
Policy Entropy: 2.45162
Value Function Loss: 0.01980

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.08508
Policy Update Magnitude: 0.47281
Value Function Update Magnitude: 0.66351

Collected Steps per Second: 22,509.69610
Overall Steps per Second: 10,868.02788

Timestep Collection Time: 2.22198
Timestep Consumption Time: 2.38015
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.60212

Cumulative Model Updates: 313,810
Cumulative Timesteps: 2,617,125,174

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2617125174...
Checkpoint 2617125174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.90104
Policy Entropy: 2.43616
Value Function Loss: 0.02016

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.08983
Policy Update Magnitude: 0.48090
Value Function Update Magnitude: 0.67057

Collected Steps per Second: 22,428.54700
Overall Steps per Second: 10,737.61984

Timestep Collection Time: 2.23055
Timestep Consumption Time: 2.42858
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.65913

Cumulative Model Updates: 313,816
Cumulative Timesteps: 2,617,175,202

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.44904
Policy Entropy: 2.41252
Value Function Loss: 0.02146

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.09232
Policy Update Magnitude: 0.48505
Value Function Update Magnitude: 0.66638

Collected Steps per Second: 22,473.85122
Overall Steps per Second: 10,754.91590

Timestep Collection Time: 2.22623
Timestep Consumption Time: 2.42578
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.65201

Cumulative Model Updates: 313,822
Cumulative Timesteps: 2,617,225,234

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2617225234...
Checkpoint 2617225234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.07955
Policy Entropy: 2.41071
Value Function Loss: 0.02195

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.47472
Value Function Update Magnitude: 0.67623

Collected Steps per Second: 22,191.74087
Overall Steps per Second: 10,766.64930

Timestep Collection Time: 2.25318
Timestep Consumption Time: 2.39098
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.64416

Cumulative Model Updates: 313,828
Cumulative Timesteps: 2,617,275,236

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.50735
Policy Entropy: 2.40331
Value Function Loss: 0.02299

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.09915
Policy Update Magnitude: 0.48216
Value Function Update Magnitude: 0.67378

Collected Steps per Second: 22,587.63670
Overall Steps per Second: 10,651.54695

Timestep Collection Time: 2.21475
Timestep Consumption Time: 2.48184
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.69659

Cumulative Model Updates: 313,834
Cumulative Timesteps: 2,617,325,262

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2617325262...
Checkpoint 2617325262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.55160
Policy Entropy: 2.42203
Value Function Loss: 0.02322

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.08733
Policy Update Magnitude: 0.50056
Value Function Update Magnitude: 0.67420

Collected Steps per Second: 22,101.69005
Overall Steps per Second: 10,499.26914

Timestep Collection Time: 2.26263
Timestep Consumption Time: 2.50037
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.76300

Cumulative Model Updates: 313,840
Cumulative Timesteps: 2,617,375,270

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.68980
Policy Entropy: 2.40234
Value Function Loss: 0.02273

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.08319
Policy Update Magnitude: 0.50596
Value Function Update Magnitude: 0.68599

Collected Steps per Second: 22,031.97138
Overall Steps per Second: 10,523.62637

Timestep Collection Time: 2.26997
Timestep Consumption Time: 2.48238
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.75235

Cumulative Model Updates: 313,846
Cumulative Timesteps: 2,617,425,282

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2617425282...
Checkpoint 2617425282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.64896
Policy Entropy: 2.39687
Value Function Loss: 0.02220

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.10859
Policy Update Magnitude: 0.49417
Value Function Update Magnitude: 0.67652

Collected Steps per Second: 21,668.97379
Overall Steps per Second: 10,544.89307

Timestep Collection Time: 2.30763
Timestep Consumption Time: 2.43438
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.74201

Cumulative Model Updates: 313,852
Cumulative Timesteps: 2,617,475,286

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.35224
Policy Entropy: 2.40476
Value Function Loss: 0.02120

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.11845
Policy Update Magnitude: 0.45485
Value Function Update Magnitude: 0.65493

Collected Steps per Second: 22,016.76838
Overall Steps per Second: 10,433.36167

Timestep Collection Time: 2.27163
Timestep Consumption Time: 2.52203
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.79366

Cumulative Model Updates: 313,858
Cumulative Timesteps: 2,617,525,300

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2617525300...
Checkpoint 2617525300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.85461
Policy Entropy: 2.42141
Value Function Loss: 0.02123

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.10654
Policy Update Magnitude: 0.48867
Value Function Update Magnitude: 0.65260

Collected Steps per Second: 22,188.40363
Overall Steps per Second: 10,589.52895

Timestep Collection Time: 2.25379
Timestep Consumption Time: 2.46861
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.72240

Cumulative Model Updates: 313,864
Cumulative Timesteps: 2,617,575,308

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.69530
Policy Entropy: 2.41428
Value Function Loss: 0.02111

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.10386
Policy Update Magnitude: 0.50252
Value Function Update Magnitude: 0.67586

Collected Steps per Second: 22,224.90317
Overall Steps per Second: 10,532.45214

Timestep Collection Time: 2.25045
Timestep Consumption Time: 2.49830
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.74875

Cumulative Model Updates: 313,870
Cumulative Timesteps: 2,617,625,324

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2617625324...
Checkpoint 2617625324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.60342
Policy Entropy: 2.39227
Value Function Loss: 0.02065

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.49616
Value Function Update Magnitude: 0.67588

Collected Steps per Second: 22,205.69298
Overall Steps per Second: 10,673.43601

Timestep Collection Time: 2.25204
Timestep Consumption Time: 2.43324
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.68528

Cumulative Model Updates: 313,876
Cumulative Timesteps: 2,617,675,332

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.12184
Policy Entropy: 2.39649
Value Function Loss: 0.02025

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.48719
Value Function Update Magnitude: 0.66188

Collected Steps per Second: 22,640.17945
Overall Steps per Second: 10,759.46631

Timestep Collection Time: 2.20970
Timestep Consumption Time: 2.43997
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.64967

Cumulative Model Updates: 313,882
Cumulative Timesteps: 2,617,725,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2617725360...
Checkpoint 2617725360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.06660
Policy Entropy: 2.42934
Value Function Loss: 0.02133

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.48965
Value Function Update Magnitude: 0.63390

Collected Steps per Second: 22,104.67176
Overall Steps per Second: 10,644.10246

Timestep Collection Time: 2.26314
Timestep Consumption Time: 2.43674
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.69988

Cumulative Model Updates: 313,888
Cumulative Timesteps: 2,617,775,386

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.07484
Policy Entropy: 2.43862
Value Function Loss: 0.02241

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.09428
Policy Update Magnitude: 0.49266
Value Function Update Magnitude: 0.63159

Collected Steps per Second: 22,376.06700
Overall Steps per Second: 10,581.51108

Timestep Collection Time: 2.23507
Timestep Consumption Time: 2.49129
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.72636

Cumulative Model Updates: 313,894
Cumulative Timesteps: 2,617,825,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2617825398...
Checkpoint 2617825398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.64639
Policy Entropy: 2.43884
Value Function Loss: 0.02353

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.09388
Policy Update Magnitude: 0.51092
Value Function Update Magnitude: 0.66328

Collected Steps per Second: 22,330.58364
Overall Steps per Second: 10,737.82686

Timestep Collection Time: 2.23944
Timestep Consumption Time: 2.41774
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.65718

Cumulative Model Updates: 313,900
Cumulative Timesteps: 2,617,875,406

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.56693
Policy Entropy: 2.43772
Value Function Loss: 0.02208

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.10453
Policy Update Magnitude: 0.51614
Value Function Update Magnitude: 0.68610

Collected Steps per Second: 21,923.26262
Overall Steps per Second: 10,475.18424

Timestep Collection Time: 2.28123
Timestep Consumption Time: 2.49310
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.77433

Cumulative Model Updates: 313,906
Cumulative Timesteps: 2,617,925,418

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2617925418...
Checkpoint 2617925418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.80750
Policy Entropy: 2.43109
Value Function Loss: 0.02229

Mean KL Divergence: 0.02695
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.48458
Value Function Update Magnitude: 0.67349

Collected Steps per Second: 22,058.48653
Overall Steps per Second: 10,480.50076

Timestep Collection Time: 2.26697
Timestep Consumption Time: 2.50436
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.77134

Cumulative Model Updates: 313,912
Cumulative Timesteps: 2,617,975,424

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.07851
Policy Entropy: 2.43554
Value Function Loss: 0.02078

Mean KL Divergence: 0.02424
SB3 Clip Fraction: 0.13566
Policy Update Magnitude: 0.48565
Value Function Update Magnitude: 0.65973

Collected Steps per Second: 21,708.21855
Overall Steps per Second: 10,438.85353

Timestep Collection Time: 2.30466
Timestep Consumption Time: 2.48801
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.79267

Cumulative Model Updates: 313,918
Cumulative Timesteps: 2,618,025,454

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2618025454...
Checkpoint 2618025454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.03277
Policy Entropy: 2.42889
Value Function Loss: 0.02204

Mean KL Divergence: 0.02410
SB3 Clip Fraction: 0.14043
Policy Update Magnitude: 0.48014
Value Function Update Magnitude: 0.64489

Collected Steps per Second: 21,874.43678
Overall Steps per Second: 10,641.91606

Timestep Collection Time: 2.28596
Timestep Consumption Time: 2.41282
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.69878

Cumulative Model Updates: 313,924
Cumulative Timesteps: 2,618,075,458

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.78289
Policy Entropy: 2.44171
Value Function Loss: 0.02129

Mean KL Divergence: 0.02169
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.48274
Value Function Update Magnitude: 0.64284

Collected Steps per Second: 21,913.92542
Overall Steps per Second: 10,450.07176

Timestep Collection Time: 2.28193
Timestep Consumption Time: 2.50330
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.78523

Cumulative Model Updates: 313,930
Cumulative Timesteps: 2,618,125,464

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2618125464...
Checkpoint 2618125464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.76811
Policy Entropy: 2.44053
Value Function Loss: 0.02162

Mean KL Divergence: 0.02273
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.47340
Value Function Update Magnitude: 0.64918

Collected Steps per Second: 21,858.69172
Overall Steps per Second: 10,556.78624

Timestep Collection Time: 2.28760
Timestep Consumption Time: 2.44907
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.73667

Cumulative Model Updates: 313,936
Cumulative Timesteps: 2,618,175,468

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.73298
Policy Entropy: 2.44062
Value Function Loss: 0.02131

Mean KL Divergence: 0.02398
SB3 Clip Fraction: 0.14019
Policy Update Magnitude: 0.47139
Value Function Update Magnitude: 0.65887

Collected Steps per Second: 22,200.88457
Overall Steps per Second: 10,513.13307

Timestep Collection Time: 2.25225
Timestep Consumption Time: 2.50389
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.75615

Cumulative Model Updates: 313,942
Cumulative Timesteps: 2,618,225,470

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2618225470...
Checkpoint 2618225470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.50498
Policy Entropy: 2.44177
Value Function Loss: 0.02114

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.10925
Policy Update Magnitude: 0.48130
Value Function Update Magnitude: 0.64169

Collected Steps per Second: 22,080.39125
Overall Steps per Second: 10,657.04279

Timestep Collection Time: 2.26581
Timestep Consumption Time: 2.42874
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.69455

Cumulative Model Updates: 313,948
Cumulative Timesteps: 2,618,275,500

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.92751
Policy Entropy: 2.44121
Value Function Loss: 0.02078

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.09484
Policy Update Magnitude: 0.49168
Value Function Update Magnitude: 0.65136

Collected Steps per Second: 22,509.64743
Overall Steps per Second: 10,612.49059

Timestep Collection Time: 2.22145
Timestep Consumption Time: 2.49036
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.71181

Cumulative Model Updates: 313,954
Cumulative Timesteps: 2,618,325,504

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2618325504...
Checkpoint 2618325504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.28004
Policy Entropy: 2.46717
Value Function Loss: 0.01966

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.08572
Policy Update Magnitude: 0.48652
Value Function Update Magnitude: 0.64629

Collected Steps per Second: 22,407.14492
Overall Steps per Second: 10,553.65333

Timestep Collection Time: 2.23268
Timestep Consumption Time: 2.50767
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.74035

Cumulative Model Updates: 313,960
Cumulative Timesteps: 2,618,375,532

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.65825
Policy Entropy: 2.45693
Value Function Loss: 0.01947

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.07936
Policy Update Magnitude: 0.48158
Value Function Update Magnitude: 0.63051

Collected Steps per Second: 22,402.69660
Overall Steps per Second: 10,576.31619

Timestep Collection Time: 2.23250
Timestep Consumption Time: 2.49637
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.72887

Cumulative Model Updates: 313,966
Cumulative Timesteps: 2,618,425,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2618425546...
Checkpoint 2618425546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.68125
Policy Entropy: 2.45115
Value Function Loss: 0.02001

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.08527
Policy Update Magnitude: 0.48123
Value Function Update Magnitude: 0.63435

Collected Steps per Second: 22,682.98397
Overall Steps per Second: 10,908.08250

Timestep Collection Time: 2.20562
Timestep Consumption Time: 2.38089
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.58651

Cumulative Model Updates: 313,972
Cumulative Timesteps: 2,618,475,576

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.45964
Policy Entropy: 2.42541
Value Function Loss: 0.02068

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.08289
Policy Update Magnitude: 0.48650
Value Function Update Magnitude: 0.65131

Collected Steps per Second: 22,329.22006
Overall Steps per Second: 10,535.12863

Timestep Collection Time: 2.24002
Timestep Consumption Time: 2.50771
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.74774

Cumulative Model Updates: 313,978
Cumulative Timesteps: 2,618,525,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2618525594...
Checkpoint 2618525594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.22663
Policy Entropy: 2.43724
Value Function Loss: 0.02081

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.09587
Policy Update Magnitude: 0.48769
Value Function Update Magnitude: 0.65465

Collected Steps per Second: 21,832.09347
Overall Steps per Second: 10,559.98412

Timestep Collection Time: 2.29030
Timestep Consumption Time: 2.44475
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.73504

Cumulative Model Updates: 313,984
Cumulative Timesteps: 2,618,575,596

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.48124
Policy Entropy: 2.45473
Value Function Loss: 0.02072

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.08991
Policy Update Magnitude: 0.49810
Value Function Update Magnitude: 0.65586

Collected Steps per Second: 20,925.26180
Overall Steps per Second: 10,174.84927

Timestep Collection Time: 2.38974
Timestep Consumption Time: 2.52492
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.91467

Cumulative Model Updates: 313,990
Cumulative Timesteps: 2,618,625,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2618625602...
Checkpoint 2618625602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.83877
Policy Entropy: 2.45423
Value Function Loss: 0.02126

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.09176
Policy Update Magnitude: 0.49852
Value Function Update Magnitude: 0.67657

Collected Steps per Second: 21,940.63091
Overall Steps per Second: 10,450.73713

Timestep Collection Time: 2.27997
Timestep Consumption Time: 2.50668
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.78665

Cumulative Model Updates: 313,996
Cumulative Timesteps: 2,618,675,626

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.20623
Policy Entropy: 2.44759
Value Function Loss: 0.02192

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.09574
Policy Update Magnitude: 0.49668
Value Function Update Magnitude: 0.70219

Collected Steps per Second: 22,450.02816
Overall Steps per Second: 10,830.20268

Timestep Collection Time: 2.22850
Timestep Consumption Time: 2.39098
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.61949

Cumulative Model Updates: 314,002
Cumulative Timesteps: 2,618,725,656

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2618725656...
Checkpoint 2618725656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.08317
Policy Entropy: 2.43268
Value Function Loss: 0.02199

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.09930
Policy Update Magnitude: 0.49949
Value Function Update Magnitude: 0.68749

Collected Steps per Second: 22,379.08453
Overall Steps per Second: 10,676.50475

Timestep Collection Time: 2.23485
Timestep Consumption Time: 2.44964
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.68449

Cumulative Model Updates: 314,008
Cumulative Timesteps: 2,618,775,670

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.35516
Policy Entropy: 2.43706
Value Function Loss: 0.02210

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.08867
Policy Update Magnitude: 0.51782
Value Function Update Magnitude: 0.67532

Collected Steps per Second: 22,379.76883
Overall Steps per Second: 10,498.52299

Timestep Collection Time: 2.23416
Timestep Consumption Time: 2.52841
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.76257

Cumulative Model Updates: 314,014
Cumulative Timesteps: 2,618,825,670

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2618825670...
Checkpoint 2618825670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.91759
Policy Entropy: 2.43936
Value Function Loss: 0.02146

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.08703
Policy Update Magnitude: 0.50687
Value Function Update Magnitude: 0.66904

Collected Steps per Second: 22,067.25377
Overall Steps per Second: 10,680.56530

Timestep Collection Time: 2.26653
Timestep Consumption Time: 2.41637
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.68290

Cumulative Model Updates: 314,020
Cumulative Timesteps: 2,618,875,686

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.68853
Policy Entropy: 2.43771
Value Function Loss: 0.02126

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.08904
Policy Update Magnitude: 0.49679
Value Function Update Magnitude: 0.66931

Collected Steps per Second: 22,235.65887
Overall Steps per Second: 10,824.11691

Timestep Collection Time: 2.24990
Timestep Consumption Time: 2.37200
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.62190

Cumulative Model Updates: 314,026
Cumulative Timesteps: 2,618,925,714

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2618925714...
Checkpoint 2618925714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.86520
Policy Entropy: 2.42067
Value Function Loss: 0.02201

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.09391
Policy Update Magnitude: 0.48114
Value Function Update Magnitude: 0.67414

Collected Steps per Second: 22,251.98943
Overall Steps per Second: 10,689.48892

Timestep Collection Time: 2.24744
Timestep Consumption Time: 2.43099
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.67843

Cumulative Model Updates: 314,032
Cumulative Timesteps: 2,618,975,724

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.25863
Policy Entropy: 2.41926
Value Function Loss: 0.02238

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.48626
Value Function Update Magnitude: 0.69388

Collected Steps per Second: 21,854.88248
Overall Steps per Second: 10,443.17101

Timestep Collection Time: 2.28928
Timestep Consumption Time: 2.50160
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.79088

Cumulative Model Updates: 314,038
Cumulative Timesteps: 2,619,025,756

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2619025756...
Checkpoint 2619025756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.70625
Policy Entropy: 2.43085
Value Function Loss: 0.02160

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.48866
Value Function Update Magnitude: 0.68400

Collected Steps per Second: 22,046.33177
Overall Steps per Second: 10,707.35444

Timestep Collection Time: 2.26850
Timestep Consumption Time: 2.40231
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.67081

Cumulative Model Updates: 314,044
Cumulative Timesteps: 2,619,075,768

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.34590
Policy Entropy: 2.45570
Value Function Loss: 0.02087

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.09159
Policy Update Magnitude: 0.49068
Value Function Update Magnitude: 0.65428

Collected Steps per Second: 22,845.25222
Overall Steps per Second: 10,817.13310

Timestep Collection Time: 2.18890
Timestep Consumption Time: 2.43395
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.62285

Cumulative Model Updates: 314,050
Cumulative Timesteps: 2,619,125,774

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2619125774...
Checkpoint 2619125774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.94603
Policy Entropy: 2.46131
Value Function Loss: 0.02018

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.09520
Policy Update Magnitude: 0.48381
Value Function Update Magnitude: 0.64698

Collected Steps per Second: 22,195.30896
Overall Steps per Second: 10,433.06848

Timestep Collection Time: 2.25399
Timestep Consumption Time: 2.54115
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.79514

Cumulative Model Updates: 314,056
Cumulative Timesteps: 2,619,175,802

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.54935
Policy Entropy: 2.44372
Value Function Loss: 0.02123

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.47894
Value Function Update Magnitude: 0.65797

Collected Steps per Second: 22,345.41248
Overall Steps per Second: 10,631.45749

Timestep Collection Time: 2.23876
Timestep Consumption Time: 2.46671
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.70547

Cumulative Model Updates: 314,062
Cumulative Timesteps: 2,619,225,828

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2619225828...
Checkpoint 2619225828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.61887
Policy Entropy: 2.42695
Value Function Loss: 0.02074

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.09587
Policy Update Magnitude: 0.48732
Value Function Update Magnitude: 0.67488

Collected Steps per Second: 22,263.98500
Overall Steps per Second: 10,737.82416

Timestep Collection Time: 2.24650
Timestep Consumption Time: 2.41143
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.65793

Cumulative Model Updates: 314,068
Cumulative Timesteps: 2,619,275,844

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.07925
Policy Entropy: 2.43128
Value Function Loss: 0.02229

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.10716
Policy Update Magnitude: 0.49350
Value Function Update Magnitude: 0.69711

Collected Steps per Second: 22,611.43334
Overall Steps per Second: 10,619.50849

Timestep Collection Time: 2.21145
Timestep Consumption Time: 2.49724
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.70869

Cumulative Model Updates: 314,074
Cumulative Timesteps: 2,619,325,848

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2619325848...
Checkpoint 2619325848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.49510
Policy Entropy: 2.40779
Value Function Loss: 0.02175

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.11064
Policy Update Magnitude: 0.49246
Value Function Update Magnitude: 0.71196

Collected Steps per Second: 21,999.00886
Overall Steps per Second: 10,497.54458

Timestep Collection Time: 2.27374
Timestep Consumption Time: 2.49119
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.76492

Cumulative Model Updates: 314,080
Cumulative Timesteps: 2,619,375,868

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.89878
Policy Entropy: 2.42747
Value Function Loss: 0.02185

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.09880
Policy Update Magnitude: 0.49463
Value Function Update Magnitude: 0.70047

Collected Steps per Second: 22,279.79619
Overall Steps per Second: 10,579.75357

Timestep Collection Time: 2.24419
Timestep Consumption Time: 2.48182
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.72601

Cumulative Model Updates: 314,086
Cumulative Timesteps: 2,619,425,868

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2619425868...
Checkpoint 2619425868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.66779
Policy Entropy: 2.43568
Value Function Loss: 0.02173

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.09532
Policy Update Magnitude: 0.49767
Value Function Update Magnitude: 0.68084

Collected Steps per Second: 22,259.66094
Overall Steps per Second: 10,848.19039

Timestep Collection Time: 2.24658
Timestep Consumption Time: 2.36323
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.60980

Cumulative Model Updates: 314,092
Cumulative Timesteps: 2,619,475,876

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.65237
Policy Entropy: 2.45130
Value Function Loss: 0.02192

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.09373
Policy Update Magnitude: 0.49012
Value Function Update Magnitude: 0.67910

Collected Steps per Second: 22,152.71310
Overall Steps per Second: 10,547.88140

Timestep Collection Time: 2.25850
Timestep Consumption Time: 2.48482
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.74332

Cumulative Model Updates: 314,098
Cumulative Timesteps: 2,619,525,908

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2619525908...
Checkpoint 2619525908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.10770
Policy Entropy: 2.44259
Value Function Loss: 0.02036

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.10671
Policy Update Magnitude: 0.47953
Value Function Update Magnitude: 0.68563

Collected Steps per Second: 21,743.81047
Overall Steps per Second: 10,579.44435

Timestep Collection Time: 2.30024
Timestep Consumption Time: 2.42742
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.72766

Cumulative Model Updates: 314,104
Cumulative Timesteps: 2,619,575,924

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.00648
Policy Entropy: 2.45704
Value Function Loss: 0.01987

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.09863
Policy Update Magnitude: 0.46351
Value Function Update Magnitude: 0.68976

Collected Steps per Second: 21,582.15196
Overall Steps per Second: 10,531.43369

Timestep Collection Time: 2.31710
Timestep Consumption Time: 2.43135
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.74845

Cumulative Model Updates: 314,110
Cumulative Timesteps: 2,619,625,932

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2619625932...
Checkpoint 2619625932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.66717
Policy Entropy: 2.44122
Value Function Loss: 0.01983

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.10422
Policy Update Magnitude: 0.46891
Value Function Update Magnitude: 0.70185

Collected Steps per Second: 21,778.26700
Overall Steps per Second: 10,641.96575

Timestep Collection Time: 2.29642
Timestep Consumption Time: 2.40309
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.69951

Cumulative Model Updates: 314,116
Cumulative Timesteps: 2,619,675,944

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.69408
Policy Entropy: 2.45979
Value Function Loss: 0.02152

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.11809
Policy Update Magnitude: 0.45370
Value Function Update Magnitude: 0.68406

Collected Steps per Second: 22,379.21590
Overall Steps per Second: 10,545.87962

Timestep Collection Time: 2.23422
Timestep Consumption Time: 2.50697
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.74119

Cumulative Model Updates: 314,122
Cumulative Timesteps: 2,619,725,944

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2619725944...
Checkpoint 2619725944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.14781
Policy Entropy: 2.43003
Value Function Loss: 0.02249

Mean KL Divergence: 0.02552
SB3 Clip Fraction: 0.12826
Policy Update Magnitude: 0.44427
Value Function Update Magnitude: 0.69496

Collected Steps per Second: 22,240.32131
Overall Steps per Second: 10,565.26111

Timestep Collection Time: 2.24898
Timestep Consumption Time: 2.48522
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.73419

Cumulative Model Updates: 314,128
Cumulative Timesteps: 2,619,775,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.23770
Policy Entropy: 2.44572
Value Function Loss: 0.02224

Mean KL Divergence: 0.03190
SB3 Clip Fraction: 0.11984
Policy Update Magnitude: 0.47895
Value Function Update Magnitude: 0.71195

Collected Steps per Second: 22,349.66899
Overall Steps per Second: 10,511.71680

Timestep Collection Time: 2.23851
Timestep Consumption Time: 2.52094
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.75945

Cumulative Model Updates: 314,134
Cumulative Timesteps: 2,619,825,992

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2619825992...
Checkpoint 2619825992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.61496
Policy Entropy: 2.41804
Value Function Loss: 0.02194

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.11233
Policy Update Magnitude: 0.50142
Value Function Update Magnitude: 0.69868

Collected Steps per Second: 22,970.64676
Overall Steps per Second: 10,725.83920

Timestep Collection Time: 2.17695
Timestep Consumption Time: 2.48525
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.66220

Cumulative Model Updates: 314,140
Cumulative Timesteps: 2,619,875,998

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.10543
Policy Entropy: 2.43958
Value Function Loss: 0.02070

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.09893
Policy Update Magnitude: 0.49472
Value Function Update Magnitude: 0.69346

Collected Steps per Second: 22,661.61579
Overall Steps per Second: 10,801.82413

Timestep Collection Time: 2.20717
Timestep Consumption Time: 2.42335
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.63051

Cumulative Model Updates: 314,146
Cumulative Timesteps: 2,619,926,016

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2619926016...
Checkpoint 2619926016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.95985
Policy Entropy: 2.43412
Value Function Loss: 0.02123

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.09132
Policy Update Magnitude: 0.48383
Value Function Update Magnitude: 0.65722

Collected Steps per Second: 22,345.17079
Overall Steps per Second: 10,577.44899

Timestep Collection Time: 2.23851
Timestep Consumption Time: 2.49041
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.72893

Cumulative Model Updates: 314,152
Cumulative Timesteps: 2,619,976,036

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.98072
Policy Entropy: 2.44933
Value Function Loss: 0.02156

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.08588
Policy Update Magnitude: 0.48300
Value Function Update Magnitude: 0.65207

Collected Steps per Second: 22,394.52075
Overall Steps per Second: 10,884.38974

Timestep Collection Time: 2.23394
Timestep Consumption Time: 2.36237
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.59631

Cumulative Model Updates: 314,158
Cumulative Timesteps: 2,620,026,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2620026064...
Checkpoint 2620026064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.89625
Policy Entropy: 2.43761
Value Function Loss: 0.02143

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.09223
Policy Update Magnitude: 0.48907
Value Function Update Magnitude: 0.65958

Collected Steps per Second: 22,325.60681
Overall Steps per Second: 10,631.65600

Timestep Collection Time: 2.24003
Timestep Consumption Time: 2.46385
PPO Batch Consumption Time: 0.28514
Total Iteration Time: 4.70388

Cumulative Model Updates: 314,164
Cumulative Timesteps: 2,620,076,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.19550
Policy Entropy: 2.43814
Value Function Loss: 0.02096

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.09368
Policy Update Magnitude: 0.49701
Value Function Update Magnitude: 0.65396

Collected Steps per Second: 21,965.42233
Overall Steps per Second: 10,501.98317

Timestep Collection Time: 2.27758
Timestep Consumption Time: 2.48609
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.76367

Cumulative Model Updates: 314,170
Cumulative Timesteps: 2,620,126,102

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2620126102...
Checkpoint 2620126102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.53563
Policy Entropy: 2.44877
Value Function Loss: 0.02051

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.08783
Policy Update Magnitude: 0.49338
Value Function Update Magnitude: 0.66233

Collected Steps per Second: 21,890.58036
Overall Steps per Second: 10,667.81335

Timestep Collection Time: 2.28473
Timestep Consumption Time: 2.40358
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.68831

Cumulative Model Updates: 314,176
Cumulative Timesteps: 2,620,176,116

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.69936
Policy Entropy: 2.46816
Value Function Loss: 0.02015

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.48174
Value Function Update Magnitude: 0.68321

Collected Steps per Second: 21,744.15438
Overall Steps per Second: 10,608.79420

Timestep Collection Time: 2.30158
Timestep Consumption Time: 2.41582
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.71741

Cumulative Model Updates: 314,182
Cumulative Timesteps: 2,620,226,162

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2620226162...
Checkpoint 2620226162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.05213
Policy Entropy: 2.47150
Value Function Loss: 0.02035

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.08965
Policy Update Magnitude: 0.48256
Value Function Update Magnitude: 0.68789

Collected Steps per Second: 21,758.57253
Overall Steps per Second: 10,473.99652

Timestep Collection Time: 2.29813
Timestep Consumption Time: 2.47598
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.77411

Cumulative Model Updates: 314,188
Cumulative Timesteps: 2,620,276,166

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.39426
Policy Entropy: 2.46604
Value Function Loss: 0.02107

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.07935
Policy Update Magnitude: 0.48457
Value Function Update Magnitude: 0.68492

Collected Steps per Second: 21,982.25303
Overall Steps per Second: 10,444.33543

Timestep Collection Time: 2.27465
Timestep Consumption Time: 2.51282
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.78748

Cumulative Model Updates: 314,194
Cumulative Timesteps: 2,620,326,168

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2620326168...
Checkpoint 2620326168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.54120
Policy Entropy: 2.44339
Value Function Loss: 0.02119

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.08392
Policy Update Magnitude: 0.49924
Value Function Update Magnitude: 0.69414

Collected Steps per Second: 21,934.43953
Overall Steps per Second: 10,684.39647

Timestep Collection Time: 2.28043
Timestep Consumption Time: 2.40116
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.68159

Cumulative Model Updates: 314,200
Cumulative Timesteps: 2,620,376,188

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.89546
Policy Entropy: 2.44283
Value Function Loss: 0.02142

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.08445
Policy Update Magnitude: 0.49181
Value Function Update Magnitude: 0.67403

Collected Steps per Second: 22,487.52986
Overall Steps per Second: 10,844.78357

Timestep Collection Time: 2.22363
Timestep Consumption Time: 2.38725
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.61088

Cumulative Model Updates: 314,206
Cumulative Timesteps: 2,620,426,192

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2620426192...
Checkpoint 2620426192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.10588
Policy Entropy: 2.44428
Value Function Loss: 0.02027

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.08839
Policy Update Magnitude: 0.48472
Value Function Update Magnitude: 0.66449

Collected Steps per Second: 22,402.36326
Overall Steps per Second: 10,616.16318

Timestep Collection Time: 2.23298
Timestep Consumption Time: 2.47908
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.71206

Cumulative Model Updates: 314,212
Cumulative Timesteps: 2,620,476,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.93556
Policy Entropy: 2.45582
Value Function Loss: 0.02095

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.10599
Policy Update Magnitude: 0.47582
Value Function Update Magnitude: 0.66152

Collected Steps per Second: 21,300.57171
Overall Steps per Second: 10,412.14151

Timestep Collection Time: 2.34792
Timestep Consumption Time: 2.45532
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.80324

Cumulative Model Updates: 314,218
Cumulative Timesteps: 2,620,526,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2620526228...
Checkpoint 2620526228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.92825
Policy Entropy: 2.44615
Value Function Loss: 0.02026

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.11421
Policy Update Magnitude: 0.47396
Value Function Update Magnitude: 0.66606

Collected Steps per Second: 22,146.10664
Overall Steps per Second: 10,646.85624

Timestep Collection Time: 2.25782
Timestep Consumption Time: 2.43859
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.69641

Cumulative Model Updates: 314,224
Cumulative Timesteps: 2,620,576,230

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.59379
Policy Entropy: 2.43129
Value Function Loss: 0.02190

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.10549
Policy Update Magnitude: 0.49737
Value Function Update Magnitude: 0.66201

Collected Steps per Second: 22,108.92095
Overall Steps per Second: 10,448.87994

Timestep Collection Time: 2.26280
Timestep Consumption Time: 2.52508
PPO Batch Consumption Time: 0.29737
Total Iteration Time: 4.78788

Cumulative Model Updates: 314,230
Cumulative Timesteps: 2,620,626,258

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2620626258...
Checkpoint 2620626258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.46325
Policy Entropy: 2.43379
Value Function Loss: 0.02324

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.50409
Value Function Update Magnitude: 0.66161

Collected Steps per Second: 22,969.48765
Overall Steps per Second: 10,700.68816

Timestep Collection Time: 2.17724
Timestep Consumption Time: 2.49630
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.67353

Cumulative Model Updates: 314,236
Cumulative Timesteps: 2,620,676,268

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.17331
Policy Entropy: 2.42699
Value Function Loss: 0.02408

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.09697
Policy Update Magnitude: 0.50250
Value Function Update Magnitude: 0.66212

Collected Steps per Second: 22,329.79591
Overall Steps per Second: 10,513.56342

Timestep Collection Time: 2.23979
Timestep Consumption Time: 2.51731
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.75709

Cumulative Model Updates: 314,242
Cumulative Timesteps: 2,620,726,282

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2620726282...
Checkpoint 2620726282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.57601
Policy Entropy: 2.42311
Value Function Loss: 0.02392

Mean KL Divergence: 0.02290
SB3 Clip Fraction: 0.12077
Policy Update Magnitude: 0.49368
Value Function Update Magnitude: 0.67038

Collected Steps per Second: 21,762.44009
Overall Steps per Second: 10,568.52085

Timestep Collection Time: 2.29882
Timestep Consumption Time: 2.43486
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.73368

Cumulative Model Updates: 314,248
Cumulative Timesteps: 2,620,776,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.46465
Policy Entropy: 2.41620
Value Function Loss: 0.02359

Mean KL Divergence: 0.02245
SB3 Clip Fraction: 0.13452
Policy Update Magnitude: 0.44706
Value Function Update Magnitude: 0.68372

Collected Steps per Second: 21,890.92985
Overall Steps per Second: 10,637.17259

Timestep Collection Time: 2.28451
Timestep Consumption Time: 2.41693
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.70144

Cumulative Model Updates: 314,254
Cumulative Timesteps: 2,620,826,320

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2620826320...
Checkpoint 2620826320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.25844
Policy Entropy: 2.44960
Value Function Loss: 0.02103

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.10820
Policy Update Magnitude: 0.46521
Value Function Update Magnitude: 0.67529

Collected Steps per Second: 21,571.91928
Overall Steps per Second: 10,546.54374

Timestep Collection Time: 2.31876
Timestep Consumption Time: 2.42403
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.74279

Cumulative Model Updates: 314,260
Cumulative Timesteps: 2,620,876,340

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.22246
Policy Entropy: 2.44643
Value Function Loss: 0.02078

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.10444
Policy Update Magnitude: 0.48546
Value Function Update Magnitude: 0.66686

Collected Steps per Second: 22,280.93524
Overall Steps per Second: 10,549.48251

Timestep Collection Time: 2.24497
Timestep Consumption Time: 2.49650
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.74146

Cumulative Model Updates: 314,266
Cumulative Timesteps: 2,620,926,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2620926360...
Checkpoint 2620926360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.77424
Policy Entropy: 2.43712
Value Function Loss: 0.02061

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.11001
Policy Update Magnitude: 0.48103
Value Function Update Magnitude: 0.65416

Collected Steps per Second: 21,883.28036
Overall Steps per Second: 10,496.64542

Timestep Collection Time: 2.28485
Timestep Consumption Time: 2.47858
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.76343

Cumulative Model Updates: 314,272
Cumulative Timesteps: 2,620,976,360

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.91996
Policy Entropy: 2.43077
Value Function Loss: 0.02116

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.12270
Policy Update Magnitude: 0.47094
Value Function Update Magnitude: 0.66648

Collected Steps per Second: 22,255.10407
Overall Steps per Second: 10,477.55356

Timestep Collection Time: 2.24704
Timestep Consumption Time: 2.52583
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.77287

Cumulative Model Updates: 314,278
Cumulative Timesteps: 2,621,026,368

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2621026368...
Checkpoint 2621026368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.22723
Policy Entropy: 2.43155
Value Function Loss: 0.02215

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.11116
Policy Update Magnitude: 0.49812
Value Function Update Magnitude: 0.66550

Collected Steps per Second: 22,217.56000
Overall Steps per Second: 10,669.30931

Timestep Collection Time: 2.25119
Timestep Consumption Time: 2.43665
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.68784

Cumulative Model Updates: 314,284
Cumulative Timesteps: 2,621,076,384

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.79368
Policy Entropy: 2.44747
Value Function Loss: 0.02164

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.09899
Policy Update Magnitude: 0.49475
Value Function Update Magnitude: 0.68727

Collected Steps per Second: 22,732.58714
Overall Steps per Second: 10,803.70208

Timestep Collection Time: 2.20028
Timestep Consumption Time: 2.42943
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.62971

Cumulative Model Updates: 314,290
Cumulative Timesteps: 2,621,126,402

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2621126402...
Checkpoint 2621126402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.16072
Policy Entropy: 2.44717
Value Function Loss: 0.02108

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.48550
Value Function Update Magnitude: 0.70317

Collected Steps per Second: 22,138.72824
Overall Steps per Second: 10,645.27500

Timestep Collection Time: 2.25975
Timestep Consumption Time: 2.43980
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.69955

Cumulative Model Updates: 314,296
Cumulative Timesteps: 2,621,176,430

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.01007
Policy Entropy: 2.43767
Value Function Loss: 0.02077

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.09184
Policy Update Magnitude: 0.48736
Value Function Update Magnitude: 0.68441

Collected Steps per Second: 22,344.17809
Overall Steps per Second: 10,551.14054

Timestep Collection Time: 2.23808
Timestep Consumption Time: 2.50151
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.73958

Cumulative Model Updates: 314,302
Cumulative Timesteps: 2,621,226,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2621226438...
Checkpoint 2621226438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.18392
Policy Entropy: 2.44607
Value Function Loss: 0.02044

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.48052
Value Function Update Magnitude: 0.67865

Collected Steps per Second: 22,175.08019
Overall Steps per Second: 10,611.17846

Timestep Collection Time: 2.25560
Timestep Consumption Time: 2.45811
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.71371

Cumulative Model Updates: 314,308
Cumulative Timesteps: 2,621,276,456

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.37113
Policy Entropy: 2.44717
Value Function Loss: 0.02059

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.08746
Policy Update Magnitude: 0.47383
Value Function Update Magnitude: 0.65975

Collected Steps per Second: 22,726.79260
Overall Steps per Second: 10,684.97152

Timestep Collection Time: 2.20110
Timestep Consumption Time: 2.48061
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.68172

Cumulative Model Updates: 314,314
Cumulative Timesteps: 2,621,326,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2621326480...
Checkpoint 2621326480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.58752
Policy Entropy: 2.46214
Value Function Loss: 0.02061

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.08856
Policy Update Magnitude: 0.48536
Value Function Update Magnitude: 0.64907

Collected Steps per Second: 21,877.89830
Overall Steps per Second: 10,431.54885

Timestep Collection Time: 2.28550
Timestep Consumption Time: 2.50784
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.79334

Cumulative Model Updates: 314,320
Cumulative Timesteps: 2,621,376,482

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.72340
Policy Entropy: 2.46403
Value Function Loss: 0.02253

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.09008
Policy Update Magnitude: 0.49401
Value Function Update Magnitude: 0.66200

Collected Steps per Second: 22,132.04154
Overall Steps per Second: 10,816.78257

Timestep Collection Time: 2.25998
Timestep Consumption Time: 2.36413
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.62411

Cumulative Model Updates: 314,326
Cumulative Timesteps: 2,621,426,500

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2621426500...
Checkpoint 2621426500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.79610
Policy Entropy: 2.48268
Value Function Loss: 0.02256

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.49359
Value Function Update Magnitude: 0.66780

Collected Steps per Second: 21,968.10478
Overall Steps per Second: 10,623.29423

Timestep Collection Time: 2.27621
Timestep Consumption Time: 2.43081
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.70701

Cumulative Model Updates: 314,332
Cumulative Timesteps: 2,621,476,504

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.58143
Policy Entropy: 2.49403
Value Function Loss: 0.02301

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.08912
Policy Update Magnitude: 0.49636
Value Function Update Magnitude: 0.66411

Collected Steps per Second: 22,139.09503
Overall Steps per Second: 10,542.36496

Timestep Collection Time: 2.25980
Timestep Consumption Time: 2.48581
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.74561

Cumulative Model Updates: 314,338
Cumulative Timesteps: 2,621,526,534

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2621526534...
Checkpoint 2621526534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.88839
Policy Entropy: 2.49506
Value Function Loss: 0.02243

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.48787
Value Function Update Magnitude: 0.68622

Collected Steps per Second: 22,090.48839
Overall Steps per Second: 10,599.72469

Timestep Collection Time: 2.26369
Timestep Consumption Time: 2.45398
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.71767

Cumulative Model Updates: 314,344
Cumulative Timesteps: 2,621,576,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.12562
Policy Entropy: 2.46005
Value Function Loss: 0.02218

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.08346
Policy Update Magnitude: 0.49649
Value Function Update Magnitude: 0.69724

Collected Steps per Second: 22,703.55003
Overall Steps per Second: 10,927.13343

Timestep Collection Time: 2.20292
Timestep Consumption Time: 2.37413
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.57705

Cumulative Model Updates: 314,350
Cumulative Timesteps: 2,621,626,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2621626554...
Checkpoint 2621626554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.94871
Policy Entropy: 2.45240
Value Function Loss: 0.02162

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.09045
Policy Update Magnitude: 0.49897
Value Function Update Magnitude: 0.68786

Collected Steps per Second: 22,268.44657
Overall Steps per Second: 10,682.45733

Timestep Collection Time: 2.24533
Timestep Consumption Time: 2.43524
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.68057

Cumulative Model Updates: 314,356
Cumulative Timesteps: 2,621,676,554

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.13772
Policy Entropy: 2.43210
Value Function Loss: 0.02079

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.49268
Value Function Update Magnitude: 0.69286

Collected Steps per Second: 22,576.57002
Overall Steps per Second: 10,638.87396

Timestep Collection Time: 2.21469
Timestep Consumption Time: 2.48506
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.69975

Cumulative Model Updates: 314,362
Cumulative Timesteps: 2,621,726,554

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2621726554...
Checkpoint 2621726554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.71099
Policy Entropy: 2.44572
Value Function Loss: 0.02062

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.49289
Value Function Update Magnitude: 0.69884

Collected Steps per Second: 22,117.23861
Overall Steps per Second: 10,474.03579

Timestep Collection Time: 2.26086
Timestep Consumption Time: 2.51323
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 4.77409

Cumulative Model Updates: 314,368
Cumulative Timesteps: 2,621,776,558

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.64065
Policy Entropy: 2.43946
Value Function Loss: 0.02217

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.09827
Policy Update Magnitude: 0.48818
Value Function Update Magnitude: 0.69864

Collected Steps per Second: 22,482.69243
Overall Steps per Second: 10,917.03462

Timestep Collection Time: 2.22420
Timestep Consumption Time: 2.35635
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.58055

Cumulative Model Updates: 314,374
Cumulative Timesteps: 2,621,826,564

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2621826564...
Checkpoint 2621826564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175.60141
Policy Entropy: 2.46162
Value Function Loss: 0.02273

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.11820
Policy Update Magnitude: 0.46543
Value Function Update Magnitude: 0.71182

Collected Steps per Second: 21,939.21479
Overall Steps per Second: 10,658.54538

Timestep Collection Time: 2.27957
Timestep Consumption Time: 2.41263
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.69220

Cumulative Model Updates: 314,380
Cumulative Timesteps: 2,621,876,576

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.99985
Policy Entropy: 2.47738
Value Function Loss: 0.02141

Mean KL Divergence: 0.02253
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.43830
Value Function Update Magnitude: 0.72523

Collected Steps per Second: 22,241.07865
Overall Steps per Second: 10,552.48977

Timestep Collection Time: 2.24845
Timestep Consumption Time: 2.49052
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.73898

Cumulative Model Updates: 314,386
Cumulative Timesteps: 2,621,926,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2621926584...
Checkpoint 2621926584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.81783
Policy Entropy: 2.48309
Value Function Loss: 0.01929

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.11874
Policy Update Magnitude: 0.47012
Value Function Update Magnitude: 0.70689

Collected Steps per Second: 21,661.13253
Overall Steps per Second: 10,554.13313

Timestep Collection Time: 2.30948
Timestep Consumption Time: 2.43046
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.73994

Cumulative Model Updates: 314,392
Cumulative Timesteps: 2,621,976,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.85185
Policy Entropy: 2.46868
Value Function Loss: 0.01982

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.10873
Policy Update Magnitude: 0.49675
Value Function Update Magnitude: 0.67763

Collected Steps per Second: 22,140.98629
Overall Steps per Second: 10,828.88289

Timestep Collection Time: 2.25970
Timestep Consumption Time: 2.36054
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.62024

Cumulative Model Updates: 314,398
Cumulative Timesteps: 2,622,026,642

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2622026642...
Checkpoint 2622026642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.44809
Policy Entropy: 2.45188
Value Function Loss: 0.02105

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.09342
Policy Update Magnitude: 0.50094
Value Function Update Magnitude: 0.65998

Collected Steps per Second: 22,420.72477
Overall Steps per Second: 10,688.41595

Timestep Collection Time: 2.23124
Timestep Consumption Time: 2.44915
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.68039

Cumulative Model Updates: 314,404
Cumulative Timesteps: 2,622,076,668

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.86163
Policy Entropy: 2.44877
Value Function Loss: 0.02209

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.09567
Policy Update Magnitude: 0.49638
Value Function Update Magnitude: 0.66321

Collected Steps per Second: 22,345.84066
Overall Steps per Second: 10,553.62168

Timestep Collection Time: 2.23863
Timestep Consumption Time: 2.50136
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.73998

Cumulative Model Updates: 314,410
Cumulative Timesteps: 2,622,126,692

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2622126692...
Checkpoint 2622126692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.76123
Policy Entropy: 2.44833
Value Function Loss: 0.02257

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.09429
Policy Update Magnitude: 0.49674
Value Function Update Magnitude: 0.66464

Collected Steps per Second: 22,032.26819
Overall Steps per Second: 10,506.23824

Timestep Collection Time: 2.27040
Timestep Consumption Time: 2.49077
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.76117

Cumulative Model Updates: 314,416
Cumulative Timesteps: 2,622,176,714

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.77537
Policy Entropy: 2.47226
Value Function Loss: 0.02234

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.09467
Policy Update Magnitude: 0.49828
Value Function Update Magnitude: 0.66216

Collected Steps per Second: 22,358.76875
Overall Steps per Second: 10,848.76466

Timestep Collection Time: 2.23715
Timestep Consumption Time: 2.37351
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.61066

Cumulative Model Updates: 314,422
Cumulative Timesteps: 2,622,226,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2622226734...
Checkpoint 2622226734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.02649
Policy Entropy: 2.47356
Value Function Loss: 0.02196

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.09074
Policy Update Magnitude: 0.49049
Value Function Update Magnitude: 0.65262

Collected Steps per Second: 22,362.14407
Overall Steps per Second: 10,698.32582

Timestep Collection Time: 2.23699
Timestep Consumption Time: 2.43888
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.67587

Cumulative Model Updates: 314,428
Cumulative Timesteps: 2,622,276,758

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.84824
Policy Entropy: 2.49055
Value Function Loss: 0.02139

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.48570
Value Function Update Magnitude: 0.64640

Collected Steps per Second: 22,506.93557
Overall Steps per Second: 10,560.48617

Timestep Collection Time: 2.22278
Timestep Consumption Time: 2.51450
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.73728

Cumulative Model Updates: 314,434
Cumulative Timesteps: 2,622,326,786

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2622326786...
Checkpoint 2622326786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.99366
Policy Entropy: 2.48316
Value Function Loss: 0.02188

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.48566
Value Function Update Magnitude: 0.65394

Collected Steps per Second: 22,187.03316
Overall Steps per Second: 10,573.83053

Timestep Collection Time: 2.25411
Timestep Consumption Time: 2.47568
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.72979

Cumulative Model Updates: 314,440
Cumulative Timesteps: 2,622,376,798

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.92793
Policy Entropy: 2.50072
Value Function Loss: 0.02103

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.09489
Policy Update Magnitude: 0.47442
Value Function Update Magnitude: 0.65632

Collected Steps per Second: 20,706.10741
Overall Steps per Second: 10,437.25387

Timestep Collection Time: 2.41552
Timestep Consumption Time: 2.37655
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.79207

Cumulative Model Updates: 314,446
Cumulative Timesteps: 2,622,426,814

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2622426814...
Checkpoint 2622426814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.53410
Policy Entropy: 2.48510
Value Function Loss: 0.02077

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.09386
Policy Update Magnitude: 0.46697
Value Function Update Magnitude: 0.64601

Collected Steps per Second: 21,886.50161
Overall Steps per Second: 10,587.46748

Timestep Collection Time: 2.28506
Timestep Consumption Time: 2.43864
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.72370

Cumulative Model Updates: 314,452
Cumulative Timesteps: 2,622,476,826

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.71993
Policy Entropy: 2.47559
Value Function Loss: 0.02073

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.12116
Policy Update Magnitude: 0.47130
Value Function Update Magnitude: 0.64397

Collected Steps per Second: 22,041.17441
Overall Steps per Second: 10,509.56182

Timestep Collection Time: 2.26903
Timestep Consumption Time: 2.48969
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.75871

Cumulative Model Updates: 314,458
Cumulative Timesteps: 2,622,526,838

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2622526838...
Checkpoint 2622526838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.86973
Policy Entropy: 2.46349
Value Function Loss: 0.01939

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.11907
Policy Update Magnitude: 0.45818
Value Function Update Magnitude: 0.66028

Collected Steps per Second: 21,409.58506
Overall Steps per Second: 10,535.89995

Timestep Collection Time: 2.33615
Timestep Consumption Time: 2.41105
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.74720

Cumulative Model Updates: 314,464
Cumulative Timesteps: 2,622,576,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.46190
Policy Entropy: 2.47578
Value Function Loss: 0.01869

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.12930
Policy Update Magnitude: 0.44282
Value Function Update Magnitude: 0.65777

Collected Steps per Second: 22,301.20342
Overall Steps per Second: 10,688.82930

Timestep Collection Time: 2.24239
Timestep Consumption Time: 2.43614
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.67853

Cumulative Model Updates: 314,470
Cumulative Timesteps: 2,622,626,862

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2622626862...
Checkpoint 2622626862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.52065
Policy Entropy: 2.48618
Value Function Loss: 0.01980

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.12315
Policy Update Magnitude: 0.45646
Value Function Update Magnitude: 0.64999

Collected Steps per Second: 22,400.90779
Overall Steps per Second: 10,515.64407

Timestep Collection Time: 2.23205
Timestep Consumption Time: 2.52277
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.75482

Cumulative Model Updates: 314,476
Cumulative Timesteps: 2,622,676,862

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.98685
Policy Entropy: 2.49096
Value Function Loss: 0.02155

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.12306
Policy Update Magnitude: 0.48417
Value Function Update Magnitude: 0.65538

Collected Steps per Second: 22,386.45897
Overall Steps per Second: 10,516.86667

Timestep Collection Time: 2.23546
Timestep Consumption Time: 2.52299
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.75845

Cumulative Model Updates: 314,482
Cumulative Timesteps: 2,622,726,906

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2622726906...
Checkpoint 2622726906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.92066
Policy Entropy: 2.50285
Value Function Loss: 0.02263

Mean KL Divergence: 0.02734
SB3 Clip Fraction: 0.14293
Policy Update Magnitude: 0.48472
Value Function Update Magnitude: 0.66108

Collected Steps per Second: 22,239.01080
Overall Steps per Second: 10,717.04809

Timestep Collection Time: 2.24875
Timestep Consumption Time: 2.41765
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.66640

Cumulative Model Updates: 314,488
Cumulative Timesteps: 2,622,776,916

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.25333
Policy Entropy: 2.49137
Value Function Loss: 0.02190

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.48739
Value Function Update Magnitude: 0.64911

Collected Steps per Second: 22,737.06228
Overall Steps per Second: 10,766.87555

Timestep Collection Time: 2.19993
Timestep Consumption Time: 2.44580
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.64573

Cumulative Model Updates: 314,494
Cumulative Timesteps: 2,622,826,936

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2622826936...
Checkpoint 2622826936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.25024
Policy Entropy: 2.47764
Value Function Loss: 0.02184

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.10908
Policy Update Magnitude: 0.49140
Value Function Update Magnitude: 0.64430

Collected Steps per Second: 22,283.71099
Overall Steps per Second: 10,644.14668

Timestep Collection Time: 2.24424
Timestep Consumption Time: 2.45412
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.69836

Cumulative Model Updates: 314,500
Cumulative Timesteps: 2,622,876,946

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.51701
Policy Entropy: 2.47342
Value Function Loss: 0.02101

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.09562
Policy Update Magnitude: 0.49023
Value Function Update Magnitude: 0.65612

Collected Steps per Second: 22,617.25222
Overall Steps per Second: 10,800.98682

Timestep Collection Time: 2.21167
Timestep Consumption Time: 2.41957
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.63124

Cumulative Model Updates: 314,506
Cumulative Timesteps: 2,622,926,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2622926968...
Checkpoint 2622926968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.37356
Policy Entropy: 2.47879
Value Function Loss: 0.02102

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.49470
Value Function Update Magnitude: 0.64590

Collected Steps per Second: 22,041.48553
Overall Steps per Second: 10,694.65372

Timestep Collection Time: 2.26954
Timestep Consumption Time: 2.40794
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.67748

Cumulative Model Updates: 314,512
Cumulative Timesteps: 2,622,976,992

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.02451
Policy Entropy: 2.49531
Value Function Loss: 0.02033

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.09288
Policy Update Magnitude: 0.48440
Value Function Update Magnitude: 0.63873

Collected Steps per Second: 21,773.16656
Overall Steps per Second: 10,560.76314

Timestep Collection Time: 2.29705
Timestep Consumption Time: 2.43878
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.73583

Cumulative Model Updates: 314,518
Cumulative Timesteps: 2,623,027,006

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2623027006...
Checkpoint 2623027006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.75985
Policy Entropy: 2.49210
Value Function Loss: 0.02221

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.48881
Value Function Update Magnitude: 0.64709

Collected Steps per Second: 21,795.09732
Overall Steps per Second: 10,618.64061

Timestep Collection Time: 2.29437
Timestep Consumption Time: 2.41490
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.70927

Cumulative Model Updates: 314,524
Cumulative Timesteps: 2,623,077,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.03616
Policy Entropy: 2.50836
Value Function Loss: 0.02255

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.49443
Value Function Update Magnitude: 0.65387

Collected Steps per Second: 22,268.30953
Overall Steps per Second: 10,519.32002

Timestep Collection Time: 2.24588
Timestep Consumption Time: 2.50842
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.75430

Cumulative Model Updates: 314,530
Cumulative Timesteps: 2,623,127,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2623127024...
Checkpoint 2623127024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.60081
Policy Entropy: 2.49240
Value Function Loss: 0.02267

Mean KL Divergence: 0.02360
SB3 Clip Fraction: 0.12112
Policy Update Magnitude: 0.47667
Value Function Update Magnitude: 0.64455

Collected Steps per Second: 21,740.73156
Overall Steps per Second: 10,596.14325

Timestep Collection Time: 2.30001
Timestep Consumption Time: 2.41906
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.71908

Cumulative Model Updates: 314,536
Cumulative Timesteps: 2,623,177,028

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.17244
Policy Entropy: 2.48146
Value Function Loss: 0.02145

Mean KL Divergence: 0.02156
SB3 Clip Fraction: 0.12260
Policy Update Magnitude: 0.45822
Value Function Update Magnitude: 0.63217

Collected Steps per Second: 21,675.43203
Overall Steps per Second: 10,524.59244

Timestep Collection Time: 2.30768
Timestep Consumption Time: 2.44500
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.75268

Cumulative Model Updates: 314,542
Cumulative Timesteps: 2,623,227,048

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2623227048...
Checkpoint 2623227048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.35862
Policy Entropy: 2.48818
Value Function Loss: 0.02028

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.11320
Policy Update Magnitude: 0.47199
Value Function Update Magnitude: 0.64315

Collected Steps per Second: 22,151.10984
Overall Steps per Second: 10,526.86645

Timestep Collection Time: 2.25840
Timestep Consumption Time: 2.49382
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.75222

Cumulative Model Updates: 314,548
Cumulative Timesteps: 2,623,277,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.79688
Policy Entropy: 2.47596
Value Function Loss: 0.02133

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.10535
Policy Update Magnitude: 0.48083
Value Function Update Magnitude: 0.65803

Collected Steps per Second: 22,609.78890
Overall Steps per Second: 10,610.18985

Timestep Collection Time: 2.21232
Timestep Consumption Time: 2.50202
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.71434

Cumulative Model Updates: 314,554
Cumulative Timesteps: 2,623,327,094

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2623327094...
Checkpoint 2623327094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.31779
Policy Entropy: 2.49597
Value Function Loss: 0.02105

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.09458
Policy Update Magnitude: 0.48366
Value Function Update Magnitude: 0.67136

Collected Steps per Second: 22,028.57344
Overall Steps per Second: 10,503.22285

Timestep Collection Time: 2.26978
Timestep Consumption Time: 2.49066
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.76044

Cumulative Model Updates: 314,560
Cumulative Timesteps: 2,623,377,094

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.44801
Policy Entropy: 2.50416
Value Function Loss: 0.02232

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.09658
Policy Update Magnitude: 0.49177
Value Function Update Magnitude: 0.69313

Collected Steps per Second: 22,729.73162
Overall Steps per Second: 10,869.51751

Timestep Collection Time: 2.20073
Timestep Consumption Time: 2.40131
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.60204

Cumulative Model Updates: 314,566
Cumulative Timesteps: 2,623,427,116

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2623427116...
Checkpoint 2623427116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.90646
Policy Entropy: 2.52831
Value Function Loss: 0.02060

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.09904
Policy Update Magnitude: 0.48258
Value Function Update Magnitude: 0.68922

Collected Steps per Second: 22,209.24963
Overall Steps per Second: 10,694.82370

Timestep Collection Time: 2.25158
Timestep Consumption Time: 2.42414
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.67572

Cumulative Model Updates: 314,572
Cumulative Timesteps: 2,623,477,122

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.50569
Policy Entropy: 2.53327
Value Function Loss: 0.02280

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.10034
Policy Update Magnitude: 0.47595
Value Function Update Magnitude: 0.69015

Collected Steps per Second: 22,450.84014
Overall Steps per Second: 10,606.73614

Timestep Collection Time: 2.22789
Timestep Consumption Time: 2.48779
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.71568

Cumulative Model Updates: 314,578
Cumulative Timesteps: 2,623,527,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2623527140...
Checkpoint 2623527140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.82008
Policy Entropy: 2.51457
Value Function Loss: 0.02129

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.09094
Policy Update Magnitude: 0.48535
Value Function Update Magnitude: 0.68155

Collected Steps per Second: 22,137.73956
Overall Steps per Second: 10,836.71798

Timestep Collection Time: 2.25877
Timestep Consumption Time: 2.35555
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.61431

Cumulative Model Updates: 314,584
Cumulative Timesteps: 2,623,577,144

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.51105
Policy Entropy: 2.51511
Value Function Loss: 0.02203

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.48033
Value Function Update Magnitude: 0.66088

Collected Steps per Second: 21,940.33765
Overall Steps per Second: 10,542.44562

Timestep Collection Time: 2.28037
Timestep Consumption Time: 2.46540
PPO Batch Consumption Time: 0.28453
Total Iteration Time: 4.74577

Cumulative Model Updates: 314,590
Cumulative Timesteps: 2,623,627,176

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2623627176...
Checkpoint 2623627176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.78395
Policy Entropy: 2.49290
Value Function Loss: 0.02153

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.07537
Policy Update Magnitude: 0.47880
Value Function Update Magnitude: 0.65920

Collected Steps per Second: 21,710.17914
Overall Steps per Second: 10,540.88998

Timestep Collection Time: 2.30334
Timestep Consumption Time: 2.44066
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.74400

Cumulative Model Updates: 314,596
Cumulative Timesteps: 2,623,677,182

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.90623
Policy Entropy: 2.50354
Value Function Loss: 0.02151

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.08038
Policy Update Magnitude: 0.49210
Value Function Update Magnitude: 0.67959

Collected Steps per Second: 21,898.59132
Overall Steps per Second: 10,490.14706

Timestep Collection Time: 2.28389
Timestep Consumption Time: 2.48382
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.76771

Cumulative Model Updates: 314,602
Cumulative Timesteps: 2,623,727,196

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2623727196...
Checkpoint 2623727196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.53136
Policy Entropy: 2.48690
Value Function Loss: 0.02142

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.07991
Policy Update Magnitude: 0.49862
Value Function Update Magnitude: 0.68668

Collected Steps per Second: 21,824.76651
Overall Steps per Second: 10,625.05652

Timestep Collection Time: 2.29226
Timestep Consumption Time: 2.41623
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.70849

Cumulative Model Updates: 314,608
Cumulative Timesteps: 2,623,777,224

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.16727
Policy Entropy: 2.50002
Value Function Loss: 0.01978

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.08440
Policy Update Magnitude: 0.49548
Value Function Update Magnitude: 0.67804

Collected Steps per Second: 23,056.55540
Overall Steps per Second: 10,699.99754

Timestep Collection Time: 2.16927
Timestep Consumption Time: 2.50512
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.67439

Cumulative Model Updates: 314,614
Cumulative Timesteps: 2,623,827,240

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2623827240...
Checkpoint 2623827240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.79733
Policy Entropy: 2.49231
Value Function Loss: 0.01922

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.08997
Policy Update Magnitude: 0.48026
Value Function Update Magnitude: 0.66722

Collected Steps per Second: 22,318.37086
Overall Steps per Second: 10,457.79719

Timestep Collection Time: 2.24111
Timestep Consumption Time: 2.54173
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.78284

Cumulative Model Updates: 314,620
Cumulative Timesteps: 2,623,877,258

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.41030
Policy Entropy: 2.48580
Value Function Loss: 0.01959

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.09395
Policy Update Magnitude: 0.46653
Value Function Update Magnitude: 0.63026

Collected Steps per Second: 22,490.86132
Overall Steps per Second: 10,783.14341

Timestep Collection Time: 2.22428
Timestep Consumption Time: 2.41500
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.63928

Cumulative Model Updates: 314,626
Cumulative Timesteps: 2,623,927,284

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2623927284...
Checkpoint 2623927284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.77868
Policy Entropy: 2.46689
Value Function Loss: 0.02049

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.08740
Policy Update Magnitude: 0.47372
Value Function Update Magnitude: 0.61739

Collected Steps per Second: 22,081.40901
Overall Steps per Second: 10,727.34519

Timestep Collection Time: 2.26489
Timestep Consumption Time: 2.39721
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.66210

Cumulative Model Updates: 314,632
Cumulative Timesteps: 2,623,977,296

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.12561
Policy Entropy: 2.47876
Value Function Loss: 0.02136

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.09498
Policy Update Magnitude: 0.47596
Value Function Update Magnitude: 0.63687

Collected Steps per Second: 22,410.85528
Overall Steps per Second: 10,572.46173

Timestep Collection Time: 2.23178
Timestep Consumption Time: 2.49901
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.73078

Cumulative Model Updates: 314,638
Cumulative Timesteps: 2,624,027,312

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2624027312...
Checkpoint 2624027312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.78116
Policy Entropy: 2.49180
Value Function Loss: 0.02071

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.46560
Value Function Update Magnitude: 0.65838

Collected Steps per Second: 22,394.87532
Overall Steps per Second: 10,539.66263

Timestep Collection Time: 2.23346
Timestep Consumption Time: 2.51224
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.74569

Cumulative Model Updates: 314,644
Cumulative Timesteps: 2,624,077,330

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.85307
Policy Entropy: 2.47843
Value Function Loss: 0.02179

Mean KL Divergence: 0.02112
SB3 Clip Fraction: 0.12766
Policy Update Magnitude: 0.46084
Value Function Update Magnitude: 0.66761

Collected Steps per Second: 22,331.72472
Overall Steps per Second: 10,633.61586

Timestep Collection Time: 2.24013
Timestep Consumption Time: 2.46438
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.70451

Cumulative Model Updates: 314,650
Cumulative Timesteps: 2,624,127,356

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2624127356...
Checkpoint 2624127356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.22206
Policy Entropy: 2.47253
Value Function Loss: 0.02052

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.11902
Policy Update Magnitude: 0.47038
Value Function Update Magnitude: 0.66856

Collected Steps per Second: 22,339.51760
Overall Steps per Second: 10,891.32253

Timestep Collection Time: 2.23819
Timestep Consumption Time: 2.35262
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.59081

Cumulative Model Updates: 314,656
Cumulative Timesteps: 2,624,177,356

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.72793
Policy Entropy: 2.45311
Value Function Loss: 0.02003

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.10970
Policy Update Magnitude: 0.48183
Value Function Update Magnitude: 0.67261

Collected Steps per Second: 22,031.39780
Overall Steps per Second: 10,513.71511

Timestep Collection Time: 2.26958
Timestep Consumption Time: 2.48630
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.75588

Cumulative Model Updates: 314,662
Cumulative Timesteps: 2,624,227,358

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2624227358...
Checkpoint 2624227358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.92563
Policy Entropy: 2.46962
Value Function Loss: 0.01921

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.09549
Policy Update Magnitude: 0.48476
Value Function Update Magnitude: 0.65316

Collected Steps per Second: 21,891.76252
Overall Steps per Second: 10,596.49788

Timestep Collection Time: 2.28488
Timestep Consumption Time: 2.43555
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.72043

Cumulative Model Updates: 314,668
Cumulative Timesteps: 2,624,277,378

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.47529
Policy Entropy: 2.44676
Value Function Loss: 0.02151

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.08936
Policy Update Magnitude: 0.48228
Value Function Update Magnitude: 0.63617

Collected Steps per Second: 21,009.74214
Overall Steps per Second: 10,180.21509

Timestep Collection Time: 2.38051
Timestep Consumption Time: 2.53235
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.91286

Cumulative Model Updates: 314,674
Cumulative Timesteps: 2,624,327,392

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2624327392...
Checkpoint 2624327392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.18869
Policy Entropy: 2.44830
Value Function Loss: 0.02201

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.09154
Policy Update Magnitude: 0.48920
Value Function Update Magnitude: 0.65039

Collected Steps per Second: 21,827.50683
Overall Steps per Second: 10,595.58066

Timestep Collection Time: 2.29124
Timestep Consumption Time: 2.42884
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.72008

Cumulative Model Updates: 314,680
Cumulative Timesteps: 2,624,377,404

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.96926
Policy Entropy: 2.43809
Value Function Loss: 0.02169

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.09263
Policy Update Magnitude: 0.49510
Value Function Update Magnitude: 0.66837

Collected Steps per Second: 22,091.71498
Overall Steps per Second: 10,519.09187

Timestep Collection Time: 2.26438
Timestep Consumption Time: 2.49117
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.75554

Cumulative Model Updates: 314,686
Cumulative Timesteps: 2,624,427,428

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2624427428...
Checkpoint 2624427428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.89274
Policy Entropy: 2.45281
Value Function Loss: 0.02078

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.09197
Policy Update Magnitude: 0.48441
Value Function Update Magnitude: 0.66758

Collected Steps per Second: 22,120.99495
Overall Steps per Second: 10,521.31563

Timestep Collection Time: 2.26210
Timestep Consumption Time: 2.49395
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.75606

Cumulative Model Updates: 314,692
Cumulative Timesteps: 2,624,477,468

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.72980
Policy Entropy: 2.46882
Value Function Loss: 0.02079

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.09734
Policy Update Magnitude: 0.47881
Value Function Update Magnitude: 0.66775

Collected Steps per Second: 22,253.67274
Overall Steps per Second: 10,452.53117

Timestep Collection Time: 2.24826
Timestep Consumption Time: 2.53833
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.78659

Cumulative Model Updates: 314,698
Cumulative Timesteps: 2,624,527,500

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2624527500...
Checkpoint 2624527500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.55446
Policy Entropy: 2.49643
Value Function Loss: 0.02025

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.47358
Value Function Update Magnitude: 0.66618

Collected Steps per Second: 22,141.44080
Overall Steps per Second: 10,646.61999

Timestep Collection Time: 2.25929
Timestep Consumption Time: 2.43929
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.69858

Cumulative Model Updates: 314,704
Cumulative Timesteps: 2,624,577,524

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.67270
Policy Entropy: 2.50005
Value Function Loss: 0.01979

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.08915
Policy Update Magnitude: 0.47246
Value Function Update Magnitude: 0.65460

Collected Steps per Second: 22,491.97867
Overall Steps per Second: 10,611.21588

Timestep Collection Time: 2.22373
Timestep Consumption Time: 2.48978
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.71350

Cumulative Model Updates: 314,710
Cumulative Timesteps: 2,624,627,540

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2624627540...
Checkpoint 2624627540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.44330
Policy Entropy: 2.48853
Value Function Loss: 0.01956

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.47864
Value Function Update Magnitude: 0.66389

Collected Steps per Second: 21,395.08976
Overall Steps per Second: 10,479.64309

Timestep Collection Time: 2.33708
Timestep Consumption Time: 2.43427
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.77135

Cumulative Model Updates: 314,716
Cumulative Timesteps: 2,624,677,542

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.26720
Policy Entropy: 2.46885
Value Function Loss: 0.02064

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.08278
Policy Update Magnitude: 0.48709
Value Function Update Magnitude: 0.66816

Collected Steps per Second: 22,131.54351
Overall Steps per Second: 10,547.94228

Timestep Collection Time: 2.26048
Timestep Consumption Time: 2.48243
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.74292

Cumulative Model Updates: 314,722
Cumulative Timesteps: 2,624,727,570

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2624727570...
Checkpoint 2624727570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.48094
Policy Entropy: 2.45811
Value Function Loss: 0.02172

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.08669
Policy Update Magnitude: 0.49368
Value Function Update Magnitude: 0.69525

Collected Steps per Second: 23,089.89241
Overall Steps per Second: 10,903.18692

Timestep Collection Time: 2.16606
Timestep Consumption Time: 2.42104
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.58710

Cumulative Model Updates: 314,728
Cumulative Timesteps: 2,624,777,584

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.15616
Policy Entropy: 2.47358
Value Function Loss: 0.02163

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 0.48513
Value Function Update Magnitude: 0.69106

Collected Steps per Second: 22,302.91414
Overall Steps per Second: 10,532.14457

Timestep Collection Time: 2.24222
Timestep Consumption Time: 2.50591
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.74813

Cumulative Model Updates: 314,734
Cumulative Timesteps: 2,624,827,592

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2624827592...
Checkpoint 2624827592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.03689
Policy Entropy: 2.47550
Value Function Loss: 0.02177

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.48406
Value Function Update Magnitude: 0.66198

Collected Steps per Second: 21,663.01711
Overall Steps per Second: 10,601.03569

Timestep Collection Time: 2.30854
Timestep Consumption Time: 2.40892
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.71746

Cumulative Model Updates: 314,740
Cumulative Timesteps: 2,624,877,602

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.40151
Policy Entropy: 2.47230
Value Function Loss: 0.02193

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.08716
Policy Update Magnitude: 0.48008
Value Function Update Magnitude: 0.64282

Collected Steps per Second: 21,627.78609
Overall Steps per Second: 10,488.82528

Timestep Collection Time: 2.31212
Timestep Consumption Time: 2.45543
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.76755

Cumulative Model Updates: 314,746
Cumulative Timesteps: 2,624,927,608

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2624927608...
Checkpoint 2624927608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.56241
Policy Entropy: 2.45522
Value Function Loss: 0.02133

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.09352
Policy Update Magnitude: 0.47968
Value Function Update Magnitude: 0.66082

Collected Steps per Second: 22,164.24757
Overall Steps per Second: 10,697.23734

Timestep Collection Time: 2.25643
Timestep Consumption Time: 2.41880
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.67523

Cumulative Model Updates: 314,752
Cumulative Timesteps: 2,624,977,620

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.51860
Policy Entropy: 2.45373
Value Function Loss: 0.02030

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.49144
Value Function Update Magnitude: 0.66248

Collected Steps per Second: 22,072.29834
Overall Steps per Second: 10,461.60536

Timestep Collection Time: 2.26528
Timestep Consumption Time: 2.51410
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.77938

Cumulative Model Updates: 314,758
Cumulative Timesteps: 2,625,027,620

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2625027620...
Checkpoint 2625027620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.29183
Policy Entropy: 2.45008
Value Function Loss: 0.02037

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.09848
Policy Update Magnitude: 0.47550
Value Function Update Magnitude: 0.65504

Collected Steps per Second: 21,911.17677
Overall Steps per Second: 10,582.12117

Timestep Collection Time: 2.28285
Timestep Consumption Time: 2.44399
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.72684

Cumulative Model Updates: 314,764
Cumulative Timesteps: 2,625,077,640

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.14686
Policy Entropy: 2.45789
Value Function Loss: 0.02107

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.10073
Policy Update Magnitude: 0.47325
Value Function Update Magnitude: 0.64916

Collected Steps per Second: 22,463.84938
Overall Steps per Second: 10,793.75714

Timestep Collection Time: 2.22580
Timestep Consumption Time: 2.40651
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.63231

Cumulative Model Updates: 314,770
Cumulative Timesteps: 2,625,127,640

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2625127640...
Checkpoint 2625127640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.03311
Policy Entropy: 2.44525
Value Function Loss: 0.02215

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.09970
Policy Update Magnitude: 0.49278
Value Function Update Magnitude: 0.65483

Collected Steps per Second: 22,126.58424
Overall Steps per Second: 10,659.72437

Timestep Collection Time: 2.25973
Timestep Consumption Time: 2.43083
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.69055

Cumulative Model Updates: 314,776
Cumulative Timesteps: 2,625,177,640

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.91036
Policy Entropy: 2.44003
Value Function Loss: 0.02192

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.09205
Policy Update Magnitude: 0.48873
Value Function Update Magnitude: 0.67230

Collected Steps per Second: 22,357.71695
Overall Steps per Second: 10,528.90055

Timestep Collection Time: 2.23735
Timestep Consumption Time: 2.51358
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.75092

Cumulative Model Updates: 314,782
Cumulative Timesteps: 2,625,227,662

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2625227662...
Checkpoint 2625227662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.67512
Policy Entropy: 2.42700
Value Function Loss: 0.02255

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.09692
Policy Update Magnitude: 0.49397
Value Function Update Magnitude: 0.67492

Collected Steps per Second: 21,808.33664
Overall Steps per Second: 10,623.55037

Timestep Collection Time: 2.29362
Timestep Consumption Time: 2.41479
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.70841

Cumulative Model Updates: 314,788
Cumulative Timesteps: 2,625,277,682

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.01636
Policy Entropy: 2.45465
Value Function Loss: 0.02218

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.49265
Value Function Update Magnitude: 0.67204

Collected Steps per Second: 22,421.28438
Overall Steps per Second: 10,841.88762

Timestep Collection Time: 2.23020
Timestep Consumption Time: 2.38191
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.61211

Cumulative Model Updates: 314,794
Cumulative Timesteps: 2,625,327,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2625327686...
Checkpoint 2625327686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.56085
Policy Entropy: 2.45868
Value Function Loss: 0.02179

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.49102
Value Function Update Magnitude: 0.68684

Collected Steps per Second: 22,039.55513
Overall Steps per Second: 10,640.98805

Timestep Collection Time: 2.26937
Timestep Consumption Time: 2.43094
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.70032

Cumulative Model Updates: 314,800
Cumulative Timesteps: 2,625,377,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.09932
Policy Entropy: 2.47806
Value Function Loss: 0.02085

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.09189
Policy Update Magnitude: 0.48488
Value Function Update Magnitude: 0.66944

Collected Steps per Second: 22,076.19147
Overall Steps per Second: 10,565.35777

Timestep Collection Time: 2.26525
Timestep Consumption Time: 2.46796
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.73320

Cumulative Model Updates: 314,806
Cumulative Timesteps: 2,625,427,710

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2625427710...
Checkpoint 2625427710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.16368
Policy Entropy: 2.47206
Value Function Loss: 0.02078

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.48549
Value Function Update Magnitude: 0.66782

Collected Steps per Second: 21,680.33190
Overall Steps per Second: 10,599.38656

Timestep Collection Time: 2.30744
Timestep Consumption Time: 2.41227
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.71971

Cumulative Model Updates: 314,812
Cumulative Timesteps: 2,625,477,736

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.98515
Policy Entropy: 2.48307
Value Function Loss: 0.02019

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.10009
Policy Update Magnitude: 0.47995
Value Function Update Magnitude: 0.65970

Collected Steps per Second: 22,102.86565
Overall Steps per Second: 10,675.85783

Timestep Collection Time: 2.26287
Timestep Consumption Time: 2.42209
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.68496

Cumulative Model Updates: 314,818
Cumulative Timesteps: 2,625,527,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2625527752...
Checkpoint 2625527752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.18057
Policy Entropy: 2.49747
Value Function Loss: 0.01981

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.47063
Value Function Update Magnitude: 0.64801

Collected Steps per Second: 22,005.95537
Overall Steps per Second: 10,423.75432

Timestep Collection Time: 2.27220
Timestep Consumption Time: 2.52473
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.79693

Cumulative Model Updates: 314,824
Cumulative Timesteps: 2,625,577,754

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.55023
Policy Entropy: 2.48666
Value Function Loss: 0.02048

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.08884
Policy Update Magnitude: 0.46633
Value Function Update Magnitude: 0.64862

Collected Steps per Second: 22,056.29555
Overall Steps per Second: 10,462.72135

Timestep Collection Time: 2.26756
Timestep Consumption Time: 2.51265
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.78021

Cumulative Model Updates: 314,830
Cumulative Timesteps: 2,625,627,768

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2625627768...
Checkpoint 2625627768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.35079
Policy Entropy: 2.50142
Value Function Loss: 0.02125

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.09304
Policy Update Magnitude: 0.47628
Value Function Update Magnitude: 0.64789

Collected Steps per Second: 21,949.75315
Overall Steps per Second: 10,656.79663

Timestep Collection Time: 2.27875
Timestep Consumption Time: 2.41478
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.69353

Cumulative Model Updates: 314,836
Cumulative Timesteps: 2,625,677,786

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.95092
Policy Entropy: 2.49523
Value Function Loss: 0.02156

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.08458
Policy Update Magnitude: 0.48624
Value Function Update Magnitude: 0.65796

Collected Steps per Second: 22,162.60533
Overall Steps per Second: 10,423.66535

Timestep Collection Time: 2.25659
Timestep Consumption Time: 2.54133
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.79793

Cumulative Model Updates: 314,842
Cumulative Timesteps: 2,625,727,798

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2625727798...
Checkpoint 2625727798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.61635
Policy Entropy: 2.49481
Value Function Loss: 0.02216

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.09243
Policy Update Magnitude: 0.48800
Value Function Update Magnitude: 0.66426

Collected Steps per Second: 22,515.84197
Overall Steps per Second: 10,689.42679

Timestep Collection Time: 2.22172
Timestep Consumption Time: 2.45804
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.67976

Cumulative Model Updates: 314,848
Cumulative Timesteps: 2,625,777,822

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.97546
Policy Entropy: 2.46842
Value Function Loss: 0.02202

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.09087
Policy Update Magnitude: 0.48150
Value Function Update Magnitude: 0.65813

Collected Steps per Second: 22,527.91280
Overall Steps per Second: 10,623.24991

Timestep Collection Time: 2.22080
Timestep Consumption Time: 2.48868
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.70948

Cumulative Model Updates: 314,854
Cumulative Timesteps: 2,625,827,852

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2625827852...
Checkpoint 2625827852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.51115
Policy Entropy: 2.45981
Value Function Loss: 0.02155

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.09338
Policy Update Magnitude: 0.49024
Value Function Update Magnitude: 0.64831

Collected Steps per Second: 22,328.32401
Overall Steps per Second: 10,649.82153

Timestep Collection Time: 2.24074
Timestep Consumption Time: 2.45718
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.69792

Cumulative Model Updates: 314,860
Cumulative Timesteps: 2,625,877,884

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.05562
Policy Entropy: 2.46831
Value Function Loss: 0.02090

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.48644
Value Function Update Magnitude: 0.63631

Collected Steps per Second: 22,135.26874
Overall Steps per Second: 10,705.22253

Timestep Collection Time: 2.25947
Timestep Consumption Time: 2.41245
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.67193

Cumulative Model Updates: 314,866
Cumulative Timesteps: 2,625,927,898

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2625927898...
Checkpoint 2625927898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.71839
Policy Entropy: 2.47174
Value Function Loss: 0.02070

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.08156
Policy Update Magnitude: 0.48021
Value Function Update Magnitude: 0.63517

Collected Steps per Second: 22,319.92415
Overall Steps per Second: 10,641.38101

Timestep Collection Time: 2.24042
Timestep Consumption Time: 2.45878
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.69920

Cumulative Model Updates: 314,872
Cumulative Timesteps: 2,625,977,904

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.43620
Policy Entropy: 2.46763
Value Function Loss: 0.02111

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.08432
Policy Update Magnitude: 0.47989
Value Function Update Magnitude: 0.65098

Collected Steps per Second: 22,167.16178
Overall Steps per Second: 10,505.72031

Timestep Collection Time: 2.25667
Timestep Consumption Time: 2.50493
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.76160

Cumulative Model Updates: 314,878
Cumulative Timesteps: 2,626,027,928

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2626027928...
Checkpoint 2626027928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.29549
Policy Entropy: 2.47499
Value Function Loss: 0.02087

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.08167
Policy Update Magnitude: 0.47963
Value Function Update Magnitude: 0.65255

Collected Steps per Second: 22,069.61363
Overall Steps per Second: 10,612.40057

Timestep Collection Time: 2.26610
Timestep Consumption Time: 2.44650
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.71260

Cumulative Model Updates: 314,884
Cumulative Timesteps: 2,626,077,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.61123
Policy Entropy: 2.49590
Value Function Loss: 0.02150

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.07810
Policy Update Magnitude: 0.48308
Value Function Update Magnitude: 0.65179

Collected Steps per Second: 21,831.47228
Overall Steps per Second: 10,635.59505

Timestep Collection Time: 2.29064
Timestep Consumption Time: 2.41131
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.70195

Cumulative Model Updates: 314,890
Cumulative Timesteps: 2,626,127,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2626127948...
Checkpoint 2626127948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.15043
Policy Entropy: 2.50224
Value Function Loss: 0.02144

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.07980
Policy Update Magnitude: 0.48494
Value Function Update Magnitude: 0.66067

Collected Steps per Second: 22,037.33224
Overall Steps per Second: 10,463.08634

Timestep Collection Time: 2.26942
Timestep Consumption Time: 2.51043
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.77985

Cumulative Model Updates: 314,896
Cumulative Timesteps: 2,626,177,960

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.90815
Policy Entropy: 2.47887
Value Function Loss: 0.02352

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.08748
Policy Update Magnitude: 0.48831
Value Function Update Magnitude: 0.67946

Collected Steps per Second: 20,842.93586
Overall Steps per Second: 10,160.23238

Timestep Collection Time: 2.39976
Timestep Consumption Time: 2.52316
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.92292

Cumulative Model Updates: 314,902
Cumulative Timesteps: 2,626,227,978

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2626227978...
Checkpoint 2626227978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.42799
Policy Entropy: 2.47968
Value Function Loss: 0.02343

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.09432
Policy Update Magnitude: 0.48182
Value Function Update Magnitude: 0.69144

Collected Steps per Second: 22,514.55695
Overall Steps per Second: 10,618.26870

Timestep Collection Time: 2.22212
Timestep Consumption Time: 2.48957
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.71169

Cumulative Model Updates: 314,908
Cumulative Timesteps: 2,626,278,008

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.20116
Policy Entropy: 2.47565
Value Function Loss: 0.02276

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.11358
Policy Update Magnitude: 0.47281
Value Function Update Magnitude: 0.69760

Collected Steps per Second: 23,056.16299
Overall Steps per Second: 10,789.89219

Timestep Collection Time: 2.16966
Timestep Consumption Time: 2.46653
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.63619

Cumulative Model Updates: 314,914
Cumulative Timesteps: 2,626,328,032

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2626328032...
Checkpoint 2626328032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.65729
Policy Entropy: 2.49663
Value Function Loss: 0.02139

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.10505
Policy Update Magnitude: 0.44536
Value Function Update Magnitude: 0.68269

Collected Steps per Second: 22,313.59317
Overall Steps per Second: 10,600.18031

Timestep Collection Time: 2.24115
Timestep Consumption Time: 2.47651
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.71766

Cumulative Model Updates: 314,920
Cumulative Timesteps: 2,626,378,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.84243
Policy Entropy: 2.51494
Value Function Loss: 0.02017

Mean KL Divergence: 0.02148
SB3 Clip Fraction: 0.10782
Policy Update Magnitude: 0.45720
Value Function Update Magnitude: 0.66002

Collected Steps per Second: 22,247.41097
Overall Steps per Second: 10,480.03693

Timestep Collection Time: 2.24871
Timestep Consumption Time: 2.52494
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.77365

Cumulative Model Updates: 314,926
Cumulative Timesteps: 2,626,428,068

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2626428068...
Checkpoint 2626428068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.88102
Policy Entropy: 2.51381
Value Function Loss: 0.02130

Mean KL Divergence: 0.02197
SB3 Clip Fraction: 0.11230
Policy Update Magnitude: 0.47168
Value Function Update Magnitude: 0.65148

Collected Steps per Second: 22,317.09588
Overall Steps per Second: 10,677.67452

Timestep Collection Time: 2.24106
Timestep Consumption Time: 2.44292
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.68398

Cumulative Model Updates: 314,932
Cumulative Timesteps: 2,626,478,082

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.24152
Policy Entropy: 2.50348
Value Function Loss: 0.02114

Mean KL Divergence: 0.02413
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.46399
Value Function Update Magnitude: 0.66805

Collected Steps per Second: 23,049.39134
Overall Steps per Second: 10,841.61940

Timestep Collection Time: 2.16978
Timestep Consumption Time: 2.44319
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.61296

Cumulative Model Updates: 314,938
Cumulative Timesteps: 2,626,528,094

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2626528094...
Checkpoint 2626528094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.56003
Policy Entropy: 2.51505
Value Function Loss: 0.02045

Mean KL Divergence: 0.02339
SB3 Clip Fraction: 0.13525
Policy Update Magnitude: 0.46420
Value Function Update Magnitude: 0.66873

Collected Steps per Second: 22,124.41167
Overall Steps per Second: 10,651.59469

Timestep Collection Time: 2.25995
Timestep Consumption Time: 2.43419
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.69413

Cumulative Model Updates: 314,944
Cumulative Timesteps: 2,626,578,094

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.09954
Policy Entropy: 2.52297
Value Function Loss: 0.02008

Mean KL Divergence: 0.02537
SB3 Clip Fraction: 0.13869
Policy Update Magnitude: 0.44270
Value Function Update Magnitude: 0.67200

Collected Steps per Second: 21,706.07021
Overall Steps per Second: 10,517.74405

Timestep Collection Time: 2.30442
Timestep Consumption Time: 2.45135
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.75577

Cumulative Model Updates: 314,950
Cumulative Timesteps: 2,626,628,114

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2626628114...
Checkpoint 2626628114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.23273
Policy Entropy: 2.52366
Value Function Loss: 0.02103

Mean KL Divergence: 0.02343
SB3 Clip Fraction: 0.13421
Policy Update Magnitude: 0.46273
Value Function Update Magnitude: 0.66058

Collected Steps per Second: 21,857.09146
Overall Steps per Second: 10,658.26599

Timestep Collection Time: 2.28814
Timestep Consumption Time: 2.40418
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.69232

Cumulative Model Updates: 314,956
Cumulative Timesteps: 2,626,678,126

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.26774
Policy Entropy: 2.48205
Value Function Loss: 0.02168

Mean KL Divergence: 0.02320
SB3 Clip Fraction: 0.13682
Policy Update Magnitude: 0.46693
Value Function Update Magnitude: 0.66925

Collected Steps per Second: 22,008.68780
Overall Steps per Second: 10,426.05756

Timestep Collection Time: 2.27192
Timestep Consumption Time: 2.52395
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.79587

Cumulative Model Updates: 314,962
Cumulative Timesteps: 2,626,728,128

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2626728128...
Checkpoint 2626728128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.85207
Policy Entropy: 2.48051
Value Function Loss: 0.02052

Mean KL Divergence: 0.02614
SB3 Clip Fraction: 0.13690
Policy Update Magnitude: 0.45840
Value Function Update Magnitude: 0.66275

Collected Steps per Second: 21,908.48322
Overall Steps per Second: 10,597.20126

Timestep Collection Time: 2.28286
Timestep Consumption Time: 2.43669
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.71955

Cumulative Model Updates: 314,968
Cumulative Timesteps: 2,626,778,142

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.60175
Policy Entropy: 2.48595
Value Function Loss: 0.02083

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.11780
Policy Update Magnitude: 0.46118
Value Function Update Magnitude: 0.63997

Collected Steps per Second: 22,058.18191
Overall Steps per Second: 10,509.05474

Timestep Collection Time: 2.26791
Timestep Consumption Time: 2.49236
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.76028

Cumulative Model Updates: 314,974
Cumulative Timesteps: 2,626,828,168

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2626828168...
Checkpoint 2626828168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.70701
Policy Entropy: 2.49525
Value Function Loss: 0.02052

Mean KL Divergence: 0.02477
SB3 Clip Fraction: 0.14046
Policy Update Magnitude: 0.45531
Value Function Update Magnitude: 0.64575

Collected Steps per Second: 22,068.82095
Overall Steps per Second: 10,662.41795

Timestep Collection Time: 2.26691
Timestep Consumption Time: 2.42509
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.69199

Cumulative Model Updates: 314,980
Cumulative Timesteps: 2,626,878,196

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.14959
Policy Entropy: 2.46661
Value Function Loss: 0.02264

Mean KL Divergence: 0.02746
SB3 Clip Fraction: 0.15151
Policy Update Magnitude: 0.46768
Value Function Update Magnitude: 0.67218

Collected Steps per Second: 22,472.58570
Overall Steps per Second: 10,594.67845

Timestep Collection Time: 2.22529
Timestep Consumption Time: 2.49482
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.72011

Cumulative Model Updates: 314,986
Cumulative Timesteps: 2,626,928,204

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2626928204...
Checkpoint 2626928204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.20636
Policy Entropy: 2.46460
Value Function Loss: 0.02291

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.13638
Policy Update Magnitude: 0.49096
Value Function Update Magnitude: 0.71548

Collected Steps per Second: 22,587.94718
Overall Steps per Second: 10,607.41689

Timestep Collection Time: 2.21481
Timestep Consumption Time: 2.50151
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.71632

Cumulative Model Updates: 314,992
Cumulative Timesteps: 2,626,978,232

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.91809
Policy Entropy: 2.45272
Value Function Loss: 0.02379

Mean KL Divergence: 0.02682
SB3 Clip Fraction: 0.15971
Policy Update Magnitude: 0.48530
Value Function Update Magnitude: 0.71644

Collected Steps per Second: 22,111.37057
Overall Steps per Second: 10,707.21768

Timestep Collection Time: 2.26146
Timestep Consumption Time: 2.40866
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.67012

Cumulative Model Updates: 314,998
Cumulative Timesteps: 2,627,028,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2627028236...
Checkpoint 2627028236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.15249
Policy Entropy: 2.47304
Value Function Loss: 0.02393

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.47171
Value Function Update Magnitude: 0.70582

Collected Steps per Second: 22,335.82758
Overall Steps per Second: 10,719.15601

Timestep Collection Time: 2.23927
Timestep Consumption Time: 2.42677
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.66604

Cumulative Model Updates: 315,004
Cumulative Timesteps: 2,627,078,252

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.40130
Policy Entropy: 2.46824
Value Function Loss: 0.02336

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.11232
Policy Update Magnitude: 0.50375
Value Function Update Magnitude: 0.72846

Collected Steps per Second: 22,345.39727
Overall Steps per Second: 10,541.84257

Timestep Collection Time: 2.23822
Timestep Consumption Time: 2.50611
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.74433

Cumulative Model Updates: 315,010
Cumulative Timesteps: 2,627,128,266

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2627128266...
Checkpoint 2627128266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.54906
Policy Entropy: 2.47361
Value Function Loss: 0.02207

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.10497
Policy Update Magnitude: 0.50311
Value Function Update Magnitude: 0.71123

Collected Steps per Second: 22,184.49225
Overall Steps per Second: 10,558.03994

Timestep Collection Time: 2.25509
Timestep Consumption Time: 2.48329
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.73838

Cumulative Model Updates: 315,016
Cumulative Timesteps: 2,627,178,294

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.13736
Policy Entropy: 2.45616
Value Function Loss: 0.02196

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.49796
Value Function Update Magnitude: 0.69107

Collected Steps per Second: 21,582.90367
Overall Steps per Second: 10,442.36670

Timestep Collection Time: 2.31674
Timestep Consumption Time: 2.47164
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.78838

Cumulative Model Updates: 315,022
Cumulative Timesteps: 2,627,228,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2627228296...
Checkpoint 2627228296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.85296
Policy Entropy: 2.44501
Value Function Loss: 0.02221

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.50806
Value Function Update Magnitude: 0.67883

Collected Steps per Second: 21,793.82688
Overall Steps per Second: 10,674.78550

Timestep Collection Time: 2.29524
Timestep Consumption Time: 2.39076
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.68600

Cumulative Model Updates: 315,028
Cumulative Timesteps: 2,627,278,318

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.29187
Policy Entropy: 2.42760
Value Function Loss: 0.02238

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.08898
Policy Update Magnitude: 0.51126
Value Function Update Magnitude: 0.69462

Collected Steps per Second: 21,975.18609
Overall Steps per Second: 10,429.83750

Timestep Collection Time: 2.27538
Timestep Consumption Time: 2.51875
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.79413

Cumulative Model Updates: 315,034
Cumulative Timesteps: 2,627,328,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2627328320...
Checkpoint 2627328320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.16621
Policy Entropy: 2.42458
Value Function Loss: 0.02229

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.09465
Policy Update Magnitude: 0.50571
Value Function Update Magnitude: 0.71167

Collected Steps per Second: 21,865.65178
Overall Steps per Second: 10,597.03392

Timestep Collection Time: 2.28697
Timestep Consumption Time: 2.43190
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.71887

Cumulative Model Updates: 315,040
Cumulative Timesteps: 2,627,378,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.49806
Policy Entropy: 2.44356
Value Function Loss: 0.02231

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.08702
Policy Update Magnitude: 0.50677
Value Function Update Magnitude: 0.72013

Collected Steps per Second: 22,179.74676
Overall Steps per Second: 10,507.98966

Timestep Collection Time: 2.25521
Timestep Consumption Time: 2.50498
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.76019

Cumulative Model Updates: 315,046
Cumulative Timesteps: 2,627,428,346

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2627428346...
Checkpoint 2627428346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.53692
Policy Entropy: 2.46032
Value Function Loss: 0.02232

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.49850
Value Function Update Magnitude: 0.71849

Collected Steps per Second: 22,542.23232
Overall Steps per Second: 10,680.16330

Timestep Collection Time: 2.21868
Timestep Consumption Time: 2.46421
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.68289

Cumulative Model Updates: 315,052
Cumulative Timesteps: 2,627,478,360

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.81124
Policy Entropy: 2.47964
Value Function Loss: 0.02244

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.09091
Policy Update Magnitude: 0.49571
Value Function Update Magnitude: 0.71072

Collected Steps per Second: 22,548.48669
Overall Steps per Second: 10,738.25745

Timestep Collection Time: 2.21789
Timestep Consumption Time: 2.43929
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.65718

Cumulative Model Updates: 315,058
Cumulative Timesteps: 2,627,528,370

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2627528370...
Checkpoint 2627528370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.07899
Policy Entropy: 2.48710
Value Function Loss: 0.02219

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.09255
Policy Update Magnitude: 0.49955
Value Function Update Magnitude: 0.68100

Collected Steps per Second: 22,280.10889
Overall Steps per Second: 10,676.86253

Timestep Collection Time: 2.24469
Timestep Consumption Time: 2.43945
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.68415

Cumulative Model Updates: 315,064
Cumulative Timesteps: 2,627,578,382

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.29446
Policy Entropy: 2.47171
Value Function Loss: 0.02304

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.08971
Policy Update Magnitude: 0.48477
Value Function Update Magnitude: 0.65453

Collected Steps per Second: 22,477.58388
Overall Steps per Second: 10,612.94523

Timestep Collection Time: 2.22471
Timestep Consumption Time: 2.48709
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.71179

Cumulative Model Updates: 315,070
Cumulative Timesteps: 2,627,628,388

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2627628388...
Checkpoint 2627628388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.14579
Policy Entropy: 2.47268
Value Function Loss: 0.02240

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.08593
Policy Update Magnitude: 0.49031
Value Function Update Magnitude: 0.66044

Collected Steps per Second: 22,421.94170
Overall Steps per Second: 10,629.18788

Timestep Collection Time: 2.23121
Timestep Consumption Time: 2.47546
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.70666

Cumulative Model Updates: 315,076
Cumulative Timesteps: 2,627,678,416

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.67151
Policy Entropy: 2.46365
Value Function Loss: 0.02203

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.09171
Policy Update Magnitude: 0.49712
Value Function Update Magnitude: 0.66801

Collected Steps per Second: 22,439.41528
Overall Steps per Second: 10,833.55293

Timestep Collection Time: 2.22929
Timestep Consumption Time: 2.38821
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.61751

Cumulative Model Updates: 315,082
Cumulative Timesteps: 2,627,728,440

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2627728440...
Checkpoint 2627728440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.45354
Policy Entropy: 2.45333
Value Function Loss: 0.02205

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.09134
Policy Update Magnitude: 0.49583
Value Function Update Magnitude: 0.66846

Collected Steps per Second: 22,270.71335
Overall Steps per Second: 10,661.76050

Timestep Collection Time: 2.24591
Timestep Consumption Time: 2.44544
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.69135

Cumulative Model Updates: 315,088
Cumulative Timesteps: 2,627,778,458

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.76065
Policy Entropy: 2.45089
Value Function Loss: 0.02189

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.09346
Policy Update Magnitude: 0.48525
Value Function Update Magnitude: 0.66724

Collected Steps per Second: 21,845.88560
Overall Steps per Second: 10,449.45114

Timestep Collection Time: 2.28931
Timestep Consumption Time: 2.49678
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.78609

Cumulative Model Updates: 315,094
Cumulative Timesteps: 2,627,828,470

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2627828470...
Checkpoint 2627828470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.87587
Policy Entropy: 2.45807
Value Function Loss: 0.02216

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.08617
Policy Update Magnitude: 0.49049
Value Function Update Magnitude: 0.67748

Collected Steps per Second: 21,392.51044
Overall Steps per Second: 10,564.07716

Timestep Collection Time: 2.33820
Timestep Consumption Time: 2.39671
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.73491

Cumulative Model Updates: 315,100
Cumulative Timesteps: 2,627,878,490

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.72233
Policy Entropy: 2.48649
Value Function Loss: 0.02066

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.49261
Value Function Update Magnitude: 0.70844

Collected Steps per Second: 22,105.76259
Overall Steps per Second: 10,707.54274

Timestep Collection Time: 2.26276
Timestep Consumption Time: 2.40871
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.67147

Cumulative Model Updates: 315,106
Cumulative Timesteps: 2,627,928,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2627928510...
Checkpoint 2627928510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.64190
Policy Entropy: 2.49688
Value Function Loss: 0.02057

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.08634
Policy Update Magnitude: 0.48785
Value Function Update Magnitude: 0.71938

Collected Steps per Second: 22,162.57152
Overall Steps per Second: 10,516.45930

Timestep Collection Time: 2.25651
Timestep Consumption Time: 2.49890
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.75540

Cumulative Model Updates: 315,112
Cumulative Timesteps: 2,627,978,520

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.22825
Policy Entropy: 2.48833
Value Function Loss: 0.02112

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.49779
Value Function Update Magnitude: 0.68378

Collected Steps per Second: 21,908.64004
Overall Steps per Second: 10,426.46545

Timestep Collection Time: 2.28330
Timestep Consumption Time: 2.51449
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.79779

Cumulative Model Updates: 315,118
Cumulative Timesteps: 2,628,028,544

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2628028544...
Checkpoint 2628028544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.21148
Policy Entropy: 2.51413
Value Function Loss: 0.02093

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.49746
Value Function Update Magnitude: 0.65837

Collected Steps per Second: 21,574.52255
Overall Steps per Second: 10,510.89441

Timestep Collection Time: 2.31801
Timestep Consumption Time: 2.43991
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.75792

Cumulative Model Updates: 315,124
Cumulative Timesteps: 2,628,078,554

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.30715
Policy Entropy: 2.51014
Value Function Loss: 0.01996

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.08600
Policy Update Magnitude: 0.47785
Value Function Update Magnitude: 0.66416

Collected Steps per Second: 21,208.29968
Overall Steps per Second: 10,516.61908

Timestep Collection Time: 2.35785
Timestep Consumption Time: 2.39710
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.75495

Cumulative Model Updates: 315,130
Cumulative Timesteps: 2,628,128,560

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2628128560...
Checkpoint 2628128560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.12283
Policy Entropy: 2.53303
Value Function Loss: 0.01973

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.08590
Policy Update Magnitude: 0.48457
Value Function Update Magnitude: 0.66501

Collected Steps per Second: 22,346.92182
Overall Steps per Second: 10,672.56331

Timestep Collection Time: 2.23825
Timestep Consumption Time: 2.44835
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.68660

Cumulative Model Updates: 315,136
Cumulative Timesteps: 2,628,178,578

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.94794
Policy Entropy: 2.50768
Value Function Loss: 0.02034

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.08914
Policy Update Magnitude: 0.47989
Value Function Update Magnitude: 0.68076

Collected Steps per Second: 22,421.05113
Overall Steps per Second: 10,542.06612

Timestep Collection Time: 2.23014
Timestep Consumption Time: 2.51296
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.74309

Cumulative Model Updates: 315,142
Cumulative Timesteps: 2,628,228,580

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2628228580...
Checkpoint 2628228580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.47259
Policy Entropy: 2.53512
Value Function Loss: 0.02084

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.08351
Policy Update Magnitude: 0.49272
Value Function Update Magnitude: 0.69805

Collected Steps per Second: 22,250.78531
Overall Steps per Second: 10,561.64371

Timestep Collection Time: 2.24711
Timestep Consumption Time: 2.48700
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.73411

Cumulative Model Updates: 315,148
Cumulative Timesteps: 2,628,278,580

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.19068
Policy Entropy: 2.52713
Value Function Loss: 0.02043

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.08279
Policy Update Magnitude: 0.48852
Value Function Update Magnitude: 0.70907

Collected Steps per Second: 22,550.36486
Overall Steps per Second: 10,937.77911

Timestep Collection Time: 2.21841
Timestep Consumption Time: 2.35528
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.57369

Cumulative Model Updates: 315,154
Cumulative Timesteps: 2,628,328,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2628328606...
Checkpoint 2628328606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.31875
Policy Entropy: 2.52818
Value Function Loss: 0.02054

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.49349
Value Function Update Magnitude: 0.69460

Collected Steps per Second: 22,293.32906
Overall Steps per Second: 10,596.84052

Timestep Collection Time: 2.24354
Timestep Consumption Time: 2.47636
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.71990

Cumulative Model Updates: 315,160
Cumulative Timesteps: 2,628,378,622

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.84996
Policy Entropy: 2.50845
Value Function Loss: 0.02103

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.48824
Value Function Update Magnitude: 0.68479

Collected Steps per Second: 22,013.52487
Overall Steps per Second: 10,449.77298

Timestep Collection Time: 2.27179
Timestep Consumption Time: 2.51396
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.78575

Cumulative Model Updates: 315,166
Cumulative Timesteps: 2,628,428,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2628428632...
Checkpoint 2628428632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.58119
Policy Entropy: 2.49227
Value Function Loss: 0.02205

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.08746
Policy Update Magnitude: 0.49609
Value Function Update Magnitude: 0.69218

Collected Steps per Second: 21,981.11041
Overall Steps per Second: 10,663.24492

Timestep Collection Time: 2.27577
Timestep Consumption Time: 2.41548
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.69125

Cumulative Model Updates: 315,172
Cumulative Timesteps: 2,628,478,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.33208
Policy Entropy: 2.49406
Value Function Loss: 0.02293

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.08224
Policy Update Magnitude: 0.49965
Value Function Update Magnitude: 0.68410

Collected Steps per Second: 22,379.70606
Overall Steps per Second: 10,559.92087

Timestep Collection Time: 2.23542
Timestep Consumption Time: 2.50212
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.73754

Cumulative Model Updates: 315,178
Cumulative Timesteps: 2,628,528,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2628528684...
Checkpoint 2628528684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.22074
Policy Entropy: 2.48634
Value Function Loss: 0.02375

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.49645
Value Function Update Magnitude: 0.67064

Collected Steps per Second: 21,900.65765
Overall Steps per Second: 10,481.94505

Timestep Collection Time: 2.28404
Timestep Consumption Time: 2.48816
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.77221

Cumulative Model Updates: 315,184
Cumulative Timesteps: 2,628,578,706

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.98479
Policy Entropy: 2.49718
Value Function Loss: 0.02298

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.09018
Policy Update Magnitude: 0.49916
Value Function Update Magnitude: 0.67214

Collected Steps per Second: 22,551.34231
Overall Steps per Second: 10,573.11871

Timestep Collection Time: 2.21796
Timestep Consumption Time: 2.51271
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.73068

Cumulative Model Updates: 315,190
Cumulative Timesteps: 2,628,628,724

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2628628724...
Checkpoint 2628628724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.72218
Policy Entropy: 2.49063
Value Function Loss: 0.02192

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.09864
Policy Update Magnitude: 0.49123
Value Function Update Magnitude: 0.67548

Collected Steps per Second: 22,202.62508
Overall Steps per Second: 10,513.58658

Timestep Collection Time: 2.25226
Timestep Consumption Time: 2.50407
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.75632

Cumulative Model Updates: 315,196
Cumulative Timesteps: 2,628,678,730

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.08124
Policy Entropy: 2.49409
Value Function Loss: 0.02019

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.08710
Policy Update Magnitude: 0.48504
Value Function Update Magnitude: 0.65568

Collected Steps per Second: 23,368.87587
Overall Steps per Second: 10,930.21502

Timestep Collection Time: 2.14011
Timestep Consumption Time: 2.43546
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.57557

Cumulative Model Updates: 315,202
Cumulative Timesteps: 2,628,728,742

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2628728742...
Checkpoint 2628728742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.79792
Policy Entropy: 2.50895
Value Function Loss: 0.01898

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.08935
Policy Update Magnitude: 0.48055
Value Function Update Magnitude: 0.62730

Collected Steps per Second: 22,145.61428
Overall Steps per Second: 10,638.56667

Timestep Collection Time: 2.25869
Timestep Consumption Time: 2.44307
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.70176

Cumulative Model Updates: 315,208
Cumulative Timesteps: 2,628,778,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.82818
Policy Entropy: 2.53813
Value Function Loss: 0.01911

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.08917
Policy Update Magnitude: 0.48036
Value Function Update Magnitude: 0.63652

Collected Steps per Second: 22,592.32799
Overall Steps per Second: 10,559.05845

Timestep Collection Time: 2.21323
Timestep Consumption Time: 2.52223
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.73546

Cumulative Model Updates: 315,214
Cumulative Timesteps: 2,628,828,764

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2628828764...
Checkpoint 2628828764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.10007
Policy Entropy: 2.52711
Value Function Loss: 0.02041

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.08689
Policy Update Magnitude: 0.48818
Value Function Update Magnitude: 0.65060

Collected Steps per Second: 22,054.69738
Overall Steps per Second: 10,579.36334

Timestep Collection Time: 2.26782
Timestep Consumption Time: 2.45988
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.72769

Cumulative Model Updates: 315,220
Cumulative Timesteps: 2,628,878,780

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.95045
Policy Entropy: 2.52071
Value Function Loss: 0.01967

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.48147
Value Function Update Magnitude: 0.64082

Collected Steps per Second: 22,354.11576
Overall Steps per Second: 10,857.00049

Timestep Collection Time: 2.23780
Timestep Consumption Time: 2.36974
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.60753

Cumulative Model Updates: 315,226
Cumulative Timesteps: 2,628,928,804

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2628928804...
Checkpoint 2628928804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.79283
Policy Entropy: 2.51051
Value Function Loss: 0.01958

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.08761
Policy Update Magnitude: 0.47272
Value Function Update Magnitude: 0.62706

Collected Steps per Second: 21,825.32306
Overall Steps per Second: 10,586.77777

Timestep Collection Time: 2.29183
Timestep Consumption Time: 2.43293
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.72476

Cumulative Model Updates: 315,232
Cumulative Timesteps: 2,628,978,824

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.08481
Policy Entropy: 2.52816
Value Function Loss: 0.01864

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.09279
Policy Update Magnitude: 0.47267
Value Function Update Magnitude: 0.61478

Collected Steps per Second: 21,815.75063
Overall Steps per Second: 10,582.79975

Timestep Collection Time: 2.29293
Timestep Consumption Time: 2.43380
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.72673

Cumulative Model Updates: 315,238
Cumulative Timesteps: 2,629,028,846

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2629028846...
Checkpoint 2629028846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.16212
Policy Entropy: 2.52734
Value Function Loss: 0.02003

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.47815
Value Function Update Magnitude: 0.61922

Collected Steps per Second: 21,853.85596
Overall Steps per Second: 10,662.96563

Timestep Collection Time: 2.28976
Timestep Consumption Time: 2.40312
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.69288

Cumulative Model Updates: 315,244
Cumulative Timesteps: 2,629,078,886

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.23610
Policy Entropy: 2.52940
Value Function Loss: 0.02045

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.46687
Value Function Update Magnitude: 0.64102

Collected Steps per Second: 22,217.11882
Overall Steps per Second: 10,828.24465

Timestep Collection Time: 2.25079
Timestep Consumption Time: 2.36732
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.61811

Cumulative Model Updates: 315,250
Cumulative Timesteps: 2,629,128,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2629128892...
Checkpoint 2629128892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.03113
Policy Entropy: 2.53131
Value Function Loss: 0.02010

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.11978
Policy Update Magnitude: 0.46776
Value Function Update Magnitude: 0.63360

Collected Steps per Second: 22,075.80847
Overall Steps per Second: 10,591.05311

Timestep Collection Time: 2.26529
Timestep Consumption Time: 2.45644
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.72172

Cumulative Model Updates: 315,256
Cumulative Timesteps: 2,629,178,900

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.65060
Policy Entropy: 2.52919
Value Function Loss: 0.02017

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.45801
Value Function Update Magnitude: 0.62996

Collected Steps per Second: 22,420.27465
Overall Steps per Second: 10,419.00551

Timestep Collection Time: 2.23137
Timestep Consumption Time: 2.57024
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.80161

Cumulative Model Updates: 315,262
Cumulative Timesteps: 2,629,228,928

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2629228928...
Checkpoint 2629228928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.15536
Policy Entropy: 2.54325
Value Function Loss: 0.01885

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.11750
Policy Update Magnitude: 0.45933
Value Function Update Magnitude: 0.63201

Collected Steps per Second: 21,912.31281
Overall Steps per Second: 10,652.62855

Timestep Collection Time: 2.28255
Timestep Consumption Time: 2.41263
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.69518

Cumulative Model Updates: 315,268
Cumulative Timesteps: 2,629,278,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.70376
Policy Entropy: 2.53995
Value Function Loss: 0.01935

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.10774
Policy Update Magnitude: 0.47089
Value Function Update Magnitude: 0.63139

Collected Steps per Second: 22,578.22545
Overall Steps per Second: 10,911.26474

Timestep Collection Time: 2.21461
Timestep Consumption Time: 2.36799
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.58260

Cumulative Model Updates: 315,274
Cumulative Timesteps: 2,629,328,946

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2629328946...
Checkpoint 2629328946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.38537
Policy Entropy: 2.54433
Value Function Loss: 0.02031

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.09438
Policy Update Magnitude: 0.48441
Value Function Update Magnitude: 0.62996

Collected Steps per Second: 22,307.75615
Overall Steps per Second: 10,670.93453

Timestep Collection Time: 2.24236
Timestep Consumption Time: 2.44533
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.68769

Cumulative Model Updates: 315,280
Cumulative Timesteps: 2,629,378,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.81074
Policy Entropy: 2.54029
Value Function Loss: 0.02079

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.08511
Policy Update Magnitude: 0.48531
Value Function Update Magnitude: 0.66422

Collected Steps per Second: 22,231.82687
Overall Steps per Second: 10,527.11002

Timestep Collection Time: 2.24984
Timestep Consumption Time: 2.50151
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.75135

Cumulative Model Updates: 315,286
Cumulative Timesteps: 2,629,428,986

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2629428986...
Checkpoint 2629428986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.95236
Policy Entropy: 2.54112
Value Function Loss: 0.02030

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.08190
Policy Update Magnitude: 0.49101
Value Function Update Magnitude: 0.67721

Collected Steps per Second: 21,936.70136
Overall Steps per Second: 10,674.46165

Timestep Collection Time: 2.27947
Timestep Consumption Time: 2.40498
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.68445

Cumulative Model Updates: 315,292
Cumulative Timesteps: 2,629,478,990

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.01973
Policy Entropy: 2.55044
Value Function Loss: 0.01895

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.08599
Policy Update Magnitude: 0.48105
Value Function Update Magnitude: 0.65251

Collected Steps per Second: 22,424.65520
Overall Steps per Second: 10,903.70842

Timestep Collection Time: 2.23103
Timestep Consumption Time: 2.35732
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.58835

Cumulative Model Updates: 315,298
Cumulative Timesteps: 2,629,529,020

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2629529020...
Checkpoint 2629529020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.71904
Policy Entropy: 2.52106
Value Function Loss: 0.02022

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.08749
Policy Update Magnitude: 0.48738
Value Function Update Magnitude: 0.63923

Collected Steps per Second: 21,933.89949
Overall Steps per Second: 10,597.15235

Timestep Collection Time: 2.27967
Timestep Consumption Time: 2.43877
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.71844

Cumulative Model Updates: 315,304
Cumulative Timesteps: 2,629,579,022

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.28156
Policy Entropy: 2.50520
Value Function Loss: 0.02154

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.08743
Policy Update Magnitude: 0.49516
Value Function Update Magnitude: 0.65427

Collected Steps per Second: 22,132.55447
Overall Steps per Second: 10,484.22340

Timestep Collection Time: 2.25948
Timestep Consumption Time: 2.51036
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.76983

Cumulative Model Updates: 315,310
Cumulative Timesteps: 2,629,629,030

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2629629030...
Checkpoint 2629629030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.30492
Policy Entropy: 2.49532
Value Function Loss: 0.02229

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.50520
Value Function Update Magnitude: 0.66541

Collected Steps per Second: 21,857.67420
Overall Steps per Second: 10,558.45688

Timestep Collection Time: 2.28844
Timestep Consumption Time: 2.44899
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.73743

Cumulative Model Updates: 315,316
Cumulative Timesteps: 2,629,679,050

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.69179
Policy Entropy: 2.49564
Value Function Loss: 0.02280

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.09495
Policy Update Magnitude: 0.48685
Value Function Update Magnitude: 0.66761

Collected Steps per Second: 22,248.82071
Overall Steps per Second: 10,660.58467

Timestep Collection Time: 2.24758
Timestep Consumption Time: 2.44316
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.69074

Cumulative Model Updates: 315,322
Cumulative Timesteps: 2,629,729,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2629729056...
Checkpoint 2629729056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.26981
Policy Entropy: 2.51125
Value Function Loss: 0.02276

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.08741
Policy Update Magnitude: 0.49323
Value Function Update Magnitude: 0.66438

Collected Steps per Second: 22,423.25033
Overall Steps per Second: 10,526.37604

Timestep Collection Time: 2.23090
Timestep Consumption Time: 2.52135
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.75225

Cumulative Model Updates: 315,328
Cumulative Timesteps: 2,629,779,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.00321
Policy Entropy: 2.51344
Value Function Loss: 0.02279

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.09288
Policy Update Magnitude: 0.49290
Value Function Update Magnitude: 0.67246

Collected Steps per Second: 22,578.46300
Overall Steps per Second: 10,606.09738

Timestep Collection Time: 2.21592
Timestep Consumption Time: 2.50137
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.71729

Cumulative Model Updates: 315,334
Cumulative Timesteps: 2,629,829,112

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2629829112...
Checkpoint 2629829112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.42196
Policy Entropy: 2.51807
Value Function Loss: 0.02247

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.08485
Policy Update Magnitude: 0.48585
Value Function Update Magnitude: 0.67565

Collected Steps per Second: 22,290.68862
Overall Steps per Second: 10,600.04232

Timestep Collection Time: 2.24435
Timestep Consumption Time: 2.47526
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.71960

Cumulative Model Updates: 315,340
Cumulative Timesteps: 2,629,879,140

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.09577
Policy Entropy: 2.52616
Value Function Loss: 0.02106

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.08258
Policy Update Magnitude: 0.48245
Value Function Update Magnitude: 0.66642

Collected Steps per Second: 23,551.05740
Overall Steps per Second: 10,780.47366

Timestep Collection Time: 2.12373
Timestep Consumption Time: 2.51577
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.63950

Cumulative Model Updates: 315,346
Cumulative Timesteps: 2,629,929,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2629929156...
Checkpoint 2629929156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.95308
Policy Entropy: 2.50206
Value Function Loss: 0.02077

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.07968
Policy Update Magnitude: 0.48568
Value Function Update Magnitude: 0.65567

Collected Steps per Second: 22,258.37522
Overall Steps per Second: 10,591.54221

Timestep Collection Time: 2.24742
Timestep Consumption Time: 2.47559
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.72301

Cumulative Model Updates: 315,352
Cumulative Timesteps: 2,629,979,180

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.52934
Policy Entropy: 2.49096
Value Function Loss: 0.02101

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.09010
Policy Update Magnitude: 0.49257
Value Function Update Magnitude: 0.64272

Collected Steps per Second: 21,534.46265
Overall Steps per Second: 10,446.75699

Timestep Collection Time: 2.32242
Timestep Consumption Time: 2.46491
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.78732

Cumulative Model Updates: 315,358
Cumulative Timesteps: 2,630,029,192

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2630029192...
Checkpoint 2630029192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.89071
Policy Entropy: 2.45739
Value Function Loss: 0.02245

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.49265
Value Function Update Magnitude: 0.64216

Collected Steps per Second: 21,410.77376
Overall Steps per Second: 10,644.96741

Timestep Collection Time: 2.33602
Timestep Consumption Time: 2.36254
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.69856

Cumulative Model Updates: 315,364
Cumulative Timesteps: 2,630,079,208

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.18803
Policy Entropy: 2.45775
Value Function Loss: 0.02314

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.11569
Policy Update Magnitude: 0.46151
Value Function Update Magnitude: 0.65005

Collected Steps per Second: 22,230.13571
Overall Steps per Second: 10,502.59363

Timestep Collection Time: 2.25073
Timestep Consumption Time: 2.51324
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.76397

Cumulative Model Updates: 315,370
Cumulative Timesteps: 2,630,129,242

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2630129242...
Checkpoint 2630129242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.06325
Policy Entropy: 2.46708
Value Function Loss: 0.02240

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.12567
Policy Update Magnitude: 0.44018
Value Function Update Magnitude: 0.65895

Collected Steps per Second: 21,613.97640
Overall Steps per Second: 10,413.36225

Timestep Collection Time: 2.31369
Timestep Consumption Time: 2.48860
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.80229

Cumulative Model Updates: 315,376
Cumulative Timesteps: 2,630,179,250

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.97518
Policy Entropy: 2.49158
Value Function Loss: 0.02160

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.11040
Policy Update Magnitude: 0.49478
Value Function Update Magnitude: 0.66586

Collected Steps per Second: 22,278.40974
Overall Steps per Second: 10,663.60379

Timestep Collection Time: 2.24486
Timestep Consumption Time: 2.44511
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.68997

Cumulative Model Updates: 315,382
Cumulative Timesteps: 2,630,229,262

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2630229262...
Checkpoint 2630229262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.05695
Policy Entropy: 2.51489
Value Function Loss: 0.02117

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.10904
Policy Update Magnitude: 0.50358
Value Function Update Magnitude: 0.64663

Collected Steps per Second: 21,397.56488
Overall Steps per Second: 10,627.15020

Timestep Collection Time: 2.33699
Timestep Consumption Time: 2.36850
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.70549

Cumulative Model Updates: 315,388
Cumulative Timesteps: 2,630,279,268

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.50144
Policy Entropy: 2.51968
Value Function Loss: 0.02051

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.11321
Policy Update Magnitude: 0.48335
Value Function Update Magnitude: 0.64744

Collected Steps per Second: 22,540.22718
Overall Steps per Second: 10,495.20955

Timestep Collection Time: 2.21897
Timestep Consumption Time: 2.54664
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.76560

Cumulative Model Updates: 315,394
Cumulative Timesteps: 2,630,329,284

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2630329284...
Checkpoint 2630329284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.88276
Policy Entropy: 2.51379
Value Function Loss: 0.02044

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.11336
Policy Update Magnitude: 0.49264
Value Function Update Magnitude: 0.66135

Collected Steps per Second: 22,045.44729
Overall Steps per Second: 10,576.59395

Timestep Collection Time: 2.26895
Timestep Consumption Time: 2.46036
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.72931

Cumulative Model Updates: 315,400
Cumulative Timesteps: 2,630,379,304

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.42341
Policy Entropy: 2.52755
Value Function Loss: 0.01899

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.10219
Policy Update Magnitude: 0.48357
Value Function Update Magnitude: 0.67419

Collected Steps per Second: 22,308.88880
Overall Steps per Second: 10,596.40391

Timestep Collection Time: 2.24162
Timestep Consumption Time: 2.47772
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.71934

Cumulative Model Updates: 315,406
Cumulative Timesteps: 2,630,429,312

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2630429312...
Checkpoint 2630429312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.99407
Policy Entropy: 2.53567
Value Function Loss: 0.01991

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.08750
Policy Update Magnitude: 0.47748
Value Function Update Magnitude: 0.68064

Collected Steps per Second: 22,281.05932
Overall Steps per Second: 10,669.32679

Timestep Collection Time: 2.24424
Timestep Consumption Time: 2.44247
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.68671

Cumulative Model Updates: 315,412
Cumulative Timesteps: 2,630,479,316

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.61060
Policy Entropy: 2.52601
Value Function Loss: 0.02111

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.08147
Policy Update Magnitude: 0.48945
Value Function Update Magnitude: 0.70064

Collected Steps per Second: 22,673.43980
Overall Steps per Second: 10,764.43854

Timestep Collection Time: 2.20522
Timestep Consumption Time: 2.43970
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.64492

Cumulative Model Updates: 315,418
Cumulative Timesteps: 2,630,529,316

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2630529316...
Checkpoint 2630529316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.04784
Policy Entropy: 2.51959
Value Function Loss: 0.02209

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.49824
Value Function Update Magnitude: 0.70950

Collected Steps per Second: 22,137.27830
Overall Steps per Second: 10,641.40454

Timestep Collection Time: 2.25909
Timestep Consumption Time: 2.44048
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.69957

Cumulative Model Updates: 315,424
Cumulative Timesteps: 2,630,579,326

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.71578
Policy Entropy: 2.50476
Value Function Loss: 0.02174

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.08151
Policy Update Magnitude: 0.49754
Value Function Update Magnitude: 0.70662

Collected Steps per Second: 22,328.66857
Overall Steps per Second: 10,554.74352

Timestep Collection Time: 2.23954
Timestep Consumption Time: 2.49823
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.73777

Cumulative Model Updates: 315,430
Cumulative Timesteps: 2,630,629,332

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2630629332...
Checkpoint 2630629332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169.44437
Policy Entropy: 2.47552
Value Function Loss: 0.02051

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.08490
Policy Update Magnitude: 0.49187
Value Function Update Magnitude: 0.71763

Collected Steps per Second: 20,559.31377
Overall Steps per Second: 10,203.63459

Timestep Collection Time: 2.43335
Timestep Consumption Time: 2.46961
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.90296

Cumulative Model Updates: 315,436
Cumulative Timesteps: 2,630,679,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.53978
Policy Entropy: 2.47081
Value Function Loss: 0.02067

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.08859
Policy Update Magnitude: 0.49883
Value Function Update Magnitude: 0.69768

Collected Steps per Second: 21,087.09874
Overall Steps per Second: 10,315.92037

Timestep Collection Time: 2.37254
Timestep Consumption Time: 2.47724
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.84979

Cumulative Model Updates: 315,442
Cumulative Timesteps: 2,630,729,390

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2630729390...
Checkpoint 2630729390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.09129
Policy Entropy: 2.45409
Value Function Loss: 0.02235

Mean KL Divergence: 0.02156
SB3 Clip Fraction: 0.11595
Policy Update Magnitude: 0.47562
Value Function Update Magnitude: 0.68544

Collected Steps per Second: 20,845.20206
Overall Steps per Second: 10,362.11492

Timestep Collection Time: 2.39969
Timestep Consumption Time: 2.42770
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.82739

Cumulative Model Updates: 315,448
Cumulative Timesteps: 2,630,779,412

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.95808
Policy Entropy: 2.48895
Value Function Loss: 0.02226

Mean KL Divergence: 0.03159
SB3 Clip Fraction: 0.15032
Policy Update Magnitude: 0.44137
Value Function Update Magnitude: 0.69390

Collected Steps per Second: 21,948.56170
Overall Steps per Second: 10,520.77123

Timestep Collection Time: 2.27805
Timestep Consumption Time: 2.47445
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.75250

Cumulative Model Updates: 315,454
Cumulative Timesteps: 2,630,829,412

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2630829412...
Checkpoint 2630829412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.65694
Policy Entropy: 2.48857
Value Function Loss: 0.02254

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.12254
Policy Update Magnitude: 0.46010
Value Function Update Magnitude: 0.70143

Collected Steps per Second: 21,673.89744
Overall Steps per Second: 10,566.26156

Timestep Collection Time: 2.30701
Timestep Consumption Time: 2.42522
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.73223

Cumulative Model Updates: 315,460
Cumulative Timesteps: 2,630,879,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.04064
Policy Entropy: 2.50047
Value Function Loss: 0.02154

Mean KL Divergence: 0.02241
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.46529
Value Function Update Magnitude: 0.68490

Collected Steps per Second: 21,567.01693
Overall Steps per Second: 10,416.07632

Timestep Collection Time: 2.31882
Timestep Consumption Time: 2.48241
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.80123

Cumulative Model Updates: 315,466
Cumulative Timesteps: 2,630,929,424

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2630929424...
Checkpoint 2630929424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.95632
Policy Entropy: 2.49660
Value Function Loss: 0.02140

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.11717
Policy Update Magnitude: 0.46639
Value Function Update Magnitude: 0.68612

Collected Steps per Second: 21,881.63606
Overall Steps per Second: 10,641.04407

Timestep Collection Time: 2.28548
Timestep Consumption Time: 2.41425
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.69973

Cumulative Model Updates: 315,472
Cumulative Timesteps: 2,630,979,434

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.05290
Policy Entropy: 2.49123
Value Function Loss: 0.02135

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.10961
Policy Update Magnitude: 0.48664
Value Function Update Magnitude: 0.69169

Collected Steps per Second: 22,599.80209
Overall Steps per Second: 10,955.54059

Timestep Collection Time: 2.21374
Timestep Consumption Time: 2.35290
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.56664

Cumulative Model Updates: 315,478
Cumulative Timesteps: 2,631,029,464

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2631029464...
Checkpoint 2631029464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.25234
Policy Entropy: 2.47925
Value Function Loss: 0.02077

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.09952
Policy Update Magnitude: 0.49120
Value Function Update Magnitude: 0.69262

Collected Steps per Second: 22,444.70296
Overall Steps per Second: 10,586.07205

Timestep Collection Time: 2.22868
Timestep Consumption Time: 2.49659
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.72527

Cumulative Model Updates: 315,484
Cumulative Timesteps: 2,631,079,486

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.69911
Policy Entropy: 2.47341
Value Function Loss: 0.02070

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.08933
Policy Update Magnitude: 0.49737
Value Function Update Magnitude: 0.69531

Collected Steps per Second: 22,383.09578
Overall Steps per Second: 10,553.27737

Timestep Collection Time: 2.23463
Timestep Consumption Time: 2.50494
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.73957

Cumulative Model Updates: 315,490
Cumulative Timesteps: 2,631,129,504

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2631129504...
Checkpoint 2631129504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.19555
Policy Entropy: 2.48371
Value Function Loss: 0.02064

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.08849
Policy Update Magnitude: 0.49359
Value Function Update Magnitude: 0.70194

Collected Steps per Second: 22,062.48694
Overall Steps per Second: 10,516.24726

Timestep Collection Time: 2.26665
Timestep Consumption Time: 2.48866
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.75531

Cumulative Model Updates: 315,496
Cumulative Timesteps: 2,631,179,512

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.46135
Policy Entropy: 2.49034
Value Function Loss: 0.02123

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.08076
Policy Update Magnitude: 0.49287
Value Function Update Magnitude: 0.69584

Collected Steps per Second: 21,997.03190
Overall Steps per Second: 10,659.01606

Timestep Collection Time: 2.27331
Timestep Consumption Time: 2.41812
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.69143

Cumulative Model Updates: 315,502
Cumulative Timesteps: 2,631,229,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2631229518...
Checkpoint 2631229518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.86265
Policy Entropy: 2.48879
Value Function Loss: 0.02293

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.50310
Value Function Update Magnitude: 0.69897

Collected Steps per Second: 22,499.64465
Overall Steps per Second: 10,631.66357

Timestep Collection Time: 2.22244
Timestep Consumption Time: 2.48087
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.70331

Cumulative Model Updates: 315,508
Cumulative Timesteps: 2,631,279,522

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.16389
Policy Entropy: 2.46747
Value Function Loss: 0.02339

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.08604
Policy Update Magnitude: 0.51112
Value Function Update Magnitude: 0.71137

Collected Steps per Second: 22,504.13105
Overall Steps per Second: 10,723.98614

Timestep Collection Time: 2.22244
Timestep Consumption Time: 2.44131
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.66375

Cumulative Model Updates: 315,514
Cumulative Timesteps: 2,631,329,536

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2631329536...
Checkpoint 2631329536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.00743
Policy Entropy: 2.45734
Value Function Loss: 0.02343

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.08498
Policy Update Magnitude: 0.51332
Value Function Update Magnitude: 0.71219

Collected Steps per Second: 20,878.42927
Overall Steps per Second: 10,217.92899

Timestep Collection Time: 2.39702
Timestep Consumption Time: 2.50084
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.89786

Cumulative Model Updates: 315,520
Cumulative Timesteps: 2,631,379,582

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.16442
Policy Entropy: 2.47475
Value Function Loss: 0.02211

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.08355
Policy Update Magnitude: 0.50380
Value Function Update Magnitude: 0.69382

Collected Steps per Second: 21,793.92201
Overall Steps per Second: 10,477.67276

Timestep Collection Time: 2.29458
Timestep Consumption Time: 2.47823
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.77282

Cumulative Model Updates: 315,526
Cumulative Timesteps: 2,631,429,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2631429590...
Checkpoint 2631429590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.10302
Policy Entropy: 2.47799
Value Function Loss: 0.02165

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.09620
Policy Update Magnitude: 0.49504
Value Function Update Magnitude: 0.67107

Collected Steps per Second: 22,333.14679
Overall Steps per Second: 10,621.91120

Timestep Collection Time: 2.23972
Timestep Consumption Time: 2.46941
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.70913

Cumulative Model Updates: 315,532
Cumulative Timesteps: 2,631,479,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.67848
Policy Entropy: 2.49000
Value Function Loss: 0.02077

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.09740
Policy Update Magnitude: 0.49149
Value Function Update Magnitude: 0.66111

Collected Steps per Second: 22,175.51297
Overall Steps per Second: 10,461.40914

Timestep Collection Time: 2.25537
Timestep Consumption Time: 2.52544
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.78081

Cumulative Model Updates: 315,538
Cumulative Timesteps: 2,631,529,624

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2631529624...
Checkpoint 2631529624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.46846
Policy Entropy: 2.44528
Value Function Loss: 0.02219

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.49191
Value Function Update Magnitude: 0.66223

Collected Steps per Second: 22,022.75297
Overall Steps per Second: 10,621.74829

Timestep Collection Time: 2.27165
Timestep Consumption Time: 2.43831
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.70996

Cumulative Model Updates: 315,544
Cumulative Timesteps: 2,631,579,652

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.20221
Policy Entropy: 2.46110
Value Function Loss: 0.02178

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.09864
Policy Update Magnitude: 0.49452
Value Function Update Magnitude: 0.67613

Collected Steps per Second: 22,172.72485
Overall Steps per Second: 10,594.56801

Timestep Collection Time: 2.25538
Timestep Consumption Time: 2.46477
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.72015

Cumulative Model Updates: 315,550
Cumulative Timesteps: 2,631,629,660

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2631629660...
Checkpoint 2631629660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.26045
Policy Entropy: 2.44818
Value Function Loss: 0.02191

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.10288
Policy Update Magnitude: 0.50545
Value Function Update Magnitude: 0.68630

Collected Steps per Second: 22,515.30820
Overall Steps per Second: 10,585.91310

Timestep Collection Time: 2.22124
Timestep Consumption Time: 2.50315
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.72439

Cumulative Model Updates: 315,556
Cumulative Timesteps: 2,631,679,672

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.99035
Policy Entropy: 2.46635
Value Function Loss: 0.02169

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.09406
Policy Update Magnitude: 0.50571
Value Function Update Magnitude: 0.69866

Collected Steps per Second: 22,482.70644
Overall Steps per Second: 10,743.45453

Timestep Collection Time: 2.22464
Timestep Consumption Time: 2.43084
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.65549

Cumulative Model Updates: 315,562
Cumulative Timesteps: 2,631,729,688

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2631729688...
Checkpoint 2631729688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.67663
Policy Entropy: 2.45687
Value Function Loss: 0.02135

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.49745
Value Function Update Magnitude: 0.68470

Collected Steps per Second: 22,221.15818
Overall Steps per Second: 10,699.75266

Timestep Collection Time: 2.25137
Timestep Consumption Time: 2.42425
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.67562

Cumulative Model Updates: 315,568
Cumulative Timesteps: 2,631,779,716

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.16733
Policy Entropy: 2.43958
Value Function Loss: 0.02269

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.09361
Policy Update Magnitude: 0.50107
Value Function Update Magnitude: 0.66287

Collected Steps per Second: 22,569.42180
Overall Steps per Second: 10,931.32971

Timestep Collection Time: 2.21574
Timestep Consumption Time: 2.35900
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.57474

Cumulative Model Updates: 315,574
Cumulative Timesteps: 2,631,829,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2631829724...
Checkpoint 2631829724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.75900
Policy Entropy: 2.43488
Value Function Loss: 0.02244

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.09978
Policy Update Magnitude: 0.51172
Value Function Update Magnitude: 0.67640

Collected Steps per Second: 22,382.10605
Overall Steps per Second: 10,749.10114

Timestep Collection Time: 2.23518
Timestep Consumption Time: 2.41898
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.65416

Cumulative Model Updates: 315,580
Cumulative Timesteps: 2,631,879,752

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.91373
Policy Entropy: 2.43821
Value Function Loss: 0.02295

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.50371
Value Function Update Magnitude: 0.70441

Collected Steps per Second: 21,344.82286
Overall Steps per Second: 10,449.62886

Timestep Collection Time: 2.34305
Timestep Consumption Time: 2.44296
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.78601

Cumulative Model Updates: 315,586
Cumulative Timesteps: 2,631,929,764

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2631929764...
Checkpoint 2631929764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.78373
Policy Entropy: 2.45497
Value Function Loss: 0.02125

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.09680
Policy Update Magnitude: 0.50184
Value Function Update Magnitude: 0.70351

Collected Steps per Second: 21,669.22803
Overall Steps per Second: 10,607.47720

Timestep Collection Time: 2.30834
Timestep Consumption Time: 2.40720
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.71554

Cumulative Model Updates: 315,592
Cumulative Timesteps: 2,631,979,784

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.46037
Policy Entropy: 2.45265
Value Function Loss: 0.02115

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.08816
Policy Update Magnitude: 0.50289
Value Function Update Magnitude: 0.68709

Collected Steps per Second: 21,577.40689
Overall Steps per Second: 10,541.13862

Timestep Collection Time: 2.31807
Timestep Consumption Time: 2.42696
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.74503

Cumulative Model Updates: 315,598
Cumulative Timesteps: 2,632,029,802

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2632029802...
Checkpoint 2632029802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.14045
Policy Entropy: 2.44173
Value Function Loss: 0.02009

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.10796
Policy Update Magnitude: 0.48969
Value Function Update Magnitude: 0.67500

Collected Steps per Second: 21,992.54671
Overall Steps per Second: 10,536.41648

Timestep Collection Time: 2.27486
Timestep Consumption Time: 2.47343
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.74829

Cumulative Model Updates: 315,604
Cumulative Timesteps: 2,632,079,832

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.53868
Policy Entropy: 2.43860
Value Function Loss: 0.02054

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.11630
Policy Update Magnitude: 0.46340
Value Function Update Magnitude: 0.68731

Collected Steps per Second: 21,794.65047
Overall Steps per Second: 10,441.56397

Timestep Collection Time: 2.29506
Timestep Consumption Time: 2.49541
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.79047

Cumulative Model Updates: 315,610
Cumulative Timesteps: 2,632,129,852

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2632129852...
Checkpoint 2632129852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.80450
Policy Entropy: 2.44829
Value Function Loss: 0.02061

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.11957
Policy Update Magnitude: 0.45642
Value Function Update Magnitude: 0.69844

Collected Steps per Second: 21,901.58924
Overall Steps per Second: 10,646.85836

Timestep Collection Time: 2.28422
Timestep Consumption Time: 2.41463
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.69885

Cumulative Model Updates: 315,616
Cumulative Timesteps: 2,632,179,880

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.72829
Policy Entropy: 2.43309
Value Function Loss: 0.02205

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.12556
Policy Update Magnitude: 0.48533
Value Function Update Magnitude: 0.70460

Collected Steps per Second: 22,828.54604
Overall Steps per Second: 10,567.82951

Timestep Collection Time: 2.19085
Timestep Consumption Time: 2.54181
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.73267

Cumulative Model Updates: 315,622
Cumulative Timesteps: 2,632,229,894

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2632229894...
Checkpoint 2632229894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.78775
Policy Entropy: 2.43752
Value Function Loss: 0.02307

Mean KL Divergence: 0.02520
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.49554
Value Function Update Magnitude: 0.71382

Collected Steps per Second: 22,474.38221
Overall Steps per Second: 10,558.65530

Timestep Collection Time: 2.22529
Timestep Consumption Time: 2.51130
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.73659

Cumulative Model Updates: 315,628
Cumulative Timesteps: 2,632,279,906

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.14010
Policy Entropy: 2.44110
Value Function Loss: 0.02263

Mean KL Divergence: 0.02340
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.49138
Value Function Update Magnitude: 0.74176

Collected Steps per Second: 22,273.95702
Overall Steps per Second: 10,528.68999

Timestep Collection Time: 2.24495
Timestep Consumption Time: 2.50436
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.74931

Cumulative Model Updates: 315,634
Cumulative Timesteps: 2,632,329,910

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2632329910...
Checkpoint 2632329910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.28540
Policy Entropy: 2.46372
Value Function Loss: 0.02170

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.12126
Policy Update Magnitude: 0.49441
Value Function Update Magnitude: 0.75952

Collected Steps per Second: 22,402.51099
Overall Steps per Second: 10,628.72651

Timestep Collection Time: 2.23287
Timestep Consumption Time: 2.47343
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.70630

Cumulative Model Updates: 315,640
Cumulative Timesteps: 2,632,379,932

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.95983
Policy Entropy: 2.48156
Value Function Loss: 0.02094

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.10519
Policy Update Magnitude: 0.50026
Value Function Update Magnitude: 0.75863

Collected Steps per Second: 22,579.52214
Overall Steps per Second: 10,782.46637

Timestep Collection Time: 2.21493
Timestep Consumption Time: 2.42334
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.63827

Cumulative Model Updates: 315,646
Cumulative Timesteps: 2,632,429,944

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2632429944...
Checkpoint 2632429944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.23561
Policy Entropy: 2.47941
Value Function Loss: 0.02101

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.09549
Policy Update Magnitude: 0.49651
Value Function Update Magnitude: 0.73447

Collected Steps per Second: 22,367.06861
Overall Steps per Second: 10,727.34583

Timestep Collection Time: 2.23659
Timestep Consumption Time: 2.42682
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.66341

Cumulative Model Updates: 315,652
Cumulative Timesteps: 2,632,479,970

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.58308
Policy Entropy: 2.48044
Value Function Loss: 0.02123

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.08681
Policy Update Magnitude: 0.49583
Value Function Update Magnitude: 0.72937

Collected Steps per Second: 21,939.49179
Overall Steps per Second: 10,461.30751

Timestep Collection Time: 2.27936
Timestep Consumption Time: 2.50092
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.78028

Cumulative Model Updates: 315,658
Cumulative Timesteps: 2,632,529,978

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2632529978...
Checkpoint 2632529978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.85282
Policy Entropy: 2.45680
Value Function Loss: 0.02222

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.08757
Policy Update Magnitude: 0.50187
Value Function Update Magnitude: 0.71573

Collected Steps per Second: 21,966.30206
Overall Steps per Second: 10,599.62827

Timestep Collection Time: 2.27658
Timestep Consumption Time: 2.44132
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.71790

Cumulative Model Updates: 315,664
Cumulative Timesteps: 2,632,579,986

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.80403
Policy Entropy: 2.45926
Value Function Loss: 0.02268

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.09148
Policy Update Magnitude: 0.49378
Value Function Update Magnitude: 0.71592

Collected Steps per Second: 22,996.86519
Overall Steps per Second: 10,842.48732

Timestep Collection Time: 2.17525
Timestep Consumption Time: 2.43845
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.61370

Cumulative Model Updates: 315,670
Cumulative Timesteps: 2,632,630,010

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2632630010...
Checkpoint 2632630010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.57040
Policy Entropy: 2.46745
Value Function Loss: 0.02287

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.09025
Policy Update Magnitude: 0.49751
Value Function Update Magnitude: 0.71458

Collected Steps per Second: 21,745.31650
Overall Steps per Second: 10,582.36019

Timestep Collection Time: 2.29935
Timestep Consumption Time: 2.42550
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.72484

Cumulative Model Updates: 315,676
Cumulative Timesteps: 2,632,680,010

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.61359
Policy Entropy: 2.48115
Value Function Loss: 0.02339

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.09693
Policy Update Magnitude: 0.51428
Value Function Update Magnitude: 0.70860

Collected Steps per Second: 21,955.60562
Overall Steps per Second: 10,562.67045

Timestep Collection Time: 2.27787
Timestep Consumption Time: 2.45692
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.73479

Cumulative Model Updates: 315,682
Cumulative Timesteps: 2,632,730,022

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2632730022...
Checkpoint 2632730022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.82637
Policy Entropy: 2.45865
Value Function Loss: 0.02379

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.09162
Policy Update Magnitude: 0.50729
Value Function Update Magnitude: 0.72315

Collected Steps per Second: 22,437.95117
Overall Steps per Second: 10,672.49725

Timestep Collection Time: 2.22953
Timestep Consumption Time: 2.45785
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.68738

Cumulative Model Updates: 315,688
Cumulative Timesteps: 2,632,780,048

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.85516
Policy Entropy: 2.43339
Value Function Loss: 0.02276

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.08938
Policy Update Magnitude: 0.50418
Value Function Update Magnitude: 0.74271

Collected Steps per Second: 22,474.74601
Overall Steps per Second: 10,618.79631

Timestep Collection Time: 2.22588
Timestep Consumption Time: 2.48520
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.71108

Cumulative Model Updates: 315,694
Cumulative Timesteps: 2,632,830,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2632830074...
Checkpoint 2632830074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.09817
Policy Entropy: 2.45192
Value Function Loss: 0.02081

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.49910
Value Function Update Magnitude: 0.72560

Collected Steps per Second: 22,419.80856
Overall Steps per Second: 10,582.07038

Timestep Collection Time: 2.23026
Timestep Consumption Time: 2.49490
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.72516

Cumulative Model Updates: 315,700
Cumulative Timesteps: 2,632,880,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.88554
Policy Entropy: 2.49120
Value Function Loss: 0.02109

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.11057
Policy Update Magnitude: 0.48221
Value Function Update Magnitude: 0.72055

Collected Steps per Second: 22,537.03527
Overall Steps per Second: 10,704.79521

Timestep Collection Time: 2.21893
Timestep Consumption Time: 2.45263
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.67155

Cumulative Model Updates: 315,706
Cumulative Timesteps: 2,632,930,084

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2632930084...
Checkpoint 2632930084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.97161
Policy Entropy: 2.49545
Value Function Loss: 0.02248

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.12677
Policy Update Magnitude: 0.46545
Value Function Update Magnitude: 0.72109

Collected Steps per Second: 22,231.38836
Overall Steps per Second: 10,741.79314

Timestep Collection Time: 2.24934
Timestep Consumption Time: 2.40593
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.65527

Cumulative Model Updates: 315,712
Cumulative Timesteps: 2,632,980,090

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.27249
Policy Entropy: 2.47133
Value Function Loss: 0.02265

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.11153
Policy Update Magnitude: 0.49057
Value Function Update Magnitude: 0.71344

Collected Steps per Second: 22,988.25958
Overall Steps per Second: 10,821.30925

Timestep Collection Time: 2.17589
Timestep Consumption Time: 2.44647
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.62236

Cumulative Model Updates: 315,718
Cumulative Timesteps: 2,633,030,110

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2633030110...
Checkpoint 2633030110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.17018
Policy Entropy: 2.46463
Value Function Loss: 0.02197

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.10448
Policy Update Magnitude: 0.50651
Value Function Update Magnitude: 0.70495

Collected Steps per Second: 21,951.40666
Overall Steps per Second: 10,608.91160

Timestep Collection Time: 2.27812
Timestep Consumption Time: 2.43565
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.71377

Cumulative Model Updates: 315,724
Cumulative Timesteps: 2,633,080,118

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.49031
Policy Entropy: 2.47763
Value Function Loss: 0.02225

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.09899
Policy Update Magnitude: 0.50448
Value Function Update Magnitude: 0.67706

Collected Steps per Second: 21,831.65052
Overall Steps per Second: 10,596.90182

Timestep Collection Time: 2.29154
Timestep Consumption Time: 2.42947
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.72100

Cumulative Model Updates: 315,730
Cumulative Timesteps: 2,633,130,146

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2633130146...
Checkpoint 2633130146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.49347
Policy Entropy: 2.47677
Value Function Loss: 0.02223

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.09381
Policy Update Magnitude: 0.50068
Value Function Update Magnitude: 0.67383

Collected Steps per Second: 22,023.02098
Overall Steps per Second: 10,664.20106

Timestep Collection Time: 2.27062
Timestep Consumption Time: 2.41852
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.68915

Cumulative Model Updates: 315,736
Cumulative Timesteps: 2,633,180,152

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.59295
Policy Entropy: 2.45044
Value Function Loss: 0.02251

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.09238
Policy Update Magnitude: 0.50491
Value Function Update Magnitude: 0.66973

Collected Steps per Second: 22,087.47775
Overall Steps per Second: 10,487.38118

Timestep Collection Time: 2.26427
Timestep Consumption Time: 2.50451
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.76878

Cumulative Model Updates: 315,742
Cumulative Timesteps: 2,633,230,164

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2633230164...
Checkpoint 2633230164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.52464
Policy Entropy: 2.43398
Value Function Loss: 0.02044

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.09477
Policy Update Magnitude: 0.49447
Value Function Update Magnitude: 0.66044

Collected Steps per Second: 22,123.53863
Overall Steps per Second: 10,498.06414

Timestep Collection Time: 2.26112
Timestep Consumption Time: 2.50395
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.76507

Cumulative Model Updates: 315,748
Cumulative Timesteps: 2,633,280,188

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.71721
Policy Entropy: 2.44699
Value Function Loss: 0.02124

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.09745
Policy Update Magnitude: 0.48443
Value Function Update Magnitude: 0.65574

Collected Steps per Second: 22,131.00706
Overall Steps per Second: 10,461.76735

Timestep Collection Time: 2.25927
Timestep Consumption Time: 2.52003
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.77931

Cumulative Model Updates: 315,754
Cumulative Timesteps: 2,633,330,188

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2633330188...
Checkpoint 2633330188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.39583
Policy Entropy: 2.45617
Value Function Loss: 0.02183

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.10616
Policy Update Magnitude: 0.48362
Value Function Update Magnitude: 0.67501

Collected Steps per Second: 22,394.25933
Overall Steps per Second: 10,651.11245

Timestep Collection Time: 2.23316
Timestep Consumption Time: 2.46212
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.69528

Cumulative Model Updates: 315,760
Cumulative Timesteps: 2,633,380,198

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.19868
Policy Entropy: 2.47027
Value Function Loss: 0.02129

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.48595
Value Function Update Magnitude: 0.69767

Collected Steps per Second: 22,411.51685
Overall Steps per Second: 10,566.75717

Timestep Collection Time: 2.23189
Timestep Consumption Time: 2.50183
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.73371

Cumulative Model Updates: 315,766
Cumulative Timesteps: 2,633,430,218

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2633430218...
Checkpoint 2633430218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.75762
Policy Entropy: 2.45290
Value Function Loss: 0.02126

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.49388
Value Function Update Magnitude: 0.68347

Collected Steps per Second: 22,354.74179
Overall Steps per Second: 10,512.67597

Timestep Collection Time: 2.23675
Timestep Consumption Time: 2.51960
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.75635

Cumulative Model Updates: 315,772
Cumulative Timesteps: 2,633,480,220

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.21816
Policy Entropy: 2.44475
Value Function Loss: 0.02034

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.49502
Value Function Update Magnitude: 0.66671

Collected Steps per Second: 22,584.00407
Overall Steps per Second: 10,686.30068

Timestep Collection Time: 2.21520
Timestep Consumption Time: 2.46631
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.68151

Cumulative Model Updates: 315,778
Cumulative Timesteps: 2,633,530,248

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2633530248...
Checkpoint 2633530248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.10438
Policy Entropy: 2.41662
Value Function Loss: 0.02105

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.10091
Policy Update Magnitude: 0.51295
Value Function Update Magnitude: 0.67328

Collected Steps per Second: 22,382.34858
Overall Steps per Second: 10,616.37031

Timestep Collection Time: 2.23471
Timestep Consumption Time: 2.47670
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.71140

Cumulative Model Updates: 315,784
Cumulative Timesteps: 2,633,580,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.73890
Policy Entropy: 2.45468
Value Function Loss: 0.02052

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.11125
Policy Update Magnitude: 0.49745
Value Function Update Magnitude: 0.68415

Collected Steps per Second: 22,631.35842
Overall Steps per Second: 10,720.96151

Timestep Collection Time: 2.20950
Timestep Consumption Time: 2.45463
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.66413

Cumulative Model Updates: 315,790
Cumulative Timesteps: 2,633,630,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2633630270...
Checkpoint 2633630270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.94543
Policy Entropy: 2.46114
Value Function Loss: 0.01937

Mean KL Divergence: 0.02190
SB3 Clip Fraction: 0.12300
Policy Update Magnitude: 0.49534
Value Function Update Magnitude: 0.69416

Collected Steps per Second: 22,309.57793
Overall Steps per Second: 10,627.70592

Timestep Collection Time: 2.24182
Timestep Consumption Time: 2.46418
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.70600

Cumulative Model Updates: 315,796
Cumulative Timesteps: 2,633,680,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.06360
Policy Entropy: 2.51596
Value Function Loss: 0.01902

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.11169
Policy Update Magnitude: 0.50951
Value Function Update Magnitude: 0.68940

Collected Steps per Second: 21,604.49361
Overall Steps per Second: 10,474.62098

Timestep Collection Time: 2.31554
Timestep Consumption Time: 2.46039
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.77592

Cumulative Model Updates: 315,802
Cumulative Timesteps: 2,633,730,310

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2633730310...
Checkpoint 2633730310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.03569
Policy Entropy: 2.50092
Value Function Loss: 0.02019

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.50025
Value Function Update Magnitude: 0.69301

Collected Steps per Second: 21,760.89879
Overall Steps per Second: 10,636.58071

Timestep Collection Time: 2.29871
Timestep Consumption Time: 2.40412
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.70283

Cumulative Model Updates: 315,808
Cumulative Timesteps: 2,633,780,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.63586
Policy Entropy: 2.47979
Value Function Loss: 0.02024

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.09397
Policy Update Magnitude: 0.49061
Value Function Update Magnitude: 0.70636

Collected Steps per Second: 21,028.56712
Overall Steps per Second: 10,204.70877

Timestep Collection Time: 2.37905
Timestep Consumption Time: 2.52339
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.90244

Cumulative Model Updates: 315,814
Cumulative Timesteps: 2,633,830,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2633830360...
Checkpoint 2633830360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.94085
Policy Entropy: 2.44648
Value Function Loss: 0.02156

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.08126
Policy Update Magnitude: 0.48874
Value Function Update Magnitude: 0.70816

Collected Steps per Second: 22,279.86933
Overall Steps per Second: 10,487.70998

Timestep Collection Time: 2.24427
Timestep Consumption Time: 2.52341
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.76768

Cumulative Model Updates: 315,820
Cumulative Timesteps: 2,633,880,362

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.89520
Policy Entropy: 2.43936
Value Function Loss: 0.02111

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.07819
Policy Update Magnitude: 0.48413
Value Function Update Magnitude: 0.69494

Collected Steps per Second: 22,247.07063
Overall Steps per Second: 10,582.64041

Timestep Collection Time: 2.24902
Timestep Consumption Time: 2.47892
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.72793

Cumulative Model Updates: 315,826
Cumulative Timesteps: 2,633,930,396

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2633930396...
Checkpoint 2633930396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.38519
Policy Entropy: 2.43589
Value Function Loss: 0.02229

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.08234
Policy Update Magnitude: 0.48731
Value Function Update Magnitude: 0.68446

Collected Steps per Second: 22,333.52169
Overall Steps per Second: 10,887.03142

Timestep Collection Time: 2.23950
Timestep Consumption Time: 2.35459
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.59409

Cumulative Model Updates: 315,832
Cumulative Timesteps: 2,633,980,412

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.62303
Policy Entropy: 2.45442
Value Function Loss: 0.02159

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.08312
Policy Update Magnitude: 0.48979
Value Function Update Magnitude: 0.67311

Collected Steps per Second: 22,199.71343
Overall Steps per Second: 10,528.43563

Timestep Collection Time: 2.25255
Timestep Consumption Time: 2.49706
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.74961

Cumulative Model Updates: 315,838
Cumulative Timesteps: 2,634,030,418

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2634030418...
Checkpoint 2634030418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.83240
Policy Entropy: 2.46193
Value Function Loss: 0.02115

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.08701
Policy Update Magnitude: 0.49064
Value Function Update Magnitude: 0.67548

Collected Steps per Second: 22,344.57366
Overall Steps per Second: 10,633.73863

Timestep Collection Time: 2.23831
Timestep Consumption Time: 2.46503
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.70333

Cumulative Model Updates: 315,844
Cumulative Timesteps: 2,634,080,432

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.58717
Policy Entropy: 2.47042
Value Function Loss: 0.02057

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.08365
Policy Update Magnitude: 0.47781
Value Function Update Magnitude: 0.67121

Collected Steps per Second: 22,120.92213
Overall Steps per Second: 10,836.56783

Timestep Collection Time: 2.26103
Timestep Consumption Time: 2.35446
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.61548

Cumulative Model Updates: 315,850
Cumulative Timesteps: 2,634,130,448

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2634130448...
Checkpoint 2634130448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.54120
Policy Entropy: 2.45445
Value Function Loss: 0.02128

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.07876
Policy Update Magnitude: 0.48129
Value Function Update Magnitude: 0.66970

Collected Steps per Second: 21,982.71866
Overall Steps per Second: 10,632.35237

Timestep Collection Time: 2.27470
Timestep Consumption Time: 2.42831
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.70300

Cumulative Model Updates: 315,856
Cumulative Timesteps: 2,634,180,452

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.85844
Policy Entropy: 2.46607
Value Function Loss: 0.02176

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.09125
Policy Update Magnitude: 0.49750
Value Function Update Magnitude: 0.68022

Collected Steps per Second: 22,118.31495
Overall Steps per Second: 10,571.54842

Timestep Collection Time: 2.26202
Timestep Consumption Time: 2.47069
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.73270

Cumulative Model Updates: 315,862
Cumulative Timesteps: 2,634,230,484

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2634230484...
Checkpoint 2634230484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.97110
Policy Entropy: 2.47872
Value Function Loss: 0.02191

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 0.48807
Value Function Update Magnitude: 0.69683

Collected Steps per Second: 21,676.00248
Overall Steps per Second: 10,597.49327

Timestep Collection Time: 2.30753
Timestep Consumption Time: 2.41227
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.71980

Cumulative Model Updates: 315,868
Cumulative Timesteps: 2,634,280,502

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.09154
Policy Entropy: 2.50210
Value Function Loss: 0.02264

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.12289
Policy Update Magnitude: 0.45875
Value Function Update Magnitude: 0.70394

Collected Steps per Second: 22,026.65971
Overall Steps per Second: 10,660.79149

Timestep Collection Time: 2.27034
Timestep Consumption Time: 2.42049
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.69083

Cumulative Model Updates: 315,874
Cumulative Timesteps: 2,634,330,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2634330510...
Checkpoint 2634330510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.21805
Policy Entropy: 2.51087
Value Function Loss: 0.02186

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.10869
Policy Update Magnitude: 0.45645
Value Function Update Magnitude: 0.69094

Collected Steps per Second: 21,859.26664
Overall Steps per Second: 10,433.79805

Timestep Collection Time: 2.28809
Timestep Consumption Time: 2.50556
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.79365

Cumulative Model Updates: 315,880
Cumulative Timesteps: 2,634,380,526

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.76888
Policy Entropy: 2.49547
Value Function Loss: 0.02073

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.10280
Policy Update Magnitude: 0.47563
Value Function Update Magnitude: 0.67959

Collected Steps per Second: 22,072.62418
Overall Steps per Second: 10,462.57449

Timestep Collection Time: 2.26652
Timestep Consumption Time: 2.51510
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.78161

Cumulative Model Updates: 315,886
Cumulative Timesteps: 2,634,430,554

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2634430554...
Checkpoint 2634430554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.67340
Policy Entropy: 2.49335
Value Function Loss: 0.01938

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.47727
Value Function Update Magnitude: 0.65448

Collected Steps per Second: 22,176.94271
Overall Steps per Second: 10,645.61825

Timestep Collection Time: 2.25577
Timestep Consumption Time: 2.44344
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.69921

Cumulative Model Updates: 315,892
Cumulative Timesteps: 2,634,480,580

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.70191
Policy Entropy: 2.47618
Value Function Loss: 0.02022

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.48531
Value Function Update Magnitude: 0.64487

Collected Steps per Second: 22,480.58907
Overall Steps per Second: 10,630.95478

Timestep Collection Time: 2.22467
Timestep Consumption Time: 2.47970
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.70438

Cumulative Model Updates: 315,898
Cumulative Timesteps: 2,634,530,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2634530592...
Checkpoint 2634530592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.45760
Policy Entropy: 2.48037
Value Function Loss: 0.02197

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.09170
Policy Update Magnitude: 0.49182
Value Function Update Magnitude: 0.67024

Collected Steps per Second: 22,393.83958
Overall Steps per Second: 10,870.32587

Timestep Collection Time: 2.23356
Timestep Consumption Time: 2.36777
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.60133

Cumulative Model Updates: 315,904
Cumulative Timesteps: 2,634,580,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.70724
Policy Entropy: 2.47338
Value Function Loss: 0.02201

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.09852
Policy Update Magnitude: 0.48924
Value Function Update Magnitude: 0.69854

Collected Steps per Second: 22,400.93489
Overall Steps per Second: 10,521.63023

Timestep Collection Time: 2.23205
Timestep Consumption Time: 2.52007
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.75212

Cumulative Model Updates: 315,910
Cumulative Timesteps: 2,634,630,610

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2634630610...
Checkpoint 2634630610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.75982
Policy Entropy: 2.49310
Value Function Loss: 0.02170

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.10267
Policy Update Magnitude: 0.48498
Value Function Update Magnitude: 0.68149

Collected Steps per Second: 22,276.08942
Overall Steps per Second: 10,619.16763

Timestep Collection Time: 2.24626
Timestep Consumption Time: 2.46578
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.71205

Cumulative Model Updates: 315,916
Cumulative Timesteps: 2,634,680,648

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.22636
Policy Entropy: 2.50400
Value Function Loss: 0.02107

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.09888
Policy Update Magnitude: 0.49309
Value Function Update Magnitude: 0.66534

Collected Steps per Second: 22,483.59863
Overall Steps per Second: 10,896.63693

Timestep Collection Time: 2.22402
Timestep Consumption Time: 2.36492
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.58894

Cumulative Model Updates: 315,922
Cumulative Timesteps: 2,634,730,652

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2634730652...
Checkpoint 2634730652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.31102
Policy Entropy: 2.49143
Value Function Loss: 0.02189

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.10114
Policy Update Magnitude: 0.48466
Value Function Update Magnitude: 0.66385

Collected Steps per Second: 22,282.29714
Overall Steps per Second: 10,723.52647

Timestep Collection Time: 2.24438
Timestep Consumption Time: 2.41920
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.66358

Cumulative Model Updates: 315,928
Cumulative Timesteps: 2,634,780,662

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.23451
Policy Entropy: 2.47980
Value Function Loss: 0.02114

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.08471
Policy Update Magnitude: 0.48127
Value Function Update Magnitude: 0.66955

Collected Steps per Second: 21,898.59179
Overall Steps per Second: 10,435.54393

Timestep Collection Time: 2.28343
Timestep Consumption Time: 2.50827
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.79170

Cumulative Model Updates: 315,934
Cumulative Timesteps: 2,634,830,666

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2634830666...
Checkpoint 2634830666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.01195
Policy Entropy: 2.48195
Value Function Loss: 0.02021

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.09308
Policy Update Magnitude: 0.48096
Value Function Update Magnitude: 0.66677

Collected Steps per Second: 21,765.72804
Overall Steps per Second: 10,633.58143

Timestep Collection Time: 2.29802
Timestep Consumption Time: 2.40576
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.70378

Cumulative Model Updates: 315,940
Cumulative Timesteps: 2,634,880,684

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.95030
Policy Entropy: 2.50089
Value Function Loss: 0.02031

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.09313
Policy Update Magnitude: 0.48920
Value Function Update Magnitude: 0.66507

Collected Steps per Second: 21,977.84814
Overall Steps per Second: 10,791.21642

Timestep Collection Time: 2.27565
Timestep Consumption Time: 2.35904
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.63470

Cumulative Model Updates: 315,946
Cumulative Timesteps: 2,634,930,698

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2634930698...
Checkpoint 2634930698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.61005
Policy Entropy: 2.49197
Value Function Loss: 0.02148

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.49337
Value Function Update Magnitude: 0.65907

Collected Steps per Second: 21,872.81604
Overall Steps per Second: 10,477.46898

Timestep Collection Time: 2.28713
Timestep Consumption Time: 2.48750
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.77463

Cumulative Model Updates: 315,952
Cumulative Timesteps: 2,634,980,724

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.96182
Policy Entropy: 2.48291
Value Function Loss: 0.02251

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.09474
Policy Update Magnitude: 0.49681
Value Function Update Magnitude: 0.64411

Collected Steps per Second: 22,163.60457
Overall Steps per Second: 10,478.55467

Timestep Collection Time: 2.25658
Timestep Consumption Time: 2.51640
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.77299

Cumulative Model Updates: 315,958
Cumulative Timesteps: 2,635,030,738

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2635030738...
Checkpoint 2635030738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.15080
Policy Entropy: 2.46167
Value Function Loss: 0.02203

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.49493
Value Function Update Magnitude: 0.65002

Collected Steps per Second: 22,074.28847
Overall Steps per Second: 10,466.88024

Timestep Collection Time: 2.26589
Timestep Consumption Time: 2.51280
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.77869

Cumulative Model Updates: 315,964
Cumulative Timesteps: 2,635,080,756

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.96511
Policy Entropy: 2.46979
Value Function Loss: 0.02239

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.09568
Policy Update Magnitude: 0.49265
Value Function Update Magnitude: 0.66612

Collected Steps per Second: 22,367.48162
Overall Steps per Second: 10,880.65071

Timestep Collection Time: 2.23539
Timestep Consumption Time: 2.35993
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.59531

Cumulative Model Updates: 315,970
Cumulative Timesteps: 2,635,130,756

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2635130756...
Checkpoint 2635130756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.80761
Policy Entropy: 2.46050
Value Function Loss: 0.02261

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.09650
Policy Update Magnitude: 0.49701
Value Function Update Magnitude: 0.68105

Collected Steps per Second: 22,265.96500
Overall Steps per Second: 10,593.11064

Timestep Collection Time: 2.24657
Timestep Consumption Time: 2.47556
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.72213

Cumulative Model Updates: 315,976
Cumulative Timesteps: 2,635,180,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.06926
Policy Entropy: 2.47948
Value Function Loss: 0.02184

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.09172
Policy Update Magnitude: 0.50082
Value Function Update Magnitude: 0.67410

Collected Steps per Second: 22,389.82412
Overall Steps per Second: 10,563.26041

Timestep Collection Time: 2.23405
Timestep Consumption Time: 2.50123
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.73528

Cumulative Model Updates: 315,982
Cumulative Timesteps: 2,635,230,798

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2635230798...
Checkpoint 2635230798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.42928
Policy Entropy: 2.49239
Value Function Loss: 0.02123

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.08777
Policy Update Magnitude: 0.49154
Value Function Update Magnitude: 0.66509

Collected Steps per Second: 22,214.00271
Overall Steps per Second: 10,549.32026

Timestep Collection Time: 2.25128
Timestep Consumption Time: 2.48931
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.74059

Cumulative Model Updates: 315,988
Cumulative Timesteps: 2,635,280,808

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.76750
Policy Entropy: 2.48045
Value Function Loss: 0.02156

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.08309
Policy Update Magnitude: 0.49446
Value Function Update Magnitude: 0.66563

Collected Steps per Second: 23,304.09665
Overall Steps per Second: 10,942.32048

Timestep Collection Time: 2.14589
Timestep Consumption Time: 2.42426
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.57015

Cumulative Model Updates: 315,994
Cumulative Timesteps: 2,635,330,816

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2635330816...
Checkpoint 2635330816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.63173
Policy Entropy: 2.45395
Value Function Loss: 0.02227

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.08265
Policy Update Magnitude: 0.50089
Value Function Update Magnitude: 0.67370

Collected Steps per Second: 22,357.24764
Overall Steps per Second: 10,603.18469

Timestep Collection Time: 2.23650
Timestep Consumption Time: 2.47925
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.71575

Cumulative Model Updates: 316,000
Cumulative Timesteps: 2,635,380,818

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.52113
Policy Entropy: 2.42742
Value Function Loss: 0.02382

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.50450
Value Function Update Magnitude: 0.68321

Collected Steps per Second: 21,815.67954
Overall Steps per Second: 10,475.92815

Timestep Collection Time: 2.29202
Timestep Consumption Time: 2.48102
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.77304

Cumulative Model Updates: 316,006
Cumulative Timesteps: 2,635,430,820

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2635430820...
Checkpoint 2635430820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.13005
Policy Entropy: 2.42654
Value Function Loss: 0.02264

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.09530
Policy Update Magnitude: 0.49989
Value Function Update Magnitude: 0.67440

Collected Steps per Second: 21,576.68844
Overall Steps per Second: 10,572.79771

Timestep Collection Time: 2.31796
Timestep Consumption Time: 2.41248
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.73044

Cumulative Model Updates: 316,012
Cumulative Timesteps: 2,635,480,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.30490
Policy Entropy: 2.43859
Value Function Loss: 0.02223

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.09238
Policy Update Magnitude: 0.50177
Value Function Update Magnitude: 0.66366

Collected Steps per Second: 22,140.31582
Overall Steps per Second: 10,716.78404

Timestep Collection Time: 2.25887
Timestep Consumption Time: 2.40783
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.66670

Cumulative Model Updates: 316,018
Cumulative Timesteps: 2,635,530,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2635530846...
Checkpoint 2635530846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.76885
Policy Entropy: 2.45019
Value Function Loss: 0.02200

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.08904
Policy Update Magnitude: 0.50415
Value Function Update Magnitude: 0.67477

Collected Steps per Second: 22,007.02793
Overall Steps per Second: 10,459.17379

Timestep Collection Time: 2.27327
Timestep Consumption Time: 2.50990
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.78317

Cumulative Model Updates: 316,024
Cumulative Timesteps: 2,635,580,874

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.48147
Policy Entropy: 2.45597
Value Function Loss: 0.02259

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.08864
Policy Update Magnitude: 0.50396
Value Function Update Magnitude: 0.69786

Collected Steps per Second: 22,017.47373
Overall Steps per Second: 10,410.90847

Timestep Collection Time: 2.27174
Timestep Consumption Time: 2.53264
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.80438

Cumulative Model Updates: 316,030
Cumulative Timesteps: 2,635,630,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2635630892...
Checkpoint 2635630892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.28719
Policy Entropy: 2.46043
Value Function Loss: 0.02311

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.08188
Policy Update Magnitude: 0.50307
Value Function Update Magnitude: 0.69261

Collected Steps per Second: 22,311.98211
Overall Steps per Second: 10,675.07718

Timestep Collection Time: 2.24149
Timestep Consumption Time: 2.44344
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.68493

Cumulative Model Updates: 316,036
Cumulative Timesteps: 2,635,680,904

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.72079
Policy Entropy: 2.46363
Value Function Loss: 0.02257

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 0.50026
Value Function Update Magnitude: 0.68634

Collected Steps per Second: 21,750.48105
Overall Steps per Second: 10,407.37579

Timestep Collection Time: 2.29963
Timestep Consumption Time: 2.50639
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.80601

Cumulative Model Updates: 316,042
Cumulative Timesteps: 2,635,730,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2635730922...
Checkpoint 2635730922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.30272
Policy Entropy: 2.44608
Value Function Loss: 0.02172

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.08458
Policy Update Magnitude: 0.49308
Value Function Update Magnitude: 0.68665

Collected Steps per Second: 21,944.47007
Overall Steps per Second: 10,574.51884

Timestep Collection Time: 2.27975
Timestep Consumption Time: 2.45124
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.73100

Cumulative Model Updates: 316,048
Cumulative Timesteps: 2,635,780,950

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.25100
Policy Entropy: 2.44152
Value Function Loss: 0.02069

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.08340
Policy Update Magnitude: 0.49328
Value Function Update Magnitude: 0.69263

Collected Steps per Second: 22,291.13595
Overall Steps per Second: 10,538.12931

Timestep Collection Time: 2.24322
Timestep Consumption Time: 2.50183
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.74505

Cumulative Model Updates: 316,054
Cumulative Timesteps: 2,635,830,954

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2635830954...
Checkpoint 2635830954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.58200
Policy Entropy: 2.44268
Value Function Loss: 0.02156

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.08140
Policy Update Magnitude: 0.49945
Value Function Update Magnitude: 0.71252

Collected Steps per Second: 21,829.66014
Overall Steps per Second: 10,637.21928

Timestep Collection Time: 2.29156
Timestep Consumption Time: 2.41117
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.70273

Cumulative Model Updates: 316,060
Cumulative Timesteps: 2,635,880,978

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.39255
Policy Entropy: 2.46682
Value Function Loss: 0.02119

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.09457
Policy Update Magnitude: 0.50927
Value Function Update Magnitude: 0.72490

Collected Steps per Second: 23,053.96067
Overall Steps per Second: 10,864.29869

Timestep Collection Time: 2.16943
Timestep Consumption Time: 2.43409
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.60352

Cumulative Model Updates: 316,066
Cumulative Timesteps: 2,635,930,992

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2635930992...
Checkpoint 2635930992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.78137
Policy Entropy: 2.48040
Value Function Loss: 0.02118

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.49908
Value Function Update Magnitude: 0.71563

Collected Steps per Second: 22,134.92346
Overall Steps per Second: 10,625.34069

Timestep Collection Time: 2.25960
Timestep Consumption Time: 2.44764
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.70724

Cumulative Model Updates: 316,072
Cumulative Timesteps: 2,635,981,008

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.76165
Policy Entropy: 2.49756
Value Function Loss: 0.01950

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.09084
Policy Update Magnitude: 0.48196
Value Function Update Magnitude: 0.71012

Collected Steps per Second: 21,937.42872
Overall Steps per Second: 10,537.30435

Timestep Collection Time: 2.28003
Timestep Consumption Time: 2.46672
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.74675

Cumulative Model Updates: 316,078
Cumulative Timesteps: 2,636,031,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2636031026...
Checkpoint 2636031026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.54935
Policy Entropy: 2.46817
Value Function Loss: 0.01896

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.08427
Policy Update Magnitude: 0.48083
Value Function Update Magnitude: 0.67871

Collected Steps per Second: 21,485.08339
Overall Steps per Second: 10,715.52792

Timestep Collection Time: 2.32869
Timestep Consumption Time: 2.34043
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.66911

Cumulative Model Updates: 316,084
Cumulative Timesteps: 2,636,081,058

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.42971
Policy Entropy: 2.45690
Value Function Loss: 0.01932

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.48228
Value Function Update Magnitude: 0.65198

Collected Steps per Second: 22,395.60641
Overall Steps per Second: 10,589.27347

Timestep Collection Time: 2.23365
Timestep Consumption Time: 2.49037
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.72403

Cumulative Model Updates: 316,090
Cumulative Timesteps: 2,636,131,082

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2636131082...
Checkpoint 2636131082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.00814
Policy Entropy: 2.43936
Value Function Loss: 0.01979

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.47174
Value Function Update Magnitude: 0.65815

Collected Steps per Second: 21,860.11615
Overall Steps per Second: 10,430.99476

Timestep Collection Time: 2.28782
Timestep Consumption Time: 2.50674
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.79456

Cumulative Model Updates: 316,096
Cumulative Timesteps: 2,636,181,094

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.68743
Policy Entropy: 2.47788
Value Function Loss: 0.02093

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.10292
Policy Update Magnitude: 0.47648
Value Function Update Magnitude: 0.66223

Collected Steps per Second: 22,498.53789
Overall Steps per Second: 10,501.31022

Timestep Collection Time: 2.22299
Timestep Consumption Time: 2.53965
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.76264

Cumulative Model Updates: 316,102
Cumulative Timesteps: 2,636,231,108

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2636231108...
Checkpoint 2636231108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.84600
Policy Entropy: 2.47479
Value Function Loss: 0.02069

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.10059
Policy Update Magnitude: 0.49679
Value Function Update Magnitude: 0.66920

Collected Steps per Second: 22,005.99504
Overall Steps per Second: 10,558.65696

Timestep Collection Time: 2.27338
Timestep Consumption Time: 2.46472
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.73810

Cumulative Model Updates: 316,108
Cumulative Timesteps: 2,636,281,136

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.61852
Policy Entropy: 2.47801
Value Function Loss: 0.01995

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.10004
Policy Update Magnitude: 0.48948
Value Function Update Magnitude: 0.65428

Collected Steps per Second: 22,148.59831
Overall Steps per Second: 10,669.19882

Timestep Collection Time: 2.25748
Timestep Consumption Time: 2.42891
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.68639

Cumulative Model Updates: 316,114
Cumulative Timesteps: 2,636,331,136

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2636331136...
Checkpoint 2636331136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.13295
Policy Entropy: 2.46648
Value Function Loss: 0.02024

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.09259
Policy Update Magnitude: 0.47440
Value Function Update Magnitude: 0.61955

Collected Steps per Second: 22,265.55494
Overall Steps per Second: 10,554.42801

Timestep Collection Time: 2.24634
Timestep Consumption Time: 2.49252
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.73886

Cumulative Model Updates: 316,120
Cumulative Timesteps: 2,636,381,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.19384
Policy Entropy: 2.47268
Value Function Loss: 0.02075

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.08912
Policy Update Magnitude: 0.47904
Value Function Update Magnitude: 0.61044

Collected Steps per Second: 22,455.45113
Overall Steps per Second: 10,731.50388

Timestep Collection Time: 2.22699
Timestep Consumption Time: 2.43294
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.65992

Cumulative Model Updates: 316,126
Cumulative Timesteps: 2,636,431,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2636431160...
Checkpoint 2636431160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.61808
Policy Entropy: 2.47645
Value Function Loss: 0.02084

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.09318
Policy Update Magnitude: 0.47705
Value Function Update Magnitude: 0.60647

Collected Steps per Second: 22,229.96418
Overall Steps per Second: 10,717.99092

Timestep Collection Time: 2.24922
Timestep Consumption Time: 2.41584
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.66505

Cumulative Model Updates: 316,132
Cumulative Timesteps: 2,636,481,160

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.89101
Policy Entropy: 2.48876
Value Function Loss: 0.02050

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.09537
Policy Update Magnitude: 0.47331
Value Function Update Magnitude: 0.60495

Collected Steps per Second: 22,511.12601
Overall Steps per Second: 10,618.48220

Timestep Collection Time: 2.22112
Timestep Consumption Time: 2.48765
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.70877

Cumulative Model Updates: 316,138
Cumulative Timesteps: 2,636,531,160

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2636531160...
Checkpoint 2636531160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.43700
Policy Entropy: 2.49375
Value Function Loss: 0.01963

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.08314
Policy Update Magnitude: 0.47466
Value Function Update Magnitude: 0.62889

Collected Steps per Second: 21,891.38963
Overall Steps per Second: 10,484.10660

Timestep Collection Time: 2.28473
Timestep Consumption Time: 2.48592
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.77065

Cumulative Model Updates: 316,144
Cumulative Timesteps: 2,636,581,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.84080
Policy Entropy: 2.48032
Value Function Loss: 0.01962

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.08259
Policy Update Magnitude: 0.48634
Value Function Update Magnitude: 0.62482

Collected Steps per Second: 21,906.95860
Overall Steps per Second: 10,475.16886

Timestep Collection Time: 2.28256
Timestep Consumption Time: 2.49101
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.77357

Cumulative Model Updates: 316,150
Cumulative Timesteps: 2,636,631,180

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2636631180...
Checkpoint 2636631180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.43337
Policy Entropy: 2.46620
Value Function Loss: 0.01980

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.08094
Policy Update Magnitude: 0.48266
Value Function Update Magnitude: 0.60770

Collected Steps per Second: 21,525.87228
Overall Steps per Second: 10,632.52805

Timestep Collection Time: 2.32325
Timestep Consumption Time: 2.38024
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.70349

Cumulative Model Updates: 316,156
Cumulative Timesteps: 2,636,681,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.63059
Policy Entropy: 2.46997
Value Function Loss: 0.01965

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.07694
Policy Update Magnitude: 0.47391
Value Function Update Magnitude: 0.59919

Collected Steps per Second: 22,102.08155
Overall Steps per Second: 10,444.73080

Timestep Collection Time: 2.26277
Timestep Consumption Time: 2.52548
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.78825

Cumulative Model Updates: 316,162
Cumulative Timesteps: 2,636,731,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2636731202...
Checkpoint 2636731202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.51519
Policy Entropy: 2.47585
Value Function Loss: 0.02082

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.07950
Policy Update Magnitude: 0.48589
Value Function Update Magnitude: 0.61609

Collected Steps per Second: 21,870.84512
Overall Steps per Second: 10,561.73906

Timestep Collection Time: 2.28752
Timestep Consumption Time: 2.44939
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.73691

Cumulative Model Updates: 316,168
Cumulative Timesteps: 2,636,781,232

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.94051
Policy Entropy: 2.48442
Value Function Loss: 0.01953

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.09100
Policy Update Magnitude: 0.48679
Value Function Update Magnitude: 0.62981

Collected Steps per Second: 22,513.31677
Overall Steps per Second: 10,754.92071

Timestep Collection Time: 2.22100
Timestep Consumption Time: 2.42822
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.64922

Cumulative Model Updates: 316,174
Cumulative Timesteps: 2,636,831,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2636831234...
Checkpoint 2636831234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.76537
Policy Entropy: 2.46034
Value Function Loss: 0.02055

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.48680
Value Function Update Magnitude: 0.63845

Collected Steps per Second: 22,259.03187
Overall Steps per Second: 10,509.26732

Timestep Collection Time: 2.24736
Timestep Consumption Time: 2.51263
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.75999

Cumulative Model Updates: 316,180
Cumulative Timesteps: 2,636,881,258

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.58119
Policy Entropy: 2.46643
Value Function Loss: 0.01965

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.09177
Policy Update Magnitude: 0.48216
Value Function Update Magnitude: 0.64264

Collected Steps per Second: 22,813.11479
Overall Steps per Second: 10,787.30967

Timestep Collection Time: 2.19216
Timestep Consumption Time: 2.44384
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.63600

Cumulative Model Updates: 316,186
Cumulative Timesteps: 2,636,931,268

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2636931268...
Checkpoint 2636931268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.75368
Policy Entropy: 2.43927
Value Function Loss: 0.01965

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.08639
Policy Update Magnitude: 0.48344
Value Function Update Magnitude: 0.65795

Collected Steps per Second: 22,039.75520
Overall Steps per Second: 10,612.40894

Timestep Collection Time: 2.26935
Timestep Consumption Time: 2.44362
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.71297

Cumulative Model Updates: 316,192
Cumulative Timesteps: 2,636,981,284

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.61226
Policy Entropy: 2.46037
Value Function Loss: 0.02074

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.09682
Policy Update Magnitude: 0.48272
Value Function Update Magnitude: 0.68882

Collected Steps per Second: 22,347.89943
Overall Steps per Second: 10,872.79259

Timestep Collection Time: 2.23797
Timestep Consumption Time: 2.36195
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.59992

Cumulative Model Updates: 316,198
Cumulative Timesteps: 2,637,031,298

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2637031298...
Checkpoint 2637031298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.99609
Policy Entropy: 2.46699
Value Function Loss: 0.02073

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.09019
Policy Update Magnitude: 0.48261
Value Function Update Magnitude: 0.71952

Collected Steps per Second: 22,221.78671
Overall Steps per Second: 10,692.92365

Timestep Collection Time: 2.25022
Timestep Consumption Time: 2.42614
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.67636

Cumulative Model Updates: 316,204
Cumulative Timesteps: 2,637,081,302

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.53657
Policy Entropy: 2.48201
Value Function Loss: 0.02060

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.08393
Policy Update Magnitude: 0.48750
Value Function Update Magnitude: 0.73095

Collected Steps per Second: 22,106.35742
Overall Steps per Second: 10,498.90034

Timestep Collection Time: 2.26243
Timestep Consumption Time: 2.50131
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.76374

Cumulative Model Updates: 316,210
Cumulative Timesteps: 2,637,131,316

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2637131316...
Checkpoint 2637131316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.07650
Policy Entropy: 2.46806
Value Function Loss: 0.02084

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.07928
Policy Update Magnitude: 0.49331
Value Function Update Magnitude: 0.71648

Collected Steps per Second: 21,609.32303
Overall Steps per Second: 10,566.25512

Timestep Collection Time: 2.31483
Timestep Consumption Time: 2.41929
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.73413

Cumulative Model Updates: 316,216
Cumulative Timesteps: 2,637,181,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.06854
Policy Entropy: 2.45937
Value Function Loss: 0.02098

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.48951
Value Function Update Magnitude: 0.68876

Collected Steps per Second: 22,206.42976
Overall Steps per Second: 10,738.99269

Timestep Collection Time: 2.25241
Timestep Consumption Time: 2.40520
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.65761

Cumulative Model Updates: 316,222
Cumulative Timesteps: 2,637,231,356

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2637231356...
Checkpoint 2637231356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.11114
Policy Entropy: 2.46213
Value Function Loss: 0.02068

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.09650
Policy Update Magnitude: 0.48665
Value Function Update Magnitude: 0.67351

Collected Steps per Second: 22,062.89915
Overall Steps per Second: 10,471.74072

Timestep Collection Time: 2.26761
Timestep Consumption Time: 2.51001
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.77762

Cumulative Model Updates: 316,228
Cumulative Timesteps: 2,637,281,386

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.89341
Policy Entropy: 2.46950
Value Function Loss: 0.01980

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.08980
Policy Update Magnitude: 0.48180
Value Function Update Magnitude: 0.64944

Collected Steps per Second: 22,311.45137
Overall Steps per Second: 10,422.86021

Timestep Collection Time: 2.24172
Timestep Consumption Time: 2.55696
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.79868

Cumulative Model Updates: 316,234
Cumulative Timesteps: 2,637,331,402

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2637331402...
Checkpoint 2637331402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.10336
Policy Entropy: 2.45810
Value Function Loss: 0.02067

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.08847
Policy Update Magnitude: 0.48583
Value Function Update Magnitude: 0.63755

Collected Steps per Second: 22,037.47755
Overall Steps per Second: 10,545.69713

Timestep Collection Time: 2.26968
Timestep Consumption Time: 2.47330
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.74298

Cumulative Model Updates: 316,240
Cumulative Timesteps: 2,637,381,420

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.97976
Policy Entropy: 2.44638
Value Function Loss: 0.02121

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.49258
Value Function Update Magnitude: 0.65271

Collected Steps per Second: 22,484.68188
Overall Steps per Second: 10,601.75303

Timestep Collection Time: 2.22436
Timestep Consumption Time: 2.49316
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.71752

Cumulative Model Updates: 316,246
Cumulative Timesteps: 2,637,431,434

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2637431434...
Checkpoint 2637431434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.68437
Policy Entropy: 2.42770
Value Function Loss: 0.02126

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.09576
Policy Update Magnitude: 0.49323
Value Function Update Magnitude: 0.67780

Collected Steps per Second: 22,102.60019
Overall Steps per Second: 10,652.20118

Timestep Collection Time: 2.26344
Timestep Consumption Time: 2.43305
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.69649

Cumulative Model Updates: 316,252
Cumulative Timesteps: 2,637,481,462

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.72182
Policy Entropy: 2.44980
Value Function Loss: 0.01964

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.09156
Policy Update Magnitude: 0.48907
Value Function Update Magnitude: 0.68243

Collected Steps per Second: 22,644.53313
Overall Steps per Second: 10,738.55736

Timestep Collection Time: 2.20822
Timestep Consumption Time: 2.44828
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.65649

Cumulative Model Updates: 316,258
Cumulative Timesteps: 2,637,531,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2637531466...
Checkpoint 2637531466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.89595
Policy Entropy: 2.45605
Value Function Loss: 0.02001

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.09676
Policy Update Magnitude: 0.49791
Value Function Update Magnitude: 0.67571

Collected Steps per Second: 21,946.38433
Overall Steps per Second: 10,483.49668

Timestep Collection Time: 2.27883
Timestep Consumption Time: 2.49172
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.77055

Cumulative Model Updates: 316,264
Cumulative Timesteps: 2,637,581,478

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.47273
Policy Entropy: 2.44949
Value Function Loss: 0.02075

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.10728
Policy Update Magnitude: 0.47574
Value Function Update Magnitude: 0.67272

Collected Steps per Second: 21,532.58837
Overall Steps per Second: 10,654.43489

Timestep Collection Time: 2.32290
Timestep Consumption Time: 2.37167
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.69457

Cumulative Model Updates: 316,270
Cumulative Timesteps: 2,637,631,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2637631496...
Checkpoint 2637631496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.39421
Policy Entropy: 2.43548
Value Function Loss: 0.02130

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.44857
Value Function Update Magnitude: 0.67354

Collected Steps per Second: 22,010.88440
Overall Steps per Second: 10,625.86800

Timestep Collection Time: 2.27188
Timestep Consumption Time: 2.43419
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.70606

Cumulative Model Updates: 316,276
Cumulative Timesteps: 2,637,681,502

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.03767
Policy Entropy: 2.42913
Value Function Loss: 0.02091

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.10889
Policy Update Magnitude: 0.46160
Value Function Update Magnitude: 0.68611

Collected Steps per Second: 21,723.01111
Overall Steps per Second: 10,572.27367

Timestep Collection Time: 2.30226
Timestep Consumption Time: 2.42823
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.73049

Cumulative Model Updates: 316,282
Cumulative Timesteps: 2,637,731,514

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2637731514...
Checkpoint 2637731514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.30192
Policy Entropy: 2.41358
Value Function Loss: 0.02035

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.10935
Policy Update Magnitude: 0.48807
Value Function Update Magnitude: 0.70204

Collected Steps per Second: 21,779.71267
Overall Steps per Second: 10,648.35335

Timestep Collection Time: 2.29700
Timestep Consumption Time: 2.40119
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.69819

Cumulative Model Updates: 316,288
Cumulative Timesteps: 2,637,781,542

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.47073
Policy Entropy: 2.40941
Value Function Loss: 0.02175

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.10158
Policy Update Magnitude: 0.50174
Value Function Update Magnitude: 0.69157

Collected Steps per Second: 21,988.57825
Overall Steps per Second: 10,798.23717

Timestep Collection Time: 2.27436
Timestep Consumption Time: 2.35695
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.63131

Cumulative Model Updates: 316,294
Cumulative Timesteps: 2,637,831,552

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2637831552...
Checkpoint 2637831552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.74030
Policy Entropy: 2.40333
Value Function Loss: 0.02169

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.49695
Value Function Update Magnitude: 0.69313

Collected Steps per Second: 21,983.12359
Overall Steps per Second: 10,607.15617

Timestep Collection Time: 2.27465
Timestep Consumption Time: 2.43952
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.71418

Cumulative Model Updates: 316,300
Cumulative Timesteps: 2,637,881,556

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.99080
Policy Entropy: 2.41902
Value Function Loss: 0.02192

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.09895
Policy Update Magnitude: 0.49052
Value Function Update Magnitude: 0.68956

Collected Steps per Second: 22,350.06925
Overall Steps per Second: 10,442.41775

Timestep Collection Time: 2.23793
Timestep Consumption Time: 2.55195
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.78989

Cumulative Model Updates: 316,306
Cumulative Timesteps: 2,637,931,574

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2637931574...
Checkpoint 2637931574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.38719
Policy Entropy: 2.41785
Value Function Loss: 0.02119

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.10268
Policy Update Magnitude: 0.48900
Value Function Update Magnitude: 0.66953

Collected Steps per Second: 21,987.14507
Overall Steps per Second: 10,675.65937

Timestep Collection Time: 2.27415
Timestep Consumption Time: 2.40959
PPO Batch Consumption Time: 0.28585
Total Iteration Time: 4.68374

Cumulative Model Updates: 316,312
Cumulative Timesteps: 2,637,981,576

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.71859
Policy Entropy: 2.41501
Value Function Loss: 0.02264

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.10410
Policy Update Magnitude: 0.49865
Value Function Update Magnitude: 0.66166

Collected Steps per Second: 22,468.82908
Overall Steps per Second: 10,565.26089

Timestep Collection Time: 2.22602
Timestep Consumption Time: 2.50799
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.73401

Cumulative Model Updates: 316,318
Cumulative Timesteps: 2,638,031,592

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2638031592...
Checkpoint 2638031592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.60959
Policy Entropy: 2.41439
Value Function Loss: 0.02264

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.09442
Policy Update Magnitude: 0.51668
Value Function Update Magnitude: 0.68979

Collected Steps per Second: 22,204.63107
Overall Steps per Second: 10,619.65004

Timestep Collection Time: 2.25214
Timestep Consumption Time: 2.45686
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.70901

Cumulative Model Updates: 316,324
Cumulative Timesteps: 2,638,081,600

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.08111
Policy Entropy: 2.42710
Value Function Loss: 0.02334

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.10854
Policy Update Magnitude: 0.51226
Value Function Update Magnitude: 0.71427

Collected Steps per Second: 22,307.69015
Overall Steps per Second: 10,495.70007

Timestep Collection Time: 2.24263
Timestep Consumption Time: 2.52389
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.76652

Cumulative Model Updates: 316,330
Cumulative Timesteps: 2,638,131,628

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2638131628...
Checkpoint 2638131628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.39699
Policy Entropy: 2.43400
Value Function Loss: 0.02263

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.11490
Policy Update Magnitude: 0.48759
Value Function Update Magnitude: 0.70234

Collected Steps per Second: 22,133.93861
Overall Steps per Second: 10,564.48231

Timestep Collection Time: 2.25979
Timestep Consumption Time: 2.47476
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.73454

Cumulative Model Updates: 316,336
Cumulative Timesteps: 2,638,181,646

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.20499
Policy Entropy: 2.44156
Value Function Loss: 0.02312

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.12628
Policy Update Magnitude: 0.45535
Value Function Update Magnitude: 0.67590

Collected Steps per Second: 22,402.01069
Overall Steps per Second: 10,889.18692

Timestep Collection Time: 2.23239
Timestep Consumption Time: 2.36024
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.59263

Cumulative Model Updates: 316,342
Cumulative Timesteps: 2,638,231,656

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2638231656...
Checkpoint 2638231656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.74062
Policy Entropy: 2.42977
Value Function Loss: 0.02243

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.10211
Policy Update Magnitude: 0.47719
Value Function Update Magnitude: 0.65741

Collected Steps per Second: 21,816.74640
Overall Steps per Second: 10,570.23745

Timestep Collection Time: 2.29264
Timestep Consumption Time: 2.43932
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.73197

Cumulative Model Updates: 316,348
Cumulative Timesteps: 2,638,281,674

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.35611
Policy Entropy: 2.41170
Value Function Loss: 0.02231

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.09357
Policy Update Magnitude: 0.50260
Value Function Update Magnitude: 0.65253

Collected Steps per Second: 22,186.05252
Overall Steps per Second: 10,531.09206

Timestep Collection Time: 2.25376
Timestep Consumption Time: 2.49428
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.74804

Cumulative Model Updates: 316,354
Cumulative Timesteps: 2,638,331,676

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2638331676...
Checkpoint 2638331676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.28480
Policy Entropy: 2.42924
Value Function Loss: 0.02100

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.09026
Policy Update Magnitude: 0.48447
Value Function Update Magnitude: 0.64505

Collected Steps per Second: 21,531.17629
Overall Steps per Second: 10,694.55154

Timestep Collection Time: 2.32259
Timestep Consumption Time: 2.35344
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.67603

Cumulative Model Updates: 316,360
Cumulative Timesteps: 2,638,381,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.96907
Policy Entropy: 2.44100
Value Function Loss: 0.02076

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.08776
Policy Update Magnitude: 0.47911
Value Function Update Magnitude: 0.63833

Collected Steps per Second: 21,730.69346
Overall Steps per Second: 10,400.07369

Timestep Collection Time: 2.30172
Timestep Consumption Time: 2.50767
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.80939

Cumulative Model Updates: 316,366
Cumulative Timesteps: 2,638,431,702

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2638431702...
Checkpoint 2638431702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.90458
Policy Entropy: 2.43665
Value Function Loss: 0.02067

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.08593
Policy Update Magnitude: 0.48739
Value Function Update Magnitude: 0.64205

Collected Steps per Second: 21,851.08195
Overall Steps per Second: 10,587.31856

Timestep Collection Time: 2.28977
Timestep Consumption Time: 2.43607
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.72584

Cumulative Model Updates: 316,372
Cumulative Timesteps: 2,638,481,736

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.71219
Policy Entropy: 2.41129
Value Function Loss: 0.02028

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.08794
Policy Update Magnitude: 0.49613
Value Function Update Magnitude: 0.65426

Collected Steps per Second: 22,459.03131
Overall Steps per Second: 10,515.85204

Timestep Collection Time: 2.22681
Timestep Consumption Time: 2.52906
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.75587

Cumulative Model Updates: 316,378
Cumulative Timesteps: 2,638,531,748

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2638531748...
Checkpoint 2638531748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.12905
Policy Entropy: 2.40550
Value Function Loss: 0.02027

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.08706
Policy Update Magnitude: 0.48807
Value Function Update Magnitude: 0.65821

Collected Steps per Second: 22,219.19275
Overall Steps per Second: 10,609.96836

Timestep Collection Time: 2.25049
Timestep Consumption Time: 2.46244
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.71293

Cumulative Model Updates: 316,384
Cumulative Timesteps: 2,638,581,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.59099
Policy Entropy: 2.40535
Value Function Loss: 0.02032

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.08634
Policy Update Magnitude: 0.48050
Value Function Update Magnitude: 0.64583

Collected Steps per Second: 23,168.26753
Overall Steps per Second: 10,896.32038

Timestep Collection Time: 2.15899
Timestep Consumption Time: 2.43155
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.59054

Cumulative Model Updates: 316,390
Cumulative Timesteps: 2,638,631,772

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2638631772...
Checkpoint 2638631772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.60581
Policy Entropy: 2.41115
Value Function Loss: 0.02086

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.47553
Value Function Update Magnitude: 0.62910

Collected Steps per Second: 22,188.71383
Overall Steps per Second: 10,695.61945

Timestep Collection Time: 2.25403
Timestep Consumption Time: 2.42209
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.67612

Cumulative Model Updates: 316,396
Cumulative Timesteps: 2,638,681,786

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.89953
Policy Entropy: 2.39781
Value Function Loss: 0.02107

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.09080
Policy Update Magnitude: 0.47959
Value Function Update Magnitude: 0.65164

Collected Steps per Second: 22,492.52670
Overall Steps per Second: 10,557.30202

Timestep Collection Time: 2.22358
Timestep Consumption Time: 2.51380
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.73738

Cumulative Model Updates: 316,402
Cumulative Timesteps: 2,638,731,800

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2638731800...
Checkpoint 2638731800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.49628
Policy Entropy: 2.43512
Value Function Loss: 0.02207

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.08546
Policy Update Magnitude: 0.49309
Value Function Update Magnitude: 0.66559

Collected Steps per Second: 22,110.36602
Overall Steps per Second: 10,715.15246

Timestep Collection Time: 2.26247
Timestep Consumption Time: 2.40606
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.66853

Cumulative Model Updates: 316,408
Cumulative Timesteps: 2,638,781,824

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.76575
Policy Entropy: 2.43211
Value Function Loss: 0.02150

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.08499
Policy Update Magnitude: 0.49324
Value Function Update Magnitude: 0.66297

Collected Steps per Second: 22,264.80942
Overall Steps per Second: 10,682.86627

Timestep Collection Time: 2.24668
Timestep Consumption Time: 2.43577
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.68245

Cumulative Model Updates: 316,414
Cumulative Timesteps: 2,638,831,846

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2638831846...
Checkpoint 2638831846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.90496
Policy Entropy: 2.42057
Value Function Loss: 0.02073

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.09054
Policy Update Magnitude: 0.48757
Value Function Update Magnitude: 0.65109

Collected Steps per Second: 21,684.75232
Overall Steps per Second: 10,418.72576

Timestep Collection Time: 2.30687
Timestep Consumption Time: 2.49448
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.80135

Cumulative Model Updates: 316,420
Cumulative Timesteps: 2,638,881,870

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.91720
Policy Entropy: 2.41554
Value Function Loss: 0.02034

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.08963
Policy Update Magnitude: 0.48458
Value Function Update Magnitude: 0.63963

Collected Steps per Second: 22,038.07808
Overall Steps per Second: 10,677.77757

Timestep Collection Time: 2.26953
Timestep Consumption Time: 2.41459
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.68412

Cumulative Model Updates: 316,426
Cumulative Timesteps: 2,638,931,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2638931886...
Checkpoint 2638931886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.46811
Policy Entropy: 2.41125
Value Function Loss: 0.02005

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.08515
Policy Update Magnitude: 0.49187
Value Function Update Magnitude: 0.63788

Collected Steps per Second: 21,820.05051
Overall Steps per Second: 10,617.83890

Timestep Collection Time: 2.29193
Timestep Consumption Time: 2.41807
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.71000

Cumulative Model Updates: 316,432
Cumulative Timesteps: 2,638,981,896

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.66334
Policy Entropy: 2.42463
Value Function Loss: 0.02106

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.49516
Value Function Update Magnitude: 0.64130

Collected Steps per Second: 21,677.02131
Overall Steps per Second: 10,542.24205

Timestep Collection Time: 2.30779
Timestep Consumption Time: 2.43750
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.74529

Cumulative Model Updates: 316,438
Cumulative Timesteps: 2,639,031,922

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2639031922...
Checkpoint 2639031922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.86278
Policy Entropy: 2.43900
Value Function Loss: 0.02112

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.48943
Value Function Update Magnitude: 0.65032

Collected Steps per Second: 21,878.71253
Overall Steps per Second: 10,586.22608

Timestep Collection Time: 2.28651
Timestep Consumption Time: 2.43906
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.72557

Cumulative Model Updates: 316,444
Cumulative Timesteps: 2,639,081,948

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.58863
Policy Entropy: 2.42453
Value Function Loss: 0.02191

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 0.49758
Value Function Update Magnitude: 0.66203

Collected Steps per Second: 22,382.56827
Overall Steps per Second: 10,508.32742

Timestep Collection Time: 2.23442
Timestep Consumption Time: 2.52486
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.75927

Cumulative Model Updates: 316,450
Cumulative Timesteps: 2,639,131,960

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2639131960...
Checkpoint 2639131960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.52933
Policy Entropy: 2.42063
Value Function Loss: 0.02129

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.08688
Policy Update Magnitude: 0.49695
Value Function Update Magnitude: 0.66815

Collected Steps per Second: 22,175.56958
Overall Steps per Second: 10,496.12895

Timestep Collection Time: 2.25573
Timestep Consumption Time: 2.51003
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.76576

Cumulative Model Updates: 316,456
Cumulative Timesteps: 2,639,181,982

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.06143
Policy Entropy: 2.40473
Value Function Loss: 0.02117

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.50270
Value Function Update Magnitude: 0.65513

Collected Steps per Second: 22,196.99590
Overall Steps per Second: 10,682.72495

Timestep Collection Time: 2.25382
Timestep Consumption Time: 2.42926
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.68307

Cumulative Model Updates: 316,462
Cumulative Timesteps: 2,639,232,010

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2639232010...
Checkpoint 2639232010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.15061
Policy Entropy: 2.41912
Value Function Loss: 0.02068

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.10564
Policy Update Magnitude: 0.47730
Value Function Update Magnitude: 0.63170

Collected Steps per Second: 22,434.02537
Overall Steps per Second: 10,544.89305

Timestep Collection Time: 2.22947
Timestep Consumption Time: 2.51368
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.74315

Cumulative Model Updates: 316,468
Cumulative Timesteps: 2,639,282,026

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.80240
Policy Entropy: 2.42420
Value Function Loss: 0.02038

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.09724
Policy Update Magnitude: 0.46642
Value Function Update Magnitude: 0.61194

Collected Steps per Second: 22,269.02607
Overall Steps per Second: 10,468.33954

Timestep Collection Time: 2.24635
Timestep Consumption Time: 2.53225
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 4.77860

Cumulative Model Updates: 316,474
Cumulative Timesteps: 2,639,332,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2639332050...
Checkpoint 2639332050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.69815
Policy Entropy: 2.39679
Value Function Loss: 0.02018

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.10167
Policy Update Magnitude: 0.48041
Value Function Update Magnitude: 0.62318

Collected Steps per Second: 22,404.52444
Overall Steps per Second: 10,612.66262

Timestep Collection Time: 2.23250
Timestep Consumption Time: 2.48055
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.71305

Cumulative Model Updates: 316,480
Cumulative Timesteps: 2,639,382,068

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.80972
Policy Entropy: 2.37610
Value Function Loss: 0.01929

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.10666
Policy Update Magnitude: 0.48491
Value Function Update Magnitude: 0.62540

Collected Steps per Second: 22,332.16921
Overall Steps per Second: 10,878.90467

Timestep Collection Time: 2.23991
Timestep Consumption Time: 2.35817
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.59807

Cumulative Model Updates: 316,486
Cumulative Timesteps: 2,639,432,090

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2639432090...
Checkpoint 2639432090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.46657
Policy Entropy: 2.39705
Value Function Loss: 0.01893

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.09429
Policy Update Magnitude: 0.48100
Value Function Update Magnitude: 0.61961

Collected Steps per Second: 21,684.08431
Overall Steps per Second: 10,451.47812

Timestep Collection Time: 2.30704
Timestep Consumption Time: 2.47946
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.78650

Cumulative Model Updates: 316,492
Cumulative Timesteps: 2,639,482,116

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.40128
Policy Entropy: 2.40517
Value Function Loss: 0.02021

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.09162
Policy Update Magnitude: 0.48779
Value Function Update Magnitude: 0.61562

Collected Steps per Second: 21,171.04776
Overall Steps per Second: 10,270.33959

Timestep Collection Time: 2.36200
Timestep Consumption Time: 2.50697
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.86897

Cumulative Model Updates: 316,498
Cumulative Timesteps: 2,639,532,122

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2639532122...
Checkpoint 2639532122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.96545
Policy Entropy: 2.44057
Value Function Loss: 0.02113

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.48508
Value Function Update Magnitude: 0.61259

Collected Steps per Second: 21,729.44959
Overall Steps per Second: 10,579.00354

Timestep Collection Time: 2.30195
Timestep Consumption Time: 2.42629
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.72823

Cumulative Model Updates: 316,504
Cumulative Timesteps: 2,639,582,142

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.22849
Policy Entropy: 2.41090
Value Function Loss: 0.02261

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.09966
Policy Update Magnitude: 0.48486
Value Function Update Magnitude: 0.62539

Collected Steps per Second: 21,809.73742
Overall Steps per Second: 10,588.02835

Timestep Collection Time: 2.29402
Timestep Consumption Time: 2.43132
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.72534

Cumulative Model Updates: 316,510
Cumulative Timesteps: 2,639,632,174

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2639632174...
Checkpoint 2639632174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.91064
Policy Entropy: 2.43527
Value Function Loss: 0.02107

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.10770
Policy Update Magnitude: 0.48692
Value Function Update Magnitude: 0.62665

Collected Steps per Second: 22,299.57077
Overall Steps per Second: 10,597.16365

Timestep Collection Time: 2.24237
Timestep Consumption Time: 2.47625
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.71862

Cumulative Model Updates: 316,516
Cumulative Timesteps: 2,639,682,178

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.04484
Policy Entropy: 2.41319
Value Function Loss: 0.02048

Mean KL Divergence: 0.02306
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.45552
Value Function Update Magnitude: 0.60892

Collected Steps per Second: 21,967.34921
Overall Steps per Second: 10,432.02425

Timestep Collection Time: 2.27692
Timestep Consumption Time: 2.51773
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.79466

Cumulative Model Updates: 316,522
Cumulative Timesteps: 2,639,732,196

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2639732196...
Checkpoint 2639732196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.81113
Policy Entropy: 2.41060
Value Function Loss: 0.01993

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.10315
Policy Update Magnitude: 0.48663
Value Function Update Magnitude: 0.59984

Collected Steps per Second: 22,313.29508
Overall Steps per Second: 10,623.78251

Timestep Collection Time: 2.24216
Timestep Consumption Time: 2.46708
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.70925

Cumulative Model Updates: 316,528
Cumulative Timesteps: 2,639,782,226

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.92678
Policy Entropy: 2.40373
Value Function Loss: 0.02110

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.09336
Policy Update Magnitude: 0.50209
Value Function Update Magnitude: 0.61482

Collected Steps per Second: 22,520.02603
Overall Steps per Second: 10,597.54093

Timestep Collection Time: 2.22113
Timestep Consumption Time: 2.49883
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.71996

Cumulative Model Updates: 316,534
Cumulative Timesteps: 2,639,832,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2639832246...
Checkpoint 2639832246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.50761
Policy Entropy: 2.41785
Value Function Loss: 0.02234

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.08813
Policy Update Magnitude: 0.49891
Value Function Update Magnitude: 0.63341

Collected Steps per Second: 22,453.07347
Overall Steps per Second: 10,562.30874

Timestep Collection Time: 2.22767
Timestep Consumption Time: 2.50785
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.73552

Cumulative Model Updates: 316,540
Cumulative Timesteps: 2,639,882,264

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.08681
Policy Entropy: 2.41208
Value Function Loss: 0.02378

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.09961
Policy Update Magnitude: 0.49597
Value Function Update Magnitude: 0.63846

Collected Steps per Second: 22,340.65963
Overall Steps per Second: 10,738.57635

Timestep Collection Time: 2.23852
Timestep Consumption Time: 2.41852
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.65704

Cumulative Model Updates: 316,546
Cumulative Timesteps: 2,639,932,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2639932274...
Checkpoint 2639932274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.49776
Policy Entropy: 2.41575
Value Function Loss: 0.02189

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.10023
Policy Update Magnitude: 0.48206
Value Function Update Magnitude: 0.63920

Collected Steps per Second: 22,207.50582
Overall Steps per Second: 10,764.69217

Timestep Collection Time: 2.25221
Timestep Consumption Time: 2.39409
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.64630

Cumulative Model Updates: 316,552
Cumulative Timesteps: 2,639,982,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.09357
Policy Entropy: 2.40178
Value Function Loss: 0.02016

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.09746
Policy Update Magnitude: 0.48093
Value Function Update Magnitude: 0.62616

Collected Steps per Second: 22,329.21969
Overall Steps per Second: 10,552.97514

Timestep Collection Time: 2.23985
Timestep Consumption Time: 2.49948
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.73933

Cumulative Model Updates: 316,558
Cumulative Timesteps: 2,640,032,304

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2640032304...
Checkpoint 2640032304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.28512
Policy Entropy: 2.40012
Value Function Loss: 0.01975

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.09142
Policy Update Magnitude: 0.49318
Value Function Update Magnitude: 0.59624

Collected Steps per Second: 22,185.98494
Overall Steps per Second: 10,555.39838

Timestep Collection Time: 2.25422
Timestep Consumption Time: 2.48383
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.73805

Cumulative Model Updates: 316,564
Cumulative Timesteps: 2,640,082,316

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.75225
Policy Entropy: 2.42568
Value Function Loss: 0.02030

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.08608
Policy Update Magnitude: 0.49543
Value Function Update Magnitude: 0.60012

Collected Steps per Second: 21,865.96981
Overall Steps per Second: 10,450.61613

Timestep Collection Time: 2.28785
Timestep Consumption Time: 2.49905
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.78689

Cumulative Model Updates: 316,570
Cumulative Timesteps: 2,640,132,342

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2640132342...
Checkpoint 2640132342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.07938
Policy Entropy: 2.40100
Value Function Loss: 0.02274

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.09516
Policy Update Magnitude: 0.50345
Value Function Update Magnitude: 0.60999

Collected Steps per Second: 22,053.77025
Overall Steps per Second: 10,640.60570

Timestep Collection Time: 2.26746
Timestep Consumption Time: 2.43209
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.69954

Cumulative Model Updates: 316,576
Cumulative Timesteps: 2,640,182,348

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.77299
Policy Entropy: 2.41514
Value Function Loss: 0.02244

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.09723
Policy Update Magnitude: 0.49490
Value Function Update Magnitude: 0.63480

Collected Steps per Second: 21,814.95336
Overall Steps per Second: 10,445.08176

Timestep Collection Time: 2.29301
Timestep Consumption Time: 2.49603
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.78905

Cumulative Model Updates: 316,582
Cumulative Timesteps: 2,640,232,370

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2640232370...
Checkpoint 2640232370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.66240
Policy Entropy: 2.39728
Value Function Loss: 0.02334

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.48963
Value Function Update Magnitude: 0.65383

Collected Steps per Second: 21,894.88538
Overall Steps per Second: 10,605.04850

Timestep Collection Time: 2.28473
Timestep Consumption Time: 2.43226
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.71700

Cumulative Model Updates: 316,588
Cumulative Timesteps: 2,640,282,394

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.26239
Policy Entropy: 2.41765
Value Function Loss: 0.02199

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.49556
Value Function Update Magnitude: 0.66872

Collected Steps per Second: 22,011.87790
Overall Steps per Second: 10,463.87532

Timestep Collection Time: 2.27259
Timestep Consumption Time: 2.50805
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.78064

Cumulative Model Updates: 316,594
Cumulative Timesteps: 2,640,332,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2640332418...
Checkpoint 2640332418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.94604
Policy Entropy: 2.42997
Value Function Loss: 0.02104

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.09227
Policy Update Magnitude: 0.49197
Value Function Update Magnitude: 0.67167

Collected Steps per Second: 22,263.25998
Overall Steps per Second: 10,703.71080

Timestep Collection Time: 2.24747
Timestep Consumption Time: 2.42717
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.67464

Cumulative Model Updates: 316,600
Cumulative Timesteps: 2,640,382,454

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.74247
Policy Entropy: 2.40870
Value Function Loss: 0.02140

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.49169
Value Function Update Magnitude: 0.67415

Collected Steps per Second: 23,223.87881
Overall Steps per Second: 10,900.22866

Timestep Collection Time: 2.15313
Timestep Consumption Time: 2.43430
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.58743

Cumulative Model Updates: 316,606
Cumulative Timesteps: 2,640,432,458

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2640432458...
Checkpoint 2640432458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.11304
Policy Entropy: 2.39203
Value Function Loss: 0.02125

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.08381
Policy Update Magnitude: 0.48857
Value Function Update Magnitude: 0.67103

Collected Steps per Second: 22,608.55746
Overall Steps per Second: 10,594.28652

Timestep Collection Time: 2.21244
Timestep Consumption Time: 2.50898
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.72141

Cumulative Model Updates: 316,612
Cumulative Timesteps: 2,640,482,478

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.14778
Policy Entropy: 2.38284
Value Function Loss: 0.02205

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.08906
Policy Update Magnitude: 0.49607
Value Function Update Magnitude: 0.66153

Collected Steps per Second: 22,256.46141
Overall Steps per Second: 10,584.47574

Timestep Collection Time: 2.24681
Timestep Consumption Time: 2.47766
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.72447

Cumulative Model Updates: 316,618
Cumulative Timesteps: 2,640,532,484

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2640532484...
Checkpoint 2640532484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169.87328
Policy Entropy: 2.38544
Value Function Loss: 0.02154

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.09453
Policy Update Magnitude: 0.49594
Value Function Update Magnitude: 0.66048

Collected Steps per Second: 22,418.22632
Overall Steps per Second: 10,900.29825

Timestep Collection Time: 2.23104
Timestep Consumption Time: 2.35746
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.58850

Cumulative Model Updates: 316,624
Cumulative Timesteps: 2,640,582,500

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.02636
Policy Entropy: 2.38373
Value Function Loss: 0.02044

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.09879
Policy Update Magnitude: 0.49218
Value Function Update Magnitude: 0.67945

Collected Steps per Second: 22,347.68553
Overall Steps per Second: 10,512.68871

Timestep Collection Time: 2.23835
Timestep Consumption Time: 2.51990
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.75825

Cumulative Model Updates: 316,630
Cumulative Timesteps: 2,640,632,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2640632522...
Checkpoint 2640632522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.70956
Policy Entropy: 2.38122
Value Function Loss: 0.01999

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.49223
Value Function Update Magnitude: 0.67525

Collected Steps per Second: 21,637.55588
Overall Steps per Second: 10,569.34158

Timestep Collection Time: 2.31098
Timestep Consumption Time: 2.42006
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.73104

Cumulative Model Updates: 316,636
Cumulative Timesteps: 2,640,682,526

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.98300
Policy Entropy: 2.40704
Value Function Loss: 0.01967

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.09430
Policy Update Magnitude: 0.48511
Value Function Update Magnitude: 0.65493

Collected Steps per Second: 21,770.81547
Overall Steps per Second: 10,527.33095

Timestep Collection Time: 2.29693
Timestep Consumption Time: 2.45318
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.75011

Cumulative Model Updates: 316,642
Cumulative Timesteps: 2,640,732,532

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2640732532...
Checkpoint 2640732532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.99246
Policy Entropy: 2.42765
Value Function Loss: 0.01928

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.10800
Policy Update Magnitude: 0.48323
Value Function Update Magnitude: 0.64045

Collected Steps per Second: 21,880.44768
Overall Steps per Second: 10,652.95248

Timestep Collection Time: 2.28515
Timestep Consumption Time: 2.40839
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.69353

Cumulative Model Updates: 316,648
Cumulative Timesteps: 2,640,782,532

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.18519
Policy Entropy: 2.41800
Value Function Loss: 0.02052

Mean KL Divergence: 0.02148
SB3 Clip Fraction: 0.11870
Policy Update Magnitude: 0.49323
Value Function Update Magnitude: 0.63142

Collected Steps per Second: 22,957.68423
Overall Steps per Second: 10,826.21396

Timestep Collection Time: 2.17836
Timestep Consumption Time: 2.44099
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.61934

Cumulative Model Updates: 316,654
Cumulative Timesteps: 2,640,832,542

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2640832542...
Checkpoint 2640832542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.24634
Policy Entropy: 2.40419
Value Function Loss: 0.02075

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.11171
Policy Update Magnitude: 0.50635
Value Function Update Magnitude: 0.63683

Collected Steps per Second: 21,709.52366
Overall Steps per Second: 10,421.97130

Timestep Collection Time: 2.30433
Timestep Consumption Time: 2.49572
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.80005

Cumulative Model Updates: 316,660
Cumulative Timesteps: 2,640,882,568

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.12148
Policy Entropy: 2.39330
Value Function Loss: 0.02088

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.10740
Policy Update Magnitude: 0.49628
Value Function Update Magnitude: 0.62981

Collected Steps per Second: 22,177.06232
Overall Steps per Second: 10,392.04990

Timestep Collection Time: 2.25593
Timestep Consumption Time: 2.55832
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.81426

Cumulative Model Updates: 316,666
Cumulative Timesteps: 2,640,932,598

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2640932598...
Checkpoint 2640932598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.77894
Policy Entropy: 2.40150
Value Function Loss: 0.02044

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.09501
Policy Update Magnitude: 0.48673
Value Function Update Magnitude: 0.63127

Collected Steps per Second: 22,214.14545
Overall Steps per Second: 10,556.88464

Timestep Collection Time: 2.25145
Timestep Consumption Time: 2.48612
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.73757

Cumulative Model Updates: 316,672
Cumulative Timesteps: 2,640,982,612

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.88361
Policy Entropy: 2.39328
Value Function Loss: 0.02092

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.09772
Policy Update Magnitude: 0.48982
Value Function Update Magnitude: 0.65244

Collected Steps per Second: 22,602.36667
Overall Steps per Second: 10,632.60831

Timestep Collection Time: 2.21295
Timestep Consumption Time: 2.49125
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.70421

Cumulative Model Updates: 316,678
Cumulative Timesteps: 2,641,032,630

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2641032630...
Checkpoint 2641032630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.45545
Policy Entropy: 2.39292
Value Function Loss: 0.02187

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.10787
Policy Update Magnitude: 0.50240
Value Function Update Magnitude: 0.68383

Collected Steps per Second: 22,452.45748
Overall Steps per Second: 10,605.09645

Timestep Collection Time: 2.22702
Timestep Consumption Time: 2.48789
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.71490

Cumulative Model Updates: 316,684
Cumulative Timesteps: 2,641,082,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.44101
Policy Entropy: 2.39650
Value Function Loss: 0.02181

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.09566
Policy Update Magnitude: 0.50731
Value Function Update Magnitude: 0.69713

Collected Steps per Second: 22,576.88069
Overall Steps per Second: 10,753.84801

Timestep Collection Time: 2.21545
Timestep Consumption Time: 2.43572
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.65117

Cumulative Model Updates: 316,690
Cumulative Timesteps: 2,641,132,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2641132650...
Checkpoint 2641132650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.39390
Policy Entropy: 2.41572
Value Function Loss: 0.02151

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.51059
Value Function Update Magnitude: 0.70736

Collected Steps per Second: 22,105.73893
Overall Steps per Second: 10,636.02331

Timestep Collection Time: 2.26249
Timestep Consumption Time: 2.43983
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.70232

Cumulative Model Updates: 316,696
Cumulative Timesteps: 2,641,182,664

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.62238
Policy Entropy: 2.39877
Value Function Loss: 0.02112

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.49277
Value Function Update Magnitude: 0.69309

Collected Steps per Second: 22,703.71740
Overall Steps per Second: 10,635.53599

Timestep Collection Time: 2.20352
Timestep Consumption Time: 2.50034
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.70385

Cumulative Model Updates: 316,702
Cumulative Timesteps: 2,641,232,692

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2641232692...
Checkpoint 2641232692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.37961
Policy Entropy: 2.39738
Value Function Loss: 0.02153

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.09542
Policy Update Magnitude: 0.49868
Value Function Update Magnitude: 0.66217

Collected Steps per Second: 22,405.36130
Overall Steps per Second: 10,570.13604

Timestep Collection Time: 2.23170
Timestep Consumption Time: 2.49880
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.73050

Cumulative Model Updates: 316,708
Cumulative Timesteps: 2,641,282,694

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.88298
Policy Entropy: 2.38029
Value Function Loss: 0.02186

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.09167
Policy Update Magnitude: 0.50588
Value Function Update Magnitude: 0.66607

Collected Steps per Second: 21,520.62349
Overall Steps per Second: 10,394.75373

Timestep Collection Time: 2.32400
Timestep Consumption Time: 2.48746
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.81147

Cumulative Model Updates: 316,714
Cumulative Timesteps: 2,641,332,708

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2641332708...
Checkpoint 2641332708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.63649
Policy Entropy: 2.39025
Value Function Loss: 0.02135

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.08891
Policy Update Magnitude: 0.50712
Value Function Update Magnitude: 0.68849

Collected Steps per Second: 21,929.64766
Overall Steps per Second: 10,630.58790

Timestep Collection Time: 2.28093
Timestep Consumption Time: 2.42436
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.70529

Cumulative Model Updates: 316,720
Cumulative Timesteps: 2,641,382,728

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.20576
Policy Entropy: 2.39439
Value Function Loss: 0.02217

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.09422
Policy Update Magnitude: 0.51634
Value Function Update Magnitude: 0.70338

Collected Steps per Second: 21,257.79662
Overall Steps per Second: 10,401.11700

Timestep Collection Time: 2.35208
Timestep Consumption Time: 2.45510
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.80718

Cumulative Model Updates: 316,726
Cumulative Timesteps: 2,641,432,728

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2641432728...
Checkpoint 2641432728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.01145
Policy Entropy: 2.39728
Value Function Loss: 0.02269

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.09446
Policy Update Magnitude: 0.51075
Value Function Update Magnitude: 0.71459

Collected Steps per Second: 22,217.96822
Overall Steps per Second: 10,616.46139

Timestep Collection Time: 2.25043
Timestep Consumption Time: 2.45924
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.70967

Cumulative Model Updates: 316,732
Cumulative Timesteps: 2,641,482,728

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.94660
Policy Entropy: 2.40855
Value Function Loss: 0.02111

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.08982
Policy Update Magnitude: 0.49966
Value Function Update Magnitude: 0.71381

Collected Steps per Second: 22,113.43786
Overall Steps per Second: 10,498.41858

Timestep Collection Time: 2.26170
Timestep Consumption Time: 2.50225
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.76396

Cumulative Model Updates: 316,738
Cumulative Timesteps: 2,641,532,742

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2641532742...
Checkpoint 2641532742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.07638
Policy Entropy: 2.40432
Value Function Loss: 0.02093

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.08332
Policy Update Magnitude: 0.48994
Value Function Update Magnitude: 0.70058

Collected Steps per Second: 22,260.45876
Overall Steps per Second: 10,707.61028

Timestep Collection Time: 2.24614
Timestep Consumption Time: 2.42344
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.66958

Cumulative Model Updates: 316,744
Cumulative Timesteps: 2,641,582,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.92180
Policy Entropy: 2.40106
Value Function Loss: 0.01973

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.48773
Value Function Update Magnitude: 0.70205

Collected Steps per Second: 22,550.20026
Overall Steps per Second: 10,772.03745

Timestep Collection Time: 2.21736
Timestep Consumption Time: 2.42447
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.64183

Cumulative Model Updates: 316,750
Cumulative Timesteps: 2,641,632,744

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2641632744...
Checkpoint 2641632744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.49387
Policy Entropy: 2.38853
Value Function Loss: 0.02118

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.09290
Policy Update Magnitude: 0.49570
Value Function Update Magnitude: 0.70603

Collected Steps per Second: 22,256.78910
Overall Steps per Second: 10,656.28110

Timestep Collection Time: 2.24660
Timestep Consumption Time: 2.44566
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.69226

Cumulative Model Updates: 316,756
Cumulative Timesteps: 2,641,682,746

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.96375
Policy Entropy: 2.38933
Value Function Loss: 0.02173

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.09163
Policy Update Magnitude: 0.50557
Value Function Update Magnitude: 0.70413

Collected Steps per Second: 22,166.50728
Overall Steps per Second: 10,532.12967

Timestep Collection Time: 2.25629
Timestep Consumption Time: 2.49242
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.74871

Cumulative Model Updates: 316,762
Cumulative Timesteps: 2,641,732,760

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2641732760...
Checkpoint 2641732760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.20810
Policy Entropy: 2.39920
Value Function Loss: 0.02286

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.09597
Policy Update Magnitude: 0.51204
Value Function Update Magnitude: 0.70891

Collected Steps per Second: 21,998.20842
Overall Steps per Second: 10,718.67315

Timestep Collection Time: 2.27364
Timestep Consumption Time: 2.39261
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.66625

Cumulative Model Updates: 316,768
Cumulative Timesteps: 2,641,782,776

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.86528
Policy Entropy: 2.38213
Value Function Loss: 0.02255

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.10264
Policy Update Magnitude: 0.50742
Value Function Update Magnitude: 0.71505

Collected Steps per Second: 21,869.47186
Overall Steps per Second: 10,761.36299

Timestep Collection Time: 2.28812
Timestep Consumption Time: 2.36185
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.64997

Cumulative Model Updates: 316,774
Cumulative Timesteps: 2,641,832,816

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2641832816...
Checkpoint 2641832816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.62276
Policy Entropy: 2.38548
Value Function Loss: 0.02150

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.10575
Policy Update Magnitude: 0.49417
Value Function Update Magnitude: 0.70485

Collected Steps per Second: 22,020.21790
Overall Steps per Second: 10,635.87748

Timestep Collection Time: 2.27218
Timestep Consumption Time: 2.43208
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.70427

Cumulative Model Updates: 316,780
Cumulative Timesteps: 2,641,882,850

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.06393
Policy Entropy: 2.38657
Value Function Loss: 0.02100

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.10244
Policy Update Magnitude: 0.48489
Value Function Update Magnitude: 0.68824

Collected Steps per Second: 21,222.47353
Overall Steps per Second: 10,472.56343

Timestep Collection Time: 2.35731
Timestep Consumption Time: 2.41974
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.77705

Cumulative Model Updates: 316,786
Cumulative Timesteps: 2,641,932,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2641932878...
Checkpoint 2641932878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.24197
Policy Entropy: 2.39980
Value Function Loss: 0.02120

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.11449
Policy Update Magnitude: 0.49414
Value Function Update Magnitude: 0.67854

Collected Steps per Second: 21,844.20788
Overall Steps per Second: 10,776.74131

Timestep Collection Time: 2.28976
Timestep Consumption Time: 2.35153
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.64129

Cumulative Model Updates: 316,792
Cumulative Timesteps: 2,641,982,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.33735
Policy Entropy: 2.38398
Value Function Loss: 0.02254

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.11628
Policy Update Magnitude: 0.51699
Value Function Update Magnitude: 0.69086

Collected Steps per Second: 22,470.42727
Overall Steps per Second: 10,533.52657

Timestep Collection Time: 2.22621
Timestep Consumption Time: 2.52281
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.74903

Cumulative Model Updates: 316,798
Cumulative Timesteps: 2,642,032,920

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2642032920...
Checkpoint 2642032920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.02481
Policy Entropy: 2.37045
Value Function Loss: 0.02258

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.10302
Policy Update Magnitude: 0.52218
Value Function Update Magnitude: 0.69891

Collected Steps per Second: 22,299.03158
Overall Steps per Second: 10,496.48205

Timestep Collection Time: 2.24351
Timestep Consumption Time: 2.52266
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.76617

Cumulative Model Updates: 316,804
Cumulative Timesteps: 2,642,082,948

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.06039
Policy Entropy: 2.36890
Value Function Loss: 0.02212

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.09842
Policy Update Magnitude: 0.51677
Value Function Update Magnitude: 0.68969

Collected Steps per Second: 22,047.45833
Overall Steps per Second: 10,494.88038

Timestep Collection Time: 2.26847
Timestep Consumption Time: 2.49709
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.76556

Cumulative Model Updates: 316,810
Cumulative Timesteps: 2,642,132,962

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2642132962...
Checkpoint 2642132962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.58440
Policy Entropy: 2.35277
Value Function Loss: 0.02259

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.10310
Policy Update Magnitude: 0.51231
Value Function Update Magnitude: 0.69234

Collected Steps per Second: 22,126.35414
Overall Steps per Second: 10,663.17347

Timestep Collection Time: 2.25975
Timestep Consumption Time: 2.42929
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.68904

Cumulative Model Updates: 316,816
Cumulative Timesteps: 2,642,182,962

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.35602
Policy Entropy: 2.36471
Value Function Loss: 0.02269

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.11147
Policy Update Magnitude: 0.50348
Value Function Update Magnitude: 0.69029

Collected Steps per Second: 22,599.80690
Overall Steps per Second: 10,753.88018

Timestep Collection Time: 2.21444
Timestep Consumption Time: 2.43932
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.65376

Cumulative Model Updates: 316,822
Cumulative Timesteps: 2,642,233,008

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2642233008...
Checkpoint 2642233008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.53506
Policy Entropy: 2.35289
Value Function Loss: 0.02284

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.10091
Policy Update Magnitude: 0.50284
Value Function Update Magnitude: 0.70319

Collected Steps per Second: 22,197.17714
Overall Steps per Second: 10,639.35117

Timestep Collection Time: 2.25398
Timestep Consumption Time: 2.44856
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.70254

Cumulative Model Updates: 316,828
Cumulative Timesteps: 2,642,283,040

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.77012
Policy Entropy: 2.38803
Value Function Loss: 0.02230

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.09600
Policy Update Magnitude: 0.49242
Value Function Update Magnitude: 0.69456

Collected Steps per Second: 22,207.04847
Overall Steps per Second: 10,490.06408

Timestep Collection Time: 2.25199
Timestep Consumption Time: 2.51538
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.76737

Cumulative Model Updates: 316,834
Cumulative Timesteps: 2,642,333,050

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2642333050...
Checkpoint 2642333050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.02559
Policy Entropy: 2.40320
Value Function Loss: 0.02182

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.09242
Policy Update Magnitude: 0.48053
Value Function Update Magnitude: 0.69707

Collected Steps per Second: 21,837.43103
Overall Steps per Second: 10,697.64466

Timestep Collection Time: 2.29038
Timestep Consumption Time: 2.38504
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.67542

Cumulative Model Updates: 316,840
Cumulative Timesteps: 2,642,383,066

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.22836
Policy Entropy: 2.43034
Value Function Loss: 0.02250

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.09023
Policy Update Magnitude: 0.48147
Value Function Update Magnitude: 0.69575

Collected Steps per Second: 21,936.43190
Overall Steps per Second: 10,440.59547

Timestep Collection Time: 2.27950
Timestep Consumption Time: 2.50989
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.78938

Cumulative Model Updates: 316,846
Cumulative Timesteps: 2,642,433,070

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2642433070...
Checkpoint 2642433070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.83759
Policy Entropy: 2.42973
Value Function Loss: 0.02182

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.08906
Policy Update Magnitude: 0.49571
Value Function Update Magnitude: 0.70243

Collected Steps per Second: 21,757.30514
Overall Steps per Second: 10,624.76164

Timestep Collection Time: 2.29918
Timestep Consumption Time: 2.40906
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.70825

Cumulative Model Updates: 316,852
Cumulative Timesteps: 2,642,483,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.10871
Policy Entropy: 2.42729
Value Function Loss: 0.02080

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.49683
Value Function Update Magnitude: 0.69536

Collected Steps per Second: 21,831.90394
Overall Steps per Second: 10,649.74951

Timestep Collection Time: 2.29050
Timestep Consumption Time: 2.40501
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.69551

Cumulative Model Updates: 316,858
Cumulative Timesteps: 2,642,533,100

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2642533100...
Checkpoint 2642533100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.89653
Policy Entropy: 2.42263
Value Function Loss: 0.01946

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.08157
Policy Update Magnitude: 0.48461
Value Function Update Magnitude: 0.67685

Collected Steps per Second: 22,241.75359
Overall Steps per Second: 10,514.82610

Timestep Collection Time: 2.24937
Timestep Consumption Time: 2.50867
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.75804

Cumulative Model Updates: 316,864
Cumulative Timesteps: 2,642,583,130

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.24700
Policy Entropy: 2.42937
Value Function Loss: 0.02007

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.08226
Policy Update Magnitude: 0.48344
Value Function Update Magnitude: 0.67091

Collected Steps per Second: 22,061.70298
Overall Steps per Second: 10,421.30583

Timestep Collection Time: 2.26682
Timestep Consumption Time: 2.53200
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.79882

Cumulative Model Updates: 316,870
Cumulative Timesteps: 2,642,633,140

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2642633140...
Checkpoint 2642633140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.24002
Policy Entropy: 2.42743
Value Function Loss: 0.02053

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.08485
Policy Update Magnitude: 0.47897
Value Function Update Magnitude: 0.66683

Collected Steps per Second: 22,057.92604
Overall Steps per Second: 10,564.60621

Timestep Collection Time: 2.26857
Timestep Consumption Time: 2.46800
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.73657

Cumulative Model Updates: 316,876
Cumulative Timesteps: 2,642,683,180

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.15457
Policy Entropy: 2.43142
Value Function Loss: 0.02065

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.08109
Policy Update Magnitude: 0.48069
Value Function Update Magnitude: 0.67587

Collected Steps per Second: 22,240.26946
Overall Steps per Second: 10,509.16837

Timestep Collection Time: 2.24817
Timestep Consumption Time: 2.50958
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.75775

Cumulative Model Updates: 316,882
Cumulative Timesteps: 2,642,733,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2642733180...
Checkpoint 2642733180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.69235
Policy Entropy: 2.40495
Value Function Loss: 0.02040

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.07857
Policy Update Magnitude: 0.48181
Value Function Update Magnitude: 0.66607

Collected Steps per Second: 22,884.24494
Overall Steps per Second: 10,646.54140

Timestep Collection Time: 2.18535
Timestep Consumption Time: 2.51195
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.69730

Cumulative Model Updates: 316,888
Cumulative Timesteps: 2,642,783,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.47134
Policy Entropy: 2.41176
Value Function Loss: 0.02232

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.09751
Policy Update Magnitude: 0.48580
Value Function Update Magnitude: 0.66172

Collected Steps per Second: 22,576.29416
Overall Steps per Second: 10,588.22648

Timestep Collection Time: 2.21595
Timestep Consumption Time: 2.50892
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.72487

Cumulative Model Updates: 316,894
Cumulative Timesteps: 2,642,833,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2642833218...
Checkpoint 2642833218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.76648
Policy Entropy: 2.41648
Value Function Loss: 0.02224

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.10151
Policy Update Magnitude: 0.48939
Value Function Update Magnitude: 0.65514

Collected Steps per Second: 22,137.66318
Overall Steps per Second: 10,548.06696

Timestep Collection Time: 2.25941
Timestep Consumption Time: 2.48250
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.74191

Cumulative Model Updates: 316,900
Cumulative Timesteps: 2,642,883,236

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.07860
Policy Entropy: 2.43689
Value Function Loss: 0.02169

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.09405
Policy Update Magnitude: 0.48676
Value Function Update Magnitude: 0.66222

Collected Steps per Second: 22,449.07025
Overall Steps per Second: 10,852.10123

Timestep Collection Time: 2.22851
Timestep Consumption Time: 2.38147
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.60998

Cumulative Model Updates: 316,906
Cumulative Timesteps: 2,642,933,264

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2642933264...
Checkpoint 2642933264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.67180
Policy Entropy: 2.43586
Value Function Loss: 0.02009

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.08837
Policy Update Magnitude: 0.49194
Value Function Update Magnitude: 0.65127

Collected Steps per Second: 22,247.52185
Overall Steps per Second: 10,686.47586

Timestep Collection Time: 2.24843
Timestep Consumption Time: 2.43244
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.68087

Cumulative Model Updates: 316,912
Cumulative Timesteps: 2,642,983,286

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.91041
Policy Entropy: 2.42096
Value Function Loss: 0.01979

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.49258
Value Function Update Magnitude: 0.65844

Collected Steps per Second: 21,914.99092
Overall Steps per Second: 10,426.15507

Timestep Collection Time: 2.28218
Timestep Consumption Time: 2.51479
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.79697

Cumulative Model Updates: 316,918
Cumulative Timesteps: 2,643,033,300

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2643033300...
Checkpoint 2643033300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.44823
Policy Entropy: 2.40713
Value Function Loss: 0.02067

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.47804
Value Function Update Magnitude: 0.65170

Collected Steps per Second: 21,655.28206
Overall Steps per Second: 10,572.09818

Timestep Collection Time: 2.30955
Timestep Consumption Time: 2.42120
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.73075

Cumulative Model Updates: 316,924
Cumulative Timesteps: 2,643,083,314

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.47787
Policy Entropy: 2.36200
Value Function Loss: 0.02093

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.11409
Policy Update Magnitude: 0.48255
Value Function Update Magnitude: 0.65479

Collected Steps per Second: 22,338.70447
Overall Steps per Second: 10,526.65356

Timestep Collection Time: 2.23952
Timestep Consumption Time: 2.51299
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.75251

Cumulative Model Updates: 316,930
Cumulative Timesteps: 2,643,133,342

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2643133342...
Checkpoint 2643133342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.59220
Policy Entropy: 2.36581
Value Function Loss: 0.02144

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.11039
Policy Update Magnitude: 0.48652
Value Function Update Magnitude: 0.65915

Collected Steps per Second: 22,003.41314
Overall Steps per Second: 10,601.69045

Timestep Collection Time: 2.27292
Timestep Consumption Time: 2.44444
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.71736

Cumulative Model Updates: 316,936
Cumulative Timesteps: 2,643,183,354

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.67893
Policy Entropy: 2.35628
Value Function Loss: 0.02185

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.10756
Policy Update Magnitude: 0.48975
Value Function Update Magnitude: 0.66848

Collected Steps per Second: 22,270.09486
Overall Steps per Second: 10,495.89462

Timestep Collection Time: 2.24633
Timestep Consumption Time: 2.51991
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.76624

Cumulative Model Updates: 316,942
Cumulative Timesteps: 2,643,233,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2643233380...
Checkpoint 2643233380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.52872
Policy Entropy: 2.38388
Value Function Loss: 0.02199

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.08893
Policy Update Magnitude: 0.51121
Value Function Update Magnitude: 0.68385

Collected Steps per Second: 22,192.68326
Overall Steps per Second: 10,657.59378

Timestep Collection Time: 2.25345
Timestep Consumption Time: 2.43898
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.69243

Cumulative Model Updates: 316,948
Cumulative Timesteps: 2,643,283,390

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.80475
Policy Entropy: 2.37918
Value Function Loss: 0.02215

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.50428
Value Function Update Magnitude: 0.69520

Collected Steps per Second: 21,635.91744
Overall Steps per Second: 10,439.29119

Timestep Collection Time: 2.31162
Timestep Consumption Time: 2.47932
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.79094

Cumulative Model Updates: 316,954
Cumulative Timesteps: 2,643,333,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2643333404...
Checkpoint 2643333404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.92490
Policy Entropy: 2.38520
Value Function Loss: 0.02112

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.10158
Policy Update Magnitude: 0.49464
Value Function Update Magnitude: 0.67748

Collected Steps per Second: 22,119.65277
Overall Steps per Second: 10,673.50454

Timestep Collection Time: 2.26089
Timestep Consumption Time: 2.42455
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.68543

Cumulative Model Updates: 316,960
Cumulative Timesteps: 2,643,383,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.79091
Policy Entropy: 2.38762
Value Function Loss: 0.02103

Mean KL Divergence: 0.02202
SB3 Clip Fraction: 0.12797
Policy Update Magnitude: 0.47601
Value Function Update Magnitude: 0.66757

Collected Steps per Second: 22,593.85601
Overall Steps per Second: 10,616.08000

Timestep Collection Time: 2.21299
Timestep Consumption Time: 2.49685
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.70984

Cumulative Model Updates: 316,966
Cumulative Timesteps: 2,643,433,414

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2643433414...
Checkpoint 2643433414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.78443
Policy Entropy: 2.40355
Value Function Loss: 0.02147

Mean KL Divergence: 0.02190
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.49642
Value Function Update Magnitude: 0.65948

Collected Steps per Second: 22,296.85610
Overall Steps per Second: 10,865.02021

Timestep Collection Time: 2.24346
Timestep Consumption Time: 2.36049
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.60395

Cumulative Model Updates: 316,972
Cumulative Timesteps: 2,643,483,436

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.39679
Policy Entropy: 2.42192
Value Function Loss: 0.02100

Mean KL Divergence: 0.02238
SB3 Clip Fraction: 0.12638
Policy Update Magnitude: 0.47799
Value Function Update Magnitude: 0.66126

Collected Steps per Second: 22,570.63236
Overall Steps per Second: 10,608.47808

Timestep Collection Time: 2.21677
Timestep Consumption Time: 2.49964
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.71642

Cumulative Model Updates: 316,978
Cumulative Timesteps: 2,643,533,470

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2643533470...
Checkpoint 2643533470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.46176
Policy Entropy: 2.41885
Value Function Loss: 0.02144

Mean KL Divergence: 0.02463
SB3 Clip Fraction: 0.12915
Policy Update Magnitude: 0.46693
Value Function Update Magnitude: 0.66522

Collected Steps per Second: 21,615.01766
Overall Steps per Second: 10,543.04414

Timestep Collection Time: 2.31376
Timestep Consumption Time: 2.42984
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.74360

Cumulative Model Updates: 316,984
Cumulative Timesteps: 2,643,583,482

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.17800
Policy Entropy: 2.41181
Value Function Loss: 0.02129

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.12268
Policy Update Magnitude: 0.49583
Value Function Update Magnitude: 0.67420

Collected Steps per Second: 21,864.11247
Overall Steps per Second: 10,442.14915

Timestep Collection Time: 2.28822
Timestep Consumption Time: 2.50293
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.79116

Cumulative Model Updates: 316,990
Cumulative Timesteps: 2,643,633,512

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2643633512...
Checkpoint 2643633512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.00614
Policy Entropy: 2.40037
Value Function Loss: 0.02110

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.11802
Policy Update Magnitude: 0.51934
Value Function Update Magnitude: 0.70139

Collected Steps per Second: 21,871.33327
Overall Steps per Second: 10,656.81880

Timestep Collection Time: 2.28738
Timestep Consumption Time: 2.40708
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.69446

Cumulative Model Updates: 316,996
Cumulative Timesteps: 2,643,683,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.20252
Policy Entropy: 2.41935
Value Function Loss: 0.02185

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.09740
Policy Update Magnitude: 0.50997
Value Function Update Magnitude: 0.71234

Collected Steps per Second: 22,133.79990
Overall Steps per Second: 10,491.59848

Timestep Collection Time: 2.26016
Timestep Consumption Time: 2.50803
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.76820

Cumulative Model Updates: 317,002
Cumulative Timesteps: 2,643,733,566

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2643733566...
Checkpoint 2643733566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.29751
Policy Entropy: 2.41418
Value Function Loss: 0.02236

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.10730
Policy Update Magnitude: 0.49975
Value Function Update Magnitude: 0.71021

Collected Steps per Second: 21,252.67624
Overall Steps per Second: 10,497.38934

Timestep Collection Time: 2.35293
Timestep Consumption Time: 2.41073
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.76366

Cumulative Model Updates: 317,008
Cumulative Timesteps: 2,643,783,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.16398
Policy Entropy: 2.42285
Value Function Loss: 0.02345

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.11287
Policy Update Magnitude: 0.49158
Value Function Update Magnitude: 0.71509

Collected Steps per Second: 22,545.76549
Overall Steps per Second: 10,693.75260

Timestep Collection Time: 2.21824
Timestep Consumption Time: 2.45851
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.67675

Cumulative Model Updates: 317,014
Cumulative Timesteps: 2,643,833,584

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2643833584...
Checkpoint 2643833584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.91105
Policy Entropy: 2.40610
Value Function Loss: 0.02277

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.11273
Policy Update Magnitude: 0.50538
Value Function Update Magnitude: 0.72282

Collected Steps per Second: 22,213.24672
Overall Steps per Second: 10,494.13773

Timestep Collection Time: 2.25181
Timestep Consumption Time: 2.51466
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.76647

Cumulative Model Updates: 317,020
Cumulative Timesteps: 2,643,883,604

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.34360
Policy Entropy: 2.40306
Value Function Loss: 0.02216

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.11150
Policy Update Magnitude: 0.49390
Value Function Update Magnitude: 0.70337

Collected Steps per Second: 22,267.06413
Overall Steps per Second: 10,530.50937

Timestep Collection Time: 2.24547
Timestep Consumption Time: 2.50264
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.74811

Cumulative Model Updates: 317,026
Cumulative Timesteps: 2,643,933,604

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2643933604...
Checkpoint 2643933604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.90845
Policy Entropy: 2.39233
Value Function Loss: 0.02150

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.11540
Policy Update Magnitude: 0.46538
Value Function Update Magnitude: 0.69421

Collected Steps per Second: 22,075.41574
Overall Steps per Second: 10,584.55472

Timestep Collection Time: 2.26533
Timestep Consumption Time: 2.45929
PPO Batch Consumption Time: 0.28406
Total Iteration Time: 4.72462

Cumulative Model Updates: 317,032
Cumulative Timesteps: 2,643,983,612

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.08235
Policy Entropy: 2.37871
Value Function Loss: 0.02155

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.12424
Policy Update Magnitude: 0.46457
Value Function Update Magnitude: 0.70538

Collected Steps per Second: 22,258.37515
Overall Steps per Second: 10,585.65328

Timestep Collection Time: 2.24724
Timestep Consumption Time: 2.47802
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.72526

Cumulative Model Updates: 317,038
Cumulative Timesteps: 2,644,033,632

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2644033632...
Checkpoint 2644033632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.17302
Policy Entropy: 2.37286
Value Function Loss: 0.02236

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.11428
Policy Update Magnitude: 0.49470
Value Function Update Magnitude: 0.71057

Collected Steps per Second: 22,229.17668
Overall Steps per Second: 10,858.47772

Timestep Collection Time: 2.25020
Timestep Consumption Time: 2.35634
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.60654

Cumulative Model Updates: 317,044
Cumulative Timesteps: 2,644,083,652

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.02619
Policy Entropy: 2.37758
Value Function Loss: 0.02156

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.10645
Policy Update Magnitude: 0.50167
Value Function Update Magnitude: 0.70809

Collected Steps per Second: 22,416.50176
Overall Steps per Second: 10,576.84553

Timestep Collection Time: 2.23148
Timestep Consumption Time: 2.49791
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.72939

Cumulative Model Updates: 317,050
Cumulative Timesteps: 2,644,133,674

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2644133674...
Checkpoint 2644133674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.97611
Policy Entropy: 2.38401
Value Function Loss: 0.02038

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.09659
Policy Update Magnitude: 0.49697
Value Function Update Magnitude: 0.69186

Collected Steps per Second: 16,835.96029
Overall Steps per Second: 8,920.92559

Timestep Collection Time: 2.97102
Timestep Consumption Time: 2.63602
PPO Batch Consumption Time: 0.31194
Total Iteration Time: 5.60704

Cumulative Model Updates: 317,056
Cumulative Timesteps: 2,644,183,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.45603
Policy Entropy: 2.40453
Value Function Loss: 0.02005

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.49872
Value Function Update Magnitude: 0.65849

Collected Steps per Second: 17,435.45420
Overall Steps per Second: 8,640.58916

Timestep Collection Time: 2.86956
Timestep Consumption Time: 2.92079
PPO Batch Consumption Time: 0.34151
Total Iteration Time: 5.79035

Cumulative Model Updates: 317,062
Cumulative Timesteps: 2,644,233,726

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2644233726...
Checkpoint 2644233726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.76081
Policy Entropy: 2.41084
Value Function Loss: 0.02151

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.09163
Policy Update Magnitude: 0.50525
Value Function Update Magnitude: 0.64121

Collected Steps per Second: 17,728.18159
Overall Steps per Second: 9,560.90588

Timestep Collection Time: 2.82172
Timestep Consumption Time: 2.41042
PPO Batch Consumption Time: 0.29707
Total Iteration Time: 5.23214

Cumulative Model Updates: 317,068
Cumulative Timesteps: 2,644,283,750

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.74776
Policy Entropy: 2.42751
Value Function Loss: 0.02235

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.09153
Policy Update Magnitude: 0.49262
Value Function Update Magnitude: 0.65730

Collected Steps per Second: 19,015.20597
Overall Steps per Second: 9,442.65877

Timestep Collection Time: 2.63168
Timestep Consumption Time: 2.66788
PPO Batch Consumption Time: 0.31796
Total Iteration Time: 5.29957

Cumulative Model Updates: 317,074
Cumulative Timesteps: 2,644,333,792

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2644333792...
Checkpoint 2644333792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.68865
Policy Entropy: 2.40494
Value Function Loss: 0.02162

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.09094
Policy Update Magnitude: 0.49122
Value Function Update Magnitude: 0.66674

Collected Steps per Second: 18,115.83048
Overall Steps per Second: 9,408.75434

Timestep Collection Time: 2.76090
Timestep Consumption Time: 2.55500
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 5.31590

Cumulative Model Updates: 317,080
Cumulative Timesteps: 2,644,383,808

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.32784
Policy Entropy: 2.38341
Value Function Loss: 0.02162

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.10324
Policy Update Magnitude: 0.49448
Value Function Update Magnitude: 0.66464

Collected Steps per Second: 19,505.80460
Overall Steps per Second: 9,453.09494

Timestep Collection Time: 2.56447
Timestep Consumption Time: 2.72713
PPO Batch Consumption Time: 0.31599
Total Iteration Time: 5.29160

Cumulative Model Updates: 317,086
Cumulative Timesteps: 2,644,433,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2644433830...
Checkpoint 2644433830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.84508
Policy Entropy: 2.39250
Value Function Loss: 0.02078

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.11667
Policy Update Magnitude: 0.47018
Value Function Update Magnitude: 0.66346

Collected Steps per Second: 21,188.12069
Overall Steps per Second: 10,428.98467

Timestep Collection Time: 2.36076
Timestep Consumption Time: 2.43549
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.79625

Cumulative Model Updates: 317,092
Cumulative Timesteps: 2,644,483,850

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.72103
Policy Entropy: 2.40969
Value Function Loss: 0.02074

Mean KL Divergence: 0.02292
SB3 Clip Fraction: 0.13242
Policy Update Magnitude: 0.45546
Value Function Update Magnitude: 0.66782

Collected Steps per Second: 17,627.57828
Overall Steps per Second: 9,231.83200

Timestep Collection Time: 2.83646
Timestep Consumption Time: 2.57958
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 5.41604

Cumulative Model Updates: 317,098
Cumulative Timesteps: 2,644,533,850

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2644533850...
Checkpoint 2644533850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.93035
Policy Entropy: 2.44377
Value Function Loss: 0.02078

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.12299
Policy Update Magnitude: 0.49236
Value Function Update Magnitude: 0.66157

Collected Steps per Second: 14,761.34783
Overall Steps per Second: 7,634.43763

Timestep Collection Time: 3.38804
Timestep Consumption Time: 3.16281
PPO Batch Consumption Time: 0.40372
Total Iteration Time: 6.55084

Cumulative Model Updates: 317,104
Cumulative Timesteps: 2,644,583,862

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.91956
Policy Entropy: 2.42526
Value Function Loss: 0.02148

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.12194
Policy Update Magnitude: 0.50054
Value Function Update Magnitude: 0.67741

Collected Steps per Second: 16,300.22428
Overall Steps per Second: 7,384.40590

Timestep Collection Time: 3.07039
Timestep Consumption Time: 3.70714
PPO Batch Consumption Time: 0.48493
Total Iteration Time: 6.77753

Cumulative Model Updates: 317,110
Cumulative Timesteps: 2,644,633,910

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2644633910...
Checkpoint 2644633910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.06276
Policy Entropy: 2.41903
Value Function Loss: 0.02056

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.10310
Policy Update Magnitude: 0.50232
Value Function Update Magnitude: 0.68379

Collected Steps per Second: 15,656.87768
Overall Steps per Second: 7,239.64512

Timestep Collection Time: 3.19400
Timestep Consumption Time: 3.71353
PPO Batch Consumption Time: 0.48758
Total Iteration Time: 6.90752

Cumulative Model Updates: 317,116
Cumulative Timesteps: 2,644,683,918

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.20311
Policy Entropy: 2.38998
Value Function Loss: 0.02124

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.09189
Policy Update Magnitude: 0.51743
Value Function Update Magnitude: 0.69185

Collected Steps per Second: 15,134.79464
Overall Steps per Second: 7,295.60794

Timestep Collection Time: 3.30523
Timestep Consumption Time: 3.55150
PPO Batch Consumption Time: 0.47491
Total Iteration Time: 6.85673

Cumulative Model Updates: 317,122
Cumulative Timesteps: 2,644,733,942

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2644733942...
Checkpoint 2644733942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.06922
Policy Entropy: 2.38483
Value Function Loss: 0.02024

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.10177
Policy Update Magnitude: 0.51136
Value Function Update Magnitude: 0.68502

Collected Steps per Second: 16,004.94578
Overall Steps per Second: 7,674.28766

Timestep Collection Time: 3.12541
Timestep Consumption Time: 3.39272
PPO Batch Consumption Time: 0.43798
Total Iteration Time: 6.51813

Cumulative Model Updates: 317,128
Cumulative Timesteps: 2,644,783,964

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.85531
Policy Entropy: 2.37189
Value Function Loss: 0.02101

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.10022
Policy Update Magnitude: 0.49902
Value Function Update Magnitude: 0.67556

Collected Steps per Second: 15,728.59257
Overall Steps per Second: 7,555.52739

Timestep Collection Time: 3.18032
Timestep Consumption Time: 3.44026
PPO Batch Consumption Time: 0.44027
Total Iteration Time: 6.62058

Cumulative Model Updates: 317,134
Cumulative Timesteps: 2,644,833,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2644833986...
Checkpoint 2644833986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171.88300
Policy Entropy: 2.36925
Value Function Loss: 0.02184

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.08633
Policy Update Magnitude: 0.48807
Value Function Update Magnitude: 0.68571

Collected Steps per Second: 15,606.50172
Overall Steps per Second: 7,609.60693

Timestep Collection Time: 3.20469
Timestep Consumption Time: 3.36779
PPO Batch Consumption Time: 0.44565
Total Iteration Time: 6.57248

Cumulative Model Updates: 317,140
Cumulative Timesteps: 2,644,884,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.52369
Policy Entropy: 2.34973
Value Function Loss: 0.02206

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.08699
Policy Update Magnitude: 0.50096
Value Function Update Magnitude: 0.69938

Collected Steps per Second: 16,212.90410
Overall Steps per Second: 7,728.12420

Timestep Collection Time: 3.08433
Timestep Consumption Time: 3.38632
PPO Batch Consumption Time: 0.43520
Total Iteration Time: 6.47065

Cumulative Model Updates: 317,146
Cumulative Timesteps: 2,644,934,006

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2644934006...
Checkpoint 2644934006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.29833
Policy Entropy: 2.34467
Value Function Loss: 0.02142

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.49782
Value Function Update Magnitude: 0.69687

Collected Steps per Second: 16,016.01461
Overall Steps per Second: 7,645.98073

Timestep Collection Time: 3.12225
Timestep Consumption Time: 3.41792
PPO Batch Consumption Time: 0.44242
Total Iteration Time: 6.54017

Cumulative Model Updates: 317,152
Cumulative Timesteps: 2,644,984,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.19380
Policy Entropy: 2.35694
Value Function Loss: 0.02179

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.49662
Value Function Update Magnitude: 0.66453

Collected Steps per Second: 16,107.11356
Overall Steps per Second: 7,543.62996

Timestep Collection Time: 3.10583
Timestep Consumption Time: 3.52572
PPO Batch Consumption Time: 0.46021
Total Iteration Time: 6.63156

Cumulative Model Updates: 317,158
Cumulative Timesteps: 2,645,034,038

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2645034038...
Checkpoint 2645034038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.91846
Policy Entropy: 2.36428
Value Function Loss: 0.02251

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.09658
Policy Update Magnitude: 0.50623
Value Function Update Magnitude: 0.66827

Collected Steps per Second: 14,834.40873
Overall Steps per Second: 6,920.93399

Timestep Collection Time: 3.37081
Timestep Consumption Time: 3.85422
PPO Batch Consumption Time: 0.51182
Total Iteration Time: 7.22504

Cumulative Model Updates: 317,164
Cumulative Timesteps: 2,645,084,042

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.87088
Policy Entropy: 2.35314
Value Function Loss: 0.02259

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.10298
Policy Update Magnitude: 0.50987
Value Function Update Magnitude: 0.69101

Collected Steps per Second: 15,263.23339
Overall Steps per Second: 6,984.89566

Timestep Collection Time: 3.27598
Timestep Consumption Time: 3.88261
PPO Batch Consumption Time: 0.51365
Total Iteration Time: 7.15859

Cumulative Model Updates: 317,170
Cumulative Timesteps: 2,645,134,044

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2645134044...
Checkpoint 2645134044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.95973
Policy Entropy: 2.32145
Value Function Loss: 0.02289

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.50089
Value Function Update Magnitude: 0.69164

Collected Steps per Second: 14,990.30055
Overall Steps per Second: 7,036.57259

Timestep Collection Time: 3.33576
Timestep Consumption Time: 3.77054
PPO Batch Consumption Time: 0.49781
Total Iteration Time: 7.10630

Cumulative Model Updates: 317,176
Cumulative Timesteps: 2,645,184,048

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.09803
Policy Entropy: 2.33696
Value Function Loss: 0.02257

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.10536
Policy Update Magnitude: 0.49662
Value Function Update Magnitude: 0.67691

Collected Steps per Second: 15,120.83788
Overall Steps per Second: 6,954.82736

Timestep Collection Time: 3.30696
Timestep Consumption Time: 3.88287
PPO Batch Consumption Time: 0.51380
Total Iteration Time: 7.18983

Cumulative Model Updates: 317,182
Cumulative Timesteps: 2,645,234,052

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2645234052...
Checkpoint 2645234052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.90640
Policy Entropy: 2.33896
Value Function Loss: 0.02146

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.11311
Policy Update Magnitude: 0.48446
Value Function Update Magnitude: 0.67210

Collected Steps per Second: 14,757.79883
Overall Steps per Second: 7,169.16605

Timestep Collection Time: 3.38845
Timestep Consumption Time: 3.58670
PPO Batch Consumption Time: 0.47105
Total Iteration Time: 6.97515

Cumulative Model Updates: 317,188
Cumulative Timesteps: 2,645,284,058

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.40502
Policy Entropy: 2.35847
Value Function Loss: 0.02050

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.11925
Policy Update Magnitude: 0.45148
Value Function Update Magnitude: 0.66839

Collected Steps per Second: 15,539.30456
Overall Steps per Second: 7,742.11955

Timestep Collection Time: 3.21958
Timestep Consumption Time: 3.24248
PPO Batch Consumption Time: 0.41306
Total Iteration Time: 6.46205

Cumulative Model Updates: 317,194
Cumulative Timesteps: 2,645,334,088

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2645334088...
Checkpoint 2645334088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.66774
Policy Entropy: 2.34063
Value Function Loss: 0.02053

Mean KL Divergence: 0.02164
SB3 Clip Fraction: 0.12715
Policy Update Magnitude: 0.46073
Value Function Update Magnitude: 0.67778

Collected Steps per Second: 16,109.65155
Overall Steps per Second: 7,620.70545

Timestep Collection Time: 3.10410
Timestep Consumption Time: 3.45776
PPO Batch Consumption Time: 0.44845
Total Iteration Time: 6.56186

Cumulative Model Updates: 317,200
Cumulative Timesteps: 2,645,384,094

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.06982
Policy Entropy: 2.35621
Value Function Loss: 0.02176

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.11889
Policy Update Magnitude: 0.47981
Value Function Update Magnitude: 0.68798

Collected Steps per Second: 15,234.15785
Overall Steps per Second: 6,914.45778

Timestep Collection Time: 3.28262
Timestep Consumption Time: 3.94976
PPO Batch Consumption Time: 0.52170
Total Iteration Time: 7.23238

Cumulative Model Updates: 317,206
Cumulative Timesteps: 2,645,434,102

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2645434102...
Checkpoint 2645434102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.94085
Policy Entropy: 2.35365
Value Function Loss: 0.02162

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.12062
Policy Update Magnitude: 0.49376
Value Function Update Magnitude: 0.67654

Collected Steps per Second: 15,951.29742
Overall Steps per Second: 7,391.85572

Timestep Collection Time: 3.13567
Timestep Consumption Time: 3.63097
PPO Batch Consumption Time: 0.48136
Total Iteration Time: 6.76664

Cumulative Model Updates: 317,212
Cumulative Timesteps: 2,645,484,120

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.57358
Policy Entropy: 2.35895
Value Function Loss: 0.02149

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.10645
Policy Update Magnitude: 0.49865
Value Function Update Magnitude: 0.67753

Collected Steps per Second: 14,630.49143
Overall Steps per Second: 7,017.69445

Timestep Collection Time: 3.41766
Timestep Consumption Time: 3.70748
PPO Batch Consumption Time: 0.49989
Total Iteration Time: 7.12513

Cumulative Model Updates: 317,218
Cumulative Timesteps: 2,645,534,122

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2645534122...
Checkpoint 2645534122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.87195
Policy Entropy: 2.36324
Value Function Loss: 0.02201

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.09339
Policy Update Magnitude: 0.51080
Value Function Update Magnitude: 0.70884

Collected Steps per Second: 15,272.17832
Overall Steps per Second: 7,415.17502

Timestep Collection Time: 3.27484
Timestep Consumption Time: 3.46997
PPO Batch Consumption Time: 0.44898
Total Iteration Time: 6.74482

Cumulative Model Updates: 317,224
Cumulative Timesteps: 2,645,584,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.24315
Policy Entropy: 2.34923
Value Function Loss: 0.02269

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.09688
Policy Update Magnitude: 0.51692
Value Function Update Magnitude: 0.72511

Collected Steps per Second: 15,305.56433
Overall Steps per Second: 7,253.74630

Timestep Collection Time: 3.26809
Timestep Consumption Time: 3.62765
PPO Batch Consumption Time: 0.47557
Total Iteration Time: 6.89575

Cumulative Model Updates: 317,230
Cumulative Timesteps: 2,645,634,156

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2645634156...
Checkpoint 2645634156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.06828
Policy Entropy: 2.35688
Value Function Loss: 0.02243

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.10254
Policy Update Magnitude: 0.50641
Value Function Update Magnitude: 0.73190

Collected Steps per Second: 15,382.17289
Overall Steps per Second: 7,099.44064

Timestep Collection Time: 3.25078
Timestep Consumption Time: 3.79260
PPO Batch Consumption Time: 0.50710
Total Iteration Time: 7.04337

Cumulative Model Updates: 317,236
Cumulative Timesteps: 2,645,684,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.68764
Policy Entropy: 2.35522
Value Function Loss: 0.02196

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.09846
Policy Update Magnitude: 0.49254
Value Function Update Magnitude: 0.74552

Collected Steps per Second: 14,998.00131
Overall Steps per Second: 7,539.93280

Timestep Collection Time: 3.33418
Timestep Consumption Time: 3.29798
PPO Batch Consumption Time: 0.43359
Total Iteration Time: 6.63215

Cumulative Model Updates: 317,242
Cumulative Timesteps: 2,645,734,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2645734166...
Checkpoint 2645734166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.37088
Policy Entropy: 2.36969
Value Function Loss: 0.02091

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.49568
Value Function Update Magnitude: 0.72708

Collected Steps per Second: 16,184.03029
Overall Steps per Second: 7,204.14746

Timestep Collection Time: 3.08947
Timestep Consumption Time: 3.85098
PPO Batch Consumption Time: 0.51195
Total Iteration Time: 6.94045

Cumulative Model Updates: 317,248
Cumulative Timesteps: 2,645,784,166

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.75024
Policy Entropy: 2.35329
Value Function Loss: 0.02082

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.09823
Policy Update Magnitude: 0.49653
Value Function Update Magnitude: 0.69343

Collected Steps per Second: 15,538.15260
Overall Steps per Second: 7,513.12183

Timestep Collection Time: 3.21904
Timestep Consumption Time: 3.43837
PPO Batch Consumption Time: 0.44324
Total Iteration Time: 6.65742

Cumulative Model Updates: 317,254
Cumulative Timesteps: 2,645,834,184

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2645834184...
Checkpoint 2645834184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.12807
Policy Entropy: 2.33735
Value Function Loss: 0.01989

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.50969
Value Function Update Magnitude: 0.68980

Collected Steps per Second: 15,671.67791
Overall Steps per Second: 7,382.97480

Timestep Collection Time: 3.19226
Timestep Consumption Time: 3.58387
PPO Batch Consumption Time: 0.47203
Total Iteration Time: 6.77613

Cumulative Model Updates: 317,260
Cumulative Timesteps: 2,645,884,212

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.02013
Policy Entropy: 2.31712
Value Function Loss: 0.01989

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.50937
Value Function Update Magnitude: 0.68746

Collected Steps per Second: 14,935.33575
Overall Steps per Second: 7,347.87057

Timestep Collection Time: 3.34924
Timestep Consumption Time: 3.45845
PPO Batch Consumption Time: 0.45978
Total Iteration Time: 6.80769

Cumulative Model Updates: 317,266
Cumulative Timesteps: 2,645,934,234

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2645934234...
Checkpoint 2645934234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.94732
Policy Entropy: 2.30804
Value Function Loss: 0.02059

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.50335
Value Function Update Magnitude: 0.68316

Collected Steps per Second: 15,979.13646
Overall Steps per Second: 7,683.41574

Timestep Collection Time: 3.13021
Timestep Consumption Time: 3.37966
PPO Batch Consumption Time: 0.43679
Total Iteration Time: 6.50987

Cumulative Model Updates: 317,272
Cumulative Timesteps: 2,645,984,252

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.05903
Policy Entropy: 2.29985
Value Function Loss: 0.02208

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.09008
Policy Update Magnitude: 0.50107
Value Function Update Magnitude: 0.69824

Collected Steps per Second: 15,092.49836
Overall Steps per Second: 6,987.08752

Timestep Collection Time: 3.31357
Timestep Consumption Time: 3.84392
PPO Batch Consumption Time: 0.50842
Total Iteration Time: 7.15749

Cumulative Model Updates: 317,278
Cumulative Timesteps: 2,646,034,262

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2646034262...
Checkpoint 2646034262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.01201
Policy Entropy: 2.32083
Value Function Loss: 0.02181

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.50136
Value Function Update Magnitude: 0.73103

Collected Steps per Second: 15,166.09978
Overall Steps per Second: 7,542.19901

Timestep Collection Time: 3.29841
Timestep Consumption Time: 3.33414
PPO Batch Consumption Time: 0.43133
Total Iteration Time: 6.63255

Cumulative Model Updates: 317,284
Cumulative Timesteps: 2,646,084,286

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.26624
Policy Entropy: 2.33193
Value Function Loss: 0.02266

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.50955
Value Function Update Magnitude: 0.73488

Collected Steps per Second: 15,800.93589
Overall Steps per Second: 7,708.86219

Timestep Collection Time: 3.16500
Timestep Consumption Time: 3.32234
PPO Batch Consumption Time: 0.44012
Total Iteration Time: 6.48734

Cumulative Model Updates: 317,290
Cumulative Timesteps: 2,646,134,296

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2646134296...
Checkpoint 2646134296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.54746
Policy Entropy: 2.34498
Value Function Loss: 0.02230

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.09263
Policy Update Magnitude: 0.51559
Value Function Update Magnitude: 0.73057

Collected Steps per Second: 15,692.42643
Overall Steps per Second: 7,635.95400

Timestep Collection Time: 3.18625
Timestep Consumption Time: 3.36172
PPO Batch Consumption Time: 0.43353
Total Iteration Time: 6.54797

Cumulative Model Updates: 317,296
Cumulative Timesteps: 2,646,184,296

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.02377
Policy Entropy: 2.34486
Value Function Loss: 0.02195

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.08942
Policy Update Magnitude: 0.50463
Value Function Update Magnitude: 0.71806

Collected Steps per Second: 15,195.49416
Overall Steps per Second: 7,376.08222

Timestep Collection Time: 3.29269
Timestep Consumption Time: 3.49059
PPO Batch Consumption Time: 0.45037
Total Iteration Time: 6.78328

Cumulative Model Updates: 317,302
Cumulative Timesteps: 2,646,234,330

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2646234330...
Checkpoint 2646234330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.75474
Policy Entropy: 2.34147
Value Function Loss: 0.02183

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.08845
Policy Update Magnitude: 0.49473
Value Function Update Magnitude: 0.69534

Collected Steps per Second: 15,818.87158
Overall Steps per Second: 7,637.39321

Timestep Collection Time: 3.16154
Timestep Consumption Time: 3.38677
PPO Batch Consumption Time: 0.45062
Total Iteration Time: 6.54831

Cumulative Model Updates: 317,308
Cumulative Timesteps: 2,646,284,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.76164
Policy Entropy: 2.34451
Value Function Loss: 0.02195

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.09795
Policy Update Magnitude: 0.48408
Value Function Update Magnitude: 0.68494

Collected Steps per Second: 15,956.89889
Overall Steps per Second: 7,271.69134

Timestep Collection Time: 3.13369
Timestep Consumption Time: 3.74284
PPO Batch Consumption Time: 0.49217
Total Iteration Time: 6.87653

Cumulative Model Updates: 317,314
Cumulative Timesteps: 2,646,334,346

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2646334346...
Checkpoint 2646334346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.41996
Policy Entropy: 2.31601
Value Function Loss: 0.02356

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.09405
Policy Update Magnitude: 0.49591
Value Function Update Magnitude: 0.69409

Collected Steps per Second: 15,208.67419
Overall Steps per Second: 7,366.90644

Timestep Collection Time: 3.28931
Timestep Consumption Time: 3.50133
PPO Batch Consumption Time: 0.45412
Total Iteration Time: 6.79064

Cumulative Model Updates: 317,320
Cumulative Timesteps: 2,646,384,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.96137
Policy Entropy: 2.32168
Value Function Loss: 0.02353

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.10049
Policy Update Magnitude: 0.51204
Value Function Update Magnitude: 0.70490

Collected Steps per Second: 15,947.50769
Overall Steps per Second: 7,498.19241

Timestep Collection Time: 3.13692
Timestep Consumption Time: 3.53482
PPO Batch Consumption Time: 0.46028
Total Iteration Time: 6.67174

Cumulative Model Updates: 317,326
Cumulative Timesteps: 2,646,434,398

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2646434398...
Checkpoint 2646434398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.12812
Policy Entropy: 2.33482
Value Function Loss: 0.02280

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.09134
Policy Update Magnitude: 0.50681
Value Function Update Magnitude: 0.68858

Collected Steps per Second: 15,350.76096
Overall Steps per Second: 7,077.26150

Timestep Collection Time: 3.25834
Timestep Consumption Time: 3.80908
PPO Batch Consumption Time: 0.51079
Total Iteration Time: 7.06742

Cumulative Model Updates: 317,332
Cumulative Timesteps: 2,646,484,416

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.81392
Policy Entropy: 2.35908
Value Function Loss: 0.02180

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.09077
Policy Update Magnitude: 0.50358
Value Function Update Magnitude: 0.67084

Collected Steps per Second: 15,457.48666
Overall Steps per Second: 7,225.28156

Timestep Collection Time: 3.23584
Timestep Consumption Time: 3.68679
PPO Batch Consumption Time: 0.48423
Total Iteration Time: 6.92264

Cumulative Model Updates: 317,338
Cumulative Timesteps: 2,646,534,434

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2646534434...
Checkpoint 2646534434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.88498
Policy Entropy: 2.36971
Value Function Loss: 0.02102

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.48953
Value Function Update Magnitude: 0.65089

Collected Steps per Second: 15,820.78364
Overall Steps per Second: 7,374.97755

Timestep Collection Time: 3.16192
Timestep Consumption Time: 3.62102
PPO Batch Consumption Time: 0.47221
Total Iteration Time: 6.78294

Cumulative Model Updates: 317,344
Cumulative Timesteps: 2,646,584,458

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.96605
Policy Entropy: 2.35993
Value Function Loss: 0.02057

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.09143
Policy Update Magnitude: 0.48505
Value Function Update Magnitude: 0.65879

Collected Steps per Second: 15,104.97718
Overall Steps per Second: 6,940.32244

Timestep Collection Time: 3.31215
Timestep Consumption Time: 3.89645
PPO Batch Consumption Time: 0.52496
Total Iteration Time: 7.20860

Cumulative Model Updates: 317,350
Cumulative Timesteps: 2,646,634,488

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2646634488...
Checkpoint 2646634488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.66175
Policy Entropy: 2.35464
Value Function Loss: 0.02020

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.09429
Policy Update Magnitude: 0.47943
Value Function Update Magnitude: 0.66494

Collected Steps per Second: 14,980.98484
Overall Steps per Second: 7,353.86931

Timestep Collection Time: 3.33823
Timestep Consumption Time: 3.46227
PPO Batch Consumption Time: 0.45088
Total Iteration Time: 6.80050

Cumulative Model Updates: 317,356
Cumulative Timesteps: 2,646,684,498

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.81168
Policy Entropy: 2.33619
Value Function Loss: 0.02056

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.09058
Policy Update Magnitude: 0.48166
Value Function Update Magnitude: 0.66439

Collected Steps per Second: 15,124.16147
Overall Steps per Second: 6,957.17885

Timestep Collection Time: 3.30663
Timestep Consumption Time: 3.88163
PPO Batch Consumption Time: 0.51547
Total Iteration Time: 7.18826

Cumulative Model Updates: 317,362
Cumulative Timesteps: 2,646,734,508

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2646734508...
Checkpoint 2646734508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.81613
Policy Entropy: 2.33561
Value Function Loss: 0.02110

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.08376
Policy Update Magnitude: 0.48126
Value Function Update Magnitude: 0.65887

Collected Steps per Second: 14,884.68772
Overall Steps per Second: 7,057.50690

Timestep Collection Time: 3.35996
Timestep Consumption Time: 3.72639
PPO Batch Consumption Time: 0.49170
Total Iteration Time: 7.08636

Cumulative Model Updates: 317,368
Cumulative Timesteps: 2,646,784,520

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.73251
Policy Entropy: 2.31932
Value Function Loss: 0.02096

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.09195
Policy Update Magnitude: 0.49216
Value Function Update Magnitude: 0.66621

Collected Steps per Second: 15,251.74417
Overall Steps per Second: 6,971.33614

Timestep Collection Time: 3.28002
Timestep Consumption Time: 3.89594
PPO Batch Consumption Time: 0.51577
Total Iteration Time: 7.17596

Cumulative Model Updates: 317,374
Cumulative Timesteps: 2,646,834,546

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2646834546...
Checkpoint 2646834546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.45283
Policy Entropy: 2.30920
Value Function Loss: 0.02084

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.10227
Policy Update Magnitude: 0.49247
Value Function Update Magnitude: 0.68588

Collected Steps per Second: 15,017.59622
Overall Steps per Second: 7,244.42472

Timestep Collection Time: 3.33143
Timestep Consumption Time: 3.57458
PPO Batch Consumption Time: 0.47008
Total Iteration Time: 6.90600

Cumulative Model Updates: 317,380
Cumulative Timesteps: 2,646,884,576

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.82049
Policy Entropy: 2.30196
Value Function Loss: 0.02157

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.50285
Value Function Update Magnitude: 0.68794

Collected Steps per Second: 16,502.32916
Overall Steps per Second: 7,536.14341

Timestep Collection Time: 3.03060
Timestep Consumption Time: 3.60568
PPO Batch Consumption Time: 0.47151
Total Iteration Time: 6.63629

Cumulative Model Updates: 317,386
Cumulative Timesteps: 2,646,934,588

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2646934588...
Checkpoint 2646934588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.71465
Policy Entropy: 2.29693
Value Function Loss: 0.02232

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.49275
Value Function Update Magnitude: 0.67696

Collected Steps per Second: 15,608.35130
Overall Steps per Second: 7,505.21159

Timestep Collection Time: 3.20380
Timestep Consumption Time: 3.45904
PPO Batch Consumption Time: 0.44781
Total Iteration Time: 6.66284

Cumulative Model Updates: 317,392
Cumulative Timesteps: 2,646,984,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.14268
Policy Entropy: 2.31435
Value Function Loss: 0.02262

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.09435
Policy Update Magnitude: 0.48501
Value Function Update Magnitude: 0.67714

Collected Steps per Second: 15,859.04090
Overall Steps per Second: 7,560.91931

Timestep Collection Time: 3.15303
Timestep Consumption Time: 3.46045
PPO Batch Consumption Time: 0.45079
Total Iteration Time: 6.61348

Cumulative Model Updates: 317,398
Cumulative Timesteps: 2,647,034,598

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2647034598...
Checkpoint 2647034598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.99845
Policy Entropy: 2.31936
Value Function Loss: 0.02331

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.11142
Policy Update Magnitude: 0.48992
Value Function Update Magnitude: 0.69720

Collected Steps per Second: 15,313.92677
Overall Steps per Second: 7,225.82561

Timestep Collection Time: 3.26513
Timestep Consumption Time: 3.65477
PPO Batch Consumption Time: 0.49297
Total Iteration Time: 6.91990

Cumulative Model Updates: 317,404
Cumulative Timesteps: 2,647,084,600

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.42161
Policy Entropy: 2.33271
Value Function Loss: 0.02261

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.09992
Policy Update Magnitude: 0.49123
Value Function Update Magnitude: 0.70932

Collected Steps per Second: 15,199.58258
Overall Steps per Second: 7,622.01545

Timestep Collection Time: 3.29049
Timestep Consumption Time: 3.27130
PPO Batch Consumption Time: 0.41625
Total Iteration Time: 6.56178

Cumulative Model Updates: 317,410
Cumulative Timesteps: 2,647,134,614

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2647134614...
Checkpoint 2647134614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.79457
Policy Entropy: 2.33825
Value Function Loss: 0.02205

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.09493
Policy Update Magnitude: 0.48708
Value Function Update Magnitude: 0.69828

Collected Steps per Second: 18,140.67149
Overall Steps per Second: 9,372.83226

Timestep Collection Time: 2.75701
Timestep Consumption Time: 2.57905
PPO Batch Consumption Time: 0.30715
Total Iteration Time: 5.33606

Cumulative Model Updates: 317,416
Cumulative Timesteps: 2,647,184,628

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2647184628...
Checkpoint 2647184628 saved!
