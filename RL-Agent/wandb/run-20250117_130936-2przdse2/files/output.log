Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,176.30264
Policy Entropy: 0.51373
Value Function Loss: 0.13821

Mean KL Divergence: 0.00132
SB3 Clip Fraction: 0.01701
Policy Update Magnitude: 0.06445
Value Function Update Magnitude: 0.12763

Collected Steps per Second: 12,707.70705
Overall Steps per Second: 10,114.81724

Timestep Collection Time: 3.93808
Timestep Consumption Time: 1.00951
PPO Batch Consumption Time: 0.20118
Total Iteration Time: 4.94759

Cumulative Model Updates: 47,576
Cumulative Timesteps: 396,902,648

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,458.35915
Policy Entropy: 0.52536
Value Function Loss: 0.12123

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02932
Policy Update Magnitude: 0.12963
Value Function Update Magnitude: 0.25565

Collected Steps per Second: 13,024.29128
Overall Steps per Second: 9,766.07645

Timestep Collection Time: 3.83929
Timestep Consumption Time: 1.28089
PPO Batch Consumption Time: 0.14617
Total Iteration Time: 5.12017

Cumulative Model Updates: 47,580
Cumulative Timesteps: 396,952,652

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 396952652...
Checkpoint 396952652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,433.87598
Policy Entropy: 0.53249
Value Function Loss: 0.10763

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05411
Policy Update Magnitude: 0.18520
Value Function Update Magnitude: 0.35457

Collected Steps per Second: 13,089.63838
Overall Steps per Second: 9,387.77288

Timestep Collection Time: 3.82241
Timestep Consumption Time: 1.50729
PPO Batch Consumption Time: 0.15053
Total Iteration Time: 5.32970

Cumulative Model Updates: 47,586
Cumulative Timesteps: 397,002,686

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,477.94779
Policy Entropy: 0.52874
Value Function Loss: 0.10830

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07932
Policy Update Magnitude: 0.15727
Value Function Update Magnitude: 0.34918

Collected Steps per Second: 14,247.33822
Overall Steps per Second: 10,104.12069

Timestep Collection Time: 3.51041
Timestep Consumption Time: 1.43945
PPO Batch Consumption Time: 0.13907
Total Iteration Time: 4.94986

Cumulative Model Updates: 47,592
Cumulative Timesteps: 397,052,700

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 397052700...
Checkpoint 397052700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,409.49571
Policy Entropy: 0.52832
Value Function Loss: 0.10832

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07066
Policy Update Magnitude: 0.16862
Value Function Update Magnitude: 0.37500

Collected Steps per Second: 14,014.34900
Overall Steps per Second: 9,964.93257

Timestep Collection Time: 3.57091
Timestep Consumption Time: 1.45110
PPO Batch Consumption Time: 0.14320
Total Iteration Time: 5.02201

Cumulative Model Updates: 47,598
Cumulative Timesteps: 397,102,744

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,607.33332
Policy Entropy: 0.51999
Value Function Loss: 0.11292

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06886
Policy Update Magnitude: 0.18200
Value Function Update Magnitude: 0.36181

Collected Steps per Second: 14,386.75831
Overall Steps per Second: 10,138.56019

Timestep Collection Time: 3.47639
Timestep Consumption Time: 1.45666
PPO Batch Consumption Time: 0.14347
Total Iteration Time: 4.93305

Cumulative Model Updates: 47,604
Cumulative Timesteps: 397,152,758

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 397152758...
Checkpoint 397152758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,647.94762
Policy Entropy: 0.53146
Value Function Loss: 0.12385

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.06553
Policy Update Magnitude: 0.17737
Value Function Update Magnitude: 0.36877

Collected Steps per Second: 12,822.79791
Overall Steps per Second: 9,245.54897

Timestep Collection Time: 3.89930
Timestep Consumption Time: 1.50870
PPO Batch Consumption Time: 0.14720
Total Iteration Time: 5.40801

Cumulative Model Updates: 47,610
Cumulative Timesteps: 397,202,758

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,271.19852
Policy Entropy: 0.53091
Value Function Loss: 0.12084

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09209
Policy Update Magnitude: 0.15303
Value Function Update Magnitude: 0.42512

Collected Steps per Second: 14,539.24843
Overall Steps per Second: 10,097.27302

Timestep Collection Time: 3.43966
Timestep Consumption Time: 1.51317
PPO Batch Consumption Time: 0.14252
Total Iteration Time: 4.95282

Cumulative Model Updates: 47,616
Cumulative Timesteps: 397,252,768

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 397252768...
Checkpoint 397252768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,672.63242
Policy Entropy: 0.52596
Value Function Loss: 0.12086

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06355
Policy Update Magnitude: 0.16649
Value Function Update Magnitude: 0.42854

Collected Steps per Second: 13,979.53452
Overall Steps per Second: 9,913.95028

Timestep Collection Time: 3.57666
Timestep Consumption Time: 1.46674
PPO Batch Consumption Time: 0.14442
Total Iteration Time: 5.04340

Cumulative Model Updates: 47,622
Cumulative Timesteps: 397,302,768

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,548.56090
Policy Entropy: 0.51845
Value Function Loss: 0.11269

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05014
Policy Update Magnitude: 0.18516
Value Function Update Magnitude: 0.39260

Collected Steps per Second: 13,988.78459
Overall Steps per Second: 9,836.79173

Timestep Collection Time: 3.57601
Timestep Consumption Time: 1.50939
PPO Batch Consumption Time: 0.14578
Total Iteration Time: 5.08540

Cumulative Model Updates: 47,628
Cumulative Timesteps: 397,352,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 397352792...
Checkpoint 397352792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,615.21153
Policy Entropy: 0.51921
Value Function Loss: 0.11249

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04864
Policy Update Magnitude: 0.19389
Value Function Update Magnitude: 0.37191

Collected Steps per Second: 12,569.39547
Overall Steps per Second: 9,101.15463

Timestep Collection Time: 3.97935
Timestep Consumption Time: 1.51644
PPO Batch Consumption Time: 0.14963
Total Iteration Time: 5.49579

Cumulative Model Updates: 47,634
Cumulative Timesteps: 397,402,810

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,170.17103
Policy Entropy: 0.51662
Value Function Loss: 0.11301

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05690
Policy Update Magnitude: 0.19435
Value Function Update Magnitude: 0.38257

Collected Steps per Second: 13,670.46601
Overall Steps per Second: 9,901.08163

Timestep Collection Time: 3.65884
Timestep Consumption Time: 1.39293
PPO Batch Consumption Time: 0.13166
Total Iteration Time: 5.05177

Cumulative Model Updates: 47,640
Cumulative Timesteps: 397,452,828

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 397452828...
Checkpoint 397452828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,156.76083
Policy Entropy: 0.50758
Value Function Loss: 0.11393

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.09591
Policy Update Magnitude: 0.16789
Value Function Update Magnitude: 0.38377

Collected Steps per Second: 13,646.32708
Overall Steps per Second: 9,887.11789

Timestep Collection Time: 3.66531
Timestep Consumption Time: 1.39360
PPO Batch Consumption Time: 0.13331
Total Iteration Time: 5.05891

Cumulative Model Updates: 47,646
Cumulative Timesteps: 397,502,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,628.17043
Policy Entropy: 0.50543
Value Function Loss: 0.10542

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07917
Policy Update Magnitude: 0.16207
Value Function Update Magnitude: 0.39937

Collected Steps per Second: 14,326.07375
Overall Steps per Second: 10,099.98774

Timestep Collection Time: 3.49042
Timestep Consumption Time: 1.46048
PPO Batch Consumption Time: 0.14437
Total Iteration Time: 4.95090

Cumulative Model Updates: 47,652
Cumulative Timesteps: 397,552,850

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 397552850...
Checkpoint 397552850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,629.78361
Policy Entropy: 0.50139
Value Function Loss: 0.09529

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08234
Policy Update Magnitude: 0.16698
Value Function Update Magnitude: 0.41277

Collected Steps per Second: 14,091.45861
Overall Steps per Second: 10,041.68911

Timestep Collection Time: 3.55052
Timestep Consumption Time: 1.43191
PPO Batch Consumption Time: 0.13972
Total Iteration Time: 4.98243

Cumulative Model Updates: 47,658
Cumulative Timesteps: 397,602,882

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,940.29212
Policy Entropy: 0.50051
Value Function Loss: 0.09614

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06995
Policy Update Magnitude: 0.17862
Value Function Update Magnitude: 0.40351

Collected Steps per Second: 14,593.77404
Overall Steps per Second: 10,249.84772

Timestep Collection Time: 3.42749
Timestep Consumption Time: 1.45258
PPO Batch Consumption Time: 0.14323
Total Iteration Time: 4.88007

Cumulative Model Updates: 47,664
Cumulative Timesteps: 397,652,902

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 397652902...
Checkpoint 397652902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,863.48017
Policy Entropy: 0.48859
Value Function Loss: 0.10893

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.06955
Policy Update Magnitude: 0.17003
Value Function Update Magnitude: 0.37671

Collected Steps per Second: 14,167.36875
Overall Steps per Second: 10,084.19000

Timestep Collection Time: 3.52952
Timestep Consumption Time: 1.42913
PPO Batch Consumption Time: 0.13686
Total Iteration Time: 4.95865

Cumulative Model Updates: 47,670
Cumulative Timesteps: 397,702,906

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,895.30632
Policy Entropy: 0.49148
Value Function Loss: 0.11416

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08159
Policy Update Magnitude: 0.16011
Value Function Update Magnitude: 0.38401

Collected Steps per Second: 14,534.12642
Overall Steps per Second: 10,208.49948

Timestep Collection Time: 3.44321
Timestep Consumption Time: 1.45898
PPO Batch Consumption Time: 0.14455
Total Iteration Time: 4.90219

Cumulative Model Updates: 47,676
Cumulative Timesteps: 397,752,950

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 397752950...
Checkpoint 397752950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,879.23018
Policy Entropy: 0.49383
Value Function Loss: 0.11225

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.08240
Policy Update Magnitude: 0.14894
Value Function Update Magnitude: 0.39780

Collected Steps per Second: 14,419.43737
Overall Steps per Second: 10,225.60530

Timestep Collection Time: 3.46962
Timestep Consumption Time: 1.42300
PPO Batch Consumption Time: 0.13947
Total Iteration Time: 4.89262

Cumulative Model Updates: 47,682
Cumulative Timesteps: 397,802,980

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,947.64053
Policy Entropy: 0.49252
Value Function Loss: 0.10499

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.07214
Policy Update Magnitude: 0.14748
Value Function Update Magnitude: 0.37613

Collected Steps per Second: 14,385.65145
Overall Steps per Second: 10,141.72188

Timestep Collection Time: 3.47624
Timestep Consumption Time: 1.45468
PPO Batch Consumption Time: 0.14306
Total Iteration Time: 4.93092

Cumulative Model Updates: 47,688
Cumulative Timesteps: 397,852,988

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 397852988...
Checkpoint 397852988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,667.05053
Policy Entropy: 0.49259
Value Function Loss: 0.10708

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07152
Policy Update Magnitude: 0.14202
Value Function Update Magnitude: 0.36693

Collected Steps per Second: 14,248.47921
Overall Steps per Second: 10,103.79517

Timestep Collection Time: 3.50929
Timestep Consumption Time: 1.43955
PPO Batch Consumption Time: 0.14183
Total Iteration Time: 4.94883

Cumulative Model Updates: 47,694
Cumulative Timesteps: 397,902,990

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,093.75909
Policy Entropy: 0.48901
Value Function Loss: 0.10753

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06504
Policy Update Magnitude: 0.14014
Value Function Update Magnitude: 0.37223

Collected Steps per Second: 14,619.07332
Overall Steps per Second: 10,274.88046

Timestep Collection Time: 3.42334
Timestep Consumption Time: 1.44738
PPO Batch Consumption Time: 0.14318
Total Iteration Time: 4.87071

Cumulative Model Updates: 47,700
Cumulative Timesteps: 397,953,036

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 397953036...
Checkpoint 397953036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,246.73636
Policy Entropy: 0.49512
Value Function Loss: 0.10511

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.06864
Policy Update Magnitude: 0.14490
Value Function Update Magnitude: 0.37480

Collected Steps per Second: 14,184.97294
Overall Steps per Second: 9,946.00030

Timestep Collection Time: 3.52528
Timestep Consumption Time: 1.50247
PPO Batch Consumption Time: 0.14208
Total Iteration Time: 5.02775

Cumulative Model Updates: 47,706
Cumulative Timesteps: 398,003,042

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,789.07628
Policy Entropy: 0.48818
Value Function Loss: 0.10791

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07476
Policy Update Magnitude: 0.13624
Value Function Update Magnitude: 0.36957

Collected Steps per Second: 14,836.57474
Overall Steps per Second: 10,316.05788

Timestep Collection Time: 3.37086
Timestep Consumption Time: 1.47712
PPO Batch Consumption Time: 0.13796
Total Iteration Time: 4.84798

Cumulative Model Updates: 47,712
Cumulative Timesteps: 398,053,054

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 398053054...
Checkpoint 398053054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,653.44810
Policy Entropy: 0.48962
Value Function Loss: 0.13334

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07138
Policy Update Magnitude: 0.15920
Value Function Update Magnitude: 0.41194

Collected Steps per Second: 14,727.32885
Overall Steps per Second: 10,293.19066

Timestep Collection Time: 3.39573
Timestep Consumption Time: 1.46282
PPO Batch Consumption Time: 0.14378
Total Iteration Time: 4.85855

Cumulative Model Updates: 47,718
Cumulative Timesteps: 398,103,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,333.95314
Policy Entropy: 0.48544
Value Function Loss: 0.14387

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06110
Policy Update Magnitude: 0.18271
Value Function Update Magnitude: 0.42838

Collected Steps per Second: 14,693.20544
Overall Steps per Second: 10,142.09067

Timestep Collection Time: 3.40348
Timestep Consumption Time: 1.52726
PPO Batch Consumption Time: 0.14474
Total Iteration Time: 4.93074

Cumulative Model Updates: 47,724
Cumulative Timesteps: 398,153,072

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 398153072...
Checkpoint 398153072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,175.55372
Policy Entropy: 0.49781
Value Function Loss: 0.14220

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05498
Policy Update Magnitude: 0.20760
Value Function Update Magnitude: 0.44705

Collected Steps per Second: 14,390.78469
Overall Steps per Second: 9,916.17500

Timestep Collection Time: 3.47445
Timestep Consumption Time: 1.56782
PPO Batch Consumption Time: 0.15256
Total Iteration Time: 5.04227

Cumulative Model Updates: 47,730
Cumulative Timesteps: 398,203,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,443.36792
Policy Entropy: 0.49650
Value Function Loss: 0.12567

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.05309
Policy Update Magnitude: 0.20378
Value Function Update Magnitude: 0.45189

Collected Steps per Second: 15,145.72949
Overall Steps per Second: 10,378.15000

Timestep Collection Time: 3.30179
Timestep Consumption Time: 1.51680
PPO Batch Consumption Time: 0.14576
Total Iteration Time: 4.81859

Cumulative Model Updates: 47,736
Cumulative Timesteps: 398,253,080

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 398253080...
Checkpoint 398253080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,439.78046
Policy Entropy: 0.49827
Value Function Loss: 0.11989

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05599
Policy Update Magnitude: 0.19694
Value Function Update Magnitude: 0.47181

Collected Steps per Second: 14,453.56516
Overall Steps per Second: 10,093.52351

Timestep Collection Time: 3.46046
Timestep Consumption Time: 1.49480
PPO Batch Consumption Time: 0.14071
Total Iteration Time: 4.95526

Cumulative Model Updates: 47,742
Cumulative Timesteps: 398,303,096

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,955.22662
Policy Entropy: 0.48482
Value Function Loss: 0.12241

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07414
Policy Update Magnitude: 0.16898
Value Function Update Magnitude: 0.49114

Collected Steps per Second: 14,687.91011
Overall Steps per Second: 10,173.08941

Timestep Collection Time: 3.40443
Timestep Consumption Time: 1.51089
PPO Batch Consumption Time: 0.14035
Total Iteration Time: 4.91532

Cumulative Model Updates: 47,748
Cumulative Timesteps: 398,353,100

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 398353100...
Checkpoint 398353100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,140.98686
Policy Entropy: 0.47722
Value Function Loss: 0.11587

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.16652
Value Function Update Magnitude: 0.47791

Collected Steps per Second: 14,455.77189
Overall Steps per Second: 10,108.65970

Timestep Collection Time: 3.46007
Timestep Consumption Time: 1.48796
PPO Batch Consumption Time: 0.13832
Total Iteration Time: 4.94803

Cumulative Model Updates: 47,754
Cumulative Timesteps: 398,403,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,465.20968
Policy Entropy: 0.46818
Value Function Loss: 0.11654

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.05712
Policy Update Magnitude: 0.16174
Value Function Update Magnitude: 0.43148

Collected Steps per Second: 15,080.19802
Overall Steps per Second: 10,389.42262

Timestep Collection Time: 3.31653
Timestep Consumption Time: 1.49740
PPO Batch Consumption Time: 0.14038
Total Iteration Time: 4.81393

Cumulative Model Updates: 47,760
Cumulative Timesteps: 398,453,132

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 398453132...
Checkpoint 398453132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,060.97956
Policy Entropy: 0.48025
Value Function Loss: 0.10729

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05082
Policy Update Magnitude: 0.17639
Value Function Update Magnitude: 0.40462

Collected Steps per Second: 14,371.78819
Overall Steps per Second: 10,073.50009

Timestep Collection Time: 3.47973
Timestep Consumption Time: 1.48478
PPO Batch Consumption Time: 0.14049
Total Iteration Time: 4.96451

Cumulative Model Updates: 47,766
Cumulative Timesteps: 398,503,142

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,283.38266
Policy Entropy: 0.47763
Value Function Loss: 0.09712

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05071
Policy Update Magnitude: 0.16751
Value Function Update Magnitude: 0.43477

Collected Steps per Second: 15,136.04240
Overall Steps per Second: 10,353.01573

Timestep Collection Time: 3.30522
Timestep Consumption Time: 1.52699
PPO Batch Consumption Time: 0.14215
Total Iteration Time: 4.83222

Cumulative Model Updates: 47,772
Cumulative Timesteps: 398,553,170

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 398553170...
Checkpoint 398553170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,528.89667
Policy Entropy: 0.48805
Value Function Loss: 0.09595

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04559
Policy Update Magnitude: 0.17260
Value Function Update Magnitude: 0.43004

Collected Steps per Second: 14,712.28953
Overall Steps per Second: 10,084.08178

Timestep Collection Time: 3.40083
Timestep Consumption Time: 1.56085
PPO Batch Consumption Time: 0.14549
Total Iteration Time: 4.96168

Cumulative Model Updates: 47,778
Cumulative Timesteps: 398,603,204

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,172.95842
Policy Entropy: 0.48255
Value Function Loss: 0.09986

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05106
Policy Update Magnitude: 0.17154
Value Function Update Magnitude: 0.44900

Collected Steps per Second: 14,647.05610
Overall Steps per Second: 10,126.04908

Timestep Collection Time: 3.41379
Timestep Consumption Time: 1.52417
PPO Batch Consumption Time: 0.14419
Total Iteration Time: 4.93796

Cumulative Model Updates: 47,784
Cumulative Timesteps: 398,653,206

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 398653206...
Checkpoint 398653206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,179.77731
Policy Entropy: 0.47723
Value Function Loss: 0.11020

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04990
Policy Update Magnitude: 0.17976
Value Function Update Magnitude: 0.43140

Collected Steps per Second: 14,653.36485
Overall Steps per Second: 10,128.93254

Timestep Collection Time: 3.41287
Timestep Consumption Time: 1.52447
PPO Batch Consumption Time: 0.14319
Total Iteration Time: 4.93734

Cumulative Model Updates: 47,790
Cumulative Timesteps: 398,703,216

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,858.74696
Policy Entropy: 0.46949
Value Function Loss: 0.11460

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.05202
Policy Update Magnitude: 0.17666
Value Function Update Magnitude: 0.41939

Collected Steps per Second: 14,967.62017
Overall Steps per Second: 10,350.85008

Timestep Collection Time: 3.34228
Timestep Consumption Time: 1.49075
PPO Batch Consumption Time: 0.14209
Total Iteration Time: 4.83303

Cumulative Model Updates: 47,796
Cumulative Timesteps: 398,753,242

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 398753242...
Checkpoint 398753242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,102.60757
Policy Entropy: 0.47974
Value Function Loss: 0.11013

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.10928
Policy Update Magnitude: 0.15731
Value Function Update Magnitude: 0.46621

Collected Steps per Second: 14,417.09082
Overall Steps per Second: 9,870.71923

Timestep Collection Time: 3.46949
Timestep Consumption Time: 1.59802
PPO Batch Consumption Time: 0.15156
Total Iteration Time: 5.06751

Cumulative Model Updates: 47,802
Cumulative Timesteps: 398,803,262

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,966.16633
Policy Entropy: 0.47706
Value Function Loss: 0.09624

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.11414
Policy Update Magnitude: 0.12700
Value Function Update Magnitude: 0.44773

Collected Steps per Second: 14,889.23620
Overall Steps per Second: 10,276.08406

Timestep Collection Time: 3.36015
Timestep Consumption Time: 1.50844
PPO Batch Consumption Time: 0.14504
Total Iteration Time: 4.86859

Cumulative Model Updates: 47,808
Cumulative Timesteps: 398,853,292

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 398853292...
Checkpoint 398853292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,393.95649
Policy Entropy: 0.48380
Value Function Loss: 0.08679

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08241
Policy Update Magnitude: 0.12865
Value Function Update Magnitude: 0.42380

Collected Steps per Second: 14,295.04058
Overall Steps per Second: 9,959.17340

Timestep Collection Time: 3.49856
Timestep Consumption Time: 1.52315
PPO Batch Consumption Time: 0.14377
Total Iteration Time: 5.02170

Cumulative Model Updates: 47,814
Cumulative Timesteps: 398,903,304

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,747.12202
Policy Entropy: 0.48167
Value Function Loss: 0.08981

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.07329
Policy Update Magnitude: 0.13665
Value Function Update Magnitude: 0.43661

Collected Steps per Second: 14,791.54764
Overall Steps per Second: 10,194.36677

Timestep Collection Time: 3.38261
Timestep Consumption Time: 1.52540
PPO Batch Consumption Time: 0.14064
Total Iteration Time: 4.90800

Cumulative Model Updates: 47,820
Cumulative Timesteps: 398,953,338

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 398953338...
Checkpoint 398953338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,685.32753
Policy Entropy: 0.48512
Value Function Loss: 0.09232

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.06552
Policy Update Magnitude: 0.16182
Value Function Update Magnitude: 0.44221

Collected Steps per Second: 14,235.61140
Overall Steps per Second: 9,861.18573

Timestep Collection Time: 3.51443
Timestep Consumption Time: 1.55900
PPO Batch Consumption Time: 0.14535
Total Iteration Time: 5.07343

Cumulative Model Updates: 47,826
Cumulative Timesteps: 399,003,368

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,176.37949
Policy Entropy: 0.48729
Value Function Loss: 0.08964

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06529
Policy Update Magnitude: 0.15376
Value Function Update Magnitude: 0.42911

Collected Steps per Second: 14,662.47673
Overall Steps per Second: 10,133.91931

Timestep Collection Time: 3.41075
Timestep Consumption Time: 1.52416
PPO Batch Consumption Time: 0.14074
Total Iteration Time: 4.93491

Cumulative Model Updates: 47,832
Cumulative Timesteps: 399,053,378

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 399053378...
Checkpoint 399053378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,744.43979
Policy Entropy: 0.48877
Value Function Loss: 0.09084

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04728
Policy Update Magnitude: 0.16470
Value Function Update Magnitude: 0.41745

Collected Steps per Second: 14,544.57753
Overall Steps per Second: 10,097.08311

Timestep Collection Time: 3.43812
Timestep Consumption Time: 1.51440
PPO Batch Consumption Time: 0.14450
Total Iteration Time: 4.95252

Cumulative Model Updates: 47,838
Cumulative Timesteps: 399,103,384

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,635.86279
Policy Entropy: 0.48774
Value Function Loss: 0.09534

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04238
Policy Update Magnitude: 0.17527
Value Function Update Magnitude: 0.42033

Collected Steps per Second: 14,764.00460
Overall Steps per Second: 10,206.59523

Timestep Collection Time: 3.38905
Timestep Consumption Time: 1.51327
PPO Batch Consumption Time: 0.14166
Total Iteration Time: 4.90232

Cumulative Model Updates: 47,844
Cumulative Timesteps: 399,153,420

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 399153420...
Checkpoint 399153420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,335.99194
Policy Entropy: 0.48133
Value Function Loss: 0.10914

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03724
Policy Update Magnitude: 0.17475
Value Function Update Magnitude: 0.40554

Collected Steps per Second: 14,612.82469
Overall Steps per Second: 10,079.57103

Timestep Collection Time: 3.42384
Timestep Consumption Time: 1.53986
PPO Batch Consumption Time: 0.14328
Total Iteration Time: 4.96370

Cumulative Model Updates: 47,850
Cumulative Timesteps: 399,203,452

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,561.97825
Policy Entropy: 0.48651
Value Function Loss: 0.10979

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04140
Policy Update Magnitude: 0.17482
Value Function Update Magnitude: 0.43829

Collected Steps per Second: 14,724.25979
Overall Steps per Second: 10,138.38909

Timestep Collection Time: 3.39603
Timestep Consumption Time: 1.53612
PPO Batch Consumption Time: 0.14163
Total Iteration Time: 4.93214

Cumulative Model Updates: 47,856
Cumulative Timesteps: 399,253,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 399253456...
Checkpoint 399253456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,359.64231
Policy Entropy: 0.48919
Value Function Loss: 0.10600

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.05196
Policy Update Magnitude: 0.16704
Value Function Update Magnitude: 0.45406

Collected Steps per Second: 14,573.81572
Overall Steps per Second: 10,046.03414

Timestep Collection Time: 3.43081
Timestep Consumption Time: 1.54628
PPO Batch Consumption Time: 0.14466
Total Iteration Time: 4.97709

Cumulative Model Updates: 47,862
Cumulative Timesteps: 399,303,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,220.97720
Policy Entropy: 0.48963
Value Function Loss: 0.10065

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.06416
Policy Update Magnitude: 0.15395
Value Function Update Magnitude: 0.44991

Collected Steps per Second: 14,732.82896
Overall Steps per Second: 10,150.06812

Timestep Collection Time: 3.39500
Timestep Consumption Time: 1.53285
PPO Batch Consumption Time: 0.14163
Total Iteration Time: 4.92785

Cumulative Model Updates: 47,868
Cumulative Timesteps: 399,353,474

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 399353474...
Checkpoint 399353474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,361.54941
Policy Entropy: 0.48200
Value Function Loss: 0.09948

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06459
Policy Update Magnitude: 0.16571
Value Function Update Magnitude: 0.44900

Collected Steps per Second: 14,431.17596
Overall Steps per Second: 10,085.70672

Timestep Collection Time: 3.46486
Timestep Consumption Time: 1.49285
PPO Batch Consumption Time: 0.14166
Total Iteration Time: 4.95771

Cumulative Model Updates: 47,874
Cumulative Timesteps: 399,403,476

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,005.25448
Policy Entropy: 0.49623
Value Function Loss: 0.09898

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.06119
Policy Update Magnitude: 0.17674
Value Function Update Magnitude: 0.44424

Collected Steps per Second: 14,186.15516
Overall Steps per Second: 9,617.58170

Timestep Collection Time: 3.52513
Timestep Consumption Time: 1.67452
PPO Batch Consumption Time: 0.15996
Total Iteration Time: 5.19964

Cumulative Model Updates: 47,880
Cumulative Timesteps: 399,453,484

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 399453484...
Checkpoint 399453484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,430.36154
Policy Entropy: 0.49864
Value Function Loss: 0.09624

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.05904
Policy Update Magnitude: 0.17764
Value Function Update Magnitude: 0.43641

Collected Steps per Second: 14,389.00222
Overall Steps per Second: 10,215.03630

Timestep Collection Time: 3.47502
Timestep Consumption Time: 1.41993
PPO Batch Consumption Time: 0.13332
Total Iteration Time: 4.89494

Cumulative Model Updates: 47,886
Cumulative Timesteps: 399,503,486

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,810.44761
Policy Entropy: 0.50793
Value Function Loss: 0.09832

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05490
Policy Update Magnitude: 0.17440
Value Function Update Magnitude: 0.43961

Collected Steps per Second: 14,423.97072
Overall Steps per Second: 10,048.18496

Timestep Collection Time: 3.46728
Timestep Consumption Time: 1.50993
PPO Batch Consumption Time: 0.13879
Total Iteration Time: 4.97722

Cumulative Model Updates: 47,892
Cumulative Timesteps: 399,553,498

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 399553498...
Checkpoint 399553498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,036.77066
Policy Entropy: 0.50439
Value Function Loss: 0.09530

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03911
Policy Update Magnitude: 0.16992
Value Function Update Magnitude: 0.40044

Collected Steps per Second: 14,276.61476
Overall Steps per Second: 9,625.97680

Timestep Collection Time: 3.50489
Timestep Consumption Time: 1.69333
PPO Batch Consumption Time: 0.16524
Total Iteration Time: 5.19823

Cumulative Model Updates: 47,898
Cumulative Timesteps: 399,603,536

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,983.80418
Policy Entropy: 0.50308
Value Function Loss: 0.09708

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04183
Policy Update Magnitude: 0.16796
Value Function Update Magnitude: 0.35384

Collected Steps per Second: 14,042.64819
Overall Steps per Second: 9,687.87547

Timestep Collection Time: 3.56258
Timestep Consumption Time: 1.60140
PPO Batch Consumption Time: 0.15108
Total Iteration Time: 5.16398

Cumulative Model Updates: 47,904
Cumulative Timesteps: 399,653,564

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 399653564...
Checkpoint 399653564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,533.63951
Policy Entropy: 0.49840
Value Function Loss: 0.10889

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03939
Policy Update Magnitude: 0.17247
Value Function Update Magnitude: 0.33866

Collected Steps per Second: 14,093.32294
Overall Steps per Second: 9,870.84948

Timestep Collection Time: 3.54977
Timestep Consumption Time: 1.51849
PPO Batch Consumption Time: 0.13898
Total Iteration Time: 5.06826

Cumulative Model Updates: 47,910
Cumulative Timesteps: 399,703,592

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,216.17537
Policy Entropy: 0.49452
Value Function Loss: 0.12620

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04386
Policy Update Magnitude: 0.18676
Value Function Update Magnitude: 0.40876

Collected Steps per Second: 14,435.48860
Overall Steps per Second: 10,143.32178

Timestep Collection Time: 3.46452
Timestep Consumption Time: 1.46602
PPO Batch Consumption Time: 0.13619
Total Iteration Time: 4.93053

Cumulative Model Updates: 47,916
Cumulative Timesteps: 399,753,604

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 399753604...
Checkpoint 399753604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,542.03939
Policy Entropy: 0.49588
Value Function Loss: 0.13221

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05418
Policy Update Magnitude: 0.18496
Value Function Update Magnitude: 0.43584

Collected Steps per Second: 14,506.87066
Overall Steps per Second: 10,113.23291

Timestep Collection Time: 3.44788
Timestep Consumption Time: 1.49791
PPO Batch Consumption Time: 0.13666
Total Iteration Time: 4.94580

Cumulative Model Updates: 47,922
Cumulative Timesteps: 399,803,622

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,793.74869
Policy Entropy: 0.50025
Value Function Loss: 0.12664

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.05742
Policy Update Magnitude: 0.17783
Value Function Update Magnitude: 0.44940

Collected Steps per Second: 14,212.34332
Overall Steps per Second: 9,663.25349

Timestep Collection Time: 3.51877
Timestep Consumption Time: 1.65650
PPO Batch Consumption Time: 0.15459
Total Iteration Time: 5.17528

Cumulative Model Updates: 47,928
Cumulative Timesteps: 399,853,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 399853632...
Checkpoint 399853632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,378.72086
Policy Entropy: 0.50262
Value Function Loss: 0.12156

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.06607
Policy Update Magnitude: 0.15642
Value Function Update Magnitude: 0.44794

Collected Steps per Second: 13,824.40775
Overall Steps per Second: 9,883.73542

Timestep Collection Time: 3.61867
Timestep Consumption Time: 1.44277
PPO Batch Consumption Time: 0.13268
Total Iteration Time: 5.06145

Cumulative Model Updates: 47,934
Cumulative Timesteps: 399,903,658

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,396.30338
Policy Entropy: 0.49664
Value Function Loss: 0.11429

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.06580
Policy Update Magnitude: 0.14843
Value Function Update Magnitude: 0.41063

Collected Steps per Second: 15,076.23065
Overall Steps per Second: 10,374.90021

Timestep Collection Time: 3.31727
Timestep Consumption Time: 1.50321
PPO Batch Consumption Time: 0.13383
Total Iteration Time: 4.82048

Cumulative Model Updates: 47,940
Cumulative Timesteps: 399,953,670

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 399953670...
Checkpoint 399953670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,408.02084
Policy Entropy: 0.49172
Value Function Loss: 0.12327

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06027
Policy Update Magnitude: 0.14543
Value Function Update Magnitude: 0.37405

Collected Steps per Second: 15,115.23569
Overall Steps per Second: 10,512.87862

Timestep Collection Time: 3.30924
Timestep Consumption Time: 1.44873
PPO Batch Consumption Time: 0.13371
Total Iteration Time: 4.75797

Cumulative Model Updates: 47,946
Cumulative Timesteps: 400,003,690

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,522.23618
Policy Entropy: 0.49944
Value Function Loss: 0.12702

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06398
Policy Update Magnitude: 0.15818
Value Function Update Magnitude: 0.38510

Collected Steps per Second: 15,383.46536
Overall Steps per Second: 10,511.32218

Timestep Collection Time: 3.25076
Timestep Consumption Time: 1.50677
PPO Batch Consumption Time: 0.13831
Total Iteration Time: 4.75754

Cumulative Model Updates: 47,952
Cumulative Timesteps: 400,053,698

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 400053698...
Checkpoint 400053698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,542.89857
Policy Entropy: 0.50751
Value Function Loss: 0.12579

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.06890
Policy Update Magnitude: 0.16383
Value Function Update Magnitude: 0.38649

Collected Steps per Second: 14,428.88023
Overall Steps per Second: 10,081.27959

Timestep Collection Time: 3.46818
Timestep Consumption Time: 1.49567
PPO Batch Consumption Time: 0.14062
Total Iteration Time: 4.96385

Cumulative Model Updates: 47,958
Cumulative Timesteps: 400,103,740

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,115.79089
Policy Entropy: 0.50857
Value Function Loss: 0.12579

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06430
Policy Update Magnitude: 0.16151
Value Function Update Magnitude: 0.43692

Collected Steps per Second: 13,816.07594
Overall Steps per Second: 9,651.96933

Timestep Collection Time: 3.62172
Timestep Consumption Time: 1.56250
PPO Batch Consumption Time: 0.14413
Total Iteration Time: 5.18423

Cumulative Model Updates: 47,964
Cumulative Timesteps: 400,153,778

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 400153778...
Checkpoint 400153778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,020.78322
Policy Entropy: 0.51006
Value Function Loss: 0.12004

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.06538
Policy Update Magnitude: 0.15484
Value Function Update Magnitude: 0.47047

Collected Steps per Second: 14,708.40813
Overall Steps per Second: 10,246.84232

Timestep Collection Time: 3.40023
Timestep Consumption Time: 1.48049
PPO Batch Consumption Time: 0.13548
Total Iteration Time: 4.88072

Cumulative Model Updates: 47,970
Cumulative Timesteps: 400,203,790

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,694.86291
Policy Entropy: 0.51397
Value Function Loss: 0.11653

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06189
Policy Update Magnitude: 0.15669
Value Function Update Magnitude: 0.48350

Collected Steps per Second: 15,081.34043
Overall Steps per Second: 10,393.44179

Timestep Collection Time: 3.31655
Timestep Consumption Time: 1.49591
PPO Batch Consumption Time: 0.13478
Total Iteration Time: 4.81246

Cumulative Model Updates: 47,976
Cumulative Timesteps: 400,253,808

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 400253808...
Checkpoint 400253808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,035.74301
Policy Entropy: 0.51453
Value Function Loss: 0.11803

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07618
Policy Update Magnitude: 0.16675
Value Function Update Magnitude: 0.45981

Collected Steps per Second: 15,053.89794
Overall Steps per Second: 10,381.74833

Timestep Collection Time: 3.32259
Timestep Consumption Time: 1.49528
PPO Batch Consumption Time: 0.13680
Total Iteration Time: 4.81788

Cumulative Model Updates: 47,982
Cumulative Timesteps: 400,303,826

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,379.30229
Policy Entropy: 0.51882
Value Function Loss: 0.11777

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.06681
Policy Update Magnitude: 0.17857
Value Function Update Magnitude: 0.43609

Collected Steps per Second: 14,756.37347
Overall Steps per Second: 10,197.82654

Timestep Collection Time: 3.38877
Timestep Consumption Time: 1.51482
PPO Batch Consumption Time: 0.13843
Total Iteration Time: 4.90359

Cumulative Model Updates: 47,988
Cumulative Timesteps: 400,353,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 400353832...
Checkpoint 400353832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,158.85904
Policy Entropy: 0.52307
Value Function Loss: 0.11601

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.06646
Policy Update Magnitude: 0.17088
Value Function Update Magnitude: 0.36492

Collected Steps per Second: 15,201.22111
Overall Steps per Second: 10,386.82192

Timestep Collection Time: 3.29105
Timestep Consumption Time: 1.52544
PPO Batch Consumption Time: 0.14619
Total Iteration Time: 4.81649

Cumulative Model Updates: 47,994
Cumulative Timesteps: 400,403,860

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,489.63574
Policy Entropy: 0.51827
Value Function Loss: 0.12161

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07085
Policy Update Magnitude: 0.15393
Value Function Update Magnitude: 0.40911

Collected Steps per Second: 14,020.26659
Overall Steps per Second: 9,735.65159

Timestep Collection Time: 3.56684
Timestep Consumption Time: 1.56975
PPO Batch Consumption Time: 0.15289
Total Iteration Time: 5.13658

Cumulative Model Updates: 48,000
Cumulative Timesteps: 400,453,868

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 400453868...
Checkpoint 400453868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,628.74505
Policy Entropy: 0.51382
Value Function Loss: 0.12917

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07186
Policy Update Magnitude: 0.15436
Value Function Update Magnitude: 0.40577

Collected Steps per Second: 15,076.79210
Overall Steps per Second: 10,451.50445

Timestep Collection Time: 3.31821
Timestep Consumption Time: 1.46847
PPO Batch Consumption Time: 0.13719
Total Iteration Time: 4.78668

Cumulative Model Updates: 48,006
Cumulative Timesteps: 400,503,896

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,295.17698
Policy Entropy: 0.51138
Value Function Loss: 0.13174

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.05926
Policy Update Magnitude: 0.18062
Value Function Update Magnitude: 0.37410

Collected Steps per Second: 15,223.68149
Overall Steps per Second: 10,226.85715

Timestep Collection Time: 3.28528
Timestep Consumption Time: 1.60518
PPO Batch Consumption Time: 0.14980
Total Iteration Time: 4.89046

Cumulative Model Updates: 48,012
Cumulative Timesteps: 400,553,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 400553910...
Checkpoint 400553910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,056.65540
Policy Entropy: 0.51720
Value Function Loss: 0.12873

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.05976
Policy Update Magnitude: 0.18687
Value Function Update Magnitude: 0.34917

Collected Steps per Second: 15,073.25128
Overall Steps per Second: 10,408.41603

Timestep Collection Time: 3.31966
Timestep Consumption Time: 1.48780
PPO Batch Consumption Time: 0.13367
Total Iteration Time: 4.80746

Cumulative Model Updates: 48,018
Cumulative Timesteps: 400,603,948

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,479.99864
Policy Entropy: 0.51758
Value Function Loss: 0.13006

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06892
Policy Update Magnitude: 0.17076
Value Function Update Magnitude: 0.36813

Collected Steps per Second: 15,299.10896
Overall Steps per Second: 10,236.81664

Timestep Collection Time: 3.26921
Timestep Consumption Time: 1.61668
PPO Batch Consumption Time: 0.14395
Total Iteration Time: 4.88589

Cumulative Model Updates: 48,024
Cumulative Timesteps: 400,653,964

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 400653964...
Checkpoint 400653964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,582.28547
Policy Entropy: 0.52698
Value Function Loss: 0.12465

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06895
Policy Update Magnitude: 0.15733
Value Function Update Magnitude: 0.39710

Collected Steps per Second: 14,398.06720
Overall Steps per Second: 10,043.34025

Timestep Collection Time: 3.47574
Timestep Consumption Time: 1.50706
PPO Batch Consumption Time: 0.13908
Total Iteration Time: 4.98280

Cumulative Model Updates: 48,030
Cumulative Timesteps: 400,704,008

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,259.54768
Policy Entropy: 0.52059
Value Function Loss: 0.11335

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06856
Policy Update Magnitude: 0.14988
Value Function Update Magnitude: 0.37141

Collected Steps per Second: 14,686.99725
Overall Steps per Second: 10,152.15379

Timestep Collection Time: 3.40464
Timestep Consumption Time: 1.52081
PPO Batch Consumption Time: 0.14001
Total Iteration Time: 4.92546

Cumulative Model Updates: 48,036
Cumulative Timesteps: 400,754,012

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 400754012...
Checkpoint 400754012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,471.17440
Policy Entropy: 0.52976
Value Function Loss: 0.10231

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.06519
Policy Update Magnitude: 0.15675
Value Function Update Magnitude: 0.35817

Collected Steps per Second: 14,785.13452
Overall Steps per Second: 10,212.18026

Timestep Collection Time: 3.38232
Timestep Consumption Time: 1.51458
PPO Batch Consumption Time: 0.14006
Total Iteration Time: 4.89690

Cumulative Model Updates: 48,042
Cumulative Timesteps: 400,804,020

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,792.34511
Policy Entropy: 0.52480
Value Function Loss: 0.10539

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.06611
Policy Update Magnitude: 0.15519
Value Function Update Magnitude: 0.38596

Collected Steps per Second: 14,412.43665
Overall Steps per Second: 10,069.43636

Timestep Collection Time: 3.47103
Timestep Consumption Time: 1.49707
PPO Batch Consumption Time: 0.13809
Total Iteration Time: 4.96810

Cumulative Model Updates: 48,048
Cumulative Timesteps: 400,854,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 400854046...
Checkpoint 400854046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,857.23029
Policy Entropy: 0.53218
Value Function Loss: 0.10152

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05855
Policy Update Magnitude: 0.16256
Value Function Update Magnitude: 0.40173

Collected Steps per Second: 13,294.57362
Overall Steps per Second: 9,413.30355

Timestep Collection Time: 3.76153
Timestep Consumption Time: 1.55095
PPO Batch Consumption Time: 0.14222
Total Iteration Time: 5.31248

Cumulative Model Updates: 48,054
Cumulative Timesteps: 400,904,054

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,512.36370
Policy Entropy: 0.52424
Value Function Loss: 0.09648

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.05819
Policy Update Magnitude: 0.17385
Value Function Update Magnitude: 0.36665

Collected Steps per Second: 14,924.21120
Overall Steps per Second: 10,228.95132

Timestep Collection Time: 3.35133
Timestep Consumption Time: 1.53832
PPO Batch Consumption Time: 0.14063
Total Iteration Time: 4.88965

Cumulative Model Updates: 48,060
Cumulative Timesteps: 400,954,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 400954070...
Checkpoint 400954070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,420.48644
Policy Entropy: 0.51786
Value Function Loss: 0.10091

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07060
Policy Update Magnitude: 0.16737
Value Function Update Magnitude: 0.38831

Collected Steps per Second: 14,722.66881
Overall Steps per Second: 10,168.02262

Timestep Collection Time: 3.39735
Timestep Consumption Time: 1.52180
PPO Batch Consumption Time: 0.13896
Total Iteration Time: 4.91915

Cumulative Model Updates: 48,066
Cumulative Timesteps: 401,004,088

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,450.59624
Policy Entropy: 0.50876
Value Function Loss: 0.10309

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.05926
Policy Update Magnitude: 0.16835
Value Function Update Magnitude: 0.40630

Collected Steps per Second: 14,006.39931
Overall Steps per Second: 9,880.07123

Timestep Collection Time: 3.57051
Timestep Consumption Time: 1.49119
PPO Batch Consumption Time: 0.13410
Total Iteration Time: 5.06170

Cumulative Model Updates: 48,072
Cumulative Timesteps: 401,054,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 401054098...
Checkpoint 401054098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,231.40756
Policy Entropy: 0.51370
Value Function Loss: 0.10606

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.05431
Policy Update Magnitude: 0.17541
Value Function Update Magnitude: 0.39355

Collected Steps per Second: 14,182.91245
Overall Steps per Second: 9,979.39309

Timestep Collection Time: 3.52720
Timestep Consumption Time: 1.48573
PPO Batch Consumption Time: 0.13384
Total Iteration Time: 5.01293

Cumulative Model Updates: 48,078
Cumulative Timesteps: 401,104,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,361.18494
Policy Entropy: 0.51094
Value Function Loss: 0.10756

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.05052
Policy Update Magnitude: 0.18572
Value Function Update Magnitude: 0.39672

Collected Steps per Second: 13,972.50519
Overall Steps per Second: 9,856.56256

Timestep Collection Time: 3.57974
Timestep Consumption Time: 1.49484
PPO Batch Consumption Time: 0.13609
Total Iteration Time: 5.07459

Cumulative Model Updates: 48,084
Cumulative Timesteps: 401,154,142

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 401154142...
Checkpoint 401154142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,053.80164
Policy Entropy: 0.50867
Value Function Loss: 0.11289

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04488
Policy Update Magnitude: 0.18984
Value Function Update Magnitude: 0.46541

Collected Steps per Second: 15,367.31536
Overall Steps per Second: 10,512.94310

Timestep Collection Time: 3.25522
Timestep Consumption Time: 1.50310
PPO Batch Consumption Time: 0.13900
Total Iteration Time: 4.75833

Cumulative Model Updates: 48,090
Cumulative Timesteps: 401,204,166

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,505.08402
Policy Entropy: 0.50618
Value Function Loss: 0.12010

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03836
Policy Update Magnitude: 0.19908
Value Function Update Magnitude: 0.46176

Collected Steps per Second: 14,392.30619
Overall Steps per Second: 9,803.78590

Timestep Collection Time: 3.47519
Timestep Consumption Time: 1.62651
PPO Batch Consumption Time: 0.16164
Total Iteration Time: 5.10170

Cumulative Model Updates: 48,096
Cumulative Timesteps: 401,254,182

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 401254182...
Checkpoint 401254182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,130.15234
Policy Entropy: 0.51338
Value Function Loss: 0.11449

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04615
Policy Update Magnitude: 0.20450
Value Function Update Magnitude: 0.43387

Collected Steps per Second: 15,178.83055
Overall Steps per Second: 10,524.47161

Timestep Collection Time: 3.29551
Timestep Consumption Time: 1.45741
PPO Batch Consumption Time: 0.13388
Total Iteration Time: 4.75292

Cumulative Model Updates: 48,102
Cumulative Timesteps: 401,304,204

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,354.32149
Policy Entropy: 0.51506
Value Function Loss: 0.10861

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04538
Policy Update Magnitude: 0.19512
Value Function Update Magnitude: 0.41216

Collected Steps per Second: 14,980.61322
Overall Steps per Second: 10,444.31358

Timestep Collection Time: 3.33805
Timestep Consumption Time: 1.44982
PPO Batch Consumption Time: 0.13322
Total Iteration Time: 4.78787

Cumulative Model Updates: 48,108
Cumulative Timesteps: 401,354,210

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 401354210...
Checkpoint 401354210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,105.66388
Policy Entropy: 0.51612
Value Function Loss: 0.10841

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05370
Policy Update Magnitude: 0.19072
Value Function Update Magnitude: 0.43304

Collected Steps per Second: 15,254.45038
Overall Steps per Second: 10,692.25452

Timestep Collection Time: 3.27786
Timestep Consumption Time: 1.39861
PPO Batch Consumption Time: 0.12952
Total Iteration Time: 4.67647

Cumulative Model Updates: 48,114
Cumulative Timesteps: 401,404,212

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,473.51492
Policy Entropy: 0.51185
Value Function Loss: 0.11536

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03958
Policy Update Magnitude: 0.18938
Value Function Update Magnitude: 0.44841

Collected Steps per Second: 14,410.82920
Overall Steps per Second: 9,768.84445

Timestep Collection Time: 3.47031
Timestep Consumption Time: 1.64903
PPO Batch Consumption Time: 0.15471
Total Iteration Time: 5.11934

Cumulative Model Updates: 48,120
Cumulative Timesteps: 401,454,222

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 401454222...
Checkpoint 401454222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,614.38990
Policy Entropy: 0.51556
Value Function Loss: 0.10879

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04539
Policy Update Magnitude: 0.19576
Value Function Update Magnitude: 0.49377

Collected Steps per Second: 13,038.10498
Overall Steps per Second: 9,301.48036

Timestep Collection Time: 3.83629
Timestep Consumption Time: 1.54113
PPO Batch Consumption Time: 0.14062
Total Iteration Time: 5.37742

Cumulative Model Updates: 48,126
Cumulative Timesteps: 401,504,240

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,422.96583
Policy Entropy: 0.52327
Value Function Loss: 0.09809

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04876
Policy Update Magnitude: 0.18854
Value Function Update Magnitude: 0.48966

Collected Steps per Second: 14,156.46812
Overall Steps per Second: 9,806.88977

Timestep Collection Time: 3.53266
Timestep Consumption Time: 1.56682
PPO Batch Consumption Time: 0.14077
Total Iteration Time: 5.09948

Cumulative Model Updates: 48,132
Cumulative Timesteps: 401,554,250

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 401554250...
Checkpoint 401554250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,282.67825
Policy Entropy: 0.53035
Value Function Loss: 0.09148

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04798
Policy Update Magnitude: 0.17639
Value Function Update Magnitude: 0.45697

Collected Steps per Second: 13,830.35001
Overall Steps per Second: 9,638.69785

Timestep Collection Time: 3.61524
Timestep Consumption Time: 1.57219
PPO Batch Consumption Time: 0.14617
Total Iteration Time: 5.18742

Cumulative Model Updates: 48,138
Cumulative Timesteps: 401,604,250

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,530.79380
Policy Entropy: 0.52742
Value Function Loss: 0.09604

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.04639
Policy Update Magnitude: 0.17569
Value Function Update Magnitude: 0.44555

Collected Steps per Second: 14,876.56032
Overall Steps per Second: 10,169.93153

Timestep Collection Time: 3.36274
Timestep Consumption Time: 1.55627
PPO Batch Consumption Time: 0.14403
Total Iteration Time: 4.91901

Cumulative Model Updates: 48,144
Cumulative Timesteps: 401,654,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 401654276...
Checkpoint 401654276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,140.65752
Policy Entropy: 0.53458
Value Function Loss: 0.09433

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.05223
Policy Update Magnitude: 0.17937
Value Function Update Magnitude: 0.44624

Collected Steps per Second: 14,710.49825
Overall Steps per Second: 10,192.52620

Timestep Collection Time: 3.40192
Timestep Consumption Time: 1.50795
PPO Batch Consumption Time: 0.13696
Total Iteration Time: 4.90987

Cumulative Model Updates: 48,150
Cumulative Timesteps: 401,704,320

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,075.83555
Policy Entropy: 0.52349
Value Function Loss: 0.09117

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05318
Policy Update Magnitude: 0.17958
Value Function Update Magnitude: 0.44107

Collected Steps per Second: 15,062.28803
Overall Steps per Second: 10,320.09505

Timestep Collection Time: 3.32021
Timestep Consumption Time: 1.52567
PPO Batch Consumption Time: 0.13975
Total Iteration Time: 4.84589

Cumulative Model Updates: 48,156
Cumulative Timesteps: 401,754,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 401754330...
Checkpoint 401754330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,731.84692
Policy Entropy: 0.52472
Value Function Loss: 0.09041

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.05030
Policy Update Magnitude: 0.17097
Value Function Update Magnitude: 0.45610

Collected Steps per Second: 14,571.82672
Overall Steps per Second: 10,123.76470

Timestep Collection Time: 3.43210
Timestep Consumption Time: 1.50796
PPO Batch Consumption Time: 0.13766
Total Iteration Time: 4.94006

Cumulative Model Updates: 48,162
Cumulative Timesteps: 401,804,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,950.21019
Policy Entropy: 0.51197
Value Function Loss: 0.10022

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04255
Policy Update Magnitude: 0.16879
Value Function Update Magnitude: 0.47586

Collected Steps per Second: 14,894.77883
Overall Steps per Second: 10,261.55267

Timestep Collection Time: 3.35849
Timestep Consumption Time: 1.51640
PPO Batch Consumption Time: 0.14044
Total Iteration Time: 4.87490

Cumulative Model Updates: 48,168
Cumulative Timesteps: 401,854,366

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 401854366...
Checkpoint 401854366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,736.80867
Policy Entropy: 0.51629
Value Function Loss: 0.11293

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.04041
Policy Update Magnitude: 0.18050
Value Function Update Magnitude: 0.46836

Collected Steps per Second: 14,530.77420
Overall Steps per Second: 10,114.63318

Timestep Collection Time: 3.44139
Timestep Consumption Time: 1.50254
PPO Batch Consumption Time: 0.14031
Total Iteration Time: 4.94393

Cumulative Model Updates: 48,174
Cumulative Timesteps: 401,904,372

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,885.45847
Policy Entropy: 0.51339
Value Function Loss: 0.11756

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03536
Policy Update Magnitude: 0.18762
Value Function Update Magnitude: 0.44117

Collected Steps per Second: 14,726.47255
Overall Steps per Second: 10,245.72892

Timestep Collection Time: 3.39660
Timestep Consumption Time: 1.48543
PPO Batch Consumption Time: 0.13836
Total Iteration Time: 4.88203

Cumulative Model Updates: 48,180
Cumulative Timesteps: 401,954,392

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 401954392...
Checkpoint 401954392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,092.21358
Policy Entropy: 0.52537
Value Function Loss: 0.11860

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.04328
Policy Update Magnitude: 0.17931
Value Function Update Magnitude: 0.43909

Collected Steps per Second: 14,601.95698
Overall Steps per Second: 10,081.02755

Timestep Collection Time: 3.42529
Timestep Consumption Time: 1.53610
PPO Batch Consumption Time: 0.14190
Total Iteration Time: 4.96140

Cumulative Model Updates: 48,186
Cumulative Timesteps: 402,004,408

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,178.97656
Policy Entropy: 0.52406
Value Function Loss: 0.11362

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04045
Policy Update Magnitude: 0.17833
Value Function Update Magnitude: 0.42167

Collected Steps per Second: 14,567.44199
Overall Steps per Second: 10,113.18155

Timestep Collection Time: 3.43396
Timestep Consumption Time: 1.51246
PPO Batch Consumption Time: 0.14148
Total Iteration Time: 4.94642

Cumulative Model Updates: 48,192
Cumulative Timesteps: 402,054,432

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 402054432...
Checkpoint 402054432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,510.94912
Policy Entropy: 0.52889
Value Function Loss: 0.10575

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04764
Policy Update Magnitude: 0.17911
Value Function Update Magnitude: 0.43802

Collected Steps per Second: 14,546.27418
Overall Steps per Second: 10,044.53872

Timestep Collection Time: 3.43744
Timestep Consumption Time: 1.54058
PPO Batch Consumption Time: 0.14001
Total Iteration Time: 4.97803

Cumulative Model Updates: 48,198
Cumulative Timesteps: 402,104,434

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,121.85490
Policy Entropy: 0.53351
Value Function Loss: 0.10496

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04958
Policy Update Magnitude: 0.17746
Value Function Update Magnitude: 0.39966

Collected Steps per Second: 14,837.64348
Overall Steps per Second: 10,282.71715

Timestep Collection Time: 3.37062
Timestep Consumption Time: 1.49308
PPO Batch Consumption Time: 0.14006
Total Iteration Time: 4.86370

Cumulative Model Updates: 48,204
Cumulative Timesteps: 402,154,446

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 402154446...
Checkpoint 402154446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,201.16684
Policy Entropy: 0.53146
Value Function Loss: 0.10358

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05321
Policy Update Magnitude: 0.17884
Value Function Update Magnitude: 0.42144

Collected Steps per Second: 14,541.95910
Overall Steps per Second: 10,065.67113

Timestep Collection Time: 3.44011
Timestep Consumption Time: 1.52985
PPO Batch Consumption Time: 0.14489
Total Iteration Time: 4.96996

Cumulative Model Updates: 48,210
Cumulative Timesteps: 402,204,472

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,141.76061
Policy Entropy: 0.53043
Value Function Loss: 0.09742

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.05243
Policy Update Magnitude: 0.17744
Value Function Update Magnitude: 0.45144

Collected Steps per Second: 14,735.94455
Overall Steps per Second: 10,144.55792

Timestep Collection Time: 3.39306
Timestep Consumption Time: 1.53569
PPO Batch Consumption Time: 0.14036
Total Iteration Time: 4.92875

Cumulative Model Updates: 48,216
Cumulative Timesteps: 402,254,472

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 402254472...
Checkpoint 402254472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,581.42309
Policy Entropy: 0.52476
Value Function Loss: 0.10572

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.04915
Policy Update Magnitude: 0.17744
Value Function Update Magnitude: 0.45084

Collected Steps per Second: 14,543.38498
Overall Steps per Second: 9,972.73506

Timestep Collection Time: 3.43964
Timestep Consumption Time: 1.57644
PPO Batch Consumption Time: 0.14422
Total Iteration Time: 5.01608

Cumulative Model Updates: 48,222
Cumulative Timesteps: 402,304,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,318.89502
Policy Entropy: 0.52769
Value Function Loss: 0.11364

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.04924
Policy Update Magnitude: 0.18158
Value Function Update Magnitude: 0.46124

Collected Steps per Second: 13,712.24159
Overall Steps per Second: 9,508.53668

Timestep Collection Time: 3.64842
Timestep Consumption Time: 1.61296
PPO Batch Consumption Time: 0.15078
Total Iteration Time: 5.26138

Cumulative Model Updates: 48,228
Cumulative Timesteps: 402,354,524

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 402354524...
Checkpoint 402354524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,338.29008
Policy Entropy: 0.52362
Value Function Loss: 0.12055

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05142
Policy Update Magnitude: 0.19040
Value Function Update Magnitude: 0.46925

Collected Steps per Second: 14,376.87712
Overall Steps per Second: 9,900.05385

Timestep Collection Time: 3.48087
Timestep Consumption Time: 1.57405
PPO Batch Consumption Time: 0.14553
Total Iteration Time: 5.05492

Cumulative Model Updates: 48,234
Cumulative Timesteps: 402,404,568

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,181.50708
Policy Entropy: 0.52862
Value Function Loss: 0.12011

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.07619
Policy Update Magnitude: 0.17404
Value Function Update Magnitude: 0.47306

Collected Steps per Second: 13,477.83635
Overall Steps per Second: 9,485.15282

Timestep Collection Time: 3.71098
Timestep Consumption Time: 1.56210
PPO Batch Consumption Time: 0.14322
Total Iteration Time: 5.27308

Cumulative Model Updates: 48,240
Cumulative Timesteps: 402,454,584

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 402454584...
Checkpoint 402454584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,754.17901
Policy Entropy: 0.53250
Value Function Loss: 0.11650

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.14927
Value Function Update Magnitude: 0.42831

Collected Steps per Second: 12,507.02326
Overall Steps per Second: 9,029.57538

Timestep Collection Time: 3.99903
Timestep Consumption Time: 1.54010
PPO Batch Consumption Time: 0.13867
Total Iteration Time: 5.53913

Cumulative Model Updates: 48,246
Cumulative Timesteps: 402,504,600

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,648.93245
Policy Entropy: 0.54202
Value Function Loss: 0.11357

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07484
Policy Update Magnitude: 0.14274
Value Function Update Magnitude: 0.46855

Collected Steps per Second: 15,311.49270
Overall Steps per Second: 10,597.66723

Timestep Collection Time: 3.26591
Timestep Consumption Time: 1.45267
PPO Batch Consumption Time: 0.13264
Total Iteration Time: 4.71859

Cumulative Model Updates: 48,252
Cumulative Timesteps: 402,554,606

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 402554606...
Checkpoint 402554606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,802.24324
Policy Entropy: 0.54063
Value Function Loss: 0.10190

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07019
Policy Update Magnitude: 0.14177
Value Function Update Magnitude: 0.46759

Collected Steps per Second: 12,670.56804
Overall Steps per Second: 9,071.96115

Timestep Collection Time: 3.94789
Timestep Consumption Time: 1.56602
PPO Batch Consumption Time: 0.14483
Total Iteration Time: 5.51391

Cumulative Model Updates: 48,258
Cumulative Timesteps: 402,604,628

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,628.18633
Policy Entropy: 0.54978
Value Function Loss: 0.10442

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.06577
Policy Update Magnitude: 0.16134
Value Function Update Magnitude: 0.44750

Collected Steps per Second: 14,747.11883
Overall Steps per Second: 10,071.34142

Timestep Collection Time: 3.39266
Timestep Consumption Time: 1.57510
PPO Batch Consumption Time: 0.14635
Total Iteration Time: 4.96776

Cumulative Model Updates: 48,264
Cumulative Timesteps: 402,654,660

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 402654660...
Checkpoint 402654660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,680.04544
Policy Entropy: 0.53630
Value Function Loss: 0.10494

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07469
Policy Update Magnitude: 0.15949
Value Function Update Magnitude: 0.40468

Collected Steps per Second: 14,586.80426
Overall Steps per Second: 10,103.97924

Timestep Collection Time: 3.42776
Timestep Consumption Time: 1.52079
PPO Batch Consumption Time: 0.14000
Total Iteration Time: 4.94855

Cumulative Model Updates: 48,270
Cumulative Timesteps: 402,704,660

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,432.73513
Policy Entropy: 0.54414
Value Function Loss: 0.10846

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.05593
Policy Update Magnitude: 0.17186
Value Function Update Magnitude: 0.37663

Collected Steps per Second: 14,865.41715
Overall Steps per Second: 10,175.72838

Timestep Collection Time: 3.36418
Timestep Consumption Time: 1.55045
PPO Batch Consumption Time: 0.14702
Total Iteration Time: 4.91464

Cumulative Model Updates: 48,276
Cumulative Timesteps: 402,754,670

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 402754670...
Checkpoint 402754670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,897.74528
Policy Entropy: 0.54052
Value Function Loss: 0.10466

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06131
Policy Update Magnitude: 0.17394
Value Function Update Magnitude: 0.39997

Collected Steps per Second: 14,378.02618
Overall Steps per Second: 9,870.47196

Timestep Collection Time: 3.47864
Timestep Consumption Time: 1.58859
PPO Batch Consumption Time: 0.14679
Total Iteration Time: 5.06723

Cumulative Model Updates: 48,282
Cumulative Timesteps: 402,804,686

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,944.09770
Policy Entropy: 0.55282
Value Function Loss: 0.10268

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.05006
Policy Update Magnitude: 0.17730
Value Function Update Magnitude: 0.41949

Collected Steps per Second: 14,246.02937
Overall Steps per Second: 9,816.96649

Timestep Collection Time: 3.51242
Timestep Consumption Time: 1.58468
PPO Batch Consumption Time: 0.14740
Total Iteration Time: 5.09709

Cumulative Model Updates: 48,288
Cumulative Timesteps: 402,854,724

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 402854724...
Checkpoint 402854724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,158.77048
Policy Entropy: 0.54246
Value Function Loss: 0.10437

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04710
Policy Update Magnitude: 0.17272
Value Function Update Magnitude: 0.46784

Collected Steps per Second: 14,249.33451
Overall Steps per Second: 9,871.71119

Timestep Collection Time: 3.50894
Timestep Consumption Time: 1.55604
PPO Batch Consumption Time: 0.14288
Total Iteration Time: 5.06498

Cumulative Model Updates: 48,294
Cumulative Timesteps: 402,904,724

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,641.38802
Policy Entropy: 0.53833
Value Function Loss: 0.10346

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.04004
Policy Update Magnitude: 0.17098
Value Function Update Magnitude: 0.44819

Collected Steps per Second: 14,379.69252
Overall Steps per Second: 10,006.15034

Timestep Collection Time: 3.47907
Timestep Consumption Time: 1.52065
PPO Batch Consumption Time: 0.13943
Total Iteration Time: 4.99973

Cumulative Model Updates: 48,300
Cumulative Timesteps: 402,954,752

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 402954752...
Checkpoint 402954752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,921.76785
Policy Entropy: 0.53455
Value Function Loss: 0.10276

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03691
Policy Update Magnitude: 0.17275
Value Function Update Magnitude: 0.41695

Collected Steps per Second: 12,944.71526
Overall Steps per Second: 9,175.71421

Timestep Collection Time: 3.86582
Timestep Consumption Time: 1.58792
PPO Batch Consumption Time: 0.13892
Total Iteration Time: 5.45374

Cumulative Model Updates: 48,306
Cumulative Timesteps: 403,004,794

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,626.52130
Policy Entropy: 0.54031
Value Function Loss: 0.09719

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.04127
Policy Update Magnitude: 0.17310
Value Function Update Magnitude: 0.38499

Collected Steps per Second: 13,588.93198
Overall Steps per Second: 9,484.50161

Timestep Collection Time: 3.68241
Timestep Consumption Time: 1.59357
PPO Batch Consumption Time: 0.13948
Total Iteration Time: 5.27598

Cumulative Model Updates: 48,312
Cumulative Timesteps: 403,054,834

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 403054834...
Checkpoint 403054834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,501.69729
Policy Entropy: 0.53891
Value Function Loss: 0.10646

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03729
Policy Update Magnitude: 0.17752
Value Function Update Magnitude: 0.36421

Collected Steps per Second: 14,747.54311
Overall Steps per Second: 10,175.93338

Timestep Collection Time: 3.39175
Timestep Consumption Time: 1.52377
PPO Batch Consumption Time: 0.14092
Total Iteration Time: 4.91552

Cumulative Model Updates: 48,318
Cumulative Timesteps: 403,104,854

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,529.00893
Policy Entropy: 0.53969
Value Function Loss: 0.10704

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.04047
Policy Update Magnitude: 0.18505
Value Function Update Magnitude: 0.35742

Collected Steps per Second: 14,627.51477
Overall Steps per Second: 10,003.02266

Timestep Collection Time: 3.41986
Timestep Consumption Time: 1.58103
PPO Batch Consumption Time: 0.14554
Total Iteration Time: 5.00089

Cumulative Model Updates: 48,324
Cumulative Timesteps: 403,154,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 403154878...
Checkpoint 403154878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,575.62920
Policy Entropy: 0.54475
Value Function Loss: 0.10723

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.04251
Policy Update Magnitude: 0.17983
Value Function Update Magnitude: 0.34968

Collected Steps per Second: 14,589.06495
Overall Steps per Second: 10,051.47050

Timestep Collection Time: 3.43024
Timestep Consumption Time: 1.54853
PPO Batch Consumption Time: 0.14691
Total Iteration Time: 4.97877

Cumulative Model Updates: 48,330
Cumulative Timesteps: 403,204,922

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,360.42719
Policy Entropy: 0.54413
Value Function Loss: 0.09617

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04378
Policy Update Magnitude: 0.16910
Value Function Update Magnitude: 0.35543

Collected Steps per Second: 13,998.19782
Overall Steps per Second: 9,873.86081

Timestep Collection Time: 3.57289
Timestep Consumption Time: 1.49240
PPO Batch Consumption Time: 0.13440
Total Iteration Time: 5.06529

Cumulative Model Updates: 48,336
Cumulative Timesteps: 403,254,936

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 403254936...
Checkpoint 403254936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,203.50056
Policy Entropy: 0.54176
Value Function Loss: 0.09370

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05050
Policy Update Magnitude: 0.15654
Value Function Update Magnitude: 0.34991

Collected Steps per Second: 13,907.51155
Overall Steps per Second: 9,846.65056

Timestep Collection Time: 3.59777
Timestep Consumption Time: 1.48376
PPO Batch Consumption Time: 0.13349
Total Iteration Time: 5.08152

Cumulative Model Updates: 48,342
Cumulative Timesteps: 403,304,972

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,894.85238
Policy Entropy: 0.53572
Value Function Loss: 0.09741

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04595
Policy Update Magnitude: 0.15150
Value Function Update Magnitude: 0.33731

Collected Steps per Second: 14,409.80404
Overall Steps per Second: 10,078.33372

Timestep Collection Time: 3.47028
Timestep Consumption Time: 1.49146
PPO Batch Consumption Time: 0.13382
Total Iteration Time: 4.96173

Cumulative Model Updates: 48,348
Cumulative Timesteps: 403,354,978

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 403354978...
Checkpoint 403354978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,827.32998
Policy Entropy: 0.54223
Value Function Loss: 0.09615

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05370
Policy Update Magnitude: 0.15508
Value Function Update Magnitude: 0.32811

Collected Steps per Second: 13,816.13084
Overall Steps per Second: 9,409.36636

Timestep Collection Time: 3.61896
Timestep Consumption Time: 1.69490
PPO Batch Consumption Time: 0.15870
Total Iteration Time: 5.31385

Cumulative Model Updates: 48,354
Cumulative Timesteps: 403,404,978

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,270.12281
Policy Entropy: 0.53243
Value Function Loss: 0.10196

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.05041
Policy Update Magnitude: 0.16187
Value Function Update Magnitude: 0.33111

Collected Steps per Second: 14,785.09674
Overall Steps per Second: 10,299.92896

Timestep Collection Time: 3.38300
Timestep Consumption Time: 1.47315
PPO Batch Consumption Time: 0.13530
Total Iteration Time: 4.85615

Cumulative Model Updates: 48,360
Cumulative Timesteps: 403,454,996

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 403454996...
Checkpoint 403454996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,108.76294
Policy Entropy: 0.54133
Value Function Loss: 0.09967

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05673
Policy Update Magnitude: 0.16807
Value Function Update Magnitude: 0.36810

Collected Steps per Second: 14,755.47016
Overall Steps per Second: 10,225.63990

Timestep Collection Time: 3.39006
Timestep Consumption Time: 1.50176
PPO Batch Consumption Time: 0.13675
Total Iteration Time: 4.89182

Cumulative Model Updates: 48,366
Cumulative Timesteps: 403,505,018

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,286.42488
Policy Entropy: 0.53816
Value Function Loss: 0.09422

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05265
Policy Update Magnitude: 0.17475
Value Function Update Magnitude: 0.36242

Collected Steps per Second: 14,994.97440
Overall Steps per Second: 10,360.08974

Timestep Collection Time: 3.33632
Timestep Consumption Time: 1.49260
PPO Batch Consumption Time: 0.13323
Total Iteration Time: 4.82892

Cumulative Model Updates: 48,372
Cumulative Timesteps: 403,555,046

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 403555046...
Checkpoint 403555046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,340.29410
Policy Entropy: 0.54205
Value Function Loss: 0.09619

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05150
Policy Update Magnitude: 0.17489
Value Function Update Magnitude: 0.35900

Collected Steps per Second: 14,623.20993
Overall Steps per Second: 10,240.18610

Timestep Collection Time: 3.41977
Timestep Consumption Time: 1.46374
PPO Batch Consumption Time: 0.13475
Total Iteration Time: 4.88351

Cumulative Model Updates: 48,378
Cumulative Timesteps: 403,605,054

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,596.11031
Policy Entropy: 0.53290
Value Function Loss: 0.10772

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04569
Policy Update Magnitude: 0.17551
Value Function Update Magnitude: 0.39132

Collected Steps per Second: 15,019.37964
Overall Steps per Second: 10,333.43879

Timestep Collection Time: 3.33076
Timestep Consumption Time: 1.51041
PPO Batch Consumption Time: 0.13558
Total Iteration Time: 4.84118

Cumulative Model Updates: 48,384
Cumulative Timesteps: 403,655,080

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 403655080...
Checkpoint 403655080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,898.96793
Policy Entropy: 0.52950
Value Function Loss: 0.10955

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04648
Policy Update Magnitude: 0.17407
Value Function Update Magnitude: 0.43677

Collected Steps per Second: 14,872.69239
Overall Steps per Second: 10,313.87183

Timestep Collection Time: 3.36227
Timestep Consumption Time: 1.48615
PPO Batch Consumption Time: 0.13523
Total Iteration Time: 4.84842

Cumulative Model Updates: 48,390
Cumulative Timesteps: 403,705,086

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,997.96073
Policy Entropy: 0.53145
Value Function Loss: 0.09992

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.05177
Policy Update Magnitude: 0.17217
Value Function Update Magnitude: 0.46051

Collected Steps per Second: 15,259.72186
Overall Steps per Second: 10,463.11029

Timestep Collection Time: 3.27804
Timestep Consumption Time: 1.50275
PPO Batch Consumption Time: 0.13759
Total Iteration Time: 4.78080

Cumulative Model Updates: 48,396
Cumulative Timesteps: 403,755,108

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 403755108...
Checkpoint 403755108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,882.69317
Policy Entropy: 0.53340
Value Function Loss: 0.09125

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.05794
Policy Update Magnitude: 0.16851
Value Function Update Magnitude: 0.42468

Collected Steps per Second: 15,055.40942
Overall Steps per Second: 10,337.73090

Timestep Collection Time: 3.32279
Timestep Consumption Time: 1.51637
PPO Batch Consumption Time: 0.13629
Total Iteration Time: 4.83917

Cumulative Model Updates: 48,402
Cumulative Timesteps: 403,805,134

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,038.14892
Policy Entropy: 0.53531
Value Function Loss: 0.09516

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07433
Policy Update Magnitude: 0.15783
Value Function Update Magnitude: 0.38951

Collected Steps per Second: 15,137.00085
Overall Steps per Second: 10,356.64586

Timestep Collection Time: 3.30343
Timestep Consumption Time: 1.52478
PPO Batch Consumption Time: 0.13848
Total Iteration Time: 4.82820

Cumulative Model Updates: 48,408
Cumulative Timesteps: 403,855,138

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 403855138...
Checkpoint 403855138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,327.87437
Policy Entropy: 0.53862
Value Function Loss: 0.10084

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06766
Policy Update Magnitude: 0.16540
Value Function Update Magnitude: 0.39526

Collected Steps per Second: 14,938.83875
Overall Steps per Second: 10,307.09607

Timestep Collection Time: 3.34805
Timestep Consumption Time: 1.50453
PPO Batch Consumption Time: 0.13685
Total Iteration Time: 4.85258

Cumulative Model Updates: 48,414
Cumulative Timesteps: 403,905,154

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,228.61075
Policy Entropy: 0.52497
Value Function Loss: 0.10256

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.06531
Policy Update Magnitude: 0.16872
Value Function Update Magnitude: 0.40870

Collected Steps per Second: 15,021.98947
Overall Steps per Second: 10,406.76302

Timestep Collection Time: 3.33112
Timestep Consumption Time: 1.47729
PPO Batch Consumption Time: 0.13797
Total Iteration Time: 4.80841

Cumulative Model Updates: 48,420
Cumulative Timesteps: 403,955,194

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 403955194...
Checkpoint 403955194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,745.67138
Policy Entropy: 0.52591
Value Function Loss: 0.11387

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.05932
Policy Update Magnitude: 0.17493
Value Function Update Magnitude: 0.41929

Collected Steps per Second: 15,033.40381
Overall Steps per Second: 10,327.10443

Timestep Collection Time: 3.32859
Timestep Consumption Time: 1.51691
PPO Batch Consumption Time: 0.13697
Total Iteration Time: 4.84550

Cumulative Model Updates: 48,426
Cumulative Timesteps: 404,005,234

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,766.29043
Policy Entropy: 0.51991
Value Function Loss: 0.10638

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.08550
Policy Update Magnitude: 0.15810
Value Function Update Magnitude: 0.38539

Collected Steps per Second: 14,968.33373
Overall Steps per Second: 9,942.27499

Timestep Collection Time: 3.34239
Timestep Consumption Time: 1.68966
PPO Batch Consumption Time: 0.15928
Total Iteration Time: 5.03205

Cumulative Model Updates: 48,432
Cumulative Timesteps: 404,055,264

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 404055264...
Checkpoint 404055264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,170.96298
Policy Entropy: 0.51786
Value Function Loss: 0.10652

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.06505
Policy Update Magnitude: 0.14367
Value Function Update Magnitude: 0.40780

Collected Steps per Second: 13,853.19426
Overall Steps per Second: 9,762.90049

Timestep Collection Time: 3.60971
Timestep Consumption Time: 1.51233
PPO Batch Consumption Time: 0.13589
Total Iteration Time: 5.12204

Cumulative Model Updates: 48,438
Cumulative Timesteps: 404,105,270

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,671.32711
Policy Entropy: 0.51412
Value Function Loss: 0.09949

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.06736
Policy Update Magnitude: 0.15274
Value Function Update Magnitude: 0.45864

Collected Steps per Second: 15,039.99768
Overall Steps per Second: 10,375.96854

Timestep Collection Time: 3.32633
Timestep Consumption Time: 1.49520
PPO Batch Consumption Time: 0.13559
Total Iteration Time: 4.82153

Cumulative Model Updates: 48,444
Cumulative Timesteps: 404,155,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 404155298...
Checkpoint 404155298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,677.73523
Policy Entropy: 0.52130
Value Function Loss: 0.10163

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06139
Policy Update Magnitude: 0.16751
Value Function Update Magnitude: 0.44671

Collected Steps per Second: 15,032.70118
Overall Steps per Second: 10,349.06830

Timestep Collection Time: 3.32635
Timestep Consumption Time: 1.50539
PPO Batch Consumption Time: 0.13641
Total Iteration Time: 4.83174

Cumulative Model Updates: 48,450
Cumulative Timesteps: 404,205,302

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,708.36315
Policy Entropy: 0.52757
Value Function Loss: 0.10474

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05534
Policy Update Magnitude: 0.17411
Value Function Update Magnitude: 0.42519

Collected Steps per Second: 15,252.28691
Overall Steps per Second: 10,439.07910

Timestep Collection Time: 3.27951
Timestep Consumption Time: 1.51210
PPO Batch Consumption Time: 0.13698
Total Iteration Time: 4.79161

Cumulative Model Updates: 48,456
Cumulative Timesteps: 404,255,322

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 404255322...
Checkpoint 404255322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,971.91643
Policy Entropy: 0.53469
Value Function Loss: 0.10445

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04277
Policy Update Magnitude: 0.17398
Value Function Update Magnitude: 0.40767

Collected Steps per Second: 14,953.67924
Overall Steps per Second: 10,352.92863

Timestep Collection Time: 3.34446
Timestep Consumption Time: 1.48625
PPO Batch Consumption Time: 0.13386
Total Iteration Time: 4.83071

Cumulative Model Updates: 48,462
Cumulative Timesteps: 404,305,334

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,440.88794
Policy Entropy: 0.53084
Value Function Loss: 0.10449

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.04544
Policy Update Magnitude: 0.17218
Value Function Update Magnitude: 0.42325

Collected Steps per Second: 15,208.72993
Overall Steps per Second: 10,446.70268

Timestep Collection Time: 3.28759
Timestep Consumption Time: 1.49861
PPO Batch Consumption Time: 0.13524
Total Iteration Time: 4.78620

Cumulative Model Updates: 48,468
Cumulative Timesteps: 404,355,334

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 404355334...
Checkpoint 404355334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,281.41739
Policy Entropy: 0.53211
Value Function Loss: 0.10284

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03499
Policy Update Magnitude: 0.17042
Value Function Update Magnitude: 0.45144

Collected Steps per Second: 15,003.54480
Overall Steps per Second: 10,358.63421

Timestep Collection Time: 3.33348
Timestep Consumption Time: 1.49476
PPO Batch Consumption Time: 0.13514
Total Iteration Time: 4.82824

Cumulative Model Updates: 48,474
Cumulative Timesteps: 404,405,348

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,383.44813
Policy Entropy: 0.52864
Value Function Loss: 0.11575

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03732
Policy Update Magnitude: 0.17177
Value Function Update Magnitude: 0.42011

Collected Steps per Second: 15,268.78771
Overall Steps per Second: 10,407.32950

Timestep Collection Time: 3.27479
Timestep Consumption Time: 1.52971
PPO Batch Consumption Time: 0.13547
Total Iteration Time: 4.80450

Cumulative Model Updates: 48,480
Cumulative Timesteps: 404,455,350

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 404455350...
Checkpoint 404455350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,777.70125
Policy Entropy: 0.52384
Value Function Loss: 0.11673

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.04627
Policy Update Magnitude: 0.17755
Value Function Update Magnitude: 0.43185

Collected Steps per Second: 15,086.09323
Overall Steps per Second: 10,394.79268

Timestep Collection Time: 3.31617
Timestep Consumption Time: 1.49663
PPO Batch Consumption Time: 0.13510
Total Iteration Time: 4.81279

Cumulative Model Updates: 48,486
Cumulative Timesteps: 404,505,378

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,311.65985
Policy Entropy: 0.52132
Value Function Loss: 0.11230

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04525
Policy Update Magnitude: 0.18001
Value Function Update Magnitude: 0.48554

Collected Steps per Second: 15,144.06917
Overall Steps per Second: 10,424.69420

Timestep Collection Time: 3.30400
Timestep Consumption Time: 1.49576
PPO Batch Consumption Time: 0.13490
Total Iteration Time: 4.79976

Cumulative Model Updates: 48,492
Cumulative Timesteps: 404,555,414

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 404555414...
Checkpoint 404555414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,643.43458
Policy Entropy: 0.51193
Value Function Loss: 0.11495

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04675
Policy Update Magnitude: 0.18007
Value Function Update Magnitude: 0.46492

Collected Steps per Second: 14,944.52613
Overall Steps per Second: 10,347.00112

Timestep Collection Time: 3.34798
Timestep Consumption Time: 1.48762
PPO Batch Consumption Time: 0.13380
Total Iteration Time: 4.83560

Cumulative Model Updates: 48,498
Cumulative Timesteps: 404,605,448

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,997.81500
Policy Entropy: 0.51567
Value Function Loss: 0.11517

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04789
Policy Update Magnitude: 0.18124
Value Function Update Magnitude: 0.46259

Collected Steps per Second: 15,059.45494
Overall Steps per Second: 10,447.03529

Timestep Collection Time: 3.32044
Timestep Consumption Time: 1.46599
PPO Batch Consumption Time: 0.13383
Total Iteration Time: 4.78643

Cumulative Model Updates: 48,504
Cumulative Timesteps: 404,655,452

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 404655452...
Checkpoint 404655452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,527.72191
Policy Entropy: 0.52260
Value Function Loss: 0.10766

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04561
Policy Update Magnitude: 0.17669
Value Function Update Magnitude: 0.43157

Collected Steps per Second: 14,913.64647
Overall Steps per Second: 10,321.25851

Timestep Collection Time: 3.35465
Timestep Consumption Time: 1.49263
PPO Batch Consumption Time: 0.13592
Total Iteration Time: 4.84728

Cumulative Model Updates: 48,510
Cumulative Timesteps: 404,705,482

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,888.15313
Policy Entropy: 0.52890
Value Function Loss: 0.11036

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.05815
Policy Update Magnitude: 0.16720
Value Function Update Magnitude: 0.40098

Collected Steps per Second: 15,237.91074
Overall Steps per Second: 10,474.30187

Timestep Collection Time: 3.28300
Timestep Consumption Time: 1.49307
PPO Batch Consumption Time: 0.13583
Total Iteration Time: 4.77607

Cumulative Model Updates: 48,516
Cumulative Timesteps: 404,755,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 404755508...
Checkpoint 404755508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,909.55558
Policy Entropy: 0.52375
Value Function Loss: 0.10696

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04733
Policy Update Magnitude: 0.17045
Value Function Update Magnitude: 0.39930

Collected Steps per Second: 15,042.33295
Overall Steps per Second: 10,402.80100

Timestep Collection Time: 3.32581
Timestep Consumption Time: 1.48328
PPO Batch Consumption Time: 0.13406
Total Iteration Time: 4.80909

Cumulative Model Updates: 48,522
Cumulative Timesteps: 404,805,536

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,488.90852
Policy Entropy: 0.52419
Value Function Loss: 0.10119

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04035
Policy Update Magnitude: 0.17617
Value Function Update Magnitude: 0.42367

Collected Steps per Second: 15,000.22929
Overall Steps per Second: 10,359.85596

Timestep Collection Time: 3.33422
Timestep Consumption Time: 1.49346
PPO Batch Consumption Time: 0.13449
Total Iteration Time: 4.82767

Cumulative Model Updates: 48,528
Cumulative Timesteps: 404,855,550

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 404855550...
Checkpoint 404855550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,281.69252
Policy Entropy: 0.51894
Value Function Loss: 0.10455

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.04462
Policy Update Magnitude: 0.17738
Value Function Update Magnitude: 0.37984

Collected Steps per Second: 14,838.45919
Overall Steps per Second: 10,278.33083

Timestep Collection Time: 3.36962
Timestep Consumption Time: 1.49498
PPO Batch Consumption Time: 0.13713
Total Iteration Time: 4.86460

Cumulative Model Updates: 48,534
Cumulative Timesteps: 404,905,550

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,464.33842
Policy Entropy: 0.51780
Value Function Loss: 0.11560

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.04521
Policy Update Magnitude: 0.17489
Value Function Update Magnitude: 0.36850

Collected Steps per Second: 14,705.22462
Overall Steps per Second: 10,437.14368

Timestep Collection Time: 3.40070
Timestep Consumption Time: 1.39065
PPO Batch Consumption Time: 0.13486
Total Iteration Time: 4.79135

Cumulative Model Updates: 48,540
Cumulative Timesteps: 404,955,558

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 404955558...
Checkpoint 404955558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,180.36904
Policy Entropy: 0.52545
Value Function Loss: 0.11001

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06071
Policy Update Magnitude: 0.17408
Value Function Update Magnitude: 0.38848

Collected Steps per Second: 14,608.25386
Overall Steps per Second: 10,363.50503

Timestep Collection Time: 3.42491
Timestep Consumption Time: 1.40280
PPO Batch Consumption Time: 0.13577
Total Iteration Time: 4.82771

Cumulative Model Updates: 48,546
Cumulative Timesteps: 405,005,590

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,704.34562
Policy Entropy: 0.51514
Value Function Loss: 0.11192

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06026
Policy Update Magnitude: 0.17190
Value Function Update Magnitude: 0.33605

Collected Steps per Second: 14,582.44183
Overall Steps per Second: 10,349.93164

Timestep Collection Time: 3.43029
Timestep Consumption Time: 1.40279
PPO Batch Consumption Time: 0.13512
Total Iteration Time: 4.83308

Cumulative Model Updates: 48,552
Cumulative Timesteps: 405,055,612

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 405055612...
Checkpoint 405055612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,793.94706
Policy Entropy: 0.51877
Value Function Loss: 0.09657

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.04678
Policy Update Magnitude: 0.17101
Value Function Update Magnitude: 0.35986

Collected Steps per Second: 14,542.82509
Overall Steps per Second: 10,310.77140

Timestep Collection Time: 3.43908
Timestep Consumption Time: 1.41157
PPO Batch Consumption Time: 0.13607
Total Iteration Time: 4.85066

Cumulative Model Updates: 48,558
Cumulative Timesteps: 405,105,626

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,556.79526
Policy Entropy: 0.51618
Value Function Loss: 0.09924

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04840
Policy Update Magnitude: 0.17082
Value Function Update Magnitude: 0.35689

Collected Steps per Second: 14,582.82998
Overall Steps per Second: 10,353.62521

Timestep Collection Time: 3.42992
Timestep Consumption Time: 1.40104
PPO Batch Consumption Time: 0.13309
Total Iteration Time: 4.83096

Cumulative Model Updates: 48,564
Cumulative Timesteps: 405,155,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 405155644...
Checkpoint 405155644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,127.61140
Policy Entropy: 0.52493
Value Function Loss: 0.09547

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07296
Policy Update Magnitude: 0.15576
Value Function Update Magnitude: 0.35672

Collected Steps per Second: 14,762.00954
Overall Steps per Second: 10,435.34117

Timestep Collection Time: 3.38734
Timestep Consumption Time: 1.40445
PPO Batch Consumption Time: 0.13502
Total Iteration Time: 4.79179

Cumulative Model Updates: 48,570
Cumulative Timesteps: 405,205,648

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,014.10160
Policy Entropy: 0.52399
Value Function Loss: 0.10799

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07579
Policy Update Magnitude: 0.16131
Value Function Update Magnitude: 0.35582

Collected Steps per Second: 14,837.96025
Overall Steps per Second: 10,497.20686

Timestep Collection Time: 3.37108
Timestep Consumption Time: 1.39399
PPO Batch Consumption Time: 0.13474
Total Iteration Time: 4.76508

Cumulative Model Updates: 48,576
Cumulative Timesteps: 405,255,668

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 405255668...
Checkpoint 405255668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,580.05756
Policy Entropy: 0.51837
Value Function Loss: 0.09886

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.08564
Policy Update Magnitude: 0.15427
Value Function Update Magnitude: 0.35881

Collected Steps per Second: 14,339.46774
Overall Steps per Second: 10,189.96435

Timestep Collection Time: 3.48841
Timestep Consumption Time: 1.42053
PPO Batch Consumption Time: 0.13694
Total Iteration Time: 4.90895

Cumulative Model Updates: 48,582
Cumulative Timesteps: 405,305,690

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,235.33198
Policy Entropy: 0.51493
Value Function Loss: 0.09458

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.06315
Policy Update Magnitude: 0.15832
Value Function Update Magnitude: 0.35494

Collected Steps per Second: 14,735.01792
Overall Steps per Second: 10,406.83400

Timestep Collection Time: 3.39382
Timestep Consumption Time: 1.41148
PPO Batch Consumption Time: 0.13549
Total Iteration Time: 4.80530

Cumulative Model Updates: 48,588
Cumulative Timesteps: 405,355,698

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 405355698...
Checkpoint 405355698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,095.42186
Policy Entropy: 0.51014
Value Function Loss: 0.09428

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07576
Policy Update Magnitude: 0.15866
Value Function Update Magnitude: 0.37135

Collected Steps per Second: 14,577.42775
Overall Steps per Second: 10,331.77074

Timestep Collection Time: 3.43051
Timestep Consumption Time: 1.40971
PPO Batch Consumption Time: 0.13619
Total Iteration Time: 4.84022

Cumulative Model Updates: 48,594
Cumulative Timesteps: 405,405,706

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,712.42739
Policy Entropy: 0.51336
Value Function Loss: 0.09730

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08172
Policy Update Magnitude: 0.15268
Value Function Update Magnitude: 0.39548

Collected Steps per Second: 14,755.00762
Overall Steps per Second: 10,366.46991

Timestep Collection Time: 3.38882
Timestep Consumption Time: 1.43462
PPO Batch Consumption Time: 0.13686
Total Iteration Time: 4.82344

Cumulative Model Updates: 48,600
Cumulative Timesteps: 405,455,708

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 405455708...
Checkpoint 405455708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,112.53132
Policy Entropy: 0.51590
Value Function Loss: 0.10162

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07520
Policy Update Magnitude: 0.15163
Value Function Update Magnitude: 0.40430

Collected Steps per Second: 14,543.19804
Overall Steps per Second: 10,261.33341

Timestep Collection Time: 3.43831
Timestep Consumption Time: 1.43474
PPO Batch Consumption Time: 0.13807
Total Iteration Time: 4.87305

Cumulative Model Updates: 48,606
Cumulative Timesteps: 405,505,712

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,006.38150
Policy Entropy: 0.51265
Value Function Loss: 0.10411

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07534
Policy Update Magnitude: 0.15840
Value Function Update Magnitude: 0.40090

Collected Steps per Second: 14,905.13221
Overall Steps per Second: 10,351.77876

Timestep Collection Time: 3.35562
Timestep Consumption Time: 1.47601
PPO Batch Consumption Time: 0.13565
Total Iteration Time: 4.83163

Cumulative Model Updates: 48,612
Cumulative Timesteps: 405,555,728

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 405555728...
Checkpoint 405555728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,815.85334
Policy Entropy: 0.51074
Value Function Loss: 0.11458

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07046
Policy Update Magnitude: 0.17175
Value Function Update Magnitude: 0.36251

Collected Steps per Second: 14,814.93939
Overall Steps per Second: 10,328.91108

Timestep Collection Time: 3.37740
Timestep Consumption Time: 1.46687
PPO Batch Consumption Time: 0.13384
Total Iteration Time: 4.84427

Cumulative Model Updates: 48,618
Cumulative Timesteps: 405,605,764

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,846.60796
Policy Entropy: 0.50780
Value Function Loss: 0.11647

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07180
Policy Update Magnitude: 0.17293
Value Function Update Magnitude: 0.41753

Collected Steps per Second: 15,172.69449
Overall Steps per Second: 10,479.52345

Timestep Collection Time: 3.29724
Timestep Consumption Time: 1.47664
PPO Batch Consumption Time: 0.13653
Total Iteration Time: 4.77388

Cumulative Model Updates: 48,624
Cumulative Timesteps: 405,655,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 405655792...
Checkpoint 405655792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,176.62724
Policy Entropy: 0.49792
Value Function Loss: 0.10793

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.06637
Policy Update Magnitude: 0.16307
Value Function Update Magnitude: 0.45067

Collected Steps per Second: 14,774.62175
Overall Steps per Second: 10,228.13735

Timestep Collection Time: 3.38621
Timestep Consumption Time: 1.50520
PPO Batch Consumption Time: 0.13576
Total Iteration Time: 4.89141

Cumulative Model Updates: 48,630
Cumulative Timesteps: 405,705,822

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,877.17992
Policy Entropy: 0.51141
Value Function Loss: 0.10380

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06199
Policy Update Magnitude: 0.17078
Value Function Update Magnitude: 0.45197

Collected Steps per Second: 15,041.08247
Overall Steps per Second: 10,443.83129

Timestep Collection Time: 3.32436
Timestep Consumption Time: 1.46334
PPO Batch Consumption Time: 0.13531
Total Iteration Time: 4.78771

Cumulative Model Updates: 48,636
Cumulative Timesteps: 405,755,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 405755824...
Checkpoint 405755824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,234.14703
Policy Entropy: 0.50666
Value Function Loss: 0.09633

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07770
Policy Update Magnitude: 0.17014
Value Function Update Magnitude: 0.42610

Collected Steps per Second: 14,899.58527
Overall Steps per Second: 10,304.00524

Timestep Collection Time: 3.35620
Timestep Consumption Time: 1.49686
PPO Batch Consumption Time: 0.13394
Total Iteration Time: 4.85306

Cumulative Model Updates: 48,642
Cumulative Timesteps: 405,805,830

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,707.42705
Policy Entropy: 0.50871
Value Function Loss: 0.11590

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07266
Policy Update Magnitude: 0.16773
Value Function Update Magnitude: 0.40658

Collected Steps per Second: 14,276.28633
Overall Steps per Second: 9,701.55650

Timestep Collection Time: 3.50371
Timestep Consumption Time: 1.65216
PPO Batch Consumption Time: 0.15846
Total Iteration Time: 5.15587

Cumulative Model Updates: 48,648
Cumulative Timesteps: 405,855,850

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 405855850...
Checkpoint 405855850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,085.87401
Policy Entropy: 0.50605
Value Function Loss: 0.11853

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07262
Policy Update Magnitude: 0.18150
Value Function Update Magnitude: 0.40971

Collected Steps per Second: 14,886.69908
Overall Steps per Second: 10,171.59351

Timestep Collection Time: 3.36166
Timestep Consumption Time: 1.55832
PPO Batch Consumption Time: 0.13740
Total Iteration Time: 4.91998

Cumulative Model Updates: 48,654
Cumulative Timesteps: 405,905,894

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,839.22209
Policy Entropy: 0.51150
Value Function Loss: 0.11971

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08074
Policy Update Magnitude: 0.18458
Value Function Update Magnitude: 0.43998

Collected Steps per Second: 15,004.04806
Overall Steps per Second: 10,374.95678

Timestep Collection Time: 3.33283
Timestep Consumption Time: 1.48704
PPO Batch Consumption Time: 0.13401
Total Iteration Time: 4.81988

Cumulative Model Updates: 48,660
Cumulative Timesteps: 405,955,900

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 405955900...
Checkpoint 405955900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,829.70023
Policy Entropy: 0.51860
Value Function Loss: 0.11525

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08058
Policy Update Magnitude: 0.17418
Value Function Update Magnitude: 0.45602

Collected Steps per Second: 14,906.61335
Overall Steps per Second: 10,372.94999

Timestep Collection Time: 3.35650
Timestep Consumption Time: 1.46701
PPO Batch Consumption Time: 0.13334
Total Iteration Time: 4.82351

Cumulative Model Updates: 48,666
Cumulative Timesteps: 406,005,934

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,754.29213
Policy Entropy: 0.52286
Value Function Loss: 0.11200

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06938
Policy Update Magnitude: 0.17913
Value Function Update Magnitude: 0.45255

Collected Steps per Second: 15,266.63578
Overall Steps per Second: 10,428.90841

Timestep Collection Time: 3.27525
Timestep Consumption Time: 1.51931
PPO Batch Consumption Time: 0.13919
Total Iteration Time: 4.79456

Cumulative Model Updates: 48,672
Cumulative Timesteps: 406,055,936

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 406055936...
Checkpoint 406055936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,859.68143
Policy Entropy: 0.51444
Value Function Loss: 0.10707

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07152
Policy Update Magnitude: 0.18119
Value Function Update Magnitude: 0.44954

Collected Steps per Second: 14,927.19754
Overall Steps per Second: 10,306.63559

Timestep Collection Time: 3.35173
Timestep Consumption Time: 1.50261
PPO Batch Consumption Time: 0.13607
Total Iteration Time: 4.85435

Cumulative Model Updates: 48,678
Cumulative Timesteps: 406,105,968

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,195.33867
Policy Entropy: 0.50892
Value Function Loss: 0.10453

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.06516
Policy Update Magnitude: 0.17040
Value Function Update Magnitude: 0.45742

Collected Steps per Second: 15,182.62143
Overall Steps per Second: 10,437.30422

Timestep Collection Time: 3.29442
Timestep Consumption Time: 1.49781
PPO Batch Consumption Time: 0.13557
Total Iteration Time: 4.79223

Cumulative Model Updates: 48,684
Cumulative Timesteps: 406,155,986

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 406155986...
Checkpoint 406155986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,987.09781
Policy Entropy: 0.51061
Value Function Loss: 0.10504

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05812
Policy Update Magnitude: 0.18276
Value Function Update Magnitude: 0.45472

Collected Steps per Second: 14,921.65876
Overall Steps per Second: 10,327.68343

Timestep Collection Time: 3.35365
Timestep Consumption Time: 1.49177
PPO Batch Consumption Time: 0.13522
Total Iteration Time: 4.84542

Cumulative Model Updates: 48,690
Cumulative Timesteps: 406,206,028

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,857.13269
Policy Entropy: 0.52352
Value Function Loss: 0.11031

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04195
Policy Update Magnitude: 0.18661
Value Function Update Magnitude: 0.42617

Collected Steps per Second: 15,069.12296
Overall Steps per Second: 10,446.43129

Timestep Collection Time: 3.31844
Timestep Consumption Time: 1.46846
PPO Batch Consumption Time: 0.13604
Total Iteration Time: 4.78690

Cumulative Model Updates: 48,696
Cumulative Timesteps: 406,256,034

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 406256034...
Checkpoint 406256034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,792.85419
Policy Entropy: 0.52380
Value Function Loss: 0.11185

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.04110
Policy Update Magnitude: 0.19069
Value Function Update Magnitude: 0.38070

Collected Steps per Second: 14,664.90249
Overall Steps per Second: 9,848.05556

Timestep Collection Time: 3.41032
Timestep Consumption Time: 1.66804
PPO Batch Consumption Time: 0.15227
Total Iteration Time: 5.07836

Cumulative Model Updates: 48,702
Cumulative Timesteps: 406,306,046

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,190.43776
Policy Entropy: 0.53063
Value Function Loss: 0.10604

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04616
Policy Update Magnitude: 0.17895
Value Function Update Magnitude: 0.34574

Collected Steps per Second: 14,428.12516
Overall Steps per Second: 10,207.93804

Timestep Collection Time: 3.46836
Timestep Consumption Time: 1.43390
PPO Batch Consumption Time: 0.13287
Total Iteration Time: 4.90226

Cumulative Model Updates: 48,708
Cumulative Timesteps: 406,356,088

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 406356088...
Checkpoint 406356088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,295.47751
Policy Entropy: 0.52495
Value Function Loss: 0.09989

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.04689
Policy Update Magnitude: 0.17209
Value Function Update Magnitude: 0.34487

Collected Steps per Second: 14,682.41799
Overall Steps per Second: 9,929.32583

Timestep Collection Time: 3.40598
Timestep Consumption Time: 1.63042
PPO Batch Consumption Time: 0.15652
Total Iteration Time: 5.03639

Cumulative Model Updates: 48,714
Cumulative Timesteps: 406,406,096

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,168.30992
Policy Entropy: 0.53500
Value Function Loss: 0.10411

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.06353
Policy Update Magnitude: 0.15831
Value Function Update Magnitude: 0.39494

Collected Steps per Second: 14,437.75728
Overall Steps per Second: 10,062.11896

Timestep Collection Time: 3.46342
Timestep Consumption Time: 1.50611
PPO Batch Consumption Time: 0.13816
Total Iteration Time: 4.96953

Cumulative Model Updates: 48,720
Cumulative Timesteps: 406,456,100

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 406456100...
Checkpoint 406456100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,014.10595
Policy Entropy: 0.53983
Value Function Loss: 0.09946

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06602
Policy Update Magnitude: 0.16365
Value Function Update Magnitude: 0.39413

Collected Steps per Second: 14,758.79643
Overall Steps per Second: 10,322.92187

Timestep Collection Time: 3.38971
Timestep Consumption Time: 1.45659
PPO Batch Consumption Time: 0.13222
Total Iteration Time: 4.84630

Cumulative Model Updates: 48,726
Cumulative Timesteps: 406,506,128

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,986.53142
Policy Entropy: 0.53853
Value Function Loss: 0.11356

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.06226
Policy Update Magnitude: 0.17384
Value Function Update Magnitude: 0.36723

Collected Steps per Second: 15,165.92128
Overall Steps per Second: 10,498.78885

Timestep Collection Time: 3.29700
Timestep Consumption Time: 1.46565
PPO Batch Consumption Time: 0.13604
Total Iteration Time: 4.76264

Cumulative Model Updates: 48,732
Cumulative Timesteps: 406,556,130

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 406556130...
Checkpoint 406556130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,030.66032
Policy Entropy: 0.53620
Value Function Loss: 0.11463

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05454
Policy Update Magnitude: 0.18062
Value Function Update Magnitude: 0.35690

Collected Steps per Second: 14,826.97161
Overall Steps per Second: 9,986.83296

Timestep Collection Time: 3.37223
Timestep Consumption Time: 1.63436
PPO Batch Consumption Time: 0.15865
Total Iteration Time: 5.00659

Cumulative Model Updates: 48,738
Cumulative Timesteps: 406,606,130

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,414.98537
Policy Entropy: 0.53084
Value Function Loss: 0.12307

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.05624
Policy Update Magnitude: 0.18346
Value Function Update Magnitude: 0.29390

Collected Steps per Second: 13,255.90421
Overall Steps per Second: 9,205.00672

Timestep Collection Time: 3.77281
Timestep Consumption Time: 1.66032
PPO Batch Consumption Time: 0.16104
Total Iteration Time: 5.43313

Cumulative Model Updates: 48,744
Cumulative Timesteps: 406,656,142

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 406656142...
Checkpoint 406656142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,960.60959
Policy Entropy: 0.53884
Value Function Loss: 0.12299

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.06914
Policy Update Magnitude: 0.17038
Value Function Update Magnitude: 0.32028

Collected Steps per Second: 14,363.15256
Overall Steps per Second: 10,149.79355

Timestep Collection Time: 3.48294
Timestep Consumption Time: 1.44583
PPO Batch Consumption Time: 0.13361
Total Iteration Time: 4.92877

Cumulative Model Updates: 48,750
Cumulative Timesteps: 406,706,168

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,032.75862
Policy Entropy: 0.53730
Value Function Loss: 0.11775

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.07562
Policy Update Magnitude: 0.16398
Value Function Update Magnitude: 0.38144

Collected Steps per Second: 14,510.82804
Overall Steps per Second: 9,698.99746

Timestep Collection Time: 3.44598
Timestep Consumption Time: 1.70961
PPO Batch Consumption Time: 0.16247
Total Iteration Time: 5.15558

Cumulative Model Updates: 48,756
Cumulative Timesteps: 406,756,172

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 406756172...
Checkpoint 406756172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,478.22792
Policy Entropy: 0.53697
Value Function Loss: 0.10935

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07323
Policy Update Magnitude: 0.15856
Value Function Update Magnitude: 0.38690

Collected Steps per Second: 13,800.53517
Overall Steps per Second: 9,435.65705

Timestep Collection Time: 3.62435
Timestep Consumption Time: 1.67660
PPO Batch Consumption Time: 0.15901
Total Iteration Time: 5.30096

Cumulative Model Updates: 48,762
Cumulative Timesteps: 406,806,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,941.14112
Policy Entropy: 0.53688
Value Function Loss: 0.10482

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07343
Policy Update Magnitude: 0.14478
Value Function Update Magnitude: 0.36093

Collected Steps per Second: 14,855.61191
Overall Steps per Second: 10,276.29527

Timestep Collection Time: 3.36694
Timestep Consumption Time: 1.50038
PPO Batch Consumption Time: 0.13660
Total Iteration Time: 4.86732

Cumulative Model Updates: 48,768
Cumulative Timesteps: 406,856,208

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 406856208...
Checkpoint 406856208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,285.18761
Policy Entropy: 0.53541
Value Function Loss: 0.10082

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07078
Policy Update Magnitude: 0.14527
Value Function Update Magnitude: 0.36080

Collected Steps per Second: 13,284.70628
Overall Steps per Second: 9,490.68635

Timestep Collection Time: 3.76704
Timestep Consumption Time: 1.50592
PPO Batch Consumption Time: 0.13331
Total Iteration Time: 5.27296

Cumulative Model Updates: 48,774
Cumulative Timesteps: 406,906,252

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,117.44138
Policy Entropy: 0.52878
Value Function Loss: 0.10872

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06247
Policy Update Magnitude: 0.15502
Value Function Update Magnitude: 0.38170

Collected Steps per Second: 13,200.72500
Overall Steps per Second: 9,551.58868

Timestep Collection Time: 3.78873
Timestep Consumption Time: 1.44747
PPO Batch Consumption Time: 0.13467
Total Iteration Time: 5.23620

Cumulative Model Updates: 48,780
Cumulative Timesteps: 406,956,266

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 406956266...
Checkpoint 406956266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,004.42556
Policy Entropy: 0.52379
Value Function Loss: 0.11831

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.05974
Policy Update Magnitude: 0.16596
Value Function Update Magnitude: 0.38077

Collected Steps per Second: 15,178.71234
Overall Steps per Second: 10,491.11066

Timestep Collection Time: 3.29540
Timestep Consumption Time: 1.47244
PPO Batch Consumption Time: 0.13566
Total Iteration Time: 4.76785

Cumulative Model Updates: 48,786
Cumulative Timesteps: 407,006,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,357.61804
Policy Entropy: 0.53643
Value Function Loss: 0.11817

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05576
Policy Update Magnitude: 0.17546
Value Function Update Magnitude: 0.44660

Collected Steps per Second: 15,365.70517
Overall Steps per Second: 10,501.47989

Timestep Collection Time: 3.25530
Timestep Consumption Time: 1.50784
PPO Batch Consumption Time: 0.14183
Total Iteration Time: 4.76314

Cumulative Model Updates: 48,792
Cumulative Timesteps: 407,056,306

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 407056306...
Checkpoint 407056306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,777.15512
Policy Entropy: 0.54055
Value Function Loss: 0.10823

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06411
Policy Update Magnitude: 0.16817
Value Function Update Magnitude: 0.49065

Collected Steps per Second: 14,873.31653
Overall Steps per Second: 10,305.84109

Timestep Collection Time: 3.36172
Timestep Consumption Time: 1.48989
PPO Batch Consumption Time: 0.13471
Total Iteration Time: 4.85162

Cumulative Model Updates: 48,798
Cumulative Timesteps: 407,106,306

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,170.19651
Policy Entropy: 0.54620
Value Function Loss: 0.09001

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06301
Policy Update Magnitude: 0.16498
Value Function Update Magnitude: 0.47033

Collected Steps per Second: 15,406.72004
Overall Steps per Second: 10,039.04018

Timestep Collection Time: 3.24638
Timestep Consumption Time: 1.73577
PPO Batch Consumption Time: 0.17020
Total Iteration Time: 4.98215

Cumulative Model Updates: 48,804
Cumulative Timesteps: 407,156,322

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 407156322...
Checkpoint 407156322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,494.15742
Policy Entropy: 0.54499
Value Function Loss: 0.08280

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05606
Policy Update Magnitude: 0.16140
Value Function Update Magnitude: 0.43621

Collected Steps per Second: 13,492.26052
Overall Steps per Second: 9,538.71661

Timestep Collection Time: 3.70746
Timestep Consumption Time: 1.53664
PPO Batch Consumption Time: 0.13520
Total Iteration Time: 5.24410

Cumulative Model Updates: 48,810
Cumulative Timesteps: 407,206,344

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,638.89396
Policy Entropy: 0.53740
Value Function Loss: 0.08315

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.04879
Policy Update Magnitude: 0.15799
Value Function Update Magnitude: 0.41854

Collected Steps per Second: 15,342.21016
Overall Steps per Second: 10,503.67879

Timestep Collection Time: 3.25950
Timestep Consumption Time: 1.50149
PPO Batch Consumption Time: 0.13319
Total Iteration Time: 4.76100

Cumulative Model Updates: 48,816
Cumulative Timesteps: 407,256,352

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 407256352...
Checkpoint 407256352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,213.46858
Policy Entropy: 0.53886
Value Function Loss: 0.09153

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04723
Policy Update Magnitude: 0.16316
Value Function Update Magnitude: 0.42309

Collected Steps per Second: 14,802.48040
Overall Steps per Second: 10,306.53533

Timestep Collection Time: 3.37808
Timestep Consumption Time: 1.47360
PPO Batch Consumption Time: 0.13653
Total Iteration Time: 4.85168

Cumulative Model Updates: 48,822
Cumulative Timesteps: 407,306,356

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,056.27562
Policy Entropy: 0.54519
Value Function Loss: 0.09595

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04737
Policy Update Magnitude: 0.16724
Value Function Update Magnitude: 0.42801

Collected Steps per Second: 13,872.94751
Overall Steps per Second: 9,764.05651

Timestep Collection Time: 3.60644
Timestep Consumption Time: 1.51766
PPO Batch Consumption Time: 0.13861
Total Iteration Time: 5.12410

Cumulative Model Updates: 48,828
Cumulative Timesteps: 407,356,388

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 407356388...
Checkpoint 407356388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,764.90974
Policy Entropy: 0.53934
Value Function Loss: 0.09879

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04460
Policy Update Magnitude: 0.17303
Value Function Update Magnitude: 0.41744

Collected Steps per Second: 14,672.13553
Overall Steps per Second: 10,198.55307

Timestep Collection Time: 3.40877
Timestep Consumption Time: 1.49525
PPO Batch Consumption Time: 0.13977
Total Iteration Time: 4.90403

Cumulative Model Updates: 48,834
Cumulative Timesteps: 407,406,402

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,892.86087
Policy Entropy: 0.53318
Value Function Loss: 0.10156

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.04234
Policy Update Magnitude: 0.17314
Value Function Update Magnitude: 0.37768

Collected Steps per Second: 13,837.02725
Overall Steps per Second: 9,640.98178

Timestep Collection Time: 3.61378
Timestep Consumption Time: 1.57283
PPO Batch Consumption Time: 0.14674
Total Iteration Time: 5.18661

Cumulative Model Updates: 48,840
Cumulative Timesteps: 407,456,406

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 407456406...
Checkpoint 407456406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,445.07823
Policy Entropy: 0.53121
Value Function Loss: 0.10684

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04840
Policy Update Magnitude: 0.17390
Value Function Update Magnitude: 0.36203

Collected Steps per Second: 14,252.55074
Overall Steps per Second: 9,923.37181

Timestep Collection Time: 3.50828
Timestep Consumption Time: 1.53053
PPO Batch Consumption Time: 0.13904
Total Iteration Time: 5.03881

Cumulative Model Updates: 48,846
Cumulative Timesteps: 407,506,408

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,890.48828
Policy Entropy: 0.53034
Value Function Loss: 0.10783

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05565
Policy Update Magnitude: 0.17750
Value Function Update Magnitude: 0.38134

Collected Steps per Second: 14,984.36307
Overall Steps per Second: 10,367.67458

Timestep Collection Time: 3.33988
Timestep Consumption Time: 1.48724
PPO Batch Consumption Time: 0.13993
Total Iteration Time: 4.82712

Cumulative Model Updates: 48,852
Cumulative Timesteps: 407,556,454

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 407556454...
Checkpoint 407556454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,020.38903
Policy Entropy: 0.53183
Value Function Loss: 0.10745

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.05236
Policy Update Magnitude: 0.18975
Value Function Update Magnitude: 0.40653

Collected Steps per Second: 14,208.87881
Overall Steps per Second: 9,922.71716

Timestep Collection Time: 3.52118
Timestep Consumption Time: 1.52099
PPO Batch Consumption Time: 0.13833
Total Iteration Time: 5.04217

Cumulative Model Updates: 48,858
Cumulative Timesteps: 407,606,486

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,182.29505
Policy Entropy: 0.53045
Value Function Loss: 0.09692

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04522
Policy Update Magnitude: 0.18517
Value Function Update Magnitude: 0.41867

Collected Steps per Second: 14,378.40422
Overall Steps per Second: 9,952.12528

Timestep Collection Time: 3.48078
Timestep Consumption Time: 1.54810
PPO Batch Consumption Time: 0.14304
Total Iteration Time: 5.02888

Cumulative Model Updates: 48,864
Cumulative Timesteps: 407,656,534

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 407656534...
Checkpoint 407656534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,179.03731
Policy Entropy: 0.54108
Value Function Loss: 0.09612

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04833
Policy Update Magnitude: 0.17747
Value Function Update Magnitude: 0.38244

Collected Steps per Second: 14,603.38626
Overall Steps per Second: 9,879.72647

Timestep Collection Time: 3.42482
Timestep Consumption Time: 1.63746
PPO Batch Consumption Time: 0.15523
Total Iteration Time: 5.06229

Cumulative Model Updates: 48,870
Cumulative Timesteps: 407,706,548

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,163.19476
Policy Entropy: 0.53780
Value Function Loss: 0.10218

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04952
Policy Update Magnitude: 0.17655
Value Function Update Magnitude: 0.36240

Collected Steps per Second: 13,772.83594
Overall Steps per Second: 9,684.24419

Timestep Collection Time: 3.63150
Timestep Consumption Time: 1.53318
PPO Batch Consumption Time: 0.13804
Total Iteration Time: 5.16468

Cumulative Model Updates: 48,876
Cumulative Timesteps: 407,756,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 407756564...
Checkpoint 407756564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,991.97206
Policy Entropy: 0.53352
Value Function Loss: 0.09438

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.05193
Policy Update Magnitude: 0.17489
Value Function Update Magnitude: 0.40517

Collected Steps per Second: 14,302.92371
Overall Steps per Second: 9,892.31329

Timestep Collection Time: 3.49817
Timestep Consumption Time: 1.55970
PPO Batch Consumption Time: 0.14295
Total Iteration Time: 5.05787

Cumulative Model Updates: 48,882
Cumulative Timesteps: 407,806,598

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,549.99995
Policy Entropy: 0.52402
Value Function Loss: 0.10363

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05321
Policy Update Magnitude: 0.16607
Value Function Update Magnitude: 0.42317

Collected Steps per Second: 14,754.92555
Overall Steps per Second: 10,143.62872

Timestep Collection Time: 3.39209
Timestep Consumption Time: 1.54204
PPO Batch Consumption Time: 0.14150
Total Iteration Time: 4.93413

Cumulative Model Updates: 48,888
Cumulative Timesteps: 407,856,648

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 407856648...
Checkpoint 407856648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,724.90620
Policy Entropy: 0.52717
Value Function Loss: 0.10609

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04541
Policy Update Magnitude: 0.16481
Value Function Update Magnitude: 0.40401

Collected Steps per Second: 14,666.26004
Overall Steps per Second: 9,902.94347

Timestep Collection Time: 3.41014
Timestep Consumption Time: 1.64028
PPO Batch Consumption Time: 0.15893
Total Iteration Time: 5.05042

Cumulative Model Updates: 48,894
Cumulative Timesteps: 407,906,662

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,283.19428
Policy Entropy: 0.53701
Value Function Loss: 0.10601

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.04208
Policy Update Magnitude: 0.17390
Value Function Update Magnitude: 0.42608

Collected Steps per Second: 13,738.46177
Overall Steps per Second: 9,615.83250

Timestep Collection Time: 3.64087
Timestep Consumption Time: 1.56096
PPO Batch Consumption Time: 0.14264
Total Iteration Time: 5.20184

Cumulative Model Updates: 48,900
Cumulative Timesteps: 407,956,682

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 407956682...
Checkpoint 407956682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,107.07846
Policy Entropy: 0.54476
Value Function Loss: 0.09499

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04468
Policy Update Magnitude: 0.17215
Value Function Update Magnitude: 0.39327

Collected Steps per Second: 14,688.50465
Overall Steps per Second: 10,261.60232

Timestep Collection Time: 3.40429
Timestep Consumption Time: 1.46863
PPO Batch Consumption Time: 0.13289
Total Iteration Time: 4.87292

Cumulative Model Updates: 48,906
Cumulative Timesteps: 408,006,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,317.12280
Policy Entropy: 0.54848
Value Function Loss: 0.08973

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04621
Policy Update Magnitude: 0.16341
Value Function Update Magnitude: 0.40676

Collected Steps per Second: 15,430.70943
Overall Steps per Second: 10,660.97286

Timestep Collection Time: 3.24340
Timestep Consumption Time: 1.45110
PPO Batch Consumption Time: 0.13255
Total Iteration Time: 4.69451

Cumulative Model Updates: 48,912
Cumulative Timesteps: 408,056,734

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 408056734...
Checkpoint 408056734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,575.06667
Policy Entropy: 0.53967
Value Function Loss: 0.09821

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.05658
Policy Update Magnitude: 0.15636
Value Function Update Magnitude: 0.42763

Collected Steps per Second: 14,826.90733
Overall Steps per Second: 10,334.57462

Timestep Collection Time: 3.37387
Timestep Consumption Time: 1.46658
PPO Batch Consumption Time: 0.13331
Total Iteration Time: 4.84045

Cumulative Model Updates: 48,918
Cumulative Timesteps: 408,106,758

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,394.27845
Policy Entropy: 0.54162
Value Function Loss: 0.08998

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07053
Policy Update Magnitude: 0.14446
Value Function Update Magnitude: 0.42656

Collected Steps per Second: 15,529.48317
Overall Steps per Second: 10,648.49632

Timestep Collection Time: 3.22136
Timestep Consumption Time: 1.47658
PPO Batch Consumption Time: 0.13127
Total Iteration Time: 4.69794

Cumulative Model Updates: 48,924
Cumulative Timesteps: 408,156,784

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 408156784...
Checkpoint 408156784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,122.31766
Policy Entropy: 0.53855
Value Function Loss: 0.09020

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05406
Policy Update Magnitude: 0.15440
Value Function Update Magnitude: 0.42050

Collected Steps per Second: 13,672.82989
Overall Steps per Second: 9,537.77220

Timestep Collection Time: 3.65777
Timestep Consumption Time: 1.58581
PPO Batch Consumption Time: 0.14665
Total Iteration Time: 5.24357

Cumulative Model Updates: 48,930
Cumulative Timesteps: 408,206,796

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,379.12064
Policy Entropy: 0.53953
Value Function Loss: 0.09572

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04621
Policy Update Magnitude: 0.16409
Value Function Update Magnitude: 0.40982

Collected Steps per Second: 14,886.56027
Overall Steps per Second: 10,271.86609

Timestep Collection Time: 3.36075
Timestep Consumption Time: 1.50984
PPO Batch Consumption Time: 0.13729
Total Iteration Time: 4.87059

Cumulative Model Updates: 48,936
Cumulative Timesteps: 408,256,826

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 408256826...
Checkpoint 408256826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,160.18241
Policy Entropy: 0.53828
Value Function Loss: 0.09502

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.04195
Policy Update Magnitude: 0.17117
Value Function Update Magnitude: 0.43585

Collected Steps per Second: 14,162.30325
Overall Steps per Second: 9,833.66863

Timestep Collection Time: 3.53205
Timestep Consumption Time: 1.55476
PPO Batch Consumption Time: 0.13817
Total Iteration Time: 5.08681

Cumulative Model Updates: 48,942
Cumulative Timesteps: 408,306,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,151.21037
Policy Entropy: 0.53571
Value Function Loss: 0.10377

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04407
Policy Update Magnitude: 0.17685
Value Function Update Magnitude: 0.45233

Collected Steps per Second: 14,979.44479
Overall Steps per Second: 10,226.88665

Timestep Collection Time: 3.34098
Timestep Consumption Time: 1.55259
PPO Batch Consumption Time: 0.14759
Total Iteration Time: 4.89357

Cumulative Model Updates: 48,948
Cumulative Timesteps: 408,356,894

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 408356894...
Checkpoint 408356894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,171.68947
Policy Entropy: 0.53542
Value Function Loss: 0.09253

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03773
Policy Update Magnitude: 0.16830
Value Function Update Magnitude: 0.45742

Collected Steps per Second: 14,972.75625
Overall Steps per Second: 10,101.59558

Timestep Collection Time: 3.34060
Timestep Consumption Time: 1.61089
PPO Batch Consumption Time: 0.14860
Total Iteration Time: 4.95150

Cumulative Model Updates: 48,954
Cumulative Timesteps: 408,406,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,915.60230
Policy Entropy: 0.52914
Value Function Loss: 0.10042

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03686
Policy Update Magnitude: 0.17258
Value Function Update Magnitude: 0.43981

Collected Steps per Second: 13,592.25781
Overall Steps per Second: 9,559.67507

Timestep Collection Time: 3.67989
Timestep Consumption Time: 1.55230
PPO Batch Consumption Time: 0.13814
Total Iteration Time: 5.23219

Cumulative Model Updates: 48,960
Cumulative Timesteps: 408,456,930

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 408456930...
Checkpoint 408456930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,330.49131
Policy Entropy: 0.53287
Value Function Loss: 0.09989

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.04278
Policy Update Magnitude: 0.17301
Value Function Update Magnitude: 0.39809

Collected Steps per Second: 14,979.57818
Overall Steps per Second: 10,326.26314

Timestep Collection Time: 3.33961
Timestep Consumption Time: 1.50493
PPO Batch Consumption Time: 0.13875
Total Iteration Time: 4.84454

Cumulative Model Updates: 48,966
Cumulative Timesteps: 408,506,956

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,218.45477
Policy Entropy: 0.53931
Value Function Loss: 0.10857

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05216
Policy Update Magnitude: 0.17859
Value Function Update Magnitude: 0.36656

Collected Steps per Second: 15,125.60927
Overall Steps per Second: 10,419.07716

Timestep Collection Time: 3.30684
Timestep Consumption Time: 1.49378
PPO Batch Consumption Time: 0.13485
Total Iteration Time: 4.80062

Cumulative Model Updates: 48,972
Cumulative Timesteps: 408,556,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 408556974...
Checkpoint 408556974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,395.45105
Policy Entropy: 0.53694
Value Function Loss: 0.11022

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04894
Policy Update Magnitude: 0.17790
Value Function Update Magnitude: 0.36157

Collected Steps per Second: 14,044.86886
Overall Steps per Second: 9,836.28004

Timestep Collection Time: 3.56002
Timestep Consumption Time: 1.52320
PPO Batch Consumption Time: 0.14009
Total Iteration Time: 5.08322

Cumulative Model Updates: 48,978
Cumulative Timesteps: 408,606,974

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,110.98525
Policy Entropy: 0.53059
Value Function Loss: 0.10276

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04119
Policy Update Magnitude: 0.18083
Value Function Update Magnitude: 0.37462

Collected Steps per Second: 14,809.36012
Overall Steps per Second: 10,248.46568

Timestep Collection Time: 3.37840
Timestep Consumption Time: 1.50350
PPO Batch Consumption Time: 0.14129
Total Iteration Time: 4.88190

Cumulative Model Updates: 48,984
Cumulative Timesteps: 408,657,006

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 408657006...
Checkpoint 408657006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,681.64352
Policy Entropy: 0.52980
Value Function Loss: 0.09552

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05440
Policy Update Magnitude: 0.17118
Value Function Update Magnitude: 0.40211

Collected Steps per Second: 14,723.22986
Overall Steps per Second: 10,118.78588

Timestep Collection Time: 3.39708
Timestep Consumption Time: 1.54580
PPO Batch Consumption Time: 0.13974
Total Iteration Time: 4.94289

Cumulative Model Updates: 48,990
Cumulative Timesteps: 408,707,022

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,518.16492
Policy Entropy: 0.53325
Value Function Loss: 0.09627

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.05155
Policy Update Magnitude: 0.16831
Value Function Update Magnitude: 0.39676

Collected Steps per Second: 14,294.51986
Overall Steps per Second: 9,800.71360

Timestep Collection Time: 3.49924
Timestep Consumption Time: 1.60447
PPO Batch Consumption Time: 0.13998
Total Iteration Time: 5.10371

Cumulative Model Updates: 48,996
Cumulative Timesteps: 408,757,042

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 408757042...
Checkpoint 408757042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,031.53756
Policy Entropy: 0.53074
Value Function Loss: 0.10318

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.05347
Policy Update Magnitude: 0.16567
Value Function Update Magnitude: 0.35802

Collected Steps per Second: 13,573.64177
Overall Steps per Second: 9,730.78587

Timestep Collection Time: 3.68656
Timestep Consumption Time: 1.45589
PPO Batch Consumption Time: 0.13384
Total Iteration Time: 5.14244

Cumulative Model Updates: 49,002
Cumulative Timesteps: 408,807,082

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,136.04438
Policy Entropy: 0.52581
Value Function Loss: 0.11092

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04866
Policy Update Magnitude: 0.16477
Value Function Update Magnitude: 0.33541

Collected Steps per Second: 14,755.84534
Overall Steps per Second: 9,990.72301

Timestep Collection Time: 3.39133
Timestep Consumption Time: 1.61751
PPO Batch Consumption Time: 0.15131
Total Iteration Time: 5.00885

Cumulative Model Updates: 49,008
Cumulative Timesteps: 408,857,124

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 408857124...
Checkpoint 408857124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,312.22636
Policy Entropy: 0.51432
Value Function Loss: 0.11786

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04827
Policy Update Magnitude: 0.16450
Value Function Update Magnitude: 0.28096

Collected Steps per Second: 14,313.54129
Overall Steps per Second: 10,063.51161

Timestep Collection Time: 3.49501
Timestep Consumption Time: 1.47602
PPO Batch Consumption Time: 0.13788
Total Iteration Time: 4.97103

Cumulative Model Updates: 49,014
Cumulative Timesteps: 408,907,150

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,642.07659
Policy Entropy: 0.51742
Value Function Loss: 0.11607

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04427
Policy Update Magnitude: 0.16860
Value Function Update Magnitude: 0.23534

Collected Steps per Second: 12,897.29828
Overall Steps per Second: 9,138.01985

Timestep Collection Time: 3.87694
Timestep Consumption Time: 1.59493
PPO Batch Consumption Time: 0.14593
Total Iteration Time: 5.47186

Cumulative Model Updates: 49,020
Cumulative Timesteps: 408,957,152

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 408957152...
Checkpoint 408957152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,606.46870
Policy Entropy: 0.52227
Value Function Loss: 0.11787

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04435
Policy Update Magnitude: 0.17132
Value Function Update Magnitude: 0.23293

Collected Steps per Second: 14,878.11117
Overall Steps per Second: 10,352.66267

Timestep Collection Time: 3.36145
Timestep Consumption Time: 1.46939
PPO Batch Consumption Time: 0.13657
Total Iteration Time: 4.83083

Cumulative Model Updates: 49,026
Cumulative Timesteps: 409,007,164

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,548.91411
Policy Entropy: 0.52751
Value Function Loss: 0.11028

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.04273
Policy Update Magnitude: 0.16816
Value Function Update Magnitude: 0.30022

Collected Steps per Second: 15,116.81614
Overall Steps per Second: 10,507.92890

Timestep Collection Time: 3.30797
Timestep Consumption Time: 1.45091
PPO Batch Consumption Time: 0.13624
Total Iteration Time: 4.75888

Cumulative Model Updates: 49,032
Cumulative Timesteps: 409,057,170

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 409057170...
Checkpoint 409057170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,533.84476
Policy Entropy: 0.52594
Value Function Loss: 0.11333

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05414
Policy Update Magnitude: 0.17511
Value Function Update Magnitude: 0.38305

Collected Steps per Second: 14,162.34920
Overall Steps per Second: 9,804.63570

Timestep Collection Time: 3.53176
Timestep Consumption Time: 1.56971
PPO Batch Consumption Time: 0.14413
Total Iteration Time: 5.10146

Cumulative Model Updates: 49,038
Cumulative Timesteps: 409,107,188

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,792.64307
Policy Entropy: 0.51718
Value Function Loss: 0.11376

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.06934
Policy Update Magnitude: 0.15830
Value Function Update Magnitude: 0.42692

Collected Steps per Second: 14,911.52687
Overall Steps per Second: 10,199.75454

Timestep Collection Time: 3.35432
Timestep Consumption Time: 1.54953
PPO Batch Consumption Time: 0.13569
Total Iteration Time: 4.90384

Cumulative Model Updates: 49,044
Cumulative Timesteps: 409,157,206

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 409157206...
Checkpoint 409157206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,504.35906
Policy Entropy: 0.52159
Value Function Loss: 0.11572

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.08377
Policy Update Magnitude: 0.16047
Value Function Update Magnitude: 0.45256

Collected Steps per Second: 14,316.68109
Overall Steps per Second: 9,924.88688

Timestep Collection Time: 3.49453
Timestep Consumption Time: 1.54634
PPO Batch Consumption Time: 0.14720
Total Iteration Time: 5.04086

Cumulative Model Updates: 49,050
Cumulative Timesteps: 409,207,236

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,363.11135
Policy Entropy: 0.52350
Value Function Loss: 0.11285

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07534
Policy Update Magnitude: 0.14684
Value Function Update Magnitude: 0.42782

Collected Steps per Second: 14,973.32243
Overall Steps per Second: 10,328.35345

Timestep Collection Time: 3.33994
Timestep Consumption Time: 1.50207
PPO Batch Consumption Time: 0.13779
Total Iteration Time: 4.84201

Cumulative Model Updates: 49,056
Cumulative Timesteps: 409,257,246

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 409257246...
Checkpoint 409257246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,922.77269
Policy Entropy: 0.51958
Value Function Loss: 0.11172

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06917
Policy Update Magnitude: 0.14652
Value Function Update Magnitude: 0.39153

Collected Steps per Second: 14,805.12689
Overall Steps per Second: 10,141.25534

Timestep Collection Time: 3.37923
Timestep Consumption Time: 1.55408
PPO Batch Consumption Time: 0.13991
Total Iteration Time: 4.93331

Cumulative Model Updates: 49,062
Cumulative Timesteps: 409,307,276

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,454.72656
Policy Entropy: 0.51423
Value Function Loss: 0.11227

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.06514
Policy Update Magnitude: 0.14991
Value Function Update Magnitude: 0.41758

Collected Steps per Second: 15,006.93408
Overall Steps per Second: 10,167.13746

Timestep Collection Time: 3.33339
Timestep Consumption Time: 1.58677
PPO Batch Consumption Time: 0.14596
Total Iteration Time: 4.92017

Cumulative Model Updates: 49,068
Cumulative Timesteps: 409,357,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 409357300...
Checkpoint 409357300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,377.81993
Policy Entropy: 0.51411
Value Function Loss: 0.10784

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06466
Policy Update Magnitude: 0.15312
Value Function Update Magnitude: 0.41918

Collected Steps per Second: 15,027.31966
Overall Steps per Second: 10,212.38807

Timestep Collection Time: 3.32927
Timestep Consumption Time: 1.56968
PPO Batch Consumption Time: 0.14342
Total Iteration Time: 4.89895

Cumulative Model Updates: 49,074
Cumulative Timesteps: 409,407,330

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,625.37093
Policy Entropy: 0.51806
Value Function Loss: 0.10575

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.05937
Policy Update Magnitude: 0.16042
Value Function Update Magnitude: 0.40569

Collected Steps per Second: 15,293.22683
Overall Steps per Second: 10,383.15309

Timestep Collection Time: 3.26942
Timestep Consumption Time: 1.54607
PPO Batch Consumption Time: 0.14368
Total Iteration Time: 4.81549

Cumulative Model Updates: 49,080
Cumulative Timesteps: 409,457,330

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 409457330...
Checkpoint 409457330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,143.77233
Policy Entropy: 0.53269
Value Function Loss: 0.09103

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.05523
Policy Update Magnitude: 0.15552
Value Function Update Magnitude: 0.37081

Collected Steps per Second: 14,263.58666
Overall Steps per Second: 9,964.67734

Timestep Collection Time: 3.50641
Timestep Consumption Time: 1.51272
PPO Batch Consumption Time: 0.13847
Total Iteration Time: 5.01913

Cumulative Model Updates: 49,086
Cumulative Timesteps: 409,507,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,583.33057
Policy Entropy: 0.52651
Value Function Loss: 0.09982

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.05146
Policy Update Magnitude: 0.16064
Value Function Update Magnitude: 0.35309

Collected Steps per Second: 15,185.67239
Overall Steps per Second: 10,505.21298

Timestep Collection Time: 3.29310
Timestep Consumption Time: 1.46720
PPO Batch Consumption Time: 0.13662
Total Iteration Time: 4.76030

Cumulative Model Updates: 49,092
Cumulative Timesteps: 409,557,352

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 409557352...
Checkpoint 409557352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,565.42144
Policy Entropy: 0.52658
Value Function Loss: 0.09146

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.04031
Policy Update Magnitude: 0.16597
Value Function Update Magnitude: 0.34071

Collected Steps per Second: 14,783.55688
Overall Steps per Second: 10,160.16806

Timestep Collection Time: 3.38403
Timestep Consumption Time: 1.53990
PPO Batch Consumption Time: 0.14449
Total Iteration Time: 4.92393

Cumulative Model Updates: 49,098
Cumulative Timesteps: 409,607,380

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,880.68939
Policy Entropy: 0.51179
Value Function Loss: 0.09630

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04349
Policy Update Magnitude: 0.16301
Value Function Update Magnitude: 0.30164

Collected Steps per Second: 14,783.36706
Overall Steps per Second: 10,147.18097

Timestep Collection Time: 3.38461
Timestep Consumption Time: 1.54641
PPO Batch Consumption Time: 0.13923
Total Iteration Time: 4.93102

Cumulative Model Updates: 49,104
Cumulative Timesteps: 409,657,416

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 409657416...
Checkpoint 409657416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,676.27532
Policy Entropy: 0.51933
Value Function Loss: 0.10487

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03405
Policy Update Magnitude: 0.16558
Value Function Update Magnitude: 0.30173

Collected Steps per Second: 15,178.62750
Overall Steps per Second: 10,410.79073

Timestep Collection Time: 3.29476
Timestep Consumption Time: 1.50891
PPO Batch Consumption Time: 0.13735
Total Iteration Time: 4.80367

Cumulative Model Updates: 49,110
Cumulative Timesteps: 409,707,426

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,060.32510
Policy Entropy: 0.52170
Value Function Loss: 0.10105

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03913
Policy Update Magnitude: 0.16716
Value Function Update Magnitude: 0.31872

Collected Steps per Second: 14,795.75898
Overall Steps per Second: 9,903.02547

Timestep Collection Time: 3.38219
Timestep Consumption Time: 1.67102
PPO Batch Consumption Time: 0.16350
Total Iteration Time: 5.05320

Cumulative Model Updates: 49,116
Cumulative Timesteps: 409,757,468

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 409757468...
Checkpoint 409757468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,619.80616
Policy Entropy: 0.51971
Value Function Loss: 0.09679

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03962
Policy Update Magnitude: 0.16817
Value Function Update Magnitude: 0.32958

Collected Steps per Second: 15,150.61693
Overall Steps per Second: 10,363.20598

Timestep Collection Time: 3.30112
Timestep Consumption Time: 1.52499
PPO Batch Consumption Time: 0.14211
Total Iteration Time: 4.82611

Cumulative Model Updates: 49,122
Cumulative Timesteps: 409,807,482

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,267.81796
Policy Entropy: 0.51919
Value Function Loss: 0.08809

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03710
Policy Update Magnitude: 0.16700
Value Function Update Magnitude: 0.36141

Collected Steps per Second: 14,714.89905
Overall Steps per Second: 10,120.57040

Timestep Collection Time: 3.40104
Timestep Consumption Time: 1.54394
PPO Batch Consumption Time: 0.14192
Total Iteration Time: 4.94498

Cumulative Model Updates: 49,128
Cumulative Timesteps: 409,857,528

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 409857528...
Checkpoint 409857528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,276.45113
Policy Entropy: 0.51959
Value Function Loss: 0.08978

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04533
Policy Update Magnitude: 0.16213
Value Function Update Magnitude: 0.37724

Collected Steps per Second: 15,078.48738
Overall Steps per Second: 10,424.93938

Timestep Collection Time: 3.31638
Timestep Consumption Time: 1.48039
PPO Batch Consumption Time: 0.13632
Total Iteration Time: 4.79677

Cumulative Model Updates: 49,134
Cumulative Timesteps: 409,907,534

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,892.48738
Policy Entropy: 0.52255
Value Function Loss: 0.09507

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03705
Policy Update Magnitude: 0.16255
Value Function Update Magnitude: 0.38054

Collected Steps per Second: 14,961.38143
Overall Steps per Second: 10,253.23720

Timestep Collection Time: 3.34247
Timestep Consumption Time: 1.53482
PPO Batch Consumption Time: 0.14289
Total Iteration Time: 4.87729

Cumulative Model Updates: 49,140
Cumulative Timesteps: 409,957,542

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 409957542...
Checkpoint 409957542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,912.60288
Policy Entropy: 0.53546
Value Function Loss: 0.09966

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03714
Policy Update Magnitude: 0.16753
Value Function Update Magnitude: 0.34335

Collected Steps per Second: 15,304.57697
Overall Steps per Second: 10,520.99791

Timestep Collection Time: 3.26726
Timestep Consumption Time: 1.48552
PPO Batch Consumption Time: 0.13791
Total Iteration Time: 4.75278

Cumulative Model Updates: 49,146
Cumulative Timesteps: 410,007,546

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,360.99988
Policy Entropy: 0.54026
Value Function Loss: 0.09251

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04287
Policy Update Magnitude: 0.16558
Value Function Update Magnitude: 0.35704

Collected Steps per Second: 15,121.46445
Overall Steps per Second: 10,310.41784

Timestep Collection Time: 3.30709
Timestep Consumption Time: 1.54315
PPO Batch Consumption Time: 0.14084
Total Iteration Time: 4.85024

Cumulative Model Updates: 49,152
Cumulative Timesteps: 410,057,554

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 410057554...
Checkpoint 410057554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,663.98620
Policy Entropy: 0.54416
Value Function Loss: 0.09360

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04160
Policy Update Magnitude: 0.16562
Value Function Update Magnitude: 0.37948

Collected Steps per Second: 15,130.88414
Overall Steps per Second: 10,431.13030

Timestep Collection Time: 3.30490
Timestep Consumption Time: 1.48902
PPO Batch Consumption Time: 0.13614
Total Iteration Time: 4.79392

Cumulative Model Updates: 49,158
Cumulative Timesteps: 410,107,560

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,783.89701
Policy Entropy: 0.54324
Value Function Loss: 0.09084

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.04272
Policy Update Magnitude: 0.16818
Value Function Update Magnitude: 0.38604

Collected Steps per Second: 15,046.38445
Overall Steps per Second: 10,318.95809

Timestep Collection Time: 3.32572
Timestep Consumption Time: 1.52361
PPO Batch Consumption Time: 0.14216
Total Iteration Time: 4.84933

Cumulative Model Updates: 49,164
Cumulative Timesteps: 410,157,600

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 410157600...
Checkpoint 410157600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,333.70936
Policy Entropy: 0.54714
Value Function Loss: 0.09569

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05439
Policy Update Magnitude: 0.16426
Value Function Update Magnitude: 0.40770

Collected Steps per Second: 14,828.07045
Overall Steps per Second: 10,273.57060

Timestep Collection Time: 3.37198
Timestep Consumption Time: 1.49487
PPO Batch Consumption Time: 0.13789
Total Iteration Time: 4.86686

Cumulative Model Updates: 49,170
Cumulative Timesteps: 410,207,600

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,969.95859
Policy Entropy: 0.53767
Value Function Loss: 0.09199

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.06778
Policy Update Magnitude: 0.15137
Value Function Update Magnitude: 0.41843

Collected Steps per Second: 14,958.97807
Overall Steps per Second: 10,227.13354

Timestep Collection Time: 3.34448
Timestep Consumption Time: 1.54741
PPO Batch Consumption Time: 0.14203
Total Iteration Time: 4.89189

Cumulative Model Updates: 49,176
Cumulative Timesteps: 410,257,630

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 410257630...
Checkpoint 410257630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,062.48264
Policy Entropy: 0.53771
Value Function Loss: 0.08325

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07593
Policy Update Magnitude: 0.14959
Value Function Update Magnitude: 0.42337

Collected Steps per Second: 14,859.80674
Overall Steps per Second: 10,325.95973

Timestep Collection Time: 3.36801
Timestep Consumption Time: 1.47880
PPO Batch Consumption Time: 0.13465
Total Iteration Time: 4.84681

Cumulative Model Updates: 49,182
Cumulative Timesteps: 410,307,678

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,032.04204
Policy Entropy: 0.54335
Value Function Loss: 0.08245

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08059
Policy Update Magnitude: 0.13470
Value Function Update Magnitude: 0.41178

Collected Steps per Second: 14,838.25094
Overall Steps per Second: 10,228.02503

Timestep Collection Time: 3.37263
Timestep Consumption Time: 1.52020
PPO Batch Consumption Time: 0.13916
Total Iteration Time: 4.89283

Cumulative Model Updates: 49,188
Cumulative Timesteps: 410,357,722

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 410357722...
Checkpoint 410357722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,812.04559
Policy Entropy: 0.54381
Value Function Loss: 0.09252

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.06572
Policy Update Magnitude: 0.15174
Value Function Update Magnitude: 0.41566

Collected Steps per Second: 14,435.00965
Overall Steps per Second: 10,080.40113

Timestep Collection Time: 3.46449
Timestep Consumption Time: 1.49662
PPO Batch Consumption Time: 0.13505
Total Iteration Time: 4.96111

Cumulative Model Updates: 49,194
Cumulative Timesteps: 410,407,732

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,822.70379
Policy Entropy: 0.53960
Value Function Loss: 0.09106

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06283
Policy Update Magnitude: 0.16745
Value Function Update Magnitude: 0.42998

Collected Steps per Second: 15,359.66331
Overall Steps per Second: 10,329.13548

Timestep Collection Time: 3.25541
Timestep Consumption Time: 1.58546
PPO Batch Consumption Time: 0.14611
Total Iteration Time: 4.84087

Cumulative Model Updates: 49,200
Cumulative Timesteps: 410,457,734

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 410457734...
Checkpoint 410457734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,659.24759
Policy Entropy: 0.52682
Value Function Loss: 0.10346

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06279
Policy Update Magnitude: 0.16110
Value Function Update Magnitude: 0.42437

Collected Steps per Second: 14,851.61393
Overall Steps per Second: 10,283.79363

Timestep Collection Time: 3.36731
Timestep Consumption Time: 1.49568
PPO Batch Consumption Time: 0.13648
Total Iteration Time: 4.86299

Cumulative Model Updates: 49,206
Cumulative Timesteps: 410,507,744

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,819.06905
Policy Entropy: 0.51660
Value Function Loss: 0.10351

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07334
Policy Update Magnitude: 0.15732
Value Function Update Magnitude: 0.42962

Collected Steps per Second: 15,078.27663
Overall Steps per Second: 10,270.70214

Timestep Collection Time: 3.31722
Timestep Consumption Time: 1.55275
PPO Batch Consumption Time: 0.14378
Total Iteration Time: 4.86997

Cumulative Model Updates: 49,212
Cumulative Timesteps: 410,557,762

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 410557762...
Checkpoint 410557762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,056.34785
Policy Entropy: 0.51944
Value Function Loss: 0.10585

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07591
Policy Update Magnitude: 0.15416
Value Function Update Magnitude: 0.41518

Collected Steps per Second: 14,339.57195
Overall Steps per Second: 10,055.36846

Timestep Collection Time: 3.48811
Timestep Consumption Time: 1.48615
PPO Batch Consumption Time: 0.13513
Total Iteration Time: 4.97426

Cumulative Model Updates: 49,218
Cumulative Timesteps: 410,607,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,073.40718
Policy Entropy: 0.52555
Value Function Loss: 0.10470

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.06339
Policy Update Magnitude: 0.15208
Value Function Update Magnitude: 0.38783

Collected Steps per Second: 15,157.50011
Overall Steps per Second: 10,466.35565

Timestep Collection Time: 3.30120
Timestep Consumption Time: 1.47964
PPO Batch Consumption Time: 0.13766
Total Iteration Time: 4.78084

Cumulative Model Updates: 49,224
Cumulative Timesteps: 410,657,818

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 410657818...
Checkpoint 410657818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,313.53218
Policy Entropy: 0.53267
Value Function Loss: 0.10977

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.05680
Policy Update Magnitude: 0.16703
Value Function Update Magnitude: 0.33335

Collected Steps per Second: 14,777.91151
Overall Steps per Second: 10,259.37282

Timestep Collection Time: 3.38478
Timestep Consumption Time: 1.49076
PPO Batch Consumption Time: 0.14116
Total Iteration Time: 4.87554

Cumulative Model Updates: 49,230
Cumulative Timesteps: 410,707,838

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,202.25492
Policy Entropy: 0.53265
Value Function Loss: 0.10874

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04500
Policy Update Magnitude: 0.17622
Value Function Update Magnitude: 0.35573

Collected Steps per Second: 15,316.45316
Overall Steps per Second: 10,404.77690

Timestep Collection Time: 3.26538
Timestep Consumption Time: 1.54145
PPO Batch Consumption Time: 0.14104
Total Iteration Time: 4.80683

Cumulative Model Updates: 49,236
Cumulative Timesteps: 410,757,852

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 410757852...
Checkpoint 410757852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,319.80713
Policy Entropy: 0.53470
Value Function Loss: 0.10015

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.05625
Policy Update Magnitude: 0.17227
Value Function Update Magnitude: 0.33679

Collected Steps per Second: 14,355.58146
Overall Steps per Second: 10,049.84717

Timestep Collection Time: 3.48408
Timestep Consumption Time: 1.49271
PPO Batch Consumption Time: 0.13733
Total Iteration Time: 4.97679

Cumulative Model Updates: 49,242
Cumulative Timesteps: 410,807,868

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,866.34040
Policy Entropy: 0.53022
Value Function Loss: 0.11662

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.06939
Policy Update Magnitude: 0.15719
Value Function Update Magnitude: 0.30501

Collected Steps per Second: 15,471.96003
Overall Steps per Second: 10,528.28262

Timestep Collection Time: 3.23359
Timestep Consumption Time: 1.51837
PPO Batch Consumption Time: 0.14146
Total Iteration Time: 4.75196

Cumulative Model Updates: 49,248
Cumulative Timesteps: 410,857,898

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 410857898...
Checkpoint 410857898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,671.59186
Policy Entropy: 0.53598
Value Function Loss: 0.12574

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05578
Policy Update Magnitude: 0.17093
Value Function Update Magnitude: 0.27268

Collected Steps per Second: 14,765.07789
Overall Steps per Second: 10,316.88872

Timestep Collection Time: 3.38745
Timestep Consumption Time: 1.46052
PPO Batch Consumption Time: 0.13695
Total Iteration Time: 4.84797

Cumulative Model Updates: 49,254
Cumulative Timesteps: 410,907,914

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,369.70486
Policy Entropy: 0.53746
Value Function Loss: 0.11792

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.06728
Policy Update Magnitude: 0.17971
Value Function Update Magnitude: 0.27596

Collected Steps per Second: 15,407.27498
Overall Steps per Second: 10,427.43125

Timestep Collection Time: 3.24522
Timestep Consumption Time: 1.54982
PPO Batch Consumption Time: 0.14282
Total Iteration Time: 4.79504

Cumulative Model Updates: 49,260
Cumulative Timesteps: 410,957,914

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 410957914...
Checkpoint 410957914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,377.74663
Policy Entropy: 0.53951
Value Function Loss: 0.10779

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07389
Policy Update Magnitude: 0.16011
Value Function Update Magnitude: 0.36927

Collected Steps per Second: 14,671.57139
Overall Steps per Second: 10,251.62422

Timestep Collection Time: 3.40836
Timestep Consumption Time: 1.46950
PPO Batch Consumption Time: 0.13829
Total Iteration Time: 4.87786

Cumulative Model Updates: 49,266
Cumulative Timesteps: 411,007,920

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,209.81168
Policy Entropy: 0.54193
Value Function Loss: 0.09883

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.06345
Policy Update Magnitude: 0.14616
Value Function Update Magnitude: 0.40475

Collected Steps per Second: 15,347.15440
Overall Steps per Second: 10,424.15168

Timestep Collection Time: 3.26132
Timestep Consumption Time: 1.54022
PPO Batch Consumption Time: 0.14268
Total Iteration Time: 4.80154

Cumulative Model Updates: 49,272
Cumulative Timesteps: 411,057,972

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 411057972...
Checkpoint 411057972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,552.96048
Policy Entropy: 0.54258
Value Function Loss: 0.10958

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.04264
Policy Update Magnitude: 0.16156
Value Function Update Magnitude: 0.41034

Collected Steps per Second: 14,535.20605
Overall Steps per Second: 10,048.28824

Timestep Collection Time: 3.44061
Timestep Consumption Time: 1.53636
PPO Batch Consumption Time: 0.13846
Total Iteration Time: 4.97697

Cumulative Model Updates: 49,278
Cumulative Timesteps: 411,107,982

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,505.29707
Policy Entropy: 0.54214
Value Function Loss: 0.09682

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.05052
Policy Update Magnitude: 0.16812
Value Function Update Magnitude: 0.38724

Collected Steps per Second: 15,159.77891
Overall Steps per Second: 10,498.53410

Timestep Collection Time: 3.29992
Timestep Consumption Time: 1.46513
PPO Batch Consumption Time: 0.13711
Total Iteration Time: 4.76505

Cumulative Model Updates: 49,284
Cumulative Timesteps: 411,158,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 411158008...
Checkpoint 411158008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,697.74641
Policy Entropy: 0.54329
Value Function Loss: 0.09184

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04229
Policy Update Magnitude: 0.16858
Value Function Update Magnitude: 0.39892

Collected Steps per Second: 14,547.12552
Overall Steps per Second: 10,024.45212

Timestep Collection Time: 3.43752
Timestep Consumption Time: 1.55088
PPO Batch Consumption Time: 0.13980
Total Iteration Time: 4.98840

Cumulative Model Updates: 49,290
Cumulative Timesteps: 411,208,014

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,322.74851
Policy Entropy: 0.54633
Value Function Loss: 0.10493

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03934
Policy Update Magnitude: 0.16768
Value Function Update Magnitude: 0.42845

Collected Steps per Second: 15,392.39660
Overall Steps per Second: 10,599.50116

Timestep Collection Time: 3.25083
Timestep Consumption Time: 1.46996
PPO Batch Consumption Time: 0.13849
Total Iteration Time: 4.72079

Cumulative Model Updates: 49,296
Cumulative Timesteps: 411,258,052

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 411258052...
Checkpoint 411258052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,409.32541
Policy Entropy: 0.54307
Value Function Loss: 0.10673

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04550
Policy Update Magnitude: 0.17320
Value Function Update Magnitude: 0.46466

Collected Steps per Second: 14,496.68832
Overall Steps per Second: 10,070.08024

Timestep Collection Time: 3.45017
Timestep Consumption Time: 1.51663
PPO Batch Consumption Time: 0.13821
Total Iteration Time: 4.96679

Cumulative Model Updates: 49,302
Cumulative Timesteps: 411,308,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,368.21060
Policy Entropy: 0.54205
Value Function Loss: 0.10925

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05494
Policy Update Magnitude: 0.17515
Value Function Update Magnitude: 0.46239

Collected Steps per Second: 15,301.84519
Overall Steps per Second: 10,465.89603

Timestep Collection Time: 3.26823
Timestep Consumption Time: 1.51014
PPO Batch Consumption Time: 0.13892
Total Iteration Time: 4.77838

Cumulative Model Updates: 49,308
Cumulative Timesteps: 411,358,078

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 411358078...
Checkpoint 411358078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,896.04528
Policy Entropy: 0.53984
Value Function Loss: 0.09807

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.06118
Policy Update Magnitude: 0.16134
Value Function Update Magnitude: 0.42326

Collected Steps per Second: 14,830.38174
Overall Steps per Second: 10,076.45381

Timestep Collection Time: 3.37173
Timestep Consumption Time: 1.59073
PPO Batch Consumption Time: 0.15473
Total Iteration Time: 4.96246

Cumulative Model Updates: 49,314
Cumulative Timesteps: 411,408,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,346.35446
Policy Entropy: 0.54317
Value Function Loss: 0.09842

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06603
Policy Update Magnitude: 0.15503
Value Function Update Magnitude: 0.38867

Collected Steps per Second: 15,253.64011
Overall Steps per Second: 10,550.47858

Timestep Collection Time: 3.27869
Timestep Consumption Time: 1.46157
PPO Batch Consumption Time: 0.13700
Total Iteration Time: 4.74026

Cumulative Model Updates: 49,320
Cumulative Timesteps: 411,458,094

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 411458094...
Checkpoint 411458094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,029.15511
Policy Entropy: 0.53296
Value Function Loss: 0.10240

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06596
Policy Update Magnitude: 0.15762
Value Function Update Magnitude: 0.41552

Collected Steps per Second: 14,788.27687
Overall Steps per Second: 10,272.84704

Timestep Collection Time: 3.38322
Timestep Consumption Time: 1.48709
PPO Batch Consumption Time: 0.13883
Total Iteration Time: 4.87031

Cumulative Model Updates: 49,326
Cumulative Timesteps: 411,508,126

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,908.71624
Policy Entropy: 0.54177
Value Function Loss: 0.10639

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07122
Policy Update Magnitude: 0.16472
Value Function Update Magnitude: 0.39342

Collected Steps per Second: 15,270.72870
Overall Steps per Second: 10,368.16820

Timestep Collection Time: 3.27633
Timestep Consumption Time: 1.54921
PPO Batch Consumption Time: 0.14637
Total Iteration Time: 4.82554

Cumulative Model Updates: 49,332
Cumulative Timesteps: 411,558,158

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 411558158...
Checkpoint 411558158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,477.66164
Policy Entropy: 0.53894
Value Function Loss: 0.10920

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07038
Policy Update Magnitude: 0.16839
Value Function Update Magnitude: 0.36634

Collected Steps per Second: 14,857.11772
Overall Steps per Second: 10,190.20314

Timestep Collection Time: 3.36876
Timestep Consumption Time: 1.54282
PPO Batch Consumption Time: 0.14139
Total Iteration Time: 4.91158

Cumulative Model Updates: 49,338
Cumulative Timesteps: 411,608,208

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,196.38132
Policy Entropy: 0.53640
Value Function Loss: 0.10464

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07968
Policy Update Magnitude: 0.15803
Value Function Update Magnitude: 0.36465

Collected Steps per Second: 15,316.64555
Overall Steps per Second: 10,507.19598

Timestep Collection Time: 3.26638
Timestep Consumption Time: 1.49512
PPO Batch Consumption Time: 0.13489
Total Iteration Time: 4.76150

Cumulative Model Updates: 49,344
Cumulative Timesteps: 411,658,238

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 411658238...
Checkpoint 411658238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,508.11502
Policy Entropy: 0.53466
Value Function Loss: 0.10057

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06080
Policy Update Magnitude: 0.16018
Value Function Update Magnitude: 0.35069

Collected Steps per Second: 14,798.72430
Overall Steps per Second: 10,226.47980

Timestep Collection Time: 3.37894
Timestep Consumption Time: 1.51072
PPO Batch Consumption Time: 0.14246
Total Iteration Time: 4.88966

Cumulative Model Updates: 49,350
Cumulative Timesteps: 411,708,242

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,867.38920
Policy Entropy: 0.53881
Value Function Loss: 0.10169

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06355
Policy Update Magnitude: 0.16311
Value Function Update Magnitude: 0.37969

Collected Steps per Second: 15,088.99129
Overall Steps per Second: 10,366.29181

Timestep Collection Time: 3.31473
Timestep Consumption Time: 1.51013
PPO Batch Consumption Time: 0.13848
Total Iteration Time: 4.82487

Cumulative Model Updates: 49,356
Cumulative Timesteps: 411,758,258

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 411758258...
Checkpoint 411758258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,858.30462
Policy Entropy: 0.54720
Value Function Loss: 0.10524

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.06904
Policy Update Magnitude: 0.15571
Value Function Update Magnitude: 0.38615

Collected Steps per Second: 14,713.48960
Overall Steps per Second: 10,041.52340

Timestep Collection Time: 3.40001
Timestep Consumption Time: 1.58190
PPO Batch Consumption Time: 0.14904
Total Iteration Time: 4.98191

Cumulative Model Updates: 49,362
Cumulative Timesteps: 411,808,284

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,045.01255
Policy Entropy: 0.53502
Value Function Loss: 0.09307

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06067
Policy Update Magnitude: 0.16016
Value Function Update Magnitude: 0.40950

Collected Steps per Second: 14,715.11826
Overall Steps per Second: 10,176.54766

Timestep Collection Time: 3.39882
Timestep Consumption Time: 1.51582
PPO Batch Consumption Time: 0.13820
Total Iteration Time: 4.91463

Cumulative Model Updates: 49,368
Cumulative Timesteps: 411,858,298

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 411858298...
Checkpoint 411858298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,914.12122
Policy Entropy: 0.53729
Value Function Loss: 0.09320

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07343
Policy Update Magnitude: 0.15774
Value Function Update Magnitude: 0.39398

Collected Steps per Second: 14,889.86644
Overall Steps per Second: 10,286.08381

Timestep Collection Time: 3.35879
Timestep Consumption Time: 1.50331
PPO Batch Consumption Time: 0.14035
Total Iteration Time: 4.86210

Cumulative Model Updates: 49,374
Cumulative Timesteps: 411,908,310

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,601.54891
Policy Entropy: 0.53695
Value Function Loss: 0.08973

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07828
Policy Update Magnitude: 0.14920
Value Function Update Magnitude: 0.37722

Collected Steps per Second: 14,965.76823
Overall Steps per Second: 10,325.12160

Timestep Collection Time: 3.34203
Timestep Consumption Time: 1.50208
PPO Batch Consumption Time: 0.13680
Total Iteration Time: 4.84411

Cumulative Model Updates: 49,380
Cumulative Timesteps: 411,958,326

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 411958326...
Checkpoint 411958326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,016.36623
Policy Entropy: 0.53983
Value Function Loss: 0.09983

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.14566
Value Function Update Magnitude: 0.35840

Collected Steps per Second: 14,992.06478
Overall Steps per Second: 10,379.49906

Timestep Collection Time: 3.33683
Timestep Consumption Time: 1.48286
PPO Batch Consumption Time: 0.13931
Total Iteration Time: 4.81969

Cumulative Model Updates: 49,386
Cumulative Timesteps: 412,008,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,826.53030
Policy Entropy: 0.54399
Value Function Loss: 0.09880

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.05732
Policy Update Magnitude: 0.15608
Value Function Update Magnitude: 0.34273

Collected Steps per Second: 14,446.74311
Overall Steps per Second: 10,058.86829

Timestep Collection Time: 3.46279
Timestep Consumption Time: 1.51054
PPO Batch Consumption Time: 0.13864
Total Iteration Time: 4.97332

Cumulative Model Updates: 49,392
Cumulative Timesteps: 412,058,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 412058378...
Checkpoint 412058378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,571.40489
Policy Entropy: 0.54908
Value Function Loss: 0.10332

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04558
Policy Update Magnitude: 0.17562
Value Function Update Magnitude: 0.32709

Collected Steps per Second: 15,129.88044
Overall Steps per Second: 10,353.12276

Timestep Collection Time: 3.30564
Timestep Consumption Time: 1.52517
PPO Batch Consumption Time: 0.13913
Total Iteration Time: 4.83081

Cumulative Model Updates: 49,398
Cumulative Timesteps: 412,108,392

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,539.08130
Policy Entropy: 0.55813
Value Function Loss: 0.09524

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04499
Policy Update Magnitude: 0.17490
Value Function Update Magnitude: 0.33418

Collected Steps per Second: 14,951.19657
Overall Steps per Second: 10,324.98802

Timestep Collection Time: 3.34609
Timestep Consumption Time: 1.49925
PPO Batch Consumption Time: 0.13619
Total Iteration Time: 4.84533

Cumulative Model Updates: 49,404
Cumulative Timesteps: 412,158,420

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 412158420...
Checkpoint 412158420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,011.76681
Policy Entropy: 0.56075
Value Function Loss: 0.10200

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04248
Policy Update Magnitude: 0.17858
Value Function Update Magnitude: 0.35025

Collected Steps per Second: 14,938.44345
Overall Steps per Second: 10,245.73999

Timestep Collection Time: 3.34734
Timestep Consumption Time: 1.53313
PPO Batch Consumption Time: 0.14034
Total Iteration Time: 4.88047

Cumulative Model Updates: 49,410
Cumulative Timesteps: 412,208,424

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,557.68842
Policy Entropy: 0.56087
Value Function Loss: 0.09912

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04275
Policy Update Magnitude: 0.18463
Value Function Update Magnitude: 0.34906

Collected Steps per Second: 14,896.00307
Overall Steps per Second: 10,388.06267

Timestep Collection Time: 3.35701
Timestep Consumption Time: 1.45679
PPO Batch Consumption Time: 0.13454
Total Iteration Time: 4.81379

Cumulative Model Updates: 49,416
Cumulative Timesteps: 412,258,430

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 412258430...
Checkpoint 412258430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,772.88523
Policy Entropy: 0.55666
Value Function Loss: 0.09879

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04561
Policy Update Magnitude: 0.17937
Value Function Update Magnitude: 0.37750

Collected Steps per Second: 15,221.80889
Overall Steps per Second: 10,326.37888

Timestep Collection Time: 3.28647
Timestep Consumption Time: 1.55802
PPO Batch Consumption Time: 0.14156
Total Iteration Time: 4.84449

Cumulative Model Updates: 49,422
Cumulative Timesteps: 412,308,456

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,110.34925
Policy Entropy: 0.55672
Value Function Loss: 0.09354

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03621
Policy Update Magnitude: 0.17529
Value Function Update Magnitude: 0.38090

Collected Steps per Second: 14,888.42165
Overall Steps per Second: 10,290.86949

Timestep Collection Time: 3.36019
Timestep Consumption Time: 1.50120
PPO Batch Consumption Time: 0.13585
Total Iteration Time: 4.86140

Cumulative Model Updates: 49,428
Cumulative Timesteps: 412,358,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 412358484...
Checkpoint 412358484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,035.84071
Policy Entropy: 0.55604
Value Function Loss: 0.08929

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.04094
Policy Update Magnitude: 0.17359
Value Function Update Magnitude: 0.39419

Collected Steps per Second: 15,021.77888
Overall Steps per Second: 10,298.01759

Timestep Collection Time: 3.33050
Timestep Consumption Time: 1.52772
PPO Batch Consumption Time: 0.14044
Total Iteration Time: 4.85822

Cumulative Model Updates: 49,434
Cumulative Timesteps: 412,408,514

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,834.72944
Policy Entropy: 0.54832
Value Function Loss: 0.08529

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.04394
Policy Update Magnitude: 0.16680
Value Function Update Magnitude: 0.39836

Collected Steps per Second: 14,589.80367
Overall Steps per Second: 10,170.41057

Timestep Collection Time: 3.43020
Timestep Consumption Time: 1.49054
PPO Batch Consumption Time: 0.13647
Total Iteration Time: 4.92075

Cumulative Model Updates: 49,440
Cumulative Timesteps: 412,458,560

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 412458560...
Checkpoint 412458560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,493.24423
Policy Entropy: 0.55770
Value Function Loss: 0.08508

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06167
Policy Update Magnitude: 0.15947
Value Function Update Magnitude: 0.39739

Collected Steps per Second: 14,824.95316
Overall Steps per Second: 10,209.65476

Timestep Collection Time: 3.37552
Timestep Consumption Time: 1.52591
PPO Batch Consumption Time: 0.14063
Total Iteration Time: 4.90144

Cumulative Model Updates: 49,446
Cumulative Timesteps: 412,508,602

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,139.30188
Policy Entropy: 0.55098
Value Function Loss: 0.08936

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06879
Policy Update Magnitude: 0.14782
Value Function Update Magnitude: 0.35672

Collected Steps per Second: 14,653.73962
Overall Steps per Second: 10,207.31637

Timestep Collection Time: 3.41292
Timestep Consumption Time: 1.48671
PPO Batch Consumption Time: 0.13820
Total Iteration Time: 4.89962

Cumulative Model Updates: 49,452
Cumulative Timesteps: 412,558,614

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 412558614...
Checkpoint 412558614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,046.26476
Policy Entropy: 0.54807
Value Function Loss: 0.08455

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.06070
Policy Update Magnitude: 0.15368
Value Function Update Magnitude: 0.35062

Collected Steps per Second: 15,058.13246
Overall Steps per Second: 10,307.51382

Timestep Collection Time: 3.32060
Timestep Consumption Time: 1.53043
PPO Batch Consumption Time: 0.14243
Total Iteration Time: 4.85102

Cumulative Model Updates: 49,458
Cumulative Timesteps: 412,608,616

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,726.62673
Policy Entropy: 0.54329
Value Function Loss: 0.09586

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05339
Policy Update Magnitude: 0.16521
Value Function Update Magnitude: 0.38176

Collected Steps per Second: 14,389.64180
Overall Steps per Second: 10,151.92407

Timestep Collection Time: 3.47792
Timestep Consumption Time: 1.45179
PPO Batch Consumption Time: 0.13380
Total Iteration Time: 4.92971

Cumulative Model Updates: 49,464
Cumulative Timesteps: 412,658,662

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 412658662...
Checkpoint 412658662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,109.87912
Policy Entropy: 0.54187
Value Function Loss: 0.10277

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05742
Policy Update Magnitude: 0.17271
Value Function Update Magnitude: 0.39932

Collected Steps per Second: 14,848.71274
Overall Steps per Second: 10,333.07248

Timestep Collection Time: 3.36824
Timestep Consumption Time: 1.47195
PPO Batch Consumption Time: 0.14018
Total Iteration Time: 4.84019

Cumulative Model Updates: 49,470
Cumulative Timesteps: 412,708,676

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,389.74572
Policy Entropy: 0.53128
Value Function Loss: 0.11510

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04855
Policy Update Magnitude: 0.17752
Value Function Update Magnitude: 0.42093

Collected Steps per Second: 14,892.41934
Overall Steps per Second: 10,322.70515

Timestep Collection Time: 3.35916
Timestep Consumption Time: 1.48705
PPO Batch Consumption Time: 0.13457
Total Iteration Time: 4.84621

Cumulative Model Updates: 49,476
Cumulative Timesteps: 412,758,702

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 412758702...
Checkpoint 412758702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,738.78528
Policy Entropy: 0.52271
Value Function Loss: 0.12061

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.04114
Policy Update Magnitude: 0.17489
Value Function Update Magnitude: 0.44128

Collected Steps per Second: 15,247.52405
Overall Steps per Second: 10,434.00402

Timestep Collection Time: 3.28145
Timestep Consumption Time: 1.51383
PPO Batch Consumption Time: 0.13900
Total Iteration Time: 4.79528

Cumulative Model Updates: 49,482
Cumulative Timesteps: 412,808,736

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,436.34294
Policy Entropy: 0.52409
Value Function Loss: 0.12018

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04558
Policy Update Magnitude: 0.17953
Value Function Update Magnitude: 0.42156

Collected Steps per Second: 14,570.99340
Overall Steps per Second: 10,107.25439

Timestep Collection Time: 3.43257
Timestep Consumption Time: 1.51595
PPO Batch Consumption Time: 0.13827
Total Iteration Time: 4.94852

Cumulative Model Updates: 49,488
Cumulative Timesteps: 412,858,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 412858752...
Checkpoint 412858752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,082.91484
Policy Entropy: 0.52676
Value Function Loss: 0.11639

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04300
Policy Update Magnitude: 0.17264
Value Function Update Magnitude: 0.37349

Collected Steps per Second: 15,184.95343
Overall Steps per Second: 10,444.51626

Timestep Collection Time: 3.29300
Timestep Consumption Time: 1.49459
PPO Batch Consumption Time: 0.13629
Total Iteration Time: 4.78758

Cumulative Model Updates: 49,494
Cumulative Timesteps: 412,908,756

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,468.20340
Policy Entropy: 0.53532
Value Function Loss: 0.10162

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.06474
Policy Update Magnitude: 0.16703
Value Function Update Magnitude: 0.37962

Collected Steps per Second: 14,545.43170
Overall Steps per Second: 10,137.84641

Timestep Collection Time: 3.43792
Timestep Consumption Time: 1.49469
PPO Batch Consumption Time: 0.13515
Total Iteration Time: 4.93261

Cumulative Model Updates: 49,500
Cumulative Timesteps: 412,958,762

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 412958762...
Checkpoint 412958762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,736.75660
Policy Entropy: 0.53025
Value Function Loss: 0.09395

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07375
Policy Update Magnitude: 0.15009
Value Function Update Magnitude: 0.38829

Collected Steps per Second: 15,193.57467
Overall Steps per Second: 10,431.53678

Timestep Collection Time: 3.29126
Timestep Consumption Time: 1.50247
PPO Batch Consumption Time: 0.13662
Total Iteration Time: 4.79373

Cumulative Model Updates: 49,506
Cumulative Timesteps: 413,008,768

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,988.33629
Policy Entropy: 0.52511
Value Function Loss: 0.08825

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07328
Policy Update Magnitude: 0.15504
Value Function Update Magnitude: 0.40127

Collected Steps per Second: 14,710.87337
Overall Steps per Second: 10,132.78248

Timestep Collection Time: 3.39993
Timestep Consumption Time: 1.53612
PPO Batch Consumption Time: 0.14047
Total Iteration Time: 4.93606

Cumulative Model Updates: 49,512
Cumulative Timesteps: 413,058,784

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 413058784...
Checkpoint 413058784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,085.45168
Policy Entropy: 0.51063
Value Function Loss: 0.10367

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07151
Policy Update Magnitude: 0.16061
Value Function Update Magnitude: 0.37025

Collected Steps per Second: 15,221.54116
Overall Steps per Second: 10,501.02843

Timestep Collection Time: 3.28482
Timestep Consumption Time: 1.47662
PPO Batch Consumption Time: 0.13695
Total Iteration Time: 4.76144

Cumulative Model Updates: 49,518
Cumulative Timesteps: 413,108,784

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,081.61026
Policy Entropy: 0.52131
Value Function Loss: 0.09804

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06298
Policy Update Magnitude: 0.16518
Value Function Update Magnitude: 0.36208

Collected Steps per Second: 15,029.65104
Overall Steps per Second: 10,278.18839

Timestep Collection Time: 3.32995
Timestep Consumption Time: 1.53939
PPO Batch Consumption Time: 0.14187
Total Iteration Time: 4.86934

Cumulative Model Updates: 49,524
Cumulative Timesteps: 413,158,832

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 413158832...
Checkpoint 413158832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,135.54050
Policy Entropy: 0.51843
Value Function Loss: 0.09194

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05350
Policy Update Magnitude: 0.16822
Value Function Update Magnitude: 0.37593

Collected Steps per Second: 15,045.54295
Overall Steps per Second: 10,407.79387

Timestep Collection Time: 3.32497
Timestep Consumption Time: 1.48162
PPO Batch Consumption Time: 0.13893
Total Iteration Time: 4.80659

Cumulative Model Updates: 49,530
Cumulative Timesteps: 413,208,858

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,501.30447
Policy Entropy: 0.52752
Value Function Loss: 0.08635

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04478
Policy Update Magnitude: 0.16468
Value Function Update Magnitude: 0.35078

Collected Steps per Second: 14,998.48300
Overall Steps per Second: 10,058.34536

Timestep Collection Time: 3.33487
Timestep Consumption Time: 1.63792
PPO Batch Consumption Time: 0.15517
Total Iteration Time: 4.97279

Cumulative Model Updates: 49,536
Cumulative Timesteps: 413,258,876

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 413258876...
Checkpoint 413258876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,426.79663
Policy Entropy: 0.52662
Value Function Loss: 0.08850

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03901
Policy Update Magnitude: 0.16210
Value Function Update Magnitude: 0.31116

Collected Steps per Second: 15,124.86526
Overall Steps per Second: 10,407.54853

Timestep Collection Time: 3.30714
Timestep Consumption Time: 1.49899
PPO Batch Consumption Time: 0.13731
Total Iteration Time: 4.80613

Cumulative Model Updates: 49,542
Cumulative Timesteps: 413,308,896

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,815.43747
Policy Entropy: 0.52740
Value Function Loss: 0.09571

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04853
Policy Update Magnitude: 0.16205
Value Function Update Magnitude: 0.33539

Collected Steps per Second: 14,952.29067
Overall Steps per Second: 10,303.44836

Timestep Collection Time: 3.34571
Timestep Consumption Time: 1.50956
PPO Batch Consumption Time: 0.13702
Total Iteration Time: 4.85527

Cumulative Model Updates: 49,548
Cumulative Timesteps: 413,358,922

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 413358922...
Checkpoint 413358922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,901.24736
Policy Entropy: 0.51651
Value Function Loss: 0.09763

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06797
Policy Update Magnitude: 0.15293
Value Function Update Magnitude: 0.37574

Collected Steps per Second: 15,082.53953
Overall Steps per Second: 10,364.78707

Timestep Collection Time: 3.31536
Timestep Consumption Time: 1.50905
PPO Batch Consumption Time: 0.13915
Total Iteration Time: 4.82441

Cumulative Model Updates: 49,554
Cumulative Timesteps: 413,408,926

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,044.02293
Policy Entropy: 0.51535
Value Function Loss: 0.09966

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06373
Policy Update Magnitude: 0.16063
Value Function Update Magnitude: 0.40684

Collected Steps per Second: 15,091.63119
Overall Steps per Second: 10,053.71733

Timestep Collection Time: 3.31376
Timestep Consumption Time: 1.66052
PPO Batch Consumption Time: 0.16869
Total Iteration Time: 4.97428

Cumulative Model Updates: 49,560
Cumulative Timesteps: 413,458,936

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 413458936...
Checkpoint 413458936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,068.20436
Policy Entropy: 0.51244
Value Function Loss: 0.10000

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05382
Policy Update Magnitude: 0.17317
Value Function Update Magnitude: 0.43521

Collected Steps per Second: 14,846.44153
Overall Steps per Second: 10,278.41585

Timestep Collection Time: 3.36902
Timestep Consumption Time: 1.49729
PPO Batch Consumption Time: 0.13703
Total Iteration Time: 4.86631

Cumulative Model Updates: 49,566
Cumulative Timesteps: 413,508,954

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,377.55643
Policy Entropy: 0.51782
Value Function Loss: 0.10409

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06102
Policy Update Magnitude: 0.17300
Value Function Update Magnitude: 0.41256

Collected Steps per Second: 14,904.92603
Overall Steps per Second: 10,328.04780

Timestep Collection Time: 3.35500
Timestep Consumption Time: 1.48677
PPO Batch Consumption Time: 0.14072
Total Iteration Time: 4.84177

Cumulative Model Updates: 49,572
Cumulative Timesteps: 413,558,960

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 413558960...
Checkpoint 413558960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,811.87368
Policy Entropy: 0.52677
Value Function Loss: 0.10842

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07993
Policy Update Magnitude: 0.15532
Value Function Update Magnitude: 0.41880

Collected Steps per Second: 14,983.93930
Overall Steps per Second: 10,420.65962

Timestep Collection Time: 3.33918
Timestep Consumption Time: 1.46225
PPO Batch Consumption Time: 0.13783
Total Iteration Time: 4.80142

Cumulative Model Updates: 49,578
Cumulative Timesteps: 413,608,994

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,508.24254
Policy Entropy: 0.51900
Value Function Loss: 0.11184

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06509
Policy Update Magnitude: 0.15997
Value Function Update Magnitude: 0.41209

Collected Steps per Second: 15,081.91949
Overall Steps per Second: 10,161.38351

Timestep Collection Time: 3.31695
Timestep Consumption Time: 1.60620
PPO Batch Consumption Time: 0.15137
Total Iteration Time: 4.92315

Cumulative Model Updates: 49,584
Cumulative Timesteps: 413,659,020

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 413659020...
Checkpoint 413659020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,323.83107
Policy Entropy: 0.51645
Value Function Loss: 0.10538

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05146
Policy Update Magnitude: 0.17361
Value Function Update Magnitude: 0.41277

Collected Steps per Second: 14,653.91250
Overall Steps per Second: 10,128.06589

Timestep Collection Time: 3.41315
Timestep Consumption Time: 1.52521
PPO Batch Consumption Time: 0.14147
Total Iteration Time: 4.93836

Cumulative Model Updates: 49,590
Cumulative Timesteps: 413,709,036

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,026.31668
Policy Entropy: 0.50533
Value Function Loss: 0.10448

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.05077
Policy Update Magnitude: 0.18072
Value Function Update Magnitude: 0.42293

Collected Steps per Second: 15,244.17371
Overall Steps per Second: 10,471.76310

Timestep Collection Time: 3.28178
Timestep Consumption Time: 1.49564
PPO Batch Consumption Time: 0.14016
Total Iteration Time: 4.77742

Cumulative Model Updates: 49,596
Cumulative Timesteps: 413,759,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 413759064...
Checkpoint 413759064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,448.83169
Policy Entropy: 0.51624
Value Function Loss: 0.08919

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04819
Policy Update Magnitude: 0.18413
Value Function Update Magnitude: 0.42156

Collected Steps per Second: 14,787.38961
Overall Steps per Second: 10,278.80963

Timestep Collection Time: 3.38396
Timestep Consumption Time: 1.48430
PPO Batch Consumption Time: 0.13810
Total Iteration Time: 4.86827

Cumulative Model Updates: 49,602
Cumulative Timesteps: 413,809,104

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,260.17205
Policy Entropy: 0.51560
Value Function Loss: 0.08679

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.05313
Policy Update Magnitude: 0.16599
Value Function Update Magnitude: 0.40298

Collected Steps per Second: 15,260.04092
Overall Steps per Second: 10,515.09812

Timestep Collection Time: 3.27784
Timestep Consumption Time: 1.47913
PPO Batch Consumption Time: 0.13998
Total Iteration Time: 4.75697

Cumulative Model Updates: 49,608
Cumulative Timesteps: 413,859,124

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 413859124...
Checkpoint 413859124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,563.23731
Policy Entropy: 0.52994
Value Function Loss: 0.07689

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04604
Policy Update Magnitude: 0.16352
Value Function Update Magnitude: 0.39124

Collected Steps per Second: 14,272.50086
Overall Steps per Second: 10,022.68607

Timestep Collection Time: 3.50520
Timestep Consumption Time: 1.48627
PPO Batch Consumption Time: 0.13783
Total Iteration Time: 4.99148

Cumulative Model Updates: 49,614
Cumulative Timesteps: 413,909,152

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,129.19961
Policy Entropy: 0.52020
Value Function Loss: 0.08492

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.04002
Policy Update Magnitude: 0.17369
Value Function Update Magnitude: 0.40049

Collected Steps per Second: 15,391.03027
Overall Steps per Second: 10,434.81242

Timestep Collection Time: 3.25085
Timestep Consumption Time: 1.54406
PPO Batch Consumption Time: 0.14194
Total Iteration Time: 4.79491

Cumulative Model Updates: 49,620
Cumulative Timesteps: 413,959,186

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 413959186...
Checkpoint 413959186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,035.86720
Policy Entropy: 0.53242
Value Function Loss: 0.08364

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04973
Policy Update Magnitude: 0.17601
Value Function Update Magnitude: 0.43039

Collected Steps per Second: 14,035.26655
Overall Steps per Second: 9,728.84691

Timestep Collection Time: 3.56302
Timestep Consumption Time: 1.57715
PPO Batch Consumption Time: 0.14722
Total Iteration Time: 5.14018

Cumulative Model Updates: 49,626
Cumulative Timesteps: 414,009,194

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,307.36662
Policy Entropy: 0.51943
Value Function Loss: 0.09153

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.04112
Policy Update Magnitude: 0.16923
Value Function Update Magnitude: 0.41453

Collected Steps per Second: 13,701.23604
Overall Steps per Second: 9,757.54106

Timestep Collection Time: 3.65135
Timestep Consumption Time: 1.47576
PPO Batch Consumption Time: 0.13928
Total Iteration Time: 5.12711

Cumulative Model Updates: 49,632
Cumulative Timesteps: 414,059,222

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 414059222...
Checkpoint 414059222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,254.31514
Policy Entropy: 0.52334
Value Function Loss: 0.09114

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04189
Policy Update Magnitude: 0.17190
Value Function Update Magnitude: 0.40969

Collected Steps per Second: 15,040.16987
Overall Steps per Second: 10,359.43546

Timestep Collection Time: 3.32523
Timestep Consumption Time: 1.50245
PPO Batch Consumption Time: 0.13521
Total Iteration Time: 4.82768

Cumulative Model Updates: 49,638
Cumulative Timesteps: 414,109,234

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,308.30288
Policy Entropy: 0.52180
Value Function Loss: 0.09603

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04888
Policy Update Magnitude: 0.17154
Value Function Update Magnitude: 0.39626

Collected Steps per Second: 15,094.08266
Overall Steps per Second: 10,435.99856

Timestep Collection Time: 3.31295
Timestep Consumption Time: 1.47873
PPO Batch Consumption Time: 0.13598
Total Iteration Time: 4.79168

Cumulative Model Updates: 49,644
Cumulative Timesteps: 414,159,240

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 414159240...
Checkpoint 414159240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,545.81984
Policy Entropy: 0.52970
Value Function Loss: 0.08979

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.05198
Policy Update Magnitude: 0.16608
Value Function Update Magnitude: 0.41755

Collected Steps per Second: 15,139.60866
Overall Steps per Second: 10,279.59939

Timestep Collection Time: 3.30352
Timestep Consumption Time: 1.56184
PPO Batch Consumption Time: 0.14893
Total Iteration Time: 4.86536

Cumulative Model Updates: 49,650
Cumulative Timesteps: 414,209,254

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,497.92884
Policy Entropy: 0.52550
Value Function Loss: 0.09341

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04944
Policy Update Magnitude: 0.16798
Value Function Update Magnitude: 0.41540

Collected Steps per Second: 14,846.79283
Overall Steps per Second: 10,245.70281

Timestep Collection Time: 3.36773
Timestep Consumption Time: 1.51236
PPO Batch Consumption Time: 0.13896
Total Iteration Time: 4.88009

Cumulative Model Updates: 49,656
Cumulative Timesteps: 414,259,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 414259254...
Checkpoint 414259254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,094.13724
Policy Entropy: 0.53129
Value Function Loss: 0.08813

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04609
Policy Update Magnitude: 0.16695
Value Function Update Magnitude: 0.40794

Collected Steps per Second: 14,055.47708
Overall Steps per Second: 9,938.59098

Timestep Collection Time: 3.55762
Timestep Consumption Time: 1.47368
PPO Batch Consumption Time: 0.13934
Total Iteration Time: 5.03130

Cumulative Model Updates: 49,662
Cumulative Timesteps: 414,309,258

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,861.97467
Policy Entropy: 0.53786
Value Function Loss: 0.09359

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.04342
Policy Update Magnitude: 0.17071
Value Function Update Magnitude: 0.41495

Collected Steps per Second: 14,972.38688
Overall Steps per Second: 10,232.07241

Timestep Collection Time: 3.33948
Timestep Consumption Time: 1.54711
PPO Batch Consumption Time: 0.14300
Total Iteration Time: 4.88660

Cumulative Model Updates: 49,668
Cumulative Timesteps: 414,359,258

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 414359258...
Checkpoint 414359258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,238.39467
Policy Entropy: 0.54153
Value Function Loss: 0.09423

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05565
Policy Update Magnitude: 0.16856
Value Function Update Magnitude: 0.41360

Collected Steps per Second: 15,220.94198
Overall Steps per Second: 10,349.89744

Timestep Collection Time: 3.28547
Timestep Consumption Time: 1.54627
PPO Batch Consumption Time: 0.13982
Total Iteration Time: 4.83174

Cumulative Model Updates: 49,674
Cumulative Timesteps: 414,409,266

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,285.97237
Policy Entropy: 0.54282
Value Function Loss: 0.09596

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07113
Policy Update Magnitude: 0.16279
Value Function Update Magnitude: 0.39935

Collected Steps per Second: 15,044.44717
Overall Steps per Second: 10,296.43384

Timestep Collection Time: 3.32495
Timestep Consumption Time: 1.53324
PPO Batch Consumption Time: 0.14096
Total Iteration Time: 4.85819

Cumulative Model Updates: 49,680
Cumulative Timesteps: 414,459,288

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 414459288...
Checkpoint 414459288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,196.71918
Policy Entropy: 0.52955
Value Function Loss: 0.09888

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07207
Policy Update Magnitude: 0.16027
Value Function Update Magnitude: 0.42496

Collected Steps per Second: 14,623.24526
Overall Steps per Second: 10,172.09399

Timestep Collection Time: 3.41949
Timestep Consumption Time: 1.49631
PPO Batch Consumption Time: 0.13644
Total Iteration Time: 4.91580

Cumulative Model Updates: 49,686
Cumulative Timesteps: 414,509,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,152.55480
Policy Entropy: 0.52656
Value Function Loss: 0.09426

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.06136
Policy Update Magnitude: 0.16702
Value Function Update Magnitude: 0.44489

Collected Steps per Second: 14,968.03080
Overall Steps per Second: 10,230.38745

Timestep Collection Time: 3.34139
Timestep Consumption Time: 1.54738
PPO Batch Consumption Time: 0.14180
Total Iteration Time: 4.88877

Cumulative Model Updates: 49,692
Cumulative Timesteps: 414,559,306

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 414559306...
Checkpoint 414559306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,571.52567
Policy Entropy: 0.52041
Value Function Loss: 0.09687

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05746
Policy Update Magnitude: 0.17153
Value Function Update Magnitude: 0.44067

Collected Steps per Second: 15,079.73691
Overall Steps per Second: 10,368.82159

Timestep Collection Time: 3.31611
Timestep Consumption Time: 1.50662
PPO Batch Consumption Time: 0.13820
Total Iteration Time: 4.82273

Cumulative Model Updates: 49,698
Cumulative Timesteps: 414,609,312

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,299.59443
Policy Entropy: 0.52944
Value Function Loss: 0.09270

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.04965
Policy Update Magnitude: 0.17300
Value Function Update Magnitude: 0.42620

Collected Steps per Second: 15,219.95197
Overall Steps per Second: 10,395.46803

Timestep Collection Time: 3.28753
Timestep Consumption Time: 1.52572
PPO Batch Consumption Time: 0.13983
Total Iteration Time: 4.81325

Cumulative Model Updates: 49,704
Cumulative Timesteps: 414,659,348

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 414659348...
Checkpoint 414659348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,253.51963
Policy Entropy: 0.53165
Value Function Loss: 0.09459

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04443
Policy Update Magnitude: 0.17101
Value Function Update Magnitude: 0.36341

Collected Steps per Second: 14,554.67413
Overall Steps per Second: 10,151.11703

Timestep Collection Time: 3.43711
Timestep Consumption Time: 1.49102
PPO Batch Consumption Time: 0.13681
Total Iteration Time: 4.92813

Cumulative Model Updates: 49,710
Cumulative Timesteps: 414,709,374

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,711.52836
Policy Entropy: 0.52414
Value Function Loss: 0.10520

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03999
Policy Update Magnitude: 0.17433
Value Function Update Magnitude: 0.34603

Collected Steps per Second: 14,462.66764
Overall Steps per Second: 10,012.91034

Timestep Collection Time: 3.45897
Timestep Consumption Time: 1.53718
PPO Batch Consumption Time: 0.14195
Total Iteration Time: 4.99615

Cumulative Model Updates: 49,716
Cumulative Timesteps: 414,759,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 414759400...
Checkpoint 414759400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,241.67823
Policy Entropy: 0.51853
Value Function Loss: 0.10508

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04756
Policy Update Magnitude: 0.17210
Value Function Update Magnitude: 0.35655

Collected Steps per Second: 14,831.46944
Overall Steps per Second: 10,282.89955

Timestep Collection Time: 3.37364
Timestep Consumption Time: 1.49231
PPO Batch Consumption Time: 0.13512
Total Iteration Time: 4.86594

Cumulative Model Updates: 49,722
Cumulative Timesteps: 414,809,436

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,286.00436
Policy Entropy: 0.52264
Value Function Loss: 0.10726

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03656
Policy Update Magnitude: 0.17105
Value Function Update Magnitude: 0.39194

Collected Steps per Second: 15,088.49807
Overall Steps per Second: 10,338.02360

Timestep Collection Time: 3.31445
Timestep Consumption Time: 1.52304
PPO Batch Consumption Time: 0.13957
Total Iteration Time: 4.83748

Cumulative Model Updates: 49,728
Cumulative Timesteps: 414,859,446

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 414859446...
Checkpoint 414859446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,947.18078
Policy Entropy: 0.53401
Value Function Loss: 0.09467

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03595
Policy Update Magnitude: 0.17218
Value Function Update Magnitude: 0.38986

Collected Steps per Second: 14,224.55733
Overall Steps per Second: 10,001.12434

Timestep Collection Time: 3.51688
Timestep Consumption Time: 1.48516
PPO Batch Consumption Time: 0.13878
Total Iteration Time: 5.00204

Cumulative Model Updates: 49,734
Cumulative Timesteps: 414,909,472

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,170.81644
Policy Entropy: 0.53100
Value Function Loss: 0.10222

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04493
Policy Update Magnitude: 0.17244
Value Function Update Magnitude: 0.34544

Collected Steps per Second: 15,210.38272
Overall Steps per Second: 10,336.66116

Timestep Collection Time: 3.28802
Timestep Consumption Time: 1.55030
PPO Batch Consumption Time: 0.14570
Total Iteration Time: 4.83831

Cumulative Model Updates: 49,740
Cumulative Timesteps: 414,959,484

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 414959484...
Checkpoint 414959484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,351.35124
Policy Entropy: 0.54094
Value Function Loss: 0.09822

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08128
Policy Update Magnitude: 0.15325
Value Function Update Magnitude: 0.34593

Collected Steps per Second: 14,910.97319
Overall Steps per Second: 10,312.77657

Timestep Collection Time: 3.35511
Timestep Consumption Time: 1.49596
PPO Batch Consumption Time: 0.14045
Total Iteration Time: 4.85107

Cumulative Model Updates: 49,746
Cumulative Timesteps: 415,009,512

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,262.96431
Policy Entropy: 0.53381
Value Function Loss: 0.09222

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.07409
Policy Update Magnitude: 0.16084
Value Function Update Magnitude: 0.38579

Collected Steps per Second: 15,001.17117
Overall Steps per Second: 10,333.60363

Timestep Collection Time: 3.33427
Timestep Consumption Time: 1.50605
PPO Batch Consumption Time: 0.14155
Total Iteration Time: 4.84032

Cumulative Model Updates: 49,752
Cumulative Timesteps: 415,059,530

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 415059530...
Checkpoint 415059530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,369.30011
Policy Entropy: 0.52813
Value Function Loss: 0.08734

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.06855
Policy Update Magnitude: 0.16278
Value Function Update Magnitude: 0.40788

Collected Steps per Second: 13,696.82977
Overall Steps per Second: 9,531.83129

Timestep Collection Time: 3.65223
Timestep Consumption Time: 1.59587
PPO Batch Consumption Time: 0.13974
Total Iteration Time: 5.24810

Cumulative Model Updates: 49,758
Cumulative Timesteps: 415,109,554

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,332.32062
Policy Entropy: 0.52743
Value Function Loss: 0.09070

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06417
Policy Update Magnitude: 0.15896
Value Function Update Magnitude: 0.40343

Collected Steps per Second: 14,210.66222
Overall Steps per Second: 9,760.79288

Timestep Collection Time: 3.52074
Timestep Consumption Time: 1.60508
PPO Batch Consumption Time: 0.14204
Total Iteration Time: 5.12581

Cumulative Model Updates: 49,764
Cumulative Timesteps: 415,159,586

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 415159586...
Checkpoint 415159586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,391.93712
Policy Entropy: 0.52487
Value Function Loss: 0.09107

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05791
Policy Update Magnitude: 0.16513
Value Function Update Magnitude: 0.42548

Collected Steps per Second: 14,478.56229
Overall Steps per Second: 10,149.37922

Timestep Collection Time: 3.45393
Timestep Consumption Time: 1.47326
PPO Batch Consumption Time: 0.13838
Total Iteration Time: 4.92720

Cumulative Model Updates: 49,770
Cumulative Timesteps: 415,209,594

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,283.10992
Policy Entropy: 0.52875
Value Function Loss: 0.09519

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07451
Policy Update Magnitude: 0.15936
Value Function Update Magnitude: 0.43525

Collected Steps per Second: 15,145.63179
Overall Steps per Second: 10,397.91616

Timestep Collection Time: 3.30181
Timestep Consumption Time: 1.50762
PPO Batch Consumption Time: 0.14201
Total Iteration Time: 4.80943

Cumulative Model Updates: 49,776
Cumulative Timesteps: 415,259,602

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 415259602...
Checkpoint 415259602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,202.74553
Policy Entropy: 0.53092
Value Function Loss: 0.08553

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07166
Policy Update Magnitude: 0.15642
Value Function Update Magnitude: 0.43570

Collected Steps per Second: 14,340.05020
Overall Steps per Second: 9,991.87321

Timestep Collection Time: 3.48785
Timestep Consumption Time: 1.51781
PPO Batch Consumption Time: 0.13916
Total Iteration Time: 5.00567

Cumulative Model Updates: 49,782
Cumulative Timesteps: 415,309,618

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,448.52220
Policy Entropy: 0.53417
Value Function Loss: 0.08651

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.06533
Policy Update Magnitude: 0.15595
Value Function Update Magnitude: 0.41799

Collected Steps per Second: 15,156.07980
Overall Steps per Second: 10,338.61625

Timestep Collection Time: 3.29940
Timestep Consumption Time: 1.53742
PPO Batch Consumption Time: 0.14117
Total Iteration Time: 4.83682

Cumulative Model Updates: 49,788
Cumulative Timesteps: 415,359,624

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 415359624...
Checkpoint 415359624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,302.39706
Policy Entropy: 0.53445
Value Function Loss: 0.09057

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.15752
Value Function Update Magnitude: 0.42471

Collected Steps per Second: 14,655.40228
Overall Steps per Second: 10,232.79904

Timestep Collection Time: 3.41471
Timestep Consumption Time: 1.47583
PPO Batch Consumption Time: 0.13516
Total Iteration Time: 4.89055

Cumulative Model Updates: 49,794
Cumulative Timesteps: 415,409,668

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,038.36367
Policy Entropy: 0.52496
Value Function Loss: 0.10003

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.06702
Policy Update Magnitude: 0.15783
Value Function Update Magnitude: 0.41294

Collected Steps per Second: 15,128.10195
Overall Steps per Second: 10,393.65830

Timestep Collection Time: 3.30550
Timestep Consumption Time: 1.50570
PPO Batch Consumption Time: 0.13776
Total Iteration Time: 4.81120

Cumulative Model Updates: 49,800
Cumulative Timesteps: 415,459,674

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 415459674...
Checkpoint 415459674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,497.04665
Policy Entropy: 0.53223
Value Function Loss: 0.09848

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.05776
Policy Update Magnitude: 0.17709
Value Function Update Magnitude: 0.42365

Collected Steps per Second: 14,690.69308
Overall Steps per Second: 10,157.83835

Timestep Collection Time: 3.40556
Timestep Consumption Time: 1.51970
PPO Batch Consumption Time: 0.13801
Total Iteration Time: 4.92526

Cumulative Model Updates: 49,806
Cumulative Timesteps: 415,509,704

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,006.18067
Policy Entropy: 0.53297
Value Function Loss: 0.09679

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05507
Policy Update Magnitude: 0.17541
Value Function Update Magnitude: 0.41357

Collected Steps per Second: 15,341.89627
Overall Steps per Second: 10,482.79783

Timestep Collection Time: 3.26022
Timestep Consumption Time: 1.51121
PPO Batch Consumption Time: 0.13890
Total Iteration Time: 4.77144

Cumulative Model Updates: 49,812
Cumulative Timesteps: 415,559,722

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 415559722...
Checkpoint 415559722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,225.73501
Policy Entropy: 0.53693
Value Function Loss: 0.09568

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04846
Policy Update Magnitude: 0.17960
Value Function Update Magnitude: 0.39027

Collected Steps per Second: 14,784.78774
Overall Steps per Second: 10,319.74223

Timestep Collection Time: 3.38361
Timestep Consumption Time: 1.46399
PPO Batch Consumption Time: 0.13680
Total Iteration Time: 4.84760

Cumulative Model Updates: 49,818
Cumulative Timesteps: 415,609,748

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,326.85947
Policy Entropy: 0.52991
Value Function Loss: 0.10076

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04714
Policy Update Magnitude: 0.17746
Value Function Update Magnitude: 0.39906

Collected Steps per Second: 15,267.59592
Overall Steps per Second: 10,407.51244

Timestep Collection Time: 3.27609
Timestep Consumption Time: 1.52986
PPO Batch Consumption Time: 0.14181
Total Iteration Time: 4.80595

Cumulative Model Updates: 49,824
Cumulative Timesteps: 415,659,766

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 415659766...
Checkpoint 415659766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,398.25271
Policy Entropy: 0.53415
Value Function Loss: 0.09986

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04397
Policy Update Magnitude: 0.17321
Value Function Update Magnitude: 0.45492

Collected Steps per Second: 14,557.63860
Overall Steps per Second: 9,942.64104

Timestep Collection Time: 3.43531
Timestep Consumption Time: 1.59454
PPO Batch Consumption Time: 0.14829
Total Iteration Time: 5.02985

Cumulative Model Updates: 49,830
Cumulative Timesteps: 415,709,776

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,639.58679
Policy Entropy: 0.52891
Value Function Loss: 0.09430

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04372
Policy Update Magnitude: 0.17392
Value Function Update Magnitude: 0.45071

Collected Steps per Second: 15,279.36677
Overall Steps per Second: 10,461.64077

Timestep Collection Time: 3.27304
Timestep Consumption Time: 1.50728
PPO Batch Consumption Time: 0.13962
Total Iteration Time: 4.78032

Cumulative Model Updates: 49,836
Cumulative Timesteps: 415,759,786

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 415759786...
Checkpoint 415759786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,695.54516
Policy Entropy: 0.52731
Value Function Loss: 0.09355

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03474
Policy Update Magnitude: 0.17517
Value Function Update Magnitude: 0.43656

Collected Steps per Second: 14,744.72136
Overall Steps per Second: 10,223.63480

Timestep Collection Time: 3.39145
Timestep Consumption Time: 1.49976
PPO Batch Consumption Time: 0.13845
Total Iteration Time: 4.89122

Cumulative Model Updates: 49,842
Cumulative Timesteps: 415,809,792

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,558.89655
Policy Entropy: 0.53648
Value Function Loss: 0.09227

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03429
Policy Update Magnitude: 0.17806
Value Function Update Magnitude: 0.43228

Collected Steps per Second: 15,261.71923
Overall Steps per Second: 10,426.57500

Timestep Collection Time: 3.27709
Timestep Consumption Time: 1.51969
PPO Batch Consumption Time: 0.14020
Total Iteration Time: 4.79678

Cumulative Model Updates: 49,848
Cumulative Timesteps: 415,859,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 415859806...
Checkpoint 415859806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,689.30241
Policy Entropy: 0.53788
Value Function Loss: 0.09518

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03575
Policy Update Magnitude: 0.18175
Value Function Update Magnitude: 0.43304

Collected Steps per Second: 14,879.71831
Overall Steps per Second: 9,845.75153

Timestep Collection Time: 3.36068
Timestep Consumption Time: 1.71826
PPO Batch Consumption Time: 0.16229
Total Iteration Time: 5.07894

Cumulative Model Updates: 49,854
Cumulative Timesteps: 415,909,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,720.08371
Policy Entropy: 0.54231
Value Function Loss: 0.10423

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04255
Policy Update Magnitude: 0.18217
Value Function Update Magnitude: 0.41973

Collected Steps per Second: 15,294.92821
Overall Steps per Second: 10,456.49427

Timestep Collection Time: 3.27050
Timestep Consumption Time: 1.51333
PPO Batch Consumption Time: 0.14131
Total Iteration Time: 4.78382

Cumulative Model Updates: 49,860
Cumulative Timesteps: 415,959,834

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 415959834...
Checkpoint 415959834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,238.24115
Policy Entropy: 0.54164
Value Function Loss: 0.10475

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04607
Policy Update Magnitude: 0.18204
Value Function Update Magnitude: 0.42998

Collected Steps per Second: 14,703.01189
Overall Steps per Second: 10,280.79155

Timestep Collection Time: 3.40230
Timestep Consumption Time: 1.46348
PPO Batch Consumption Time: 0.13701
Total Iteration Time: 4.86577

Cumulative Model Updates: 49,866
Cumulative Timesteps: 416,009,858

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,687.70463
Policy Entropy: 0.55357
Value Function Loss: 0.10009

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04651
Policy Update Magnitude: 0.17889
Value Function Update Magnitude: 0.43605

Collected Steps per Second: 15,051.23521
Overall Steps per Second: 10,436.29091

Timestep Collection Time: 3.32385
Timestep Consumption Time: 1.46981
PPO Batch Consumption Time: 0.13938
Total Iteration Time: 4.79366

Cumulative Model Updates: 49,872
Cumulative Timesteps: 416,059,886

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 416059886...
Checkpoint 416059886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,209.80153
Policy Entropy: 0.55440
Value Function Loss: 0.10579

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05243
Policy Update Magnitude: 0.16738
Value Function Update Magnitude: 0.39660

Collected Steps per Second: 14,953.99413
Overall Steps per Second: 10,076.63210

Timestep Collection Time: 3.34386
Timestep Consumption Time: 1.61852
PPO Batch Consumption Time: 0.15310
Total Iteration Time: 4.96237

Cumulative Model Updates: 49,878
Cumulative Timesteps: 416,109,890

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,308.82984
Policy Entropy: 0.54579
Value Function Loss: 0.10313

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06263
Policy Update Magnitude: 0.16710
Value Function Update Magnitude: 0.44128

Collected Steps per Second: 14,917.75505
Overall Steps per Second: 10,289.84906

Timestep Collection Time: 3.35278
Timestep Consumption Time: 1.50793
PPO Batch Consumption Time: 0.13743
Total Iteration Time: 4.86071

Cumulative Model Updates: 49,884
Cumulative Timesteps: 416,159,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 416159906...
Checkpoint 416159906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,565.39517
Policy Entropy: 0.55759
Value Function Loss: 0.10239

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07127
Policy Update Magnitude: 0.15813
Value Function Update Magnitude: 0.46495

Collected Steps per Second: 14,656.29795
Overall Steps per Second: 10,198.26242

Timestep Collection Time: 3.41287
Timestep Consumption Time: 1.49189
PPO Batch Consumption Time: 0.14164
Total Iteration Time: 4.90476

Cumulative Model Updates: 49,890
Cumulative Timesteps: 416,209,926

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,408.68336
Policy Entropy: 0.56215
Value Function Loss: 0.10512

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06952
Policy Update Magnitude: 0.16803
Value Function Update Magnitude: 0.43319

Collected Steps per Second: 15,065.51442
Overall Steps per Second: 10,472.23045

Timestep Collection Time: 3.32136
Timestep Consumption Time: 1.45680
PPO Batch Consumption Time: 0.12922
Total Iteration Time: 4.77816

Cumulative Model Updates: 49,896
Cumulative Timesteps: 416,259,964

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 416259964...
Checkpoint 416259964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,486.99266
Policy Entropy: 0.56253
Value Function Loss: 0.10111

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.06661
Policy Update Magnitude: 0.17385
Value Function Update Magnitude: 0.43362

Collected Steps per Second: 15,002.25214
Overall Steps per Second: 10,320.82068

Timestep Collection Time: 3.33350
Timestep Consumption Time: 1.51205
PPO Batch Consumption Time: 0.13777
Total Iteration Time: 4.84554

Cumulative Model Updates: 49,902
Cumulative Timesteps: 416,309,974

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,787.82860
Policy Entropy: 0.55176
Value Function Loss: 0.10472

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.05956
Policy Update Magnitude: 0.17423
Value Function Update Magnitude: 0.44512

Collected Steps per Second: 14,686.15286
Overall Steps per Second: 10,194.21186

Timestep Collection Time: 3.40525
Timestep Consumption Time: 1.50048
PPO Batch Consumption Time: 0.13732
Total Iteration Time: 4.90572

Cumulative Model Updates: 49,908
Cumulative Timesteps: 416,359,984

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 416359984...
Checkpoint 416359984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,874.62840
Policy Entropy: 0.55188
Value Function Loss: 0.08552

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04771
Policy Update Magnitude: 0.17139
Value Function Update Magnitude: 0.41538

Collected Steps per Second: 14,779.08895
Overall Steps per Second: 10,166.36303

Timestep Collection Time: 3.38329
Timestep Consumption Time: 1.53508
PPO Batch Consumption Time: 0.14064
Total Iteration Time: 4.91838

Cumulative Model Updates: 49,914
Cumulative Timesteps: 416,409,986

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,449.94338
Policy Entropy: 0.55052
Value Function Loss: 0.08987

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.05199
Policy Update Magnitude: 0.17225
Value Function Update Magnitude: 0.41393

Collected Steps per Second: 14,826.50526
Overall Steps per Second: 10,299.51700

Timestep Collection Time: 3.37382
Timestep Consumption Time: 1.48291
PPO Batch Consumption Time: 0.13540
Total Iteration Time: 4.85673

Cumulative Model Updates: 49,920
Cumulative Timesteps: 416,460,008

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 416460008...
Checkpoint 416460008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,800.86718
Policy Entropy: 0.55811
Value Function Loss: 0.09129

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.04969
Policy Update Magnitude: 0.17918
Value Function Update Magnitude: 0.42138

Collected Steps per Second: 14,832.51204
Overall Steps per Second: 10,220.56071

Timestep Collection Time: 3.37354
Timestep Consumption Time: 1.52228
PPO Batch Consumption Time: 0.13936
Total Iteration Time: 4.89582

Cumulative Model Updates: 49,926
Cumulative Timesteps: 416,510,046

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,494.94675
Policy Entropy: 0.56014
Value Function Loss: 0.10217

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04227
Policy Update Magnitude: 0.19157
Value Function Update Magnitude: 0.40846

Collected Steps per Second: 14,719.64058
Overall Steps per Second: 10,214.57239

Timestep Collection Time: 3.39818
Timestep Consumption Time: 1.49874
PPO Batch Consumption Time: 0.13754
Total Iteration Time: 4.89693

Cumulative Model Updates: 49,932
Cumulative Timesteps: 416,560,066

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 416560066...
Checkpoint 416560066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,953.89733
Policy Entropy: 0.56568
Value Function Loss: 0.09652

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05617
Policy Update Magnitude: 0.18825
Value Function Update Magnitude: 0.40020

Collected Steps per Second: 14,765.07194
Overall Steps per Second: 10,170.76844

Timestep Collection Time: 3.38705
Timestep Consumption Time: 1.52999
PPO Batch Consumption Time: 0.13839
Total Iteration Time: 4.91703

Cumulative Model Updates: 49,938
Cumulative Timesteps: 416,610,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,402.48012
Policy Entropy: 0.56009
Value Function Loss: 0.09860

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07124
Policy Update Magnitude: 0.17914
Value Function Update Magnitude: 0.40951

Collected Steps per Second: 15,170.93547
Overall Steps per Second: 10,426.16235

Timestep Collection Time: 3.29591
Timestep Consumption Time: 1.49991
PPO Batch Consumption Time: 0.13674
Total Iteration Time: 4.79582

Cumulative Model Updates: 49,944
Cumulative Timesteps: 416,660,078

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 416660078...
Checkpoint 416660078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,784.64701
Policy Entropy: 0.54141
Value Function Loss: 0.10698

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.06650
Policy Update Magnitude: 0.19271
Value Function Update Magnitude: 0.43627

Collected Steps per Second: 14,880.18725
Overall Steps per Second: 10,230.74545

Timestep Collection Time: 3.36273
Timestep Consumption Time: 1.52822
PPO Batch Consumption Time: 0.14145
Total Iteration Time: 4.89094

Cumulative Model Updates: 49,950
Cumulative Timesteps: 416,710,116

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,560.47843
Policy Entropy: 0.53763
Value Function Loss: 0.12368

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07500
Policy Update Magnitude: 0.19662
Value Function Update Magnitude: 0.46985

Collected Steps per Second: 14,605.33512
Overall Steps per Second: 10,136.84908

Timestep Collection Time: 3.42395
Timestep Consumption Time: 1.50933
PPO Batch Consumption Time: 0.13660
Total Iteration Time: 4.93329

Cumulative Model Updates: 49,956
Cumulative Timesteps: 416,760,124

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 416760124...
Checkpoint 416760124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,374.44455
Policy Entropy: 0.54393
Value Function Loss: 0.12117

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.09500
Policy Update Magnitude: 0.17888
Value Function Update Magnitude: 0.49291

Collected Steps per Second: 14,972.80770
Overall Steps per Second: 10,375.03719

Timestep Collection Time: 3.34179
Timestep Consumption Time: 1.48094
PPO Batch Consumption Time: 0.13979
Total Iteration Time: 4.82273

Cumulative Model Updates: 49,962
Cumulative Timesteps: 416,810,160

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,931.70575
Policy Entropy: 0.56054
Value Function Loss: 0.10980

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08865
Policy Update Magnitude: 0.16693
Value Function Update Magnitude: 0.46380

Collected Steps per Second: 15,112.28738
Overall Steps per Second: 10,440.71182

Timestep Collection Time: 3.30923
Timestep Consumption Time: 1.48068
PPO Batch Consumption Time: 0.13832
Total Iteration Time: 4.78990

Cumulative Model Updates: 49,968
Cumulative Timesteps: 416,860,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 416860170...
Checkpoint 416860170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,911.70477
Policy Entropy: 0.55722
Value Function Loss: 0.10449

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.16545
Value Function Update Magnitude: 0.40017

Collected Steps per Second: 14,952.30121
Overall Steps per Second: 10,242.53776

Timestep Collection Time: 3.34584
Timestep Consumption Time: 1.53850
PPO Batch Consumption Time: 0.14381
Total Iteration Time: 4.88434

Cumulative Model Updates: 49,974
Cumulative Timesteps: 416,910,198

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,610.87343
Policy Entropy: 0.55599
Value Function Loss: 0.10411

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.15661
Value Function Update Magnitude: 0.37651

Collected Steps per Second: 14,202.98831
Overall Steps per Second: 9,941.85316

Timestep Collection Time: 3.52208
Timestep Consumption Time: 1.50958
PPO Batch Consumption Time: 0.13686
Total Iteration Time: 5.03166

Cumulative Model Updates: 49,980
Cumulative Timesteps: 416,960,222

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 416960222...
Checkpoint 416960222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,623.00763
Policy Entropy: 0.55986
Value Function Loss: 0.10714

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.06498
Policy Update Magnitude: 0.16723
Value Function Update Magnitude: 0.37774

Collected Steps per Second: 14,997.43752
Overall Steps per Second: 10,300.21123

Timestep Collection Time: 3.33564
Timestep Consumption Time: 1.52116
PPO Batch Consumption Time: 0.13998
Total Iteration Time: 4.85679

Cumulative Model Updates: 49,986
Cumulative Timesteps: 417,010,248

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,420.38372
Policy Entropy: 0.55966
Value Function Loss: 0.10979

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07177
Policy Update Magnitude: 0.16444
Value Function Update Magnitude: 0.37000

Collected Steps per Second: 15,070.69772
Overall Steps per Second: 10,380.07386

Timestep Collection Time: 3.31889
Timestep Consumption Time: 1.49976
PPO Batch Consumption Time: 0.13687
Total Iteration Time: 4.81866

Cumulative Model Updates: 49,992
Cumulative Timesteps: 417,060,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 417060266...
Checkpoint 417060266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,404.95580
Policy Entropy: 0.55756
Value Function Loss: 0.11512

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.07111
Policy Update Magnitude: 0.16153
Value Function Update Magnitude: 0.35286

Collected Steps per Second: 14,950.01382
Overall Steps per Second: 10,246.07811

Timestep Collection Time: 3.34649
Timestep Consumption Time: 1.53636
PPO Batch Consumption Time: 0.14289
Total Iteration Time: 4.88284

Cumulative Model Updates: 49,998
Cumulative Timesteps: 417,110,296

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,114.03713
Policy Entropy: 0.55477
Value Function Loss: 0.11569

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05537
Policy Update Magnitude: 0.17362
Value Function Update Magnitude: 0.34547

Collected Steps per Second: 14,504.29447
Overall Steps per Second: 10,092.58633

Timestep Collection Time: 3.44850
Timestep Consumption Time: 1.50742
PPO Batch Consumption Time: 0.13903
Total Iteration Time: 4.95592

Cumulative Model Updates: 50,004
Cumulative Timesteps: 417,160,314

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 417160314...
Checkpoint 417160314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,056.34875
Policy Entropy: 0.55267
Value Function Loss: 0.12303

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06050
Policy Update Magnitude: 0.19082
Value Function Update Magnitude: 0.33253

Collected Steps per Second: 15,145.57373
Overall Steps per Second: 10,282.99374

Timestep Collection Time: 3.30143
Timestep Consumption Time: 1.56117
PPO Batch Consumption Time: 0.14357
Total Iteration Time: 4.86259

Cumulative Model Updates: 50,010
Cumulative Timesteps: 417,210,316

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,439.12067
Policy Entropy: 0.55566
Value Function Loss: 0.11834

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.06771
Policy Update Magnitude: 0.16777
Value Function Update Magnitude: 0.33556

Collected Steps per Second: 14,672.03495
Overall Steps per Second: 10,142.34165

Timestep Collection Time: 3.40812
Timestep Consumption Time: 1.52211
PPO Batch Consumption Time: 0.13828
Total Iteration Time: 4.93022

Cumulative Model Updates: 50,016
Cumulative Timesteps: 417,260,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 417260320...
Checkpoint 417260320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,718.91384
Policy Entropy: 0.56241
Value Function Loss: 0.11182

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06116
Policy Update Magnitude: 0.16540
Value Function Update Magnitude: 0.38951

Collected Steps per Second: 14,961.40723
Overall Steps per Second: 10,250.88456

Timestep Collection Time: 3.34327
Timestep Consumption Time: 1.53631
PPO Batch Consumption Time: 0.13965
Total Iteration Time: 4.87958

Cumulative Model Updates: 50,022
Cumulative Timesteps: 417,310,340

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,695.70789
Policy Entropy: 0.55883
Value Function Loss: 0.09787

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.05758
Policy Update Magnitude: 0.18177
Value Function Update Magnitude: 0.37728

Collected Steps per Second: 14,440.20518
Overall Steps per Second: 10,038.84685

Timestep Collection Time: 3.46394
Timestep Consumption Time: 1.51870
PPO Batch Consumption Time: 0.13828
Total Iteration Time: 4.98264

Cumulative Model Updates: 50,028
Cumulative Timesteps: 417,360,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 417360360...
Checkpoint 417360360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,965.39273
Policy Entropy: 0.56458
Value Function Loss: 0.09180

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.05612
Policy Update Magnitude: 0.17949
Value Function Update Magnitude: 0.34169

Collected Steps per Second: 14,807.29345
Overall Steps per Second: 10,192.07398

Timestep Collection Time: 3.37685
Timestep Consumption Time: 1.52912
PPO Batch Consumption Time: 0.14193
Total Iteration Time: 4.90597

Cumulative Model Updates: 50,034
Cumulative Timesteps: 417,410,362

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,222.60122
Policy Entropy: 0.56307
Value Function Loss: 0.09277

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07405
Policy Update Magnitude: 0.17193
Value Function Update Magnitude: 0.32953

Collected Steps per Second: 15,002.39093
Overall Steps per Second: 10,355.60098

Timestep Collection Time: 3.33280
Timestep Consumption Time: 1.49550
PPO Batch Consumption Time: 0.13622
Total Iteration Time: 4.82831

Cumulative Model Updates: 50,040
Cumulative Timesteps: 417,460,362

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 417460362...
Checkpoint 417460362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,276.95125
Policy Entropy: 0.56491
Value Function Loss: 0.10581

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.10474
Policy Update Magnitude: 0.15166
Value Function Update Magnitude: 0.35999

Collected Steps per Second: 15,122.72713
Overall Steps per Second: 10,366.75470

Timestep Collection Time: 3.30972
Timestep Consumption Time: 1.51841
PPO Batch Consumption Time: 0.13916
Total Iteration Time: 4.82813

Cumulative Model Updates: 50,046
Cumulative Timesteps: 417,510,414

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,061.01104
Policy Entropy: 0.56432
Value Function Loss: 0.10950

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.09001
Policy Update Magnitude: 0.13944
Value Function Update Magnitude: 0.41412

Collected Steps per Second: 14,568.00277
Overall Steps per Second: 10,023.86281

Timestep Collection Time: 3.43506
Timestep Consumption Time: 1.55722
PPO Batch Consumption Time: 0.14309
Total Iteration Time: 4.99229

Cumulative Model Updates: 50,052
Cumulative Timesteps: 417,560,456

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 417560456...
Checkpoint 417560456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,155.49885
Policy Entropy: 0.55044
Value Function Loss: 0.11920

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07351
Policy Update Magnitude: 0.14856
Value Function Update Magnitude: 0.37376

Collected Steps per Second: 15,305.66458
Overall Steps per Second: 10,440.20355

Timestep Collection Time: 3.26938
Timestep Consumption Time: 1.52363
PPO Batch Consumption Time: 0.14034
Total Iteration Time: 4.79301

Cumulative Model Updates: 50,058
Cumulative Timesteps: 417,610,496

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,349.65856
Policy Entropy: 0.54235
Value Function Loss: 0.11564

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.06926
Policy Update Magnitude: 0.16629
Value Function Update Magnitude: 0.35870

Collected Steps per Second: 15,026.12088
Overall Steps per Second: 10,290.31950

Timestep Collection Time: 3.32887
Timestep Consumption Time: 1.53201
PPO Batch Consumption Time: 0.14102
Total Iteration Time: 4.86088

Cumulative Model Updates: 50,064
Cumulative Timesteps: 417,660,516

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 417660516...
Checkpoint 417660516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,729.59253
Policy Entropy: 0.54576
Value Function Loss: 0.11803

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.06747
Policy Update Magnitude: 0.18169
Value Function Update Magnitude: 0.40767

Collected Steps per Second: 15,043.05476
Overall Steps per Second: 10,329.52673

Timestep Collection Time: 3.32432
Timestep Consumption Time: 1.51694
PPO Batch Consumption Time: 0.14216
Total Iteration Time: 4.84127

Cumulative Model Updates: 50,070
Cumulative Timesteps: 417,710,524

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,713.07842
Policy Entropy: 0.54924
Value Function Loss: 0.10919

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07792
Policy Update Magnitude: 0.18844
Value Function Update Magnitude: 0.43814

Collected Steps per Second: 14,761.53169
Overall Steps per Second: 10,077.07759

Timestep Collection Time: 3.38800
Timestep Consumption Time: 1.57495
PPO Batch Consumption Time: 0.14335
Total Iteration Time: 4.96295

Cumulative Model Updates: 50,076
Cumulative Timesteps: 417,760,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 417760536...
Checkpoint 417760536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,605.33205
Policy Entropy: 0.54135
Value Function Loss: 0.11146

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08237
Policy Update Magnitude: 0.17045
Value Function Update Magnitude: 0.45247

Collected Steps per Second: 15,141.34444
Overall Steps per Second: 10,314.28320

Timestep Collection Time: 3.30420
Timestep Consumption Time: 1.54636
PPO Batch Consumption Time: 0.14131
Total Iteration Time: 4.85056

Cumulative Model Updates: 50,082
Cumulative Timesteps: 417,810,566

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,741.36834
Policy Entropy: 0.54409
Value Function Loss: 0.11258

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07409
Policy Update Magnitude: 0.17767
Value Function Update Magnitude: 0.42635

Collected Steps per Second: 14,931.97726
Overall Steps per Second: 10,350.13928

Timestep Collection Time: 3.34865
Timestep Consumption Time: 1.48239
PPO Batch Consumption Time: 0.13771
Total Iteration Time: 4.83105

Cumulative Model Updates: 50,088
Cumulative Timesteps: 417,860,568

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 417860568...
Checkpoint 417860568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,089.84830
Policy Entropy: 0.54752
Value Function Loss: 0.10563

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07824
Policy Update Magnitude: 0.16881
Value Function Update Magnitude: 0.42789

Collected Steps per Second: 15,091.13082
Overall Steps per Second: 10,333.33049

Timestep Collection Time: 3.31400
Timestep Consumption Time: 1.52587
PPO Batch Consumption Time: 0.13992
Total Iteration Time: 4.83987

Cumulative Model Updates: 50,094
Cumulative Timesteps: 417,910,580

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,748.15061
Policy Entropy: 0.54537
Value Function Loss: 0.10699

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.15916
Value Function Update Magnitude: 0.44077

Collected Steps per Second: 13,953.31302
Overall Steps per Second: 9,570.22581

Timestep Collection Time: 3.58352
Timestep Consumption Time: 1.64122
PPO Batch Consumption Time: 0.14921
Total Iteration Time: 5.22475

Cumulative Model Updates: 50,100
Cumulative Timesteps: 417,960,582

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 417960582...
Checkpoint 417960582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,237.72133
Policy Entropy: 0.55489
Value Function Loss: 0.11201

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07830
Policy Update Magnitude: 0.17445
Value Function Update Magnitude: 0.40052

Collected Steps per Second: 14,329.38020
Overall Steps per Second: 10,037.05389

Timestep Collection Time: 3.49171
Timestep Consumption Time: 1.49322
PPO Batch Consumption Time: 0.13614
Total Iteration Time: 4.98493

Cumulative Model Updates: 50,106
Cumulative Timesteps: 418,010,616

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,091.05530
Policy Entropy: 0.55512
Value Function Loss: 0.11407

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08315
Policy Update Magnitude: 0.17567
Value Function Update Magnitude: 0.39853

Collected Steps per Second: 14,994.69746
Overall Steps per Second: 10,376.72080

Timestep Collection Time: 3.33651
Timestep Consumption Time: 1.48486
PPO Batch Consumption Time: 0.13687
Total Iteration Time: 4.82137

Cumulative Model Updates: 50,112
Cumulative Timesteps: 418,060,646

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 418060646...
Checkpoint 418060646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,168.33340
Policy Entropy: 0.55339
Value Function Loss: 0.11485

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06468
Policy Update Magnitude: 0.17301
Value Function Update Magnitude: 0.38942

Collected Steps per Second: 14,967.32699
Overall Steps per Second: 10,297.61835

Timestep Collection Time: 3.34088
Timestep Consumption Time: 1.51500
PPO Batch Consumption Time: 0.13937
Total Iteration Time: 4.85588

Cumulative Model Updates: 50,118
Cumulative Timesteps: 418,110,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,331.70282
Policy Entropy: 0.54816
Value Function Loss: 0.10234

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06272
Policy Update Magnitude: 0.18210
Value Function Update Magnitude: 0.38626

Collected Steps per Second: 14,744.89579
Overall Steps per Second: 9,766.21510

Timestep Collection Time: 3.39250
Timestep Consumption Time: 1.72945
PPO Batch Consumption Time: 0.16019
Total Iteration Time: 5.12194

Cumulative Model Updates: 50,124
Cumulative Timesteps: 418,160,672

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 418160672...
Checkpoint 418160672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,787.62955
Policy Entropy: 0.54267
Value Function Loss: 0.11285

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.05133
Policy Update Magnitude: 0.17159
Value Function Update Magnitude: 0.37407

Collected Steps per Second: 14,116.75779
Overall Steps per Second: 9,881.73335

Timestep Collection Time: 3.54288
Timestep Consumption Time: 1.51838
PPO Batch Consumption Time: 0.13549
Total Iteration Time: 5.06126

Cumulative Model Updates: 50,130
Cumulative Timesteps: 418,210,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,848.04089
Policy Entropy: 0.53745
Value Function Loss: 0.11088

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.05832
Policy Update Magnitude: 0.17550
Value Function Update Magnitude: 0.37444

Collected Steps per Second: 14,976.78670
Overall Steps per Second: 10,276.85090

Timestep Collection Time: 3.34037
Timestep Consumption Time: 1.52766
PPO Batch Consumption Time: 0.14063
Total Iteration Time: 4.86803

Cumulative Model Updates: 50,136
Cumulative Timesteps: 418,260,714

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 418260714...
Checkpoint 418260714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,411.59449
Policy Entropy: 0.53566
Value Function Loss: 0.10565

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07476
Policy Update Magnitude: 0.16077
Value Function Update Magnitude: 0.36245

Collected Steps per Second: 14,906.79245
Overall Steps per Second: 10,307.46601

Timestep Collection Time: 3.35431
Timestep Consumption Time: 1.49674
PPO Batch Consumption Time: 0.13741
Total Iteration Time: 4.85105

Cumulative Model Updates: 50,142
Cumulative Timesteps: 418,310,716

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,165.90367
Policy Entropy: 0.53355
Value Function Loss: 0.10201

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.06556
Policy Update Magnitude: 0.17754
Value Function Update Magnitude: 0.38029

Collected Steps per Second: 14,763.91957
Overall Steps per Second: 9,887.97744

Timestep Collection Time: 3.38758
Timestep Consumption Time: 1.67048
PPO Batch Consumption Time: 0.16403
Total Iteration Time: 5.05806

Cumulative Model Updates: 50,148
Cumulative Timesteps: 418,360,730

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 418360730...
Checkpoint 418360730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,365.28059
Policy Entropy: 0.53527
Value Function Loss: 0.10646

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05001
Policy Update Magnitude: 0.18368
Value Function Update Magnitude: 0.40815

Collected Steps per Second: 14,859.04541
Overall Steps per Second: 10,320.78699

Timestep Collection Time: 3.36576
Timestep Consumption Time: 1.47999
PPO Batch Consumption Time: 0.13544
Total Iteration Time: 4.84575

Cumulative Model Updates: 50,154
Cumulative Timesteps: 418,410,742

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,290.46075
Policy Entropy: 0.53570
Value Function Loss: 0.11190

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.05117
Policy Update Magnitude: 0.19026
Value Function Update Magnitude: 0.45253

Collected Steps per Second: 14,950.65165
Overall Steps per Second: 10,311.08039

Timestep Collection Time: 3.34701
Timestep Consumption Time: 1.50602
PPO Batch Consumption Time: 0.13867
Total Iteration Time: 4.85303

Cumulative Model Updates: 50,160
Cumulative Timesteps: 418,460,782

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 418460782...
Checkpoint 418460782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,929.93943
Policy Entropy: 0.53877
Value Function Loss: 0.10539

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05536
Policy Update Magnitude: 0.18317
Value Function Update Magnitude: 0.43806

Collected Steps per Second: 14,794.97759
Overall Steps per Second: 10,240.72605

Timestep Collection Time: 3.38115
Timestep Consumption Time: 1.50366
PPO Batch Consumption Time: 0.13767
Total Iteration Time: 4.88481

Cumulative Model Updates: 50,166
Cumulative Timesteps: 418,510,806

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,110.98718
Policy Entropy: 0.54464
Value Function Loss: 0.10638

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07112
Policy Update Magnitude: 0.17157
Value Function Update Magnitude: 0.41579

Collected Steps per Second: 14,878.25809
Overall Steps per Second: 9,957.02902

Timestep Collection Time: 3.36249
Timestep Consumption Time: 1.66190
PPO Batch Consumption Time: 0.16145
Total Iteration Time: 5.02439

Cumulative Model Updates: 50,172
Cumulative Timesteps: 418,560,834

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 418560834...
Checkpoint 418560834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,077.13677
Policy Entropy: 0.55185
Value Function Loss: 0.10427

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08452
Policy Update Magnitude: 0.16193
Value Function Update Magnitude: 0.45552

Collected Steps per Second: 14,636.77843
Overall Steps per Second: 10,161.81802

Timestep Collection Time: 3.41879
Timestep Consumption Time: 1.50553
PPO Batch Consumption Time: 0.13790
Total Iteration Time: 4.92432

Cumulative Model Updates: 50,178
Cumulative Timesteps: 418,610,874

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,889.86274
Policy Entropy: 0.54823
Value Function Loss: 0.10588

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08065
Policy Update Magnitude: 0.16037
Value Function Update Magnitude: 0.47416

Collected Steps per Second: 15,170.05169
Overall Steps per Second: 10,419.58808

Timestep Collection Time: 3.29742
Timestep Consumption Time: 1.50335
PPO Batch Consumption Time: 0.13767
Total Iteration Time: 4.80077

Cumulative Model Updates: 50,184
Cumulative Timesteps: 418,660,896

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 418660896...
Checkpoint 418660896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,536.03508
Policy Entropy: 0.55257
Value Function Loss: 0.10135

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.07097
Policy Update Magnitude: 0.16784
Value Function Update Magnitude: 0.48287

Collected Steps per Second: 14,901.84709
Overall Steps per Second: 10,259.83175

Timestep Collection Time: 3.35811
Timestep Consumption Time: 1.51936
PPO Batch Consumption Time: 0.13791
Total Iteration Time: 4.87747

Cumulative Model Updates: 50,190
Cumulative Timesteps: 418,710,938

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,018.84372
Policy Entropy: 0.54647
Value Function Loss: 0.10318

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05303
Policy Update Magnitude: 0.17694
Value Function Update Magnitude: 0.47624

Collected Steps per Second: 14,994.82278
Overall Steps per Second: 9,903.85721

Timestep Collection Time: 3.33528
Timestep Consumption Time: 1.71447
PPO Batch Consumption Time: 0.16272
Total Iteration Time: 5.04975

Cumulative Model Updates: 50,196
Cumulative Timesteps: 418,760,950

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 418760950...
Checkpoint 418760950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,280.83707
Policy Entropy: 0.54590
Value Function Loss: 0.09831

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04960
Policy Update Magnitude: 0.17984
Value Function Update Magnitude: 0.47535

Collected Steps per Second: 14,493.16768
Overall Steps per Second: 10,086.56563

Timestep Collection Time: 3.45114
Timestep Consumption Time: 1.50773
PPO Batch Consumption Time: 0.13899
Total Iteration Time: 4.95887

Cumulative Model Updates: 50,202
Cumulative Timesteps: 418,810,968

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,748.39507
Policy Entropy: 0.54311
Value Function Loss: 0.11144

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05199
Policy Update Magnitude: 0.17372
Value Function Update Magnitude: 0.48315

Collected Steps per Second: 15,074.45509
Overall Steps per Second: 10,299.79930

Timestep Collection Time: 3.31886
Timestep Consumption Time: 1.53852
PPO Batch Consumption Time: 0.14092
Total Iteration Time: 4.85738

Cumulative Model Updates: 50,208
Cumulative Timesteps: 418,860,998

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 418860998...
Checkpoint 418860998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,414.16738
Policy Entropy: 0.55244
Value Function Loss: 0.10633

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.06848
Policy Update Magnitude: 0.16019
Value Function Update Magnitude: 0.48637

Collected Steps per Second: 14,805.73720
Overall Steps per Second: 10,240.49110

Timestep Collection Time: 3.37991
Timestep Consumption Time: 1.50677
PPO Batch Consumption Time: 0.13891
Total Iteration Time: 4.88668

Cumulative Model Updates: 50,214
Cumulative Timesteps: 418,911,040

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,427.30674
Policy Entropy: 0.55228
Value Function Loss: 0.10220

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.06839
Policy Update Magnitude: 0.15561
Value Function Update Magnitude: 0.46684

Collected Steps per Second: 15,265.56161
Overall Steps per Second: 10,414.95399

Timestep Collection Time: 3.27770
Timestep Consumption Time: 1.52654
PPO Batch Consumption Time: 0.14067
Total Iteration Time: 4.80425

Cumulative Model Updates: 50,220
Cumulative Timesteps: 418,961,076

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 418961076...
Checkpoint 418961076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,080.93478
Policy Entropy: 0.54781
Value Function Loss: 0.10008

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.06783
Policy Update Magnitude: 0.14683
Value Function Update Magnitude: 0.43694

Collected Steps per Second: 14,562.91584
Overall Steps per Second: 10,194.76726

Timestep Collection Time: 3.43434
Timestep Consumption Time: 1.47151
PPO Batch Consumption Time: 0.13687
Total Iteration Time: 4.90585

Cumulative Model Updates: 50,226
Cumulative Timesteps: 419,011,090

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,356.11143
Policy Entropy: 0.53678
Value Function Loss: 0.09961

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07189
Policy Update Magnitude: 0.14805
Value Function Update Magnitude: 0.42611

Collected Steps per Second: 15,337.93285
Overall Steps per Second: 10,392.81170

Timestep Collection Time: 3.25989
Timestep Consumption Time: 1.55113
PPO Batch Consumption Time: 0.13902
Total Iteration Time: 4.81102

Cumulative Model Updates: 50,232
Cumulative Timesteps: 419,061,090

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 419061090...
Checkpoint 419061090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,949.78150
Policy Entropy: 0.54195
Value Function Loss: 0.10028

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05877
Policy Update Magnitude: 0.15987
Value Function Update Magnitude: 0.40028

Collected Steps per Second: 15,044.01823
Overall Steps per Second: 10,319.15380

Timestep Collection Time: 3.32504
Timestep Consumption Time: 1.52245
PPO Batch Consumption Time: 0.13878
Total Iteration Time: 4.84749

Cumulative Model Updates: 50,238
Cumulative Timesteps: 419,111,112

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,710.39046
Policy Entropy: 0.53557
Value Function Loss: 0.10033

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05338
Policy Update Magnitude: 0.16879
Value Function Update Magnitude: 0.39481

Collected Steps per Second: 15,323.29448
Overall Steps per Second: 10,419.55559

Timestep Collection Time: 3.26314
Timestep Consumption Time: 1.53572
PPO Batch Consumption Time: 0.14087
Total Iteration Time: 4.79886

Cumulative Model Updates: 50,244
Cumulative Timesteps: 419,161,114

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 419161114...
Checkpoint 419161114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,882.29530
Policy Entropy: 0.53874
Value Function Loss: 0.10256

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05221
Policy Update Magnitude: 0.16818
Value Function Update Magnitude: 0.40063

Collected Steps per Second: 14,426.44816
Overall Steps per Second: 10,077.04951

Timestep Collection Time: 3.46683
Timestep Consumption Time: 1.49633
PPO Batch Consumption Time: 0.13376
Total Iteration Time: 4.96316

Cumulative Model Updates: 50,250
Cumulative Timesteps: 419,211,128

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,508.68542
Policy Entropy: 0.52716
Value Function Loss: 0.10726

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05483
Policy Update Magnitude: 0.17544
Value Function Update Magnitude: 0.42930

Collected Steps per Second: 15,073.65610
Overall Steps per Second: 10,283.35971

Timestep Collection Time: 3.31771
Timestep Consumption Time: 1.54549
PPO Batch Consumption Time: 0.14130
Total Iteration Time: 4.86320

Cumulative Model Updates: 50,256
Cumulative Timesteps: 419,261,138

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 419261138...
Checkpoint 419261138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,472.12567
Policy Entropy: 0.53097
Value Function Loss: 0.11300

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05457
Policy Update Magnitude: 0.17980
Value Function Update Magnitude: 0.44234

Collected Steps per Second: 14,889.29901
Overall Steps per Second: 10,314.15007

Timestep Collection Time: 3.36000
Timestep Consumption Time: 1.49043
PPO Batch Consumption Time: 0.13838
Total Iteration Time: 4.85042

Cumulative Model Updates: 50,262
Cumulative Timesteps: 419,311,166

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,744.33777
Policy Entropy: 0.53135
Value Function Loss: 0.11761

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.05999
Policy Update Magnitude: 0.18173
Value Function Update Magnitude: 0.44263

Collected Steps per Second: 15,222.18586
Overall Steps per Second: 10,462.08986

Timestep Collection Time: 3.28652
Timestep Consumption Time: 1.49532
PPO Batch Consumption Time: 0.13933
Total Iteration Time: 4.78184

Cumulative Model Updates: 50,268
Cumulative Timesteps: 419,361,194

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 419361194...
Checkpoint 419361194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,916.35167
Policy Entropy: 0.53990
Value Function Loss: 0.11169

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05906
Policy Update Magnitude: 0.17729
Value Function Update Magnitude: 0.46181

Collected Steps per Second: 14,311.07562
Overall Steps per Second: 10,091.54828

Timestep Collection Time: 3.49492
Timestep Consumption Time: 1.46131
PPO Batch Consumption Time: 0.13651
Total Iteration Time: 4.95623

Cumulative Model Updates: 50,274
Cumulative Timesteps: 419,411,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,225.52866
Policy Entropy: 0.55037
Value Function Loss: 0.10475

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.04790
Policy Update Magnitude: 0.18018
Value Function Update Magnitude: 0.47291

Collected Steps per Second: 15,063.00539
Overall Steps per Second: 10,355.15232

Timestep Collection Time: 3.31939
Timestep Consumption Time: 1.50912
PPO Batch Consumption Time: 0.13828
Total Iteration Time: 4.82851

Cumulative Model Updates: 50,280
Cumulative Timesteps: 419,461,210

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 419461210...
Checkpoint 419461210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,312.35474
Policy Entropy: 0.55337
Value Function Loss: 0.10471

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05423
Policy Update Magnitude: 0.17915
Value Function Update Magnitude: 0.46979

Collected Steps per Second: 14,437.32678
Overall Steps per Second: 10,118.96609

Timestep Collection Time: 3.46643
Timestep Consumption Time: 1.47933
PPO Batch Consumption Time: 0.13487
Total Iteration Time: 4.94576

Cumulative Model Updates: 50,286
Cumulative Timesteps: 419,511,256

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,297.24328
Policy Entropy: 0.55354
Value Function Loss: 0.10718

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04971
Policy Update Magnitude: 0.17850
Value Function Update Magnitude: 0.45913

Collected Steps per Second: 15,174.17969
Overall Steps per Second: 10,389.20468

Timestep Collection Time: 3.29797
Timestep Consumption Time: 1.51895
PPO Batch Consumption Time: 0.14044
Total Iteration Time: 4.81692

Cumulative Model Updates: 50,292
Cumulative Timesteps: 419,561,300

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 419561300...
Checkpoint 419561300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,760.90440
Policy Entropy: 0.55338
Value Function Loss: 0.10871

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03968
Policy Update Magnitude: 0.18384
Value Function Update Magnitude: 0.44360

Collected Steps per Second: 14,157.72316
Overall Steps per Second: 9,933.70625

Timestep Collection Time: 3.53334
Timestep Consumption Time: 1.50245
PPO Batch Consumption Time: 0.13752
Total Iteration Time: 5.03578

Cumulative Model Updates: 50,298
Cumulative Timesteps: 419,611,324

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,661.97697
Policy Entropy: 0.54034
Value Function Loss: 0.10975

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04327
Policy Update Magnitude: 0.18537
Value Function Update Magnitude: 0.45667

Collected Steps per Second: 15,316.47849
Overall Steps per Second: 10,504.95138

Timestep Collection Time: 3.26537
Timestep Consumption Time: 1.49562
PPO Batch Consumption Time: 0.13730
Total Iteration Time: 4.76099

Cumulative Model Updates: 50,304
Cumulative Timesteps: 419,661,338

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 419661338...
Checkpoint 419661338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,276.67324
Policy Entropy: 0.53803
Value Function Loss: 0.11949

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.07332
Policy Update Magnitude: 0.16644
Value Function Update Magnitude: 0.44614

Collected Steps per Second: 14,912.07457
Overall Steps per Second: 10,293.78446

Timestep Collection Time: 3.35419
Timestep Consumption Time: 1.50485
PPO Batch Consumption Time: 0.13709
Total Iteration Time: 4.85905

Cumulative Model Updates: 50,310
Cumulative Timesteps: 419,711,356

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,677.74942
Policy Entropy: 0.53768
Value Function Loss: 0.12627

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07364
Policy Update Magnitude: 0.16969
Value Function Update Magnitude: 0.39886

Collected Steps per Second: 15,320.51932
Overall Steps per Second: 10,511.39082

Timestep Collection Time: 3.26556
Timestep Consumption Time: 1.49404
PPO Batch Consumption Time: 0.13711
Total Iteration Time: 4.75960

Cumulative Model Updates: 50,316
Cumulative Timesteps: 419,761,386

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 419761386...
Checkpoint 419761386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,158.53405
Policy Entropy: 0.54430
Value Function Loss: 0.12905

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.08754
Policy Update Magnitude: 0.17429
Value Function Update Magnitude: 0.39531

Collected Steps per Second: 14,467.19907
Overall Steps per Second: 10,110.75908

Timestep Collection Time: 3.45734
Timestep Consumption Time: 1.48967
PPO Batch Consumption Time: 0.13882
Total Iteration Time: 4.94701

Cumulative Model Updates: 50,322
Cumulative Timesteps: 419,811,404

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,332.10851
Policy Entropy: 0.54347
Value Function Loss: 0.12868

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.09222
Policy Update Magnitude: 0.16851
Value Function Update Magnitude: 0.43104

Collected Steps per Second: 15,212.49756
Overall Steps per Second: 10,419.92385

Timestep Collection Time: 3.28756
Timestep Consumption Time: 1.51209
PPO Batch Consumption Time: 0.13918
Total Iteration Time: 4.79965

Cumulative Model Updates: 50,328
Cumulative Timesteps: 419,861,416

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 419861416...
Checkpoint 419861416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,570.69090
Policy Entropy: 0.54734
Value Function Loss: 0.11931

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.08595
Policy Update Magnitude: 0.15325
Value Function Update Magnitude: 0.43819

Collected Steps per Second: 14,875.55463
Overall Steps per Second: 10,295.82253

Timestep Collection Time: 3.36256
Timestep Consumption Time: 1.49572
PPO Batch Consumption Time: 0.14184
Total Iteration Time: 4.85828

Cumulative Model Updates: 50,334
Cumulative Timesteps: 419,911,436

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,414.46731
Policy Entropy: 0.53620
Value Function Loss: 0.11486

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07275
Policy Update Magnitude: 0.14781
Value Function Update Magnitude: 0.41830

Collected Steps per Second: 15,327.75672
Overall Steps per Second: 10,508.51747

Timestep Collection Time: 3.26388
Timestep Consumption Time: 1.49683
PPO Batch Consumption Time: 0.13606
Total Iteration Time: 4.76071

Cumulative Model Updates: 50,340
Cumulative Timesteps: 419,961,464

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 419961464...
Checkpoint 419961464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,574.78122
Policy Entropy: 0.53309
Value Function Loss: 0.10490

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.06704
Policy Update Magnitude: 0.15692
Value Function Update Magnitude: 0.44287

Collected Steps per Second: 14,726.40522
Overall Steps per Second: 10,139.40352

Timestep Collection Time: 3.39621
Timestep Consumption Time: 1.53642
PPO Batch Consumption Time: 0.13827
Total Iteration Time: 4.93264

Cumulative Model Updates: 50,346
Cumulative Timesteps: 420,011,478

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,084.71818
Policy Entropy: 0.53218
Value Function Loss: 0.11039

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06664
Policy Update Magnitude: 0.15144
Value Function Update Magnitude: 0.42748

Collected Steps per Second: 15,108.99191
Overall Steps per Second: 10,432.82872

Timestep Collection Time: 3.31127
Timestep Consumption Time: 1.48417
PPO Batch Consumption Time: 0.13625
Total Iteration Time: 4.79544

Cumulative Model Updates: 50,352
Cumulative Timesteps: 420,061,508

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 420061508...
Checkpoint 420061508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,856.33320
Policy Entropy: 0.54185
Value Function Loss: 0.11793

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06160
Policy Update Magnitude: 0.16681
Value Function Update Magnitude: 0.36793

Collected Steps per Second: 14,932.25671
Overall Steps per Second: 10,252.15219

Timestep Collection Time: 3.34953
Timestep Consumption Time: 1.52906
PPO Batch Consumption Time: 0.13944
Total Iteration Time: 4.87859

Cumulative Model Updates: 50,358
Cumulative Timesteps: 420,111,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,133.65653
Policy Entropy: 0.53574
Value Function Loss: 0.12000

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.06575
Policy Update Magnitude: 0.17788
Value Function Update Magnitude: 0.36847

Collected Steps per Second: 14,991.62995
Overall Steps per Second: 10,335.78236

Timestep Collection Time: 3.33720
Timestep Consumption Time: 1.50327
PPO Batch Consumption Time: 0.13837
Total Iteration Time: 4.84047

Cumulative Model Updates: 50,364
Cumulative Timesteps: 420,161,554

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 420161554...
Checkpoint 420161554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,527.73497
Policy Entropy: 0.53202
Value Function Loss: 0.11487

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07453
Policy Update Magnitude: 0.16306
Value Function Update Magnitude: 0.45117

Collected Steps per Second: 14,932.94106
Overall Steps per Second: 10,143.25991

Timestep Collection Time: 3.34897
Timestep Consumption Time: 1.58140
PPO Batch Consumption Time: 0.14666
Total Iteration Time: 4.93037

Cumulative Model Updates: 50,370
Cumulative Timesteps: 420,211,564

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,212.53972
Policy Entropy: 0.53662
Value Function Loss: 0.10481

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07913
Policy Update Magnitude: 0.14543
Value Function Update Magnitude: 0.44969

Collected Steps per Second: 15,121.57002
Overall Steps per Second: 10,369.90454

Timestep Collection Time: 3.30984
Timestep Consumption Time: 1.51663
PPO Batch Consumption Time: 0.13810
Total Iteration Time: 4.82647

Cumulative Model Updates: 50,376
Cumulative Timesteps: 420,261,614

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 420261614...
Checkpoint 420261614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,090.02448
Policy Entropy: 0.54509
Value Function Loss: 0.10382

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07070
Policy Update Magnitude: 0.14873
Value Function Update Magnitude: 0.40483

Collected Steps per Second: 14,929.26366
Overall Steps per Second: 10,340.54767

Timestep Collection Time: 3.35181
Timestep Consumption Time: 1.48740
PPO Batch Consumption Time: 0.13916
Total Iteration Time: 4.83920

Cumulative Model Updates: 50,382
Cumulative Timesteps: 420,311,654

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,573.79924
Policy Entropy: 0.54656
Value Function Loss: 0.09554

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.05880
Policy Update Magnitude: 0.14388
Value Function Update Magnitude: 0.42095

Collected Steps per Second: 15,033.26975
Overall Steps per Second: 10,376.99313

Timestep Collection Time: 3.32729
Timestep Consumption Time: 1.49299
PPO Batch Consumption Time: 0.13704
Total Iteration Time: 4.82028

Cumulative Model Updates: 50,388
Cumulative Timesteps: 420,361,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 420361674...
Checkpoint 420361674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,369.14030
Policy Entropy: 0.54802
Value Function Loss: 0.09069

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.04953
Policy Update Magnitude: 0.16083
Value Function Update Magnitude: 0.41392

Collected Steps per Second: 15,050.91745
Overall Steps per Second: 10,015.72991

Timestep Collection Time: 3.32299
Timestep Consumption Time: 1.67056
PPO Batch Consumption Time: 0.16307
Total Iteration Time: 4.99355

Cumulative Model Updates: 50,394
Cumulative Timesteps: 420,411,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,775.07927
Policy Entropy: 0.54795
Value Function Loss: 0.09996

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04625
Policy Update Magnitude: 0.17119
Value Function Update Magnitude: 0.37701

Collected Steps per Second: 15,171.85375
Overall Steps per Second: 10,376.16147

Timestep Collection Time: 3.29676
Timestep Consumption Time: 1.52371
PPO Batch Consumption Time: 0.13974
Total Iteration Time: 4.82047

Cumulative Model Updates: 50,400
Cumulative Timesteps: 420,461,706

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 420461706...
Checkpoint 420461706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,595.02539
Policy Entropy: 0.54422
Value Function Loss: 0.10781

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04561
Policy Update Magnitude: 0.18107
Value Function Update Magnitude: 0.38632

Collected Steps per Second: 14,710.23258
Overall Steps per Second: 10,152.73870

Timestep Collection Time: 3.40144
Timestep Consumption Time: 1.52688
PPO Batch Consumption Time: 0.14324
Total Iteration Time: 4.92833

Cumulative Model Updates: 50,406
Cumulative Timesteps: 420,511,742

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,711.62653
Policy Entropy: 0.55148
Value Function Loss: 0.10602

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06723
Policy Update Magnitude: 0.16393
Value Function Update Magnitude: 0.40728

Collected Steps per Second: 14,980.49341
Overall Steps per Second: 10,382.16152

Timestep Collection Time: 3.34008
Timestep Consumption Time: 1.47934
PPO Batch Consumption Time: 0.13746
Total Iteration Time: 4.81942

Cumulative Model Updates: 50,412
Cumulative Timesteps: 420,561,778

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 420561778...
Checkpoint 420561778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,354.39453
Policy Entropy: 0.54597
Value Function Loss: 0.09731

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07156
Policy Update Magnitude: 0.15830
Value Function Update Magnitude: 0.39226

Collected Steps per Second: 15,186.20822
Overall Steps per Second: 10,238.34740

Timestep Collection Time: 3.29351
Timestep Consumption Time: 1.59165
PPO Batch Consumption Time: 0.15192
Total Iteration Time: 4.88516

Cumulative Model Updates: 50,418
Cumulative Timesteps: 420,611,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,066.04842
Policy Entropy: 0.54867
Value Function Loss: 0.10146

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06084
Policy Update Magnitude: 0.15272
Value Function Update Magnitude: 0.35977

Collected Steps per Second: 14,757.65098
Overall Steps per Second: 10,249.71080

Timestep Collection Time: 3.38997
Timestep Consumption Time: 1.49095
PPO Batch Consumption Time: 0.13581
Total Iteration Time: 4.88092

Cumulative Model Updates: 50,424
Cumulative Timesteps: 420,661,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 420661822...
Checkpoint 420661822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,747.76907
Policy Entropy: 0.53824
Value Function Loss: 0.10719

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.06835
Policy Update Magnitude: 0.15307
Value Function Update Magnitude: 0.38003

Collected Steps per Second: 15,047.70864
Overall Steps per Second: 10,353.37951

Timestep Collection Time: 3.32370
Timestep Consumption Time: 1.50700
PPO Batch Consumption Time: 0.14273
Total Iteration Time: 4.83069

Cumulative Model Updates: 50,430
Cumulative Timesteps: 420,711,836

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,561.87964
Policy Entropy: 0.53825
Value Function Loss: 0.10780

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08392
Policy Update Magnitude: 0.14532
Value Function Update Magnitude: 0.37876

Collected Steps per Second: 14,975.72106
Overall Steps per Second: 10,295.32643

Timestep Collection Time: 3.33900
Timestep Consumption Time: 1.51796
PPO Batch Consumption Time: 0.14036
Total Iteration Time: 4.85696

Cumulative Model Updates: 50,436
Cumulative Timesteps: 420,761,840

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 420761840...
Checkpoint 420761840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,775.92415
Policy Entropy: 0.54711
Value Function Loss: 0.09611

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07237
Policy Update Magnitude: 0.15393
Value Function Update Magnitude: 0.37655

Collected Steps per Second: 15,080.39420
Overall Steps per Second: 10,382.52801

Timestep Collection Time: 3.31676
Timestep Consumption Time: 1.50076
PPO Batch Consumption Time: 0.14230
Total Iteration Time: 4.81752

Cumulative Model Updates: 50,442
Cumulative Timesteps: 420,811,858

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,392.61479
Policy Entropy: 0.55221
Value Function Loss: 0.09654

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.06789
Policy Update Magnitude: 0.16767
Value Function Update Magnitude: 0.41817

Collected Steps per Second: 14,601.26419
Overall Steps per Second: 10,165.74276

Timestep Collection Time: 3.42450
Timestep Consumption Time: 1.49418
PPO Batch Consumption Time: 0.13644
Total Iteration Time: 4.91868

Cumulative Model Updates: 50,448
Cumulative Timesteps: 420,861,860

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 420861860...
Checkpoint 420861860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,031.80515
Policy Entropy: 0.55729
Value Function Loss: 0.09075

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05798
Policy Update Magnitude: 0.17387
Value Function Update Magnitude: 0.43841

Collected Steps per Second: 15,294.56438
Overall Steps per Second: 10,409.96495

Timestep Collection Time: 3.27057
Timestep Consumption Time: 1.53463
PPO Batch Consumption Time: 0.14211
Total Iteration Time: 4.80520

Cumulative Model Updates: 50,454
Cumulative Timesteps: 420,911,882

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,178.40496
Policy Entropy: 0.55912
Value Function Loss: 0.09473

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.05385
Policy Update Magnitude: 0.17239
Value Function Update Magnitude: 0.45544

Collected Steps per Second: 14,985.22740
Overall Steps per Second: 10,308.94808

Timestep Collection Time: 3.33916
Timestep Consumption Time: 1.51469
PPO Batch Consumption Time: 0.13767
Total Iteration Time: 4.85384

Cumulative Model Updates: 50,460
Cumulative Timesteps: 420,961,920

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 420961920...
Checkpoint 420961920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,600.64913
Policy Entropy: 0.55810
Value Function Loss: 0.08823

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04616
Policy Update Magnitude: 0.16895
Value Function Update Magnitude: 0.46590

Collected Steps per Second: 15,013.38068
Overall Steps per Second: 10,300.47028

Timestep Collection Time: 3.33036
Timestep Consumption Time: 1.52378
PPO Batch Consumption Time: 0.13919
Total Iteration Time: 4.85415

Cumulative Model Updates: 50,466
Cumulative Timesteps: 421,011,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,404.81636
Policy Entropy: 0.56243
Value Function Loss: 0.09738

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03672
Policy Update Magnitude: 0.16693
Value Function Update Magnitude: 0.46089

Collected Steps per Second: 14,106.00858
Overall Steps per Second: 9,731.98568

Timestep Collection Time: 3.54544
Timestep Consumption Time: 1.59349
PPO Batch Consumption Time: 0.14928
Total Iteration Time: 5.13893

Cumulative Model Updates: 50,472
Cumulative Timesteps: 421,061,932

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 421061932...
Checkpoint 421061932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,506.78809
Policy Entropy: 0.55910
Value Function Loss: 0.10100

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04409
Policy Update Magnitude: 0.16756
Value Function Update Magnitude: 0.46024

Collected Steps per Second: 14,632.75752
Overall Steps per Second: 10,046.42729

Timestep Collection Time: 3.42000
Timestep Consumption Time: 1.56128
PPO Batch Consumption Time: 0.14884
Total Iteration Time: 4.98127

Cumulative Model Updates: 50,478
Cumulative Timesteps: 421,111,976

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,674.25995
Policy Entropy: 0.56762
Value Function Loss: 0.10400

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.06645
Policy Update Magnitude: 0.16693
Value Function Update Magnitude: 0.45408

Collected Steps per Second: 13,042.48617
Overall Steps per Second: 9,281.41318

Timestep Collection Time: 3.83731
Timestep Consumption Time: 1.55498
PPO Batch Consumption Time: 0.14698
Total Iteration Time: 5.39228

Cumulative Model Updates: 50,484
Cumulative Timesteps: 421,162,024

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 421162024...
Checkpoint 421162024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,821.39048
Policy Entropy: 0.56120
Value Function Loss: 0.10339

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05852
Policy Update Magnitude: 0.15699
Value Function Update Magnitude: 0.45389

Collected Steps per Second: 14,016.30718
Overall Steps per Second: 9,790.59784

Timestep Collection Time: 3.57070
Timestep Consumption Time: 1.54115
PPO Batch Consumption Time: 0.14020
Total Iteration Time: 5.11184

Cumulative Model Updates: 50,490
Cumulative Timesteps: 421,212,072

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,751.67342
Policy Entropy: 0.56702
Value Function Loss: 0.10777

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05667
Policy Update Magnitude: 0.16864
Value Function Update Magnitude: 0.44181

Collected Steps per Second: 13,392.92527
Overall Steps per Second: 9,516.29025

Timestep Collection Time: 3.73540
Timestep Consumption Time: 1.52169
PPO Batch Consumption Time: 0.13807
Total Iteration Time: 5.25709

Cumulative Model Updates: 50,496
Cumulative Timesteps: 421,262,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 421262100...
Checkpoint 421262100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,454.13074
Policy Entropy: 0.56346
Value Function Loss: 0.10138

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05574
Policy Update Magnitude: 0.17518
Value Function Update Magnitude: 0.42103

Collected Steps per Second: 15,323.71642
Overall Steps per Second: 10,658.07269

Timestep Collection Time: 3.26344
Timestep Consumption Time: 1.42859
PPO Batch Consumption Time: 0.13235
Total Iteration Time: 4.69203

Cumulative Model Updates: 50,502
Cumulative Timesteps: 421,312,108

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,069.95105
Policy Entropy: 0.56350
Value Function Loss: 0.10476

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04898
Policy Update Magnitude: 0.17353
Value Function Update Magnitude: 0.40825

Collected Steps per Second: 15,035.11665
Overall Steps per Second: 10,184.92930

Timestep Collection Time: 3.32701
Timestep Consumption Time: 1.58436
PPO Batch Consumption Time: 0.14777
Total Iteration Time: 4.91137

Cumulative Model Updates: 50,508
Cumulative Timesteps: 421,362,130

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 421362130...
Checkpoint 421362130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,565.24103
Policy Entropy: 0.55809
Value Function Loss: 0.09586

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04749
Policy Update Magnitude: 0.17040
Value Function Update Magnitude: 0.39197

Collected Steps per Second: 15,154.59576
Overall Steps per Second: 10,456.68898

Timestep Collection Time: 3.29973
Timestep Consumption Time: 1.48248
PPO Batch Consumption Time: 0.13388
Total Iteration Time: 4.78220

Cumulative Model Updates: 50,514
Cumulative Timesteps: 421,412,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,722.09893
Policy Entropy: 0.56164
Value Function Loss: 0.09989

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06660
Policy Update Magnitude: 0.15744
Value Function Update Magnitude: 0.38380

Collected Steps per Second: 13,162.90623
Overall Steps per Second: 9,385.57797

Timestep Collection Time: 3.79916
Timestep Consumption Time: 1.52901
PPO Batch Consumption Time: 0.13960
Total Iteration Time: 5.32817

Cumulative Model Updates: 50,520
Cumulative Timesteps: 421,462,144

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 421462144...
Checkpoint 421462144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,863.84522
Policy Entropy: 0.55877
Value Function Loss: 0.09908

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08340
Policy Update Magnitude: 0.14083
Value Function Update Magnitude: 0.37743

Collected Steps per Second: 14,292.62884
Overall Steps per Second: 9,963.12271

Timestep Collection Time: 3.50111
Timestep Consumption Time: 1.52142
PPO Batch Consumption Time: 0.14025
Total Iteration Time: 5.02252

Cumulative Model Updates: 50,526
Cumulative Timesteps: 421,512,184

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,883.34570
Policy Entropy: 0.56074
Value Function Loss: 0.10605

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07848
Policy Update Magnitude: 0.13823
Value Function Update Magnitude: 0.40680

Collected Steps per Second: 15,421.67991
Overall Steps per Second: 10,903.23096

Timestep Collection Time: 3.24362
Timestep Consumption Time: 1.34420
PPO Batch Consumption Time: 0.11854
Total Iteration Time: 4.58781

Cumulative Model Updates: 50,532
Cumulative Timesteps: 421,562,206

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 421562206...
Checkpoint 421562206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,272.66391
Policy Entropy: 0.55992
Value Function Loss: 0.10241

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07221
Policy Update Magnitude: 0.15932
Value Function Update Magnitude: 0.42413

Collected Steps per Second: 15,218.85254
Overall Steps per Second: 10,790.63256

Timestep Collection Time: 3.28698
Timestep Consumption Time: 1.34890
PPO Batch Consumption Time: 0.11763
Total Iteration Time: 4.63587

Cumulative Model Updates: 50,538
Cumulative Timesteps: 421,612,230

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,471.10383
Policy Entropy: 0.56352
Value Function Loss: 0.09588

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.05889
Policy Update Magnitude: 0.16608
Value Function Update Magnitude: 0.37868

Collected Steps per Second: 15,671.87622
Overall Steps per Second: 10,925.76046

Timestep Collection Time: 3.19068
Timestep Consumption Time: 1.38602
PPO Batch Consumption Time: 0.11773
Total Iteration Time: 4.57671

Cumulative Model Updates: 50,544
Cumulative Timesteps: 421,662,234

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 421662234...
Checkpoint 421662234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,145.35207
Policy Entropy: 0.56703
Value Function Loss: 0.09416

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.05817
Policy Update Magnitude: 0.16437
Value Function Update Magnitude: 0.38917

Collected Steps per Second: 14,996.57925
Overall Steps per Second: 10,639.75948

Timestep Collection Time: 3.33436
Timestep Consumption Time: 1.36537
PPO Batch Consumption Time: 0.11623
Total Iteration Time: 4.69973

Cumulative Model Updates: 50,550
Cumulative Timesteps: 421,712,238

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,282.71630
Policy Entropy: 0.55430
Value Function Loss: 0.09535

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05411
Policy Update Magnitude: 0.16288
Value Function Update Magnitude: 0.38509

Collected Steps per Second: 15,449.41452
Overall Steps per Second: 10,877.09666

Timestep Collection Time: 3.23779
Timestep Consumption Time: 1.36104
PPO Batch Consumption Time: 0.11723
Total Iteration Time: 4.59884

Cumulative Model Updates: 50,556
Cumulative Timesteps: 421,762,260

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 421762260...
Checkpoint 421762260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,649.34184
Policy Entropy: 0.54863
Value Function Loss: 0.10668

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.04875
Policy Update Magnitude: 0.16445
Value Function Update Magnitude: 0.40779

Collected Steps per Second: 14,742.60102
Overall Steps per Second: 10,428.99576

Timestep Collection Time: 3.39289
Timestep Consumption Time: 1.40335
PPO Batch Consumption Time: 0.11911
Total Iteration Time: 4.79624

Cumulative Model Updates: 50,562
Cumulative Timesteps: 421,812,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,489.63057
Policy Entropy: 0.54562
Value Function Loss: 0.11295

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.04983
Policy Update Magnitude: 0.16642
Value Function Update Magnitude: 0.37982

Collected Steps per Second: 15,689.92640
Overall Steps per Second: 10,984.97520

Timestep Collection Time: 3.18803
Timestep Consumption Time: 1.36546
PPO Batch Consumption Time: 0.11923
Total Iteration Time: 4.55349

Cumulative Model Updates: 50,568
Cumulative Timesteps: 421,862,300

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 421862300...
Checkpoint 421862300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,436.74420
Policy Entropy: 0.55050
Value Function Loss: 0.10878

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04479
Policy Update Magnitude: 0.16548
Value Function Update Magnitude: 0.36082

Collected Steps per Second: 15,196.59455
Overall Steps per Second: 10,701.17196

Timestep Collection Time: 3.29126
Timestep Consumption Time: 1.38262
PPO Batch Consumption Time: 0.11797
Total Iteration Time: 4.67388

Cumulative Model Updates: 50,574
Cumulative Timesteps: 421,912,316

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,688.67566
Policy Entropy: 0.55973
Value Function Loss: 0.10359

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04011
Policy Update Magnitude: 0.17004
Value Function Update Magnitude: 0.34533

Collected Steps per Second: 15,696.73186
Overall Steps per Second: 10,951.15871

Timestep Collection Time: 3.18665
Timestep Consumption Time: 1.38090
PPO Batch Consumption Time: 0.11797
Total Iteration Time: 4.56755

Cumulative Model Updates: 50,580
Cumulative Timesteps: 421,962,336

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 421962336...
Checkpoint 421962336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,599.01740
Policy Entropy: 0.55820
Value Function Loss: 0.09955

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04464
Policy Update Magnitude: 0.16867
Value Function Update Magnitude: 0.32166

Collected Steps per Second: 15,102.71294
Overall Steps per Second: 10,656.98990

Timestep Collection Time: 3.31133
Timestep Consumption Time: 1.38137
PPO Batch Consumption Time: 0.11667
Total Iteration Time: 4.69269

Cumulative Model Updates: 50,586
Cumulative Timesteps: 422,012,346

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,519.08704
Policy Entropy: 0.56304
Value Function Loss: 0.10678

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06937
Policy Update Magnitude: 0.15490
Value Function Update Magnitude: 0.36224

Collected Steps per Second: 15,709.04345
Overall Steps per Second: 10,975.91188

Timestep Collection Time: 3.18466
Timestep Consumption Time: 1.37332
PPO Batch Consumption Time: 0.11755
Total Iteration Time: 4.55798

Cumulative Model Updates: 50,592
Cumulative Timesteps: 422,062,374

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 422062374...
Checkpoint 422062374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,945.15775
Policy Entropy: 0.54802
Value Function Loss: 0.10842

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.05804
Policy Update Magnitude: 0.14401
Value Function Update Magnitude: 0.40295

Collected Steps per Second: 15,442.64647
Overall Steps per Second: 10,923.46730

Timestep Collection Time: 3.23779
Timestep Consumption Time: 1.33951
PPO Batch Consumption Time: 0.11674
Total Iteration Time: 4.57730

Cumulative Model Updates: 50,598
Cumulative Timesteps: 422,112,374

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,280.54924
Policy Entropy: 0.56008
Value Function Loss: 0.10832

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.05239
Policy Update Magnitude: 0.15735
Value Function Update Magnitude: 0.42369

Collected Steps per Second: 15,700.66099
Overall Steps per Second: 10,958.64885

Timestep Collection Time: 3.18534
Timestep Consumption Time: 1.37836
PPO Batch Consumption Time: 0.11797
Total Iteration Time: 4.56370

Cumulative Model Updates: 50,604
Cumulative Timesteps: 422,162,386

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 422162386...
Checkpoint 422162386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,871.66328
Policy Entropy: 0.56069
Value Function Loss: 0.11196

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04302
Policy Update Magnitude: 0.17324
Value Function Update Magnitude: 0.43402

Collected Steps per Second: 15,318.22559
Overall Steps per Second: 10,770.99134

Timestep Collection Time: 3.26526
Timestep Consumption Time: 1.37851
PPO Batch Consumption Time: 0.11731
Total Iteration Time: 4.64377

Cumulative Model Updates: 50,610
Cumulative Timesteps: 422,212,404

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,101.68449
Policy Entropy: 0.55774
Value Function Loss: 0.12072

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.04222
Policy Update Magnitude: 0.17283
Value Function Update Magnitude: 0.42788

Collected Steps per Second: 15,550.65842
Overall Steps per Second: 10,971.92256

Timestep Collection Time: 3.21594
Timestep Consumption Time: 1.34206
PPO Batch Consumption Time: 0.11841
Total Iteration Time: 4.55800

Cumulative Model Updates: 50,616
Cumulative Timesteps: 422,262,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 422262414...
Checkpoint 422262414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,383.57371
Policy Entropy: 0.55491
Value Function Loss: 0.11542

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.04951
Policy Update Magnitude: 0.17493
Value Function Update Magnitude: 0.37784

Collected Steps per Second: 15,528.07660
Overall Steps per Second: 10,964.67723

Timestep Collection Time: 3.22152
Timestep Consumption Time: 1.34077
PPO Batch Consumption Time: 0.11770
Total Iteration Time: 4.56229

Cumulative Model Updates: 50,622
Cumulative Timesteps: 422,312,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,101.14275
Policy Entropy: 0.55868
Value Function Loss: 0.10239

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08704
Policy Update Magnitude: 0.15497
Value Function Update Magnitude: 0.38476

Collected Steps per Second: 15,363.90898
Overall Steps per Second: 10,790.03842

Timestep Collection Time: 3.25555
Timestep Consumption Time: 1.38002
PPO Batch Consumption Time: 0.11975
Total Iteration Time: 4.63557

Cumulative Model Updates: 50,628
Cumulative Timesteps: 422,362,456

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 422362456...
Checkpoint 422362456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,637.80934
Policy Entropy: 0.54987
Value Function Loss: 0.10724

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08139
Policy Update Magnitude: 0.15040
Value Function Update Magnitude: 0.40966

Collected Steps per Second: 15,242.13798
Overall Steps per Second: 10,796.33089

Timestep Collection Time: 3.28038
Timestep Consumption Time: 1.35082
PPO Batch Consumption Time: 0.11384
Total Iteration Time: 4.63120

Cumulative Model Updates: 50,634
Cumulative Timesteps: 422,412,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,728.41542
Policy Entropy: 0.54834
Value Function Loss: 0.12519

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07002
Policy Update Magnitude: 0.16031
Value Function Update Magnitude: 0.40407

Collected Steps per Second: 15,288.14148
Overall Steps per Second: 10,794.65013

Timestep Collection Time: 3.27103
Timestep Consumption Time: 1.36163
PPO Batch Consumption Time: 0.11914
Total Iteration Time: 4.63267

Cumulative Model Updates: 50,640
Cumulative Timesteps: 422,462,464

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 422462464...
Checkpoint 422462464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,913.57329
Policy Entropy: 0.54671
Value Function Loss: 0.13610

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08649
Policy Update Magnitude: 0.15158
Value Function Update Magnitude: 0.38514

Collected Steps per Second: 15,525.27946
Overall Steps per Second: 10,939.27549

Timestep Collection Time: 3.22146
Timestep Consumption Time: 1.35051
PPO Batch Consumption Time: 0.11866
Total Iteration Time: 4.57197

Cumulative Model Updates: 50,646
Cumulative Timesteps: 422,512,478

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,764.00712
Policy Entropy: 0.55119
Value Function Loss: 0.12795

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07849
Policy Update Magnitude: 0.14652
Value Function Update Magnitude: 0.36966

Collected Steps per Second: 14,849.86793
Overall Steps per Second: 10,600.41185

Timestep Collection Time: 3.36784
Timestep Consumption Time: 1.35009
PPO Batch Consumption Time: 0.11762
Total Iteration Time: 4.71793

Cumulative Model Updates: 50,652
Cumulative Timesteps: 422,562,490

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 422562490...
Checkpoint 422562490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,169.76424
Policy Entropy: 0.54903
Value Function Loss: 0.10743

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07700
Policy Update Magnitude: 0.15210
Value Function Update Magnitude: 0.40733

Collected Steps per Second: 15,341.31136
Overall Steps per Second: 10,778.64782

Timestep Collection Time: 3.25996
Timestep Consumption Time: 1.37996
PPO Batch Consumption Time: 0.11757
Total Iteration Time: 4.63991

Cumulative Model Updates: 50,658
Cumulative Timesteps: 422,612,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,742.52790
Policy Entropy: 0.54797
Value Function Loss: 0.10341

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07334
Policy Update Magnitude: 0.14925
Value Function Update Magnitude: 0.37727

Collected Steps per Second: 15,255.65990
Overall Steps per Second: 10,721.14242

Timestep Collection Time: 3.27996
Timestep Consumption Time: 1.38726
PPO Batch Consumption Time: 0.11779
Total Iteration Time: 4.66723

Cumulative Model Updates: 50,664
Cumulative Timesteps: 422,662,540

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 422662540...
Checkpoint 422662540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,553.50956
Policy Entropy: 0.54686
Value Function Loss: 0.09631

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.07299
Policy Update Magnitude: 0.15614
Value Function Update Magnitude: 0.31974

Collected Steps per Second: 15,309.30046
Overall Steps per Second: 10,790.96120

Timestep Collection Time: 3.26847
Timestep Consumption Time: 1.36856
PPO Batch Consumption Time: 0.11723
Total Iteration Time: 4.63703

Cumulative Model Updates: 50,670
Cumulative Timesteps: 422,712,578

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,235.86328
Policy Entropy: 0.54155
Value Function Loss: 0.09333

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05720
Policy Update Magnitude: 0.16602
Value Function Update Magnitude: 0.32132

Collected Steps per Second: 15,319.78865
Overall Steps per Second: 10,817.97777

Timestep Collection Time: 3.26558
Timestep Consumption Time: 1.35894
PPO Batch Consumption Time: 0.11827
Total Iteration Time: 4.62452

Cumulative Model Updates: 50,676
Cumulative Timesteps: 422,762,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 422762606...
Checkpoint 422762606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,880.70456
Policy Entropy: 0.54261
Value Function Loss: 0.09664

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05398
Policy Update Magnitude: 0.17362
Value Function Update Magnitude: 0.30950

Collected Steps per Second: 15,372.04590
Overall Steps per Second: 10,787.35969

Timestep Collection Time: 3.25318
Timestep Consumption Time: 1.38262
PPO Batch Consumption Time: 0.11806
Total Iteration Time: 4.63580

Cumulative Model Updates: 50,682
Cumulative Timesteps: 422,812,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,278.42367
Policy Entropy: 0.55164
Value Function Loss: 0.09414

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05515
Policy Update Magnitude: 0.17337
Value Function Update Magnitude: 0.33201

Collected Steps per Second: 15,370.79996
Overall Steps per Second: 10,793.95564

Timestep Collection Time: 3.25422
Timestep Consumption Time: 1.37985
PPO Batch Consumption Time: 0.11802
Total Iteration Time: 4.63408

Cumulative Model Updates: 50,688
Cumulative Timesteps: 422,862,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 422862634...
Checkpoint 422862634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,091.82519
Policy Entropy: 0.55500
Value Function Loss: 0.09360

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05444
Policy Update Magnitude: 0.16926
Value Function Update Magnitude: 0.35933

Collected Steps per Second: 15,165.46764
Overall Steps per Second: 10,720.46641

Timestep Collection Time: 3.29723
Timestep Consumption Time: 1.36712
PPO Batch Consumption Time: 0.11635
Total Iteration Time: 4.66435

Cumulative Model Updates: 50,694
Cumulative Timesteps: 422,912,638

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,518.17189
Policy Entropy: 0.55549
Value Function Loss: 0.09411

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.04911
Policy Update Magnitude: 0.17161
Value Function Update Magnitude: 0.38463

Collected Steps per Second: 15,605.00297
Overall Steps per Second: 10,935.81433

Timestep Collection Time: 3.20602
Timestep Consumption Time: 1.36885
PPO Batch Consumption Time: 0.11785
Total Iteration Time: 4.57488

Cumulative Model Updates: 50,700
Cumulative Timesteps: 422,962,668

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 422962668...
Checkpoint 422962668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,239.98946
Policy Entropy: 0.55413
Value Function Loss: 0.10028

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05628
Policy Update Magnitude: 0.17325
Value Function Update Magnitude: 0.38955

Collected Steps per Second: 14,963.46731
Overall Steps per Second: 10,608.75607

Timestep Collection Time: 3.34254
Timestep Consumption Time: 1.37206
PPO Batch Consumption Time: 0.11806
Total Iteration Time: 4.71460

Cumulative Model Updates: 50,706
Cumulative Timesteps: 423,012,684

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,565.08861
Policy Entropy: 0.55588
Value Function Loss: 0.09660

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06131
Policy Update Magnitude: 0.17119
Value Function Update Magnitude: 0.36762

Collected Steps per Second: 15,759.95660
Overall Steps per Second: 10,999.99441

Timestep Collection Time: 3.17361
Timestep Consumption Time: 1.37330
PPO Batch Consumption Time: 0.11729
Total Iteration Time: 4.54691

Cumulative Model Updates: 50,712
Cumulative Timesteps: 423,062,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 423062700...
Checkpoint 423062700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,522.27801
Policy Entropy: 0.55607
Value Function Loss: 0.09611

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05382
Policy Update Magnitude: 0.16749
Value Function Update Magnitude: 0.35977

Collected Steps per Second: 15,266.61838
Overall Steps per Second: 10,738.26345

Timestep Collection Time: 3.27708
Timestep Consumption Time: 1.38196
PPO Batch Consumption Time: 0.11831
Total Iteration Time: 4.65904

Cumulative Model Updates: 50,718
Cumulative Timesteps: 423,112,730

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,173.34220
Policy Entropy: 0.55489
Value Function Loss: 0.09162

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07702
Policy Update Magnitude: 0.15993
Value Function Update Magnitude: 0.38387

Collected Steps per Second: 15,611.11976
Overall Steps per Second: 10,913.35101

Timestep Collection Time: 3.20285
Timestep Consumption Time: 1.37870
PPO Batch Consumption Time: 0.11865
Total Iteration Time: 4.58154

Cumulative Model Updates: 50,724
Cumulative Timesteps: 423,162,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 423162730...
Checkpoint 423162730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,295.68836
Policy Entropy: 0.55766
Value Function Loss: 0.09074

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07623
Policy Update Magnitude: 0.13878
Value Function Update Magnitude: 0.36205

Collected Steps per Second: 15,284.65330
Overall Steps per Second: 10,711.51289

Timestep Collection Time: 3.27387
Timestep Consumption Time: 1.39774
PPO Batch Consumption Time: 0.11897
Total Iteration Time: 4.67161

Cumulative Model Updates: 50,730
Cumulative Timesteps: 423,212,770

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,392.62704
Policy Entropy: 0.56127
Value Function Loss: 0.10421

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07610
Policy Update Magnitude: 0.12945
Value Function Update Magnitude: 0.33274

Collected Steps per Second: 14,668.08466
Overall Steps per Second: 10,291.84950

Timestep Collection Time: 3.41026
Timestep Consumption Time: 1.45009
PPO Batch Consumption Time: 0.13084
Total Iteration Time: 4.86035

Cumulative Model Updates: 50,736
Cumulative Timesteps: 423,262,792

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 423262792...
Checkpoint 423262792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,493.08058
Policy Entropy: 0.56298
Value Function Loss: 0.10667

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06852
Policy Update Magnitude: 0.14552
Value Function Update Magnitude: 0.37289

Collected Steps per Second: 15,220.38801
Overall Steps per Second: 10,588.46458

Timestep Collection Time: 3.28651
Timestep Consumption Time: 1.43768
PPO Batch Consumption Time: 0.13240
Total Iteration Time: 4.72420

Cumulative Model Updates: 50,742
Cumulative Timesteps: 423,312,814

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,513.72375
Policy Entropy: 0.56110
Value Function Loss: 0.10656

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07112
Policy Update Magnitude: 0.14653
Value Function Update Magnitude: 0.42016

Collected Steps per Second: 15,497.14543
Overall Steps per Second: 10,670.43207

Timestep Collection Time: 3.22653
Timestep Consumption Time: 1.45950
PPO Batch Consumption Time: 0.13201
Total Iteration Time: 4.68603

Cumulative Model Updates: 50,748
Cumulative Timesteps: 423,362,816

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 423362816...
Checkpoint 423362816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,533.84427
Policy Entropy: 0.56222
Value Function Loss: 0.09717

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06774
Policy Update Magnitude: 0.14099
Value Function Update Magnitude: 0.41612

Collected Steps per Second: 13,646.67031
Overall Steps per Second: 9,656.75650

Timestep Collection Time: 3.66492
Timestep Consumption Time: 1.51425
PPO Batch Consumption Time: 0.13568
Total Iteration Time: 5.17917

Cumulative Model Updates: 50,754
Cumulative Timesteps: 423,412,830

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,240.71741
Policy Entropy: 0.56373
Value Function Loss: 0.10379

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.06053
Policy Update Magnitude: 0.15015
Value Function Update Magnitude: 0.37504

Collected Steps per Second: 15,206.48276
Overall Steps per Second: 10,471.17678

Timestep Collection Time: 3.28847
Timestep Consumption Time: 1.48712
PPO Batch Consumption Time: 0.13464
Total Iteration Time: 4.77559

Cumulative Model Updates: 50,760
Cumulative Timesteps: 423,462,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 423462836...
Checkpoint 423462836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,512.27095
Policy Entropy: 0.56242
Value Function Loss: 0.10841

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.06373
Policy Update Magnitude: 0.16671
Value Function Update Magnitude: 0.38403

Collected Steps per Second: 15,431.59222
Overall Steps per Second: 10,548.03185

Timestep Collection Time: 3.24153
Timestep Consumption Time: 1.50077
PPO Batch Consumption Time: 0.13369
Total Iteration Time: 4.74231

Cumulative Model Updates: 50,766
Cumulative Timesteps: 423,512,858

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,409.17261
Policy Entropy: 0.56381
Value Function Loss: 0.10168

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.07284
Policy Update Magnitude: 0.15453
Value Function Update Magnitude: 0.38991

Collected Steps per Second: 15,648.42814
Overall Steps per Second: 10,805.80656

Timestep Collection Time: 3.19674
Timestep Consumption Time: 1.43262
PPO Batch Consumption Time: 0.13488
Total Iteration Time: 4.62936

Cumulative Model Updates: 50,772
Cumulative Timesteps: 423,562,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 423562882...
Checkpoint 423562882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,469.61716
Policy Entropy: 0.55592
Value Function Loss: 0.10098

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.06608
Policy Update Magnitude: 0.15531
Value Function Update Magnitude: 0.41922

Collected Steps per Second: 15,557.44505
Overall Steps per Second: 10,768.91551

Timestep Collection Time: 3.21544
Timestep Consumption Time: 1.42978
PPO Batch Consumption Time: 0.13201
Total Iteration Time: 4.64522

Cumulative Model Updates: 50,778
Cumulative Timesteps: 423,612,906

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,606.24818
Policy Entropy: 0.55576
Value Function Loss: 0.09446

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.05182
Policy Update Magnitude: 0.16848
Value Function Update Magnitude: 0.44514

Collected Steps per Second: 15,351.41988
Overall Steps per Second: 10,559.81504

Timestep Collection Time: 3.25781
Timestep Consumption Time: 1.47826
PPO Batch Consumption Time: 0.13376
Total Iteration Time: 4.73607

Cumulative Model Updates: 50,784
Cumulative Timesteps: 423,662,918

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 423662918...
Checkpoint 423662918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,398.22394
Policy Entropy: 0.55660
Value Function Loss: 0.09559

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.05504
Policy Update Magnitude: 0.17040
Value Function Update Magnitude: 0.44857

Collected Steps per Second: 15,324.20836
Overall Steps per Second: 10,634.89032

Timestep Collection Time: 3.26294
Timestep Consumption Time: 1.43875
PPO Batch Consumption Time: 0.13186
Total Iteration Time: 4.70169

Cumulative Model Updates: 50,790
Cumulative Timesteps: 423,712,920

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,720.08116
Policy Entropy: 0.56663
Value Function Loss: 0.08958

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06638
Policy Update Magnitude: 0.15818
Value Function Update Magnitude: 0.43800

Collected Steps per Second: 15,159.73231
Overall Steps per Second: 10,537.03995

Timestep Collection Time: 3.29927
Timestep Consumption Time: 1.44742
PPO Batch Consumption Time: 0.13063
Total Iteration Time: 4.74668

Cumulative Model Updates: 50,796
Cumulative Timesteps: 423,762,936

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 423762936...
Checkpoint 423762936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,296.01419
Policy Entropy: 0.57137
Value Function Loss: 0.08966

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06697
Policy Update Magnitude: 0.15064
Value Function Update Magnitude: 0.43130

Collected Steps per Second: 15,248.00346
Overall Steps per Second: 10,567.41662

Timestep Collection Time: 3.28109
Timestep Consumption Time: 1.45328
PPO Batch Consumption Time: 0.13275
Total Iteration Time: 4.73436

Cumulative Model Updates: 50,802
Cumulative Timesteps: 423,812,966

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,402.35365
Policy Entropy: 0.57925
Value Function Loss: 0.08633

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04968
Policy Update Magnitude: 0.16297
Value Function Update Magnitude: 0.42845

Collected Steps per Second: 15,327.74189
Overall Steps per Second: 10,509.35223

Timestep Collection Time: 3.26284
Timestep Consumption Time: 1.49597
PPO Batch Consumption Time: 0.13644
Total Iteration Time: 4.75881

Cumulative Model Updates: 50,808
Cumulative Timesteps: 423,862,978

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 423862978...
Checkpoint 423862978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,599.96649
Policy Entropy: 0.57301
Value Function Loss: 0.09361

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.05160
Policy Update Magnitude: 0.16867
Value Function Update Magnitude: 0.43418

Collected Steps per Second: 15,614.28957
Overall Steps per Second: 10,742.63422

Timestep Collection Time: 3.20220
Timestep Consumption Time: 1.45216
PPO Batch Consumption Time: 0.13316
Total Iteration Time: 4.65435

Cumulative Model Updates: 50,814
Cumulative Timesteps: 423,912,978

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,749.90099
Policy Entropy: 0.57901
Value Function Loss: 0.09225

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.04129
Policy Update Magnitude: 0.17799
Value Function Update Magnitude: 0.43967

Collected Steps per Second: 15,470.69907
Overall Steps per Second: 10,608.56037

Timestep Collection Time: 3.23308
Timestep Consumption Time: 1.48179
PPO Batch Consumption Time: 0.13324
Total Iteration Time: 4.71487

Cumulative Model Updates: 50,820
Cumulative Timesteps: 423,962,996

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 423962996...
Checkpoint 423962996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,703.88693
Policy Entropy: 0.57876
Value Function Loss: 0.09374

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.04841
Policy Update Magnitude: 0.17766
Value Function Update Magnitude: 0.41492

Collected Steps per Second: 15,621.64872
Overall Steps per Second: 10,636.11284

Timestep Collection Time: 3.20120
Timestep Consumption Time: 1.50052
PPO Batch Consumption Time: 0.13645
Total Iteration Time: 4.70172

Cumulative Model Updates: 50,826
Cumulative Timesteps: 424,013,004

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,769.15318
Policy Entropy: 0.57752
Value Function Loss: 0.09055

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04588
Policy Update Magnitude: 0.17362
Value Function Update Magnitude: 0.37660

Collected Steps per Second: 15,538.08655
Overall Steps per Second: 10,635.67666

Timestep Collection Time: 3.21919
Timestep Consumption Time: 1.48385
PPO Batch Consumption Time: 0.13638
Total Iteration Time: 4.70304

Cumulative Model Updates: 50,832
Cumulative Timesteps: 424,063,024

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 424063024...
Checkpoint 424063024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,708.02174
Policy Entropy: 0.58755
Value Function Loss: 0.08647

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.04134
Policy Update Magnitude: 0.17319
Value Function Update Magnitude: 0.37392

Collected Steps per Second: 15,282.39538
Overall Steps per Second: 10,544.43316

Timestep Collection Time: 3.27265
Timestep Consumption Time: 1.47051
PPO Batch Consumption Time: 0.13426
Total Iteration Time: 4.74317

Cumulative Model Updates: 50,838
Cumulative Timesteps: 424,113,038

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,499.56222
Policy Entropy: 0.58251
Value Function Loss: 0.08249

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04316
Policy Update Magnitude: 0.17192
Value Function Update Magnitude: 0.39507

Collected Steps per Second: 15,215.19200
Overall Steps per Second: 10,201.07373

Timestep Collection Time: 3.28750
Timestep Consumption Time: 1.61590
PPO Batch Consumption Time: 0.15700
Total Iteration Time: 4.90341

Cumulative Model Updates: 50,844
Cumulative Timesteps: 424,163,058

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 424163058...
Checkpoint 424163058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,998.72001
Policy Entropy: 0.58743
Value Function Loss: 0.07934

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.04131
Policy Update Magnitude: 0.17199
Value Function Update Magnitude: 0.38968

Collected Steps per Second: 14,257.63936
Overall Steps per Second: 9,962.72784

Timestep Collection Time: 3.50689
Timestep Consumption Time: 1.51181
PPO Batch Consumption Time: 0.14105
Total Iteration Time: 5.01871

Cumulative Model Updates: 50,850
Cumulative Timesteps: 424,213,058

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,076.00900
Policy Entropy: 0.58252
Value Function Loss: 0.09002

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04059
Policy Update Magnitude: 0.17358
Value Function Update Magnitude: 0.37386

Collected Steps per Second: 15,102.58310
Overall Steps per Second: 10,405.80714

Timestep Collection Time: 3.31294
Timestep Consumption Time: 1.49533
PPO Batch Consumption Time: 0.13705
Total Iteration Time: 4.80828

Cumulative Model Updates: 50,856
Cumulative Timesteps: 424,263,092

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 424263092...
Checkpoint 424263092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,780.35320
Policy Entropy: 0.57920
Value Function Loss: 0.09824

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.04310
Policy Update Magnitude: 0.17666
Value Function Update Magnitude: 0.40457

Collected Steps per Second: 14,724.53323
Overall Steps per Second: 10,254.76497

Timestep Collection Time: 3.39678
Timestep Consumption Time: 1.48056
PPO Batch Consumption Time: 0.13693
Total Iteration Time: 4.87734

Cumulative Model Updates: 50,862
Cumulative Timesteps: 424,313,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,250.47141
Policy Entropy: 0.57924
Value Function Loss: 0.09416

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04466
Policy Update Magnitude: 0.17672
Value Function Update Magnitude: 0.43186

Collected Steps per Second: 15,274.52201
Overall Steps per Second: 10,460.26658

Timestep Collection Time: 3.27500
Timestep Consumption Time: 1.50729
PPO Batch Consumption Time: 0.13767
Total Iteration Time: 4.78229

Cumulative Model Updates: 50,868
Cumulative Timesteps: 424,363,132

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 424363132...
Checkpoint 424363132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,302.53828
Policy Entropy: 0.57670
Value Function Loss: 0.09422

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.04732
Policy Update Magnitude: 0.17288
Value Function Update Magnitude: 0.41098

Collected Steps per Second: 14,667.26203
Overall Steps per Second: 10,141.91834

Timestep Collection Time: 3.41100
Timestep Consumption Time: 1.52199
PPO Batch Consumption Time: 0.13885
Total Iteration Time: 4.93299

Cumulative Model Updates: 50,874
Cumulative Timesteps: 424,413,162

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,260.40226
Policy Entropy: 0.58279
Value Function Loss: 0.08758

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04645
Policy Update Magnitude: 0.16982
Value Function Update Magnitude: 0.42778

Collected Steps per Second: 15,108.18468
Overall Steps per Second: 10,422.66682

Timestep Collection Time: 3.30973
Timestep Consumption Time: 1.48789
PPO Batch Consumption Time: 0.13615
Total Iteration Time: 4.79762

Cumulative Model Updates: 50,880
Cumulative Timesteps: 424,463,166

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 424463166...
Checkpoint 424463166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,128.39682
Policy Entropy: 0.58004
Value Function Loss: 0.09997

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04645
Policy Update Magnitude: 0.17583
Value Function Update Magnitude: 0.44007

Collected Steps per Second: 14,965.47498
Overall Steps per Second: 10,273.63684

Timestep Collection Time: 3.34410
Timestep Consumption Time: 1.52721
PPO Batch Consumption Time: 0.14076
Total Iteration Time: 4.87130

Cumulative Model Updates: 50,886
Cumulative Timesteps: 424,513,212

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,081.30801
Policy Entropy: 0.57557
Value Function Loss: 0.10680

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.05226
Policy Update Magnitude: 0.18364
Value Function Update Magnitude: 0.43536

Collected Steps per Second: 15,073.40691
Overall Steps per Second: 10,413.21622

Timestep Collection Time: 3.31816
Timestep Consumption Time: 1.48497
PPO Batch Consumption Time: 0.13624
Total Iteration Time: 4.80313

Cumulative Model Updates: 50,892
Cumulative Timesteps: 424,563,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 424563228...
Checkpoint 424563228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,409.59609
Policy Entropy: 0.57471
Value Function Loss: 0.11456

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.04669
Policy Update Magnitude: 0.18832
Value Function Update Magnitude: 0.40016

Collected Steps per Second: 14,883.38488
Overall Steps per Second: 10,303.85668

Timestep Collection Time: 3.36160
Timestep Consumption Time: 1.49406
PPO Batch Consumption Time: 0.13897
Total Iteration Time: 4.85566

Cumulative Model Updates: 50,898
Cumulative Timesteps: 424,613,260

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,157.46744
Policy Entropy: 0.57229
Value Function Loss: 0.10670

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.05096
Policy Update Magnitude: 0.18465
Value Function Update Magnitude: 0.35794

Collected Steps per Second: 15,232.57218
Overall Steps per Second: 10,458.84727

Timestep Collection Time: 3.28362
Timestep Consumption Time: 1.49874
PPO Batch Consumption Time: 0.13653
Total Iteration Time: 4.78236

Cumulative Model Updates: 50,904
Cumulative Timesteps: 424,663,278

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 424663278...
Checkpoint 424663278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,463.25369
Policy Entropy: 0.57719
Value Function Loss: 0.10164

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06064
Policy Update Magnitude: 0.17038
Value Function Update Magnitude: 0.33651

Collected Steps per Second: 14,967.31609
Overall Steps per Second: 10,320.50496

Timestep Collection Time: 3.34288
Timestep Consumption Time: 1.50513
PPO Batch Consumption Time: 0.13667
Total Iteration Time: 4.84802

Cumulative Model Updates: 50,910
Cumulative Timesteps: 424,713,312

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,008.47897
Policy Entropy: 0.57442
Value Function Loss: 0.09506

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07777
Policy Update Magnitude: 0.15652
Value Function Update Magnitude: 0.36596

Collected Steps per Second: 15,055.84415
Overall Steps per Second: 10,426.95980

Timestep Collection Time: 3.32217
Timestep Consumption Time: 1.47482
PPO Batch Consumption Time: 0.13451
Total Iteration Time: 4.79699

Cumulative Model Updates: 50,916
Cumulative Timesteps: 424,763,330

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 424763330...
Checkpoint 424763330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,944.68258
Policy Entropy: 0.57894
Value Function Loss: 0.10098

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07667
Policy Update Magnitude: 0.16039
Value Function Update Magnitude: 0.39046

Collected Steps per Second: 15,008.29967
Overall Steps per Second: 10,332.65108

Timestep Collection Time: 3.33242
Timestep Consumption Time: 1.50796
PPO Batch Consumption Time: 0.13745
Total Iteration Time: 4.84038

Cumulative Model Updates: 50,922
Cumulative Timesteps: 424,813,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,627.07070
Policy Entropy: 0.57605
Value Function Loss: 0.10223

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07147
Policy Update Magnitude: 0.15584
Value Function Update Magnitude: 0.38801

Collected Steps per Second: 15,159.15966
Overall Steps per Second: 10,442.48070

Timestep Collection Time: 3.29886
Timestep Consumption Time: 1.49004
PPO Batch Consumption Time: 0.13576
Total Iteration Time: 4.78890

Cumulative Model Updates: 50,928
Cumulative Timesteps: 424,863,352

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 424863352...
Checkpoint 424863352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,023.36283
Policy Entropy: 0.56853
Value Function Loss: 0.10111

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.09842
Policy Update Magnitude: 0.15545
Value Function Update Magnitude: 0.39275

Collected Steps per Second: 14,509.34313
Overall Steps per Second: 10,066.25391

Timestep Collection Time: 3.44840
Timestep Consumption Time: 1.52207
PPO Batch Consumption Time: 0.13893
Total Iteration Time: 4.97047

Cumulative Model Updates: 50,934
Cumulative Timesteps: 424,913,386

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,144.65412
Policy Entropy: 0.56028
Value Function Loss: 0.09556

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.06614
Policy Update Magnitude: 0.14035
Value Function Update Magnitude: 0.42592

Collected Steps per Second: 15,119.74468
Overall Steps per Second: 10,469.30630

Timestep Collection Time: 3.30839
Timestep Consumption Time: 1.46958
PPO Batch Consumption Time: 0.13849
Total Iteration Time: 4.77797

Cumulative Model Updates: 50,940
Cumulative Timesteps: 424,963,408

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 424963408...
Checkpoint 424963408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,056.18565
Policy Entropy: 0.56631
Value Function Loss: 0.08875

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.04980
Policy Update Magnitude: 0.15613
Value Function Update Magnitude: 0.42595

Collected Steps per Second: 14,912.20329
Overall Steps per Second: 10,307.20042

Timestep Collection Time: 3.35309
Timestep Consumption Time: 1.49808
PPO Batch Consumption Time: 0.13660
Total Iteration Time: 4.85117

Cumulative Model Updates: 50,946
Cumulative Timesteps: 425,013,410

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,330.32171
Policy Entropy: 0.57141
Value Function Loss: 0.09237

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05786
Policy Update Magnitude: 0.16784
Value Function Update Magnitude: 0.44251

Collected Steps per Second: 15,006.95299
Overall Steps per Second: 10,428.24776

Timestep Collection Time: 3.33339
Timestep Consumption Time: 1.46358
PPO Batch Consumption Time: 0.13623
Total Iteration Time: 4.79697

Cumulative Model Updates: 50,952
Cumulative Timesteps: 425,063,434

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 425063434...
Checkpoint 425063434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,391.58148
Policy Entropy: 0.56987
Value Function Loss: 0.09063

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06006
Policy Update Magnitude: 0.17158
Value Function Update Magnitude: 0.44464

Collected Steps per Second: 15,078.21099
Overall Steps per Second: 10,389.89579

Timestep Collection Time: 3.31870
Timestep Consumption Time: 1.49752
PPO Batch Consumption Time: 0.13982
Total Iteration Time: 4.81622

Cumulative Model Updates: 50,958
Cumulative Timesteps: 425,113,474

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,709.37018
Policy Entropy: 0.56078
Value Function Loss: 0.09223

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04419
Policy Update Magnitude: 0.16868
Value Function Update Magnitude: 0.44539

Collected Steps per Second: 15,169.24320
Overall Steps per Second: 10,492.53979

Timestep Collection Time: 3.29746
Timestep Consumption Time: 1.46973
PPO Batch Consumption Time: 0.13762
Total Iteration Time: 4.76720

Cumulative Model Updates: 50,964
Cumulative Timesteps: 425,163,494

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 425163494...
Checkpoint 425163494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,503.65692
Policy Entropy: 0.56089
Value Function Loss: 0.08998

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04396
Policy Update Magnitude: 0.17348
Value Function Update Magnitude: 0.42524

Collected Steps per Second: 15,070.80994
Overall Steps per Second: 10,357.98880

Timestep Collection Time: 3.31913
Timestep Consumption Time: 1.51018
PPO Batch Consumption Time: 0.13711
Total Iteration Time: 4.82932

Cumulative Model Updates: 50,970
Cumulative Timesteps: 425,213,516

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,834.25169
Policy Entropy: 0.55895
Value Function Loss: 0.08774

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03884
Policy Update Magnitude: 0.17984
Value Function Update Magnitude: 0.42637

Collected Steps per Second: 15,038.66594
Overall Steps per Second: 10,455.64934

Timestep Collection Time: 3.32609
Timestep Consumption Time: 1.45792
PPO Batch Consumption Time: 0.13656
Total Iteration Time: 4.78402

Cumulative Model Updates: 50,976
Cumulative Timesteps: 425,263,536

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 425263536...
Checkpoint 425263536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,501.04864
Policy Entropy: 0.56340
Value Function Loss: 0.08706

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.04023
Policy Update Magnitude: 0.18131
Value Function Update Magnitude: 0.43329

Collected Steps per Second: 15,066.69463
Overall Steps per Second: 10,383.42938

Timestep Collection Time: 3.31977
Timestep Consumption Time: 1.49733
PPO Batch Consumption Time: 0.13729
Total Iteration Time: 4.81710

Cumulative Model Updates: 50,982
Cumulative Timesteps: 425,313,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,733.48920
Policy Entropy: 0.56022
Value Function Loss: 0.08591

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03630
Policy Update Magnitude: 0.18177
Value Function Update Magnitude: 0.42761

Collected Steps per Second: 15,062.97882
Overall Steps per Second: 10,443.01779

Timestep Collection Time: 3.32245
Timestep Consumption Time: 1.46984
PPO Batch Consumption Time: 0.13727
Total Iteration Time: 4.79229

Cumulative Model Updates: 50,988
Cumulative Timesteps: 425,363,600

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 425363600...
Checkpoint 425363600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,027.96600
Policy Entropy: 0.55653
Value Function Loss: 0.09072

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03951
Policy Update Magnitude: 0.18695
Value Function Update Magnitude: 0.43021

Collected Steps per Second: 14,920.30201
Overall Steps per Second: 10,289.85768

Timestep Collection Time: 3.35114
Timestep Consumption Time: 1.50802
PPO Batch Consumption Time: 0.13682
Total Iteration Time: 4.85915

Cumulative Model Updates: 50,994
Cumulative Timesteps: 425,413,600

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,990.27388
Policy Entropy: 0.54854
Value Function Loss: 0.09528

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03477
Policy Update Magnitude: 0.18350
Value Function Update Magnitude: 0.44381

Collected Steps per Second: 15,045.38084
Overall Steps per Second: 10,409.39182

Timestep Collection Time: 3.32448
Timestep Consumption Time: 1.48061
PPO Batch Consumption Time: 0.13817
Total Iteration Time: 4.80508

Cumulative Model Updates: 51,000
Cumulative Timesteps: 425,463,618

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 425463618...
Checkpoint 425463618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,083.26945
Policy Entropy: 0.55027
Value Function Loss: 0.10203

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03676
Policy Update Magnitude: 0.18857
Value Function Update Magnitude: 0.44637

Collected Steps per Second: 14,968.53504
Overall Steps per Second: 10,394.51495

Timestep Collection Time: 3.34087
Timestep Consumption Time: 1.47012
PPO Batch Consumption Time: 0.13690
Total Iteration Time: 4.81100

Cumulative Model Updates: 51,006
Cumulative Timesteps: 425,513,626

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,427.25526
Policy Entropy: 0.55722
Value Function Loss: 0.09998

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03535
Policy Update Magnitude: 0.18735
Value Function Update Magnitude: 0.41937

Collected Steps per Second: 14,674.81229
Overall Steps per Second: 10,185.87480

Timestep Collection Time: 3.40843
Timestep Consumption Time: 1.50210
PPO Batch Consumption Time: 0.14245
Total Iteration Time: 4.91053

Cumulative Model Updates: 51,012
Cumulative Timesteps: 425,563,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 425563644...
Checkpoint 425563644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,225.14060
Policy Entropy: 0.56330
Value Function Loss: 0.10217

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03463
Policy Update Magnitude: 0.18529
Value Function Update Magnitude: 0.36266

Collected Steps per Second: 14,948.53757
Overall Steps per Second: 10,406.74752

Timestep Collection Time: 3.34481
Timestep Consumption Time: 1.45977
PPO Batch Consumption Time: 0.13558
Total Iteration Time: 4.80458

Cumulative Model Updates: 51,018
Cumulative Timesteps: 425,613,644

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,702.46475
Policy Entropy: 0.57011
Value Function Loss: 0.09620

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04545
Policy Update Magnitude: 0.17615
Value Function Update Magnitude: 0.35548

Collected Steps per Second: 15,097.50963
Overall Steps per Second: 10,325.61524

Timestep Collection Time: 3.31313
Timestep Consumption Time: 1.53113
PPO Batch Consumption Time: 0.13844
Total Iteration Time: 4.84426

Cumulative Model Updates: 51,024
Cumulative Timesteps: 425,663,664

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 425663664...
Checkpoint 425663664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,654.22333
Policy Entropy: 0.57053
Value Function Loss: 0.09939

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.04104
Policy Update Magnitude: 0.17762
Value Function Update Magnitude: 0.36557

Collected Steps per Second: 14,921.76339
Overall Steps per Second: 10,321.99863

Timestep Collection Time: 3.35121
Timestep Consumption Time: 1.49339
PPO Batch Consumption Time: 0.13600
Total Iteration Time: 4.84460

Cumulative Model Updates: 51,030
Cumulative Timesteps: 425,713,670

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,722.09851
Policy Entropy: 0.57113
Value Function Loss: 0.09225

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.04108
Policy Update Magnitude: 0.17946
Value Function Update Magnitude: 0.37464

Collected Steps per Second: 15,118.62547
Overall Steps per Second: 10,445.84665

Timestep Collection Time: 3.30982
Timestep Consumption Time: 1.48060
PPO Batch Consumption Time: 0.13815
Total Iteration Time: 4.79042

Cumulative Model Updates: 51,036
Cumulative Timesteps: 425,763,710

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 425763710...
Checkpoint 425763710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,516.54909
Policy Entropy: 0.55917
Value Function Loss: 0.08865

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04653
Policy Update Magnitude: 0.17501
Value Function Update Magnitude: 0.37031

Collected Steps per Second: 14,841.40220
Overall Steps per Second: 10,310.46697

Timestep Collection Time: 3.37124
Timestep Consumption Time: 1.48149
PPO Batch Consumption Time: 0.13529
Total Iteration Time: 4.85274

Cumulative Model Updates: 51,042
Cumulative Timesteps: 425,813,744

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,135.80013
Policy Entropy: 0.56309
Value Function Loss: 0.09338

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04297
Policy Update Magnitude: 0.17523
Value Function Update Magnitude: 0.33635

Collected Steps per Second: 15,023.87188
Overall Steps per Second: 10,334.16515

Timestep Collection Time: 3.32804
Timestep Consumption Time: 1.51028
PPO Batch Consumption Time: 0.14294
Total Iteration Time: 4.83832

Cumulative Model Updates: 51,048
Cumulative Timesteps: 425,863,744

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 425863744...
Checkpoint 425863744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,621.15237
Policy Entropy: 0.56649
Value Function Loss: 0.09280

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.04171
Policy Update Magnitude: 0.17877
Value Function Update Magnitude: 0.39240

Collected Steps per Second: 14,878.26544
Overall Steps per Second: 10,284.54392

Timestep Collection Time: 3.36061
Timestep Consumption Time: 1.50106
PPO Batch Consumption Time: 0.13796
Total Iteration Time: 4.86166

Cumulative Model Updates: 51,054
Cumulative Timesteps: 425,913,744

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,041.85298
Policy Entropy: 0.55961
Value Function Loss: 0.09912

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.04001
Policy Update Magnitude: 0.17612
Value Function Update Magnitude: 0.40680

Collected Steps per Second: 15,301.38319
Overall Steps per Second: 10,463.98865

Timestep Collection Time: 3.26872
Timestep Consumption Time: 1.51110
PPO Batch Consumption Time: 0.14133
Total Iteration Time: 4.77982

Cumulative Model Updates: 51,060
Cumulative Timesteps: 425,963,760

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 425963760...
Checkpoint 425963760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,368.47367
Policy Entropy: 0.56404
Value Function Loss: 0.08912

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03728
Policy Update Magnitude: 0.17627
Value Function Update Magnitude: 0.38006

Collected Steps per Second: 14,806.58838
Overall Steps per Second: 10,297.84671

Timestep Collection Time: 3.37701
Timestep Consumption Time: 1.47857
PPO Batch Consumption Time: 0.13663
Total Iteration Time: 4.85558

Cumulative Model Updates: 51,066
Cumulative Timesteps: 426,013,762

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,594.65156
Policy Entropy: 0.57316
Value Function Loss: 0.08808

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.06526
Policy Update Magnitude: 0.16756
Value Function Update Magnitude: 0.36839

Collected Steps per Second: 15,265.91294
Overall Steps per Second: 10,421.92250

Timestep Collection Time: 3.27802
Timestep Consumption Time: 1.52359
PPO Batch Consumption Time: 0.14037
Total Iteration Time: 4.80161

Cumulative Model Updates: 51,072
Cumulative Timesteps: 426,063,804

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 426063804...
Checkpoint 426063804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,775.15793
Policy Entropy: 0.57791
Value Function Loss: 0.08106

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06884
Policy Update Magnitude: 0.14593
Value Function Update Magnitude: 0.36656

Collected Steps per Second: 15,057.37621
Overall Steps per Second: 10,370.14387

Timestep Collection Time: 3.32090
Timestep Consumption Time: 1.50102
PPO Batch Consumption Time: 0.13582
Total Iteration Time: 4.82192

Cumulative Model Updates: 51,078
Cumulative Timesteps: 426,113,808

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,501.19110
Policy Entropy: 0.57621
Value Function Loss: 0.08463

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.06879
Policy Update Magnitude: 0.14492
Value Function Update Magnitude: 0.39250

Collected Steps per Second: 15,244.23881
Overall Steps per Second: 10,360.20038

Timestep Collection Time: 3.28111
Timestep Consumption Time: 1.54679
PPO Batch Consumption Time: 0.14247
Total Iteration Time: 4.82790

Cumulative Model Updates: 51,084
Cumulative Timesteps: 426,163,826

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 426163826...
Checkpoint 426163826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,115.04893
Policy Entropy: 0.57132
Value Function Loss: 0.09026

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.06415
Policy Update Magnitude: 0.15818
Value Function Update Magnitude: 0.40552

Collected Steps per Second: 14,854.20388
Overall Steps per Second: 10,270.34465

Timestep Collection Time: 3.36645
Timestep Consumption Time: 1.50252
PPO Batch Consumption Time: 0.13734
Total Iteration Time: 4.86897

Cumulative Model Updates: 51,090
Cumulative Timesteps: 426,213,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,534.68112
Policy Entropy: 0.57573
Value Function Loss: 0.09359

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.05989
Policy Update Magnitude: 0.16776
Value Function Update Magnitude: 0.40364

Collected Steps per Second: 15,199.06350
Overall Steps per Second: 10,382.03097

Timestep Collection Time: 3.29139
Timestep Consumption Time: 1.52713
PPO Batch Consumption Time: 0.13916
Total Iteration Time: 4.81852

Cumulative Model Updates: 51,096
Cumulative Timesteps: 426,263,858

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 426263858...
Checkpoint 426263858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,046.08393
Policy Entropy: 0.58216
Value Function Loss: 0.09657

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05185
Policy Update Magnitude: 0.17842
Value Function Update Magnitude: 0.41492

Collected Steps per Second: 14,521.57339
Overall Steps per Second: 10,111.29113

Timestep Collection Time: 3.44384
Timestep Consumption Time: 1.50211
PPO Batch Consumption Time: 0.13719
Total Iteration Time: 4.94596

Cumulative Model Updates: 51,102
Cumulative Timesteps: 426,313,868

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,546.31333
Policy Entropy: 0.57139
Value Function Loss: 0.09349

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.04802
Policy Update Magnitude: 0.17860
Value Function Update Magnitude: 0.42728

Collected Steps per Second: 15,141.76319
Overall Steps per Second: 10,484.96364

Timestep Collection Time: 3.30252
Timestep Consumption Time: 1.46678
PPO Batch Consumption Time: 0.13789
Total Iteration Time: 4.76931

Cumulative Model Updates: 51,108
Cumulative Timesteps: 426,363,874

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 426363874...
Checkpoint 426363874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,131.90453
Policy Entropy: 0.57165
Value Function Loss: 0.09316

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.05113
Policy Update Magnitude: 0.17625
Value Function Update Magnitude: 0.44098

Collected Steps per Second: 14,820.55327
Overall Steps per Second: 10,251.71746

Timestep Collection Time: 3.37450
Timestep Consumption Time: 1.50390
PPO Batch Consumption Time: 0.13769
Total Iteration Time: 4.87840

Cumulative Model Updates: 51,114
Cumulative Timesteps: 426,413,886

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,641.53142
Policy Entropy: 0.56920
Value Function Loss: 0.09848

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04420
Policy Update Magnitude: 0.18150
Value Function Update Magnitude: 0.45005

Collected Steps per Second: 15,281.40318
Overall Steps per Second: 10,540.21810

Timestep Collection Time: 3.27339
Timestep Consumption Time: 1.47243
PPO Batch Consumption Time: 0.13922
Total Iteration Time: 4.74582

Cumulative Model Updates: 51,120
Cumulative Timesteps: 426,463,908

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 426463908...
Checkpoint 426463908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,877.23441
Policy Entropy: 0.57741
Value Function Loss: 0.09748

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04795
Policy Update Magnitude: 0.18371
Value Function Update Magnitude: 0.42471

Collected Steps per Second: 14,874.23185
Overall Steps per Second: 10,252.03843

Timestep Collection Time: 3.36367
Timestep Consumption Time: 1.51653
PPO Batch Consumption Time: 0.13721
Total Iteration Time: 4.88020

Cumulative Model Updates: 51,126
Cumulative Timesteps: 426,513,940

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,026.65848
Policy Entropy: 0.58207
Value Function Loss: 0.09375

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04491
Policy Update Magnitude: 0.17505
Value Function Update Magnitude: 0.38845

Collected Steps per Second: 15,106.57381
Overall Steps per Second: 10,428.06354

Timestep Collection Time: 3.31061
Timestep Consumption Time: 1.48529
PPO Batch Consumption Time: 0.13639
Total Iteration Time: 4.79590

Cumulative Model Updates: 51,132
Cumulative Timesteps: 426,563,952

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 426563952...
Checkpoint 426563952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,433.93408
Policy Entropy: 0.58391
Value Function Loss: 0.08509

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04519
Policy Update Magnitude: 0.17670
Value Function Update Magnitude: 0.39696

Collected Steps per Second: 14,930.95107
Overall Steps per Second: 10,306.23136

Timestep Collection Time: 3.35089
Timestep Consumption Time: 1.50365
PPO Batch Consumption Time: 0.13887
Total Iteration Time: 4.85454

Cumulative Model Updates: 51,138
Cumulative Timesteps: 426,613,984

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,573.10252
Policy Entropy: 0.59346
Value Function Loss: 0.07908

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04173
Policy Update Magnitude: 0.17451
Value Function Update Magnitude: 0.41266

Collected Steps per Second: 15,123.47685
Overall Steps per Second: 10,429.91608

Timestep Collection Time: 3.30770
Timestep Consumption Time: 1.48850
PPO Batch Consumption Time: 0.13718
Total Iteration Time: 4.79620

Cumulative Model Updates: 51,144
Cumulative Timesteps: 426,664,008

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 426664008...
Checkpoint 426664008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,529.31311
Policy Entropy: 0.59597
Value Function Loss: 0.08485

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.04379
Policy Update Magnitude: 0.18041
Value Function Update Magnitude: 0.41835

Collected Steps per Second: 14,891.51668
Overall Steps per Second: 10,281.60176

Timestep Collection Time: 3.35883
Timestep Consumption Time: 1.50598
PPO Batch Consumption Time: 0.14060
Total Iteration Time: 4.86481

Cumulative Model Updates: 51,150
Cumulative Timesteps: 426,714,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,196.77299
Policy Entropy: 0.59858
Value Function Loss: 0.08166

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.04201
Policy Update Magnitude: 0.18032
Value Function Update Magnitude: 0.42751

Collected Steps per Second: 15,091.32812
Overall Steps per Second: 10,387.17060

Timestep Collection Time: 3.31409
Timestep Consumption Time: 1.50089
PPO Batch Consumption Time: 0.13641
Total Iteration Time: 4.81498

Cumulative Model Updates: 51,156
Cumulative Timesteps: 426,764,040

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 426764040...
Checkpoint 426764040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,027.74179
Policy Entropy: 0.59533
Value Function Loss: 0.08766

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03888
Policy Update Magnitude: 0.17571
Value Function Update Magnitude: 0.41422

Collected Steps per Second: 14,920.63540
Overall Steps per Second: 10,262.35190

Timestep Collection Time: 3.35415
Timestep Consumption Time: 1.52251
PPO Batch Consumption Time: 0.14038
Total Iteration Time: 4.87666

Cumulative Model Updates: 51,162
Cumulative Timesteps: 426,814,086

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,137.26712
Policy Entropy: 0.58673
Value Function Loss: 0.09054

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05429
Policy Update Magnitude: 0.17989
Value Function Update Magnitude: 0.38732

Collected Steps per Second: 15,175.19094
Overall Steps per Second: 10,496.39689

Timestep Collection Time: 3.29617
Timestep Consumption Time: 1.46928
PPO Batch Consumption Time: 0.13617
Total Iteration Time: 4.76544

Cumulative Model Updates: 51,168
Cumulative Timesteps: 426,864,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 426864106...
Checkpoint 426864106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,052.03598
Policy Entropy: 0.58703
Value Function Loss: 0.09929

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.07165
Policy Update Magnitude: 0.16853
Value Function Update Magnitude: 0.35870

Collected Steps per Second: 15,042.13576
Overall Steps per Second: 10,307.91219

Timestep Collection Time: 3.32453
Timestep Consumption Time: 1.52689
PPO Batch Consumption Time: 0.13810
Total Iteration Time: 4.85142

Cumulative Model Updates: 51,174
Cumulative Timesteps: 426,914,114

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,837.72591
Policy Entropy: 0.59178
Value Function Loss: 0.08801

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07368
Policy Update Magnitude: 0.16121
Value Function Update Magnitude: 0.37650

Collected Steps per Second: 15,147.40058
Overall Steps per Second: 10,409.12276

Timestep Collection Time: 3.30274
Timestep Consumption Time: 1.50342
PPO Batch Consumption Time: 0.13788
Total Iteration Time: 4.80617

Cumulative Model Updates: 51,180
Cumulative Timesteps: 426,964,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 426964142...
Checkpoint 426964142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,673.88941
Policy Entropy: 0.60053
Value Function Loss: 0.08990

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.06390
Policy Update Magnitude: 0.15914
Value Function Update Magnitude: 0.40828

Collected Steps per Second: 14,974.79244
Overall Steps per Second: 10,301.24285

Timestep Collection Time: 3.33908
Timestep Consumption Time: 1.51490
PPO Batch Consumption Time: 0.13980
Total Iteration Time: 4.85398

Cumulative Model Updates: 51,186
Cumulative Timesteps: 427,014,144

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,228.94612
Policy Entropy: 0.59997
Value Function Loss: 0.08617

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07054
Policy Update Magnitude: 0.15500
Value Function Update Magnitude: 0.38863

Collected Steps per Second: 14,841.69174
Overall Steps per Second: 9,946.86458

Timestep Collection Time: 3.37158
Timestep Consumption Time: 1.65915
PPO Batch Consumption Time: 0.16603
Total Iteration Time: 5.03073

Cumulative Model Updates: 51,192
Cumulative Timesteps: 427,064,184

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 427064184...
Checkpoint 427064184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,931.25748
Policy Entropy: 0.60334
Value Function Loss: 0.08578

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07598
Policy Update Magnitude: 0.16073
Value Function Update Magnitude: 0.39962

Collected Steps per Second: 14,777.17699
Overall Steps per Second: 10,240.27131

Timestep Collection Time: 3.38481
Timestep Consumption Time: 1.49963
PPO Batch Consumption Time: 0.13629
Total Iteration Time: 4.88444

Cumulative Model Updates: 51,198
Cumulative Timesteps: 427,114,202

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,639.47049
Policy Entropy: 0.60819
Value Function Loss: 0.07993

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.07481
Policy Update Magnitude: 0.17079
Value Function Update Magnitude: 0.39980

Collected Steps per Second: 15,120.84490
Overall Steps per Second: 10,379.91446

Timestep Collection Time: 3.30722
Timestep Consumption Time: 1.51054
PPO Batch Consumption Time: 0.13741
Total Iteration Time: 4.81777

Cumulative Model Updates: 51,204
Cumulative Timesteps: 427,164,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 427164210...
Checkpoint 427164210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,275.54201
Policy Entropy: 0.61056
Value Function Loss: 0.08109

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05703
Policy Update Magnitude: 0.17711
Value Function Update Magnitude: 0.38420

Collected Steps per Second: 14,948.54523
Overall Steps per Second: 10,313.64856

Timestep Collection Time: 3.34628
Timestep Consumption Time: 1.50380
PPO Batch Consumption Time: 0.13857
Total Iteration Time: 4.85008

Cumulative Model Updates: 51,210
Cumulative Timesteps: 427,214,232

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,864.95752
Policy Entropy: 0.61317
Value Function Loss: 0.08202

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05371
Policy Update Magnitude: 0.18373
Value Function Update Magnitude: 0.37721

Collected Steps per Second: 15,132.10423
Overall Steps per Second: 10,347.53956

Timestep Collection Time: 3.30476
Timestep Consumption Time: 1.52808
PPO Batch Consumption Time: 0.13927
Total Iteration Time: 4.83284

Cumulative Model Updates: 51,216
Cumulative Timesteps: 427,264,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 427264240...
Checkpoint 427264240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,730.05185
Policy Entropy: 0.60891
Value Function Loss: 0.08392

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.04143
Policy Update Magnitude: 0.18564
Value Function Update Magnitude: 0.38171

Collected Steps per Second: 13,920.60756
Overall Steps per Second: 9,737.08640

Timestep Collection Time: 3.59309
Timestep Consumption Time: 1.54376
PPO Batch Consumption Time: 0.14298
Total Iteration Time: 5.13685

Cumulative Model Updates: 51,222
Cumulative Timesteps: 427,314,258

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,481.19573
Policy Entropy: 0.61548
Value Function Loss: 0.08752

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04296
Policy Update Magnitude: 0.19180
Value Function Update Magnitude: 0.39198

Collected Steps per Second: 13,743.51339
Overall Steps per Second: 9,708.79701

Timestep Collection Time: 3.64114
Timestep Consumption Time: 1.51316
PPO Batch Consumption Time: 0.13600
Total Iteration Time: 5.15429

Cumulative Model Updates: 51,228
Cumulative Timesteps: 427,364,300

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 427364300...
Checkpoint 427364300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,839.73002
Policy Entropy: 0.61105
Value Function Loss: 0.09782

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04939
Policy Update Magnitude: 0.18973
Value Function Update Magnitude: 0.35792

Collected Steps per Second: 14,789.21031
Overall Steps per Second: 10,220.69375

Timestep Collection Time: 3.38395
Timestep Consumption Time: 1.51258
PPO Batch Consumption Time: 0.13815
Total Iteration Time: 4.89654

Cumulative Model Updates: 51,234
Cumulative Timesteps: 427,414,346

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,672.18730
Policy Entropy: 0.61201
Value Function Loss: 0.10345

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.05047
Policy Update Magnitude: 0.18828
Value Function Update Magnitude: 0.36627

Collected Steps per Second: 14,946.43576
Overall Steps per Second: 10,114.65575

Timestep Collection Time: 3.34702
Timestep Consumption Time: 1.59887
PPO Batch Consumption Time: 0.14826
Total Iteration Time: 4.94589

Cumulative Model Updates: 51,240
Cumulative Timesteps: 427,464,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 427464372...
Checkpoint 427464372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,195.82901
Policy Entropy: 0.61106
Value Function Loss: 0.10335

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04527
Policy Update Magnitude: 0.19508
Value Function Update Magnitude: 0.41204

Collected Steps per Second: 13,340.75945
Overall Steps per Second: 9,363.30815

Timestep Collection Time: 3.74821
Timestep Consumption Time: 1.59221
PPO Batch Consumption Time: 0.15035
Total Iteration Time: 5.34042

Cumulative Model Updates: 51,246
Cumulative Timesteps: 427,514,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,605.74225
Policy Entropy: 0.61715
Value Function Loss: 0.09889

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07342
Policy Update Magnitude: 0.19656
Value Function Update Magnitude: 0.45386

Collected Steps per Second: 14,293.08759
Overall Steps per Second: 9,905.32100

Timestep Collection Time: 3.49833
Timestep Consumption Time: 1.54966
PPO Batch Consumption Time: 0.15022
Total Iteration Time: 5.04799

Cumulative Model Updates: 51,252
Cumulative Timesteps: 427,564,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 427564378...
Checkpoint 427564378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,043.60557
Policy Entropy: 0.60508
Value Function Loss: 0.09308

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.09565
Policy Update Magnitude: 0.17299
Value Function Update Magnitude: 0.47428

Collected Steps per Second: 13,749.24015
Overall Steps per Second: 9,504.88366

Timestep Collection Time: 3.63773
Timestep Consumption Time: 1.62441
PPO Batch Consumption Time: 0.15486
Total Iteration Time: 5.26214

Cumulative Model Updates: 51,258
Cumulative Timesteps: 427,614,394

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,563.66830
Policy Entropy: 0.60778
Value Function Loss: 0.09114

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.09669
Policy Update Magnitude: 0.16257
Value Function Update Magnitude: 0.45019

Collected Steps per Second: 13,850.65220
Overall Steps per Second: 9,651.06781

Timestep Collection Time: 3.61052
Timestep Consumption Time: 1.57109
PPO Batch Consumption Time: 0.13890
Total Iteration Time: 5.18160

Cumulative Model Updates: 51,264
Cumulative Timesteps: 427,664,402

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 427664402...
Checkpoint 427664402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,766.04380
Policy Entropy: 0.60714
Value Function Loss: 0.09086

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.16109
Value Function Update Magnitude: 0.44576

Collected Steps per Second: 13,974.96283
Overall Steps per Second: 9,744.49102

Timestep Collection Time: 3.57840
Timestep Consumption Time: 1.55353
PPO Batch Consumption Time: 0.14490
Total Iteration Time: 5.13193

Cumulative Model Updates: 51,270
Cumulative Timesteps: 427,714,410

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,668.28198
Policy Entropy: 0.60984
Value Function Loss: 0.08358

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07586
Policy Update Magnitude: 0.16828
Value Function Update Magnitude: 0.42434

Collected Steps per Second: 14,879.97595
Overall Steps per Second: 9,827.28796

Timestep Collection Time: 3.36197
Timestep Consumption Time: 1.72855
PPO Batch Consumption Time: 0.15665
Total Iteration Time: 5.09052

Cumulative Model Updates: 51,276
Cumulative Timesteps: 427,764,436

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 427764436...
Checkpoint 427764436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,164.37896
Policy Entropy: 0.61320
Value Function Loss: 0.08334

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07477
Policy Update Magnitude: 0.16650
Value Function Update Magnitude: 0.37904

Collected Steps per Second: 12,581.48770
Overall Steps per Second: 8,806.97748

Timestep Collection Time: 3.97552
Timestep Consumption Time: 1.70384
PPO Batch Consumption Time: 0.16194
Total Iteration Time: 5.67936

Cumulative Model Updates: 51,282
Cumulative Timesteps: 427,814,454

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,421.01406
Policy Entropy: 0.61889
Value Function Loss: 0.08316

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.06534
Policy Update Magnitude: 0.17043
Value Function Update Magnitude: 0.36960

Collected Steps per Second: 12,818.70078
Overall Steps per Second: 8,937.63946

Timestep Collection Time: 3.90055
Timestep Consumption Time: 1.69377
PPO Batch Consumption Time: 0.15953
Total Iteration Time: 5.59432

Cumulative Model Updates: 51,288
Cumulative Timesteps: 427,864,454

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 427864454...
Checkpoint 427864454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,748.34560
Policy Entropy: 0.63089
Value Function Loss: 0.08192

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.05885
Policy Update Magnitude: 0.17718
Value Function Update Magnitude: 0.38631

Collected Steps per Second: 13,137.65253
Overall Steps per Second: 9,059.41830

Timestep Collection Time: 3.80738
Timestep Consumption Time: 1.71395
PPO Batch Consumption Time: 0.16365
Total Iteration Time: 5.52133

Cumulative Model Updates: 51,294
Cumulative Timesteps: 427,914,474

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,287.98219
Policy Entropy: 0.63103
Value Function Loss: 0.08525

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07591
Policy Update Magnitude: 0.17358
Value Function Update Magnitude: 0.38954

Collected Steps per Second: 13,802.10499
Overall Steps per Second: 9,321.10485

Timestep Collection Time: 3.62466
Timestep Consumption Time: 1.74251
PPO Batch Consumption Time: 0.16414
Total Iteration Time: 5.36717

Cumulative Model Updates: 51,300
Cumulative Timesteps: 427,964,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 427964502...
Checkpoint 427964502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,825.79072
Policy Entropy: 0.62067
Value Function Loss: 0.08757

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06964
Policy Update Magnitude: 0.16970
Value Function Update Magnitude: 0.38500

Collected Steps per Second: 13,885.01313
Overall Steps per Second: 9,728.52069

Timestep Collection Time: 3.60360
Timestep Consumption Time: 1.53963
PPO Batch Consumption Time: 0.14049
Total Iteration Time: 5.14323

Cumulative Model Updates: 51,306
Cumulative Timesteps: 428,014,538

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,346.71247
Policy Entropy: 0.63134
Value Function Loss: 0.09623

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07833
Policy Update Magnitude: 0.17522
Value Function Update Magnitude: 0.38902

Collected Steps per Second: 14,870.71052
Overall Steps per Second: 10,213.67341

Timestep Collection Time: 3.36272
Timestep Consumption Time: 1.53327
PPO Batch Consumption Time: 0.14175
Total Iteration Time: 4.89599

Cumulative Model Updates: 51,312
Cumulative Timesteps: 428,064,544

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 428064544...
Checkpoint 428064544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,838.35928
Policy Entropy: 0.62294
Value Function Loss: 0.08482

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.07345
Policy Update Magnitude: 0.16921
Value Function Update Magnitude: 0.42085

Collected Steps per Second: 14,873.76070
Overall Steps per Second: 10,137.98747

Timestep Collection Time: 3.36243
Timestep Consumption Time: 1.57070
PPO Batch Consumption Time: 0.14724
Total Iteration Time: 4.93313

Cumulative Model Updates: 51,318
Cumulative Timesteps: 428,114,556

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,119.49195
Policy Entropy: 0.63356
Value Function Loss: 0.08209

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07093
Policy Update Magnitude: 0.17395
Value Function Update Magnitude: 0.41542

Collected Steps per Second: 14,044.94934
Overall Steps per Second: 9,501.68197

Timestep Collection Time: 3.56156
Timestep Consumption Time: 1.70298
PPO Batch Consumption Time: 0.16162
Total Iteration Time: 5.26454

Cumulative Model Updates: 51,324
Cumulative Timesteps: 428,164,578

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 428164578...
Checkpoint 428164578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,321.50088
Policy Entropy: 0.62322
Value Function Loss: 0.07748

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.06655
Policy Update Magnitude: 0.17435
Value Function Update Magnitude: 0.40314

Collected Steps per Second: 14,371.60027
Overall Steps per Second: 9,980.92567

Timestep Collection Time: 3.47978
Timestep Consumption Time: 1.53078
PPO Batch Consumption Time: 0.14011
Total Iteration Time: 5.01056

Cumulative Model Updates: 51,330
Cumulative Timesteps: 428,214,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,340.43508
Policy Entropy: 0.63067
Value Function Loss: 0.08607

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.06799
Policy Update Magnitude: 0.17854
Value Function Update Magnitude: 0.41404

Collected Steps per Second: 13,689.41470
Overall Steps per Second: 9,345.35916

Timestep Collection Time: 3.65304
Timestep Consumption Time: 1.69806
PPO Batch Consumption Time: 0.16010
Total Iteration Time: 5.35111

Cumulative Model Updates: 51,336
Cumulative Timesteps: 428,264,596

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 428264596...
Checkpoint 428264596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,106.43838
Policy Entropy: 0.63131
Value Function Loss: 0.08514

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07002
Policy Update Magnitude: 0.18959
Value Function Update Magnitude: 0.41962

Collected Steps per Second: 12,922.98263
Overall Steps per Second: 9,396.21428

Timestep Collection Time: 3.87264
Timestep Consumption Time: 1.45355
PPO Batch Consumption Time: 0.14149
Total Iteration Time: 5.32619

Cumulative Model Updates: 51,342
Cumulative Timesteps: 428,314,642

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,788.43169
Policy Entropy: 0.63631
Value Function Loss: 0.07946

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.06010
Policy Update Magnitude: 0.18997
Value Function Update Magnitude: 0.41416

Collected Steps per Second: 13,583.07146
Overall Steps per Second: 9,437.99367

Timestep Collection Time: 3.68223
Timestep Consumption Time: 1.61720
PPO Batch Consumption Time: 0.16327
Total Iteration Time: 5.29943

Cumulative Model Updates: 51,348
Cumulative Timesteps: 428,364,658

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 428364658...
Checkpoint 428364658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,771.70283
Policy Entropy: 0.64200
Value Function Loss: 0.07597

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04946
Policy Update Magnitude: 0.19267
Value Function Update Magnitude: 0.41034

Collected Steps per Second: 12,927.90835
Overall Steps per Second: 9,154.19382

Timestep Collection Time: 3.86853
Timestep Consumption Time: 1.59476
PPO Batch Consumption Time: 0.16175
Total Iteration Time: 5.46329

Cumulative Model Updates: 51,354
Cumulative Timesteps: 428,414,670

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,163.53119
Policy Entropy: 0.63176
Value Function Loss: 0.08428

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04385
Policy Update Magnitude: 0.20009
Value Function Update Magnitude: 0.37179

Collected Steps per Second: 13,970.94499
Overall Steps per Second: 10,030.31909

Timestep Collection Time: 3.58129
Timestep Consumption Time: 1.40699
PPO Batch Consumption Time: 0.13735
Total Iteration Time: 4.98828

Cumulative Model Updates: 51,360
Cumulative Timesteps: 428,464,704

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 428464704...
Checkpoint 428464704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,376.30786
Policy Entropy: 0.62600
Value Function Loss: 0.09106

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04520
Policy Update Magnitude: 0.20362
Value Function Update Magnitude: 0.32748

Collected Steps per Second: 14,523.53856
Overall Steps per Second: 10,288.71874

Timestep Collection Time: 3.44489
Timestep Consumption Time: 1.41791
PPO Batch Consumption Time: 0.13886
Total Iteration Time: 4.86280

Cumulative Model Updates: 51,366
Cumulative Timesteps: 428,514,736

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,754.08586
Policy Entropy: 0.61796
Value Function Loss: 0.09302

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05529
Policy Update Magnitude: 0.19635
Value Function Update Magnitude: 0.37102

Collected Steps per Second: 14,741.16836
Overall Steps per Second: 10,389.94427

Timestep Collection Time: 3.39295
Timestep Consumption Time: 1.42094
PPO Batch Consumption Time: 0.13784
Total Iteration Time: 4.81389

Cumulative Model Updates: 51,372
Cumulative Timesteps: 428,564,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 428564752...
Checkpoint 428564752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,509.74543
Policy Entropy: 0.62235
Value Function Loss: 0.08764

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05778
Policy Update Magnitude: 0.18179
Value Function Update Magnitude: 0.40856

Collected Steps per Second: 14,469.58674
Overall Steps per Second: 10,289.85519

Timestep Collection Time: 3.45746
Timestep Consumption Time: 1.40442
PPO Batch Consumption Time: 0.13657
Total Iteration Time: 4.86188

Cumulative Model Updates: 51,378
Cumulative Timesteps: 428,614,780

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,879.03219
Policy Entropy: 0.62439
Value Function Loss: 0.08440

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07019
Policy Update Magnitude: 0.16890
Value Function Update Magnitude: 0.42860

Collected Steps per Second: 12,247.64931
Overall Steps per Second: 8,759.50544

Timestep Collection Time: 4.08438
Timestep Consumption Time: 1.62645
PPO Batch Consumption Time: 0.16476
Total Iteration Time: 5.71082

Cumulative Model Updates: 51,384
Cumulative Timesteps: 428,664,804

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 428664804...
Checkpoint 428664804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,375.00391
Policy Entropy: 0.62153
Value Function Loss: 0.09044

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06189
Policy Update Magnitude: 0.17125
Value Function Update Magnitude: 0.42455

Collected Steps per Second: 12,558.77447
Overall Steps per Second: 8,836.42778

Timestep Collection Time: 3.98287
Timestep Consumption Time: 1.67779
PPO Batch Consumption Time: 0.16090
Total Iteration Time: 5.66066

Cumulative Model Updates: 51,390
Cumulative Timesteps: 428,714,824

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,894.22187
Policy Entropy: 0.61257
Value Function Loss: 0.09161

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06425
Policy Update Magnitude: 0.18302
Value Function Update Magnitude: 0.42690

Collected Steps per Second: 12,830.56376
Overall Steps per Second: 8,977.70615

Timestep Collection Time: 3.89975
Timestep Consumption Time: 1.67361
PPO Batch Consumption Time: 0.16229
Total Iteration Time: 5.57336

Cumulative Model Updates: 51,396
Cumulative Timesteps: 428,764,860

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 428764860...
Checkpoint 428764860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,276.84524
Policy Entropy: 0.61585
Value Function Loss: 0.09494

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06419
Policy Update Magnitude: 0.18364
Value Function Update Magnitude: 0.42494

Collected Steps per Second: 12,733.33017
Overall Steps per Second: 8,885.36168

Timestep Collection Time: 3.92890
Timestep Consumption Time: 1.70148
PPO Batch Consumption Time: 0.16515
Total Iteration Time: 5.63038

Cumulative Model Updates: 51,402
Cumulative Timesteps: 428,814,888

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,661.19813
Policy Entropy: 0.62192
Value Function Loss: 0.08680

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04604
Policy Update Magnitude: 0.18471
Value Function Update Magnitude: 0.45430

Collected Steps per Second: 12,596.22247
Overall Steps per Second: 8,827.25427

Timestep Collection Time: 3.97103
Timestep Consumption Time: 1.69551
PPO Batch Consumption Time: 0.16342
Total Iteration Time: 5.66654

Cumulative Model Updates: 51,408
Cumulative Timesteps: 428,864,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 428864908...
Checkpoint 428864908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,252.93769
Policy Entropy: 0.62029
Value Function Loss: 0.09093

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04702
Policy Update Magnitude: 0.19242
Value Function Update Magnitude: 0.46222

Collected Steps per Second: 13,235.73141
Overall Steps per Second: 9,186.63355

Timestep Collection Time: 3.77856
Timestep Consumption Time: 1.66544
PPO Batch Consumption Time: 0.15975
Total Iteration Time: 5.44400

Cumulative Model Updates: 51,414
Cumulative Timesteps: 428,914,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,234.63445
Policy Entropy: 0.62003
Value Function Loss: 0.08856

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.05928
Policy Update Magnitude: 0.19237
Value Function Update Magnitude: 0.47686

Collected Steps per Second: 14,176.71550
Overall Steps per Second: 9,637.15426

Timestep Collection Time: 3.52705
Timestep Consumption Time: 1.66141
PPO Batch Consumption Time: 0.16035
Total Iteration Time: 5.18846

Cumulative Model Updates: 51,420
Cumulative Timesteps: 428,964,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 428964922...
Checkpoint 428964922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,079.92061
Policy Entropy: 0.61620
Value Function Loss: 0.08827

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.06832
Policy Update Magnitude: 0.18113
Value Function Update Magnitude: 0.46038

Collected Steps per Second: 13,376.72303
Overall Steps per Second: 9,517.78352

Timestep Collection Time: 3.73858
Timestep Consumption Time: 1.51579
PPO Batch Consumption Time: 0.14366
Total Iteration Time: 5.25437

Cumulative Model Updates: 51,426
Cumulative Timesteps: 429,014,932

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,080.56351
Policy Entropy: 0.61880
Value Function Loss: 0.08356

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08259
Policy Update Magnitude: 0.17949
Value Function Update Magnitude: 0.46072

Collected Steps per Second: 12,977.04037
Overall Steps per Second: 9,131.87652

Timestep Collection Time: 3.85419
Timestep Consumption Time: 1.62289
PPO Batch Consumption Time: 0.14544
Total Iteration Time: 5.47708

Cumulative Model Updates: 51,432
Cumulative Timesteps: 429,064,948

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 429064948...
Checkpoint 429064948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,096.11619
Policy Entropy: 0.61970
Value Function Loss: 0.08898

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07599
Policy Update Magnitude: 0.17451
Value Function Update Magnitude: 0.45030

Collected Steps per Second: 14,068.53296
Overall Steps per Second: 9,905.73328

Timestep Collection Time: 3.55417
Timestep Consumption Time: 1.49361
PPO Batch Consumption Time: 0.13411
Total Iteration Time: 5.04778

Cumulative Model Updates: 51,438
Cumulative Timesteps: 429,114,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,993.31993
Policy Entropy: 0.62637
Value Function Loss: 0.09568

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07476
Policy Update Magnitude: 0.16587
Value Function Update Magnitude: 0.43700

Collected Steps per Second: 13,461.24413
Overall Steps per Second: 9,546.31050

Timestep Collection Time: 3.71511
Timestep Consumption Time: 1.52356
PPO Batch Consumption Time: 0.14195
Total Iteration Time: 5.23867

Cumulative Model Updates: 51,444
Cumulative Timesteps: 429,164,960

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 429164960...
Checkpoint 429164960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,202.12451
Policy Entropy: 0.62601
Value Function Loss: 0.09664

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07748
Policy Update Magnitude: 0.16336
Value Function Update Magnitude: 0.43005

Collected Steps per Second: 14,551.48033
Overall Steps per Second: 9,794.98249

Timestep Collection Time: 3.43759
Timestep Consumption Time: 1.66931
PPO Batch Consumption Time: 0.15730
Total Iteration Time: 5.10690

Cumulative Model Updates: 51,450
Cumulative Timesteps: 429,214,982

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,962.28905
Policy Entropy: 0.62524
Value Function Loss: 0.09500

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05085
Policy Update Magnitude: 0.17925
Value Function Update Magnitude: 0.41713

Collected Steps per Second: 13,722.46921
Overall Steps per Second: 9,502.85934

Timestep Collection Time: 3.64424
Timestep Consumption Time: 1.61817
PPO Batch Consumption Time: 0.14819
Total Iteration Time: 5.26242

Cumulative Model Updates: 51,456
Cumulative Timesteps: 429,264,990

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 429264990...
Checkpoint 429264990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,353.33243
Policy Entropy: 0.62133
Value Function Loss: 0.09412

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04795
Policy Update Magnitude: 0.19812
Value Function Update Magnitude: 0.41897

Collected Steps per Second: 14,027.89191
Overall Steps per Second: 9,722.69800

Timestep Collection Time: 3.56504
Timestep Consumption Time: 1.57859
PPO Batch Consumption Time: 0.14237
Total Iteration Time: 5.14363

Cumulative Model Updates: 51,462
Cumulative Timesteps: 429,315,000

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,738.28366
Policy Entropy: 0.62287
Value Function Loss: 0.09340

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.05012
Policy Update Magnitude: 0.19737
Value Function Update Magnitude: 0.43042

Collected Steps per Second: 14,039.83596
Overall Steps per Second: 9,663.67431

Timestep Collection Time: 3.56357
Timestep Consumption Time: 1.61375
PPO Batch Consumption Time: 0.15140
Total Iteration Time: 5.17733

Cumulative Model Updates: 51,468
Cumulative Timesteps: 429,365,032

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 429365032...
Checkpoint 429365032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,036.10994
Policy Entropy: 0.62831
Value Function Loss: 0.08899

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04594
Policy Update Magnitude: 0.18881
Value Function Update Magnitude: 0.43342

Collected Steps per Second: 12,966.05678
Overall Steps per Second: 9,215.73583

Timestep Collection Time: 3.85746
Timestep Consumption Time: 1.56978
PPO Batch Consumption Time: 0.14128
Total Iteration Time: 5.42724

Cumulative Model Updates: 51,474
Cumulative Timesteps: 429,415,048

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,652.30148
Policy Entropy: 0.63861
Value Function Loss: 0.07937

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04829
Policy Update Magnitude: 0.19059
Value Function Update Magnitude: 0.42242

Collected Steps per Second: 12,912.31814
Overall Steps per Second: 9,176.89198

Timestep Collection Time: 3.87367
Timestep Consumption Time: 1.57676
PPO Batch Consumption Time: 0.15113
Total Iteration Time: 5.45043

Cumulative Model Updates: 51,480
Cumulative Timesteps: 429,465,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 429465066...
Checkpoint 429465066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,643.73565
Policy Entropy: 0.64619
Value Function Loss: 0.07945

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04645
Policy Update Magnitude: 0.18340
Value Function Update Magnitude: 0.39407

Collected Steps per Second: 12,615.31446
Overall Steps per Second: 8,804.47720

Timestep Collection Time: 3.96566
Timestep Consumption Time: 1.71645
PPO Batch Consumption Time: 0.16077
Total Iteration Time: 5.68211

Cumulative Model Updates: 51,486
Cumulative Timesteps: 429,515,094

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,916.87581
Policy Entropy: 0.64677
Value Function Loss: 0.08225

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.04777
Policy Update Magnitude: 0.18712
Value Function Update Magnitude: 0.40644

Collected Steps per Second: 14,183.86897
Overall Steps per Second: 9,655.25552

Timestep Collection Time: 3.52598
Timestep Consumption Time: 1.65379
PPO Batch Consumption Time: 0.13132
Total Iteration Time: 5.17977

Cumulative Model Updates: 51,492
Cumulative Timesteps: 429,565,106

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 429565106...
Checkpoint 429565106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,249.92270
Policy Entropy: 0.64358
Value Function Loss: 0.09373

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.05314
Policy Update Magnitude: 0.19422
Value Function Update Magnitude: 0.42848

Collected Steps per Second: 12,630.63112
Overall Steps per Second: 9,138.77356

Timestep Collection Time: 3.95942
Timestep Consumption Time: 1.51287
PPO Batch Consumption Time: 0.12501
Total Iteration Time: 5.47229

Cumulative Model Updates: 51,498
Cumulative Timesteps: 429,615,116

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,022.73541
Policy Entropy: 0.63803
Value Function Loss: 0.09683

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.05501
Policy Update Magnitude: 0.19560
Value Function Update Magnitude: 0.41615

Collected Steps per Second: 15,550.76663
Overall Steps per Second: 11,046.76968

Timestep Collection Time: 3.21566
Timestep Consumption Time: 1.31109
PPO Batch Consumption Time: 0.10960
Total Iteration Time: 4.52675

Cumulative Model Updates: 51,504
Cumulative Timesteps: 429,665,122

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 429665122...
Checkpoint 429665122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,453.09322
Policy Entropy: 0.64495
Value Function Loss: 0.09439

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05336
Policy Update Magnitude: 0.19204
Value Function Update Magnitude: 0.39210

Collected Steps per Second: 15,974.88950
Overall Steps per Second: 11,063.14544

Timestep Collection Time: 3.13004
Timestep Consumption Time: 1.38965
PPO Batch Consumption Time: 0.11729
Total Iteration Time: 4.51969

Cumulative Model Updates: 51,510
Cumulative Timesteps: 429,715,124

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,327.90630
Policy Entropy: 0.64686
Value Function Loss: 0.09948

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04703
Policy Update Magnitude: 0.18916
Value Function Update Magnitude: 0.39857

Collected Steps per Second: 16,158.51934
Overall Steps per Second: 11,260.54207

Timestep Collection Time: 3.09682
Timestep Consumption Time: 1.34702
PPO Batch Consumption Time: 0.11170
Total Iteration Time: 4.44384

Cumulative Model Updates: 51,516
Cumulative Timesteps: 429,765,164

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 429765164...
Checkpoint 429765164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,285.60153
Policy Entropy: 0.64761
Value Function Loss: 0.10594

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04720
Policy Update Magnitude: 0.19077
Value Function Update Magnitude: 0.41541

Collected Steps per Second: 15,925.69072
Overall Steps per Second: 10,920.05896

Timestep Collection Time: 3.14071
Timestep Consumption Time: 1.43967
PPO Batch Consumption Time: 0.12879
Total Iteration Time: 4.58038

Cumulative Model Updates: 51,522
Cumulative Timesteps: 429,815,182

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,788.57766
Policy Entropy: 0.63710
Value Function Loss: 0.10197

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05709
Policy Update Magnitude: 0.18742
Value Function Update Magnitude: 0.40011

Collected Steps per Second: 15,375.30805
Overall Steps per Second: 10,684.91442

Timestep Collection Time: 3.25236
Timestep Consumption Time: 1.42770
PPO Batch Consumption Time: 0.12430
Total Iteration Time: 4.68006

Cumulative Model Updates: 51,528
Cumulative Timesteps: 429,865,188

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 429865188...
Checkpoint 429865188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,855.85403
Policy Entropy: 0.64276
Value Function Loss: 0.10036

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04981
Policy Update Magnitude: 0.18997
Value Function Update Magnitude: 0.37070

Collected Steps per Second: 15,771.91727
Overall Steps per Second: 10,978.80093

Timestep Collection Time: 3.17146
Timestep Consumption Time: 1.38459
PPO Batch Consumption Time: 0.11375
Total Iteration Time: 4.55605

Cumulative Model Updates: 51,534
Cumulative Timesteps: 429,915,208

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,445.17922
Policy Entropy: 0.64290
Value Function Loss: 0.09229

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.04482
Policy Update Magnitude: 0.18757
Value Function Update Magnitude: 0.38843

Collected Steps per Second: 15,902.42932
Overall Steps per Second: 11,133.81196

Timestep Collection Time: 3.14531
Timestep Consumption Time: 1.34714
PPO Batch Consumption Time: 0.11519
Total Iteration Time: 4.49244

Cumulative Model Updates: 51,540
Cumulative Timesteps: 429,965,226

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 429965226...
Checkpoint 429965226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,954.46317
Policy Entropy: 0.65032
Value Function Loss: 0.09299

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03737
Policy Update Magnitude: 0.18411
Value Function Update Magnitude: 0.38620

Collected Steps per Second: 15,754.17392
Overall Steps per Second: 10,975.05958

Timestep Collection Time: 3.17529
Timestep Consumption Time: 1.38269
PPO Batch Consumption Time: 0.11832
Total Iteration Time: 4.55797

Cumulative Model Updates: 51,546
Cumulative Timesteps: 430,015,250

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,299.51951
Policy Entropy: 0.65672
Value Function Loss: 0.09779

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03708
Policy Update Magnitude: 0.19235
Value Function Update Magnitude: 0.41277

Collected Steps per Second: 15,465.60559
Overall Steps per Second: 10,704.95693

Timestep Collection Time: 3.23557
Timestep Consumption Time: 1.43890
PPO Batch Consumption Time: 0.12560
Total Iteration Time: 4.67447

Cumulative Model Updates: 51,552
Cumulative Timesteps: 430,065,290

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 430065290...
Checkpoint 430065290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,749.91453
Policy Entropy: 0.66282
Value Function Loss: 0.09653

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05561
Policy Update Magnitude: 0.19329
Value Function Update Magnitude: 0.41035

Collected Steps per Second: 15,172.70173
Overall Steps per Second: 10,641.47823

Timestep Collection Time: 3.29618
Timestep Consumption Time: 1.40354
PPO Batch Consumption Time: 0.12509
Total Iteration Time: 4.69972

Cumulative Model Updates: 51,558
Cumulative Timesteps: 430,115,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,386.57005
Policy Entropy: 0.64621
Value Function Loss: 0.09561

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08669
Policy Update Magnitude: 0.17161
Value Function Update Magnitude: 0.40831

Collected Steps per Second: 15,492.79879
Overall Steps per Second: 10,792.56223

Timestep Collection Time: 3.22963
Timestep Consumption Time: 1.40653
PPO Batch Consumption Time: 0.11976
Total Iteration Time: 4.63616

Cumulative Model Updates: 51,564
Cumulative Timesteps: 430,165,338

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 430165338...
Checkpoint 430165338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,973.58655
Policy Entropy: 0.65469
Value Function Loss: 0.07752

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.15672
Value Function Update Magnitude: 0.38684

Collected Steps per Second: 15,641.87880
Overall Steps per Second: 10,935.55716

Timestep Collection Time: 3.19706
Timestep Consumption Time: 1.37591
PPO Batch Consumption Time: 0.11559
Total Iteration Time: 4.57297

Cumulative Model Updates: 51,570
Cumulative Timesteps: 430,215,346

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,717.31653
Policy Entropy: 0.64288
Value Function Loss: 0.08378

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06426
Policy Update Magnitude: 0.16280
Value Function Update Magnitude: 0.34149

Collected Steps per Second: 16,431.25552
Overall Steps per Second: 11,272.43951

Timestep Collection Time: 3.04298
Timestep Consumption Time: 1.39262
PPO Batch Consumption Time: 0.11838
Total Iteration Time: 4.43560

Cumulative Model Updates: 51,576
Cumulative Timesteps: 430,265,346

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 430265346...
Checkpoint 430265346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,908.88293
Policy Entropy: 0.64410
Value Function Loss: 0.09180

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.06629
Policy Update Magnitude: 0.17857
Value Function Update Magnitude: 0.33338

Collected Steps per Second: 15,683.43346
Overall Steps per Second: 11,030.51681

Timestep Collection Time: 3.18910
Timestep Consumption Time: 1.34523
PPO Batch Consumption Time: 0.11040
Total Iteration Time: 4.53433

Cumulative Model Updates: 51,582
Cumulative Timesteps: 430,315,362

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,875.86295
Policy Entropy: 0.64254
Value Function Loss: 0.10517

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07891
Policy Update Magnitude: 0.17985
Value Function Update Magnitude: 0.34623

Collected Steps per Second: 15,349.95082
Overall Steps per Second: 10,678.66403

Timestep Collection Time: 3.25786
Timestep Consumption Time: 1.42512
PPO Batch Consumption Time: 0.12230
Total Iteration Time: 4.68298

Cumulative Model Updates: 51,588
Cumulative Timesteps: 430,365,370

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 430365370...
Checkpoint 430365370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,057.58142
Policy Entropy: 0.64184
Value Function Loss: 0.10998

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08354
Policy Update Magnitude: 0.17070
Value Function Update Magnitude: 0.40417

Collected Steps per Second: 15,642.14965
Overall Steps per Second: 10,890.18711

Timestep Collection Time: 3.19713
Timestep Consumption Time: 1.39508
PPO Batch Consumption Time: 0.11669
Total Iteration Time: 4.59221

Cumulative Model Updates: 51,594
Cumulative Timesteps: 430,415,380

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,527.81307
Policy Entropy: 0.64331
Value Function Loss: 0.10284

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07811
Policy Update Magnitude: 0.17009
Value Function Update Magnitude: 0.40680

Collected Steps per Second: 16,384.54176
Overall Steps per Second: 11,340.65602

Timestep Collection Time: 3.05312
Timestep Consumption Time: 1.35791
PPO Batch Consumption Time: 0.11008
Total Iteration Time: 4.41103

Cumulative Model Updates: 51,600
Cumulative Timesteps: 430,465,404

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 430465404...
Checkpoint 430465404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,765.91256
Policy Entropy: 0.65480
Value Function Loss: 0.11000

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07045
Policy Update Magnitude: 0.18484
Value Function Update Magnitude: 0.37982

Collected Steps per Second: 16,096.46396
Overall Steps per Second: 11,146.22957

Timestep Collection Time: 3.10727
Timestep Consumption Time: 1.37999
PPO Batch Consumption Time: 0.11531
Total Iteration Time: 4.48726

Cumulative Model Updates: 51,606
Cumulative Timesteps: 430,515,420

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,666.30988
Policy Entropy: 0.66873
Value Function Loss: 0.09610

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06117
Policy Update Magnitude: 0.19048
Value Function Update Magnitude: 0.36215

Collected Steps per Second: 16,162.41730
Overall Steps per Second: 11,209.30433

Timestep Collection Time: 3.09459
Timestep Consumption Time: 1.36742
PPO Batch Consumption Time: 0.11335
Total Iteration Time: 4.46201

Cumulative Model Updates: 51,612
Cumulative Timesteps: 430,565,436

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 430565436...
Checkpoint 430565436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,191.23763
Policy Entropy: 0.67135
Value Function Loss: 0.08870

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06134
Policy Update Magnitude: 0.18020
Value Function Update Magnitude: 0.35776

Collected Steps per Second: 15,975.19669
Overall Steps per Second: 11,050.50733

Timestep Collection Time: 3.13023
Timestep Consumption Time: 1.39499
PPO Batch Consumption Time: 0.12016
Total Iteration Time: 4.52522

Cumulative Model Updates: 51,618
Cumulative Timesteps: 430,615,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,416.88963
Policy Entropy: 0.66407
Value Function Loss: 0.08557

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.07213
Policy Update Magnitude: 0.16262
Value Function Update Magnitude: 0.37522

Collected Steps per Second: 16,207.91711
Overall Steps per Second: 11,284.24317

Timestep Collection Time: 3.08578
Timestep Consumption Time: 1.34642
PPO Batch Consumption Time: 0.11328
Total Iteration Time: 4.43220

Cumulative Model Updates: 51,624
Cumulative Timesteps: 430,665,456

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 430665456...
Checkpoint 430665456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,970.04710
Policy Entropy: 0.64528
Value Function Loss: 0.09075

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06693
Policy Update Magnitude: 0.16701
Value Function Update Magnitude: 0.38557

Collected Steps per Second: 15,952.58877
Overall Steps per Second: 11,067.97925

Timestep Collection Time: 3.13617
Timestep Consumption Time: 1.38408
PPO Batch Consumption Time: 0.11597
Total Iteration Time: 4.52025

Cumulative Model Updates: 51,630
Cumulative Timesteps: 430,715,486

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,214.66163
Policy Entropy: 0.63297
Value Function Loss: 0.09597

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.06796
Policy Update Magnitude: 0.17594
Value Function Update Magnitude: 0.40768

Collected Steps per Second: 16,426.23442
Overall Steps per Second: 11,414.89840

Timestep Collection Time: 3.04549
Timestep Consumption Time: 1.33702
PPO Batch Consumption Time: 0.10982
Total Iteration Time: 4.38252

Cumulative Model Updates: 51,636
Cumulative Timesteps: 430,765,512

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 430765512...
Checkpoint 430765512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,955.45402
Policy Entropy: 0.63379
Value Function Loss: 0.09828

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06480
Policy Update Magnitude: 0.18017
Value Function Update Magnitude: 0.41590

Collected Steps per Second: 15,877.35968
Overall Steps per Second: 11,103.76983

Timestep Collection Time: 3.14989
Timestep Consumption Time: 1.35416
PPO Batch Consumption Time: 0.11212
Total Iteration Time: 4.50406

Cumulative Model Updates: 51,642
Cumulative Timesteps: 430,815,524

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,726.15558
Policy Entropy: 0.64065
Value Function Loss: 0.09859

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04652
Policy Update Magnitude: 0.17829
Value Function Update Magnitude: 0.41509

Collected Steps per Second: 16,088.73716
Overall Steps per Second: 11,062.46266

Timestep Collection Time: 3.10876
Timestep Consumption Time: 1.41248
PPO Batch Consumption Time: 0.12421
Total Iteration Time: 4.52124

Cumulative Model Updates: 51,648
Cumulative Timesteps: 430,865,540

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 430865540...
Checkpoint 430865540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,581.94514
Policy Entropy: 0.64450
Value Function Loss: 0.10176

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04388
Policy Update Magnitude: 0.18319
Value Function Update Magnitude: 0.41479

Collected Steps per Second: 16,198.40740
Overall Steps per Second: 11,373.06981

Timestep Collection Time: 3.08833
Timestep Consumption Time: 1.31031
PPO Batch Consumption Time: 0.11163
Total Iteration Time: 4.39864

Cumulative Model Updates: 51,654
Cumulative Timesteps: 430,915,566

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,239.76171
Policy Entropy: 0.64875
Value Function Loss: 0.09359

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03875
Policy Update Magnitude: 0.18326
Value Function Update Magnitude: 0.42615

Collected Steps per Second: 16,436.56861
Overall Steps per Second: 11,267.39888

Timestep Collection Time: 3.04480
Timestep Consumption Time: 1.39687
PPO Batch Consumption Time: 0.11777
Total Iteration Time: 4.44166

Cumulative Model Updates: 51,660
Cumulative Timesteps: 430,965,612

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 430965612...
Checkpoint 430965612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,235.18801
Policy Entropy: 0.65005
Value Function Loss: 0.09097

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03660
Policy Update Magnitude: 0.18554
Value Function Update Magnitude: 0.40781

Collected Steps per Second: 15,810.94471
Overall Steps per Second: 11,020.07308

Timestep Collection Time: 3.16426
Timestep Consumption Time: 1.37563
PPO Batch Consumption Time: 0.12036
Total Iteration Time: 4.53990

Cumulative Model Updates: 51,666
Cumulative Timesteps: 431,015,642

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,513.76644
Policy Entropy: 0.65358
Value Function Loss: 0.08448

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.04382
Policy Update Magnitude: 0.18855
Value Function Update Magnitude: 0.41337

Collected Steps per Second: 15,610.87596
Overall Steps per Second: 10,846.00039

Timestep Collection Time: 3.20354
Timestep Consumption Time: 1.40738
PPO Batch Consumption Time: 0.12623
Total Iteration Time: 4.61092

Cumulative Model Updates: 51,672
Cumulative Timesteps: 431,065,652

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 431065652...
Checkpoint 431065652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,888.37394
Policy Entropy: 0.65367
Value Function Loss: 0.08667

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03792
Policy Update Magnitude: 0.18809
Value Function Update Magnitude: 0.39404

Collected Steps per Second: 15,243.77651
Overall Steps per Second: 10,637.06208

Timestep Collection Time: 3.28042
Timestep Consumption Time: 1.42069
PPO Batch Consumption Time: 0.12879
Total Iteration Time: 4.70111

Cumulative Model Updates: 51,678
Cumulative Timesteps: 431,115,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,327.30884
Policy Entropy: 0.66271
Value Function Loss: 0.08574

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03688
Policy Update Magnitude: 0.18230
Value Function Update Magnitude: 0.35337

Collected Steps per Second: 15,693.56324
Overall Steps per Second: 10,976.10109

Timestep Collection Time: 3.18666
Timestep Consumption Time: 1.36961
PPO Batch Consumption Time: 0.11476
Total Iteration Time: 4.55626

Cumulative Model Updates: 51,684
Cumulative Timesteps: 431,165,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 431165668...
Checkpoint 431165668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,139.63455
Policy Entropy: 0.65083
Value Function Loss: 0.09162

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03854
Policy Update Magnitude: 0.18560
Value Function Update Magnitude: 0.36518

Collected Steps per Second: 15,510.08033
Overall Steps per Second: 10,938.10849

Timestep Collection Time: 3.22629
Timestep Consumption Time: 1.34854
PPO Batch Consumption Time: 0.11540
Total Iteration Time: 4.57483

Cumulative Model Updates: 51,690
Cumulative Timesteps: 431,215,708

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,672.84421
Policy Entropy: 0.64331
Value Function Loss: 0.09204

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04367
Policy Update Magnitude: 0.18627
Value Function Update Magnitude: 0.39696

Collected Steps per Second: 16,076.04635
Overall Steps per Second: 11,101.52107

Timestep Collection Time: 3.11084
Timestep Consumption Time: 1.39395
PPO Batch Consumption Time: 0.11805
Total Iteration Time: 4.50479

Cumulative Model Updates: 51,696
Cumulative Timesteps: 431,265,718

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 431265718...
Checkpoint 431265718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,040.38982
Policy Entropy: 0.64620
Value Function Loss: 0.09118

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04233
Policy Update Magnitude: 0.18267
Value Function Update Magnitude: 0.38689

Collected Steps per Second: 16,085.54667
Overall Steps per Second: 10,973.08800

Timestep Collection Time: 3.10900
Timestep Consumption Time: 1.44851
PPO Batch Consumption Time: 0.12600
Total Iteration Time: 4.55751

Cumulative Model Updates: 51,702
Cumulative Timesteps: 431,315,728

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,466.11072
Policy Entropy: 0.64365
Value Function Loss: 0.09159

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03955
Policy Update Magnitude: 0.18033
Value Function Update Magnitude: 0.36971

Collected Steps per Second: 16,144.35221
Overall Steps per Second: 11,260.90619

Timestep Collection Time: 3.09706
Timestep Consumption Time: 1.34308
PPO Batch Consumption Time: 0.11502
Total Iteration Time: 4.44014

Cumulative Model Updates: 51,708
Cumulative Timesteps: 431,365,728

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 431365728...
Checkpoint 431365728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,114.97747
Policy Entropy: 0.64499
Value Function Loss: 0.08655

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.04011
Policy Update Magnitude: 0.18131
Value Function Update Magnitude: 0.39328

Collected Steps per Second: 16,434.35670
Overall Steps per Second: 11,451.60238

Timestep Collection Time: 3.04521
Timestep Consumption Time: 1.32501
PPO Batch Consumption Time: 0.11082
Total Iteration Time: 4.37022

Cumulative Model Updates: 51,714
Cumulative Timesteps: 431,415,774

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,417.84081
Policy Entropy: 0.64655
Value Function Loss: 0.08621

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03924
Policy Update Magnitude: 0.17886
Value Function Update Magnitude: 0.39218

Collected Steps per Second: 16,523.60981
Overall Steps per Second: 11,366.58599

Timestep Collection Time: 3.02730
Timestep Consumption Time: 1.37349
PPO Batch Consumption Time: 0.11963
Total Iteration Time: 4.40079

Cumulative Model Updates: 51,720
Cumulative Timesteps: 431,465,796

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 431465796...
Checkpoint 431465796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,971.18390
Policy Entropy: 0.63598
Value Function Loss: 0.08335

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07053
Policy Update Magnitude: 0.17038
Value Function Update Magnitude: 0.33311

Collected Steps per Second: 16,166.87043
Overall Steps per Second: 11,013.02339

Timestep Collection Time: 3.09497
Timestep Consumption Time: 1.44838
PPO Batch Consumption Time: 0.12469
Total Iteration Time: 4.54335

Cumulative Model Updates: 51,726
Cumulative Timesteps: 431,515,832

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,908.19930
Policy Entropy: 0.63822
Value Function Loss: 0.08955

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07759
Policy Update Magnitude: 0.15753
Value Function Update Magnitude: 0.33550

Collected Steps per Second: 14,537.88133
Overall Steps per Second: 10,402.55894

Timestep Collection Time: 3.44122
Timestep Consumption Time: 1.36798
PPO Batch Consumption Time: 0.11562
Total Iteration Time: 4.80920

Cumulative Model Updates: 51,732
Cumulative Timesteps: 431,565,860

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 431565860...
Checkpoint 431565860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,498.45582
Policy Entropy: 0.64356
Value Function Loss: 0.09854

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.05802
Policy Update Magnitude: 0.15883
Value Function Update Magnitude: 0.37261

Collected Steps per Second: 15,877.57832
Overall Steps per Second: 11,100.46574

Timestep Collection Time: 3.15098
Timestep Consumption Time: 1.35603
PPO Batch Consumption Time: 0.11665
Total Iteration Time: 4.50702

Cumulative Model Updates: 51,738
Cumulative Timesteps: 431,615,890

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,111.15639
Policy Entropy: 0.64574
Value Function Loss: 0.10463

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.05835
Policy Update Magnitude: 0.18108
Value Function Update Magnitude: 0.42805

Collected Steps per Second: 15,934.95794
Overall Steps per Second: 11,026.45723

Timestep Collection Time: 3.13801
Timestep Consumption Time: 1.39690
PPO Batch Consumption Time: 0.12473
Total Iteration Time: 4.53491

Cumulative Model Updates: 51,744
Cumulative Timesteps: 431,665,894

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 431665894...
Checkpoint 431665894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,289.89486
Policy Entropy: 0.64327
Value Function Loss: 0.09728

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07121
Policy Update Magnitude: 0.17501
Value Function Update Magnitude: 0.44943

Collected Steps per Second: 15,642.40575
Overall Steps per Second: 10,776.72569

Timestep Collection Time: 3.19695
Timestep Consumption Time: 1.44342
PPO Batch Consumption Time: 0.12700
Total Iteration Time: 4.64037

Cumulative Model Updates: 51,750
Cumulative Timesteps: 431,715,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,151.81058
Policy Entropy: 0.65308
Value Function Loss: 0.09086

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07717
Policy Update Magnitude: 0.17439
Value Function Update Magnitude: 0.44051

Collected Steps per Second: 15,905.56419
Overall Steps per Second: 11,133.47076

Timestep Collection Time: 3.14443
Timestep Consumption Time: 1.34779
PPO Batch Consumption Time: 0.11236
Total Iteration Time: 4.49222

Cumulative Model Updates: 51,756
Cumulative Timesteps: 431,765,916

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 431765916...
Checkpoint 431765916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,224.77129
Policy Entropy: 0.65449
Value Function Loss: 0.08879

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08205
Policy Update Magnitude: 0.16557
Value Function Update Magnitude: 0.42549

Collected Steps per Second: 15,808.26796
Overall Steps per Second: 11,087.75005

Timestep Collection Time: 3.16328
Timestep Consumption Time: 1.34674
PPO Batch Consumption Time: 0.11552
Total Iteration Time: 4.51002

Cumulative Model Updates: 51,762
Cumulative Timesteps: 431,815,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,276.01889
Policy Entropy: 0.65837
Value Function Loss: 0.09063

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07356
Policy Update Magnitude: 0.17242
Value Function Update Magnitude: 0.42749

Collected Steps per Second: 15,725.84874
Overall Steps per Second: 10,867.84201

Timestep Collection Time: 3.18088
Timestep Consumption Time: 1.42188
PPO Batch Consumption Time: 0.12107
Total Iteration Time: 4.60275

Cumulative Model Updates: 51,768
Cumulative Timesteps: 431,865,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 431865944...
Checkpoint 431865944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,799.55088
Policy Entropy: 0.66368
Value Function Loss: 0.08396

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06096
Policy Update Magnitude: 0.18017
Value Function Update Magnitude: 0.42782

Collected Steps per Second: 15,758.42327
Overall Steps per Second: 10,858.83611

Timestep Collection Time: 3.17392
Timestep Consumption Time: 1.43210
PPO Batch Consumption Time: 0.12619
Total Iteration Time: 4.60602

Cumulative Model Updates: 51,774
Cumulative Timesteps: 431,915,960

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,194.06013
Policy Entropy: 0.66735
Value Function Loss: 0.08922

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04924
Policy Update Magnitude: 0.18217
Value Function Update Magnitude: 0.41807

Collected Steps per Second: 15,483.04558
Overall Steps per Second: 10,780.47482

Timestep Collection Time: 3.23037
Timestep Consumption Time: 1.40913
PPO Batch Consumption Time: 0.12091
Total Iteration Time: 4.63950

Cumulative Model Updates: 51,780
Cumulative Timesteps: 431,965,976

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 431965976...
Checkpoint 431965976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,007.99095
Policy Entropy: 0.65885
Value Function Loss: 0.08963

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.04522
Policy Update Magnitude: 0.19178
Value Function Update Magnitude: 0.42550

Collected Steps per Second: 15,825.14002
Overall Steps per Second: 10,913.85575

Timestep Collection Time: 3.16092
Timestep Consumption Time: 1.42243
PPO Batch Consumption Time: 0.12275
Total Iteration Time: 4.58335

Cumulative Model Updates: 51,786
Cumulative Timesteps: 432,015,998

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,715.63929
Policy Entropy: 0.66167
Value Function Loss: 0.09438

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.05050
Policy Update Magnitude: 0.19107
Value Function Update Magnitude: 0.42202

Collected Steps per Second: 16,486.39696
Overall Steps per Second: 11,273.05651

Timestep Collection Time: 3.03426
Timestep Consumption Time: 1.40322
PPO Batch Consumption Time: 0.11853
Total Iteration Time: 4.43748

Cumulative Model Updates: 51,792
Cumulative Timesteps: 432,066,022

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 432066022...
Checkpoint 432066022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,426.78092
Policy Entropy: 0.66887
Value Function Loss: 0.09090

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06325
Policy Update Magnitude: 0.18277
Value Function Update Magnitude: 0.41284

Collected Steps per Second: 16,125.55136
Overall Steps per Second: 11,224.28983

Timestep Collection Time: 3.10079
Timestep Consumption Time: 1.35401
PPO Batch Consumption Time: 0.11315
Total Iteration Time: 4.45480

Cumulative Model Updates: 51,798
Cumulative Timesteps: 432,116,024

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,729.28321
Policy Entropy: 0.66708
Value Function Loss: 0.09288

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05341
Policy Update Magnitude: 0.18080
Value Function Update Magnitude: 0.40296

Collected Steps per Second: 16,145.95249
Overall Steps per Second: 11,124.05116

Timestep Collection Time: 3.09774
Timestep Consumption Time: 1.39846
PPO Batch Consumption Time: 0.12166
Total Iteration Time: 4.49620

Cumulative Model Updates: 51,804
Cumulative Timesteps: 432,166,040

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 432166040...
Checkpoint 432166040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,521.65512
Policy Entropy: 0.66660
Value Function Loss: 0.09847

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04873
Policy Update Magnitude: 0.18721
Value Function Update Magnitude: 0.40376

Collected Steps per Second: 15,200.50486
Overall Steps per Second: 10,596.27689

Timestep Collection Time: 3.29055
Timestep Consumption Time: 1.42979
PPO Batch Consumption Time: 0.13015
Total Iteration Time: 4.72034

Cumulative Model Updates: 51,810
Cumulative Timesteps: 432,216,058

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,388.99343
Policy Entropy: 0.65387
Value Function Loss: 0.09857

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.04204
Policy Update Magnitude: 0.18997
Value Function Update Magnitude: 0.39746

Collected Steps per Second: 15,592.12595
Overall Steps per Second: 10,682.33386

Timestep Collection Time: 3.20675
Timestep Consumption Time: 1.47388
PPO Batch Consumption Time: 0.13103
Total Iteration Time: 4.68063

Cumulative Model Updates: 51,816
Cumulative Timesteps: 432,266,058

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 432266058...
Checkpoint 432266058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,445.28969
Policy Entropy: 0.65802
Value Function Loss: 0.09801

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.05100
Policy Update Magnitude: 0.19764
Value Function Update Magnitude: 0.41368

Collected Steps per Second: 15,075.91453
Overall Steps per Second: 10,492.47024

Timestep Collection Time: 3.31894
Timestep Consumption Time: 1.44982
PPO Batch Consumption Time: 0.12488
Total Iteration Time: 4.76875

Cumulative Model Updates: 51,822
Cumulative Timesteps: 432,316,094

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,096.51542
Policy Entropy: 0.65886
Value Function Loss: 0.08996

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04937
Policy Update Magnitude: 0.19350
Value Function Update Magnitude: 0.42203

Collected Steps per Second: 15,488.72467
Overall Steps per Second: 10,841.20201

Timestep Collection Time: 3.22893
Timestep Consumption Time: 1.38421
PPO Batch Consumption Time: 0.11805
Total Iteration Time: 4.61314

Cumulative Model Updates: 51,828
Cumulative Timesteps: 432,366,106

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 432366106...
Checkpoint 432366106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,467.86708
Policy Entropy: 0.65711
Value Function Loss: 0.08589

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04905
Policy Update Magnitude: 0.18688
Value Function Update Magnitude: 0.41984

Collected Steps per Second: 15,777.68876
Overall Steps per Second: 10,846.42604

Timestep Collection Time: 3.17055
Timestep Consumption Time: 1.44147
PPO Batch Consumption Time: 0.13074
Total Iteration Time: 4.61203

Cumulative Model Updates: 51,834
Cumulative Timesteps: 432,416,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,832.10779
Policy Entropy: 0.66172
Value Function Loss: 0.08437

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.04986
Policy Update Magnitude: 0.17706
Value Function Update Magnitude: 0.40757

Collected Steps per Second: 15,445.43565
Overall Steps per Second: 10,865.49507

Timestep Collection Time: 3.23733
Timestep Consumption Time: 1.36458
PPO Batch Consumption Time: 0.11433
Total Iteration Time: 4.60191

Cumulative Model Updates: 51,840
Cumulative Timesteps: 432,466,132

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 432466132...
Checkpoint 432466132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,071.66308
Policy Entropy: 0.66283
Value Function Loss: 0.08546

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.04264
Policy Update Magnitude: 0.17439
Value Function Update Magnitude: 0.39912

Collected Steps per Second: 15,382.71736
Overall Steps per Second: 10,631.42151

Timestep Collection Time: 3.25196
Timestep Consumption Time: 1.45334
PPO Batch Consumption Time: 0.12505
Total Iteration Time: 4.70530

Cumulative Model Updates: 51,846
Cumulative Timesteps: 432,516,156

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,113.66026
Policy Entropy: 0.66862
Value Function Loss: 0.08990

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04873
Policy Update Magnitude: 0.18239
Value Function Update Magnitude: 0.42085

Collected Steps per Second: 15,645.38838
Overall Steps per Second: 10,825.79285

Timestep Collection Time: 3.19621
Timestep Consumption Time: 1.42294
PPO Batch Consumption Time: 0.12664
Total Iteration Time: 4.61915

Cumulative Model Updates: 51,852
Cumulative Timesteps: 432,566,162

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 432566162...
Checkpoint 432566162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,558.74445
Policy Entropy: 0.66494
Value Function Loss: 0.09675

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05825
Policy Update Magnitude: 0.18661
Value Function Update Magnitude: 0.44779

Collected Steps per Second: 15,089.47857
Overall Steps per Second: 10,491.76962

Timestep Collection Time: 3.31569
Timestep Consumption Time: 1.45300
PPO Batch Consumption Time: 0.12870
Total Iteration Time: 4.76869

Cumulative Model Updates: 51,858
Cumulative Timesteps: 432,616,194

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,922.88876
Policy Entropy: 0.66290
Value Function Loss: 0.09837

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06203
Policy Update Magnitude: 0.19369
Value Function Update Magnitude: 0.46544

Collected Steps per Second: 15,752.02852
Overall Steps per Second: 10,905.49439

Timestep Collection Time: 3.17559
Timestep Consumption Time: 1.41127
PPO Batch Consumption Time: 0.11963
Total Iteration Time: 4.58686

Cumulative Model Updates: 51,864
Cumulative Timesteps: 432,666,216

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 432666216...
Checkpoint 432666216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,267.95323
Policy Entropy: 0.66627
Value Function Loss: 0.09308

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06223
Policy Update Magnitude: 0.18571
Value Function Update Magnitude: 0.46162

Collected Steps per Second: 15,775.54643
Overall Steps per Second: 10,999.26213

Timestep Collection Time: 3.16959
Timestep Consumption Time: 1.37635
PPO Batch Consumption Time: 0.11460
Total Iteration Time: 4.54594

Cumulative Model Updates: 51,870
Cumulative Timesteps: 432,716,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,787.72105
Policy Entropy: 0.66905
Value Function Loss: 0.08529

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05403
Policy Update Magnitude: 0.18729
Value Function Update Magnitude: 0.45287

Collected Steps per Second: 15,957.17494
Overall Steps per Second: 11,036.38290

Timestep Collection Time: 3.13439
Timestep Consumption Time: 1.39753
PPO Batch Consumption Time: 0.11705
Total Iteration Time: 4.53192

Cumulative Model Updates: 51,876
Cumulative Timesteps: 432,766,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 432766234...
Checkpoint 432766234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,708.23602
Policy Entropy: 0.66619
Value Function Loss: 0.08653

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.05425
Policy Update Magnitude: 0.18049
Value Function Update Magnitude: 0.43605

Collected Steps per Second: 16,050.52128
Overall Steps per Second: 11,091.66935

Timestep Collection Time: 3.11666
Timestep Consumption Time: 1.39339
PPO Batch Consumption Time: 0.11675
Total Iteration Time: 4.51005

Cumulative Model Updates: 51,882
Cumulative Timesteps: 432,816,258

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,784.91286
Policy Entropy: 0.66352
Value Function Loss: 0.09470

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.05189
Policy Update Magnitude: 0.17861
Value Function Update Magnitude: 0.42756

Collected Steps per Second: 16,103.28517
Overall Steps per Second: 10,911.09665

Timestep Collection Time: 3.10508
Timestep Consumption Time: 1.47759
PPO Batch Consumption Time: 0.13183
Total Iteration Time: 4.58267

Cumulative Model Updates: 51,888
Cumulative Timesteps: 432,866,260

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 432866260...
Checkpoint 432866260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,439.40406
Policy Entropy: 0.65959
Value Function Loss: 0.09207

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.05070
Policy Update Magnitude: 0.17212
Value Function Update Magnitude: 0.41483

Collected Steps per Second: 15,955.30193
Overall Steps per Second: 11,060.51213

Timestep Collection Time: 3.13463
Timestep Consumption Time: 1.38722
PPO Batch Consumption Time: 0.11538
Total Iteration Time: 4.52185

Cumulative Model Updates: 51,894
Cumulative Timesteps: 432,916,274

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,467.03307
Policy Entropy: 0.66111
Value Function Loss: 0.08889

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04964
Policy Update Magnitude: 0.17085
Value Function Update Magnitude: 0.39595

Collected Steps per Second: 15,728.99759
Overall Steps per Second: 10,875.65930

Timestep Collection Time: 3.17999
Timestep Consumption Time: 1.41909
PPO Batch Consumption Time: 0.12500
Total Iteration Time: 4.59908

Cumulative Model Updates: 51,900
Cumulative Timesteps: 432,966,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 432966292...
Checkpoint 432966292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,190.13969
Policy Entropy: 0.66263
Value Function Loss: 0.07954

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.04707
Policy Update Magnitude: 0.17414
Value Function Update Magnitude: 0.38177

Collected Steps per Second: 15,749.08668
Overall Steps per Second: 10,908.08677

Timestep Collection Time: 3.17593
Timestep Consumption Time: 1.40948
PPO Batch Consumption Time: 0.12014
Total Iteration Time: 4.58541

Cumulative Model Updates: 51,906
Cumulative Timesteps: 433,016,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,206.37305
Policy Entropy: 0.66007
Value Function Loss: 0.09028

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04620
Policy Update Magnitude: 0.17910
Value Function Update Magnitude: 0.38387

Collected Steps per Second: 16,126.84942
Overall Steps per Second: 11,114.11122

Timestep Collection Time: 3.10191
Timestep Consumption Time: 1.39904
PPO Batch Consumption Time: 0.11931
Total Iteration Time: 4.50094

Cumulative Model Updates: 51,912
Cumulative Timesteps: 433,066,334

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 433066334...
Checkpoint 433066334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,179.64883
Policy Entropy: 0.65168
Value Function Loss: 0.08939

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.05742
Policy Update Magnitude: 0.18028
Value Function Update Magnitude: 0.37393

Collected Steps per Second: 15,695.61907
Overall Steps per Second: 10,805.88752

Timestep Collection Time: 3.18726
Timestep Consumption Time: 1.44225
PPO Batch Consumption Time: 0.12539
Total Iteration Time: 4.62951

Cumulative Model Updates: 51,918
Cumulative Timesteps: 433,116,360

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,544.14710
Policy Entropy: 0.66062
Value Function Loss: 0.10098

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05174
Policy Update Magnitude: 0.17955
Value Function Update Magnitude: 0.34940

Collected Steps per Second: 15,468.61959
Overall Steps per Second: 10,702.21167

Timestep Collection Time: 3.23416
Timestep Consumption Time: 1.44039
PPO Batch Consumption Time: 0.12573
Total Iteration Time: 4.67455

Cumulative Model Updates: 51,924
Cumulative Timesteps: 433,166,388

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 433166388...
Checkpoint 433166388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,930.85365
Policy Entropy: 0.66648
Value Function Loss: 0.09162

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03799
Policy Update Magnitude: 0.18912
Value Function Update Magnitude: 0.36978

Collected Steps per Second: 15,611.66246
Overall Steps per Second: 10,803.60940

Timestep Collection Time: 3.20325
Timestep Consumption Time: 1.42558
PPO Batch Consumption Time: 0.12339
Total Iteration Time: 4.62882

Cumulative Model Updates: 51,930
Cumulative Timesteps: 433,216,396

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,483.17282
Policy Entropy: 0.65975
Value Function Loss: 0.09548

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03824
Policy Update Magnitude: 0.19561
Value Function Update Magnitude: 0.40486

Collected Steps per Second: 15,872.60735
Overall Steps per Second: 11,030.91360

Timestep Collection Time: 3.15109
Timestep Consumption Time: 1.38308
PPO Batch Consumption Time: 0.12344
Total Iteration Time: 4.53417

Cumulative Model Updates: 51,936
Cumulative Timesteps: 433,266,412

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 433266412...
Checkpoint 433266412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,079.45149
Policy Entropy: 0.65221
Value Function Loss: 0.09307

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05114
Policy Update Magnitude: 0.19120
Value Function Update Magnitude: 0.43245

Collected Steps per Second: 15,620.89951
Overall Steps per Second: 10,829.49796

Timestep Collection Time: 3.20084
Timestep Consumption Time: 1.41618
PPO Batch Consumption Time: 0.12463
Total Iteration Time: 4.61702

Cumulative Model Updates: 51,942
Cumulative Timesteps: 433,316,412

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,705.71613
Policy Entropy: 0.66043
Value Function Loss: 0.10161

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08450
Policy Update Magnitude: 0.16698
Value Function Update Magnitude: 0.44422

Collected Steps per Second: 15,811.77745
Overall Steps per Second: 11,155.01081

Timestep Collection Time: 3.16359
Timestep Consumption Time: 1.32067
PPO Batch Consumption Time: 0.10278
Total Iteration Time: 4.48426

Cumulative Model Updates: 51,948
Cumulative Timesteps: 433,366,434

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 433366434...
Checkpoint 433366434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,438.88895
Policy Entropy: 0.65660
Value Function Loss: 0.09561

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.07863
Policy Update Magnitude: 0.15870
Value Function Update Magnitude: 0.42170

Collected Steps per Second: 17,175.46203
Overall Steps per Second: 12,172.87261

Timestep Collection Time: 2.91206
Timestep Consumption Time: 1.19675
PPO Batch Consumption Time: 0.07837
Total Iteration Time: 4.10881

Cumulative Model Updates: 51,954
Cumulative Timesteps: 433,416,450

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,056.48850
Policy Entropy: 0.66500
Value Function Loss: 0.09228

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.08484
Policy Update Magnitude: 0.16687
Value Function Update Magnitude: 0.38517

Collected Steps per Second: 18,892.07161
Overall Steps per Second: 12,616.03581

Timestep Collection Time: 2.64714
Timestep Consumption Time: 1.31686
PPO Batch Consumption Time: 0.09472
Total Iteration Time: 3.96400

Cumulative Model Updates: 51,960
Cumulative Timesteps: 433,466,460

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 433466460...
Checkpoint 433466460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,939.21014
Policy Entropy: 0.65263
Value Function Loss: 0.08584

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.15037
Value Function Update Magnitude: 0.35651

Collected Steps per Second: 18,245.22451
Overall Steps per Second: 12,153.52003

Timestep Collection Time: 2.74340
Timestep Consumption Time: 1.37507
PPO Batch Consumption Time: 0.10633
Total Iteration Time: 4.11848

Cumulative Model Updates: 51,966
Cumulative Timesteps: 433,516,514

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,438.22575
Policy Entropy: 0.65494
Value Function Loss: 0.08754

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08114
Policy Update Magnitude: 0.14849
Value Function Update Magnitude: 0.34421

Collected Steps per Second: 21,035.39358
Overall Steps per Second: 13,846.75808

Timestep Collection Time: 2.37761
Timestep Consumption Time: 1.23435
PPO Batch Consumption Time: 0.09306
Total Iteration Time: 3.61196

Cumulative Model Updates: 51,972
Cumulative Timesteps: 433,566,528

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 433566528...
Checkpoint 433566528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,602.77743
Policy Entropy: 0.64466
Value Function Loss: 0.09160

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07916
Policy Update Magnitude: 0.15173
Value Function Update Magnitude: 0.37145

Collected Steps per Second: 21,883.85278
Overall Steps per Second: 14,164.57903

Timestep Collection Time: 2.28625
Timestep Consumption Time: 1.24594
PPO Batch Consumption Time: 0.10262
Total Iteration Time: 3.53219

Cumulative Model Updates: 51,978
Cumulative Timesteps: 433,616,560

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,734.28279
Policy Entropy: 0.64510
Value Function Loss: 0.09498

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.06997
Policy Update Magnitude: 0.16506
Value Function Update Magnitude: 0.37739

Collected Steps per Second: 22,404.66892
Overall Steps per Second: 14,562.72647

Timestep Collection Time: 2.23168
Timestep Consumption Time: 1.20175
PPO Batch Consumption Time: 0.09187
Total Iteration Time: 3.43342

Cumulative Model Updates: 51,984
Cumulative Timesteps: 433,666,560

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 433666560...
Checkpoint 433666560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,836.95211
Policy Entropy: 0.64112
Value Function Loss: 0.09146

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07591
Policy Update Magnitude: 0.16419
Value Function Update Magnitude: 0.38365

Collected Steps per Second: 22,354.96660
Overall Steps per Second: 14,298.01040

Timestep Collection Time: 2.23727
Timestep Consumption Time: 1.26070
PPO Batch Consumption Time: 0.10256
Total Iteration Time: 3.49797

Cumulative Model Updates: 51,990
Cumulative Timesteps: 433,716,574

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,872.64568
Policy Entropy: 0.64324
Value Function Loss: 0.08704

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06197
Policy Update Magnitude: 0.16322
Value Function Update Magnitude: 0.39473

Collected Steps per Second: 22,399.59766
Overall Steps per Second: 14,081.71098

Timestep Collection Time: 2.23254
Timestep Consumption Time: 1.31873
PPO Batch Consumption Time: 0.10772
Total Iteration Time: 3.55127

Cumulative Model Updates: 51,996
Cumulative Timesteps: 433,766,582

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 433766582...
Checkpoint 433766582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,549.78373
Policy Entropy: 0.64017
Value Function Loss: 0.08773

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05662
Policy Update Magnitude: 0.17542
Value Function Update Magnitude: 0.40529

Collected Steps per Second: 21,023.11543
Overall Steps per Second: 14,417.92961

Timestep Collection Time: 2.38014
Timestep Consumption Time: 1.09040
PPO Batch Consumption Time: 0.07549
Total Iteration Time: 3.47054

Cumulative Model Updates: 52,002
Cumulative Timesteps: 433,816,620

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,424.18260
Policy Entropy: 0.64080
Value Function Loss: 0.08716

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.05362
Policy Update Magnitude: 0.17688
Value Function Update Magnitude: 0.42293

Collected Steps per Second: 22,282.23731
Overall Steps per Second: 14,234.26493

Timestep Collection Time: 2.24466
Timestep Consumption Time: 1.26912
PPO Batch Consumption Time: 0.10254
Total Iteration Time: 3.51377

Cumulative Model Updates: 52,008
Cumulative Timesteps: 433,866,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 433866636...
Checkpoint 433866636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,167.61560
Policy Entropy: 0.64560
Value Function Loss: 0.08511

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05503
Policy Update Magnitude: 0.17733
Value Function Update Magnitude: 0.40644

Collected Steps per Second: 22,157.50893
Overall Steps per Second: 14,504.99312

Timestep Collection Time: 2.25793
Timestep Consumption Time: 1.19123
PPO Batch Consumption Time: 0.09222
Total Iteration Time: 3.44916

Cumulative Model Updates: 52,014
Cumulative Timesteps: 433,916,666

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,584.80121
Policy Entropy: 0.64971
Value Function Loss: 0.08543

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06224
Policy Update Magnitude: 0.17169
Value Function Update Magnitude: 0.39438

Collected Steps per Second: 21,743.49174
Overall Steps per Second: 14,064.83287

Timestep Collection Time: 2.30037
Timestep Consumption Time: 1.25588
PPO Batch Consumption Time: 0.10118
Total Iteration Time: 3.55625

Cumulative Model Updates: 52,020
Cumulative Timesteps: 433,966,684

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 433966684...
Checkpoint 433966684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,123.21647
Policy Entropy: 0.64700
Value Function Loss: 0.08937

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05647
Policy Update Magnitude: 0.18024
Value Function Update Magnitude: 0.37941

Collected Steps per Second: 22,180.37797
Overall Steps per Second: 14,244.40910

Timestep Collection Time: 2.25551
Timestep Consumption Time: 1.25661
PPO Batch Consumption Time: 0.10199
Total Iteration Time: 3.51211

Cumulative Model Updates: 52,026
Cumulative Timesteps: 434,016,712

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,159.95281
Policy Entropy: 0.65474
Value Function Loss: 0.08723

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05625
Policy Update Magnitude: 0.18063
Value Function Update Magnitude: 0.34955

Collected Steps per Second: 22,554.62418
Overall Steps per Second: 14,482.83256

Timestep Collection Time: 2.21888
Timestep Consumption Time: 1.23666
PPO Batch Consumption Time: 0.09619
Total Iteration Time: 3.45554

Cumulative Model Updates: 52,032
Cumulative Timesteps: 434,066,758

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 434066758...
Checkpoint 434066758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,878.92831
Policy Entropy: 0.65559
Value Function Loss: 0.08918

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03845
Policy Update Magnitude: 0.18300
Value Function Update Magnitude: 0.32338

Collected Steps per Second: 22,016.24756
Overall Steps per Second: 14,090.59099

Timestep Collection Time: 2.27269
Timestep Consumption Time: 1.27834
PPO Batch Consumption Time: 0.10269
Total Iteration Time: 3.55102

Cumulative Model Updates: 52,038
Cumulative Timesteps: 434,116,794

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,771.86772
Policy Entropy: 0.65583
Value Function Loss: 0.08958

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04719
Policy Update Magnitude: 0.18802
Value Function Update Magnitude: 0.37997

Collected Steps per Second: 22,654.54897
Overall Steps per Second: 14,593.14539

Timestep Collection Time: 2.20786
Timestep Consumption Time: 1.21964
PPO Batch Consumption Time: 0.09336
Total Iteration Time: 3.42750

Cumulative Model Updates: 52,044
Cumulative Timesteps: 434,166,812

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 434166812...
Checkpoint 434166812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,559.96789
Policy Entropy: 0.65573
Value Function Loss: 0.09417

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.05338
Policy Update Magnitude: 0.18511
Value Function Update Magnitude: 0.40489

Collected Steps per Second: 21,478.51462
Overall Steps per Second: 14,074.81515

Timestep Collection Time: 2.32893
Timestep Consumption Time: 1.22508
PPO Batch Consumption Time: 0.09629
Total Iteration Time: 3.55401

Cumulative Model Updates: 52,050
Cumulative Timesteps: 434,216,834

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,476.97389
Policy Entropy: 0.66144
Value Function Loss: 0.09632

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04990
Policy Update Magnitude: 0.18650
Value Function Update Magnitude: 0.40657

Collected Steps per Second: 22,317.24559
Overall Steps per Second: 14,331.29010

Timestep Collection Time: 2.24069
Timestep Consumption Time: 1.24860
PPO Batch Consumption Time: 0.10018
Total Iteration Time: 3.48929

Cumulative Model Updates: 52,056
Cumulative Timesteps: 434,266,840

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 434266840...
Checkpoint 434266840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,695.36433
Policy Entropy: 0.65835
Value Function Loss: 0.09138

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.04753
Policy Update Magnitude: 0.19266
Value Function Update Magnitude: 0.40892

Collected Steps per Second: 22,357.19509
Overall Steps per Second: 14,453.93496

Timestep Collection Time: 2.23642
Timestep Consumption Time: 1.22285
PPO Batch Consumption Time: 0.09665
Total Iteration Time: 3.45927

Cumulative Model Updates: 52,062
Cumulative Timesteps: 434,316,840

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,344.33658
Policy Entropy: 0.64824
Value Function Loss: 0.08349

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.05947
Policy Update Magnitude: 0.18974
Value Function Update Magnitude: 0.37546

Collected Steps per Second: 22,374.28282
Overall Steps per Second: 14,637.43727

Timestep Collection Time: 2.23471
Timestep Consumption Time: 1.18119
PPO Batch Consumption Time: 0.09299
Total Iteration Time: 3.41590

Cumulative Model Updates: 52,068
Cumulative Timesteps: 434,366,840

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 434366840...
Checkpoint 434366840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,273.06298
Policy Entropy: 0.64106
Value Function Loss: 0.08873

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07857
Policy Update Magnitude: 0.17007
Value Function Update Magnitude: 0.37629

Collected Steps per Second: 22,109.54710
Overall Steps per Second: 14,192.39461

Timestep Collection Time: 2.26255
Timestep Consumption Time: 1.26215
PPO Batch Consumption Time: 0.10457
Total Iteration Time: 3.52470

Cumulative Model Updates: 52,074
Cumulative Timesteps: 434,416,864

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,757.58165
Policy Entropy: 0.65007
Value Function Loss: 0.09013

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05931
Policy Update Magnitude: 0.17262
Value Function Update Magnitude: 0.46082

Collected Steps per Second: 22,548.26298
Overall Steps per Second: 14,600.81331

Timestep Collection Time: 2.21818
Timestep Consumption Time: 1.20739
PPO Batch Consumption Time: 0.09441
Total Iteration Time: 3.42556

Cumulative Model Updates: 52,080
Cumulative Timesteps: 434,466,880

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 434466880...
Checkpoint 434466880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,553.28905
Policy Entropy: 0.65106
Value Function Loss: 0.09184

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.06511
Policy Update Magnitude: 0.18635
Value Function Update Magnitude: 0.43373

Collected Steps per Second: 21,882.68530
Overall Steps per Second: 14,120.11111

Timestep Collection Time: 2.28573
Timestep Consumption Time: 1.25659
PPO Batch Consumption Time: 0.10116
Total Iteration Time: 3.54232

Cumulative Model Updates: 52,086
Cumulative Timesteps: 434,516,898

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,059.54791
Policy Entropy: 0.65029
Value Function Loss: 0.08843

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05836
Policy Update Magnitude: 0.18694
Value Function Update Magnitude: 0.43303

Collected Steps per Second: 22,926.23502
Overall Steps per Second: 14,650.40219

Timestep Collection Time: 2.18213
Timestep Consumption Time: 1.23266
PPO Batch Consumption Time: 0.09652
Total Iteration Time: 3.41479

Cumulative Model Updates: 52,092
Cumulative Timesteps: 434,566,926

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 434566926...
Checkpoint 434566926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,164.05776
Policy Entropy: 0.64404
Value Function Loss: 0.08882

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.06982
Policy Update Magnitude: 0.17586
Value Function Update Magnitude: 0.42210

Collected Steps per Second: 21,812.45069
Overall Steps per Second: 14,108.26619

Timestep Collection Time: 2.29319
Timestep Consumption Time: 1.25225
PPO Batch Consumption Time: 0.10156
Total Iteration Time: 3.54544

Cumulative Model Updates: 52,098
Cumulative Timesteps: 434,616,946

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,791.69914
Policy Entropy: 0.64849
Value Function Loss: 0.08830

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.08647
Policy Update Magnitude: 0.16945
Value Function Update Magnitude: 0.41686

Collected Steps per Second: 21,823.64041
Overall Steps per Second: 14,598.56827

Timestep Collection Time: 2.29137
Timestep Consumption Time: 1.13404
PPO Batch Consumption Time: 0.09305
Total Iteration Time: 3.42540

Cumulative Model Updates: 52,104
Cumulative Timesteps: 434,666,952

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 434666952...
Checkpoint 434666952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,009.13562
Policy Entropy: 0.65003
Value Function Loss: 0.08952

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07251
Policy Update Magnitude: 0.17882
Value Function Update Magnitude: 0.41795

Collected Steps per Second: 21,638.65258
Overall Steps per Second: 14,267.47314

Timestep Collection Time: 2.31197
Timestep Consumption Time: 1.19446
PPO Batch Consumption Time: 0.10361
Total Iteration Time: 3.50644

Cumulative Model Updates: 52,110
Cumulative Timesteps: 434,716,980

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,500.73062
Policy Entropy: 0.64940
Value Function Loss: 0.08945

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.05078
Policy Update Magnitude: 0.18818
Value Function Update Magnitude: 0.41377

Collected Steps per Second: 21,973.01413
Overall Steps per Second: 14,521.77968

Timestep Collection Time: 2.27643
Timestep Consumption Time: 1.16805
PPO Batch Consumption Time: 0.09716
Total Iteration Time: 3.44448

Cumulative Model Updates: 52,116
Cumulative Timesteps: 434,767,000

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 434767000...
Checkpoint 434767000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,053.17181
Policy Entropy: 0.65435
Value Function Loss: 0.09723

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04986
Policy Update Magnitude: 0.19720
Value Function Update Magnitude: 0.41745

Collected Steps per Second: 21,695.50459
Overall Steps per Second: 14,246.30994

Timestep Collection Time: 2.30582
Timestep Consumption Time: 1.20568
PPO Batch Consumption Time: 0.10316
Total Iteration Time: 3.51151

Cumulative Model Updates: 52,122
Cumulative Timesteps: 434,817,026

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,137.97497
Policy Entropy: 0.65276
Value Function Loss: 0.08766

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04515
Policy Update Magnitude: 0.20770
Value Function Update Magnitude: 0.43345

Collected Steps per Second: 22,271.40068
Overall Steps per Second: 14,670.65081

Timestep Collection Time: 2.24674
Timestep Consumption Time: 1.16402
PPO Batch Consumption Time: 0.10123
Total Iteration Time: 3.41076

Cumulative Model Updates: 52,128
Cumulative Timesteps: 434,867,064

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 434867064...
Checkpoint 434867064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,203.81321
Policy Entropy: 0.65831
Value Function Loss: 0.08576

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.05137
Policy Update Magnitude: 0.19794
Value Function Update Magnitude: 0.42906

Collected Steps per Second: 21,430.93022
Overall Steps per Second: 14,150.35732

Timestep Collection Time: 2.33504
Timestep Consumption Time: 1.20141
PPO Batch Consumption Time: 0.10272
Total Iteration Time: 3.53645

Cumulative Model Updates: 52,134
Cumulative Timesteps: 434,917,106

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,813.65670
Policy Entropy: 0.65458
Value Function Loss: 0.09450

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.04981
Policy Update Magnitude: 0.19615
Value Function Update Magnitude: 0.43807

Collected Steps per Second: 21,837.93763
Overall Steps per Second: 14,514.51049

Timestep Collection Time: 2.29014
Timestep Consumption Time: 1.15551
PPO Batch Consumption Time: 0.09613
Total Iteration Time: 3.44566

Cumulative Model Updates: 52,140
Cumulative Timesteps: 434,967,118

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 434967118...
Checkpoint 434967118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,812.98622
Policy Entropy: 0.64698
Value Function Loss: 0.11219

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.06965
Policy Update Magnitude: 0.17741
Value Function Update Magnitude: 0.41774

Collected Steps per Second: 21,774.78279
Overall Steps per Second: 14,276.86937

Timestep Collection Time: 2.29724
Timestep Consumption Time: 1.20646
PPO Batch Consumption Time: 0.10242
Total Iteration Time: 3.50371

Cumulative Model Updates: 52,146
Cumulative Timesteps: 435,017,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,007.56249
Policy Entropy: 0.64888
Value Function Loss: 0.10968

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.06786
Policy Update Magnitude: 0.17292
Value Function Update Magnitude: 0.37079

Collected Steps per Second: 21,923.97811
Overall Steps per Second: 14,508.23127

Timestep Collection Time: 2.28134
Timestep Consumption Time: 1.16608
PPO Batch Consumption Time: 0.09975
Total Iteration Time: 3.44742

Cumulative Model Updates: 52,152
Cumulative Timesteps: 435,067,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 435067156...
Checkpoint 435067156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,653.10861
Policy Entropy: 0.64783
Value Function Loss: 0.09697

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07302
Policy Update Magnitude: 0.16198
Value Function Update Magnitude: 0.39840

Collected Steps per Second: 20,869.91492
Overall Steps per Second: 13,987.79489

Timestep Collection Time: 2.39704
Timestep Consumption Time: 1.17936
PPO Batch Consumption Time: 0.09465
Total Iteration Time: 3.57640

Cumulative Model Updates: 52,158
Cumulative Timesteps: 435,117,182

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,622.30626
Policy Entropy: 0.65529
Value Function Loss: 0.07717

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07080
Policy Update Magnitude: 0.15689
Value Function Update Magnitude: 0.40247

Collected Steps per Second: 22,470.31491
Overall Steps per Second: 14,696.72410

Timestep Collection Time: 2.22578
Timestep Consumption Time: 1.17729
PPO Batch Consumption Time: 0.09157
Total Iteration Time: 3.40307

Cumulative Model Updates: 52,164
Cumulative Timesteps: 435,167,196

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 435167196...
Checkpoint 435167196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,051.62160
Policy Entropy: 0.64889
Value Function Loss: 0.07204

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06134
Policy Update Magnitude: 0.16104
Value Function Update Magnitude: 0.38216

Collected Steps per Second: 22,127.67494
Overall Steps per Second: 14,260.99405

Timestep Collection Time: 2.25970
Timestep Consumption Time: 1.24650
PPO Batch Consumption Time: 0.10336
Total Iteration Time: 3.50621

Cumulative Model Updates: 52,170
Cumulative Timesteps: 435,217,198

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,962.91577
Policy Entropy: 0.64927
Value Function Loss: 0.07836

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05284
Policy Update Magnitude: 0.16843
Value Function Update Magnitude: 0.39067

Collected Steps per Second: 22,674.87340
Overall Steps per Second: 14,594.66140

Timestep Collection Time: 2.20570
Timestep Consumption Time: 1.22117
PPO Batch Consumption Time: 0.09892
Total Iteration Time: 3.42687

Cumulative Model Updates: 52,176
Cumulative Timesteps: 435,267,212

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 435267212...
Checkpoint 435267212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,823.73172
Policy Entropy: 0.65687
Value Function Loss: 0.07928

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.05111
Policy Update Magnitude: 0.17968
Value Function Update Magnitude: 0.39861

Collected Steps per Second: 22,459.17962
Overall Steps per Second: 14,307.78402

Timestep Collection Time: 2.22769
Timestep Consumption Time: 1.26915
PPO Batch Consumption Time: 0.10162
Total Iteration Time: 3.49684

Cumulative Model Updates: 52,182
Cumulative Timesteps: 435,317,244

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,441.65403
Policy Entropy: 0.66256
Value Function Loss: 0.08632

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04152
Policy Update Magnitude: 0.18314
Value Function Update Magnitude: 0.39833

Collected Steps per Second: 22,874.97445
Overall Steps per Second: 14,511.69083

Timestep Collection Time: 2.18719
Timestep Consumption Time: 1.26051
PPO Batch Consumption Time: 0.10129
Total Iteration Time: 3.44770

Cumulative Model Updates: 52,188
Cumulative Timesteps: 435,367,276

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 435367276...
Checkpoint 435367276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,155.00045
Policy Entropy: 0.66558
Value Function Loss: 0.08493

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04886
Policy Update Magnitude: 0.18979
Value Function Update Magnitude: 0.39743

Collected Steps per Second: 21,941.89113
Overall Steps per Second: 14,096.75397

Timestep Collection Time: 2.28048
Timestep Consumption Time: 1.26913
PPO Batch Consumption Time: 0.10356
Total Iteration Time: 3.54961

Cumulative Model Updates: 52,194
Cumulative Timesteps: 435,417,314

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,007.56863
Policy Entropy: 0.66158
Value Function Loss: 0.08385

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.04266
Policy Update Magnitude: 0.19105
Value Function Update Magnitude: 0.39710

Collected Steps per Second: 23,026.76405
Overall Steps per Second: 14,496.77238

Timestep Collection Time: 2.17139
Timestep Consumption Time: 1.27766
PPO Batch Consumption Time: 0.09435
Total Iteration Time: 3.44904

Cumulative Model Updates: 52,200
Cumulative Timesteps: 435,467,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 435467314...
Checkpoint 435467314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,984.63567
Policy Entropy: 0.66028
Value Function Loss: 0.08381

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.04724
Policy Update Magnitude: 0.18666
Value Function Update Magnitude: 0.36887

Collected Steps per Second: 22,496.86905
Overall Steps per Second: 14,363.29527

Timestep Collection Time: 2.22289
Timestep Consumption Time: 1.25877
PPO Batch Consumption Time: 0.10154
Total Iteration Time: 3.48165

Cumulative Model Updates: 52,206
Cumulative Timesteps: 435,517,322

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,216.56863
Policy Entropy: 0.65761
Value Function Loss: 0.09674

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04458
Policy Update Magnitude: 0.18185
Value Function Update Magnitude: 0.40939

Collected Steps per Second: 22,075.18957
Overall Steps per Second: 14,400.61194

Timestep Collection Time: 2.26698
Timestep Consumption Time: 1.20815
PPO Batch Consumption Time: 0.09270
Total Iteration Time: 3.47513

Cumulative Model Updates: 52,212
Cumulative Timesteps: 435,567,366

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 435567366...
Checkpoint 435567366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,076.91219
Policy Entropy: 0.66290
Value Function Loss: 0.09343

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04232
Policy Update Magnitude: 0.18941
Value Function Update Magnitude: 0.43984

Collected Steps per Second: 22,185.34475
Overall Steps per Second: 14,150.36058

Timestep Collection Time: 2.25383
Timestep Consumption Time: 1.27979
PPO Batch Consumption Time: 0.10296
Total Iteration Time: 3.53362

Cumulative Model Updates: 52,218
Cumulative Timesteps: 435,617,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,302.54162
Policy Entropy: 0.67191
Value Function Loss: 0.09115

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.05155
Policy Update Magnitude: 0.19483
Value Function Update Magnitude: 0.41915

Collected Steps per Second: 22,751.90077
Overall Steps per Second: 14,612.44953

Timestep Collection Time: 2.19788
Timestep Consumption Time: 1.22427
PPO Batch Consumption Time: 0.09546
Total Iteration Time: 3.42215

Cumulative Model Updates: 52,224
Cumulative Timesteps: 435,667,374

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 435667374...
Checkpoint 435667374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,825.74613
Policy Entropy: 0.67591
Value Function Loss: 0.09879

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04310
Policy Update Magnitude: 0.19143
Value Function Update Magnitude: 0.37455

Collected Steps per Second: 22,451.11674
Overall Steps per Second: 14,483.99228

Timestep Collection Time: 2.22813
Timestep Consumption Time: 1.22561
PPO Batch Consumption Time: 0.10051
Total Iteration Time: 3.45374

Cumulative Model Updates: 52,230
Cumulative Timesteps: 435,717,398

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,306.02009
Policy Entropy: 0.68113
Value Function Loss: 0.10352

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07215
Policy Update Magnitude: 0.18631
Value Function Update Magnitude: 0.35916

Collected Steps per Second: 22,730.10930
Overall Steps per Second: 14,469.74954

Timestep Collection Time: 2.20096
Timestep Consumption Time: 1.25646
PPO Batch Consumption Time: 0.10270
Total Iteration Time: 3.45742

Cumulative Model Updates: 52,236
Cumulative Timesteps: 435,767,426

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 435767426...
Checkpoint 435767426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,016.68279
Policy Entropy: 0.67591
Value Function Loss: 0.10246

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07165
Policy Update Magnitude: 0.17356
Value Function Update Magnitude: 0.35349

Collected Steps per Second: 22,040.22288
Overall Steps per Second: 14,221.71252

Timestep Collection Time: 2.26858
Timestep Consumption Time: 1.24717
PPO Batch Consumption Time: 0.10314
Total Iteration Time: 3.51575

Cumulative Model Updates: 52,242
Cumulative Timesteps: 435,817,426

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,593.85328
Policy Entropy: 0.66873
Value Function Loss: 0.10186

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06200
Policy Update Magnitude: 0.19044
Value Function Update Magnitude: 0.34689

Collected Steps per Second: 20,649.68955
Overall Steps per Second: 13,619.89069

Timestep Collection Time: 2.42241
Timestep Consumption Time: 1.25031
PPO Batch Consumption Time: 0.09840
Total Iteration Time: 3.67272

Cumulative Model Updates: 52,248
Cumulative Timesteps: 435,867,448

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 435867448...
Checkpoint 435867448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,117.08184
Policy Entropy: 0.65855
Value Function Loss: 0.11094

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07914
Policy Update Magnitude: 0.18149
Value Function Update Magnitude: 0.34099

Collected Steps per Second: 21,165.96156
Overall Steps per Second: 13,929.39892

Timestep Collection Time: 2.36247
Timestep Consumption Time: 1.22735
PPO Batch Consumption Time: 0.09467
Total Iteration Time: 3.58982

Cumulative Model Updates: 52,254
Cumulative Timesteps: 435,917,452

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,787.19329
Policy Entropy: 0.65320
Value Function Loss: 0.10336

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08086
Policy Update Magnitude: 0.15924
Value Function Update Magnitude: 0.36168

Collected Steps per Second: 20,488.40306
Overall Steps per Second: 13,363.45177

Timestep Collection Time: 2.44138
Timestep Consumption Time: 1.30166
PPO Batch Consumption Time: 0.10460
Total Iteration Time: 3.74304

Cumulative Model Updates: 52,260
Cumulative Timesteps: 435,967,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 435967472...
Checkpoint 435967472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,629.02066
Policy Entropy: 0.64929
Value Function Loss: 0.10028

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07220
Policy Update Magnitude: 0.15668
Value Function Update Magnitude: 0.39978

Collected Steps per Second: 22,140.45339
Overall Steps per Second: 14,150.30059

Timestep Collection Time: 2.25867
Timestep Consumption Time: 1.27539
PPO Batch Consumption Time: 0.10304
Total Iteration Time: 3.53406

Cumulative Model Updates: 52,266
Cumulative Timesteps: 436,017,480

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,460.67809
Policy Entropy: 0.65958
Value Function Loss: 0.08762

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06343
Policy Update Magnitude: 0.17833
Value Function Update Magnitude: 0.42639

Collected Steps per Second: 21,546.85649
Overall Steps per Second: 13,640.41884

Timestep Collection Time: 2.32136
Timestep Consumption Time: 1.34554
PPO Batch Consumption Time: 0.10821
Total Iteration Time: 3.66690

Cumulative Model Updates: 52,272
Cumulative Timesteps: 436,067,498

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 436067498...
Checkpoint 436067498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,363.94801
Policy Entropy: 0.66976
Value Function Loss: 0.09015

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06208
Policy Update Magnitude: 0.19319
Value Function Update Magnitude: 0.45751

Collected Steps per Second: 19,757.26295
Overall Steps per Second: 13,213.77570

Timestep Collection Time: 2.53173
Timestep Consumption Time: 1.25372
PPO Batch Consumption Time: 0.09765
Total Iteration Time: 3.78544

Cumulative Model Updates: 52,278
Cumulative Timesteps: 436,117,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,730.01820
Policy Entropy: 0.66977
Value Function Loss: 0.09063

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.18356
Value Function Update Magnitude: 0.46074

Collected Steps per Second: 19,737.49464
Overall Steps per Second: 13,492.97539

Timestep Collection Time: 2.53365
Timestep Consumption Time: 1.17257
PPO Batch Consumption Time: 0.08140
Total Iteration Time: 3.70622

Cumulative Model Updates: 52,284
Cumulative Timesteps: 436,167,526

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 436167526...
Checkpoint 436167526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,549.98795
Policy Entropy: 0.66614
Value Function Loss: 0.08889

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07802
Policy Update Magnitude: 0.17002
Value Function Update Magnitude: 0.45951

Collected Steps per Second: 18,710.09452
Overall Steps per Second: 12,745.22243

Timestep Collection Time: 2.67267
Timestep Consumption Time: 1.25083
PPO Batch Consumption Time: 0.10026
Total Iteration Time: 3.92351

Cumulative Model Updates: 52,290
Cumulative Timesteps: 436,217,532

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,726.82248
Policy Entropy: 0.66001
Value Function Loss: 0.08804

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.07887
Policy Update Magnitude: 0.17579
Value Function Update Magnitude: 0.45162

Collected Steps per Second: 21,055.18071
Overall Steps per Second: 13,620.33170

Timestep Collection Time: 2.37604
Timestep Consumption Time: 1.29700
PPO Batch Consumption Time: 0.10709
Total Iteration Time: 3.67304

Cumulative Model Updates: 52,296
Cumulative Timesteps: 436,267,560

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 436267560...
Checkpoint 436267560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,040.95468
Policy Entropy: 0.65908
Value Function Loss: 0.08218

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08560
Policy Update Magnitude: 0.17182
Value Function Update Magnitude: 0.44304

Collected Steps per Second: 19,331.25615
Overall Steps per Second: 11,626.33362

Timestep Collection Time: 2.58824
Timestep Consumption Time: 1.71526
PPO Batch Consumption Time: 0.08625
Total Iteration Time: 4.30351

Cumulative Model Updates: 52,302
Cumulative Timesteps: 436,317,594

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,713.84121
Policy Entropy: 0.66605
Value Function Loss: 0.07672

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06307
Policy Update Magnitude: 0.17320
Value Function Update Magnitude: 0.43254

Collected Steps per Second: 15,275.21552
Overall Steps per Second: 11,000.93021

Timestep Collection Time: 3.27354
Timestep Consumption Time: 1.27190
PPO Batch Consumption Time: 0.07700
Total Iteration Time: 4.54543

Cumulative Model Updates: 52,308
Cumulative Timesteps: 436,367,598

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 436367598...
Checkpoint 436367598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,797.64429
Policy Entropy: 0.67347
Value Function Loss: 0.08661

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06731
Policy Update Magnitude: 0.17870
Value Function Update Magnitude: 0.42320

Collected Steps per Second: 19,603.60473
Overall Steps per Second: 12,115.83793

Timestep Collection Time: 2.55137
Timestep Consumption Time: 1.57678
PPO Batch Consumption Time: 0.14116
Total Iteration Time: 4.12815

Cumulative Model Updates: 52,314
Cumulative Timesteps: 436,417,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,927.01499
Policy Entropy: 0.68833
Value Function Loss: 0.08461

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.06021
Policy Update Magnitude: 0.19106
Value Function Update Magnitude: 0.39954

Collected Steps per Second: 14,308.60750
Overall Steps per Second: 9,948.97046

Timestep Collection Time: 3.49636
Timestep Consumption Time: 1.53210
PPO Batch Consumption Time: 0.13589
Total Iteration Time: 5.02846

Cumulative Model Updates: 52,320
Cumulative Timesteps: 436,467,642

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 436467642...
Checkpoint 436467642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,814.74950
Policy Entropy: 0.68350
Value Function Loss: 0.09316

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.05145
Policy Update Magnitude: 0.19972
Value Function Update Magnitude: 0.38145

Collected Steps per Second: 15,097.77895
Overall Steps per Second: 11,212.12936

Timestep Collection Time: 3.31307
Timestep Consumption Time: 1.14817
PPO Batch Consumption Time: 0.07910
Total Iteration Time: 4.46124

Cumulative Model Updates: 52,326
Cumulative Timesteps: 436,517,662

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,294.10993
Policy Entropy: 0.68524
Value Function Loss: 0.08759

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06721
Policy Update Magnitude: 0.19705
Value Function Update Magnitude: 0.36164

Collected Steps per Second: 15,421.52376
Overall Steps per Second: 10,981.50463

Timestep Collection Time: 3.24417
Timestep Consumption Time: 1.31167
PPO Batch Consumption Time: 0.09553
Total Iteration Time: 4.55584

Cumulative Model Updates: 52,332
Cumulative Timesteps: 436,567,692

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 436567692...
Checkpoint 436567692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,644.58919
Policy Entropy: 0.68046
Value Function Loss: 0.08946

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09060
Policy Update Magnitude: 0.17388
Value Function Update Magnitude: 0.38125

Collected Steps per Second: 18,159.93810
Overall Steps per Second: 12,050.40508

Timestep Collection Time: 2.75552
Timestep Consumption Time: 1.39704
PPO Batch Consumption Time: 0.11039
Total Iteration Time: 4.15256

Cumulative Model Updates: 52,338
Cumulative Timesteps: 436,617,732

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,867.07648
Policy Entropy: 0.66670
Value Function Loss: 0.09281

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08232
Policy Update Magnitude: 0.17527
Value Function Update Magnitude: 0.40945

Collected Steps per Second: 20,138.72008
Overall Steps per Second: 13,670.26208

Timestep Collection Time: 2.48427
Timestep Consumption Time: 1.17550
PPO Batch Consumption Time: 0.08069
Total Iteration Time: 3.65977

Cumulative Model Updates: 52,344
Cumulative Timesteps: 436,667,762

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 436667762...
Checkpoint 436667762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,140.65379
Policy Entropy: 0.66369
Value Function Loss: 0.09527

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.06800
Policy Update Magnitude: 0.18179
Value Function Update Magnitude: 0.43232

Collected Steps per Second: 19,648.41153
Overall Steps per Second: 12,958.26748

Timestep Collection Time: 2.54545
Timestep Consumption Time: 1.31417
PPO Batch Consumption Time: 0.10258
Total Iteration Time: 3.85962

Cumulative Model Updates: 52,350
Cumulative Timesteps: 436,717,776

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,437.03818
Policy Entropy: 0.67202
Value Function Loss: 0.09150

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05889
Policy Update Magnitude: 0.19143
Value Function Update Magnitude: 0.43415

Collected Steps per Second: 20,332.86802
Overall Steps per Second: 13,010.48491

Timestep Collection Time: 2.46084
Timestep Consumption Time: 1.38498
PPO Batch Consumption Time: 0.11463
Total Iteration Time: 3.84582

Cumulative Model Updates: 52,356
Cumulative Timesteps: 436,767,812

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 436767812...
Checkpoint 436767812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,192.50768
Policy Entropy: 0.68754
Value Function Loss: 0.08709

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05463
Policy Update Magnitude: 0.18958
Value Function Update Magnitude: 0.42945

Collected Steps per Second: 17,030.98981
Overall Steps per Second: 11,441.99185

Timestep Collection Time: 2.93629
Timestep Consumption Time: 1.43427
PPO Batch Consumption Time: 0.11366
Total Iteration Time: 4.37057

Cumulative Model Updates: 52,362
Cumulative Timesteps: 436,817,820

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,199.84447
Policy Entropy: 0.68245
Value Function Loss: 0.08542

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05731
Policy Update Magnitude: 0.18787
Value Function Update Magnitude: 0.42206

Collected Steps per Second: 17,866.69938
Overall Steps per Second: 12,791.07767

Timestep Collection Time: 2.80063
Timestep Consumption Time: 1.11132
PPO Batch Consumption Time: 0.07786
Total Iteration Time: 3.91195

Cumulative Model Updates: 52,368
Cumulative Timesteps: 436,867,858

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 436867858...
Checkpoint 436867858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,314.22688
Policy Entropy: 0.67877
Value Function Loss: 0.08298

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08308
Policy Update Magnitude: 0.16862
Value Function Update Magnitude: 0.42381

Collected Steps per Second: 15,413.09402
Overall Steps per Second: 11,320.63164

Timestep Collection Time: 3.24724
Timestep Consumption Time: 1.17389
PPO Batch Consumption Time: 0.08260
Total Iteration Time: 4.42113

Cumulative Model Updates: 52,374
Cumulative Timesteps: 436,917,908

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,813.08640
Policy Entropy: 0.67115
Value Function Loss: 0.08262

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07204
Policy Update Magnitude: 0.16772
Value Function Update Magnitude: 0.42760

Collected Steps per Second: 15,063.13696
Overall Steps per Second: 10,478.16032

Timestep Collection Time: 3.32096
Timestep Consumption Time: 1.45317
PPO Batch Consumption Time: 0.12245
Total Iteration Time: 4.77412

Cumulative Model Updates: 52,380
Cumulative Timesteps: 436,967,932

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 436967932...
Checkpoint 436967932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,972.86129
Policy Entropy: 0.68266
Value Function Loss: 0.08609

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06279
Policy Update Magnitude: 0.18546
Value Function Update Magnitude: 0.41843

Collected Steps per Second: 16,267.61726
Overall Steps per Second: 11,065.57893

Timestep Collection Time: 3.07507
Timestep Consumption Time: 1.44562
PPO Batch Consumption Time: 0.13326
Total Iteration Time: 4.52069

Cumulative Model Updates: 52,386
Cumulative Timesteps: 437,017,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,023.97243
Policy Entropy: 0.67120
Value Function Loss: 0.08640

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.06063
Policy Update Magnitude: 0.19541
Value Function Update Magnitude: 0.41871

Collected Steps per Second: 15,706.22626
Overall Steps per Second: 10,793.07391

Timestep Collection Time: 3.18549
Timestep Consumption Time: 1.45008
PPO Batch Consumption Time: 0.12895
Total Iteration Time: 4.63557

Cumulative Model Updates: 52,392
Cumulative Timesteps: 437,067,988

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 437067988...
Checkpoint 437067988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,662.07964
Policy Entropy: 0.66756
Value Function Loss: 0.09007

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05340
Policy Update Magnitude: 0.19402
Value Function Update Magnitude: 0.41689

Collected Steps per Second: 15,718.98810
Overall Steps per Second: 10,921.12089

Timestep Collection Time: 3.18112
Timestep Consumption Time: 1.39753
PPO Batch Consumption Time: 0.11889
Total Iteration Time: 4.57865

Cumulative Model Updates: 52,398
Cumulative Timesteps: 437,117,992

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,448.15734
Policy Entropy: 0.65638
Value Function Loss: 0.09356

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06280
Policy Update Magnitude: 0.18836
Value Function Update Magnitude: 0.41615

Collected Steps per Second: 15,254.19165
Overall Steps per Second: 10,693.24189

Timestep Collection Time: 3.27910
Timestep Consumption Time: 1.39862
PPO Batch Consumption Time: 0.11743
Total Iteration Time: 4.67772

Cumulative Model Updates: 52,404
Cumulative Timesteps: 437,168,012

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 437168012...
Checkpoint 437168012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,829.46863
Policy Entropy: 0.66147
Value Function Loss: 0.08871

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05488
Policy Update Magnitude: 0.17923
Value Function Update Magnitude: 0.42579

Collected Steps per Second: 15,637.70497
Overall Steps per Second: 10,744.52873

Timestep Collection Time: 3.19855
Timestep Consumption Time: 1.45666
PPO Batch Consumption Time: 0.12657
Total Iteration Time: 4.65521

Cumulative Model Updates: 52,410
Cumulative Timesteps: 437,218,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,460.47910
Policy Entropy: 0.65844
Value Function Loss: 0.08955

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06511
Policy Update Magnitude: 0.18343
Value Function Update Magnitude: 0.42245

Collected Steps per Second: 15,484.36801
Overall Steps per Second: 10,978.93812

Timestep Collection Time: 3.22945
Timestep Consumption Time: 1.32527
PPO Batch Consumption Time: 0.10996
Total Iteration Time: 4.55472

Cumulative Model Updates: 52,416
Cumulative Timesteps: 437,268,036

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 437268036...
Checkpoint 437268036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,286.58492
Policy Entropy: 0.65278
Value Function Loss: 0.09296

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.05784
Policy Update Magnitude: 0.18067
Value Function Update Magnitude: 0.43328

Collected Steps per Second: 15,708.21891
Overall Steps per Second: 11,053.26340

Timestep Collection Time: 3.18445
Timestep Consumption Time: 1.34109
PPO Batch Consumption Time: 0.11549
Total Iteration Time: 4.52554

Cumulative Model Updates: 52,422
Cumulative Timesteps: 437,318,058

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,580.05888
Policy Entropy: 0.65098
Value Function Loss: 0.09485

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06616
Policy Update Magnitude: 0.17786
Value Function Update Magnitude: 0.43250

Collected Steps per Second: 16,123.87646
Overall Steps per Second: 11,244.82724

Timestep Collection Time: 3.10174
Timestep Consumption Time: 1.34582
PPO Batch Consumption Time: 0.11661
Total Iteration Time: 4.44756

Cumulative Model Updates: 52,428
Cumulative Timesteps: 437,368,070

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 437368070...
Checkpoint 437368070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,325.87483
Policy Entropy: 0.65229
Value Function Loss: 0.08634

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07502
Policy Update Magnitude: 0.16687
Value Function Update Magnitude: 0.41133

Collected Steps per Second: 16,007.48527
Overall Steps per Second: 10,918.13016

Timestep Collection Time: 3.12379
Timestep Consumption Time: 1.45612
PPO Batch Consumption Time: 0.12522
Total Iteration Time: 4.57991

Cumulative Model Updates: 52,434
Cumulative Timesteps: 437,418,074

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,211.53447
Policy Entropy: 0.65540
Value Function Loss: 0.08558

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.06945
Policy Update Magnitude: 0.17001
Value Function Update Magnitude: 0.40030

Collected Steps per Second: 15,485.22306
Overall Steps per Second: 10,745.60499

Timestep Collection Time: 3.22979
Timestep Consumption Time: 1.42458
PPO Batch Consumption Time: 0.12624
Total Iteration Time: 4.65437

Cumulative Model Updates: 52,440
Cumulative Timesteps: 437,468,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 437468088...
Checkpoint 437468088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,521.14362
Policy Entropy: 0.65872
Value Function Loss: 0.08272

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07705
Policy Update Magnitude: 0.17866
Value Function Update Magnitude: 0.39012

Collected Steps per Second: 15,012.37939
Overall Steps per Second: 10,517.58359

Timestep Collection Time: 3.33272
Timestep Consumption Time: 1.42427
PPO Batch Consumption Time: 0.12319
Total Iteration Time: 4.75699

Cumulative Model Updates: 52,446
Cumulative Timesteps: 437,518,120

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,782.16144
Policy Entropy: 0.65443
Value Function Loss: 0.08675

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.06970
Policy Update Magnitude: 0.17689
Value Function Update Magnitude: 0.37355

Collected Steps per Second: 15,532.68509
Overall Steps per Second: 10,714.46921

Timestep Collection Time: 3.21953
Timestep Consumption Time: 1.44780
PPO Batch Consumption Time: 0.12725
Total Iteration Time: 4.66733

Cumulative Model Updates: 52,452
Cumulative Timesteps: 437,568,128

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 437568128...
Checkpoint 437568128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,675.31574
Policy Entropy: 0.64962
Value Function Loss: 0.08330

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08064
Policy Update Magnitude: 0.17683
Value Function Update Magnitude: 0.41683

Collected Steps per Second: 15,191.09529
Overall Steps per Second: 10,654.74692

Timestep Collection Time: 3.29232
Timestep Consumption Time: 1.40173
PPO Batch Consumption Time: 0.12481
Total Iteration Time: 4.69406

Cumulative Model Updates: 52,458
Cumulative Timesteps: 437,618,142

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,916.08396
Policy Entropy: 0.64699
Value Function Loss: 0.08373

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05796
Policy Update Magnitude: 0.18230
Value Function Update Magnitude: 0.42178

Collected Steps per Second: 15,714.15264
Overall Steps per Second: 11,419.55517

Timestep Collection Time: 3.18197
Timestep Consumption Time: 1.19666
PPO Batch Consumption Time: 0.08809
Total Iteration Time: 4.37863

Cumulative Model Updates: 52,464
Cumulative Timesteps: 437,668,144

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 437668144...
Checkpoint 437668144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,771.15944
Policy Entropy: 0.64512
Value Function Loss: 0.08448

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05706
Policy Update Magnitude: 0.18912
Value Function Update Magnitude: 0.41788

Collected Steps per Second: 16,353.50035
Overall Steps per Second: 11,148.00984

Timestep Collection Time: 3.05806
Timestep Consumption Time: 1.42794
PPO Batch Consumption Time: 0.11331
Total Iteration Time: 4.48600

Cumulative Model Updates: 52,470
Cumulative Timesteps: 437,718,154

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,861.15814
Policy Entropy: 0.65513
Value Function Loss: 0.08352

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04844
Policy Update Magnitude: 0.18617
Value Function Update Magnitude: 0.42434

Collected Steps per Second: 17,046.09995
Overall Steps per Second: 11,802.71410

Timestep Collection Time: 2.93334
Timestep Consumption Time: 1.30314
PPO Batch Consumption Time: 0.10041
Total Iteration Time: 4.23648

Cumulative Model Updates: 52,476
Cumulative Timesteps: 437,768,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 437768156...
Checkpoint 437768156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,801.37322
Policy Entropy: 0.66240
Value Function Loss: 0.08584

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04304
Policy Update Magnitude: 0.18962
Value Function Update Magnitude: 0.41160

Collected Steps per Second: 19,359.48973
Overall Steps per Second: 12,878.27917

Timestep Collection Time: 2.58271
Timestep Consumption Time: 1.29979
PPO Batch Consumption Time: 0.10432
Total Iteration Time: 3.88251

Cumulative Model Updates: 52,482
Cumulative Timesteps: 437,818,156

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,744.30307
Policy Entropy: 0.65956
Value Function Loss: 0.09196

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04920
Policy Update Magnitude: 0.18896
Value Function Update Magnitude: 0.40995

Collected Steps per Second: 21,542.22239
Overall Steps per Second: 14,006.80808

Timestep Collection Time: 2.32149
Timestep Consumption Time: 1.24892
PPO Batch Consumption Time: 0.09759
Total Iteration Time: 3.57041

Cumulative Model Updates: 52,488
Cumulative Timesteps: 437,868,166

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 437868166...
Checkpoint 437868166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,981.64989
Policy Entropy: 0.66056
Value Function Loss: 0.08683

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06289
Policy Update Magnitude: 0.18125
Value Function Update Magnitude: 0.43315

Collected Steps per Second: 22,006.38050
Overall Steps per Second: 14,395.14432

Timestep Collection Time: 2.27270
Timestep Consumption Time: 1.20166
PPO Batch Consumption Time: 0.09246
Total Iteration Time: 3.47437

Cumulative Model Updates: 52,494
Cumulative Timesteps: 437,918,180

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,744.79638
Policy Entropy: 0.66449
Value Function Loss: 0.08724

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05698
Policy Update Magnitude: 0.17945
Value Function Update Magnitude: 0.44911

Collected Steps per Second: 22,239.89143
Overall Steps per Second: 14,314.37518

Timestep Collection Time: 2.24848
Timestep Consumption Time: 1.24493
PPO Batch Consumption Time: 0.10147
Total Iteration Time: 3.49341

Cumulative Model Updates: 52,500
Cumulative Timesteps: 437,968,186

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 437968186...
Checkpoint 437968186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,162.17829
Policy Entropy: 0.66733
Value Function Loss: 0.08964

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.08746
Policy Update Magnitude: 0.17512
Value Function Update Magnitude: 0.44091

Collected Steps per Second: 22,427.49049
Overall Steps per Second: 14,461.65377

Timestep Collection Time: 2.23057
Timestep Consumption Time: 1.22865
PPO Batch Consumption Time: 0.10064
Total Iteration Time: 3.45922

Cumulative Model Updates: 52,506
Cumulative Timesteps: 438,018,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,769.95110
Policy Entropy: 0.66231
Value Function Loss: 0.09532

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.05850
Policy Update Magnitude: 0.17484
Value Function Update Magnitude: 0.41044

Collected Steps per Second: 21,729.33560
Overall Steps per Second: 14,041.45893

Timestep Collection Time: 2.30223
Timestep Consumption Time: 1.26050
PPO Batch Consumption Time: 0.10273
Total Iteration Time: 3.56274

Cumulative Model Updates: 52,512
Cumulative Timesteps: 438,068,238

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 438068238...
Checkpoint 438068238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,152.43256
Policy Entropy: 0.66728
Value Function Loss: 0.09077

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07979
Policy Update Magnitude: 0.17146
Value Function Update Magnitude: 0.40991

Collected Steps per Second: 21,415.99327
Overall Steps per Second: 13,918.16918

Timestep Collection Time: 2.33517
Timestep Consumption Time: 1.25797
PPO Batch Consumption Time: 0.10372
Total Iteration Time: 3.59315

Cumulative Model Updates: 52,518
Cumulative Timesteps: 438,118,248

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,894.31406
Policy Entropy: 0.66864
Value Function Loss: 0.08250

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.06632
Policy Update Magnitude: 0.17060
Value Function Update Magnitude: 0.40892

Collected Steps per Second: 21,244.38189
Overall Steps per Second: 13,608.48727

Timestep Collection Time: 2.35375
Timestep Consumption Time: 1.32072
PPO Batch Consumption Time: 0.10071
Total Iteration Time: 3.67447

Cumulative Model Updates: 52,524
Cumulative Timesteps: 438,168,252

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 438168252...
Checkpoint 438168252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,792.35611
Policy Entropy: 0.68579
Value Function Loss: 0.07701

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05134
Policy Update Magnitude: 0.17267
Value Function Update Magnitude: 0.39835

Collected Steps per Second: 21,214.90467
Overall Steps per Second: 13,487.71157

Timestep Collection Time: 2.35787
Timestep Consumption Time: 1.35084
PPO Batch Consumption Time: 0.11231
Total Iteration Time: 3.70871

Cumulative Model Updates: 52,530
Cumulative Timesteps: 438,218,274

Timesteps Collected: 50,022
--------END ITERATION REPORT--------
