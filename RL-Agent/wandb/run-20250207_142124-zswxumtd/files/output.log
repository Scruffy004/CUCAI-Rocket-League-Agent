Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.15013
Policy Entropy: 3.12473
Value Function Loss: 0.00581

Mean KL Divergence: 0.00070
SB3 Clip Fraction: 0.00519
Policy Update Magnitude: 0.20037
Value Function Update Magnitude: 0.18053

Collected Steps per Second: 7,159.33019
Overall Steps per Second: 4,189.24699

Timestep Collection Time: 6.98613
Timestep Consumption Time: 4.95301
PPO Batch Consumption Time: 2.00948
Total Iteration Time: 11.93914

Cumulative Model Updates: 117,126
Cumulative Timesteps: 976,860,772

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 938.49501
Policy Entropy: 3.09982
Value Function Loss: 0.00571

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02475
Policy Update Magnitude: 0.22627
Value Function Update Magnitude: 0.19335

Collected Steps per Second: 20,894.41954
Overall Steps per Second: 13,351.70022

Timestep Collection Time: 2.39327
Timestep Consumption Time: 1.35202
PPO Batch Consumption Time: 0.32358
Total Iteration Time: 3.74529

Cumulative Model Updates: 117,128
Cumulative Timesteps: 976,910,778

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 976910778...
Checkpoint 976910778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.76578
Policy Entropy: 3.10396
Value Function Loss: 0.00555

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.07596
Policy Update Magnitude: 0.44604
Value Function Update Magnitude: 0.38531

Collected Steps per Second: 20,609.53533
Overall Steps per Second: 11,448.95937

Timestep Collection Time: 2.42723
Timestep Consumption Time: 1.94208
PPO Batch Consumption Time: 0.30573
Total Iteration Time: 4.36931

Cumulative Model Updates: 117,132
Cumulative Timesteps: 976,960,802

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,631.18402
Policy Entropy: 3.09331
Value Function Loss: 0.00567

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09918
Policy Update Magnitude: 0.63330
Value Function Update Magnitude: 0.55754

Collected Steps per Second: 21,548.60430
Overall Steps per Second: 10,599.21753

Timestep Collection Time: 2.32108
Timestep Consumption Time: 2.39776
PPO Batch Consumption Time: 0.28156
Total Iteration Time: 4.71884

Cumulative Model Updates: 117,138
Cumulative Timesteps: 977,010,818

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 977010818...
Checkpoint 977010818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.16728
Policy Entropy: 3.09512
Value Function Loss: 0.00520

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.59785
Value Function Update Magnitude: 0.53908

Collected Steps per Second: 21,334.49384
Overall Steps per Second: 10,463.60657

Timestep Collection Time: 2.34381
Timestep Consumption Time: 2.43504
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.77885

Cumulative Model Updates: 117,144
Cumulative Timesteps: 977,060,822

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,085.11476
Policy Entropy: 3.11138
Value Function Loss: 0.00524

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.57672
Value Function Update Magnitude: 0.52750

Collected Steps per Second: 21,646.96738
Overall Steps per Second: 10,598.47141

Timestep Collection Time: 2.31053
Timestep Consumption Time: 2.40864
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.71917

Cumulative Model Updates: 117,150
Cumulative Timesteps: 977,110,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 977110838...
Checkpoint 977110838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.17440
Policy Entropy: 3.12137
Value Function Loss: 0.00498

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.56544
Value Function Update Magnitude: 0.51834

Collected Steps per Second: 20,907.51579
Overall Steps per Second: 10,407.45011

Timestep Collection Time: 2.39196
Timestep Consumption Time: 2.41325
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.80521

Cumulative Model Updates: 117,156
Cumulative Timesteps: 977,160,848

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 950.74399
Policy Entropy: 3.12220
Value Function Loss: 0.00509

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10049
Policy Update Magnitude: 0.55966
Value Function Update Magnitude: 0.52980

Collected Steps per Second: 21,878.52214
Overall Steps per Second: 10,746.06833

Timestep Collection Time: 2.28589
Timestep Consumption Time: 2.36809
PPO Batch Consumption Time: 0.27709
Total Iteration Time: 4.65398

Cumulative Model Updates: 117,162
Cumulative Timesteps: 977,210,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 977210860...
Checkpoint 977210860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.37106
Policy Entropy: 3.10044
Value Function Loss: 0.00513

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09285
Policy Update Magnitude: 0.56297
Value Function Update Magnitude: 0.53379

Collected Steps per Second: 21,065.92680
Overall Steps per Second: 10,236.51515

Timestep Collection Time: 2.37474
Timestep Consumption Time: 2.51228
PPO Batch Consumption Time: 0.30541
Total Iteration Time: 4.88701

Cumulative Model Updates: 117,168
Cumulative Timesteps: 977,260,886

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646.15053
Policy Entropy: 3.10715
Value Function Loss: 0.00518

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09125
Policy Update Magnitude: 0.56591
Value Function Update Magnitude: 0.52439

Collected Steps per Second: 20,765.90532
Overall Steps per Second: 10,473.43279

Timestep Collection Time: 2.40837
Timestep Consumption Time: 2.36676
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.77513

Cumulative Model Updates: 117,174
Cumulative Timesteps: 977,310,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 977310898...
Checkpoint 977310898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,859.09814
Policy Entropy: 3.12853
Value Function Loss: 0.00493

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09675
Policy Update Magnitude: 0.55712
Value Function Update Magnitude: 0.53428

Collected Steps per Second: 20,749.64867
Overall Steps per Second: 10,490.66618

Timestep Collection Time: 2.41084
Timestep Consumption Time: 2.35759
PPO Batch Consumption Time: 0.27689
Total Iteration Time: 4.76843

Cumulative Model Updates: 117,180
Cumulative Timesteps: 977,360,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,284.08758
Policy Entropy: 3.13318
Value Function Loss: 0.00471

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08912
Policy Update Magnitude: 0.54376
Value Function Update Magnitude: 0.52826

Collected Steps per Second: 21,566.40578
Overall Steps per Second: 10,557.41121

Timestep Collection Time: 2.31861
Timestep Consumption Time: 2.41778
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.73639

Cumulative Model Updates: 117,186
Cumulative Timesteps: 977,410,926

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 977410926...
Checkpoint 977410926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,631.43280
Policy Entropy: 3.13573
Value Function Loss: 0.00467

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09564
Policy Update Magnitude: 0.55278
Value Function Update Magnitude: 0.53573

Collected Steps per Second: 20,684.40051
Overall Steps per Second: 10,340.45913

Timestep Collection Time: 2.41834
Timestep Consumption Time: 2.41916
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.83750

Cumulative Model Updates: 117,192
Cumulative Timesteps: 977,460,948

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,826.56753
Policy Entropy: 3.12426
Value Function Loss: 0.00472

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.56102
Value Function Update Magnitude: 0.53713

Collected Steps per Second: 21,324.87797
Overall Steps per Second: 10,464.93666

Timestep Collection Time: 2.34543
Timestep Consumption Time: 2.43396
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.77939

Cumulative Model Updates: 117,198
Cumulative Timesteps: 977,510,964

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 977510964...
Checkpoint 977510964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,335.15480
Policy Entropy: 3.11459
Value Function Loss: 0.00469

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.10844
Policy Update Magnitude: 0.56425
Value Function Update Magnitude: 0.53038

Collected Steps per Second: 20,753.96616
Overall Steps per Second: 10,308.69041

Timestep Collection Time: 2.40995
Timestep Consumption Time: 2.44188
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.85183

Cumulative Model Updates: 117,204
Cumulative Timesteps: 977,560,980

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,660.54843
Policy Entropy: 3.10629
Value Function Loss: 0.00456

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.10965
Policy Update Magnitude: 0.55877
Value Function Update Magnitude: 0.52095

Collected Steps per Second: 21,580.19603
Overall Steps per Second: 10,590.88782

Timestep Collection Time: 2.31777
Timestep Consumption Time: 2.40497
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.72274

Cumulative Model Updates: 117,210
Cumulative Timesteps: 977,610,998

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 977610998...
Checkpoint 977610998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,725.54992
Policy Entropy: 3.08168
Value Function Loss: 0.00452

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11388
Policy Update Magnitude: 0.55472
Value Function Update Magnitude: 0.52487

Collected Steps per Second: 21,352.61314
Overall Steps per Second: 10,587.36008

Timestep Collection Time: 2.34182
Timestep Consumption Time: 2.38117
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.72299

Cumulative Model Updates: 117,216
Cumulative Timesteps: 977,661,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,418.99393
Policy Entropy: 3.08400
Value Function Loss: 0.00465

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.10922
Policy Update Magnitude: 0.55873
Value Function Update Magnitude: 0.53453

Collected Steps per Second: 21,605.65353
Overall Steps per Second: 10,503.05252

Timestep Collection Time: 2.31421
Timestep Consumption Time: 2.44631
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.76052

Cumulative Model Updates: 117,222
Cumulative Timesteps: 977,711,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 977711002...
Checkpoint 977711002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,498.01618
Policy Entropy: 3.07856
Value Function Loss: 0.00488

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10486
Policy Update Magnitude: 0.56396
Value Function Update Magnitude: 0.53410

Collected Steps per Second: 21,362.93473
Overall Steps per Second: 10,604.16493

Timestep Collection Time: 2.34097
Timestep Consumption Time: 2.37510
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.71607

Cumulative Model Updates: 117,228
Cumulative Timesteps: 977,761,012

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.05296
Policy Entropy: 3.08073
Value Function Loss: 0.00504

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.10994
Policy Update Magnitude: 0.57137
Value Function Update Magnitude: 0.53850

Collected Steps per Second: 21,698.98244
Overall Steps per Second: 10,574.11899

Timestep Collection Time: 2.30555
Timestep Consumption Time: 2.42563
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.73117

Cumulative Model Updates: 117,234
Cumulative Timesteps: 977,811,040

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 977811040...
Checkpoint 977811040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,209.08074
Policy Entropy: 3.08558
Value Function Loss: 0.00485

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.56522
Value Function Update Magnitude: 0.52417

Collected Steps per Second: 20,705.96838
Overall Steps per Second: 10,234.25854

Timestep Collection Time: 2.41573
Timestep Consumption Time: 2.47178
PPO Batch Consumption Time: 0.29954
Total Iteration Time: 4.88751

Cumulative Model Updates: 117,240
Cumulative Timesteps: 977,861,060

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,501.80406
Policy Entropy: 3.10201
Value Function Loss: 0.00486

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09827
Policy Update Magnitude: 0.56133
Value Function Update Magnitude: 0.51689

Collected Steps per Second: 20,151.36774
Overall Steps per Second: 10,042.01628

Timestep Collection Time: 2.48192
Timestep Consumption Time: 2.49856
PPO Batch Consumption Time: 0.30106
Total Iteration Time: 4.98047

Cumulative Model Updates: 117,246
Cumulative Timesteps: 977,911,074

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 977911074...
Checkpoint 977911074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 712.13422
Policy Entropy: 3.09796
Value Function Loss: 0.00479

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09633
Policy Update Magnitude: 0.55822
Value Function Update Magnitude: 0.51921

Collected Steps per Second: 20,445.10804
Overall Steps per Second: 10,204.53422

Timestep Collection Time: 2.44645
Timestep Consumption Time: 2.45509
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.90155

Cumulative Model Updates: 117,252
Cumulative Timesteps: 977,961,092

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 927.07144
Policy Entropy: 3.09272
Value Function Loss: 0.00512

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.56682
Value Function Update Magnitude: 0.52750

Collected Steps per Second: 21,770.62625
Overall Steps per Second: 10,413.89193

Timestep Collection Time: 2.29768
Timestep Consumption Time: 2.50571
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.80339

Cumulative Model Updates: 117,258
Cumulative Timesteps: 978,011,114

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 978011114...
Checkpoint 978011114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,790.26575
Policy Entropy: 3.09770
Value Function Loss: 0.00528

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10178
Policy Update Magnitude: 0.57525
Value Function Update Magnitude: 0.55455

Collected Steps per Second: 21,700.01683
Overall Steps per Second: 10,494.88409

Timestep Collection Time: 2.30544
Timestep Consumption Time: 2.46146
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.76689

Cumulative Model Updates: 117,264
Cumulative Timesteps: 978,061,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 972.55800
Policy Entropy: 3.11283
Value Function Loss: 0.00510

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09407
Policy Update Magnitude: 0.57385
Value Function Update Magnitude: 0.54790

Collected Steps per Second: 21,970.24057
Overall Steps per Second: 10,641.26677

Timestep Collection Time: 2.27790
Timestep Consumption Time: 2.42511
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.70301

Cumulative Model Updates: 117,270
Cumulative Timesteps: 978,111,188

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 978111188...
Checkpoint 978111188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,933.05095
Policy Entropy: 3.12760
Value Function Loss: 0.00480

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.56196
Value Function Update Magnitude: 0.53807

Collected Steps per Second: 21,163.06477
Overall Steps per Second: 10,266.18138

Timestep Collection Time: 2.36336
Timestep Consumption Time: 2.50856
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.87192

Cumulative Model Updates: 117,276
Cumulative Timesteps: 978,161,204

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391.47434
Policy Entropy: 3.13114
Value Function Loss: 0.00489

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08568
Policy Update Magnitude: 0.55234
Value Function Update Magnitude: 0.52920

Collected Steps per Second: 21,884.10507
Overall Steps per Second: 10,441.69301

Timestep Collection Time: 2.28568
Timestep Consumption Time: 2.50473
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.79041

Cumulative Model Updates: 117,282
Cumulative Timesteps: 978,211,224

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 978211224...
Checkpoint 978211224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.71969
Policy Entropy: 3.13540
Value Function Loss: 0.00507

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08655
Policy Update Magnitude: 0.55648
Value Function Update Magnitude: 0.54335

Collected Steps per Second: 21,209.78803
Overall Steps per Second: 10,335.51971

Timestep Collection Time: 2.35872
Timestep Consumption Time: 2.48167
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.84040

Cumulative Model Updates: 117,288
Cumulative Timesteps: 978,261,252

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 964.80209
Policy Entropy: 3.12278
Value Function Loss: 0.00523

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08914
Policy Update Magnitude: 0.56136
Value Function Update Magnitude: 0.55311

Collected Steps per Second: 21,925.95668
Overall Steps per Second: 10,463.40935

Timestep Collection Time: 2.28150
Timestep Consumption Time: 2.49935
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.78085

Cumulative Model Updates: 117,294
Cumulative Timesteps: 978,311,276

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 978311276...
Checkpoint 978311276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,705.70109
Policy Entropy: 3.10706
Value Function Loss: 0.00522

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08762
Policy Update Magnitude: 0.56418
Value Function Update Magnitude: 0.54759

Collected Steps per Second: 21,847.84637
Overall Steps per Second: 10,498.87942

Timestep Collection Time: 2.28901
Timestep Consumption Time: 2.47435
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.76337

Cumulative Model Updates: 117,300
Cumulative Timesteps: 978,361,286

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,301.71179
Policy Entropy: 3.10980
Value Function Loss: 0.00528

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.56109
Value Function Update Magnitude: 0.55529

Collected Steps per Second: 22,008.15194
Overall Steps per Second: 10,421.87754

Timestep Collection Time: 2.27352
Timestep Consumption Time: 2.52753
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.80105

Cumulative Model Updates: 117,306
Cumulative Timesteps: 978,411,322

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 978411322...
Checkpoint 978411322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,312.50374
Policy Entropy: 3.11543
Value Function Loss: 0.00525

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.12360
Policy Update Magnitude: 0.57127
Value Function Update Magnitude: 0.55729

Collected Steps per Second: 21,759.36788
Overall Steps per Second: 10,581.86641

Timestep Collection Time: 2.29869
Timestep Consumption Time: 2.42808
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.72677

Cumulative Model Updates: 117,312
Cumulative Timesteps: 978,461,340

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.43522
Policy Entropy: 3.12521
Value Function Loss: 0.00549

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.13915
Policy Update Magnitude: 0.57930
Value Function Update Magnitude: 0.57530

Collected Steps per Second: 21,987.23838
Overall Steps per Second: 10,412.64204

Timestep Collection Time: 2.27568
Timestep Consumption Time: 2.52963
PPO Batch Consumption Time: 0.29682
Total Iteration Time: 4.80531

Cumulative Model Updates: 117,318
Cumulative Timesteps: 978,511,376

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 978511376...
Checkpoint 978511376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,500.50272
Policy Entropy: 3.12299
Value Function Loss: 0.00533

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.13915
Policy Update Magnitude: 0.58211
Value Function Update Magnitude: 0.57635

Collected Steps per Second: 21,405.94621
Overall Steps per Second: 10,354.03992

Timestep Collection Time: 2.33617
Timestep Consumption Time: 2.49363
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.82981

Cumulative Model Updates: 117,324
Cumulative Timesteps: 978,561,384

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.61707
Policy Entropy: 3.12890
Value Function Loss: 0.00509

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.12421
Policy Update Magnitude: 0.57583
Value Function Update Magnitude: 0.58236

Collected Steps per Second: 22,217.29689
Overall Steps per Second: 10,542.29027

Timestep Collection Time: 2.25095
Timestep Consumption Time: 2.49280
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.74375

Cumulative Model Updates: 117,330
Cumulative Timesteps: 978,611,394

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 978611394...
Checkpoint 978611394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,010.57615
Policy Entropy: 3.13094
Value Function Loss: 0.00492

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.56743
Value Function Update Magnitude: 0.56674

Collected Steps per Second: 21,901.62693
Overall Steps per Second: 10,593.33947

Timestep Collection Time: 2.28385
Timestep Consumption Time: 2.43799
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.72183

Cumulative Model Updates: 117,336
Cumulative Timesteps: 978,661,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.37737
Policy Entropy: 3.12801
Value Function Loss: 0.00476

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.12845
Policy Update Magnitude: 0.55547
Value Function Update Magnitude: 0.54467

Collected Steps per Second: 22,209.45395
Overall Steps per Second: 10,510.70751

Timestep Collection Time: 2.25228
Timestep Consumption Time: 2.50686
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.75915

Cumulative Model Updates: 117,342
Cumulative Timesteps: 978,711,436

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 978711436...
Checkpoint 978711436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,436.87906
Policy Entropy: 3.12305
Value Function Loss: 0.00483

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.12538
Policy Update Magnitude: 0.55367
Value Function Update Magnitude: 0.53259

Collected Steps per Second: 21,473.47861
Overall Steps per Second: 10,550.88559

Timestep Collection Time: 2.32976
Timestep Consumption Time: 2.41183
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.74159

Cumulative Model Updates: 117,348
Cumulative Timesteps: 978,761,464

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,077.63172
Policy Entropy: 3.12955
Value Function Loss: 0.00512

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.13951
Policy Update Magnitude: 0.56160
Value Function Update Magnitude: 0.55414

Collected Steps per Second: 21,868.99162
Overall Steps per Second: 10,626.90342

Timestep Collection Time: 2.28826
Timestep Consumption Time: 2.42073
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.70899

Cumulative Model Updates: 117,354
Cumulative Timesteps: 978,811,506

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 978811506...
Checkpoint 978811506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.88238
Policy Entropy: 3.12422
Value Function Loss: 0.00517

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.13788
Policy Update Magnitude: 0.57076
Value Function Update Magnitude: 0.56055

Collected Steps per Second: 21,332.07982
Overall Steps per Second: 10,284.39350

Timestep Collection Time: 2.34604
Timestep Consumption Time: 2.52016
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.86621

Cumulative Model Updates: 117,360
Cumulative Timesteps: 978,861,552

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,125.17586
Policy Entropy: 3.12332
Value Function Loss: 0.00522

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.56974
Value Function Update Magnitude: 0.55000

Collected Steps per Second: 21,870.06077
Overall Steps per Second: 10,483.23491

Timestep Collection Time: 2.28641
Timestep Consumption Time: 2.48349
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.76990

Cumulative Model Updates: 117,366
Cumulative Timesteps: 978,911,556

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 978911556...
Checkpoint 978911556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.87201
Policy Entropy: 3.14011
Value Function Loss: 0.00489

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.10887
Policy Update Magnitude: 0.55882
Value Function Update Magnitude: 0.53174

Collected Steps per Second: 21,253.52890
Overall Steps per Second: 10,389.83901

Timestep Collection Time: 2.35264
Timestep Consumption Time: 2.45994
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.81259

Cumulative Model Updates: 117,372
Cumulative Timesteps: 978,961,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,631.39306
Policy Entropy: 3.12503
Value Function Loss: 0.00491

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.11883
Policy Update Magnitude: 0.55009
Value Function Update Magnitude: 0.50457

Collected Steps per Second: 22,071.23207
Overall Steps per Second: 10,494.99137

Timestep Collection Time: 2.26575
Timestep Consumption Time: 2.49918
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.76494

Cumulative Model Updates: 117,378
Cumulative Timesteps: 979,011,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 979011566...
Checkpoint 979011566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,296.26742
Policy Entropy: 3.14007
Value Function Loss: 0.00484

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11054
Policy Update Magnitude: 0.54822
Value Function Update Magnitude: 0.50026

Collected Steps per Second: 21,780.10756
Overall Steps per Second: 10,441.77797

Timestep Collection Time: 2.29677
Timestep Consumption Time: 2.49398
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.79075

Cumulative Model Updates: 117,384
Cumulative Timesteps: 979,061,590

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.47175
Policy Entropy: 3.12670
Value Function Loss: 0.00519

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11281
Policy Update Magnitude: 0.55927
Value Function Update Magnitude: 0.51650

Collected Steps per Second: 22,113.35853
Overall Steps per Second: 10,363.01721

Timestep Collection Time: 2.26189
Timestep Consumption Time: 2.56470
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.82659

Cumulative Model Updates: 117,390
Cumulative Timesteps: 979,111,608

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 979111608...
Checkpoint 979111608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.97543
Policy Entropy: 3.13607
Value Function Loss: 0.00479

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11336
Policy Update Magnitude: 0.56374
Value Function Update Magnitude: 0.52686

Collected Steps per Second: 21,939.38361
Overall Steps per Second: 10,266.64796

Timestep Collection Time: 2.27992
Timestep Consumption Time: 2.59217
PPO Batch Consumption Time: 0.30601
Total Iteration Time: 4.87209

Cumulative Model Updates: 117,396
Cumulative Timesteps: 979,161,628

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,258.07191
Policy Entropy: 3.12141
Value Function Loss: 0.00514

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10277
Policy Update Magnitude: 0.56529
Value Function Update Magnitude: 0.52178

Collected Steps per Second: 22,305.90641
Overall Steps per Second: 10,483.81417

Timestep Collection Time: 2.24219
Timestep Consumption Time: 2.52841
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.77059

Cumulative Model Updates: 117,402
Cumulative Timesteps: 979,211,642

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 979211642...
Checkpoint 979211642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,117.26384
Policy Entropy: 3.12468
Value Function Loss: 0.00481

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10713
Policy Update Magnitude: 0.56278
Value Function Update Magnitude: 0.51678

Collected Steps per Second: 21,631.90724
Overall Steps per Second: 10,343.16761

Timestep Collection Time: 2.31149
Timestep Consumption Time: 2.52281
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.83430

Cumulative Model Updates: 117,408
Cumulative Timesteps: 979,261,644

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.06680
Policy Entropy: 3.13093
Value Function Loss: 0.00500

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09757
Policy Update Magnitude: 0.55985
Value Function Update Magnitude: 0.53171

Collected Steps per Second: 22,368.36467
Overall Steps per Second: 10,526.18462

Timestep Collection Time: 2.23566
Timestep Consumption Time: 2.51516
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.75082

Cumulative Model Updates: 117,414
Cumulative Timesteps: 979,311,652

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 979311652...
Checkpoint 979311652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,426.66607
Policy Entropy: 3.13473
Value Function Loss: 0.00471

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.55761
Value Function Update Magnitude: 0.52994

Collected Steps per Second: 21,924.61871
Overall Steps per Second: 10,472.42747

Timestep Collection Time: 2.28109
Timestep Consumption Time: 2.49450
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.77559

Cumulative Model Updates: 117,420
Cumulative Timesteps: 979,361,664

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.86864
Policy Entropy: 3.11597
Value Function Loss: 0.00484

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08815
Policy Update Magnitude: 0.55411
Value Function Update Magnitude: 0.53481

Collected Steps per Second: 21,676.89431
Overall Steps per Second: 10,350.44544

Timestep Collection Time: 2.30734
Timestep Consumption Time: 2.52491
PPO Batch Consumption Time: 0.29566
Total Iteration Time: 4.83226

Cumulative Model Updates: 117,426
Cumulative Timesteps: 979,411,680

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 979411680...
Checkpoint 979411680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 958.96624
Policy Entropy: 3.10064
Value Function Loss: 0.00492

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09042
Policy Update Magnitude: 0.55985
Value Function Update Magnitude: 0.54188

Collected Steps per Second: 21,564.72057
Overall Steps per Second: 10,394.42757

Timestep Collection Time: 2.31944
Timestep Consumption Time: 2.49256
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.81200

Cumulative Model Updates: 117,432
Cumulative Timesteps: 979,461,698

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,877.76579
Policy Entropy: 3.09626
Value Function Loss: 0.00514

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.56549
Value Function Update Magnitude: 0.52696

Collected Steps per Second: 21,463.41438
Overall Steps per Second: 10,443.45647

Timestep Collection Time: 2.33048
Timestep Consumption Time: 2.45912
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.78960

Cumulative Model Updates: 117,438
Cumulative Timesteps: 979,511,718

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 979511718...
Checkpoint 979511718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.68874
Policy Entropy: 3.10927
Value Function Loss: 0.00535

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.57489
Value Function Update Magnitude: 0.55668

Collected Steps per Second: 20,971.66506
Overall Steps per Second: 10,151.90070

Timestep Collection Time: 2.38446
Timestep Consumption Time: 2.54132
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.92578

Cumulative Model Updates: 117,444
Cumulative Timesteps: 979,561,724

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.39242
Policy Entropy: 3.12311
Value Function Loss: 0.00521

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10115
Policy Update Magnitude: 0.57978
Value Function Update Magnitude: 0.57017

Collected Steps per Second: 21,716.18372
Overall Steps per Second: 10,481.01357

Timestep Collection Time: 2.30335
Timestep Consumption Time: 2.46909
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.77244

Cumulative Model Updates: 117,450
Cumulative Timesteps: 979,611,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 979611744...
Checkpoint 979611744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 915.59716
Policy Entropy: 3.11940
Value Function Loss: 0.00521

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.09955
Policy Update Magnitude: 0.57275
Value Function Update Magnitude: 0.56263

Collected Steps per Second: 21,750.27714
Overall Steps per Second: 10,564.95356

Timestep Collection Time: 2.29937
Timestep Consumption Time: 2.43439
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.73376

Cumulative Model Updates: 117,456
Cumulative Timesteps: 979,661,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,506.38020
Policy Entropy: 3.10636
Value Function Loss: 0.00524

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10092
Policy Update Magnitude: 0.57508
Value Function Update Magnitude: 0.55138

Collected Steps per Second: 22,259.17047
Overall Steps per Second: 10,456.98575

Timestep Collection Time: 2.24627
Timestep Consumption Time: 2.53523
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.78149

Cumulative Model Updates: 117,462
Cumulative Timesteps: 979,711,756

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 979711756...
Checkpoint 979711756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.10894
Policy Entropy: 3.10321
Value Function Loss: 0.00517

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08813
Policy Update Magnitude: 0.57821
Value Function Update Magnitude: 0.55018

Collected Steps per Second: 21,874.22500
Overall Steps per Second: 10,426.61130

Timestep Collection Time: 2.28589
Timestep Consumption Time: 2.50973
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.79561

Cumulative Model Updates: 117,468
Cumulative Timesteps: 979,761,758

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.45982
Policy Entropy: 3.10825
Value Function Loss: 0.00521

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09750
Policy Update Magnitude: 0.58506
Value Function Update Magnitude: 0.55055

Collected Steps per Second: 22,073.08095
Overall Steps per Second: 10,456.55348

Timestep Collection Time: 2.26538
Timestep Consumption Time: 2.51669
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.78207

Cumulative Model Updates: 117,474
Cumulative Timesteps: 979,811,762

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 979811762...
Checkpoint 979811762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,305.74731
Policy Entropy: 3.11704
Value Function Loss: 0.00533

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11303
Policy Update Magnitude: 0.58025
Value Function Update Magnitude: 0.55513

Collected Steps per Second: 22,072.56357
Overall Steps per Second: 10,545.70501

Timestep Collection Time: 2.26544
Timestep Consumption Time: 2.47621
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.74165

Cumulative Model Updates: 117,480
Cumulative Timesteps: 979,861,766

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507.79496
Policy Entropy: 3.13329
Value Function Loss: 0.00540

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11641
Policy Update Magnitude: 0.56538
Value Function Update Magnitude: 0.54827

Collected Steps per Second: 22,506.23020
Overall Steps per Second: 10,629.43572

Timestep Collection Time: 2.22276
Timestep Consumption Time: 2.48360
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.70636

Cumulative Model Updates: 117,486
Cumulative Timesteps: 979,911,792

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 979911792...
Checkpoint 979911792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.61105
Policy Entropy: 3.13904
Value Function Loss: 0.00564

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10463
Policy Update Magnitude: 0.56571
Value Function Update Magnitude: 0.53212

Collected Steps per Second: 21,556.38068
Overall Steps per Second: 10,586.38826

Timestep Collection Time: 2.32154
Timestep Consumption Time: 2.40566
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.72720

Cumulative Model Updates: 117,492
Cumulative Timesteps: 979,961,836

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 885.66687
Policy Entropy: 3.14108
Value Function Loss: 0.00597

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08904
Policy Update Magnitude: 0.57729
Value Function Update Magnitude: 0.53845

Collected Steps per Second: 21,802.91432
Overall Steps per Second: 10,437.21856

Timestep Collection Time: 2.29355
Timestep Consumption Time: 2.49758
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.79112

Cumulative Model Updates: 117,498
Cumulative Timesteps: 980,011,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 980011842...
Checkpoint 980011842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.94896
Policy Entropy: 3.12257
Value Function Loss: 0.00575

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09769
Policy Update Magnitude: 0.57431
Value Function Update Magnitude: 0.53104

Collected Steps per Second: 20,489.07321
Overall Steps per Second: 10,051.84512

Timestep Collection Time: 2.44169
Timestep Consumption Time: 2.53530
PPO Batch Consumption Time: 0.29914
Total Iteration Time: 4.97700

Cumulative Model Updates: 117,504
Cumulative Timesteps: 980,061,870

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 857.93709
Policy Entropy: 3.12050
Value Function Loss: 0.00525

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09694
Policy Update Magnitude: 0.56925
Value Function Update Magnitude: 0.53237

Collected Steps per Second: 21,943.70732
Overall Steps per Second: 10,641.44339

Timestep Collection Time: 2.27974
Timestep Consumption Time: 2.42131
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.70105

Cumulative Model Updates: 117,510
Cumulative Timesteps: 980,111,896

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 980111896...
Checkpoint 980111896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.23521
Policy Entropy: 3.11943
Value Function Loss: 0.00511

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.56172
Value Function Update Magnitude: 0.52974

Collected Steps per Second: 21,623.45500
Overall Steps per Second: 10,556.17877

Timestep Collection Time: 2.31267
Timestep Consumption Time: 2.42465
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.73732

Cumulative Model Updates: 117,516
Cumulative Timesteps: 980,161,904

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 886.81856
Policy Entropy: 3.11814
Value Function Loss: 0.00499

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.10790
Policy Update Magnitude: 0.56382
Value Function Update Magnitude: 0.52765

Collected Steps per Second: 21,726.52597
Overall Steps per Second: 10,548.10518

Timestep Collection Time: 2.30198
Timestep Consumption Time: 2.43954
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.74152

Cumulative Model Updates: 117,522
Cumulative Timesteps: 980,211,918

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 980211918...
Checkpoint 980211918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,736.01420
Policy Entropy: 3.11877
Value Function Loss: 0.00529

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09585
Policy Update Magnitude: 0.56922
Value Function Update Magnitude: 0.54584

Collected Steps per Second: 22,089.72860
Overall Steps per Second: 10,616.73807

Timestep Collection Time: 2.26431
Timestep Consumption Time: 2.44693
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.71124

Cumulative Model Updates: 117,528
Cumulative Timesteps: 980,261,936

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.01647
Policy Entropy: 3.11773
Value Function Loss: 0.00507

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09289
Policy Update Magnitude: 0.56615
Value Function Update Magnitude: 0.53883

Collected Steps per Second: 22,563.40139
Overall Steps per Second: 10,508.58281

Timestep Collection Time: 2.21722
Timestep Consumption Time: 2.54346
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.76068

Cumulative Model Updates: 117,534
Cumulative Timesteps: 980,311,964

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 980311964...
Checkpoint 980311964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,719.67988
Policy Entropy: 3.11450
Value Function Loss: 0.00506

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.56371
Value Function Update Magnitude: 0.53133

Collected Steps per Second: 21,754.81474
Overall Steps per Second: 10,583.46106

Timestep Collection Time: 2.29917
Timestep Consumption Time: 2.42688
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.72605

Cumulative Model Updates: 117,540
Cumulative Timesteps: 980,361,982

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.78815
Policy Entropy: 3.12455
Value Function Loss: 0.00492

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09100
Policy Update Magnitude: 0.56304
Value Function Update Magnitude: 0.53302

Collected Steps per Second: 22,331.56410
Overall Steps per Second: 10,573.31664

Timestep Collection Time: 2.23907
Timestep Consumption Time: 2.49000
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.72907

Cumulative Model Updates: 117,546
Cumulative Timesteps: 980,411,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 980411984...
Checkpoint 980411984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.64444
Policy Entropy: 3.10369
Value Function Loss: 0.00505

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.56004
Value Function Update Magnitude: 0.53564

Collected Steps per Second: 21,826.93496
Overall Steps per Second: 10,553.92651

Timestep Collection Time: 2.29212
Timestep Consumption Time: 2.44829
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.74042

Cumulative Model Updates: 117,552
Cumulative Timesteps: 980,462,014

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.85840
Policy Entropy: 3.09274
Value Function Loss: 0.00508

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09288
Policy Update Magnitude: 0.56086
Value Function Update Magnitude: 0.52668

Collected Steps per Second: 22,209.43609
Overall Steps per Second: 10,560.81474

Timestep Collection Time: 2.25175
Timestep Consumption Time: 2.48368
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.73543

Cumulative Model Updates: 117,558
Cumulative Timesteps: 980,512,024

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 980512024...
Checkpoint 980512024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317.96861
Policy Entropy: 3.07597
Value Function Loss: 0.00533

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.56369
Value Function Update Magnitude: 0.51055

Collected Steps per Second: 22,151.67520
Overall Steps per Second: 10,531.63668

Timestep Collection Time: 2.25807
Timestep Consumption Time: 2.49143
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.74950

Cumulative Model Updates: 117,564
Cumulative Timesteps: 980,562,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.41513
Policy Entropy: 3.09620
Value Function Loss: 0.00513

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09285
Policy Update Magnitude: 0.56831
Value Function Update Magnitude: 0.50333

Collected Steps per Second: 21,528.50120
Overall Steps per Second: 10,465.28686

Timestep Collection Time: 2.32250
Timestep Consumption Time: 2.45520
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.77770

Cumulative Model Updates: 117,570
Cumulative Timesteps: 980,612,044

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 980612044...
Checkpoint 980612044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.67075
Policy Entropy: 3.10373
Value Function Loss: 0.00499

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.56984
Value Function Update Magnitude: 0.51294

Collected Steps per Second: 21,385.77752
Overall Steps per Second: 10,317.78046

Timestep Collection Time: 2.33922
Timestep Consumption Time: 2.50931
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.84852

Cumulative Model Updates: 117,576
Cumulative Timesteps: 980,662,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,050.09738
Policy Entropy: 3.10523
Value Function Loss: 0.00486

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09129
Policy Update Magnitude: 0.56326
Value Function Update Magnitude: 0.51670

Collected Steps per Second: 21,652.50445
Overall Steps per Second: 10,331.75628

Timestep Collection Time: 2.30948
Timestep Consumption Time: 2.53055
PPO Batch Consumption Time: 0.30022
Total Iteration Time: 4.84003

Cumulative Model Updates: 117,582
Cumulative Timesteps: 980,712,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 980712076...
Checkpoint 980712076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.99634
Policy Entropy: 3.08829
Value Function Loss: 0.00494

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09365
Policy Update Magnitude: 0.56556
Value Function Update Magnitude: 0.52514

Collected Steps per Second: 21,585.40770
Overall Steps per Second: 10,442.41495

Timestep Collection Time: 2.31656
Timestep Consumption Time: 2.47198
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.78855

Cumulative Model Updates: 117,588
Cumulative Timesteps: 980,762,080

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.38222
Policy Entropy: 3.09494
Value Function Loss: 0.00500

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10066
Policy Update Magnitude: 0.56803
Value Function Update Magnitude: 0.53089

Collected Steps per Second: 22,005.85576
Overall Steps per Second: 10,459.84819

Timestep Collection Time: 2.27212
Timestep Consumption Time: 2.50806
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.78018

Cumulative Model Updates: 117,594
Cumulative Timesteps: 980,812,080

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 980812080...
Checkpoint 980812080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.92055
Policy Entropy: 3.09842
Value Function Loss: 0.00511

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10312
Policy Update Magnitude: 0.56254
Value Function Update Magnitude: 0.53583

Collected Steps per Second: 21,779.94380
Overall Steps per Second: 10,435.72183

Timestep Collection Time: 2.29789
Timestep Consumption Time: 2.49794
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.79584

Cumulative Model Updates: 117,600
Cumulative Timesteps: 980,862,128

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.73343
Policy Entropy: 3.10974
Value Function Loss: 0.00498

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11190
Policy Update Magnitude: 0.55976
Value Function Update Magnitude: 0.54082

Collected Steps per Second: 22,192.74333
Overall Steps per Second: 10,525.84366

Timestep Collection Time: 2.25344
Timestep Consumption Time: 2.49772
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.75116

Cumulative Model Updates: 117,606
Cumulative Timesteps: 980,912,138

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 980912138...
Checkpoint 980912138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.40467
Policy Entropy: 3.11775
Value Function Loss: 0.00502

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11316
Policy Update Magnitude: 0.55713
Value Function Update Magnitude: 0.53892

Collected Steps per Second: 21,949.95207
Overall Steps per Second: 10,559.13192

Timestep Collection Time: 2.27846
Timestep Consumption Time: 2.45792
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.73637

Cumulative Model Updates: 117,612
Cumulative Timesteps: 980,962,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,329.05916
Policy Entropy: 3.12627
Value Function Loss: 0.00475

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11161
Policy Update Magnitude: 0.55896
Value Function Update Magnitude: 0.52535

Collected Steps per Second: 22,191.04317
Overall Steps per Second: 10,484.99331

Timestep Collection Time: 2.25379
Timestep Consumption Time: 2.51626
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.77006

Cumulative Model Updates: 117,618
Cumulative Timesteps: 981,012,164

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 981012164...
Checkpoint 981012164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,719.19184
Policy Entropy: 3.12333
Value Function Loss: 0.00488

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10282
Policy Update Magnitude: 0.56001
Value Function Update Magnitude: 0.50363

Collected Steps per Second: 22,146.41224
Overall Steps per Second: 10,624.50896

Timestep Collection Time: 2.25842
Timestep Consumption Time: 2.44918
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.70761

Cumulative Model Updates: 117,624
Cumulative Timesteps: 981,062,180

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,661.53324
Policy Entropy: 3.11077
Value Function Loss: 0.00474

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09454
Policy Update Magnitude: 0.55734
Value Function Update Magnitude: 0.49564

Collected Steps per Second: 22,050.19157
Overall Steps per Second: 10,451.20732

Timestep Collection Time: 2.26774
Timestep Consumption Time: 2.51678
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.78452

Cumulative Model Updates: 117,630
Cumulative Timesteps: 981,112,184

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 981112184...
Checkpoint 981112184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,645.33080
Policy Entropy: 3.10459
Value Function Loss: 0.00509

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08905
Policy Update Magnitude: 0.56026
Value Function Update Magnitude: 0.50863

Collected Steps per Second: 21,903.87919
Overall Steps per Second: 10,605.77684

Timestep Collection Time: 2.28288
Timestep Consumption Time: 2.43191
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.71479

Cumulative Model Updates: 117,636
Cumulative Timesteps: 981,162,188

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710.51606
Policy Entropy: 3.09620
Value Function Loss: 0.00503

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08872
Policy Update Magnitude: 0.56869
Value Function Update Magnitude: 0.52882

Collected Steps per Second: 21,833.37960
Overall Steps per Second: 10,497.80286

Timestep Collection Time: 2.29062
Timestep Consumption Time: 2.47342
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.76404

Cumulative Model Updates: 117,642
Cumulative Timesteps: 981,212,200

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 981212200...
Checkpoint 981212200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449.94227
Policy Entropy: 3.09750
Value Function Loss: 0.00497

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09340
Policy Update Magnitude: 0.57689
Value Function Update Magnitude: 0.54692

Collected Steps per Second: 21,653.99498
Overall Steps per Second: 10,595.59810

Timestep Collection Time: 2.30987
Timestep Consumption Time: 2.41077
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.72064

Cumulative Model Updates: 117,648
Cumulative Timesteps: 981,262,218

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.65250
Policy Entropy: 3.10404
Value Function Loss: 0.00498

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08970
Policy Update Magnitude: 0.57304
Value Function Update Magnitude: 0.54978

Collected Steps per Second: 21,473.29473
Overall Steps per Second: 10,486.45228

Timestep Collection Time: 2.32894
Timestep Consumption Time: 2.44007
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.76901

Cumulative Model Updates: 117,654
Cumulative Timesteps: 981,312,228

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 981312228...
Checkpoint 981312228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,585.63173
Policy Entropy: 3.10631
Value Function Loss: 0.00482

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09293
Policy Update Magnitude: 0.56721
Value Function Update Magnitude: 0.54031

Collected Steps per Second: 21,198.58852
Overall Steps per Second: 10,232.70433

Timestep Collection Time: 2.35987
Timestep Consumption Time: 2.52896
PPO Batch Consumption Time: 0.29652
Total Iteration Time: 4.88883

Cumulative Model Updates: 117,660
Cumulative Timesteps: 981,362,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.69846
Policy Entropy: 3.11032
Value Function Loss: 0.00514

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.56354
Value Function Update Magnitude: 0.54832

Collected Steps per Second: 21,267.78696
Overall Steps per Second: 10,498.60217

Timestep Collection Time: 2.35210
Timestep Consumption Time: 2.41272
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.76482

Cumulative Model Updates: 117,666
Cumulative Timesteps: 981,412,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 981412278...
Checkpoint 981412278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,796.64408
Policy Entropy: 3.08684
Value Function Loss: 0.00542

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10129
Policy Update Magnitude: 0.57392
Value Function Update Magnitude: 0.54358

Collected Steps per Second: 21,227.55283
Overall Steps per Second: 10,377.56495

Timestep Collection Time: 2.35760
Timestep Consumption Time: 2.46492
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.82252

Cumulative Model Updates: 117,672
Cumulative Timesteps: 981,462,324

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,868.31621
Policy Entropy: 3.07922
Value Function Loss: 0.00556

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.12594
Policy Update Magnitude: 0.58571
Value Function Update Magnitude: 0.53534

Collected Steps per Second: 21,896.55475
Overall Steps per Second: 10,458.63422

Timestep Collection Time: 2.28547
Timestep Consumption Time: 2.49947
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.78495

Cumulative Model Updates: 117,678
Cumulative Timesteps: 981,512,368

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 981512368...
Checkpoint 981512368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.62696
Policy Entropy: 3.08101
Value Function Loss: 0.00543

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.13119
Policy Update Magnitude: 0.58554
Value Function Update Magnitude: 0.53863

Collected Steps per Second: 21,978.78879
Overall Steps per Second: 10,422.05271

Timestep Collection Time: 2.27574
Timestep Consumption Time: 2.52351
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.79925

Cumulative Model Updates: 117,684
Cumulative Timesteps: 981,562,386

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.62043
Policy Entropy: 3.09786
Value Function Loss: 0.00503

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.13104
Policy Update Magnitude: 0.58003
Value Function Update Magnitude: 0.52853

Collected Steps per Second: 21,991.97403
Overall Steps per Second: 10,462.74893

Timestep Collection Time: 2.27419
Timestep Consumption Time: 2.50600
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.78020

Cumulative Model Updates: 117,690
Cumulative Timesteps: 981,612,400

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 981612400...
Checkpoint 981612400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,435.32281
Policy Entropy: 3.11439
Value Function Loss: 0.00509

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.58009
Value Function Update Magnitude: 0.53845

Collected Steps per Second: 20,580.43729
Overall Steps per Second: 10,008.43060

Timestep Collection Time: 2.43056
Timestep Consumption Time: 2.56743
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.99799

Cumulative Model Updates: 117,696
Cumulative Timesteps: 981,662,422

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.05033
Policy Entropy: 3.11052
Value Function Loss: 0.00512

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.10706
Policy Update Magnitude: 0.58527
Value Function Update Magnitude: 0.53229

Collected Steps per Second: 22,330.84175
Overall Steps per Second: 10,487.95290

Timestep Collection Time: 2.24040
Timestep Consumption Time: 2.52984
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.77023

Cumulative Model Updates: 117,702
Cumulative Timesteps: 981,712,452

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 981712452...
Checkpoint 981712452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,768.98813
Policy Entropy: 3.10614
Value Function Loss: 0.00498

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.10860
Policy Update Magnitude: 0.58022
Value Function Update Magnitude: 0.52675

Collected Steps per Second: 21,970.84384
Overall Steps per Second: 10,487.70206

Timestep Collection Time: 2.27583
Timestep Consumption Time: 2.49184
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.76768

Cumulative Model Updates: 117,708
Cumulative Timesteps: 981,762,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,530.92064
Policy Entropy: 3.08713
Value Function Loss: 0.00529

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.09923
Policy Update Magnitude: 0.57805
Value Function Update Magnitude: 0.52819

Collected Steps per Second: 22,060.27459
Overall Steps per Second: 10,465.55528

Timestep Collection Time: 2.26761
Timestep Consumption Time: 2.51227
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.77987

Cumulative Model Updates: 117,714
Cumulative Timesteps: 981,812,478

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 981812478...
Checkpoint 981812478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.74312
Policy Entropy: 3.07345
Value Function Loss: 0.00534

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.58212
Value Function Update Magnitude: 0.54047

Collected Steps per Second: 21,589.81535
Overall Steps per Second: 10,359.09650

Timestep Collection Time: 2.31720
Timestep Consumption Time: 2.51217
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.82938

Cumulative Model Updates: 117,720
Cumulative Timesteps: 981,862,506

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.15660
Policy Entropy: 3.07361
Value Function Loss: 0.00529

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.10671
Policy Update Magnitude: 0.57726
Value Function Update Magnitude: 0.56999

Collected Steps per Second: 22,122.27007
Overall Steps per Second: 10,468.72269

Timestep Collection Time: 2.26044
Timestep Consumption Time: 2.51627
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.77670

Cumulative Model Updates: 117,726
Cumulative Timesteps: 981,912,512

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 981912512...
Checkpoint 981912512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348.72536
Policy Entropy: 3.09232
Value Function Loss: 0.00476

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09587
Policy Update Magnitude: 0.56516
Value Function Update Magnitude: 0.56768

Collected Steps per Second: 21,948.91630
Overall Steps per Second: 10,466.05679

Timestep Collection Time: 2.27847
Timestep Consumption Time: 2.49983
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.77830

Cumulative Model Updates: 117,732
Cumulative Timesteps: 981,962,522

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,700.92262
Policy Entropy: 3.10668
Value Function Loss: 0.00473

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09570
Policy Update Magnitude: 0.55729
Value Function Update Magnitude: 0.56652

Collected Steps per Second: 21,499.63547
Overall Steps per Second: 10,433.16953

Timestep Collection Time: 2.32590
Timestep Consumption Time: 2.46708
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.79298

Cumulative Model Updates: 117,738
Cumulative Timesteps: 982,012,528

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 982012528...
Checkpoint 982012528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,246.63066
Policy Entropy: 3.09119
Value Function Loss: 0.00466

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10021
Policy Update Magnitude: 0.55750
Value Function Update Magnitude: 0.56890

Collected Steps per Second: 21,364.46290
Overall Steps per Second: 10,292.01562

Timestep Collection Time: 2.34043
Timestep Consumption Time: 2.51790
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.85833

Cumulative Model Updates: 117,744
Cumulative Timesteps: 982,062,530

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.38617
Policy Entropy: 3.08270
Value Function Loss: 0.00468

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.55934
Value Function Update Magnitude: 0.55303

Collected Steps per Second: 21,849.26584
Overall Steps per Second: 10,381.27697

Timestep Collection Time: 2.28914
Timestep Consumption Time: 2.52877
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.81790

Cumulative Model Updates: 117,750
Cumulative Timesteps: 982,112,546

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 982112546...
Checkpoint 982112546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,470.46846
Policy Entropy: 3.07192
Value Function Loss: 0.00487

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.56329
Value Function Update Magnitude: 0.54217

Collected Steps per Second: 21,515.28699
Overall Steps per Second: 10,307.57435

Timestep Collection Time: 2.32486
Timestep Consumption Time: 2.52788
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.85274

Cumulative Model Updates: 117,756
Cumulative Timesteps: 982,162,566

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.86378
Policy Entropy: 3.09201
Value Function Loss: 0.00487

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08600
Policy Update Magnitude: 0.56257
Value Function Update Magnitude: 0.52973

Collected Steps per Second: 22,405.18255
Overall Steps per Second: 10,425.16790

Timestep Collection Time: 2.23198
Timestep Consumption Time: 2.56487
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.79685

Cumulative Model Updates: 117,762
Cumulative Timesteps: 982,212,574

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 982212574...
Checkpoint 982212574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402.46674
Policy Entropy: 3.08577
Value Function Loss: 0.00540

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09459
Policy Update Magnitude: 0.57503
Value Function Update Magnitude: 0.53260

Collected Steps per Second: 22,036.46369
Overall Steps per Second: 10,556.21932

Timestep Collection Time: 2.27006
Timestep Consumption Time: 2.46876
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.73882

Cumulative Model Updates: 117,768
Cumulative Timesteps: 982,262,598

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,505.30517
Policy Entropy: 3.09932
Value Function Loss: 0.00519

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09820
Policy Update Magnitude: 0.57897
Value Function Update Magnitude: 0.53952

Collected Steps per Second: 21,943.48264
Overall Steps per Second: 10,357.12731

Timestep Collection Time: 2.27967
Timestep Consumption Time: 2.55024
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.82991

Cumulative Model Updates: 117,774
Cumulative Timesteps: 982,312,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 982312622...
Checkpoint 982312622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,197.55482
Policy Entropy: 3.10110
Value Function Loss: 0.00522

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.57183
Value Function Update Magnitude: 0.52878

Collected Steps per Second: 21,615.83930
Overall Steps per Second: 10,397.92128

Timestep Collection Time: 2.31423
Timestep Consumption Time: 2.49673
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.81096

Cumulative Model Updates: 117,780
Cumulative Timesteps: 982,362,646

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.22138
Policy Entropy: 3.09861
Value Function Loss: 0.00482

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09327
Policy Update Magnitude: 0.56459
Value Function Update Magnitude: 0.51996

Collected Steps per Second: 22,303.88323
Overall Steps per Second: 10,504.90673

Timestep Collection Time: 2.24266
Timestep Consumption Time: 2.51893
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.76158

Cumulative Model Updates: 117,786
Cumulative Timesteps: 982,412,666

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 982412666...
Checkpoint 982412666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,705.54852
Policy Entropy: 3.07089
Value Function Loss: 0.00512

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.56521
Value Function Update Magnitude: 0.51167

Collected Steps per Second: 21,929.29080
Overall Steps per Second: 10,538.91644

Timestep Collection Time: 2.28024
Timestep Consumption Time: 2.46446
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.74470

Cumulative Model Updates: 117,792
Cumulative Timesteps: 982,462,670

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,765.38863
Policy Entropy: 3.06819
Value Function Loss: 0.00501

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.57251
Value Function Update Magnitude: 0.52769

Collected Steps per Second: 22,399.80722
Overall Steps per Second: 10,572.28379

Timestep Collection Time: 2.23261
Timestep Consumption Time: 2.49768
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.73029

Cumulative Model Updates: 117,798
Cumulative Timesteps: 982,512,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 982512680...
Checkpoint 982512680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.50039
Policy Entropy: 3.07597
Value Function Loss: 0.00509

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09749
Policy Update Magnitude: 0.57926
Value Function Update Magnitude: 0.54066

Collected Steps per Second: 21,608.23755
Overall Steps per Second: 10,474.77867

Timestep Collection Time: 2.31514
Timestep Consumption Time: 2.46072
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.77585

Cumulative Model Updates: 117,804
Cumulative Timesteps: 982,562,706

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.52322
Policy Entropy: 3.09341
Value Function Loss: 0.00477

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09340
Policy Update Magnitude: 0.57471
Value Function Update Magnitude: 0.53505

Collected Steps per Second: 21,555.42186
Overall Steps per Second: 10,450.40969

Timestep Collection Time: 2.31969
Timestep Consumption Time: 2.46500
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.78469

Cumulative Model Updates: 117,810
Cumulative Timesteps: 982,612,708

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 982612708...
Checkpoint 982612708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,145.46472
Policy Entropy: 3.09812
Value Function Loss: 0.00500

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10334
Policy Update Magnitude: 0.57391
Value Function Update Magnitude: 0.53823

Collected Steps per Second: 20,773.22227
Overall Steps per Second: 10,182.47823

Timestep Collection Time: 2.40839
Timestep Consumption Time: 2.50495
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.91334

Cumulative Model Updates: 117,816
Cumulative Timesteps: 982,662,738

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564.52574
Policy Entropy: 3.10888
Value Function Loss: 0.00507

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10657
Policy Update Magnitude: 0.57469
Value Function Update Magnitude: 0.53999

Collected Steps per Second: 21,542.92151
Overall Steps per Second: 10,509.11705

Timestep Collection Time: 2.32151
Timestep Consumption Time: 2.43741
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.75892

Cumulative Model Updates: 117,822
Cumulative Timesteps: 982,712,750

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 982712750...
Checkpoint 982712750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 929.21193
Policy Entropy: 3.09307
Value Function Loss: 0.00528

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10437
Policy Update Magnitude: 0.58083
Value Function Update Magnitude: 0.55323

Collected Steps per Second: 21,462.41735
Overall Steps per Second: 10,271.77050

Timestep Collection Time: 2.32965
Timestep Consumption Time: 2.53806
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.86771

Cumulative Model Updates: 117,828
Cumulative Timesteps: 982,762,750

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,705.55101
Policy Entropy: 3.08989
Value Function Loss: 0.00502

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.10755
Policy Update Magnitude: 0.57855
Value Function Update Magnitude: 0.55429

Collected Steps per Second: 22,286.88545
Overall Steps per Second: 10,422.46389

Timestep Collection Time: 2.24383
Timestep Consumption Time: 2.55427
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.79810

Cumulative Model Updates: 117,834
Cumulative Timesteps: 982,812,758

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 982812758...
Checkpoint 982812758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.46666
Policy Entropy: 3.08169
Value Function Loss: 0.00500

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.10525
Policy Update Magnitude: 0.58102
Value Function Update Magnitude: 0.54642

Collected Steps per Second: 21,649.05602
Overall Steps per Second: 10,267.79264

Timestep Collection Time: 2.31077
Timestep Consumption Time: 2.56136
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.87213

Cumulative Model Updates: 117,840
Cumulative Timesteps: 982,862,784

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,689.60213
Policy Entropy: 3.09538
Value Function Loss: 0.00476

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09723
Policy Update Magnitude: 0.57973
Value Function Update Magnitude: 0.53317

Collected Steps per Second: 22,716.12137
Overall Steps per Second: 10,767.90576

Timestep Collection Time: 2.20214
Timestep Consumption Time: 2.44352
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.64566

Cumulative Model Updates: 117,846
Cumulative Timesteps: 982,912,808

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 982912808...
Checkpoint 982912808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.20393
Policy Entropy: 3.10233
Value Function Loss: 0.00461

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09688
Policy Update Magnitude: 0.57220
Value Function Update Magnitude: 0.52277

Collected Steps per Second: 21,849.86496
Overall Steps per Second: 10,417.01138

Timestep Collection Time: 2.28926
Timestep Consumption Time: 2.51250
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.80176

Cumulative Model Updates: 117,852
Cumulative Timesteps: 982,962,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,578.20985
Policy Entropy: 3.10584
Value Function Loss: 0.00458

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.09828
Policy Update Magnitude: 0.56589
Value Function Update Magnitude: 0.51275

Collected Steps per Second: 22,313.75723
Overall Steps per Second: 10,657.20049

Timestep Collection Time: 2.24194
Timestep Consumption Time: 2.45217
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.69410

Cumulative Model Updates: 117,858
Cumulative Timesteps: 983,012,854

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 983012854...
Checkpoint 983012854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.25710
Policy Entropy: 3.10171
Value Function Loss: 0.00476

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10298
Policy Update Magnitude: 0.56375
Value Function Update Magnitude: 0.51388

Collected Steps per Second: 21,802.91148
Overall Steps per Second: 10,465.38565

Timestep Collection Time: 2.29474
Timestep Consumption Time: 2.48597
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.78071

Cumulative Model Updates: 117,864
Cumulative Timesteps: 983,062,886

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.03876
Policy Entropy: 3.10821
Value Function Loss: 0.00483

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10680
Policy Update Magnitude: 0.56498
Value Function Update Magnitude: 0.51738

Collected Steps per Second: 22,527.62228
Overall Steps per Second: 10,684.76133

Timestep Collection Time: 2.22056
Timestep Consumption Time: 2.46125
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.68181

Cumulative Model Updates: 117,870
Cumulative Timesteps: 983,112,910

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 983112910...
Checkpoint 983112910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,365.17606
Policy Entropy: 3.11631
Value Function Loss: 0.00493

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10700
Policy Update Magnitude: 0.56121
Value Function Update Magnitude: 0.51139

Collected Steps per Second: 21,621.91333
Overall Steps per Second: 10,340.58305

Timestep Collection Time: 2.31256
Timestep Consumption Time: 2.52295
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.83551

Cumulative Model Updates: 117,876
Cumulative Timesteps: 983,162,912

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,635.25330
Policy Entropy: 3.11608
Value Function Loss: 0.00521

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10064
Policy Update Magnitude: 0.56010
Value Function Update Magnitude: 0.52707

Collected Steps per Second: 21,411.27955
Overall Steps per Second: 10,437.00002

Timestep Collection Time: 2.33578
Timestep Consumption Time: 2.45602
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.79180

Cumulative Model Updates: 117,882
Cumulative Timesteps: 983,212,924

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 983212924...
Checkpoint 983212924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,488.92964
Policy Entropy: 3.12515
Value Function Loss: 0.00515

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09381
Policy Update Magnitude: 0.55901
Value Function Update Magnitude: 0.55200

Collected Steps per Second: 21,687.93237
Overall Steps per Second: 10,577.29023

Timestep Collection Time: 2.30681
Timestep Consumption Time: 2.42313
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.72994

Cumulative Model Updates: 117,888
Cumulative Timesteps: 983,262,954

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617.17924
Policy Entropy: 3.11717
Value Function Loss: 0.00514

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09461
Policy Update Magnitude: 0.56399
Value Function Update Magnitude: 0.55215

Collected Steps per Second: 21,529.15737
Overall Steps per Second: 10,407.63140

Timestep Collection Time: 2.32290
Timestep Consumption Time: 2.48223
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.80513

Cumulative Model Updates: 117,894
Cumulative Timesteps: 983,312,964

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 983312964...
Checkpoint 983312964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,905.20659
Policy Entropy: 3.12166
Value Function Loss: 0.00485

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10559
Policy Update Magnitude: 0.56155
Value Function Update Magnitude: 0.54443

Collected Steps per Second: 21,297.13947
Overall Steps per Second: 10,246.57966

Timestep Collection Time: 2.34839
Timestep Consumption Time: 2.53265
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.88104

Cumulative Model Updates: 117,900
Cumulative Timesteps: 983,362,978

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,711.38057
Policy Entropy: 3.11730
Value Function Loss: 0.00463

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11025
Policy Update Magnitude: 0.54933
Value Function Update Magnitude: 0.53554

Collected Steps per Second: 22,360.82603
Overall Steps per Second: 10,435.95990

Timestep Collection Time: 2.23722
Timestep Consumption Time: 2.55640
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.79362

Cumulative Model Updates: 117,906
Cumulative Timesteps: 983,413,004

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 983413004...
Checkpoint 983413004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.13595
Policy Entropy: 3.11681
Value Function Loss: 0.00485

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.55656
Value Function Update Magnitude: 0.51706

Collected Steps per Second: 21,821.69283
Overall Steps per Second: 10,378.57385

Timestep Collection Time: 2.29139
Timestep Consumption Time: 2.52642
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.81781

Cumulative Model Updates: 117,912
Cumulative Timesteps: 983,463,006

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.40718
Policy Entropy: 3.12843
Value Function Loss: 0.00479

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09041
Policy Update Magnitude: 0.56266
Value Function Update Magnitude: 0.52597

Collected Steps per Second: 22,065.05821
Overall Steps per Second: 10,324.87082

Timestep Collection Time: 2.26603
Timestep Consumption Time: 2.57665
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.84268

Cumulative Model Updates: 117,918
Cumulative Timesteps: 983,513,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 983513006...
Checkpoint 983513006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.69311
Policy Entropy: 3.13422
Value Function Loss: 0.00496

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.55749
Value Function Update Magnitude: 0.53477

Collected Steps per Second: 21,962.30070
Overall Steps per Second: 10,668.51635

Timestep Collection Time: 2.27745
Timestep Consumption Time: 2.41093
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.68837

Cumulative Model Updates: 117,924
Cumulative Timesteps: 983,563,024

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,975.29635
Policy Entropy: 3.14404
Value Function Loss: 0.00465

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.55239
Value Function Update Magnitude: 0.53306

Collected Steps per Second: 21,069.79211
Overall Steps per Second: 10,318.78087

Timestep Collection Time: 2.37326
Timestep Consumption Time: 2.47267
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.84592

Cumulative Model Updates: 117,930
Cumulative Timesteps: 983,613,028

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 983613028...
Checkpoint 983613028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,680.35629
Policy Entropy: 3.12098
Value Function Loss: 0.00448

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10424
Policy Update Magnitude: 0.54407
Value Function Update Magnitude: 0.52519

Collected Steps per Second: 21,952.54764
Overall Steps per Second: 10,398.55363

Timestep Collection Time: 2.27810
Timestep Consumption Time: 2.53123
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.80932

Cumulative Model Updates: 117,936
Cumulative Timesteps: 983,663,038

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,443.15635
Policy Entropy: 3.11618
Value Function Loss: 0.00475

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.09905
Policy Update Magnitude: 0.54506
Value Function Update Magnitude: 0.52387

Collected Steps per Second: 22,250.89522
Overall Steps per Second: 10,464.78900

Timestep Collection Time: 2.24710
Timestep Consumption Time: 2.53083
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.77793

Cumulative Model Updates: 117,942
Cumulative Timesteps: 983,713,038

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 983713038...
Checkpoint 983713038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667.64524
Policy Entropy: 3.10990
Value Function Loss: 0.00488

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.10597
Policy Update Magnitude: 0.55607
Value Function Update Magnitude: 0.52217

Collected Steps per Second: 21,917.31363
Overall Steps per Second: 10,581.60428

Timestep Collection Time: 2.28221
Timestep Consumption Time: 2.44486
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.72707

Cumulative Model Updates: 117,948
Cumulative Timesteps: 983,763,058

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.61008
Policy Entropy: 3.11142
Value Function Loss: 0.00489

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10260
Policy Update Magnitude: 0.55965
Value Function Update Magnitude: 0.51175

Collected Steps per Second: 21,701.27608
Overall Steps per Second: 10,405.95457

Timestep Collection Time: 2.30466
Timestep Consumption Time: 2.50163
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.80629

Cumulative Model Updates: 117,954
Cumulative Timesteps: 983,813,072

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 983813072...
Checkpoint 983813072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457.77516
Policy Entropy: 3.12823
Value Function Loss: 0.00471

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10428
Policy Update Magnitude: 0.55524
Value Function Update Magnitude: 0.49829

Collected Steps per Second: 21,659.80633
Overall Steps per Second: 10,399.36546

Timestep Collection Time: 2.30861
Timestep Consumption Time: 2.49976
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.80837

Cumulative Model Updates: 117,960
Cumulative Timesteps: 983,863,076

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525.82400
Policy Entropy: 3.12813
Value Function Loss: 0.00472

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10065
Policy Update Magnitude: 0.55534
Value Function Update Magnitude: 0.50746

Collected Steps per Second: 21,874.28715
Overall Steps per Second: 10,480.92454

Timestep Collection Time: 2.28615
Timestep Consumption Time: 2.48518
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.77133

Cumulative Model Updates: 117,966
Cumulative Timesteps: 983,913,084

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 983913084...
Checkpoint 983913084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,375.82154
Policy Entropy: 3.13383
Value Function Loss: 0.00438

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.09904
Policy Update Magnitude: 0.55521
Value Function Update Magnitude: 0.52623

Collected Steps per Second: 21,353.60689
Overall Steps per Second: 10,324.36231

Timestep Collection Time: 2.34199
Timestep Consumption Time: 2.50189
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.84388

Cumulative Model Updates: 117,972
Cumulative Timesteps: 983,963,094

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 772.80219
Policy Entropy: 3.12191
Value Function Loss: 0.00444

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.10349
Policy Update Magnitude: 0.55000
Value Function Update Magnitude: 0.52470

Collected Steps per Second: 21,695.62265
Overall Steps per Second: 10,495.92027

Timestep Collection Time: 2.30553
Timestep Consumption Time: 2.46013
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.76566

Cumulative Model Updates: 117,978
Cumulative Timesteps: 984,013,114

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 984013114...
Checkpoint 984013114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 983.04491
Policy Entropy: 3.12129
Value Function Loss: 0.00449

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.09938
Policy Update Magnitude: 0.55225
Value Function Update Magnitude: 0.52816

Collected Steps per Second: 22,018.32277
Overall Steps per Second: 10,360.32320

Timestep Collection Time: 2.27111
Timestep Consumption Time: 2.55557
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.82668

Cumulative Model Updates: 117,984
Cumulative Timesteps: 984,063,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,922.31096
Policy Entropy: 3.11252
Value Function Loss: 0.00465

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.55841
Value Function Update Magnitude: 0.54282

Collected Steps per Second: 22,110.76890
Overall Steps per Second: 10,499.96350

Timestep Collection Time: 2.26179
Timestep Consumption Time: 2.50108
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.76287

Cumulative Model Updates: 117,990
Cumulative Timesteps: 984,113,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 984113130...
Checkpoint 984113130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 978.56355
Policy Entropy: 3.11033
Value Function Loss: 0.00478

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10152
Policy Update Magnitude: 0.56381
Value Function Update Magnitude: 0.54621

Collected Steps per Second: 22,184.80644
Overall Steps per Second: 10,479.88437

Timestep Collection Time: 2.25443
Timestep Consumption Time: 2.51796
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.77238

Cumulative Model Updates: 117,996
Cumulative Timesteps: 984,163,144

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,759.51109
Policy Entropy: 3.10591
Value Function Loss: 0.00477

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10131
Policy Update Magnitude: 0.56165
Value Function Update Magnitude: 0.52401

Collected Steps per Second: 22,249.39092
Overall Steps per Second: 10,472.47163

Timestep Collection Time: 2.24842
Timestep Consumption Time: 2.52848
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.77690

Cumulative Model Updates: 118,002
Cumulative Timesteps: 984,213,170

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 984213170...
Checkpoint 984213170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,105.07581
Policy Entropy: 3.10960
Value Function Loss: 0.00491

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.10417
Policy Update Magnitude: 0.55385
Value Function Update Magnitude: 0.50352

Collected Steps per Second: 21,854.61109
Overall Steps per Second: 10,561.73580

Timestep Collection Time: 2.28913
Timestep Consumption Time: 2.44759
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.73672

Cumulative Model Updates: 118,008
Cumulative Timesteps: 984,263,198

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.14974
Policy Entropy: 3.11169
Value Function Loss: 0.00458

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.10923
Policy Update Magnitude: 0.54484
Value Function Update Magnitude: 0.49775

Collected Steps per Second: 22,114.10020
Overall Steps per Second: 10,549.88548

Timestep Collection Time: 2.26263
Timestep Consumption Time: 2.48017
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.74280

Cumulative Model Updates: 118,014
Cumulative Timesteps: 984,313,234

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 984313234...
Checkpoint 984313234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.94012
Policy Entropy: 3.12283
Value Function Loss: 0.00443

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10658
Policy Update Magnitude: 0.53398
Value Function Update Magnitude: 0.49194

Collected Steps per Second: 21,871.51915
Overall Steps per Second: 10,562.97898

Timestep Collection Time: 2.28617
Timestep Consumption Time: 2.44753
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.73370

Cumulative Model Updates: 118,020
Cumulative Timesteps: 984,363,236

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,744.90119
Policy Entropy: 3.13530
Value Function Loss: 0.00446

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09825
Policy Update Magnitude: 0.53826
Value Function Update Magnitude: 0.49607

Collected Steps per Second: 22,164.78718
Overall Steps per Second: 10,601.09808

Timestep Collection Time: 2.25592
Timestep Consumption Time: 2.46076
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.71668

Cumulative Model Updates: 118,026
Cumulative Timesteps: 984,413,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 984413238...
Checkpoint 984413238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 978.27068
Policy Entropy: 3.12547
Value Function Loss: 0.00484

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10608
Policy Update Magnitude: 0.55057
Value Function Update Magnitude: 0.51448

Collected Steps per Second: 21,565.04478
Overall Steps per Second: 10,519.59339

Timestep Collection Time: 2.31977
Timestep Consumption Time: 2.43573
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.75551

Cumulative Model Updates: 118,032
Cumulative Timesteps: 984,463,264

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.54564
Policy Entropy: 3.12146
Value Function Loss: 0.00483

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10611
Policy Update Magnitude: 0.55887
Value Function Update Magnitude: 0.55057

Collected Steps per Second: 21,737.35291
Overall Steps per Second: 10,437.84185

Timestep Collection Time: 2.30046
Timestep Consumption Time: 2.49037
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.79084

Cumulative Model Updates: 118,038
Cumulative Timesteps: 984,513,270

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 984513270...
Checkpoint 984513270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.62681
Policy Entropy: 3.11649
Value Function Loss: 0.00480

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.55701
Value Function Update Magnitude: 0.52960

Collected Steps per Second: 21,419.61661
Overall Steps per Second: 10,357.67742

Timestep Collection Time: 2.33506
Timestep Consumption Time: 2.49383
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.82888

Cumulative Model Updates: 118,044
Cumulative Timesteps: 984,563,286

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.56271
Policy Entropy: 3.10913
Value Function Loss: 0.00474

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09668
Policy Update Magnitude: 0.56247
Value Function Update Magnitude: 0.51740

Collected Steps per Second: 20,962.31264
Overall Steps per Second: 10,297.63331

Timestep Collection Time: 2.38619
Timestep Consumption Time: 2.47124
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.85743

Cumulative Model Updates: 118,050
Cumulative Timesteps: 984,613,306

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 984613306...
Checkpoint 984613306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220.87165
Policy Entropy: 3.10085
Value Function Loss: 0.00479

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.57437
Value Function Update Magnitude: 0.52060

Collected Steps per Second: 21,408.19612
Overall Steps per Second: 10,359.46782

Timestep Collection Time: 2.33686
Timestep Consumption Time: 2.49234
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.82921

Cumulative Model Updates: 118,056
Cumulative Timesteps: 984,663,334

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,659.62080
Policy Entropy: 3.10374
Value Function Loss: 0.00489

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.56915
Value Function Update Magnitude: 0.53375

Collected Steps per Second: 22,211.43110
Overall Steps per Second: 10,463.82747

Timestep Collection Time: 2.25226
Timestep Consumption Time: 2.52859
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.78085

Cumulative Model Updates: 118,062
Cumulative Timesteps: 984,713,360

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 984713360...
Checkpoint 984713360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.75273
Policy Entropy: 3.11207
Value Function Loss: 0.00487

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.56300
Value Function Update Magnitude: 0.53523

Collected Steps per Second: 21,432.72751
Overall Steps per Second: 10,327.82308

Timestep Collection Time: 2.33307
Timestep Consumption Time: 2.50861
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.84168

Cumulative Model Updates: 118,068
Cumulative Timesteps: 984,763,364

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 787.68340
Policy Entropy: 3.12517
Value Function Loss: 0.00507

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10403
Policy Update Magnitude: 0.57145
Value Function Update Magnitude: 0.53258

Collected Steps per Second: 22,402.35265
Overall Steps per Second: 10,699.29242

Timestep Collection Time: 2.23244
Timestep Consumption Time: 2.44188
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.67433

Cumulative Model Updates: 118,074
Cumulative Timesteps: 984,813,376

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 984813376...
Checkpoint 984813376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469.44281
Policy Entropy: 3.12636
Value Function Loss: 0.00490

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.56536
Value Function Update Magnitude: 0.54118

Collected Steps per Second: 21,868.15540
Overall Steps per Second: 10,620.77314

Timestep Collection Time: 2.28643
Timestep Consumption Time: 2.42133
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.70776

Cumulative Model Updates: 118,080
Cumulative Timesteps: 984,863,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,905.80693
Policy Entropy: 3.12872
Value Function Loss: 0.00467

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.10839
Policy Update Magnitude: 0.55549
Value Function Update Magnitude: 0.53440

Collected Steps per Second: 22,195.75672
Overall Steps per Second: 10,464.89928

Timestep Collection Time: 2.25358
Timestep Consumption Time: 2.52620
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.77979

Cumulative Model Updates: 118,086
Cumulative Timesteps: 984,913,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 984913396...
Checkpoint 984913396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.00565
Policy Entropy: 3.12999
Value Function Loss: 0.00467

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.55689
Value Function Update Magnitude: 0.53561

Collected Steps per Second: 21,783.25854
Overall Steps per Second: 10,580.05679

Timestep Collection Time: 2.29598
Timestep Consumption Time: 2.43121
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.72720

Cumulative Model Updates: 118,092
Cumulative Timesteps: 984,963,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.21962
Policy Entropy: 3.13293
Value Function Loss: 0.00458

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10098
Policy Update Magnitude: 0.55723
Value Function Update Magnitude: 0.53426

Collected Steps per Second: 22,194.72371
Overall Steps per Second: 10,519.07123

Timestep Collection Time: 2.25378
Timestep Consumption Time: 2.50158
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.75536

Cumulative Model Updates: 118,098
Cumulative Timesteps: 985,013,432

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 985013432...
Checkpoint 985013432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,470.14443
Policy Entropy: 3.12857
Value Function Loss: 0.00480

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09612
Policy Update Magnitude: 0.55622
Value Function Update Magnitude: 0.52209

Collected Steps per Second: 21,486.84001
Overall Steps per Second: 10,269.85758

Timestep Collection Time: 2.32766
Timestep Consumption Time: 2.54232
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.86998

Cumulative Model Updates: 118,104
Cumulative Timesteps: 985,063,446

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,126.48222
Policy Entropy: 3.12704
Value Function Loss: 0.00479

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.56143
Value Function Update Magnitude: 0.52182

Collected Steps per Second: 21,696.29800
Overall Steps per Second: 10,384.97731

Timestep Collection Time: 2.30463
Timestep Consumption Time: 2.51021
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.81484

Cumulative Model Updates: 118,110
Cumulative Timesteps: 985,113,448

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 985113448...
Checkpoint 985113448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 842.91704
Policy Entropy: 3.12061
Value Function Loss: 0.00480

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09374
Policy Update Magnitude: 0.56460
Value Function Update Magnitude: 0.53393

Collected Steps per Second: 21,262.21977
Overall Steps per Second: 10,276.04330

Timestep Collection Time: 2.35159
Timestep Consumption Time: 2.51410
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.86569

Cumulative Model Updates: 118,116
Cumulative Timesteps: 985,163,448

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.71848
Policy Entropy: 3.11866
Value Function Loss: 0.00506

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09439
Policy Update Magnitude: 0.57499
Value Function Update Magnitude: 0.55045

Collected Steps per Second: 21,913.92895
Overall Steps per Second: 10,459.53685

Timestep Collection Time: 2.28175
Timestep Consumption Time: 2.49877
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.78052

Cumulative Model Updates: 118,122
Cumulative Timesteps: 985,213,450

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 985213450...
Checkpoint 985213450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,809.37298
Policy Entropy: 3.11257
Value Function Loss: 0.00496

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09464
Policy Update Magnitude: 0.58349
Value Function Update Magnitude: 0.56023

Collected Steps per Second: 21,068.97970
Overall Steps per Second: 10,195.36580

Timestep Collection Time: 2.37439
Timestep Consumption Time: 2.53235
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.90674

Cumulative Model Updates: 118,128
Cumulative Timesteps: 985,263,476

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,803.51831
Policy Entropy: 3.11205
Value Function Loss: 0.00489

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09391
Policy Update Magnitude: 0.57720
Value Function Update Magnitude: 0.56939

Collected Steps per Second: 21,954.32186
Overall Steps per Second: 10,478.77491

Timestep Collection Time: 2.27782
Timestep Consumption Time: 2.49449
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.77231

Cumulative Model Updates: 118,134
Cumulative Timesteps: 985,313,484

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 985313484...
Checkpoint 985313484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.80814
Policy Entropy: 3.11485
Value Function Loss: 0.00473

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09604
Policy Update Magnitude: 0.57446
Value Function Update Magnitude: 0.56295

Collected Steps per Second: 21,982.57804
Overall Steps per Second: 10,423.50609

Timestep Collection Time: 2.27544
Timestep Consumption Time: 2.52333
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.79877

Cumulative Model Updates: 118,140
Cumulative Timesteps: 985,363,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 810.17821
Policy Entropy: 3.10666
Value Function Loss: 0.00478

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09577
Policy Update Magnitude: 0.57307
Value Function Update Magnitude: 0.55543

Collected Steps per Second: 21,273.79156
Overall Steps per Second: 10,328.04866

Timestep Collection Time: 2.35059
Timestep Consumption Time: 2.49117
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.84177

Cumulative Model Updates: 118,146
Cumulative Timesteps: 985,413,510

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 985413510...
Checkpoint 985413510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,616.62062
Policy Entropy: 3.10955
Value Function Loss: 0.00496

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.09998
Policy Update Magnitude: 0.57340
Value Function Update Magnitude: 0.56128

Collected Steps per Second: 21,378.03077
Overall Steps per Second: 10,389.28799

Timestep Collection Time: 2.33979
Timestep Consumption Time: 2.47479
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.81457

Cumulative Model Updates: 118,152
Cumulative Timesteps: 985,463,530

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754.79601
Policy Entropy: 3.09571
Value Function Loss: 0.00506

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09559
Policy Update Magnitude: 0.58255
Value Function Update Magnitude: 0.58519

Collected Steps per Second: 21,530.26079
Overall Steps per Second: 10,264.34231

Timestep Collection Time: 2.32343
Timestep Consumption Time: 2.55014
PPO Batch Consumption Time: 0.29547
Total Iteration Time: 4.87357

Cumulative Model Updates: 118,158
Cumulative Timesteps: 985,513,554

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 985513554...
Checkpoint 985513554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.89770
Policy Entropy: 3.09024
Value Function Loss: 0.00503

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09838
Policy Update Magnitude: 0.58700
Value Function Update Magnitude: 0.59387

Collected Steps per Second: 21,724.10954
Overall Steps per Second: 10,371.56245

Timestep Collection Time: 2.30288
Timestep Consumption Time: 2.52069
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.82357

Cumulative Model Updates: 118,164
Cumulative Timesteps: 985,563,582

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 926.26721
Policy Entropy: 3.06126
Value Function Loss: 0.00518

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09085
Policy Update Magnitude: 0.58981
Value Function Update Magnitude: 0.59951

Collected Steps per Second: 22,288.15158
Overall Steps per Second: 10,669.49537

Timestep Collection Time: 2.24361
Timestep Consumption Time: 2.44321
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.68682

Cumulative Model Updates: 118,170
Cumulative Timesteps: 985,613,588

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 985613588...
Checkpoint 985613588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,306.40484
Policy Entropy: 3.05677
Value Function Loss: 0.00495

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10487
Policy Update Magnitude: 0.58868
Value Function Update Magnitude: 0.57971

Collected Steps per Second: 22,034.77381
Overall Steps per Second: 10,464.56413

Timestep Collection Time: 2.26969
Timestep Consumption Time: 2.50949
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.77918

Cumulative Model Updates: 118,176
Cumulative Timesteps: 985,663,600

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,401.04394
Policy Entropy: 3.06399
Value Function Loss: 0.00482

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09345
Policy Update Magnitude: 0.57993
Value Function Update Magnitude: 0.55317

Collected Steps per Second: 21,657.96851
Overall Steps per Second: 10,323.41199

Timestep Collection Time: 2.30880
Timestep Consumption Time: 2.53494
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.84375

Cumulative Model Updates: 118,182
Cumulative Timesteps: 985,713,604

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 985713604...
Checkpoint 985713604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529.73142
Policy Entropy: 3.07541
Value Function Loss: 0.00484

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09655
Policy Update Magnitude: 0.57536
Value Function Update Magnitude: 0.51807

Collected Steps per Second: 21,941.51532
Overall Steps per Second: 10,557.80205

Timestep Collection Time: 2.27988
Timestep Consumption Time: 2.45823
PPO Batch Consumption Time: 0.28156
Total Iteration Time: 4.73811

Cumulative Model Updates: 118,188
Cumulative Timesteps: 985,763,628

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.16324
Policy Entropy: 3.09535
Value Function Loss: 0.00488

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08753
Policy Update Magnitude: 0.56883
Value Function Update Magnitude: 0.51346

Collected Steps per Second: 22,209.45745
Overall Steps per Second: 10,488.72274

Timestep Collection Time: 2.25255
Timestep Consumption Time: 2.51714
PPO Batch Consumption Time: 0.29508
Total Iteration Time: 4.76969

Cumulative Model Updates: 118,194
Cumulative Timesteps: 985,813,656

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 985813656...
Checkpoint 985813656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,508.52662
Policy Entropy: 3.09661
Value Function Loss: 0.00484

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10053
Policy Update Magnitude: 0.56478
Value Function Update Magnitude: 0.50298

Collected Steps per Second: 21,931.82809
Overall Steps per Second: 10,624.14449

Timestep Collection Time: 2.28107
Timestep Consumption Time: 2.42783
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.70890

Cumulative Model Updates: 118,200
Cumulative Timesteps: 985,863,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,749.60484
Policy Entropy: 3.08729
Value Function Loss: 0.00480

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09714
Policy Update Magnitude: 0.57307
Value Function Update Magnitude: 0.50402

Collected Steps per Second: 21,913.43950
Overall Steps per Second: 10,398.97666

Timestep Collection Time: 2.28198
Timestep Consumption Time: 2.52676
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.80874

Cumulative Model Updates: 118,206
Cumulative Timesteps: 985,913,690

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 985913690...
Checkpoint 985913690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,765.01267
Policy Entropy: 3.05607
Value Function Loss: 0.00454

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08613
Policy Update Magnitude: 0.57799
Value Function Update Magnitude: 0.49129

Collected Steps per Second: 21,103.30008
Overall Steps per Second: 10,267.87773

Timestep Collection Time: 2.36958
Timestep Consumption Time: 2.50056
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.87014

Cumulative Model Updates: 118,212
Cumulative Timesteps: 985,963,696

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656.04175
Policy Entropy: 3.05721
Value Function Loss: 0.00493

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10266
Policy Update Magnitude: 0.58048
Value Function Update Magnitude: 0.48615

Collected Steps per Second: 21,736.98612
Overall Steps per Second: 10,470.15415

Timestep Collection Time: 2.30032
Timestep Consumption Time: 2.47535
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.77567

Cumulative Model Updates: 118,218
Cumulative Timesteps: 986,013,698

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 986013698...
Checkpoint 986013698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.16854
Policy Entropy: 3.05021
Value Function Loss: 0.00500

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.12027
Policy Update Magnitude: 0.58013
Value Function Update Magnitude: 0.50833

Collected Steps per Second: 21,405.02689
Overall Steps per Second: 10,325.75308

Timestep Collection Time: 2.33618
Timestep Consumption Time: 2.50666
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.84284

Cumulative Model Updates: 118,224
Cumulative Timesteps: 986,063,704

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.98939
Policy Entropy: 3.06511
Value Function Loss: 0.00508

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.11352
Policy Update Magnitude: 0.58163
Value Function Update Magnitude: 0.51436

Collected Steps per Second: 21,961.92558
Overall Steps per Second: 10,494.20781

Timestep Collection Time: 2.27694
Timestep Consumption Time: 2.48816
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.76510

Cumulative Model Updates: 118,230
Cumulative Timesteps: 986,113,710

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 986113710...
Checkpoint 986113710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 874.05301
Policy Entropy: 3.05697
Value Function Loss: 0.00498

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.11172
Policy Update Magnitude: 0.58069
Value Function Update Magnitude: 0.51375

Collected Steps per Second: 21,388.89959
Overall Steps per Second: 10,497.05783

Timestep Collection Time: 2.33813
Timestep Consumption Time: 2.42606
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.76419

Cumulative Model Updates: 118,236
Cumulative Timesteps: 986,163,720

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,086.08843
Policy Entropy: 3.05542
Value Function Loss: 0.00497

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11081
Policy Update Magnitude: 0.57592
Value Function Update Magnitude: 0.51044

Collected Steps per Second: 22,316.17683
Overall Steps per Second: 10,409.37970

Timestep Collection Time: 2.24160
Timestep Consumption Time: 2.56406
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.80567

Cumulative Model Updates: 118,242
Cumulative Timesteps: 986,213,744

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 986213744...
Checkpoint 986213744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.40352
Policy Entropy: 3.05441
Value Function Loss: 0.00521

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.11658
Policy Update Magnitude: 0.57821
Value Function Update Magnitude: 0.51547

Collected Steps per Second: 21,251.01578
Overall Steps per Second: 10,198.69490

Timestep Collection Time: 2.35349
Timestep Consumption Time: 2.55047
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.90396

Cumulative Model Updates: 118,248
Cumulative Timesteps: 986,263,758

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.60614
Policy Entropy: 3.05609
Value Function Loss: 0.00516

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.10584
Policy Update Magnitude: 0.58846
Value Function Update Magnitude: 0.52850

Collected Steps per Second: 21,817.01978
Overall Steps per Second: 10,452.84524

Timestep Collection Time: 2.29252
Timestep Consumption Time: 2.49240
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.78492

Cumulative Model Updates: 118,254
Cumulative Timesteps: 986,313,774

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 986313774...
Checkpoint 986313774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.84878
Policy Entropy: 3.06180
Value Function Loss: 0.00491

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11225
Policy Update Magnitude: 0.57638
Value Function Update Magnitude: 0.52847

Collected Steps per Second: 21,773.98316
Overall Steps per Second: 10,374.15085

Timestep Collection Time: 2.29687
Timestep Consumption Time: 2.52396
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.82083

Cumulative Model Updates: 118,260
Cumulative Timesteps: 986,363,786

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.27543
Policy Entropy: 3.06026
Value Function Loss: 0.00494

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09947
Policy Update Magnitude: 0.57244
Value Function Update Magnitude: 0.52738

Collected Steps per Second: 22,274.16182
Overall Steps per Second: 10,476.26628

Timestep Collection Time: 2.24547
Timestep Consumption Time: 2.52875
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.77422

Cumulative Model Updates: 118,266
Cumulative Timesteps: 986,413,802

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 986413802...
Checkpoint 986413802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,413.72671
Policy Entropy: 3.07003
Value Function Loss: 0.00509

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09301
Policy Update Magnitude: 0.57769
Value Function Update Magnitude: 0.53602

Collected Steps per Second: 21,919.55203
Overall Steps per Second: 10,583.38335

Timestep Collection Time: 2.28189
Timestep Consumption Time: 2.44420
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.72609

Cumulative Model Updates: 118,272
Cumulative Timesteps: 986,463,820

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,320.64329
Policy Entropy: 3.05970
Value Function Loss: 0.00524

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09381
Policy Update Magnitude: 0.58896
Value Function Update Magnitude: 0.53486

Collected Steps per Second: 22,294.58941
Overall Steps per Second: 10,557.15923

Timestep Collection Time: 2.24377
Timestep Consumption Time: 2.49462
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.73840

Cumulative Model Updates: 118,278
Cumulative Timesteps: 986,513,844

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 986513844...
Checkpoint 986513844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.63228
Policy Entropy: 3.07070
Value Function Loss: 0.00498

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10622
Policy Update Magnitude: 0.58530
Value Function Update Magnitude: 0.52335

Collected Steps per Second: 21,581.65871
Overall Steps per Second: 10,378.84098

Timestep Collection Time: 2.31734
Timestep Consumption Time: 2.50131
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.81865

Cumulative Model Updates: 118,284
Cumulative Timesteps: 986,563,856

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,737.69126
Policy Entropy: 3.05587
Value Function Loss: 0.00498

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10616
Policy Update Magnitude: 0.57687
Value Function Update Magnitude: 0.50347

Collected Steps per Second: 21,798.24206
Overall Steps per Second: 10,534.18218

Timestep Collection Time: 2.29385
Timestep Consumption Time: 2.45279
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.74664

Cumulative Model Updates: 118,290
Cumulative Timesteps: 986,613,858

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 986613858...
Checkpoint 986613858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.94724
Policy Entropy: 3.04868
Value Function Loss: 0.00485

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.09877
Policy Update Magnitude: 0.58039
Value Function Update Magnitude: 0.49577

Collected Steps per Second: 21,336.56915
Overall Steps per Second: 10,329.92083

Timestep Collection Time: 2.34377
Timestep Consumption Time: 2.49731
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.84108

Cumulative Model Updates: 118,296
Cumulative Timesteps: 986,663,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391.02328
Policy Entropy: 3.03674
Value Function Loss: 0.00493

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.10480
Policy Update Magnitude: 0.57957
Value Function Update Magnitude: 0.49656

Collected Steps per Second: 21,531.94665
Overall Steps per Second: 10,361.38344

Timestep Collection Time: 2.32315
Timestep Consumption Time: 2.50458
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.82773

Cumulative Model Updates: 118,302
Cumulative Timesteps: 986,713,888

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 986713888...
Checkpoint 986713888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 842.64891
Policy Entropy: 3.03169
Value Function Loss: 0.00504

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.11580
Policy Update Magnitude: 0.57796
Value Function Update Magnitude: 0.49544

Collected Steps per Second: 20,724.13719
Overall Steps per Second: 10,282.27527

Timestep Collection Time: 2.41303
Timestep Consumption Time: 2.45048
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.86352

Cumulative Model Updates: 118,308
Cumulative Timesteps: 986,763,896

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.85978
Policy Entropy: 3.02880
Value Function Loss: 0.00522

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12236
Policy Update Magnitude: 0.58983
Value Function Update Magnitude: 0.50193

Collected Steps per Second: 21,737.80868
Overall Steps per Second: 10,392.65745

Timestep Collection Time: 2.30097
Timestep Consumption Time: 2.51185
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.81282

Cumulative Model Updates: 118,314
Cumulative Timesteps: 986,813,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 986813914...
Checkpoint 986813914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.33767
Policy Entropy: 3.02284
Value Function Loss: 0.00544

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12024
Policy Update Magnitude: 0.59293
Value Function Update Magnitude: 0.51931

Collected Steps per Second: 21,355.05380
Overall Steps per Second: 10,363.21384

Timestep Collection Time: 2.34146
Timestep Consumption Time: 2.48349
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.82495

Cumulative Model Updates: 118,320
Cumulative Timesteps: 986,863,916

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,685.45770
Policy Entropy: 3.02865
Value Function Loss: 0.00546

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11357
Policy Update Magnitude: 0.58811
Value Function Update Magnitude: 0.51641

Collected Steps per Second: 22,186.77140
Overall Steps per Second: 10,426.69497

Timestep Collection Time: 2.25477
Timestep Consumption Time: 2.54311
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.79788

Cumulative Model Updates: 118,326
Cumulative Timesteps: 986,913,942

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 986913942...
Checkpoint 986913942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,703.48798
Policy Entropy: 3.04115
Value Function Loss: 0.00540

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11072
Policy Update Magnitude: 0.57926
Value Function Update Magnitude: 0.50121

Collected Steps per Second: 21,801.57117
Overall Steps per Second: 10,446.73682

Timestep Collection Time: 2.29369
Timestep Consumption Time: 2.49307
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.78676

Cumulative Model Updates: 118,332
Cumulative Timesteps: 986,963,948

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.20976
Policy Entropy: 3.04624
Value Function Loss: 0.00525

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10786
Policy Update Magnitude: 0.57342
Value Function Update Magnitude: 0.48359

Collected Steps per Second: 22,319.94883
Overall Steps per Second: 10,474.43856

Timestep Collection Time: 2.24158
Timestep Consumption Time: 2.53500
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.77658

Cumulative Model Updates: 118,338
Cumulative Timesteps: 987,013,980

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 987013980...
Checkpoint 987013980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,552.37921
Policy Entropy: 3.02840
Value Function Loss: 0.00520

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11469
Policy Update Magnitude: 0.57285
Value Function Update Magnitude: 0.47934

Collected Steps per Second: 21,727.03055
Overall Steps per Second: 10,348.88068

Timestep Collection Time: 2.30275
Timestep Consumption Time: 2.53178
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.83453

Cumulative Model Updates: 118,344
Cumulative Timesteps: 987,064,012

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,928.43603
Policy Entropy: 3.00800
Value Function Loss: 0.00532

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.11834
Policy Update Magnitude: 0.57995
Value Function Update Magnitude: 0.50423

Collected Steps per Second: 22,448.29802
Overall Steps per Second: 10,735.06660

Timestep Collection Time: 2.22805
Timestep Consumption Time: 2.43107
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.65912

Cumulative Model Updates: 118,350
Cumulative Timesteps: 987,114,028

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 987114028...
Checkpoint 987114028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657.73113
Policy Entropy: 2.99911
Value Function Loss: 0.00548

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.13570
Policy Update Magnitude: 0.58996
Value Function Update Magnitude: 0.52268

Collected Steps per Second: 21,715.67176
Overall Steps per Second: 10,499.39580

Timestep Collection Time: 2.30387
Timestep Consumption Time: 2.46117
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.76504

Cumulative Model Updates: 118,356
Cumulative Timesteps: 987,164,058

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.64313
Policy Entropy: 3.01189
Value Function Loss: 0.00535

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12079
Policy Update Magnitude: 0.59343
Value Function Update Magnitude: 0.54252

Collected Steps per Second: 22,177.37751
Overall Steps per Second: 10,613.39016

Timestep Collection Time: 2.25509
Timestep Consumption Time: 2.45707
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.71216

Cumulative Model Updates: 118,362
Cumulative Timesteps: 987,214,070

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 987214070...
Checkpoint 987214070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,436.98238
Policy Entropy: 3.02445
Value Function Loss: 0.00513

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.10690
Policy Update Magnitude: 0.58742
Value Function Update Magnitude: 0.54428

Collected Steps per Second: 20,723.10004
Overall Steps per Second: 10,166.15011

Timestep Collection Time: 2.41344
Timestep Consumption Time: 2.50622
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.91966

Cumulative Model Updates: 118,368
Cumulative Timesteps: 987,264,084

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,095.58025
Policy Entropy: 3.02743
Value Function Loss: 0.00479

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.57193
Value Function Update Magnitude: 0.52564

Collected Steps per Second: 22,079.37111
Overall Steps per Second: 10,629.95255

Timestep Collection Time: 2.26483
Timestep Consumption Time: 2.43943
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.70425

Cumulative Model Updates: 118,374
Cumulative Timesteps: 987,314,090

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 987314090...
Checkpoint 987314090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.63466
Policy Entropy: 3.02945
Value Function Loss: 0.00468

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 0.56016
Value Function Update Magnitude: 0.52595

Collected Steps per Second: 21,599.41504
Overall Steps per Second: 10,548.43931

Timestep Collection Time: 2.31497
Timestep Consumption Time: 2.42526
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.74023

Cumulative Model Updates: 118,380
Cumulative Timesteps: 987,364,092

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,751.52707
Policy Entropy: 3.05394
Value Function Loss: 0.00469

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.10710
Policy Update Magnitude: 0.55725
Value Function Update Magnitude: 0.51287

Collected Steps per Second: 21,906.25679
Overall Steps per Second: 10,574.30064

Timestep Collection Time: 2.28391
Timestep Consumption Time: 2.44756
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.73147

Cumulative Model Updates: 118,386
Cumulative Timesteps: 987,414,124

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 987414124...
Checkpoint 987414124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,658.11076
Policy Entropy: 3.07424
Value Function Loss: 0.00500

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.09942
Policy Update Magnitude: 0.55934
Value Function Update Magnitude: 0.48810

Collected Steps per Second: 21,175.78639
Overall Steps per Second: 10,363.80393

Timestep Collection Time: 2.36119
Timestep Consumption Time: 2.46330
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.82448

Cumulative Model Updates: 118,392
Cumulative Timesteps: 987,464,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.36265
Policy Entropy: 3.08790
Value Function Loss: 0.00488

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08816
Policy Update Magnitude: 0.55788
Value Function Update Magnitude: 0.47854

Collected Steps per Second: 21,992.71846
Overall Steps per Second: 10,599.20494

Timestep Collection Time: 2.27430
Timestep Consumption Time: 2.44474
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.71903

Cumulative Model Updates: 118,398
Cumulative Timesteps: 987,514,142

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 987514142...
Checkpoint 987514142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,573.80165
Policy Entropy: 3.07667
Value Function Loss: 0.00480

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09697
Policy Update Magnitude: 0.55087
Value Function Update Magnitude: 0.48279

Collected Steps per Second: 21,255.90944
Overall Steps per Second: 10,233.93126

Timestep Collection Time: 2.35257
Timestep Consumption Time: 2.53373
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.88629

Cumulative Model Updates: 118,404
Cumulative Timesteps: 987,564,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,010.49945
Policy Entropy: 3.07461
Value Function Loss: 0.00453

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08864
Policy Update Magnitude: 0.54890
Value Function Update Magnitude: 0.47850

Collected Steps per Second: 22,090.40299
Overall Steps per Second: 10,486.96998

Timestep Collection Time: 2.26406
Timestep Consumption Time: 2.50510
PPO Batch Consumption Time: 0.28181
Total Iteration Time: 4.76916

Cumulative Model Updates: 118,410
Cumulative Timesteps: 987,614,162

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 987614162...
Checkpoint 987614162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,932.39208
Policy Entropy: 3.05577
Value Function Loss: 0.00481

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08736
Policy Update Magnitude: 0.54961
Value Function Update Magnitude: 0.47585

Collected Steps per Second: 21,452.29047
Overall Steps per Second: 10,264.88810

Timestep Collection Time: 2.33122
Timestep Consumption Time: 2.54073
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.87195

Cumulative Model Updates: 118,416
Cumulative Timesteps: 987,664,172

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.24677
Policy Entropy: 3.04986
Value Function Loss: 0.00491

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09407
Policy Update Magnitude: 0.55789
Value Function Update Magnitude: 0.49192

Collected Steps per Second: 22,303.30895
Overall Steps per Second: 10,462.80420

Timestep Collection Time: 2.24254
Timestep Consumption Time: 2.53783
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.78036

Cumulative Model Updates: 118,422
Cumulative Timesteps: 987,714,188

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 987714188...
Checkpoint 987714188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.91306
Policy Entropy: 3.04301
Value Function Loss: 0.00488

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.09788
Policy Update Magnitude: 0.56556
Value Function Update Magnitude: 0.49422

Collected Steps per Second: 21,854.30840
Overall Steps per Second: 10,596.55597

Timestep Collection Time: 2.28852
Timestep Consumption Time: 2.43132
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.71984

Cumulative Model Updates: 118,428
Cumulative Timesteps: 987,764,202

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,545.95308
Policy Entropy: 3.05026
Value Function Loss: 0.00506

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09848
Policy Update Magnitude: 0.56947
Value Function Update Magnitude: 0.49384

Collected Steps per Second: 22,287.00922
Overall Steps per Second: 10,430.25631

Timestep Collection Time: 2.24373
Timestep Consumption Time: 2.55059
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.79432

Cumulative Model Updates: 118,434
Cumulative Timesteps: 987,814,208

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 987814208...
Checkpoint 987814208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.51048
Policy Entropy: 3.06437
Value Function Loss: 0.00497

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09835
Policy Update Magnitude: 0.56846
Value Function Update Magnitude: 0.50279

Collected Steps per Second: 20,698.60888
Overall Steps per Second: 10,169.95787

Timestep Collection Time: 2.41610
Timestep Consumption Time: 2.50132
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.91742

Cumulative Model Updates: 118,440
Cumulative Timesteps: 987,864,218

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,776.38982
Policy Entropy: 3.07890
Value Function Loss: 0.00541

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.57008
Value Function Update Magnitude: 0.51990

Collected Steps per Second: 22,084.60788
Overall Steps per Second: 10,520.49217

Timestep Collection Time: 2.26465
Timestep Consumption Time: 2.48931
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.75396

Cumulative Model Updates: 118,446
Cumulative Timesteps: 987,914,232

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 987914232...
Checkpoint 987914232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,750.90487
Policy Entropy: 3.09088
Value Function Loss: 0.00509

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.56453
Value Function Update Magnitude: 0.54943

Collected Steps per Second: 21,791.64166
Overall Steps per Second: 10,424.76628

Timestep Collection Time: 2.29446
Timestep Consumption Time: 2.50181
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.79627

Cumulative Model Updates: 118,452
Cumulative Timesteps: 987,964,232

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.07501
Policy Entropy: 3.08858
Value Function Loss: 0.00546

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10535
Policy Update Magnitude: 0.56648
Value Function Update Magnitude: 0.54377

Collected Steps per Second: 22,037.90507
Overall Steps per Second: 10,659.73720

Timestep Collection Time: 2.26900
Timestep Consumption Time: 2.42192
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.69092

Cumulative Model Updates: 118,458
Cumulative Timesteps: 988,014,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 988014236...
Checkpoint 988014236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.37006
Policy Entropy: 3.07482
Value Function Loss: 0.00517

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.57379
Value Function Update Magnitude: 0.54049

Collected Steps per Second: 21,302.81239
Overall Steps per Second: 10,335.60407

Timestep Collection Time: 2.34852
Timestep Consumption Time: 2.49203
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.84055

Cumulative Model Updates: 118,464
Cumulative Timesteps: 988,064,266

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,615.15966
Policy Entropy: 3.07302
Value Function Loss: 0.00510

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.56573
Value Function Update Magnitude: 0.52725

Collected Steps per Second: 21,630.32578
Overall Steps per Second: 10,365.93952

Timestep Collection Time: 2.31166
Timestep Consumption Time: 2.51202
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.82368

Cumulative Model Updates: 118,470
Cumulative Timesteps: 988,114,268

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 988114268...
Checkpoint 988114268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,515.00157
Policy Entropy: 3.07250
Value Function Loss: 0.00487

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.11082
Policy Update Magnitude: 0.55671
Value Function Update Magnitude: 0.50100

Collected Steps per Second: 21,440.17143
Overall Steps per Second: 10,249.93309

Timestep Collection Time: 2.33319
Timestep Consumption Time: 2.54723
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.88042

Cumulative Model Updates: 118,476
Cumulative Timesteps: 988,164,292

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.78650
Policy Entropy: 3.07368
Value Function Loss: 0.00492

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.09995
Policy Update Magnitude: 0.56017
Value Function Update Magnitude: 0.48573

Collected Steps per Second: 21,637.31428
Overall Steps per Second: 10,422.33327

Timestep Collection Time: 2.31184
Timestep Consumption Time: 2.48766
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.79950

Cumulative Model Updates: 118,482
Cumulative Timesteps: 988,214,314

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 988214314...
Checkpoint 988214314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,243.36327
Policy Entropy: 3.04644
Value Function Loss: 0.00500

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09708
Policy Update Magnitude: 0.57483
Value Function Update Magnitude: 0.49071

Collected Steps per Second: 21,863.84587
Overall Steps per Second: 10,362.84331

Timestep Collection Time: 2.28752
Timestep Consumption Time: 2.53876
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.82628

Cumulative Model Updates: 118,488
Cumulative Timesteps: 988,264,328

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,520.82995
Policy Entropy: 3.03990
Value Function Loss: 0.00473

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.09709
Policy Update Magnitude: 0.57083
Value Function Update Magnitude: 0.48476

Collected Steps per Second: 22,339.59200
Overall Steps per Second: 10,609.55933

Timestep Collection Time: 2.23836
Timestep Consumption Time: 2.47475
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.71311

Cumulative Model Updates: 118,494
Cumulative Timesteps: 988,314,332

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 988314332...
Checkpoint 988314332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,290.64316
Policy Entropy: 3.05366
Value Function Loss: 0.00470

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10453
Policy Update Magnitude: 0.57058
Value Function Update Magnitude: 0.48025

Collected Steps per Second: 21,947.52689
Overall Steps per Second: 10,447.51222

Timestep Collection Time: 2.27916
Timestep Consumption Time: 2.50877
PPO Batch Consumption Time: 0.29522
Total Iteration Time: 4.78793

Cumulative Model Updates: 118,500
Cumulative Timesteps: 988,364,354

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,565.30551
Policy Entropy: 3.07336
Value Function Loss: 0.00481

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11275
Policy Update Magnitude: 0.56922
Value Function Update Magnitude: 0.48325

Collected Steps per Second: 22,149.79445
Overall Steps per Second: 10,448.11670

Timestep Collection Time: 2.25880
Timestep Consumption Time: 2.52981
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.78861

Cumulative Model Updates: 118,506
Cumulative Timesteps: 988,414,386

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 988414386...
Checkpoint 988414386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,083.97777
Policy Entropy: 3.07871
Value Function Loss: 0.00480

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10451
Policy Update Magnitude: 0.57177
Value Function Update Magnitude: 0.49642

Collected Steps per Second: 21,814.48703
Overall Steps per Second: 10,518.57429

Timestep Collection Time: 2.29316
Timestep Consumption Time: 2.46262
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.75578

Cumulative Model Updates: 118,512
Cumulative Timesteps: 988,464,410

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,528.05719
Policy Entropy: 3.05476
Value Function Loss: 0.00489

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.10637
Policy Update Magnitude: 0.56225
Value Function Update Magnitude: 0.47011

Collected Steps per Second: 21,873.80876
Overall Steps per Second: 10,318.68998

Timestep Collection Time: 2.28648
Timestep Consumption Time: 2.56045
PPO Batch Consumption Time: 0.29711
Total Iteration Time: 4.84693

Cumulative Model Updates: 118,518
Cumulative Timesteps: 988,514,424

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 988514424...
Checkpoint 988514424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,755.77666
Policy Entropy: 3.04097
Value Function Loss: 0.00520

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10626
Policy Update Magnitude: 0.56705
Value Function Update Magnitude: 0.46084

Collected Steps per Second: 21,814.21924
Overall Steps per Second: 10,459.49330

Timestep Collection Time: 2.29346
Timestep Consumption Time: 2.48976
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.78321

Cumulative Model Updates: 118,524
Cumulative Timesteps: 988,564,454

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.80275
Policy Entropy: 3.03150
Value Function Loss: 0.00522

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11274
Policy Update Magnitude: 0.57625
Value Function Update Magnitude: 0.47055

Collected Steps per Second: 22,034.40748
Overall Steps per Second: 10,427.65783

Timestep Collection Time: 2.26954
Timestep Consumption Time: 2.52617
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.79571

Cumulative Model Updates: 118,530
Cumulative Timesteps: 988,614,462

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 988614462...
Checkpoint 988614462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,575.37749
Policy Entropy: 3.04351
Value Function Loss: 0.00493

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11121
Policy Update Magnitude: 0.57265
Value Function Update Magnitude: 0.47836

Collected Steps per Second: 21,537.36603
Overall Steps per Second: 10,496.40031

Timestep Collection Time: 2.32192
Timestep Consumption Time: 2.44238
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.76430

Cumulative Model Updates: 118,536
Cumulative Timesteps: 988,664,470

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421.48935
Policy Entropy: 3.06270
Value Function Loss: 0.00470

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.10801
Policy Update Magnitude: 0.55866
Value Function Update Magnitude: 0.46754

Collected Steps per Second: 21,775.73647
Overall Steps per Second: 10,573.84939

Timestep Collection Time: 2.29696
Timestep Consumption Time: 2.43339
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.73035

Cumulative Model Updates: 118,542
Cumulative Timesteps: 988,714,488

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 988714488...
Checkpoint 988714488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,804.44959
Policy Entropy: 3.05546
Value Function Loss: 0.00465

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10466
Policy Update Magnitude: 0.56012
Value Function Update Magnitude: 0.47682

Collected Steps per Second: 21,559.74475
Overall Steps per Second: 10,377.70318

Timestep Collection Time: 2.32053
Timestep Consumption Time: 2.50038
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.82091

Cumulative Model Updates: 118,548
Cumulative Timesteps: 988,764,518

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,708.74068
Policy Entropy: 3.04934
Value Function Loss: 0.00470

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.56190
Value Function Update Magnitude: 0.48779

Collected Steps per Second: 21,769.85178
Overall Steps per Second: 10,615.33951

Timestep Collection Time: 2.29758
Timestep Consumption Time: 2.41428
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.71186

Cumulative Model Updates: 118,554
Cumulative Timesteps: 988,814,536

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 988814536...
Checkpoint 988814536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,354.70702
Policy Entropy: 3.04831
Value Function Loss: 0.00485

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09599
Policy Update Magnitude: 0.56130
Value Function Update Magnitude: 0.49651

Collected Steps per Second: 21,753.50626
Overall Steps per Second: 10,485.86888

Timestep Collection Time: 2.29885
Timestep Consumption Time: 2.47024
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.76908

Cumulative Model Updates: 118,560
Cumulative Timesteps: 988,864,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,553.22715
Policy Entropy: 3.04470
Value Function Loss: 0.00503

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.56754
Value Function Update Magnitude: 0.48858

Collected Steps per Second: 22,206.43457
Overall Steps per Second: 10,563.90957

Timestep Collection Time: 2.25169
Timestep Consumption Time: 2.48160
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.73329

Cumulative Model Updates: 118,566
Cumulative Timesteps: 988,914,546

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 988914546...
Checkpoint 988914546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,071.02260
Policy Entropy: 3.05065
Value Function Loss: 0.00505

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10563
Policy Update Magnitude: 0.57947
Value Function Update Magnitude: 0.49433

Collected Steps per Second: 21,972.82406
Overall Steps per Second: 10,390.04149

Timestep Collection Time: 2.27690
Timestep Consumption Time: 2.53828
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.81519

Cumulative Model Updates: 118,572
Cumulative Timesteps: 988,964,576

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.39448
Policy Entropy: 3.04669
Value Function Loss: 0.00471

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11046
Policy Update Magnitude: 0.57667
Value Function Update Magnitude: 0.50358

Collected Steps per Second: 21,938.92532
Overall Steps per Second: 10,562.08435

Timestep Collection Time: 2.28051
Timestep Consumption Time: 2.45643
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.73694

Cumulative Model Updates: 118,578
Cumulative Timesteps: 989,014,608

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 989014608...
Checkpoint 989014608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,530.26589
Policy Entropy: 3.04281
Value Function Loss: 0.00481

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10447
Policy Update Magnitude: 0.57173
Value Function Update Magnitude: 0.49671

Collected Steps per Second: 21,884.53242
Overall Steps per Second: 10,543.76005

Timestep Collection Time: 2.28536
Timestep Consumption Time: 2.45811
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.74347

Cumulative Model Updates: 118,584
Cumulative Timesteps: 989,064,622

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,732.84998
Policy Entropy: 3.03688
Value Function Loss: 0.00476

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.09829
Policy Update Magnitude: 0.58036
Value Function Update Magnitude: 0.48778

Collected Steps per Second: 22,290.31890
Overall Steps per Second: 10,461.02706

Timestep Collection Time: 2.24322
Timestep Consumption Time: 2.53662
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.77984

Cumulative Model Updates: 118,590
Cumulative Timesteps: 989,114,624

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 989114624...
Checkpoint 989114624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,917.94070
Policy Entropy: 3.03698
Value Function Loss: 0.00499

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.59398
Value Function Update Magnitude: 0.50036

Collected Steps per Second: 21,294.24831
Overall Steps per Second: 10,118.11792

Timestep Collection Time: 2.34937
Timestep Consumption Time: 2.59503
PPO Batch Consumption Time: 0.30597
Total Iteration Time: 4.94440

Cumulative Model Updates: 118,596
Cumulative Timesteps: 989,164,652

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 828.45765
Policy Entropy: 3.05235
Value Function Loss: 0.00475

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.09749
Policy Update Magnitude: 0.58212
Value Function Update Magnitude: 0.49961

Collected Steps per Second: 21,251.65764
Overall Steps per Second: 10,232.42808

Timestep Collection Time: 2.35417
Timestep Consumption Time: 2.53519
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.88936

Cumulative Model Updates: 118,602
Cumulative Timesteps: 989,214,682

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 989214682...
Checkpoint 989214682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,699.87229
Policy Entropy: 3.07142
Value Function Loss: 0.00455

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08919
Policy Update Magnitude: 0.57192
Value Function Update Magnitude: 0.50360

Collected Steps per Second: 21,537.08893
Overall Steps per Second: 10,500.47976

Timestep Collection Time: 2.32213
Timestep Consumption Time: 2.44070
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.76283

Cumulative Model Updates: 118,608
Cumulative Timesteps: 989,264,694

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,917.54029
Policy Entropy: 3.06210
Value Function Loss: 0.00457

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.56769
Value Function Update Magnitude: 0.48044

Collected Steps per Second: 21,311.32027
Overall Steps per Second: 10,262.93497

Timestep Collection Time: 2.34692
Timestep Consumption Time: 2.52654
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.87346

Cumulative Model Updates: 118,614
Cumulative Timesteps: 989,314,710

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 989314710...
Checkpoint 989314710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.84293
Policy Entropy: 3.06059
Value Function Loss: 0.00456

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.56372
Value Function Update Magnitude: 0.47481

Collected Steps per Second: 21,714.93283
Overall Steps per Second: 10,421.84713

Timestep Collection Time: 2.30404
Timestep Consumption Time: 2.49665
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.80068

Cumulative Model Updates: 118,620
Cumulative Timesteps: 989,364,742

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,588.30114
Policy Entropy: 3.05012
Value Function Loss: 0.00476

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09563
Policy Update Magnitude: 0.56978
Value Function Update Magnitude: 0.47766

Collected Steps per Second: 21,846.99895
Overall Steps per Second: 10,502.03850

Timestep Collection Time: 2.28993
Timestep Consumption Time: 2.47372
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.76365

Cumulative Model Updates: 118,626
Cumulative Timesteps: 989,414,770

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 989414770...
Checkpoint 989414770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,376.59284
Policy Entropy: 3.05419
Value Function Loss: 0.00483

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.10715
Policy Update Magnitude: 0.57828
Value Function Update Magnitude: 0.48437

Collected Steps per Second: 21,648.79602
Overall Steps per Second: 10,386.30514

Timestep Collection Time: 2.31052
Timestep Consumption Time: 2.50544
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.81596

Cumulative Model Updates: 118,632
Cumulative Timesteps: 989,464,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.05290
Policy Entropy: 3.05542
Value Function Loss: 0.00490

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.10977
Policy Update Magnitude: 0.58135
Value Function Update Magnitude: 0.51331

Collected Steps per Second: 22,432.04298
Overall Steps per Second: 10,639.27218

Timestep Collection Time: 2.22994
Timestep Consumption Time: 2.47170
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.70164

Cumulative Model Updates: 118,638
Cumulative Timesteps: 989,514,812

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 989514812...
Checkpoint 989514812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,361.09498
Policy Entropy: 3.06547
Value Function Loss: 0.00476

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10303
Policy Update Magnitude: 0.58096
Value Function Update Magnitude: 0.54002

Collected Steps per Second: 21,855.45786
Overall Steps per Second: 10,382.74161

Timestep Collection Time: 2.28895
Timestep Consumption Time: 2.52924
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.81819

Cumulative Model Updates: 118,644
Cumulative Timesteps: 989,564,838

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,518.72222
Policy Entropy: 3.07201
Value Function Loss: 0.00478

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10085
Policy Update Magnitude: 0.57998
Value Function Update Magnitude: 0.52897

Collected Steps per Second: 22,174.32448
Overall Steps per Second: 10,449.29940

Timestep Collection Time: 2.25522
Timestep Consumption Time: 2.53055
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.78578

Cumulative Model Updates: 118,650
Cumulative Timesteps: 989,614,846

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 989614846...
Checkpoint 989614846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,601.67560
Policy Entropy: 3.04952
Value Function Loss: 0.00472

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09268
Policy Update Magnitude: 0.57827
Value Function Update Magnitude: 0.51861

Collected Steps per Second: 22,053.06516
Overall Steps per Second: 10,536.45124

Timestep Collection Time: 2.26844
Timestep Consumption Time: 2.47946
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.74790

Cumulative Model Updates: 118,656
Cumulative Timesteps: 989,664,872

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,513.39192
Policy Entropy: 3.04817
Value Function Loss: 0.00509

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09043
Policy Update Magnitude: 0.59597
Value Function Update Magnitude: 0.52115

Collected Steps per Second: 22,072.18761
Overall Steps per Second: 10,460.62084

Timestep Collection Time: 2.26557
Timestep Consumption Time: 2.51484
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.78040

Cumulative Model Updates: 118,662
Cumulative Timesteps: 989,714,878

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 989714878...
Checkpoint 989714878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673.05448
Policy Entropy: 3.04955
Value Function Loss: 0.00523

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09080
Policy Update Magnitude: 0.60397
Value Function Update Magnitude: 0.52446

Collected Steps per Second: 21,699.57038
Overall Steps per Second: 10,324.58361

Timestep Collection Time: 2.30558
Timestep Consumption Time: 2.54014
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.84572

Cumulative Model Updates: 118,668
Cumulative Timesteps: 989,764,908

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,897.78260
Policy Entropy: 3.04655
Value Function Loss: 0.00530

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09663
Policy Update Magnitude: 0.60464
Value Function Update Magnitude: 0.54454

Collected Steps per Second: 21,569.91361
Overall Steps per Second: 10,227.33875

Timestep Collection Time: 2.31851
Timestep Consumption Time: 2.57133
PPO Batch Consumption Time: 0.30108
Total Iteration Time: 4.88984

Cumulative Model Updates: 118,674
Cumulative Timesteps: 989,814,918

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 989814918...
Checkpoint 989814918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,166.75814
Policy Entropy: 3.03860
Value Function Loss: 0.00516

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09667
Policy Update Magnitude: 0.59572
Value Function Update Magnitude: 0.55496

Collected Steps per Second: 21,477.16248
Overall Steps per Second: 10,347.10397

Timestep Collection Time: 2.32899
Timestep Consumption Time: 2.50522
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.83420

Cumulative Model Updates: 118,680
Cumulative Timesteps: 989,864,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,672.31692
Policy Entropy: 3.04329
Value Function Loss: 0.00503

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.58855
Value Function Update Magnitude: 0.53883

Collected Steps per Second: 21,808.43845
Overall Steps per Second: 10,412.35936

Timestep Collection Time: 2.29370
Timestep Consumption Time: 2.51040
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.80410

Cumulative Model Updates: 118,686
Cumulative Timesteps: 989,914,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 989914960...
Checkpoint 989914960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,129.48329
Policy Entropy: 3.05217
Value Function Loss: 0.00486

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.11736
Policy Update Magnitude: 0.58163
Value Function Update Magnitude: 0.51993

Collected Steps per Second: 21,458.98544
Overall Steps per Second: 10,296.18380

Timestep Collection Time: 2.33189
Timestep Consumption Time: 2.52816
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.86005

Cumulative Model Updates: 118,692
Cumulative Timesteps: 989,965,000

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,504.18253
Policy Entropy: 3.06382
Value Function Loss: 0.00478

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09849
Policy Update Magnitude: 0.57632
Value Function Update Magnitude: 0.51143

Collected Steps per Second: 21,953.74073
Overall Steps per Second: 10,392.35471

Timestep Collection Time: 2.27852
Timestep Consumption Time: 2.53483
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.81335

Cumulative Model Updates: 118,698
Cumulative Timesteps: 990,015,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 990015022...
Checkpoint 990015022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.09902
Policy Entropy: 3.06585
Value Function Loss: 0.00473

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09805
Policy Update Magnitude: 0.58007
Value Function Update Magnitude: 0.50661

Collected Steps per Second: 21,860.35942
Overall Steps per Second: 10,349.44138

Timestep Collection Time: 2.28816
Timestep Consumption Time: 2.54495
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.83311

Cumulative Model Updates: 118,704
Cumulative Timesteps: 990,065,042

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.61587
Policy Entropy: 3.05971
Value Function Loss: 0.00449

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.57453
Value Function Update Magnitude: 0.51175

Collected Steps per Second: 20,990.31806
Overall Steps per Second: 10,205.88974

Timestep Collection Time: 2.38424
Timestep Consumption Time: 2.51940
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.90364

Cumulative Model Updates: 118,710
Cumulative Timesteps: 990,115,088

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 990115088...
Checkpoint 990115088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,734.35086
Policy Entropy: 3.03350
Value Function Loss: 0.00490

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.57935
Value Function Update Magnitude: 0.49695

Collected Steps per Second: 21,382.99353
Overall Steps per Second: 10,304.70525

Timestep Collection Time: 2.33877
Timestep Consumption Time: 2.51435
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.85312

Cumulative Model Updates: 118,716
Cumulative Timesteps: 990,165,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.21628
Policy Entropy: 3.01670
Value Function Loss: 0.00521

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09979
Policy Update Magnitude: 0.59465
Value Function Update Magnitude: 0.51056

Collected Steps per Second: 22,372.84858
Overall Steps per Second: 10,541.34173

Timestep Collection Time: 2.23575
Timestep Consumption Time: 2.50938
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.74513

Cumulative Model Updates: 118,722
Cumulative Timesteps: 990,215,118

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 990215118...
Checkpoint 990215118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 969.25153
Policy Entropy: 3.00579
Value Function Loss: 0.00558

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.59876
Value Function Update Magnitude: 0.52393

Collected Steps per Second: 21,889.28403
Overall Steps per Second: 10,644.68683

Timestep Collection Time: 2.28459
Timestep Consumption Time: 2.41334
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.69793

Cumulative Model Updates: 118,728
Cumulative Timesteps: 990,265,126

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.24724
Policy Entropy: 3.03105
Value Function Loss: 0.00524

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12143
Policy Update Magnitude: 0.58953
Value Function Update Magnitude: 0.53203

Collected Steps per Second: 22,339.90712
Overall Steps per Second: 10,466.09606

Timestep Collection Time: 2.23824
Timestep Consumption Time: 2.53928
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.77752

Cumulative Model Updates: 118,734
Cumulative Timesteps: 990,315,128

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 990315128...
Checkpoint 990315128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.40663
Policy Entropy: 3.03572
Value Function Loss: 0.00531

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.11910
Policy Update Magnitude: 0.58938
Value Function Update Magnitude: 0.53274

Collected Steps per Second: 21,703.24000
Overall Steps per Second: 10,495.15619

Timestep Collection Time: 2.30436
Timestep Consumption Time: 2.46089
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.76525

Cumulative Model Updates: 118,740
Cumulative Timesteps: 990,365,140

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554.51807
Policy Entropy: 3.04291
Value Function Loss: 0.00499

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10178
Policy Update Magnitude: 0.58920
Value Function Update Magnitude: 0.52780

Collected Steps per Second: 22,035.01320
Overall Steps per Second: 10,553.60672

Timestep Collection Time: 2.27002
Timestep Consumption Time: 2.46959
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.73961

Cumulative Model Updates: 118,746
Cumulative Timesteps: 990,415,160

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 990415160...
Checkpoint 990415160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,454.00286
Policy Entropy: 3.03621
Value Function Loss: 0.00508

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.58688
Value Function Update Magnitude: 0.53212

Collected Steps per Second: 21,220.18841
Overall Steps per Second: 10,172.77280

Timestep Collection Time: 2.35709
Timestep Consumption Time: 2.55976
PPO Batch Consumption Time: 0.30685
Total Iteration Time: 4.91685

Cumulative Model Updates: 118,752
Cumulative Timesteps: 990,465,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.79022
Policy Entropy: 3.01895
Value Function Loss: 0.00502

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10048
Policy Update Magnitude: 0.58781
Value Function Update Magnitude: 0.53175

Collected Steps per Second: 21,869.16325
Overall Steps per Second: 10,493.46894

Timestep Collection Time: 2.28696
Timestep Consumption Time: 2.47924
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.76620

Cumulative Model Updates: 118,758
Cumulative Timesteps: 990,515,192

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 990515192...
Checkpoint 990515192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,660.72093
Policy Entropy: 3.01503
Value Function Loss: 0.00527

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.09883
Policy Update Magnitude: 0.59218
Value Function Update Magnitude: 0.54299

Collected Steps per Second: 20,912.37369
Overall Steps per Second: 10,204.11640

Timestep Collection Time: 2.39179
Timestep Consumption Time: 2.50996
PPO Batch Consumption Time: 0.29508
Total Iteration Time: 4.90175

Cumulative Model Updates: 118,764
Cumulative Timesteps: 990,565,210

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 934.52222
Policy Entropy: 3.00321
Value Function Loss: 0.00538

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.60570
Value Function Update Magnitude: 0.53607

Collected Steps per Second: 21,779.09205
Overall Steps per Second: 10,431.22711

Timestep Collection Time: 2.29661
Timestep Consumption Time: 2.49842
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.79503

Cumulative Model Updates: 118,770
Cumulative Timesteps: 990,615,228

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 990615228...
Checkpoint 990615228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.49191
Policy Entropy: 2.99670
Value Function Loss: 0.00549

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11506
Policy Update Magnitude: 0.61627
Value Function Update Magnitude: 0.51663

Collected Steps per Second: 21,491.13567
Overall Steps per Second: 10,398.49315

Timestep Collection Time: 2.32682
Timestep Consumption Time: 2.48215
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.80897

Cumulative Model Updates: 118,776
Cumulative Timesteps: 990,665,234

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,406.32292
Policy Entropy: 2.97752
Value Function Loss: 0.00538

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.13238
Policy Update Magnitude: 0.61400
Value Function Update Magnitude: 0.51937

Collected Steps per Second: 22,007.19139
Overall Steps per Second: 10,462.05068

Timestep Collection Time: 2.27244
Timestep Consumption Time: 2.50769
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.78013

Cumulative Model Updates: 118,782
Cumulative Timesteps: 990,715,244

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 990715244...
Checkpoint 990715244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 994.75792
Policy Entropy: 2.98075
Value Function Loss: 0.00539

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.12219
Policy Update Magnitude: 0.60813
Value Function Update Magnitude: 0.52491

Collected Steps per Second: 21,932.92999
Overall Steps per Second: 10,479.55945

Timestep Collection Time: 2.28095
Timestep Consumption Time: 2.49291
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.77386

Cumulative Model Updates: 118,788
Cumulative Timesteps: 990,765,272

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.67545
Policy Entropy: 2.96408
Value Function Loss: 0.00539

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.60902
Value Function Update Magnitude: 0.53167

Collected Steps per Second: 22,375.30601
Overall Steps per Second: 10,487.75373

Timestep Collection Time: 2.23523
Timestep Consumption Time: 2.53357
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.76880

Cumulative Model Updates: 118,794
Cumulative Timesteps: 990,815,286

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 990815286...
Checkpoint 990815286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 977.23019
Policy Entropy: 2.95384
Value Function Loss: 0.00561

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.13788
Policy Update Magnitude: 0.61100
Value Function Update Magnitude: 0.53236

Collected Steps per Second: 22,033.23597
Overall Steps per Second: 10,554.28774

Timestep Collection Time: 2.26957
Timestep Consumption Time: 2.46841
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.73798

Cumulative Model Updates: 118,800
Cumulative Timesteps: 990,865,292

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.04342
Policy Entropy: 2.95361
Value Function Loss: 0.00529

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.13384
Policy Update Magnitude: 0.60420
Value Function Update Magnitude: 0.54194

Collected Steps per Second: 22,134.66575
Overall Steps per Second: 10,481.65455

Timestep Collection Time: 2.26026
Timestep Consumption Time: 2.51285
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.77310

Cumulative Model Updates: 118,806
Cumulative Timesteps: 990,915,322

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 990915322...
Checkpoint 990915322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.07222
Policy Entropy: 2.98538
Value Function Loss: 0.00493

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11193
Policy Update Magnitude: 0.59441
Value Function Update Magnitude: 0.53495

Collected Steps per Second: 21,635.71788
Overall Steps per Second: 10,345.60093

Timestep Collection Time: 2.31229
Timestep Consumption Time: 2.52339
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.83568

Cumulative Model Updates: 118,812
Cumulative Timesteps: 990,965,350

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,995.61098
Policy Entropy: 2.97807
Value Function Loss: 0.00498

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.11499
Policy Update Magnitude: 0.59051
Value Function Update Magnitude: 0.51498

Collected Steps per Second: 20,585.12355
Overall Steps per Second: 10,280.89425

Timestep Collection Time: 2.42904
Timestep Consumption Time: 2.43455
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.86358

Cumulative Model Updates: 118,818
Cumulative Timesteps: 991,015,352

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 991015352...
Checkpoint 991015352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707.40080
Policy Entropy: 3.00109
Value Function Loss: 0.00504

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.11939
Policy Update Magnitude: 0.59240
Value Function Update Magnitude: 0.49708

Collected Steps per Second: 21,214.88241
Overall Steps per Second: 10,222.44736

Timestep Collection Time: 2.35778
Timestep Consumption Time: 2.53537
PPO Batch Consumption Time: 0.29955
Total Iteration Time: 4.89315

Cumulative Model Updates: 118,824
Cumulative Timesteps: 991,065,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.74394
Policy Entropy: 2.97501
Value Function Loss: 0.00495

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11517
Policy Update Magnitude: 0.58779
Value Function Update Magnitude: 0.48412

Collected Steps per Second: 21,480.41155
Overall Steps per Second: 10,294.54133

Timestep Collection Time: 2.32835
Timestep Consumption Time: 2.52995
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.85830

Cumulative Model Updates: 118,830
Cumulative Timesteps: 991,115,386

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 991115386...
Checkpoint 991115386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,303.64766
Policy Entropy: 2.99057
Value Function Loss: 0.00476

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10257
Policy Update Magnitude: 0.58175
Value Function Update Magnitude: 0.47219

Collected Steps per Second: 21,445.17949
Overall Steps per Second: 10,377.56121

Timestep Collection Time: 2.33153
Timestep Consumption Time: 2.48656
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.81809

Cumulative Model Updates: 118,836
Cumulative Timesteps: 991,165,386

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.72749
Policy Entropy: 2.97799
Value Function Loss: 0.00478

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.58522
Value Function Update Magnitude: 0.47699

Collected Steps per Second: 22,208.66629
Overall Steps per Second: 10,472.63309

Timestep Collection Time: 2.25272
Timestep Consumption Time: 2.52449
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.77721

Cumulative Model Updates: 118,842
Cumulative Timesteps: 991,215,416

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 991215416...
Checkpoint 991215416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.83081
Policy Entropy: 2.97711
Value Function Loss: 0.00496

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.59136
Value Function Update Magnitude: 0.49365

Collected Steps per Second: 21,958.81515
Overall Steps per Second: 10,418.41251

Timestep Collection Time: 2.27826
Timestep Consumption Time: 2.52362
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.80188

Cumulative Model Updates: 118,848
Cumulative Timesteps: 991,265,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,097.26420
Policy Entropy: 2.97405
Value Function Loss: 0.00489

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11198
Policy Update Magnitude: 0.58539
Value Function Update Magnitude: 0.49608

Collected Steps per Second: 22,358.18868
Overall Steps per Second: 10,608.35657

Timestep Collection Time: 2.23748
Timestep Consumption Time: 2.47824
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.71572

Cumulative Model Updates: 118,854
Cumulative Timesteps: 991,315,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 991315470...
Checkpoint 991315470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.89046
Policy Entropy: 2.96991
Value Function Loss: 0.00475

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10787
Policy Update Magnitude: 0.58414
Value Function Update Magnitude: 0.50173

Collected Steps per Second: 21,643.85737
Overall Steps per Second: 10,322.17865

Timestep Collection Time: 2.31086
Timestep Consumption Time: 2.53463
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.84549

Cumulative Model Updates: 118,860
Cumulative Timesteps: 991,365,486

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,963.81298
Policy Entropy: 2.98276
Value Function Loss: 0.00464

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.58138
Value Function Update Magnitude: 0.48994

Collected Steps per Second: 22,347.28854
Overall Steps per Second: 10,442.35230

Timestep Collection Time: 2.23750
Timestep Consumption Time: 2.55089
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.78838

Cumulative Model Updates: 118,866
Cumulative Timesteps: 991,415,488

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 991415488...
Checkpoint 991415488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.16674
Policy Entropy: 2.98032
Value Function Loss: 0.00476

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.12265
Policy Update Magnitude: 0.57892
Value Function Update Magnitude: 0.48818

Collected Steps per Second: 22,024.28414
Overall Steps per Second: 10,575.18390

Timestep Collection Time: 2.27077
Timestep Consumption Time: 2.45842
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.72918

Cumulative Model Updates: 118,872
Cumulative Timesteps: 991,465,500

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,332.19281
Policy Entropy: 2.98481
Value Function Loss: 0.00494

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.12473
Policy Update Magnitude: 0.57347
Value Function Update Magnitude: 0.50116

Collected Steps per Second: 22,181.51992
Overall Steps per Second: 10,458.11584

Timestep Collection Time: 2.25431
Timestep Consumption Time: 2.52705
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.78136

Cumulative Model Updates: 118,878
Cumulative Timesteps: 991,515,504

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 991515504...
Checkpoint 991515504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.27883
Policy Entropy: 2.97509
Value Function Loss: 0.00540

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11779
Policy Update Magnitude: 0.58913
Value Function Update Magnitude: 0.50511

Collected Steps per Second: 21,552.31761
Overall Steps per Second: 10,345.91564

Timestep Collection Time: 2.32049
Timestep Consumption Time: 2.51349
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.83398

Cumulative Model Updates: 118,884
Cumulative Timesteps: 991,565,516

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.51254
Policy Entropy: 2.98850
Value Function Loss: 0.00533

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12200
Policy Update Magnitude: 0.59646
Value Function Update Magnitude: 0.50735

Collected Steps per Second: 21,849.17908
Overall Steps per Second: 10,365.41174

Timestep Collection Time: 2.28942
Timestep Consumption Time: 2.53644
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.82586

Cumulative Model Updates: 118,890
Cumulative Timesteps: 991,615,538

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 991615538...
Checkpoint 991615538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 854.18152
Policy Entropy: 2.99808
Value Function Loss: 0.00513

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.10439
Policy Update Magnitude: 0.58695
Value Function Update Magnitude: 0.50430

Collected Steps per Second: 21,344.94670
Overall Steps per Second: 10,369.99127

Timestep Collection Time: 2.34360
Timestep Consumption Time: 2.48032
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.82392

Cumulative Model Updates: 118,896
Cumulative Timesteps: 991,665,562

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 784.45998
Policy Entropy: 3.00402
Value Function Loss: 0.00486

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09669
Policy Update Magnitude: 0.58809
Value Function Update Magnitude: 0.49837

Collected Steps per Second: 21,981.90825
Overall Steps per Second: 10,401.44755

Timestep Collection Time: 2.27569
Timestep Consumption Time: 2.53364
PPO Batch Consumption Time: 0.29782
Total Iteration Time: 4.80933

Cumulative Model Updates: 118,902
Cumulative Timesteps: 991,715,586

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 991715586...
Checkpoint 991715586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 920.05247
Policy Entropy: 3.01903
Value Function Loss: 0.00488

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.59048
Value Function Update Magnitude: 0.49220

Collected Steps per Second: 20,077.20042
Overall Steps per Second: 10,064.39534

Timestep Collection Time: 2.49069
Timestep Consumption Time: 2.47792
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.96860

Cumulative Model Updates: 118,908
Cumulative Timesteps: 991,765,592

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,717.95008
Policy Entropy: 3.01994
Value Function Loss: 0.00544

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09540
Policy Update Magnitude: 0.59802
Value Function Update Magnitude: 0.51877

Collected Steps per Second: 22,194.78104
Overall Steps per Second: 10,490.66648

Timestep Collection Time: 2.25314
Timestep Consumption Time: 2.51376
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.76690

Cumulative Model Updates: 118,914
Cumulative Timesteps: 991,815,600

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 991815600...
Checkpoint 991815600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,696.84881
Policy Entropy: 3.02233
Value Function Loss: 0.00553

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.10600
Policy Update Magnitude: 0.59924
Value Function Update Magnitude: 0.55081

Collected Steps per Second: 22,066.96851
Overall Steps per Second: 10,616.39025

Timestep Collection Time: 2.26628
Timestep Consumption Time: 2.44436
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.71064

Cumulative Model Updates: 118,920
Cumulative Timesteps: 991,865,610

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.70381
Policy Entropy: 3.01191
Value Function Loss: 0.00542

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12237
Policy Update Magnitude: 0.59435
Value Function Update Magnitude: 0.52865

Collected Steps per Second: 22,428.23469
Overall Steps per Second: 10,480.91317

Timestep Collection Time: 2.22978
Timestep Consumption Time: 2.54175
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.77153

Cumulative Model Updates: 118,926
Cumulative Timesteps: 991,915,620

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 991915620...
Checkpoint 991915620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,672.10981
Policy Entropy: 3.01997
Value Function Loss: 0.00516

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.58692
Value Function Update Magnitude: 0.51995

Collected Steps per Second: 22,002.97849
Overall Steps per Second: 10,567.19948

Timestep Collection Time: 2.27296
Timestep Consumption Time: 2.45979
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.73276

Cumulative Model Updates: 118,932
Cumulative Timesteps: 991,965,632

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,791.49826
Policy Entropy: 3.02104
Value Function Loss: 0.00527

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10513
Policy Update Magnitude: 0.58460
Value Function Update Magnitude: 0.49959

Collected Steps per Second: 22,427.94172
Overall Steps per Second: 10,546.80903

Timestep Collection Time: 2.23025
Timestep Consumption Time: 2.51241
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.74267

Cumulative Model Updates: 118,938
Cumulative Timesteps: 992,015,652

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 992015652...
Checkpoint 992015652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.32232
Policy Entropy: 3.02919
Value Function Loss: 0.00522

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11641
Policy Update Magnitude: 0.58532
Value Function Update Magnitude: 0.51738

Collected Steps per Second: 21,883.36548
Overall Steps per Second: 10,625.83183

Timestep Collection Time: 2.28502
Timestep Consumption Time: 2.42087
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.70589

Cumulative Model Updates: 118,944
Cumulative Timesteps: 992,065,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.44345
Policy Entropy: 3.04439
Value Function Loss: 0.00507

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10725
Policy Update Magnitude: 0.58434
Value Function Update Magnitude: 0.53917

Collected Steps per Second: 22,321.65366
Overall Steps per Second: 10,529.95903

Timestep Collection Time: 2.24114
Timestep Consumption Time: 2.50968
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.75083

Cumulative Model Updates: 118,950
Cumulative Timesteps: 992,115,682

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 992115682...
Checkpoint 992115682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.91792
Policy Entropy: 3.03931
Value Function Loss: 0.00461

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.09975
Policy Update Magnitude: 0.57451
Value Function Update Magnitude: 0.51916

Collected Steps per Second: 21,702.29703
Overall Steps per Second: 10,565.22607

Timestep Collection Time: 2.30409
Timestep Consumption Time: 2.42880
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.73289

Cumulative Model Updates: 118,956
Cumulative Timesteps: 992,165,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,452.50936
Policy Entropy: 3.02700
Value Function Loss: 0.00468

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10550
Policy Update Magnitude: 0.56563
Value Function Update Magnitude: 0.51268

Collected Steps per Second: 21,952.29537
Overall Steps per Second: 10,427.95001

Timestep Collection Time: 2.27840
Timestep Consumption Time: 2.51795
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.79634

Cumulative Model Updates: 118,962
Cumulative Timesteps: 992,215,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 992215702...
Checkpoint 992215702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,745.63449
Policy Entropy: 3.01211
Value Function Loss: 0.00473

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10288
Policy Update Magnitude: 0.56411
Value Function Update Magnitude: 0.51451

Collected Steps per Second: 21,654.98486
Overall Steps per Second: 10,376.76032

Timestep Collection Time: 2.31023
Timestep Consumption Time: 2.51093
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.82116

Cumulative Model Updates: 118,968
Cumulative Timesteps: 992,265,730

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.65444
Policy Entropy: 2.99749
Value Function Loss: 0.00507

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10277
Policy Update Magnitude: 0.57915
Value Function Update Magnitude: 0.52264

Collected Steps per Second: 21,918.34175
Overall Steps per Second: 10,390.19074

Timestep Collection Time: 2.28202
Timestep Consumption Time: 2.53195
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.81396

Cumulative Model Updates: 118,974
Cumulative Timesteps: 992,315,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 992315748...
Checkpoint 992315748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,725.36969
Policy Entropy: 2.99726
Value Function Loss: 0.00526

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10134
Policy Update Magnitude: 0.57858
Value Function Update Magnitude: 0.52500

Collected Steps per Second: 21,684.40150
Overall Steps per Second: 10,535.03100

Timestep Collection Time: 2.30599
Timestep Consumption Time: 2.44046
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.74645

Cumulative Model Updates: 118,980
Cumulative Timesteps: 992,365,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,915.18533
Policy Entropy: 3.01484
Value Function Loss: 0.00529

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10050
Policy Update Magnitude: 0.57750
Value Function Update Magnitude: 0.51987

Collected Steps per Second: 22,013.08859
Overall Steps per Second: 10,579.18567

Timestep Collection Time: 2.27228
Timestep Consumption Time: 2.45587
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.72815

Cumulative Model Updates: 118,986
Cumulative Timesteps: 992,415,772

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 992415772...
Checkpoint 992415772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.57839
Policy Entropy: 3.02044
Value Function Loss: 0.00515

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.57432
Value Function Update Magnitude: 0.51042

Collected Steps per Second: 22,123.46513
Overall Steps per Second: 10,610.29770

Timestep Collection Time: 2.26050
Timestep Consumption Time: 2.45285
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.71335

Cumulative Model Updates: 118,992
Cumulative Timesteps: 992,465,782

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.13717
Policy Entropy: 3.02132
Value Function Loss: 0.00510

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.12295
Policy Update Magnitude: 0.58210
Value Function Update Magnitude: 0.51221

Collected Steps per Second: 22,333.83482
Overall Steps per Second: 10,564.84526

Timestep Collection Time: 2.23893
Timestep Consumption Time: 2.49412
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.73306

Cumulative Model Updates: 118,998
Cumulative Timesteps: 992,515,786

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 992515786...
Checkpoint 992515786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,339.02413
Policy Entropy: 3.02168
Value Function Loss: 0.00522

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12496
Policy Update Magnitude: 0.58827
Value Function Update Magnitude: 0.51150

Collected Steps per Second: 22,280.39217
Overall Steps per Second: 10,495.30652

Timestep Collection Time: 2.24431
Timestep Consumption Time: 2.52011
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.76442

Cumulative Model Updates: 119,004
Cumulative Timesteps: 992,565,790

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.45551
Policy Entropy: 3.02659
Value Function Loss: 0.00524

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.11588
Policy Update Magnitude: 0.58612
Value Function Update Magnitude: 0.53758

Collected Steps per Second: 22,372.29902
Overall Steps per Second: 10,565.21292

Timestep Collection Time: 2.23625
Timestep Consumption Time: 2.49910
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.73535

Cumulative Model Updates: 119,010
Cumulative Timesteps: 992,615,820

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 992615820...
Checkpoint 992615820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,720.72836
Policy Entropy: 3.03363
Value Function Loss: 0.00522

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.57846
Value Function Update Magnitude: 0.54954

Collected Steps per Second: 22,364.78430
Overall Steps per Second: 10,587.64702

Timestep Collection Time: 2.23566
Timestep Consumption Time: 2.48683
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.72248

Cumulative Model Updates: 119,016
Cumulative Timesteps: 992,665,820

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,673.47897
Policy Entropy: 3.03173
Value Function Loss: 0.00506

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.11571
Policy Update Magnitude: 0.57768
Value Function Update Magnitude: 0.52757

Collected Steps per Second: 22,258.36494
Overall Steps per Second: 10,462.19734

Timestep Collection Time: 2.24653
Timestep Consumption Time: 2.53297
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.77949

Cumulative Model Updates: 119,022
Cumulative Timesteps: 992,715,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 992715824...
Checkpoint 992715824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,013.43530
Policy Entropy: 3.03405
Value Function Loss: 0.00497

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10736
Policy Update Magnitude: 0.56548
Value Function Update Magnitude: 0.50772

Collected Steps per Second: 22,221.02347
Overall Steps per Second: 10,670.26268

Timestep Collection Time: 2.25048
Timestep Consumption Time: 2.43619
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.68667

Cumulative Model Updates: 119,028
Cumulative Timesteps: 992,765,832

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,575.82482
Policy Entropy: 3.01395
Value Function Loss: 0.00481

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.55861
Value Function Update Magnitude: 0.49204

Collected Steps per Second: 22,109.31748
Overall Steps per Second: 10,536.24325

Timestep Collection Time: 2.26212
Timestep Consumption Time: 2.48473
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.74685

Cumulative Model Updates: 119,034
Cumulative Timesteps: 992,815,846

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 992815846...
Checkpoint 992815846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,592.97253
Policy Entropy: 2.99990
Value Function Loss: 0.00480

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09096
Policy Update Magnitude: 0.56699
Value Function Update Magnitude: 0.49814

Collected Steps per Second: 21,621.47675
Overall Steps per Second: 10,432.63894

Timestep Collection Time: 2.31335
Timestep Consumption Time: 2.48103
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.79438

Cumulative Model Updates: 119,040
Cumulative Timesteps: 992,865,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,708.51089
Policy Entropy: 2.98137
Value Function Loss: 0.00466

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.57355
Value Function Update Magnitude: 0.50403

Collected Steps per Second: 21,704.37591
Overall Steps per Second: 10,590.89359

Timestep Collection Time: 2.30424
Timestep Consumption Time: 2.41793
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.72217

Cumulative Model Updates: 119,046
Cumulative Timesteps: 992,915,876

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 992915876...
Checkpoint 992915876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,719.91556
Policy Entropy: 2.97820
Value Function Loss: 0.00465

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09370
Policy Update Magnitude: 0.56539
Value Function Update Magnitude: 0.49340

Collected Steps per Second: 21,585.51351
Overall Steps per Second: 10,520.61585

Timestep Collection Time: 2.31665
Timestep Consumption Time: 2.43650
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.75314

Cumulative Model Updates: 119,052
Cumulative Timesteps: 992,965,882

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507.97528
Policy Entropy: 2.98792
Value Function Loss: 0.00467

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.56156
Value Function Update Magnitude: 0.47018

Collected Steps per Second: 21,683.58201
Overall Steps per Second: 10,459.97236

Timestep Collection Time: 2.30672
Timestep Consumption Time: 2.47513
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.78185

Cumulative Model Updates: 119,058
Cumulative Timesteps: 993,015,900

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 993015900...
Checkpoint 993015900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.24380
Policy Entropy: 3.00047
Value Function Loss: 0.00482

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09779
Policy Update Magnitude: 0.56147
Value Function Update Magnitude: 0.46476

Collected Steps per Second: 21,830.32990
Overall Steps per Second: 10,521.49323

Timestep Collection Time: 2.29094
Timestep Consumption Time: 2.46238
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.75332

Cumulative Model Updates: 119,064
Cumulative Timesteps: 993,065,912

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.75409
Policy Entropy: 3.03037
Value Function Loss: 0.00502

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09256
Policy Update Magnitude: 0.57221
Value Function Update Magnitude: 0.47721

Collected Steps per Second: 21,829.47196
Overall Steps per Second: 10,532.19159

Timestep Collection Time: 2.29085
Timestep Consumption Time: 2.45726
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.74811

Cumulative Model Updates: 119,070
Cumulative Timesteps: 993,115,920

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 993115920...
Checkpoint 993115920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.36434
Policy Entropy: 3.01507
Value Function Loss: 0.00494

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09228
Policy Update Magnitude: 0.57678
Value Function Update Magnitude: 0.49529

Collected Steps per Second: 22,123.46331
Overall Steps per Second: 10,630.13388

Timestep Collection Time: 2.26122
Timestep Consumption Time: 2.44484
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.70606

Cumulative Model Updates: 119,076
Cumulative Timesteps: 993,165,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.27880
Policy Entropy: 3.02543
Value Function Loss: 0.00500

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09222
Policy Update Magnitude: 0.57934
Value Function Update Magnitude: 0.49862

Collected Steps per Second: 22,404.78404
Overall Steps per Second: 10,572.58536

Timestep Collection Time: 2.23176
Timestep Consumption Time: 2.49765
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.72940

Cumulative Model Updates: 119,082
Cumulative Timesteps: 993,215,948

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 993215948...
Checkpoint 993215948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655.79503
Policy Entropy: 3.02938
Value Function Loss: 0.00487

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08842
Policy Update Magnitude: 0.56778
Value Function Update Magnitude: 0.50273

Collected Steps per Second: 22,141.04479
Overall Steps per Second: 10,499.41283

Timestep Collection Time: 2.25870
Timestep Consumption Time: 2.50442
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.76312

Cumulative Model Updates: 119,088
Cumulative Timesteps: 993,265,958

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,070.62298
Policy Entropy: 3.04277
Value Function Loss: 0.00459

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08737
Policy Update Magnitude: 0.55467
Value Function Update Magnitude: 0.49978

Collected Steps per Second: 21,883.13794
Overall Steps per Second: 10,420.65505

Timestep Collection Time: 2.28605
Timestep Consumption Time: 2.51461
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.80066

Cumulative Model Updates: 119,094
Cumulative Timesteps: 993,315,984

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 993315984...
Checkpoint 993315984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.81769
Policy Entropy: 3.03265
Value Function Loss: 0.00468

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10820
Policy Update Magnitude: 0.55754
Value Function Update Magnitude: 0.48381

Collected Steps per Second: 21,988.43320
Overall Steps per Second: 10,443.89061

Timestep Collection Time: 2.27565
Timestep Consumption Time: 2.51548
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.79113

Cumulative Model Updates: 119,100
Cumulative Timesteps: 993,366,022

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,568.58145
Policy Entropy: 3.02334
Value Function Loss: 0.00471

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10173
Policy Update Magnitude: 0.55887
Value Function Update Magnitude: 0.48007

Collected Steps per Second: 22,227.81843
Overall Steps per Second: 10,707.57001

Timestep Collection Time: 2.25033
Timestep Consumption Time: 2.42113
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.67146

Cumulative Model Updates: 119,106
Cumulative Timesteps: 993,416,042

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 993416042...
Checkpoint 993416042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.89766
Policy Entropy: 3.02055
Value Function Loss: 0.00516

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10302
Policy Update Magnitude: 0.56933
Value Function Update Magnitude: 0.48917

Collected Steps per Second: 21,718.20342
Overall Steps per Second: 10,383.33102

Timestep Collection Time: 2.30231
Timestep Consumption Time: 2.51329
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.81560

Cumulative Model Updates: 119,112
Cumulative Timesteps: 993,466,044

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.25392
Policy Entropy: 3.02943
Value Function Loss: 0.00540

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09300
Policy Update Magnitude: 0.58037
Value Function Update Magnitude: 0.50380

Collected Steps per Second: 22,084.80078
Overall Steps per Second: 10,616.27283

Timestep Collection Time: 2.26445
Timestep Consumption Time: 2.44624
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.71069

Cumulative Model Updates: 119,118
Cumulative Timesteps: 993,516,054

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 993516054...
Checkpoint 993516054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,155.74300
Policy Entropy: 3.01897
Value Function Loss: 0.00537

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11041
Policy Update Magnitude: 0.58805
Value Function Update Magnitude: 0.52456

Collected Steps per Second: 21,688.90287
Overall Steps per Second: 10,337.07230

Timestep Collection Time: 2.30616
Timestep Consumption Time: 2.53254
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.83870

Cumulative Model Updates: 119,124
Cumulative Timesteps: 993,566,072

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.39929
Policy Entropy: 3.01904
Value Function Loss: 0.00514

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10652
Policy Update Magnitude: 0.58178
Value Function Update Magnitude: 0.53238

Collected Steps per Second: 21,978.07605
Overall Steps per Second: 10,484.68137

Timestep Collection Time: 2.27627
Timestep Consumption Time: 2.49526
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.77153

Cumulative Model Updates: 119,130
Cumulative Timesteps: 993,616,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 993616100...
Checkpoint 993616100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,773.54177
Policy Entropy: 3.00939
Value Function Loss: 0.00506

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09768
Policy Update Magnitude: 0.58588
Value Function Update Magnitude: 0.52116

Collected Steps per Second: 21,567.22496
Overall Steps per Second: 10,316.30507

Timestep Collection Time: 2.31843
Timestep Consumption Time: 2.52847
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.84689

Cumulative Model Updates: 119,136
Cumulative Timesteps: 993,666,102

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,427.49152
Policy Entropy: 3.02673
Value Function Loss: 0.00497

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.58157
Value Function Update Magnitude: 0.52533

Collected Steps per Second: 22,565.09251
Overall Steps per Second: 10,687.73523

Timestep Collection Time: 2.21696
Timestep Consumption Time: 2.46373
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.68069

Cumulative Model Updates: 119,142
Cumulative Timesteps: 993,716,128

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 993716128...
Checkpoint 993716128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,750.68267
Policy Entropy: 3.03308
Value Function Loss: 0.00498

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09822
Policy Update Magnitude: 0.57653
Value Function Update Magnitude: 0.52756

Collected Steps per Second: 22,160.57496
Overall Steps per Second: 10,614.08103

Timestep Collection Time: 2.25653
Timestep Consumption Time: 2.45476
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.71129

Cumulative Model Updates: 119,148
Cumulative Timesteps: 993,766,134

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450.13979
Policy Entropy: 3.03302
Value Function Loss: 0.00489

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09179
Policy Update Magnitude: 0.57686
Value Function Update Magnitude: 0.53364

Collected Steps per Second: 22,576.49510
Overall Steps per Second: 10,526.53892

Timestep Collection Time: 2.21505
Timestep Consumption Time: 2.53561
PPO Batch Consumption Time: 0.29492
Total Iteration Time: 4.75066

Cumulative Model Updates: 119,154
Cumulative Timesteps: 993,816,142

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 993816142...
Checkpoint 993816142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.81910
Policy Entropy: 3.02641
Value Function Loss: 0.00479

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09285
Policy Update Magnitude: 0.57214
Value Function Update Magnitude: 0.54013

Collected Steps per Second: 21,851.10650
Overall Steps per Second: 10,561.89742

Timestep Collection Time: 2.28840
Timestep Consumption Time: 2.44598
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.73438

Cumulative Model Updates: 119,160
Cumulative Timesteps: 993,866,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451.60441
Policy Entropy: 3.03835
Value Function Loss: 0.00484

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10436
Policy Update Magnitude: 0.57477
Value Function Update Magnitude: 0.52265

Collected Steps per Second: 22,137.08549
Overall Steps per Second: 10,497.12789

Timestep Collection Time: 2.25974
Timestep Consumption Time: 2.50576
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.76549

Cumulative Model Updates: 119,166
Cumulative Timesteps: 993,916,170

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 993916170...
Checkpoint 993916170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.15121
Policy Entropy: 3.02461
Value Function Loss: 0.00517

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10418
Policy Update Magnitude: 0.58376
Value Function Update Magnitude: 0.52164

Collected Steps per Second: 22,100.65355
Overall Steps per Second: 10,656.34013

Timestep Collection Time: 2.26301
Timestep Consumption Time: 2.43035
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.69336

Cumulative Model Updates: 119,172
Cumulative Timesteps: 993,966,184

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.96977
Policy Entropy: 3.02117
Value Function Loss: 0.00509

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.09820
Policy Update Magnitude: 0.59177
Value Function Update Magnitude: 0.53694

Collected Steps per Second: 21,987.84538
Overall Steps per Second: 10,479.00993

Timestep Collection Time: 2.27535
Timestep Consumption Time: 2.49896
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.77431

Cumulative Model Updates: 119,178
Cumulative Timesteps: 994,016,214

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 994016214...
Checkpoint 994016214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.13649
Policy Entropy: 3.00826
Value Function Loss: 0.00503

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11481
Policy Update Magnitude: 0.58828
Value Function Update Magnitude: 0.53705

Collected Steps per Second: 21,426.78484
Overall Steps per Second: 10,327.10581

Timestep Collection Time: 2.33446
Timestep Consumption Time: 2.50910
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.84356

Cumulative Model Updates: 119,184
Cumulative Timesteps: 994,066,234

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.91139
Policy Entropy: 3.01890
Value Function Loss: 0.00484

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11296
Policy Update Magnitude: 0.58363
Value Function Update Magnitude: 0.52636

Collected Steps per Second: 22,013.22959
Overall Steps per Second: 10,533.83364

Timestep Collection Time: 2.27236
Timestep Consumption Time: 2.47634
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.74870

Cumulative Model Updates: 119,190
Cumulative Timesteps: 994,116,256

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 994116256...
Checkpoint 994116256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.62753
Policy Entropy: 3.02122
Value Function Loss: 0.00485

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10531
Policy Update Magnitude: 0.57381
Value Function Update Magnitude: 0.51307

Collected Steps per Second: 21,548.93281
Overall Steps per Second: 10,464.74534

Timestep Collection Time: 2.32169
Timestep Consumption Time: 2.45912
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.78081

Cumulative Model Updates: 119,196
Cumulative Timesteps: 994,166,286

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,745.60389
Policy Entropy: 3.03265
Value Function Loss: 0.00496

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10200
Policy Update Magnitude: 0.56987
Value Function Update Magnitude: 0.51920

Collected Steps per Second: 21,191.94457
Overall Steps per Second: 10,340.90953

Timestep Collection Time: 2.36043
Timestep Consumption Time: 2.47687
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.83729

Cumulative Model Updates: 119,202
Cumulative Timesteps: 994,216,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 994216308...
Checkpoint 994216308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,849.07203
Policy Entropy: 3.03020
Value Function Loss: 0.00515

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10093
Policy Update Magnitude: 0.57354
Value Function Update Magnitude: 0.53222

Collected Steps per Second: 21,898.60081
Overall Steps per Second: 10,345.24922

Timestep Collection Time: 2.28416
Timestep Consumption Time: 2.55091
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.83507

Cumulative Model Updates: 119,208
Cumulative Timesteps: 994,266,328

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.99803
Policy Entropy: 3.02996
Value Function Loss: 0.00503

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10774
Policy Update Magnitude: 0.57622
Value Function Update Magnitude: 0.52740

Collected Steps per Second: 22,383.35256
Overall Steps per Second: 10,709.96482

Timestep Collection Time: 2.23398
Timestep Consumption Time: 2.43494
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.66892

Cumulative Model Updates: 119,214
Cumulative Timesteps: 994,316,332

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 994316332...
Checkpoint 994316332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,484.45060
Policy Entropy: 3.02742
Value Function Loss: 0.00499

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09823
Policy Update Magnitude: 0.57913
Value Function Update Magnitude: 0.52801

Collected Steps per Second: 21,614.09432
Overall Steps per Second: 10,318.23637

Timestep Collection Time: 2.31460
Timestep Consumption Time: 2.53390
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.84850

Cumulative Model Updates: 119,220
Cumulative Timesteps: 994,366,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,363.19559
Policy Entropy: 3.03653
Value Function Loss: 0.00477

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09053
Policy Update Magnitude: 0.57202
Value Function Update Magnitude: 0.52615

Collected Steps per Second: 22,374.44567
Overall Steps per Second: 10,466.11212

Timestep Collection Time: 2.23568
Timestep Consumption Time: 2.54375
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.77943

Cumulative Model Updates: 119,226
Cumulative Timesteps: 994,416,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 994416382...
Checkpoint 994416382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,963.88444
Policy Entropy: 3.04006
Value Function Loss: 0.00464

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09720
Policy Update Magnitude: 0.56938
Value Function Update Magnitude: 0.51286

Collected Steps per Second: 22,027.69940
Overall Steps per Second: 10,610.05122

Timestep Collection Time: 2.27096
Timestep Consumption Time: 2.44382
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.71477

Cumulative Model Updates: 119,232
Cumulative Timesteps: 994,466,406

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,547.71352
Policy Entropy: 3.04299
Value Function Loss: 0.00447

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09074
Policy Update Magnitude: 0.55708
Value Function Update Magnitude: 0.49541

Collected Steps per Second: 22,364.82484
Overall Steps per Second: 10,457.49775

Timestep Collection Time: 2.23583
Timestep Consumption Time: 2.54581
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.78164

Cumulative Model Updates: 119,238
Cumulative Timesteps: 994,516,410

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 994516410...
Checkpoint 994516410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,376.32937
Policy Entropy: 3.04076
Value Function Loss: 0.00434

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09493
Policy Update Magnitude: 0.54914
Value Function Update Magnitude: 0.49702

Collected Steps per Second: 22,129.90368
Overall Steps per Second: 10,621.22848

Timestep Collection Time: 2.26029
Timestep Consumption Time: 2.44915
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.70944

Cumulative Model Updates: 119,244
Cumulative Timesteps: 994,566,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,336.52376
Policy Entropy: 3.03557
Value Function Loss: 0.00436

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08734
Policy Update Magnitude: 0.54889
Value Function Update Magnitude: 0.50505

Collected Steps per Second: 21,866.17919
Overall Steps per Second: 10,532.09929

Timestep Collection Time: 2.28728
Timestep Consumption Time: 2.46144
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.74872

Cumulative Model Updates: 119,250
Cumulative Timesteps: 994,616,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 994616444...
Checkpoint 994616444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,474.01253
Policy Entropy: 3.04324
Value Function Loss: 0.00469

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.56550
Value Function Update Magnitude: 0.52302

Collected Steps per Second: 21,779.54614
Overall Steps per Second: 10,603.00257

Timestep Collection Time: 2.29619
Timestep Consumption Time: 2.42040
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.71659

Cumulative Model Updates: 119,256
Cumulative Timesteps: 994,666,454

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,491.95416
Policy Entropy: 3.03923
Value Function Loss: 0.00511

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10547
Policy Update Magnitude: 0.58117
Value Function Update Magnitude: 0.54002

Collected Steps per Second: 22,212.42408
Overall Steps per Second: 10,519.07623

Timestep Collection Time: 2.25099
Timestep Consumption Time: 2.50228
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.75327

Cumulative Model Updates: 119,262
Cumulative Timesteps: 994,716,454

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 994716454...
Checkpoint 994716454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.79716
Policy Entropy: 3.03087
Value Function Loss: 0.00506

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10321
Policy Update Magnitude: 0.57975
Value Function Update Magnitude: 0.54314

Collected Steps per Second: 20,621.58136
Overall Steps per Second: 10,117.59186

Timestep Collection Time: 2.42474
Timestep Consumption Time: 2.51734
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.94209

Cumulative Model Updates: 119,268
Cumulative Timesteps: 994,766,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,607.49480
Policy Entropy: 3.01203
Value Function Loss: 0.00519

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.10740
Policy Update Magnitude: 0.57162
Value Function Update Magnitude: 0.52072

Collected Steps per Second: 22,183.17549
Overall Steps per Second: 10,562.27821

Timestep Collection Time: 2.25513
Timestep Consumption Time: 2.48116
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.73629

Cumulative Model Updates: 119,274
Cumulative Timesteps: 994,816,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 994816482...
Checkpoint 994816482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416.38141
Policy Entropy: 3.01049
Value Function Loss: 0.00501

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10805
Policy Update Magnitude: 0.56735
Value Function Update Magnitude: 0.51536

Collected Steps per Second: 22,064.02865
Overall Steps per Second: 10,566.08448

Timestep Collection Time: 2.26686
Timestep Consumption Time: 2.46678
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.73364

Cumulative Model Updates: 119,280
Cumulative Timesteps: 994,866,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,621.92397
Policy Entropy: 3.01515
Value Function Loss: 0.00498

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10754
Policy Update Magnitude: 0.57356
Value Function Update Magnitude: 0.53224

Collected Steps per Second: 22,488.00803
Overall Steps per Second: 10,439.99592

Timestep Collection Time: 2.22403
Timestep Consumption Time: 2.56659
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.79061

Cumulative Model Updates: 119,286
Cumulative Timesteps: 994,916,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 994916512...
Checkpoint 994916512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,829.84029
Policy Entropy: 3.01596
Value Function Loss: 0.00465

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.57100
Value Function Update Magnitude: 0.54621

Collected Steps per Second: 22,059.55745
Overall Steps per Second: 10,583.73687

Timestep Collection Time: 2.26723
Timestep Consumption Time: 2.45833
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.72555

Cumulative Model Updates: 119,292
Cumulative Timesteps: 994,966,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,412.39558
Policy Entropy: 3.03046
Value Function Loss: 0.00488

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.12724
Policy Update Magnitude: 0.57000
Value Function Update Magnitude: 0.54168

Collected Steps per Second: 22,622.35768
Overall Steps per Second: 10,533.95387

Timestep Collection Time: 2.21047
Timestep Consumption Time: 2.53666
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 4.74713

Cumulative Model Updates: 119,298
Cumulative Timesteps: 995,016,532

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 995016532...
Checkpoint 995016532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,964.49705
Policy Entropy: 3.03195
Value Function Loss: 0.00516

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13048
Policy Update Magnitude: 0.57055
Value Function Update Magnitude: 0.55490

Collected Steps per Second: 22,036.42314
Overall Steps per Second: 10,592.94125

Timestep Collection Time: 2.26979
Timestep Consumption Time: 2.45204
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.72182

Cumulative Model Updates: 119,304
Cumulative Timesteps: 995,066,550

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,079.46306
Policy Entropy: 3.04592
Value Function Loss: 0.00495

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.12178
Policy Update Magnitude: 0.57384
Value Function Update Magnitude: 0.55600

Collected Steps per Second: 22,417.79708
Overall Steps per Second: 10,555.51390

Timestep Collection Time: 2.23037
Timestep Consumption Time: 2.50649
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.73686

Cumulative Model Updates: 119,310
Cumulative Timesteps: 995,116,550

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 995116550...
Checkpoint 995116550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,180.08259
Policy Entropy: 3.03388
Value Function Loss: 0.00478

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.11804
Policy Update Magnitude: 0.56075
Value Function Update Magnitude: 0.52689

Collected Steps per Second: 21,796.18156
Overall Steps per Second: 10,529.02278

Timestep Collection Time: 2.29508
Timestep Consumption Time: 2.45598
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.75106

Cumulative Model Updates: 119,316
Cumulative Timesteps: 995,166,574

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.87578
Policy Entropy: 3.04694
Value Function Loss: 0.00490

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.12194
Policy Update Magnitude: 0.57519
Value Function Update Magnitude: 0.52180

Collected Steps per Second: 22,044.68265
Overall Steps per Second: 10,523.81031

Timestep Collection Time: 2.26939
Timestep Consumption Time: 2.48440
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.75379

Cumulative Model Updates: 119,322
Cumulative Timesteps: 995,216,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 995216602...
Checkpoint 995216602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464.76042
Policy Entropy: 3.03727
Value Function Loss: 0.00489

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.12564
Policy Update Magnitude: 0.57321
Value Function Update Magnitude: 0.53669

Collected Steps per Second: 21,560.44194
Overall Steps per Second: 10,568.00291

Timestep Collection Time: 2.32036
Timestep Consumption Time: 2.41355
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.73391

Cumulative Model Updates: 119,328
Cumulative Timesteps: 995,266,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.02229
Policy Entropy: 3.04663
Value Function Loss: 0.00522

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.13580
Policy Update Magnitude: 0.57542
Value Function Update Magnitude: 0.53405

Collected Steps per Second: 22,238.26710
Overall Steps per Second: 10,529.80462

Timestep Collection Time: 2.25036
Timestep Consumption Time: 2.50225
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.75260

Cumulative Model Updates: 119,334
Cumulative Timesteps: 995,316,674

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 995316674...
Checkpoint 995316674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,757.34093
Policy Entropy: 3.03530
Value Function Loss: 0.00517

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.13815
Policy Update Magnitude: 0.57858
Value Function Update Magnitude: 0.56207

Collected Steps per Second: 21,571.59338
Overall Steps per Second: 10,362.19200

Timestep Collection Time: 2.31796
Timestep Consumption Time: 2.50747
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.82543

Cumulative Model Updates: 119,340
Cumulative Timesteps: 995,366,676

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728.00578
Policy Entropy: 3.04364
Value Function Loss: 0.00498

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.12145
Policy Update Magnitude: 0.57700
Value Function Update Magnitude: 0.56630

Collected Steps per Second: 22,231.42072
Overall Steps per Second: 10,485.84734

Timestep Collection Time: 2.24916
Timestep Consumption Time: 2.51936
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.76852

Cumulative Model Updates: 119,346
Cumulative Timesteps: 995,416,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 995416678...
Checkpoint 995416678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,000.41911
Policy Entropy: 3.05197
Value Function Loss: 0.00484

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.10950
Policy Update Magnitude: 0.57429
Value Function Update Magnitude: 0.53291

Collected Steps per Second: 21,979.30539
Overall Steps per Second: 10,520.02448

Timestep Collection Time: 2.27587
Timestep Consumption Time: 2.47906
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.75493

Cumulative Model Updates: 119,352
Cumulative Timesteps: 995,466,700

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372.52418
Policy Entropy: 3.05819
Value Function Loss: 0.00503

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.12679
Policy Update Magnitude: 0.57266
Value Function Update Magnitude: 0.52013

Collected Steps per Second: 22,211.58917
Overall Steps per Second: 10,456.70033

Timestep Collection Time: 2.25189
Timestep Consumption Time: 2.53146
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.78334

Cumulative Model Updates: 119,358
Cumulative Timesteps: 995,516,718

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 995516718...
Checkpoint 995516718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,721.16577
Policy Entropy: 3.04120
Value Function Loss: 0.00498

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.13612
Policy Update Magnitude: 0.56485
Value Function Update Magnitude: 0.50523

Collected Steps per Second: 21,285.84023
Overall Steps per Second: 10,478.68205

Timestep Collection Time: 2.35011
Timestep Consumption Time: 2.42378
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.77388

Cumulative Model Updates: 119,364
Cumulative Timesteps: 995,566,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.93337
Policy Entropy: 3.03559
Value Function Loss: 0.00499

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.13349
Policy Update Magnitude: 0.56740
Value Function Update Magnitude: 0.50361

Collected Steps per Second: 22,477.34508
Overall Steps per Second: 10,555.20394

Timestep Collection Time: 2.22446
Timestep Consumption Time: 2.51254
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.73700

Cumulative Model Updates: 119,370
Cumulative Timesteps: 995,616,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 995616742...
Checkpoint 995616742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,651.09019
Policy Entropy: 3.04298
Value Function Loss: 0.00493

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.12509
Policy Update Magnitude: 0.58493
Value Function Update Magnitude: 0.50561

Collected Steps per Second: 22,161.11656
Overall Steps per Second: 10,626.23134

Timestep Collection Time: 2.25657
Timestep Consumption Time: 2.44952
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.70609

Cumulative Model Updates: 119,376
Cumulative Timesteps: 995,666,750

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,648.35152
Policy Entropy: 3.05901
Value Function Loss: 0.00502

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11579
Policy Update Magnitude: 0.58333
Value Function Update Magnitude: 0.51971

Collected Steps per Second: 22,518.10212
Overall Steps per Second: 10,632.12141

Timestep Collection Time: 2.22097
Timestep Consumption Time: 2.48289
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.70386

Cumulative Model Updates: 119,382
Cumulative Timesteps: 995,716,762

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 995716762...
Checkpoint 995716762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,075.62141
Policy Entropy: 3.04577
Value Function Loss: 0.00523

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10338
Policy Update Magnitude: 0.57286
Value Function Update Magnitude: 0.51360

Collected Steps per Second: 22,021.49698
Overall Steps per Second: 10,490.01734

Timestep Collection Time: 2.27105
Timestep Consumption Time: 2.49653
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.76758

Cumulative Model Updates: 119,388
Cumulative Timesteps: 995,766,774

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,611.18589
Policy Entropy: 3.04301
Value Function Loss: 0.00492

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.57012
Value Function Update Magnitude: 0.51315

Collected Steps per Second: 22,021.93169
Overall Steps per Second: 10,496.57600

Timestep Collection Time: 2.27164
Timestep Consumption Time: 2.49429
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.76594

Cumulative Model Updates: 119,394
Cumulative Timesteps: 995,816,800

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 995816800...
Checkpoint 995816800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,059.83967
Policy Entropy: 3.04064
Value Function Loss: 0.00491

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10087
Policy Update Magnitude: 0.56600
Value Function Update Magnitude: 0.49325

Collected Steps per Second: 21,635.13648
Overall Steps per Second: 10,535.01585

Timestep Collection Time: 2.31161
Timestep Consumption Time: 2.43561
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.74722

Cumulative Model Updates: 119,400
Cumulative Timesteps: 995,866,812

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,137.61617
Policy Entropy: 3.05506
Value Function Loss: 0.00449

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.54953
Value Function Update Magnitude: 0.48686

Collected Steps per Second: 21,937.31177
Overall Steps per Second: 10,570.93576

Timestep Collection Time: 2.28050
Timestep Consumption Time: 2.45210
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.73260

Cumulative Model Updates: 119,406
Cumulative Timesteps: 995,916,840

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 995916840...
Checkpoint 995916840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,745.88554
Policy Entropy: 3.07063
Value Function Loss: 0.00457

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09687
Policy Update Magnitude: 0.53726
Value Function Update Magnitude: 0.49072

Collected Steps per Second: 21,785.88992
Overall Steps per Second: 10,515.14323

Timestep Collection Time: 2.29635
Timestep Consumption Time: 2.46136
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.75771

Cumulative Model Updates: 119,412
Cumulative Timesteps: 995,966,868

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,718.83866
Policy Entropy: 3.07261
Value Function Loss: 0.00464

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09945
Policy Update Magnitude: 0.53705
Value Function Update Magnitude: 0.49171

Collected Steps per Second: 22,281.48669
Overall Steps per Second: 10,519.07101

Timestep Collection Time: 2.24500
Timestep Consumption Time: 2.51036
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.75536

Cumulative Model Updates: 119,418
Cumulative Timesteps: 996,016,890

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 996016890...
Checkpoint 996016890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,723.80082
Policy Entropy: 3.06152
Value Function Loss: 0.00457

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09444
Policy Update Magnitude: 0.53948
Value Function Update Magnitude: 0.50663

Collected Steps per Second: 21,887.30518
Overall Steps per Second: 10,562.94902

Timestep Collection Time: 2.28580
Timestep Consumption Time: 2.45057
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.73637

Cumulative Model Updates: 119,424
Cumulative Timesteps: 996,066,920

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,943.38148
Policy Entropy: 3.04245
Value Function Loss: 0.00484

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09967
Policy Update Magnitude: 0.55139
Value Function Update Magnitude: 0.51138

Collected Steps per Second: 22,297.12542
Overall Steps per Second: 10,544.39063

Timestep Collection Time: 2.24352
Timestep Consumption Time: 2.50062
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.74413

Cumulative Model Updates: 119,430
Cumulative Timesteps: 996,116,944

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 996116944...
Checkpoint 996116944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.28480
Policy Entropy: 3.05044
Value Function Loss: 0.00450

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09108
Policy Update Magnitude: 0.55764
Value Function Update Magnitude: 0.52321

Collected Steps per Second: 21,890.92110
Overall Steps per Second: 10,574.84324

Timestep Collection Time: 2.28478
Timestep Consumption Time: 2.44493
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.72972

Cumulative Model Updates: 119,436
Cumulative Timesteps: 996,166,960

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 920.13569
Policy Entropy: 3.05113
Value Function Loss: 0.00469

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08792
Policy Update Magnitude: 0.56009
Value Function Update Magnitude: 0.51277

Collected Steps per Second: 22,111.05850
Overall Steps per Second: 10,569.70811

Timestep Collection Time: 2.26267
Timestep Consumption Time: 2.47067
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.73334

Cumulative Model Updates: 119,442
Cumulative Timesteps: 996,216,990

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 996216990...
Checkpoint 996216990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,400.83684
Policy Entropy: 3.06403
Value Function Loss: 0.00470

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08906
Policy Update Magnitude: 0.55246
Value Function Update Magnitude: 0.51085

Collected Steps per Second: 22,366.57117
Overall Steps per Second: 10,589.77145

Timestep Collection Time: 2.23691
Timestep Consumption Time: 2.48765
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.72456

Cumulative Model Updates: 119,448
Cumulative Timesteps: 996,267,022

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,827.67397
Policy Entropy: 3.05294
Value Function Loss: 0.00497

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10239
Policy Update Magnitude: 0.55084
Value Function Update Magnitude: 0.52380

Collected Steps per Second: 22,228.74431
Overall Steps per Second: 10,520.16815

Timestep Collection Time: 2.24979
Timestep Consumption Time: 2.50394
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.75373

Cumulative Model Updates: 119,454
Cumulative Timesteps: 996,317,032

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 996317032...
Checkpoint 996317032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,460.68219
Policy Entropy: 3.05487
Value Function Loss: 0.00500

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10022
Policy Update Magnitude: 0.55560
Value Function Update Magnitude: 0.53833

Collected Steps per Second: 21,810.88152
Overall Steps per Second: 10,522.51773

Timestep Collection Time: 2.29271
Timestep Consumption Time: 2.45958
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.75228

Cumulative Model Updates: 119,460
Cumulative Timesteps: 996,367,038

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,410.99363
Policy Entropy: 3.03813
Value Function Loss: 0.00517

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09348
Policy Update Magnitude: 0.56616
Value Function Update Magnitude: 0.55654

Collected Steps per Second: 21,739.03124
Overall Steps per Second: 10,508.31909

Timestep Collection Time: 2.30102
Timestep Consumption Time: 2.45921
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.76023

Cumulative Model Updates: 119,466
Cumulative Timesteps: 996,417,060

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 996417060...
Checkpoint 996417060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.07703
Policy Entropy: 3.03128
Value Function Loss: 0.00526

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10164
Policy Update Magnitude: 0.57912
Value Function Update Magnitude: 0.58546

Collected Steps per Second: 21,904.20912
Overall Steps per Second: 10,599.89449

Timestep Collection Time: 2.28404
Timestep Consumption Time: 2.43582
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.71986

Cumulative Model Updates: 119,472
Cumulative Timesteps: 996,467,090

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.64916
Policy Entropy: 3.03563
Value Function Loss: 0.00520

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10381
Policy Update Magnitude: 0.58171
Value Function Update Magnitude: 0.57948

Collected Steps per Second: 21,869.17101
Overall Steps per Second: 10,545.66268

Timestep Collection Time: 2.28733
Timestep Consumption Time: 2.45604
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.74337

Cumulative Model Updates: 119,478
Cumulative Timesteps: 996,517,112

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 996517112...
Checkpoint 996517112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,961.63823
Policy Entropy: 3.03770
Value Function Loss: 0.00503

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09090
Policy Update Magnitude: 0.57865
Value Function Update Magnitude: 0.57767

Collected Steps per Second: 21,833.68279
Overall Steps per Second: 10,591.18737

Timestep Collection Time: 2.29105
Timestep Consumption Time: 2.43194
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.72298

Cumulative Model Updates: 119,484
Cumulative Timesteps: 996,567,134

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.80899
Policy Entropy: 3.04781
Value Function Loss: 0.00507

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09573
Policy Update Magnitude: 0.58198
Value Function Update Magnitude: 0.57332

Collected Steps per Second: 22,480.82886
Overall Steps per Second: 10,485.31961

Timestep Collection Time: 2.22483
Timestep Consumption Time: 2.54527
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.77010

Cumulative Model Updates: 119,490
Cumulative Timesteps: 996,617,150

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 996617150...
Checkpoint 996617150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,704.27685
Policy Entropy: 3.03047
Value Function Loss: 0.00493

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10500
Policy Update Magnitude: 0.57802
Value Function Update Magnitude: 0.57421

Collected Steps per Second: 20,983.07683
Overall Steps per Second: 10,255.53627

Timestep Collection Time: 2.38316
Timestep Consumption Time: 2.49284
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.87600

Cumulative Model Updates: 119,496
Cumulative Timesteps: 996,667,156

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,830.60575
Policy Entropy: 3.01944
Value Function Loss: 0.00483

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10504
Policy Update Magnitude: 0.56982
Value Function Update Magnitude: 0.55230

Collected Steps per Second: 21,689.19266
Overall Steps per Second: 10,378.93315

Timestep Collection Time: 2.30622
Timestep Consumption Time: 2.51316
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.81938

Cumulative Model Updates: 119,502
Cumulative Timesteps: 996,717,176

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 996717176...
Checkpoint 996717176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.51759
Policy Entropy: 3.00302
Value Function Loss: 0.00475

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.56611
Value Function Update Magnitude: 0.53290

Collected Steps per Second: 21,805.26599
Overall Steps per Second: 10,445.15174

Timestep Collection Time: 2.29486
Timestep Consumption Time: 2.49588
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.79074

Cumulative Model Updates: 119,508
Cumulative Timesteps: 996,767,216

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.06704
Policy Entropy: 3.01318
Value Function Loss: 0.00486

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09772
Policy Update Magnitude: 0.56559
Value Function Update Magnitude: 0.52528

Collected Steps per Second: 22,112.64365
Overall Steps per Second: 10,610.71505

Timestep Collection Time: 2.26251
Timestep Consumption Time: 2.45254
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.71505

Cumulative Model Updates: 119,514
Cumulative Timesteps: 996,817,246

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 996817246...
Checkpoint 996817246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.60554
Policy Entropy: 3.02174
Value Function Loss: 0.00506

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10093
Policy Update Magnitude: 0.57537
Value Function Update Magnitude: 0.53860

Collected Steps per Second: 22,077.94930
Overall Steps per Second: 10,366.84612

Timestep Collection Time: 2.26615
Timestep Consumption Time: 2.56000
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.82615

Cumulative Model Updates: 119,520
Cumulative Timesteps: 996,867,278

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,962.49099
Policy Entropy: 3.03350
Value Function Loss: 0.00484

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.10432
Policy Update Magnitude: 0.56799
Value Function Update Magnitude: 0.54056

Collected Steps per Second: 22,506.53872
Overall Steps per Second: 10,573.89416

Timestep Collection Time: 2.22184
Timestep Consumption Time: 2.50735
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.72919

Cumulative Model Updates: 119,526
Cumulative Timesteps: 996,917,284

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 996917284...
Checkpoint 996917284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,484.56292
Policy Entropy: 3.02842
Value Function Loss: 0.00475

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.10965
Policy Update Magnitude: 0.55714
Value Function Update Magnitude: 0.52602

Collected Steps per Second: 22,169.20197
Overall Steps per Second: 10,470.86413

Timestep Collection Time: 2.25574
Timestep Consumption Time: 2.52018
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.77592

Cumulative Model Updates: 119,532
Cumulative Timesteps: 996,967,292

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,417.21649
Policy Entropy: 3.03661
Value Function Loss: 0.00479

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.55827
Value Function Update Magnitude: 0.52547

Collected Steps per Second: 22,156.89929
Overall Steps per Second: 10,464.66743

Timestep Collection Time: 2.25754
Timestep Consumption Time: 2.52236
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.77989

Cumulative Model Updates: 119,538
Cumulative Timesteps: 997,017,312

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 997017312...
Checkpoint 997017312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,427.11553
Policy Entropy: 3.04043
Value Function Loss: 0.00490

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09215
Policy Update Magnitude: 0.56761
Value Function Update Magnitude: 0.53000

Collected Steps per Second: 22,153.16444
Overall Steps per Second: 10,644.86331

Timestep Collection Time: 2.25747
Timestep Consumption Time: 2.44058
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.69804

Cumulative Model Updates: 119,544
Cumulative Timesteps: 997,067,322

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.48836
Policy Entropy: 3.03377
Value Function Loss: 0.00508

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.57355
Value Function Update Magnitude: 0.52685

Collected Steps per Second: 22,363.43279
Overall Steps per Second: 10,510.64276

Timestep Collection Time: 2.23633
Timestep Consumption Time: 2.52190
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.75822

Cumulative Model Updates: 119,550
Cumulative Timesteps: 997,117,334

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 997117334...
Checkpoint 997117334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.90929
Policy Entropy: 3.00987
Value Function Loss: 0.00514

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.09501
Policy Update Magnitude: 0.57806
Value Function Update Magnitude: 0.53214

Collected Steps per Second: 22,045.49636
Overall Steps per Second: 10,529.11021

Timestep Collection Time: 2.26831
Timestep Consumption Time: 2.48100
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.74931

Cumulative Model Updates: 119,556
Cumulative Timesteps: 997,167,340

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629.05293
Policy Entropy: 3.00583
Value Function Loss: 0.00497

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.57733
Value Function Update Magnitude: 0.53734

Collected Steps per Second: 22,099.14096
Overall Steps per Second: 10,481.24205

Timestep Collection Time: 2.26362
Timestep Consumption Time: 2.50910
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.77272

Cumulative Model Updates: 119,562
Cumulative Timesteps: 997,217,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 997217364...
Checkpoint 997217364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,953.73717
Policy Entropy: 3.00132
Value Function Loss: 0.00498

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10365
Policy Update Magnitude: 0.57761
Value Function Update Magnitude: 0.52900

Collected Steps per Second: 21,757.92502
Overall Steps per Second: 10,567.19907

Timestep Collection Time: 2.29958
Timestep Consumption Time: 2.43526
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.73484

Cumulative Model Updates: 119,568
Cumulative Timesteps: 997,267,398

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,917.42011
Policy Entropy: 2.99636
Value Function Loss: 0.00509

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.58684
Value Function Update Magnitude: 0.52747

Collected Steps per Second: 21,994.84277
Overall Steps per Second: 10,473.01030

Timestep Collection Time: 2.27335
Timestep Consumption Time: 2.50102
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.77437

Cumulative Model Updates: 119,574
Cumulative Timesteps: 997,317,400

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 997317400...
Checkpoint 997317400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 893.00137
Policy Entropy: 2.99090
Value Function Loss: 0.00507

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.13489
Policy Update Magnitude: 0.58204
Value Function Update Magnitude: 0.51980

Collected Steps per Second: 21,181.35303
Overall Steps per Second: 10,235.77221

Timestep Collection Time: 2.36198
Timestep Consumption Time: 2.52578
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.88776

Cumulative Model Updates: 119,580
Cumulative Timesteps: 997,367,430

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,922.39185
Policy Entropy: 3.00034
Value Function Loss: 0.00515

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.57202
Value Function Update Magnitude: 0.50238

Collected Steps per Second: 21,530.90467
Overall Steps per Second: 10,452.36099

Timestep Collection Time: 2.32261
Timestep Consumption Time: 2.46176
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.78437

Cumulative Model Updates: 119,586
Cumulative Timesteps: 997,417,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 997417438...
Checkpoint 997417438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.69845
Policy Entropy: 3.01437
Value Function Loss: 0.00510

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.12996
Policy Update Magnitude: 0.57414
Value Function Update Magnitude: 0.51097

Collected Steps per Second: 21,244.15088
Overall Steps per Second: 10,223.40024

Timestep Collection Time: 2.35444
Timestep Consumption Time: 2.53807
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.89250

Cumulative Model Updates: 119,592
Cumulative Timesteps: 997,467,456

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,664.07913
Policy Entropy: 3.01848
Value Function Loss: 0.00517

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.13250
Policy Update Magnitude: 0.57195
Value Function Update Magnitude: 0.51788

Collected Steps per Second: 22,442.99952
Overall Steps per Second: 10,447.41176

Timestep Collection Time: 2.22849
Timestep Consumption Time: 2.55872
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.78721

Cumulative Model Updates: 119,598
Cumulative Timesteps: 997,517,470

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 997517470...
Checkpoint 997517470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.14235
Policy Entropy: 3.01834
Value Function Loss: 0.00494

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.57667
Value Function Update Magnitude: 0.50221

Collected Steps per Second: 22,099.59005
Overall Steps per Second: 10,612.03643

Timestep Collection Time: 2.26357
Timestep Consumption Time: 2.45032
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.71389

Cumulative Model Updates: 119,604
Cumulative Timesteps: 997,567,494

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,573.50384
Policy Entropy: 3.02231
Value Function Loss: 0.00514

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.14083
Policy Update Magnitude: 0.57647
Value Function Update Magnitude: 0.51172

Collected Steps per Second: 22,415.77187
Overall Steps per Second: 10,579.73065

Timestep Collection Time: 2.23093
Timestep Consumption Time: 2.49585
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.72677

Cumulative Model Updates: 119,610
Cumulative Timesteps: 997,617,502

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 997617502...
Checkpoint 997617502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.72816
Policy Entropy: 3.01520
Value Function Loss: 0.00514

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.58069
Value Function Update Magnitude: 0.52325

Collected Steps per Second: 22,062.73856
Overall Steps per Second: 10,579.22651

Timestep Collection Time: 2.26672
Timestep Consumption Time: 2.46047
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.72719

Cumulative Model Updates: 119,616
Cumulative Timesteps: 997,667,512

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.79640
Policy Entropy: 3.02644
Value Function Loss: 0.00524

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.58616
Value Function Update Magnitude: 0.52788

Collected Steps per Second: 22,261.26395
Overall Steps per Second: 10,558.52891

Timestep Collection Time: 2.24614
Timestep Consumption Time: 2.48955
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.73570

Cumulative Model Updates: 119,622
Cumulative Timesteps: 997,717,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 997717514...
Checkpoint 997717514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580.30359
Policy Entropy: 3.02298
Value Function Loss: 0.00515

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12020
Policy Update Magnitude: 0.58525
Value Function Update Magnitude: 0.52089

Collected Steps per Second: 22,263.44654
Overall Steps per Second: 10,499.67718

Timestep Collection Time: 2.24619
Timestep Consumption Time: 2.51662
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.76281

Cumulative Model Updates: 119,628
Cumulative Timesteps: 997,767,522

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.30885
Policy Entropy: 3.01581
Value Function Loss: 0.00496

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.58094
Value Function Update Magnitude: 0.53416

Collected Steps per Second: 22,523.31851
Overall Steps per Second: 10,547.87490

Timestep Collection Time: 2.22116
Timestep Consumption Time: 2.52178
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.74295

Cumulative Model Updates: 119,634
Cumulative Timesteps: 997,817,550

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 997817550...
Checkpoint 997817550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 910.82802
Policy Entropy: 3.00776
Value Function Loss: 0.00510

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.12785
Policy Update Magnitude: 0.58413
Value Function Update Magnitude: 0.54083

Collected Steps per Second: 22,192.43496
Overall Steps per Second: 10,561.28563

Timestep Collection Time: 2.25428
Timestep Consumption Time: 2.48264
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.73692

Cumulative Model Updates: 119,640
Cumulative Timesteps: 997,867,578

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.68881
Policy Entropy: 3.01392
Value Function Loss: 0.00521

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.13202
Policy Update Magnitude: 0.59029
Value Function Update Magnitude: 0.55638

Collected Steps per Second: 21,921.84359
Overall Steps per Second: 10,478.61329

Timestep Collection Time: 2.28147
Timestep Consumption Time: 2.49149
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.77296

Cumulative Model Updates: 119,646
Cumulative Timesteps: 997,917,592

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 997917592...
Checkpoint 997917592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,660.69707
Policy Entropy: 3.02264
Value Function Loss: 0.00540

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.12021
Policy Update Magnitude: 0.59697
Value Function Update Magnitude: 0.57736

Collected Steps per Second: 21,417.95696
Overall Steps per Second: 10,387.33418

Timestep Collection Time: 2.33542
Timestep Consumption Time: 2.48006
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.81548

Cumulative Model Updates: 119,652
Cumulative Timesteps: 997,967,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467.68888
Policy Entropy: 3.02518
Value Function Loss: 0.00529

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.10916
Policy Update Magnitude: 0.60202
Value Function Update Magnitude: 0.58381

Collected Steps per Second: 22,251.31863
Overall Steps per Second: 10,653.81347

Timestep Collection Time: 2.24778
Timestep Consumption Time: 2.44688
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.69466

Cumulative Model Updates: 119,658
Cumulative Timesteps: 998,017,628

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 998017628...
Checkpoint 998017628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.71068
Policy Entropy: 3.02931
Value Function Loss: 0.00500

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10228
Policy Update Magnitude: 0.59452
Value Function Update Magnitude: 0.57594

Collected Steps per Second: 21,625.87547
Overall Steps per Second: 10,451.47055

Timestep Collection Time: 2.31269
Timestep Consumption Time: 2.47266
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.78536

Cumulative Model Updates: 119,664
Cumulative Timesteps: 998,067,642

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,719.34714
Policy Entropy: 3.03199
Value Function Loss: 0.00481

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09630
Policy Update Magnitude: 0.58142
Value Function Update Magnitude: 0.55028

Collected Steps per Second: 22,335.74874
Overall Steps per Second: 10,688.62384

Timestep Collection Time: 2.24053
Timestep Consumption Time: 2.44145
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.68199

Cumulative Model Updates: 119,670
Cumulative Timesteps: 998,117,686

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 998117686...
Checkpoint 998117686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,923.26832
Policy Entropy: 3.04538
Value Function Loss: 0.00482

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08696
Policy Update Magnitude: 0.58254
Value Function Update Magnitude: 0.53780

Collected Steps per Second: 21,924.31113
Overall Steps per Second: 10,572.79073

Timestep Collection Time: 2.28231
Timestep Consumption Time: 2.45041
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.73271

Cumulative Model Updates: 119,676
Cumulative Timesteps: 998,167,724

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.12799
Policy Entropy: 3.05187
Value Function Loss: 0.00478

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09692
Policy Update Magnitude: 0.58619
Value Function Update Magnitude: 0.55510

Collected Steps per Second: 22,472.84232
Overall Steps per Second: 10,538.58909

Timestep Collection Time: 2.22500
Timestep Consumption Time: 2.51966
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.74466

Cumulative Model Updates: 119,682
Cumulative Timesteps: 998,217,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 998217726...
Checkpoint 998217726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.44746
Policy Entropy: 3.05793
Value Function Loss: 0.00499

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10355
Policy Update Magnitude: 0.58250
Value Function Update Magnitude: 0.56234

Collected Steps per Second: 22,077.41043
Overall Steps per Second: 10,639.36196

Timestep Collection Time: 2.26539
Timestep Consumption Time: 2.43545
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.70085

Cumulative Model Updates: 119,688
Cumulative Timesteps: 998,267,740

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.09153
Policy Entropy: 3.04425
Value Function Loss: 0.00500

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.58253
Value Function Update Magnitude: 0.55474

Collected Steps per Second: 22,388.82924
Overall Steps per Second: 10,569.13085

Timestep Collection Time: 2.23335
Timestep Consumption Time: 2.49760
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.73095

Cumulative Model Updates: 119,694
Cumulative Timesteps: 998,317,742

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 998317742...
Checkpoint 998317742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.59578
Policy Entropy: 3.01870
Value Function Loss: 0.00520

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.58418
Value Function Update Magnitude: 0.55365

Collected Steps per Second: 22,186.88542
Overall Steps per Second: 10,524.47478

Timestep Collection Time: 2.25494
Timestep Consumption Time: 2.49875
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.75368

Cumulative Model Updates: 119,700
Cumulative Timesteps: 998,367,772

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,581.96449
Policy Entropy: 3.01630
Value Function Loss: 0.00523

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09626
Policy Update Magnitude: 0.59039
Value Function Update Magnitude: 0.53955

Collected Steps per Second: 21,760.55719
Overall Steps per Second: 10,550.71687

Timestep Collection Time: 2.29792
Timestep Consumption Time: 2.44147
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.73939

Cumulative Model Updates: 119,706
Cumulative Timesteps: 998,417,776

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 998417776...
Checkpoint 998417776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,102.73889
Policy Entropy: 3.02507
Value Function Loss: 0.00518

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.58680
Value Function Update Magnitude: 0.51673

Collected Steps per Second: 22,073.79291
Overall Steps per Second: 10,640.26695

Timestep Collection Time: 2.26649
Timestep Consumption Time: 2.43546
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.70195

Cumulative Model Updates: 119,712
Cumulative Timesteps: 998,467,806

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 960.88923
Policy Entropy: 3.04741
Value Function Loss: 0.00510

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09453
Policy Update Magnitude: 0.58154
Value Function Update Magnitude: 0.52586

Collected Steps per Second: 21,897.32523
Overall Steps per Second: 10,391.54899

Timestep Collection Time: 2.28466
Timestep Consumption Time: 2.52963
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.81430

Cumulative Model Updates: 119,718
Cumulative Timesteps: 998,517,834

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 998517834...
Checkpoint 998517834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.84501
Policy Entropy: 3.04853
Value Function Loss: 0.00489

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.57707
Value Function Update Magnitude: 0.52038

Collected Steps per Second: 21,350.73515
Overall Steps per Second: 10,339.07422

Timestep Collection Time: 2.34268
Timestep Consumption Time: 2.49508
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.83776

Cumulative Model Updates: 119,724
Cumulative Timesteps: 998,567,852

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,999.71423
Policy Entropy: 3.05812
Value Function Loss: 0.00480

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.57513
Value Function Update Magnitude: 0.52421

Collected Steps per Second: 21,938.96745
Overall Steps per Second: 10,416.12581

Timestep Collection Time: 2.27960
Timestep Consumption Time: 2.52180
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.80140

Cumulative Model Updates: 119,730
Cumulative Timesteps: 998,617,864

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 998617864...
Checkpoint 998617864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.48065
Policy Entropy: 3.06046
Value Function Loss: 0.00479

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.09784
Policy Update Magnitude: 0.56150
Value Function Update Magnitude: 0.51270

Collected Steps per Second: 21,610.59549
Overall Steps per Second: 10,517.56858

Timestep Collection Time: 2.31470
Timestep Consumption Time: 2.44134
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.75604

Cumulative Model Updates: 119,736
Cumulative Timesteps: 998,667,886

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.47345
Policy Entropy: 3.05054
Value Function Loss: 0.00505

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09274
Policy Update Magnitude: 0.55905
Value Function Update Magnitude: 0.51160

Collected Steps per Second: 22,059.41742
Overall Steps per Second: 10,491.19204

Timestep Collection Time: 2.26697
Timestep Consumption Time: 2.49970
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.76667

Cumulative Model Updates: 119,742
Cumulative Timesteps: 998,717,894

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 998717894...
Checkpoint 998717894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,885.02335
Policy Entropy: 3.04559
Value Function Loss: 0.00514

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.57062
Value Function Update Magnitude: 0.52218

Collected Steps per Second: 21,391.13206
Overall Steps per Second: 10,245.66313

Timestep Collection Time: 2.33742
Timestep Consumption Time: 2.54270
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.88011

Cumulative Model Updates: 119,748
Cumulative Timesteps: 998,767,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,782.79224
Policy Entropy: 3.04102
Value Function Loss: 0.00485

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10288
Policy Update Magnitude: 0.56996
Value Function Update Magnitude: 0.53650

Collected Steps per Second: 22,574.53445
Overall Steps per Second: 10,568.40050

Timestep Collection Time: 2.21489
Timestep Consumption Time: 2.51620
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.73108

Cumulative Model Updates: 119,754
Cumulative Timesteps: 998,817,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 998817894...
Checkpoint 998817894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.34854
Policy Entropy: 3.04845
Value Function Loss: 0.00491

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.55984
Value Function Update Magnitude: 0.51772

Collected Steps per Second: 22,140.99108
Overall Steps per Second: 10,522.77034

Timestep Collection Time: 2.25907
Timestep Consumption Time: 2.49424
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.75331

Cumulative Model Updates: 119,760
Cumulative Timesteps: 998,867,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,951.01305
Policy Entropy: 3.03899
Value Function Loss: 0.00519

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.10268
Policy Update Magnitude: 0.56796
Value Function Update Magnitude: 0.50305

Collected Steps per Second: 22,196.79490
Overall Steps per Second: 10,513.03051

Timestep Collection Time: 2.25357
Timestep Consumption Time: 2.50453
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.75810

Cumulative Model Updates: 119,766
Cumulative Timesteps: 998,917,934

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 998917934...
Checkpoint 998917934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,304.83670
Policy Entropy: 3.02624
Value Function Loss: 0.00547

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.10796
Policy Update Magnitude: 0.57716
Value Function Update Magnitude: 0.51352

Collected Steps per Second: 22,206.18373
Overall Steps per Second: 10,607.19420

Timestep Collection Time: 2.25181
Timestep Consumption Time: 2.46235
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.71416

Cumulative Model Updates: 119,772
Cumulative Timesteps: 998,967,938

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,792.60490
Policy Entropy: 3.02937
Value Function Loss: 0.00536

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.10979
Policy Update Magnitude: 0.57090
Value Function Update Magnitude: 0.53871

Collected Steps per Second: 22,427.57853
Overall Steps per Second: 10,525.42325

Timestep Collection Time: 2.23109
Timestep Consumption Time: 2.52292
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.75401

Cumulative Model Updates: 119,778
Cumulative Timesteps: 999,017,976

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 999017976...
Checkpoint 999017976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.08984
Policy Entropy: 3.03454
Value Function Loss: 0.00520

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11109
Policy Update Magnitude: 0.57625
Value Function Update Magnitude: 0.55211

Collected Steps per Second: 22,135.84814
Overall Steps per Second: 10,562.50047

Timestep Collection Time: 2.25878
Timestep Consumption Time: 2.47495
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.73373

Cumulative Model Updates: 119,784
Cumulative Timesteps: 999,067,976

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.21252
Policy Entropy: 3.04740
Value Function Loss: 0.00495

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.57691
Value Function Update Magnitude: 0.53947

Collected Steps per Second: 22,341.11085
Overall Steps per Second: 10,580.80297

Timestep Collection Time: 2.23937
Timestep Consumption Time: 2.48901
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.72837

Cumulative Model Updates: 119,790
Cumulative Timesteps: 999,118,006

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 999118006...
Checkpoint 999118006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.65553
Policy Entropy: 3.03552
Value Function Loss: 0.00495

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09580
Policy Update Magnitude: 0.57008
Value Function Update Magnitude: 0.51595

Collected Steps per Second: 21,767.39134
Overall Steps per Second: 10,553.88279

Timestep Collection Time: 2.29738
Timestep Consumption Time: 2.44097
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.73835

Cumulative Model Updates: 119,796
Cumulative Timesteps: 999,168,014

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.93486
Policy Entropy: 3.03356
Value Function Loss: 0.00518

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.57227
Value Function Update Magnitude: 0.50017

Collected Steps per Second: 21,945.84439
Overall Steps per Second: 10,430.49254

Timestep Collection Time: 2.27897
Timestep Consumption Time: 2.51601
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.79498

Cumulative Model Updates: 119,802
Cumulative Timesteps: 999,218,028

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 999218028...
Checkpoint 999218028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.66974
Policy Entropy: 3.01947
Value Function Loss: 0.00545

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09200
Policy Update Magnitude: 0.58306
Value Function Update Magnitude: 0.51606

Collected Steps per Second: 21,678.83439
Overall Steps per Second: 10,581.55070

Timestep Collection Time: 2.30695
Timestep Consumption Time: 2.41939
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.72634

Cumulative Model Updates: 119,808
Cumulative Timesteps: 999,268,040

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.95887
Policy Entropy: 3.03040
Value Function Loss: 0.00516

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.09967
Policy Update Magnitude: 0.57959
Value Function Update Magnitude: 0.54154

Collected Steps per Second: 22,090.60266
Overall Steps per Second: 10,482.30003

Timestep Collection Time: 2.26395
Timestep Consumption Time: 2.50714
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.77109

Cumulative Model Updates: 119,814
Cumulative Timesteps: 999,318,052

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 999318052...
Checkpoint 999318052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,401.56716
Policy Entropy: 3.04466
Value Function Loss: 0.00498

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09155
Policy Update Magnitude: 0.56779
Value Function Update Magnitude: 0.53355

Collected Steps per Second: 22,030.38994
Overall Steps per Second: 10,374.86539

Timestep Collection Time: 2.27041
Timestep Consumption Time: 2.55067
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.82107

Cumulative Model Updates: 119,820
Cumulative Timesteps: 999,368,070

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,351.78621
Policy Entropy: 3.06386
Value Function Loss: 0.00505

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09244
Policy Update Magnitude: 0.56108
Value Function Update Magnitude: 0.52485

Collected Steps per Second: 22,673.67443
Overall Steps per Second: 10,809.56513

Timestep Collection Time: 2.20652
Timestep Consumption Time: 2.42178
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.62831

Cumulative Model Updates: 119,826
Cumulative Timesteps: 999,418,100

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 999418100...
Checkpoint 999418100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,675.01876
Policy Entropy: 3.05263
Value Function Loss: 0.00521

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09058
Policy Update Magnitude: 0.56890
Value Function Update Magnitude: 0.53294

Collected Steps per Second: 22,250.10652
Overall Steps per Second: 10,595.55495

Timestep Collection Time: 2.24826
Timestep Consumption Time: 2.47297
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.72123

Cumulative Model Updates: 119,832
Cumulative Timesteps: 999,468,124

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.90449
Policy Entropy: 3.05455
Value Function Loss: 0.00520

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09289
Policy Update Magnitude: 0.57735
Value Function Update Magnitude: 0.54604

Collected Steps per Second: 22,631.90492
Overall Steps per Second: 10,563.04310

Timestep Collection Time: 2.20989
Timestep Consumption Time: 2.52492
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.73481

Cumulative Model Updates: 119,838
Cumulative Timesteps: 999,518,138

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 999518138...
Checkpoint 999518138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,209.55792
Policy Entropy: 3.03212
Value Function Loss: 0.00511

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.58287
Value Function Update Magnitude: 0.53803

Collected Steps per Second: 21,828.84974
Overall Steps per Second: 10,562.99643

Timestep Collection Time: 2.29091
Timestep Consumption Time: 2.44335
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.73426

Cumulative Model Updates: 119,844
Cumulative Timesteps: 999,568,146

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,662.59232
Policy Entropy: 3.02880
Value Function Loss: 0.00526

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10045
Policy Update Magnitude: 0.58366
Value Function Update Magnitude: 0.50955

Collected Steps per Second: 21,836.11076
Overall Steps per Second: 10,318.83981

Timestep Collection Time: 2.29033
Timestep Consumption Time: 2.55633
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.84667

Cumulative Model Updates: 119,850
Cumulative Timesteps: 999,618,158

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 999618158...
Checkpoint 999618158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.22088
Policy Entropy: 3.02478
Value Function Loss: 0.00547

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09862
Policy Update Magnitude: 0.58664
Value Function Update Magnitude: 0.49314

Collected Steps per Second: 21,893.38757
Overall Steps per Second: 10,462.98456

Timestep Collection Time: 2.28453
Timestep Consumption Time: 2.49575
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.78028

Cumulative Model Updates: 119,856
Cumulative Timesteps: 999,668,174

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,632.00596
Policy Entropy: 3.01611
Value Function Loss: 0.00533

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09308
Policy Update Magnitude: 0.57937
Value Function Update Magnitude: 0.48559

Collected Steps per Second: 22,363.44206
Overall Steps per Second: 10,731.81265

Timestep Collection Time: 2.23669
Timestep Consumption Time: 2.42422
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.66091

Cumulative Model Updates: 119,862
Cumulative Timesteps: 999,718,194

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 999718194...
Checkpoint 999718194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,122.25677
Policy Entropy: 3.01750
Value Function Loss: 0.00531

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.57709
Value Function Update Magnitude: 0.50377

Collected Steps per Second: 21,445.74122
Overall Steps per Second: 10,290.00487

Timestep Collection Time: 2.33221
Timestep Consumption Time: 2.52843
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.86064

Cumulative Model Updates: 119,868
Cumulative Timesteps: 999,768,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,171.95741
Policy Entropy: 3.02155
Value Function Loss: 0.00505

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09632
Policy Update Magnitude: 0.58052
Value Function Update Magnitude: 0.49804

Collected Steps per Second: 21,856.96636
Overall Steps per Second: 10,371.89659

Timestep Collection Time: 2.28824
Timestep Consumption Time: 2.53383
PPO Batch Consumption Time: 0.29485
Total Iteration Time: 4.82207

Cumulative Model Updates: 119,874
Cumulative Timesteps: 999,818,224

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 999818224...
Checkpoint 999818224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.78671
Policy Entropy: 3.03274
Value Function Loss: 0.00519

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09370
Policy Update Magnitude: 0.58264
Value Function Update Magnitude: 0.50225

Collected Steps per Second: 20,953.57181
Overall Steps per Second: 10,204.85198

Timestep Collection Time: 2.38756
Timestep Consumption Time: 2.51481
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.90237

Cumulative Model Updates: 119,880
Cumulative Timesteps: 999,868,252

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,592.12964
Policy Entropy: 3.03871
Value Function Loss: 0.00519

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09768
Policy Update Magnitude: 0.58276
Value Function Update Magnitude: 0.49131

Collected Steps per Second: 22,401.76219
Overall Steps per Second: 10,446.22001

Timestep Collection Time: 2.23268
Timestep Consumption Time: 2.55527
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.78795

Cumulative Model Updates: 119,886
Cumulative Timesteps: 999,918,268

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 999918268...
Checkpoint 999918268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,312.59366
Policy Entropy: 3.04092
Value Function Loss: 0.00501

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10173
Policy Update Magnitude: 0.57714
Value Function Update Magnitude: 0.48219

Collected Steps per Second: 21,531.00426
Overall Steps per Second: 10,184.32861

Timestep Collection Time: 2.32223
Timestep Consumption Time: 2.58727
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.90950

Cumulative Model Updates: 119,892
Cumulative Timesteps: 999,968,268

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 878.13705
Policy Entropy: 3.03211
Value Function Loss: 0.00489

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09125
Policy Update Magnitude: 0.57262
Value Function Update Magnitude: 0.47526

Collected Steps per Second: 22,401.30726
Overall Steps per Second: 10,584.39378

Timestep Collection Time: 2.23246
Timestep Consumption Time: 2.49242
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.72488

Cumulative Model Updates: 119,898
Cumulative Timesteps: 1,000,018,278

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1000018278...
Checkpoint 1000018278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.62536
Policy Entropy: 3.02967
Value Function Loss: 0.00480

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.57354
Value Function Update Magnitude: 0.46536

Collected Steps per Second: 22,042.21302
Overall Steps per Second: 10,612.31037

Timestep Collection Time: 2.26974
Timestep Consumption Time: 2.44460
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.71434

Cumulative Model Updates: 119,904
Cumulative Timesteps: 1,000,068,308

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,839.44403
Policy Entropy: 3.02340
Value Function Loss: 0.00487

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09657
Policy Update Magnitude: 0.57976
Value Function Update Magnitude: 0.48141

Collected Steps per Second: 22,461.57894
Overall Steps per Second: 10,551.93028

Timestep Collection Time: 2.22736
Timestep Consumption Time: 2.51395
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.74131

Cumulative Model Updates: 119,910
Cumulative Timesteps: 1,000,118,338

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1000118338...
Checkpoint 1000118338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.41549
Policy Entropy: 3.02133
Value Function Loss: 0.00509

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.58002
Value Function Update Magnitude: 0.49960

Collected Steps per Second: 22,086.66052
Overall Steps per Second: 10,482.36435

Timestep Collection Time: 2.26508
Timestep Consumption Time: 2.50751
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.77259

Cumulative Model Updates: 119,916
Cumulative Timesteps: 1,000,168,366

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 973.42633
Policy Entropy: 3.00256
Value Function Loss: 0.00540

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 0.59074
Value Function Update Magnitude: 0.51981

Collected Steps per Second: 22,205.89184
Overall Steps per Second: 10,450.65536

Timestep Collection Time: 2.25183
Timestep Consumption Time: 2.53294
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.78477

Cumulative Model Updates: 119,922
Cumulative Timesteps: 1,000,218,370

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1000218370...
Checkpoint 1000218370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.60547
Policy Entropy: 3.01365
Value Function Loss: 0.00543

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.10460
Policy Update Magnitude: 0.59953
Value Function Update Magnitude: 0.52063

Collected Steps per Second: 21,585.53451
Overall Steps per Second: 10,566.60280

Timestep Collection Time: 2.31674
Timestep Consumption Time: 2.41591
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.73265

Cumulative Model Updates: 119,928
Cumulative Timesteps: 1,000,268,378

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,632.68839
Policy Entropy: 3.00997
Value Function Loss: 0.00547

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11091
Policy Update Magnitude: 0.59608
Value Function Update Magnitude: 0.52569

Collected Steps per Second: 21,649.22425
Overall Steps per Second: 10,494.32635

Timestep Collection Time: 2.31149
Timestep Consumption Time: 2.45699
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.76848

Cumulative Model Updates: 119,934
Cumulative Timesteps: 1,000,318,420

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1000318420...
Checkpoint 1000318420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,110.91690
Policy Entropy: 3.02674
Value Function Loss: 0.00534

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11236
Policy Update Magnitude: 0.59049
Value Function Update Magnitude: 0.53656

Collected Steps per Second: 21,607.79142
Overall Steps per Second: 10,364.37578

Timestep Collection Time: 2.31518
Timestep Consumption Time: 2.51154
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.82673

Cumulative Model Updates: 119,940
Cumulative Timesteps: 1,000,368,446

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457.05109
Policy Entropy: 3.00420
Value Function Loss: 0.00532

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.59298
Value Function Update Magnitude: 0.55414

Collected Steps per Second: 20,803.78046
Overall Steps per Second: 10,273.32094

Timestep Collection Time: 2.40466
Timestep Consumption Time: 2.46485
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.86951

Cumulative Model Updates: 119,946
Cumulative Timesteps: 1,000,418,472

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1000418472...
Checkpoint 1000418472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.70615
Policy Entropy: 3.00834
Value Function Loss: 0.00521

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.10880
Policy Update Magnitude: 0.59672
Value Function Update Magnitude: 0.56136

Collected Steps per Second: 21,358.26540
Overall Steps per Second: 10,272.95458

Timestep Collection Time: 2.34129
Timestep Consumption Time: 2.52644
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.86773

Cumulative Model Updates: 119,952
Cumulative Timesteps: 1,000,468,478

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386.64527
Policy Entropy: 2.99346
Value Function Loss: 0.00515

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11178
Policy Update Magnitude: 0.59952
Value Function Update Magnitude: 0.55737

Collected Steps per Second: 22,333.50912
Overall Steps per Second: 10,450.75545

Timestep Collection Time: 2.23888
Timestep Consumption Time: 2.54566
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.78453

Cumulative Model Updates: 119,958
Cumulative Timesteps: 1,000,518,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1000518480...
Checkpoint 1000518480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653.86329
Policy Entropy: 2.99987
Value Function Loss: 0.00501

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.10807
Policy Update Magnitude: 0.59939
Value Function Update Magnitude: 0.56489

Collected Steps per Second: 22,305.00947
Overall Steps per Second: 10,533.48169

Timestep Collection Time: 2.24192
Timestep Consumption Time: 2.50542
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.74734

Cumulative Model Updates: 119,964
Cumulative Timesteps: 1,000,568,486

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,856.06170
Policy Entropy: 2.99149
Value Function Loss: 0.00500

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.09867
Policy Update Magnitude: 0.59503
Value Function Update Magnitude: 0.55318

Collected Steps per Second: 22,359.36482
Overall Steps per Second: 10,586.98090

Timestep Collection Time: 2.23754
Timestep Consumption Time: 2.48807
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.72562

Cumulative Model Updates: 119,970
Cumulative Timesteps: 1,000,618,516

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1000618516...
Checkpoint 1000618516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,572.93307
Policy Entropy: 3.01644
Value Function Loss: 0.00504

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.11916
Policy Update Magnitude: 0.59663
Value Function Update Magnitude: 0.55409

Collected Steps per Second: 22,217.02676
Overall Steps per Second: 10,652.96850

Timestep Collection Time: 2.25197
Timestep Consumption Time: 2.44456
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.69653

Cumulative Model Updates: 119,976
Cumulative Timesteps: 1,000,668,548

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531.59201
Policy Entropy: 3.02204
Value Function Loss: 0.00531

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.11875
Policy Update Magnitude: 0.59954
Value Function Update Magnitude: 0.58978

Collected Steps per Second: 22,570.73702
Overall Steps per Second: 10,778.76386

Timestep Collection Time: 2.21659
Timestep Consumption Time: 2.42495
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.64153

Cumulative Model Updates: 119,982
Cumulative Timesteps: 1,000,718,578

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1000718578...
Checkpoint 1000718578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,758.62879
Policy Entropy: 3.02988
Value Function Loss: 0.00538

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.12697
Policy Update Magnitude: 0.60277
Value Function Update Magnitude: 0.60397

Collected Steps per Second: 22,237.95474
Overall Steps per Second: 10,667.44289

Timestep Collection Time: 2.24913
Timestep Consumption Time: 2.43953
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.68866

Cumulative Model Updates: 119,988
Cumulative Timesteps: 1,000,768,594

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391.56358
Policy Entropy: 3.02747
Value Function Loss: 0.00541

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.11601
Policy Update Magnitude: 0.59814
Value Function Update Magnitude: 0.60283

Collected Steps per Second: 21,672.07819
Overall Steps per Second: 10,481.56207

Timestep Collection Time: 2.30758
Timestep Consumption Time: 2.46366
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.77124

Cumulative Model Updates: 119,994
Cumulative Timesteps: 1,000,818,604

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1000818604...
Checkpoint 1000818604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.25839
Policy Entropy: 3.01814
Value Function Loss: 0.00541

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.10862
Policy Update Magnitude: 0.60138
Value Function Update Magnitude: 0.61794

Collected Steps per Second: 21,714.97425
Overall Steps per Second: 10,395.58021

Timestep Collection Time: 2.30385
Timestep Consumption Time: 2.50858
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.81243

Cumulative Model Updates: 120,000
Cumulative Timesteps: 1,000,868,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764.64854
Policy Entropy: 3.02944
Value Function Loss: 0.00506

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09292
Policy Update Magnitude: 0.59243
Value Function Update Magnitude: 0.59217

Collected Steps per Second: 22,050.21890
Overall Steps per Second: 10,534.54529

Timestep Collection Time: 2.26819
Timestep Consumption Time: 2.47943
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.74762

Cumulative Model Updates: 120,006
Cumulative Timesteps: 1,000,918,646

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1000918646...
Checkpoint 1000918646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,846.14002
Policy Entropy: 3.02043
Value Function Loss: 0.00492

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.58545
Value Function Update Magnitude: 0.57152

Collected Steps per Second: 22,009.88975
Overall Steps per Second: 10,413.74346

Timestep Collection Time: 2.27189
Timestep Consumption Time: 2.52984
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.80173

Cumulative Model Updates: 120,012
Cumulative Timesteps: 1,000,968,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,773.36050
Policy Entropy: 3.02585
Value Function Loss: 0.00504

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.58653
Value Function Update Magnitude: 0.56585

Collected Steps per Second: 22,245.09106
Overall Steps per Second: 10,472.34606

Timestep Collection Time: 2.24877
Timestep Consumption Time: 2.52801
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.77677

Cumulative Model Updates: 120,018
Cumulative Timesteps: 1,001,018,674

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1001018674...
Checkpoint 1001018674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,504.85018
Policy Entropy: 3.01479
Value Function Loss: 0.00489

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10034
Policy Update Magnitude: 0.58590
Value Function Update Magnitude: 0.54212

Collected Steps per Second: 22,116.08584
Overall Steps per Second: 10,610.06540

Timestep Collection Time: 2.26170
Timestep Consumption Time: 2.45269
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.71439

Cumulative Model Updates: 120,024
Cumulative Timesteps: 1,001,068,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.24619
Policy Entropy: 3.01780
Value Function Loss: 0.00520

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10171
Policy Update Magnitude: 0.58865
Value Function Update Magnitude: 0.54136

Collected Steps per Second: 22,111.17260
Overall Steps per Second: 10,444.88318

Timestep Collection Time: 2.26157
Timestep Consumption Time: 2.52604
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.78761

Cumulative Model Updates: 120,030
Cumulative Timesteps: 1,001,118,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1001118700...
Checkpoint 1001118700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,616.94619
Policy Entropy: 3.02080
Value Function Loss: 0.00510

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10293
Policy Update Magnitude: 0.58424
Value Function Update Magnitude: 0.55194

Collected Steps per Second: 22,231.74637
Overall Steps per Second: 10,722.04677

Timestep Collection Time: 2.24949
Timestep Consumption Time: 2.41474
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.66422

Cumulative Model Updates: 120,036
Cumulative Timesteps: 1,001,168,710

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,547.99666
Policy Entropy: 3.04066
Value Function Loss: 0.00512

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10414
Policy Update Magnitude: 0.58314
Value Function Update Magnitude: 0.54356

Collected Steps per Second: 22,236.97751
Overall Steps per Second: 10,454.88250

Timestep Collection Time: 2.24914
Timestep Consumption Time: 2.53466
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.78379

Cumulative Model Updates: 120,042
Cumulative Timesteps: 1,001,218,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1001218724...
Checkpoint 1001218724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,336.25286
Policy Entropy: 3.05198
Value Function Loss: 0.00509

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11149
Policy Update Magnitude: 0.57637
Value Function Update Magnitude: 0.57267

Collected Steps per Second: 22,293.18259
Overall Steps per Second: 10,591.65704

Timestep Collection Time: 2.24329
Timestep Consumption Time: 2.47835
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.72164

Cumulative Model Updates: 120,048
Cumulative Timesteps: 1,001,268,734

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.92766
Policy Entropy: 3.05206
Value Function Loss: 0.00534

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10305
Policy Update Magnitude: 0.58313
Value Function Update Magnitude: 0.57381

Collected Steps per Second: 22,389.66307
Overall Steps per Second: 10,563.97447

Timestep Collection Time: 2.23317
Timestep Consumption Time: 2.49989
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.73307

Cumulative Model Updates: 120,054
Cumulative Timesteps: 1,001,318,734

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1001318734...
Checkpoint 1001318734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,256.25710
Policy Entropy: 3.04909
Value Function Loss: 0.00532

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09658
Policy Update Magnitude: 0.59224
Value Function Update Magnitude: 0.59209

Collected Steps per Second: 21,700.06522
Overall Steps per Second: 10,529.13747

Timestep Collection Time: 2.30479
Timestep Consumption Time: 2.44527
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.75006

Cumulative Model Updates: 120,060
Cumulative Timesteps: 1,001,368,748

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,907.97668
Policy Entropy: 3.04332
Value Function Loss: 0.00514

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09017
Policy Update Magnitude: 0.58651
Value Function Update Magnitude: 0.60025

Collected Steps per Second: 22,042.89446
Overall Steps per Second: 10,475.12463

Timestep Collection Time: 2.26957
Timestep Consumption Time: 2.50631
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.77589

Cumulative Model Updates: 120,066
Cumulative Timesteps: 1,001,418,776

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1001418776...
Checkpoint 1001418776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,078.04912
Policy Entropy: 3.03867
Value Function Loss: 0.00503

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09210
Policy Update Magnitude: 0.58868
Value Function Update Magnitude: 0.58794

Collected Steps per Second: 22,027.94378
Overall Steps per Second: 10,605.25981

Timestep Collection Time: 2.27102
Timestep Consumption Time: 2.44607
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.71709

Cumulative Model Updates: 120,072
Cumulative Timesteps: 1,001,468,802

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 997.77303
Policy Entropy: 3.03357
Value Function Loss: 0.00497

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.09931
Policy Update Magnitude: 0.58327
Value Function Update Magnitude: 0.57408

Collected Steps per Second: 22,232.61248
Overall Steps per Second: 10,481.65816

Timestep Collection Time: 2.24976
Timestep Consumption Time: 2.52220
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.77195

Cumulative Model Updates: 120,078
Cumulative Timesteps: 1,001,518,820

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1001518820...
Checkpoint 1001518820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,484.07536
Policy Entropy: 3.03799
Value Function Loss: 0.00480

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.09732
Policy Update Magnitude: 0.57375
Value Function Update Magnitude: 0.56729

Collected Steps per Second: 22,328.44997
Overall Steps per Second: 10,587.03973

Timestep Collection Time: 2.24028
Timestep Consumption Time: 2.48455
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.72483

Cumulative Model Updates: 120,084
Cumulative Timesteps: 1,001,568,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,450.13591
Policy Entropy: 3.03858
Value Function Loss: 0.00487

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.09965
Policy Update Magnitude: 0.56922
Value Function Update Magnitude: 0.55250

Collected Steps per Second: 22,616.21098
Overall Steps per Second: 10,507.81349

Timestep Collection Time: 2.21116
Timestep Consumption Time: 2.54797
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.75913

Cumulative Model Updates: 120,090
Cumulative Timesteps: 1,001,618,850

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1001618850...
Checkpoint 1001618850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,692.84256
Policy Entropy: 3.04730
Value Function Loss: 0.00487

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09313
Policy Update Magnitude: 0.56884
Value Function Update Magnitude: 0.54471

Collected Steps per Second: 22,095.34748
Overall Steps per Second: 10,679.35789

Timestep Collection Time: 2.26382
Timestep Consumption Time: 2.41998
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.68380

Cumulative Model Updates: 120,096
Cumulative Timesteps: 1,001,668,870

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.38239
Policy Entropy: 3.04535
Value Function Loss: 0.00495

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09503
Policy Update Magnitude: 0.57176
Value Function Update Magnitude: 0.56006

Collected Steps per Second: 22,449.41799
Overall Steps per Second: 10,551.09835

Timestep Collection Time: 2.22750
Timestep Consumption Time: 2.51192
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.73941

Cumulative Model Updates: 120,102
Cumulative Timesteps: 1,001,718,876

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1001718876...
Checkpoint 1001718876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,702.58647
Policy Entropy: 3.04340
Value Function Loss: 0.00478

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09995
Policy Update Magnitude: 0.56796
Value Function Update Magnitude: 0.57145

Collected Steps per Second: 21,855.20811
Overall Steps per Second: 10,576.94243

Timestep Collection Time: 2.28852
Timestep Consumption Time: 2.44026
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.72878

Cumulative Model Updates: 120,108
Cumulative Timesteps: 1,001,768,892

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,470.22711
Policy Entropy: 3.02701
Value Function Loss: 0.00479

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11388
Policy Update Magnitude: 0.56692
Value Function Update Magnitude: 0.56382

Collected Steps per Second: 22,431.03696
Overall Steps per Second: 10,551.86316

Timestep Collection Time: 2.22959
Timestep Consumption Time: 2.51005
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.73964

Cumulative Model Updates: 120,114
Cumulative Timesteps: 1,001,818,904

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1001818904...
Checkpoint 1001818904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,411.56240
Policy Entropy: 3.03306
Value Function Loss: 0.00500

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.10944
Policy Update Magnitude: 0.57608
Value Function Update Magnitude: 0.56453

Collected Steps per Second: 21,486.49317
Overall Steps per Second: 10,486.48182

Timestep Collection Time: 2.32807
Timestep Consumption Time: 2.44207
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.77014

Cumulative Model Updates: 120,120
Cumulative Timesteps: 1,001,868,926

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788.43476
Policy Entropy: 3.02682
Value Function Loss: 0.00519

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.11471
Policy Update Magnitude: 0.58380
Value Function Update Magnitude: 0.55928

Collected Steps per Second: 21,899.93161
Overall Steps per Second: 10,443.09484

Timestep Collection Time: 2.28366
Timestep Consumption Time: 2.50534
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.78900

Cumulative Model Updates: 120,126
Cumulative Timesteps: 1,001,918,938

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1001918938...
Checkpoint 1001918938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,720.20337
Policy Entropy: 3.03773
Value Function Loss: 0.00525

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.11590
Policy Update Magnitude: 0.58234
Value Function Update Magnitude: 0.55455

Collected Steps per Second: 21,389.12605
Overall Steps per Second: 10,383.56620

Timestep Collection Time: 2.33904
Timestep Consumption Time: 2.47915
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.81819

Cumulative Model Updates: 120,132
Cumulative Timesteps: 1,001,968,968

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,810.00510
Policy Entropy: 3.03925
Value Function Loss: 0.00511

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11222
Policy Update Magnitude: 0.57395
Value Function Update Magnitude: 0.54593

Collected Steps per Second: 21,670.68352
Overall Steps per Second: 10,305.75293

Timestep Collection Time: 2.30782
Timestep Consumption Time: 2.54501
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.85282

Cumulative Model Updates: 120,138
Cumulative Timesteps: 1,002,018,980

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1002018980...
Checkpoint 1002018980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,471.05330
Policy Entropy: 3.03273
Value Function Loss: 0.00488

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09814
Policy Update Magnitude: 0.56711
Value Function Update Magnitude: 0.53235

Collected Steps per Second: 21,481.19571
Overall Steps per Second: 10,353.71522

Timestep Collection Time: 2.32818
Timestep Consumption Time: 2.50217
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.83034

Cumulative Model Updates: 120,144
Cumulative Timesteps: 1,002,068,992

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,672.92843
Policy Entropy: 3.03240
Value Function Loss: 0.00502

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10640
Policy Update Magnitude: 0.57287
Value Function Update Magnitude: 0.52039

Collected Steps per Second: 22,078.76715
Overall Steps per Second: 10,433.93614

Timestep Collection Time: 2.26462
Timestep Consumption Time: 2.52744
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.79206

Cumulative Model Updates: 120,150
Cumulative Timesteps: 1,002,118,992

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1002118992...
Checkpoint 1002118992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 850.33133
Policy Entropy: 3.02910
Value Function Loss: 0.00520

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10496
Policy Update Magnitude: 0.57958
Value Function Update Magnitude: 0.53754

Collected Steps per Second: 21,742.62463
Overall Steps per Second: 10,470.40575

Timestep Collection Time: 2.30009
Timestep Consumption Time: 2.47623
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.77632

Cumulative Model Updates: 120,156
Cumulative Timesteps: 1,002,169,002

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.93900
Policy Entropy: 3.04194
Value Function Loss: 0.00530

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10076
Policy Update Magnitude: 0.58637
Value Function Update Magnitude: 0.53461

Collected Steps per Second: 22,449.25734
Overall Steps per Second: 10,452.14896

Timestep Collection Time: 2.22787
Timestep Consumption Time: 2.55718
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.78504

Cumulative Model Updates: 120,162
Cumulative Timesteps: 1,002,219,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1002219016...
Checkpoint 1002219016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,582.86232
Policy Entropy: 3.05532
Value Function Loss: 0.00517

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.09715
Policy Update Magnitude: 0.58584
Value Function Update Magnitude: 0.54640

Collected Steps per Second: 22,204.11051
Overall Steps per Second: 10,570.37139

Timestep Collection Time: 2.25220
Timestep Consumption Time: 2.47876
PPO Batch Consumption Time: 0.28185
Total Iteration Time: 4.73096

Cumulative Model Updates: 120,168
Cumulative Timesteps: 1,002,269,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,790.84308
Policy Entropy: 3.04361
Value Function Loss: 0.00512

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09454
Policy Update Magnitude: 0.58243
Value Function Update Magnitude: 0.53613

Collected Steps per Second: 21,999.79393
Overall Steps per Second: 10,561.05354

Timestep Collection Time: 2.27402
Timestep Consumption Time: 2.46301
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.73703

Cumulative Model Updates: 120,174
Cumulative Timesteps: 1,002,319,052

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1002319052...
Checkpoint 1002319052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,938.82283
Policy Entropy: 3.03724
Value Function Loss: 0.00524

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.58616
Value Function Update Magnitude: 0.52042

Collected Steps per Second: 21,916.02766
Overall Steps per Second: 10,557.98274

Timestep Collection Time: 2.28280
Timestep Consumption Time: 2.45579
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.73859

Cumulative Model Updates: 120,180
Cumulative Timesteps: 1,002,369,082

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.44303
Policy Entropy: 3.03235
Value Function Loss: 0.00540

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10131
Policy Update Magnitude: 0.58744
Value Function Update Magnitude: 0.50502

Collected Steps per Second: 22,621.13097
Overall Steps per Second: 10,640.80010

Timestep Collection Time: 2.21147
Timestep Consumption Time: 2.48987
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.70134

Cumulative Model Updates: 120,186
Cumulative Timesteps: 1,002,419,108

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1002419108...
Checkpoint 1002419108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.68342
Policy Entropy: 3.02015
Value Function Loss: 0.00544

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10164
Policy Update Magnitude: 0.58425
Value Function Update Magnitude: 0.49579

Collected Steps per Second: 22,327.67035
Overall Steps per Second: 10,524.10533

Timestep Collection Time: 2.24009
Timestep Consumption Time: 2.51243
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.75252

Cumulative Model Updates: 120,192
Cumulative Timesteps: 1,002,469,124

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499.67256
Policy Entropy: 3.02403
Value Function Loss: 0.00509

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.58852
Value Function Update Magnitude: 0.49950

Collected Steps per Second: 22,239.07360
Overall Steps per Second: 10,538.88252

Timestep Collection Time: 2.24973
Timestep Consumption Time: 2.49764
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.74737

Cumulative Model Updates: 120,198
Cumulative Timesteps: 1,002,519,156

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1002519156...
Checkpoint 1002519156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.37243
Policy Entropy: 3.02446
Value Function Loss: 0.00516

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09588
Policy Update Magnitude: 0.58241
Value Function Update Magnitude: 0.50213

Collected Steps per Second: 21,736.88100
Overall Steps per Second: 10,617.63639

Timestep Collection Time: 2.30107
Timestep Consumption Time: 2.40978
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.71084

Cumulative Model Updates: 120,204
Cumulative Timesteps: 1,002,569,174

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,893.82462
Policy Entropy: 3.03534
Value Function Loss: 0.00507

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09348
Policy Update Magnitude: 0.57256
Value Function Update Magnitude: 0.49717

Collected Steps per Second: 22,160.51263
Overall Steps per Second: 10,579.97428

Timestep Collection Time: 2.25699
Timestep Consumption Time: 2.47043
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.72742

Cumulative Model Updates: 120,210
Cumulative Timesteps: 1,002,619,190

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1002619190...
Checkpoint 1002619190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,744.14373
Policy Entropy: 3.04009
Value Function Loss: 0.00510

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10261
Policy Update Magnitude: 0.57118
Value Function Update Magnitude: 0.50204

Collected Steps per Second: 21,701.92647
Overall Steps per Second: 10,538.89484

Timestep Collection Time: 2.30422
Timestep Consumption Time: 2.44068
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.74490

Cumulative Model Updates: 120,216
Cumulative Timesteps: 1,002,669,196

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,947.74260
Policy Entropy: 3.04157
Value Function Loss: 0.00522

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09662
Policy Update Magnitude: 0.57481
Value Function Update Magnitude: 0.52513

Collected Steps per Second: 21,892.41000
Overall Steps per Second: 10,472.43756

Timestep Collection Time: 2.28444
Timestep Consumption Time: 2.49114
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.77558

Cumulative Model Updates: 120,222
Cumulative Timesteps: 1,002,719,208

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1002719208...
Checkpoint 1002719208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409.38822
Policy Entropy: 3.03506
Value Function Loss: 0.00521

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10036
Policy Update Magnitude: 0.58475
Value Function Update Magnitude: 0.54373

Collected Steps per Second: 21,864.42353
Overall Steps per Second: 10,553.25101

Timestep Collection Time: 2.28801
Timestep Consumption Time: 2.45233
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.74034

Cumulative Model Updates: 120,228
Cumulative Timesteps: 1,002,769,234

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,293.27745
Policy Entropy: 3.02392
Value Function Loss: 0.00526

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.09905
Policy Update Magnitude: 0.58777
Value Function Update Magnitude: 0.53940

Collected Steps per Second: 22,581.32335
Overall Steps per Second: 10,523.94475

Timestep Collection Time: 2.21510
Timestep Consumption Time: 2.53787
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.75297

Cumulative Model Updates: 120,234
Cumulative Timesteps: 1,002,819,254

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1002819254...
Checkpoint 1002819254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.94196
Policy Entropy: 2.99817
Value Function Loss: 0.00537

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.11738
Policy Update Magnitude: 0.58838
Value Function Update Magnitude: 0.55418

Collected Steps per Second: 22,157.17199
Overall Steps per Second: 10,574.63477

Timestep Collection Time: 2.25805
Timestep Consumption Time: 2.47327
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.73132

Cumulative Model Updates: 120,240
Cumulative Timesteps: 1,002,869,286

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,401.74468
Policy Entropy: 3.01460
Value Function Loss: 0.00576

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.11150
Policy Update Magnitude: 0.60232
Value Function Update Magnitude: 0.55824

Collected Steps per Second: 22,303.73565
Overall Steps per Second: 10,553.30584

Timestep Collection Time: 2.24187
Timestep Consumption Time: 2.49617
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.73804

Cumulative Model Updates: 120,246
Cumulative Timesteps: 1,002,919,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1002919288...
Checkpoint 1002919288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 749.33721
Policy Entropy: 3.03230
Value Function Loss: 0.00542

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11332
Policy Update Magnitude: 0.59750
Value Function Update Magnitude: 0.56605

Collected Steps per Second: 22,133.52587
Overall Steps per Second: 10,504.04418

Timestep Collection Time: 2.25992
Timestep Consumption Time: 2.50206
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.76198

Cumulative Model Updates: 120,252
Cumulative Timesteps: 1,002,969,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,427.24175
Policy Entropy: 3.04871
Value Function Loss: 0.00510

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10381
Policy Update Magnitude: 0.58771
Value Function Update Magnitude: 0.55667

Collected Steps per Second: 22,262.01518
Overall Steps per Second: 10,490.29392

Timestep Collection Time: 2.24652
Timestep Consumption Time: 2.52094
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.76745

Cumulative Model Updates: 120,258
Cumulative Timesteps: 1,003,019,320

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1003019320...
Checkpoint 1003019320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.87420
Policy Entropy: 3.03522
Value Function Loss: 0.00488

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09107
Policy Update Magnitude: 0.58805
Value Function Update Magnitude: 0.53760

Collected Steps per Second: 21,784.84759
Overall Steps per Second: 10,392.67254

Timestep Collection Time: 2.29683
Timestep Consumption Time: 2.51772
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.81455

Cumulative Model Updates: 120,264
Cumulative Timesteps: 1,003,069,356

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.25652
Policy Entropy: 3.01459
Value Function Loss: 0.00498

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.58740
Value Function Update Magnitude: 0.53630

Collected Steps per Second: 21,867.19817
Overall Steps per Second: 10,374.84984

Timestep Collection Time: 2.28744
Timestep Consumption Time: 2.53383
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.82127

Cumulative Model Updates: 120,270
Cumulative Timesteps: 1,003,119,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1003119376...
Checkpoint 1003119376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.38632
Policy Entropy: 3.00911
Value Function Loss: 0.00535

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11050
Policy Update Magnitude: 0.59210
Value Function Update Magnitude: 0.55363

Collected Steps per Second: 22,047.74725
Overall Steps per Second: 10,581.54994

Timestep Collection Time: 2.26790
Timestep Consumption Time: 2.45750
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.72539

Cumulative Model Updates: 120,276
Cumulative Timesteps: 1,003,169,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,374.78346
Policy Entropy: 3.00573
Value Function Loss: 0.00550

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.10677
Policy Update Magnitude: 0.60083
Value Function Update Magnitude: 0.56933

Collected Steps per Second: 22,189.09738
Overall Steps per Second: 10,464.66407

Timestep Collection Time: 2.25363
Timestep Consumption Time: 2.52493
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.77856

Cumulative Model Updates: 120,282
Cumulative Timesteps: 1,003,219,384

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1003219384...
Checkpoint 1003219384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 791.91827
Policy Entropy: 3.01023
Value Function Loss: 0.00563

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10131
Policy Update Magnitude: 0.59910
Value Function Update Magnitude: 0.56207

Collected Steps per Second: 21,688.27054
Overall Steps per Second: 10,589.67262

Timestep Collection Time: 2.30659
Timestep Consumption Time: 2.41744
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.72404

Cumulative Model Updates: 120,288
Cumulative Timesteps: 1,003,269,410

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,767.90193
Policy Entropy: 3.01729
Value Function Loss: 0.00534

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11232
Policy Update Magnitude: 0.58888
Value Function Update Magnitude: 0.55983

Collected Steps per Second: 21,889.20944
Overall Steps per Second: 10,493.81674

Timestep Collection Time: 2.28514
Timestep Consumption Time: 2.48147
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.76662

Cumulative Model Updates: 120,294
Cumulative Timesteps: 1,003,319,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1003319430...
Checkpoint 1003319430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,477.07154
Policy Entropy: 3.02224
Value Function Loss: 0.00520

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.10920
Policy Update Magnitude: 0.58305
Value Function Update Magnitude: 0.54961

Collected Steps per Second: 21,572.75682
Overall Steps per Second: 10,567.33937

Timestep Collection Time: 2.31792
Timestep Consumption Time: 2.41402
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.73194

Cumulative Model Updates: 120,300
Cumulative Timesteps: 1,003,369,434

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,128.29091
Policy Entropy: 3.02596
Value Function Loss: 0.00512

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10565
Policy Update Magnitude: 0.58425
Value Function Update Magnitude: 0.53256

Collected Steps per Second: 21,951.37303
Overall Steps per Second: 10,524.63817

Timestep Collection Time: 2.27822
Timestep Consumption Time: 2.47349
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.75171

Cumulative Model Updates: 120,306
Cumulative Timesteps: 1,003,419,444

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1003419444...
Checkpoint 1003419444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.15981
Policy Entropy: 3.02770
Value Function Loss: 0.00514

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10280
Policy Update Magnitude: 0.58730
Value Function Update Magnitude: 0.52483

Collected Steps per Second: 21,805.24178
Overall Steps per Second: 10,314.12219

Timestep Collection Time: 2.29422
Timestep Consumption Time: 2.55602
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.85024

Cumulative Model Updates: 120,312
Cumulative Timesteps: 1,003,469,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,141.86802
Policy Entropy: 3.00242
Value Function Loss: 0.00516

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.58422
Value Function Update Magnitude: 0.51402

Collected Steps per Second: 22,438.47792
Overall Steps per Second: 10,560.10782

Timestep Collection Time: 2.22876
Timestep Consumption Time: 2.50699
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.73575

Cumulative Model Updates: 120,318
Cumulative Timesteps: 1,003,519,480

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1003519480...
Checkpoint 1003519480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,283.24341
Policy Entropy: 2.98936
Value Function Loss: 0.00532

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.10643
Policy Update Magnitude: 0.59314
Value Function Update Magnitude: 0.50674

Collected Steps per Second: 21,936.90385
Overall Steps per Second: 10,439.25033

Timestep Collection Time: 2.27963
Timestep Consumption Time: 2.51075
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.79038

Cumulative Model Updates: 120,324
Cumulative Timesteps: 1,003,569,488

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.73013
Policy Entropy: 2.98867
Value Function Loss: 0.00518

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.10722
Policy Update Magnitude: 0.59443
Value Function Update Magnitude: 0.51137

Collected Steps per Second: 22,421.81019
Overall Steps per Second: 10,485.20098

Timestep Collection Time: 2.23015
Timestep Consumption Time: 2.53886
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.76901

Cumulative Model Updates: 120,330
Cumulative Timesteps: 1,003,619,492

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1003619492...
Checkpoint 1003619492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,976.13309
Policy Entropy: 3.00398
Value Function Loss: 0.00547

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.59108
Value Function Update Magnitude: 0.51260

Collected Steps per Second: 21,627.55271
Overall Steps per Second: 10,386.25584

Timestep Collection Time: 2.31196
Timestep Consumption Time: 2.50229
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.81425

Cumulative Model Updates: 120,336
Cumulative Timesteps: 1,003,669,494

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.84168
Policy Entropy: 2.99853
Value Function Loss: 0.00550

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.10766
Policy Update Magnitude: 0.59920
Value Function Update Magnitude: 0.53143

Collected Steps per Second: 21,633.21283
Overall Steps per Second: 10,351.89852

Timestep Collection Time: 2.31172
Timestep Consumption Time: 2.51927
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.83100

Cumulative Model Updates: 120,342
Cumulative Timesteps: 1,003,719,504

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1003719504...
Checkpoint 1003719504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.64529
Policy Entropy: 3.00836
Value Function Loss: 0.00551

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.12677
Policy Update Magnitude: 0.60565
Value Function Update Magnitude: 0.55261

Collected Steps per Second: 21,866.96494
Overall Steps per Second: 10,523.59627

Timestep Collection Time: 2.28674
Timestep Consumption Time: 2.46487
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.75161

Cumulative Model Updates: 120,348
Cumulative Timesteps: 1,003,769,508

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 784.34749
Policy Entropy: 3.03668
Value Function Loss: 0.00520

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12255
Policy Update Magnitude: 0.58990
Value Function Update Magnitude: 0.54816

Collected Steps per Second: 22,457.27499
Overall Steps per Second: 10,514.69256

Timestep Collection Time: 2.22752
Timestep Consumption Time: 2.53001
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.75753

Cumulative Model Updates: 120,354
Cumulative Timesteps: 1,003,819,532

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1003819532...
Checkpoint 1003819532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,669.00741
Policy Entropy: 3.04103
Value Function Loss: 0.00484

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.10611
Policy Update Magnitude: 0.57865
Value Function Update Magnitude: 0.52517

Collected Steps per Second: 21,614.85830
Overall Steps per Second: 10,564.15744

Timestep Collection Time: 2.31359
Timestep Consumption Time: 2.42015
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.73374

Cumulative Model Updates: 120,360
Cumulative Timesteps: 1,003,869,540

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,737.25859
Policy Entropy: 3.02426
Value Function Loss: 0.00505

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10290
Policy Update Magnitude: 0.58321
Value Function Update Magnitude: 0.51226

Collected Steps per Second: 22,004.56279
Overall Steps per Second: 10,452.77907

Timestep Collection Time: 2.27326
Timestep Consumption Time: 2.51227
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.78552

Cumulative Model Updates: 120,366
Cumulative Timesteps: 1,003,919,562

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1003919562...
Checkpoint 1003919562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.60128
Policy Entropy: 3.00818
Value Function Loss: 0.00514

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10293
Policy Update Magnitude: 0.58655
Value Function Update Magnitude: 0.52740

Collected Steps per Second: 21,207.17505
Overall Steps per Second: 10,299.44130

Timestep Collection Time: 2.35873
Timestep Consumption Time: 2.49804
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.85677

Cumulative Model Updates: 120,372
Cumulative Timesteps: 1,003,969,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,852.93051
Policy Entropy: 3.02675
Value Function Loss: 0.00521

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.09928
Policy Update Magnitude: 0.58198
Value Function Update Magnitude: 0.52861

Collected Steps per Second: 22,048.59717
Overall Steps per Second: 10,483.21964

Timestep Collection Time: 2.26908
Timestep Consumption Time: 2.50331
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.77239

Cumulative Model Updates: 120,378
Cumulative Timesteps: 1,004,019,614

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1004019614...
Checkpoint 1004019614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,530.96442
Policy Entropy: 3.04354
Value Function Loss: 0.00476

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.10436
Policy Update Magnitude: 0.57489
Value Function Update Magnitude: 0.51125

Collected Steps per Second: 21,677.34928
Overall Steps per Second: 10,510.17876

Timestep Collection Time: 2.30674
Timestep Consumption Time: 2.45093
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.75767

Cumulative Model Updates: 120,384
Cumulative Timesteps: 1,004,069,618

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507.54985
Policy Entropy: 3.04990
Value Function Loss: 0.00481

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.10800
Policy Update Magnitude: 0.56472
Value Function Update Magnitude: 0.49143

Collected Steps per Second: 22,361.99200
Overall Steps per Second: 10,461.67535

Timestep Collection Time: 2.23603
Timestep Consumption Time: 2.54351
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.77954

Cumulative Model Updates: 120,390
Cumulative Timesteps: 1,004,119,620

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1004119620...
Checkpoint 1004119620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,085.46737
Policy Entropy: 3.02728
Value Function Loss: 0.00499

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.56800
Value Function Update Magnitude: 0.49950

Collected Steps per Second: 21,464.43979
Overall Steps per Second: 10,132.40341

Timestep Collection Time: 2.33065
Timestep Consumption Time: 2.60658
PPO Batch Consumption Time: 0.29711
Total Iteration Time: 4.93723

Cumulative Model Updates: 120,396
Cumulative Timesteps: 1,004,169,646

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,610.30932
Policy Entropy: 3.01947
Value Function Loss: 0.00526

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.10816
Policy Update Magnitude: 0.58074
Value Function Update Magnitude: 0.52636

Collected Steps per Second: 22,628.28325
Overall Steps per Second: 10,578.43944

Timestep Collection Time: 2.20962
Timestep Consumption Time: 2.51697
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.72660

Cumulative Model Updates: 120,402
Cumulative Timesteps: 1,004,219,646

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1004219646...
Checkpoint 1004219646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.24964
Policy Entropy: 3.01592
Value Function Loss: 0.00526

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.58642
Value Function Update Magnitude: 0.54642

Collected Steps per Second: 22,019.90238
Overall Steps per Second: 10,602.07509

Timestep Collection Time: 2.27067
Timestep Consumption Time: 2.44538
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.71606

Cumulative Model Updates: 120,408
Cumulative Timesteps: 1,004,269,646

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 950.68795
Policy Entropy: 3.03702
Value Function Loss: 0.00533

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09348
Policy Update Magnitude: 0.58668
Value Function Update Magnitude: 0.52697

Collected Steps per Second: 22,519.87027
Overall Steps per Second: 10,522.48511

Timestep Collection Time: 2.22062
Timestep Consumption Time: 2.53187
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.75249

Cumulative Model Updates: 120,414
Cumulative Timesteps: 1,004,319,654

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1004319654...
Checkpoint 1004319654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,825.32523
Policy Entropy: 3.02969
Value Function Loss: 0.00542

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.58968
Value Function Update Magnitude: 0.52910

Collected Steps per Second: 22,198.47252
Overall Steps per Second: 10,625.80931

Timestep Collection Time: 2.25313
Timestep Consumption Time: 2.45390
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.70703

Cumulative Model Updates: 120,420
Cumulative Timesteps: 1,004,369,670

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,874.97726
Policy Entropy: 3.03137
Value Function Loss: 0.00525

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09298
Policy Update Magnitude: 0.58943
Value Function Update Magnitude: 0.53374

Collected Steps per Second: 22,553.59059
Overall Steps per Second: 10,601.94898

Timestep Collection Time: 2.21774
Timestep Consumption Time: 2.50007
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.71781

Cumulative Model Updates: 120,426
Cumulative Timesteps: 1,004,419,688

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1004419688...
Checkpoint 1004419688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.65629
Policy Entropy: 3.01908
Value Function Loss: 0.00493

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09131
Policy Update Magnitude: 0.57756
Value Function Update Magnitude: 0.52986

Collected Steps per Second: 21,603.90071
Overall Steps per Second: 10,473.70409

Timestep Collection Time: 2.31579
Timestep Consumption Time: 2.46094
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.77672

Cumulative Model Updates: 120,432
Cumulative Timesteps: 1,004,469,718

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,533.60309
Policy Entropy: 3.02951
Value Function Loss: 0.00498

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09367
Policy Update Magnitude: 0.57022
Value Function Update Magnitude: 0.51509

Collected Steps per Second: 22,091.58553
Overall Steps per Second: 10,484.40460

Timestep Collection Time: 2.26448
Timestep Consumption Time: 2.50699
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.77147

Cumulative Model Updates: 120,438
Cumulative Timesteps: 1,004,519,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1004519744...
Checkpoint 1004519744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,763.29792
Policy Entropy: 3.02803
Value Function Loss: 0.00515

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09418
Policy Update Magnitude: 0.57464
Value Function Update Magnitude: 0.51116

Collected Steps per Second: 21,797.42455
Overall Steps per Second: 10,538.64127

Timestep Collection Time: 2.29440
Timestep Consumption Time: 2.45118
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.74558

Cumulative Model Updates: 120,444
Cumulative Timesteps: 1,004,569,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,066.93893
Policy Entropy: 3.02349
Value Function Loss: 0.00514

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.09867
Policy Update Magnitude: 0.57871
Value Function Update Magnitude: 0.51465

Collected Steps per Second: 21,882.06310
Overall Steps per Second: 10,585.89244

Timestep Collection Time: 2.28516
Timestep Consumption Time: 2.43849
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.72365

Cumulative Model Updates: 120,450
Cumulative Timesteps: 1,004,619,760

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1004619760...
Checkpoint 1004619760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655.93168
Policy Entropy: 3.02806
Value Function Loss: 0.00514

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10119
Policy Update Magnitude: 0.57919
Value Function Update Magnitude: 0.52862

Collected Steps per Second: 21,670.64340
Overall Steps per Second: 10,582.88331

Timestep Collection Time: 2.30755
Timestep Consumption Time: 2.41763
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.72518

Cumulative Model Updates: 120,456
Cumulative Timesteps: 1,004,669,766

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.71794
Policy Entropy: 3.02471
Value Function Loss: 0.00503

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08910
Policy Update Magnitude: 0.57897
Value Function Update Magnitude: 0.55156

Collected Steps per Second: 22,371.77102
Overall Steps per Second: 10,438.38133

Timestep Collection Time: 2.23514
Timestep Consumption Time: 2.55526
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.79040

Cumulative Model Updates: 120,462
Cumulative Timesteps: 1,004,719,770

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1004719770...
Checkpoint 1004719770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,115.51478
Policy Entropy: 3.02172
Value Function Loss: 0.00504

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09391
Policy Update Magnitude: 0.58192
Value Function Update Magnitude: 0.55778

Collected Steps per Second: 22,058.69085
Overall Steps per Second: 10,559.87195

Timestep Collection Time: 2.26668
Timestep Consumption Time: 2.46823
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.73491

Cumulative Model Updates: 120,468
Cumulative Timesteps: 1,004,769,770

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.58042
Policy Entropy: 3.00867
Value Function Loss: 0.00484

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.58094
Value Function Update Magnitude: 0.53875

Collected Steps per Second: 22,512.15983
Overall Steps per Second: 10,599.82727

Timestep Collection Time: 2.22102
Timestep Consumption Time: 2.49604
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.71706

Cumulative Model Updates: 120,474
Cumulative Timesteps: 1,004,819,770

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1004819770...
Checkpoint 1004819770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,433.53357
Policy Entropy: 3.01058
Value Function Loss: 0.00533

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.10464
Policy Update Magnitude: 0.58767
Value Function Update Magnitude: 0.53701

Collected Steps per Second: 22,200.92969
Overall Steps per Second: 10,672.11199

Timestep Collection Time: 2.25306
Timestep Consumption Time: 2.43392
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.68698

Cumulative Model Updates: 120,480
Cumulative Timesteps: 1,004,869,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.14417
Policy Entropy: 3.01073
Value Function Loss: 0.00540

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.11951
Policy Update Magnitude: 0.59763
Value Function Update Magnitude: 0.55372

Collected Steps per Second: 22,210.05595
Overall Steps per Second: 10,478.68211

Timestep Collection Time: 2.25249
Timestep Consumption Time: 2.52177
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.77426

Cumulative Model Updates: 120,486
Cumulative Timesteps: 1,004,919,818

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1004919818...
Checkpoint 1004919818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,499.85892
Policy Entropy: 3.01912
Value Function Loss: 0.00529

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.59429
Value Function Update Magnitude: 0.55674

Collected Steps per Second: 22,364.58403
Overall Steps per Second: 10,545.47718

Timestep Collection Time: 2.23693
Timestep Consumption Time: 2.50709
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.74402

Cumulative Model Updates: 120,492
Cumulative Timesteps: 1,004,969,846

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,627.83511
Policy Entropy: 3.01666
Value Function Loss: 0.00479

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.58486
Value Function Update Magnitude: 0.55766

Collected Steps per Second: 21,803.23004
Overall Steps per Second: 10,431.50809

Timestep Collection Time: 2.29324
Timestep Consumption Time: 2.49993
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.79317

Cumulative Model Updates: 120,498
Cumulative Timesteps: 1,005,019,846

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1005019846...
Checkpoint 1005019846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,465.22629
Policy Entropy: 3.02119
Value Function Loss: 0.00496

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.10825
Policy Update Magnitude: 0.57997
Value Function Update Magnitude: 0.54403

Collected Steps per Second: 21,752.67978
Overall Steps per Second: 10,604.32771

Timestep Collection Time: 2.29884
Timestep Consumption Time: 2.41678
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.71562

Cumulative Model Updates: 120,504
Cumulative Timesteps: 1,005,069,852

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,732.53332
Policy Entropy: 3.02789
Value Function Loss: 0.00546

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.58793
Value Function Update Magnitude: 0.56208

Collected Steps per Second: 21,857.60913
Overall Steps per Second: 10,524.59352

Timestep Collection Time: 2.28753
Timestep Consumption Time: 2.46324
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.75078

Cumulative Model Updates: 120,510
Cumulative Timesteps: 1,005,119,852

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1005119852...
Checkpoint 1005119852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.55133
Policy Entropy: 3.04098
Value Function Loss: 0.00527

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.11491
Policy Update Magnitude: 0.58529
Value Function Update Magnitude: 0.57203

Collected Steps per Second: 21,716.52318
Overall Steps per Second: 10,600.11984

Timestep Collection Time: 2.30322
Timestep Consumption Time: 2.41540
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.71863

Cumulative Model Updates: 120,516
Cumulative Timesteps: 1,005,169,870

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.18500
Policy Entropy: 3.04955
Value Function Loss: 0.00532

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.11014
Policy Update Magnitude: 0.58167
Value Function Update Magnitude: 0.55239

Collected Steps per Second: 21,769.56943
Overall Steps per Second: 10,466.08969

Timestep Collection Time: 2.29697
Timestep Consumption Time: 2.48075
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.77772

Cumulative Model Updates: 120,522
Cumulative Timesteps: 1,005,219,874

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1005219874...
Checkpoint 1005219874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.45612
Policy Entropy: 3.04684
Value Function Loss: 0.00521

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10208
Policy Update Magnitude: 0.58077
Value Function Update Magnitude: 0.53131

Collected Steps per Second: 21,972.66387
Overall Steps per Second: 10,647.34232

Timestep Collection Time: 2.27610
Timestep Consumption Time: 2.42103
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.69713

Cumulative Model Updates: 120,528
Cumulative Timesteps: 1,005,269,886

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,546.77972
Policy Entropy: 3.03864
Value Function Loss: 0.00538

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.58531
Value Function Update Magnitude: 0.50741

Collected Steps per Second: 22,482.91963
Overall Steps per Second: 10,527.14483

Timestep Collection Time: 2.22524
Timestep Consumption Time: 2.52723
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.75248

Cumulative Model Updates: 120,534
Cumulative Timesteps: 1,005,319,916

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1005319916...
Checkpoint 1005319916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.84073
Policy Entropy: 3.02750
Value Function Loss: 0.00499

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.58101
Value Function Update Magnitude: 0.50291

Collected Steps per Second: 22,360.43905
Overall Steps per Second: 10,553.34325

Timestep Collection Time: 2.23681
Timestep Consumption Time: 2.50254
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.73935

Cumulative Model Updates: 120,540
Cumulative Timesteps: 1,005,369,932

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,077.51034
Policy Entropy: 3.01072
Value Function Loss: 0.00507

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.10652
Policy Update Magnitude: 0.57679
Value Function Update Magnitude: 0.50276

Collected Steps per Second: 22,318.94728
Overall Steps per Second: 10,507.26559

Timestep Collection Time: 2.24088
Timestep Consumption Time: 2.51907
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.75994

Cumulative Model Updates: 120,546
Cumulative Timesteps: 1,005,419,946

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1005419946...
Checkpoint 1005419946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,262.96100
Policy Entropy: 3.02554
Value Function Loss: 0.00519

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10324
Policy Update Magnitude: 0.58171
Value Function Update Magnitude: 0.50939

Collected Steps per Second: 22,177.44332
Overall Steps per Second: 10,640.71684

Timestep Collection Time: 2.25463
Timestep Consumption Time: 2.44449
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.69912

Cumulative Model Updates: 120,552
Cumulative Timesteps: 1,005,469,948

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.78827
Policy Entropy: 3.03947
Value Function Loss: 0.00513

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10305
Policy Update Magnitude: 0.57943
Value Function Update Magnitude: 0.51611

Collected Steps per Second: 22,311.85646
Overall Steps per Second: 10,557.93725

Timestep Collection Time: 2.24168
Timestep Consumption Time: 2.49561
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.73729

Cumulative Model Updates: 120,558
Cumulative Timesteps: 1,005,519,964

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1005519964...
Checkpoint 1005519964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.43592
Policy Entropy: 3.05327
Value Function Loss: 0.00511

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.57047
Value Function Update Magnitude: 0.52457

Collected Steps per Second: 22,199.47098
Overall Steps per Second: 10,485.58318

Timestep Collection Time: 2.25375
Timestep Consumption Time: 2.51776
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.77150

Cumulative Model Updates: 120,564
Cumulative Timesteps: 1,005,569,996

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,514.52210
Policy Entropy: 3.04786
Value Function Loss: 0.00512

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.57420
Value Function Update Magnitude: 0.53177

Collected Steps per Second: 22,370.84540
Overall Steps per Second: 10,536.11894

Timestep Collection Time: 2.23604
Timestep Consumption Time: 2.51163
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.74767

Cumulative Model Updates: 120,570
Cumulative Timesteps: 1,005,620,018

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1005620018...
Checkpoint 1005620018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,705.69318
Policy Entropy: 3.04232
Value Function Loss: 0.00522

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09129
Policy Update Magnitude: 0.57951
Value Function Update Magnitude: 0.55176

Collected Steps per Second: 22,186.13408
Overall Steps per Second: 10,677.44332

Timestep Collection Time: 2.25411
Timestep Consumption Time: 2.42959
PPO Batch Consumption Time: 0.27644
Total Iteration Time: 4.68371

Cumulative Model Updates: 120,576
Cumulative Timesteps: 1,005,670,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,021.30987
Policy Entropy: 3.05233
Value Function Loss: 0.00495

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10083
Policy Update Magnitude: 0.57281
Value Function Update Magnitude: 0.54353

Collected Steps per Second: 21,977.76026
Overall Steps per Second: 10,467.11138

Timestep Collection Time: 2.27576
Timestep Consumption Time: 2.50264
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.77840

Cumulative Model Updates: 120,582
Cumulative Timesteps: 1,005,720,044

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1005720044...
Checkpoint 1005720044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421.61852
Policy Entropy: 3.04829
Value Function Loss: 0.00500

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.57121
Value Function Update Magnitude: 0.52182

Collected Steps per Second: 21,647.51393
Overall Steps per Second: 10,521.02479

Timestep Collection Time: 2.31103
Timestep Consumption Time: 2.44402
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.75505

Cumulative Model Updates: 120,588
Cumulative Timesteps: 1,005,770,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,374.53187
Policy Entropy: 3.04787
Value Function Loss: 0.00490

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10006
Policy Update Magnitude: 0.56662
Value Function Update Magnitude: 0.50330

Collected Steps per Second: 21,593.96457
Overall Steps per Second: 10,572.80097

Timestep Collection Time: 2.31648
Timestep Consumption Time: 2.41472
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.73120

Cumulative Model Updates: 120,594
Cumulative Timesteps: 1,005,820,094

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1005820094...
Checkpoint 1005820094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,398.58856
Policy Entropy: 3.04586
Value Function Loss: 0.00484

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09755
Policy Update Magnitude: 0.56620
Value Function Update Magnitude: 0.50591

Collected Steps per Second: 21,683.02048
Overall Steps per Second: 10,562.31465

Timestep Collection Time: 2.30669
Timestep Consumption Time: 2.42864
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.73533

Cumulative Model Updates: 120,600
Cumulative Timesteps: 1,005,870,110

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,732.25675
Policy Entropy: 3.06494
Value Function Loss: 0.00459

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09568
Policy Update Magnitude: 0.56104
Value Function Update Magnitude: 0.50538

Collected Steps per Second: 22,058.81899
Overall Steps per Second: 10,453.48739

Timestep Collection Time: 2.26676
Timestep Consumption Time: 2.51653
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.78328

Cumulative Model Updates: 120,606
Cumulative Timesteps: 1,005,920,112

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1005920112...
Checkpoint 1005920112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.44475
Policy Entropy: 3.06136
Value Function Loss: 0.00457

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.56381
Value Function Update Magnitude: 0.52083

Collected Steps per Second: 22,182.91466
Overall Steps per Second: 10,562.36304

Timestep Collection Time: 2.25453
Timestep Consumption Time: 2.48040
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.73493

Cumulative Model Updates: 120,612
Cumulative Timesteps: 1,005,970,124

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 839.67427
Policy Entropy: 3.04510
Value Function Loss: 0.00496

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.09694
Policy Update Magnitude: 0.57526
Value Function Update Magnitude: 0.53698

Collected Steps per Second: 22,581.45180
Overall Steps per Second: 10,503.27309

Timestep Collection Time: 2.21509
Timestep Consumption Time: 2.54723
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.76233

Cumulative Model Updates: 120,618
Cumulative Timesteps: 1,006,020,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1006020144...
Checkpoint 1006020144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,587.61023
Policy Entropy: 3.03716
Value Function Loss: 0.00504

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.09846
Policy Update Magnitude: 0.57116
Value Function Update Magnitude: 0.54834

Collected Steps per Second: 20,833.80100
Overall Steps per Second: 10,310.25576

Timestep Collection Time: 2.40110
Timestep Consumption Time: 2.45077
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.85187

Cumulative Model Updates: 120,624
Cumulative Timesteps: 1,006,070,168

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.47328
Policy Entropy: 3.04253
Value Function Loss: 0.00474

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09263
Policy Update Magnitude: 0.56679
Value Function Update Magnitude: 0.55031

Collected Steps per Second: 22,575.02099
Overall Steps per Second: 10,581.53287

Timestep Collection Time: 2.21572
Timestep Consumption Time: 2.51138
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.72710

Cumulative Model Updates: 120,630
Cumulative Timesteps: 1,006,120,188

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1006120188...
Checkpoint 1006120188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,318.42598
Policy Entropy: 3.04255
Value Function Loss: 0.00466

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.56313
Value Function Update Magnitude: 0.52860

Collected Steps per Second: 22,356.21747
Overall Steps per Second: 10,499.68000

Timestep Collection Time: 2.23696
Timestep Consumption Time: 2.52604
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.76300

Cumulative Model Updates: 120,636
Cumulative Timesteps: 1,006,170,198

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.71421
Policy Entropy: 3.04253
Value Function Loss: 0.00487

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08329
Policy Update Magnitude: 0.56779
Value Function Update Magnitude: 0.50784

Collected Steps per Second: 22,379.39567
Overall Steps per Second: 10,571.51416

Timestep Collection Time: 2.23518
Timestep Consumption Time: 2.49659
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.73177

Cumulative Model Updates: 120,642
Cumulative Timesteps: 1,006,220,220

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1006220220...
Checkpoint 1006220220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,272.40669
Policy Entropy: 3.03568
Value Function Loss: 0.00491

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09197
Policy Update Magnitude: 0.57096
Value Function Update Magnitude: 0.51746

Collected Steps per Second: 22,273.89248
Overall Steps per Second: 10,560.82124

Timestep Collection Time: 2.24604
Timestep Consumption Time: 2.49109
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.73713

Cumulative Model Updates: 120,648
Cumulative Timesteps: 1,006,270,248

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,348.31210
Policy Entropy: 3.01166
Value Function Loss: 0.00507

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09540
Policy Update Magnitude: 0.57636
Value Function Update Magnitude: 0.51023

Collected Steps per Second: 22,321.02325
Overall Steps per Second: 10,585.09711

Timestep Collection Time: 2.24138
Timestep Consumption Time: 2.48507
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.72646

Cumulative Model Updates: 120,654
Cumulative Timesteps: 1,006,320,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1006320278...
Checkpoint 1006320278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,276.13532
Policy Entropy: 3.00365
Value Function Loss: 0.00506

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.09500
Policy Update Magnitude: 0.58098
Value Function Update Magnitude: 0.50097

Collected Steps per Second: 21,955.27694
Overall Steps per Second: 10,442.66985

Timestep Collection Time: 2.27790
Timestep Consumption Time: 2.51129
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.78920

Cumulative Model Updates: 120,660
Cumulative Timesteps: 1,006,370,290

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.48253
Policy Entropy: 3.00587
Value Function Loss: 0.00479

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.10348
Policy Update Magnitude: 0.56991
Value Function Update Magnitude: 0.49456

Collected Steps per Second: 21,869.51623
Overall Steps per Second: 10,470.51695

Timestep Collection Time: 2.28766
Timestep Consumption Time: 2.49052
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.77818

Cumulative Model Updates: 120,666
Cumulative Timesteps: 1,006,420,320

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1006420320...
Checkpoint 1006420320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580.40159
Policy Entropy: 3.02382
Value Function Loss: 0.00458

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.55729
Value Function Update Magnitude: 0.49014

Collected Steps per Second: 21,752.79772
Overall Steps per Second: 10,558.67390

Timestep Collection Time: 2.29984
Timestep Consumption Time: 2.43825
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.73809

Cumulative Model Updates: 120,672
Cumulative Timesteps: 1,006,470,348

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,212.39022
Policy Entropy: 3.01915
Value Function Loss: 0.00452

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11294
Policy Update Magnitude: 0.55268
Value Function Update Magnitude: 0.49466

Collected Steps per Second: 22,129.44749
Overall Steps per Second: 10,542.55867

Timestep Collection Time: 2.25952
Timestep Consumption Time: 2.48335
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.74287

Cumulative Model Updates: 120,678
Cumulative Timesteps: 1,006,520,350

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1006520350...
Checkpoint 1006520350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,333.94720
Policy Entropy: 3.01095
Value Function Loss: 0.00483

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11456
Policy Update Magnitude: 0.57321
Value Function Update Magnitude: 0.52971

Collected Steps per Second: 22,167.91812
Overall Steps per Second: 10,585.47831

Timestep Collection Time: 2.25569
Timestep Consumption Time: 2.46814
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.72383

Cumulative Model Updates: 120,684
Cumulative Timesteps: 1,006,570,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.99225
Policy Entropy: 2.99931
Value Function Loss: 0.00485

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.10995
Policy Update Magnitude: 0.58383
Value Function Update Magnitude: 0.55859

Collected Steps per Second: 22,294.58978
Overall Steps per Second: 10,491.00232

Timestep Collection Time: 2.24306
Timestep Consumption Time: 2.52370
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.76675

Cumulative Model Updates: 120,690
Cumulative Timesteps: 1,006,620,362

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1006620362...
Checkpoint 1006620362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.59414
Policy Entropy: 2.99940
Value Function Loss: 0.00473

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.11911
Policy Update Magnitude: 0.58645
Value Function Update Magnitude: 0.56805

Collected Steps per Second: 21,991.18753
Overall Steps per Second: 10,594.93134

Timestep Collection Time: 2.27500
Timestep Consumption Time: 2.44707
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.72207

Cumulative Model Updates: 120,696
Cumulative Timesteps: 1,006,670,392

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,128.28191
Policy Entropy: 3.00516
Value Function Loss: 0.00476

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11059
Policy Update Magnitude: 0.58379
Value Function Update Magnitude: 0.56527

Collected Steps per Second: 22,194.51680
Overall Steps per Second: 10,493.35912

Timestep Collection Time: 2.25299
Timestep Consumption Time: 2.51231
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.76530

Cumulative Model Updates: 120,702
Cumulative Timesteps: 1,006,720,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1006720396...
Checkpoint 1006720396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,865.55550
Policy Entropy: 3.01906
Value Function Loss: 0.00473

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.09848
Policy Update Magnitude: 0.58161
Value Function Update Magnitude: 0.55751

Collected Steps per Second: 22,047.22119
Overall Steps per Second: 10,577.03981

Timestep Collection Time: 2.26913
Timestep Consumption Time: 2.46074
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.72987

Cumulative Model Updates: 120,708
Cumulative Timesteps: 1,006,770,424

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,511.47981
Policy Entropy: 3.02952
Value Function Loss: 0.00460

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.57296
Value Function Update Magnitude: 0.54267

Collected Steps per Second: 21,833.10258
Overall Steps per Second: 10,526.62653

Timestep Collection Time: 2.29147
Timestep Consumption Time: 2.46124
PPO Batch Consumption Time: 0.28516
Total Iteration Time: 4.75271

Cumulative Model Updates: 120,714
Cumulative Timesteps: 1,006,820,454

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1006820454...
Checkpoint 1006820454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710.04793
Policy Entropy: 3.02387
Value Function Loss: 0.00457

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.56831
Value Function Update Magnitude: 0.53227

Collected Steps per Second: 21,436.37417
Overall Steps per Second: 10,398.87129

Timestep Collection Time: 2.33398
Timestep Consumption Time: 2.47731
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.81129

Cumulative Model Updates: 120,720
Cumulative Timesteps: 1,006,870,486

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,802.64817
Policy Entropy: 3.00881
Value Function Loss: 0.00446

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.11427
Policy Update Magnitude: 0.56358
Value Function Update Magnitude: 0.52876

Collected Steps per Second: 22,038.83644
Overall Steps per Second: 10,476.59151

Timestep Collection Time: 2.26981
Timestep Consumption Time: 2.50502
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.77484

Cumulative Model Updates: 120,726
Cumulative Timesteps: 1,006,920,510

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1006920510...
Checkpoint 1006920510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,137.39201
Policy Entropy: 3.00682
Value Function Loss: 0.00447

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.10639
Policy Update Magnitude: 0.55879
Value Function Update Magnitude: 0.52640

Collected Steps per Second: 21,839.77526
Overall Steps per Second: 10,435.45137

Timestep Collection Time: 2.28958
Timestep Consumption Time: 2.50216
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.79174

Cumulative Model Updates: 120,732
Cumulative Timesteps: 1,006,970,514

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.37630
Policy Entropy: 3.00667
Value Function Loss: 0.00460

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09740
Policy Update Magnitude: 0.55571
Value Function Update Magnitude: 0.50652

Collected Steps per Second: 21,906.43744
Overall Steps per Second: 10,451.57356

Timestep Collection Time: 2.28271
Timestep Consumption Time: 2.50183
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.78454

Cumulative Model Updates: 120,738
Cumulative Timesteps: 1,007,020,520

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1007020520...
Checkpoint 1007020520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,141.78780
Policy Entropy: 2.99665
Value Function Loss: 0.00483

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11894
Policy Update Magnitude: 0.56373
Value Function Update Magnitude: 0.50764

Collected Steps per Second: 21,938.57497
Overall Steps per Second: 10,368.28255

Timestep Collection Time: 2.28009
Timestep Consumption Time: 2.54443
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.82452

Cumulative Model Updates: 120,744
Cumulative Timesteps: 1,007,070,542

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,551.46511
Policy Entropy: 3.01057
Value Function Loss: 0.00475

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10474
Policy Update Magnitude: 0.56275
Value Function Update Magnitude: 0.50646

Collected Steps per Second: 22,551.87167
Overall Steps per Second: 10,646.05798

Timestep Collection Time: 2.21755
Timestep Consumption Time: 2.47996
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.69751

Cumulative Model Updates: 120,750
Cumulative Timesteps: 1,007,120,552

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1007120552...
Checkpoint 1007120552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,117.28093
Policy Entropy: 3.00426
Value Function Loss: 0.00455

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.56139
Value Function Update Magnitude: 0.49684

Collected Steps per Second: 22,063.57417
Overall Steps per Second: 10,676.28862

Timestep Collection Time: 2.26672
Timestep Consumption Time: 2.41768
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.68440

Cumulative Model Updates: 120,756
Cumulative Timesteps: 1,007,170,564

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507.54965
Policy Entropy: 2.99441
Value Function Loss: 0.00478

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10245
Policy Update Magnitude: 0.57106
Value Function Update Magnitude: 0.51039

Collected Steps per Second: 22,391.29005
Overall Steps per Second: 10,521.07702

Timestep Collection Time: 2.23417
Timestep Consumption Time: 2.52066
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.75484

Cumulative Model Updates: 120,762
Cumulative Timesteps: 1,007,220,590

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1007220590...
Checkpoint 1007220590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564.70562
Policy Entropy: 2.97243
Value Function Loss: 0.00484

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.10532
Policy Update Magnitude: 0.58276
Value Function Update Magnitude: 0.53251

Collected Steps per Second: 22,184.19589
Overall Steps per Second: 10,647.36675

Timestep Collection Time: 2.25458
Timestep Consumption Time: 2.44292
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.69750

Cumulative Model Updates: 120,768
Cumulative Timesteps: 1,007,270,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 849.70255
Policy Entropy: 2.95696
Value Function Loss: 0.00519

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10049
Policy Update Magnitude: 0.58933
Value Function Update Magnitude: 0.53522

Collected Steps per Second: 22,147.66352
Overall Steps per Second: 10,450.73594

Timestep Collection Time: 2.25812
Timestep Consumption Time: 2.52738
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.78550

Cumulative Model Updates: 120,774
Cumulative Timesteps: 1,007,320,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1007320618...
Checkpoint 1007320618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,447.34601
Policy Entropy: 2.96035
Value Function Loss: 0.00507

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.11171
Policy Update Magnitude: 0.58838
Value Function Update Magnitude: 0.54022

Collected Steps per Second: 22,013.03357
Overall Steps per Second: 10,591.27438

Timestep Collection Time: 2.27265
Timestep Consumption Time: 2.45086
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.72351

Cumulative Model Updates: 120,780
Cumulative Timesteps: 1,007,370,646

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,124.17707
Policy Entropy: 2.97812
Value Function Loss: 0.00476

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.10677
Policy Update Magnitude: 0.57488
Value Function Update Magnitude: 0.52194

Collected Steps per Second: 22,039.81705
Overall Steps per Second: 10,529.54378

Timestep Collection Time: 2.26989
Timestep Consumption Time: 2.48131
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.75120

Cumulative Model Updates: 120,786
Cumulative Timesteps: 1,007,420,674

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1007420674...
Checkpoint 1007420674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,344.15559
Policy Entropy: 2.98712
Value Function Loss: 0.00470

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.56947
Value Function Update Magnitude: 0.51707

Collected Steps per Second: 21,545.05406
Overall Steps per Second: 10,539.65526

Timestep Collection Time: 2.32090
Timestep Consumption Time: 2.42346
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.74437

Cumulative Model Updates: 120,792
Cumulative Timesteps: 1,007,470,678

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,587.68274
Policy Entropy: 2.97353
Value Function Loss: 0.00488

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.10722
Policy Update Magnitude: 0.57690
Value Function Update Magnitude: 0.53162

Collected Steps per Second: 21,657.08256
Overall Steps per Second: 10,530.36727

Timestep Collection Time: 2.30881
Timestep Consumption Time: 2.43956
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.74836

Cumulative Model Updates: 120,798
Cumulative Timesteps: 1,007,520,680

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1007520680...
Checkpoint 1007520680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.40306
Policy Entropy: 2.97130
Value Function Loss: 0.00516

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.10956
Policy Update Magnitude: 0.58434
Value Function Update Magnitude: 0.54431

Collected Steps per Second: 21,402.10303
Overall Steps per Second: 10,247.92438

Timestep Collection Time: 2.33715
Timestep Consumption Time: 2.54383
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.88099

Cumulative Model Updates: 120,804
Cumulative Timesteps: 1,007,570,700

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.06312
Policy Entropy: 2.98433
Value Function Loss: 0.00500

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11291
Policy Update Magnitude: 0.58028
Value Function Update Magnitude: 0.53272

Collected Steps per Second: 22,378.17824
Overall Steps per Second: 10,463.54102

Timestep Collection Time: 2.23530
Timestep Consumption Time: 2.54530
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.78060

Cumulative Model Updates: 120,810
Cumulative Timesteps: 1,007,620,722

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1007620722...
Checkpoint 1007620722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618.87136
Policy Entropy: 3.00300
Value Function Loss: 0.00508

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.09874
Policy Update Magnitude: 0.57801
Value Function Update Magnitude: 0.55460

Collected Steps per Second: 22,144.92686
Overall Steps per Second: 10,576.58886

Timestep Collection Time: 2.25803
Timestep Consumption Time: 2.46977
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.72780

Cumulative Model Updates: 120,816
Cumulative Timesteps: 1,007,670,726

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,742.84390
Policy Entropy: 3.00224
Value Function Loss: 0.00486

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.57832
Value Function Update Magnitude: 0.55687

Collected Steps per Second: 22,356.23509
Overall Steps per Second: 10,511.51920

Timestep Collection Time: 2.23750
Timestep Consumption Time: 2.52128
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.75878

Cumulative Model Updates: 120,822
Cumulative Timesteps: 1,007,720,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1007720748...
Checkpoint 1007720748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,961.41899
Policy Entropy: 2.98762
Value Function Loss: 0.00523

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.58071
Value Function Update Magnitude: 0.54448

Collected Steps per Second: 22,119.44678
Overall Steps per Second: 10,688.05315

Timestep Collection Time: 2.26064
Timestep Consumption Time: 2.41786
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.67849

Cumulative Model Updates: 120,828
Cumulative Timesteps: 1,007,770,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.29216
Policy Entropy: 2.97975
Value Function Loss: 0.00512

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.10799
Policy Update Magnitude: 0.57903
Value Function Update Magnitude: 0.53774

Collected Steps per Second: 22,631.32509
Overall Steps per Second: 10,803.43879

Timestep Collection Time: 2.20968
Timestep Consumption Time: 2.41922
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.62890

Cumulative Model Updates: 120,834
Cumulative Timesteps: 1,007,820,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1007820760...
Checkpoint 1007820760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,767.24409
Policy Entropy: 2.98165
Value Function Loss: 0.00516

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.10828
Policy Update Magnitude: 0.58028
Value Function Update Magnitude: 0.52236

Collected Steps per Second: 21,947.12982
Overall Steps per Second: 10,597.63074

Timestep Collection Time: 2.28039
Timestep Consumption Time: 2.44218
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.72257

Cumulative Model Updates: 120,840
Cumulative Timesteps: 1,007,870,808

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,205.15886
Policy Entropy: 3.00472
Value Function Loss: 0.00512

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.10849
Policy Update Magnitude: 0.57578
Value Function Update Magnitude: 0.51451

Collected Steps per Second: 22,200.49956
Overall Steps per Second: 10,502.69791

Timestep Collection Time: 2.25274
Timestep Consumption Time: 2.50908
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.76182

Cumulative Model Updates: 120,846
Cumulative Timesteps: 1,007,920,820

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1007920820...
Checkpoint 1007920820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.49620
Policy Entropy: 3.02961
Value Function Loss: 0.00504

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.10766
Policy Update Magnitude: 0.57403
Value Function Update Magnitude: 0.52369

Collected Steps per Second: 20,617.32441
Overall Steps per Second: 10,238.28430

Timestep Collection Time: 2.42611
Timestep Consumption Time: 2.45947
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.88558

Cumulative Model Updates: 120,852
Cumulative Timesteps: 1,007,970,840

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,670.32945
Policy Entropy: 3.03072
Value Function Loss: 0.00510

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.11952
Policy Update Magnitude: 0.57313
Value Function Update Magnitude: 0.51834

Collected Steps per Second: 21,824.38318
Overall Steps per Second: 10,556.42111

Timestep Collection Time: 2.29193
Timestep Consumption Time: 2.44642
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.73835

Cumulative Model Updates: 120,858
Cumulative Timesteps: 1,008,020,860

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1008020860...
Checkpoint 1008020860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,496.63619
Policy Entropy: 3.00635
Value Function Loss: 0.00523

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.58068
Value Function Update Magnitude: 0.51421

Collected Steps per Second: 21,624.84533
Overall Steps per Second: 10,382.40452

Timestep Collection Time: 2.31327
Timestep Consumption Time: 2.50489
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.81815

Cumulative Model Updates: 120,864
Cumulative Timesteps: 1,008,070,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,931.39685
Policy Entropy: 2.98174
Value Function Loss: 0.00518

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.12474
Policy Update Magnitude: 0.58585
Value Function Update Magnitude: 0.50368

Collected Steps per Second: 22,249.79390
Overall Steps per Second: 10,562.58108

Timestep Collection Time: 2.24820
Timestep Consumption Time: 2.48757
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.73577

Cumulative Model Updates: 120,870
Cumulative Timesteps: 1,008,120,906

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1008120906...
Checkpoint 1008120906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.00743
Policy Entropy: 2.98334
Value Function Loss: 0.00492

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.10528
Policy Update Magnitude: 0.58883
Value Function Update Magnitude: 0.48973

Collected Steps per Second: 22,059.47129
Overall Steps per Second: 10,492.73027

Timestep Collection Time: 2.26687
Timestep Consumption Time: 2.49890
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.76578

Cumulative Model Updates: 120,876
Cumulative Timesteps: 1,008,170,912

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.63328
Policy Entropy: 2.99409
Value Function Loss: 0.00474

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.10615
Policy Update Magnitude: 0.58125
Value Function Update Magnitude: 0.46952

Collected Steps per Second: 22,595.22302
Overall Steps per Second: 10,572.49760

Timestep Collection Time: 2.21401
Timestep Consumption Time: 2.51770
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.73171

Cumulative Model Updates: 120,882
Cumulative Timesteps: 1,008,220,938

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1008220938...
Checkpoint 1008220938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.49211
Policy Entropy: 2.98889
Value Function Loss: 0.00479

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.10632
Policy Update Magnitude: 0.57383
Value Function Update Magnitude: 0.45824

Collected Steps per Second: 22,022.54655
Overall Steps per Second: 10,515.95563

Timestep Collection Time: 2.27058
Timestep Consumption Time: 2.48448
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.75506

Cumulative Model Updates: 120,888
Cumulative Timesteps: 1,008,270,942

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,805.51001
Policy Entropy: 3.00115
Value Function Loss: 0.00509

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.12535
Policy Update Magnitude: 0.57891
Value Function Update Magnitude: 0.47641

Collected Steps per Second: 22,365.72927
Overall Steps per Second: 10,465.54036

Timestep Collection Time: 2.23619
Timestep Consumption Time: 2.54273
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.77892

Cumulative Model Updates: 120,894
Cumulative Timesteps: 1,008,320,956

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1008320956...
Checkpoint 1008320956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 834.76784
Policy Entropy: 3.00305
Value Function Loss: 0.00532

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.11579
Policy Update Magnitude: 0.58206
Value Function Update Magnitude: 0.49851

Collected Steps per Second: 21,982.89801
Overall Steps per Second: 10,633.79325

Timestep Collection Time: 2.27531
Timestep Consumption Time: 2.42837
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.70368

Cumulative Model Updates: 120,900
Cumulative Timesteps: 1,008,370,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.84211
Policy Entropy: 3.01480
Value Function Loss: 0.00528

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11220
Policy Update Magnitude: 0.58835
Value Function Update Magnitude: 0.52071

Collected Steps per Second: 22,687.55610
Overall Steps per Second: 10,705.83071

Timestep Collection Time: 2.20385
Timestep Consumption Time: 2.46650
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.67035

Cumulative Model Updates: 120,906
Cumulative Timesteps: 1,008,420,974

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1008420974...
Checkpoint 1008420974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.57844
Policy Entropy: 3.01562
Value Function Loss: 0.00516

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.10989
Policy Update Magnitude: 0.58655
Value Function Update Magnitude: 0.52161

Collected Steps per Second: 22,060.99710
Overall Steps per Second: 10,522.76433

Timestep Collection Time: 2.26653
Timestep Consumption Time: 2.48526
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.75179

Cumulative Model Updates: 120,912
Cumulative Timesteps: 1,008,470,976

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,571.20410
Policy Entropy: 3.04198
Value Function Loss: 0.00485

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.57884
Value Function Update Magnitude: 0.52101

Collected Steps per Second: 22,022.73067
Overall Steps per Second: 10,373.32181

Timestep Collection Time: 2.27165
Timestep Consumption Time: 2.55110
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.82276

Cumulative Model Updates: 120,918
Cumulative Timesteps: 1,008,521,004

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1008521004...
Checkpoint 1008521004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.43486
Policy Entropy: 3.02784
Value Function Loss: 0.00481

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10001
Policy Update Magnitude: 0.56832
Value Function Update Magnitude: 0.51490

Collected Steps per Second: 21,523.02094
Overall Steps per Second: 10,357.20642

Timestep Collection Time: 2.32402
Timestep Consumption Time: 2.50546
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.82949

Cumulative Model Updates: 120,924
Cumulative Timesteps: 1,008,571,024

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451.48598
Policy Entropy: 3.02985
Value Function Loss: 0.00511

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.57355
Value Function Update Magnitude: 0.50104

Collected Steps per Second: 21,923.32727
Overall Steps per Second: 10,441.28053

Timestep Collection Time: 2.28131
Timestep Consumption Time: 2.50871
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.79003

Cumulative Model Updates: 120,930
Cumulative Timesteps: 1,008,621,038

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1008621038...
Checkpoint 1008621038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,025.04567
Policy Entropy: 3.01285
Value Function Loss: 0.00503

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.10885
Policy Update Magnitude: 0.57954
Value Function Update Magnitude: 0.51709

Collected Steps per Second: 21,486.03122
Overall Steps per Second: 10,467.18445

Timestep Collection Time: 2.32728
Timestep Consumption Time: 2.44994
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.77722

Cumulative Model Updates: 120,936
Cumulative Timesteps: 1,008,671,042

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983.08834
Policy Entropy: 3.02261
Value Function Loss: 0.00512

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.09964
Policy Update Magnitude: 0.58501
Value Function Update Magnitude: 0.51187

Collected Steps per Second: 22,156.38113
Overall Steps per Second: 10,525.71588

Timestep Collection Time: 2.25813
Timestep Consumption Time: 2.49518
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.75331

Cumulative Model Updates: 120,942
Cumulative Timesteps: 1,008,721,074

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1008721074...
Checkpoint 1008721074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,619.81425
Policy Entropy: 3.04250
Value Function Loss: 0.00527

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10451
Policy Update Magnitude: 0.58716
Value Function Update Magnitude: 0.51508

Collected Steps per Second: 22,034.12685
Overall Steps per Second: 10,569.28723

Timestep Collection Time: 2.26930
Timestep Consumption Time: 2.46158
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.73088

Cumulative Model Updates: 120,948
Cumulative Timesteps: 1,008,771,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.02042
Policy Entropy: 3.04899
Value Function Loss: 0.00542

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.10518
Policy Update Magnitude: 0.58481
Value Function Update Magnitude: 0.50566

Collected Steps per Second: 22,392.47971
Overall Steps per Second: 10,524.27076

Timestep Collection Time: 2.23289
Timestep Consumption Time: 2.51803
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.75092

Cumulative Model Updates: 120,954
Cumulative Timesteps: 1,008,821,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1008821076...
Checkpoint 1008821076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,751.25905
Policy Entropy: 3.06323
Value Function Loss: 0.00529

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10130
Policy Update Magnitude: 0.58275
Value Function Update Magnitude: 0.51032

Collected Steps per Second: 22,116.33729
Overall Steps per Second: 10,642.29625

Timestep Collection Time: 2.26113
Timestep Consumption Time: 2.43785
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.69899

Cumulative Model Updates: 120,960
Cumulative Timesteps: 1,008,871,084

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.84977
Policy Entropy: 3.05423
Value Function Loss: 0.00495

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.10702
Policy Update Magnitude: 0.58281
Value Function Update Magnitude: 0.50977

Collected Steps per Second: 22,332.14428
Overall Steps per Second: 10,610.40231

Timestep Collection Time: 2.23991
Timestep Consumption Time: 2.47452
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.71443

Cumulative Model Updates: 120,966
Cumulative Timesteps: 1,008,921,106

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1008921106...
Checkpoint 1008921106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.80290
Policy Entropy: 3.06026
Value Function Loss: 0.00501

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.10365
Policy Update Magnitude: 0.57798
Value Function Update Magnitude: 0.51137

Collected Steps per Second: 22,253.99274
Overall Steps per Second: 10,475.21683

Timestep Collection Time: 2.24751
Timestep Consumption Time: 2.52719
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.77470

Cumulative Model Updates: 120,972
Cumulative Timesteps: 1,008,971,122

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667.10602
Policy Entropy: 3.07107
Value Function Loss: 0.00490

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 0.56942
Value Function Update Magnitude: 0.51574

Collected Steps per Second: 22,481.96144
Overall Steps per Second: 10,528.49212

Timestep Collection Time: 2.22498
Timestep Consumption Time: 2.52612
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.75111

Cumulative Model Updates: 120,978
Cumulative Timesteps: 1,009,021,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1009021144...
Checkpoint 1009021144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,378.86675
Policy Entropy: 3.08329
Value Function Loss: 0.00497

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.56380
Value Function Update Magnitude: 0.53495

Collected Steps per Second: 21,857.28622
Overall Steps per Second: 10,580.04229

Timestep Collection Time: 2.28775
Timestep Consumption Time: 2.43851
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.72626

Cumulative Model Updates: 120,984
Cumulative Timesteps: 1,009,071,148

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,636.61060
Policy Entropy: 3.07073
Value Function Loss: 0.00493

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09367
Policy Update Magnitude: 0.56813
Value Function Update Magnitude: 0.53820

Collected Steps per Second: 21,959.74597
Overall Steps per Second: 10,407.42096

Timestep Collection Time: 2.27753
Timestep Consumption Time: 2.52808
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.80561

Cumulative Model Updates: 120,990
Cumulative Timesteps: 1,009,121,162

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1009121162...
Checkpoint 1009121162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,858.66653
Policy Entropy: 3.06558
Value Function Loss: 0.00486

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.09843
Policy Update Magnitude: 0.56913
Value Function Update Magnitude: 0.52519

Collected Steps per Second: 21,801.38652
Overall Steps per Second: 10,581.95485

Timestep Collection Time: 2.29462
Timestep Consumption Time: 2.43286
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.72748

Cumulative Model Updates: 120,996
Cumulative Timesteps: 1,009,171,188

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,753.48046
Policy Entropy: 3.06273
Value Function Loss: 0.00482

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10104
Policy Update Magnitude: 0.56257
Value Function Update Magnitude: 0.51582

Collected Steps per Second: 22,195.89376
Overall Steps per Second: 10,517.82832

Timestep Collection Time: 2.25375
Timestep Consumption Time: 2.50236
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.75611

Cumulative Model Updates: 121,002
Cumulative Timesteps: 1,009,221,212

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1009221212...
Checkpoint 1009221212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.92406
Policy Entropy: 3.08171
Value Function Loss: 0.00469

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09374
Policy Update Magnitude: 0.55921
Value Function Update Magnitude: 0.51291

Collected Steps per Second: 21,943.46656
Overall Steps per Second: 10,368.03305

Timestep Collection Time: 2.27995
Timestep Consumption Time: 2.54546
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.82541

Cumulative Model Updates: 121,008
Cumulative Timesteps: 1,009,271,242

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.67426
Policy Entropy: 3.06788
Value Function Loss: 0.00466

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09569
Policy Update Magnitude: 0.56369
Value Function Update Magnitude: 0.51643

Collected Steps per Second: 22,369.76056
Overall Steps per Second: 10,657.16544

Timestep Collection Time: 2.23561
Timestep Consumption Time: 2.45701
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.69262

Cumulative Model Updates: 121,014
Cumulative Timesteps: 1,009,321,252

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1009321252...
Checkpoint 1009321252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,735.17148
Policy Entropy: 3.06919
Value Function Loss: 0.00460

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.56429
Value Function Update Magnitude: 0.51111

Collected Steps per Second: 22,154.68905
Overall Steps per Second: 10,694.89484

Timestep Collection Time: 2.25713
Timestep Consumption Time: 2.41856
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.67569

Cumulative Model Updates: 121,020
Cumulative Timesteps: 1,009,371,258

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,997.82994
Policy Entropy: 3.07013
Value Function Loss: 0.00467

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09365
Policy Update Magnitude: 0.55887
Value Function Update Magnitude: 0.49365

Collected Steps per Second: 21,647.04599
Overall Steps per Second: 10,474.26223

Timestep Collection Time: 2.31062
Timestep Consumption Time: 2.46471
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.77532

Cumulative Model Updates: 121,026
Cumulative Timesteps: 1,009,421,276

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1009421276...
Checkpoint 1009421276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,780.56214
Policy Entropy: 3.07600
Value Function Loss: 0.00468

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08619
Policy Update Magnitude: 0.55595
Value Function Update Magnitude: 0.49832

Collected Steps per Second: 22,177.58090
Overall Steps per Second: 10,620.59468

Timestep Collection Time: 2.25516
Timestep Consumption Time: 2.45399
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.70915

Cumulative Model Updates: 121,032
Cumulative Timesteps: 1,009,471,290

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,110.05852
Policy Entropy: 3.07467
Value Function Loss: 0.00460

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09002
Policy Update Magnitude: 0.55734
Value Function Update Magnitude: 0.49663

Collected Steps per Second: 22,376.64999
Overall Steps per Second: 10,572.84632

Timestep Collection Time: 2.23572
Timestep Consumption Time: 2.49602
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.73174

Cumulative Model Updates: 121,038
Cumulative Timesteps: 1,009,521,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1009521318...
Checkpoint 1009521318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.89730
Policy Entropy: 3.06234
Value Function Loss: 0.00460

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.56110
Value Function Update Magnitude: 0.49502

Collected Steps per Second: 22,025.80148
Overall Steps per Second: 10,645.43220

Timestep Collection Time: 2.27170
Timestep Consumption Time: 2.42853
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.70023

Cumulative Model Updates: 121,044
Cumulative Timesteps: 1,009,571,354

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,204.66464
Policy Entropy: 3.04727
Value Function Loss: 0.00474

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.56623
Value Function Update Magnitude: 0.51372

Collected Steps per Second: 21,764.97647
Overall Steps per Second: 10,378.58788

Timestep Collection Time: 2.29764
Timestep Consumption Time: 2.52075
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.81838

Cumulative Model Updates: 121,050
Cumulative Timesteps: 1,009,621,362

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1009621362...
Checkpoint 1009621362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,597.82944
Policy Entropy: 3.05122
Value Function Loss: 0.00470

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.56323
Value Function Update Magnitude: 0.52851

Collected Steps per Second: 21,206.08023
Overall Steps per Second: 10,223.26991

Timestep Collection Time: 2.35904
Timestep Consumption Time: 2.53431
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.89335

Cumulative Model Updates: 121,056
Cumulative Timesteps: 1,009,671,388

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,631.04937
Policy Entropy: 3.06378
Value Function Loss: 0.00488

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11086
Policy Update Magnitude: 0.56766
Value Function Update Magnitude: 0.51957

Collected Steps per Second: 21,949.79554
Overall Steps per Second: 10,460.54090

Timestep Collection Time: 2.27875
Timestep Consumption Time: 2.50284
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.78159

Cumulative Model Updates: 121,062
Cumulative Timesteps: 1,009,721,406

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1009721406...
Checkpoint 1009721406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,895.88478
Policy Entropy: 3.07824
Value Function Loss: 0.00506

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.57414
Value Function Update Magnitude: 0.51625

Collected Steps per Second: 21,800.46875
Overall Steps per Second: 10,562.57371

Timestep Collection Time: 2.29472
Timestep Consumption Time: 2.44144
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.73616

Cumulative Model Updates: 121,068
Cumulative Timesteps: 1,009,771,432

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.04567
Policy Entropy: 3.08208
Value Function Loss: 0.00519

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09265
Policy Update Magnitude: 0.57322
Value Function Update Magnitude: 0.53829

Collected Steps per Second: 22,190.42912
Overall Steps per Second: 10,572.06347

Timestep Collection Time: 2.25521
Timestep Consumption Time: 2.47840
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.73361

Cumulative Model Updates: 121,074
Cumulative Timesteps: 1,009,821,476

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1009821476...
Checkpoint 1009821476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.18984
Policy Entropy: 3.07700
Value Function Loss: 0.00510

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.10459
Policy Update Magnitude: 0.57025
Value Function Update Magnitude: 0.53333

Collected Steps per Second: 21,821.32581
Overall Steps per Second: 10,500.83930

Timestep Collection Time: 2.29170
Timestep Consumption Time: 2.47058
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.76229

Cumulative Model Updates: 121,080
Cumulative Timesteps: 1,009,871,484

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,634.72648
Policy Entropy: 3.07552
Value Function Loss: 0.00504

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09451
Policy Update Magnitude: 0.56298
Value Function Update Magnitude: 0.54654

Collected Steps per Second: 22,375.76354
Overall Steps per Second: 10,539.60981

Timestep Collection Time: 2.23465
Timestep Consumption Time: 2.50955
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.74420

Cumulative Model Updates: 121,086
Cumulative Timesteps: 1,009,921,486

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1009921486...
Checkpoint 1009921486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,803.54673
Policy Entropy: 3.07841
Value Function Loss: 0.00502

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.09897
Policy Update Magnitude: 0.57005
Value Function Update Magnitude: 0.55432

Collected Steps per Second: 22,152.61552
Overall Steps per Second: 10,710.50290

Timestep Collection Time: 2.25824
Timestep Consumption Time: 2.41250
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.67074

Cumulative Model Updates: 121,092
Cumulative Timesteps: 1,009,971,512

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,786.24680
Policy Entropy: 3.07290
Value Function Loss: 0.00499

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.10591
Policy Update Magnitude: 0.56914
Value Function Update Magnitude: 0.54673

Collected Steps per Second: 22,694.85598
Overall Steps per Second: 10,782.80290

Timestep Collection Time: 2.20341
Timestep Consumption Time: 2.43416
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.63757

Cumulative Model Updates: 121,098
Cumulative Timesteps: 1,010,021,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1010021518...
Checkpoint 1010021518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,015.29341
Policy Entropy: 3.07383
Value Function Loss: 0.00480

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.10567
Policy Update Magnitude: 0.56149
Value Function Update Magnitude: 0.53256

Collected Steps per Second: 21,613.00402
Overall Steps per Second: 10,345.54129

Timestep Collection Time: 2.31481
Timestep Consumption Time: 2.52109
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.83590

Cumulative Model Updates: 121,104
Cumulative Timesteps: 1,010,071,548

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,660.00404
Policy Entropy: 3.06383
Value Function Loss: 0.00479

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.55581
Value Function Update Magnitude: 0.52015

Collected Steps per Second: 22,469.52062
Overall Steps per Second: 10,572.81856

Timestep Collection Time: 2.22604
Timestep Consumption Time: 2.50477
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.73081

Cumulative Model Updates: 121,110
Cumulative Timesteps: 1,010,121,566

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1010121566...
Checkpoint 1010121566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.80226
Policy Entropy: 3.07551
Value Function Loss: 0.00456

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.10529
Policy Update Magnitude: 0.55137
Value Function Update Magnitude: 0.50077

Collected Steps per Second: 22,086.10269
Overall Steps per Second: 10,420.61462

Timestep Collection Time: 2.26495
Timestep Consumption Time: 2.53553
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.80048

Cumulative Model Updates: 121,116
Cumulative Timesteps: 1,010,171,590

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558.80814
Policy Entropy: 3.07522
Value Function Loss: 0.00453

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10057
Policy Update Magnitude: 0.54799
Value Function Update Magnitude: 0.51170

Collected Steps per Second: 22,129.28896
Overall Steps per Second: 10,466.79920

Timestep Collection Time: 2.26071
Timestep Consumption Time: 2.51897
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.77968

Cumulative Model Updates: 121,122
Cumulative Timesteps: 1,010,221,618

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1010221618...
Checkpoint 1010221618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.79457
Policy Entropy: 3.07149
Value Function Loss: 0.00456

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.10659
Policy Update Magnitude: 0.55830
Value Function Update Magnitude: 0.53783

Collected Steps per Second: 21,684.92914
Overall Steps per Second: 10,390.73726

Timestep Collection Time: 2.30658
Timestep Consumption Time: 2.50713
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.81371

Cumulative Model Updates: 121,128
Cumulative Timesteps: 1,010,271,636

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,309.07535
Policy Entropy: 3.07342
Value Function Loss: 0.00461

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.11725
Policy Update Magnitude: 0.55768
Value Function Update Magnitude: 0.52941

Collected Steps per Second: 22,005.83000
Overall Steps per Second: 10,490.06417

Timestep Collection Time: 2.27249
Timestep Consumption Time: 2.49469
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.76718

Cumulative Model Updates: 121,134
Cumulative Timesteps: 1,010,321,644

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1010321644...
Checkpoint 1010321644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464.74424
Policy Entropy: 3.07243
Value Function Loss: 0.00475

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.10795
Policy Update Magnitude: 0.55490
Value Function Update Magnitude: 0.51975

Collected Steps per Second: 21,916.58617
Overall Steps per Second: 10,461.88665

Timestep Collection Time: 2.28138
Timestep Consumption Time: 2.49788
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.77925

Cumulative Model Updates: 121,140
Cumulative Timesteps: 1,010,371,644

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,861.62981
Policy Entropy: 3.07718
Value Function Loss: 0.00475

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.10460
Policy Update Magnitude: 0.55785
Value Function Update Magnitude: 0.52478

Collected Steps per Second: 22,494.51185
Overall Steps per Second: 10,421.99777

Timestep Collection Time: 2.22365
Timestep Consumption Time: 2.57581
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.79946

Cumulative Model Updates: 121,146
Cumulative Timesteps: 1,010,421,664

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1010421664...
Checkpoint 1010421664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.09647
Policy Entropy: 3.06361
Value Function Loss: 0.00497

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09088
Policy Update Magnitude: 0.55983
Value Function Update Magnitude: 0.52959

Collected Steps per Second: 22,127.36189
Overall Steps per Second: 10,568.32897

Timestep Collection Time: 2.26082
Timestep Consumption Time: 2.47276
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.73358

Cumulative Model Updates: 121,152
Cumulative Timesteps: 1,010,471,690

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,032.30508
Policy Entropy: 3.06216
Value Function Loss: 0.00508

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08928
Policy Update Magnitude: 0.56585
Value Function Update Magnitude: 0.52451

Collected Steps per Second: 22,206.99948
Overall Steps per Second: 10,535.76039

Timestep Collection Time: 2.25262
Timestep Consumption Time: 2.49540
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.74802

Cumulative Model Updates: 121,158
Cumulative Timesteps: 1,010,521,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1010521714...
Checkpoint 1010521714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.45935
Policy Entropy: 3.06779
Value Function Loss: 0.00478

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09501
Policy Update Magnitude: 0.56194
Value Function Update Magnitude: 0.51966

Collected Steps per Second: 22,080.47127
Overall Steps per Second: 10,587.00498

Timestep Collection Time: 2.26454
Timestep Consumption Time: 2.45842
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.72296

Cumulative Model Updates: 121,164
Cumulative Timesteps: 1,010,571,716

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,308.19105
Policy Entropy: 3.05741
Value Function Loss: 0.00467

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09245
Policy Update Magnitude: 0.55238
Value Function Update Magnitude: 0.50839

Collected Steps per Second: 22,230.62338
Overall Steps per Second: 10,506.68384

Timestep Collection Time: 2.24969
Timestep Consumption Time: 2.51033
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.76002

Cumulative Model Updates: 121,170
Cumulative Timesteps: 1,010,621,728

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1010621728...
Checkpoint 1010621728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,514.44637
Policy Entropy: 3.04422
Value Function Loss: 0.00458

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11036
Policy Update Magnitude: 0.55647
Value Function Update Magnitude: 0.50829

Collected Steps per Second: 22,220.21651
Overall Steps per Second: 10,586.35504

Timestep Collection Time: 2.25245
Timestep Consumption Time: 2.47533
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.72778

Cumulative Model Updates: 121,176
Cumulative Timesteps: 1,010,671,778

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.14045
Policy Entropy: 3.02062
Value Function Loss: 0.00484

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10446
Policy Update Magnitude: 0.55824
Value Function Update Magnitude: 0.50764

Collected Steps per Second: 22,354.11317
Overall Steps per Second: 10,510.88399

Timestep Collection Time: 2.23681
Timestep Consumption Time: 2.52035
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.75716

Cumulative Model Updates: 121,182
Cumulative Timesteps: 1,010,721,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1010721780...
Checkpoint 1010721780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,738.70283
Policy Entropy: 3.03119
Value Function Loss: 0.00486

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.56204
Value Function Update Magnitude: 0.49089

Collected Steps per Second: 22,051.92681
Overall Steps per Second: 10,620.07652

Timestep Collection Time: 2.26855
Timestep Consumption Time: 2.44196
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.71051

Cumulative Model Updates: 121,188
Cumulative Timesteps: 1,010,771,806

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,902.12432
Policy Entropy: 3.03211
Value Function Loss: 0.00464

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.55692
Value Function Update Magnitude: 0.49956

Collected Steps per Second: 21,976.27638
Overall Steps per Second: 10,501.32017

Timestep Collection Time: 2.27636
Timestep Consumption Time: 2.48742
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.76378

Cumulative Model Updates: 121,194
Cumulative Timesteps: 1,010,821,832

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1010821832...
Checkpoint 1010821832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,725.39453
Policy Entropy: 3.05254
Value Function Loss: 0.00470

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09734
Policy Update Magnitude: 0.55711
Value Function Update Magnitude: 0.50074

Collected Steps per Second: 21,648.89221
Overall Steps per Second: 10,564.76364

Timestep Collection Time: 2.31014
Timestep Consumption Time: 2.42371
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.73385

Cumulative Model Updates: 121,200
Cumulative Timesteps: 1,010,871,844

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.59933
Policy Entropy: 3.03623
Value Function Loss: 0.00492

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.10600
Policy Update Magnitude: 0.58474
Value Function Update Magnitude: 0.51240

Collected Steps per Second: 21,627.41779
Overall Steps per Second: 10,588.60156

Timestep Collection Time: 2.31281
Timestep Consumption Time: 2.41114
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.72395

Cumulative Model Updates: 121,206
Cumulative Timesteps: 1,010,921,864

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1010921864...
Checkpoint 1010921864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390.85395
Policy Entropy: 3.04168
Value Function Loss: 0.00488

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.11102
Policy Update Magnitude: 0.58970
Value Function Update Magnitude: 0.53678

Collected Steps per Second: 21,947.93205
Overall Steps per Second: 10,573.58530

Timestep Collection Time: 2.27939
Timestep Consumption Time: 2.45202
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.73141

Cumulative Model Updates: 121,212
Cumulative Timesteps: 1,010,971,892

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512.43397
Policy Entropy: 3.03222
Value Function Loss: 0.00479

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.12411
Policy Update Magnitude: 0.58276
Value Function Update Magnitude: 0.54326

Collected Steps per Second: 21,731.55051
Overall Steps per Second: 10,455.73444

Timestep Collection Time: 2.30099
Timestep Consumption Time: 2.48146
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.78245

Cumulative Model Updates: 121,218
Cumulative Timesteps: 1,011,021,896

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1011021896...
Checkpoint 1011021896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,644.47089
Policy Entropy: 3.04499
Value Function Loss: 0.00456

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.12410
Policy Update Magnitude: 0.57252
Value Function Update Magnitude: 0.52885

Collected Steps per Second: 21,856.75016
Overall Steps per Second: 10,291.14154

Timestep Collection Time: 2.28762
Timestep Consumption Time: 2.57092
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.85855

Cumulative Model Updates: 121,224
Cumulative Timesteps: 1,011,071,896

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.69386
Policy Entropy: 3.03160
Value Function Loss: 0.00465

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.11434
Policy Update Magnitude: 0.57230
Value Function Update Magnitude: 0.51447

Collected Steps per Second: 22,182.58684
Overall Steps per Second: 10,410.48116

Timestep Collection Time: 2.25483
Timestep Consumption Time: 2.54975
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.80458

Cumulative Model Updates: 121,230
Cumulative Timesteps: 1,011,121,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1011121914...
Checkpoint 1011121914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.05431
Policy Entropy: 3.05288
Value Function Loss: 0.00478

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.11272
Policy Update Magnitude: 0.57001
Value Function Update Magnitude: 0.51005

Collected Steps per Second: 22,147.85887
Overall Steps per Second: 10,545.43984

Timestep Collection Time: 2.25882
Timestep Consumption Time: 2.48522
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.74404

Cumulative Model Updates: 121,236
Cumulative Timesteps: 1,011,171,942

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.38712
Policy Entropy: 3.05880
Value Function Loss: 0.00462

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.11380
Policy Update Magnitude: 0.56060
Value Function Update Magnitude: 0.50653

Collected Steps per Second: 22,333.52169
Overall Steps per Second: 10,511.54041

Timestep Collection Time: 2.23950
Timestep Consumption Time: 2.51870
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.75820

Cumulative Model Updates: 121,242
Cumulative Timesteps: 1,011,221,958

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1011221958...
Checkpoint 1011221958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,837.98212
Policy Entropy: 3.07291
Value Function Loss: 0.00477

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.10520
Policy Update Magnitude: 0.55913
Value Function Update Magnitude: 0.50659

Collected Steps per Second: 22,099.26690
Overall Steps per Second: 10,667.35496

Timestep Collection Time: 2.26360
Timestep Consumption Time: 2.42584
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.68945

Cumulative Model Updates: 121,248
Cumulative Timesteps: 1,011,271,982

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,414.48972
Policy Entropy: 3.06747
Value Function Loss: 0.00471

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.10407
Policy Update Magnitude: 0.56455
Value Function Update Magnitude: 0.51233

Collected Steps per Second: 22,298.42232
Overall Steps per Second: 10,463.97418

Timestep Collection Time: 2.24357
Timestep Consumption Time: 2.53741
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.78098

Cumulative Model Updates: 121,254
Cumulative Timesteps: 1,011,322,010

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1011322010...
Checkpoint 1011322010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392.57506
Policy Entropy: 3.06743
Value Function Loss: 0.00486

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.56195
Value Function Update Magnitude: 0.52812

Collected Steps per Second: 22,074.19307
Overall Steps per Second: 10,592.82867

Timestep Collection Time: 2.26609
Timestep Consumption Time: 2.45617
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.72225

Cumulative Model Updates: 121,260
Cumulative Timesteps: 1,011,372,032

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,592.46248
Policy Entropy: 3.05696
Value Function Loss: 0.00504

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09902
Policy Update Magnitude: 0.56492
Value Function Update Magnitude: 0.53829

Collected Steps per Second: 22,296.25772
Overall Steps per Second: 10,480.78083

Timestep Collection Time: 2.24280
Timestep Consumption Time: 2.52841
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.77121

Cumulative Model Updates: 121,266
Cumulative Timesteps: 1,011,422,038

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1011422038...
Checkpoint 1011422038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,013.26571
Policy Entropy: 3.06196
Value Function Loss: 0.00504

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.56626
Value Function Update Magnitude: 0.54178

Collected Steps per Second: 21,829.80079
Overall Steps per Second: 10,569.40280

Timestep Collection Time: 2.29136
Timestep Consumption Time: 2.44117
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.73253

Cumulative Model Updates: 121,272
Cumulative Timesteps: 1,011,472,058

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,978.36114
Policy Entropy: 3.06481
Value Function Loss: 0.00499

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.09632
Policy Update Magnitude: 0.56692
Value Function Update Magnitude: 0.53991

Collected Steps per Second: 22,057.28571
Overall Steps per Second: 10,532.31613

Timestep Collection Time: 2.26782
Timestep Consumption Time: 2.48156
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.74938

Cumulative Model Updates: 121,278
Cumulative Timesteps: 1,011,522,080

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1011522080...
Checkpoint 1011522080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,090.78209
Policy Entropy: 3.07392
Value Function Loss: 0.00481

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.10435
Policy Update Magnitude: 0.56941
Value Function Update Magnitude: 0.54952

Collected Steps per Second: 21,416.99254
Overall Steps per Second: 10,296.14973

Timestep Collection Time: 2.33590
Timestep Consumption Time: 2.52300
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.85890

Cumulative Model Updates: 121,284
Cumulative Timesteps: 1,011,572,108

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,192.59836
Policy Entropy: 3.05598
Value Function Loss: 0.00504

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10415
Policy Update Magnitude: 0.57748
Value Function Update Magnitude: 0.55540

Collected Steps per Second: 22,053.17531
Overall Steps per Second: 10,527.98431

Timestep Collection Time: 2.26815
Timestep Consumption Time: 2.48299
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.75115

Cumulative Model Updates: 121,290
Cumulative Timesteps: 1,011,622,128

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1011622128...
Checkpoint 1011622128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 772.55839
Policy Entropy: 3.05290
Value Function Loss: 0.00498

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.10878
Policy Update Magnitude: 0.57772
Value Function Update Magnitude: 0.55951

Collected Steps per Second: 21,984.35674
Overall Steps per Second: 10,465.62074

Timestep Collection Time: 2.27525
Timestep Consumption Time: 2.50420
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.77946

Cumulative Model Updates: 121,296
Cumulative Timesteps: 1,011,672,148

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655.63543
Policy Entropy: 3.05202
Value Function Loss: 0.00500

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.10470
Policy Update Magnitude: 0.57086
Value Function Update Magnitude: 0.55951

Collected Steps per Second: 20,847.44827
Overall Steps per Second: 10,039.56126

Timestep Collection Time: 2.40068
Timestep Consumption Time: 2.58440
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.98508

Cumulative Model Updates: 121,302
Cumulative Timesteps: 1,011,722,196

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1011722196...
Checkpoint 1011722196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,837.80437
Policy Entropy: 3.05135
Value Function Loss: 0.00502

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09027
Policy Update Magnitude: 0.56453
Value Function Update Magnitude: 0.52940

Collected Steps per Second: 21,850.03899
Overall Steps per Second: 10,335.45682

Timestep Collection Time: 2.28906
Timestep Consumption Time: 2.55021
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.83926

Cumulative Model Updates: 121,308
Cumulative Timesteps: 1,011,772,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,523.64903
Policy Entropy: 3.04305
Value Function Loss: 0.00495

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09380
Policy Update Magnitude: 0.56456
Value Function Update Magnitude: 0.51395

Collected Steps per Second: 22,489.54739
Overall Steps per Second: 10,726.76170

Timestep Collection Time: 2.22397
Timestep Consumption Time: 2.43876
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.66273

Cumulative Model Updates: 121,314
Cumulative Timesteps: 1,011,822,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1011822228...
Checkpoint 1011822228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.15054
Policy Entropy: 3.01869
Value Function Loss: 0.00509

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.11377
Policy Update Magnitude: 0.56974
Value Function Update Magnitude: 0.51501

Collected Steps per Second: 21,326.25239
Overall Steps per Second: 10,250.85467

Timestep Collection Time: 2.34500
Timestep Consumption Time: 2.53362
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.87862

Cumulative Model Updates: 121,320
Cumulative Timesteps: 1,011,872,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,349.46012
Policy Entropy: 3.02608
Value Function Loss: 0.00478

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11015
Policy Update Magnitude: 0.56494
Value Function Update Magnitude: 0.53652

Collected Steps per Second: 22,414.16239
Overall Steps per Second: 10,515.71419

Timestep Collection Time: 2.23171
Timestep Consumption Time: 2.52517
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.75688

Cumulative Model Updates: 121,326
Cumulative Timesteps: 1,011,922,260

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1011922260...
Checkpoint 1011922260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 994.93830
Policy Entropy: 3.01688
Value Function Loss: 0.00481

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.11700
Policy Update Magnitude: 0.56335
Value Function Update Magnitude: 0.55664

Collected Steps per Second: 21,713.65838
Overall Steps per Second: 10,587.70975

Timestep Collection Time: 2.30380
Timestep Consumption Time: 2.42092
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.72472

Cumulative Model Updates: 121,332
Cumulative Timesteps: 1,011,972,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.94275
Policy Entropy: 3.01333
Value Function Loss: 0.00478

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.10761
Policy Update Magnitude: 0.56445
Value Function Update Magnitude: 0.53956

Collected Steps per Second: 22,469.20371
Overall Steps per Second: 10,510.68960

Timestep Collection Time: 2.22527
Timestep Consumption Time: 2.53179
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.75706

Cumulative Model Updates: 121,338
Cumulative Timesteps: 1,012,022,284

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1012022284...
Checkpoint 1012022284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.28066
Policy Entropy: 3.00698
Value Function Loss: 0.00516

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10432
Policy Update Magnitude: 0.57700
Value Function Update Magnitude: 0.52818

Collected Steps per Second: 22,075.19161
Overall Steps per Second: 10,621.86418

Timestep Collection Time: 2.26535
Timestep Consumption Time: 2.44268
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.70802

Cumulative Model Updates: 121,344
Cumulative Timesteps: 1,012,072,292

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,717.45779
Policy Entropy: 3.01894
Value Function Loss: 0.00506

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11629
Policy Update Magnitude: 0.58355
Value Function Update Magnitude: 0.53695

Collected Steps per Second: 21,878.38952
Overall Steps per Second: 10,466.86753

Timestep Collection Time: 2.28618
Timestep Consumption Time: 2.49252
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.77870

Cumulative Model Updates: 121,350
Cumulative Timesteps: 1,012,122,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1012122310...
Checkpoint 1012122310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,201.04242
Policy Entropy: 3.01845
Value Function Loss: 0.00523

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.12325
Policy Update Magnitude: 0.58499
Value Function Update Magnitude: 0.54596

Collected Steps per Second: 21,687.12078
Overall Steps per Second: 10,530.13551

Timestep Collection Time: 2.30588
Timestep Consumption Time: 2.44315
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.74904

Cumulative Model Updates: 121,356
Cumulative Timesteps: 1,012,172,318

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,489.57636
Policy Entropy: 3.00556
Value Function Loss: 0.00540

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.11307
Policy Update Magnitude: 0.58638
Value Function Update Magnitude: 0.55583

Collected Steps per Second: 21,949.11224
Overall Steps per Second: 10,582.53709

Timestep Collection Time: 2.27818
Timestep Consumption Time: 2.44696
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.72514

Cumulative Model Updates: 121,362
Cumulative Timesteps: 1,012,222,322

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1012222322...
Checkpoint 1012222322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.84932
Policy Entropy: 3.00695
Value Function Loss: 0.00535

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.10572
Policy Update Magnitude: 0.57893
Value Function Update Magnitude: 0.56425

Collected Steps per Second: 21,607.32975
Overall Steps per Second: 10,483.82823

Timestep Collection Time: 2.31468
Timestep Consumption Time: 2.45591
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.77059

Cumulative Model Updates: 121,368
Cumulative Timesteps: 1,012,272,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 851.19263
Policy Entropy: 3.00079
Value Function Loss: 0.00544

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09755
Policy Update Magnitude: 0.58227
Value Function Update Magnitude: 0.54077

Collected Steps per Second: 22,474.73984
Overall Steps per Second: 10,560.55082

Timestep Collection Time: 2.22597
Timestep Consumption Time: 2.51129
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.73725

Cumulative Model Updates: 121,374
Cumulative Timesteps: 1,012,322,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1012322364...
Checkpoint 1012322364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.94930
Policy Entropy: 3.01548
Value Function Loss: 0.00545

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10038
Policy Update Magnitude: 0.58999
Value Function Update Magnitude: 0.51787

Collected Steps per Second: 22,162.19272
Overall Steps per Second: 10,592.99935

Timestep Collection Time: 2.25682
Timestep Consumption Time: 2.46479
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.72161

Cumulative Model Updates: 121,380
Cumulative Timesteps: 1,012,372,380

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.53798
Policy Entropy: 3.01888
Value Function Loss: 0.00526

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09558
Policy Update Magnitude: 0.58138
Value Function Update Magnitude: 0.51599

Collected Steps per Second: 22,481.31274
Overall Steps per Second: 10,482.31191

Timestep Collection Time: 2.22434
Timestep Consumption Time: 2.54618
PPO Batch Consumption Time: 0.29508
Total Iteration Time: 4.77051

Cumulative Model Updates: 121,386
Cumulative Timesteps: 1,012,422,386

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1012422386...
Checkpoint 1012422386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.37616
Policy Entropy: 3.03212
Value Function Loss: 0.00521

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09407
Policy Update Magnitude: 0.57099
Value Function Update Magnitude: 0.50215

Collected Steps per Second: 21,931.81350
Overall Steps per Second: 10,560.15155

Timestep Collection Time: 2.28016
Timestep Consumption Time: 2.45538
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.73554

Cumulative Model Updates: 121,392
Cumulative Timesteps: 1,012,472,394

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.49828
Policy Entropy: 3.00459
Value Function Loss: 0.00521

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09600
Policy Update Magnitude: 0.57872
Value Function Update Magnitude: 0.49621

Collected Steps per Second: 22,372.87047
Overall Steps per Second: 10,542.07695

Timestep Collection Time: 2.23592
Timestep Consumption Time: 2.50925
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.74518

Cumulative Model Updates: 121,398
Cumulative Timesteps: 1,012,522,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1012522418...
Checkpoint 1012522418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,314.46887
Policy Entropy: 2.99363
Value Function Loss: 0.00529

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10116
Policy Update Magnitude: 0.58641
Value Function Update Magnitude: 0.52399

Collected Steps per Second: 22,246.46001
Overall Steps per Second: 10,640.39757

Timestep Collection Time: 2.24764
Timestep Consumption Time: 2.45162
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.69926

Cumulative Model Updates: 121,404
Cumulative Timesteps: 1,012,572,420

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.26349
Policy Entropy: 3.00062
Value Function Loss: 0.00503

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.09496
Policy Update Magnitude: 0.59278
Value Function Update Magnitude: 0.52435

Collected Steps per Second: 22,194.56836
Overall Steps per Second: 10,509.99727

Timestep Collection Time: 2.25397
Timestep Consumption Time: 2.50587
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.75985

Cumulative Model Updates: 121,410
Cumulative Timesteps: 1,012,622,446

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1012622446...
Checkpoint 1012622446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.61606
Policy Entropy: 3.00172
Value Function Loss: 0.00486

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.57951
Value Function Update Magnitude: 0.51145

Collected Steps per Second: 21,322.49608
Overall Steps per Second: 10,502.02748

Timestep Collection Time: 2.34579
Timestep Consumption Time: 2.41691
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.76270

Cumulative Model Updates: 121,416
Cumulative Timesteps: 1,012,672,464

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.70286
Policy Entropy: 3.00293
Value Function Loss: 0.00499

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10229
Policy Update Magnitude: 0.57211
Value Function Update Magnitude: 0.51538

Collected Steps per Second: 21,922.79829
Overall Steps per Second: 10,530.56426

Timestep Collection Time: 2.28091
Timestep Consumption Time: 2.46755
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.74846

Cumulative Model Updates: 121,422
Cumulative Timesteps: 1,012,722,468

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1012722468...
Checkpoint 1012722468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,677.13573
Policy Entropy: 2.99214
Value Function Loss: 0.00517

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.11410
Policy Update Magnitude: 0.57465
Value Function Update Magnitude: 0.52641

Collected Steps per Second: 21,661.14460
Overall Steps per Second: 10,378.92364

Timestep Collection Time: 2.31003
Timestep Consumption Time: 2.51108
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.82112

Cumulative Model Updates: 121,428
Cumulative Timesteps: 1,012,772,506

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.67114
Policy Entropy: 2.98896
Value Function Loss: 0.00557

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.12681
Policy Update Magnitude: 0.58371
Value Function Update Magnitude: 0.51685

Collected Steps per Second: 21,833.88764
Overall Steps per Second: 10,516.80983

Timestep Collection Time: 2.29048
Timestep Consumption Time: 2.46477
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.75524

Cumulative Model Updates: 121,434
Cumulative Timesteps: 1,012,822,516

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1012822516...
Checkpoint 1012822516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 794.44584
Policy Entropy: 2.99036
Value Function Loss: 0.00569

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.12674
Policy Update Magnitude: 0.59545
Value Function Update Magnitude: 0.50347

Collected Steps per Second: 21,812.58956
Overall Steps per Second: 10,452.04357

Timestep Collection Time: 2.29317
Timestep Consumption Time: 2.49250
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.78567

Cumulative Model Updates: 121,440
Cumulative Timesteps: 1,012,872,536

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,616.93550
Policy Entropy: 2.99468
Value Function Loss: 0.00555

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.59286
Value Function Update Magnitude: 0.51026

Collected Steps per Second: 22,184.83199
Overall Steps per Second: 10,408.27299

Timestep Collection Time: 2.25424
Timestep Consumption Time: 2.55059
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.80483

Cumulative Model Updates: 121,446
Cumulative Timesteps: 1,012,922,546

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1012922546...
Checkpoint 1012922546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.04697
Policy Entropy: 3.00423
Value Function Loss: 0.00515

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.58619
Value Function Update Magnitude: 0.52307

Collected Steps per Second: 22,106.40921
Overall Steps per Second: 10,644.29799

Timestep Collection Time: 2.26242
Timestep Consumption Time: 2.43625
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.69867

Cumulative Model Updates: 121,452
Cumulative Timesteps: 1,012,972,560

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,431.39207
Policy Entropy: 2.99660
Value Function Loss: 0.00497

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.10520
Policy Update Magnitude: 0.58138
Value Function Update Magnitude: 0.51696

Collected Steps per Second: 22,398.13035
Overall Steps per Second: 10,604.65035

Timestep Collection Time: 2.23340
Timestep Consumption Time: 2.48378
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.71718

Cumulative Model Updates: 121,458
Cumulative Timesteps: 1,013,022,584

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1013022584...
Checkpoint 1013022584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,178.87640
Policy Entropy: 2.98791
Value Function Loss: 0.00490

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.10216
Policy Update Magnitude: 0.58556
Value Function Update Magnitude: 0.51508

Collected Steps per Second: 22,068.82362
Overall Steps per Second: 10,493.11759

Timestep Collection Time: 2.26682
Timestep Consumption Time: 2.50069
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.76751

Cumulative Model Updates: 121,464
Cumulative Timesteps: 1,013,072,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,865.63527
Policy Entropy: 2.98905
Value Function Loss: 0.00498

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.09848
Policy Update Magnitude: 0.58448
Value Function Update Magnitude: 0.52809

Collected Steps per Second: 22,310.04845
Overall Steps per Second: 10,591.19993

Timestep Collection Time: 2.24114
Timestep Consumption Time: 2.47976
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.72090

Cumulative Model Updates: 121,470
Cumulative Timesteps: 1,013,122,610

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1013122610...
Checkpoint 1013122610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349.70544
Policy Entropy: 2.99841
Value Function Loss: 0.00480

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09765
Policy Update Magnitude: 0.58091
Value Function Update Magnitude: 0.54515

Collected Steps per Second: 22,038.69318
Overall Steps per Second: 10,501.05842

Timestep Collection Time: 2.27064
Timestep Consumption Time: 2.49478
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.76542

Cumulative Model Updates: 121,476
Cumulative Timesteps: 1,013,172,652

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.69289
Policy Entropy: 2.99480
Value Function Loss: 0.00488

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10098
Policy Update Magnitude: 0.57589
Value Function Update Magnitude: 0.54830

Collected Steps per Second: 22,552.65306
Overall Steps per Second: 10,531.22436

Timestep Collection Time: 2.21828
Timestep Consumption Time: 2.53217
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.75044

Cumulative Model Updates: 121,482
Cumulative Timesteps: 1,013,222,680

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1013222680...
Checkpoint 1013222680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.26718
Policy Entropy: 2.99444
Value Function Loss: 0.00511

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08918
Policy Update Magnitude: 0.57323
Value Function Update Magnitude: 0.54656

Collected Steps per Second: 21,918.68568
Overall Steps per Second: 10,556.38596

Timestep Collection Time: 2.28180
Timestep Consumption Time: 2.45600
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.73780

Cumulative Model Updates: 121,488
Cumulative Timesteps: 1,013,272,694

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,769.36880
Policy Entropy: 2.98269
Value Function Loss: 0.00521

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09119
Policy Update Magnitude: 0.58340
Value Function Update Magnitude: 0.54125

Collected Steps per Second: 22,023.11921
Overall Steps per Second: 10,474.73396

Timestep Collection Time: 2.27080
Timestep Consumption Time: 2.50355
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.77435

Cumulative Model Updates: 121,494
Cumulative Timesteps: 1,013,322,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1013322704...
Checkpoint 1013322704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 895.46736
Policy Entropy: 2.96829
Value Function Loss: 0.00523

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09861
Policy Update Magnitude: 0.58171
Value Function Update Magnitude: 0.53084

Collected Steps per Second: 21,623.84548
Overall Steps per Second: 10,567.64140

Timestep Collection Time: 2.31300
Timestep Consumption Time: 2.41994
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.73294

Cumulative Model Updates: 121,500
Cumulative Timesteps: 1,013,372,720

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.05953
Policy Entropy: 2.96325
Value Function Loss: 0.00505

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09689
Policy Update Magnitude: 0.58398
Value Function Update Magnitude: 0.54004

Collected Steps per Second: 22,018.83384
Overall Steps per Second: 10,545.66490

Timestep Collection Time: 2.27196
Timestep Consumption Time: 2.47179
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.74375

Cumulative Model Updates: 121,506
Cumulative Timesteps: 1,013,422,746

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1013422746...
Checkpoint 1013422746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,592.29793
Policy Entropy: 2.97157
Value Function Loss: 0.00512

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.58846
Value Function Update Magnitude: 0.53982

Collected Steps per Second: 21,663.38108
Overall Steps per Second: 10,368.54392

Timestep Collection Time: 2.30887
Timestep Consumption Time: 2.51514
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.82401

Cumulative Model Updates: 121,512
Cumulative Timesteps: 1,013,472,764

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,406.12201
Policy Entropy: 2.95539
Value Function Loss: 0.00512

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10029
Policy Update Magnitude: 0.59131
Value Function Update Magnitude: 0.54019

Collected Steps per Second: 21,991.52654
Overall Steps per Second: 10,436.84780

Timestep Collection Time: 2.27388
Timestep Consumption Time: 2.51742
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.79129

Cumulative Model Updates: 121,518
Cumulative Timesteps: 1,013,522,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1013522770...
Checkpoint 1013522770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,869.12600
Policy Entropy: 2.96100
Value Function Loss: 0.00525

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.10654
Policy Update Magnitude: 0.60272
Value Function Update Magnitude: 0.53579

Collected Steps per Second: 22,182.80858
Overall Steps per Second: 10,477.29211

Timestep Collection Time: 2.25517
Timestep Consumption Time: 2.51954
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.77471

Cumulative Model Updates: 121,524
Cumulative Timesteps: 1,013,572,796

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,373.91589
Policy Entropy: 2.97117
Value Function Loss: 0.00506

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.10867
Policy Update Magnitude: 0.59536
Value Function Update Magnitude: 0.53659

Collected Steps per Second: 21,307.12980
Overall Steps per Second: 10,394.81943

Timestep Collection Time: 2.34757
Timestep Consumption Time: 2.46444
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.81201

Cumulative Model Updates: 121,530
Cumulative Timesteps: 1,013,622,816

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1013622816...
Checkpoint 1013622816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,991.68282
Policy Entropy: 2.98721
Value Function Loss: 0.00524

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.10814
Policy Update Magnitude: 0.58952
Value Function Update Magnitude: 0.53726

Collected Steps per Second: 21,199.33436
Overall Steps per Second: 10,273.66025

Timestep Collection Time: 2.36073
Timestep Consumption Time: 2.51056
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.87129

Cumulative Model Updates: 121,536
Cumulative Timesteps: 1,013,672,862

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.55344
Policy Entropy: 2.99981
Value Function Loss: 0.00496

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.10899
Policy Update Magnitude: 0.58417
Value Function Update Magnitude: 0.53780

Collected Steps per Second: 21,953.36869
Overall Steps per Second: 10,462.48975

Timestep Collection Time: 2.27801
Timestep Consumption Time: 2.50192
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.77993

Cumulative Model Updates: 121,542
Cumulative Timesteps: 1,013,722,872

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1013722872...
Checkpoint 1013722872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,958.70063
Policy Entropy: 2.98284
Value Function Loss: 0.00520

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.58607
Value Function Update Magnitude: 0.52059

Collected Steps per Second: 21,539.10618
Overall Steps per Second: 10,283.41301

Timestep Collection Time: 2.32257
Timestep Consumption Time: 2.54216
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.86473

Cumulative Model Updates: 121,548
Cumulative Timesteps: 1,013,772,898

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544.20980
Policy Entropy: 2.99790
Value Function Loss: 0.00504

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09348
Policy Update Magnitude: 0.58814
Value Function Update Magnitude: 0.51305

Collected Steps per Second: 22,061.98109
Overall Steps per Second: 10,361.42083

Timestep Collection Time: 2.26743
Timestep Consumption Time: 2.56048
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.82791

Cumulative Model Updates: 121,554
Cumulative Timesteps: 1,013,822,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1013822922...
Checkpoint 1013822922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.98420
Policy Entropy: 3.00252
Value Function Loss: 0.00498

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09304
Policy Update Magnitude: 0.57574
Value Function Update Magnitude: 0.52113

Collected Steps per Second: 21,525.71848
Overall Steps per Second: 10,259.31259

Timestep Collection Time: 2.32327
Timestep Consumption Time: 2.55133
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.87460

Cumulative Model Updates: 121,560
Cumulative Timesteps: 1,013,872,932

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,379.67705
Policy Entropy: 3.00953
Value Function Loss: 0.00495

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10343
Policy Update Magnitude: 0.57903
Value Function Update Magnitude: 0.51201

Collected Steps per Second: 22,423.89821
Overall Steps per Second: 10,625.23175

Timestep Collection Time: 2.23030
Timestep Consumption Time: 2.47661
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.70691

Cumulative Model Updates: 121,566
Cumulative Timesteps: 1,013,922,944

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1013922944...
Checkpoint 1013922944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.60657
Policy Entropy: 2.99336
Value Function Loss: 0.00494

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.10920
Policy Update Magnitude: 0.57842
Value Function Update Magnitude: 0.50741

Collected Steps per Second: 22,105.58039
Overall Steps per Second: 10,434.55806

Timestep Collection Time: 2.26368
Timestep Consumption Time: 2.53192
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.79560

Cumulative Model Updates: 121,572
Cumulative Timesteps: 1,013,972,984

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,396.92624
Policy Entropy: 2.99355
Value Function Loss: 0.00485

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.10690
Policy Update Magnitude: 0.57207
Value Function Update Magnitude: 0.50903

Collected Steps per Second: 22,245.44730
Overall Steps per Second: 10,450.34189

Timestep Collection Time: 2.24891
Timestep Consumption Time: 2.53830
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.78721

Cumulative Model Updates: 121,578
Cumulative Timesteps: 1,014,023,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1014023012...
Checkpoint 1014023012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.92185
Policy Entropy: 2.98174
Value Function Loss: 0.00483

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10262
Policy Update Magnitude: 0.57266
Value Function Update Magnitude: 0.49819

Collected Steps per Second: 21,935.22080
Overall Steps per Second: 10,539.06236

Timestep Collection Time: 2.28026
Timestep Consumption Time: 2.46570
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.74596

Cumulative Model Updates: 121,584
Cumulative Timesteps: 1,014,073,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.37027
Policy Entropy: 2.97343
Value Function Loss: 0.00486

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09712
Policy Update Magnitude: 0.58295
Value Function Update Magnitude: 0.49396

Collected Steps per Second: 22,244.78458
Overall Steps per Second: 10,590.45513

Timestep Collection Time: 2.24898
Timestep Consumption Time: 2.47490
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.72388

Cumulative Model Updates: 121,590
Cumulative Timesteps: 1,014,123,058

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1014123058...
Checkpoint 1014123058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.15780
Policy Entropy: 2.97753
Value Function Loss: 0.00495

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.09963
Policy Update Magnitude: 0.58341
Value Function Update Magnitude: 0.51102

Collected Steps per Second: 22,148.56489
Overall Steps per Second: 10,643.85966

Timestep Collection Time: 2.25830
Timestep Consumption Time: 2.44094
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.69924

Cumulative Model Updates: 121,596
Cumulative Timesteps: 1,014,173,076

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.17070
Policy Entropy: 2.97294
Value Function Loss: 0.00506

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09701
Policy Update Magnitude: 0.58253
Value Function Update Magnitude: 0.51366

Collected Steps per Second: 21,960.10686
Overall Steps per Second: 10,420.34063

Timestep Collection Time: 2.27704
Timestep Consumption Time: 2.52165
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.79869

Cumulative Model Updates: 121,602
Cumulative Timesteps: 1,014,223,080

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1014223080...
Checkpoint 1014223080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,922.40161
Policy Entropy: 2.97803
Value Function Loss: 0.00498

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09710
Policy Update Magnitude: 0.58706
Value Function Update Magnitude: 0.52199

Collected Steps per Second: 21,898.09209
Overall Steps per Second: 10,577.45131

Timestep Collection Time: 2.28403
Timestep Consumption Time: 2.44451
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.72855

Cumulative Model Updates: 121,608
Cumulative Timesteps: 1,014,273,096

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,034.83096
Policy Entropy: 2.97126
Value Function Loss: 0.00499

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10594
Policy Update Magnitude: 0.58316
Value Function Update Magnitude: 0.52350

Collected Steps per Second: 21,825.40184
Overall Steps per Second: 10,533.18642

Timestep Collection Time: 2.29302
Timestep Consumption Time: 2.45825
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.75127

Cumulative Model Updates: 121,614
Cumulative Timesteps: 1,014,323,142

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1014323142...
Checkpoint 1014323142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,915.58912
Policy Entropy: 2.98539
Value Function Loss: 0.00538

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.09792
Policy Update Magnitude: 0.58992
Value Function Update Magnitude: 0.52089

Collected Steps per Second: 21,817.64819
Overall Steps per Second: 10,600.91395

Timestep Collection Time: 2.29236
Timestep Consumption Time: 2.42553
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.71790

Cumulative Model Updates: 121,620
Cumulative Timesteps: 1,014,373,156

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.16069
Policy Entropy: 2.97831
Value Function Loss: 0.00542

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.09896
Policy Update Magnitude: 0.60073
Value Function Update Magnitude: 0.54178

Collected Steps per Second: 22,372.07713
Overall Steps per Second: 10,503.60189

Timestep Collection Time: 2.23564
Timestep Consumption Time: 2.52615
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.76180

Cumulative Model Updates: 121,626
Cumulative Timesteps: 1,014,423,172

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1014423172...
Checkpoint 1014423172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.46708
Policy Entropy: 2.97690
Value Function Loss: 0.00567

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.10621
Policy Update Magnitude: 0.60596
Value Function Update Magnitude: 0.53778

Collected Steps per Second: 21,808.48828
Overall Steps per Second: 10,545.91263

Timestep Collection Time: 2.29296
Timestep Consumption Time: 2.44878
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.74174

Cumulative Model Updates: 121,632
Cumulative Timesteps: 1,014,473,178

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,819.43780
Policy Entropy: 2.98474
Value Function Loss: 0.00523

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.11541
Policy Update Magnitude: 0.59386
Value Function Update Magnitude: 0.54251

Collected Steps per Second: 22,459.87162
Overall Steps per Second: 10,553.40004

Timestep Collection Time: 2.22619
Timestep Consumption Time: 2.51162
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.73781

Cumulative Model Updates: 121,638
Cumulative Timesteps: 1,014,523,178

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1014523178...
Checkpoint 1014523178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,074.24902
Policy Entropy: 2.99711
Value Function Loss: 0.00491

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.10522
Policy Update Magnitude: 0.57755
Value Function Update Magnitude: 0.53807

Collected Steps per Second: 22,301.44470
Overall Steps per Second: 10,684.40159

Timestep Collection Time: 2.24255
Timestep Consumption Time: 2.43830
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.68084

Cumulative Model Updates: 121,644
Cumulative Timesteps: 1,014,573,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,516.34657
Policy Entropy: 3.00528
Value Function Loss: 0.00487

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.09905
Policy Update Magnitude: 0.57115
Value Function Update Magnitude: 0.51747

Collected Steps per Second: 22,318.33203
Overall Steps per Second: 10,485.19912

Timestep Collection Time: 2.24040
Timestep Consumption Time: 2.52842
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.76882

Cumulative Model Updates: 121,650
Cumulative Timesteps: 1,014,623,192

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1014623192...
Checkpoint 1014623192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,609.94331
Policy Entropy: 3.01816
Value Function Loss: 0.00484

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11010
Policy Update Magnitude: 0.56742
Value Function Update Magnitude: 0.50807

Collected Steps per Second: 22,106.72823
Overall Steps per Second: 10,648.61011

Timestep Collection Time: 2.26194
Timestep Consumption Time: 2.43389
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.69582

Cumulative Model Updates: 121,656
Cumulative Timesteps: 1,014,673,196

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,196.57367
Policy Entropy: 3.04075
Value Function Loss: 0.00479

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09716
Policy Update Magnitude: 0.56344
Value Function Update Magnitude: 0.49332

Collected Steps per Second: 21,893.29499
Overall Steps per Second: 10,390.60599

Timestep Collection Time: 2.28618
Timestep Consumption Time: 2.53086
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.81704

Cumulative Model Updates: 121,662
Cumulative Timesteps: 1,014,723,248

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1014723248...
Checkpoint 1014723248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,493.83972
Policy Entropy: 3.03453
Value Function Loss: 0.00469

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.56152
Value Function Update Magnitude: 0.48394

Collected Steps per Second: 21,593.94495
Overall Steps per Second: 10,403.03912

Timestep Collection Time: 2.31546
Timestep Consumption Time: 2.49082
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.80629

Cumulative Model Updates: 121,668
Cumulative Timesteps: 1,014,773,248

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,959.87579
Policy Entropy: 3.02112
Value Function Loss: 0.00492

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.09489
Policy Update Magnitude: 0.56465
Value Function Update Magnitude: 0.50659

Collected Steps per Second: 22,134.85074
Overall Steps per Second: 10,614.50304

Timestep Collection Time: 2.26006
Timestep Consumption Time: 2.45293
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.71299

Cumulative Model Updates: 121,674
Cumulative Timesteps: 1,014,823,274

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1014823274...
Checkpoint 1014823274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.52212
Policy Entropy: 3.00496
Value Function Loss: 0.00489

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08696
Policy Update Magnitude: 0.56522
Value Function Update Magnitude: 0.49139

Collected Steps per Second: 21,417.64860
Overall Steps per Second: 10,279.04677

Timestep Collection Time: 2.33508
Timestep Consumption Time: 2.53035
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.86543

Cumulative Model Updates: 121,680
Cumulative Timesteps: 1,014,873,286

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.24472
Policy Entropy: 3.00965
Value Function Loss: 0.00517

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.57501
Value Function Update Magnitude: 0.47143

Collected Steps per Second: 21,516.91311
Overall Steps per Second: 10,457.47216

Timestep Collection Time: 2.32375
Timestep Consumption Time: 2.45752
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.78127

Cumulative Model Updates: 121,686
Cumulative Timesteps: 1,014,923,286

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1014923286...
Checkpoint 1014923286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 941.20548
Policy Entropy: 3.00477
Value Function Loss: 0.00527

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.10908
Policy Update Magnitude: 0.57955
Value Function Update Magnitude: 0.49887

Collected Steps per Second: 21,873.94972
Overall Steps per Second: 10,624.25960

Timestep Collection Time: 2.28601
Timestep Consumption Time: 2.42058
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.70659

Cumulative Model Updates: 121,692
Cumulative Timesteps: 1,014,973,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,536.28248
Policy Entropy: 3.01607
Value Function Loss: 0.00506

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.11429
Policy Update Magnitude: 0.57684
Value Function Update Magnitude: 0.52465

Collected Steps per Second: 21,985.88954
Overall Steps per Second: 10,462.43699

Timestep Collection Time: 2.27419
Timestep Consumption Time: 2.50482
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.77900

Cumulative Model Updates: 121,698
Cumulative Timesteps: 1,015,023,290

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1015023290...
Checkpoint 1015023290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.81082
Policy Entropy: 3.00720
Value Function Loss: 0.00504

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10264
Policy Update Magnitude: 0.57155
Value Function Update Magnitude: 0.51940

Collected Steps per Second: 22,110.45128
Overall Steps per Second: 10,583.59197

Timestep Collection Time: 2.26201
Timestep Consumption Time: 2.46361
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.72562

Cumulative Model Updates: 121,704
Cumulative Timesteps: 1,015,073,304

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,704.18472
Policy Entropy: 2.99944
Value Function Loss: 0.00507

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10189
Policy Update Magnitude: 0.58135
Value Function Update Magnitude: 0.54220

Collected Steps per Second: 22,619.80435
Overall Steps per Second: 10,560.50909

Timestep Collection Time: 2.21063
Timestep Consumption Time: 2.52437
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.73500

Cumulative Model Updates: 121,710
Cumulative Timesteps: 1,015,123,308

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1015123308...
Checkpoint 1015123308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.56481
Policy Entropy: 2.99457
Value Function Loss: 0.00524

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10204
Policy Update Magnitude: 0.58381
Value Function Update Magnitude: 0.57102

Collected Steps per Second: 21,950.22270
Overall Steps per Second: 10,651.13358

Timestep Collection Time: 2.27897
Timestep Consumption Time: 2.41761
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.69659

Cumulative Model Updates: 121,716
Cumulative Timesteps: 1,015,173,332

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,379.44978
Policy Entropy: 3.01523
Value Function Loss: 0.00569

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.11081
Policy Update Magnitude: 0.58794
Value Function Update Magnitude: 0.57247

Collected Steps per Second: 22,488.09887
Overall Steps per Second: 10,751.74784

Timestep Collection Time: 2.22349
Timestep Consumption Time: 2.42711
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.65059

Cumulative Model Updates: 121,722
Cumulative Timesteps: 1,015,223,334

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1015223334...
Checkpoint 1015223334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.74566
Policy Entropy: 3.01531
Value Function Loss: 0.00561

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.58533
Value Function Update Magnitude: 0.56330

Collected Steps per Second: 21,975.14026
Overall Steps per Second: 10,639.82395

Timestep Collection Time: 2.27657
Timestep Consumption Time: 2.42539
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.70196

Cumulative Model Updates: 121,728
Cumulative Timesteps: 1,015,273,362

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 984.31275
Policy Entropy: 3.01887
Value Function Loss: 0.00571

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.10630
Policy Update Magnitude: 0.58703
Value Function Update Magnitude: 0.54891

Collected Steps per Second: 22,406.85019
Overall Steps per Second: 10,579.28234

Timestep Collection Time: 2.23200
Timestep Consumption Time: 2.49536
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.72735

Cumulative Model Updates: 121,734
Cumulative Timesteps: 1,015,323,374

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1015323374...
Checkpoint 1015323374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.06133
Policy Entropy: 3.01350
Value Function Loss: 0.00546

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09737
Policy Update Magnitude: 0.58948
Value Function Update Magnitude: 0.53820

Collected Steps per Second: 21,722.85626
Overall Steps per Second: 10,577.79895

Timestep Collection Time: 2.30320
Timestep Consumption Time: 2.42671
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.72991

Cumulative Model Updates: 121,740
Cumulative Timesteps: 1,015,373,406

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 913.10895
Policy Entropy: 3.02257
Value Function Loss: 0.00551

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09879
Policy Update Magnitude: 0.58474
Value Function Update Magnitude: 0.54312

Collected Steps per Second: 22,073.47438
Overall Steps per Second: 10,491.86852

Timestep Collection Time: 2.26643
Timestep Consumption Time: 2.50183
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.76826

Cumulative Model Updates: 121,746
Cumulative Timesteps: 1,015,423,434

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1015423434...
Checkpoint 1015423434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,813.00544
Policy Entropy: 3.02877
Value Function Loss: 0.00518

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.09711
Policy Update Magnitude: 0.57255
Value Function Update Magnitude: 0.53443

Collected Steps per Second: 21,516.24591
Overall Steps per Second: 10,228.39636

Timestep Collection Time: 2.32513
Timestep Consumption Time: 2.56596
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.89109

Cumulative Model Updates: 121,752
Cumulative Timesteps: 1,015,473,462

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,119.45259
Policy Entropy: 3.02331
Value Function Loss: 0.00503

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10195
Policy Update Magnitude: 0.56481
Value Function Update Magnitude: 0.51342

Collected Steps per Second: 21,554.83181
Overall Steps per Second: 10,538.87808

Timestep Collection Time: 2.32115
Timestep Consumption Time: 2.42622
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.74737

Cumulative Model Updates: 121,758
Cumulative Timesteps: 1,015,523,494

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1015523494...
Checkpoint 1015523494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,741.76820
Policy Entropy: 3.00951
Value Function Loss: 0.00487

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09660
Policy Update Magnitude: 0.56341
Value Function Update Magnitude: 0.50435

Collected Steps per Second: 21,787.10564
Overall Steps per Second: 10,542.04096

Timestep Collection Time: 2.29494
Timestep Consumption Time: 2.44798
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.74291

Cumulative Model Updates: 121,764
Cumulative Timesteps: 1,015,573,494

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 849.96021
Policy Entropy: 3.00469
Value Function Loss: 0.00499

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.09937
Policy Update Magnitude: 0.57091
Value Function Update Magnitude: 0.49576

Collected Steps per Second: 21,552.87263
Overall Steps per Second: 10,534.59922

Timestep Collection Time: 2.32127
Timestep Consumption Time: 2.42784
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.74911

Cumulative Model Updates: 121,770
Cumulative Timesteps: 1,015,623,524

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1015623524...
Checkpoint 1015623524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,644.45023
Policy Entropy: 3.00379
Value Function Loss: 0.00506

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10035
Policy Update Magnitude: 0.57338
Value Function Update Magnitude: 0.49385

Collected Steps per Second: 21,950.37584
Overall Steps per Second: 10,539.53445

Timestep Collection Time: 2.27896
Timestep Consumption Time: 2.46736
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.74632

Cumulative Model Updates: 121,776
Cumulative Timesteps: 1,015,673,548

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 884.03388
Policy Entropy: 3.02684
Value Function Loss: 0.00496

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10166
Policy Update Magnitude: 0.56955
Value Function Update Magnitude: 0.49793

Collected Steps per Second: 21,937.25442
Overall Steps per Second: 10,518.66023

Timestep Collection Time: 2.28069
Timestep Consumption Time: 2.47581
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.75650

Cumulative Model Updates: 121,782
Cumulative Timesteps: 1,015,723,580

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1015723580...
Checkpoint 1015723580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.91918
Policy Entropy: 3.02860
Value Function Loss: 0.00486

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09168
Policy Update Magnitude: 0.56392
Value Function Update Magnitude: 0.50568

Collected Steps per Second: 22,269.13388
Overall Steps per Second: 10,634.16231

Timestep Collection Time: 2.24526
Timestep Consumption Time: 2.45657
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.70183

Cumulative Model Updates: 121,788
Cumulative Timesteps: 1,015,773,580

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.67508
Policy Entropy: 3.03815
Value Function Loss: 0.00488

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.56343
Value Function Update Magnitude: 0.50280

Collected Steps per Second: 22,385.98899
Overall Steps per Second: 10,554.34287

Timestep Collection Time: 2.23479
Timestep Consumption Time: 2.50525
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.74004

Cumulative Model Updates: 121,794
Cumulative Timesteps: 1,015,823,608

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1015823608...
Checkpoint 1015823608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.80443
Policy Entropy: 3.02094
Value Function Loss: 0.00538

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10359
Policy Update Magnitude: 0.57708
Value Function Update Magnitude: 0.51825

Collected Steps per Second: 22,186.09281
Overall Steps per Second: 10,544.56680

Timestep Collection Time: 2.25393
Timestep Consumption Time: 2.48841
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.74235

Cumulative Model Updates: 121,800
Cumulative Timesteps: 1,015,873,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 914.49430
Policy Entropy: 3.02892
Value Function Loss: 0.00534

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10375
Policy Update Magnitude: 0.57795
Value Function Update Magnitude: 0.55272

Collected Steps per Second: 22,544.72565
Overall Steps per Second: 10,646.27351

Timestep Collection Time: 2.21826
Timestep Consumption Time: 2.47916
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.69742

Cumulative Model Updates: 121,806
Cumulative Timesteps: 1,015,923,624

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1015923624...
Checkpoint 1015923624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.35622
Policy Entropy: 3.01631
Value Function Loss: 0.00513

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10513
Policy Update Magnitude: 0.57292
Value Function Update Magnitude: 0.53667

Collected Steps per Second: 22,203.81301
Overall Steps per Second: 10,465.62576

Timestep Collection Time: 2.25250
Timestep Consumption Time: 2.52639
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.77888

Cumulative Model Updates: 121,812
Cumulative Timesteps: 1,015,973,638

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,361.39324
Policy Entropy: 3.03418
Value Function Loss: 0.00474

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09473
Policy Update Magnitude: 0.56507
Value Function Update Magnitude: 0.52259

Collected Steps per Second: 21,884.45646
Overall Steps per Second: 10,437.50769

Timestep Collection Time: 2.28564
Timestep Consumption Time: 2.50669
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.79233

Cumulative Model Updates: 121,818
Cumulative Timesteps: 1,016,023,658

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1016023658...
Checkpoint 1016023658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.17110
Policy Entropy: 3.04260
Value Function Loss: 0.00477

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09361
Policy Update Magnitude: 0.55762
Value Function Update Magnitude: 0.50807

Collected Steps per Second: 21,805.52008
Overall Steps per Second: 10,607.91493

Timestep Collection Time: 2.29364
Timestep Consumption Time: 2.42114
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.71478

Cumulative Model Updates: 121,824
Cumulative Timesteps: 1,016,073,672

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.91132
Policy Entropy: 3.05172
Value Function Loss: 0.00488

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10404
Policy Update Magnitude: 0.55551
Value Function Update Magnitude: 0.51488

Collected Steps per Second: 21,337.41115
Overall Steps per Second: 10,228.70393

Timestep Collection Time: 2.34452
Timestep Consumption Time: 2.54623
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.89075

Cumulative Model Updates: 121,830
Cumulative Timesteps: 1,016,123,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1016123698...
Checkpoint 1016123698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.99801
Policy Entropy: 3.03742
Value Function Loss: 0.00500

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09830
Policy Update Magnitude: 0.55309
Value Function Update Magnitude: 0.51495

Collected Steps per Second: 21,234.68454
Overall Steps per Second: 10,407.61147

Timestep Collection Time: 2.35483
Timestep Consumption Time: 2.44973
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.80456

Cumulative Model Updates: 121,836
Cumulative Timesteps: 1,016,173,702

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.32272
Policy Entropy: 3.03829
Value Function Loss: 0.00490

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09386
Policy Update Magnitude: 0.56353
Value Function Update Magnitude: 0.51520

Collected Steps per Second: 21,781.74405
Overall Steps per Second: 10,499.48409

Timestep Collection Time: 2.29642
Timestep Consumption Time: 2.46763
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.76404

Cumulative Model Updates: 121,842
Cumulative Timesteps: 1,016,223,722

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1016223722...
Checkpoint 1016223722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 859.93516
Policy Entropy: 3.02663
Value Function Loss: 0.00479

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09578
Policy Update Magnitude: 0.56513
Value Function Update Magnitude: 0.53063

Collected Steps per Second: 21,898.79795
Overall Steps per Second: 10,373.04443

Timestep Collection Time: 2.28497
Timestep Consumption Time: 2.53888
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.82385

Cumulative Model Updates: 121,848
Cumulative Timesteps: 1,016,273,760

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.85941
Policy Entropy: 3.03043
Value Function Loss: 0.00486

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.10482
Policy Update Magnitude: 0.57182
Value Function Update Magnitude: 0.53511

Collected Steps per Second: 22,520.94206
Overall Steps per Second: 10,747.64761

Timestep Collection Time: 2.22024
Timestep Consumption Time: 2.43212
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.65237

Cumulative Model Updates: 121,854
Cumulative Timesteps: 1,016,323,762

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1016323762...
Checkpoint 1016323762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,737.04997
Policy Entropy: 3.02165
Value Function Loss: 0.00535

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10347
Policy Update Magnitude: 0.57665
Value Function Update Magnitude: 0.54887

Collected Steps per Second: 21,525.38766
Overall Steps per Second: 10,414.73154

Timestep Collection Time: 2.32395
Timestep Consumption Time: 2.47924
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.80320

Cumulative Model Updates: 121,860
Cumulative Timesteps: 1,016,373,786

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.52507
Policy Entropy: 3.02829
Value Function Loss: 0.00523

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.10718
Policy Update Magnitude: 0.57722
Value Function Update Magnitude: 0.55238

Collected Steps per Second: 22,358.72879
Overall Steps per Second: 10,722.26688

Timestep Collection Time: 2.23752
Timestep Consumption Time: 2.42829
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.66580

Cumulative Model Updates: 121,866
Cumulative Timesteps: 1,016,423,814

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1016423814...
Checkpoint 1016423814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,339.27040
Policy Entropy: 3.04126
Value Function Loss: 0.00519

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.10911
Policy Update Magnitude: 0.57139
Value Function Update Magnitude: 0.55268

Collected Steps per Second: 22,094.03167
Overall Steps per Second: 10,617.14964

Timestep Collection Time: 2.26305
Timestep Consumption Time: 2.44631
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.70936

Cumulative Model Updates: 121,872
Cumulative Timesteps: 1,016,473,814

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.57325
Policy Entropy: 3.03287
Value Function Loss: 0.00494

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.11447
Policy Update Magnitude: 0.56104
Value Function Update Magnitude: 0.54437

Collected Steps per Second: 22,466.42093
Overall Steps per Second: 10,509.86719

Timestep Collection Time: 2.22706
Timestep Consumption Time: 2.53361
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.76067

Cumulative Model Updates: 121,878
Cumulative Timesteps: 1,016,523,848

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1016523848...
Checkpoint 1016523848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.72519
Policy Entropy: 3.02829
Value Function Loss: 0.00513

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.10712
Policy Update Magnitude: 0.56864
Value Function Update Magnitude: 0.53689

Collected Steps per Second: 22,004.64768
Overall Steps per Second: 10,599.91071

Timestep Collection Time: 2.27352
Timestep Consumption Time: 2.44614
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.71966

Cumulative Model Updates: 121,884
Cumulative Timesteps: 1,016,573,876

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.10988
Policy Entropy: 3.00961
Value Function Loss: 0.00531

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10583
Policy Update Magnitude: 0.58508
Value Function Update Magnitude: 0.54502

Collected Steps per Second: 21,868.92029
Overall Steps per Second: 10,435.70715

Timestep Collection Time: 2.28681
Timestep Consumption Time: 2.50539
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.79220

Cumulative Model Updates: 121,890
Cumulative Timesteps: 1,016,623,886

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1016623886...
Checkpoint 1016623886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,570.48142
Policy Entropy: 3.01284
Value Function Loss: 0.00539

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11448
Policy Update Magnitude: 0.59179
Value Function Update Magnitude: 0.54580

Collected Steps per Second: 21,672.62038
Overall Steps per Second: 10,574.41048

Timestep Collection Time: 2.30789
Timestep Consumption Time: 2.42221
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.73010

Cumulative Model Updates: 121,896
Cumulative Timesteps: 1,016,673,904

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,939.22439
Policy Entropy: 3.02235
Value Function Loss: 0.00539

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.10994
Policy Update Magnitude: 0.58145
Value Function Update Magnitude: 0.55427

Collected Steps per Second: 22,034.61071
Overall Steps per Second: 10,542.61720

Timestep Collection Time: 2.26970
Timestep Consumption Time: 2.47409
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.74379

Cumulative Model Updates: 121,902
Cumulative Timesteps: 1,016,723,916

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1016723916...
Checkpoint 1016723916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,684.81462
Policy Entropy: 3.02919
Value Function Loss: 0.00531

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.10584
Policy Update Magnitude: 0.57397
Value Function Update Magnitude: 0.55308

Collected Steps per Second: 21,779.58573
Overall Steps per Second: 10,610.72573

Timestep Collection Time: 2.29674
Timestep Consumption Time: 2.41755
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.71429

Cumulative Model Updates: 121,908
Cumulative Timesteps: 1,016,773,938

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.20379
Policy Entropy: 3.03546
Value Function Loss: 0.00542

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10021
Policy Update Magnitude: 0.57887
Value Function Update Magnitude: 0.53166

Collected Steps per Second: 22,333.26278
Overall Steps per Second: 10,566.05607

Timestep Collection Time: 2.23908
Timestep Consumption Time: 2.49362
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.73270

Cumulative Model Updates: 121,914
Cumulative Timesteps: 1,016,823,944

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1016823944...
Checkpoint 1016823944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.86416
Policy Entropy: 3.03269
Value Function Loss: 0.00524

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.58488
Value Function Update Magnitude: 0.52348

Collected Steps per Second: 21,989.45609
Overall Steps per Second: 10,604.25238

Timestep Collection Time: 2.27409
Timestep Consumption Time: 2.44157
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.71566

Cumulative Model Updates: 121,920
Cumulative Timesteps: 1,016,873,950

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.99725
Policy Entropy: 3.02901
Value Function Loss: 0.00509

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.11556
Policy Update Magnitude: 0.57779
Value Function Update Magnitude: 0.51862

Collected Steps per Second: 22,573.57233
Overall Steps per Second: 10,760.60657

Timestep Collection Time: 2.21525
Timestep Consumption Time: 2.43189
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.64714

Cumulative Model Updates: 121,926
Cumulative Timesteps: 1,016,923,956

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1016923956...
Checkpoint 1016923956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,052.22397
Policy Entropy: 3.03235
Value Function Loss: 0.00483

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.11827
Policy Update Magnitude: 0.57093
Value Function Update Magnitude: 0.51944

Collected Steps per Second: 21,699.04493
Overall Steps per Second: 10,327.71014

Timestep Collection Time: 2.30572
Timestep Consumption Time: 2.53872
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.84444

Cumulative Model Updates: 121,932
Cumulative Timesteps: 1,016,973,988

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.36239
Policy Entropy: 3.03158
Value Function Loss: 0.00496

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.12562
Policy Update Magnitude: 0.57031
Value Function Update Magnitude: 0.51844

Collected Steps per Second: 22,437.66600
Overall Steps per Second: 10,647.08226

Timestep Collection Time: 2.22947
Timestep Consumption Time: 2.46891
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.69838

Cumulative Model Updates: 121,938
Cumulative Timesteps: 1,017,024,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1017024012...
Checkpoint 1017024012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,583.39564
Policy Entropy: 3.03978
Value Function Loss: 0.00512

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.10716
Policy Update Magnitude: 0.57368
Value Function Update Magnitude: 0.52220

Collected Steps per Second: 22,320.98037
Overall Steps per Second: 10,584.18820

Timestep Collection Time: 2.24112
Timestep Consumption Time: 2.48518
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.72630

Cumulative Model Updates: 121,944
Cumulative Timesteps: 1,017,074,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.66722
Policy Entropy: 3.02012
Value Function Loss: 0.00520

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11303
Policy Update Magnitude: 0.57628
Value Function Update Magnitude: 0.51132

Collected Steps per Second: 22,447.36906
Overall Steps per Second: 10,700.65662

Timestep Collection Time: 2.22832
Timestep Consumption Time: 2.44616
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.67448

Cumulative Model Updates: 121,950
Cumulative Timesteps: 1,017,124,056

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1017124056...
Checkpoint 1017124056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 748.54388
Policy Entropy: 3.01434
Value Function Loss: 0.00535

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10358
Policy Update Magnitude: 0.58592
Value Function Update Magnitude: 0.51139

Collected Steps per Second: 21,698.80052
Overall Steps per Second: 10,351.25621

Timestep Collection Time: 2.30566
Timestep Consumption Time: 2.52757
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.83323

Cumulative Model Updates: 121,956
Cumulative Timesteps: 1,017,174,086

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,829.32427
Policy Entropy: 3.01089
Value Function Loss: 0.00515

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10425
Policy Update Magnitude: 0.58918
Value Function Update Magnitude: 0.52613

Collected Steps per Second: 22,540.99127
Overall Steps per Second: 10,752.56680

Timestep Collection Time: 2.21862
Timestep Consumption Time: 2.43236
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.65098

Cumulative Model Updates: 121,962
Cumulative Timesteps: 1,017,224,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1017224096...
Checkpoint 1017224096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,609.71439
Policy Entropy: 3.02910
Value Function Loss: 0.00500

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09746
Policy Update Magnitude: 0.57787
Value Function Update Magnitude: 0.51056

Collected Steps per Second: 21,440.42414
Overall Steps per Second: 10,287.79532

Timestep Collection Time: 2.33214
Timestep Consumption Time: 2.52819
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.86032

Cumulative Model Updates: 121,968
Cumulative Timesteps: 1,017,274,098

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,435.79659
Policy Entropy: 3.04609
Value Function Loss: 0.00513

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08961
Policy Update Magnitude: 0.56748
Value Function Update Magnitude: 0.49796

Collected Steps per Second: 22,073.06950
Overall Steps per Second: 10,490.79400

Timestep Collection Time: 2.26566
Timestep Consumption Time: 2.50138
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.76704

Cumulative Model Updates: 121,974
Cumulative Timesteps: 1,017,324,108

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1017324108...
Checkpoint 1017324108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.06318
Policy Entropy: 3.05230
Value Function Loss: 0.00507

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09176
Policy Update Magnitude: 0.56539
Value Function Update Magnitude: 0.50586

Collected Steps per Second: 21,121.03006
Overall Steps per Second: 10,150.32781

Timestep Collection Time: 2.36835
Timestep Consumption Time: 2.55977
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.92812

Cumulative Model Updates: 121,980
Cumulative Timesteps: 1,017,374,130

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.86887
Policy Entropy: 3.03449
Value Function Loss: 0.00513

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09100
Policy Update Magnitude: 0.57098
Value Function Update Magnitude: 0.52109

Collected Steps per Second: 21,807.37219
Overall Steps per Second: 10,445.83590

Timestep Collection Time: 2.29344
Timestep Consumption Time: 2.49449
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.78794

Cumulative Model Updates: 121,986
Cumulative Timesteps: 1,017,424,144

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1017424144...
Checkpoint 1017424144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.92555
Policy Entropy: 3.03538
Value Function Loss: 0.00514

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09107
Policy Update Magnitude: 0.56804
Value Function Update Magnitude: 0.53923

Collected Steps per Second: 21,698.66028
Overall Steps per Second: 10,587.82996

Timestep Collection Time: 2.30438
Timestep Consumption Time: 2.41821
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.72259

Cumulative Model Updates: 121,992
Cumulative Timesteps: 1,017,474,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.57177
Policy Entropy: 3.01732
Value Function Loss: 0.00523

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10321
Policy Update Magnitude: 0.57335
Value Function Update Magnitude: 0.53515

Collected Steps per Second: 22,345.17935
Overall Steps per Second: 10,528.31254

Timestep Collection Time: 2.23771
Timestep Consumption Time: 2.51158
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.74929

Cumulative Model Updates: 121,998
Cumulative Timesteps: 1,017,524,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1017524148...
Checkpoint 1017524148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,584.19613
Policy Entropy: 3.01930
Value Function Loss: 0.00496

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09098
Policy Update Magnitude: 0.56911
Value Function Update Magnitude: 0.52839

Collected Steps per Second: 21,842.38666
Overall Steps per Second: 10,396.27022

Timestep Collection Time: 2.28922
Timestep Consumption Time: 2.52039
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.80961

Cumulative Model Updates: 122,004
Cumulative Timesteps: 1,017,574,150

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.01017
Policy Entropy: 3.00217
Value Function Loss: 0.00483

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.56521
Value Function Update Magnitude: 0.51420

Collected Steps per Second: 22,213.69098
Overall Steps per Second: 10,659.05394

Timestep Collection Time: 2.25185
Timestep Consumption Time: 2.44106
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 4.69291

Cumulative Model Updates: 122,010
Cumulative Timesteps: 1,017,624,172

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1017624172...
Checkpoint 1017624172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 940.67814
Policy Entropy: 2.99997
Value Function Loss: 0.00470

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09458
Policy Update Magnitude: 0.56455
Value Function Update Magnitude: 0.49029

Collected Steps per Second: 21,880.85128
Overall Steps per Second: 10,594.96408

Timestep Collection Time: 2.28620
Timestep Consumption Time: 2.43529
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.72149

Cumulative Model Updates: 122,016
Cumulative Timesteps: 1,017,674,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 955.57452
Policy Entropy: 3.00919
Value Function Loss: 0.00494

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10076
Policy Update Magnitude: 0.56650
Value Function Update Magnitude: 0.47578

Collected Steps per Second: 22,298.01039
Overall Steps per Second: 10,557.60962

Timestep Collection Time: 2.24280
Timestep Consumption Time: 2.49407
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.73687

Cumulative Model Updates: 122,022
Cumulative Timesteps: 1,017,724,206

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1017724206...
Checkpoint 1017724206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,858.25917
Policy Entropy: 3.01723
Value Function Loss: 0.00498

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11462
Policy Update Magnitude: 0.56791
Value Function Update Magnitude: 0.48604

Collected Steps per Second: 22,224.01573
Overall Steps per Second: 10,633.69901

Timestep Collection Time: 2.25009
Timestep Consumption Time: 2.45251
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.70260

Cumulative Model Updates: 122,028
Cumulative Timesteps: 1,017,774,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 995.71619
Policy Entropy: 3.01564
Value Function Loss: 0.00517

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.11880
Policy Update Magnitude: 0.57079
Value Function Update Magnitude: 0.48344

Collected Steps per Second: 22,545.12914
Overall Steps per Second: 10,637.54208

Timestep Collection Time: 2.21822
Timestep Consumption Time: 2.48306
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.70127

Cumulative Model Updates: 122,034
Cumulative Timesteps: 1,017,824,222

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1017824222...
Checkpoint 1017824222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.34473
Policy Entropy: 3.00084
Value Function Loss: 0.00538

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.12799
Policy Update Magnitude: 0.58881
Value Function Update Magnitude: 0.49741

Collected Steps per Second: 21,572.89624
Overall Steps per Second: 10,461.76646

Timestep Collection Time: 2.31874
Timestep Consumption Time: 2.46267
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.78141

Cumulative Model Updates: 122,040
Cumulative Timesteps: 1,017,874,244

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.41058
Policy Entropy: 2.99465
Value Function Loss: 0.00532

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.13367
Policy Update Magnitude: 0.58632
Value Function Update Magnitude: 0.50190

Collected Steps per Second: 22,052.61574
Overall Steps per Second: 10,488.09710

Timestep Collection Time: 2.26767
Timestep Consumption Time: 2.50040
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.76807

Cumulative Model Updates: 122,046
Cumulative Timesteps: 1,017,924,252

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1017924252...
Checkpoint 1017924252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 973.78545
Policy Entropy: 2.99486
Value Function Loss: 0.00526

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.14043
Policy Update Magnitude: 0.58508
Value Function Update Magnitude: 0.51256

Collected Steps per Second: 21,570.16990
Overall Steps per Second: 10,376.71301

Timestep Collection Time: 2.31959
Timestep Consumption Time: 2.50217
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.82176

Cumulative Model Updates: 122,052
Cumulative Timesteps: 1,017,974,286

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.17269
Policy Entropy: 2.99580
Value Function Loss: 0.00525

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.13494
Policy Update Magnitude: 0.58761
Value Function Update Magnitude: 0.49346

Collected Steps per Second: 22,218.64074
Overall Steps per Second: 10,442.93006

Timestep Collection Time: 2.25108
Timestep Consumption Time: 2.53838
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.78946

Cumulative Model Updates: 122,058
Cumulative Timesteps: 1,018,024,302

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1018024302...
Checkpoint 1018024302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.19601
Policy Entropy: 3.00527
Value Function Loss: 0.00528

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.11934
Policy Update Magnitude: 0.58524
Value Function Update Magnitude: 0.48915

Collected Steps per Second: 21,760.74551
Overall Steps per Second: 10,544.63713

Timestep Collection Time: 2.29882
Timestep Consumption Time: 2.44520
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.74402

Cumulative Model Updates: 122,064
Cumulative Timesteps: 1,018,074,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,662.98580
Policy Entropy: 3.01054
Value Function Loss: 0.00520

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11142
Policy Update Magnitude: 0.57567
Value Function Update Magnitude: 0.49895

Collected Steps per Second: 22,103.58556
Overall Steps per Second: 10,407.59804

Timestep Collection Time: 2.26226
Timestep Consumption Time: 2.54231
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.80457

Cumulative Model Updates: 122,070
Cumulative Timesteps: 1,018,124,330

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1018124330...
Checkpoint 1018124330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542.16910
Policy Entropy: 3.01033
Value Function Loss: 0.00515

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10217
Policy Update Magnitude: 0.57689
Value Function Update Magnitude: 0.51216

Collected Steps per Second: 21,683.52392
Overall Steps per Second: 10,527.61569

Timestep Collection Time: 2.30627
Timestep Consumption Time: 2.44391
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.75017

Cumulative Model Updates: 122,076
Cumulative Timesteps: 1,018,174,338

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.84412
Policy Entropy: 2.98877
Value Function Loss: 0.00528

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10130
Policy Update Magnitude: 0.58443
Value Function Update Magnitude: 0.52113

Collected Steps per Second: 22,552.16592
Overall Steps per Second: 10,568.45417

Timestep Collection Time: 2.21735
Timestep Consumption Time: 2.51428
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.73163

Cumulative Model Updates: 122,082
Cumulative Timesteps: 1,018,224,344

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1018224344...
Checkpoint 1018224344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.09809
Policy Entropy: 2.99932
Value Function Loss: 0.00543

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.58809
Value Function Update Magnitude: 0.51698

Collected Steps per Second: 22,118.78683
Overall Steps per Second: 10,595.61020

Timestep Collection Time: 2.26179
Timestep Consumption Time: 2.45979
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.72158

Cumulative Model Updates: 122,088
Cumulative Timesteps: 1,018,274,372

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,146.47699
Policy Entropy: 3.01252
Value Function Loss: 0.00546

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.58507
Value Function Update Magnitude: 0.50322

Collected Steps per Second: 22,599.43469
Overall Steps per Second: 10,577.79100

Timestep Collection Time: 2.21333
Timestep Consumption Time: 2.51545
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.72878

Cumulative Model Updates: 122,094
Cumulative Timesteps: 1,018,324,392

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1018324392...
Checkpoint 1018324392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,788.90946
Policy Entropy: 3.01188
Value Function Loss: 0.00516

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09804
Policy Update Magnitude: 0.58359
Value Function Update Magnitude: 0.50908

Collected Steps per Second: 22,115.42412
Overall Steps per Second: 10,552.73945

Timestep Collection Time: 2.26132
Timestep Consumption Time: 2.47774
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.73905

Cumulative Model Updates: 122,100
Cumulative Timesteps: 1,018,374,402

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,154.69491
Policy Entropy: 3.01567
Value Function Loss: 0.00500

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.09234
Policy Update Magnitude: 0.58240
Value Function Update Magnitude: 0.51483

Collected Steps per Second: 22,381.06641
Overall Steps per Second: 10,587.88325

Timestep Collection Time: 2.23466
Timestep Consumption Time: 2.48904
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.72370

Cumulative Model Updates: 122,106
Cumulative Timesteps: 1,018,424,416

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1018424416...
Checkpoint 1018424416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 909.71452
Policy Entropy: 3.01611
Value Function Loss: 0.00510

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.57582
Value Function Update Magnitude: 0.52688

Collected Steps per Second: 22,240.78636
Overall Steps per Second: 10,490.86084

Timestep Collection Time: 2.24830
Timestep Consumption Time: 2.51813
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.76643

Cumulative Model Updates: 122,112
Cumulative Timesteps: 1,018,474,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,336.23896
Policy Entropy: 3.02353
Value Function Loss: 0.00492

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08530
Policy Update Magnitude: 0.57101
Value Function Update Magnitude: 0.53412

Collected Steps per Second: 21,650.13886
Overall Steps per Second: 10,488.18330

Timestep Collection Time: 2.30992
Timestep Consumption Time: 2.45831
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.76822

Cumulative Model Updates: 122,118
Cumulative Timesteps: 1,018,524,430

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1018524430...
Checkpoint 1018524430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 964.74410
Policy Entropy: 3.00809
Value Function Loss: 0.00526

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10120
Policy Update Magnitude: 0.56939
Value Function Update Magnitude: 0.53029

Collected Steps per Second: 21,567.65860
Overall Steps per Second: 10,558.15295

Timestep Collection Time: 2.31931
Timestep Consumption Time: 2.41845
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.73776

Cumulative Model Updates: 122,124
Cumulative Timesteps: 1,018,574,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.81927
Policy Entropy: 3.01116
Value Function Loss: 0.00534

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.09984
Policy Update Magnitude: 0.57068
Value Function Update Magnitude: 0.52608

Collected Steps per Second: 21,577.56451
Overall Steps per Second: 10,501.27676

Timestep Collection Time: 2.31861
Timestep Consumption Time: 2.44557
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.76418

Cumulative Model Updates: 122,130
Cumulative Timesteps: 1,018,624,482

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1018624482...
Checkpoint 1018624482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 949.98851
Policy Entropy: 3.00687
Value Function Loss: 0.00520

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.09617
Policy Update Magnitude: 0.56609
Value Function Update Magnitude: 0.53589

Collected Steps per Second: 21,382.65954
Overall Steps per Second: 10,260.51408

Timestep Collection Time: 2.33928
Timestep Consumption Time: 2.53572
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.87500

Cumulative Model Updates: 122,136
Cumulative Timesteps: 1,018,674,502

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.02823
Policy Entropy: 3.01436
Value Function Loss: 0.00509

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.56577
Value Function Update Magnitude: 0.54325

Collected Steps per Second: 22,474.34845
Overall Steps per Second: 10,495.22540

Timestep Collection Time: 2.22476
Timestep Consumption Time: 2.53931
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.76407

Cumulative Model Updates: 122,142
Cumulative Timesteps: 1,018,724,502

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1018724502...
Checkpoint 1018724502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,808.39395
Policy Entropy: 3.01584
Value Function Loss: 0.00482

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.56196
Value Function Update Magnitude: 0.54420

Collected Steps per Second: 22,152.05927
Overall Steps per Second: 10,536.43187

Timestep Collection Time: 2.25713
Timestep Consumption Time: 2.48831
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.74544

Cumulative Model Updates: 122,148
Cumulative Timesteps: 1,018,774,502

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,537.34944
Policy Entropy: 2.99828
Value Function Loss: 0.00515

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.10302
Policy Update Magnitude: 0.56637
Value Function Update Magnitude: 0.55654

Collected Steps per Second: 22,314.31432
Overall Steps per Second: 10,455.49236

Timestep Collection Time: 2.24179
Timestep Consumption Time: 2.54268
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.78447

Cumulative Model Updates: 122,154
Cumulative Timesteps: 1,018,824,526

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1018824526...
Checkpoint 1018824526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.34454
Policy Entropy: 2.98297
Value Function Loss: 0.00525

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.58632
Value Function Update Magnitude: 0.56045

Collected Steps per Second: 21,655.22487
Overall Steps per Second: 10,378.64283

Timestep Collection Time: 2.30956
Timestep Consumption Time: 2.50938
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.81893

Cumulative Model Updates: 122,160
Cumulative Timesteps: 1,018,874,540

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,688.82804
Policy Entropy: 2.96524
Value Function Loss: 0.00533

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.09839
Policy Update Magnitude: 0.59361
Value Function Update Magnitude: 0.56185

Collected Steps per Second: 22,286.05569
Overall Steps per Second: 10,641.26688

Timestep Collection Time: 2.24382
Timestep Consumption Time: 2.45543
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.69925

Cumulative Model Updates: 122,166
Cumulative Timesteps: 1,018,924,546

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1018924546...
Checkpoint 1018924546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 953.63857
Policy Entropy: 2.96464
Value Function Loss: 0.00539

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10222
Policy Update Magnitude: 0.58946
Value Function Update Magnitude: 0.56348

Collected Steps per Second: 22,144.92741
Overall Steps per Second: 10,694.93382

Timestep Collection Time: 2.25903
Timestep Consumption Time: 2.41851
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.67754

Cumulative Model Updates: 122,172
Cumulative Timesteps: 1,018,974,572

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,086.87546
Policy Entropy: 2.95739
Value Function Loss: 0.00526

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10389
Policy Update Magnitude: 0.59278
Value Function Update Magnitude: 0.54202

Collected Steps per Second: 22,243.67585
Overall Steps per Second: 10,487.43734

Timestep Collection Time: 2.24909
Timestep Consumption Time: 2.52119
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.77028

Cumulative Model Updates: 122,178
Cumulative Timesteps: 1,019,024,600

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1019024600...
Checkpoint 1019024600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 919.02430
Policy Entropy: 2.97614
Value Function Loss: 0.00533

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11060
Policy Update Magnitude: 0.58904
Value Function Update Magnitude: 0.52625

Collected Steps per Second: 22,032.33758
Overall Steps per Second: 10,608.19438

Timestep Collection Time: 2.27057
Timestep Consumption Time: 2.44522
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.71579

Cumulative Model Updates: 122,184
Cumulative Timesteps: 1,019,074,626

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,792.82393
Policy Entropy: 3.01720
Value Function Loss: 0.00507

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.57412
Value Function Update Magnitude: 0.51670

Collected Steps per Second: 21,657.93876
Overall Steps per Second: 10,575.18461

Timestep Collection Time: 2.31010
Timestep Consumption Time: 2.42098
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.73108

Cumulative Model Updates: 122,190
Cumulative Timesteps: 1,019,124,658

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1019124658...
Checkpoint 1019124658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.15936
Policy Entropy: 3.02380
Value Function Loss: 0.00498

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09644
Policy Update Magnitude: 0.55985
Value Function Update Magnitude: 0.51187

Collected Steps per Second: 21,246.64361
Overall Steps per Second: 10,314.76721

Timestep Collection Time: 2.35454
Timestep Consumption Time: 2.49540
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.84994

Cumulative Model Updates: 122,196
Cumulative Timesteps: 1,019,174,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.02784
Policy Entropy: 3.02157
Value Function Loss: 0.00500

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09413
Policy Update Magnitude: 0.55886
Value Function Update Magnitude: 0.51324

Collected Steps per Second: 21,971.74055
Overall Steps per Second: 10,516.03307

Timestep Collection Time: 2.27638
Timestep Consumption Time: 2.47979
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.75617

Cumulative Model Updates: 122,202
Cumulative Timesteps: 1,019,224,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1019224700...
Checkpoint 1019224700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.66176
Policy Entropy: 3.01294
Value Function Loss: 0.00498

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.10618
Policy Update Magnitude: 0.56132
Value Function Update Magnitude: 0.50606

Collected Steps per Second: 21,035.91932
Overall Steps per Second: 10,413.58536

Timestep Collection Time: 2.37708
Timestep Consumption Time: 2.42473
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.80180

Cumulative Model Updates: 122,208
Cumulative Timesteps: 1,019,274,704

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 715.02606
Policy Entropy: 3.03124
Value Function Loss: 0.00506

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.10722
Policy Update Magnitude: 0.56900
Value Function Update Magnitude: 0.51493

Collected Steps per Second: 21,856.52288
Overall Steps per Second: 10,454.14964

Timestep Collection Time: 2.28783
Timestep Consumption Time: 2.49534
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.78317

Cumulative Model Updates: 122,214
Cumulative Timesteps: 1,019,324,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1019324708...
Checkpoint 1019324708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,403.97044
Policy Entropy: 3.03321
Value Function Loss: 0.00498

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10232
Policy Update Magnitude: 0.57539
Value Function Update Magnitude: 0.52969

Collected Steps per Second: 21,517.91357
Overall Steps per Second: 10,354.20474

Timestep Collection Time: 2.32495
Timestep Consumption Time: 2.50671
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.83166

Cumulative Model Updates: 122,220
Cumulative Timesteps: 1,019,374,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.84180
Policy Entropy: 3.02832
Value Function Loss: 0.00507

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.09567
Policy Update Magnitude: 0.57476
Value Function Update Magnitude: 0.54036

Collected Steps per Second: 22,222.08302
Overall Steps per Second: 10,673.11873

Timestep Collection Time: 2.25091
Timestep Consumption Time: 2.43563
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.68654

Cumulative Model Updates: 122,226
Cumulative Timesteps: 1,019,424,756

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1019424756...
Checkpoint 1019424756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.77042
Policy Entropy: 3.01503
Value Function Loss: 0.00538

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.10822
Policy Update Magnitude: 0.57973
Value Function Update Magnitude: 0.53327

Collected Steps per Second: 21,941.60470
Overall Steps per Second: 10,292.09480

Timestep Collection Time: 2.27878
Timestep Consumption Time: 2.57932
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.85810

Cumulative Model Updates: 122,232
Cumulative Timesteps: 1,019,474,756

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.70232
Policy Entropy: 2.99624
Value Function Loss: 0.00558

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12152
Policy Update Magnitude: 0.58232
Value Function Update Magnitude: 0.54766

Collected Steps per Second: 21,981.57901
Overall Steps per Second: 10,457.27356

Timestep Collection Time: 2.27563
Timestep Consumption Time: 2.50783
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.78346

Cumulative Model Updates: 122,238
Cumulative Timesteps: 1,019,524,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1019524778...
Checkpoint 1019524778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,337.22982
Policy Entropy: 2.98405
Value Function Loss: 0.00559

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.12330
Policy Update Magnitude: 0.58749
Value Function Update Magnitude: 0.54842

Collected Steps per Second: 21,865.87551
Overall Steps per Second: 10,606.28788

Timestep Collection Time: 2.28749
Timestep Consumption Time: 2.42839
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.71588

Cumulative Model Updates: 122,244
Cumulative Timesteps: 1,019,574,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.03345
Policy Entropy: 2.99997
Value Function Loss: 0.00546

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.11783
Policy Update Magnitude: 0.58657
Value Function Update Magnitude: 0.55052

Collected Steps per Second: 22,548.55081
Overall Steps per Second: 10,630.94682

Timestep Collection Time: 2.21761
Timestep Consumption Time: 2.48601
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.70363

Cumulative Model Updates: 122,250
Cumulative Timesteps: 1,019,624,800

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1019624800...
Checkpoint 1019624800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.83891
Policy Entropy: 3.02380
Value Function Loss: 0.00532

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.11585
Policy Update Magnitude: 0.57931
Value Function Update Magnitude: 0.55321

Collected Steps per Second: 22,349.29024
Overall Steps per Second: 10,576.69559

Timestep Collection Time: 2.23730
Timestep Consumption Time: 2.49027
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.72756

Cumulative Model Updates: 122,256
Cumulative Timesteps: 1,019,674,802

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.60842
Policy Entropy: 3.04749
Value Function Loss: 0.00527

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11012
Policy Update Magnitude: 0.57704
Value Function Update Magnitude: 0.53537

Collected Steps per Second: 22,213.21704
Overall Steps per Second: 10,492.44814

Timestep Collection Time: 2.25154
Timestep Consumption Time: 2.51512
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.76667

Cumulative Model Updates: 122,262
Cumulative Timesteps: 1,019,724,816

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1019724816...
Checkpoint 1019724816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,932.39838
Policy Entropy: 3.03556
Value Function Loss: 0.00502

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11621
Policy Update Magnitude: 0.56975
Value Function Update Magnitude: 0.53150

Collected Steps per Second: 21,921.07606
Overall Steps per Second: 10,599.22329

Timestep Collection Time: 2.28210
Timestep Consumption Time: 2.43768
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.71978

Cumulative Model Updates: 122,268
Cumulative Timesteps: 1,019,774,842

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,309.20172
Policy Entropy: 3.04080
Value Function Loss: 0.00476

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.10521
Policy Update Magnitude: 0.55891
Value Function Update Magnitude: 0.52589

Collected Steps per Second: 22,111.91986
Overall Steps per Second: 10,450.92130

Timestep Collection Time: 2.26339
Timestep Consumption Time: 2.52547
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.78886

Cumulative Model Updates: 122,274
Cumulative Timesteps: 1,019,824,890

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1019824890...
Checkpoint 1019824890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.84784
Policy Entropy: 3.02211
Value Function Loss: 0.00482

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.56430
Value Function Update Magnitude: 0.50585

Collected Steps per Second: 21,705.97977
Overall Steps per Second: 10,522.02477

Timestep Collection Time: 2.30397
Timestep Consumption Time: 2.44891
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.75289

Cumulative Model Updates: 122,280
Cumulative Timesteps: 1,019,874,900

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,197.41165
Policy Entropy: 3.02873
Value Function Loss: 0.00485

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10393
Policy Update Magnitude: 0.56266
Value Function Update Magnitude: 0.50668

Collected Steps per Second: 21,910.49839
Overall Steps per Second: 10,555.10887

Timestep Collection Time: 2.28283
Timestep Consumption Time: 2.45592
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.73875

Cumulative Model Updates: 122,286
Cumulative Timesteps: 1,019,924,918

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1019924918...
Checkpoint 1019924918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,907.17039
Policy Entropy: 3.02836
Value Function Loss: 0.00481

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.09969
Policy Update Magnitude: 0.55192
Value Function Update Magnitude: 0.51110

Collected Steps per Second: 21,755.59283
Overall Steps per Second: 10,532.75549

Timestep Collection Time: 2.29918
Timestep Consumption Time: 2.44982
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.74899

Cumulative Model Updates: 122,292
Cumulative Timesteps: 1,019,974,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,826.65902
Policy Entropy: 3.03926
Value Function Loss: 0.00506

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10232
Policy Update Magnitude: 0.55092
Value Function Update Magnitude: 0.51964

Collected Steps per Second: 22,225.00499
Overall Steps per Second: 10,580.31725

Timestep Collection Time: 2.25116
Timestep Consumption Time: 2.47762
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.72878

Cumulative Model Updates: 122,298
Cumulative Timesteps: 1,020,024,970

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1020024970...
Checkpoint 1020024970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.87049
Policy Entropy: 3.03769
Value Function Loss: 0.00516

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09440
Policy Update Magnitude: 0.55968
Value Function Update Magnitude: 0.51791

Collected Steps per Second: 22,208.67665
Overall Steps per Second: 10,570.29388

Timestep Collection Time: 2.25182
Timestep Consumption Time: 2.47936
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.73118

Cumulative Model Updates: 122,304
Cumulative Timesteps: 1,020,074,980

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 868.93468
Policy Entropy: 3.04374
Value Function Loss: 0.00510

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10441
Policy Update Magnitude: 0.55921
Value Function Update Magnitude: 0.50252

Collected Steps per Second: 22,234.55698
Overall Steps per Second: 10,460.04196

Timestep Collection Time: 2.25001
Timestep Consumption Time: 2.53276
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.78277

Cumulative Model Updates: 122,310
Cumulative Timesteps: 1,020,125,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1020125008...
Checkpoint 1020125008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,041.10298
Policy Entropy: 3.03998
Value Function Loss: 0.00493

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09305
Policy Update Magnitude: 0.55159
Value Function Update Magnitude: 0.49195

Collected Steps per Second: 22,082.05724
Overall Steps per Second: 10,616.94885

Timestep Collection Time: 2.26455
Timestep Consumption Time: 2.44546
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.71002

Cumulative Model Updates: 122,316
Cumulative Timesteps: 1,020,175,014

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,957.71453
Policy Entropy: 3.03576
Value Function Loss: 0.00502

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09723
Policy Update Magnitude: 0.55727
Value Function Update Magnitude: 0.49156

Collected Steps per Second: 22,377.54079
Overall Steps per Second: 10,480.17470

Timestep Collection Time: 2.23528
Timestep Consumption Time: 2.53754
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.77282

Cumulative Model Updates: 122,322
Cumulative Timesteps: 1,020,225,034

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1020225034...
Checkpoint 1020225034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,466.68415
Policy Entropy: 3.03676
Value Function Loss: 0.00559

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09483
Policy Update Magnitude: 0.57429
Value Function Update Magnitude: 0.53394

Collected Steps per Second: 22,113.69525
Overall Steps per Second: 10,608.88848

Timestep Collection Time: 2.26195
Timestep Consumption Time: 2.45297
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.71491

Cumulative Model Updates: 122,328
Cumulative Timesteps: 1,020,275,054

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,613.08378
Policy Entropy: 3.03649
Value Function Loss: 0.00566

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.09799
Policy Update Magnitude: 0.58636
Value Function Update Magnitude: 0.55819

Collected Steps per Second: 22,304.36249
Overall Steps per Second: 10,566.45366

Timestep Collection Time: 2.24207
Timestep Consumption Time: 2.49064
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.73271

Cumulative Model Updates: 122,334
Cumulative Timesteps: 1,020,325,062

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1020325062...
Checkpoint 1020325062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.04742
Policy Entropy: 3.04022
Value Function Loss: 0.00551

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.57800
Value Function Update Magnitude: 0.54018

Collected Steps per Second: 21,455.64717
Overall Steps per Second: 10,348.71563

Timestep Collection Time: 2.33095
Timestep Consumption Time: 2.50173
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.83268

Cumulative Model Updates: 122,340
Cumulative Timesteps: 1,020,375,074

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.31587
Policy Entropy: 3.04399
Value Function Loss: 0.00505

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09530
Policy Update Magnitude: 0.56928
Value Function Update Magnitude: 0.52293

Collected Steps per Second: 21,942.59467
Overall Steps per Second: 10,437.51912

Timestep Collection Time: 2.27986
Timestep Consumption Time: 2.51304
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.79290

Cumulative Model Updates: 122,346
Cumulative Timesteps: 1,020,425,100

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1020425100...
Checkpoint 1020425100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,832.17431
Policy Entropy: 3.04530
Value Function Loss: 0.00506

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.56260
Value Function Update Magnitude: 0.49761

Collected Steps per Second: 21,972.09672
Overall Steps per Second: 10,478.45735

Timestep Collection Time: 2.27634
Timestep Consumption Time: 2.49688
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.77322

Cumulative Model Updates: 122,352
Cumulative Timesteps: 1,020,475,116

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.57964
Policy Entropy: 3.03133
Value Function Loss: 0.00529

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09314
Policy Update Magnitude: 0.56464
Value Function Update Magnitude: 0.49185

Collected Steps per Second: 21,716.33089
Overall Steps per Second: 10,428.90438

Timestep Collection Time: 2.30306
Timestep Consumption Time: 2.49265
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.79571

Cumulative Model Updates: 122,358
Cumulative Timesteps: 1,020,525,130

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1020525130...
Checkpoint 1020525130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,546.70648
Policy Entropy: 3.01039
Value Function Loss: 0.00535

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.09880
Policy Update Magnitude: 0.56947
Value Function Update Magnitude: 0.50079

Collected Steps per Second: 21,863.15404
Overall Steps per Second: 10,564.41796

Timestep Collection Time: 2.28878
Timestep Consumption Time: 2.44787
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.73665

Cumulative Model Updates: 122,364
Cumulative Timesteps: 1,020,575,170

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,576.76749
Policy Entropy: 2.99618
Value Function Loss: 0.00516

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09615
Policy Update Magnitude: 0.57524
Value Function Update Magnitude: 0.50748

Collected Steps per Second: 22,191.35529
Overall Steps per Second: 10,534.23215

Timestep Collection Time: 2.25340
Timestep Consumption Time: 2.49360
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.74700

Cumulative Model Updates: 122,370
Cumulative Timesteps: 1,020,625,176

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1020625176...
Checkpoint 1020625176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,069.82536
Policy Entropy: 2.99774
Value Function Loss: 0.00509

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 0.57541
Value Function Update Magnitude: 0.51139

Collected Steps per Second: 22,000.16914
Overall Steps per Second: 10,565.95312

Timestep Collection Time: 2.27380
Timestep Consumption Time: 2.46065
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.73445

Cumulative Model Updates: 122,376
Cumulative Timesteps: 1,020,675,200

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,782.21335
Policy Entropy: 3.00493
Value Function Loss: 0.00496

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.56376
Value Function Update Magnitude: 0.51188

Collected Steps per Second: 21,849.80800
Overall Steps per Second: 10,518.42838

Timestep Collection Time: 2.28908
Timestep Consumption Time: 2.46600
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.75508

Cumulative Model Updates: 122,382
Cumulative Timesteps: 1,020,725,216

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1020725216...
Checkpoint 1020725216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.17736
Policy Entropy: 3.00783
Value Function Loss: 0.00504

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.09897
Policy Update Magnitude: 0.56289
Value Function Update Magnitude: 0.52203

Collected Steps per Second: 21,768.58381
Overall Steps per Second: 10,409.35750

Timestep Collection Time: 2.29707
Timestep Consumption Time: 2.50668
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.80375

Cumulative Model Updates: 122,388
Cumulative Timesteps: 1,020,775,220

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,387.20860
Policy Entropy: 3.00842
Value Function Loss: 0.00489

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09545
Policy Update Magnitude: 0.56723
Value Function Update Magnitude: 0.51575

Collected Steps per Second: 22,383.31658
Overall Steps per Second: 10,751.39623

Timestep Collection Time: 2.23434
Timestep Consumption Time: 2.41733
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.65167

Cumulative Model Updates: 122,394
Cumulative Timesteps: 1,020,825,232

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1020825232...
Checkpoint 1020825232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.86532
Policy Entropy: 3.01383
Value Function Loss: 0.00493

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 0.56977
Value Function Update Magnitude: 0.50744

Collected Steps per Second: 22,100.59886
Overall Steps per Second: 10,568.82259

Timestep Collection Time: 2.26302
Timestep Consumption Time: 2.46921
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.73222

Cumulative Model Updates: 122,400
Cumulative Timesteps: 1,020,875,246

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.82537
Policy Entropy: 3.01058
Value Function Loss: 0.00517

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10312
Policy Update Magnitude: 0.57383
Value Function Update Magnitude: 0.50601

Collected Steps per Second: 22,470.87405
Overall Steps per Second: 10,505.04993

Timestep Collection Time: 2.22537
Timestep Consumption Time: 2.53482
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.76019

Cumulative Model Updates: 122,406
Cumulative Timesteps: 1,020,925,252

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1020925252...
Checkpoint 1020925252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,547.43191
Policy Entropy: 3.00727
Value Function Loss: 0.00529

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11239
Policy Update Magnitude: 0.57462
Value Function Update Magnitude: 0.51473

Collected Steps per Second: 22,090.36932
Overall Steps per Second: 10,647.62086

Timestep Collection Time: 2.26443
Timestep Consumption Time: 2.43353
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.69795

Cumulative Model Updates: 122,412
Cumulative Timesteps: 1,020,975,274

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.22116
Policy Entropy: 3.00854
Value Function Loss: 0.00496

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09378
Policy Update Magnitude: 0.56813
Value Function Update Magnitude: 0.51434

Collected Steps per Second: 21,613.54367
Overall Steps per Second: 10,347.51487

Timestep Collection Time: 2.31447
Timestep Consumption Time: 2.51992
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.83440

Cumulative Model Updates: 122,418
Cumulative Timesteps: 1,021,025,298

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1021025298...
Checkpoint 1021025298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.76119
Policy Entropy: 3.00658
Value Function Loss: 0.00477

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.09960
Policy Update Magnitude: 0.56025
Value Function Update Magnitude: 0.49552

Collected Steps per Second: 21,583.24931
Overall Steps per Second: 10,328.57668

Timestep Collection Time: 2.31670
Timestep Consumption Time: 2.52443
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.84113

Cumulative Model Updates: 122,424
Cumulative Timesteps: 1,021,075,300

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,702.57860
Policy Entropy: 3.00753
Value Function Loss: 0.00507

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10181
Policy Update Magnitude: 0.55774
Value Function Update Magnitude: 0.49801

Collected Steps per Second: 21,724.48975
Overall Steps per Second: 10,391.04136

Timestep Collection Time: 2.30210
Timestep Consumption Time: 2.51089
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.81299

Cumulative Model Updates: 122,430
Cumulative Timesteps: 1,021,125,312

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1021125312...
Checkpoint 1021125312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,709.89536
Policy Entropy: 3.01497
Value Function Loss: 0.00508

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09432
Policy Update Magnitude: 0.56504
Value Function Update Magnitude: 0.50528

Collected Steps per Second: 21,231.90371
Overall Steps per Second: 10,265.28152

Timestep Collection Time: 2.35608
Timestep Consumption Time: 2.51705
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.87313

Cumulative Model Updates: 122,436
Cumulative Timesteps: 1,021,175,336

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,232.74784
Policy Entropy: 3.00652
Value Function Loss: 0.00510

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08795
Policy Update Magnitude: 0.56189
Value Function Update Magnitude: 0.50427

Collected Steps per Second: 22,155.29468
Overall Steps per Second: 10,533.82207

Timestep Collection Time: 2.25707
Timestep Consumption Time: 2.49012
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.74718

Cumulative Model Updates: 122,442
Cumulative Timesteps: 1,021,225,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1021225342...
Checkpoint 1021225342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.73409
Policy Entropy: 3.00350
Value Function Loss: 0.00505

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09276
Policy Update Magnitude: 0.56024
Value Function Update Magnitude: 0.49314

Collected Steps per Second: 21,909.17038
Overall Steps per Second: 10,551.81294

Timestep Collection Time: 2.28279
Timestep Consumption Time: 2.45706
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.73985

Cumulative Model Updates: 122,448
Cumulative Timesteps: 1,021,275,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,861.82948
Policy Entropy: 3.00836
Value Function Loss: 0.00488

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.09827
Policy Update Magnitude: 0.55787
Value Function Update Magnitude: 0.49730

Collected Steps per Second: 22,436.19790
Overall Steps per Second: 10,458.72551

Timestep Collection Time: 2.22943
Timestep Consumption Time: 2.55318
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.78261

Cumulative Model Updates: 122,454
Cumulative Timesteps: 1,021,325,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1021325376...
Checkpoint 1021325376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,421.37715
Policy Entropy: 3.01482
Value Function Loss: 0.00501

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.10923
Policy Update Magnitude: 0.55736
Value Function Update Magnitude: 0.49551

Collected Steps per Second: 22,075.14871
Overall Steps per Second: 10,520.13220

Timestep Collection Time: 2.26590
Timestep Consumption Time: 2.48880
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.75469

Cumulative Model Updates: 122,460
Cumulative Timesteps: 1,021,375,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,092.37576
Policy Entropy: 3.00479
Value Function Loss: 0.00500

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.10708
Policy Update Magnitude: 0.55616
Value Function Update Magnitude: 0.48450

Collected Steps per Second: 22,551.21539
Overall Steps per Second: 10,505.78748

Timestep Collection Time: 2.21718
Timestep Consumption Time: 2.54211
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.75928

Cumulative Model Updates: 122,466
Cumulative Timesteps: 1,021,425,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1021425396...
Checkpoint 1021425396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.96319
Policy Entropy: 2.98742
Value Function Loss: 0.00545

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11073
Policy Update Magnitude: 0.56588
Value Function Update Magnitude: 0.49022

Collected Steps per Second: 22,003.19505
Overall Steps per Second: 10,594.80537

Timestep Collection Time: 2.27358
Timestep Consumption Time: 2.44817
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.72175

Cumulative Model Updates: 122,472
Cumulative Timesteps: 1,021,475,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,749.76594
Policy Entropy: 2.98753
Value Function Loss: 0.00513

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.10867
Policy Update Magnitude: 0.56539
Value Function Update Magnitude: 0.50137

Collected Steps per Second: 22,471.85053
Overall Steps per Second: 10,565.70157

Timestep Collection Time: 2.22518
Timestep Consumption Time: 2.50749
PPO Batch Consumption Time: 0.29485
Total Iteration Time: 4.73267

Cumulative Model Updates: 122,478
Cumulative Timesteps: 1,021,525,426

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1021525426...
Checkpoint 1021525426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.01058
Policy Entropy: 2.99640
Value Function Loss: 0.00522

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09755
Policy Update Magnitude: 0.56821
Value Function Update Magnitude: 0.49849

Collected Steps per Second: 22,045.09169
Overall Steps per Second: 10,610.26210

Timestep Collection Time: 2.26899
Timestep Consumption Time: 2.44532
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.71430

Cumulative Model Updates: 122,484
Cumulative Timesteps: 1,021,575,446

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,731.50731
Policy Entropy: 2.98792
Value Function Loss: 0.00524

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10797
Policy Update Magnitude: 0.57176
Value Function Update Magnitude: 0.49271

Collected Steps per Second: 22,291.82271
Overall Steps per Second: 10,457.18637

Timestep Collection Time: 2.24414
Timestep Consumption Time: 2.53975
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.78389

Cumulative Model Updates: 122,490
Cumulative Timesteps: 1,021,625,472

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1021625472...
Checkpoint 1021625472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473.40254
Policy Entropy: 2.97012
Value Function Loss: 0.00539

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.11717
Policy Update Magnitude: 0.57858
Value Function Update Magnitude: 0.50168

Collected Steps per Second: 21,290.98351
Overall Steps per Second: 10,258.36816

Timestep Collection Time: 2.34907
Timestep Consumption Time: 2.52636
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.87543

Cumulative Model Updates: 122,496
Cumulative Timesteps: 1,021,675,486

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.72575
Policy Entropy: 2.97353
Value Function Loss: 0.00530

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.57808
Value Function Update Magnitude: 0.49639

Collected Steps per Second: 22,237.14498
Overall Steps per Second: 10,580.60795

Timestep Collection Time: 2.24966
Timestep Consumption Time: 2.47842
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.72808

Cumulative Model Updates: 122,502
Cumulative Timesteps: 1,021,725,512

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1021725512...
Checkpoint 1021725512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,642.29845
Policy Entropy: 2.97729
Value Function Loss: 0.00531

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.57907
Value Function Update Magnitude: 0.48649

Collected Steps per Second: 21,426.27163
Overall Steps per Second: 10,447.62048

Timestep Collection Time: 2.33405
Timestep Consumption Time: 2.45269
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.78674

Cumulative Model Updates: 122,508
Cumulative Timesteps: 1,021,775,522

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.56011
Policy Entropy: 2.99126
Value Function Loss: 0.00527

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.57771
Value Function Update Magnitude: 0.50008

Collected Steps per Second: 22,246.55011
Overall Steps per Second: 10,452.15531

Timestep Collection Time: 2.24781
Timestep Consumption Time: 2.53647
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.78428

Cumulative Model Updates: 122,514
Cumulative Timesteps: 1,021,825,528

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1021825528...
Checkpoint 1021825528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.66968
Policy Entropy: 2.98637
Value Function Loss: 0.00509

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.12061
Policy Update Magnitude: 0.56862
Value Function Update Magnitude: 0.49162

Collected Steps per Second: 21,652.07797
Overall Steps per Second: 10,323.47984

Timestep Collection Time: 2.30980
Timestep Consumption Time: 2.53469
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.84449

Cumulative Model Updates: 122,520
Cumulative Timesteps: 1,021,875,540

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,728.43160
Policy Entropy: 2.98119
Value Function Loss: 0.00509

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.10486
Policy Update Magnitude: 0.56708
Value Function Update Magnitude: 0.49207

Collected Steps per Second: 22,779.36695
Overall Steps per Second: 10,813.80884

Timestep Collection Time: 2.19576
Timestep Consumption Time: 2.42962
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.62538

Cumulative Model Updates: 122,526
Cumulative Timesteps: 1,021,925,558

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1021925558...
Checkpoint 1021925558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.43792
Policy Entropy: 2.96506
Value Function Loss: 0.00512

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.10628
Policy Update Magnitude: 0.57131
Value Function Update Magnitude: 0.49581

Collected Steps per Second: 22,038.95847
Overall Steps per Second: 10,574.41208

Timestep Collection Time: 2.26880
Timestep Consumption Time: 2.45978
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.72858

Cumulative Model Updates: 122,532
Cumulative Timesteps: 1,021,975,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 955.90476
Policy Entropy: 2.96437
Value Function Loss: 0.00542

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.11468
Policy Update Magnitude: 0.58144
Value Function Update Magnitude: 0.50973

Collected Steps per Second: 22,110.01019
Overall Steps per Second: 10,492.95132

Timestep Collection Time: 2.26169
Timestep Consumption Time: 2.50398
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.76568

Cumulative Model Updates: 122,538
Cumulative Timesteps: 1,022,025,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1022025566...
Checkpoint 1022025566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,005.55844
Policy Entropy: 2.96638
Value Function Loss: 0.00541

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11365
Policy Update Magnitude: 0.58176
Value Function Update Magnitude: 0.50974

Collected Steps per Second: 21,808.65903
Overall Steps per Second: 10,380.92702

Timestep Collection Time: 2.29368
Timestep Consumption Time: 2.52497
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.81864

Cumulative Model Updates: 122,544
Cumulative Timesteps: 1,022,075,588

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.18953
Policy Entropy: 2.99089
Value Function Loss: 0.00506

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.10421
Policy Update Magnitude: 0.57095
Value Function Update Magnitude: 0.49854

Collected Steps per Second: 22,731.74365
Overall Steps per Second: 10,805.40881

Timestep Collection Time: 2.19957
Timestep Consumption Time: 2.42774
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.62731

Cumulative Model Updates: 122,550
Cumulative Timesteps: 1,022,125,588

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1022125588...
Checkpoint 1022125588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,427.16745
Policy Entropy: 2.98777
Value Function Loss: 0.00489

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.10714
Policy Update Magnitude: 0.56550
Value Function Update Magnitude: 0.49963

Collected Steps per Second: 22,045.68166
Overall Steps per Second: 10,607.13046

Timestep Collection Time: 2.26902
Timestep Consumption Time: 2.44687
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.71588

Cumulative Model Updates: 122,556
Cumulative Timesteps: 1,022,175,610

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,414.05963
Policy Entropy: 3.00779
Value Function Loss: 0.00488

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.09900
Policy Update Magnitude: 0.55903
Value Function Update Magnitude: 0.49504

Collected Steps per Second: 22,229.62489
Overall Steps per Second: 10,471.14169

Timestep Collection Time: 2.24934
Timestep Consumption Time: 2.52588
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.77522

Cumulative Model Updates: 122,562
Cumulative Timesteps: 1,022,225,612

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1022225612...
Checkpoint 1022225612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,560.63820
Policy Entropy: 3.00361
Value Function Loss: 0.00486

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.55555
Value Function Update Magnitude: 0.50258

Collected Steps per Second: 21,361.15410
Overall Steps per Second: 10,324.44485

Timestep Collection Time: 2.34070
Timestep Consumption Time: 2.50218
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.84288

Cumulative Model Updates: 122,568
Cumulative Timesteps: 1,022,275,612

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,520.22372
Policy Entropy: 2.99314
Value Function Loss: 0.00479

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.55668
Value Function Update Magnitude: 0.50919

Collected Steps per Second: 22,243.04666
Overall Steps per Second: 10,543.10774

Timestep Collection Time: 2.24789
Timestep Consumption Time: 2.49454
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.74243

Cumulative Model Updates: 122,574
Cumulative Timesteps: 1,022,325,612

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1022325612...
Checkpoint 1022325612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.63145
Policy Entropy: 2.99725
Value Function Loss: 0.00483

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09519
Policy Update Magnitude: 0.55416
Value Function Update Magnitude: 0.49976

Collected Steps per Second: 21,985.82355
Overall Steps per Second: 10,444.44089

Timestep Collection Time: 2.27483
Timestep Consumption Time: 2.51375
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.78858

Cumulative Model Updates: 122,580
Cumulative Timesteps: 1,022,375,626

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,695.33596
Policy Entropy: 2.98331
Value Function Loss: 0.00499

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.09952
Policy Update Magnitude: 0.55527
Value Function Update Magnitude: 0.49936

Collected Steps per Second: 22,501.83079
Overall Steps per Second: 10,452.57986

Timestep Collection Time: 2.22213
Timestep Consumption Time: 2.56157
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.78370

Cumulative Model Updates: 122,586
Cumulative Timesteps: 1,022,425,628

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1022425628...
Checkpoint 1022425628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416.69871
Policy Entropy: 2.99340
Value Function Loss: 0.00518

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10208
Policy Update Magnitude: 0.56285
Value Function Update Magnitude: 0.49497

Collected Steps per Second: 22,048.80294
Overall Steps per Second: 10,572.90100

Timestep Collection Time: 2.26879
Timestep Consumption Time: 2.46256
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.73134

Cumulative Model Updates: 122,592
Cumulative Timesteps: 1,022,475,652

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,826.47292
Policy Entropy: 2.98644
Value Function Loss: 0.00499

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.55408
Value Function Update Magnitude: 0.48868

Collected Steps per Second: 22,443.24869
Overall Steps per Second: 10,512.10645

Timestep Collection Time: 2.22873
Timestep Consumption Time: 2.52959
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.75832

Cumulative Model Updates: 122,598
Cumulative Timesteps: 1,022,525,672

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1022525672...
Checkpoint 1022525672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.89918
Policy Entropy: 2.99071
Value Function Loss: 0.00511

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.55741
Value Function Update Magnitude: 0.48970

Collected Steps per Second: 22,120.25100
Overall Steps per Second: 10,680.68162

Timestep Collection Time: 2.26110
Timestep Consumption Time: 2.42175
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.68285

Cumulative Model Updates: 122,604
Cumulative Timesteps: 1,022,575,688

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,553.26924
Policy Entropy: 2.99762
Value Function Loss: 0.00478

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.56621
Value Function Update Magnitude: 0.48952

Collected Steps per Second: 22,346.38269
Overall Steps per Second: 10,594.63759

Timestep Collection Time: 2.23821
Timestep Consumption Time: 2.48266
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.72088

Cumulative Model Updates: 122,610
Cumulative Timesteps: 1,022,625,704

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1022625704...
Checkpoint 1022625704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.45822
Policy Entropy: 3.01315
Value Function Loss: 0.00499

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09261
Policy Update Magnitude: 0.56598
Value Function Update Magnitude: 0.52345

Collected Steps per Second: 21,761.84927
Overall Steps per Second: 10,489.68888

Timestep Collection Time: 2.29861
Timestep Consumption Time: 2.47007
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.76868

Cumulative Model Updates: 122,616
Cumulative Timesteps: 1,022,675,726

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,431.96826
Policy Entropy: 3.01641
Value Function Loss: 0.00490

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09298
Policy Update Magnitude: 0.57341
Value Function Update Magnitude: 0.54196

Collected Steps per Second: 22,317.28061
Overall Steps per Second: 10,594.60000

Timestep Collection Time: 2.24131
Timestep Consumption Time: 2.47996
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.72127

Cumulative Model Updates: 122,622
Cumulative Timesteps: 1,022,725,746

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1022725746...
Checkpoint 1022725746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,730.12106
Policy Entropy: 3.00674
Value Function Loss: 0.00500

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08668
Policy Update Magnitude: 0.56790
Value Function Update Magnitude: 0.55717

Collected Steps per Second: 21,846.86348
Overall Steps per Second: 10,589.17045

Timestep Collection Time: 2.28994
Timestep Consumption Time: 2.43451
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.72445

Cumulative Model Updates: 122,628
Cumulative Timesteps: 1,022,775,774

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,651.56640
Policy Entropy: 3.00818
Value Function Loss: 0.00456

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.56243
Value Function Update Magnitude: 0.53756

Collected Steps per Second: 21,962.80370
Overall Steps per Second: 10,487.63519

Timestep Collection Time: 2.27676
Timestep Consumption Time: 2.49114
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.76790

Cumulative Model Updates: 122,634
Cumulative Timesteps: 1,022,825,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1022825778...
Checkpoint 1022825778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.82280
Policy Entropy: 3.00526
Value Function Loss: 0.00453

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.55996
Value Function Update Magnitude: 0.49391

Collected Steps per Second: 21,353.08312
Overall Steps per Second: 10,439.41815

Timestep Collection Time: 2.34243
Timestep Consumption Time: 2.44884
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.79126

Cumulative Model Updates: 122,640
Cumulative Timesteps: 1,022,875,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,381.50447
Policy Entropy: 3.01020
Value Function Loss: 0.00458

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09028
Policy Update Magnitude: 0.55477
Value Function Update Magnitude: 0.48722

Collected Steps per Second: 21,753.29297
Overall Steps per Second: 10,474.42312

Timestep Collection Time: 2.29878
Timestep Consumption Time: 2.47533
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.77411

Cumulative Model Updates: 122,646
Cumulative Timesteps: 1,022,925,802

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1022925802...
Checkpoint 1022925802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.76656
Policy Entropy: 3.00371
Value Function Loss: 0.00472

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.55281
Value Function Update Magnitude: 0.50230

Collected Steps per Second: 21,976.43439
Overall Steps per Second: 10,327.87386

Timestep Collection Time: 2.27589
Timestep Consumption Time: 2.56692
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.84282

Cumulative Model Updates: 122,652
Cumulative Timesteps: 1,022,975,818

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,725.78686
Policy Entropy: 3.01487
Value Function Loss: 0.00484

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.56102
Value Function Update Magnitude: 0.49674

Collected Steps per Second: 21,830.59142
Overall Steps per Second: 10,364.98537

Timestep Collection Time: 2.29119
Timestep Consumption Time: 2.53448
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.82567

Cumulative Model Updates: 122,658
Cumulative Timesteps: 1,023,025,836

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1023025836...
Checkpoint 1023025836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,421.30309
Policy Entropy: 3.01366
Value Function Loss: 0.00502

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10170
Policy Update Magnitude: 0.56669
Value Function Update Magnitude: 0.49664

Collected Steps per Second: 21,940.52174
Overall Steps per Second: 10,399.42602

Timestep Collection Time: 2.28007
Timestep Consumption Time: 2.53038
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.81046

Cumulative Model Updates: 122,664
Cumulative Timesteps: 1,023,075,862

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,727.15307
Policy Entropy: 3.01744
Value Function Loss: 0.00493

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.10858
Policy Update Magnitude: 0.56221
Value Function Update Magnitude: 0.49069

Collected Steps per Second: 22,265.28145
Overall Steps per Second: 10,517.06028

Timestep Collection Time: 2.24709
Timestep Consumption Time: 2.51014
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.75722

Cumulative Model Updates: 122,670
Cumulative Timesteps: 1,023,125,894

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1023125894...
Checkpoint 1023125894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.24760
Policy Entropy: 2.99310
Value Function Loss: 0.00492

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.10988
Policy Update Magnitude: 0.56196
Value Function Update Magnitude: 0.50983

Collected Steps per Second: 22,283.75281
Overall Steps per Second: 10,506.17299

Timestep Collection Time: 2.24495
Timestep Consumption Time: 2.51663
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.76158

Cumulative Model Updates: 122,676
Cumulative Timesteps: 1,023,175,920

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,630.64653
Policy Entropy: 3.00238
Value Function Loss: 0.00485

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11359
Policy Update Magnitude: 0.56393
Value Function Update Magnitude: 0.52617

Collected Steps per Second: 22,280.55357
Overall Steps per Second: 10,469.32498

Timestep Collection Time: 2.24465
Timestep Consumption Time: 2.53236
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.77700

Cumulative Model Updates: 122,682
Cumulative Timesteps: 1,023,225,932

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1023225932...
Checkpoint 1023225932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.81270
Policy Entropy: 3.00709
Value Function Loss: 0.00515

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.12195
Policy Update Magnitude: 0.58374
Value Function Update Magnitude: 0.52909

Collected Steps per Second: 22,206.06825
Overall Steps per Second: 10,545.17603

Timestep Collection Time: 2.25263
Timestep Consumption Time: 2.49096
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.74359

Cumulative Model Updates: 122,688
Cumulative Timesteps: 1,023,275,954

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.74487
Policy Entropy: 3.02529
Value Function Loss: 0.00527

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.12258
Policy Update Magnitude: 0.58546
Value Function Update Magnitude: 0.54353

Collected Steps per Second: 21,706.19137
Overall Steps per Second: 10,522.81214

Timestep Collection Time: 2.30386
Timestep Consumption Time: 2.44848
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.75234

Cumulative Model Updates: 122,694
Cumulative Timesteps: 1,023,325,962

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1023325962...
Checkpoint 1023325962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.26822
Policy Entropy: 3.03188
Value Function Loss: 0.00507

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.57410
Value Function Update Magnitude: 0.53125

Collected Steps per Second: 21,710.03408
Overall Steps per Second: 10,550.42048

Timestep Collection Time: 2.30419
Timestep Consumption Time: 2.43723
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.74142

Cumulative Model Updates: 122,700
Cumulative Timesteps: 1,023,375,986

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 896.34772
Policy Entropy: 3.03568
Value Function Loss: 0.00518

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.12449
Policy Update Magnitude: 0.57438
Value Function Update Magnitude: 0.53012

Collected Steps per Second: 22,110.99941
Overall Steps per Second: 10,483.87443

Timestep Collection Time: 2.26277
Timestep Consumption Time: 2.50952
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.77228

Cumulative Model Updates: 122,706
Cumulative Timesteps: 1,023,426,018

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1023426018...
Checkpoint 1023426018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643.26300
Policy Entropy: 3.04520
Value Function Loss: 0.00506

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.14021
Policy Update Magnitude: 0.57080
Value Function Update Magnitude: 0.52762

Collected Steps per Second: 21,700.69396
Overall Steps per Second: 10,568.80544

Timestep Collection Time: 2.30527
Timestep Consumption Time: 2.42809
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.73336

Cumulative Model Updates: 122,712
Cumulative Timesteps: 1,023,476,044

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.25829
Policy Entropy: 3.04107
Value Function Loss: 0.00509

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.56901
Value Function Update Magnitude: 0.51461

Collected Steps per Second: 22,145.09046
Overall Steps per Second: 10,544.28016

Timestep Collection Time: 2.25856
Timestep Consumption Time: 2.48487
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.74342

Cumulative Model Updates: 122,718
Cumulative Timesteps: 1,023,526,060

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1023526060...
Checkpoint 1023526060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.71209
Policy Entropy: 3.03815
Value Function Loss: 0.00462

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.11337
Policy Update Magnitude: 0.55869
Value Function Update Magnitude: 0.52064

Collected Steps per Second: 21,608.26421
Overall Steps per Second: 10,380.01709

Timestep Collection Time: 2.31458
Timestep Consumption Time: 2.50372
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.81830

Cumulative Model Updates: 122,724
Cumulative Timesteps: 1,023,576,074

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485.33733
Policy Entropy: 3.02818
Value Function Loss: 0.00473

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.11730
Policy Update Magnitude: 0.55977
Value Function Update Magnitude: 0.52468

Collected Steps per Second: 22,638.82618
Overall Steps per Second: 10,666.96440

Timestep Collection Time: 2.20966
Timestep Consumption Time: 2.47996
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.68962

Cumulative Model Updates: 122,730
Cumulative Timesteps: 1,023,626,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1023626098...
Checkpoint 1023626098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,470.59771
Policy Entropy: 3.01309
Value Function Loss: 0.00483

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11006
Policy Update Magnitude: 0.56745
Value Function Update Magnitude: 0.55337

Collected Steps per Second: 22,025.88546
Overall Steps per Second: 10,579.60189

Timestep Collection Time: 2.27015
Timestep Consumption Time: 2.45612
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.72626

Cumulative Model Updates: 122,736
Cumulative Timesteps: 1,023,676,100

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541.70154
Policy Entropy: 3.01188
Value Function Loss: 0.00505

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.57205
Value Function Update Magnitude: 0.58041

Collected Steps per Second: 22,483.48877
Overall Steps per Second: 10,602.56213

Timestep Collection Time: 2.22474
Timestep Consumption Time: 2.49298
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.71773

Cumulative Model Updates: 122,742
Cumulative Timesteps: 1,023,726,120

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1023726120...
Checkpoint 1023726120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,921.63500
Policy Entropy: 3.02829
Value Function Loss: 0.00499

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.09858
Policy Update Magnitude: 0.57637
Value Function Update Magnitude: 0.60584

Collected Steps per Second: 22,253.51931
Overall Steps per Second: 10,622.38279

Timestep Collection Time: 2.24693
Timestep Consumption Time: 2.46030
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.70723

Cumulative Model Updates: 122,748
Cumulative Timesteps: 1,023,776,122

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,644.77660
Policy Entropy: 3.04754
Value Function Loss: 0.00489

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.56555
Value Function Update Magnitude: 0.58777

Collected Steps per Second: 22,527.10709
Overall Steps per Second: 10,565.20710

Timestep Collection Time: 2.21955
Timestep Consumption Time: 2.51297
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.73251

Cumulative Model Updates: 122,754
Cumulative Timesteps: 1,023,826,122

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1023826122...
Checkpoint 1023826122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.89761
Policy Entropy: 3.05671
Value Function Loss: 0.00519

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08978
Policy Update Magnitude: 0.56634
Value Function Update Magnitude: 0.58375

Collected Steps per Second: 22,028.24864
Overall Steps per Second: 10,504.58200

Timestep Collection Time: 2.27063
Timestep Consumption Time: 2.49091
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.76154

Cumulative Model Updates: 122,760
Cumulative Timesteps: 1,023,876,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,833.67385
Policy Entropy: 3.05291
Value Function Loss: 0.00494

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09647
Policy Update Magnitude: 0.57051
Value Function Update Magnitude: 0.57524

Collected Steps per Second: 22,460.41038
Overall Steps per Second: 10,498.05987

Timestep Collection Time: 2.22614
Timestep Consumption Time: 2.53665
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.76278

Cumulative Model Updates: 122,766
Cumulative Timesteps: 1,023,926,140

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1023926140...
Checkpoint 1023926140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,505.74685
Policy Entropy: 3.04243
Value Function Loss: 0.00494

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.09897
Policy Update Magnitude: 0.55804
Value Function Update Magnitude: 0.55545

Collected Steps per Second: 21,054.64291
Overall Steps per Second: 10,167.60161

Timestep Collection Time: 2.37601
Timestep Consumption Time: 2.54413
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.92014

Cumulative Model Updates: 122,772
Cumulative Timesteps: 1,023,976,166

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,026.83273
Policy Entropy: 3.03115
Value Function Loss: 0.00505

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.09991
Policy Update Magnitude: 0.56364
Value Function Update Magnitude: 0.56248

Collected Steps per Second: 22,071.21807
Overall Steps per Second: 10,451.19158

Timestep Collection Time: 2.26612
Timestep Consumption Time: 2.51956
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.78567

Cumulative Model Updates: 122,778
Cumulative Timesteps: 1,024,026,182

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1024026182...
Checkpoint 1024026182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,086.00310
Policy Entropy: 3.04437
Value Function Loss: 0.00517

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09252
Policy Update Magnitude: 0.57990
Value Function Update Magnitude: 0.59323

Collected Steps per Second: 21,742.61854
Overall Steps per Second: 10,585.31483

Timestep Collection Time: 2.30037
Timestep Consumption Time: 2.42467
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.72504

Cumulative Model Updates: 122,784
Cumulative Timesteps: 1,024,076,198

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,314.16465
Policy Entropy: 3.04499
Value Function Loss: 0.00502

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.09569
Policy Update Magnitude: 0.57597
Value Function Update Magnitude: 0.58803

Collected Steps per Second: 21,988.41209
Overall Steps per Second: 10,532.54358

Timestep Collection Time: 2.27520
Timestep Consumption Time: 2.47465
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.74985

Cumulative Model Updates: 122,790
Cumulative Timesteps: 1,024,126,226

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1024126226...
Checkpoint 1024126226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,505.34939
Policy Entropy: 3.05418
Value Function Loss: 0.00510

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.56566
Value Function Update Magnitude: 0.56229

Collected Steps per Second: 21,540.78128
Overall Steps per Second: 10,549.02488

Timestep Collection Time: 2.32201
Timestep Consumption Time: 2.41947
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.74148

Cumulative Model Updates: 122,796
Cumulative Timesteps: 1,024,176,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,533.40713
Policy Entropy: 3.04183
Value Function Loss: 0.00490

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10262
Policy Update Magnitude: 0.55629
Value Function Update Magnitude: 0.54149

Collected Steps per Second: 22,194.56887
Overall Steps per Second: 10,559.56868

Timestep Collection Time: 2.25361
Timestep Consumption Time: 2.48313
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.73675

Cumulative Model Updates: 122,802
Cumulative Timesteps: 1,024,226,262

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1024226262...
Checkpoint 1024226262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,845.37422
Policy Entropy: 3.04071
Value Function Loss: 0.00507

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.11801
Policy Update Magnitude: 0.56179
Value Function Update Magnitude: 0.51677

Collected Steps per Second: 22,267.64507
Overall Steps per Second: 10,560.86090

Timestep Collection Time: 2.24586
Timestep Consumption Time: 2.48955
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.73541

Cumulative Model Updates: 122,808
Cumulative Timesteps: 1,024,276,272

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.14531
Policy Entropy: 3.05040
Value Function Loss: 0.00503

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.10888
Policy Update Magnitude: 0.56335
Value Function Update Magnitude: 0.50270

Collected Steps per Second: 22,542.03873
Overall Steps per Second: 10,505.50712

Timestep Collection Time: 2.21888
Timestep Consumption Time: 2.54225
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.76112

Cumulative Model Updates: 122,814
Cumulative Timesteps: 1,024,326,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1024326290...
Checkpoint 1024326290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,869.82095
Policy Entropy: 3.06802
Value Function Loss: 0.00496

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.09872
Policy Update Magnitude: 0.55902
Value Function Update Magnitude: 0.52216

Collected Steps per Second: 22,171.88749
Overall Steps per Second: 10,636.54528

Timestep Collection Time: 2.25592
Timestep Consumption Time: 2.44655
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.70247

Cumulative Model Updates: 122,820
Cumulative Timesteps: 1,024,376,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,805.12232
Policy Entropy: 3.05744
Value Function Loss: 0.00494

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08667
Policy Update Magnitude: 0.55453
Value Function Update Magnitude: 0.51467

Collected Steps per Second: 22,293.00584
Overall Steps per Second: 10,440.20296

Timestep Collection Time: 2.24402
Timestep Consumption Time: 2.54765
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.79167

Cumulative Model Updates: 122,826
Cumulative Timesteps: 1,024,426,334

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1024426334...
Checkpoint 1024426334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,712.77245
Policy Entropy: 3.04552
Value Function Loss: 0.00482

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08452
Policy Update Magnitude: 0.56135
Value Function Update Magnitude: 0.50666

Collected Steps per Second: 22,110.17760
Overall Steps per Second: 10,615.27054

Timestep Collection Time: 2.26204
Timestep Consumption Time: 2.44948
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.71151

Cumulative Model Updates: 122,832
Cumulative Timesteps: 1,024,476,348

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.67462
Policy Entropy: 3.04075
Value Function Loss: 0.00477

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09182
Policy Update Magnitude: 0.55738
Value Function Update Magnitude: 0.50676

Collected Steps per Second: 22,244.19124
Overall Steps per Second: 10,517.12691

Timestep Collection Time: 2.24832
Timestep Consumption Time: 2.50697
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.75529

Cumulative Model Updates: 122,838
Cumulative Timesteps: 1,024,526,360

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1024526360...
Checkpoint 1024526360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,642.73073
Policy Entropy: 3.05784
Value Function Loss: 0.00459

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.10823
Policy Update Magnitude: 0.55438
Value Function Update Magnitude: 0.50208

Collected Steps per Second: 22,072.82992
Overall Steps per Second: 10,671.05902

Timestep Collection Time: 2.26577
Timestep Consumption Time: 2.42092
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.68670

Cumulative Model Updates: 122,844
Cumulative Timesteps: 1,024,576,372

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,336.55271
Policy Entropy: 3.06257
Value Function Loss: 0.00462

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10427
Policy Update Magnitude: 0.55180
Value Function Update Magnitude: 0.48143

Collected Steps per Second: 21,923.69633
Overall Steps per Second: 10,514.48093

Timestep Collection Time: 2.28201
Timestep Consumption Time: 2.47619
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.75820

Cumulative Model Updates: 122,850
Cumulative Timesteps: 1,024,626,402

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1024626402...
Checkpoint 1024626402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,658.92935
Policy Entropy: 3.05636
Value Function Loss: 0.00464

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10235
Policy Update Magnitude: 0.55452
Value Function Update Magnitude: 0.47805

Collected Steps per Second: 21,819.58046
Overall Steps per Second: 10,596.34611

Timestep Collection Time: 2.29262
Timestep Consumption Time: 2.42825
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.72087

Cumulative Model Updates: 122,856
Cumulative Timesteps: 1,024,676,426

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.40400
Policy Entropy: 3.06419
Value Function Loss: 0.00492

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.09720
Policy Update Magnitude: 0.55750
Value Function Update Magnitude: 0.50114

Collected Steps per Second: 21,864.17279
Overall Steps per Second: 10,552.25078

Timestep Collection Time: 2.28712
Timestep Consumption Time: 2.45177
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.73889

Cumulative Model Updates: 122,862
Cumulative Timesteps: 1,024,726,432

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1024726432...
Checkpoint 1024726432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.28412
Policy Entropy: 3.06454
Value Function Loss: 0.00497

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11131
Policy Update Magnitude: 0.56297
Value Function Update Magnitude: 0.51878

Collected Steps per Second: 21,658.56232
Overall Steps per Second: 10,509.92560

Timestep Collection Time: 2.30874
Timestep Consumption Time: 2.44905
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.75779

Cumulative Model Updates: 122,868
Cumulative Timesteps: 1,024,776,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,881.39643
Policy Entropy: 3.06950
Value Function Loss: 0.00513

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.56453
Value Function Update Magnitude: 0.50381

Collected Steps per Second: 21,805.95499
Overall Steps per Second: 10,486.67785

Timestep Collection Time: 2.29332
Timestep Consumption Time: 2.47540
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.76872

Cumulative Model Updates: 122,874
Cumulative Timesteps: 1,024,826,444

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1024826444...
Checkpoint 1024826444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 906.02225
Policy Entropy: 3.06445
Value Function Loss: 0.00512

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10399
Policy Update Magnitude: 0.56528
Value Function Update Magnitude: 0.50776

Collected Steps per Second: 22,065.46907
Overall Steps per Second: 10,340.22610

Timestep Collection Time: 2.26689
Timestep Consumption Time: 2.57053
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.83742

Cumulative Model Updates: 122,880
Cumulative Timesteps: 1,024,876,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.00267
Policy Entropy: 3.06860
Value Function Loss: 0.00480

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10166
Policy Update Magnitude: 0.56291
Value Function Update Magnitude: 0.53436

Collected Steps per Second: 21,388.30217
Overall Steps per Second: 10,360.83176

Timestep Collection Time: 2.33913
Timestep Consumption Time: 2.48963
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.82876

Cumulative Model Updates: 122,886
Cumulative Timesteps: 1,024,926,494

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1024926494...
Checkpoint 1024926494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,326.75512
Policy Entropy: 3.05752
Value Function Loss: 0.00492

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09533
Policy Update Magnitude: 0.56137
Value Function Update Magnitude: 0.54330

Collected Steps per Second: 21,658.45188
Overall Steps per Second: 10,575.76638

Timestep Collection Time: 2.30968
Timestep Consumption Time: 2.42038
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.73006

Cumulative Model Updates: 122,892
Cumulative Timesteps: 1,024,976,518

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.53383
Policy Entropy: 3.04893
Value Function Loss: 0.00502

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.56365
Value Function Update Magnitude: 0.53852

Collected Steps per Second: 21,875.13159
Overall Steps per Second: 10,570.75751

Timestep Collection Time: 2.28689
Timestep Consumption Time: 2.44560
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.73249

Cumulative Model Updates: 122,898
Cumulative Timesteps: 1,025,026,544

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1025026544...
Checkpoint 1025026544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,715.56909
Policy Entropy: 3.04460
Value Function Loss: 0.00479

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.55885
Value Function Update Magnitude: 0.53877

Collected Steps per Second: 21,976.94991
Overall Steps per Second: 10,543.16573

Timestep Collection Time: 2.27557
Timestep Consumption Time: 2.46779
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.74336

Cumulative Model Updates: 122,904
Cumulative Timesteps: 1,025,076,554

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,495.85260
Policy Entropy: 3.05752
Value Function Loss: 0.00456

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.55153
Value Function Update Magnitude: 0.51076

Collected Steps per Second: 22,316.00585
Overall Steps per Second: 10,489.70507

Timestep Collection Time: 2.24090
Timestep Consumption Time: 2.52644
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.76734

Cumulative Model Updates: 122,910
Cumulative Timesteps: 1,025,126,562

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1025126562...
Checkpoint 1025126562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.10635
Policy Entropy: 3.06046
Value Function Loss: 0.00469

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08834
Policy Update Magnitude: 0.55314
Value Function Update Magnitude: 0.50113

Collected Steps per Second: 21,798.55800
Overall Steps per Second: 10,571.59788

Timestep Collection Time: 2.29428
Timestep Consumption Time: 2.43651
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 4.73079

Cumulative Model Updates: 122,916
Cumulative Timesteps: 1,025,176,574

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,198.48488
Policy Entropy: 3.06739
Value Function Loss: 0.00491

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08733
Policy Update Magnitude: 0.55731
Value Function Update Magnitude: 0.50896

Collected Steps per Second: 22,315.14797
Overall Steps per Second: 10,520.43639

Timestep Collection Time: 2.24117
Timestep Consumption Time: 2.51263
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.75380

Cumulative Model Updates: 122,922
Cumulative Timesteps: 1,025,226,586

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1025226586...
Checkpoint 1025226586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,809.11177
Policy Entropy: 3.04828
Value Function Loss: 0.00501

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09056
Policy Update Magnitude: 0.55464
Value Function Update Magnitude: 0.50292

Collected Steps per Second: 21,600.21126
Overall Steps per Second: 10,571.60516

Timestep Collection Time: 2.31563
Timestep Consumption Time: 2.41573
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.73135

Cumulative Model Updates: 122,928
Cumulative Timesteps: 1,025,276,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531.67352
Policy Entropy: 3.05055
Value Function Loss: 0.00499

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09605
Policy Update Magnitude: 0.55299
Value Function Update Magnitude: 0.50054

Collected Steps per Second: 22,382.73856
Overall Steps per Second: 10,560.06098

Timestep Collection Time: 2.23440
Timestep Consumption Time: 2.50156
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.73596

Cumulative Model Updates: 122,934
Cumulative Timesteps: 1,025,326,616

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1025326616...
Checkpoint 1025326616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,797.33851
Policy Entropy: 3.03454
Value Function Loss: 0.00491

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09090
Policy Update Magnitude: 0.55774
Value Function Update Magnitude: 0.51326

Collected Steps per Second: 22,071.09861
Overall Steps per Second: 10,581.41050

Timestep Collection Time: 2.26577
Timestep Consumption Time: 2.46026
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.72602

Cumulative Model Updates: 122,940
Cumulative Timesteps: 1,025,376,624

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,338.87559
Policy Entropy: 3.05025
Value Function Loss: 0.00482

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09315
Policy Update Magnitude: 0.56047
Value Function Update Magnitude: 0.53712

Collected Steps per Second: 22,321.62688
Overall Steps per Second: 10,485.70718

Timestep Collection Time: 2.23998
Timestep Consumption Time: 2.52842
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.76840

Cumulative Model Updates: 122,946
Cumulative Timesteps: 1,025,426,624

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1025426624...
Checkpoint 1025426624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.35470
Policy Entropy: 3.05215
Value Function Loss: 0.00484

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.09848
Policy Update Magnitude: 0.55480
Value Function Update Magnitude: 0.52260

Collected Steps per Second: 21,375.82962
Overall Steps per Second: 10,303.62086

Timestep Collection Time: 2.34012
Timestep Consumption Time: 2.51468
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.85480

Cumulative Model Updates: 122,952
Cumulative Timesteps: 1,025,476,646

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,705.00840
Policy Entropy: 3.06668
Value Function Loss: 0.00507

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.55444
Value Function Update Magnitude: 0.52469

Collected Steps per Second: 21,756.70418
Overall Steps per Second: 10,349.62182

Timestep Collection Time: 2.29814
Timestep Consumption Time: 2.53295
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.83109

Cumulative Model Updates: 122,958
Cumulative Timesteps: 1,025,526,646

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1025526646...
Checkpoint 1025526646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,978.41682
Policy Entropy: 3.06752
Value Function Loss: 0.00485

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.55786
Value Function Update Magnitude: 0.54266

Collected Steps per Second: 21,491.20288
Overall Steps per Second: 10,324.52355

Timestep Collection Time: 2.32663
Timestep Consumption Time: 2.51641
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.84303

Cumulative Model Updates: 122,964
Cumulative Timesteps: 1,025,576,648

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469.94518
Policy Entropy: 3.06188
Value Function Loss: 0.00493

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09612
Policy Update Magnitude: 0.56463
Value Function Update Magnitude: 0.51786

Collected Steps per Second: 21,968.80502
Overall Steps per Second: 10,411.90523

Timestep Collection Time: 2.27650
Timestep Consumption Time: 2.52685
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.80335

Cumulative Model Updates: 122,970
Cumulative Timesteps: 1,025,626,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1025626660...
Checkpoint 1025626660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,561.26085
Policy Entropy: 3.05161
Value Function Loss: 0.00501

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.56645
Value Function Update Magnitude: 0.51180

Collected Steps per Second: 21,658.58173
Overall Steps per Second: 10,505.89546

Timestep Collection Time: 2.30911
Timestep Consumption Time: 2.45127
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.76037

Cumulative Model Updates: 122,976
Cumulative Timesteps: 1,025,676,672

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,669.51897
Policy Entropy: 3.02913
Value Function Loss: 0.00506

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.11466
Policy Update Magnitude: 0.56319
Value Function Update Magnitude: 0.50793

Collected Steps per Second: 22,265.86933
Overall Steps per Second: 10,545.21764

Timestep Collection Time: 2.24676
Timestep Consumption Time: 2.49719
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.74395

Cumulative Model Updates: 122,982
Cumulative Timesteps: 1,025,726,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1025726698...
Checkpoint 1025726698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,582.31011
Policy Entropy: 3.03756
Value Function Loss: 0.00513

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.11670
Policy Update Magnitude: 0.56535
Value Function Update Magnitude: 0.50390

Collected Steps per Second: 21,791.63270
Overall Steps per Second: 10,295.34933

Timestep Collection Time: 2.29464
Timestep Consumption Time: 2.56231
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.85695

Cumulative Model Updates: 122,988
Cumulative Timesteps: 1,025,776,702

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,441.20824
Policy Entropy: 3.03105
Value Function Loss: 0.00492

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.10844
Policy Update Magnitude: 0.56366
Value Function Update Magnitude: 0.50956

Collected Steps per Second: 22,461.47754
Overall Steps per Second: 10,658.04929

Timestep Collection Time: 2.22639
Timestep Consumption Time: 2.46565
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.69204

Cumulative Model Updates: 122,994
Cumulative Timesteps: 1,025,826,710

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1025826710...
Checkpoint 1025826710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,550.94651
Policy Entropy: 3.05557
Value Function Loss: 0.00481

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.56113
Value Function Update Magnitude: 0.49725

Collected Steps per Second: 22,040.74815
Overall Steps per Second: 10,673.48340

Timestep Collection Time: 2.26889
Timestep Consumption Time: 2.41637
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.68526

Cumulative Model Updates: 123,000
Cumulative Timesteps: 1,025,876,718

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.58382
Policy Entropy: 3.04950
Value Function Loss: 0.00472

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.56522
Value Function Update Magnitude: 0.51368

Collected Steps per Second: 22,551.26416
Overall Steps per Second: 10,581.41082

Timestep Collection Time: 2.21788
Timestep Consumption Time: 2.50890
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.72678

Cumulative Model Updates: 123,006
Cumulative Timesteps: 1,025,926,734

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1025926734...
Checkpoint 1025926734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,429.00489
Policy Entropy: 3.04616
Value Function Loss: 0.00485

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08912
Policy Update Magnitude: 0.57189
Value Function Update Magnitude: 0.52897

Collected Steps per Second: 21,965.77192
Overall Steps per Second: 10,534.78580

Timestep Collection Time: 2.27727
Timestep Consumption Time: 2.47100
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.74827

Cumulative Model Updates: 123,012
Cumulative Timesteps: 1,025,976,756

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,844.74075
Policy Entropy: 3.03458
Value Function Loss: 0.00484

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.09491
Policy Update Magnitude: 0.57784
Value Function Update Magnitude: 0.54023

Collected Steps per Second: 22,647.16322
Overall Steps per Second: 10,675.31401

Timestep Collection Time: 2.20911
Timestep Consumption Time: 2.47741
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.68651

Cumulative Model Updates: 123,018
Cumulative Timesteps: 1,026,026,786

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1026026786...
Checkpoint 1026026786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.38674
Policy Entropy: 3.02852
Value Function Loss: 0.00496

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.09896
Policy Update Magnitude: 0.57457
Value Function Update Magnitude: 0.53333

Collected Steps per Second: 22,178.18670
Overall Steps per Second: 10,495.94395

Timestep Collection Time: 2.25510
Timestep Consumption Time: 2.50998
PPO Batch Consumption Time: 0.29639
Total Iteration Time: 4.76508

Cumulative Model Updates: 123,024
Cumulative Timesteps: 1,026,076,800

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,124.20903
Policy Entropy: 3.03005
Value Function Loss: 0.00488

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.10777
Policy Update Magnitude: 0.56600
Value Function Update Magnitude: 0.52002

Collected Steps per Second: 22,061.54898
Overall Steps per Second: 10,459.41930

Timestep Collection Time: 2.26811
Timestep Consumption Time: 2.51590
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.78401

Cumulative Model Updates: 123,030
Cumulative Timesteps: 1,026,126,838

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1026126838...
Checkpoint 1026126838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,283.40028
Policy Entropy: 3.04467
Value Function Loss: 0.00503

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.56731
Value Function Update Magnitude: 0.51785

Collected Steps per Second: 21,505.84418
Overall Steps per Second: 10,341.04550

Timestep Collection Time: 2.32597
Timestep Consumption Time: 2.51126
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.83723

Cumulative Model Updates: 123,036
Cumulative Timesteps: 1,026,176,860

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 957.18321
Policy Entropy: 3.03905
Value Function Loss: 0.00522

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.09797
Policy Update Magnitude: 0.57796
Value Function Update Magnitude: 0.52745

Collected Steps per Second: 22,266.54080
Overall Steps per Second: 10,720.55612

Timestep Collection Time: 2.24606
Timestep Consumption Time: 2.41900
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.66506

Cumulative Model Updates: 123,042
Cumulative Timesteps: 1,026,226,872

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1026226872...
Checkpoint 1026226872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.43182
Policy Entropy: 3.05796
Value Function Loss: 0.00507

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.57706
Value Function Update Magnitude: 0.52873

Collected Steps per Second: 21,586.17884
Overall Steps per Second: 10,434.14863

Timestep Collection Time: 2.31676
Timestep Consumption Time: 2.47616
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.79292

Cumulative Model Updates: 123,048
Cumulative Timesteps: 1,026,276,882

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469.19238
Policy Entropy: 3.04464
Value Function Loss: 0.00504

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09085
Policy Update Magnitude: 0.56831
Value Function Update Magnitude: 0.52894

Collected Steps per Second: 22,227.35407
Overall Steps per Second: 10,632.11724

Timestep Collection Time: 2.24957
Timestep Consumption Time: 2.45335
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.70292

Cumulative Model Updates: 123,054
Cumulative Timesteps: 1,026,326,884

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1026326884...
Checkpoint 1026326884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,354.14293
Policy Entropy: 3.06196
Value Function Loss: 0.00486

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09127
Policy Update Magnitude: 0.56321
Value Function Update Magnitude: 0.53271

Collected Steps per Second: 21,821.39761
Overall Steps per Second: 10,277.57468

Timestep Collection Time: 2.29142
Timestep Consumption Time: 2.57374
PPO Batch Consumption Time: 0.29572
Total Iteration Time: 4.86516

Cumulative Model Updates: 123,060
Cumulative Timesteps: 1,026,376,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,572.42040
Policy Entropy: 3.05582
Value Function Loss: 0.00483

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09587
Policy Update Magnitude: 0.55852
Value Function Update Magnitude: 0.53502

Collected Steps per Second: 22,388.89310
Overall Steps per Second: 10,494.14587

Timestep Collection Time: 2.23414
Timestep Consumption Time: 2.53232
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.76647

Cumulative Model Updates: 123,066
Cumulative Timesteps: 1,026,426,906

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1026426906...
Checkpoint 1026426906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.51333
Policy Entropy: 3.06264
Value Function Loss: 0.00499

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09518
Policy Update Magnitude: 0.56206
Value Function Update Magnitude: 0.52977

Collected Steps per Second: 22,185.02538
Overall Steps per Second: 10,609.77706

Timestep Collection Time: 2.25431
Timestep Consumption Time: 2.45945
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.71377

Cumulative Model Updates: 123,072
Cumulative Timesteps: 1,026,476,918

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,955.64641
Policy Entropy: 3.06006
Value Function Loss: 0.00502

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09401
Policy Update Magnitude: 0.56038
Value Function Update Magnitude: 0.50958

Collected Steps per Second: 22,719.77247
Overall Steps per Second: 10,812.45472

Timestep Collection Time: 2.20205
Timestep Consumption Time: 2.42502
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.62707

Cumulative Model Updates: 123,078
Cumulative Timesteps: 1,026,526,948

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1026526948...
Checkpoint 1026526948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,958.17046
Policy Entropy: 3.05740
Value Function Loss: 0.00511

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.10517
Policy Update Magnitude: 0.56663
Value Function Update Magnitude: 0.49913

Collected Steps per Second: 21,598.35513
Overall Steps per Second: 10,415.76332

Timestep Collection Time: 2.31610
Timestep Consumption Time: 2.48662
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.80272

Cumulative Model Updates: 123,084
Cumulative Timesteps: 1,026,576,972

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.74839
Policy Entropy: 3.05087
Value Function Loss: 0.00491

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.11321
Policy Update Magnitude: 0.57667
Value Function Update Magnitude: 0.52330

Collected Steps per Second: 22,719.31009
Overall Steps per Second: 10,832.90005

Timestep Collection Time: 2.20148
Timestep Consumption Time: 2.41557
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.61705

Cumulative Model Updates: 123,090
Cumulative Timesteps: 1,026,626,988

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1026626988...
Checkpoint 1026626988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,603.50345
Policy Entropy: 3.03991
Value Function Loss: 0.00504

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.11460
Policy Update Magnitude: 0.57697
Value Function Update Magnitude: 0.53550

Collected Steps per Second: 21,893.05453
Overall Steps per Second: 10,602.59787

Timestep Collection Time: 2.28447
Timestep Consumption Time: 2.43268
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.71715

Cumulative Model Updates: 123,096
Cumulative Timesteps: 1,026,677,002

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,361.91957
Policy Entropy: 3.03448
Value Function Loss: 0.00511

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.11294
Policy Update Magnitude: 0.57613
Value Function Update Magnitude: 0.55005

Collected Steps per Second: 21,778.53540
Overall Steps per Second: 10,442.26755

Timestep Collection Time: 2.29666
Timestep Consumption Time: 2.49329
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.78996

Cumulative Model Updates: 123,102
Cumulative Timesteps: 1,026,727,020

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1026727020...
Checkpoint 1026727020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.88653
Policy Entropy: 3.01915
Value Function Loss: 0.00527

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.10576
Policy Update Magnitude: 0.58706
Value Function Update Magnitude: 0.55408

Collected Steps per Second: 21,606.89755
Overall Steps per Second: 10,336.04526

Timestep Collection Time: 2.31472
Timestep Consumption Time: 2.52407
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.83879

Cumulative Model Updates: 123,108
Cumulative Timesteps: 1,026,777,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,718.43928
Policy Entropy: 3.01224
Value Function Loss: 0.00517

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.11517
Policy Update Magnitude: 0.59145
Value Function Update Magnitude: 0.56030

Collected Steps per Second: 21,873.70829
Overall Steps per Second: 10,383.17741

Timestep Collection Time: 2.28622
Timestep Consumption Time: 2.53004
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.81625

Cumulative Model Updates: 123,114
Cumulative Timesteps: 1,026,827,042

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1026827042...
Checkpoint 1026827042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,035.35245
Policy Entropy: 3.00689
Value Function Loss: 0.00496

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.10803
Policy Update Magnitude: 0.58170
Value Function Update Magnitude: 0.54748

Collected Steps per Second: 21,630.94133
Overall Steps per Second: 10,523.44992

Timestep Collection Time: 2.31280
Timestep Consumption Time: 2.44116
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.75395

Cumulative Model Updates: 123,120
Cumulative Timesteps: 1,026,877,070

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.98812
Policy Entropy: 3.01738
Value Function Loss: 0.00493

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10080
Policy Update Magnitude: 0.57657
Value Function Update Magnitude: 0.53045

Collected Steps per Second: 22,149.53131
Overall Steps per Second: 10,510.08001

Timestep Collection Time: 2.25756
Timestep Consumption Time: 2.50015
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.75772

Cumulative Model Updates: 123,126
Cumulative Timesteps: 1,026,927,074

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1026927074...
Checkpoint 1026927074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,860.63759
Policy Entropy: 3.01079
Value Function Loss: 0.00489

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.10332
Policy Update Magnitude: 0.57386
Value Function Update Magnitude: 0.53287

Collected Steps per Second: 21,440.62075
Overall Steps per Second: 10,382.77941

Timestep Collection Time: 2.33267
Timestep Consumption Time: 2.48434
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.81701

Cumulative Model Updates: 123,132
Cumulative Timesteps: 1,026,977,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.18138
Policy Entropy: 3.02786
Value Function Loss: 0.00484

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10022
Policy Update Magnitude: 0.57769
Value Function Update Magnitude: 0.51541

Collected Steps per Second: 22,699.18480
Overall Steps per Second: 10,780.45954

Timestep Collection Time: 2.20396
Timestep Consumption Time: 2.43666
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.64062

Cumulative Model Updates: 123,138
Cumulative Timesteps: 1,027,027,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1027027116...
Checkpoint 1027027116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,148.11607
Policy Entropy: 3.00764
Value Function Loss: 0.00471

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.57155
Value Function Update Magnitude: 0.50901

Collected Steps per Second: 22,108.17513
Overall Steps per Second: 10,634.47311

Timestep Collection Time: 2.26296
Timestep Consumption Time: 2.44155
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.70451

Cumulative Model Updates: 123,144
Cumulative Timesteps: 1,027,077,146

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,266.45488
Policy Entropy: 3.00505
Value Function Loss: 0.00478

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.09856
Policy Update Magnitude: 0.57240
Value Function Update Magnitude: 0.51965

Collected Steps per Second: 22,480.51021
Overall Steps per Second: 10,529.96915

Timestep Collection Time: 2.22522
Timestep Consumption Time: 2.52541
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.75063

Cumulative Model Updates: 123,150
Cumulative Timesteps: 1,027,127,170

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1027127170...
Checkpoint 1027127170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558.58547
Policy Entropy: 2.98896
Value Function Loss: 0.00480

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10168
Policy Update Magnitude: 0.57525
Value Function Update Magnitude: 0.52806

Collected Steps per Second: 21,907.98253
Overall Steps per Second: 10,526.48175

Timestep Collection Time: 2.28264
Timestep Consumption Time: 2.46805
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.75069

Cumulative Model Updates: 123,156
Cumulative Timesteps: 1,027,177,178

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,999.37699
Policy Entropy: 2.99922
Value Function Loss: 0.00472

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10205
Policy Update Magnitude: 0.56899
Value Function Update Magnitude: 0.54657

Collected Steps per Second: 22,538.42530
Overall Steps per Second: 10,542.19036

Timestep Collection Time: 2.21914
Timestep Consumption Time: 2.52522
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.74437

Cumulative Model Updates: 123,162
Cumulative Timesteps: 1,027,227,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1027227194...
Checkpoint 1027227194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,210.93662
Policy Entropy: 2.99585
Value Function Loss: 0.00486

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10446
Policy Update Magnitude: 0.56255
Value Function Update Magnitude: 0.54533

Collected Steps per Second: 22,329.24785
Overall Steps per Second: 10,551.04759

Timestep Collection Time: 2.23948
Timestep Consumption Time: 2.49995
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.73943

Cumulative Model Updates: 123,168
Cumulative Timesteps: 1,027,277,200

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,671.29462
Policy Entropy: 3.00622
Value Function Loss: 0.00493

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.56843
Value Function Update Magnitude: 0.53797

Collected Steps per Second: 22,285.20184
Overall Steps per Second: 10,533.36712

Timestep Collection Time: 2.24436
Timestep Consumption Time: 2.50398
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.74834

Cumulative Model Updates: 123,174
Cumulative Timesteps: 1,027,327,216

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1027327216...
Checkpoint 1027327216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.79863
Policy Entropy: 3.01963
Value Function Loss: 0.00497

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.57193
Value Function Update Magnitude: 0.52965

Collected Steps per Second: 21,600.98211
Overall Steps per Second: 10,511.50962

Timestep Collection Time: 2.31527
Timestep Consumption Time: 2.44257
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.75783

Cumulative Model Updates: 123,180
Cumulative Timesteps: 1,027,377,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.90292
Policy Entropy: 3.04533
Value Function Loss: 0.00499

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.56416
Value Function Update Magnitude: 0.53953

Collected Steps per Second: 22,013.54704
Overall Steps per Second: 10,523.46061

Timestep Collection Time: 2.27142
Timestep Consumption Time: 2.48006
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.75148

Cumulative Model Updates: 123,186
Cumulative Timesteps: 1,027,427,230

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1027427230...
Checkpoint 1027427230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,687.63056
Policy Entropy: 3.01985
Value Function Loss: 0.00491

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.13903
Policy Update Magnitude: 0.56669
Value Function Update Magnitude: 0.55894

Collected Steps per Second: 21,776.20389
Overall Steps per Second: 10,612.01518

Timestep Collection Time: 2.29755
Timestep Consumption Time: 2.41710
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.71466

Cumulative Model Updates: 123,192
Cumulative Timesteps: 1,027,477,262

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,429.29686
Policy Entropy: 3.00723
Value Function Loss: 0.00509

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.12218
Policy Update Magnitude: 0.57604
Value Function Update Magnitude: 0.56243

Collected Steps per Second: 22,072.75763
Overall Steps per Second: 10,468.33599

Timestep Collection Time: 2.26750
Timestep Consumption Time: 2.51358
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.78108

Cumulative Model Updates: 123,198
Cumulative Timesteps: 1,027,527,312

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1027527312...
Checkpoint 1027527312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,418.84841
Policy Entropy: 2.98216
Value Function Loss: 0.00511

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.11996
Policy Update Magnitude: 0.58247
Value Function Update Magnitude: 0.56548

Collected Steps per Second: 21,684.95311
Overall Steps per Second: 10,369.00028

Timestep Collection Time: 2.30704
Timestep Consumption Time: 2.51773
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.82477

Cumulative Model Updates: 123,204
Cumulative Timesteps: 1,027,577,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,904.42216
Policy Entropy: 2.99348
Value Function Loss: 0.00503

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11290
Policy Update Magnitude: 0.57752
Value Function Update Magnitude: 0.56445

Collected Steps per Second: 22,439.45527
Overall Steps per Second: 10,437.84808

Timestep Collection Time: 2.22982
Timestep Consumption Time: 2.56389
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.79371

Cumulative Model Updates: 123,210
Cumulative Timesteps: 1,027,627,376

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1027627376...
Checkpoint 1027627376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,396.03815
Policy Entropy: 3.00081
Value Function Loss: 0.00522

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.11588
Policy Update Magnitude: 0.58018
Value Function Update Magnitude: 0.57881

Collected Steps per Second: 22,062.63352
Overall Steps per Second: 10,505.80806

Timestep Collection Time: 2.26745
Timestep Consumption Time: 2.49429
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.76175

Cumulative Model Updates: 123,216
Cumulative Timesteps: 1,027,677,402

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345.40176
Policy Entropy: 3.02458
Value Function Loss: 0.00535

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.10992
Policy Update Magnitude: 0.57313
Value Function Update Magnitude: 0.62350

Collected Steps per Second: 22,314.29284
Overall Steps per Second: 10,451.39299

Timestep Collection Time: 2.24161
Timestep Consumption Time: 2.54435
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.78596

Cumulative Model Updates: 123,222
Cumulative Timesteps: 1,027,727,422

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1027727422...
Checkpoint 1027727422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.98009
Policy Entropy: 3.02488
Value Function Loss: 0.00514

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.10235
Policy Update Magnitude: 0.58065
Value Function Update Magnitude: 0.63277

Collected Steps per Second: 22,232.75196
Overall Steps per Second: 10,639.44824

Timestep Collection Time: 2.24992
Timestep Consumption Time: 2.45164
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.70156

Cumulative Model Updates: 123,228
Cumulative Timesteps: 1,027,777,444

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.69022
Policy Entropy: 3.02060
Value Function Loss: 0.00511

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.58339
Value Function Update Magnitude: 0.63407

Collected Steps per Second: 22,585.40569
Overall Steps per Second: 10,674.84474

Timestep Collection Time: 2.21417
Timestep Consumption Time: 2.47049
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.68466

Cumulative Model Updates: 123,234
Cumulative Timesteps: 1,027,827,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1027827452...
Checkpoint 1027827452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.34474
Policy Entropy: 3.01704
Value Function Loss: 0.00484

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.10093
Policy Update Magnitude: 0.57972
Value Function Update Magnitude: 0.60907

Collected Steps per Second: 22,278.12786
Overall Steps per Second: 10,618.71373

Timestep Collection Time: 2.24525
Timestep Consumption Time: 2.46530
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.71055

Cumulative Model Updates: 123,240
Cumulative Timesteps: 1,027,877,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.26758
Policy Entropy: 3.00277
Value Function Loss: 0.00482

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.09980
Policy Update Magnitude: 0.57562
Value Function Update Magnitude: 0.57524

Collected Steps per Second: 22,512.03355
Overall Steps per Second: 10,692.93362

Timestep Collection Time: 2.22112
Timestep Consumption Time: 2.45505
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.67617

Cumulative Model Updates: 123,246
Cumulative Timesteps: 1,027,927,474

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1027927474...
Checkpoint 1027927474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,566.38231
Policy Entropy: 3.00822
Value Function Loss: 0.00481

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.09796
Policy Update Magnitude: 0.56899
Value Function Update Magnitude: 0.55631

Collected Steps per Second: 21,510.07540
Overall Steps per Second: 10,341.59084

Timestep Collection Time: 2.32579
Timestep Consumption Time: 2.51176
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.83755

Cumulative Model Updates: 123,252
Cumulative Timesteps: 1,027,977,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.51522
Policy Entropy: 3.00216
Value Function Loss: 0.00493

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.57166
Value Function Update Magnitude: 0.54519

Collected Steps per Second: 22,222.02578
Overall Steps per Second: 10,728.77264

Timestep Collection Time: 2.25110
Timestep Consumption Time: 2.41150
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.66260

Cumulative Model Updates: 123,258
Cumulative Timesteps: 1,028,027,526

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1028027526...
Checkpoint 1028027526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,910.59026
Policy Entropy: 3.00669
Value Function Loss: 0.00523

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09378
Policy Update Magnitude: 0.58006
Value Function Update Magnitude: 0.54890

Collected Steps per Second: 21,565.46435
Overall Steps per Second: 10,452.40185

Timestep Collection Time: 2.31889
Timestep Consumption Time: 2.46546
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.78435

Cumulative Model Updates: 123,264
Cumulative Timesteps: 1,028,077,534

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,665.61553
Policy Entropy: 3.00552
Value Function Loss: 0.00521

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10449
Policy Update Magnitude: 0.58124
Value Function Update Magnitude: 0.54551

Collected Steps per Second: 21,973.79856
Overall Steps per Second: 10,456.96056

Timestep Collection Time: 2.27617
Timestep Consumption Time: 2.50687
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.78303

Cumulative Model Updates: 123,270
Cumulative Timesteps: 1,028,127,550

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1028127550...
Checkpoint 1028127550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.68490
Policy Entropy: 3.00538
Value Function Loss: 0.00527

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.10893
Policy Update Magnitude: 0.58325
Value Function Update Magnitude: 0.52190

Collected Steps per Second: 21,944.88387
Overall Steps per Second: 10,445.13912

Timestep Collection Time: 2.27944
Timestep Consumption Time: 2.50958
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.78902

Cumulative Model Updates: 123,276
Cumulative Timesteps: 1,028,177,572

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,335.63247
Policy Entropy: 3.02355
Value Function Loss: 0.00524

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.57757
Value Function Update Magnitude: 0.51320

Collected Steps per Second: 22,303.73706
Overall Steps per Second: 10,464.81561

Timestep Collection Time: 2.24205
Timestep Consumption Time: 2.53644
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.77849

Cumulative Model Updates: 123,282
Cumulative Timesteps: 1,028,227,578

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1028227578...
Checkpoint 1028227578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 954.80520
Policy Entropy: 3.04216
Value Function Loss: 0.00537

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09299
Policy Update Magnitude: 0.57948
Value Function Update Magnitude: 0.52101

Collected Steps per Second: 22,188.75412
Overall Steps per Second: 10,564.15097

Timestep Collection Time: 2.25375
Timestep Consumption Time: 2.47999
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.73375

Cumulative Model Updates: 123,288
Cumulative Timesteps: 1,028,277,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,001.53909
Policy Entropy: 3.03542
Value Function Loss: 0.00516

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.09707
Policy Update Magnitude: 0.57690
Value Function Update Magnitude: 0.54998

Collected Steps per Second: 22,220.21208
Overall Steps per Second: 10,499.72682

Timestep Collection Time: 2.25191
Timestep Consumption Time: 2.51373
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.76565

Cumulative Model Updates: 123,294
Cumulative Timesteps: 1,028,327,624

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1028327624...
Checkpoint 1028327624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.82886
Policy Entropy: 3.02401
Value Function Loss: 0.00507

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08854
Policy Update Magnitude: 0.57551
Value Function Update Magnitude: 0.57154

Collected Steps per Second: 21,507.19595
Overall Steps per Second: 10,397.61547

Timestep Collection Time: 2.32592
Timestep Consumption Time: 2.48518
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.81110

Cumulative Model Updates: 123,300
Cumulative Timesteps: 1,028,377,648

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558.87771
Policy Entropy: 3.02858
Value Function Loss: 0.00524

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09464
Policy Update Magnitude: 0.58059
Value Function Update Magnitude: 0.56667

Collected Steps per Second: 22,519.96641
Overall Steps per Second: 10,715.91865

Timestep Collection Time: 2.22132
Timestep Consumption Time: 2.44688
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.66820

Cumulative Model Updates: 123,306
Cumulative Timesteps: 1,028,427,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1028427672...
Checkpoint 1028427672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 782.55043
Policy Entropy: 3.04250
Value Function Loss: 0.00509

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.57597
Value Function Update Magnitude: 0.55877

Collected Steps per Second: 21,938.59701
Overall Steps per Second: 10,651.72558

Timestep Collection Time: 2.28036
Timestep Consumption Time: 2.41634
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.69670

Cumulative Model Updates: 123,312
Cumulative Timesteps: 1,028,477,700

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,028.23623
Policy Entropy: 3.04632
Value Function Loss: 0.00501

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09082
Policy Update Magnitude: 0.56995
Value Function Update Magnitude: 0.53800

Collected Steps per Second: 22,437.29491
Overall Steps per Second: 10,578.77407

Timestep Collection Time: 2.22861
Timestep Consumption Time: 2.49821
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.72682

Cumulative Model Updates: 123,318
Cumulative Timesteps: 1,028,527,704

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1028527704...
Checkpoint 1028527704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,299.90925
Policy Entropy: 3.03493
Value Function Loss: 0.00478

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09209
Policy Update Magnitude: 0.56464
Value Function Update Magnitude: 0.53565

Collected Steps per Second: 21,818.18277
Overall Steps per Second: 10,523.18126

Timestep Collection Time: 2.29267
Timestep Consumption Time: 2.46083
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.75351

Cumulative Model Updates: 123,324
Cumulative Timesteps: 1,028,577,726

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,729.17738
Policy Entropy: 3.03558
Value Function Loss: 0.00490

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.09489
Policy Update Magnitude: 0.56644
Value Function Update Magnitude: 0.52856

Collected Steps per Second: 21,653.75009
Overall Steps per Second: 10,461.12790

Timestep Collection Time: 2.31045
Timestep Consumption Time: 2.47201
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.78247

Cumulative Model Updates: 123,330
Cumulative Timesteps: 1,028,627,756

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1028627756...
Checkpoint 1028627756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580.58893
Policy Entropy: 3.03532
Value Function Loss: 0.00478

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10026
Policy Update Magnitude: 0.56324
Value Function Update Magnitude: 0.51594

Collected Steps per Second: 21,272.84553
Overall Steps per Second: 10,149.89059

Timestep Collection Time: 2.35107
Timestep Consumption Time: 2.57647
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.92754

Cumulative Model Updates: 123,336
Cumulative Timesteps: 1,028,677,770

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445.08010
Policy Entropy: 3.04420
Value Function Loss: 0.00457

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08795
Policy Update Magnitude: 0.55091
Value Function Update Magnitude: 0.50378

Collected Steps per Second: 21,931.92156
Overall Steps per Second: 10,546.18458

Timestep Collection Time: 2.27978
Timestep Consumption Time: 2.46127
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.74105

Cumulative Model Updates: 123,342
Cumulative Timesteps: 1,028,727,770

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1028727770...
Checkpoint 1028727770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,495.96603
Policy Entropy: 3.03545
Value Function Loss: 0.00449

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08799
Policy Update Magnitude: 0.54835
Value Function Update Magnitude: 0.48547

Collected Steps per Second: 21,931.66315
Overall Steps per Second: 10,561.77444

Timestep Collection Time: 2.28054
Timestep Consumption Time: 2.45503
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.73557

Cumulative Model Updates: 123,348
Cumulative Timesteps: 1,028,777,786

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.47979
Policy Entropy: 3.04920
Value Function Loss: 0.00465

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09627
Policy Update Magnitude: 0.55315
Value Function Update Magnitude: 0.48189

Collected Steps per Second: 22,210.50465
Overall Steps per Second: 10,539.74230

Timestep Collection Time: 2.25227
Timestep Consumption Time: 2.49396
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.74623

Cumulative Model Updates: 123,354
Cumulative Timesteps: 1,028,827,810

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1028827810...
Checkpoint 1028827810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.65590
Policy Entropy: 3.04170
Value Function Loss: 0.00462

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.55161
Value Function Update Magnitude: 0.49101

Collected Steps per Second: 21,990.29300
Overall Steps per Second: 10,529.16818

Timestep Collection Time: 2.27428
Timestep Consumption Time: 2.47558
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.74985

Cumulative Model Updates: 123,360
Cumulative Timesteps: 1,028,877,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,769.80254
Policy Entropy: 3.04073
Value Function Loss: 0.00457

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10047
Policy Update Magnitude: 0.55048
Value Function Update Magnitude: 0.48180

Collected Steps per Second: 22,341.08095
Overall Steps per Second: 10,524.82731

Timestep Collection Time: 2.23812
Timestep Consumption Time: 2.51274
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.75086

Cumulative Model Updates: 123,366
Cumulative Timesteps: 1,028,927,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1028927824...
Checkpoint 1028927824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,693.37943
Policy Entropy: 3.01110
Value Function Loss: 0.00480

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.55752
Value Function Update Magnitude: 0.49134

Collected Steps per Second: 22,243.41349
Overall Steps per Second: 10,641.05743

Timestep Collection Time: 2.24831
Timestep Consumption Time: 2.45141
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.69972

Cumulative Model Updates: 123,372
Cumulative Timesteps: 1,028,977,834

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 888.96153
Policy Entropy: 2.99977
Value Function Loss: 0.00481

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.10686
Policy Update Magnitude: 0.55614
Value Function Update Magnitude: 0.50126

Collected Steps per Second: 22,279.65303
Overall Steps per Second: 10,476.63758

Timestep Collection Time: 2.24510
Timestep Consumption Time: 2.52933
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.77443

Cumulative Model Updates: 123,378
Cumulative Timesteps: 1,029,027,854

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1029027854...
Checkpoint 1029027854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,998.26660
Policy Entropy: 2.97695
Value Function Loss: 0.00508

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.09820
Policy Update Magnitude: 0.58096
Value Function Update Magnitude: 0.49099

Collected Steps per Second: 22,079.80454
Overall Steps per Second: 10,702.30609

Timestep Collection Time: 2.26451
Timestep Consumption Time: 2.40738
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.67189

Cumulative Model Updates: 123,384
Cumulative Timesteps: 1,029,077,854

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,047.34711
Policy Entropy: 2.98749
Value Function Loss: 0.00522

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.09887
Policy Update Magnitude: 0.58722
Value Function Update Magnitude: 0.51258

Collected Steps per Second: 22,551.69585
Overall Steps per Second: 10,772.02089

Timestep Collection Time: 2.21810
Timestep Consumption Time: 2.42559
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.64370

Cumulative Model Updates: 123,390
Cumulative Timesteps: 1,029,127,876

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1029127876...
Checkpoint 1029127876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,703.56485
Policy Entropy: 2.98687
Value Function Loss: 0.00515

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.09861
Policy Update Magnitude: 0.57944
Value Function Update Magnitude: 0.53443

Collected Steps per Second: 22,163.71543
Overall Steps per Second: 10,675.95525

Timestep Collection Time: 2.25630
Timestep Consumption Time: 2.42787
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.68417

Cumulative Model Updates: 123,396
Cumulative Timesteps: 1,029,177,884

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,016.39917
Policy Entropy: 3.00148
Value Function Loss: 0.00509

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.57211
Value Function Update Magnitude: 0.54682

Collected Steps per Second: 21,847.99972
Overall Steps per Second: 10,554.38234

Timestep Collection Time: 2.28936
Timestep Consumption Time: 2.44971
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.73907

Cumulative Model Updates: 123,402
Cumulative Timesteps: 1,029,227,902

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1029227902...
Checkpoint 1029227902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.84124
Policy Entropy: 3.00199
Value Function Loss: 0.00497

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09211
Policy Update Magnitude: 0.56452
Value Function Update Magnitude: 0.53146

Collected Steps per Second: 21,692.12167
Overall Steps per Second: 10,537.31545

Timestep Collection Time: 2.30581
Timestep Consumption Time: 2.44094
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.74675

Cumulative Model Updates: 123,408
Cumulative Timesteps: 1,029,277,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.31888
Policy Entropy: 3.00032
Value Function Loss: 0.00529

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10011
Policy Update Magnitude: 0.56722
Value Function Update Magnitude: 0.52224

Collected Steps per Second: 21,977.07105
Overall Steps per Second: 10,467.11137

Timestep Collection Time: 2.27655
Timestep Consumption Time: 2.50337
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.77992

Cumulative Model Updates: 123,414
Cumulative Timesteps: 1,029,327,952

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1029327952...
Checkpoint 1029327952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,939.62454
Policy Entropy: 3.00430
Value Function Loss: 0.00549

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10642
Policy Update Magnitude: 0.57705
Value Function Update Magnitude: 0.52568

Collected Steps per Second: 21,553.31399
Overall Steps per Second: 10,563.30168

Timestep Collection Time: 2.32076
Timestep Consumption Time: 2.41451
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.73526

Cumulative Model Updates: 123,420
Cumulative Timesteps: 1,029,377,972

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.14493
Policy Entropy: 2.99512
Value Function Loss: 0.00528

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10083
Policy Update Magnitude: 0.58459
Value Function Update Magnitude: 0.54284

Collected Steps per Second: 21,856.31049
Overall Steps per Second: 10,622.44933

Timestep Collection Time: 2.28877
Timestep Consumption Time: 2.42050
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.70927

Cumulative Model Updates: 123,426
Cumulative Timesteps: 1,029,427,996

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1029427996...
Checkpoint 1029427996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,569.23354
Policy Entropy: 2.98586
Value Function Loss: 0.00503

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.09970
Policy Update Magnitude: 0.58561
Value Function Update Magnitude: 0.53833

Collected Steps per Second: 22,251.90843
Overall Steps per Second: 10,558.43657

Timestep Collection Time: 2.24826
Timestep Consumption Time: 2.48994
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.73820

Cumulative Model Updates: 123,432
Cumulative Timesteps: 1,029,478,024

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,873.79127
Policy Entropy: 2.97374
Value Function Loss: 0.00510

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10381
Policy Update Magnitude: 0.58048
Value Function Update Magnitude: 0.52036

Collected Steps per Second: 22,115.41723
Overall Steps per Second: 10,411.21011

Timestep Collection Time: 2.26105
Timestep Consumption Time: 2.54185
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.80290

Cumulative Model Updates: 123,438
Cumulative Timesteps: 1,029,528,028

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1029528028...
Checkpoint 1029528028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,010.86181
Policy Entropy: 2.97861
Value Function Loss: 0.00510

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.09791
Policy Update Magnitude: 0.57600
Value Function Update Magnitude: 0.51948

Collected Steps per Second: 22,041.99611
Overall Steps per Second: 10,589.61987

Timestep Collection Time: 2.26967
Timestep Consumption Time: 2.45458
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.72425

Cumulative Model Updates: 123,444
Cumulative Timesteps: 1,029,578,056

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 817.88301
Policy Entropy: 2.99897
Value Function Loss: 0.00507

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.58238
Value Function Update Magnitude: 0.50489

Collected Steps per Second: 22,314.85781
Overall Steps per Second: 10,567.92342

Timestep Collection Time: 2.24174
Timestep Consumption Time: 2.49183
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.73357

Cumulative Model Updates: 123,450
Cumulative Timesteps: 1,029,628,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1029628080...
Checkpoint 1029628080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,030.41965
Policy Entropy: 3.00071
Value Function Loss: 0.00506

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09693
Policy Update Magnitude: 0.58123
Value Function Update Magnitude: 0.50386

Collected Steps per Second: 21,676.83955
Overall Steps per Second: 10,392.97269

Timestep Collection Time: 2.30716
Timestep Consumption Time: 2.50493
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.81210

Cumulative Model Updates: 123,456
Cumulative Timesteps: 1,029,678,092

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.25397
Policy Entropy: 2.99858
Value Function Loss: 0.00500

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.10781
Policy Update Magnitude: 0.57465
Value Function Update Magnitude: 0.49971

Collected Steps per Second: 22,069.47459
Overall Steps per Second: 10,641.60716

Timestep Collection Time: 2.26621
Timestep Consumption Time: 2.43365
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.69985

Cumulative Model Updates: 123,462
Cumulative Timesteps: 1,029,728,106

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1029728106...
Checkpoint 1029728106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,187.77910
Policy Entropy: 2.99697
Value Function Loss: 0.00509

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.57824
Value Function Update Magnitude: 0.50011

Collected Steps per Second: 21,901.86125
Overall Steps per Second: 10,618.61523

Timestep Collection Time: 2.28346
Timestep Consumption Time: 2.42638
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.70984

Cumulative Model Updates: 123,468
Cumulative Timesteps: 1,029,778,118

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,663.24367
Policy Entropy: 3.00332
Value Function Loss: 0.00535

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11123
Policy Update Magnitude: 0.58335
Value Function Update Magnitude: 0.52683

Collected Steps per Second: 21,964.78820
Overall Steps per Second: 10,546.62113

Timestep Collection Time: 2.27755
Timestep Consumption Time: 2.46577
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.74332

Cumulative Model Updates: 123,474
Cumulative Timesteps: 1,029,828,144

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1029828144...
Checkpoint 1029828144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,620.95992
Policy Entropy: 3.02438
Value Function Loss: 0.00496

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.11844
Policy Update Magnitude: 0.57687
Value Function Update Magnitude: 0.53661

Collected Steps per Second: 21,524.36239
Overall Steps per Second: 10,355.26906

Timestep Collection Time: 2.32304
Timestep Consumption Time: 2.50561
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.82865

Cumulative Model Updates: 123,480
Cumulative Timesteps: 1,029,878,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691.22037
Policy Entropy: 3.03999
Value Function Loss: 0.00492

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.11094
Policy Update Magnitude: 0.56151
Value Function Update Magnitude: 0.51285

Collected Steps per Second: 22,033.99911
Overall Steps per Second: 10,656.86675

Timestep Collection Time: 2.26977
Timestep Consumption Time: 2.42317
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.69294

Cumulative Model Updates: 123,486
Cumulative Timesteps: 1,029,928,158

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1029928158...
Checkpoint 1029928158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 892.02313
Policy Entropy: 3.03740
Value Function Loss: 0.00478

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10187
Policy Update Magnitude: 0.56377
Value Function Update Magnitude: 0.48881

Collected Steps per Second: 21,788.97783
Overall Steps per Second: 10,385.80001

Timestep Collection Time: 2.29483
Timestep Consumption Time: 2.51963
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.81446

Cumulative Model Updates: 123,492
Cumulative Timesteps: 1,029,978,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,695.33195
Policy Entropy: 3.02128
Value Function Loss: 0.00473

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.10368
Policy Update Magnitude: 0.56218
Value Function Update Magnitude: 0.48629

Collected Steps per Second: 22,541.50133
Overall Steps per Second: 10,556.25487

Timestep Collection Time: 2.21928
Timestep Consumption Time: 2.51971
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.73899

Cumulative Model Updates: 123,498
Cumulative Timesteps: 1,030,028,186

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1030028186...
Checkpoint 1030028186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,107.96363
Policy Entropy: 3.01686
Value Function Loss: 0.00468

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.09970
Policy Update Magnitude: 0.56721
Value Function Update Magnitude: 0.47778

Collected Steps per Second: 22,286.34086
Overall Steps per Second: 10,479.98986

Timestep Collection Time: 2.24469
Timestep Consumption Time: 2.52878
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.77348

Cumulative Model Updates: 123,504
Cumulative Timesteps: 1,030,078,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 989.26587
Policy Entropy: 3.02108
Value Function Loss: 0.00479

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09451
Policy Update Magnitude: 0.57112
Value Function Update Magnitude: 0.48756

Collected Steps per Second: 22,294.11418
Overall Steps per Second: 10,503.88557

Timestep Collection Time: 2.24355
Timestep Consumption Time: 2.51831
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.76186

Cumulative Model Updates: 123,510
Cumulative Timesteps: 1,030,128,230

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1030128230...
Checkpoint 1030128230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,347.74269
Policy Entropy: 3.01910
Value Function Loss: 0.00478

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08518
Policy Update Magnitude: 0.57513
Value Function Update Magnitude: 0.48853

Collected Steps per Second: 22,188.48348
Overall Steps per Second: 10,532.65933

Timestep Collection Time: 2.25405
Timestep Consumption Time: 2.49442
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.74847

Cumulative Model Updates: 123,516
Cumulative Timesteps: 1,030,178,244

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,142.49881
Policy Entropy: 3.01183
Value Function Loss: 0.00482

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08674
Policy Update Magnitude: 0.57378
Value Function Update Magnitude: 0.49210

Collected Steps per Second: 22,287.75505
Overall Steps per Second: 10,561.54717

Timestep Collection Time: 2.24437
Timestep Consumption Time: 2.49187
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.73624

Cumulative Model Updates: 123,522
Cumulative Timesteps: 1,030,228,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1030228266...
Checkpoint 1030228266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,811.67475
Policy Entropy: 3.01485
Value Function Loss: 0.00480

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10321
Policy Update Magnitude: 0.57597
Value Function Update Magnitude: 0.48912

Collected Steps per Second: 22,140.27791
Overall Steps per Second: 10,554.10530

Timestep Collection Time: 2.25950
Timestep Consumption Time: 2.48045
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.73996

Cumulative Model Updates: 123,528
Cumulative Timesteps: 1,030,278,292

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,776.66800
Policy Entropy: 3.01344
Value Function Loss: 0.00480

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09328
Policy Update Magnitude: 0.57520
Value Function Update Magnitude: 0.49056

Collected Steps per Second: 22,118.95288
Overall Steps per Second: 10,443.55588

Timestep Collection Time: 2.26123
Timestep Consumption Time: 2.52795
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.78917

Cumulative Model Updates: 123,534
Cumulative Timesteps: 1,030,328,308

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1030328308...
Checkpoint 1030328308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.28936
Policy Entropy: 3.01738
Value Function Loss: 0.00475

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09165
Policy Update Magnitude: 0.57462
Value Function Update Magnitude: 0.48673

Collected Steps per Second: 21,756.87600
Overall Steps per Second: 10,429.39595

Timestep Collection Time: 2.29868
Timestep Consumption Time: 2.49662
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.79529

Cumulative Model Updates: 123,540
Cumulative Timesteps: 1,030,378,320

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,783.00642
Policy Entropy: 3.00758
Value Function Loss: 0.00478

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09417
Policy Update Magnitude: 0.57193
Value Function Update Magnitude: 0.50387

Collected Steps per Second: 22,082.00626
Overall Steps per Second: 10,620.51475

Timestep Collection Time: 2.26528
Timestep Consumption Time: 2.44466
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.70994

Cumulative Model Updates: 123,546
Cumulative Timesteps: 1,030,428,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1030428342...
Checkpoint 1030428342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.72659
Policy Entropy: 3.01550
Value Function Loss: 0.00476

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09015
Policy Update Magnitude: 0.57135
Value Function Update Magnitude: 0.50901

Collected Steps per Second: 20,617.84535
Overall Steps per Second: 10,201.20708

Timestep Collection Time: 2.42605
Timestep Consumption Time: 2.47729
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.90334

Cumulative Model Updates: 123,552
Cumulative Timesteps: 1,030,478,362

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,580.22522
Policy Entropy: 3.02081
Value Function Loss: 0.00476

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09319
Policy Update Magnitude: 0.56721
Value Function Update Magnitude: 0.50253

Collected Steps per Second: 21,540.24971
Overall Steps per Second: 10,456.61675

Timestep Collection Time: 2.32244
Timestep Consumption Time: 2.46170
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.78415

Cumulative Model Updates: 123,558
Cumulative Timesteps: 1,030,528,388

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1030528388...
Checkpoint 1030528388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,753.43368
Policy Entropy: 3.01579
Value Function Loss: 0.00488

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.57181
Value Function Update Magnitude: 0.51129

Collected Steps per Second: 20,350.99776
Overall Steps per Second: 9,996.47953

Timestep Collection Time: 2.45806
Timestep Consumption Time: 2.54610
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 5.00416

Cumulative Model Updates: 123,564
Cumulative Timesteps: 1,030,578,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531.24075
Policy Entropy: 3.01341
Value Function Loss: 0.00506

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10311
Policy Update Magnitude: 0.57594
Value Function Update Magnitude: 0.51602

Collected Steps per Second: 22,058.76158
Overall Steps per Second: 10,370.55489

Timestep Collection Time: 2.26704
Timestep Consumption Time: 2.55508
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.82211

Cumulative Model Updates: 123,570
Cumulative Timesteps: 1,030,628,420

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1030628420...
Checkpoint 1030628420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.77548
Policy Entropy: 3.00790
Value Function Loss: 0.00519

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09242
Policy Update Magnitude: 0.58756
Value Function Update Magnitude: 0.52691

Collected Steps per Second: 22,089.04683
Overall Steps per Second: 10,561.83993

Timestep Collection Time: 2.26483
Timestep Consumption Time: 2.47184
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.73667

Cumulative Model Updates: 123,576
Cumulative Timesteps: 1,030,678,448

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.95560
Policy Entropy: 3.02226
Value Function Loss: 0.00526

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09494
Policy Update Magnitude: 0.59256
Value Function Update Magnitude: 0.53047

Collected Steps per Second: 22,377.63289
Overall Steps per Second: 10,555.26846

Timestep Collection Time: 2.23455
Timestep Consumption Time: 2.50280
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.73735

Cumulative Model Updates: 123,582
Cumulative Timesteps: 1,030,728,452

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1030728452...
Checkpoint 1030728452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.21354
Policy Entropy: 3.00822
Value Function Loss: 0.00532

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.09937
Policy Update Magnitude: 0.59399
Value Function Update Magnitude: 0.54647

Collected Steps per Second: 22,191.10794
Overall Steps per Second: 10,657.55358

Timestep Collection Time: 2.25406
Timestep Consumption Time: 2.43933
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.69338

Cumulative Model Updates: 123,588
Cumulative Timesteps: 1,030,778,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,599.30234
Policy Entropy: 3.02909
Value Function Loss: 0.00501

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.09425
Policy Update Magnitude: 0.58618
Value Function Update Magnitude: 0.54013

Collected Steps per Second: 22,648.46610
Overall Steps per Second: 10,746.81445

Timestep Collection Time: 2.20871
Timestep Consumption Time: 2.44606
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.65477

Cumulative Model Updates: 123,594
Cumulative Timesteps: 1,030,828,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1030828496...
Checkpoint 1030828496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.86498
Policy Entropy: 3.03108
Value Function Loss: 0.00513

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.57525
Value Function Update Magnitude: 0.53044

Collected Steps per Second: 21,715.42762
Overall Steps per Second: 10,375.09718

Timestep Collection Time: 2.30362
Timestep Consumption Time: 2.51793
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.82155

Cumulative Model Updates: 123,600
Cumulative Timesteps: 1,030,878,520

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,661.59433
Policy Entropy: 3.03470
Value Function Loss: 0.00485

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10263
Policy Update Magnitude: 0.56830
Value Function Update Magnitude: 0.52115

Collected Steps per Second: 22,565.42421
Overall Steps per Second: 10,749.55615

Timestep Collection Time: 2.21605
Timestep Consumption Time: 2.43587
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.65191

Cumulative Model Updates: 123,606
Cumulative Timesteps: 1,030,928,526

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1030928526...
Checkpoint 1030928526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,645.71947
Policy Entropy: 3.02425
Value Function Loss: 0.00483

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11240
Policy Update Magnitude: 0.56702
Value Function Update Magnitude: 0.50807

Collected Steps per Second: 21,454.69597
Overall Steps per Second: 10,337.53366

Timestep Collection Time: 2.33180
Timestep Consumption Time: 2.50765
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.83945

Cumulative Model Updates: 123,612
Cumulative Timesteps: 1,030,978,554

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.56909
Policy Entropy: 3.01551
Value Function Loss: 0.00473

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.56277
Value Function Update Magnitude: 0.51603

Collected Steps per Second: 22,191.15006
Overall Steps per Second: 10,576.92824

Timestep Collection Time: 2.25432
Timestep Consumption Time: 2.47541
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.72973

Cumulative Model Updates: 123,618
Cumulative Timesteps: 1,031,028,580

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1031028580...
Checkpoint 1031028580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 864.57596
Policy Entropy: 3.02864
Value Function Loss: 0.00497

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10392
Policy Update Magnitude: 0.57052
Value Function Update Magnitude: 0.54273

Collected Steps per Second: 21,794.23543
Overall Steps per Second: 10,458.88707

Timestep Collection Time: 2.29428
Timestep Consumption Time: 2.48654
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.78081

Cumulative Model Updates: 123,624
Cumulative Timesteps: 1,031,078,582

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,004.54577
Policy Entropy: 3.03037
Value Function Loss: 0.00504

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.58136
Value Function Update Magnitude: 0.56629

Collected Steps per Second: 21,703.53107
Overall Steps per Second: 10,519.96848

Timestep Collection Time: 2.30469
Timestep Consumption Time: 2.45007
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.75477

Cumulative Model Updates: 123,630
Cumulative Timesteps: 1,031,128,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1031128602...
Checkpoint 1031128602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317.41836
Policy Entropy: 3.02035
Value Function Loss: 0.00499

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.09814
Policy Update Magnitude: 0.57858
Value Function Update Magnitude: 0.54844

Collected Steps per Second: 21,594.19401
Overall Steps per Second: 10,566.61520

Timestep Collection Time: 2.31599
Timestep Consumption Time: 2.41703
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.73302

Cumulative Model Updates: 123,636
Cumulative Timesteps: 1,031,178,614

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.82030
Policy Entropy: 2.98862
Value Function Loss: 0.00507

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.09446
Policy Update Magnitude: 0.57906
Value Function Update Magnitude: 0.53911

Collected Steps per Second: 22,233.74919
Overall Steps per Second: 10,476.74926

Timestep Collection Time: 2.25018
Timestep Consumption Time: 2.52515
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.77534

Cumulative Model Updates: 123,642
Cumulative Timesteps: 1,031,228,644

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1031228644...
Checkpoint 1031228644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,875.82595
Policy Entropy: 2.98107
Value Function Loss: 0.00500

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.09829
Policy Update Magnitude: 0.58156
Value Function Update Magnitude: 0.54540

Collected Steps per Second: 22,100.13678
Overall Steps per Second: 10,406.44938

Timestep Collection Time: 2.26361
Timestep Consumption Time: 2.54361
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.80721

Cumulative Model Updates: 123,648
Cumulative Timesteps: 1,031,278,670

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,405.37640
Policy Entropy: 2.98427
Value Function Loss: 0.00507

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.11820
Policy Update Magnitude: 0.57649
Value Function Update Magnitude: 0.54116

Collected Steps per Second: 22,719.73318
Overall Steps per Second: 10,647.64863

Timestep Collection Time: 2.20082
Timestep Consumption Time: 2.49524
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.69606

Cumulative Model Updates: 123,654
Cumulative Timesteps: 1,031,328,672

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1031328672...
Checkpoint 1031328672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,662.67544
Policy Entropy: 2.99274
Value Function Loss: 0.00521

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.12590
Policy Update Magnitude: 0.57525
Value Function Update Magnitude: 0.54327

Collected Steps per Second: 21,668.37006
Overall Steps per Second: 10,588.53970

Timestep Collection Time: 2.30843
Timestep Consumption Time: 2.41554
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.72398

Cumulative Model Updates: 123,660
Cumulative Timesteps: 1,031,378,692

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,399.09907
Policy Entropy: 2.99784
Value Function Loss: 0.00512

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.12868
Policy Update Magnitude: 0.57896
Value Function Update Magnitude: 0.55062

Collected Steps per Second: 22,276.09187
Overall Steps per Second: 10,534.71837

Timestep Collection Time: 2.24501
Timestep Consumption Time: 2.50215
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.74716

Cumulative Model Updates: 123,666
Cumulative Timesteps: 1,031,428,702

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1031428702...
Checkpoint 1031428702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,850.62627
Policy Entropy: 3.00303
Value Function Loss: 0.00519

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11221
Policy Update Magnitude: 0.58147
Value Function Update Magnitude: 0.55121

Collected Steps per Second: 21,561.77186
Overall Steps per Second: 10,393.68590

Timestep Collection Time: 2.31910
Timestep Consumption Time: 2.49189
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.81100

Cumulative Model Updates: 123,672
Cumulative Timesteps: 1,031,478,706

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648.91714
Policy Entropy: 3.00632
Value Function Loss: 0.00501

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10592
Policy Update Magnitude: 0.58676
Value Function Update Magnitude: 0.54946

Collected Steps per Second: 22,854.33403
Overall Steps per Second: 10,735.07509

Timestep Collection Time: 2.18821
Timestep Consumption Time: 2.47035
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.65856

Cumulative Model Updates: 123,678
Cumulative Timesteps: 1,031,528,716

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1031528716...
Checkpoint 1031528716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660.85683
Policy Entropy: 3.01224
Value Function Loss: 0.00504

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10339
Policy Update Magnitude: 0.58544
Value Function Update Magnitude: 0.55521

Collected Steps per Second: 22,201.48986
Overall Steps per Second: 10,608.62798

Timestep Collection Time: 2.25273
Timestep Consumption Time: 2.46173
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.71446

Cumulative Model Updates: 123,684
Cumulative Timesteps: 1,031,578,730

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 979.99788
Policy Entropy: 3.00304
Value Function Loss: 0.00514

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09047
Policy Update Magnitude: 0.58686
Value Function Update Magnitude: 0.55122

Collected Steps per Second: 21,390.80337
Overall Steps per Second: 10,487.20949

Timestep Collection Time: 2.33829
Timestep Consumption Time: 2.43113
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.76943

Cumulative Model Updates: 123,690
Cumulative Timesteps: 1,031,628,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1031628748...
Checkpoint 1031628748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.65074
Policy Entropy: 3.00155
Value Function Loss: 0.00503

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.58435
Value Function Update Magnitude: 0.55476

Collected Steps per Second: 21,575.64693
Overall Steps per Second: 10,565.32361

Timestep Collection Time: 2.31789
Timestep Consumption Time: 2.41552
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.73341

Cumulative Model Updates: 123,696
Cumulative Timesteps: 1,031,678,758

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,506.00802
Policy Entropy: 2.99614
Value Function Loss: 0.00512

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.59053
Value Function Update Magnitude: 0.56313

Collected Steps per Second: 21,967.18500
Overall Steps per Second: 10,556.22970

Timestep Collection Time: 2.27731
Timestep Consumption Time: 2.46170
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.73900

Cumulative Model Updates: 123,702
Cumulative Timesteps: 1,031,728,784

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1031728784...
Checkpoint 1031728784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,528.14226
Policy Entropy: 2.99709
Value Function Loss: 0.00480

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09117
Policy Update Magnitude: 0.58112
Value Function Update Magnitude: 0.57082

Collected Steps per Second: 21,678.55288
Overall Steps per Second: 10,555.26755

Timestep Collection Time: 2.30753
Timestep Consumption Time: 2.43171
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.73925

Cumulative Model Updates: 123,708
Cumulative Timesteps: 1,031,778,808

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.44765
Policy Entropy: 2.99191
Value Function Loss: 0.00514

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.10154
Policy Update Magnitude: 0.58461
Value Function Update Magnitude: 0.57556

Collected Steps per Second: 22,322.25366
Overall Steps per Second: 10,507.72317

Timestep Collection Time: 2.24001
Timestep Consumption Time: 2.51859
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.75860

Cumulative Model Updates: 123,714
Cumulative Timesteps: 1,031,828,810

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1031828810...
Checkpoint 1031828810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243.06289
Policy Entropy: 2.98854
Value Function Loss: 0.00505

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11188
Policy Update Magnitude: 0.58932
Value Function Update Magnitude: 0.59498

Collected Steps per Second: 21,833.06602
Overall Steps per Second: 10,548.72234

Timestep Collection Time: 2.29065
Timestep Consumption Time: 2.45039
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.74105

Cumulative Model Updates: 123,720
Cumulative Timesteps: 1,031,878,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.51555
Policy Entropy: 2.99556
Value Function Loss: 0.00514

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10089
Policy Update Magnitude: 0.58037
Value Function Update Magnitude: 0.59679

Collected Steps per Second: 22,435.19880
Overall Steps per Second: 10,567.70880

Timestep Collection Time: 2.22918
Timestep Consumption Time: 2.50335
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.73253

Cumulative Model Updates: 123,726
Cumulative Timesteps: 1,031,928,834

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1031928834...
Checkpoint 1031928834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.15555
Policy Entropy: 2.97462
Value Function Loss: 0.00498

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10707
Policy Update Magnitude: 0.58009
Value Function Update Magnitude: 0.57435

Collected Steps per Second: 22,218.32822
Overall Steps per Second: 10,666.42960

Timestep Collection Time: 2.25075
Timestep Consumption Time: 2.43760
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.68835

Cumulative Model Updates: 123,732
Cumulative Timesteps: 1,031,978,842

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,945.56250
Policy Entropy: 2.99679
Value Function Loss: 0.00493

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.58607
Value Function Update Magnitude: 0.55655

Collected Steps per Second: 22,460.03032
Overall Steps per Second: 10,526.20147

Timestep Collection Time: 2.22680
Timestep Consumption Time: 2.52458
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.75138

Cumulative Model Updates: 123,738
Cumulative Timesteps: 1,032,028,856

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1032028856...
Checkpoint 1032028856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,750.20803
Policy Entropy: 2.99249
Value Function Loss: 0.00515

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.58730
Value Function Update Magnitude: 0.54169

Collected Steps per Second: 21,961.60740
Overall Steps per Second: 10,598.72567

Timestep Collection Time: 2.27779
Timestep Consumption Time: 2.44202
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.71981

Cumulative Model Updates: 123,744
Cumulative Timesteps: 1,032,078,880

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.86617
Policy Entropy: 3.00990
Value Function Loss: 0.00537

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.59099
Value Function Update Magnitude: 0.53856

Collected Steps per Second: 22,528.39794
Overall Steps per Second: 10,783.48387

Timestep Collection Time: 2.21951
Timestep Consumption Time: 2.41740
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.63691

Cumulative Model Updates: 123,750
Cumulative Timesteps: 1,032,128,882

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1032128882...
Checkpoint 1032128882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 925.68458
Policy Entropy: 3.01934
Value Function Loss: 0.00545

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.11438
Policy Update Magnitude: 0.59396
Value Function Update Magnitude: 0.55495

Collected Steps per Second: 21,617.20682
Overall Steps per Second: 10,460.55684

Timestep Collection Time: 2.31408
Timestep Consumption Time: 2.46807
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.78215

Cumulative Model Updates: 123,756
Cumulative Timesteps: 1,032,178,906

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 880.30117
Policy Entropy: 3.02482
Value Function Loss: 0.00541

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.11191
Policy Update Magnitude: 0.59477
Value Function Update Magnitude: 0.56418

Collected Steps per Second: 22,144.26034
Overall Steps per Second: 10,684.20271

Timestep Collection Time: 2.25882
Timestep Consumption Time: 2.42285
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.68168

Cumulative Model Updates: 123,762
Cumulative Timesteps: 1,032,228,926

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1032228926...
Checkpoint 1032228926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 850.23652
Policy Entropy: 3.02378
Value Function Loss: 0.00515

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.12130
Policy Update Magnitude: 0.59042
Value Function Update Magnitude: 0.56400

Collected Steps per Second: 21,663.83542
Overall Steps per Second: 10,399.25398

Timestep Collection Time: 2.30799
Timestep Consumption Time: 2.50004
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.80804

Cumulative Model Updates: 123,768
Cumulative Timesteps: 1,032,278,926

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,998.65605
Policy Entropy: 3.01756
Value Function Loss: 0.00491

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.12163
Policy Update Magnitude: 0.58156
Value Function Update Magnitude: 0.54400

Collected Steps per Second: 22,115.12250
Overall Steps per Second: 10,470.80511

Timestep Collection Time: 2.26225
Timestep Consumption Time: 2.51579
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.77805

Cumulative Model Updates: 123,774
Cumulative Timesteps: 1,032,328,956

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1032328956...
Checkpoint 1032328956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.53300
Policy Entropy: 3.01669
Value Function Loss: 0.00478

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.11043
Policy Update Magnitude: 0.57708
Value Function Update Magnitude: 0.52988

Collected Steps per Second: 21,334.83134
Overall Steps per Second: 10,481.85612

Timestep Collection Time: 2.34480
Timestep Consumption Time: 2.42782
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.77263

Cumulative Model Updates: 123,780
Cumulative Timesteps: 1,032,378,982

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.62061
Policy Entropy: 3.00893
Value Function Loss: 0.00502

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.10480
Policy Update Magnitude: 0.57552
Value Function Update Magnitude: 0.54204

Collected Steps per Second: 22,424.16576
Overall Steps per Second: 10,528.34614

Timestep Collection Time: 2.23018
Timestep Consumption Time: 2.51985
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.75003

Cumulative Model Updates: 123,786
Cumulative Timesteps: 1,032,428,992

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1032428992...
Checkpoint 1032428992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650.02419
Policy Entropy: 2.98836
Value Function Loss: 0.00495

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.10325
Policy Update Magnitude: 0.57931
Value Function Update Magnitude: 0.53682

Collected Steps per Second: 20,744.06618
Overall Steps per Second: 10,100.70765

Timestep Collection Time: 2.41158
Timestep Consumption Time: 2.54114
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.95272

Cumulative Model Updates: 123,792
Cumulative Timesteps: 1,032,479,018

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 765.79200
Policy Entropy: 2.98920
Value Function Loss: 0.00502

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.57807
Value Function Update Magnitude: 0.51744

Collected Steps per Second: 22,059.54516
Overall Steps per Second: 10,464.80608

Timestep Collection Time: 2.26714
Timestep Consumption Time: 2.51193
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.77907

Cumulative Model Updates: 123,798
Cumulative Timesteps: 1,032,529,030

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1032529030...
Checkpoint 1032529030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,895.85245
Policy Entropy: 2.98352
Value Function Loss: 0.00493

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09666
Policy Update Magnitude: 0.58328
Value Function Update Magnitude: 0.50352

Collected Steps per Second: 21,650.48710
Overall Steps per Second: 10,387.51081

Timestep Collection Time: 2.31006
Timestep Consumption Time: 2.50476
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.81482

Cumulative Model Updates: 123,804
Cumulative Timesteps: 1,032,579,044

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,829.29750
Policy Entropy: 2.99310
Value Function Loss: 0.00495

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10158
Policy Update Magnitude: 0.58302
Value Function Update Magnitude: 0.50620

Collected Steps per Second: 22,214.96191
Overall Steps per Second: 10,618.93529

Timestep Collection Time: 2.25182
Timestep Consumption Time: 2.45901
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.71083

Cumulative Model Updates: 123,810
Cumulative Timesteps: 1,032,629,068

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1032629068...
Checkpoint 1032629068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,371.77636
Policy Entropy: 2.99658
Value Function Loss: 0.00510

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.11169
Policy Update Magnitude: 0.58015
Value Function Update Magnitude: 0.50243

Collected Steps per Second: 22,008.02215
Overall Steps per Second: 10,312.79180

Timestep Collection Time: 2.27281
Timestep Consumption Time: 2.57748
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.85029

Cumulative Model Updates: 123,816
Cumulative Timesteps: 1,032,679,088

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,912.45462
Policy Entropy: 3.01299
Value Function Loss: 0.00493

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.10342
Policy Update Magnitude: 0.58164
Value Function Update Magnitude: 0.50633

Collected Steps per Second: 22,468.56557
Overall Steps per Second: 10,594.60601

Timestep Collection Time: 2.22667
Timestep Consumption Time: 2.49555
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.72221

Cumulative Model Updates: 123,822
Cumulative Timesteps: 1,032,729,118

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1032729118...
Checkpoint 1032729118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.65395
Policy Entropy: 3.01757
Value Function Loss: 0.00525

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.09585
Policy Update Magnitude: 0.57823
Value Function Update Magnitude: 0.51187

Collected Steps per Second: 22,191.20982
Overall Steps per Second: 10,565.81864

Timestep Collection Time: 2.25387
Timestep Consumption Time: 2.47989
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.73376

Cumulative Model Updates: 123,828
Cumulative Timesteps: 1,032,779,134

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 808.57441
Policy Entropy: 3.01384
Value Function Loss: 0.00532

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.08951
Policy Update Magnitude: 0.57941
Value Function Update Magnitude: 0.51450

Collected Steps per Second: 22,340.61503
Overall Steps per Second: 10,588.10436

Timestep Collection Time: 2.23826
Timestep Consumption Time: 2.48440
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.72266

Cumulative Model Updates: 123,834
Cumulative Timesteps: 1,032,829,138

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1032829138...
Checkpoint 1032829138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.95485
Policy Entropy: 3.00137
Value Function Loss: 0.00552

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.10702
Policy Update Magnitude: 0.58192
Value Function Update Magnitude: 0.52565

Collected Steps per Second: 21,572.33358
Overall Steps per Second: 10,425.25962

Timestep Collection Time: 2.31815
Timestep Consumption Time: 2.47866
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.79681

Cumulative Model Updates: 123,840
Cumulative Timesteps: 1,032,879,146

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.30225
Policy Entropy: 3.01434
Value Function Loss: 0.00533

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.12461
Policy Update Magnitude: 0.58111
Value Function Update Magnitude: 0.52260

Collected Steps per Second: 22,454.62200
Overall Steps per Second: 10,527.97688

Timestep Collection Time: 2.22716
Timestep Consumption Time: 2.52304
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.75020

Cumulative Model Updates: 123,846
Cumulative Timesteps: 1,032,929,156

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1032929156...
Checkpoint 1032929156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.38179
Policy Entropy: 3.02557
Value Function Loss: 0.00510

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.12031
Policy Update Magnitude: 0.57552
Value Function Update Magnitude: 0.52939

Collected Steps per Second: 21,983.98139
Overall Steps per Second: 10,615.22033

Timestep Collection Time: 2.27620
Timestep Consumption Time: 2.43778
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.71399

Cumulative Model Updates: 123,852
Cumulative Timesteps: 1,032,979,196

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.09222
Policy Entropy: 3.03047
Value Function Loss: 0.00520

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.13370
Policy Update Magnitude: 0.57015
Value Function Update Magnitude: 0.53298

Collected Steps per Second: 22,266.33913
Overall Steps per Second: 10,474.60531

Timestep Collection Time: 2.24590
Timestep Consumption Time: 2.52831
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.77421

Cumulative Model Updates: 123,858
Cumulative Timesteps: 1,033,029,204

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1033029204...
Checkpoint 1033029204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,685.96431
Policy Entropy: 3.02059
Value Function Loss: 0.00550

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.13324
Policy Update Magnitude: 0.57898
Value Function Update Magnitude: 0.53757

Collected Steps per Second: 21,554.46216
Overall Steps per Second: 10,531.79567

Timestep Collection Time: 2.32045
Timestep Consumption Time: 2.42860
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.74905

Cumulative Model Updates: 123,864
Cumulative Timesteps: 1,033,079,220

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,986.03731
Policy Entropy: 3.01008
Value Function Loss: 0.00538

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.13883
Policy Update Magnitude: 0.58656
Value Function Update Magnitude: 0.54989

Collected Steps per Second: 22,009.42261
Overall Steps per Second: 10,509.63116

Timestep Collection Time: 2.27230
Timestep Consumption Time: 2.48638
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.75868

Cumulative Model Updates: 123,870
Cumulative Timesteps: 1,033,129,232

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1033129232...
Checkpoint 1033129232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.49557
Policy Entropy: 3.01099
Value Function Loss: 0.00501

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.57772
Value Function Update Magnitude: 0.52862

Collected Steps per Second: 21,609.23540
Overall Steps per Second: 10,391.15998

Timestep Collection Time: 2.31521
Timestep Consumption Time: 2.49946
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.81467

Cumulative Model Updates: 123,876
Cumulative Timesteps: 1,033,179,262

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,019.26078
Policy Entropy: 3.02457
Value Function Loss: 0.00480

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.11738
Policy Update Magnitude: 0.55909
Value Function Update Magnitude: 0.51398

Collected Steps per Second: 21,885.13107
Overall Steps per Second: 10,438.36194

Timestep Collection Time: 2.28520
Timestep Consumption Time: 2.50597
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.79117

Cumulative Model Updates: 123,882
Cumulative Timesteps: 1,033,229,274

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1033229274...
Checkpoint 1033229274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 922.73465
Policy Entropy: 3.02947
Value Function Loss: 0.00484

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09784
Policy Update Magnitude: 0.56311
Value Function Update Magnitude: 0.51961

Collected Steps per Second: 21,856.71715
Overall Steps per Second: 10,567.71699

Timestep Collection Time: 2.28845
Timestep Consumption Time: 2.44464
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.73309

Cumulative Model Updates: 123,888
Cumulative Timesteps: 1,033,279,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,850.26122
Policy Entropy: 3.01973
Value Function Loss: 0.00530

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09757
Policy Update Magnitude: 0.57371
Value Function Update Magnitude: 0.52835

Collected Steps per Second: 22,534.65121
Overall Steps per Second: 10,605.57390

Timestep Collection Time: 2.21907
Timestep Consumption Time: 2.49600
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.71507

Cumulative Model Updates: 123,894
Cumulative Timesteps: 1,033,329,298

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1033329298...
Checkpoint 1033329298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.81425
Policy Entropy: 3.00563
Value Function Loss: 0.00536

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.58249
Value Function Update Magnitude: 0.52489

Collected Steps per Second: 21,978.14271
Overall Steps per Second: 10,652.13086

Timestep Collection Time: 2.27544
Timestep Consumption Time: 2.41939
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.69484

Cumulative Model Updates: 123,900
Cumulative Timesteps: 1,033,379,308

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,270.76490
Policy Entropy: 3.00961
Value Function Loss: 0.00527

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09258
Policy Update Magnitude: 0.57559
Value Function Update Magnitude: 0.51696

Collected Steps per Second: 22,214.91628
Overall Steps per Second: 10,456.02506

Timestep Collection Time: 2.25083
Timestep Consumption Time: 2.53129
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.78212

Cumulative Model Updates: 123,906
Cumulative Timesteps: 1,033,429,310

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1033429310...
Checkpoint 1033429310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.36947
Policy Entropy: 3.01810
Value Function Loss: 0.00525

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10439
Policy Update Magnitude: 0.57997
Value Function Update Magnitude: 0.51605

Collected Steps per Second: 22,250.42092
Overall Steps per Second: 10,562.11335

Timestep Collection Time: 2.24715
Timestep Consumption Time: 2.48675
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.73390

Cumulative Model Updates: 123,912
Cumulative Timesteps: 1,033,479,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,941.68701
Policy Entropy: 3.01321
Value Function Loss: 0.00527

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.58286
Value Function Update Magnitude: 0.52031

Collected Steps per Second: 22,445.21677
Overall Steps per Second: 10,568.12926

Timestep Collection Time: 2.22889
Timestep Consumption Time: 2.50496
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.73386

Cumulative Model Updates: 123,918
Cumulative Timesteps: 1,033,529,338

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1033529338...
Checkpoint 1033529338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,276.53504
Policy Entropy: 3.00921
Value Function Loss: 0.00517

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.57961
Value Function Update Magnitude: 0.51752

Collected Steps per Second: 22,322.54769
Overall Steps per Second: 10,566.28772

Timestep Collection Time: 2.23989
Timestep Consumption Time: 2.49214
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.73203

Cumulative Model Updates: 123,924
Cumulative Timesteps: 1,033,579,338

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,862.33665
Policy Entropy: 3.00447
Value Function Loss: 0.00503

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.09919
Policy Update Magnitude: 0.57717
Value Function Update Magnitude: 0.51172

Collected Steps per Second: 22,248.22470
Overall Steps per Second: 10,467.35976

Timestep Collection Time: 2.24782
Timestep Consumption Time: 2.52989
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.77771

Cumulative Model Updates: 123,930
Cumulative Timesteps: 1,033,629,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1033629348...
Checkpoint 1033629348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 852.73638
Policy Entropy: 3.01307
Value Function Loss: 0.00517

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10276
Policy Update Magnitude: 0.58148
Value Function Update Magnitude: 0.52844

Collected Steps per Second: 22,094.47945
Overall Steps per Second: 10,561.74012

Timestep Collection Time: 2.26419
Timestep Consumption Time: 2.47234
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.73653

Cumulative Model Updates: 123,936
Cumulative Timesteps: 1,033,679,374

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558.07826
Policy Entropy: 3.02053
Value Function Loss: 0.00515

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.10729
Policy Update Magnitude: 0.57776
Value Function Update Magnitude: 0.54358

Collected Steps per Second: 21,830.83647
Overall Steps per Second: 10,539.14027

Timestep Collection Time: 2.29061
Timestep Consumption Time: 2.45418
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.74479

Cumulative Model Updates: 123,942
Cumulative Timesteps: 1,033,729,380

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1033729380...
Checkpoint 1033729380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,614.88536
Policy Entropy: 3.01144
Value Function Loss: 0.00511

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11051
Policy Update Magnitude: 0.57375
Value Function Update Magnitude: 0.53061

Collected Steps per Second: 21,859.51280
Overall Steps per Second: 10,639.15784

Timestep Collection Time: 2.28852
Timestep Consumption Time: 2.41354
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.70206

Cumulative Model Updates: 123,948
Cumulative Timesteps: 1,033,779,406

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384.92782
Policy Entropy: 2.99475
Value Function Loss: 0.00531

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12008
Policy Update Magnitude: 0.57550
Value Function Update Magnitude: 0.51456

Collected Steps per Second: 21,691.07824
Overall Steps per Second: 10,419.37201

Timestep Collection Time: 2.30546
Timestep Consumption Time: 2.49406
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.79952

Cumulative Model Updates: 123,954
Cumulative Timesteps: 1,033,829,414

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1033829414...
Checkpoint 1033829414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.99307
Policy Entropy: 2.97398
Value Function Loss: 0.00569

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.12786
Policy Update Magnitude: 0.59061
Value Function Update Magnitude: 0.52579

Collected Steps per Second: 21,803.92734
Overall Steps per Second: 10,559.59811

Timestep Collection Time: 2.29399
Timestep Consumption Time: 2.44274
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.73673

Cumulative Model Updates: 123,960
Cumulative Timesteps: 1,033,879,432

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,776.78238
Policy Entropy: 2.99305
Value Function Loss: 0.00527

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.58690
Value Function Update Magnitude: 0.54586

Collected Steps per Second: 21,789.28821
Overall Steps per Second: 10,507.10922

Timestep Collection Time: 2.29489
Timestep Consumption Time: 2.46417
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.75906

Cumulative Model Updates: 123,966
Cumulative Timesteps: 1,033,929,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1033929436...
Checkpoint 1033929436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.42738
Policy Entropy: 3.00070
Value Function Loss: 0.00511

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11044
Policy Update Magnitude: 0.58350
Value Function Update Magnitude: 0.54690

Collected Steps per Second: 22,170.09813
Overall Steps per Second: 10,589.20337

Timestep Collection Time: 2.25628
Timestep Consumption Time: 2.46759
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.72387

Cumulative Model Updates: 123,972
Cumulative Timesteps: 1,033,979,458

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.14529
Policy Entropy: 3.00931
Value Function Loss: 0.00484

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.09787
Policy Update Magnitude: 0.57484
Value Function Update Magnitude: 0.55064

Collected Steps per Second: 22,077.27824
Overall Steps per Second: 10,582.81568

Timestep Collection Time: 2.26504
Timestep Consumption Time: 2.46016
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.72521

Cumulative Model Updates: 123,978
Cumulative Timesteps: 1,034,029,464

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1034029464...
Checkpoint 1034029464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.63139
Policy Entropy: 3.00675
Value Function Loss: 0.00491

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.57342
Value Function Update Magnitude: 0.53762

Collected Steps per Second: 22,103.88827
Overall Steps per Second: 10,600.24603

Timestep Collection Time: 2.26331
Timestep Consumption Time: 2.45620
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.71951

Cumulative Model Updates: 123,984
Cumulative Timesteps: 1,034,079,492

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,282.28805
Policy Entropy: 3.00237
Value Function Loss: 0.00513

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09278
Policy Update Magnitude: 0.57641
Value Function Update Magnitude: 0.53646

Collected Steps per Second: 22,331.92647
Overall Steps per Second: 10,490.17938

Timestep Collection Time: 2.23939
Timestep Consumption Time: 2.52792
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.76732

Cumulative Model Updates: 123,990
Cumulative Timesteps: 1,034,129,502

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1034129502...
Checkpoint 1034129502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,596.82575
Policy Entropy: 2.99420
Value Function Loss: 0.00511

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10406
Policy Update Magnitude: 0.57958
Value Function Update Magnitude: 0.56129

Collected Steps per Second: 22,214.89621
Overall Steps per Second: 10,668.86648

Timestep Collection Time: 2.25164
Timestep Consumption Time: 2.43677
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.68841

Cumulative Model Updates: 123,996
Cumulative Timesteps: 1,034,179,522

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,818.98233
Policy Entropy: 3.00266
Value Function Loss: 0.00517

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.10755
Policy Update Magnitude: 0.57898
Value Function Update Magnitude: 0.57904

Collected Steps per Second: 22,300.97141
Overall Steps per Second: 10,579.07911

Timestep Collection Time: 2.24205
Timestep Consumption Time: 2.48425
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.72631

Cumulative Model Updates: 124,002
Cumulative Timesteps: 1,034,229,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1034229522...
Checkpoint 1034229522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.02700
Policy Entropy: 3.00387
Value Function Loss: 0.00523

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.10605
Policy Update Magnitude: 0.58011
Value Function Update Magnitude: 0.56738

Collected Steps per Second: 22,227.94814
Overall Steps per Second: 10,480.63698

Timestep Collection Time: 2.24942
Timestep Consumption Time: 2.52128
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.77070

Cumulative Model Updates: 124,008
Cumulative Timesteps: 1,034,279,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,674.96754
Policy Entropy: 3.01221
Value Function Loss: 0.00514

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.57709
Value Function Update Magnitude: 0.54505

Collected Steps per Second: 21,504.97495
Overall Steps per Second: 10,419.42325

Timestep Collection Time: 2.32523
Timestep Consumption Time: 2.47388
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.79911

Cumulative Model Updates: 124,014
Cumulative Timesteps: 1,034,329,526

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1034329526...
Checkpoint 1034329526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.30479
Policy Entropy: 3.00706
Value Function Loss: 0.00486

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.11802
Policy Update Magnitude: 0.56607
Value Function Update Magnitude: 0.54014

Collected Steps per Second: 21,154.19057
Overall Steps per Second: 10,302.91285

Timestep Collection Time: 2.36407
Timestep Consumption Time: 2.48990
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.85397

Cumulative Model Updates: 124,020
Cumulative Timesteps: 1,034,379,536

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,773.81606
Policy Entropy: 3.01300
Value Function Loss: 0.00493

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.12425
Policy Update Magnitude: 0.56025
Value Function Update Magnitude: 0.52928

Collected Steps per Second: 22,128.06124
Overall Steps per Second: 10,469.54204

Timestep Collection Time: 2.25994
Timestep Consumption Time: 2.51659
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.77652

Cumulative Model Updates: 124,026
Cumulative Timesteps: 1,034,429,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1034429544...
Checkpoint 1034429544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,779.33753
Policy Entropy: 3.01110
Value Function Loss: 0.00506

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.55881
Value Function Update Magnitude: 0.53119

Collected Steps per Second: 21,851.68068
Overall Steps per Second: 10,513.39413

Timestep Collection Time: 2.28879
Timestep Consumption Time: 2.46838
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 4.75717

Cumulative Model Updates: 124,032
Cumulative Timesteps: 1,034,479,558

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,741.21823
Policy Entropy: 3.01760
Value Function Loss: 0.00511

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.12299
Policy Update Magnitude: 0.56063
Value Function Update Magnitude: 0.51671

Collected Steps per Second: 22,173.50745
Overall Steps per Second: 10,471.55174

Timestep Collection Time: 2.25521
Timestep Consumption Time: 2.52020
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.77541

Cumulative Model Updates: 124,038
Cumulative Timesteps: 1,034,529,564

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1034529564...
Checkpoint 1034529564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,452.58609
Policy Entropy: 3.02630
Value Function Loss: 0.00476

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.12129
Policy Update Magnitude: 0.55503
Value Function Update Magnitude: 0.50147

Collected Steps per Second: 21,876.89772
Overall Steps per Second: 10,564.89364

Timestep Collection Time: 2.28680
Timestep Consumption Time: 2.44851
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.73531

Cumulative Model Updates: 124,044
Cumulative Timesteps: 1,034,579,592

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,676.58969
Policy Entropy: 3.01438
Value Function Loss: 0.00501

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11238
Policy Update Magnitude: 0.56132
Value Function Update Magnitude: 0.51496

Collected Steps per Second: 22,119.91923
Overall Steps per Second: 10,516.17285

Timestep Collection Time: 2.26050
Timestep Consumption Time: 2.49428
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.75477

Cumulative Model Updates: 124,050
Cumulative Timesteps: 1,034,629,594

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1034629594...
Checkpoint 1034629594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.12450
Policy Entropy: 3.01957
Value Function Loss: 0.00517

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.10675
Policy Update Magnitude: 0.56881
Value Function Update Magnitude: 0.53613

Collected Steps per Second: 21,949.52583
Overall Steps per Second: 10,621.70077

Timestep Collection Time: 2.27877
Timestep Consumption Time: 2.43027
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.70904

Cumulative Model Updates: 124,056
Cumulative Timesteps: 1,034,679,612

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 769.25420
Policy Entropy: 3.00220
Value Function Loss: 0.00557

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.58369
Value Function Update Magnitude: 0.55224

Collected Steps per Second: 22,367.33801
Overall Steps per Second: 10,576.94903

Timestep Collection Time: 2.23567
Timestep Consumption Time: 2.49216
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.72783

Cumulative Model Updates: 124,062
Cumulative Timesteps: 1,034,729,618

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1034729618...
Checkpoint 1034729618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.18791
Policy Entropy: 3.00724
Value Function Loss: 0.00540

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.09694
Policy Update Magnitude: 0.58491
Value Function Update Magnitude: 0.56796

Collected Steps per Second: 21,744.16699
Overall Steps per Second: 10,614.84986

Timestep Collection Time: 2.30057
Timestep Consumption Time: 2.41207
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.71264

Cumulative Model Updates: 124,068
Cumulative Timesteps: 1,034,779,642

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.71359
Policy Entropy: 2.99391
Value Function Loss: 0.00493

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.10283
Policy Update Magnitude: 0.57649
Value Function Update Magnitude: 0.56889

Collected Steps per Second: 22,048.20129
Overall Steps per Second: 10,377.01344

Timestep Collection Time: 2.26876
Timestep Consumption Time: 2.55171
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.82046

Cumulative Model Updates: 124,074
Cumulative Timesteps: 1,034,829,664

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1034829664...
Checkpoint 1034829664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,099.42640
Policy Entropy: 3.01413
Value Function Loss: 0.00466

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09347
Policy Update Magnitude: 0.56699
Value Function Update Magnitude: 0.53804

Collected Steps per Second: 21,673.37041
Overall Steps per Second: 10,396.61586

Timestep Collection Time: 2.30707
Timestep Consumption Time: 2.50238
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.80945

Cumulative Model Updates: 124,080
Cumulative Timesteps: 1,034,879,666

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.74700
Policy Entropy: 3.00944
Value Function Loss: 0.00510

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.57254
Value Function Update Magnitude: 0.51578

Collected Steps per Second: 22,641.31172
Overall Steps per Second: 10,757.30434

Timestep Collection Time: 2.21012
Timestep Consumption Time: 2.44160
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.65172

Cumulative Model Updates: 124,086
Cumulative Timesteps: 1,034,929,706

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1034929706...
Checkpoint 1034929706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,461.69873
Policy Entropy: 3.00778
Value Function Loss: 0.00534

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.58149
Value Function Update Magnitude: 0.52374

Collected Steps per Second: 21,547.53647
Overall Steps per Second: 10,511.91836

Timestep Collection Time: 2.32054
Timestep Consumption Time: 2.43615
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.75670

Cumulative Model Updates: 124,092
Cumulative Timesteps: 1,034,979,708

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.54990
Policy Entropy: 3.00016
Value Function Loss: 0.00529

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.09919
Policy Update Magnitude: 0.57610
Value Function Update Magnitude: 0.52615

Collected Steps per Second: 22,022.95933
Overall Steps per Second: 10,596.06735

Timestep Collection Time: 2.27090
Timestep Consumption Time: 2.44896
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.71986

Cumulative Model Updates: 124,098
Cumulative Timesteps: 1,035,029,720

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1035029720...
Checkpoint 1035029720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,979.76476
Policy Entropy: 2.99674
Value Function Loss: 0.00512

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.10370
Policy Update Magnitude: 0.57459
Value Function Update Magnitude: 0.52427

Collected Steps per Second: 21,540.78329
Overall Steps per Second: 10,517.91022

Timestep Collection Time: 2.32146
Timestep Consumption Time: 2.43291
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.75437

Cumulative Model Updates: 124,104
Cumulative Timesteps: 1,035,079,726

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,911.96567
Policy Entropy: 3.01032
Value Function Loss: 0.00500

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11270
Policy Update Magnitude: 0.57816
Value Function Update Magnitude: 0.52155

Collected Steps per Second: 22,086.62434
Overall Steps per Second: 10,498.70089

Timestep Collection Time: 2.26472
Timestep Consumption Time: 2.49968
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.76440

Cumulative Model Updates: 124,110
Cumulative Timesteps: 1,035,129,746

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1035129746...
Checkpoint 1035129746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,405.10270
Policy Entropy: 2.99733
Value Function Loss: 0.00503

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11230
Policy Update Magnitude: 0.57090
Value Function Update Magnitude: 0.51414

Collected Steps per Second: 21,532.00027
Overall Steps per Second: 10,288.37562

Timestep Collection Time: 2.32324
Timestep Consumption Time: 2.53895
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.86219

Cumulative Model Updates: 124,116
Cumulative Timesteps: 1,035,179,770

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,488.95010
Policy Entropy: 3.01482
Value Function Loss: 0.00508

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09199
Policy Update Magnitude: 0.57231
Value Function Update Magnitude: 0.50547

Collected Steps per Second: 22,532.84640
Overall Steps per Second: 10,535.54056

Timestep Collection Time: 2.21934
Timestep Consumption Time: 2.52726
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.74660

Cumulative Model Updates: 124,122
Cumulative Timesteps: 1,035,229,778

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1035229778...
Checkpoint 1035229778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 764.42475
Policy Entropy: 3.00285
Value Function Loss: 0.00521

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10160
Policy Update Magnitude: 0.57349
Value Function Update Magnitude: 0.51039

Collected Steps per Second: 22,054.12392
Overall Steps per Second: 10,502.75716

Timestep Collection Time: 2.26896
Timestep Consumption Time: 2.49550
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.76446

Cumulative Model Updates: 124,128
Cumulative Timesteps: 1,035,279,818

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,693.53215
Policy Entropy: 3.00212
Value Function Loss: 0.00524

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.10804
Policy Update Magnitude: 0.56949
Value Function Update Magnitude: 0.51354

Collected Steps per Second: 22,512.34776
Overall Steps per Second: 10,624.06865

Timestep Collection Time: 2.22154
Timestep Consumption Time: 2.48589
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.70742

Cumulative Model Updates: 124,134
Cumulative Timesteps: 1,035,329,830

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1035329830...
Checkpoint 1035329830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.17276
Policy Entropy: 2.98462
Value Function Loss: 0.00523

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.11452
Policy Update Magnitude: 0.57373
Value Function Update Magnitude: 0.51763

Collected Steps per Second: 22,018.79767
Overall Steps per Second: 10,436.40875

Timestep Collection Time: 2.27188
Timestep Consumption Time: 2.52134
PPO Batch Consumption Time: 0.29641
Total Iteration Time: 4.79322

Cumulative Model Updates: 124,140
Cumulative Timesteps: 1,035,379,854

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,942.81519
Policy Entropy: 2.98055
Value Function Loss: 0.00508

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11338
Policy Update Magnitude: 0.57866
Value Function Update Magnitude: 0.53096

Collected Steps per Second: 22,529.98912
Overall Steps per Second: 10,655.19046

Timestep Collection Time: 2.21980
Timestep Consumption Time: 2.47388
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.69367

Cumulative Model Updates: 124,146
Cumulative Timesteps: 1,035,429,866

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1035429866...
Checkpoint 1035429866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,505.47160
Policy Entropy: 2.98820
Value Function Loss: 0.00491

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10223
Policy Update Magnitude: 0.57447
Value Function Update Magnitude: 0.52767

Collected Steps per Second: 21,823.25952
Overall Steps per Second: 10,431.16946

Timestep Collection Time: 2.29223
Timestep Consumption Time: 2.50339
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.79563

Cumulative Model Updates: 124,152
Cumulative Timesteps: 1,035,479,890

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,784.71278
Policy Entropy: 2.97865
Value Function Loss: 0.00503

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.09433
Policy Update Magnitude: 0.57364
Value Function Update Magnitude: 0.51196

Collected Steps per Second: 22,501.83410
Overall Steps per Second: 10,606.90950

Timestep Collection Time: 2.22249
Timestep Consumption Time: 2.49237
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.71485

Cumulative Model Updates: 124,158
Cumulative Timesteps: 1,035,529,900

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1035529900...
Checkpoint 1035529900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,582.71381
Policy Entropy: 2.99193
Value Function Loss: 0.00504

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10084
Policy Update Magnitude: 0.57235
Value Function Update Magnitude: 0.50963

Collected Steps per Second: 21,472.17638
Overall Steps per Second: 10,480.37724

Timestep Collection Time: 2.32906
Timestep Consumption Time: 2.44271
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.77177

Cumulative Model Updates: 124,164
Cumulative Timesteps: 1,035,579,910

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,537.66258
Policy Entropy: 2.98299
Value Function Loss: 0.00508

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09627
Policy Update Magnitude: 0.57790
Value Function Update Magnitude: 0.51723

Collected Steps per Second: 22,000.61513
Overall Steps per Second: 10,504.96737

Timestep Collection Time: 2.27366
Timestep Consumption Time: 2.48808
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.76175

Cumulative Model Updates: 124,170
Cumulative Timesteps: 1,035,629,932

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1035629932...
Checkpoint 1035629932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,148.20351
Policy Entropy: 2.99356
Value Function Loss: 0.00510

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.10576
Policy Update Magnitude: 0.58632
Value Function Update Magnitude: 0.53060

Collected Steps per Second: 21,630.83451
Overall Steps per Second: 10,367.76015

Timestep Collection Time: 2.31262
Timestep Consumption Time: 2.51233
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.82496

Cumulative Model Updates: 124,176
Cumulative Timesteps: 1,035,679,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,479.11610
Policy Entropy: 2.99543
Value Function Loss: 0.00496

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.09907
Policy Update Magnitude: 0.58601
Value Function Update Magnitude: 0.53388

Collected Steps per Second: 22,048.49708
Overall Steps per Second: 10,467.25861

Timestep Collection Time: 2.26809
Timestep Consumption Time: 2.50947
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.77756

Cumulative Model Updates: 124,182
Cumulative Timesteps: 1,035,729,964

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1035729964...
Checkpoint 1035729964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 941.87224
Policy Entropy: 2.99317
Value Function Loss: 0.00514

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.11235
Policy Update Magnitude: 0.58241
Value Function Update Magnitude: 0.53322

Collected Steps per Second: 21,732.38206
Overall Steps per Second: 10,565.35977

Timestep Collection Time: 2.30136
Timestep Consumption Time: 2.43241
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.73377

Cumulative Model Updates: 124,188
Cumulative Timesteps: 1,035,779,978

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,516.58740
Policy Entropy: 2.98794
Value Function Loss: 0.00535

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.10133
Policy Update Magnitude: 0.58264
Value Function Update Magnitude: 0.53277

Collected Steps per Second: 21,880.41947
Overall Steps per Second: 10,372.11803

Timestep Collection Time: 2.28597
Timestep Consumption Time: 2.53638
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.82235

Cumulative Model Updates: 124,194
Cumulative Timesteps: 1,035,829,996

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1035829996...
Checkpoint 1035829996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.36960
Policy Entropy: 2.98119
Value Function Loss: 0.00560

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10092
Policy Update Magnitude: 0.58351
Value Function Update Magnitude: 0.53623

Collected Steps per Second: 22,046.13637
Overall Steps per Second: 10,578.02179

Timestep Collection Time: 2.26897
Timestep Consumption Time: 2.45989
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.72886

Cumulative Model Updates: 124,200
Cumulative Timesteps: 1,035,880,018

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.12205
Policy Entropy: 2.98172
Value Function Loss: 0.00574

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.11529
Policy Update Magnitude: 0.58443
Value Function Update Magnitude: 0.54277

Collected Steps per Second: 22,533.57363
Overall Steps per Second: 10,516.69266

Timestep Collection Time: 2.21962
Timestep Consumption Time: 2.53625
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.75587

Cumulative Model Updates: 124,206
Cumulative Timesteps: 1,035,930,034

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1035930034...
Checkpoint 1035930034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.60726
Policy Entropy: 2.99485
Value Function Loss: 0.00535

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.12617
Policy Update Magnitude: 0.58193
Value Function Update Magnitude: 0.54442

Collected Steps per Second: 21,654.99276
Overall Steps per Second: 10,571.12228

Timestep Collection Time: 2.31014
Timestep Consumption Time: 2.42219
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.73233

Cumulative Model Updates: 124,212
Cumulative Timesteps: 1,035,980,060

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,011.17090
Policy Entropy: 3.00525
Value Function Loss: 0.00495

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.57376
Value Function Update Magnitude: 0.55184

Collected Steps per Second: 22,289.47047
Overall Steps per Second: 10,526.92180

Timestep Collection Time: 2.24366
Timestep Consumption Time: 2.50702
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.75068

Cumulative Model Updates: 124,218
Cumulative Timesteps: 1,036,030,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1036030070...
Checkpoint 1036030070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,344.47047
Policy Entropy: 3.00904
Value Function Loss: 0.00477

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.11679
Policy Update Magnitude: 0.56908
Value Function Update Magnitude: 0.55322

Collected Steps per Second: 22,002.24572
Overall Steps per Second: 10,557.48143

Timestep Collection Time: 2.27268
Timestep Consumption Time: 2.46368
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.73636

Cumulative Model Updates: 124,224
Cumulative Timesteps: 1,036,080,074

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,638.82350
Policy Entropy: 3.00609
Value Function Loss: 0.00457

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.11110
Policy Update Magnitude: 0.56947
Value Function Update Magnitude: 0.53832

Collected Steps per Second: 22,370.98653
Overall Steps per Second: 10,564.62728

Timestep Collection Time: 2.23638
Timestep Consumption Time: 2.49924
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.73561

Cumulative Model Updates: 124,230
Cumulative Timesteps: 1,036,130,104

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1036130104...
Checkpoint 1036130104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,799.00248
Policy Entropy: 3.00367
Value Function Loss: 0.00478

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.11419
Policy Update Magnitude: 0.56517
Value Function Update Magnitude: 0.51745

Collected Steps per Second: 22,122.89386
Overall Steps per Second: 10,606.38864

Timestep Collection Time: 2.26119
Timestep Consumption Time: 2.45522
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.71640

Cumulative Model Updates: 124,236
Cumulative Timesteps: 1,036,180,128

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.53574
Policy Entropy: 3.01173
Value Function Loss: 0.00497

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11039
Policy Update Magnitude: 0.56894
Value Function Update Magnitude: 0.52234

Collected Steps per Second: 20,878.05170
Overall Steps per Second: 10,037.35196

Timestep Collection Time: 2.39620
Timestep Consumption Time: 2.58798
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.98418

Cumulative Model Updates: 124,242
Cumulative Timesteps: 1,036,230,156

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1036230156...
Checkpoint 1036230156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,239.51903
Policy Entropy: 3.03006
Value Function Loss: 0.00501

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.10947
Policy Update Magnitude: 0.55906
Value Function Update Magnitude: 0.52796

Collected Steps per Second: 21,838.60723
Overall Steps per Second: 10,412.10903

Timestep Collection Time: 2.28998
Timestep Consumption Time: 2.51308
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.80306

Cumulative Model Updates: 124,248
Cumulative Timesteps: 1,036,280,166

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,497.64852
Policy Entropy: 3.01215
Value Function Loss: 0.00525

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.10890
Policy Update Magnitude: 0.55758
Value Function Update Magnitude: 0.54450

Collected Steps per Second: 22,094.04847
Overall Steps per Second: 10,656.56521

Timestep Collection Time: 2.26396
Timestep Consumption Time: 2.42986
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.69382

Cumulative Model Updates: 124,254
Cumulative Timesteps: 1,036,330,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1036330186...
Checkpoint 1036330186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.72830
Policy Entropy: 3.00282
Value Function Loss: 0.00503

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11077
Policy Update Magnitude: 0.56872
Value Function Update Magnitude: 0.53806

Collected Steps per Second: 21,710.48331
Overall Steps per Second: 10,379.61197

Timestep Collection Time: 2.30405
Timestep Consumption Time: 2.51521
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.81926

Cumulative Model Updates: 124,260
Cumulative Timesteps: 1,036,380,208

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,536.94626
Policy Entropy: 3.01169
Value Function Loss: 0.00492

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.11319
Policy Update Magnitude: 0.57229
Value Function Update Magnitude: 0.52224

Collected Steps per Second: 22,755.99608
Overall Steps per Second: 10,716.12883

Timestep Collection Time: 2.19793
Timestep Consumption Time: 2.46943
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.66736

Cumulative Model Updates: 124,266
Cumulative Timesteps: 1,036,430,224

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1036430224...
Checkpoint 1036430224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,914.63883
Policy Entropy: 3.01557
Value Function Loss: 0.00493

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09678
Policy Update Magnitude: 0.55869
Value Function Update Magnitude: 0.51438

Collected Steps per Second: 22,016.14230
Overall Steps per Second: 10,581.51893

Timestep Collection Time: 2.27170
Timestep Consumption Time: 2.45485
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.72654

Cumulative Model Updates: 124,272
Cumulative Timesteps: 1,036,480,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,740.97109
Policy Entropy: 3.01920
Value Function Loss: 0.00478

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09223
Policy Update Magnitude: 0.55726
Value Function Update Magnitude: 0.49923

Collected Steps per Second: 22,261.98304
Overall Steps per Second: 10,547.81652

Timestep Collection Time: 2.24688
Timestep Consumption Time: 2.49533
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.74221

Cumulative Model Updates: 124,278
Cumulative Timesteps: 1,036,530,258

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1036530258...
Checkpoint 1036530258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,742.31494
Policy Entropy: 2.99247
Value Function Loss: 0.00497

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.10597
Policy Update Magnitude: 0.55428
Value Function Update Magnitude: 0.48826

Collected Steps per Second: 22,104.56184
Overall Steps per Second: 10,628.72437

Timestep Collection Time: 2.26252
Timestep Consumption Time: 2.44284
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.70536

Cumulative Model Updates: 124,284
Cumulative Timesteps: 1,036,580,270

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,123.30412
Policy Entropy: 3.00176
Value Function Loss: 0.00494

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11055
Policy Update Magnitude: 0.55896
Value Function Update Magnitude: 0.49211

Collected Steps per Second: 22,507.61609
Overall Steps per Second: 10,552.74011

Timestep Collection Time: 2.22227
Timestep Consumption Time: 2.51754
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.73981

Cumulative Model Updates: 124,290
Cumulative Timesteps: 1,036,630,288

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1036630288...
Checkpoint 1036630288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,775.69835
Policy Entropy: 3.00852
Value Function Loss: 0.00500

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10308
Policy Update Magnitude: 0.55801
Value Function Update Magnitude: 0.49106

Collected Steps per Second: 22,169.80714
Overall Steps per Second: 10,508.87952

Timestep Collection Time: 2.25550
Timestep Consumption Time: 2.50276
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.75826

Cumulative Model Updates: 124,296
Cumulative Timesteps: 1,036,680,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.57925
Policy Entropy: 3.02801
Value Function Loss: 0.00491

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09648
Policy Update Magnitude: 0.55207
Value Function Update Magnitude: 0.48930

Collected Steps per Second: 22,284.65534
Overall Steps per Second: 10,515.42046

Timestep Collection Time: 2.24397
Timestep Consumption Time: 2.51153
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.75549

Cumulative Model Updates: 124,302
Cumulative Timesteps: 1,036,730,298

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1036730298...
Checkpoint 1036730298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,320.03995
Policy Entropy: 3.03763
Value Function Loss: 0.00483

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09171
Policy Update Magnitude: 0.54902
Value Function Update Magnitude: 0.50171

Collected Steps per Second: 21,331.21580
Overall Steps per Second: 10,278.75639

Timestep Collection Time: 2.34436
Timestep Consumption Time: 2.52082
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.86518

Cumulative Model Updates: 124,308
Cumulative Timesteps: 1,036,780,306

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,496.41033
Policy Entropy: 3.03067
Value Function Loss: 0.00496

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09081
Policy Update Magnitude: 0.55687
Value Function Update Magnitude: 0.49175

Collected Steps per Second: 22,174.79585
Overall Steps per Second: 10,468.22913

Timestep Collection Time: 2.25589
Timestep Consumption Time: 2.52276
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.77865

Cumulative Model Updates: 124,314
Cumulative Timesteps: 1,036,830,330

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1036830330...
Checkpoint 1036830330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,429.09482
Policy Entropy: 3.01760
Value Function Loss: 0.00520

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.57226
Value Function Update Magnitude: 0.51922

Collected Steps per Second: 21,779.56799
Overall Steps per Second: 10,548.00251

Timestep Collection Time: 2.29683
Timestep Consumption Time: 2.44568
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.74251

Cumulative Model Updates: 124,320
Cumulative Timesteps: 1,036,880,354

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,658.13100
Policy Entropy: 3.01436
Value Function Loss: 0.00524

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.10979
Policy Update Magnitude: 0.57175
Value Function Update Magnitude: 0.52697

Collected Steps per Second: 21,996.49056
Overall Steps per Second: 10,474.14100

Timestep Collection Time: 2.27318
Timestep Consumption Time: 2.50067
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.77385

Cumulative Model Updates: 124,326
Cumulative Timesteps: 1,036,930,356

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1036930356...
Checkpoint 1036930356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,485.87854
Policy Entropy: 3.01073
Value Function Loss: 0.00507

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.10777
Policy Update Magnitude: 0.56931
Value Function Update Magnitude: 0.51779

Collected Steps per Second: 21,439.60211
Overall Steps per Second: 10,541.62493

Timestep Collection Time: 2.33297
Timestep Consumption Time: 2.41184
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.74481

Cumulative Model Updates: 124,332
Cumulative Timesteps: 1,036,980,374

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.50481
Policy Entropy: 3.02036
Value Function Loss: 0.00507

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.10903
Policy Update Magnitude: 0.57547
Value Function Update Magnitude: 0.51821

Collected Steps per Second: 22,376.50849
Overall Steps per Second: 10,529.12926

Timestep Collection Time: 2.23547
Timestep Consumption Time: 2.51535
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.75082

Cumulative Model Updates: 124,338
Cumulative Timesteps: 1,037,030,396

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1037030396...
Checkpoint 1037030396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,011.22388
Policy Entropy: 3.02037
Value Function Loss: 0.00519

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.10017
Policy Update Magnitude: 0.56523
Value Function Update Magnitude: 0.51990

Collected Steps per Second: 21,824.41265
Overall Steps per Second: 10,376.99347

Timestep Collection Time: 2.29101
Timestep Consumption Time: 2.52734
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.81835

Cumulative Model Updates: 124,344
Cumulative Timesteps: 1,037,080,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.44295
Policy Entropy: 3.03586
Value Function Loss: 0.00526

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.10876
Policy Update Magnitude: 0.58158
Value Function Update Magnitude: 0.53245

Collected Steps per Second: 22,743.10169
Overall Steps per Second: 10,744.38493

Timestep Collection Time: 2.19864
Timestep Consumption Time: 2.45532
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.65397

Cumulative Model Updates: 124,350
Cumulative Timesteps: 1,037,130,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1037130400...
Checkpoint 1037130400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,840.80492
Policy Entropy: 3.03357
Value Function Loss: 0.00514

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.10638
Policy Update Magnitude: 0.57800
Value Function Update Magnitude: 0.53355

Collected Steps per Second: 21,844.78402
Overall Steps per Second: 10,609.53377

Timestep Collection Time: 2.28952
Timestep Consumption Time: 2.42455
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.71406

Cumulative Model Updates: 124,356
Cumulative Timesteps: 1,037,180,414

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.56322
Policy Entropy: 3.04505
Value Function Loss: 0.00501

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.09973
Policy Update Magnitude: 0.57607
Value Function Update Magnitude: 0.51067

Collected Steps per Second: 22,514.82621
Overall Steps per Second: 10,508.75647

Timestep Collection Time: 2.22085
Timestep Consumption Time: 2.53728
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.75813

Cumulative Model Updates: 124,362
Cumulative Timesteps: 1,037,230,416

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1037230416...
Checkpoint 1037230416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485.52100
Policy Entropy: 3.02617
Value Function Loss: 0.00529

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09824
Policy Update Magnitude: 0.57270
Value Function Update Magnitude: 0.50929

Collected Steps per Second: 22,047.08250
Overall Steps per Second: 10,592.53342

Timestep Collection Time: 2.26869
Timestep Consumption Time: 2.45332
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.72201

Cumulative Model Updates: 124,368
Cumulative Timesteps: 1,037,280,434

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,621.46244
Policy Entropy: 3.00706
Value Function Loss: 0.00544

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.09471
Policy Update Magnitude: 0.57783
Value Function Update Magnitude: 0.51937

Collected Steps per Second: 22,483.77721
Overall Steps per Second: 10,596.64264

Timestep Collection Time: 2.22445
Timestep Consumption Time: 2.49535
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.71980

Cumulative Model Updates: 124,374
Cumulative Timesteps: 1,037,330,448

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1037330448...
Checkpoint 1037330448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,854.88263
Policy Entropy: 3.00303
Value Function Loss: 0.00547

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09439
Policy Update Magnitude: 0.57691
Value Function Update Magnitude: 0.51547

Collected Steps per Second: 21,996.73291
Overall Steps per Second: 10,533.58331

Timestep Collection Time: 2.27334
Timestep Consumption Time: 2.47395
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.74729

Cumulative Model Updates: 124,380
Cumulative Timesteps: 1,037,380,454

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,362.50188
Policy Entropy: 2.99626
Value Function Loss: 0.00568

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10415
Policy Update Magnitude: 0.58402
Value Function Update Magnitude: 0.51138

Collected Steps per Second: 22,033.80273
Overall Steps per Second: 10,462.36744

Timestep Collection Time: 2.26988
Timestep Consumption Time: 2.51050
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.78037

Cumulative Model Updates: 124,386
Cumulative Timesteps: 1,037,430,468

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1037430468...
Checkpoint 1037430468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.27395
Policy Entropy: 3.01632
Value Function Loss: 0.00574

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.10754
Policy Update Magnitude: 0.58738
Value Function Update Magnitude: 0.52866

Collected Steps per Second: 21,661.61982
Overall Steps per Second: 10,563.69999

Timestep Collection Time: 2.30897
Timestep Consumption Time: 2.42574
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.73470

Cumulative Model Updates: 124,392
Cumulative Timesteps: 1,037,480,484

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 985.81716
Policy Entropy: 3.00597
Value Function Loss: 0.00550

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.10943
Policy Update Magnitude: 0.58550
Value Function Update Magnitude: 0.53885

Collected Steps per Second: 22,087.73189
Overall Steps per Second: 10,543.06281

Timestep Collection Time: 2.26415
Timestep Consumption Time: 2.47925
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.74340

Cumulative Model Updates: 124,398
Cumulative Timesteps: 1,037,530,494

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1037530494...
Checkpoint 1037530494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,903.93958
Policy Entropy: 3.02198
Value Function Loss: 0.00515

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11056
Policy Update Magnitude: 0.57602
Value Function Update Magnitude: 0.53141

Collected Steps per Second: 21,874.22870
Overall Steps per Second: 10,620.74767

Timestep Collection Time: 2.28671
Timestep Consumption Time: 2.42294
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.70965

Cumulative Model Updates: 124,404
Cumulative Timesteps: 1,037,580,514

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 972.86486
Policy Entropy: 3.01327
Value Function Loss: 0.00496

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11063
Policy Update Magnitude: 0.56814
Value Function Update Magnitude: 0.50436

Collected Steps per Second: 22,037.32126
Overall Steps per Second: 10,411.49844

Timestep Collection Time: 2.26888
Timestep Consumption Time: 2.53350
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.80238

Cumulative Model Updates: 124,410
Cumulative Timesteps: 1,037,630,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1037630514...
Checkpoint 1037630514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.37490
Policy Entropy: 3.01197
Value Function Loss: 0.00515

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.12557
Policy Update Magnitude: 0.56301
Value Function Update Magnitude: 0.50387

Collected Steps per Second: 22,236.75849
Overall Steps per Second: 10,627.86876

Timestep Collection Time: 2.24970
Timestep Consumption Time: 2.45736
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.70706

Cumulative Model Updates: 124,416
Cumulative Timesteps: 1,037,680,540

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.99576
Policy Entropy: 3.00597
Value Function Loss: 0.00534

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.12178
Policy Update Magnitude: 0.57023
Value Function Update Magnitude: 0.52597

Collected Steps per Second: 22,352.42917
Overall Steps per Second: 10,539.69430

Timestep Collection Time: 2.23779
Timestep Consumption Time: 2.50808
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.74587

Cumulative Model Updates: 124,422
Cumulative Timesteps: 1,037,730,560

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1037730560...
Checkpoint 1037730560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 984.25875
Policy Entropy: 3.00755
Value Function Loss: 0.00528

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.11349
Policy Update Magnitude: 0.57832
Value Function Update Magnitude: 0.55505

Collected Steps per Second: 21,830.94156
Overall Steps per Second: 10,564.45786

Timestep Collection Time: 2.29079
Timestep Consumption Time: 2.44301
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.73380

Cumulative Model Updates: 124,428
Cumulative Timesteps: 1,037,780,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,460.23672
Policy Entropy: 3.00711
Value Function Loss: 0.00501

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.09915
Policy Update Magnitude: 0.57051
Value Function Update Magnitude: 0.54872

Collected Steps per Second: 22,327.53376
Overall Steps per Second: 10,497.72022

Timestep Collection Time: 2.23939
Timestep Consumption Time: 2.52355
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.76294

Cumulative Model Updates: 124,434
Cumulative Timesteps: 1,037,830,570

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1037830570...
Checkpoint 1037830570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.41622
Policy Entropy: 3.01599
Value Function Loss: 0.00498

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.09459
Policy Update Magnitude: 0.57018
Value Function Update Magnitude: 0.53996

Collected Steps per Second: 20,876.59837
Overall Steps per Second: 10,187.67687

Timestep Collection Time: 2.39531
Timestep Consumption Time: 2.51317
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.90848

Cumulative Model Updates: 124,440
Cumulative Timesteps: 1,037,880,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.84739
Policy Entropy: 3.01811
Value Function Loss: 0.00498

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.10240
Policy Update Magnitude: 0.56941
Value Function Update Magnitude: 0.53275

Collected Steps per Second: 22,225.65603
Overall Steps per Second: 10,498.44376

Timestep Collection Time: 2.25082
Timestep Consumption Time: 2.51426
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.76509

Cumulative Model Updates: 124,446
Cumulative Timesteps: 1,037,930,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1037930602...
Checkpoint 1037930602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 814.20489
Policy Entropy: 3.02943
Value Function Loss: 0.00473

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.09791
Policy Update Magnitude: 0.55333
Value Function Update Magnitude: 0.51321

Collected Steps per Second: 21,936.29888
Overall Steps per Second: 10,582.52162

Timestep Collection Time: 2.28060
Timestep Consumption Time: 2.44681
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.72742

Cumulative Model Updates: 124,452
Cumulative Timesteps: 1,037,980,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,002.72135
Policy Entropy: 3.04055
Value Function Loss: 0.00471

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.54206
Value Function Update Magnitude: 0.47694

Collected Steps per Second: 22,117.45821
Overall Steps per Second: 10,491.45963

Timestep Collection Time: 2.26066
Timestep Consumption Time: 2.50512
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.76578

Cumulative Model Updates: 124,458
Cumulative Timesteps: 1,038,030,630

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1038030630...
Checkpoint 1038030630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565.32872
Policy Entropy: 3.04223
Value Function Loss: 0.00487

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.09990
Policy Update Magnitude: 0.53876
Value Function Update Magnitude: 0.47423

Collected Steps per Second: 21,760.81871
Overall Steps per Second: 10,460.29435

Timestep Collection Time: 2.29918
Timestep Consumption Time: 2.48386
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.78304

Cumulative Model Updates: 124,464
Cumulative Timesteps: 1,038,080,662

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,573.49367
Policy Entropy: 3.02767
Value Function Loss: 0.00510

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09557
Policy Update Magnitude: 0.54929
Value Function Update Magnitude: 0.49210

Collected Steps per Second: 20,401.54188
Overall Steps per Second: 10,251.46835

Timestep Collection Time: 2.45217
Timestep Consumption Time: 2.42791
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.88008

Cumulative Model Updates: 124,470
Cumulative Timesteps: 1,038,130,690

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1038130690...
Checkpoint 1038130690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,205.24320
Policy Entropy: 3.01521
Value Function Loss: 0.00508

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.10734
Policy Update Magnitude: 0.56167
Value Function Update Magnitude: 0.51158

Collected Steps per Second: 21,700.89320
Overall Steps per Second: 10,365.88365

Timestep Collection Time: 2.30461
Timestep Consumption Time: 2.52007
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.82467

Cumulative Model Updates: 124,476
Cumulative Timesteps: 1,038,180,702

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,873.46820
Policy Entropy: 3.01846
Value Function Loss: 0.00507

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.11432
Policy Update Magnitude: 0.55654
Value Function Update Magnitude: 0.51297

Collected Steps per Second: 21,681.35458
Overall Steps per Second: 10,328.45243

Timestep Collection Time: 2.30659
Timestep Consumption Time: 2.53537
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.84196

Cumulative Model Updates: 124,482
Cumulative Timesteps: 1,038,230,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1038230712...
Checkpoint 1038230712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,125.24261
Policy Entropy: 3.04059
Value Function Loss: 0.00489

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.10970
Policy Update Magnitude: 0.55598
Value Function Update Magnitude: 0.50961

Collected Steps per Second: 22,430.17285
Overall Steps per Second: 10,593.79020

Timestep Collection Time: 2.22914
Timestep Consumption Time: 2.49061
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.71975

Cumulative Model Updates: 124,488
Cumulative Timesteps: 1,038,280,712

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,820.52831
Policy Entropy: 3.04490
Value Function Loss: 0.00518

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11108
Policy Update Magnitude: 0.55242
Value Function Update Magnitude: 0.49725

Collected Steps per Second: 22,358.18504
Overall Steps per Second: 10,555.81084

Timestep Collection Time: 2.23703
Timestep Consumption Time: 2.50121
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.73824

Cumulative Model Updates: 124,494
Cumulative Timesteps: 1,038,330,728

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1038330728...
Checkpoint 1038330728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.36270
Policy Entropy: 3.03114
Value Function Loss: 0.00497

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.55448
Value Function Update Magnitude: 0.51150

Collected Steps per Second: 22,244.26491
Overall Steps per Second: 10,580.54504

Timestep Collection Time: 2.24786
Timestep Consumption Time: 2.47798
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.72584

Cumulative Model Updates: 124,500
Cumulative Timesteps: 1,038,380,730

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,790.48225
Policy Entropy: 3.02720
Value Function Loss: 0.00499

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.12363
Policy Update Magnitude: 0.56096
Value Function Update Magnitude: 0.53346

Collected Steps per Second: 21,873.41816
Overall Steps per Second: 10,444.94052

Timestep Collection Time: 2.28670
Timestep Consumption Time: 2.50203
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.78873

Cumulative Model Updates: 124,506
Cumulative Timesteps: 1,038,430,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1038430748...
Checkpoint 1038430748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445.91258
Policy Entropy: 3.04192
Value Function Loss: 0.00500

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11015
Policy Update Magnitude: 0.55370
Value Function Update Magnitude: 0.54020

Collected Steps per Second: 22,285.44742
Overall Steps per Second: 10,645.89141

Timestep Collection Time: 2.24380
Timestep Consumption Time: 2.45323
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.69702

Cumulative Model Updates: 124,512
Cumulative Timesteps: 1,038,480,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618.61456
Policy Entropy: 3.05002
Value Function Loss: 0.00512

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.09821
Policy Update Magnitude: 0.55412
Value Function Update Magnitude: 0.52455

Collected Steps per Second: 22,423.60798
Overall Steps per Second: 10,635.09289

Timestep Collection Time: 2.22997
Timestep Consumption Time: 2.47182
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.70179

Cumulative Model Updates: 124,518
Cumulative Timesteps: 1,038,530,756

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1038530756...
Checkpoint 1038530756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,161.65848
Policy Entropy: 3.05001
Value Function Loss: 0.00526

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.10288
Policy Update Magnitude: 0.55661
Value Function Update Magnitude: 0.54619

Collected Steps per Second: 22,312.93151
Overall Steps per Second: 10,577.16861

Timestep Collection Time: 2.24211
Timestep Consumption Time: 2.48770
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.72981

Cumulative Model Updates: 124,524
Cumulative Timesteps: 1,038,580,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 876.01882
Policy Entropy: 3.04721
Value Function Loss: 0.00537

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.10313
Policy Update Magnitude: 0.56791
Value Function Update Magnitude: 0.57725

Collected Steps per Second: 21,889.75198
Overall Steps per Second: 10,356.91672

Timestep Collection Time: 2.28637
Timestep Consumption Time: 2.54596
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.83233

Cumulative Model Updates: 124,530
Cumulative Timesteps: 1,038,630,832

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1038630832...
Checkpoint 1038630832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.66426
Policy Entropy: 3.05888
Value Function Loss: 0.00542

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10064
Policy Update Magnitude: 0.57801
Value Function Update Magnitude: 0.58041

Collected Steps per Second: 21,922.21824
Overall Steps per Second: 10,574.67613

Timestep Collection Time: 2.28198
Timestep Consumption Time: 2.44876
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.73074

Cumulative Model Updates: 124,536
Cumulative Timesteps: 1,038,680,858

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,818.32115
Policy Entropy: 3.05775
Value Function Loss: 0.00530

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.10404
Policy Update Magnitude: 0.57030
Value Function Update Magnitude: 0.55764

Collected Steps per Second: 21,665.76786
Overall Steps per Second: 10,533.23019

Timestep Collection Time: 2.30825
Timestep Consumption Time: 2.43958
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.74783

Cumulative Model Updates: 124,542
Cumulative Timesteps: 1,038,730,868

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1038730868...
Checkpoint 1038730868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,514.95341
Policy Entropy: 3.06793
Value Function Loss: 0.00494

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.55381
Value Function Update Magnitude: 0.54833

Collected Steps per Second: 21,834.48049
Overall Steps per Second: 10,552.56629

Timestep Collection Time: 2.29087
Timestep Consumption Time: 2.44921
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.74008

Cumulative Model Updates: 124,548
Cumulative Timesteps: 1,038,780,888

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608.21030
Policy Entropy: 3.05675
Value Function Loss: 0.00475

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.54478
Value Function Update Magnitude: 0.55211

Collected Steps per Second: 22,463.01398
Overall Steps per Second: 10,512.32739

Timestep Collection Time: 2.22695
Timestep Consumption Time: 2.53165
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.75860

Cumulative Model Updates: 124,554
Cumulative Timesteps: 1,038,830,912

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1038830912...
Checkpoint 1038830912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,679.93859
Policy Entropy: 3.03590
Value Function Loss: 0.00485

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09340
Policy Update Magnitude: 0.55073
Value Function Update Magnitude: 0.53832

Collected Steps per Second: 22,004.56230
Overall Steps per Second: 10,633.35432

Timestep Collection Time: 2.27280
Timestep Consumption Time: 2.43051
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.70331

Cumulative Model Updates: 124,560
Cumulative Timesteps: 1,038,880,924

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.37701
Policy Entropy: 3.03254
Value Function Loss: 0.00510

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09050
Policy Update Magnitude: 0.56759
Value Function Update Magnitude: 0.52031

Collected Steps per Second: 22,526.67492
Overall Steps per Second: 10,550.05066

Timestep Collection Time: 2.22003
Timestep Consumption Time: 2.52023
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.74026

Cumulative Model Updates: 124,566
Cumulative Timesteps: 1,038,930,934

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1038930934...
Checkpoint 1038930934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,875.55805
Policy Entropy: 3.02338
Value Function Loss: 0.00528

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.09612
Policy Update Magnitude: 0.57046
Value Function Update Magnitude: 0.51456

Collected Steps per Second: 21,923.87121
Overall Steps per Second: 10,546.05564

Timestep Collection Time: 2.28089
Timestep Consumption Time: 2.46079
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.74168

Cumulative Model Updates: 124,572
Cumulative Timesteps: 1,038,980,940

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.56013
Policy Entropy: 3.02858
Value Function Loss: 0.00539

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.10615
Policy Update Magnitude: 0.57675
Value Function Update Magnitude: 0.52998

Collected Steps per Second: 22,306.28333
Overall Steps per Second: 10,529.91464

Timestep Collection Time: 2.24287
Timestep Consumption Time: 2.50836
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.75123

Cumulative Model Updates: 124,578
Cumulative Timesteps: 1,039,030,970

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1039030970...
Checkpoint 1039030970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,500.61785
Policy Entropy: 3.01106
Value Function Loss: 0.00530

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11176
Policy Update Magnitude: 0.57711
Value Function Update Magnitude: 0.54019

Collected Steps per Second: 21,976.94924
Overall Steps per Second: 10,572.12854

Timestep Collection Time: 2.27620
Timestep Consumption Time: 2.45548
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.73169

Cumulative Model Updates: 124,584
Cumulative Timesteps: 1,039,080,994

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,393.20219
Policy Entropy: 3.02712
Value Function Loss: 0.00503

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.10672
Policy Update Magnitude: 0.57438
Value Function Update Magnitude: 0.53821

Collected Steps per Second: 22,445.06026
Overall Steps per Second: 10,586.76185

Timestep Collection Time: 2.22971
Timestep Consumption Time: 2.49751
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.72722

Cumulative Model Updates: 124,590
Cumulative Timesteps: 1,039,131,040

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1039131040...
Checkpoint 1039131040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.98494
Policy Entropy: 3.04185
Value Function Loss: 0.00477

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.11450
Policy Update Magnitude: 0.55384
Value Function Update Magnitude: 0.51774

Collected Steps per Second: 21,804.82882
Overall Steps per Second: 10,525.23388

Timestep Collection Time: 2.29325
Timestep Consumption Time: 2.45761
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.75087

Cumulative Model Updates: 124,596
Cumulative Timesteps: 1,039,181,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.49303
Policy Entropy: 3.05064
Value Function Loss: 0.00471

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.09702
Policy Update Magnitude: 0.54123
Value Function Update Magnitude: 0.50184

Collected Steps per Second: 21,489.40102
Overall Steps per Second: 10,450.16312

Timestep Collection Time: 2.32738
Timestep Consumption Time: 2.45857
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.78595

Cumulative Model Updates: 124,602
Cumulative Timesteps: 1,039,231,058

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1039231058...
Checkpoint 1039231058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,594.95803
Policy Entropy: 3.04543
Value Function Loss: 0.00459

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08926
Policy Update Magnitude: 0.54541
Value Function Update Magnitude: 0.49757

Collected Steps per Second: 21,732.18164
Overall Steps per Second: 10,419.74822

Timestep Collection Time: 2.30193
Timestep Consumption Time: 2.49914
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.80108

Cumulative Model Updates: 124,608
Cumulative Timesteps: 1,039,281,084

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,791.77251
Policy Entropy: 3.03597
Value Function Loss: 0.00494

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08979
Policy Update Magnitude: 0.55843
Value Function Update Magnitude: 0.50702

Collected Steps per Second: 21,973.17359
Overall Steps per Second: 10,649.02872

Timestep Collection Time: 2.27559
Timestep Consumption Time: 2.41986
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.69545

Cumulative Model Updates: 124,614
Cumulative Timesteps: 1,039,331,086

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1039331086...
Checkpoint 1039331086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.78818
Policy Entropy: 3.03219
Value Function Loss: 0.00485

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09327
Policy Update Magnitude: 0.55670
Value Function Update Magnitude: 0.52209

Collected Steps per Second: 21,449.58575
Overall Steps per Second: 10,250.58932

Timestep Collection Time: 2.33161
Timestep Consumption Time: 2.54733
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.87894

Cumulative Model Updates: 124,620
Cumulative Timesteps: 1,039,381,098

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,562.65731
Policy Entropy: 3.03954
Value Function Loss: 0.00486

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09125
Policy Update Magnitude: 0.54932
Value Function Update Magnitude: 0.49988

Collected Steps per Second: 22,577.11043
Overall Steps per Second: 10,438.97201

Timestep Collection Time: 2.21516
Timestep Consumption Time: 2.57573
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.79089

Cumulative Model Updates: 124,626
Cumulative Timesteps: 1,039,431,110

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1039431110...
Checkpoint 1039431110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878.82230
Policy Entropy: 3.03798
Value Function Loss: 0.00498

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.55050
Value Function Update Magnitude: 0.48689

Collected Steps per Second: 22,122.98539
Overall Steps per Second: 10,571.00399

Timestep Collection Time: 2.26009
Timestep Consumption Time: 2.46983
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.72992

Cumulative Model Updates: 124,632
Cumulative Timesteps: 1,039,481,110

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,979.95861
Policy Entropy: 3.03872
Value Function Loss: 0.00492

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09624
Policy Update Magnitude: 0.54698
Value Function Update Magnitude: 0.50485

Collected Steps per Second: 22,487.24461
Overall Steps per Second: 10,592.83900

Timestep Collection Time: 2.22455
Timestep Consumption Time: 2.49789
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.72244

Cumulative Model Updates: 124,638
Cumulative Timesteps: 1,039,531,134

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1039531134...
Checkpoint 1039531134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,059.27617
Policy Entropy: 3.04578
Value Function Loss: 0.00462

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09209
Policy Update Magnitude: 0.54048
Value Function Update Magnitude: 0.52042

Collected Steps per Second: 21,401.60528
Overall Steps per Second: 10,291.46734

Timestep Collection Time: 2.33655
Timestep Consumption Time: 2.52242
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.85898

Cumulative Model Updates: 124,644
Cumulative Timesteps: 1,039,581,140

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.42537
Policy Entropy: 3.03944
Value Function Loss: 0.00460

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08953
Policy Update Magnitude: 0.54625
Value Function Update Magnitude: 0.51764

Collected Steps per Second: 22,452.90589
Overall Steps per Second: 10,697.05430

Timestep Collection Time: 2.22742
Timestep Consumption Time: 2.44789
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.67531

Cumulative Model Updates: 124,650
Cumulative Timesteps: 1,039,631,152

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1039631152...
Checkpoint 1039631152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,985.46261
Policy Entropy: 3.04563
Value Function Loss: 0.00468

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09658
Policy Update Magnitude: 0.54784
Value Function Update Magnitude: 0.50480

Collected Steps per Second: 21,806.32028
Overall Steps per Second: 10,411.37072

Timestep Collection Time: 2.29337
Timestep Consumption Time: 2.51003
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.80340

Cumulative Model Updates: 124,656
Cumulative Timesteps: 1,039,681,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.23340
Policy Entropy: 3.02419
Value Function Loss: 0.00496

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10159
Policy Update Magnitude: 0.54223
Value Function Update Magnitude: 0.49821

Collected Steps per Second: 22,531.74559
Overall Steps per Second: 10,718.20133

Timestep Collection Time: 2.22025
Timestep Consumption Time: 2.44714
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.66739

Cumulative Model Updates: 124,662
Cumulative Timesteps: 1,039,731,188

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1039731188...
Checkpoint 1039731188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,870.94539
Policy Entropy: 3.04031
Value Function Loss: 0.00475

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10104
Policy Update Magnitude: 0.54318
Value Function Update Magnitude: 0.48861

Collected Steps per Second: 21,746.15984
Overall Steps per Second: 10,405.20038

Timestep Collection Time: 2.29935
Timestep Consumption Time: 2.50613
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.80548

Cumulative Model Updates: 124,668
Cumulative Timesteps: 1,039,781,190

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,368.59554
Policy Entropy: 3.03365
Value Function Loss: 0.00496

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10065
Policy Update Magnitude: 0.54678
Value Function Update Magnitude: 0.49677

Collected Steps per Second: 22,125.01260
Overall Steps per Second: 10,522.43396

Timestep Collection Time: 2.26025
Timestep Consumption Time: 2.49227
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.75251

Cumulative Model Updates: 124,674
Cumulative Timesteps: 1,039,831,198

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1039831198...
Checkpoint 1039831198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,714.94701
Policy Entropy: 3.05289
Value Function Loss: 0.00450

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.54729
Value Function Update Magnitude: 0.51033

Collected Steps per Second: 21,833.39986
Overall Steps per Second: 10,410.26581

Timestep Collection Time: 2.29144
Timestep Consumption Time: 2.51439
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.80583

Cumulative Model Updates: 124,680
Cumulative Timesteps: 1,039,881,228

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,206.81699
Policy Entropy: 3.04330
Value Function Loss: 0.00438

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.09856
Policy Update Magnitude: 0.54469
Value Function Update Magnitude: 0.50263

Collected Steps per Second: 22,008.92046
Overall Steps per Second: 10,478.98900

Timestep Collection Time: 2.27217
Timestep Consumption Time: 2.50005
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.77222

Cumulative Model Updates: 124,686
Cumulative Timesteps: 1,039,931,236

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1039931236...
Checkpoint 1039931236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,993.49349
Policy Entropy: 3.04428
Value Function Loss: 0.00441

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08991
Policy Update Magnitude: 0.53913
Value Function Update Magnitude: 0.50606

Collected Steps per Second: 21,596.81185
Overall Steps per Second: 10,357.96478

Timestep Collection Time: 2.31618
Timestep Consumption Time: 2.51315
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.82933

Cumulative Model Updates: 124,692
Cumulative Timesteps: 1,039,981,258

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,146.02099
Policy Entropy: 3.02650
Value Function Loss: 0.00472

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.09602
Policy Update Magnitude: 0.54398
Value Function Update Magnitude: 0.54157

Collected Steps per Second: 22,062.57110
Overall Steps per Second: 10,480.29721

Timestep Collection Time: 2.26637
Timestep Consumption Time: 2.50468
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.77105

Cumulative Model Updates: 124,698
Cumulative Timesteps: 1,040,031,260

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1040031260...
Checkpoint 1040031260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.21289
Policy Entropy: 3.03148
Value Function Loss: 0.00494

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.54542
Value Function Update Magnitude: 0.53005

Collected Steps per Second: 21,702.91722
Overall Steps per Second: 10,407.52704

Timestep Collection Time: 2.30513
Timestep Consumption Time: 2.50178
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.80691

Cumulative Model Updates: 124,704
Cumulative Timesteps: 1,040,081,288

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,006.47430
Policy Entropy: 3.05824
Value Function Loss: 0.00491

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.54860
Value Function Update Magnitude: 0.49581

Collected Steps per Second: 22,433.15260
Overall Steps per Second: 10,490.58578

Timestep Collection Time: 2.22982
Timestep Consumption Time: 2.53845
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.76828

Cumulative Model Updates: 124,710
Cumulative Timesteps: 1,040,131,310

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1040131310...
Checkpoint 1040131310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,584.98872
Policy Entropy: 3.07809
Value Function Loss: 0.00496

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09862
Policy Update Magnitude: 0.54450
Value Function Update Magnitude: 0.50394

Collected Steps per Second: 21,986.72257
Overall Steps per Second: 10,566.81041

Timestep Collection Time: 2.27419
Timestep Consumption Time: 2.45780
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.73199

Cumulative Model Updates: 124,716
Cumulative Timesteps: 1,040,181,312

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.89267
Policy Entropy: 3.08849
Value Function Loss: 0.00496

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.10011
Policy Update Magnitude: 0.53670
Value Function Update Magnitude: 0.50771

Collected Steps per Second: 21,879.04806
Overall Steps per Second: 10,566.10361

Timestep Collection Time: 2.28621
Timestep Consumption Time: 2.44780
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.73401

Cumulative Model Updates: 124,722
Cumulative Timesteps: 1,040,231,332

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1040231332...
Checkpoint 1040231332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,631.98368
Policy Entropy: 3.06023
Value Function Loss: 0.00523

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.53902
Value Function Update Magnitude: 0.51144

Collected Steps per Second: 21,823.30903
Overall Steps per Second: 10,634.19662

Timestep Collection Time: 2.29223
Timestep Consumption Time: 2.41184
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.70407

Cumulative Model Updates: 124,728
Cumulative Timesteps: 1,040,281,356

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.31789
Policy Entropy: 3.04667
Value Function Loss: 0.00536

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.55151
Value Function Update Magnitude: 0.51609

Collected Steps per Second: 22,138.74609
Overall Steps per Second: 10,539.30041

Timestep Collection Time: 2.25957
Timestep Consumption Time: 2.48686
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.74643

Cumulative Model Updates: 124,734
Cumulative Timesteps: 1,040,331,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1040331380...
Checkpoint 1040331380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.28346
Policy Entropy: 3.02921
Value Function Loss: 0.00496

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.55495
Value Function Update Magnitude: 0.50697

Collected Steps per Second: 21,956.36287
Overall Steps per Second: 10,526.23247

Timestep Collection Time: 2.27724
Timestep Consumption Time: 2.47279
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.75004

Cumulative Model Updates: 124,740
Cumulative Timesteps: 1,040,381,380

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.95055
Policy Entropy: 3.04607
Value Function Loss: 0.00480

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08900
Policy Update Magnitude: 0.55634
Value Function Update Magnitude: 0.48763

Collected Steps per Second: 22,111.90490
Overall Steps per Second: 10,442.73152

Timestep Collection Time: 2.26168
Timestep Consumption Time: 2.52730
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.78898

Cumulative Model Updates: 124,746
Cumulative Timesteps: 1,040,431,390

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1040431390...
Checkpoint 1040431390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 844.04523
Policy Entropy: 3.04355
Value Function Loss: 0.00500

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.56609
Value Function Update Magnitude: 0.50742

Collected Steps per Second: 21,548.44516
Overall Steps per Second: 10,580.50095

Timestep Collection Time: 2.32082
Timestep Consumption Time: 2.40580
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.72662

Cumulative Model Updates: 124,752
Cumulative Timesteps: 1,040,481,400

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.57406
Policy Entropy: 3.05143
Value Function Loss: 0.00499

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.57492
Value Function Update Magnitude: 0.52989

Collected Steps per Second: 22,013.60074
Overall Steps per Second: 10,531.53453

Timestep Collection Time: 2.27269
Timestep Consumption Time: 2.47781
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.75049

Cumulative Model Updates: 124,758
Cumulative Timesteps: 1,040,531,430

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1040531430...
Checkpoint 1040531430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,406.01982
Policy Entropy: 3.04421
Value Function Loss: 0.00493

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09388
Policy Update Magnitude: 0.57258
Value Function Update Magnitude: 0.54004

Collected Steps per Second: 21,744.00857
Overall Steps per Second: 10,592.18979

Timestep Collection Time: 2.30086
Timestep Consumption Time: 2.42243
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.72329

Cumulative Model Updates: 124,764
Cumulative Timesteps: 1,040,581,460

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 885.84912
Policy Entropy: 3.04660
Value Function Loss: 0.00487

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08777
Policy Update Magnitude: 0.56942
Value Function Update Magnitude: 0.53985

Collected Steps per Second: 21,969.78263
Overall Steps per Second: 10,480.34525

Timestep Collection Time: 2.27640
Timestep Consumption Time: 2.49558
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.77198

Cumulative Model Updates: 124,770
Cumulative Timesteps: 1,040,631,472

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1040631472...
Checkpoint 1040631472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,112.53111
Policy Entropy: 3.03841
Value Function Loss: 0.00494

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09194
Policy Update Magnitude: 0.56898
Value Function Update Magnitude: 0.51675

Collected Steps per Second: 21,776.20357
Overall Steps per Second: 10,371.98774

Timestep Collection Time: 2.29664
Timestep Consumption Time: 2.52520
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.82183

Cumulative Model Updates: 124,776
Cumulative Timesteps: 1,040,681,484

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.52243
Policy Entropy: 3.04487
Value Function Loss: 0.00499

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10119
Policy Update Magnitude: 0.56253
Value Function Update Magnitude: 0.50238

Collected Steps per Second: 22,168.21000
Overall Steps per Second: 10,368.39249

Timestep Collection Time: 2.25566
Timestep Consumption Time: 2.56707
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.82273

Cumulative Model Updates: 124,782
Cumulative Timesteps: 1,040,731,488

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1040731488...
Checkpoint 1040731488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,160.79788
Policy Entropy: 3.06609
Value Function Loss: 0.00480

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.54845
Value Function Update Magnitude: 0.49279

Collected Steps per Second: 22,289.69879
Overall Steps per Second: 10,602.59322

Timestep Collection Time: 2.24391
Timestep Consumption Time: 2.47343
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.71734

Cumulative Model Updates: 124,788
Cumulative Timesteps: 1,040,781,504

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,072.46912
Policy Entropy: 3.06674
Value Function Loss: 0.00480

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09277
Policy Update Magnitude: 0.54974
Value Function Update Magnitude: 0.49962

Collected Steps per Second: 22,513.22152
Overall Steps per Second: 10,544.92209

Timestep Collection Time: 2.22198
Timestep Consumption Time: 2.52191
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.74389

Cumulative Model Updates: 124,794
Cumulative Timesteps: 1,040,831,528

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1040831528...
Checkpoint 1040831528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,053.81747
Policy Entropy: 3.06506
Value Function Loss: 0.00463

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10057
Policy Update Magnitude: 0.55243
Value Function Update Magnitude: 0.51231

Collected Steps per Second: 21,878.15985
Overall Steps per Second: 10,550.72160

Timestep Collection Time: 2.28621
Timestep Consumption Time: 2.45451
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.74072

Cumulative Model Updates: 124,800
Cumulative Timesteps: 1,040,881,546

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.86696
Policy Entropy: 3.03950
Value Function Loss: 0.00487

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.54371
Value Function Update Magnitude: 0.50396

Collected Steps per Second: 22,583.69883
Overall Steps per Second: 10,792.18080

Timestep Collection Time: 2.21531
Timestep Consumption Time: 2.42045
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.63576

Cumulative Model Updates: 124,806
Cumulative Timesteps: 1,040,931,576

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1040931576...
Checkpoint 1040931576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,854.32939
Policy Entropy: 3.05294
Value Function Loss: 0.00498

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.10023
Policy Update Magnitude: 0.54776
Value Function Update Magnitude: 0.50375

Collected Steps per Second: 22,110.86177
Overall Steps per Second: 10,638.96188

Timestep Collection Time: 2.26178
Timestep Consumption Time: 2.43886
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.70065

Cumulative Model Updates: 124,812
Cumulative Timesteps: 1,040,981,586

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292.84064
Policy Entropy: 3.02691
Value Function Loss: 0.00514

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10780
Policy Update Magnitude: 0.55351
Value Function Update Magnitude: 0.49307

Collected Steps per Second: 22,479.11094
Overall Steps per Second: 10,547.50109

Timestep Collection Time: 2.22509
Timestep Consumption Time: 2.51708
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.74217

Cumulative Model Updates: 124,818
Cumulative Timesteps: 1,041,031,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1041031604...
Checkpoint 1041031604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.53287
Policy Entropy: 3.03349
Value Function Loss: 0.00473

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.54876
Value Function Update Magnitude: 0.48928

Collected Steps per Second: 21,417.76345
Overall Steps per Second: 10,385.78456

Timestep Collection Time: 2.33544
Timestep Consumption Time: 2.48075
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.81620

Cumulative Model Updates: 124,824
Cumulative Timesteps: 1,041,081,624

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,351.27843
Policy Entropy: 3.02731
Value Function Loss: 0.00474

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.10325
Policy Update Magnitude: 0.54517
Value Function Update Magnitude: 0.49343

Collected Steps per Second: 22,320.47646
Overall Steps per Second: 10,713.75046

Timestep Collection Time: 2.24126
Timestep Consumption Time: 2.42807
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.66933

Cumulative Model Updates: 124,830
Cumulative Timesteps: 1,041,131,650

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1041131650...
Checkpoint 1041131650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,838.63123
Policy Entropy: 3.03458
Value Function Loss: 0.00497

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.10729
Policy Update Magnitude: 0.55605
Value Function Update Magnitude: 0.50201

Collected Steps per Second: 21,775.60272
Overall Steps per Second: 10,429.35491

Timestep Collection Time: 2.29716
Timestep Consumption Time: 2.49911
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.79627

Cumulative Model Updates: 124,836
Cumulative Timesteps: 1,041,181,672

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.34817
Policy Entropy: 3.03541
Value Function Loss: 0.00497

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.09990
Policy Update Magnitude: 0.56307
Value Function Update Magnitude: 0.50709

Collected Steps per Second: 22,099.34205
Overall Steps per Second: 10,590.51368

Timestep Collection Time: 2.26305
Timestep Consumption Time: 2.45929
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.72234

Cumulative Model Updates: 124,842
Cumulative Timesteps: 1,041,231,684

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1041231684...
Checkpoint 1041231684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.42642
Policy Entropy: 3.02849
Value Function Loss: 0.00487

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.09954
Policy Update Magnitude: 0.55575
Value Function Update Magnitude: 0.49651

Collected Steps per Second: 21,619.48743
Overall Steps per Second: 10,301.01550

Timestep Collection Time: 2.31393
Timestep Consumption Time: 2.54248
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.85641

Cumulative Model Updates: 124,848
Cumulative Timesteps: 1,041,281,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,866.64976
Policy Entropy: 3.03160
Value Function Loss: 0.00454

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09218
Policy Update Magnitude: 0.55218
Value Function Update Magnitude: 0.48631

Collected Steps per Second: 22,484.66820
Overall Steps per Second: 10,536.62659

Timestep Collection Time: 2.22498
Timestep Consumption Time: 2.52303
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.74801

Cumulative Model Updates: 124,854
Cumulative Timesteps: 1,041,331,738

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1041331738...
Checkpoint 1041331738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,819.34289
Policy Entropy: 3.03781
Value Function Loss: 0.00432

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09317
Policy Update Magnitude: 0.54033
Value Function Update Magnitude: 0.47705

Collected Steps per Second: 21,963.44834
Overall Steps per Second: 10,603.83823

Timestep Collection Time: 2.27778
Timestep Consumption Time: 2.44013
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.71791

Cumulative Model Updates: 124,860
Cumulative Timesteps: 1,041,381,766

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,185.31241
Policy Entropy: 3.05051
Value Function Loss: 0.00417

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08959
Policy Update Magnitude: 0.52983
Value Function Update Magnitude: 0.46544

Collected Steps per Second: 22,550.64992
Overall Steps per Second: 10,607.65571

Timestep Collection Time: 2.21803
Timestep Consumption Time: 2.49724
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.71527

Cumulative Model Updates: 124,866
Cumulative Timesteps: 1,041,431,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1041431784...
Checkpoint 1041431784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,056.72378
Policy Entropy: 3.05745
Value Function Loss: 0.00438

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.52444
Value Function Update Magnitude: 0.47129

Collected Steps per Second: 21,368.46275
Overall Steps per Second: 10,446.28988

Timestep Collection Time: 2.34018
Timestep Consumption Time: 2.44679
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.78696

Cumulative Model Updates: 124,872
Cumulative Timesteps: 1,041,481,790

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,003.66138
Policy Entropy: 3.05737
Value Function Loss: 0.00450

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.53911
Value Function Update Magnitude: 0.46703

Collected Steps per Second: 22,401.31533
Overall Steps per Second: 10,511.89614

Timestep Collection Time: 2.23335
Timestep Consumption Time: 2.52602
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.75937

Cumulative Model Updates: 124,878
Cumulative Timesteps: 1,041,531,820

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1041531820...
Checkpoint 1041531820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.67138
Policy Entropy: 3.02855
Value Function Loss: 0.00478

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08829
Policy Update Magnitude: 0.55107
Value Function Update Magnitude: 0.48420

Collected Steps per Second: 22,019.30674
Overall Steps per Second: 10,614.55249

Timestep Collection Time: 2.27128
Timestep Consumption Time: 2.44037
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.71164

Cumulative Model Updates: 124,884
Cumulative Timesteps: 1,041,581,832

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,505.05284
Policy Entropy: 3.01291
Value Function Loss: 0.00511

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10160
Policy Update Magnitude: 0.56446
Value Function Update Magnitude: 0.50494

Collected Steps per Second: 22,067.38869
Overall Steps per Second: 10,423.73441

Timestep Collection Time: 2.26697
Timestep Consumption Time: 2.53227
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.79924

Cumulative Model Updates: 124,890
Cumulative Timesteps: 1,041,631,858

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1041631858...
Checkpoint 1041631858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,552.97682
Policy Entropy: 3.00095
Value Function Loss: 0.00490

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.10417
Policy Update Magnitude: 0.56418
Value Function Update Magnitude: 0.51123

Collected Steps per Second: 21,587.09429
Overall Steps per Second: 10,363.72828

Timestep Collection Time: 2.31675
Timestep Consumption Time: 2.50892
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.82568

Cumulative Model Updates: 124,896
Cumulative Timesteps: 1,041,681,870

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,945.59222
Policy Entropy: 3.00699
Value Function Loss: 0.00474

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.10906
Policy Update Magnitude: 0.55320
Value Function Update Magnitude: 0.49502

Collected Steps per Second: 22,104.70282
Overall Steps per Second: 10,680.53370

Timestep Collection Time: 2.26196
Timestep Consumption Time: 2.41945
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.68141

Cumulative Model Updates: 124,902
Cumulative Timesteps: 1,041,731,870

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1041731870...
Checkpoint 1041731870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,527.73695
Policy Entropy: 3.00558
Value Function Loss: 0.00457

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.10597
Policy Update Magnitude: 0.54989
Value Function Update Magnitude: 0.48260

Collected Steps per Second: 21,588.91663
Overall Steps per Second: 10,323.69129

Timestep Collection Time: 2.31600
Timestep Consumption Time: 2.52723
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.84323

Cumulative Model Updates: 124,908
Cumulative Timesteps: 1,041,781,870

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.21734
Policy Entropy: 2.99352
Value Function Loss: 0.00504

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.12254
Policy Update Magnitude: 0.55854
Value Function Update Magnitude: 0.49277

Collected Steps per Second: 22,219.41295
Overall Steps per Second: 10,371.28052

Timestep Collection Time: 2.25127
Timestep Consumption Time: 2.57185
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.82313

Cumulative Model Updates: 124,914
Cumulative Timesteps: 1,041,831,892

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1041831892...
Checkpoint 1041831892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,114.07353
Policy Entropy: 2.99348
Value Function Loss: 0.00514

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.56990
Value Function Update Magnitude: 0.50413

Collected Steps per Second: 21,571.16929
Overall Steps per Second: 10,171.96248

Timestep Collection Time: 2.31930
Timestep Consumption Time: 2.59912
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.91842

Cumulative Model Updates: 124,920
Cumulative Timesteps: 1,041,881,922

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,030.34511
Policy Entropy: 2.99898
Value Function Loss: 0.00516

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.56939
Value Function Update Magnitude: 0.50133

Collected Steps per Second: 22,440.23417
Overall Steps per Second: 10,503.05405

Timestep Collection Time: 2.22939
Timestep Consumption Time: 2.53380
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.76319

Cumulative Model Updates: 124,926
Cumulative Timesteps: 1,041,931,950

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1041931950...
Checkpoint 1041931950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,386.65704
Policy Entropy: 3.01566
Value Function Loss: 0.00502

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.10291
Policy Update Magnitude: 0.56071
Value Function Update Magnitude: 0.49746

Collected Steps per Second: 22,133.79281
Overall Steps per Second: 10,606.83576

Timestep Collection Time: 2.26089
Timestep Consumption Time: 2.45701
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.71790

Cumulative Model Updates: 124,932
Cumulative Timesteps: 1,041,981,992

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,623.58411
Policy Entropy: 3.01479
Value Function Loss: 0.00474

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.55879
Value Function Update Magnitude: 0.47825

Collected Steps per Second: 22,331.39336
Overall Steps per Second: 10,495.28588

Timestep Collection Time: 2.23981
Timestep Consumption Time: 2.52595
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.76576

Cumulative Model Updates: 124,938
Cumulative Timesteps: 1,042,032,010

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1042032010...
Checkpoint 1042032010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.36590
Policy Entropy: 3.01282
Value Function Loss: 0.00486

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.55895
Value Function Update Magnitude: 0.47049

Collected Steps per Second: 22,103.80931
Overall Steps per Second: 10,694.11921

Timestep Collection Time: 2.26223
Timestep Consumption Time: 2.41361
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.67584

Cumulative Model Updates: 124,944
Cumulative Timesteps: 1,042,082,014

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656.51373
Policy Entropy: 3.01858
Value Function Loss: 0.00479

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09038
Policy Update Magnitude: 0.56631
Value Function Update Magnitude: 0.47230

Collected Steps per Second: 22,446.61055
Overall Steps per Second: 10,654.89997

Timestep Collection Time: 2.22849
Timestep Consumption Time: 2.46625
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.69474

Cumulative Model Updates: 124,950
Cumulative Timesteps: 1,042,132,036

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1042132036...
Checkpoint 1042132036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,856.00708
Policy Entropy: 3.03390
Value Function Loss: 0.00477

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.09516
Policy Update Magnitude: 0.56470
Value Function Update Magnitude: 0.49020

Collected Steps per Second: 22,127.96333
Overall Steps per Second: 10,584.42165

Timestep Collection Time: 2.25995
Timestep Consumption Time: 2.46473
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.72468

Cumulative Model Updates: 124,956
Cumulative Timesteps: 1,042,182,044

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,587.18670
Policy Entropy: 3.04990
Value Function Loss: 0.00464

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09305
Policy Update Magnitude: 0.55201
Value Function Update Magnitude: 0.49735

Collected Steps per Second: 21,958.51173
Overall Steps per Second: 10,420.86214

Timestep Collection Time: 2.27821
Timestep Consumption Time: 2.52236
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.80056

Cumulative Model Updates: 124,962
Cumulative Timesteps: 1,042,232,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1042232070...
Checkpoint 1042232070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650.86983
Policy Entropy: 3.05879
Value Function Loss: 0.00461

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.09536
Policy Update Magnitude: 0.55280
Value Function Update Magnitude: 0.48423

Collected Steps per Second: 21,879.69361
Overall Steps per Second: 10,594.40719

Timestep Collection Time: 2.28669
Timestep Consumption Time: 2.43581
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.72249

Cumulative Model Updates: 124,968
Cumulative Timesteps: 1,042,282,102

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.93132
Policy Entropy: 3.06545
Value Function Loss: 0.00490

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.55987
Value Function Update Magnitude: 0.48792

Collected Steps per Second: 21,969.89263
Overall Steps per Second: 10,535.63972

Timestep Collection Time: 2.27584
Timestep Consumption Time: 2.46995
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.74580

Cumulative Model Updates: 124,974
Cumulative Timesteps: 1,042,332,102

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1042332102...
Checkpoint 1042332102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 739.19922
Policy Entropy: 3.05169
Value Function Loss: 0.00510

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.56163
Value Function Update Magnitude: 0.49627

Collected Steps per Second: 21,677.34775
Overall Steps per Second: 10,478.90165

Timestep Collection Time: 2.30665
Timestep Consumption Time: 2.46504
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.77168

Cumulative Model Updates: 124,980
Cumulative Timesteps: 1,042,382,104

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.20524
Policy Entropy: 3.04684
Value Function Loss: 0.00534

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10052
Policy Update Magnitude: 0.56958
Value Function Update Magnitude: 0.52304

Collected Steps per Second: 22,045.45706
Overall Steps per Second: 10,434.53444

Timestep Collection Time: 2.26813
Timestep Consumption Time: 2.52384
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.79197

Cumulative Model Updates: 124,986
Cumulative Timesteps: 1,042,432,106

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1042432106...
Checkpoint 1042432106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,709.63527
Policy Entropy: 3.03487
Value Function Loss: 0.00528

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.57233
Value Function Update Magnitude: 0.54167

Collected Steps per Second: 22,177.23496
Overall Steps per Second: 10,599.04712

Timestep Collection Time: 2.25456
Timestep Consumption Time: 2.46284
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.71741

Cumulative Model Updates: 124,992
Cumulative Timesteps: 1,042,482,106

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.17959
Policy Entropy: 3.04232
Value Function Loss: 0.00543

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.57706
Value Function Update Magnitude: 0.54812

Collected Steps per Second: 21,898.00105
Overall Steps per Second: 10,424.16604

Timestep Collection Time: 2.28350
Timestep Consumption Time: 2.51343
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.79693

Cumulative Model Updates: 124,998
Cumulative Timesteps: 1,042,532,110

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1042532110...
Checkpoint 1042532110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.99283
Policy Entropy: 3.06195
Value Function Loss: 0.00531

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.09397
Policy Update Magnitude: 0.58047
Value Function Update Magnitude: 0.53610

Collected Steps per Second: 21,808.10308
Overall Steps per Second: 10,499.42325

Timestep Collection Time: 2.29300
Timestep Consumption Time: 2.46974
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.76274

Cumulative Model Updates: 125,004
Cumulative Timesteps: 1,042,582,116

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,675.74734
Policy Entropy: 3.06829
Value Function Loss: 0.00559

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.09600
Policy Update Magnitude: 0.57629
Value Function Update Magnitude: 0.53422

Collected Steps per Second: 22,382.58551
Overall Steps per Second: 10,645.45872

Timestep Collection Time: 2.23477
Timestep Consumption Time: 2.46394
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.69872

Cumulative Model Updates: 125,010
Cumulative Timesteps: 1,042,632,136

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1042632136...
Checkpoint 1042632136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,809.70227
Policy Entropy: 3.05764
Value Function Loss: 0.00538

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.09996
Policy Update Magnitude: 0.56572
Value Function Update Magnitude: 0.52602

Collected Steps per Second: 22,043.94381
Overall Steps per Second: 10,587.54748

Timestep Collection Time: 2.26829
Timestep Consumption Time: 2.45443
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.72272

Cumulative Model Updates: 125,016
Cumulative Timesteps: 1,042,682,138

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,830.62719
Policy Entropy: 3.03898
Value Function Loss: 0.00514

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.56768
Value Function Update Magnitude: 0.51879

Collected Steps per Second: 21,942.76458
Overall Steps per Second: 10,560.18238

Timestep Collection Time: 2.27975
Timestep Consumption Time: 2.45729
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.73704

Cumulative Model Updates: 125,022
Cumulative Timesteps: 1,042,732,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1042732162...
Checkpoint 1042732162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,546.24810
Policy Entropy: 3.03200
Value Function Loss: 0.00497

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.10735
Policy Update Magnitude: 0.55556
Value Function Update Magnitude: 0.51088

Collected Steps per Second: 22,245.34207
Overall Steps per Second: 10,657.78086

Timestep Collection Time: 2.24838
Timestep Consumption Time: 2.44453
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.69291

Cumulative Model Updates: 125,028
Cumulative Timesteps: 1,042,782,178

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.46238
Policy Entropy: 3.03869
Value Function Loss: 0.00489

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.10424
Policy Update Magnitude: 0.55150
Value Function Update Magnitude: 0.50910

Collected Steps per Second: 21,824.84735
Overall Steps per Second: 10,431.02957

Timestep Collection Time: 2.29152
Timestep Consumption Time: 2.50302
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.79454

Cumulative Model Updates: 125,034
Cumulative Timesteps: 1,042,832,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1042832190...
Checkpoint 1042832190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,007.79919
Policy Entropy: 3.05161
Value Function Loss: 0.00502

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10260
Policy Update Magnitude: 0.55563
Value Function Update Magnitude: 0.50723

Collected Steps per Second: 21,312.46266
Overall Steps per Second: 10,258.55955

Timestep Collection Time: 2.34680
Timestep Consumption Time: 2.52874
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.87554

Cumulative Model Updates: 125,040
Cumulative Timesteps: 1,042,882,206

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,820.67126
Policy Entropy: 3.05274
Value Function Loss: 0.00518

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.09994
Policy Update Magnitude: 0.56393
Value Function Update Magnitude: 0.52995

Collected Steps per Second: 21,898.10164
Overall Steps per Second: 10,437.19020

Timestep Collection Time: 2.28431
Timestep Consumption Time: 2.50836
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.79267

Cumulative Model Updates: 125,046
Cumulative Timesteps: 1,042,932,228

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1042932228...
Checkpoint 1042932228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,149.16343
Policy Entropy: 3.04948
Value Function Loss: 0.00512

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10291
Policy Update Magnitude: 0.56359
Value Function Update Magnitude: 0.54120

Collected Steps per Second: 21,392.59334
Overall Steps per Second: 10,327.14005

Timestep Collection Time: 2.33857
Timestep Consumption Time: 2.50576
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.84432

Cumulative Model Updates: 125,052
Cumulative Timesteps: 1,042,982,256

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,583.65044
Policy Entropy: 3.05149
Value Function Loss: 0.00508

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.56289
Value Function Update Magnitude: 0.54222

Collected Steps per Second: 21,795.43205
Overall Steps per Second: 10,366.89030

Timestep Collection Time: 2.29498
Timestep Consumption Time: 2.53000
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.82498

Cumulative Model Updates: 125,058
Cumulative Timesteps: 1,043,032,276

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1043032276...
Checkpoint 1043032276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,752.45112
Policy Entropy: 3.05813
Value Function Loss: 0.00519

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.56754
Value Function Update Magnitude: 0.54397

Collected Steps per Second: 21,828.87799
Overall Steps per Second: 10,541.12403

Timestep Collection Time: 2.29119
Timestep Consumption Time: 2.45347
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.74466

Cumulative Model Updates: 125,064
Cumulative Timesteps: 1,043,082,290

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 909.27198
Policy Entropy: 3.05628
Value Function Loss: 0.00521

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09102
Policy Update Magnitude: 0.56848
Value Function Update Magnitude: 0.53632

Collected Steps per Second: 22,447.28850
Overall Steps per Second: 10,486.85285

Timestep Collection Time: 2.22824
Timestep Consumption Time: 2.54135
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.76959

Cumulative Model Updates: 125,070
Cumulative Timesteps: 1,043,132,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1043132308...
Checkpoint 1043132308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,087.48561
Policy Entropy: 3.05345
Value Function Loss: 0.00516

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11139
Policy Update Magnitude: 0.56837
Value Function Update Magnitude: 0.52583

Collected Steps per Second: 21,858.42419
Overall Steps per Second: 10,545.32525

Timestep Collection Time: 2.28754
Timestep Consumption Time: 2.45409
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.74163

Cumulative Model Updates: 125,076
Cumulative Timesteps: 1,043,182,310

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,215.51349
Policy Entropy: 3.04565
Value Function Loss: 0.00528

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11064
Policy Update Magnitude: 0.56428
Value Function Update Magnitude: 0.50952

Collected Steps per Second: 22,364.28081
Overall Steps per Second: 10,540.76510

Timestep Collection Time: 2.23687
Timestep Consumption Time: 2.50908
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.74596

Cumulative Model Updates: 125,082
Cumulative Timesteps: 1,043,232,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1043232336...
Checkpoint 1043232336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,111.29219
Policy Entropy: 3.03797
Value Function Loss: 0.00526

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.11506
Policy Update Magnitude: 0.56733
Value Function Update Magnitude: 0.53097

Collected Steps per Second: 22,154.03499
Overall Steps per Second: 10,623.68607

Timestep Collection Time: 2.25774
Timestep Consumption Time: 2.45042
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.70816

Cumulative Model Updates: 125,088
Cumulative Timesteps: 1,043,282,354

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667.28004
Policy Entropy: 3.02784
Value Function Loss: 0.00512

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.10218
Policy Update Magnitude: 0.56491
Value Function Update Magnitude: 0.54692

Collected Steps per Second: 22,235.28809
Overall Steps per Second: 10,477.09699

Timestep Collection Time: 2.24895
Timestep Consumption Time: 2.52394
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.77289

Cumulative Model Updates: 125,094
Cumulative Timesteps: 1,043,332,360

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1043332360...
Checkpoint 1043332360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,685.58120
Policy Entropy: 3.03671
Value Function Loss: 0.00513

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10110
Policy Update Magnitude: 0.56034
Value Function Update Magnitude: 0.54280

Collected Steps per Second: 22,075.94689
Overall Steps per Second: 10,611.18301

Timestep Collection Time: 2.26518
Timestep Consumption Time: 2.44740
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.71258

Cumulative Model Updates: 125,100
Cumulative Timesteps: 1,043,382,366

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,771.02661
Policy Entropy: 3.04496
Value Function Loss: 0.00504

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11062
Policy Update Magnitude: 0.55853
Value Function Update Magnitude: 0.53253

Collected Steps per Second: 22,303.03765
Overall Steps per Second: 10,488.03519

Timestep Collection Time: 2.24283
Timestep Consumption Time: 2.52660
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.76943

Cumulative Model Updates: 125,106
Cumulative Timesteps: 1,043,432,388

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1043432388...
Checkpoint 1043432388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.90826
Policy Entropy: 3.05603
Value Function Loss: 0.00520

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10233
Policy Update Magnitude: 0.56871
Value Function Update Magnitude: 0.54031

Collected Steps per Second: 21,618.88509
Overall Steps per Second: 10,569.62064

Timestep Collection Time: 2.31344
Timestep Consumption Time: 2.41842
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.73186

Cumulative Model Updates: 125,112
Cumulative Timesteps: 1,043,482,402

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,625.45201
Policy Entropy: 3.04800
Value Function Loss: 0.00501

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.09896
Policy Update Magnitude: 0.56787
Value Function Update Magnitude: 0.54102

Collected Steps per Second: 22,072.88731
Overall Steps per Second: 10,542.43561

Timestep Collection Time: 2.26568
Timestep Consumption Time: 2.47801
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.74369

Cumulative Model Updates: 125,118
Cumulative Timesteps: 1,043,532,412

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1043532412...
Checkpoint 1043532412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,622.42199
Policy Entropy: 3.02564
Value Function Loss: 0.00480

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.10458
Policy Update Magnitude: 0.56092
Value Function Update Magnitude: 0.53428

Collected Steps per Second: 21,596.38145
Overall Steps per Second: 10,572.92748

Timestep Collection Time: 2.31668
Timestep Consumption Time: 2.41540
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.73209

Cumulative Model Updates: 125,124
Cumulative Timesteps: 1,043,582,444

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.20707
Policy Entropy: 3.04429
Value Function Loss: 0.00484

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.10930
Policy Update Magnitude: 0.56280
Value Function Update Magnitude: 0.54136

Collected Steps per Second: 21,939.02160
Overall Steps per Second: 10,509.11233

Timestep Collection Time: 2.28096
Timestep Consumption Time: 2.48081
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.76177

Cumulative Model Updates: 125,130
Cumulative Timesteps: 1,043,632,486

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1043632486...
Checkpoint 1043632486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.52774
Policy Entropy: 3.04340
Value Function Loss: 0.00497

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.10262
Policy Update Magnitude: 0.56144
Value Function Update Magnitude: 0.53220

Collected Steps per Second: 21,426.48832
Overall Steps per Second: 10,235.15707

Timestep Collection Time: 2.33580
Timestep Consumption Time: 2.55401
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.88981

Cumulative Model Updates: 125,136
Cumulative Timesteps: 1,043,682,534

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.17154
Policy Entropy: 3.06084
Value Function Loss: 0.00520

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.56206
Value Function Update Magnitude: 0.54400

Collected Steps per Second: 22,429.22774
Overall Steps per Second: 10,596.94686

Timestep Collection Time: 2.22932
Timestep Consumption Time: 2.48921
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.71853

Cumulative Model Updates: 125,142
Cumulative Timesteps: 1,043,732,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1043732536...
Checkpoint 1043732536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.16874
Policy Entropy: 3.04643
Value Function Loss: 0.00535

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08877
Policy Update Magnitude: 0.56906
Value Function Update Magnitude: 0.53873

Collected Steps per Second: 20,836.98919
Overall Steps per Second: 10,239.76852

Timestep Collection Time: 2.40083
Timestep Consumption Time: 2.48464
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.88546

Cumulative Model Updates: 125,148
Cumulative Timesteps: 1,043,782,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.62376
Policy Entropy: 3.04981
Value Function Loss: 0.00509

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.09791
Policy Update Magnitude: 0.56457
Value Function Update Magnitude: 0.54948

Collected Steps per Second: 21,370.60231
Overall Steps per Second: 10,268.81205

Timestep Collection Time: 2.34069
Timestep Consumption Time: 2.53056
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.87125

Cumulative Model Updates: 125,154
Cumulative Timesteps: 1,043,832,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1043832584...
Checkpoint 1043832584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,522.63298
Policy Entropy: 3.05177
Value Function Loss: 0.00484

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.10069
Policy Update Magnitude: 0.55305
Value Function Update Magnitude: 0.53695

Collected Steps per Second: 21,747.54452
Overall Steps per Second: 10,395.04754

Timestep Collection Time: 2.30049
Timestep Consumption Time: 2.51238
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.81287

Cumulative Model Updates: 125,160
Cumulative Timesteps: 1,043,882,614

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,106.90197
Policy Entropy: 3.06334
Value Function Loss: 0.00460

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10319
Policy Update Magnitude: 0.54173
Value Function Update Magnitude: 0.51935

Collected Steps per Second: 22,173.75091
Overall Steps per Second: 10,689.44666

Timestep Collection Time: 2.25627
Timestep Consumption Time: 2.42405
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.68032

Cumulative Model Updates: 125,166
Cumulative Timesteps: 1,043,932,644

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1043932644...
Checkpoint 1043932644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,576.42780
Policy Entropy: 3.05460
Value Function Loss: 0.00456

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.10638
Policy Update Magnitude: 0.54601
Value Function Update Magnitude: 0.50334

Collected Steps per Second: 21,754.32353
Overall Steps per Second: 10,377.18707

Timestep Collection Time: 2.29867
Timestep Consumption Time: 2.52017
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.81884

Cumulative Model Updates: 125,172
Cumulative Timesteps: 1,043,982,650

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,452.81432
Policy Entropy: 3.05178
Value Function Loss: 0.00495

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09558
Policy Update Magnitude: 0.55094
Value Function Update Magnitude: 0.50175

Collected Steps per Second: 22,591.77610
Overall Steps per Second: 10,693.88765

Timestep Collection Time: 2.21435
Timestep Consumption Time: 2.46365
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.67800

Cumulative Model Updates: 125,178
Cumulative Timesteps: 1,044,032,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1044032676...
Checkpoint 1044032676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,743.96685
Policy Entropy: 3.06343
Value Function Loss: 0.00490

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.09432
Policy Update Magnitude: 0.55162
Value Function Update Magnitude: 0.52507

Collected Steps per Second: 21,968.35861
Overall Steps per Second: 10,430.43598

Timestep Collection Time: 2.27664
Timestep Consumption Time: 2.51837
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.79501

Cumulative Model Updates: 125,184
Cumulative Timesteps: 1,044,082,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.07221
Policy Entropy: 3.07550
Value Function Loss: 0.00488

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.54676
Value Function Update Magnitude: 0.52475

Collected Steps per Second: 22,329.50949
Overall Steps per Second: 10,678.70490

Timestep Collection Time: 2.24017
Timestep Consumption Time: 2.44410
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.68428

Cumulative Model Updates: 125,190
Cumulative Timesteps: 1,044,132,712

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1044132712...
Checkpoint 1044132712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,591.30662
Policy Entropy: 3.07321
Value Function Loss: 0.00479

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.55035
Value Function Update Magnitude: 0.51085

Collected Steps per Second: 21,818.45944
Overall Steps per Second: 10,406.31920

Timestep Collection Time: 2.29219
Timestep Consumption Time: 2.51374
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.80593

Cumulative Model Updates: 125,196
Cumulative Timesteps: 1,044,182,724

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,989.51791
Policy Entropy: 3.07056
Value Function Loss: 0.00490

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.56095
Value Function Update Magnitude: 0.53070

Collected Steps per Second: 22,554.65933
Overall Steps per Second: 10,779.10112

Timestep Collection Time: 2.21701
Timestep Consumption Time: 2.42196
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.63898

Cumulative Model Updates: 125,202
Cumulative Timesteps: 1,044,232,728

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1044232728...
Checkpoint 1044232728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.33546
Policy Entropy: 3.06961
Value Function Loss: 0.00477

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.09482
Policy Update Magnitude: 0.56485
Value Function Update Magnitude: 0.53149

Collected Steps per Second: 22,197.57107
Overall Steps per Second: 10,609.61718

Timestep Collection Time: 2.25376
Timestep Consumption Time: 2.46158
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.71534

Cumulative Model Updates: 125,208
Cumulative Timesteps: 1,044,282,756

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328.30705
Policy Entropy: 3.05721
Value Function Loss: 0.00500

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.56030
Value Function Update Magnitude: 0.53766

Collected Steps per Second: 21,968.70711
Overall Steps per Second: 10,473.54362

Timestep Collection Time: 2.27687
Timestep Consumption Time: 2.49897
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.77584

Cumulative Model Updates: 125,214
Cumulative Timesteps: 1,044,332,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1044332776...
Checkpoint 1044332776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,393.93279
Policy Entropy: 3.05883
Value Function Loss: 0.00489

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.09607
Policy Update Magnitude: 0.56017
Value Function Update Magnitude: 0.53763

Collected Steps per Second: 21,540.64959
Overall Steps per Second: 10,572.51297

Timestep Collection Time: 2.32184
Timestep Consumption Time: 2.40873
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.73057

Cumulative Model Updates: 125,220
Cumulative Timesteps: 1,044,382,790

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,013.78728
Policy Entropy: 3.04371
Value Function Loss: 0.00499

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.10718
Policy Update Magnitude: 0.56150
Value Function Update Magnitude: 0.51433

Collected Steps per Second: 21,862.08769
Overall Steps per Second: 10,558.06989

Timestep Collection Time: 2.28752
Timestep Consumption Time: 2.44914
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.73666

Cumulative Model Updates: 125,226
Cumulative Timesteps: 1,044,432,800

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1044432800...
Checkpoint 1044432800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 979.07962
Policy Entropy: 3.05224
Value Function Loss: 0.00511

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.09848
Policy Update Magnitude: 0.56101
Value Function Update Magnitude: 0.51351

Collected Steps per Second: 21,566.75875
Overall Steps per Second: 10,338.56367

Timestep Collection Time: 2.31922
Timestep Consumption Time: 2.51879
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.83800

Cumulative Model Updates: 125,232
Cumulative Timesteps: 1,044,482,818

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.90087
Policy Entropy: 3.04895
Value Function Loss: 0.00493

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.11443
Policy Update Magnitude: 0.56396
Value Function Update Magnitude: 0.52379

Collected Steps per Second: 22,737.49696
Overall Steps per Second: 10,675.66005

Timestep Collection Time: 2.19910
Timestep Consumption Time: 2.48464
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.68374

Cumulative Model Updates: 125,238
Cumulative Timesteps: 1,044,532,820

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1044532820...
Checkpoint 1044532820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,405.97891
Policy Entropy: 3.04187
Value Function Loss: 0.00505

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.10476
Policy Update Magnitude: 0.56289
Value Function Update Magnitude: 0.52829

Collected Steps per Second: 22,012.97664
Overall Steps per Second: 10,569.44317

Timestep Collection Time: 2.27221
Timestep Consumption Time: 2.46012
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.73232

Cumulative Model Updates: 125,244
Cumulative Timesteps: 1,044,582,838

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,430.91257
Policy Entropy: 3.02475
Value Function Loss: 0.00468

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.55731
Value Function Update Magnitude: 0.53651

Collected Steps per Second: 21,829.12971
Overall Steps per Second: 10,625.55152

Timestep Collection Time: 2.29125
Timestep Consumption Time: 2.41589
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.70714

Cumulative Model Updates: 125,250
Cumulative Timesteps: 1,044,632,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1044632854...
Checkpoint 1044632854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.94320
Policy Entropy: 3.02016
Value Function Loss: 0.00458

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09535
Policy Update Magnitude: 0.55084
Value Function Update Magnitude: 0.51710

Collected Steps per Second: 21,911.50549
Overall Steps per Second: 10,539.92280

Timestep Collection Time: 2.28264
Timestep Consumption Time: 2.46275
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.74539

Cumulative Model Updates: 125,256
Cumulative Timesteps: 1,044,682,870

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464.61185
Policy Entropy: 3.00513
Value Function Loss: 0.00486

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.56132
Value Function Update Magnitude: 0.51150

Collected Steps per Second: 22,447.27646
Overall Steps per Second: 10,488.17161

Timestep Collection Time: 2.22807
Timestep Consumption Time: 2.54054
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.76861

Cumulative Model Updates: 125,262
Cumulative Timesteps: 1,044,732,884

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1044732884...
Checkpoint 1044732884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,740.82238
Policy Entropy: 3.00640
Value Function Loss: 0.00490

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.10969
Policy Update Magnitude: 0.56810
Value Function Update Magnitude: 0.52426

Collected Steps per Second: 22,065.70680
Overall Steps per Second: 10,599.56749

Timestep Collection Time: 2.26668
Timestep Consumption Time: 2.45200
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.71868

Cumulative Model Updates: 125,268
Cumulative Timesteps: 1,044,782,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,534.23767
Policy Entropy: 3.00143
Value Function Loss: 0.00551

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.11364
Policy Update Magnitude: 0.57543
Value Function Update Magnitude: 0.54013

Collected Steps per Second: 22,084.86474
Overall Steps per Second: 10,484.67530

Timestep Collection Time: 2.26499
Timestep Consumption Time: 2.50597
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.77096

Cumulative Model Updates: 125,274
Cumulative Timesteps: 1,044,832,922

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1044832922...
Checkpoint 1044832922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.14525
Policy Entropy: 3.00974
Value Function Loss: 0.00549

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.58359
Value Function Update Magnitude: 0.53258

Collected Steps per Second: 21,653.37145
Overall Steps per Second: 10,388.01054

Timestep Collection Time: 2.30920
Timestep Consumption Time: 2.50423
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.81343

Cumulative Model Updates: 125,280
Cumulative Timesteps: 1,044,882,924

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.62587
Policy Entropy: 3.00320
Value Function Loss: 0.00548

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.15178
Policy Update Magnitude: 0.58424
Value Function Update Magnitude: 0.55735

Collected Steps per Second: 22,094.73628
Overall Steps per Second: 10,633.81020

Timestep Collection Time: 2.26425
Timestep Consumption Time: 2.44037
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.70462

Cumulative Model Updates: 125,286
Cumulative Timesteps: 1,044,932,952

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1044932952...
Checkpoint 1044932952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,366.66726
Policy Entropy: 3.00733
Value Function Loss: 0.00484

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.14965
Policy Update Magnitude: 0.57035
Value Function Update Magnitude: 0.54820

Collected Steps per Second: 21,629.34648
Overall Steps per Second: 10,344.01534

Timestep Collection Time: 2.31251
Timestep Consumption Time: 2.52295
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.83545

Cumulative Model Updates: 125,292
Cumulative Timesteps: 1,044,982,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,071.32597
Policy Entropy: 3.01777
Value Function Loss: 0.00474

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.13945
Policy Update Magnitude: 0.55759
Value Function Update Magnitude: 0.54530

Collected Steps per Second: 22,035.68731
Overall Steps per Second: 10,500.41506

Timestep Collection Time: 2.26914
Timestep Consumption Time: 2.49277
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.76191

Cumulative Model Updates: 125,298
Cumulative Timesteps: 1,045,032,972

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1045032972...
Checkpoint 1045032972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,777.07686
Policy Entropy: 3.04011
Value Function Loss: 0.00483

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.11523
Policy Update Magnitude: 0.55875
Value Function Update Magnitude: 0.53929

Collected Steps per Second: 21,827.16687
Overall Steps per Second: 10,614.61206

Timestep Collection Time: 2.29100
Timestep Consumption Time: 2.42005
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.71105

Cumulative Model Updates: 125,304
Cumulative Timesteps: 1,045,082,978

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 848.83043
Policy Entropy: 3.05195
Value Function Loss: 0.00486

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.55522
Value Function Update Magnitude: 0.54129

Collected Steps per Second: 22,585.54744
Overall Steps per Second: 10,501.02339

Timestep Collection Time: 2.21398
Timestep Consumption Time: 2.54784
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.76182

Cumulative Model Updates: 125,310
Cumulative Timesteps: 1,045,132,982

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1045132982...
Checkpoint 1045132982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.58647
Policy Entropy: 3.04820
Value Function Loss: 0.00486

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10030
Policy Update Magnitude: 0.54505
Value Function Update Magnitude: 0.52842

Collected Steps per Second: 22,187.24373
Overall Steps per Second: 10,514.96796

Timestep Collection Time: 2.25472
Timestep Consumption Time: 2.50288
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.75760

Cumulative Model Updates: 125,316
Cumulative Timesteps: 1,045,183,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384.70565
Policy Entropy: 3.02221
Value Function Loss: 0.00524

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.55864
Value Function Update Magnitude: 0.52426

Collected Steps per Second: 22,413.90817
Overall Steps per Second: 10,553.99015

Timestep Collection Time: 2.23111
Timestep Consumption Time: 2.50719
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.73830

Cumulative Model Updates: 125,322
Cumulative Timesteps: 1,045,233,016

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1045233016...
Checkpoint 1045233016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.15440
Policy Entropy: 3.00538
Value Function Loss: 0.00531

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.12113
Policy Update Magnitude: 0.56742
Value Function Update Magnitude: 0.54207

Collected Steps per Second: 22,043.15629
Overall Steps per Second: 10,610.88827

Timestep Collection Time: 2.26855
Timestep Consumption Time: 2.44416
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.71271

Cumulative Model Updates: 125,328
Cumulative Timesteps: 1,045,283,022

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.57274
Policy Entropy: 3.00999
Value Function Loss: 0.00542

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.11743
Policy Update Magnitude: 0.57429
Value Function Update Magnitude: 0.56570

Collected Steps per Second: 22,403.78260
Overall Steps per Second: 10,758.16469

Timestep Collection Time: 2.23203
Timestep Consumption Time: 2.41616
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.64819

Cumulative Model Updates: 125,334
Cumulative Timesteps: 1,045,333,028

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1045333028...
Checkpoint 1045333028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302.17552
Policy Entropy: 3.03112
Value Function Loss: 0.00486

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.10140
Policy Update Magnitude: 0.57253
Value Function Update Magnitude: 0.57081

Collected Steps per Second: 21,672.41253
Overall Steps per Second: 10,465.97920

Timestep Collection Time: 2.30810
Timestep Consumption Time: 2.47139
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.77949

Cumulative Model Updates: 125,340
Cumulative Timesteps: 1,045,383,050

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,848.67383
Policy Entropy: 3.02944
Value Function Loss: 0.00485

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.56209
Value Function Update Magnitude: 0.55755

Collected Steps per Second: 22,447.83658
Overall Steps per Second: 10,667.69453

Timestep Collection Time: 2.22810
Timestep Consumption Time: 2.46045
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.68855

Cumulative Model Updates: 125,346
Cumulative Timesteps: 1,045,433,066

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1045433066...
Checkpoint 1045433066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,530.07192
Policy Entropy: 3.02209
Value Function Loss: 0.00459

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.55418
Value Function Update Magnitude: 0.54768

Collected Steps per Second: 21,747.39468
Overall Steps per Second: 10,413.61912

Timestep Collection Time: 2.29959
Timestep Consumption Time: 2.50278
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.80237

Cumulative Model Updates: 125,352
Cumulative Timesteps: 1,045,483,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,668.38034
Policy Entropy: 3.02493
Value Function Loss: 0.00458

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08905
Policy Update Magnitude: 0.54662
Value Function Update Magnitude: 0.53272

Collected Steps per Second: 22,199.15820
Overall Steps per Second: 10,691.90530

Timestep Collection Time: 2.25315
Timestep Consumption Time: 2.42497
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.67812

Cumulative Model Updates: 125,358
Cumulative Timesteps: 1,045,533,094

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1045533094...
Checkpoint 1045533094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,783.97313
Policy Entropy: 3.02830
Value Function Loss: 0.00450

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.54081
Value Function Update Magnitude: 0.52637

Collected Steps per Second: 21,616.00473
Overall Steps per Second: 10,353.36769

Timestep Collection Time: 2.31310
Timestep Consumption Time: 2.51625
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.82935

Cumulative Model Updates: 125,364
Cumulative Timesteps: 1,045,583,094

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,399.22481
Policy Entropy: 3.01983
Value Function Loss: 0.00466

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.09987
Policy Update Magnitude: 0.54799
Value Function Update Magnitude: 0.53679

Collected Steps per Second: 22,036.05635
Overall Steps per Second: 10,418.85562

Timestep Collection Time: 2.26955
Timestep Consumption Time: 2.53059
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.80014

Cumulative Model Updates: 125,370
Cumulative Timesteps: 1,045,633,106

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1045633106...
Checkpoint 1045633106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,385.59902
Policy Entropy: 3.00729
Value Function Loss: 0.00483

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11229
Policy Update Magnitude: 0.55873
Value Function Update Magnitude: 0.52526

Collected Steps per Second: 21,416.37760
Overall Steps per Second: 10,325.67574

Timestep Collection Time: 2.33578
Timestep Consumption Time: 2.50884
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.84462

Cumulative Model Updates: 125,376
Cumulative Timesteps: 1,045,683,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,627.44282
Policy Entropy: 3.01830
Value Function Loss: 0.00463

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10474
Policy Update Magnitude: 0.56074
Value Function Update Magnitude: 0.51039

Collected Steps per Second: 22,025.44638
Overall Steps per Second: 10,408.37171

Timestep Collection Time: 2.27119
Timestep Consumption Time: 2.53494
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.80613

Cumulative Model Updates: 125,382
Cumulative Timesteps: 1,045,733,154

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1045733154...
Checkpoint 1045733154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.52922
Policy Entropy: 3.02034
Value Function Loss: 0.00489

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.09971
Policy Update Magnitude: 0.56519
Value Function Update Magnitude: 0.51064

Collected Steps per Second: 22,029.67987
Overall Steps per Second: 10,562.46398

Timestep Collection Time: 2.27103
Timestep Consumption Time: 2.46556
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.73658

Cumulative Model Updates: 125,388
Cumulative Timesteps: 1,045,783,184

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,082.33005
Policy Entropy: 3.01920
Value Function Loss: 0.00495

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09248
Policy Update Magnitude: 0.57036
Value Function Update Magnitude: 0.51778

Collected Steps per Second: 22,307.72038
Overall Steps per Second: 10,500.59360

Timestep Collection Time: 2.24156
Timestep Consumption Time: 2.52046
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.76202

Cumulative Model Updates: 125,394
Cumulative Timesteps: 1,045,833,188

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1045833188...
Checkpoint 1045833188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,073.36588
Policy Entropy: 3.00479
Value Function Loss: 0.00505

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.09420
Policy Update Magnitude: 0.57432
Value Function Update Magnitude: 0.51447

Collected Steps per Second: 21,474.18447
Overall Steps per Second: 10,482.57583

Timestep Collection Time: 2.32856
Timestep Consumption Time: 2.44164
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.77020

Cumulative Model Updates: 125,400
Cumulative Timesteps: 1,045,883,192

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,019.03720
Policy Entropy: 3.00762
Value Function Loss: 0.00499

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.57156
Value Function Update Magnitude: 0.51298

Collected Steps per Second: 22,517.21409
Overall Steps per Second: 10,510.13059

Timestep Collection Time: 2.22194
Timestep Consumption Time: 2.53841
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.76036

Cumulative Model Updates: 125,406
Cumulative Timesteps: 1,045,933,224

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1045933224...
Checkpoint 1045933224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 969.36426
Policy Entropy: 3.01186
Value Function Loss: 0.00487

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10289
Policy Update Magnitude: 0.56243
Value Function Update Magnitude: 0.51250

Collected Steps per Second: 22,015.41484
Overall Steps per Second: 10,582.74281

Timestep Collection Time: 2.27304
Timestep Consumption Time: 2.45560
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.72864

Cumulative Model Updates: 125,412
Cumulative Timesteps: 1,045,983,266

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.78925
Policy Entropy: 3.02661
Value Function Loss: 0.00476

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10044
Policy Update Magnitude: 0.55312
Value Function Update Magnitude: 0.50894

Collected Steps per Second: 22,330.49834
Overall Steps per Second: 10,498.56047

Timestep Collection Time: 2.23909
Timestep Consumption Time: 2.52347
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.76256

Cumulative Model Updates: 125,418
Cumulative Timesteps: 1,046,033,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1046033266...
Checkpoint 1046033266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,979.44672
Policy Entropy: 3.02452
Value Function Loss: 0.00473

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.55299
Value Function Update Magnitude: 0.50718

Collected Steps per Second: 21,706.01312
Overall Steps per Second: 10,403.15946

Timestep Collection Time: 2.30406
Timestep Consumption Time: 2.50332
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.80739

Cumulative Model Updates: 125,424
Cumulative Timesteps: 1,046,083,278

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653.79147
Policy Entropy: 3.01810
Value Function Loss: 0.00481

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09778
Policy Update Magnitude: 0.55262
Value Function Update Magnitude: 0.50060

Collected Steps per Second: 22,427.61261
Overall Steps per Second: 10,665.41379

Timestep Collection Time: 2.23002
Timestep Consumption Time: 2.45934
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.68936

Cumulative Model Updates: 125,430
Cumulative Timesteps: 1,046,133,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1046133292...
Checkpoint 1046133292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,716.61362
Policy Entropy: 3.00937
Value Function Loss: 0.00508

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10704
Policy Update Magnitude: 0.55609
Value Function Update Magnitude: 0.50345

Collected Steps per Second: 11,686.59714
Overall Steps per Second: 6,439.76352

Timestep Collection Time: 4.27995
Timestep Consumption Time: 3.48711
PPO Batch Consumption Time: 0.34557
Total Iteration Time: 7.76706

Cumulative Model Updates: 125,436
Cumulative Timesteps: 1,046,183,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,751.11335
Policy Entropy: 3.01390
Value Function Loss: 0.00492

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09096
Policy Update Magnitude: 0.55640
Value Function Update Magnitude: 0.50966

Collected Steps per Second: 18,423.01727
Overall Steps per Second: 9,437.33271

Timestep Collection Time: 2.71552
Timestep Consumption Time: 2.58556
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 5.30107

Cumulative Model Updates: 125,442
Cumulative Timesteps: 1,046,233,338

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1046233338...
Checkpoint 1046233338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,443.25560
Policy Entropy: 3.01921
Value Function Loss: 0.00469

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.55239
Value Function Update Magnitude: 0.50555

Collected Steps per Second: 21,797.78258
Overall Steps per Second: 10,571.84394

Timestep Collection Time: 2.29381
Timestep Consumption Time: 2.43573
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.72954

Cumulative Model Updates: 125,448
Cumulative Timesteps: 1,046,283,338

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,366.82780
Policy Entropy: 3.02899
Value Function Loss: 0.00474

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09409
Policy Update Magnitude: 0.55392
Value Function Update Magnitude: 0.50598

Collected Steps per Second: 22,003.77811
Overall Steps per Second: 10,554.13715

Timestep Collection Time: 2.27288
Timestep Consumption Time: 2.46573
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.73862

Cumulative Model Updates: 125,454
Cumulative Timesteps: 1,046,333,350

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1046333350...
Checkpoint 1046333350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,803.61077
Policy Entropy: 3.03860
Value Function Loss: 0.00473

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09055
Policy Update Magnitude: 0.56017
Value Function Update Magnitude: 0.51001

Collected Steps per Second: 21,776.62963
Overall Steps per Second: 10,381.59051

Timestep Collection Time: 2.29622
Timestep Consumption Time: 2.52038
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.81660

Cumulative Model Updates: 125,460
Cumulative Timesteps: 1,046,383,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,726.93207
Policy Entropy: 3.03800
Value Function Loss: 0.00490

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09465
Policy Update Magnitude: 0.55831
Value Function Update Magnitude: 0.50448

Collected Steps per Second: 22,343.53518
Overall Steps per Second: 10,696.76398

Timestep Collection Time: 2.23895
Timestep Consumption Time: 2.43779
PPO Batch Consumption Time: 0.28172
Total Iteration Time: 4.67674

Cumulative Model Updates: 125,466
Cumulative Timesteps: 1,046,433,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1046433380...
Checkpoint 1046433380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,092.93127
Policy Entropy: 3.04121
Value Function Loss: 0.00469

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.09556
Policy Update Magnitude: 0.54905
Value Function Update Magnitude: 0.49706

Collected Steps per Second: 21,883.39359
Overall Steps per Second: 10,545.45937

Timestep Collection Time: 2.28593
Timestep Consumption Time: 2.45772
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.74365

Cumulative Model Updates: 125,472
Cumulative Timesteps: 1,046,483,404

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391.16759
Policy Entropy: 3.03148
Value Function Loss: 0.00465

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.54956
Value Function Update Magnitude: 0.49776

Collected Steps per Second: 22,009.63191
Overall Steps per Second: 10,517.77622

Timestep Collection Time: 2.27255
Timestep Consumption Time: 2.48302
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.75557

Cumulative Model Updates: 125,478
Cumulative Timesteps: 1,046,533,422

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1046533422...
Checkpoint 1046533422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.85385
Policy Entropy: 3.03280
Value Function Loss: 0.00483

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.55257
Value Function Update Magnitude: 0.50667

Collected Steps per Second: 22,001.90686
Overall Steps per Second: 10,616.74362

Timestep Collection Time: 2.27253
Timestep Consumption Time: 2.43701
PPO Batch Consumption Time: 0.28183
Total Iteration Time: 4.70954

Cumulative Model Updates: 125,484
Cumulative Timesteps: 1,046,583,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,665.51608
Policy Entropy: 3.00596
Value Function Loss: 0.00506

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.09763
Policy Update Magnitude: 0.56741
Value Function Update Magnitude: 0.53990

Collected Steps per Second: 22,139.25166
Overall Steps per Second: 10,546.73979

Timestep Collection Time: 2.25952
Timestep Consumption Time: 2.48356
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.74308

Cumulative Model Updates: 125,490
Cumulative Timesteps: 1,046,633,446

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1046633446...
Checkpoint 1046633446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.55948
Policy Entropy: 3.02570
Value Function Loss: 0.00497

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10511
Policy Update Magnitude: 0.57172
Value Function Update Magnitude: 0.56628

Collected Steps per Second: 21,819.27413
Overall Steps per Second: 10,540.94824

Timestep Collection Time: 2.29238
Timestep Consumption Time: 2.45274
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.74511

Cumulative Model Updates: 125,496
Cumulative Timesteps: 1,046,683,464

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,527.29623
Policy Entropy: 3.02773
Value Function Loss: 0.00477

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11313
Policy Update Magnitude: 0.57068
Value Function Update Magnitude: 0.54518

Collected Steps per Second: 21,978.64399
Overall Steps per Second: 10,546.69088

Timestep Collection Time: 2.27548
Timestep Consumption Time: 2.46648
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.74196

Cumulative Model Updates: 125,502
Cumulative Timesteps: 1,046,733,476

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1046733476...
Checkpoint 1046733476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485.65662
Policy Entropy: 3.03505
Value Function Loss: 0.00481

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.12083
Policy Update Magnitude: 0.56661
Value Function Update Magnitude: 0.51748

Collected Steps per Second: 17,240.13153
Overall Steps per Second: 9,143.41045

Timestep Collection Time: 2.90033
Timestep Consumption Time: 2.56831
PPO Batch Consumption Time: 0.30582
Total Iteration Time: 5.46864

Cumulative Model Updates: 125,508
Cumulative Timesteps: 1,046,783,478

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1046783478...
Checkpoint 1046783478 saved!
