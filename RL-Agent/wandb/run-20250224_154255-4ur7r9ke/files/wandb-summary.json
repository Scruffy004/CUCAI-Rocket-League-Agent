{"Cumulative Timesteps":5701800,"PPO Batch Consumption Time":0.3232777913411458,"Mean KL Divergence":0.004173935817865034,"Policy Entropy":4.164445082346599,"Policy Update Magnitude":0.691881537437439,"_runtime":563.9182815,"Overall Steps per Second":9710.56518969397,"_step":227,"z_vel":-31.195565064105427,"SB3 Clip Fraction":0.041463332871596016,"Total Iteration Time":5.149442799999974,"Timestep Consumption Time":2.734306399999923,"Policy Reward":95.9625576200739,"y_vel":165.8965852574404,"_wandb":{"runtime":564},"Collected Steps per Second":20704.420669573337,"Value Function Loss":1.7002940972646077,"Timesteps Collected":50004,"Timestep Collection Time":2.4151364000000513,"Cumulative Model Updates":678,"Value Function Update Magnitude":0.4991200268268585,"x_vel":93.51528458430042,"_timestamp":1.7404303390959077e+09}