{"PPO Batch Consumption Time":0.3306279182434082,"x_vel":13.174153683815897,"Timestep Consumption Time":1.3959361000000001,"Cumulative Model Updates":75,"Policy Reward":0.012418704889940489,"_step":153,"Timestep Collection Time":2.4784539000000017,"Value Function Update Magnitude":0.04395988583564758,"Value Function Loss":0.04887521453201771,"Policy Entropy":0.7052987515926361,"y_vel":427.49623690671564,"Policy Update Magnitude":0.03642468899488449,"_timestamp":1.732470242988281e+09,"Cumulative Timesteps":1350680,"Timesteps Collected":50030,"_runtime":304.9221071,"SB3 Clip Fraction":0,"Overall Steps per Second":12913.000498142928,"Total Iteration Time":3.8743900000000018,"z_vel":18.485311843550743,"Mean KL Divergence":0.00018893661945185158,"Collected Steps per Second":20185.971584946554,"_wandb":{"runtime":304}}