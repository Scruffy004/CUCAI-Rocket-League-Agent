{"Policy Update Magnitude":0.031872451305389404,"Policy Entropy":1.1584107081095378,"y_vel":16.24129853213227,"Overall Steps per Second":15914.666431780219,"Mean KL Divergence":0.0018842138815671206,"Cumulative Timesteps":423246902,"PPO Batch Consumption Time":0.07713556289672852,"_runtime":33717.1362831,"Policy Reward":13239.247014789891,"x_vel":-11.391236685925259,"_wandb":{"runtime":33717},"_step":16923,"SB3 Clip Fraction":0.0182666660596927,"Value Function Loss":0.057677811632553734,"Timestep Consumption Time":0.8839393999996901,"Total Iteration Time":3.1425100999999813,"Collected Steps per Second":22143.207648976208,"z_vel":0.5028529187002188,"Cumulative Model Updates":25348,"Timesteps Collected":50012,"Timestep Collection Time":2.2585707000002913,"_timestamp":1.737098069850033e+09,"Value Function Update Magnitude":0.046808451414108276}