Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,393.75190
Policy Entropy: 0.88748
Value Function Loss: 0.10525

Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.01264
Value Function Update Magnitude: 0.01999

Collected Steps per Second: 20,101.89520
Overall Steps per Second: 15,927.62798

Timestep Collection Time: 2.48822
Timestep Consumption Time: 0.65211
PPO Batch Consumption Time: 0.12445
Total Iteration Time: 3.14033

Cumulative Model Updates: 23,235
Cumulative Timesteps: 387,983,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,064.40695
Policy Entropy: 0.90022
Value Function Loss: 0.08791

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01957
Policy Update Magnitude: 0.02593
Value Function Update Magnitude: 0.04153

Collected Steps per Second: 20,727.65095
Overall Steps per Second: 15,545.13619

Timestep Collection Time: 2.41301
Timestep Consumption Time: 0.80446
PPO Batch Consumption Time: 0.09266
Total Iteration Time: 3.21747

Cumulative Model Updates: 23,237
Cumulative Timesteps: 388,033,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 388033764...
Checkpoint 388033764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,600.04476
Policy Entropy: 0.90984
Value Function Loss: 0.08554

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03029
Policy Update Magnitude: 0.02640
Value Function Update Magnitude: 0.03315

Collected Steps per Second: 17,375.52703
Overall Steps per Second: 13,993.77968

Timestep Collection Time: 2.87876
Timestep Consumption Time: 0.69568
PPO Batch Consumption Time: 0.06179
Total Iteration Time: 3.57445

Cumulative Model Updates: 23,239
Cumulative Timesteps: 388,083,784

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,806.51810
Policy Entropy: 0.92463
Value Function Loss: 0.05836

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02843
Policy Update Magnitude: 0.03612
Value Function Update Magnitude: 0.04455

Collected Steps per Second: 19,186.49742
Overall Steps per Second: 14,056.97303

Timestep Collection Time: 2.60715
Timestep Consumption Time: 0.95137
PPO Batch Consumption Time: 0.12465
Total Iteration Time: 3.55852

Cumulative Model Updates: 23,242
Cumulative Timesteps: 388,133,806

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 388133806...
Checkpoint 388133806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,436.11560
Policy Entropy: 0.93389
Value Function Loss: 0.05474

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02891
Policy Update Magnitude: 0.03455
Value Function Update Magnitude: 0.04469

Collected Steps per Second: 21,106.09869
Overall Steps per Second: 16,087.01283

Timestep Collection Time: 2.36927
Timestep Consumption Time: 0.73920
PPO Batch Consumption Time: 0.06080
Total Iteration Time: 3.10847

Cumulative Model Updates: 23,245
Cumulative Timesteps: 388,183,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,031.85180
Policy Entropy: 0.92383
Value Function Loss: 0.05541

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01722
Policy Update Magnitude: 0.03182
Value Function Update Magnitude: 0.04833

Collected Steps per Second: 22,352.16262
Overall Steps per Second: 16,296.87436

Timestep Collection Time: 2.23853
Timestep Consumption Time: 0.83175
PPO Batch Consumption Time: 0.09935
Total Iteration Time: 3.07028

Cumulative Model Updates: 23,248
Cumulative Timesteps: 388,233,848

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 388233848...
Checkpoint 388233848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,148.44295
Policy Entropy: 0.91274
Value Function Loss: 0.06091

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01646
Policy Update Magnitude: 0.03258
Value Function Update Magnitude: 0.05074

Collected Steps per Second: 21,487.46509
Overall Steps per Second: 16,330.16642

Timestep Collection Time: 2.32712
Timestep Consumption Time: 0.73494
PPO Batch Consumption Time: 0.06347
Total Iteration Time: 3.06206

Cumulative Model Updates: 23,251
Cumulative Timesteps: 388,283,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,465.81224
Policy Entropy: 0.91083
Value Function Loss: 0.05519

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01144
Policy Update Magnitude: 0.03262
Value Function Update Magnitude: 0.04561

Collected Steps per Second: 19,472.32264
Overall Steps per Second: 14,278.93736

Timestep Collection Time: 2.56877
Timestep Consumption Time: 0.93429
PPO Batch Consumption Time: 0.12316
Total Iteration Time: 3.50306

Cumulative Model Updates: 23,254
Cumulative Timesteps: 388,333,872

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 388333872...
Checkpoint 388333872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,749.83326
Policy Entropy: 0.91400
Value Function Loss: 0.05432

Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.01258
Policy Update Magnitude: 0.03170
Value Function Update Magnitude: 0.04487

Collected Steps per Second: 21,672.56521
Overall Steps per Second: 16,349.35004

Timestep Collection Time: 2.30882
Timestep Consumption Time: 0.75173
PPO Batch Consumption Time: 0.06452
Total Iteration Time: 3.06055

Cumulative Model Updates: 23,257
Cumulative Timesteps: 388,383,910

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,333.74367
Policy Entropy: 0.90932
Value Function Loss: 0.04948

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02305
Policy Update Magnitude: 0.03015
Value Function Update Magnitude: 0.05058

Collected Steps per Second: 18,114.59475
Overall Steps per Second: 13,439.37303

Timestep Collection Time: 2.76054
Timestep Consumption Time: 0.96032
PPO Batch Consumption Time: 0.11542
Total Iteration Time: 3.72086

Cumulative Model Updates: 23,260
Cumulative Timesteps: 388,433,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 388433916...
Checkpoint 388433916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,441.80897
Policy Entropy: 0.89716
Value Function Loss: 0.05895

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01795
Policy Update Magnitude: 0.03251
Value Function Update Magnitude: 0.04865

Collected Steps per Second: 21,651.15906
Overall Steps per Second: 15,698.58565

Timestep Collection Time: 2.31036
Timestep Consumption Time: 0.87604
PPO Batch Consumption Time: 0.10441
Total Iteration Time: 3.18640

Cumulative Model Updates: 23,263
Cumulative Timesteps: 388,483,938

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,048.58096
Policy Entropy: 0.90295
Value Function Loss: 0.06163

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02646
Policy Update Magnitude: 0.03441
Value Function Update Magnitude: 0.04555

Collected Steps per Second: 22,241.71549
Overall Steps per Second: 16,893.42638

Timestep Collection Time: 2.24830
Timestep Consumption Time: 0.71179
PPO Batch Consumption Time: 0.06205
Total Iteration Time: 2.96009

Cumulative Model Updates: 23,266
Cumulative Timesteps: 388,533,944

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 388533944...
Checkpoint 388533944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,490.13160
Policy Entropy: 0.90998
Value Function Loss: 0.06001

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02675
Policy Update Magnitude: 0.03250
Value Function Update Magnitude: 0.04602

Collected Steps per Second: 20,372.70961
Overall Steps per Second: 15,465.61991

Timestep Collection Time: 2.45466
Timestep Consumption Time: 0.77884
PPO Batch Consumption Time: 0.07768
Total Iteration Time: 3.23349

Cumulative Model Updates: 23,269
Cumulative Timesteps: 388,583,952

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,893.50381
Policy Entropy: 0.93661
Value Function Loss: 0.05139

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02137
Policy Update Magnitude: 0.03134
Value Function Update Magnitude: 0.04537

Collected Steps per Second: 22,078.49877
Overall Steps per Second: 16,701.15681

Timestep Collection Time: 2.26483
Timestep Consumption Time: 0.72922
PPO Batch Consumption Time: 0.06069
Total Iteration Time: 2.99404

Cumulative Model Updates: 23,272
Cumulative Timesteps: 388,633,956

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 388633956...
Checkpoint 388633956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,327.67500
Policy Entropy: 0.93736
Value Function Loss: 0.04963

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01789
Policy Update Magnitude: 0.03156
Value Function Update Magnitude: 0.04064

Collected Steps per Second: 18,758.38620
Overall Steps per Second: 13,926.68687

Timestep Collection Time: 2.66718
Timestep Consumption Time: 0.92535
PPO Batch Consumption Time: 0.12041
Total Iteration Time: 3.59253

Cumulative Model Updates: 23,275
Cumulative Timesteps: 388,683,988

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,062.23524
Policy Entropy: 0.93936
Value Function Loss: 0.05002

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01876
Policy Update Magnitude: 0.03212
Value Function Update Magnitude: 0.04072

Collected Steps per Second: 22,185.28026
Overall Steps per Second: 16,715.43170

Timestep Collection Time: 2.25483
Timestep Consumption Time: 0.73786
PPO Batch Consumption Time: 0.06096
Total Iteration Time: 2.99268

Cumulative Model Updates: 23,278
Cumulative Timesteps: 388,734,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 388734012...
Checkpoint 388734012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,467.57847
Policy Entropy: 0.93345
Value Function Loss: 0.05026

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02173
Policy Update Magnitude: 0.03271
Value Function Update Magnitude: 0.04122

Collected Steps per Second: 19,843.82907
Overall Steps per Second: 14,931.40077

Timestep Collection Time: 2.52199
Timestep Consumption Time: 0.82974
PPO Batch Consumption Time: 0.09066
Total Iteration Time: 3.35173

Cumulative Model Updates: 23,281
Cumulative Timesteps: 388,784,058

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,619.00936
Policy Entropy: 0.93737
Value Function Loss: 0.04395

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02547
Policy Update Magnitude: 0.03437
Value Function Update Magnitude: 0.04142

Collected Steps per Second: 21,920.37230
Overall Steps per Second: 16,691.80432

Timestep Collection Time: 2.28317
Timestep Consumption Time: 0.71518
PPO Batch Consumption Time: 0.06005
Total Iteration Time: 2.99836

Cumulative Model Updates: 23,284
Cumulative Timesteps: 388,834,106

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 388834106...
Checkpoint 388834106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,359.59412
Policy Entropy: 0.95608
Value Function Loss: 0.04171

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02215
Policy Update Magnitude: 0.03317
Value Function Update Magnitude: 0.04001

Collected Steps per Second: 19,586.39821
Overall Steps per Second: 14,043.78062

Timestep Collection Time: 2.55483
Timestep Consumption Time: 1.00831
PPO Batch Consumption Time: 0.12521
Total Iteration Time: 3.56314

Cumulative Model Updates: 23,287
Cumulative Timesteps: 388,884,146

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,254.04148
Policy Entropy: 0.95881
Value Function Loss: 0.03665

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02467
Policy Update Magnitude: 0.03167
Value Function Update Magnitude: 0.03494

Collected Steps per Second: 22,398.51889
Overall Steps per Second: 16,534.26538

Timestep Collection Time: 2.23292
Timestep Consumption Time: 0.79195
PPO Batch Consumption Time: 0.06062
Total Iteration Time: 3.02487

Cumulative Model Updates: 23,290
Cumulative Timesteps: 388,934,160

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 388934160...
Checkpoint 388934160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,603.32095
Policy Entropy: 0.95224
Value Function Loss: 0.03932

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03735
Policy Update Magnitude: 0.02869
Value Function Update Magnitude: 0.03342

Collected Steps per Second: 19,431.95969
Overall Steps per Second: 14,088.83552

Timestep Collection Time: 2.57318
Timestep Consumption Time: 0.97587
PPO Batch Consumption Time: 0.11932
Total Iteration Time: 3.54905

Cumulative Model Updates: 23,293
Cumulative Timesteps: 388,984,162

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,530.85485
Policy Entropy: 0.94438
Value Function Loss: 0.04037

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03209
Policy Update Magnitude: 0.02527
Value Function Update Magnitude: 0.03749

Collected Steps per Second: 22,561.93109
Overall Steps per Second: 16,595.40865

Timestep Collection Time: 2.21719
Timestep Consumption Time: 0.79714
PPO Batch Consumption Time: 0.05980
Total Iteration Time: 3.01433

Cumulative Model Updates: 23,296
Cumulative Timesteps: 389,034,186

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 389034186...
Checkpoint 389034186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,974.79048
Policy Entropy: 0.94546
Value Function Loss: 0.04695

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02382
Policy Update Magnitude: 0.02415
Value Function Update Magnitude: 0.03954

Collected Steps per Second: 19,566.84030
Overall Steps per Second: 14,053.31670

Timestep Collection Time: 2.55688
Timestep Consumption Time: 1.00314
PPO Batch Consumption Time: 0.11870
Total Iteration Time: 3.56001

Cumulative Model Updates: 23,299
Cumulative Timesteps: 389,084,216

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,964.77090
Policy Entropy: 0.93709
Value Function Loss: 0.04294

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.01986
Policy Update Magnitude: 0.02522
Value Function Update Magnitude: 0.03822

Collected Steps per Second: 22,541.66389
Overall Steps per Second: 16,358.40700

Timestep Collection Time: 2.21820
Timestep Consumption Time: 0.83845
PPO Batch Consumption Time: 0.06524
Total Iteration Time: 3.05665

Cumulative Model Updates: 23,302
Cumulative Timesteps: 389,134,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 389134218...
Checkpoint 389134218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,766.40310
Policy Entropy: 0.93776
Value Function Loss: 0.04415

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01853
Policy Update Magnitude: 0.02827
Value Function Update Magnitude: 0.03715

Collected Steps per Second: 20,186.45401
Overall Steps per Second: 14,241.75378

Timestep Collection Time: 2.47701
Timestep Consumption Time: 1.03394
PPO Batch Consumption Time: 0.12818
Total Iteration Time: 3.51094

Cumulative Model Updates: 23,305
Cumulative Timesteps: 389,184,220

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,700.13453
Policy Entropy: 0.91996
Value Function Loss: 0.04530

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02687
Policy Update Magnitude: 0.02837
Value Function Update Magnitude: 0.03582

Collected Steps per Second: 22,880.14798
Overall Steps per Second: 16,434.78917

Timestep Collection Time: 2.18565
Timestep Consumption Time: 0.85716
PPO Batch Consumption Time: 0.07879
Total Iteration Time: 3.04281

Cumulative Model Updates: 23,308
Cumulative Timesteps: 389,234,228

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 389234228...
Checkpoint 389234228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,446.48424
Policy Entropy: 0.92941
Value Function Loss: 0.05290

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01719
Policy Update Magnitude: 0.03213
Value Function Update Magnitude: 0.04341

Collected Steps per Second: 19,278.33100
Overall Steps per Second: 14,149.75331

Timestep Collection Time: 2.59379
Timestep Consumption Time: 0.94012
PPO Batch Consumption Time: 0.10618
Total Iteration Time: 3.53391

Cumulative Model Updates: 23,311
Cumulative Timesteps: 389,284,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,683.45332
Policy Entropy: 0.93653
Value Function Loss: 0.05304

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01257
Policy Update Magnitude: 0.03258
Value Function Update Magnitude: 0.04488

Collected Steps per Second: 23,104.13904
Overall Steps per Second: 16,856.50803

Timestep Collection Time: 2.16411
Timestep Consumption Time: 0.80210
PPO Batch Consumption Time: 0.06161
Total Iteration Time: 2.96621

Cumulative Model Updates: 23,314
Cumulative Timesteps: 389,334,232

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 389334232...
Checkpoint 389334232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,260.75753
Policy Entropy: 0.94052
Value Function Loss: 0.04512

Mean KL Divergence: 0.00143
SB3 Clip Fraction: 0.01366
Policy Update Magnitude: 0.03035
Value Function Update Magnitude: 0.04443

Collected Steps per Second: 20,268.83179
Overall Steps per Second: 14,645.59917

Timestep Collection Time: 2.46694
Timestep Consumption Time: 0.94719
PPO Batch Consumption Time: 0.10154
Total Iteration Time: 3.41413

Cumulative Model Updates: 23,317
Cumulative Timesteps: 389,384,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,884.45399
Policy Entropy: 0.94431
Value Function Loss: 0.04294

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02129
Policy Update Magnitude: 0.03758
Value Function Update Magnitude: 0.04244

Collected Steps per Second: 22,450.51380
Overall Steps per Second: 15,711.19595

Timestep Collection Time: 2.22783
Timestep Consumption Time: 0.95563
PPO Batch Consumption Time: 0.10727
Total Iteration Time: 3.18346

Cumulative Model Updates: 23,320
Cumulative Timesteps: 389,434,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 389434250...
Checkpoint 389434250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,189.97287
Policy Entropy: 0.94353
Value Function Loss: 0.03992

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03295
Policy Update Magnitude: 0.03294
Value Function Update Magnitude: 0.04676

Collected Steps per Second: 22,779.60656
Overall Steps per Second: 16,621.76002

Timestep Collection Time: 2.19591
Timestep Consumption Time: 0.81352
PPO Batch Consumption Time: 0.05936
Total Iteration Time: 3.00943

Cumulative Model Updates: 23,323
Cumulative Timesteps: 389,484,272

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,829.71703
Policy Entropy: 0.95353
Value Function Loss: 0.04006

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02966
Policy Update Magnitude: 0.03147
Value Function Update Magnitude: 0.05407

Collected Steps per Second: 20,167.32040
Overall Steps per Second: 14,800.47302

Timestep Collection Time: 2.48085
Timestep Consumption Time: 0.89959
PPO Batch Consumption Time: 0.08711
Total Iteration Time: 3.38043

Cumulative Model Updates: 23,326
Cumulative Timesteps: 389,534,304

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 389534304...
Checkpoint 389534304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,400.12490
Policy Entropy: 0.95444
Value Function Loss: 0.03496

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02229
Policy Update Magnitude: 0.02875
Value Function Update Magnitude: 0.05315

Collected Steps per Second: 22,295.44067
Overall Steps per Second: 15,746.12498

Timestep Collection Time: 2.24306
Timestep Consumption Time: 0.93296
PPO Batch Consumption Time: 0.08838
Total Iteration Time: 3.17602

Cumulative Model Updates: 23,329
Cumulative Timesteps: 389,584,314

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,120.06838
Policy Entropy: 0.94798
Value Function Loss: 0.04239

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01975
Policy Update Magnitude: 0.02556
Value Function Update Magnitude: 0.05213

Collected Steps per Second: 22,951.15251
Overall Steps per Second: 16,698.21612

Timestep Collection Time: 2.17993
Timestep Consumption Time: 0.81631
PPO Batch Consumption Time: 0.06123
Total Iteration Time: 2.99625

Cumulative Model Updates: 23,332
Cumulative Timesteps: 389,634,346

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 389634346...
Checkpoint 389634346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,421.27942
Policy Entropy: 0.93303
Value Function Loss: 0.04748

Mean KL Divergence: 0.00138
SB3 Clip Fraction: 0.00985
Policy Update Magnitude: 0.02640
Value Function Update Magnitude: 0.05384

Collected Steps per Second: 19,928.22874
Overall Steps per Second: 14,731.88577

Timestep Collection Time: 2.51031
Timestep Consumption Time: 0.88546
PPO Batch Consumption Time: 0.08672
Total Iteration Time: 3.39576

Cumulative Model Updates: 23,335
Cumulative Timesteps: 389,684,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,725.75764
Policy Entropy: 0.92249
Value Function Loss: 0.05144

Mean KL Divergence: 0.00168
SB3 Clip Fraction: 0.01526
Policy Update Magnitude: 0.02637
Value Function Update Magnitude: 0.05522

Collected Steps per Second: 22,439.03651
Overall Steps per Second: 15,752.49282

Timestep Collection Time: 2.22924
Timestep Consumption Time: 0.94626
PPO Batch Consumption Time: 0.10040
Total Iteration Time: 3.17550

Cumulative Model Updates: 23,338
Cumulative Timesteps: 389,734,394

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 389734394...
Checkpoint 389734394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,175.12141
Policy Entropy: 0.93312
Value Function Loss: 0.04828

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01324
Policy Update Magnitude: 0.02685
Value Function Update Magnitude: 0.05403

Collected Steps per Second: 22,748.88088
Overall Steps per Second: 16,663.90934

Timestep Collection Time: 2.19835
Timestep Consumption Time: 0.80275
PPO Batch Consumption Time: 0.05976
Total Iteration Time: 3.00110

Cumulative Model Updates: 23,341
Cumulative Timesteps: 389,784,404

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,269.20606
Policy Entropy: 0.92488
Value Function Loss: 0.04877

Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.01129
Policy Update Magnitude: 0.02765
Value Function Update Magnitude: 0.05291

Collected Steps per Second: 20,601.60322
Overall Steps per Second: 14,822.03646

Timestep Collection Time: 2.42835
Timestep Consumption Time: 0.94689
PPO Batch Consumption Time: 0.09646
Total Iteration Time: 3.37524

Cumulative Model Updates: 23,344
Cumulative Timesteps: 389,834,432

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 389834432...
Checkpoint 389834432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,635.39577
Policy Entropy: 0.93006
Value Function Loss: 0.04387

Mean KL Divergence: 0.00139
SB3 Clip Fraction: 0.00987
Policy Update Magnitude: 0.02982
Value Function Update Magnitude: 0.05543

Collected Steps per Second: 22,366.95090
Overall Steps per Second: 15,724.44342

Timestep Collection Time: 2.23625
Timestep Consumption Time: 0.94466
PPO Batch Consumption Time: 0.09832
Total Iteration Time: 3.18091

Cumulative Model Updates: 23,347
Cumulative Timesteps: 389,884,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,779.27338
Policy Entropy: 0.92341
Value Function Loss: 0.04091

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01425
Policy Update Magnitude: 0.03137
Value Function Update Magnitude: 0.05456

Collected Steps per Second: 21,515.01785
Overall Steps per Second: 16,322.52953

Timestep Collection Time: 2.32396
Timestep Consumption Time: 0.73929
PPO Batch Consumption Time: 0.06591
Total Iteration Time: 3.06325

Cumulative Model Updates: 23,350
Cumulative Timesteps: 389,934,450

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 389934450...
Checkpoint 389934450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,044.57736
Policy Entropy: 0.92545
Value Function Loss: 0.04367

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02141
Policy Update Magnitude: 0.03084
Value Function Update Magnitude: 0.05217

Collected Steps per Second: 19,869.82330
Overall Steps per Second: 15,035.89037

Timestep Collection Time: 2.51749
Timestep Consumption Time: 0.80935
PPO Batch Consumption Time: 0.07693
Total Iteration Time: 3.32684

Cumulative Model Updates: 23,353
Cumulative Timesteps: 389,984,472

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,855.03142
Policy Entropy: 0.92496
Value Function Loss: 0.04585

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02530
Policy Update Magnitude: 0.03047
Value Function Update Magnitude: 0.05350

Collected Steps per Second: 22,144.32945
Overall Steps per Second: 15,797.03903

Timestep Collection Time: 2.25909
Timestep Consumption Time: 0.90771
PPO Batch Consumption Time: 0.11767
Total Iteration Time: 3.16680

Cumulative Model Updates: 23,356
Cumulative Timesteps: 390,034,498

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 390034498...
Checkpoint 390034498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,153.84227
Policy Entropy: 0.93981
Value Function Loss: 0.04879

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02299
Policy Update Magnitude: 0.03113
Value Function Update Magnitude: 0.05495

Collected Steps per Second: 21,957.55423
Overall Steps per Second: 16,614.94587

Timestep Collection Time: 2.27858
Timestep Consumption Time: 0.73269
PPO Batch Consumption Time: 0.06164
Total Iteration Time: 3.01126

Cumulative Model Updates: 23,359
Cumulative Timesteps: 390,084,530

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,447.24401
Policy Entropy: 0.93826
Value Function Loss: 0.05058

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04855
Policy Update Magnitude: 0.03272
Value Function Update Magnitude: 0.05347

Collected Steps per Second: 19,114.18839
Overall Steps per Second: 14,061.71526

Timestep Collection Time: 2.61628
Timestep Consumption Time: 0.94005
PPO Batch Consumption Time: 0.12383
Total Iteration Time: 3.55632

Cumulative Model Updates: 23,362
Cumulative Timesteps: 390,134,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 390134538...
Checkpoint 390134538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,614.17709
Policy Entropy: 0.93400
Value Function Loss: 0.05116

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03842
Policy Update Magnitude: 0.03075
Value Function Update Magnitude: 0.05480

Collected Steps per Second: 21,732.06770
Overall Steps per Second: 16,368.45012

Timestep Collection Time: 2.30112
Timestep Consumption Time: 0.75403
PPO Batch Consumption Time: 0.06553
Total Iteration Time: 3.05515

Cumulative Model Updates: 23,365
Cumulative Timesteps: 390,184,546

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,058.47984
Policy Entropy: 0.93774
Value Function Loss: 0.05201

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04958
Policy Update Magnitude: 0.02953
Value Function Update Magnitude: 0.05058

Collected Steps per Second: 19,075.92651
Overall Steps per Second: 14,182.12347

Timestep Collection Time: 2.62142
Timestep Consumption Time: 0.90457
PPO Batch Consumption Time: 0.10978
Total Iteration Time: 3.52599

Cumulative Model Updates: 23,368
Cumulative Timesteps: 390,234,552

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 390234552...
Checkpoint 390234552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,329.48714
Policy Entropy: 0.93144
Value Function Loss: 0.04797

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02928
Policy Update Magnitude: 0.03089
Value Function Update Magnitude: 0.04973

Collected Steps per Second: 21,909.25277
Overall Steps per Second: 16,733.18837

Timestep Collection Time: 2.28415
Timestep Consumption Time: 0.70655
PPO Batch Consumption Time: 0.05890
Total Iteration Time: 2.99070

Cumulative Model Updates: 23,371
Cumulative Timesteps: 390,284,596

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,053.28875
Policy Entropy: 0.93100
Value Function Loss: 0.04649

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03424
Policy Update Magnitude: 0.03152
Value Function Update Magnitude: 0.05078

Collected Steps per Second: 19,954.18348
Overall Steps per Second: 14,738.06786

Timestep Collection Time: 2.50704
Timestep Consumption Time: 0.88730
PPO Batch Consumption Time: 0.09214
Total Iteration Time: 3.39434

Cumulative Model Updates: 23,374
Cumulative Timesteps: 390,334,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 390334622...
Checkpoint 390334622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,364.21316
Policy Entropy: 0.92802
Value Function Loss: 0.04439

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03953
Policy Update Magnitude: 0.03124
Value Function Update Magnitude: 0.05503

Collected Steps per Second: 22,326.65415
Overall Steps per Second: 15,744.42429

Timestep Collection Time: 2.24001
Timestep Consumption Time: 0.93648
PPO Batch Consumption Time: 0.10819
Total Iteration Time: 3.17649

Cumulative Model Updates: 23,377
Cumulative Timesteps: 390,384,634

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,489.69542
Policy Entropy: 0.92682
Value Function Loss: 0.04839

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03221
Policy Update Magnitude: 0.03171
Value Function Update Magnitude: 0.05254

Collected Steps per Second: 23,161.56899
Overall Steps per Second: 16,974.36550

Timestep Collection Time: 2.15944
Timestep Consumption Time: 0.78712
PPO Batch Consumption Time: 0.06367
Total Iteration Time: 2.94656

Cumulative Model Updates: 23,380
Cumulative Timesteps: 390,434,650

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 390434650...
Checkpoint 390434650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,127.55299
Policy Entropy: 0.93458
Value Function Loss: 0.05558

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06589
Policy Update Magnitude: 0.03121
Value Function Update Magnitude: 0.05333

Collected Steps per Second: 22,577.39764
Overall Steps per Second: 16,677.23461

Timestep Collection Time: 2.21469
Timestep Consumption Time: 0.78353
PPO Batch Consumption Time: 0.06064
Total Iteration Time: 2.99822

Cumulative Model Updates: 23,383
Cumulative Timesteps: 390,484,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,554.35297
Policy Entropy: 0.92682
Value Function Loss: 0.05520

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04831
Policy Update Magnitude: 0.02980
Value Function Update Magnitude: 0.05472

Collected Steps per Second: 22,493.17923
Overall Steps per Second: 15,567.35786

Timestep Collection Time: 2.22467
Timestep Consumption Time: 0.98974
PPO Batch Consumption Time: 0.12244
Total Iteration Time: 3.21442

Cumulative Model Updates: 23,386
Cumulative Timesteps: 390,534,692

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 390534692...
Checkpoint 390534692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,156.03298
Policy Entropy: 0.92445
Value Function Loss: 0.05211

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03433
Policy Update Magnitude: 0.03182
Value Function Update Magnitude: 0.05214

Collected Steps per Second: 22,911.42508
Overall Steps per Second: 16,922.98633

Timestep Collection Time: 2.18267
Timestep Consumption Time: 0.77237
PPO Batch Consumption Time: 0.06064
Total Iteration Time: 2.95503

Cumulative Model Updates: 23,389
Cumulative Timesteps: 390,584,700

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,215.74869
Policy Entropy: 0.92445
Value Function Loss: 0.04337

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02645
Policy Update Magnitude: 0.02879
Value Function Update Magnitude: 0.05071

Collected Steps per Second: 23,006.99809
Overall Steps per Second: 16,462.26569

Timestep Collection Time: 2.17412
Timestep Consumption Time: 0.86434
PPO Batch Consumption Time: 0.08591
Total Iteration Time: 3.03846

Cumulative Model Updates: 23,392
Cumulative Timesteps: 390,634,720

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 390634720...
Checkpoint 390634720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,280.94398
Policy Entropy: 0.92410
Value Function Loss: 0.04740

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02304
Policy Update Magnitude: 0.03027
Value Function Update Magnitude: 0.05143

Collected Steps per Second: 22,472.76754
Overall Steps per Second: 16,626.83639

Timestep Collection Time: 2.22509
Timestep Consumption Time: 0.78233
PPO Batch Consumption Time: 0.06063
Total Iteration Time: 3.00743

Cumulative Model Updates: 23,395
Cumulative Timesteps: 390,684,724

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,319.89468
Policy Entropy: 0.92858
Value Function Loss: 0.04735

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.01801
Policy Update Magnitude: 0.03298
Value Function Update Magnitude: 0.05090

Collected Steps per Second: 20,223.76263
Overall Steps per Second: 14,702.14992

Timestep Collection Time: 2.47303
Timestep Consumption Time: 0.92878
PPO Batch Consumption Time: 0.09469
Total Iteration Time: 3.40182

Cumulative Model Updates: 23,398
Cumulative Timesteps: 390,734,738

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 390734738...
Checkpoint 390734738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,472.07508
Policy Entropy: 0.93321
Value Function Loss: 0.04780

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02471
Policy Update Magnitude: 0.03104
Value Function Update Magnitude: 0.05103

Collected Steps per Second: 22,733.01029
Overall Steps per Second: 16,575.48174

Timestep Collection Time: 2.19962
Timestep Consumption Time: 0.81712
PPO Batch Consumption Time: 0.06608
Total Iteration Time: 3.01674

Cumulative Model Updates: 23,401
Cumulative Timesteps: 390,784,742

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,645.53889
Policy Entropy: 0.92574
Value Function Loss: 0.04244

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02351
Policy Update Magnitude: 0.03085
Value Function Update Magnitude: 0.05417

Collected Steps per Second: 20,167.40380
Overall Steps per Second: 14,250.98738

Timestep Collection Time: 2.48064
Timestep Consumption Time: 1.02986
PPO Batch Consumption Time: 0.12571
Total Iteration Time: 3.51049

Cumulative Model Updates: 23,404
Cumulative Timesteps: 390,834,770

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 390834770...
Checkpoint 390834770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,329.34123
Policy Entropy: 0.92527
Value Function Loss: 0.04345

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01909
Policy Update Magnitude: 0.02909
Value Function Update Magnitude: 0.05539

Collected Steps per Second: 22,436.88437
Overall Steps per Second: 16,572.45063

Timestep Collection Time: 2.22847
Timestep Consumption Time: 0.78858
PPO Batch Consumption Time: 0.05941
Total Iteration Time: 3.01706

Cumulative Model Updates: 23,407
Cumulative Timesteps: 390,884,770

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,470.22386
Policy Entropy: 0.90981
Value Function Loss: 0.05509

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02482
Policy Update Magnitude: 0.02902
Value Function Update Magnitude: 0.05322

Collected Steps per Second: 20,179.50275
Overall Steps per Second: 14,829.15383

Timestep Collection Time: 2.47826
Timestep Consumption Time: 0.89415
PPO Batch Consumption Time: 0.09142
Total Iteration Time: 3.37241

Cumulative Model Updates: 23,410
Cumulative Timesteps: 390,934,780

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 390934780...
Checkpoint 390934780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,730.20295
Policy Entropy: 0.91485
Value Function Loss: 0.06094

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03468
Policy Update Magnitude: 0.03050
Value Function Update Magnitude: 0.05155

Collected Steps per Second: 22,741.15551
Overall Steps per Second: 15,778.36475

Timestep Collection Time: 2.20024
Timestep Consumption Time: 0.97094
PPO Batch Consumption Time: 0.11635
Total Iteration Time: 3.17118

Cumulative Model Updates: 23,413
Cumulative Timesteps: 390,984,816

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,501.09467
Policy Entropy: 0.91498
Value Function Loss: 0.05698

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03377
Policy Update Magnitude: 0.03384
Value Function Update Magnitude: 0.05886

Collected Steps per Second: 23,112.56725
Overall Steps per Second: 16,852.98420

Timestep Collection Time: 2.16402
Timestep Consumption Time: 0.80377
PPO Batch Consumption Time: 0.05967
Total Iteration Time: 2.96778

Cumulative Model Updates: 23,416
Cumulative Timesteps: 391,034,832

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 391034832...
Checkpoint 391034832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,099.04491
Policy Entropy: 0.92360
Value Function Loss: 0.05290

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05639
Policy Update Magnitude: 0.03344
Value Function Update Magnitude: 0.06173

Collected Steps per Second: 21,368.23350
Overall Steps per Second: 15,477.95881

Timestep Collection Time: 2.34039
Timestep Consumption Time: 0.89066
PPO Batch Consumption Time: 0.07885
Total Iteration Time: 3.23105

Cumulative Model Updates: 23,419
Cumulative Timesteps: 391,084,842

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,496.09251
Policy Entropy: 0.91788
Value Function Loss: 0.05222

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.05346
Policy Update Magnitude: 0.02999
Value Function Update Magnitude: 0.06428

Collected Steps per Second: 22,110.30347
Overall Steps per Second: 16,021.76634

Timestep Collection Time: 2.26247
Timestep Consumption Time: 0.85978
PPO Batch Consumption Time: 0.06654
Total Iteration Time: 3.12225

Cumulative Model Updates: 23,422
Cumulative Timesteps: 391,134,866

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 391134866...
Checkpoint 391134866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,033.23177
Policy Entropy: 0.92353
Value Function Loss: 0.05449

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08331
Policy Update Magnitude: 0.02912
Value Function Update Magnitude: 0.05875

Collected Steps per Second: 21,817.96670
Overall Steps per Second: 15,465.12548

Timestep Collection Time: 2.29215
Timestep Consumption Time: 0.94158
PPO Batch Consumption Time: 0.09921
Total Iteration Time: 3.23373

Cumulative Model Updates: 23,425
Cumulative Timesteps: 391,184,876

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,797.64577
Policy Entropy: 0.92863
Value Function Loss: 0.05048

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.07511
Policy Update Magnitude: 0.02647
Value Function Update Magnitude: 0.05750

Collected Steps per Second: 23,028.96680
Overall Steps per Second: 16,856.58084

Timestep Collection Time: 2.17283
Timestep Consumption Time: 0.79563
PPO Batch Consumption Time: 0.06024
Total Iteration Time: 2.96845

Cumulative Model Updates: 23,428
Cumulative Timesteps: 391,234,914

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 391234914...
Checkpoint 391234914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,559.83557
Policy Entropy: 0.94212
Value Function Loss: 0.04407

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.05463
Policy Update Magnitude: 0.02734
Value Function Update Magnitude: 0.05645

Collected Steps per Second: 20,057.92747
Overall Steps per Second: 14,667.83402

Timestep Collection Time: 2.49298
Timestep Consumption Time: 0.91611
PPO Batch Consumption Time: 0.08732
Total Iteration Time: 3.40909

Cumulative Model Updates: 23,431
Cumulative Timesteps: 391,284,918

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,967.45390
Policy Entropy: 0.94227
Value Function Loss: 0.04611

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05633
Policy Update Magnitude: 0.02625
Value Function Update Magnitude: 0.05794

Collected Steps per Second: 22,657.70361
Overall Steps per Second: 15,686.74088

Timestep Collection Time: 2.20755
Timestep Consumption Time: 0.98100
PPO Batch Consumption Time: 0.11157
Total Iteration Time: 3.18855

Cumulative Model Updates: 23,434
Cumulative Timesteps: 391,334,936

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 391334936...
Checkpoint 391334936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,925.81545
Policy Entropy: 0.94094
Value Function Loss: 0.04581

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03210
Policy Update Magnitude: 0.02521
Value Function Update Magnitude: 0.05829

Collected Steps per Second: 22,804.00126
Overall Steps per Second: 16,745.48701

Timestep Collection Time: 2.19330
Timestep Consumption Time: 0.79354
PPO Batch Consumption Time: 0.05933
Total Iteration Time: 2.98683

Cumulative Model Updates: 23,437
Cumulative Timesteps: 391,384,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,948.56365
Policy Entropy: 0.92365
Value Function Loss: 0.05094

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03299
Policy Update Magnitude: 0.02781
Value Function Update Magnitude: 0.05660

Collected Steps per Second: 20,152.84792
Overall Steps per Second: 14,741.14510

Timestep Collection Time: 2.48243
Timestep Consumption Time: 0.91134
PPO Batch Consumption Time: 0.08929
Total Iteration Time: 3.39377

Cumulative Model Updates: 23,440
Cumulative Timesteps: 391,434,980

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 391434980...
Checkpoint 391434980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,138.27413
Policy Entropy: 0.93568
Value Function Loss: 0.04634

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03211
Policy Update Magnitude: 0.02857
Value Function Update Magnitude: 0.05363

Collected Steps per Second: 22,287.82019
Overall Steps per Second: 15,723.69061

Timestep Collection Time: 2.24401
Timestep Consumption Time: 0.93680
PPO Batch Consumption Time: 0.09111
Total Iteration Time: 3.18081

Cumulative Model Updates: 23,443
Cumulative Timesteps: 391,484,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,570.87242
Policy Entropy: 0.93212
Value Function Loss: 0.04921

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02607
Policy Update Magnitude: 0.02884
Value Function Update Magnitude: 0.05016

Collected Steps per Second: 23,236.32094
Overall Steps per Second: 17,039.17983

Timestep Collection Time: 2.15378
Timestep Consumption Time: 0.78333
PPO Batch Consumption Time: 0.06396
Total Iteration Time: 2.93711

Cumulative Model Updates: 23,446
Cumulative Timesteps: 391,535,040

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 391535040...
Checkpoint 391535040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,210.99919
Policy Entropy: 0.94022
Value Function Loss: 0.05191

Mean KL Divergence: 0.00168
SB3 Clip Fraction: 0.01760
Policy Update Magnitude: 0.02743
Value Function Update Magnitude: 0.04509

Collected Steps per Second: 21,281.61449
Overall Steps per Second: 15,688.89446

Timestep Collection Time: 2.34992
Timestep Consumption Time: 0.83769
PPO Batch Consumption Time: 0.07023
Total Iteration Time: 3.18761

Cumulative Model Updates: 23,449
Cumulative Timesteps: 391,585,050

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,606.61462
Policy Entropy: 0.93513
Value Function Loss: 0.04738

Mean KL Divergence: 0.00138
SB3 Clip Fraction: 0.01227
Policy Update Magnitude: 0.03011
Value Function Update Magnitude: 0.04155

Collected Steps per Second: 22,652.05310
Overall Steps per Second: 16,343.34769

Timestep Collection Time: 2.20775
Timestep Consumption Time: 0.85221
PPO Batch Consumption Time: 0.08185
Total Iteration Time: 3.05996

Cumulative Model Updates: 23,452
Cumulative Timesteps: 391,635,060

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 391635060...
Checkpoint 391635060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,556.70436
Policy Entropy: 0.94413
Value Function Loss: 0.04277

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01079
Policy Update Magnitude: 0.03106
Value Function Update Magnitude: 0.04085

Collected Steps per Second: 22,506.65737
Overall Steps per Second: 16,437.67585

Timestep Collection Time: 2.22299
Timestep Consumption Time: 0.82075
PPO Batch Consumption Time: 0.06403
Total Iteration Time: 3.04374

Cumulative Model Updates: 23,455
Cumulative Timesteps: 391,685,092

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,517.97492
Policy Entropy: 0.94456
Value Function Loss: 0.04068

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.01825
Policy Update Magnitude: 0.03164
Value Function Update Magnitude: 0.03657

Collected Steps per Second: 20,511.78718
Overall Steps per Second: 15,040.16405

Timestep Collection Time: 2.43772
Timestep Consumption Time: 0.88684
PPO Batch Consumption Time: 0.08273
Total Iteration Time: 3.32456

Cumulative Model Updates: 23,458
Cumulative Timesteps: 391,735,094

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 391735094...
Checkpoint 391735094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,885.10650
Policy Entropy: 0.93553
Value Function Loss: 0.04777

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02256
Policy Update Magnitude: 0.02921
Value Function Update Magnitude: 0.04198

Collected Steps per Second: 22,511.81868
Overall Steps per Second: 16,321.07999

Timestep Collection Time: 2.22114
Timestep Consumption Time: 0.84250
PPO Batch Consumption Time: 0.06510
Total Iteration Time: 3.06365

Cumulative Model Updates: 23,461
Cumulative Timesteps: 391,785,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,134.74447
Policy Entropy: 0.93881
Value Function Loss: 0.04987

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.01965
Policy Update Magnitude: 0.03046
Value Function Update Magnitude: 0.04242

Collected Steps per Second: 20,446.41601
Overall Steps per Second: 15,053.92451

Timestep Collection Time: 2.44571
Timestep Consumption Time: 0.87608
PPO Batch Consumption Time: 0.07896
Total Iteration Time: 3.32179

Cumulative Model Updates: 23,464
Cumulative Timesteps: 391,835,102

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 391835102...
Checkpoint 391835102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,436.05705
Policy Entropy: 0.91720
Value Function Loss: 0.05341

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02619
Policy Update Magnitude: 0.02851
Value Function Update Magnitude: 0.04108

Collected Steps per Second: 22,519.89919
Overall Steps per Second: 16,002.64653

Timestep Collection Time: 2.22106
Timestep Consumption Time: 0.90455
PPO Batch Consumption Time: 0.10679
Total Iteration Time: 3.12561

Cumulative Model Updates: 23,467
Cumulative Timesteps: 391,885,120

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,409.96527
Policy Entropy: 0.93661
Value Function Loss: 0.04939

Mean KL Divergence: 0.00153
SB3 Clip Fraction: 0.01338
Policy Update Magnitude: 0.02822
Value Function Update Magnitude: 0.04257

Collected Steps per Second: 23,326.07155
Overall Steps per Second: 16,904.17285

Timestep Collection Time: 2.14447
Timestep Consumption Time: 0.81468
PPO Batch Consumption Time: 0.06643
Total Iteration Time: 2.95915

Cumulative Model Updates: 23,470
Cumulative Timesteps: 391,935,142

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 391935142...
Checkpoint 391935142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,251.26913
Policy Entropy: 0.94369
Value Function Loss: 0.04674

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02021
Policy Update Magnitude: 0.02979
Value Function Update Magnitude: 0.04660

Collected Steps per Second: 22,590.91205
Overall Steps per Second: 16,548.66835

Timestep Collection Time: 2.21416
Timestep Consumption Time: 0.80843
PPO Batch Consumption Time: 0.06382
Total Iteration Time: 3.02260

Cumulative Model Updates: 23,473
Cumulative Timesteps: 391,985,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,779.23773
Policy Entropy: 0.95861
Value Function Loss: 0.04608

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02423
Policy Update Magnitude: 0.02962
Value Function Update Magnitude: 0.04188

Collected Steps per Second: 20,626.10848
Overall Steps per Second: 14,633.31616

Timestep Collection Time: 2.42450
Timestep Consumption Time: 0.99291
PPO Batch Consumption Time: 0.11280
Total Iteration Time: 3.41741

Cumulative Model Updates: 23,476
Cumulative Timesteps: 392,035,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 392035170...
Checkpoint 392035170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,499.44979
Policy Entropy: 0.94370
Value Function Loss: 0.04558

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02365
Policy Update Magnitude: 0.03001
Value Function Update Magnitude: 0.04131

Collected Steps per Second: 22,446.46344
Overall Steps per Second: 15,724.40994

Timestep Collection Time: 2.22806
Timestep Consumption Time: 0.95248
PPO Batch Consumption Time: 0.10504
Total Iteration Time: 3.18053

Cumulative Model Updates: 23,479
Cumulative Timesteps: 392,085,182

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,396.72935
Policy Entropy: 0.91780
Value Function Loss: 0.04760

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02528
Policy Update Magnitude: 0.02969
Value Function Update Magnitude: 0.04248

Collected Steps per Second: 20,680.48974
Overall Steps per Second: 15,374.43597

Timestep Collection Time: 2.41861
Timestep Consumption Time: 0.83471
PPO Batch Consumption Time: 0.06590
Total Iteration Time: 3.25332

Cumulative Model Updates: 23,482
Cumulative Timesteps: 392,135,200

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 392135200...
Checkpoint 392135200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,128.58537
Policy Entropy: 0.92780
Value Function Loss: 0.04274

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03705
Policy Update Magnitude: 0.02757
Value Function Update Magnitude: 0.03980

Collected Steps per Second: 19,945.20848
Overall Steps per Second: 14,237.36889

Timestep Collection Time: 2.50867
Timestep Consumption Time: 1.00574
PPO Batch Consumption Time: 0.12090
Total Iteration Time: 3.51441

Cumulative Model Updates: 23,485
Cumulative Timesteps: 392,185,236

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,715.78830
Policy Entropy: 0.93520
Value Function Loss: 0.04495

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02438
Policy Update Magnitude: 0.02797
Value Function Update Magnitude: 0.03733

Collected Steps per Second: 23,007.06095
Overall Steps per Second: 16,791.38056

Timestep Collection Time: 2.17394
Timestep Consumption Time: 0.80473
PPO Batch Consumption Time: 0.06143
Total Iteration Time: 2.97867

Cumulative Model Updates: 23,488
Cumulative Timesteps: 392,235,252

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 392235252...
Checkpoint 392235252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,361.88775
Policy Entropy: 0.94298
Value Function Loss: 0.04671

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02791
Policy Update Magnitude: 0.03122
Value Function Update Magnitude: 0.03995

Collected Steps per Second: 20,081.54016
Overall Steps per Second: 14,690.62162

Timestep Collection Time: 2.49094
Timestep Consumption Time: 0.91409
PPO Batch Consumption Time: 0.09797
Total Iteration Time: 3.40503

Cumulative Model Updates: 23,491
Cumulative Timesteps: 392,285,274

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,713.71607
Policy Entropy: 0.93559
Value Function Loss: 0.04694

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02072
Policy Update Magnitude: 0.03118
Value Function Update Magnitude: 0.04507

Collected Steps per Second: 22,895.43037
Overall Steps per Second: 16,663.81016

Timestep Collection Time: 2.18402
Timestep Consumption Time: 0.81674
PPO Batch Consumption Time: 0.06135
Total Iteration Time: 3.00075

Cumulative Model Updates: 23,494
Cumulative Timesteps: 392,335,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 392335278...
Checkpoint 392335278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,365.03574
Policy Entropy: 0.93038
Value Function Loss: 0.04439

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03733
Policy Update Magnitude: 0.03064
Value Function Update Magnitude: 0.04848

Collected Steps per Second: 19,828.34093
Overall Steps per Second: 14,093.53571

Timestep Collection Time: 2.52295
Timestep Consumption Time: 1.02662
PPO Batch Consumption Time: 0.12843
Total Iteration Time: 3.54957

Cumulative Model Updates: 23,497
Cumulative Timesteps: 392,385,304

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,362.14178
Policy Entropy: 0.93365
Value Function Loss: 0.04662

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02362
Policy Update Magnitude: 0.02808
Value Function Update Magnitude: 0.05098

Collected Steps per Second: 22,232.23653
Overall Steps per Second: 16,190.65504

Timestep Collection Time: 2.25034
Timestep Consumption Time: 0.83972
PPO Batch Consumption Time: 0.06636
Total Iteration Time: 3.09005

Cumulative Model Updates: 23,500
Cumulative Timesteps: 392,435,334

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 392435334...
Checkpoint 392435334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,714.57045
Policy Entropy: 0.93779
Value Function Loss: 0.04756

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01803
Policy Update Magnitude: 0.02745
Value Function Update Magnitude: 0.05504

Collected Steps per Second: 20,312.84000
Overall Steps per Second: 15,055.91081

Timestep Collection Time: 2.46189
Timestep Consumption Time: 0.85960
PPO Batch Consumption Time: 0.08469
Total Iteration Time: 3.32149

Cumulative Model Updates: 23,503
Cumulative Timesteps: 392,485,342

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,814.21210
Policy Entropy: 0.93198
Value Function Loss: 0.04977

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01614
Policy Update Magnitude: 0.02788
Value Function Update Magnitude: 0.05587

Collected Steps per Second: 22,896.60026
Overall Steps per Second: 15,780.44551

Timestep Collection Time: 2.18495
Timestep Consumption Time: 0.98530
PPO Batch Consumption Time: 0.11818
Total Iteration Time: 3.17025

Cumulative Model Updates: 23,506
Cumulative Timesteps: 392,535,370

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 392535370...
Checkpoint 392535370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,779.15113
Policy Entropy: 0.93427
Value Function Loss: 0.04561

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01899
Policy Update Magnitude: 0.02811
Value Function Update Magnitude: 0.05414

Collected Steps per Second: 22,280.42925
Overall Steps per Second: 16,326.95976

Timestep Collection Time: 2.24421
Timestep Consumption Time: 0.81833
PPO Batch Consumption Time: 0.06378
Total Iteration Time: 3.06254

Cumulative Model Updates: 23,509
Cumulative Timesteps: 392,585,372

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,984.04117
Policy Entropy: 0.93680
Value Function Loss: 0.04431

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.01653
Policy Update Magnitude: 0.02835
Value Function Update Magnitude: 0.05273

Collected Steps per Second: 19,981.21319
Overall Steps per Second: 14,252.74499

Timestep Collection Time: 2.50335
Timestep Consumption Time: 1.00615
PPO Batch Consumption Time: 0.12174
Total Iteration Time: 3.50950

Cumulative Model Updates: 23,512
Cumulative Timesteps: 392,635,392

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 392635392...
Checkpoint 392635392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,261.67908
Policy Entropy: 0.93412
Value Function Loss: 0.04650

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.02157
Policy Update Magnitude: 0.02776
Value Function Update Magnitude: 0.05295

Collected Steps per Second: 22,547.29834
Overall Steps per Second: 16,587.47300

Timestep Collection Time: 2.21827
Timestep Consumption Time: 0.79702
PPO Batch Consumption Time: 0.06065
Total Iteration Time: 3.01529

Cumulative Model Updates: 23,515
Cumulative Timesteps: 392,685,408

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,104.38954
Policy Entropy: 0.93086
Value Function Loss: 0.04990

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03557
Policy Update Magnitude: 0.02874
Value Function Update Magnitude: 0.05664

Collected Steps per Second: 19,723.50020
Overall Steps per Second: 14,025.68608

Timestep Collection Time: 2.53505
Timestep Consumption Time: 1.02984
PPO Batch Consumption Time: 0.12555
Total Iteration Time: 3.56489

Cumulative Model Updates: 23,518
Cumulative Timesteps: 392,735,408

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 392735408...
Checkpoint 392735408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,679.27524
Policy Entropy: 0.94205
Value Function Loss: 0.05125

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02499
Policy Update Magnitude: 0.02954
Value Function Update Magnitude: 0.05995

Collected Steps per Second: 22,734.88289
Overall Steps per Second: 16,585.90600

Timestep Collection Time: 2.20041
Timestep Consumption Time: 0.81577
PPO Batch Consumption Time: 0.06170
Total Iteration Time: 3.01618

Cumulative Model Updates: 23,521
Cumulative Timesteps: 392,785,434

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,537.61519
Policy Entropy: 0.94231
Value Function Loss: 0.04967

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02163
Policy Update Magnitude: 0.02947
Value Function Update Magnitude: 0.05794

Collected Steps per Second: 20,443.45985
Overall Steps per Second: 14,836.48193

Timestep Collection Time: 2.44685
Timestep Consumption Time: 0.92471
PPO Batch Consumption Time: 0.09375
Total Iteration Time: 3.37155

Cumulative Model Updates: 23,524
Cumulative Timesteps: 392,835,456

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 392835456...
Checkpoint 392835456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,662.50919
Policy Entropy: 0.93486
Value Function Loss: 0.05317

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02597
Policy Update Magnitude: 0.03079
Value Function Update Magnitude: 0.05489

Collected Steps per Second: 21,059.20028
Overall Steps per Second: 14,849.38286

Timestep Collection Time: 2.37426
Timestep Consumption Time: 0.99288
PPO Batch Consumption Time: 0.12073
Total Iteration Time: 3.36714

Cumulative Model Updates: 23,527
Cumulative Timesteps: 392,885,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,714.53547
Policy Entropy: 0.93814
Value Function Loss: 0.06070

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02729
Policy Update Magnitude: 0.03092
Value Function Update Magnitude: 0.04842

Collected Steps per Second: 23,025.14199
Overall Steps per Second: 16,848.80630

Timestep Collection Time: 2.17215
Timestep Consumption Time: 0.79625
PPO Batch Consumption Time: 0.06106
Total Iteration Time: 2.96840

Cumulative Model Updates: 23,530
Cumulative Timesteps: 392,935,470

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 392935470...
Checkpoint 392935470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,304.42000
Policy Entropy: 0.94578
Value Function Loss: 0.06402

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03448
Policy Update Magnitude: 0.03471
Value Function Update Magnitude: 0.04610

Collected Steps per Second: 22,345.11869
Overall Steps per Second: 15,564.95654

Timestep Collection Time: 2.23816
Timestep Consumption Time: 0.97495
PPO Batch Consumption Time: 0.10938
Total Iteration Time: 3.21312

Cumulative Model Updates: 23,533
Cumulative Timesteps: 392,985,482

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,730.91748
Policy Entropy: 0.95183
Value Function Loss: 0.05865

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03637
Policy Update Magnitude: 0.03361
Value Function Update Magnitude: 0.05277

Collected Steps per Second: 23,015.50078
Overall Steps per Second: 16,400.12045

Timestep Collection Time: 2.17367
Timestep Consumption Time: 0.87680
PPO Batch Consumption Time: 0.08270
Total Iteration Time: 3.05047

Cumulative Model Updates: 23,536
Cumulative Timesteps: 393,035,510

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 393035510...
Checkpoint 393035510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,055.36379
Policy Entropy: 0.93688
Value Function Loss: 0.05323

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03243
Policy Update Magnitude: 0.03214
Value Function Update Magnitude: 0.04695

Collected Steps per Second: 21,310.59385
Overall Steps per Second: 15,050.89424

Timestep Collection Time: 2.34756
Timestep Consumption Time: 0.97636
PPO Batch Consumption Time: 0.11219
Total Iteration Time: 3.32392

Cumulative Model Updates: 23,539
Cumulative Timesteps: 393,085,538

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,277.57579
Policy Entropy: 0.93238
Value Function Loss: 0.05082

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02734
Policy Update Magnitude: 0.03335
Value Function Update Magnitude: 0.04915

Collected Steps per Second: 23,080.70746
Overall Steps per Second: 16,904.57014

Timestep Collection Time: 2.16761
Timestep Consumption Time: 0.79194
PPO Batch Consumption Time: 0.06329
Total Iteration Time: 2.95955

Cumulative Model Updates: 23,542
Cumulative Timesteps: 393,135,568

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 393135568...
Checkpoint 393135568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,633.34745
Policy Entropy: 0.93826
Value Function Loss: 0.05523

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01536
Policy Update Magnitude: 0.03301
Value Function Update Magnitude: 0.04757

Collected Steps per Second: 20,630.98986
Overall Steps per Second: 14,652.97779

Timestep Collection Time: 2.42567
Timestep Consumption Time: 0.98961
PPO Batch Consumption Time: 0.11221
Total Iteration Time: 3.41528

Cumulative Model Updates: 23,545
Cumulative Timesteps: 393,185,612

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,934.23420
Policy Entropy: 0.94743
Value Function Loss: 0.05322

Mean KL Divergence: 0.00168
SB3 Clip Fraction: 0.01579
Policy Update Magnitude: 0.03468
Value Function Update Magnitude: 0.04575

Collected Steps per Second: 21,611.27426
Overall Steps per Second: 15,778.46632

Timestep Collection Time: 2.31463
Timestep Consumption Time: 0.85564
PPO Batch Consumption Time: 0.06323
Total Iteration Time: 3.17027

Cumulative Model Updates: 23,548
Cumulative Timesteps: 393,235,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 393235634...
Checkpoint 393235634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,724.76463
Policy Entropy: 0.95140
Value Function Loss: 0.05318

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01707
Policy Update Magnitude: 0.03536
Value Function Update Magnitude: 0.04188

Collected Steps per Second: 22,148.57174
Overall Steps per Second: 15,583.65285

Timestep Collection Time: 2.25848
Timestep Consumption Time: 0.95143
PPO Batch Consumption Time: 0.10258
Total Iteration Time: 3.20990

Cumulative Model Updates: 23,551
Cumulative Timesteps: 393,285,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,506.96598
Policy Entropy: 0.96298
Value Function Loss: 0.04490

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.01974
Policy Update Magnitude: 0.03253
Value Function Update Magnitude: 0.04172

Collected Steps per Second: 23,225.04650
Overall Steps per Second: 16,434.41090

Timestep Collection Time: 2.15397
Timestep Consumption Time: 0.89001
PPO Batch Consumption Time: 0.08165
Total Iteration Time: 3.04398

Cumulative Model Updates: 23,554
Cumulative Timesteps: 393,335,682

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 393335682...
Checkpoint 393335682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,636.98280
Policy Entropy: 0.95659
Value Function Loss: 0.04589

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02814
Policy Update Magnitude: 0.02956
Value Function Update Magnitude: 0.04129

Collected Steps per Second: 21,382.15568
Overall Steps per Second: 15,033.65510

Timestep Collection Time: 2.33849
Timestep Consumption Time: 0.98751
PPO Batch Consumption Time: 0.11338
Total Iteration Time: 3.32600

Cumulative Model Updates: 23,557
Cumulative Timesteps: 393,385,684

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,838.37617
Policy Entropy: 0.96163
Value Function Loss: 0.04899

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02573
Policy Update Magnitude: 0.02884
Value Function Update Magnitude: 0.04028

Collected Steps per Second: 22,368.90457
Overall Steps per Second: 16,648.91947

Timestep Collection Time: 2.23525
Timestep Consumption Time: 0.76795
PPO Batch Consumption Time: 0.06065
Total Iteration Time: 3.00320

Cumulative Model Updates: 23,560
Cumulative Timesteps: 393,435,684

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 393435684...
Checkpoint 393435684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,096.25701
Policy Entropy: 0.95319
Value Function Loss: 0.04805

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.01942
Policy Update Magnitude: 0.02975
Value Function Update Magnitude: 0.03843

Collected Steps per Second: 19,798.21211
Overall Steps per Second: 14,651.62284

Timestep Collection Time: 2.52669
Timestep Consumption Time: 0.88754
PPO Batch Consumption Time: 0.08299
Total Iteration Time: 3.41423

Cumulative Model Updates: 23,563
Cumulative Timesteps: 393,485,708

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,156.19999
Policy Entropy: 0.96281
Value Function Loss: 0.04243

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02158
Policy Update Magnitude: 0.02812
Value Function Update Magnitude: 0.04035

Collected Steps per Second: 23,067.84754
Overall Steps per Second: 16,748.10675

Timestep Collection Time: 2.16821
Timestep Consumption Time: 0.81815
PPO Batch Consumption Time: 0.06193
Total Iteration Time: 2.98637

Cumulative Model Updates: 23,566
Cumulative Timesteps: 393,535,724

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 393535724...
Checkpoint 393535724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,637.28897
Policy Entropy: 0.95213
Value Function Loss: 0.03961

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02117
Policy Update Magnitude: 0.02827
Value Function Update Magnitude: 0.04416

Collected Steps per Second: 19,505.22771
Overall Steps per Second: 14,094.53001

Timestep Collection Time: 2.56413
Timestep Consumption Time: 0.98434
PPO Batch Consumption Time: 0.10843
Total Iteration Time: 3.54847

Cumulative Model Updates: 23,569
Cumulative Timesteps: 393,585,738

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,366.17037
Policy Entropy: 0.94303
Value Function Loss: 0.04332

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.01979
Policy Update Magnitude: 0.03225
Value Function Update Magnitude: 0.04859

Collected Steps per Second: 22,929.83950
Overall Steps per Second: 16,757.85625

Timestep Collection Time: 2.18187
Timestep Consumption Time: 0.80359
PPO Batch Consumption Time: 0.06170
Total Iteration Time: 2.98547

Cumulative Model Updates: 23,572
Cumulative Timesteps: 393,635,768

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 393635768...
Checkpoint 393635768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,748.26151
Policy Entropy: 0.92712
Value Function Loss: 0.04935

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03848
Policy Update Magnitude: 0.03167
Value Function Update Magnitude: 0.04808

Collected Steps per Second: 19,767.49250
Overall Steps per Second: 14,022.96667

Timestep Collection Time: 2.53062
Timestep Consumption Time: 1.03667
PPO Batch Consumption Time: 0.12751
Total Iteration Time: 3.56729

Cumulative Model Updates: 23,575
Cumulative Timesteps: 393,685,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,288.44739
Policy Entropy: 0.93621
Value Function Loss: 0.04585

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02499
Policy Update Magnitude: 0.02895
Value Function Update Magnitude: 0.04902

Collected Steps per Second: 22,758.75551
Overall Steps per Second: 16,654.21523

Timestep Collection Time: 2.19810
Timestep Consumption Time: 0.80570
PPO Batch Consumption Time: 0.06061
Total Iteration Time: 3.00380

Cumulative Model Updates: 23,578
Cumulative Timesteps: 393,735,818

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 393735818...
Checkpoint 393735818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,987.19331
Policy Entropy: 0.95514
Value Function Loss: 0.04779

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02211
Policy Update Magnitude: 0.03042
Value Function Update Magnitude: 0.05376

Collected Steps per Second: 20,242.08354
Overall Steps per Second: 14,750.26677

Timestep Collection Time: 2.47119
Timestep Consumption Time: 0.92007
PPO Batch Consumption Time: 0.09079
Total Iteration Time: 3.39126

Cumulative Model Updates: 23,581
Cumulative Timesteps: 393,785,840

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,535.98699
Policy Entropy: 0.95380
Value Function Loss: 0.04623

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03795
Policy Update Magnitude: 0.02928
Value Function Update Magnitude: 0.05224

Collected Steps per Second: 22,984.48616
Overall Steps per Second: 15,707.79209

Timestep Collection Time: 2.17555
Timestep Consumption Time: 1.00783
PPO Batch Consumption Time: 0.11815
Total Iteration Time: 3.18339

Cumulative Model Updates: 23,584
Cumulative Timesteps: 393,835,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 393835844...
Checkpoint 393835844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,937.76361
Policy Entropy: 0.97218
Value Function Loss: 0.04887

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02469
Policy Update Magnitude: 0.03170
Value Function Update Magnitude: 0.05211

Collected Steps per Second: 22,716.47572
Overall Steps per Second: 16,541.53513

Timestep Collection Time: 2.20263
Timestep Consumption Time: 0.82224
PPO Batch Consumption Time: 0.06080
Total Iteration Time: 3.02487

Cumulative Model Updates: 23,587
Cumulative Timesteps: 393,885,880

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,770.73775
Policy Entropy: 0.96071
Value Function Loss: 0.04834

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03866
Policy Update Magnitude: 0.03270
Value Function Update Magnitude: 0.05345

Collected Steps per Second: 19,892.74524
Overall Steps per Second: 14,822.66552

Timestep Collection Time: 2.51469
Timestep Consumption Time: 0.86015
PPO Batch Consumption Time: 0.07726
Total Iteration Time: 3.37483

Cumulative Model Updates: 23,590
Cumulative Timesteps: 393,935,904

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 393935904...
Checkpoint 393935904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,904.28791
Policy Entropy: 0.96026
Value Function Loss: 0.04349

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.04037
Policy Update Magnitude: 0.03088
Value Function Update Magnitude: 0.05442

Collected Steps per Second: 22,439.95394
Overall Steps per Second: 15,780.46567

Timestep Collection Time: 2.22861
Timestep Consumption Time: 0.94049
PPO Batch Consumption Time: 0.09537
Total Iteration Time: 3.16911

Cumulative Model Updates: 23,593
Cumulative Timesteps: 393,985,914

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,420.23883
Policy Entropy: 0.95546
Value Function Loss: 0.04835

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05014
Policy Update Magnitude: 0.03202
Value Function Update Magnitude: 0.05566

Collected Steps per Second: 22,887.01892
Overall Steps per Second: 16,714.99234

Timestep Collection Time: 2.18526
Timestep Consumption Time: 0.80691
PPO Batch Consumption Time: 0.05990
Total Iteration Time: 2.99216

Cumulative Model Updates: 23,596
Cumulative Timesteps: 394,035,928

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 394035928...
Checkpoint 394035928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,843.29637
Policy Entropy: 0.96223
Value Function Loss: 0.04859

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04219
Policy Update Magnitude: 0.03291
Value Function Update Magnitude: 0.05576

Collected Steps per Second: 18,101.67263
Overall Steps per Second: 13,913.84576

Timestep Collection Time: 2.76461
Timestep Consumption Time: 0.83210
PPO Batch Consumption Time: 0.07961
Total Iteration Time: 3.59671

Cumulative Model Updates: 23,599
Cumulative Timesteps: 394,085,972

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,614.22134
Policy Entropy: 0.96927
Value Function Loss: 0.05331

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.05943
Policy Update Magnitude: 0.03516
Value Function Update Magnitude: 0.05838

Collected Steps per Second: 22,942.85385
Overall Steps per Second: 16,842.43793

Timestep Collection Time: 2.17976
Timestep Consumption Time: 0.78952
PPO Batch Consumption Time: 0.05877
Total Iteration Time: 2.96929

Cumulative Model Updates: 23,602
Cumulative Timesteps: 394,135,982

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 394135982...
Checkpoint 394135982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,505.93408
Policy Entropy: 0.96321
Value Function Loss: 0.04826

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05406
Policy Update Magnitude: 0.03053
Value Function Update Magnitude: 0.05589

Collected Steps per Second: 19,854.70833
Overall Steps per Second: 14,693.40059

Timestep Collection Time: 2.52001
Timestep Consumption Time: 0.88520
PPO Batch Consumption Time: 0.07876
Total Iteration Time: 3.40520

Cumulative Model Updates: 23,605
Cumulative Timesteps: 394,186,016

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,835.56938
Policy Entropy: 0.94723
Value Function Loss: 0.04976

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.05727
Policy Update Magnitude: 0.02882
Value Function Update Magnitude: 0.05504

Collected Steps per Second: 22,974.66432
Overall Steps per Second: 15,775.17823

Timestep Collection Time: 2.17770
Timestep Consumption Time: 0.99386
PPO Batch Consumption Time: 0.11131
Total Iteration Time: 3.17156

Cumulative Model Updates: 23,608
Cumulative Timesteps: 394,236,048

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 394236048...
Checkpoint 394236048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,860.34330
Policy Entropy: 0.95371
Value Function Loss: 0.05576

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04467
Policy Update Magnitude: 0.02906
Value Function Update Magnitude: 0.05714

Collected Steps per Second: 22,672.01605
Overall Steps per Second: 16,744.65723

Timestep Collection Time: 2.20669
Timestep Consumption Time: 0.78113
PPO Batch Consumption Time: 0.06042
Total Iteration Time: 2.98782

Cumulative Model Updates: 23,611
Cumulative Timesteps: 394,286,078

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,862.70400
Policy Entropy: 0.95041
Value Function Loss: 0.05778

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03714
Policy Update Magnitude: 0.03098
Value Function Update Magnitude: 0.05688

Collected Steps per Second: 20,058.44895
Overall Steps per Second: 14,730.64487

Timestep Collection Time: 2.49421
Timestep Consumption Time: 0.90211
PPO Batch Consumption Time: 0.09274
Total Iteration Time: 3.39632

Cumulative Model Updates: 23,614
Cumulative Timesteps: 394,336,108

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 394336108...
Checkpoint 394336108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,156.03267
Policy Entropy: 0.95568
Value Function Loss: 0.05351

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04171
Policy Update Magnitude: 0.03202
Value Function Update Magnitude: 0.05170

Collected Steps per Second: 22,293.50668
Overall Steps per Second: 15,736.58346

Timestep Collection Time: 2.24334
Timestep Consumption Time: 0.93473
PPO Batch Consumption Time: 0.10598
Total Iteration Time: 3.17807

Cumulative Model Updates: 23,617
Cumulative Timesteps: 394,386,120

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,059.91806
Policy Entropy: 0.96697
Value Function Loss: 0.04778

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02735
Policy Update Magnitude: 0.03238
Value Function Update Magnitude: 0.05393

Collected Steps per Second: 23,303.73954
Overall Steps per Second: 16,910.90753

Timestep Collection Time: 2.14635
Timestep Consumption Time: 0.81139
PPO Batch Consumption Time: 0.06192
Total Iteration Time: 2.95774

Cumulative Model Updates: 23,620
Cumulative Timesteps: 394,436,138

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 394436138...
Checkpoint 394436138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,706.85327
Policy Entropy: 0.96731
Value Function Loss: 0.04460

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04099
Policy Update Magnitude: 0.03145
Value Function Update Magnitude: 0.05353

Collected Steps per Second: 22,036.14374
Overall Steps per Second: 16,197.63276

Timestep Collection Time: 2.26909
Timestep Consumption Time: 0.81790
PPO Batch Consumption Time: 0.06448
Total Iteration Time: 3.08699

Cumulative Model Updates: 23,623
Cumulative Timesteps: 394,486,140

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,712.89394
Policy Entropy: 0.95653
Value Function Loss: 0.05476

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03281
Policy Update Magnitude: 0.02979
Value Function Update Magnitude: 0.05347

Collected Steps per Second: 20,032.09202
Overall Steps per Second: 14,271.12817

Timestep Collection Time: 2.49819
Timestep Consumption Time: 1.00847
PPO Batch Consumption Time: 0.12537
Total Iteration Time: 3.50666

Cumulative Model Updates: 23,626
Cumulative Timesteps: 394,536,184

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 394536184...
Checkpoint 394536184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,067.39676
Policy Entropy: 0.93336
Value Function Loss: 0.06306

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03576
Policy Update Magnitude: 0.03337
Value Function Update Magnitude: 0.05307

Collected Steps per Second: 22,339.42189
Overall Steps per Second: 16,381.32829

Timestep Collection Time: 2.23855
Timestep Consumption Time: 0.81419
PPO Batch Consumption Time: 0.06356
Total Iteration Time: 3.05274

Cumulative Model Updates: 23,629
Cumulative Timesteps: 394,586,192

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,860.13177
Policy Entropy: 0.94608
Value Function Loss: 0.06446

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02905
Policy Update Magnitude: 0.03279
Value Function Update Magnitude: 0.04637

Collected Steps per Second: 20,320.18406
Overall Steps per Second: 14,916.63316

Timestep Collection Time: 2.46169
Timestep Consumption Time: 0.89175
PPO Batch Consumption Time: 0.08471
Total Iteration Time: 3.35344

Cumulative Model Updates: 23,632
Cumulative Timesteps: 394,636,214

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 394636214...
Checkpoint 394636214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,276.64888
Policy Entropy: 0.96562
Value Function Loss: 0.05248

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03336
Policy Update Magnitude: 0.03373
Value Function Update Magnitude: 0.04811

Collected Steps per Second: 22,607.07043
Overall Steps per Second: 15,775.85894

Timestep Collection Time: 2.21294
Timestep Consumption Time: 0.95824
PPO Batch Consumption Time: 0.10258
Total Iteration Time: 3.17117

Cumulative Model Updates: 23,635
Cumulative Timesteps: 394,686,242

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,478.35504
Policy Entropy: 0.97730
Value Function Loss: 0.04486

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02943
Policy Update Magnitude: 0.03141
Value Function Update Magnitude: 0.04299

Collected Steps per Second: 23,263.87983
Overall Steps per Second: 16,870.52588

Timestep Collection Time: 2.15003
Timestep Consumption Time: 0.81479
PPO Batch Consumption Time: 0.06200
Total Iteration Time: 2.96482

Cumulative Model Updates: 23,638
Cumulative Timesteps: 394,736,260

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 394736260...
Checkpoint 394736260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,736.59727
Policy Entropy: 0.97627
Value Function Loss: 0.04759

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.04014
Policy Update Magnitude: 0.03237
Value Function Update Magnitude: 0.03781

Collected Steps per Second: 20,516.80203
Overall Steps per Second: 14,685.06313

Timestep Collection Time: 2.43742
Timestep Consumption Time: 0.96795
PPO Batch Consumption Time: 0.10806
Total Iteration Time: 3.40537

Cumulative Model Updates: 23,641
Cumulative Timesteps: 394,786,268

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,144.19923
Policy Entropy: 0.97823
Value Function Loss: 0.05255

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04064
Policy Update Magnitude: 0.03078
Value Function Update Magnitude: 0.03489

Collected Steps per Second: 23,024.99253
Overall Steps per Second: 16,372.58978

Timestep Collection Time: 2.17216
Timestep Consumption Time: 0.88258
PPO Batch Consumption Time: 0.08124
Total Iteration Time: 3.05474

Cumulative Model Updates: 23,644
Cumulative Timesteps: 394,836,282

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 394836282...
Checkpoint 394836282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,090.85723
Policy Entropy: 0.96915
Value Function Loss: 0.05210

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02353
Policy Update Magnitude: 0.03293
Value Function Update Magnitude: 0.03937

Collected Steps per Second: 21,678.39595
Overall Steps per Second: 15,083.03723

Timestep Collection Time: 2.30690
Timestep Consumption Time: 1.00874
PPO Batch Consumption Time: 0.12158
Total Iteration Time: 3.31565

Cumulative Model Updates: 23,647
Cumulative Timesteps: 394,886,292

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,967.92664
Policy Entropy: 0.96460
Value Function Loss: 0.05686

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03792
Policy Update Magnitude: 0.03977
Value Function Update Magnitude: 0.04351

Collected Steps per Second: 22,609.22397
Overall Steps per Second: 16,584.12516

Timestep Collection Time: 2.21211
Timestep Consumption Time: 0.80367
PPO Batch Consumption Time: 0.06073
Total Iteration Time: 3.01578

Cumulative Model Updates: 23,650
Cumulative Timesteps: 394,936,306

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 394936306...
Checkpoint 394936306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,145.68642
Policy Entropy: 0.95965
Value Function Loss: 0.05694

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03989
Policy Update Magnitude: 0.03654
Value Function Update Magnitude: 0.04985

Collected Steps per Second: 19,686.28660
Overall Steps per Second: 14,062.87446

Timestep Collection Time: 2.54106
Timestep Consumption Time: 1.01611
PPO Batch Consumption Time: 0.12171
Total Iteration Time: 3.55717

Cumulative Model Updates: 23,653
Cumulative Timesteps: 394,986,330

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,946.03543
Policy Entropy: 0.96836
Value Function Loss: 0.06224

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04863
Policy Update Magnitude: 0.03641
Value Function Update Magnitude: 0.05098

Collected Steps per Second: 23,201.78835
Overall Steps per Second: 16,904.29910

Timestep Collection Time: 2.15595
Timestep Consumption Time: 0.80317
PPO Batch Consumption Time: 0.06496
Total Iteration Time: 2.95913

Cumulative Model Updates: 23,656
Cumulative Timesteps: 395,036,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 395036352...
Checkpoint 395036352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,598.00837
Policy Entropy: 0.96256
Value Function Loss: 0.06109

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04059
Policy Update Magnitude: 0.03710
Value Function Update Magnitude: 0.04940

Collected Steps per Second: 22,797.96373
Overall Steps per Second: 16,293.11397

Timestep Collection Time: 2.19406
Timestep Consumption Time: 0.87595
PPO Batch Consumption Time: 0.08334
Total Iteration Time: 3.07001

Cumulative Model Updates: 23,659
Cumulative Timesteps: 395,086,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,557.93490
Policy Entropy: 0.98107
Value Function Loss: 0.05589

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.06601
Policy Update Magnitude: 0.03663
Value Function Update Magnitude: 0.04852

Collected Steps per Second: 21,161.19287
Overall Steps per Second: 14,972.24150

Timestep Collection Time: 2.36537
Timestep Consumption Time: 0.97775
PPO Batch Consumption Time: 0.11641
Total Iteration Time: 3.34312

Cumulative Model Updates: 23,662
Cumulative Timesteps: 395,136,426

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 395136426...
Checkpoint 395136426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,768.72243
Policy Entropy: 0.96815
Value Function Loss: 0.05804

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.06086
Policy Update Magnitude: 0.03408
Value Function Update Magnitude: 0.04680

Collected Steps per Second: 20,823.16927
Overall Steps per Second: 15,589.24633

Timestep Collection Time: 2.40184
Timestep Consumption Time: 0.80639
PPO Batch Consumption Time: 0.06199
Total Iteration Time: 3.20824

Cumulative Model Updates: 23,665
Cumulative Timesteps: 395,186,440

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,363.47882
Policy Entropy: 0.98730
Value Function Loss: 0.05624

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06851
Policy Update Magnitude: 0.03781
Value Function Update Magnitude: 0.04055

Collected Steps per Second: 20,056.59610
Overall Steps per Second: 14,767.54184

Timestep Collection Time: 2.49434
Timestep Consumption Time: 0.89336
PPO Batch Consumption Time: 0.08542
Total Iteration Time: 3.38770

Cumulative Model Updates: 23,668
Cumulative Timesteps: 395,236,468

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 395236468...
Checkpoint 395236468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,027.60907
Policy Entropy: 0.96689
Value Function Loss: 0.05714

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.05088
Policy Update Magnitude: 0.03873
Value Function Update Magnitude: 0.04210

Collected Steps per Second: 22,620.37296
Overall Steps per Second: 16,579.90623

Timestep Collection Time: 2.21040
Timestep Consumption Time: 0.80530
PPO Batch Consumption Time: 0.06085
Total Iteration Time: 3.01570

Cumulative Model Updates: 23,671
Cumulative Timesteps: 395,286,468

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,101.56263
Policy Entropy: 0.95303
Value Function Loss: 0.05796

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05177
Policy Update Magnitude: 0.03961
Value Function Update Magnitude: 0.04722

Collected Steps per Second: 19,945.67071
Overall Steps per Second: 14,146.29702

Timestep Collection Time: 2.50811
Timestep Consumption Time: 1.02822
PPO Batch Consumption Time: 0.12587
Total Iteration Time: 3.53633

Cumulative Model Updates: 23,674
Cumulative Timesteps: 395,336,494

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 395336494...
Checkpoint 395336494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,746.80460
Policy Entropy: 0.93412
Value Function Loss: 0.05525

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03389
Policy Update Magnitude: 0.03876
Value Function Update Magnitude: 0.05031

Collected Steps per Second: 22,992.78671
Overall Steps per Second: 16,807.54308

Timestep Collection Time: 2.17590
Timestep Consumption Time: 0.80074
PPO Batch Consumption Time: 0.06018
Total Iteration Time: 2.97664

Cumulative Model Updates: 23,677
Cumulative Timesteps: 395,386,524

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,378.89479
Policy Entropy: 0.92714
Value Function Loss: 0.05996

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.05043
Policy Update Magnitude: 0.03719
Value Function Update Magnitude: 0.04569

Collected Steps per Second: 20,463.43803
Overall Steps per Second: 14,675.92734

Timestep Collection Time: 2.44397
Timestep Consumption Time: 0.96379
PPO Batch Consumption Time: 0.10622
Total Iteration Time: 3.40776

Cumulative Model Updates: 23,680
Cumulative Timesteps: 395,436,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 395436536...
Checkpoint 395436536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,546.98516
Policy Entropy: 0.94469
Value Function Loss: 0.05479

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04889
Policy Update Magnitude: 0.04189
Value Function Update Magnitude: 0.04343

Collected Steps per Second: 22,777.51811
Overall Steps per Second: 15,744.53900

Timestep Collection Time: 2.19550
Timestep Consumption Time: 0.98071
PPO Batch Consumption Time: 0.11378
Total Iteration Time: 3.17621

Cumulative Model Updates: 23,683
Cumulative Timesteps: 395,486,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,325.11383
Policy Entropy: 0.95972
Value Function Loss: 0.06040

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.04124
Policy Update Magnitude: 0.03819
Value Function Update Magnitude: 0.04816

Collected Steps per Second: 23,053.67375
Overall Steps per Second: 16,839.90187

Timestep Collection Time: 2.16946
Timestep Consumption Time: 0.80051
PPO Batch Consumption Time: 0.06056
Total Iteration Time: 2.96997

Cumulative Model Updates: 23,686
Cumulative Timesteps: 395,536,558

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 395536558...
Checkpoint 395536558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,166.70522
Policy Entropy: 0.96169
Value Function Loss: 0.05761

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.04202
Policy Update Magnitude: 0.03742
Value Function Update Magnitude: 0.05433

Collected Steps per Second: 20,049.28726
Overall Steps per Second: 14,667.09986

Timestep Collection Time: 2.49415
Timestep Consumption Time: 0.91525
PPO Batch Consumption Time: 0.09015
Total Iteration Time: 3.40940

Cumulative Model Updates: 23,689
Cumulative Timesteps: 395,586,564

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,573.39972
Policy Entropy: 0.96486
Value Function Loss: 0.05638

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.04239
Policy Update Magnitude: 0.03639
Value Function Update Magnitude: 0.05612

Collected Steps per Second: 22,970.84514
Overall Steps per Second: 15,722.17806

Timestep Collection Time: 2.17719
Timestep Consumption Time: 1.00379
PPO Batch Consumption Time: 0.12116
Total Iteration Time: 3.18098

Cumulative Model Updates: 23,692
Cumulative Timesteps: 395,636,576

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 395636576...
Checkpoint 395636576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,179.70542
Policy Entropy: 0.96608
Value Function Loss: 0.05270

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03389
Policy Update Magnitude: 0.03420
Value Function Update Magnitude: 0.05506

Collected Steps per Second: 22,297.63921
Overall Steps per Second: 16,911.84892

Timestep Collection Time: 2.24356
Timestep Consumption Time: 0.71449
PPO Batch Consumption Time: 0.05913
Total Iteration Time: 2.95804

Cumulative Model Updates: 23,695
Cumulative Timesteps: 395,686,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,790.78764
Policy Entropy: 0.95574
Value Function Loss: 0.05057

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.05067
Policy Update Magnitude: 0.03015
Value Function Update Magnitude: 0.05519

Collected Steps per Second: 20,744.55326
Overall Steps per Second: 15,467.39845

Timestep Collection Time: 2.41085
Timestep Consumption Time: 0.82253
PPO Batch Consumption Time: 0.08771
Total Iteration Time: 3.23338

Cumulative Model Updates: 23,698
Cumulative Timesteps: 395,736,614

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 395736614...
Checkpoint 395736614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,086.75642
Policy Entropy: 0.95991
Value Function Loss: 0.05323

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03742
Policy Update Magnitude: 0.03014
Value Function Update Magnitude: 0.05517

Collected Steps per Second: 21,856.29545
Overall Steps per Second: 16,668.32510

Timestep Collection Time: 2.28776
Timestep Consumption Time: 0.71206
PPO Batch Consumption Time: 0.05963
Total Iteration Time: 2.99982

Cumulative Model Updates: 23,701
Cumulative Timesteps: 395,786,616

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,336.76355
Policy Entropy: 0.94076
Value Function Loss: 0.05616

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03675
Policy Update Magnitude: 0.03035
Value Function Update Magnitude: 0.05732

Collected Steps per Second: 19,952.55554
Overall Steps per Second: 14,807.95210

Timestep Collection Time: 2.50685
Timestep Consumption Time: 0.87093
PPO Batch Consumption Time: 0.10394
Total Iteration Time: 3.37778

Cumulative Model Updates: 23,704
Cumulative Timesteps: 395,836,634

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 395836634...
Checkpoint 395836634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,919.10745
Policy Entropy: 0.93866
Value Function Loss: 0.05746

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02401
Policy Update Magnitude: 0.03216
Value Function Update Magnitude: 0.05782

Collected Steps per Second: 21,169.90040
Overall Steps per Second: 15,959.69951

Timestep Collection Time: 2.36326
Timestep Consumption Time: 0.77151
PPO Batch Consumption Time: 0.06606
Total Iteration Time: 3.13477

Cumulative Model Updates: 23,707
Cumulative Timesteps: 395,886,664

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,615.79064
Policy Entropy: 0.94630
Value Function Loss: 0.04912

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01573
Policy Update Magnitude: 0.03095
Value Function Update Magnitude: 0.05948

Collected Steps per Second: 21,954.56566
Overall Steps per Second: 15,449.59409

Timestep Collection Time: 2.27798
Timestep Consumption Time: 0.95913
PPO Batch Consumption Time: 0.10059
Total Iteration Time: 3.23711

Cumulative Model Updates: 23,710
Cumulative Timesteps: 395,936,676

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 395936676...
Checkpoint 395936676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,965.08946
Policy Entropy: 0.94605
Value Function Loss: 0.04382

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02161
Policy Update Magnitude: 0.02973
Value Function Update Magnitude: 0.05494

Collected Steps per Second: 21,832.67231
Overall Steps per Second: 15,749.49850

Timestep Collection Time: 2.29216
Timestep Consumption Time: 0.88534
PPO Batch Consumption Time: 0.11088
Total Iteration Time: 3.17750

Cumulative Model Updates: 23,713
Cumulative Timesteps: 395,986,720

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,749.04849
Policy Entropy: 0.95828
Value Function Loss: 0.04140

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02704
Policy Update Magnitude: 0.02769
Value Function Update Magnitude: 0.05185

Collected Steps per Second: 22,234.93100
Overall Steps per Second: 16,815.47448

Timestep Collection Time: 2.25006
Timestep Consumption Time: 0.72517
PPO Batch Consumption Time: 0.06092
Total Iteration Time: 2.97524

Cumulative Model Updates: 23,716
Cumulative Timesteps: 396,036,750

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 396036750...
Checkpoint 396036750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,388.79274
Policy Entropy: 0.94524
Value Function Loss: 0.04755

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01988
Policy Update Magnitude: 0.02816
Value Function Update Magnitude: 0.05054

Collected Steps per Second: 19,603.55666
Overall Steps per Second: 14,625.73182

Timestep Collection Time: 2.55066
Timestep Consumption Time: 0.86811
PPO Batch Consumption Time: 0.07944
Total Iteration Time: 3.41877

Cumulative Model Updates: 23,719
Cumulative Timesteps: 396,086,752

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,282.58072
Policy Entropy: 0.94210
Value Function Loss: 0.05142

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03587
Policy Update Magnitude: 0.02905
Value Function Update Magnitude: 0.05077

Collected Steps per Second: 22,823.19541
Overall Steps per Second: 15,796.08114

Timestep Collection Time: 2.19102
Timestep Consumption Time: 0.97471
PPO Batch Consumption Time: 0.11600
Total Iteration Time: 3.16572

Cumulative Model Updates: 23,722
Cumulative Timesteps: 396,136,758

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 396136758...
Checkpoint 396136758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,999.73147
Policy Entropy: 0.94611
Value Function Loss: 0.05370

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03530
Policy Update Magnitude: 0.02883
Value Function Update Magnitude: 0.05021

Collected Steps per Second: 22,458.29710
Overall Steps per Second: 16,673.59095

Timestep Collection Time: 2.22804
Timestep Consumption Time: 0.77299
PPO Batch Consumption Time: 0.05814
Total Iteration Time: 3.00103

Cumulative Model Updates: 23,725
Cumulative Timesteps: 396,186,796

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,623.31830
Policy Entropy: 0.95449
Value Function Loss: 0.05543

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04513
Policy Update Magnitude: 0.02984
Value Function Update Magnitude: 0.04625

Collected Steps per Second: 19,857.08045
Overall Steps per Second: 14,765.64169

Timestep Collection Time: 2.51991
Timestep Consumption Time: 0.86891
PPO Batch Consumption Time: 0.08879
Total Iteration Time: 3.38881

Cumulative Model Updates: 23,728
Cumulative Timesteps: 396,236,834

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 396236834...
Checkpoint 396236834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,252.21883
Policy Entropy: 0.95294
Value Function Loss: 0.05352

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.04516
Policy Update Magnitude: 0.03347
Value Function Update Magnitude: 0.04405

Collected Steps per Second: 22,079.18703
Overall Steps per Second: 15,741.30814

Timestep Collection Time: 2.26476
Timestep Consumption Time: 0.91185
PPO Batch Consumption Time: 0.10304
Total Iteration Time: 3.17661

Cumulative Model Updates: 23,731
Cumulative Timesteps: 396,286,838

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,053.96110
Policy Entropy: 0.95099
Value Function Loss: 0.05060

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.05148
Policy Update Magnitude: 0.03169
Value Function Update Magnitude: 0.04174

Collected Steps per Second: 22,925.62170
Overall Steps per Second: 16,925.12065

Timestep Collection Time: 2.18201
Timestep Consumption Time: 0.77359
PPO Batch Consumption Time: 0.06213
Total Iteration Time: 2.95561

Cumulative Model Updates: 23,734
Cumulative Timesteps: 396,336,862

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 396336862...
Checkpoint 396336862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,249.86340
Policy Entropy: 0.94913
Value Function Loss: 0.05043

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05373
Policy Update Magnitude: 0.02910
Value Function Update Magnitude: 0.04026

Collected Steps per Second: 22,702.70393
Overall Steps per Second: 16,771.08045

Timestep Collection Time: 2.20300
Timestep Consumption Time: 0.77916
PPO Batch Consumption Time: 0.06410
Total Iteration Time: 2.98216

Cumulative Model Updates: 23,737
Cumulative Timesteps: 396,386,876

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,530.66946
Policy Entropy: 0.95196
Value Function Loss: 0.05014

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04700
Policy Update Magnitude: 0.02939
Value Function Update Magnitude: 0.04509

Collected Steps per Second: 22,844.68402
Overall Steps per Second: 16,770.40785

Timestep Collection Time: 2.18869
Timestep Consumption Time: 0.79275
PPO Batch Consumption Time: 0.06670
Total Iteration Time: 2.98144

Cumulative Model Updates: 23,740
Cumulative Timesteps: 396,436,876

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 396436876...
Checkpoint 396436876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,969.36626
Policy Entropy: 0.93463
Value Function Loss: 0.05486

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04669
Policy Update Magnitude: 0.03418
Value Function Update Magnitude: 0.04864

Collected Steps per Second: 22,872.35599
Overall Steps per Second: 16,647.12831

Timestep Collection Time: 2.18683
Timestep Consumption Time: 0.81777
PPO Batch Consumption Time: 0.06199
Total Iteration Time: 3.00460

Cumulative Model Updates: 23,743
Cumulative Timesteps: 396,486,894

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,124.37461
Policy Entropy: 0.93395
Value Function Loss: 0.05112

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04768
Policy Update Magnitude: 0.03373
Value Function Update Magnitude: 0.04366

Collected Steps per Second: 20,461.63727
Overall Steps per Second: 14,650.91044

Timestep Collection Time: 2.44555
Timestep Consumption Time: 0.96994
PPO Batch Consumption Time: 0.11000
Total Iteration Time: 3.41549

Cumulative Model Updates: 23,746
Cumulative Timesteps: 396,536,934

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 396536934...
Checkpoint 396536934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,740.24857
Policy Entropy: 0.93134
Value Function Loss: 0.04627

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03111
Policy Update Magnitude: 0.03016
Value Function Update Magnitude: 0.04116

Collected Steps per Second: 22,586.05447
Overall Steps per Second: 15,702.94045

Timestep Collection Time: 2.21482
Timestep Consumption Time: 0.97083
PPO Batch Consumption Time: 0.11071
Total Iteration Time: 3.18565

Cumulative Model Updates: 23,749
Cumulative Timesteps: 396,586,958

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,834.01777
Policy Entropy: 0.95098
Value Function Loss: 0.04552

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03404
Policy Update Magnitude: 0.02896
Value Function Update Magnitude: 0.04043

Collected Steps per Second: 23,176.11013
Overall Steps per Second: 16,982.05282

Timestep Collection Time: 2.15860
Timestep Consumption Time: 0.78733
PPO Batch Consumption Time: 0.06425
Total Iteration Time: 2.94593

Cumulative Model Updates: 23,752
Cumulative Timesteps: 396,636,986

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 396636986...
Checkpoint 396636986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,513.64378
Policy Entropy: 0.93290
Value Function Loss: 0.05016

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02140
Policy Update Magnitude: 0.02828
Value Function Update Magnitude: 0.04100

Collected Steps per Second: 22,666.94125
Overall Steps per Second: 16,702.86835

Timestep Collection Time: 2.20603
Timestep Consumption Time: 0.78771
PPO Batch Consumption Time: 0.06529
Total Iteration Time: 2.99374

Cumulative Model Updates: 23,755
Cumulative Timesteps: 396,686,990

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,775.93812
Policy Entropy: 0.93520
Value Function Loss: 0.05736

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.01883
Policy Update Magnitude: 0.02856
Value Function Update Magnitude: 0.04442

Collected Steps per Second: 22,990.55493
Overall Steps per Second: 16,682.93150

Timestep Collection Time: 2.17524
Timestep Consumption Time: 0.82243
PPO Batch Consumption Time: 0.06575
Total Iteration Time: 2.99767

Cumulative Model Updates: 23,758
Cumulative Timesteps: 396,737,000

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 396737000...
Checkpoint 396737000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,466.90737
Policy Entropy: 0.94370
Value Function Loss: 0.05412

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01759
Policy Update Magnitude: 0.03011
Value Function Update Magnitude: 0.04259

Collected Steps per Second: 22,483.54327
Overall Steps per Second: 16,732.23773

Timestep Collection Time: 2.22456
Timestep Consumption Time: 0.76464
PPO Batch Consumption Time: 0.06160
Total Iteration Time: 2.98920

Cumulative Model Updates: 23,761
Cumulative Timesteps: 396,787,016

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,630.92766
Policy Entropy: 0.95551
Value Function Loss: 0.04898

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01927
Policy Update Magnitude: 0.03224
Value Function Update Magnitude: 0.04176

Collected Steps per Second: 22,554.68734
Overall Steps per Second: 15,571.04076

Timestep Collection Time: 2.21816
Timestep Consumption Time: 0.99485
PPO Batch Consumption Time: 0.12324
Total Iteration Time: 3.21302

Cumulative Model Updates: 23,764
Cumulative Timesteps: 396,837,046

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 396837046...
Checkpoint 396837046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,178.95459
Policy Entropy: 0.94733
Value Function Loss: 0.05243

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02406
Policy Update Magnitude: 0.03134
Value Function Update Magnitude: 0.04464

Collected Steps per Second: 22,866.21732
Overall Steps per Second: 16,687.46290

Timestep Collection Time: 2.18812
Timestep Consumption Time: 0.81018
PPO Batch Consumption Time: 0.05768
Total Iteration Time: 2.99830

Cumulative Model Updates: 23,767
Cumulative Timesteps: 396,887,080

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,662.46074
Policy Entropy: 0.95105
Value Function Loss: 0.05528

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02789
Policy Update Magnitude: 0.03225
Value Function Update Magnitude: 0.05248

Collected Steps per Second: 19,933.35841
Overall Steps per Second: 14,700.53758

Timestep Collection Time: 2.51026
Timestep Consumption Time: 0.89356
PPO Batch Consumption Time: 0.08414
Total Iteration Time: 3.40382

Cumulative Model Updates: 23,770
Cumulative Timesteps: 396,937,118

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 396937118...
Checkpoint 396937118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,757.38404
Policy Entropy: 0.94862
Value Function Loss: 0.05694

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03474
Policy Update Magnitude: 0.03321
Value Function Update Magnitude: 0.05322

Collected Steps per Second: 22,837.81915
Overall Steps per Second: 16,797.91352

Timestep Collection Time: 2.18970
Timestep Consumption Time: 0.78734
PPO Batch Consumption Time: 0.05964
Total Iteration Time: 2.97704

Cumulative Model Updates: 23,773
Cumulative Timesteps: 396,987,126

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,925.16695
Policy Entropy: 0.96950
Value Function Loss: 0.04837

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02785
Policy Update Magnitude: 0.03319
Value Function Update Magnitude: 0.05159

Collected Steps per Second: 20,807.13553
Overall Steps per Second: 14,805.29601

Timestep Collection Time: 2.40446
Timestep Consumption Time: 0.97473
PPO Batch Consumption Time: 0.10931
Total Iteration Time: 3.37920

Cumulative Model Updates: 23,776
Cumulative Timesteps: 397,037,156

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 397037156...
Checkpoint 397037156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,531.28048
Policy Entropy: 0.96753
Value Function Loss: 0.04747

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02636
Policy Update Magnitude: 0.03292
Value Function Update Magnitude: 0.05183

Collected Steps per Second: 22,302.83905
Overall Steps per Second: 15,679.44251

Timestep Collection Time: 2.24205
Timestep Consumption Time: 0.94710
PPO Batch Consumption Time: 0.10153
Total Iteration Time: 3.18914

Cumulative Model Updates: 23,779
Cumulative Timesteps: 397,087,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,724.30269
Policy Entropy: 0.96369
Value Function Loss: 0.05323

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03281
Policy Update Magnitude: 0.03081
Value Function Update Magnitude: 0.05222

Collected Steps per Second: 22,729.96999
Overall Steps per Second: 16,640.45273

Timestep Collection Time: 2.20088
Timestep Consumption Time: 0.80541
PPO Batch Consumption Time: 0.06048
Total Iteration Time: 3.00629

Cumulative Model Updates: 23,782
Cumulative Timesteps: 397,137,186

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 397137186...
Checkpoint 397137186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,104.42805
Policy Entropy: 0.96901
Value Function Loss: 0.05524

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02341
Policy Update Magnitude: 0.03038
Value Function Update Magnitude: 0.05153

Collected Steps per Second: 18,732.23932
Overall Steps per Second: 14,003.59170

Timestep Collection Time: 2.66994
Timestep Consumption Time: 0.90157
PPO Batch Consumption Time: 0.08466
Total Iteration Time: 3.57151

Cumulative Model Updates: 23,785
Cumulative Timesteps: 397,187,200

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,198.48245
Policy Entropy: 0.97401
Value Function Loss: 0.05434

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02808
Policy Update Magnitude: 0.02901
Value Function Update Magnitude: 0.05293

Collected Steps per Second: 22,660.22842
Overall Steps per Second: 16,592.02026

Timestep Collection Time: 2.20872
Timestep Consumption Time: 0.80779
PPO Batch Consumption Time: 0.06071
Total Iteration Time: 3.01651

Cumulative Model Updates: 23,788
Cumulative Timesteps: 397,237,250

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 397237250...
Checkpoint 397237250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,201.22233
Policy Entropy: 0.98550
Value Function Loss: 0.04901

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02609
Policy Update Magnitude: 0.02953
Value Function Update Magnitude: 0.05250

Collected Steps per Second: 20,340.70394
Overall Steps per Second: 14,862.70995

Timestep Collection Time: 2.45911
Timestep Consumption Time: 0.90636
PPO Batch Consumption Time: 0.08592
Total Iteration Time: 3.36547

Cumulative Model Updates: 23,791
Cumulative Timesteps: 397,287,270

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,185.67766
Policy Entropy: 0.97225
Value Function Loss: 0.05167

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01983
Policy Update Magnitude: 0.02974
Value Function Update Magnitude: 0.05251

Collected Steps per Second: 22,766.76446
Overall Steps per Second: 15,752.36219

Timestep Collection Time: 2.19724
Timestep Consumption Time: 0.97841
PPO Batch Consumption Time: 0.10722
Total Iteration Time: 3.17565

Cumulative Model Updates: 23,794
Cumulative Timesteps: 397,337,294

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 397337294...
Checkpoint 397337294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,702.55487
Policy Entropy: 0.97827
Value Function Loss: 0.05114

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02837
Policy Update Magnitude: 0.02949
Value Function Update Magnitude: 0.05426

Collected Steps per Second: 22,559.05402
Overall Steps per Second: 16,576.10972

Timestep Collection Time: 2.21720
Timestep Consumption Time: 0.80027
PPO Batch Consumption Time: 0.06006
Total Iteration Time: 3.01748

Cumulative Model Updates: 23,797
Cumulative Timesteps: 397,387,312

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,670.39609
Policy Entropy: 0.96702
Value Function Loss: 0.05557

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02861
Policy Update Magnitude: 0.02874
Value Function Update Magnitude: 0.05447

Collected Steps per Second: 20,256.40750
Overall Steps per Second: 14,836.23572

Timestep Collection Time: 2.46845
Timestep Consumption Time: 0.90181
PPO Batch Consumption Time: 0.09360
Total Iteration Time: 3.37026

Cumulative Model Updates: 23,800
Cumulative Timesteps: 397,437,314

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 397437314...
Checkpoint 397437314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,288.64155
Policy Entropy: 0.97186
Value Function Loss: 0.05255

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02951
Policy Update Magnitude: 0.02846
Value Function Update Magnitude: 0.05334

Collected Steps per Second: 22,319.98686
Overall Steps per Second: 15,734.70291

Timestep Collection Time: 2.24032
Timestep Consumption Time: 0.93762
PPO Batch Consumption Time: 0.09269
Total Iteration Time: 3.17794

Cumulative Model Updates: 23,803
Cumulative Timesteps: 397,487,318

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,814.67188
Policy Entropy: 0.97531
Value Function Loss: 0.05073

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.01921
Policy Update Magnitude: 0.03072
Value Function Update Magnitude: 0.05352

Collected Steps per Second: 22,770.80961
Overall Steps per Second: 16,720.37636

Timestep Collection Time: 2.19694
Timestep Consumption Time: 0.79498
PPO Batch Consumption Time: 0.06004
Total Iteration Time: 2.99192

Cumulative Model Updates: 23,806
Cumulative Timesteps: 397,537,344

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 397537344...
Checkpoint 397537344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,897.20798
Policy Entropy: 0.97875
Value Function Loss: 0.04712

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01491
Policy Update Magnitude: 0.03105
Value Function Update Magnitude: 0.04935

Collected Steps per Second: 20,033.51413
Overall Steps per Second: 14,778.82718

Timestep Collection Time: 2.49722
Timestep Consumption Time: 0.88790
PPO Batch Consumption Time: 0.08725
Total Iteration Time: 3.38511

Cumulative Model Updates: 23,809
Cumulative Timesteps: 397,587,372

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,192.42070
Policy Entropy: 0.96280
Value Function Loss: 0.05135

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02539
Policy Update Magnitude: 0.03011
Value Function Update Magnitude: 0.04388

Collected Steps per Second: 22,567.33736
Overall Steps per Second: 15,731.84334

Timestep Collection Time: 2.21648
Timestep Consumption Time: 0.96306
PPO Batch Consumption Time: 0.11873
Total Iteration Time: 3.17954

Cumulative Model Updates: 23,812
Cumulative Timesteps: 397,637,392

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 397637392...
Checkpoint 397637392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,423.25824
Policy Entropy: 0.94080
Value Function Loss: 0.06062

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02123
Policy Update Magnitude: 0.03121
Value Function Update Magnitude: 0.04646

Collected Steps per Second: 20,184.01089
Overall Steps per Second: 15,563.50043

Timestep Collection Time: 2.47751
Timestep Consumption Time: 0.73552
PPO Batch Consumption Time: 0.02953
Total Iteration Time: 3.21303

Cumulative Model Updates: 23,815
Cumulative Timesteps: 397,687,398

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,084.19766
Policy Entropy: 0.94498
Value Function Loss: 0.05580

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01782
Policy Update Magnitude: 0.03281
Value Function Update Magnitude: 0.05114

Collected Steps per Second: 22,876.37774
Overall Steps per Second: 16,586.22789

Timestep Collection Time: 2.18662
Timestep Consumption Time: 0.82925
PPO Batch Consumption Time: 0.07302
Total Iteration Time: 3.01588

Cumulative Model Updates: 23,818
Cumulative Timesteps: 397,737,420

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 397737420...
Checkpoint 397737420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,636.99589
Policy Entropy: 0.94091
Value Function Loss: 0.05332

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03173
Policy Update Magnitude: 0.03237
Value Function Update Magnitude: 0.05246

Collected Steps per Second: 21,593.43172
Overall Steps per Second: 15,074.95977

Timestep Collection Time: 2.31626
Timestep Consumption Time: 1.00156
PPO Batch Consumption Time: 0.11785
Total Iteration Time: 3.31782

Cumulative Model Updates: 23,821
Cumulative Timesteps: 397,787,436

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,970.39666
Policy Entropy: 0.94235
Value Function Loss: 0.04688

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01531
Policy Update Magnitude: 0.03341
Value Function Update Magnitude: 0.04683

Collected Steps per Second: 23,660.79968
Overall Steps per Second: 17,138.94593

Timestep Collection Time: 2.11405
Timestep Consumption Time: 0.80445
PPO Batch Consumption Time: 0.06558
Total Iteration Time: 2.91850

Cumulative Model Updates: 23,824
Cumulative Timesteps: 397,837,456

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 397837456...
Checkpoint 397837456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,817.10003
Policy Entropy: 0.93538
Value Function Loss: 0.05107

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02527
Policy Update Magnitude: 0.03410
Value Function Update Magnitude: 0.04733

Collected Steps per Second: 22,724.99494
Overall Steps per Second: 15,807.28386

Timestep Collection Time: 2.20110
Timestep Consumption Time: 0.96326
PPO Batch Consumption Time: 0.08847
Total Iteration Time: 3.16436

Cumulative Model Updates: 23,827
Cumulative Timesteps: 397,887,476

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,988.83721
Policy Entropy: 0.94265
Value Function Loss: 0.04768

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02903
Policy Update Magnitude: 0.02956
Value Function Update Magnitude: 0.04211

Collected Steps per Second: 22,312.24627
Overall Steps per Second: 16,403.98232

Timestep Collection Time: 2.24155
Timestep Consumption Time: 0.80734
PPO Batch Consumption Time: 0.06240
Total Iteration Time: 3.04889

Cumulative Model Updates: 23,830
Cumulative Timesteps: 397,937,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 397937490...
Checkpoint 397937490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,881.73814
Policy Entropy: 0.94427
Value Function Loss: 0.05769

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02420
Policy Update Magnitude: 0.02994
Value Function Update Magnitude: 0.03680

Collected Steps per Second: 22,284.70576
Overall Steps per Second: 16,170.08292

Timestep Collection Time: 2.24486
Timestep Consumption Time: 0.84888
PPO Batch Consumption Time: 0.07981
Total Iteration Time: 3.09374

Cumulative Model Updates: 23,833
Cumulative Timesteps: 397,987,516

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,655.74551
Policy Entropy: 0.94722
Value Function Loss: 0.05716

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02209
Policy Update Magnitude: 0.03224
Value Function Update Magnitude: 0.03185

Collected Steps per Second: 20,233.04645
Overall Steps per Second: 14,991.26603

Timestep Collection Time: 2.47259
Timestep Consumption Time: 0.86455
PPO Batch Consumption Time: 0.07628
Total Iteration Time: 3.33714

Cumulative Model Updates: 23,836
Cumulative Timesteps: 398,037,544

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 398037544...
Checkpoint 398037544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,070.91722
Policy Entropy: 0.95240
Value Function Loss: 0.06311

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03169
Policy Update Magnitude: 0.03392
Value Function Update Magnitude: 0.03388

Collected Steps per Second: 22,664.27386
Overall Steps per Second: 15,941.30551

Timestep Collection Time: 2.20762
Timestep Consumption Time: 0.93102
PPO Batch Consumption Time: 0.08401
Total Iteration Time: 3.13864

Cumulative Model Updates: 23,839
Cumulative Timesteps: 398,087,578

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,543.64703
Policy Entropy: 0.96763
Value Function Loss: 0.05138

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02741
Policy Update Magnitude: 0.03162
Value Function Update Magnitude: 0.03140

Collected Steps per Second: 20,609.28273
Overall Steps per Second: 15,365.03023

Timestep Collection Time: 2.42648
Timestep Consumption Time: 0.82818
PPO Batch Consumption Time: 0.06375
Total Iteration Time: 3.25466

Cumulative Model Updates: 23,842
Cumulative Timesteps: 398,137,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 398137586...
Checkpoint 398137586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,019.95188
Policy Entropy: 0.98031
Value Function Loss: 0.05200

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02009
Policy Update Magnitude: 0.03060
Value Function Update Magnitude: 0.03275

Collected Steps per Second: 19,890.25730
Overall Steps per Second: 14,087.28474

Timestep Collection Time: 2.51530
Timestep Consumption Time: 1.03613
PPO Batch Consumption Time: 0.12846
Total Iteration Time: 3.55143

Cumulative Model Updates: 23,845
Cumulative Timesteps: 398,187,616

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,478.28835
Policy Entropy: 0.98772
Value Function Loss: 0.05189

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02180
Policy Update Magnitude: 0.03071
Value Function Update Magnitude: 0.03038

Collected Steps per Second: 23,019.12863
Overall Steps per Second: 16,410.51666

Timestep Collection Time: 2.17237
Timestep Consumption Time: 0.87483
PPO Batch Consumption Time: 0.08071
Total Iteration Time: 3.04719

Cumulative Model Updates: 23,848
Cumulative Timesteps: 398,237,622

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 398237622...
Checkpoint 398237622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,499.27633
Policy Entropy: 0.98725
Value Function Loss: 0.05861

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.02011
Policy Update Magnitude: 0.02993
Value Function Update Magnitude: 0.02868

Collected Steps per Second: 21,525.28091
Overall Steps per Second: 15,854.79863

Timestep Collection Time: 2.32313
Timestep Consumption Time: 0.83087
PPO Batch Consumption Time: 0.07875
Total Iteration Time: 3.15400

Cumulative Model Updates: 23,851
Cumulative Timesteps: 398,287,628

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,348.37900
Policy Entropy: 0.97293
Value Function Loss: 0.05751

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02405
Policy Update Magnitude: 0.03490
Value Function Update Magnitude: 0.02940

Collected Steps per Second: 22,158.32565
Overall Steps per Second: 16,275.63044

Timestep Collection Time: 2.25712
Timestep Consumption Time: 0.81582
PPO Batch Consumption Time: 0.06542
Total Iteration Time: 3.07294

Cumulative Model Updates: 23,854
Cumulative Timesteps: 398,337,642

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 398337642...
Checkpoint 398337642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,337.20531
Policy Entropy: 0.96802
Value Function Loss: 0.05408

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02372
Policy Update Magnitude: 0.03218
Value Function Update Magnitude: 0.03075

Collected Steps per Second: 22,018.89730
Overall Steps per Second: 15,784.71668

Timestep Collection Time: 2.27268
Timestep Consumption Time: 0.89760
PPO Batch Consumption Time: 0.08246
Total Iteration Time: 3.17028

Cumulative Model Updates: 23,857
Cumulative Timesteps: 398,387,684

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,139.04407
Policy Entropy: 0.97003
Value Function Loss: 0.04837

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.01811
Policy Update Magnitude: 0.03307
Value Function Update Magnitude: 0.03078

Collected Steps per Second: 22,659.39109
Overall Steps per Second: 16,739.29072

Timestep Collection Time: 2.20739
Timestep Consumption Time: 0.78067
PPO Batch Consumption Time: 0.06426
Total Iteration Time: 2.98806

Cumulative Model Updates: 23,860
Cumulative Timesteps: 398,437,702

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 398437702...
Checkpoint 398437702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,231.42748
Policy Entropy: 0.98065
Value Function Loss: 0.05205

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02694
Policy Update Magnitude: 0.03022
Value Function Update Magnitude: 0.03169

Collected Steps per Second: 20,233.86872
Overall Steps per Second: 14,323.11562

Timestep Collection Time: 2.47110
Timestep Consumption Time: 1.01976
PPO Batch Consumption Time: 0.12208
Total Iteration Time: 3.49086

Cumulative Model Updates: 23,863
Cumulative Timesteps: 398,487,702

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,794.23607
Policy Entropy: 0.97546
Value Function Loss: 0.05889

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03076
Policy Update Magnitude: 0.03002
Value Function Update Magnitude: 0.03183

Collected Steps per Second: 22,458.18000
Overall Steps per Second: 16,636.35014

Timestep Collection Time: 2.22770
Timestep Consumption Time: 0.77957
PPO Batch Consumption Time: 0.05877
Total Iteration Time: 3.00727

Cumulative Model Updates: 23,866
Cumulative Timesteps: 398,537,732

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 398537732...
Checkpoint 398537732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,066.25395
Policy Entropy: 0.97268
Value Function Loss: 0.06060

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02377
Policy Update Magnitude: 0.03347
Value Function Update Magnitude: 0.03283

Collected Steps per Second: 20,212.53386
Overall Steps per Second: 14,841.88570

Timestep Collection Time: 2.47470
Timestep Consumption Time: 0.89549
PPO Batch Consumption Time: 0.09413
Total Iteration Time: 3.37019

Cumulative Model Updates: 23,869
Cumulative Timesteps: 398,587,752

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,497.53209
Policy Entropy: 0.96574
Value Function Loss: 0.05700

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02017
Policy Update Magnitude: 0.03652
Value Function Update Magnitude: 0.02946

Collected Steps per Second: 22,745.74788
Overall Steps per Second: 16,616.89976

Timestep Collection Time: 2.19988
Timestep Consumption Time: 0.81139
PPO Batch Consumption Time: 0.06272
Total Iteration Time: 3.01127

Cumulative Model Updates: 23,872
Cumulative Timesteps: 398,637,790

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 398637790...
Checkpoint 398637790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,319.18620
Policy Entropy: 0.96786
Value Function Loss: 0.05540

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01979
Policy Update Magnitude: 0.03420
Value Function Update Magnitude: 0.03247

Collected Steps per Second: 21,940.92879
Overall Steps per Second: 16,777.77919

Timestep Collection Time: 2.27885
Timestep Consumption Time: 0.70129
PPO Batch Consumption Time: 0.02901
Total Iteration Time: 2.98013

Cumulative Model Updates: 23,875
Cumulative Timesteps: 398,687,790

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,875.50117
Policy Entropy: 0.96980
Value Function Loss: 0.05242

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02893
Policy Update Magnitude: 0.03154
Value Function Update Magnitude: 0.03403

Collected Steps per Second: 21,738.21561
Overall Steps per Second: 15,688.26571

Timestep Collection Time: 2.30028
Timestep Consumption Time: 0.88707
PPO Batch Consumption Time: 0.08441
Total Iteration Time: 3.18735

Cumulative Model Updates: 23,878
Cumulative Timesteps: 398,737,794

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 398737794...
Checkpoint 398737794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,547.96684
Policy Entropy: 0.98132
Value Function Loss: 0.05586

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01958
Policy Update Magnitude: 0.03147
Value Function Update Magnitude: 0.03614

Collected Steps per Second: 22,269.25687
Overall Steps per Second: 16,203.96042

Timestep Collection Time: 2.24525
Timestep Consumption Time: 0.84042
PPO Batch Consumption Time: 0.06904
Total Iteration Time: 3.08567

Cumulative Model Updates: 23,881
Cumulative Timesteps: 398,787,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,661.48808
Policy Entropy: 0.98664
Value Function Loss: 0.05492

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.02307
Policy Update Magnitude: 0.03235
Value Function Update Magnitude: 0.03661

Collected Steps per Second: 22,305.85829
Overall Steps per Second: 16,148.35260

Timestep Collection Time: 2.24300
Timestep Consumption Time: 0.85527
PPO Batch Consumption Time: 0.07902
Total Iteration Time: 3.09827

Cumulative Model Updates: 23,884
Cumulative Timesteps: 398,837,826

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 398837826...
Checkpoint 398837826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,734.40221
Policy Entropy: 0.98835
Value Function Loss: 0.05444

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03171
Policy Update Magnitude: 0.03180
Value Function Update Magnitude: 0.03877

Collected Steps per Second: 22,585.26901
Overall Steps per Second: 15,871.62242

Timestep Collection Time: 2.21419
Timestep Consumption Time: 0.93659
PPO Batch Consumption Time: 0.10164
Total Iteration Time: 3.15078

Cumulative Model Updates: 23,887
Cumulative Timesteps: 398,887,834

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,003.92949
Policy Entropy: 0.98742
Value Function Loss: 0.05495

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02670
Policy Update Magnitude: 0.03182
Value Function Update Magnitude: 0.03828

Collected Steps per Second: 23,036.15935
Overall Steps per Second: 16,715.04761

Timestep Collection Time: 2.17093
Timestep Consumption Time: 0.82098
PPO Batch Consumption Time: 0.06328
Total Iteration Time: 2.99191

Cumulative Model Updates: 23,890
Cumulative Timesteps: 398,937,844

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 398937844...
Checkpoint 398937844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,586.74443
Policy Entropy: 0.98812
Value Function Loss: 0.05276

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02994
Policy Update Magnitude: 0.03378
Value Function Update Magnitude: 0.04147

Collected Steps per Second: 18,914.79591
Overall Steps per Second: 14,045.59789

Timestep Collection Time: 2.64534
Timestep Consumption Time: 0.91706
PPO Batch Consumption Time: 0.09350
Total Iteration Time: 3.56240

Cumulative Model Updates: 23,893
Cumulative Timesteps: 398,987,880

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,214.25865
Policy Entropy: 0.98022
Value Function Loss: 0.06187

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02218
Policy Update Magnitude: 0.03416
Value Function Update Magnitude: 0.04231

Collected Steps per Second: 21,836.60177
Overall Steps per Second: 16,668.34754

Timestep Collection Time: 2.29028
Timestep Consumption Time: 0.71013
PPO Batch Consumption Time: 0.02937
Total Iteration Time: 3.00042

Cumulative Model Updates: 23,896
Cumulative Timesteps: 399,037,892

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 399037892...
Checkpoint 399037892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,724.42440
Policy Entropy: 0.98559
Value Function Loss: 0.05891

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01937
Policy Update Magnitude: 0.03233
Value Function Update Magnitude: 0.04917

Collected Steps per Second: 20,639.99156
Overall Steps per Second: 14,665.55428

Timestep Collection Time: 2.42394
Timestep Consumption Time: 0.98746
PPO Batch Consumption Time: 0.10953
Total Iteration Time: 3.41140

Cumulative Model Updates: 23,899
Cumulative Timesteps: 399,087,922

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,802.98476
Policy Entropy: 0.96837
Value Function Loss: 0.06926

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03616
Policy Update Magnitude: 0.03590
Value Function Update Magnitude: 0.05018

Collected Steps per Second: 22,156.78959
Overall Steps per Second: 15,724.33465

Timestep Collection Time: 2.25854
Timestep Consumption Time: 0.92392
PPO Batch Consumption Time: 0.10148
Total Iteration Time: 3.18246

Cumulative Model Updates: 23,902
Cumulative Timesteps: 399,137,964

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 399137964...
Checkpoint 399137964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,310.48978
Policy Entropy: 0.98017
Value Function Loss: 0.06391

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02765
Policy Update Magnitude: 0.03720
Value Function Update Magnitude: 0.05125

Collected Steps per Second: 22,385.05600
Overall Steps per Second: 16,625.87557

Timestep Collection Time: 2.23381
Timestep Consumption Time: 0.77379
PPO Batch Consumption Time: 0.05916
Total Iteration Time: 3.00760

Cumulative Model Updates: 23,905
Cumulative Timesteps: 399,187,968

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,024.63349
Policy Entropy: 0.97258
Value Function Loss: 0.06960

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02125
Policy Update Magnitude: 0.04474
Value Function Update Magnitude: 0.04905

Collected Steps per Second: 20,235.73772
Overall Steps per Second: 14,820.40463

Timestep Collection Time: 2.47097
Timestep Consumption Time: 0.90289
PPO Batch Consumption Time: 0.10253
Total Iteration Time: 3.37386

Cumulative Model Updates: 23,908
Cumulative Timesteps: 399,237,970

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 399237970...
Checkpoint 399237970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,701.56452
Policy Entropy: 0.98928
Value Function Loss: 0.06392

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02339
Policy Update Magnitude: 0.03885
Value Function Update Magnitude: 0.05115

Collected Steps per Second: 22,131.28456
Overall Steps per Second: 15,765.73737

Timestep Collection Time: 2.26006
Timestep Consumption Time: 0.91252
PPO Batch Consumption Time: 0.10378
Total Iteration Time: 3.17258

Cumulative Model Updates: 23,911
Cumulative Timesteps: 399,287,988

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,685.80451
Policy Entropy: 0.99061
Value Function Loss: 0.06220

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02551
Policy Update Magnitude: 0.03658
Value Function Update Magnitude: 0.05006

Collected Steps per Second: 21,947.21489
Overall Steps per Second: 15,786.78779

Timestep Collection Time: 2.27920
Timestep Consumption Time: 0.88940
PPO Batch Consumption Time: 0.08811
Total Iteration Time: 3.16860

Cumulative Model Updates: 23,914
Cumulative Timesteps: 399,338,010

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 399338010...
Checkpoint 399338010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,937.57611
Policy Entropy: 1.00120
Value Function Loss: 0.05576

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02656
Policy Update Magnitude: 0.03440
Value Function Update Magnitude: 0.04923

Collected Steps per Second: 22,873.69979
Overall Steps per Second: 16,637.92786

Timestep Collection Time: 2.18688
Timestep Consumption Time: 0.81963
PPO Batch Consumption Time: 0.05939
Total Iteration Time: 3.00650

Cumulative Model Updates: 23,917
Cumulative Timesteps: 399,388,032

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,887.61920
Policy Entropy: 0.99846
Value Function Loss: 0.04977

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02257
Policy Update Magnitude: 0.03207
Value Function Update Magnitude: 0.05088

Collected Steps per Second: 19,385.00757
Overall Steps per Second: 13,908.72893

Timestep Collection Time: 2.58117
Timestep Consumption Time: 1.01628
PPO Batch Consumption Time: 0.13423
Total Iteration Time: 3.59745

Cumulative Model Updates: 23,920
Cumulative Timesteps: 399,438,068

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 399438068...
Checkpoint 399438068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,657.98950
Policy Entropy: 0.99719
Value Function Loss: 0.05159

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03758
Policy Update Magnitude: 0.03089
Value Function Update Magnitude: 0.05128

Collected Steps per Second: 22,597.42831
Overall Steps per Second: 16,588.80073

Timestep Collection Time: 2.21326
Timestep Consumption Time: 0.80166
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 3.01493

Cumulative Model Updates: 23,923
Cumulative Timesteps: 399,488,082

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,225.52203
Policy Entropy: 0.99585
Value Function Loss: 0.04823

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04410
Policy Update Magnitude: 0.03294
Value Function Update Magnitude: 0.05281

Collected Steps per Second: 20,062.74080
Overall Steps per Second: 14,803.11230

Timestep Collection Time: 2.49238
Timestep Consumption Time: 0.88556
PPO Batch Consumption Time: 0.08712
Total Iteration Time: 3.37794

Cumulative Model Updates: 23,926
Cumulative Timesteps: 399,538,086

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 399538086...
Checkpoint 399538086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,712.53022
Policy Entropy: 0.98965
Value Function Loss: 0.05449

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06547
Policy Update Magnitude: 0.03161
Value Function Update Magnitude: 0.05504

Collected Steps per Second: 22,778.72074
Overall Steps per Second: 16,867.81141

Timestep Collection Time: 2.19644
Timestep Consumption Time: 0.76969
PPO Batch Consumption Time: 0.05932
Total Iteration Time: 2.96612

Cumulative Model Updates: 23,929
Cumulative Timesteps: 399,588,118

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,153.88507
Policy Entropy: 0.98369
Value Function Loss: 0.05947

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04253
Policy Update Magnitude: 0.03154
Value Function Update Magnitude: 0.05341

Collected Steps per Second: 19,355.58085
Overall Steps per Second: 14,390.67086

Timestep Collection Time: 2.58365
Timestep Consumption Time: 0.89138
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 3.47503

Cumulative Model Updates: 23,932
Cumulative Timesteps: 399,638,126

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 399638126...
Checkpoint 399638126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,351.24358
Policy Entropy: 0.99162
Value Function Loss: 0.05926

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04679
Policy Update Magnitude: 0.03122
Value Function Update Magnitude: 0.05457

Collected Steps per Second: 22,437.81016
Overall Steps per Second: 17,051.68597

Timestep Collection Time: 2.22901
Timestep Consumption Time: 0.70408
PPO Batch Consumption Time: 0.02998
Total Iteration Time: 2.93308

Cumulative Model Updates: 23,935
Cumulative Timesteps: 399,688,140

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,156.79041
Policy Entropy: 1.00617
Value Function Loss: 0.05328

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02847
Policy Update Magnitude: 0.03248
Value Function Update Magnitude: 0.05506

Collected Steps per Second: 22,343.23068
Overall Steps per Second: 15,793.32198

Timestep Collection Time: 2.23817
Timestep Consumption Time: 0.92823
PPO Batch Consumption Time: 0.09251
Total Iteration Time: 3.16640

Cumulative Model Updates: 23,938
Cumulative Timesteps: 399,738,148

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 399738148...
Checkpoint 399738148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,721.40347
Policy Entropy: 1.01271
Value Function Loss: 0.04840

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04719
Policy Update Magnitude: 0.03303
Value Function Update Magnitude: 0.05257

Collected Steps per Second: 21,746.18066
Overall Steps per Second: 16,247.43550

Timestep Collection Time: 2.30027
Timestep Consumption Time: 0.77850
PPO Batch Consumption Time: 0.06574
Total Iteration Time: 3.07876

Cumulative Model Updates: 23,941
Cumulative Timesteps: 399,788,170

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,012.54006
Policy Entropy: 1.00803
Value Function Loss: 0.05113

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04593
Policy Update Magnitude: 0.03368
Value Function Update Magnitude: 0.05234

Collected Steps per Second: 22,764.99959
Overall Steps per Second: 16,602.61999

Timestep Collection Time: 2.19653
Timestep Consumption Time: 0.81528
PPO Batch Consumption Time: 0.06637
Total Iteration Time: 3.01181

Cumulative Model Updates: 23,944
Cumulative Timesteps: 399,838,174

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 399838174...
Checkpoint 399838174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,453.60332
Policy Entropy: 1.00363
Value Function Loss: 0.05538

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05394
Policy Update Magnitude: 0.03799
Value Function Update Magnitude: 0.05585

Collected Steps per Second: 22,585.69638
Overall Steps per Second: 16,036.26626

Timestep Collection Time: 2.21397
Timestep Consumption Time: 0.90421
PPO Batch Consumption Time: 0.08668
Total Iteration Time: 3.11818

Cumulative Model Updates: 23,947
Cumulative Timesteps: 399,888,178

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,735.72641
Policy Entropy: 1.00516
Value Function Loss: 0.05004

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04405
Policy Update Magnitude: 0.03426
Value Function Update Magnitude: 0.05652

Collected Steps per Second: 22,459.07271
Overall Steps per Second: 15,864.90952

Timestep Collection Time: 2.22734
Timestep Consumption Time: 0.92578
PPO Batch Consumption Time: 0.09066
Total Iteration Time: 3.15312

Cumulative Model Updates: 23,950
Cumulative Timesteps: 399,938,202

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 399938202...
Checkpoint 399938202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,390.49166
Policy Entropy: 1.00485
Value Function Loss: 0.04829

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05597
Policy Update Magnitude: 0.03278
Value Function Update Magnitude: 0.05605

Collected Steps per Second: 21,119.79233
Overall Steps per Second: 15,475.71855

Timestep Collection Time: 2.36839
Timestep Consumption Time: 0.86377
PPO Batch Consumption Time: 0.08177
Total Iteration Time: 3.23216

Cumulative Model Updates: 23,953
Cumulative Timesteps: 399,988,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,809.68828
Policy Entropy: 1.00933
Value Function Loss: 0.04381

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03989
Policy Update Magnitude: 0.02931
Value Function Update Magnitude: 0.05486

Collected Steps per Second: 21,988.41873
Overall Steps per Second: 16,185.68178

Timestep Collection Time: 2.27438
Timestep Consumption Time: 0.81539
PPO Batch Consumption Time: 0.06947
Total Iteration Time: 3.08977

Cumulative Model Updates: 23,956
Cumulative Timesteps: 400,038,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 400038232...
Checkpoint 400038232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,806.88730
Policy Entropy: 1.00413
Value Function Loss: 0.04624

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06605
Policy Update Magnitude: 0.02866
Value Function Update Magnitude: 0.05484

Collected Steps per Second: 22,006.93693
Overall Steps per Second: 15,942.36631

Timestep Collection Time: 2.27328
Timestep Consumption Time: 0.86477
PPO Batch Consumption Time: 0.07729
Total Iteration Time: 3.13805

Cumulative Model Updates: 23,959
Cumulative Timesteps: 400,088,260

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,910.92962
Policy Entropy: 1.01239
Value Function Loss: 0.04616

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03891
Policy Update Magnitude: 0.02880
Value Function Update Magnitude: 0.05620

Collected Steps per Second: 19,217.49726
Overall Steps per Second: 14,387.28700

Timestep Collection Time: 2.60294
Timestep Consumption Time: 0.87388
PPO Batch Consumption Time: 0.07781
Total Iteration Time: 3.47682

Cumulative Model Updates: 23,962
Cumulative Timesteps: 400,138,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 400138282...
Checkpoint 400138282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,982.28602
Policy Entropy: 1.01346
Value Function Loss: 0.04459

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03923
Policy Update Magnitude: 0.03114
Value Function Update Magnitude: 0.05542

Collected Steps per Second: 22,502.19962
Overall Steps per Second: 16,468.16217

Timestep Collection Time: 2.22334
Timestep Consumption Time: 0.81465
PPO Batch Consumption Time: 0.06127
Total Iteration Time: 3.03798

Cumulative Model Updates: 23,965
Cumulative Timesteps: 400,188,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,764.64650
Policy Entropy: 1.01749
Value Function Loss: 0.04859

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03659
Policy Update Magnitude: 0.03108
Value Function Update Magnitude: 0.05179

Collected Steps per Second: 20,283.06110
Overall Steps per Second: 14,580.08742

Timestep Collection Time: 2.46629
Timestep Consumption Time: 0.96469
PPO Batch Consumption Time: 0.09866
Total Iteration Time: 3.43098

Cumulative Model Updates: 23,968
Cumulative Timesteps: 400,238,336

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 400238336...
Checkpoint 400238336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,736.70332
Policy Entropy: 1.00713
Value Function Loss: 0.04890

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03441
Policy Update Magnitude: 0.03232
Value Function Update Magnitude: 0.05346

Collected Steps per Second: 23,408.60213
Overall Steps per Second: 17,659.03806

Timestep Collection Time: 2.13657
Timestep Consumption Time: 0.69564
PPO Batch Consumption Time: 0.02932
Total Iteration Time: 2.83220

Cumulative Model Updates: 23,971
Cumulative Timesteps: 400,288,350

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,363.59079
Policy Entropy: 1.01242
Value Function Loss: 0.05097

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.04006
Policy Update Magnitude: 0.03086
Value Function Update Magnitude: 0.05768

Collected Steps per Second: 20,898.96385
Overall Steps per Second: 15,639.77370

Timestep Collection Time: 2.39294
Timestep Consumption Time: 0.80468
PPO Batch Consumption Time: 0.03461
Total Iteration Time: 3.19762

Cumulative Model Updates: 23,974
Cumulative Timesteps: 400,338,360

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 400338360...
Checkpoint 400338360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,856.07552
Policy Entropy: 1.00757
Value Function Loss: 0.04920

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03301
Policy Update Magnitude: 0.03218
Value Function Update Magnitude: 0.05966

Collected Steps per Second: 21,524.38899
Overall Steps per Second: 15,595.05763

Timestep Collection Time: 2.32341
Timestep Consumption Time: 0.88337
PPO Batch Consumption Time: 0.07107
Total Iteration Time: 3.20679

Cumulative Model Updates: 23,977
Cumulative Timesteps: 400,388,370

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,138.12106
Policy Entropy: 1.01467
Value Function Loss: 0.04900

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02913
Policy Update Magnitude: 0.03551
Value Function Update Magnitude: 0.05905

Collected Steps per Second: 20,509.82238
Overall Steps per Second: 15,536.16224

Timestep Collection Time: 2.43844
Timestep Consumption Time: 0.78063
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 3.21907

Cumulative Model Updates: 23,980
Cumulative Timesteps: 400,438,382

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 400438382...
Checkpoint 400438382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,608.95832
Policy Entropy: 1.00530
Value Function Loss: 0.05120

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01595
Policy Update Magnitude: 0.04056
Value Function Update Magnitude: 0.05810

Collected Steps per Second: 20,262.66854
Overall Steps per Second: 15,024.03630

Timestep Collection Time: 2.46868
Timestep Consumption Time: 0.86079
PPO Batch Consumption Time: 0.06352
Total Iteration Time: 3.32946

Cumulative Model Updates: 23,983
Cumulative Timesteps: 400,488,404

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,779.25988
Policy Entropy: 0.99774
Value Function Loss: 0.05218

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03158
Policy Update Magnitude: 0.03711
Value Function Update Magnitude: 0.05903

Collected Steps per Second: 18,421.04111
Overall Steps per Second: 12,988.06043

Timestep Collection Time: 2.71700
Timestep Consumption Time: 1.13654
PPO Batch Consumption Time: 0.12196
Total Iteration Time: 3.85354

Cumulative Model Updates: 23,986
Cumulative Timesteps: 400,538,454

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 400538454...
Checkpoint 400538454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,236.18819
Policy Entropy: 0.99804
Value Function Loss: 0.05049

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04545
Policy Update Magnitude: 0.03491
Value Function Update Magnitude: 0.05856

Collected Steps per Second: 18,803.22362
Overall Steps per Second: 14,542.39958

Timestep Collection Time: 2.65976
Timestep Consumption Time: 0.77929
PPO Batch Consumption Time: 0.02948
Total Iteration Time: 3.43905

Cumulative Model Updates: 23,989
Cumulative Timesteps: 400,588,466

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,021.39233
Policy Entropy: 1.01739
Value Function Loss: 0.04777

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03042
Policy Update Magnitude: 0.03588
Value Function Update Magnitude: 0.05473

Collected Steps per Second: 20,220.28223
Overall Steps per Second: 15,147.65359

Timestep Collection Time: 2.47375
Timestep Consumption Time: 0.82841
PPO Batch Consumption Time: 0.04856
Total Iteration Time: 3.30216

Cumulative Model Updates: 23,992
Cumulative Timesteps: 400,638,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 400638486...
Checkpoint 400638486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,134.62677
Policy Entropy: 1.01866
Value Function Loss: 0.04843

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03122
Policy Update Magnitude: 0.03471
Value Function Update Magnitude: 0.05007

Collected Steps per Second: 21,262.70906
Overall Steps per Second: 14,807.94536

Timestep Collection Time: 2.35248
Timestep Consumption Time: 1.02544
PPO Batch Consumption Time: 0.11827
Total Iteration Time: 3.37792

Cumulative Model Updates: 23,995
Cumulative Timesteps: 400,688,506

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,665.60734
Policy Entropy: 1.03012
Value Function Loss: 0.05000

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02424
Policy Update Magnitude: 0.03077
Value Function Update Magnitude: 0.04764

Collected Steps per Second: 17,306.26636
Overall Steps per Second: 13,380.88258

Timestep Collection Time: 2.89051
Timestep Consumption Time: 0.84795
PPO Batch Consumption Time: 0.06220
Total Iteration Time: 3.73847

Cumulative Model Updates: 23,998
Cumulative Timesteps: 400,738,530

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 400738530...
Checkpoint 400738530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,404.19281
Policy Entropy: 1.01666
Value Function Loss: 0.04708

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01581
Policy Update Magnitude: 0.03039
Value Function Update Magnitude: 0.04816

Collected Steps per Second: 20,772.29937
Overall Steps per Second: 15,270.11396

Timestep Collection Time: 2.40744
Timestep Consumption Time: 0.86746
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 3.27489

Cumulative Model Updates: 24,001
Cumulative Timesteps: 400,788,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,853.78370
Policy Entropy: 1.02805
Value Function Loss: 0.04966

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01497
Policy Update Magnitude: 0.03204
Value Function Update Magnitude: 0.05192

Collected Steps per Second: 15,417.39721
Overall Steps per Second: 11,781.27759

Timestep Collection Time: 3.24439
Timestep Consumption Time: 1.00133
PPO Batch Consumption Time: 0.06751
Total Iteration Time: 4.24572

Cumulative Model Updates: 24,004
Cumulative Timesteps: 400,838,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 400838558...
Checkpoint 400838558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,801.60617
Policy Entropy: 1.01313
Value Function Loss: 0.05126

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02193
Policy Update Magnitude: 0.03211
Value Function Update Magnitude: 0.05230

Collected Steps per Second: 13,754.15852
Overall Steps per Second: 11,020.75866

Timestep Collection Time: 3.63672
Timestep Consumption Time: 0.90199
PPO Batch Consumption Time: 0.06991
Total Iteration Time: 4.53871

Cumulative Model Updates: 24,007
Cumulative Timesteps: 400,888,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,777.11666
Policy Entropy: 1.01276
Value Function Loss: 0.05668

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.02061
Policy Update Magnitude: 0.03093
Value Function Update Magnitude: 0.04870

Collected Steps per Second: 17,807.06478
Overall Steps per Second: 13,753.07842

Timestep Collection Time: 2.80844
Timestep Consumption Time: 0.82784
PPO Batch Consumption Time: 0.05792
Total Iteration Time: 3.63628

Cumulative Model Updates: 24,010
Cumulative Timesteps: 400,938,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 400938588...
Checkpoint 400938588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,248.67248
Policy Entropy: 0.99872
Value Function Loss: 0.05559

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02089
Policy Update Magnitude: 0.03080
Value Function Update Magnitude: 0.04678

Collected Steps per Second: 19,385.15807
Overall Steps per Second: 14,532.14144

Timestep Collection Time: 2.57991
Timestep Consumption Time: 0.86156
PPO Batch Consumption Time: 0.07211
Total Iteration Time: 3.44147

Cumulative Model Updates: 24,013
Cumulative Timesteps: 400,988,600

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,903.19002
Policy Entropy: 0.99028
Value Function Loss: 0.05771

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01544
Policy Update Magnitude: 0.03145
Value Function Update Magnitude: 0.04882

Collected Steps per Second: 19,449.83746
Overall Steps per Second: 14,802.85005

Timestep Collection Time: 2.57154
Timestep Consumption Time: 0.80727
PPO Batch Consumption Time: 0.06319
Total Iteration Time: 3.37881

Cumulative Model Updates: 24,016
Cumulative Timesteps: 401,038,616

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 401038616...
Checkpoint 401038616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,470.64158
Policy Entropy: 0.97573
Value Function Loss: 0.05566

Mean KL Divergence: 0.00151
SB3 Clip Fraction: 0.01301
Policy Update Magnitude: 0.03220
Value Function Update Magnitude: 0.04488

Collected Steps per Second: 19,560.64686
Overall Steps per Second: 14,756.88370

Timestep Collection Time: 2.55840
Timestep Consumption Time: 0.83283
PPO Batch Consumption Time: 0.06129
Total Iteration Time: 3.39123

Cumulative Model Updates: 24,019
Cumulative Timesteps: 401,088,660

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,402.93026
Policy Entropy: 0.98434
Value Function Loss: 0.05726

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02255
Policy Update Magnitude: 0.03167
Value Function Update Magnitude: 0.04145

Collected Steps per Second: 19,895.27175
Overall Steps per Second: 14,858.42296

Timestep Collection Time: 2.51376
Timestep Consumption Time: 0.85214
PPO Batch Consumption Time: 0.06446
Total Iteration Time: 3.36590

Cumulative Model Updates: 24,022
Cumulative Timesteps: 401,138,672

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 401138672...
Checkpoint 401138672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,753.77349
Policy Entropy: 0.98488
Value Function Loss: 0.05551

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03781
Policy Update Magnitude: 0.03228
Value Function Update Magnitude: 0.04395

Collected Steps per Second: 19,491.88112
Overall Steps per Second: 14,800.32670

Timestep Collection Time: 2.56548
Timestep Consumption Time: 0.81323
PPO Batch Consumption Time: 0.06260
Total Iteration Time: 3.37871

Cumulative Model Updates: 24,025
Cumulative Timesteps: 401,188,678

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,488.82903
Policy Entropy: 0.99447
Value Function Loss: 0.05514

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03029
Policy Update Magnitude: 0.03355
Value Function Update Magnitude: 0.04760

Collected Steps per Second: 19,863.35149
Overall Steps per Second: 14,868.46145

Timestep Collection Time: 2.51780
Timestep Consumption Time: 0.84583
PPO Batch Consumption Time: 0.06773
Total Iteration Time: 3.36363

Cumulative Model Updates: 24,028
Cumulative Timesteps: 401,238,690

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 401238690...
Checkpoint 401238690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,742.72002
Policy Entropy: 0.96592
Value Function Loss: 0.05549

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04432
Policy Update Magnitude: 0.03305
Value Function Update Magnitude: 0.04531

Collected Steps per Second: 19,041.25075
Overall Steps per Second: 14,687.23718

Timestep Collection Time: 2.62640
Timestep Consumption Time: 0.77859
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 3.40500

Cumulative Model Updates: 24,031
Cumulative Timesteps: 401,288,700

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,222.16826
Policy Entropy: 0.96468
Value Function Loss: 0.05869

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03483
Policy Update Magnitude: 0.03149
Value Function Update Magnitude: 0.04499

Collected Steps per Second: 19,706.44767
Overall Steps per Second: 15,058.72687

Timestep Collection Time: 2.53866
Timestep Consumption Time: 0.78353
PPO Batch Consumption Time: 0.05255
Total Iteration Time: 3.32219

Cumulative Model Updates: 24,034
Cumulative Timesteps: 401,338,728

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 401338728...
Checkpoint 401338728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,539.26275
Policy Entropy: 0.96719
Value Function Loss: 0.05848

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03729
Policy Update Magnitude: 0.03232
Value Function Update Magnitude: 0.04486

Collected Steps per Second: 19,638.91184
Overall Steps per Second: 14,832.73753

Timestep Collection Time: 2.54648
Timestep Consumption Time: 0.82512
PPO Batch Consumption Time: 0.05844
Total Iteration Time: 3.37160

Cumulative Model Updates: 24,037
Cumulative Timesteps: 401,388,738

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,205.28210
Policy Entropy: 0.97095
Value Function Loss: 0.05741

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02667
Policy Update Magnitude: 0.03390
Value Function Update Magnitude: 0.04390

Collected Steps per Second: 19,827.29485
Overall Steps per Second: 15,100.98691

Timestep Collection Time: 2.52208
Timestep Consumption Time: 0.78936
PPO Batch Consumption Time: 0.05903
Total Iteration Time: 3.31144

Cumulative Model Updates: 24,040
Cumulative Timesteps: 401,438,744

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 401438744...
Checkpoint 401438744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,190.25975
Policy Entropy: 0.98767
Value Function Loss: 0.04860

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04103
Policy Update Magnitude: 0.03355
Value Function Update Magnitude: 0.04426

Collected Steps per Second: 19,665.68106
Overall Steps per Second: 14,833.77340

Timestep Collection Time: 2.54281
Timestep Consumption Time: 0.82829
PPO Batch Consumption Time: 0.05760
Total Iteration Time: 3.37109

Cumulative Model Updates: 24,043
Cumulative Timesteps: 401,488,750

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,222.99646
Policy Entropy: 0.99340
Value Function Loss: 0.04572

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03597
Policy Update Magnitude: 0.03176
Value Function Update Magnitude: 0.03986

Collected Steps per Second: 20,187.84473
Overall Steps per Second: 15,273.12788

Timestep Collection Time: 2.47704
Timestep Consumption Time: 0.79708
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 3.27412

Cumulative Model Updates: 24,046
Cumulative Timesteps: 401,538,756

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 401538756...
Checkpoint 401538756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,491.92799
Policy Entropy: 0.98800
Value Function Loss: 0.04447

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05288
Policy Update Magnitude: 0.03029
Value Function Update Magnitude: 0.03810

Collected Steps per Second: 19,676.45918
Overall Steps per Second: 15,118.81119

Timestep Collection Time: 2.54202
Timestep Consumption Time: 0.76631
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 3.30833

Cumulative Model Updates: 24,049
Cumulative Timesteps: 401,588,774

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,533.96224
Policy Entropy: 0.98979
Value Function Loss: 0.04852

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05651
Policy Update Magnitude: 0.02803
Value Function Update Magnitude: 0.04011

Collected Steps per Second: 19,963.11996
Overall Steps per Second: 14,880.38702

Timestep Collection Time: 2.50542
Timestep Consumption Time: 0.85578
PPO Batch Consumption Time: 0.06626
Total Iteration Time: 3.36120

Cumulative Model Updates: 24,052
Cumulative Timesteps: 401,638,790

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 401638790...
Checkpoint 401638790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,038.11155
Policy Entropy: 0.97683
Value Function Loss: 0.05676

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06183
Policy Update Magnitude: 0.02789
Value Function Update Magnitude: 0.04658

Collected Steps per Second: 19,715.65437
Overall Steps per Second: 14,879.15690

Timestep Collection Time: 2.53697
Timestep Consumption Time: 0.82465
PPO Batch Consumption Time: 0.05810
Total Iteration Time: 3.36162

Cumulative Model Updates: 24,055
Cumulative Timesteps: 401,688,808

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,237.35496
Policy Entropy: 0.98461
Value Function Loss: 0.05569

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05375
Policy Update Magnitude: 0.03256
Value Function Update Magnitude: 0.05973

Collected Steps per Second: 19,662.07494
Overall Steps per Second: 14,776.11264

Timestep Collection Time: 2.54348
Timestep Consumption Time: 0.84104
PPO Batch Consumption Time: 0.05973
Total Iteration Time: 3.38452

Cumulative Model Updates: 24,058
Cumulative Timesteps: 401,738,818

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 401738818...
Checkpoint 401738818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,165.67263
Policy Entropy: 0.96850
Value Function Loss: 0.06151

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.04072
Policy Update Magnitude: 0.03937
Value Function Update Magnitude: 0.06971

Collected Steps per Second: 19,983.03504
Overall Steps per Second: 15,241.51846

Timestep Collection Time: 2.50292
Timestep Consumption Time: 0.77864
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 3.28156

Cumulative Model Updates: 24,061
Cumulative Timesteps: 401,788,834

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,520.01173
Policy Entropy: 0.97048
Value Function Loss: 0.06118

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03232
Policy Update Magnitude: 0.04333
Value Function Update Magnitude: 0.07052

Collected Steps per Second: 19,967.97413
Overall Steps per Second: 15,193.70193

Timestep Collection Time: 2.50541
Timestep Consumption Time: 0.78727
PPO Batch Consumption Time: 0.06022
Total Iteration Time: 3.29268

Cumulative Model Updates: 24,064
Cumulative Timesteps: 401,838,862

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 401838862...
Checkpoint 401838862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,307.78607
Policy Entropy: 0.97427
Value Function Loss: 0.06248

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03219
Policy Update Magnitude: 0.04329
Value Function Update Magnitude: 0.06161

Collected Steps per Second: 19,750.24835
Overall Steps per Second: 14,814.65899

Timestep Collection Time: 2.53172
Timestep Consumption Time: 0.84346
PPO Batch Consumption Time: 0.06267
Total Iteration Time: 3.37517

Cumulative Model Updates: 24,067
Cumulative Timesteps: 401,888,864

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,595.99517
Policy Entropy: 0.98472
Value Function Loss: 0.05636

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03532
Policy Update Magnitude: 0.04320
Value Function Update Magnitude: 0.06034

Collected Steps per Second: 19,657.56809
Overall Steps per Second: 14,895.62183

Timestep Collection Time: 2.54518
Timestep Consumption Time: 0.81366
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 3.35884

Cumulative Model Updates: 24,070
Cumulative Timesteps: 401,938,896

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 401938896...
Checkpoint 401938896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,378.53759
Policy Entropy: 0.99898
Value Function Loss: 0.05591

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03137
Policy Update Magnitude: 0.04345
Value Function Update Magnitude: 0.05812

Collected Steps per Second: 18,664.63787
Overall Steps per Second: 14,403.58631

Timestep Collection Time: 2.67929
Timestep Consumption Time: 0.79262
PPO Batch Consumption Time: 0.05408
Total Iteration Time: 3.47191

Cumulative Model Updates: 24,073
Cumulative Timesteps: 401,988,904

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,725.14168
Policy Entropy: 0.99513
Value Function Loss: 0.05165

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03602
Policy Update Magnitude: 0.03831
Value Function Update Magnitude: 0.06168

Collected Steps per Second: 19,042.63354
Overall Steps per Second: 14,604.76106

Timestep Collection Time: 2.62590
Timestep Consumption Time: 0.79792
PPO Batch Consumption Time: 0.04792
Total Iteration Time: 3.42381

Cumulative Model Updates: 24,076
Cumulative Timesteps: 402,038,908

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 402038908...
Checkpoint 402038908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,880.28484
Policy Entropy: 0.98438
Value Function Loss: 0.05008

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02034
Policy Update Magnitude: 0.03508
Value Function Update Magnitude: 0.06269

Collected Steps per Second: 18,678.25914
Overall Steps per Second: 14,323.86734

Timestep Collection Time: 2.67691
Timestep Consumption Time: 0.81377
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 3.49068

Cumulative Model Updates: 24,079
Cumulative Timesteps: 402,088,908

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,229.33106
Policy Entropy: 0.97544
Value Function Loss: 0.04690

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02940
Policy Update Magnitude: 0.03283
Value Function Update Magnitude: 0.05555

Collected Steps per Second: 19,435.07422
Overall Steps per Second: 14,810.39584

Timestep Collection Time: 2.57370
Timestep Consumption Time: 0.80366
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 3.37736

Cumulative Model Updates: 24,082
Cumulative Timesteps: 402,138,928

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 402138928...
Checkpoint 402138928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,130.75446
Policy Entropy: 0.98541
Value Function Loss: 0.04633

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.02042
Policy Update Magnitude: 0.03382
Value Function Update Magnitude: 0.05505

Collected Steps per Second: 18,951.76521
Overall Steps per Second: 14,491.66700

Timestep Collection Time: 2.63838
Timestep Consumption Time: 0.81201
PPO Batch Consumption Time: 0.05243
Total Iteration Time: 3.45040

Cumulative Model Updates: 24,085
Cumulative Timesteps: 402,188,930

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,894.01240
Policy Entropy: 0.97401
Value Function Loss: 0.05164

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02255
Policy Update Magnitude: 0.03298
Value Function Update Magnitude: 0.05821

Collected Steps per Second: 19,342.73212
Overall Steps per Second: 14,769.14438

Timestep Collection Time: 2.58691
Timestep Consumption Time: 0.80109
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 3.38801

Cumulative Model Updates: 24,088
Cumulative Timesteps: 402,238,968

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 402238968...
Checkpoint 402238968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,084.59223
Policy Entropy: 0.96848
Value Function Loss: 0.05747

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02364
Policy Update Magnitude: 0.03441
Value Function Update Magnitude: 0.06283

Collected Steps per Second: 19,438.58889
Overall Steps per Second: 14,871.16897

Timestep Collection Time: 2.57282
Timestep Consumption Time: 0.79020
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 3.36302

Cumulative Model Updates: 24,091
Cumulative Timesteps: 402,288,980

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,537.36740
Policy Entropy: 0.95935
Value Function Loss: 0.06156

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03969
Policy Update Magnitude: 0.03489
Value Function Update Magnitude: 0.06528

Collected Steps per Second: 19,099.18513
Overall Steps per Second: 14,680.03828

Timestep Collection Time: 2.61959
Timestep Consumption Time: 0.78858
PPO Batch Consumption Time: 0.06142
Total Iteration Time: 3.40817

Cumulative Model Updates: 24,094
Cumulative Timesteps: 402,339,012

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 402339012...
Checkpoint 402339012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,280.78124
Policy Entropy: 0.96978
Value Function Loss: 0.05734

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02632
Policy Update Magnitude: 0.03788
Value Function Update Magnitude: 0.06595

Collected Steps per Second: 19,487.38492
Overall Steps per Second: 14,749.33082

Timestep Collection Time: 2.56669
Timestep Consumption Time: 0.82452
PPO Batch Consumption Time: 0.05420
Total Iteration Time: 3.39120

Cumulative Model Updates: 24,097
Cumulative Timesteps: 402,389,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,250.69903
Policy Entropy: 0.97105
Value Function Loss: 0.05232

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03269
Policy Update Magnitude: 0.03634
Value Function Update Magnitude: 0.05828

Collected Steps per Second: 19,034.52020
Overall Steps per Second: 14,475.01384

Timestep Collection Time: 2.62691
Timestep Consumption Time: 0.82745
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 3.45437

Cumulative Model Updates: 24,100
Cumulative Timesteps: 402,439,032

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 402439032...
Checkpoint 402439032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,014.23550
Policy Entropy: 0.97222
Value Function Loss: 0.04869

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02905
Policy Update Magnitude: 0.03474
Value Function Update Magnitude: 0.05511

Collected Steps per Second: 19,324.81176
Overall Steps per Second: 14,630.70760

Timestep Collection Time: 2.58776
Timestep Consumption Time: 0.83026
PPO Batch Consumption Time: 0.06114
Total Iteration Time: 3.41802

Cumulative Model Updates: 24,103
Cumulative Timesteps: 402,489,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,596.71738
Policy Entropy: 0.96775
Value Function Loss: 0.05019

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02822
Policy Update Magnitude: 0.03383
Value Function Update Magnitude: 0.04963

Collected Steps per Second: 19,704.05769
Overall Steps per Second: 14,885.74157

Timestep Collection Time: 2.53775
Timestep Consumption Time: 0.82144
PPO Batch Consumption Time: 0.05919
Total Iteration Time: 3.35919

Cumulative Model Updates: 24,106
Cumulative Timesteps: 402,539,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 402539044...
Checkpoint 402539044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,461.28254
Policy Entropy: 0.97944
Value Function Loss: 0.05055

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02535
Policy Update Magnitude: 0.03354
Value Function Update Magnitude: 0.04751

Collected Steps per Second: 19,663.90294
Overall Steps per Second: 14,868.62255

Timestep Collection Time: 2.54375
Timestep Consumption Time: 0.82038
PPO Batch Consumption Time: 0.05361
Total Iteration Time: 3.36413

Cumulative Model Updates: 24,109
Cumulative Timesteps: 402,589,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,425.79658
Policy Entropy: 0.98464
Value Function Loss: 0.05521

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02489
Policy Update Magnitude: 0.03393
Value Function Update Magnitude: 0.04890

Collected Steps per Second: 19,717.95370
Overall Steps per Second: 15,009.57027

Timestep Collection Time: 2.53647
Timestep Consumption Time: 0.79567
PPO Batch Consumption Time: 0.05768
Total Iteration Time: 3.33214

Cumulative Model Updates: 24,112
Cumulative Timesteps: 402,639,078

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 402639078...
Checkpoint 402639078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,597.38790
Policy Entropy: 0.97806
Value Function Loss: 0.05852

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02927
Policy Update Magnitude: 0.03539
Value Function Update Magnitude: 0.05661

Collected Steps per Second: 19,584.17160
Overall Steps per Second: 14,979.81076

Timestep Collection Time: 2.55482
Timestep Consumption Time: 0.78528
PPO Batch Consumption Time: 0.05878
Total Iteration Time: 3.34010

Cumulative Model Updates: 24,115
Cumulative Timesteps: 402,689,112

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,152.45637
Policy Entropy: 0.96054
Value Function Loss: 0.06053

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03607
Policy Update Magnitude: 0.03555
Value Function Update Magnitude: 0.06166

Collected Steps per Second: 19,850.54116
Overall Steps per Second: 15,119.60346

Timestep Collection Time: 2.51993
Timestep Consumption Time: 0.78849
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 3.30842

Cumulative Model Updates: 24,118
Cumulative Timesteps: 402,739,134

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 402739134...
Checkpoint 402739134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,541.09531
Policy Entropy: 0.96322
Value Function Loss: 0.06221

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02992
Policy Update Magnitude: 0.03485
Value Function Update Magnitude: 0.05850

Collected Steps per Second: 16,385.21381
Overall Steps per Second: 12,888.94975

Timestep Collection Time: 3.05165
Timestep Consumption Time: 0.82779
PPO Batch Consumption Time: 0.07138
Total Iteration Time: 3.87945

Cumulative Model Updates: 24,121
Cumulative Timesteps: 402,789,136

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,892.79057
Policy Entropy: 0.97476
Value Function Loss: 0.06711

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02744
Policy Update Magnitude: 0.04166
Value Function Update Magnitude: 0.06607

Collected Steps per Second: 19,205.96113
Overall Steps per Second: 14,738.43303

Timestep Collection Time: 2.60461
Timestep Consumption Time: 0.78951
PPO Batch Consumption Time: 0.05773
Total Iteration Time: 3.39412

Cumulative Model Updates: 24,124
Cumulative Timesteps: 402,839,160

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 402839160...
Checkpoint 402839160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,326.11605
Policy Entropy: 0.98870
Value Function Loss: 0.06731

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02700
Policy Update Magnitude: 0.04077
Value Function Update Magnitude: 0.07362

Collected Steps per Second: 19,328.72181
Overall Steps per Second: 14,811.17674

Timestep Collection Time: 2.58807
Timestep Consumption Time: 0.78938
PPO Batch Consumption Time: 0.05790
Total Iteration Time: 3.37745

Cumulative Model Updates: 24,127
Cumulative Timesteps: 402,889,184

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,320.41756
Policy Entropy: 1.00856
Value Function Loss: 0.06239

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03673
Policy Update Magnitude: 0.03770
Value Function Update Magnitude: 0.07623

Collected Steps per Second: 19,384.06027
Overall Steps per Second: 14,689.31491

Timestep Collection Time: 2.58057
Timestep Consumption Time: 0.82476
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 3.40533

Cumulative Model Updates: 24,130
Cumulative Timesteps: 402,939,206

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 402939206...
Checkpoint 402939206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,119.00016
Policy Entropy: 1.01075
Value Function Loss: 0.05584

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02467
Policy Update Magnitude: 0.03866
Value Function Update Magnitude: 0.07204

Collected Steps per Second: 19,293.99847
Overall Steps per Second: 14,786.42434

Timestep Collection Time: 2.59179
Timestep Consumption Time: 0.79010
PPO Batch Consumption Time: 0.05850
Total Iteration Time: 3.38189

Cumulative Model Updates: 24,133
Cumulative Timesteps: 402,989,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,157.17893
Policy Entropy: 1.01630
Value Function Loss: 0.05304

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03884
Policy Update Magnitude: 0.03793
Value Function Update Magnitude: 0.06469

Collected Steps per Second: 19,387.38228
Overall Steps per Second: 14,881.21133

Timestep Collection Time: 2.58044
Timestep Consumption Time: 0.78138
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 3.36182

Cumulative Model Updates: 24,136
Cumulative Timesteps: 403,039,240

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 403039240...
Checkpoint 403039240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,022.45960
Policy Entropy: 1.00226
Value Function Loss: 0.05713

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03931
Policy Update Magnitude: 0.03888
Value Function Update Magnitude: 0.05861

Collected Steps per Second: 19,372.88001
Overall Steps per Second: 14,655.13451

Timestep Collection Time: 2.58103
Timestep Consumption Time: 0.83088
PPO Batch Consumption Time: 0.06316
Total Iteration Time: 3.41191

Cumulative Model Updates: 24,139
Cumulative Timesteps: 403,089,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,699.63848
Policy Entropy: 0.98620
Value Function Loss: 0.05918

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03896
Policy Update Magnitude: 0.03640
Value Function Update Magnitude: 0.05579

Collected Steps per Second: 18,722.50217
Overall Steps per Second: 14,516.99935

Timestep Collection Time: 2.67144
Timestep Consumption Time: 0.77390
PPO Batch Consumption Time: 0.05126
Total Iteration Time: 3.44534

Cumulative Model Updates: 24,142
Cumulative Timesteps: 403,139,258

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 403139258...
Checkpoint 403139258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,392.18726
Policy Entropy: 0.98852
Value Function Loss: 0.05675

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03453
Policy Update Magnitude: 0.03955
Value Function Update Magnitude: 0.05493

Collected Steps per Second: 18,409.02276
Overall Steps per Second: 14,162.41564

Timestep Collection Time: 2.71801
Timestep Consumption Time: 0.81500
PPO Batch Consumption Time: 0.06239
Total Iteration Time: 3.53301

Cumulative Model Updates: 24,145
Cumulative Timesteps: 403,189,294

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,589.12644
Policy Entropy: 0.99491
Value Function Loss: 0.05852

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02837
Policy Update Magnitude: 0.04081
Value Function Update Magnitude: 0.05786

Collected Steps per Second: 19,534.20630
Overall Steps per Second: 14,927.58991

Timestep Collection Time: 2.56074
Timestep Consumption Time: 0.79024
PPO Batch Consumption Time: 0.05824
Total Iteration Time: 3.35098

Cumulative Model Updates: 24,148
Cumulative Timesteps: 403,239,316

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 403239316...
Checkpoint 403239316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,513.91369
Policy Entropy: 1.01726
Value Function Loss: 0.05492

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02362
Policy Update Magnitude: 0.04167
Value Function Update Magnitude: 0.06033

Collected Steps per Second: 18,971.38489
Overall Steps per Second: 14,558.88166

Timestep Collection Time: 2.63681
Timestep Consumption Time: 0.79916
PPO Batch Consumption Time: 0.05379
Total Iteration Time: 3.43598

Cumulative Model Updates: 24,151
Cumulative Timesteps: 403,289,340

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,494.81979
Policy Entropy: 1.00895
Value Function Loss: 0.05785

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02069
Policy Update Magnitude: 0.04070
Value Function Update Magnitude: 0.05896

Collected Steps per Second: 19,780.88621
Overall Steps per Second: 14,903.98842

Timestep Collection Time: 2.52880
Timestep Consumption Time: 0.82748
PPO Batch Consumption Time: 0.06107
Total Iteration Time: 3.35628

Cumulative Model Updates: 24,154
Cumulative Timesteps: 403,339,362

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 403339362...
Checkpoint 403339362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,503.06169
Policy Entropy: 1.01954
Value Function Loss: 0.05449

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.01948
Policy Update Magnitude: 0.03772
Value Function Update Magnitude: 0.05566

Collected Steps per Second: 19,718.81027
Overall Steps per Second: 15,037.62020

Timestep Collection Time: 2.53707
Timestep Consumption Time: 0.78979
PPO Batch Consumption Time: 0.06187
Total Iteration Time: 3.32686

Cumulative Model Updates: 24,157
Cumulative Timesteps: 403,389,390

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,356.26122
Policy Entropy: 1.01041
Value Function Loss: 0.06180

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02200
Policy Update Magnitude: 0.03658
Value Function Update Magnitude: 0.05296

Collected Steps per Second: 19,913.72022
Overall Steps per Second: 15,212.62250

Timestep Collection Time: 2.51143
Timestep Consumption Time: 0.77610
PPO Batch Consumption Time: 0.05228
Total Iteration Time: 3.28753

Cumulative Model Updates: 24,160
Cumulative Timesteps: 403,439,402

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 403439402...
Checkpoint 403439402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,800.58196
Policy Entropy: 1.01924
Value Function Loss: 0.05935

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.03627
Value Function Update Magnitude: 0.04895

Collected Steps per Second: 19,097.10845
Overall Steps per Second: 14,510.33131

Timestep Collection Time: 2.61851
Timestep Consumption Time: 0.82772
PPO Batch Consumption Time: 0.05972
Total Iteration Time: 3.44623

Cumulative Model Updates: 24,163
Cumulative Timesteps: 403,489,408

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,316.43118
Policy Entropy: 1.02474
Value Function Loss: 0.06191

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02063
Policy Update Magnitude: 0.03852
Value Function Update Magnitude: 0.04691

Collected Steps per Second: 19,797.00314
Overall Steps per Second: 15,055.10664

Timestep Collection Time: 2.52644
Timestep Consumption Time: 0.79575
PPO Batch Consumption Time: 0.05921
Total Iteration Time: 3.32219

Cumulative Model Updates: 24,166
Cumulative Timesteps: 403,539,424

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 403539424...
Checkpoint 403539424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,914.96019
Policy Entropy: 1.02898
Value Function Loss: 0.05944

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02905
Policy Update Magnitude: 0.03732
Value Function Update Magnitude: 0.05216

Collected Steps per Second: 19,051.92273
Overall Steps per Second: 14,538.62912

Timestep Collection Time: 2.62588
Timestep Consumption Time: 0.81516
PPO Batch Consumption Time: 0.05430
Total Iteration Time: 3.44104

Cumulative Model Updates: 24,169
Cumulative Timesteps: 403,589,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,551.18172
Policy Entropy: 1.02858
Value Function Loss: 0.05732

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02392
Policy Update Magnitude: 0.03732
Value Function Update Magnitude: 0.05063

Collected Steps per Second: 19,413.81424
Overall Steps per Second: 14,813.62926

Timestep Collection Time: 2.57734
Timestep Consumption Time: 0.80036
PPO Batch Consumption Time: 0.05171
Total Iteration Time: 3.37770

Cumulative Model Updates: 24,172
Cumulative Timesteps: 403,639,488

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 403639488...
Checkpoint 403639488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,777.40399
Policy Entropy: 1.05291
Value Function Loss: 0.04625

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.03065
Policy Update Magnitude: 0.03602
Value Function Update Magnitude: 0.04919

Collected Steps per Second: 19,652.14764
Overall Steps per Second: 14,916.15929

Timestep Collection Time: 2.54557
Timestep Consumption Time: 0.80824
PPO Batch Consumption Time: 0.05396
Total Iteration Time: 3.35381

Cumulative Model Updates: 24,175
Cumulative Timesteps: 403,689,514

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,828.86232
Policy Entropy: 1.05330
Value Function Loss: 0.04165

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02091
Policy Update Magnitude: 0.03314
Value Function Update Magnitude: 0.04688

Collected Steps per Second: 19,117.25613
Overall Steps per Second: 14,608.35689

Timestep Collection Time: 2.61784
Timestep Consumption Time: 0.80800
PPO Batch Consumption Time: 0.05225
Total Iteration Time: 3.42585

Cumulative Model Updates: 24,178
Cumulative Timesteps: 403,739,560

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 403739560...
Checkpoint 403739560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,690.85093
Policy Entropy: 1.05284
Value Function Loss: 0.04652

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02601
Policy Update Magnitude: 0.03553
Value Function Update Magnitude: 0.04485

Collected Steps per Second: 18,755.67713
Overall Steps per Second: 14,252.31169

Timestep Collection Time: 2.66618
Timestep Consumption Time: 0.84244
PPO Batch Consumption Time: 0.06589
Total Iteration Time: 3.50862

Cumulative Model Updates: 24,181
Cumulative Timesteps: 403,789,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,908.65471
Policy Entropy: 1.03244
Value Function Loss: 0.05246

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03180
Policy Update Magnitude: 0.03655
Value Function Update Magnitude: 0.04556

Collected Steps per Second: 19,138.72671
Overall Steps per Second: 14,793.66193

Timestep Collection Time: 2.61522
Timestep Consumption Time: 0.76812
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 3.38334

Cumulative Model Updates: 24,184
Cumulative Timesteps: 403,839,618

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 403839618...
Checkpoint 403839618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,482.41697
Policy Entropy: 1.03038
Value Function Loss: 0.05330

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.04011
Policy Update Magnitude: 0.03650
Value Function Update Magnitude: 0.04305

Collected Steps per Second: 18,396.40545
Overall Steps per Second: 13,687.30171

Timestep Collection Time: 2.71814
Timestep Consumption Time: 0.93517
PPO Batch Consumption Time: 0.09086
Total Iteration Time: 3.65331

Cumulative Model Updates: 24,187
Cumulative Timesteps: 403,889,622

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,538.37965
Policy Entropy: 1.03056
Value Function Loss: 0.05012

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01977
Policy Update Magnitude: 0.03451
Value Function Update Magnitude: 0.04170

Collected Steps per Second: 16,821.78925
Overall Steps per Second: 12,598.93054

Timestep Collection Time: 2.97448
Timestep Consumption Time: 0.99697
PPO Batch Consumption Time: 0.08838
Total Iteration Time: 3.97145

Cumulative Model Updates: 24,190
Cumulative Timesteps: 403,939,658

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 403939658...
Checkpoint 403939658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,529.46922
Policy Entropy: 1.03376
Value Function Loss: 0.04793

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02687
Policy Update Magnitude: 0.03451
Value Function Update Magnitude: 0.04211

Collected Steps per Second: 21,062.41935
Overall Steps per Second: 15,393.97043

Timestep Collection Time: 2.37504
Timestep Consumption Time: 0.87455
PPO Batch Consumption Time: 0.07031
Total Iteration Time: 3.24958

Cumulative Model Updates: 24,193
Cumulative Timesteps: 403,989,682

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,993.98729
Policy Entropy: 1.01668
Value Function Loss: 0.05319

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.01915
Policy Update Magnitude: 0.03554
Value Function Update Magnitude: 0.04942

Collected Steps per Second: 20,361.44289
Overall Steps per Second: 14,779.22054

Timestep Collection Time: 2.45621
Timestep Consumption Time: 0.92773
PPO Batch Consumption Time: 0.08984
Total Iteration Time: 3.38394

Cumulative Model Updates: 24,196
Cumulative Timesteps: 404,039,694

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 404039694...
Checkpoint 404039694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,481.26858
Policy Entropy: 1.01309
Value Function Loss: 0.05512

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01892
Policy Update Magnitude: 0.03523
Value Function Update Magnitude: 0.05441

Collected Steps per Second: 20,473.43729
Overall Steps per Second: 16,028.20955

Timestep Collection Time: 2.44326
Timestep Consumption Time: 0.67761
PPO Batch Consumption Time: 0.02913
Total Iteration Time: 3.12087

Cumulative Model Updates: 24,199
Cumulative Timesteps: 404,089,716

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,763.54708
Policy Entropy: 1.00154
Value Function Loss: 0.05695

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02423
Policy Update Magnitude: 0.03497
Value Function Update Magnitude: 0.05629

Collected Steps per Second: 22,325.27829
Overall Steps per Second: 15,730.58466

Timestep Collection Time: 2.24158
Timestep Consumption Time: 0.93973
PPO Batch Consumption Time: 0.10626
Total Iteration Time: 3.18132

Cumulative Model Updates: 24,202
Cumulative Timesteps: 404,139,760

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 404139760...
Checkpoint 404139760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,450.62748
Policy Entropy: 1.01181
Value Function Loss: 0.05573

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02403
Policy Update Magnitude: 0.03340
Value Function Update Magnitude: 0.05709

Collected Steps per Second: 23,121.63425
Overall Steps per Second: 16,805.29139

Timestep Collection Time: 2.16265
Timestep Consumption Time: 0.81284
PPO Batch Consumption Time: 0.06058
Total Iteration Time: 2.97549

Cumulative Model Updates: 24,205
Cumulative Timesteps: 404,189,764

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,677.91691
Policy Entropy: 1.00621
Value Function Loss: 0.05845

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02144
Policy Update Magnitude: 0.03517
Value Function Update Magnitude: 0.05720

Collected Steps per Second: 21,798.32996
Overall Steps per Second: 15,570.87370

Timestep Collection Time: 2.29375
Timestep Consumption Time: 0.91737
PPO Batch Consumption Time: 0.09394
Total Iteration Time: 3.21112

Cumulative Model Updates: 24,208
Cumulative Timesteps: 404,239,764

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 404239764...
Checkpoint 404239764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,658.89130
Policy Entropy: 1.00937
Value Function Loss: 0.05383

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02115
Policy Update Magnitude: 0.03551
Value Function Update Magnitude: 0.05789

Collected Steps per Second: 23,132.41615
Overall Steps per Second: 16,977.51193

Timestep Collection Time: 2.16164
Timestep Consumption Time: 0.78367
PPO Batch Consumption Time: 0.06260
Total Iteration Time: 2.94531

Cumulative Model Updates: 24,211
Cumulative Timesteps: 404,289,768

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,896.94138
Policy Entropy: 1.00799
Value Function Loss: 0.04540

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01457
Policy Update Magnitude: 0.03428
Value Function Update Magnitude: 0.05522

Collected Steps per Second: 23,628.23139
Overall Steps per Second: 16,400.19385

Timestep Collection Time: 2.11654
Timestep Consumption Time: 0.93282
PPO Batch Consumption Time: 0.08982
Total Iteration Time: 3.04935

Cumulative Model Updates: 24,214
Cumulative Timesteps: 404,339,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 404339778...
Checkpoint 404339778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,485.74390
Policy Entropy: 1.02025
Value Function Loss: 0.04092

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01734
Policy Update Magnitude: 0.03453
Value Function Update Magnitude: 0.05328

Collected Steps per Second: 22,550.62098
Overall Steps per Second: 16,560.86683

Timestep Collection Time: 2.21759
Timestep Consumption Time: 0.80206
PPO Batch Consumption Time: 0.06181
Total Iteration Time: 3.01965

Cumulative Model Updates: 24,217
Cumulative Timesteps: 404,389,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,373.99531
Policy Entropy: 1.02425
Value Function Loss: 0.04592

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02319
Policy Update Magnitude: 0.03378
Value Function Update Magnitude: 0.04932

Collected Steps per Second: 21,024.94240
Overall Steps per Second: 14,893.64807

Timestep Collection Time: 2.37851
Timestep Consumption Time: 0.97916
PPO Batch Consumption Time: 0.11630
Total Iteration Time: 3.35767

Cumulative Model Updates: 24,220
Cumulative Timesteps: 404,439,794

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 404439794...
Checkpoint 404439794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,858.03534
Policy Entropy: 1.01248
Value Function Loss: 0.05479

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02335
Policy Update Magnitude: 0.03758
Value Function Update Magnitude: 0.04423

Collected Steps per Second: 18,592.41541
Overall Steps per Second: 14,273.88696

Timestep Collection Time: 2.69131
Timestep Consumption Time: 0.81425
PPO Batch Consumption Time: 0.06330
Total Iteration Time: 3.50556

Cumulative Model Updates: 24,223
Cumulative Timesteps: 404,489,832

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,927.50007
Policy Entropy: 1.00182
Value Function Loss: 0.05479

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02543
Policy Update Magnitude: 0.03371
Value Function Update Magnitude: 0.04623

Collected Steps per Second: 21,953.66752
Overall Steps per Second: 15,479.80623

Timestep Collection Time: 2.27871
Timestep Consumption Time: 0.95299
PPO Batch Consumption Time: 0.11395
Total Iteration Time: 3.23169

Cumulative Model Updates: 24,226
Cumulative Timesteps: 404,539,858

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 404539858...
Checkpoint 404539858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,183.49792
Policy Entropy: 1.00041
Value Function Loss: 0.05588

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04015
Policy Update Magnitude: 0.03300
Value Function Update Magnitude: 0.05229

Collected Steps per Second: 21,761.99602
Overall Steps per Second: 16,259.67793

Timestep Collection Time: 2.29859
Timestep Consumption Time: 0.77785
PPO Batch Consumption Time: 0.06311
Total Iteration Time: 3.07644

Cumulative Model Updates: 24,229
Cumulative Timesteps: 404,589,880

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,730.88043
Policy Entropy: 1.00288
Value Function Loss: 0.05309

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02159
Policy Update Magnitude: 0.03517
Value Function Update Magnitude: 0.05545

Collected Steps per Second: 20,762.59713
Overall Steps per Second: 14,866.46966

Timestep Collection Time: 2.40827
Timestep Consumption Time: 0.95513
PPO Batch Consumption Time: 0.10347
Total Iteration Time: 3.36341

Cumulative Model Updates: 24,232
Cumulative Timesteps: 404,639,882

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 404639882...
Checkpoint 404639882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,826.03663
Policy Entropy: 0.99840
Value Function Loss: 0.05287

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03123
Policy Update Magnitude: 0.03567
Value Function Update Magnitude: 0.05600

Collected Steps per Second: 23,366.24158
Overall Steps per Second: 16,741.24294

Timestep Collection Time: 2.14001
Timestep Consumption Time: 0.84686
PPO Batch Consumption Time: 0.07439
Total Iteration Time: 2.98688

Cumulative Model Updates: 24,235
Cumulative Timesteps: 404,689,886

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,689.13067
Policy Entropy: 0.99401
Value Function Loss: 0.04940

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02948
Policy Update Magnitude: 0.03245
Value Function Update Magnitude: 0.05838

Collected Steps per Second: 19,151.21799
Overall Steps per Second: 15,041.23692

Timestep Collection Time: 2.61111
Timestep Consumption Time: 0.71348
PPO Batch Consumption Time: 0.02910
Total Iteration Time: 3.32459

Cumulative Model Updates: 24,238
Cumulative Timesteps: 404,739,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 404739892...
Checkpoint 404739892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,476.19394
Policy Entropy: 1.00239
Value Function Loss: 0.04719

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03749
Policy Update Magnitude: 0.03147
Value Function Update Magnitude: 0.05946

Collected Steps per Second: 21,535.81262
Overall Steps per Second: 16,155.45771

Timestep Collection Time: 2.32292
Timestep Consumption Time: 0.77362
PPO Batch Consumption Time: 0.05897
Total Iteration Time: 3.09654

Cumulative Model Updates: 24,241
Cumulative Timesteps: 404,789,918

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,078.06761
Policy Entropy: 1.00443
Value Function Loss: 0.04929

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04389
Policy Update Magnitude: 0.03254
Value Function Update Magnitude: 0.05298

Collected Steps per Second: 20,743.56529
Overall Steps per Second: 15,156.27902

Timestep Collection Time: 2.41145
Timestep Consumption Time: 0.88897
PPO Batch Consumption Time: 0.09185
Total Iteration Time: 3.30041

Cumulative Model Updates: 24,244
Cumulative Timesteps: 404,839,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 404839940...
Checkpoint 404839940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,149.69597
Policy Entropy: 1.00580
Value Function Loss: 0.05467

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02863
Policy Update Magnitude: 0.03314
Value Function Update Magnitude: 0.05108

Collected Steps per Second: 22,291.32873
Overall Steps per Second: 16,192.32194

Timestep Collection Time: 2.24320
Timestep Consumption Time: 0.84493
PPO Batch Consumption Time: 0.06256
Total Iteration Time: 3.08813

Cumulative Model Updates: 24,247
Cumulative Timesteps: 404,889,944

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,481.43919
Policy Entropy: 0.99841
Value Function Loss: 0.05739

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04717
Policy Update Magnitude: 0.03242
Value Function Update Magnitude: 0.05552

Collected Steps per Second: 22,363.61403
Overall Steps per Second: 16,435.63839

Timestep Collection Time: 2.23667
Timestep Consumption Time: 0.80672
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 3.04339

Cumulative Model Updates: 24,250
Cumulative Timesteps: 404,939,964

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 404939964...
Checkpoint 404939964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,549.79703
Policy Entropy: 1.00802
Value Function Loss: 0.05741

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04880
Policy Update Magnitude: 0.03293
Value Function Update Magnitude: 0.06143

Collected Steps per Second: 22,466.95461
Overall Steps per Second: 17,116.83971

Timestep Collection Time: 2.22656
Timestep Consumption Time: 0.69594
PPO Batch Consumption Time: 0.02794
Total Iteration Time: 2.92250

Cumulative Model Updates: 24,253
Cumulative Timesteps: 404,989,988

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,233.47299
Policy Entropy: 1.01048
Value Function Loss: 0.05696

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03138
Policy Update Magnitude: 0.03614
Value Function Update Magnitude: 0.06316

Collected Steps per Second: 21,515.33377
Overall Steps per Second: 15,273.27925

Timestep Collection Time: 2.32625
Timestep Consumption Time: 0.95072
PPO Batch Consumption Time: 0.11457
Total Iteration Time: 3.27696

Cumulative Model Updates: 24,256
Cumulative Timesteps: 405,040,038

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 405040038...
Checkpoint 405040038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,812.03353
Policy Entropy: 1.01113
Value Function Loss: 0.05328

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04605
Policy Update Magnitude: 0.03581
Value Function Update Magnitude: 0.06086

Collected Steps per Second: 23,013.39881
Overall Steps per Second: 16,813.58891

Timestep Collection Time: 2.17334
Timestep Consumption Time: 0.80139
PPO Batch Consumption Time: 0.06162
Total Iteration Time: 2.97474

Cumulative Model Updates: 24,259
Cumulative Timesteps: 405,090,054

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,506.57362
Policy Entropy: 1.01857
Value Function Loss: 0.04914

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03240
Policy Update Magnitude: 0.03288
Value Function Update Magnitude: 0.06192

Collected Steps per Second: 21,009.41110
Overall Steps per Second: 14,661.53897

Timestep Collection Time: 2.38074
Timestep Consumption Time: 1.03077
PPO Batch Consumption Time: 0.10358
Total Iteration Time: 3.41151

Cumulative Model Updates: 24,262
Cumulative Timesteps: 405,140,072

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 405140072...
Checkpoint 405140072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,317.85661
Policy Entropy: 1.01397
Value Function Loss: 0.05316

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04762
Policy Update Magnitude: 0.03089
Value Function Update Magnitude: 0.05826

Collected Steps per Second: 23,270.81637
Overall Steps per Second: 16,532.70841

Timestep Collection Time: 2.14973
Timestep Consumption Time: 0.87615
PPO Batch Consumption Time: 0.07731
Total Iteration Time: 3.02588

Cumulative Model Updates: 24,265
Cumulative Timesteps: 405,190,098

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,533.45346
Policy Entropy: 1.01164
Value Function Loss: 0.05649

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02821
Policy Update Magnitude: 0.03251
Value Function Update Magnitude: 0.05994

Collected Steps per Second: 21,695.08313
Overall Steps per Second: 15,793.10570

Timestep Collection Time: 2.30513
Timestep Consumption Time: 0.86144
PPO Batch Consumption Time: 0.07597
Total Iteration Time: 3.16657

Cumulative Model Updates: 24,268
Cumulative Timesteps: 405,240,108

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 405240108...
Checkpoint 405240108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,835.15368
Policy Entropy: 1.00674
Value Function Loss: 0.05731

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04417
Policy Update Magnitude: 0.03248
Value Function Update Magnitude: 0.05877

Collected Steps per Second: 22,147.77624
Overall Steps per Second: 16,022.37737

Timestep Collection Time: 2.25783
Timestep Consumption Time: 0.86318
PPO Batch Consumption Time: 0.07872
Total Iteration Time: 3.12101

Cumulative Model Updates: 24,271
Cumulative Timesteps: 405,290,114

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,884.19723
Policy Entropy: 1.00808
Value Function Loss: 0.04938

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03205
Policy Update Magnitude: 0.03149
Value Function Update Magnitude: 0.05560

Collected Steps per Second: 23,211.29721
Overall Steps per Second: 16,449.79455

Timestep Collection Time: 2.15576
Timestep Consumption Time: 0.88610
PPO Batch Consumption Time: 0.10202
Total Iteration Time: 3.04186

Cumulative Model Updates: 24,274
Cumulative Timesteps: 405,340,152

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 405340152...
Checkpoint 405340152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,416.48303
Policy Entropy: 1.01690
Value Function Loss: 0.04530

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01417
Policy Update Magnitude: 0.03018
Value Function Update Magnitude: 0.05232

Collected Steps per Second: 23,311.65502
Overall Steps per Second: 17,023.83770

Timestep Collection Time: 2.14571
Timestep Consumption Time: 0.79253
PPO Batch Consumption Time: 0.06411
Total Iteration Time: 2.93823

Cumulative Model Updates: 24,277
Cumulative Timesteps: 405,390,172

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,726.04515
Policy Entropy: 1.04053
Value Function Loss: 0.04438

Mean KL Divergence: 0.00117
SB3 Clip Fraction: 0.01023
Policy Update Magnitude: 0.02997
Value Function Update Magnitude: 0.05067

Collected Steps per Second: 23,877.40216
Overall Steps per Second: 16,350.34950

Timestep Collection Time: 2.09478
Timestep Consumption Time: 0.96436
PPO Batch Consumption Time: 0.11990
Total Iteration Time: 3.05914

Cumulative Model Updates: 24,280
Cumulative Timesteps: 405,440,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 405440190...
Checkpoint 405440190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,723.36726
Policy Entropy: 1.04171
Value Function Loss: 0.04681

Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.00998
Policy Update Magnitude: 0.03074
Value Function Update Magnitude: 0.05356

Collected Steps per Second: 21,596.03326
Overall Steps per Second: 16,234.45509

Timestep Collection Time: 2.31718
Timestep Consumption Time: 0.76527
PPO Batch Consumption Time: 0.06258
Total Iteration Time: 3.08246

Cumulative Model Updates: 24,283
Cumulative Timesteps: 405,490,232

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,054.05620
Policy Entropy: 1.03405
Value Function Loss: 0.05148

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01321
Policy Update Magnitude: 0.03276
Value Function Update Magnitude: 0.05199

Collected Steps per Second: 24,379.09300
Overall Steps per Second: 17,358.69519

Timestep Collection Time: 2.05233
Timestep Consumption Time: 0.83003
PPO Batch Consumption Time: 0.08298
Total Iteration Time: 2.88236

Cumulative Model Updates: 24,286
Cumulative Timesteps: 405,540,266

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 405540266...
Checkpoint 405540266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,888.11642
Policy Entropy: 1.02754
Value Function Loss: 0.05617

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02380
Policy Update Magnitude: 0.03414
Value Function Update Magnitude: 0.05414

Collected Steps per Second: 24,126.76577
Overall Steps per Second: 17,281.48859

Timestep Collection Time: 2.07380
Timestep Consumption Time: 0.82144
PPO Batch Consumption Time: 0.06267
Total Iteration Time: 2.89524

Cumulative Model Updates: 24,289
Cumulative Timesteps: 405,590,300

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,883.46255
Policy Entropy: 1.02545
Value Function Loss: 0.05421

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02069
Policy Update Magnitude: 0.03231
Value Function Update Magnitude: 0.05960

Collected Steps per Second: 23,555.00465
Overall Steps per Second: 16,246.74733

Timestep Collection Time: 2.12320
Timestep Consumption Time: 0.95508
PPO Batch Consumption Time: 0.10092
Total Iteration Time: 3.07828

Cumulative Model Updates: 24,292
Cumulative Timesteps: 405,640,312

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 405640312...
Checkpoint 405640312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,600.32608
Policy Entropy: 1.02315
Value Function Loss: 0.05575

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.01813
Policy Update Magnitude: 0.03140
Value Function Update Magnitude: 0.06561

Collected Steps per Second: 22,945.23027
Overall Steps per Second: 16,867.49808

Timestep Collection Time: 2.17989
Timestep Consumption Time: 0.78546
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 2.96535

Cumulative Model Updates: 24,295
Cumulative Timesteps: 405,690,330

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,010.39138
Policy Entropy: 1.01339
Value Function Loss: 0.05791

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03670
Policy Update Magnitude: 0.03219
Value Function Update Magnitude: 0.06389

Collected Steps per Second: 20,781.85086
Overall Steps per Second: 15,522.73891

Timestep Collection Time: 2.40652
Timestep Consumption Time: 0.81533
PPO Batch Consumption Time: 0.04919
Total Iteration Time: 3.22185

Cumulative Model Updates: 24,298
Cumulative Timesteps: 405,740,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 405740342...
Checkpoint 405740342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,235.14606
Policy Entropy: 1.00115
Value Function Loss: 0.06283

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02581
Policy Update Magnitude: 0.03382
Value Function Update Magnitude: 0.05853

Collected Steps per Second: 23,855.63082
Overall Steps per Second: 17,672.97621

Timestep Collection Time: 2.09812
Timestep Consumption Time: 0.73400
PPO Batch Consumption Time: 0.02877
Total Iteration Time: 2.83212

Cumulative Model Updates: 24,301
Cumulative Timesteps: 405,790,394

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,409.50217
Policy Entropy: 1.01078
Value Function Loss: 0.06107

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03571
Policy Update Magnitude: 0.03465
Value Function Update Magnitude: 0.06434

Collected Steps per Second: 23,121.20125
Overall Steps per Second: 15,998.25127

Timestep Collection Time: 2.16260
Timestep Consumption Time: 0.96286
PPO Batch Consumption Time: 0.09590
Total Iteration Time: 3.12547

Cumulative Model Updates: 24,304
Cumulative Timesteps: 405,840,396

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 405840396...
Checkpoint 405840396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,427.21261
Policy Entropy: 1.00794
Value Function Loss: 0.06145

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02319
Policy Update Magnitude: 0.03173
Value Function Update Magnitude: 0.06130

Collected Steps per Second: 22,951.21950
Overall Steps per Second: 15,782.17555

Timestep Collection Time: 2.17879
Timestep Consumption Time: 0.98972
PPO Batch Consumption Time: 0.11298
Total Iteration Time: 3.16851

Cumulative Model Updates: 24,307
Cumulative Timesteps: 405,890,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,051.47518
Policy Entropy: 1.01137
Value Function Loss: 0.05172

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01800
Policy Update Magnitude: 0.02986
Value Function Update Magnitude: 0.05280

Collected Steps per Second: 23,871.33360
Overall Steps per Second: 17,150.53622

Timestep Collection Time: 2.09548
Timestep Consumption Time: 0.82116
PPO Batch Consumption Time: 0.06481
Total Iteration Time: 2.91664

Cumulative Model Updates: 24,310
Cumulative Timesteps: 405,940,424

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 405940424...
Checkpoint 405940424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,281.76839
Policy Entropy: 1.00949
Value Function Loss: 0.04674

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01723
Policy Update Magnitude: 0.03103
Value Function Update Magnitude: 0.05379

Collected Steps per Second: 21,608.01674
Overall Steps per Second: 15,285.04280

Timestep Collection Time: 2.31507
Timestep Consumption Time: 0.95768
PPO Batch Consumption Time: 0.10861
Total Iteration Time: 3.27274

Cumulative Model Updates: 24,313
Cumulative Timesteps: 405,990,448

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,514.80318
Policy Entropy: 1.00466
Value Function Loss: 0.04576

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01671
Policy Update Magnitude: 0.03061
Value Function Update Magnitude: 0.05179

Collected Steps per Second: 22,878.29378
Overall Steps per Second: 16,989.23876

Timestep Collection Time: 2.18565
Timestep Consumption Time: 0.75762
PPO Batch Consumption Time: 0.06650
Total Iteration Time: 2.94327

Cumulative Model Updates: 24,316
Cumulative Timesteps: 406,040,452

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 406040452...
Checkpoint 406040452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,387.82683
Policy Entropy: 0.99660
Value Function Loss: 0.05304

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01747
Policy Update Magnitude: 0.03127
Value Function Update Magnitude: 0.04688

Collected Steps per Second: 23,837.05725
Overall Steps per Second: 16,592.69546

Timestep Collection Time: 2.09883
Timestep Consumption Time: 0.91635
PPO Batch Consumption Time: 0.11705
Total Iteration Time: 3.01518

Cumulative Model Updates: 24,319
Cumulative Timesteps: 406,090,482

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,788.46902
Policy Entropy: 1.00702
Value Function Loss: 0.05228

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02704
Policy Update Magnitude: 0.03218
Value Function Update Magnitude: 0.04396

Collected Steps per Second: 24,368.77785
Overall Steps per Second: 17,534.56474

Timestep Collection Time: 2.05213
Timestep Consumption Time: 0.79983
PPO Batch Consumption Time: 0.06193
Total Iteration Time: 2.85197

Cumulative Model Updates: 24,322
Cumulative Timesteps: 406,140,490

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 406140490...
Checkpoint 406140490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,358.82232
Policy Entropy: 1.01829
Value Function Loss: 0.04739

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01915
Policy Update Magnitude: 0.03028
Value Function Update Magnitude: 0.04342

Collected Steps per Second: 18,557.48675
Overall Steps per Second: 14,417.47406

Timestep Collection Time: 2.69659
Timestep Consumption Time: 0.77433
PPO Batch Consumption Time: 0.02832
Total Iteration Time: 3.47093

Cumulative Model Updates: 24,325
Cumulative Timesteps: 406,190,532

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,025.78360
Policy Entropy: 1.03773
Value Function Loss: 0.04035

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01210
Policy Update Magnitude: 0.03058
Value Function Update Magnitude: 0.03939

Collected Steps per Second: 21,983.49374
Overall Steps per Second: 16,608.90055

Timestep Collection Time: 2.27462
Timestep Consumption Time: 0.73606
PPO Batch Consumption Time: 0.02832
Total Iteration Time: 3.01067

Cumulative Model Updates: 24,328
Cumulative Timesteps: 406,240,536

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 406240536...
Checkpoint 406240536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,718.40044
Policy Entropy: 1.02142
Value Function Loss: 0.04515

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01878
Policy Update Magnitude: 0.03068
Value Function Update Magnitude: 0.03660

Collected Steps per Second: 20,960.40960
Overall Steps per Second: 15,443.94107

Timestep Collection Time: 2.38669
Timestep Consumption Time: 0.85251
PPO Batch Consumption Time: 0.07244
Total Iteration Time: 3.23920

Cumulative Model Updates: 24,331
Cumulative Timesteps: 406,290,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,581.59769
Policy Entropy: 1.02826
Value Function Loss: 0.05075

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03617
Policy Update Magnitude: 0.02846
Value Function Update Magnitude: 0.03996

Collected Steps per Second: 23,482.88047
Overall Steps per Second: 16,921.86653

Timestep Collection Time: 2.12998
Timestep Consumption Time: 0.82584
PPO Batch Consumption Time: 0.06490
Total Iteration Time: 2.95582

Cumulative Model Updates: 24,334
Cumulative Timesteps: 406,340,580

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 406340580...
Checkpoint 406340580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,489.43286
Policy Entropy: 1.02283
Value Function Loss: 0.05693

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02995
Policy Update Magnitude: 0.02808
Value Function Update Magnitude: 0.04642

Collected Steps per Second: 22,707.67719
Overall Steps per Second: 16,557.50830

Timestep Collection Time: 2.20331
Timestep Consumption Time: 0.81840
PPO Batch Consumption Time: 0.07501
Total Iteration Time: 3.02171

Cumulative Model Updates: 24,337
Cumulative Timesteps: 406,390,612

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,505.42962
Policy Entropy: 1.03988
Value Function Loss: 0.05014

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02815
Policy Update Magnitude: 0.02919
Value Function Update Magnitude: 0.05051

Collected Steps per Second: 23,919.20641
Overall Steps per Second: 17,383.58938

Timestep Collection Time: 2.09062
Timestep Consumption Time: 0.78600
PPO Batch Consumption Time: 0.06370
Total Iteration Time: 2.87662

Cumulative Model Updates: 24,340
Cumulative Timesteps: 406,440,618

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 406440618...
Checkpoint 406440618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,912.03042
Policy Entropy: 1.04409
Value Function Loss: 0.04899

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02499
Policy Update Magnitude: 0.02934
Value Function Update Magnitude: 0.04824

Collected Steps per Second: 20,063.05612
Overall Steps per Second: 14,348.60566

Timestep Collection Time: 2.49324
Timestep Consumption Time: 0.99295
PPO Batch Consumption Time: 0.11078
Total Iteration Time: 3.48619

Cumulative Model Updates: 24,343
Cumulative Timesteps: 406,490,640

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,083.91032
Policy Entropy: 1.03759
Value Function Loss: 0.05277

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02743
Policy Update Magnitude: 0.03013
Value Function Update Magnitude: 0.04834

Collected Steps per Second: 22,478.84835
Overall Steps per Second: 16,432.63820

Timestep Collection Time: 2.22574
Timestep Consumption Time: 0.81894
PPO Batch Consumption Time: 0.06427
Total Iteration Time: 3.04467

Cumulative Model Updates: 24,346
Cumulative Timesteps: 406,540,672

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 406540672...
Checkpoint 406540672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,307.28204
Policy Entropy: 1.03121
Value Function Loss: 0.06206

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03085
Policy Update Magnitude: 0.03434
Value Function Update Magnitude: 0.04581

Collected Steps per Second: 20,319.58165
Overall Steps per Second: 14,993.95682

Timestep Collection Time: 2.46147
Timestep Consumption Time: 0.87428
PPO Batch Consumption Time: 0.08705
Total Iteration Time: 3.33574

Cumulative Model Updates: 24,349
Cumulative Timesteps: 406,590,688

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,222.19134
Policy Entropy: 1.03759
Value Function Loss: 0.06111

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02983
Policy Update Magnitude: 0.03673
Value Function Update Magnitude: 0.04787

Collected Steps per Second: 22,437.96781
Overall Steps per Second: 15,697.43251

Timestep Collection Time: 2.22863
Timestep Consumption Time: 0.95698
PPO Batch Consumption Time: 0.10378
Total Iteration Time: 3.18562

Cumulative Model Updates: 24,352
Cumulative Timesteps: 406,640,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 406640694...
Checkpoint 406640694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,300.13646
Policy Entropy: 1.03926
Value Function Loss: 0.05891

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02062
Policy Update Magnitude: 0.03664
Value Function Update Magnitude: 0.05252

Collected Steps per Second: 21,420.58245
Overall Steps per Second: 15,892.83045

Timestep Collection Time: 2.33616
Timestep Consumption Time: 0.81255
PPO Batch Consumption Time: 0.06761
Total Iteration Time: 3.14872

Cumulative Model Updates: 24,355
Cumulative Timesteps: 406,690,736

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,679.04052
Policy Entropy: 1.04333
Value Function Loss: 0.05348

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03123
Policy Update Magnitude: 0.03475
Value Function Update Magnitude: 0.04882

Collected Steps per Second: 22,831.87563
Overall Steps per Second: 15,580.44574

Timestep Collection Time: 2.19071
Timestep Consumption Time: 1.01960
PPO Batch Consumption Time: 0.12166
Total Iteration Time: 3.21031

Cumulative Model Updates: 24,358
Cumulative Timesteps: 406,740,754

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 406740754...
Checkpoint 406740754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,967.22383
Policy Entropy: 1.03627
Value Function Loss: 0.05254

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02172
Policy Update Magnitude: 0.03298
Value Function Update Magnitude: 0.04467

Collected Steps per Second: 19,801.69957
Overall Steps per Second: 14,692.21294

Timestep Collection Time: 2.52615
Timestep Consumption Time: 0.87851
PPO Batch Consumption Time: 0.08441
Total Iteration Time: 3.40466

Cumulative Model Updates: 24,361
Cumulative Timesteps: 406,790,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,772.65550
Policy Entropy: 1.03201
Value Function Loss: 0.05091

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02522
Policy Update Magnitude: 0.03404
Value Function Update Magnitude: 0.04561

Collected Steps per Second: 22,484.36951
Overall Steps per Second: 16,484.72842

Timestep Collection Time: 2.22403
Timestep Consumption Time: 0.80944
PPO Batch Consumption Time: 0.06373
Total Iteration Time: 3.03347

Cumulative Model Updates: 24,364
Cumulative Timesteps: 406,840,782

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 406840782...
Checkpoint 406840782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,588.34762
Policy Entropy: 1.03479
Value Function Loss: 0.05588

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03729
Policy Update Magnitude: 0.03230
Value Function Update Magnitude: 0.04810

Collected Steps per Second: 20,162.90316
Overall Steps per Second: 14,853.99473

Timestep Collection Time: 2.48010
Timestep Consumption Time: 0.88640
PPO Batch Consumption Time: 0.09001
Total Iteration Time: 3.36650

Cumulative Model Updates: 24,367
Cumulative Timesteps: 406,890,788

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,260.58575
Policy Entropy: 1.04473
Value Function Loss: 0.05427

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03901
Policy Update Magnitude: 0.03259
Value Function Update Magnitude: 0.04528

Collected Steps per Second: 24,158.78940
Overall Steps per Second: 17,548.50686

Timestep Collection Time: 2.06981
Timestep Consumption Time: 0.77967
PPO Batch Consumption Time: 0.06120
Total Iteration Time: 2.84947

Cumulative Model Updates: 24,370
Cumulative Timesteps: 406,940,792

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 406940792...
Checkpoint 406940792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,619.48268
Policy Entropy: 1.04864
Value Function Loss: 0.05117

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02697
Policy Update Magnitude: 0.03868
Value Function Update Magnitude: 0.04836

Collected Steps per Second: 20,941.64357
Overall Steps per Second: 15,430.92773

Timestep Collection Time: 2.38778
Timestep Consumption Time: 0.85273
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 3.24051

Cumulative Model Updates: 24,373
Cumulative Timesteps: 406,990,796

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,215.45717
Policy Entropy: 1.03611
Value Function Loss: 0.05164

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02772
Policy Update Magnitude: 0.03687
Value Function Update Magnitude: 0.04574

Collected Steps per Second: 23,548.60381
Overall Steps per Second: 17,578.89021

Timestep Collection Time: 2.12429
Timestep Consumption Time: 0.72140
PPO Batch Consumption Time: 0.03248
Total Iteration Time: 2.84569

Cumulative Model Updates: 24,376
Cumulative Timesteps: 407,040,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 407040820...
Checkpoint 407040820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,172.33183
Policy Entropy: 1.03782
Value Function Loss: 0.05271

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02579
Policy Update Magnitude: 0.03705
Value Function Update Magnitude: 0.04401

Collected Steps per Second: 22,391.64790
Overall Steps per Second: 15,680.71388

Timestep Collection Time: 2.23369
Timestep Consumption Time: 0.95596
PPO Batch Consumption Time: 0.09342
Total Iteration Time: 3.18965

Cumulative Model Updates: 24,379
Cumulative Timesteps: 407,090,836

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,313.69620
Policy Entropy: 1.03667
Value Function Loss: 0.05451

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03413
Policy Update Magnitude: 0.03825
Value Function Update Magnitude: 0.04205

Collected Steps per Second: 20,658.35869
Overall Steps per Second: 15,518.06441

Timestep Collection Time: 2.42101
Timestep Consumption Time: 0.80195
PPO Batch Consumption Time: 0.05787
Total Iteration Time: 3.22295

Cumulative Model Updates: 24,382
Cumulative Timesteps: 407,140,850

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 407140850...
Checkpoint 407140850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,066.54207
Policy Entropy: 1.02413
Value Function Loss: 0.05598

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03434
Policy Update Magnitude: 0.03697
Value Function Update Magnitude: 0.04034

Collected Steps per Second: 19,859.69736
Overall Steps per Second: 13,997.80180

Timestep Collection Time: 2.51877
Timestep Consumption Time: 1.05479
PPO Batch Consumption Time: 0.12153
Total Iteration Time: 3.57356

Cumulative Model Updates: 24,385
Cumulative Timesteps: 407,190,872

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,927.88088
Policy Entropy: 1.00440
Value Function Loss: 0.06199

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04075
Policy Update Magnitude: 0.03308
Value Function Update Magnitude: 0.04076

Collected Steps per Second: 20,171.43298
Overall Steps per Second: 14,740.63651

Timestep Collection Time: 2.47915
Timestep Consumption Time: 0.91338
PPO Batch Consumption Time: 0.08340
Total Iteration Time: 3.39253

Cumulative Model Updates: 24,388
Cumulative Timesteps: 407,240,880

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 407240880...
Checkpoint 407240880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,600.31484
Policy Entropy: 1.00507
Value Function Loss: 0.05859

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03882
Policy Update Magnitude: 0.03121
Value Function Update Magnitude: 0.04576

Collected Steps per Second: 20,211.20899
Overall Steps per Second: 15,611.44959

Timestep Collection Time: 2.47447
Timestep Consumption Time: 0.72908
PPO Batch Consumption Time: 0.02930
Total Iteration Time: 3.20355

Cumulative Model Updates: 24,391
Cumulative Timesteps: 407,290,892

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,970.26315
Policy Entropy: 1.01309
Value Function Loss: 0.05585

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02953
Policy Update Magnitude: 0.03719
Value Function Update Magnitude: 0.04270

Collected Steps per Second: 22,569.26392
Overall Steps per Second: 15,973.67295

Timestep Collection Time: 2.21576
Timestep Consumption Time: 0.91489
PPO Batch Consumption Time: 0.10733
Total Iteration Time: 3.13065

Cumulative Model Updates: 24,394
Cumulative Timesteps: 407,340,900

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 407340900...
Checkpoint 407340900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,160.87461
Policy Entropy: 1.02924
Value Function Loss: 0.04611

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05725
Policy Update Magnitude: 0.03557
Value Function Update Magnitude: 0.04710

Collected Steps per Second: 20,338.51988
Overall Steps per Second: 15,191.94908

Timestep Collection Time: 2.46055
Timestep Consumption Time: 0.83356
PPO Batch Consumption Time: 0.07263
Total Iteration Time: 3.29411

Cumulative Model Updates: 24,397
Cumulative Timesteps: 407,390,944

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,483.19144
Policy Entropy: 1.02063
Value Function Loss: 0.04728

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04724
Policy Update Magnitude: 0.03274
Value Function Update Magnitude: 0.05072

Collected Steps per Second: 24,467.28534
Overall Steps per Second: 17,275.56000

Timestep Collection Time: 2.04461
Timestep Consumption Time: 0.85116
PPO Batch Consumption Time: 0.07494
Total Iteration Time: 2.89577

Cumulative Model Updates: 24,400
Cumulative Timesteps: 407,440,970

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 407440970...
Checkpoint 407440970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,937.21624
Policy Entropy: 1.02338
Value Function Loss: 0.04586

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04525
Policy Update Magnitude: 0.02976
Value Function Update Magnitude: 0.04816

Collected Steps per Second: 23,567.05313
Overall Steps per Second: 17,129.49264

Timestep Collection Time: 2.12313
Timestep Consumption Time: 0.79791
PPO Batch Consumption Time: 0.06409
Total Iteration Time: 2.92104

Cumulative Model Updates: 24,403
Cumulative Timesteps: 407,491,006

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,700.55779
Policy Entropy: 1.01017
Value Function Loss: 0.04927

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03449
Policy Update Magnitude: 0.02987
Value Function Update Magnitude: 0.04811

Collected Steps per Second: 24,109.10295
Overall Steps per Second: 16,523.48745

Timestep Collection Time: 2.07457
Timestep Consumption Time: 0.95239
PPO Batch Consumption Time: 0.11984
Total Iteration Time: 3.02696

Cumulative Model Updates: 24,406
Cumulative Timesteps: 407,541,022

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 407541022...
Checkpoint 407541022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,574.57711
Policy Entropy: 1.00441
Value Function Loss: 0.05286

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02921
Policy Update Magnitude: 0.03185
Value Function Update Magnitude: 0.04635

Collected Steps per Second: 23,936.68123
Overall Steps per Second: 17,382.82360

Timestep Collection Time: 2.09010
Timestep Consumption Time: 0.78803
PPO Batch Consumption Time: 0.06176
Total Iteration Time: 2.87813

Cumulative Model Updates: 24,409
Cumulative Timesteps: 407,591,052

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,706.94223
Policy Entropy: 1.00583
Value Function Loss: 0.05203

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02911
Policy Update Magnitude: 0.03254
Value Function Update Magnitude: 0.05238

Collected Steps per Second: 21,595.83563
Overall Steps per Second: 15,101.75571

Timestep Collection Time: 2.31628
Timestep Consumption Time: 0.99605
PPO Batch Consumption Time: 0.11478
Total Iteration Time: 3.31233

Cumulative Model Updates: 24,412
Cumulative Timesteps: 407,641,074

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 407641074...
Checkpoint 407641074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,112.83353
Policy Entropy: 1.02371
Value Function Loss: 0.04993

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02525
Policy Update Magnitude: 0.03126
Value Function Update Magnitude: 0.05103

Collected Steps per Second: 23,495.34255
Overall Steps per Second: 16,731.24905

Timestep Collection Time: 2.12868
Timestep Consumption Time: 0.86058
PPO Batch Consumption Time: 0.08769
Total Iteration Time: 2.98926

Cumulative Model Updates: 24,415
Cumulative Timesteps: 407,691,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,812.53394
Policy Entropy: 1.01319
Value Function Loss: 0.04890

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02307
Policy Update Magnitude: 0.03083
Value Function Update Magnitude: 0.04573

Collected Steps per Second: 23,747.62274
Overall Steps per Second: 16,704.53663

Timestep Collection Time: 2.10589
Timestep Consumption Time: 0.88790
PPO Batch Consumption Time: 0.08886
Total Iteration Time: 2.99380

Cumulative Model Updates: 24,418
Cumulative Timesteps: 407,741,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 407741098...
Checkpoint 407741098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,864.28544
Policy Entropy: 1.01196
Value Function Loss: 0.04950

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02872
Policy Update Magnitude: 0.02928
Value Function Update Magnitude: 0.04592

Collected Steps per Second: 23,140.45318
Overall Steps per Second: 15,827.72326

Timestep Collection Time: 2.16080
Timestep Consumption Time: 0.99834
PPO Batch Consumption Time: 0.12611
Total Iteration Time: 3.15914

Cumulative Model Updates: 24,421
Cumulative Timesteps: 407,791,100

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,988.87403
Policy Entropy: 0.99548
Value Function Loss: 0.05274

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02279
Policy Update Magnitude: 0.03143
Value Function Update Magnitude: 0.04269

Collected Steps per Second: 24,109.47693
Overall Steps per Second: 17,761.99944

Timestep Collection Time: 2.07421
Timestep Consumption Time: 0.74124
PPO Batch Consumption Time: 0.05749
Total Iteration Time: 2.81545

Cumulative Model Updates: 24,424
Cumulative Timesteps: 407,841,108

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 407841108...
Checkpoint 407841108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,110.43714
Policy Entropy: 0.97972
Value Function Loss: 0.05698

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01961
Policy Update Magnitude: 0.03358
Value Function Update Magnitude: 0.04392

Collected Steps per Second: 21,247.19099
Overall Steps per Second: 15,682.31278

Timestep Collection Time: 2.35372
Timestep Consumption Time: 0.83522
PPO Batch Consumption Time: 0.08561
Total Iteration Time: 3.18894

Cumulative Model Updates: 24,427
Cumulative Timesteps: 407,891,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,234.79505
Policy Entropy: 0.97566
Value Function Loss: 0.06245

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02965
Policy Update Magnitude: 0.03187
Value Function Update Magnitude: 0.04778

Collected Steps per Second: 23,398.72794
Overall Steps per Second: 16,955.00805

Timestep Collection Time: 2.13687
Timestep Consumption Time: 0.81211
PPO Batch Consumption Time: 0.06094
Total Iteration Time: 2.94898

Cumulative Model Updates: 24,430
Cumulative Timesteps: 407,941,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 407941118...
Checkpoint 407941118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,768.34234
Policy Entropy: 0.98223
Value Function Loss: 0.06201

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03212
Policy Update Magnitude: 0.03722
Value Function Update Magnitude: 0.05486

Collected Steps per Second: 23,471.98305
Overall Steps per Second: 17,043.93727

Timestep Collection Time: 2.13105
Timestep Consumption Time: 0.80372
PPO Batch Consumption Time: 0.07308
Total Iteration Time: 2.93477

Cumulative Model Updates: 24,433
Cumulative Timesteps: 407,991,138

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,513.00994
Policy Entropy: 0.98442
Value Function Loss: 0.06296

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.06065
Policy Update Magnitude: 0.03457
Value Function Update Magnitude: 0.06019

Collected Steps per Second: 22,564.42141
Overall Steps per Second: 16,221.44859

Timestep Collection Time: 2.21694
Timestep Consumption Time: 0.86688
PPO Batch Consumption Time: 0.09514
Total Iteration Time: 3.08382

Cumulative Model Updates: 24,436
Cumulative Timesteps: 408,041,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 408041162...
Checkpoint 408041162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,872.01379
Policy Entropy: 0.99255
Value Function Loss: 0.05703

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06667
Policy Update Magnitude: 0.03568
Value Function Update Magnitude: 0.06121

Collected Steps per Second: 22,659.09159
Overall Steps per Second: 16,627.79657

Timestep Collection Time: 2.20786
Timestep Consumption Time: 0.80084
PPO Batch Consumption Time: 0.05927
Total Iteration Time: 3.00870

Cumulative Model Updates: 24,439
Cumulative Timesteps: 408,091,190

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,729.44608
Policy Entropy: 0.99158
Value Function Loss: 0.05751

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05557
Policy Update Magnitude: 0.03267
Value Function Update Magnitude: 0.05880

Collected Steps per Second: 19,784.15403
Overall Steps per Second: 14,774.46727

Timestep Collection Time: 2.52849
Timestep Consumption Time: 0.85735
PPO Batch Consumption Time: 0.08334
Total Iteration Time: 3.38584

Cumulative Model Updates: 24,442
Cumulative Timesteps: 408,141,214

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 408141214...
Checkpoint 408141214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,126.79996
Policy Entropy: 1.01602
Value Function Loss: 0.04806

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08143
Policy Update Magnitude: 0.03114
Value Function Update Magnitude: 0.05336

Collected Steps per Second: 22,364.48540
Overall Steps per Second: 15,819.88309

Timestep Collection Time: 2.23640
Timestep Consumption Time: 0.92519
PPO Batch Consumption Time: 0.09704
Total Iteration Time: 3.16159

Cumulative Model Updates: 24,445
Cumulative Timesteps: 408,191,230

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,403.44730
Policy Entropy: 1.01204
Value Function Loss: 0.05225

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.05365
Policy Update Magnitude: 0.03179
Value Function Update Magnitude: 0.04956

Collected Steps per Second: 23,174.60587
Overall Steps per Second: 16,910.53809

Timestep Collection Time: 2.15779
Timestep Consumption Time: 0.79930
PPO Batch Consumption Time: 0.06216
Total Iteration Time: 2.95709

Cumulative Model Updates: 24,448
Cumulative Timesteps: 408,241,236

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 408241236...
Checkpoint 408241236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,802.56987
Policy Entropy: 1.01145
Value Function Loss: 0.05825

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.05508
Policy Update Magnitude: 0.03354
Value Function Update Magnitude: 0.05483

Collected Steps per Second: 21,646.63950
Overall Steps per Second: 15,566.40707

Timestep Collection Time: 2.31186
Timestep Consumption Time: 0.90301
PPO Batch Consumption Time: 0.10022
Total Iteration Time: 3.21487

Cumulative Model Updates: 24,451
Cumulative Timesteps: 408,291,280

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,822.35742
Policy Entropy: 1.00372
Value Function Loss: 0.06146

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02601
Policy Update Magnitude: 0.03268
Value Function Update Magnitude: 0.05382

Collected Steps per Second: 23,623.66174
Overall Steps per Second: 16,888.55186

Timestep Collection Time: 2.11762
Timestep Consumption Time: 0.84450
PPO Batch Consumption Time: 0.08549
Total Iteration Time: 2.96212

Cumulative Model Updates: 24,454
Cumulative Timesteps: 408,341,306

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 408341306...
Checkpoint 408341306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,403.15426
Policy Entropy: 1.00371
Value Function Loss: 0.05762

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03325
Policy Update Magnitude: 0.03276
Value Function Update Magnitude: 0.05072

Collected Steps per Second: 23,517.98578
Overall Steps per Second: 16,611.75803

Timestep Collection Time: 2.12663
Timestep Consumption Time: 0.88413
PPO Batch Consumption Time: 0.09994
Total Iteration Time: 3.01076

Cumulative Model Updates: 24,457
Cumulative Timesteps: 408,391,320

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,940.75577
Policy Entropy: 1.01106
Value Function Loss: 0.05116

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.01847
Policy Update Magnitude: 0.03156
Value Function Update Magnitude: 0.04671

Collected Steps per Second: 24,326.35477
Overall Steps per Second: 17,617.23590

Timestep Collection Time: 2.05547
Timestep Consumption Time: 0.78278
PPO Batch Consumption Time: 0.06142
Total Iteration Time: 2.83824

Cumulative Model Updates: 24,460
Cumulative Timesteps: 408,441,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 408441322...
Checkpoint 408441322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,641.00222
Policy Entropy: 1.01935
Value Function Loss: 0.05255

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02414
Policy Update Magnitude: 0.03185
Value Function Update Magnitude: 0.04458

Collected Steps per Second: 20,613.38630
Overall Steps per Second: 14,933.93733

Timestep Collection Time: 2.42658
Timestep Consumption Time: 0.92284
PPO Batch Consumption Time: 0.09425
Total Iteration Time: 3.34942

Cumulative Model Updates: 24,463
Cumulative Timesteps: 408,491,342

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,710.35843
Policy Entropy: 1.02688
Value Function Loss: 0.05579

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03523
Policy Update Magnitude: 0.03172
Value Function Update Magnitude: 0.04582

Collected Steps per Second: 22,954.58573
Overall Steps per Second: 15,794.19134

Timestep Collection Time: 2.17943
Timestep Consumption Time: 0.98806
PPO Batch Consumption Time: 0.11548
Total Iteration Time: 3.16749

Cumulative Model Updates: 24,466
Cumulative Timesteps: 408,541,370

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 408541370...
Checkpoint 408541370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,325.81675
Policy Entropy: 1.03039
Value Function Loss: 0.05581

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03324
Policy Update Magnitude: 0.03465
Value Function Update Magnitude: 0.04197

Collected Steps per Second: 23,898.59441
Overall Steps per Second: 17,446.68857

Timestep Collection Time: 2.09251
Timestep Consumption Time: 0.77382
PPO Batch Consumption Time: 0.06136
Total Iteration Time: 2.86633

Cumulative Model Updates: 24,469
Cumulative Timesteps: 408,591,378

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,836.43611
Policy Entropy: 1.02598
Value Function Loss: 0.05383

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03957
Policy Update Magnitude: 0.03385
Value Function Update Magnitude: 0.04403

Collected Steps per Second: 21,132.02560
Overall Steps per Second: 14,967.80925

Timestep Collection Time: 2.36693
Timestep Consumption Time: 0.97478
PPO Batch Consumption Time: 0.09662
Total Iteration Time: 3.34170

Cumulative Model Updates: 24,472
Cumulative Timesteps: 408,641,396

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 408641396...
Checkpoint 408641396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,200.08810
Policy Entropy: 1.02423
Value Function Loss: 0.05454

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03126
Policy Update Magnitude: 0.03236
Value Function Update Magnitude: 0.04486

Collected Steps per Second: 20,529.33212
Overall Steps per Second: 15,474.11071

Timestep Collection Time: 2.43583
Timestep Consumption Time: 0.79576
PPO Batch Consumption Time: 0.05873
Total Iteration Time: 3.23159

Cumulative Model Updates: 24,475
Cumulative Timesteps: 408,691,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,132.02055
Policy Entropy: 1.02787
Value Function Loss: 0.05340

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.01737
Policy Update Magnitude: 0.03244
Value Function Update Magnitude: 0.04666

Collected Steps per Second: 21,015.16157
Overall Steps per Second: 16,185.04181

Timestep Collection Time: 2.37962
Timestep Consumption Time: 0.71015
PPO Batch Consumption Time: 0.02984
Total Iteration Time: 3.08977

Cumulative Model Updates: 24,478
Cumulative Timesteps: 408,741,410

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 408741410...
Checkpoint 408741410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,998.64661
Policy Entropy: 1.03656
Value Function Loss: 0.06028

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02693
Policy Update Magnitude: 0.03482
Value Function Update Magnitude: 0.04481

Collected Steps per Second: 22,218.96376
Overall Steps per Second: 16,266.29532

Timestep Collection Time: 2.25123
Timestep Consumption Time: 0.82384
PPO Batch Consumption Time: 0.07440
Total Iteration Time: 3.07507

Cumulative Model Updates: 24,481
Cumulative Timesteps: 408,791,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,041.62403
Policy Entropy: 1.03007
Value Function Loss: 0.05988

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01900
Policy Update Magnitude: 0.03790
Value Function Update Magnitude: 0.04400

Collected Steps per Second: 21,898.23615
Overall Steps per Second: 15,891.02513

Timestep Collection Time: 2.28438
Timestep Consumption Time: 0.86356
PPO Batch Consumption Time: 0.07940
Total Iteration Time: 3.14794

Cumulative Model Updates: 24,484
Cumulative Timesteps: 408,841,454

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 408841454...
Checkpoint 408841454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,011.38943
Policy Entropy: 1.01816
Value Function Loss: 0.06301

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02242
Policy Update Magnitude: 0.03883
Value Function Update Magnitude: 0.04200

Collected Steps per Second: 22,779.40421
Overall Steps per Second: 16,944.91598

Timestep Collection Time: 2.19628
Timestep Consumption Time: 0.75623
PPO Batch Consumption Time: 0.06056
Total Iteration Time: 2.95251

Cumulative Model Updates: 24,487
Cumulative Timesteps: 408,891,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,509.05201
Policy Entropy: 1.00725
Value Function Loss: 0.05565

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02022
Policy Update Magnitude: 0.04019
Value Function Update Magnitude: 0.04414

Collected Steps per Second: 21,531.11428
Overall Steps per Second: 15,537.58430

Timestep Collection Time: 2.32334
Timestep Consumption Time: 0.89621
PPO Batch Consumption Time: 0.09670
Total Iteration Time: 3.21955

Cumulative Model Updates: 24,490
Cumulative Timesteps: 408,941,508

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 408941508...
Checkpoint 408941508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,551.33328
Policy Entropy: 1.01957
Value Function Loss: 0.05144

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01873
Policy Update Magnitude: 0.04080
Value Function Update Magnitude: 0.04671

Collected Steps per Second: 23,729.93525
Overall Steps per Second: 16,750.05126

Timestep Collection Time: 2.10730
Timestep Consumption Time: 0.87813
PPO Batch Consumption Time: 0.08378
Total Iteration Time: 2.98542

Cumulative Model Updates: 24,493
Cumulative Timesteps: 408,991,514

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,479.71028
Policy Entropy: 1.03246
Value Function Loss: 0.04772

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01598
Policy Update Magnitude: 0.04263
Value Function Update Magnitude: 0.04899

Collected Steps per Second: 21,937.88093
Overall Steps per Second: 15,685.92344

Timestep Collection Time: 2.28108
Timestep Consumption Time: 0.90917
PPO Batch Consumption Time: 0.08956
Total Iteration Time: 3.19025

Cumulative Model Updates: 24,496
Cumulative Timesteps: 409,041,556

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 409041556...
Checkpoint 409041556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,166.79111
Policy Entropy: 1.03693
Value Function Loss: 0.05065

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02091
Policy Update Magnitude: 0.04289
Value Function Update Magnitude: 0.05010

Collected Steps per Second: 22,045.55252
Overall Steps per Second: 16,357.18834

Timestep Collection Time: 2.26821
Timestep Consumption Time: 0.78879
PPO Batch Consumption Time: 0.06348
Total Iteration Time: 3.05700

Cumulative Model Updates: 24,499
Cumulative Timesteps: 409,091,560

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,957.02737
Policy Entropy: 1.02545
Value Function Loss: 0.05618

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02664
Policy Update Magnitude: 0.04301
Value Function Update Magnitude: 0.05508

Collected Steps per Second: 21,007.15324
Overall Steps per Second: 15,064.30592

Timestep Collection Time: 2.38128
Timestep Consumption Time: 0.93941
PPO Batch Consumption Time: 0.09877
Total Iteration Time: 3.32070

Cumulative Model Updates: 24,502
Cumulative Timesteps: 409,141,584

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 409141584...
Checkpoint 409141584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,063.28393
Policy Entropy: 1.03335
Value Function Loss: 0.05597

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02755
Policy Update Magnitude: 0.04571
Value Function Update Magnitude: 0.05519

Collected Steps per Second: 23,378.94822
Overall Steps per Second: 16,740.73177

Timestep Collection Time: 2.13996
Timestep Consumption Time: 0.84856
PPO Batch Consumption Time: 0.07448
Total Iteration Time: 2.98852

Cumulative Model Updates: 24,505
Cumulative Timesteps: 409,191,614

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,845.86926
Policy Entropy: 1.04681
Value Function Loss: 0.05764

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02715
Policy Update Magnitude: 0.03963
Value Function Update Magnitude: 0.05816

Collected Steps per Second: 23,724.89371
Overall Steps per Second: 16,739.88077

Timestep Collection Time: 2.10783
Timestep Consumption Time: 0.87953
PPO Batch Consumption Time: 0.08681
Total Iteration Time: 2.98736

Cumulative Model Updates: 24,508
Cumulative Timesteps: 409,241,622

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 409241622...
Checkpoint 409241622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,894.85093
Policy Entropy: 1.05002
Value Function Loss: 0.05924

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02185
Policy Update Magnitude: 0.04300
Value Function Update Magnitude: 0.05880

Collected Steps per Second: 24,133.36962
Overall Steps per Second: 16,793.27855

Timestep Collection Time: 2.07331
Timestep Consumption Time: 0.90621
PPO Batch Consumption Time: 0.09525
Total Iteration Time: 2.97953

Cumulative Model Updates: 24,511
Cumulative Timesteps: 409,291,658

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,911.32096
Policy Entropy: 1.04678
Value Function Loss: 0.05969

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02277
Policy Update Magnitude: 0.03931
Value Function Update Magnitude: 0.06032

Collected Steps per Second: 23,681.95941
Overall Steps per Second: 16,650.31388

Timestep Collection Time: 2.11182
Timestep Consumption Time: 0.89185
PPO Batch Consumption Time: 0.08122
Total Iteration Time: 3.00367

Cumulative Model Updates: 24,514
Cumulative Timesteps: 409,341,670

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 409341670...
Checkpoint 409341670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,627.18178
Policy Entropy: 1.02987
Value Function Loss: 0.05731

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02374
Policy Update Magnitude: 0.03822
Value Function Update Magnitude: 0.06674

Collected Steps per Second: 23,671.16321
Overall Steps per Second: 16,793.25158

Timestep Collection Time: 2.11354
Timestep Consumption Time: 0.86563
PPO Batch Consumption Time: 0.09065
Total Iteration Time: 2.97917

Cumulative Model Updates: 24,517
Cumulative Timesteps: 409,391,700

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,404.84387
Policy Entropy: 1.03629
Value Function Loss: 0.04624

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02245
Policy Update Magnitude: 0.03713
Value Function Update Magnitude: 0.06515

Collected Steps per Second: 23,834.58557
Overall Steps per Second: 16,716.30287

Timestep Collection Time: 2.09796
Timestep Consumption Time: 0.89337
PPO Batch Consumption Time: 0.09437
Total Iteration Time: 2.99133

Cumulative Model Updates: 24,520
Cumulative Timesteps: 409,441,704

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 409441704...
Checkpoint 409441704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,441.89185
Policy Entropy: 1.02957
Value Function Loss: 0.05056

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03161
Policy Update Magnitude: 0.03564
Value Function Update Magnitude: 0.06211

Collected Steps per Second: 23,888.96080
Overall Steps per Second: 16,760.15770

Timestep Collection Time: 2.09360
Timestep Consumption Time: 0.89050
PPO Batch Consumption Time: 0.08800
Total Iteration Time: 2.98410

Cumulative Model Updates: 24,523
Cumulative Timesteps: 409,491,718

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,146.45353
Policy Entropy: 1.04284
Value Function Loss: 0.05328

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03225
Policy Update Magnitude: 0.03619
Value Function Update Magnitude: 0.05975

Collected Steps per Second: 23,658.57690
Overall Steps per Second: 16,718.09466

Timestep Collection Time: 2.11467
Timestep Consumption Time: 0.87790
PPO Batch Consumption Time: 0.09090
Total Iteration Time: 2.99257

Cumulative Model Updates: 24,526
Cumulative Timesteps: 409,541,748

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 409541748...
Checkpoint 409541748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,626.51556
Policy Entropy: 1.04066
Value Function Loss: 0.06029

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.04811
Policy Update Magnitude: 0.03526
Value Function Update Magnitude: 0.06044

Collected Steps per Second: 22,903.29181
Overall Steps per Second: 15,804.50560

Timestep Collection Time: 2.18309
Timestep Consumption Time: 0.98056
PPO Batch Consumption Time: 0.12643
Total Iteration Time: 3.16365

Cumulative Model Updates: 24,529
Cumulative Timesteps: 409,591,748

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,861.90169
Policy Entropy: 1.04239
Value Function Loss: 0.06410

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03257
Policy Update Magnitude: 0.03456
Value Function Update Magnitude: 0.05990

Collected Steps per Second: 23,585.18935
Overall Steps per Second: 16,867.19058

Timestep Collection Time: 2.11997
Timestep Consumption Time: 0.84436
PPO Batch Consumption Time: 0.08600
Total Iteration Time: 2.96433

Cumulative Model Updates: 24,532
Cumulative Timesteps: 409,641,748

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 409641748...
Checkpoint 409641748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,295.63440
Policy Entropy: 1.04083
Value Function Loss: 0.06067

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02653
Policy Update Magnitude: 0.03575
Value Function Update Magnitude: 0.05959

Collected Steps per Second: 20,137.48461
Overall Steps per Second: 15,119.20743

Timestep Collection Time: 2.48492
Timestep Consumption Time: 0.82478
PPO Batch Consumption Time: 0.07109
Total Iteration Time: 3.30970

Cumulative Model Updates: 24,535
Cumulative Timesteps: 409,691,788

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,874.23494
Policy Entropy: 1.04344
Value Function Loss: 0.06055

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01743
Policy Update Magnitude: 0.03857
Value Function Update Magnitude: 0.06053

Collected Steps per Second: 21,832.53977
Overall Steps per Second: 15,145.35794

Timestep Collection Time: 2.29053
Timestep Consumption Time: 1.01134
PPO Batch Consumption Time: 0.12624
Total Iteration Time: 3.30187

Cumulative Model Updates: 24,538
Cumulative Timesteps: 409,741,796

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 409741796...
Checkpoint 409741796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,788.86812
Policy Entropy: 1.05261
Value Function Loss: 0.05248

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02155
Policy Update Magnitude: 0.03828
Value Function Update Magnitude: 0.05926

Collected Steps per Second: 19,572.24532
Overall Steps per Second: 15,034.65672

Timestep Collection Time: 2.55546
Timestep Consumption Time: 0.77126
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 3.32671

Cumulative Model Updates: 24,541
Cumulative Timesteps: 409,791,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,415.43191
Policy Entropy: 1.04649
Value Function Loss: 0.05260

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02467
Policy Update Magnitude: 0.03716
Value Function Update Magnitude: 0.06216

Collected Steps per Second: 19,992.89932
Overall Steps per Second: 15,387.04559

Timestep Collection Time: 2.50089
Timestep Consumption Time: 0.74860
PPO Batch Consumption Time: 0.03236
Total Iteration Time: 3.24949

Cumulative Model Updates: 24,544
Cumulative Timesteps: 409,841,812

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 409841812...
Checkpoint 409841812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,378.86653
Policy Entropy: 1.04740
Value Function Loss: 0.05500

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03586
Policy Update Magnitude: 0.03549
Value Function Update Magnitude: 0.06208

Collected Steps per Second: 20,523.55576
Overall Steps per Second: 15,991.66066

Timestep Collection Time: 2.43798
Timestep Consumption Time: 0.69090
PPO Batch Consumption Time: 0.02890
Total Iteration Time: 3.12888

Cumulative Model Updates: 24,547
Cumulative Timesteps: 409,891,848

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,538.97033
Policy Entropy: 1.04863
Value Function Loss: 0.05383

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.04859
Policy Update Magnitude: 0.03664
Value Function Update Magnitude: 0.05948

Collected Steps per Second: 21,761.35841
Overall Steps per Second: 15,429.13901

Timestep Collection Time: 2.29793
Timestep Consumption Time: 0.94308
PPO Batch Consumption Time: 0.11279
Total Iteration Time: 3.24101

Cumulative Model Updates: 24,550
Cumulative Timesteps: 409,941,854

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 409941854...
Checkpoint 409941854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,126.25328
Policy Entropy: 1.05106
Value Function Loss: 0.05704

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.06409
Policy Update Magnitude: 0.03468
Value Function Update Magnitude: 0.06013

Collected Steps per Second: 22,548.84212
Overall Steps per Second: 15,691.46328

Timestep Collection Time: 2.21883
Timestep Consumption Time: 0.96966
PPO Batch Consumption Time: 0.11210
Total Iteration Time: 3.18849

Cumulative Model Updates: 24,553
Cumulative Timesteps: 409,991,886

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,630.27076
Policy Entropy: 1.05737
Value Function Loss: 0.05227

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04652
Policy Update Magnitude: 0.03322
Value Function Update Magnitude: 0.06115

Collected Steps per Second: 23,689.77141
Overall Steps per Second: 17,316.07606

Timestep Collection Time: 2.11146
Timestep Consumption Time: 0.77719
PPO Batch Consumption Time: 0.06294
Total Iteration Time: 2.88865

Cumulative Model Updates: 24,556
Cumulative Timesteps: 410,041,906

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 410041906...
Checkpoint 410041906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,808.67707
Policy Entropy: 1.03982
Value Function Loss: 0.05388

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04503
Policy Update Magnitude: 0.03258
Value Function Update Magnitude: 0.06072

Collected Steps per Second: 21,111.70235
Overall Steps per Second: 15,993.41975

Timestep Collection Time: 2.36940
Timestep Consumption Time: 0.75826
PPO Batch Consumption Time: 0.02795
Total Iteration Time: 3.12766

Cumulative Model Updates: 24,559
Cumulative Timesteps: 410,091,928

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,994.22414
Policy Entropy: 1.04525
Value Function Loss: 0.04889

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02091
Policy Update Magnitude: 0.03294
Value Function Update Magnitude: 0.05770

Collected Steps per Second: 24,125.53032
Overall Steps per Second: 18,038.64290

Timestep Collection Time: 2.07324
Timestep Consumption Time: 0.69959
PPO Batch Consumption Time: 0.02893
Total Iteration Time: 2.77283

Cumulative Model Updates: 24,562
Cumulative Timesteps: 410,141,946

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 410141946...
Checkpoint 410141946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,799.14881
Policy Entropy: 1.04212
Value Function Loss: 0.05077

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04255
Policy Update Magnitude: 0.03312
Value Function Update Magnitude: 0.05694

Collected Steps per Second: 22,384.22269
Overall Steps per Second: 15,849.61467

Timestep Collection Time: 2.23452
Timestep Consumption Time: 0.92127
PPO Batch Consumption Time: 0.10393
Total Iteration Time: 3.15579

Cumulative Model Updates: 24,565
Cumulative Timesteps: 410,191,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,907.56354
Policy Entropy: 1.06643
Value Function Loss: 0.04475

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02362
Policy Update Magnitude: 0.03675
Value Function Update Magnitude: 0.05364

Collected Steps per Second: 22,339.58519
Overall Steps per Second: 16,484.01008

Timestep Collection Time: 2.23907
Timestep Consumption Time: 0.79538
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 3.03446

Cumulative Model Updates: 24,568
Cumulative Timesteps: 410,241,984

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 410241984...
Checkpoint 410241984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,811.04513
Policy Entropy: 1.07730
Value Function Loss: 0.04886

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02997
Policy Update Magnitude: 0.03883
Value Function Update Magnitude: 0.04991

Collected Steps per Second: 18,904.43924
Overall Steps per Second: 14,080.09317

Timestep Collection Time: 2.64520
Timestep Consumption Time: 0.90634
PPO Batch Consumption Time: 0.09517
Total Iteration Time: 3.55154

Cumulative Model Updates: 24,571
Cumulative Timesteps: 410,291,990

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,309.38719
Policy Entropy: 1.07297
Value Function Loss: 0.04683

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02137
Policy Update Magnitude: 0.03857
Value Function Update Magnitude: 0.05243

Collected Steps per Second: 21,639.27710
Overall Steps per Second: 16,226.15610

Timestep Collection Time: 2.31200
Timestep Consumption Time: 0.77129
PPO Batch Consumption Time: 0.05845
Total Iteration Time: 3.08329

Cumulative Model Updates: 24,574
Cumulative Timesteps: 410,342,020

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 410342020...
Checkpoint 410342020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,265.01499
Policy Entropy: 1.06969
Value Function Loss: 0.04734

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.01971
Policy Update Magnitude: 0.03846
Value Function Update Magnitude: 0.05140

Collected Steps per Second: 21,071.46224
Overall Steps per Second: 15,200.24757

Timestep Collection Time: 2.37373
Timestep Consumption Time: 0.91687
PPO Batch Consumption Time: 0.09224
Total Iteration Time: 3.29060

Cumulative Model Updates: 24,577
Cumulative Timesteps: 410,392,038

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,577.74150
Policy Entropy: 1.07603
Value Function Loss: 0.04280

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02602
Policy Update Magnitude: 0.03709
Value Function Update Magnitude: 0.04905

Collected Steps per Second: 22,428.12247
Overall Steps per Second: 15,718.58214

Timestep Collection Time: 2.23032
Timestep Consumption Time: 0.95202
PPO Batch Consumption Time: 0.10547
Total Iteration Time: 3.18235

Cumulative Model Updates: 24,580
Cumulative Timesteps: 410,442,060

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 410442060...
Checkpoint 410442060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,279.09615
Policy Entropy: 1.08632
Value Function Loss: 0.04255

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02184
Policy Update Magnitude: 0.03700
Value Function Update Magnitude: 0.05018

Collected Steps per Second: 22,379.50886
Overall Steps per Second: 16,572.99242

Timestep Collection Time: 2.23571
Timestep Consumption Time: 0.78330
PPO Batch Consumption Time: 0.06004
Total Iteration Time: 3.01901

Cumulative Model Updates: 24,583
Cumulative Timesteps: 410,492,094

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,779.41924
Policy Entropy: 1.09671
Value Function Loss: 0.04408

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02183
Policy Update Magnitude: 0.03418
Value Function Update Magnitude: 0.05234

Collected Steps per Second: 21,618.35285
Overall Steps per Second: 15,745.94336

Timestep Collection Time: 2.31313
Timestep Consumption Time: 0.86267
PPO Batch Consumption Time: 0.07889
Total Iteration Time: 3.17580

Cumulative Model Updates: 24,586
Cumulative Timesteps: 410,542,100

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 410542100...
Checkpoint 410542100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,935.46405
Policy Entropy: 1.09020
Value Function Loss: 0.04258

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01545
Policy Update Magnitude: 0.03820
Value Function Update Magnitude: 0.05179

Collected Steps per Second: 23,672.10179
Overall Steps per Second: 16,988.52733

Timestep Collection Time: 2.11346
Timestep Consumption Time: 0.83147
PPO Batch Consumption Time: 0.06255
Total Iteration Time: 2.94493

Cumulative Model Updates: 24,589
Cumulative Timesteps: 410,592,130

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,992.90272
Policy Entropy: 1.08546
Value Function Loss: 0.04546

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02005
Policy Update Magnitude: 0.03681
Value Function Update Magnitude: 0.05122

Collected Steps per Second: 24,340.53826
Overall Steps per Second: 16,640.87072

Timestep Collection Time: 2.05517
Timestep Consumption Time: 0.95092
PPO Batch Consumption Time: 0.11509
Total Iteration Time: 3.00609

Cumulative Model Updates: 24,592
Cumulative Timesteps: 410,642,154

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 410642154...
Checkpoint 410642154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,475.25517
Policy Entropy: 1.08313
Value Function Loss: 0.05123

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01871
Policy Update Magnitude: 0.03336
Value Function Update Magnitude: 0.05492

Collected Steps per Second: 23,727.75274
Overall Steps per Second: 17,163.54121

Timestep Collection Time: 2.10774
Timestep Consumption Time: 0.80611
PPO Batch Consumption Time: 0.06627
Total Iteration Time: 2.91385

Cumulative Model Updates: 24,595
Cumulative Timesteps: 410,692,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,651.80451
Policy Entropy: 1.07923
Value Function Loss: 0.05827

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01917
Policy Update Magnitude: 0.03315
Value Function Update Magnitude: 0.05668

Collected Steps per Second: 22,195.41030
Overall Steps per Second: 15,225.48037

Timestep Collection Time: 2.25389
Timestep Consumption Time: 1.03179
PPO Batch Consumption Time: 0.11619
Total Iteration Time: 3.28568

Cumulative Model Updates: 24,598
Cumulative Timesteps: 410,742,192

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 410742192...
Checkpoint 410742192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,482.02088
Policy Entropy: 1.08174
Value Function Loss: 0.06129

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02239
Policy Update Magnitude: 0.03329
Value Function Update Magnitude: 0.05746

Collected Steps per Second: 23,270.25319
Overall Steps per Second: 17,704.64177

Timestep Collection Time: 2.15047
Timestep Consumption Time: 0.67602
PPO Batch Consumption Time: 0.02868
Total Iteration Time: 2.82649

Cumulative Model Updates: 24,601
Cumulative Timesteps: 410,792,234

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,373.25691
Policy Entropy: 1.09457
Value Function Loss: 0.05805

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02720
Policy Update Magnitude: 0.03422
Value Function Update Magnitude: 0.05570

Collected Steps per Second: 23,336.87444
Overall Steps per Second: 16,717.93158

Timestep Collection Time: 2.14330
Timestep Consumption Time: 0.84857
PPO Batch Consumption Time: 0.07633
Total Iteration Time: 2.99188

Cumulative Model Updates: 24,604
Cumulative Timesteps: 410,842,252

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 410842252...
Checkpoint 410842252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,861.50838
Policy Entropy: 1.10613
Value Function Loss: 0.05274

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03577
Policy Update Magnitude: 0.03476
Value Function Update Magnitude: 0.05837

Collected Steps per Second: 23,258.69306
Overall Steps per Second: 16,070.14407

Timestep Collection Time: 2.15102
Timestep Consumption Time: 0.96220
PPO Batch Consumption Time: 0.12032
Total Iteration Time: 3.11323

Cumulative Model Updates: 24,607
Cumulative Timesteps: 410,892,282

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,139.41646
Policy Entropy: 1.11059
Value Function Loss: 0.05167

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02879
Policy Update Magnitude: 0.03453
Value Function Update Magnitude: 0.06063

Collected Steps per Second: 21,482.74480
Overall Steps per Second: 15,370.57983

Timestep Collection Time: 2.32885
Timestep Consumption Time: 0.92607
PPO Batch Consumption Time: 0.08883
Total Iteration Time: 3.25492

Cumulative Model Updates: 24,610
Cumulative Timesteps: 410,942,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 410942312...
Checkpoint 410942312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,188.34911
Policy Entropy: 1.11076
Value Function Loss: 0.05360

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03616
Policy Update Magnitude: 0.03405
Value Function Update Magnitude: 0.05704

Collected Steps per Second: 21,420.89236
Overall Steps per Second: 15,596.47749

Timestep Collection Time: 2.33501
Timestep Consumption Time: 0.87200
PPO Batch Consumption Time: 0.07922
Total Iteration Time: 3.20701

Cumulative Model Updates: 24,613
Cumulative Timesteps: 410,992,330

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,316.28863
Policy Entropy: 1.10630
Value Function Loss: 0.05686

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.05004
Policy Update Magnitude: 0.03223
Value Function Update Magnitude: 0.05635

Collected Steps per Second: 22,231.65141
Overall Steps per Second: 15,985.59097

Timestep Collection Time: 2.24905
Timestep Consumption Time: 0.87877
PPO Batch Consumption Time: 0.08707
Total Iteration Time: 3.12782

Cumulative Model Updates: 24,616
Cumulative Timesteps: 411,042,330

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 411042330...
Checkpoint 411042330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,503.65533
Policy Entropy: 1.10452
Value Function Loss: 0.05668

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.06309
Policy Update Magnitude: 0.03261
Value Function Update Magnitude: 0.05567

Collected Steps per Second: 21,869.92827
Overall Steps per Second: 15,600.60554

Timestep Collection Time: 2.28743
Timestep Consumption Time: 0.91924
PPO Batch Consumption Time: 0.10668
Total Iteration Time: 3.20667

Cumulative Model Updates: 24,619
Cumulative Timesteps: 411,092,356

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,779.02602
Policy Entropy: 1.10230
Value Function Loss: 0.04952

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05341
Policy Update Magnitude: 0.03039
Value Function Update Magnitude: 0.05086

Collected Steps per Second: 23,747.72261
Overall Steps per Second: 17,152.06750

Timestep Collection Time: 2.10614
Timestep Consumption Time: 0.80989
PPO Batch Consumption Time: 0.06439
Total Iteration Time: 2.91603

Cumulative Model Updates: 24,622
Cumulative Timesteps: 411,142,372

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 411142372...
Checkpoint 411142372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,077.51768
Policy Entropy: 1.10984
Value Function Loss: 0.04834

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.05914
Policy Update Magnitude: 0.02933
Value Function Update Magnitude: 0.04375

Collected Steps per Second: 22,477.28895
Overall Steps per Second: 16,464.01887

Timestep Collection Time: 2.22554
Timestep Consumption Time: 0.81285
PPO Batch Consumption Time: 0.07302
Total Iteration Time: 3.03838

Cumulative Model Updates: 24,625
Cumulative Timesteps: 411,192,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,217.40001
Policy Entropy: 1.10655
Value Function Loss: 0.05305

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06199
Policy Update Magnitude: 0.02780
Value Function Update Magnitude: 0.04013

Collected Steps per Second: 24,518.09390
Overall Steps per Second: 17,885.02693

Timestep Collection Time: 2.04062
Timestep Consumption Time: 0.75681
PPO Batch Consumption Time: 0.06069
Total Iteration Time: 2.79742

Cumulative Model Updates: 24,628
Cumulative Timesteps: 411,242,428

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 411242428...
Checkpoint 411242428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,186.00496
Policy Entropy: 1.10083
Value Function Loss: 0.06494

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.05781
Policy Update Magnitude: 0.03098
Value Function Update Magnitude: 0.04423

Collected Steps per Second: 21,138.42831
Overall Steps per Second: 14,915.66886

Timestep Collection Time: 2.36640
Timestep Consumption Time: 0.98725
PPO Batch Consumption Time: 0.12710
Total Iteration Time: 3.35365

Cumulative Model Updates: 24,631
Cumulative Timesteps: 411,292,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,102.60554
Policy Entropy: 1.08739
Value Function Loss: 0.06013

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06744
Policy Update Magnitude: 0.03203
Value Function Update Magnitude: 0.05439

Collected Steps per Second: 22,569.42204
Overall Steps per Second: 16,632.93021

Timestep Collection Time: 2.21645
Timestep Consumption Time: 0.79108
PPO Batch Consumption Time: 0.05271
Total Iteration Time: 3.00753

Cumulative Model Updates: 24,634
Cumulative Timesteps: 411,342,474

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 411342474...
Checkpoint 411342474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,542.84059
Policy Entropy: 1.10846
Value Function Loss: 0.04887

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07207
Policy Update Magnitude: 0.03280
Value Function Update Magnitude: 0.05822

Collected Steps per Second: 21,458.68799
Overall Steps per Second: 15,796.23277

Timestep Collection Time: 2.33099
Timestep Consumption Time: 0.83559
PPO Batch Consumption Time: 0.05920
Total Iteration Time: 3.16658

Cumulative Model Updates: 24,637
Cumulative Timesteps: 411,392,494

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,397.63986
Policy Entropy: 1.11022
Value Function Loss: 0.04090

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.06942
Policy Update Magnitude: 0.02896
Value Function Update Magnitude: 0.05382

Collected Steps per Second: 23,118.00017
Overall Steps per Second: 17,566.50605

Timestep Collection Time: 2.16325
Timestep Consumption Time: 0.68365
PPO Batch Consumption Time: 0.02944
Total Iteration Time: 2.84690

Cumulative Model Updates: 24,640
Cumulative Timesteps: 411,442,504

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 411442504...
Checkpoint 411442504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,282.21739
Policy Entropy: 1.12009
Value Function Loss: 0.04030

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05427
Policy Update Magnitude: 0.02906
Value Function Update Magnitude: 0.05509

Collected Steps per Second: 20,939.23013
Overall Steps per Second: 15,034.02033

Timestep Collection Time: 2.38796
Timestep Consumption Time: 0.93797
PPO Batch Consumption Time: 0.09784
Total Iteration Time: 3.32592

Cumulative Model Updates: 24,643
Cumulative Timesteps: 411,492,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,156.16097
Policy Entropy: 1.12948
Value Function Loss: 0.04045

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06217
Policy Update Magnitude: 0.02803
Value Function Update Magnitude: 0.05572

Collected Steps per Second: 23,410.59025
Overall Steps per Second: 16,697.28581

Timestep Collection Time: 2.13732
Timestep Consumption Time: 0.85933
PPO Batch Consumption Time: 0.07048
Total Iteration Time: 2.99665

Cumulative Model Updates: 24,646
Cumulative Timesteps: 411,542,542

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 411542542...
Checkpoint 411542542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,051.70252
Policy Entropy: 1.13769
Value Function Loss: 0.04142

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03489
Policy Update Magnitude: 0.02585
Value Function Update Magnitude: 0.05301

Collected Steps per Second: 22,755.77535
Overall Steps per Second: 16,801.65316

Timestep Collection Time: 2.19812
Timestep Consumption Time: 0.77896
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 2.97709

Cumulative Model Updates: 24,649
Cumulative Timesteps: 411,592,562

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,203.89469
Policy Entropy: 1.12832
Value Function Loss: 0.04322

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02675
Policy Update Magnitude: 0.02779
Value Function Update Magnitude: 0.05412

Collected Steps per Second: 19,837.96313
Overall Steps per Second: 14,857.53587

Timestep Collection Time: 2.52133
Timestep Consumption Time: 0.84518
PPO Batch Consumption Time: 0.02910
Total Iteration Time: 3.36651

Cumulative Model Updates: 24,652
Cumulative Timesteps: 411,642,580

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 411642580...
Checkpoint 411642580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,588.68682
Policy Entropy: 1.10906
Value Function Loss: 0.04976

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05567
Policy Update Magnitude: 0.02930
Value Function Update Magnitude: 0.05839

Collected Steps per Second: 21,074.81915
Overall Steps per Second: 15,758.34988

Timestep Collection Time: 2.37392
Timestep Consumption Time: 0.80090
PPO Batch Consumption Time: 0.05959
Total Iteration Time: 3.17482

Cumulative Model Updates: 24,655
Cumulative Timesteps: 411,692,610

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,556.93373
Policy Entropy: 1.10278
Value Function Loss: 0.05351

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04751
Policy Update Magnitude: 0.03135
Value Function Update Magnitude: 0.06057

Collected Steps per Second: 24,167.30006
Overall Steps per Second: 18,122.13219

Timestep Collection Time: 2.06966
Timestep Consumption Time: 0.69039
PPO Batch Consumption Time: 0.02826
Total Iteration Time: 2.76005

Cumulative Model Updates: 24,658
Cumulative Timesteps: 411,742,628

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 411742628...
Checkpoint 411742628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,692.40180
Policy Entropy: 1.11521
Value Function Loss: 0.05833

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07722
Policy Update Magnitude: 0.03343
Value Function Update Magnitude: 0.05802

Collected Steps per Second: 22,317.33090
Overall Steps per Second: 16,139.59292

Timestep Collection Time: 2.24104
Timestep Consumption Time: 0.85780
PPO Batch Consumption Time: 0.07967
Total Iteration Time: 3.09884

Cumulative Model Updates: 24,661
Cumulative Timesteps: 411,792,642

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,409.00899
Policy Entropy: 1.12312
Value Function Loss: 0.06501

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07596
Policy Update Magnitude: 0.03042
Value Function Update Magnitude: 0.05898

Collected Steps per Second: 21,396.54558
Overall Steps per Second: 15,610.03014

Timestep Collection Time: 2.33860
Timestep Consumption Time: 0.86690
PPO Batch Consumption Time: 0.04761
Total Iteration Time: 3.20550

Cumulative Model Updates: 24,664
Cumulative Timesteps: 411,842,680

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 411842680...
Checkpoint 411842680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,193.51332
Policy Entropy: 1.12940
Value Function Loss: 0.06644

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.06998
Policy Update Magnitude: 0.03331
Value Function Update Magnitude: 0.05157

Collected Steps per Second: 21,405.37740
Overall Steps per Second: 15,143.83847

Timestep Collection Time: 2.33792
Timestep Consumption Time: 0.96666
PPO Batch Consumption Time: 0.12257
Total Iteration Time: 3.30458

Cumulative Model Updates: 24,667
Cumulative Timesteps: 411,892,724

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,742.01760
Policy Entropy: 1.11869
Value Function Loss: 0.06325

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05021
Policy Update Magnitude: 0.03417
Value Function Update Magnitude: 0.05302

Collected Steps per Second: 24,004.24076
Overall Steps per Second: 16,614.15846

Timestep Collection Time: 2.08397
Timestep Consumption Time: 0.92696
PPO Batch Consumption Time: 0.10594
Total Iteration Time: 3.01093

Cumulative Model Updates: 24,670
Cumulative Timesteps: 411,942,748

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 411942748...
Checkpoint 411942748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,907.04603
Policy Entropy: 1.12217
Value Function Loss: 0.05308

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.04821
Policy Update Magnitude: 0.03267
Value Function Update Magnitude: 0.04895

Collected Steps per Second: 23,643.76563
Overall Steps per Second: 16,727.13296

Timestep Collection Time: 2.11675
Timestep Consumption Time: 0.87527
PPO Batch Consumption Time: 0.07395
Total Iteration Time: 2.99203

Cumulative Model Updates: 24,673
Cumulative Timesteps: 411,992,796

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,639.23515
Policy Entropy: 1.11759
Value Function Loss: 0.04922

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03943
Policy Update Magnitude: 0.03194
Value Function Update Magnitude: 0.05043

Collected Steps per Second: 22,490.89243
Overall Steps per Second: 15,688.79111

Timestep Collection Time: 2.22312
Timestep Consumption Time: 0.96387
PPO Batch Consumption Time: 0.10489
Total Iteration Time: 3.18699

Cumulative Model Updates: 24,676
Cumulative Timesteps: 412,042,796

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 412042796...
Checkpoint 412042796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,962.16731
Policy Entropy: 1.10955
Value Function Loss: 0.04972

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02217
Policy Update Magnitude: 0.03083
Value Function Update Magnitude: 0.05177

Collected Steps per Second: 21,468.09019
Overall Steps per Second: 16,033.74824

Timestep Collection Time: 2.33025
Timestep Consumption Time: 0.78979
PPO Batch Consumption Time: 0.06389
Total Iteration Time: 3.12004

Cumulative Model Updates: 24,679
Cumulative Timesteps: 412,092,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,471.77130
Policy Entropy: 1.10926
Value Function Loss: 0.05664

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02727
Policy Update Magnitude: 0.03252
Value Function Update Magnitude: 0.05214

Collected Steps per Second: 21,522.43995
Overall Steps per Second: 15,350.56636

Timestep Collection Time: 2.32325
Timestep Consumption Time: 0.93409
PPO Batch Consumption Time: 0.11002
Total Iteration Time: 3.25734

Cumulative Model Updates: 24,682
Cumulative Timesteps: 412,142,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 412142824...
Checkpoint 412142824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,813.66861
Policy Entropy: 1.11680
Value Function Loss: 0.05480

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03175
Policy Update Magnitude: 0.03374
Value Function Update Magnitude: 0.05791

Collected Steps per Second: 20,345.94119
Overall Steps per Second: 14,658.76642

Timestep Collection Time: 2.45877
Timestep Consumption Time: 0.95393
PPO Batch Consumption Time: 0.08039
Total Iteration Time: 3.41270

Cumulative Model Updates: 24,685
Cumulative Timesteps: 412,192,850

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,139.13710
Policy Entropy: 1.13180
Value Function Loss: 0.04840

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.03237
Value Function Update Magnitude: 0.07013

Collected Steps per Second: 20,111.27725
Overall Steps per Second: 14,961.48951

Timestep Collection Time: 2.48637
Timestep Consumption Time: 0.85581
PPO Batch Consumption Time: 0.06808
Total Iteration Time: 3.34218

Cumulative Model Updates: 24,688
Cumulative Timesteps: 412,242,854

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 412242854...
Checkpoint 412242854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,547.90710
Policy Entropy: 1.12519
Value Function Loss: 0.04880

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03197
Policy Update Magnitude: 0.03080
Value Function Update Magnitude: 0.07519

Collected Steps per Second: 19,835.09894
Overall Steps per Second: 14,886.30448

Timestep Collection Time: 2.52240
Timestep Consumption Time: 0.83854
PPO Batch Consumption Time: 0.06161
Total Iteration Time: 3.36094

Cumulative Model Updates: 24,691
Cumulative Timesteps: 412,292,886

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,076.10532
Policy Entropy: 1.11307
Value Function Loss: 0.04650

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02973
Policy Update Magnitude: 0.02939
Value Function Update Magnitude: 0.05882

Collected Steps per Second: 22,440.74030
Overall Steps per Second: 16,257.22520

Timestep Collection Time: 2.22889
Timestep Consumption Time: 0.84777
PPO Batch Consumption Time: 0.07964
Total Iteration Time: 3.07666

Cumulative Model Updates: 24,694
Cumulative Timesteps: 412,342,904

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 412342904...
Checkpoint 412342904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,644.87868
Policy Entropy: 1.11580
Value Function Loss: 0.04670

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02511
Policy Update Magnitude: 0.03034
Value Function Update Magnitude: 0.05609

Collected Steps per Second: 20,443.11542
Overall Steps per Second: 14,934.06486

Timestep Collection Time: 2.44591
Timestep Consumption Time: 0.90228
PPO Batch Consumption Time: 0.09218
Total Iteration Time: 3.34818

Cumulative Model Updates: 24,697
Cumulative Timesteps: 412,392,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,924.14044
Policy Entropy: 1.11089
Value Function Loss: 0.04538

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05336
Policy Update Magnitude: 0.02895
Value Function Update Magnitude: 0.05466

Collected Steps per Second: 22,498.98669
Overall Steps per Second: 16,506.35901

Timestep Collection Time: 2.22366
Timestep Consumption Time: 0.80730
PPO Batch Consumption Time: 0.07539
Total Iteration Time: 3.03095

Cumulative Model Updates: 24,700
Cumulative Timesteps: 412,442,936

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 412442936...
Checkpoint 412442936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,619.64810
Policy Entropy: 1.11458
Value Function Loss: 0.04672

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04681
Policy Update Magnitude: 0.02976
Value Function Update Magnitude: 0.05384

Collected Steps per Second: 22,003.33524
Overall Steps per Second: 15,955.92501

Timestep Collection Time: 2.27384
Timestep Consumption Time: 0.86180
PPO Batch Consumption Time: 0.08206
Total Iteration Time: 3.13564

Cumulative Model Updates: 24,703
Cumulative Timesteps: 412,492,968

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,423.17045
Policy Entropy: 1.12376
Value Function Loss: 0.05521

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.04961
Policy Update Magnitude: 0.03155
Value Function Update Magnitude: 0.05540

Collected Steps per Second: 23,615.73549
Overall Steps per Second: 16,982.20661

Timestep Collection Time: 2.11791
Timestep Consumption Time: 0.82729
PPO Batch Consumption Time: 0.05958
Total Iteration Time: 2.94520

Cumulative Model Updates: 24,706
Cumulative Timesteps: 412,542,984

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 412542984...
Checkpoint 412542984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,587.12691
Policy Entropy: 1.12343
Value Function Loss: 0.05176

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05382
Policy Update Magnitude: 0.03108
Value Function Update Magnitude: 0.05503

Collected Steps per Second: 22,757.00771
Overall Steps per Second: 17,316.05989

Timestep Collection Time: 2.19721
Timestep Consumption Time: 0.69040
PPO Batch Consumption Time: 0.02879
Total Iteration Time: 2.88761

Cumulative Model Updates: 24,709
Cumulative Timesteps: 412,592,986

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,079.79151
Policy Entropy: 1.11748
Value Function Loss: 0.05753

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04228
Policy Update Magnitude: 0.03177
Value Function Update Magnitude: 0.05504

Collected Steps per Second: 21,960.10755
Overall Steps per Second: 15,934.87798

Timestep Collection Time: 2.27749
Timestep Consumption Time: 0.86116
PPO Batch Consumption Time: 0.09186
Total Iteration Time: 3.13865

Cumulative Model Updates: 24,712
Cumulative Timesteps: 412,643,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 412643000...
Checkpoint 412643000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,372.05758
Policy Entropy: 1.11256
Value Function Loss: 0.05299

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.04859
Policy Update Magnitude: 0.03333
Value Function Update Magnitude: 0.05986

Collected Steps per Second: 22,097.24626
Overall Steps per Second: 15,756.78275

Timestep Collection Time: 2.26390
Timestep Consumption Time: 0.91098
PPO Batch Consumption Time: 0.09802
Total Iteration Time: 3.17489

Cumulative Model Updates: 24,715
Cumulative Timesteps: 412,693,026

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,290.72511
Policy Entropy: 1.11417
Value Function Loss: 0.05352

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.04310
Policy Update Magnitude: 0.03188
Value Function Update Magnitude: 0.06082

Collected Steps per Second: 21,691.47451
Overall Steps per Second: 15,923.21207

Timestep Collection Time: 2.30616
Timestep Consumption Time: 0.83542
PPO Batch Consumption Time: 0.06195
Total Iteration Time: 3.14158

Cumulative Model Updates: 24,718
Cumulative Timesteps: 412,743,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 412743050...
Checkpoint 412743050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,107.56022
Policy Entropy: 1.12208
Value Function Loss: 0.05200

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.05415
Policy Update Magnitude: 0.03268
Value Function Update Magnitude: 0.05738

Collected Steps per Second: 23,738.17935
Overall Steps per Second: 16,581.17485

Timestep Collection Time: 2.10825
Timestep Consumption Time: 0.90999
PPO Batch Consumption Time: 0.11183
Total Iteration Time: 3.01824

Cumulative Model Updates: 24,721
Cumulative Timesteps: 412,793,096

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,934.99011
Policy Entropy: 1.12840
Value Function Loss: 0.05350

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05183
Policy Update Magnitude: 0.03357
Value Function Update Magnitude: 0.05596

Collected Steps per Second: 22,855.32539
Overall Steps per Second: 16,772.38978

Timestep Collection Time: 2.18829
Timestep Consumption Time: 0.79364
PPO Batch Consumption Time: 0.05879
Total Iteration Time: 2.98192

Cumulative Model Updates: 24,724
Cumulative Timesteps: 412,843,110

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 412843110...
Checkpoint 412843110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,522.62359
Policy Entropy: 1.12826
Value Function Loss: 0.06037

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.06817
Policy Update Magnitude: 0.03353
Value Function Update Magnitude: 0.05369

Collected Steps per Second: 21,667.24772
Overall Steps per Second: 15,622.13164

Timestep Collection Time: 2.30902
Timestep Consumption Time: 0.89349
PPO Batch Consumption Time: 0.09705
Total Iteration Time: 3.20251

Cumulative Model Updates: 24,727
Cumulative Timesteps: 412,893,140

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,744.30357
Policy Entropy: 1.14129
Value Function Loss: 0.05607

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07237
Policy Update Magnitude: 0.03265
Value Function Update Magnitude: 0.05276

Collected Steps per Second: 24,250.81591
Overall Steps per Second: 16,777.16856

Timestep Collection Time: 2.06294
Timestep Consumption Time: 0.91897
PPO Batch Consumption Time: 0.10413
Total Iteration Time: 2.98191

Cumulative Model Updates: 24,730
Cumulative Timesteps: 412,943,168

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 412943168...
Checkpoint 412943168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,504.81175
Policy Entropy: 1.14844
Value Function Loss: 0.05444

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06617
Policy Update Magnitude: 0.03343
Value Function Update Magnitude: 0.04828

Collected Steps per Second: 23,940.69003
Overall Steps per Second: 16,663.94953

Timestep Collection Time: 2.08950
Timestep Consumption Time: 0.91243
PPO Batch Consumption Time: 0.09252
Total Iteration Time: 3.00193

Cumulative Model Updates: 24,733
Cumulative Timesteps: 412,993,192

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,353.72981
Policy Entropy: 1.16726
Value Function Loss: 0.04993

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06264
Policy Update Magnitude: 0.03372
Value Function Update Magnitude: 0.04410

Collected Steps per Second: 24,571.00223
Overall Steps per Second: 16,703.44053

Timestep Collection Time: 2.03565
Timestep Consumption Time: 0.95882
PPO Batch Consumption Time: 0.08084
Total Iteration Time: 2.99447

Cumulative Model Updates: 24,736
Cumulative Timesteps: 413,043,210

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 413043210...
Checkpoint 413043210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,360.14812
Policy Entropy: 1.15567
Value Function Loss: 0.05717

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04654
Policy Update Magnitude: 0.03238
Value Function Update Magnitude: 0.04044

Collected Steps per Second: 22,033.22362
Overall Steps per Second: 15,834.75663

Timestep Collection Time: 2.26948
Timestep Consumption Time: 0.88838
PPO Batch Consumption Time: 0.09449
Total Iteration Time: 3.15786

Cumulative Model Updates: 24,739
Cumulative Timesteps: 413,093,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,011.64167
Policy Entropy: 1.14192
Value Function Loss: 0.05531

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03523
Policy Update Magnitude: 0.03292
Value Function Update Magnitude: 0.04077

Collected Steps per Second: 24,097.10663
Overall Steps per Second: 17,744.30452

Timestep Collection Time: 2.07519
Timestep Consumption Time: 0.74296
PPO Batch Consumption Time: 0.06003
Total Iteration Time: 2.81814

Cumulative Model Updates: 24,742
Cumulative Timesteps: 413,143,220

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 413143220...
Checkpoint 413143220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,551.44393
Policy Entropy: 1.12914
Value Function Loss: 0.05233

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.03893
Policy Update Magnitude: 0.03447
Value Function Update Magnitude: 0.03884

Collected Steps per Second: 21,809.87607
Overall Steps per Second: 15,708.76850

Timestep Collection Time: 2.29309
Timestep Consumption Time: 0.89061
PPO Batch Consumption Time: 0.08133
Total Iteration Time: 3.18370

Cumulative Model Updates: 24,745
Cumulative Timesteps: 413,193,232

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,707.33427
Policy Entropy: 1.13349
Value Function Loss: 0.04769

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07433
Policy Update Magnitude: 0.03428
Value Function Update Magnitude: 0.03790

Collected Steps per Second: 24,051.40803
Overall Steps per Second: 17,132.79468

Timestep Collection Time: 2.07938
Timestep Consumption Time: 0.83970
PPO Batch Consumption Time: 0.06280
Total Iteration Time: 2.91908

Cumulative Model Updates: 24,748
Cumulative Timesteps: 413,243,244

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 413243244...
Checkpoint 413243244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,724.50104
Policy Entropy: 1.12726
Value Function Loss: 0.05154

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06730
Policy Update Magnitude: 0.03249
Value Function Update Magnitude: 0.03816

Collected Steps per Second: 23,102.58488
Overall Steps per Second: 17,070.81460

Timestep Collection Time: 2.16539
Timestep Consumption Time: 0.76511
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 2.93050

Cumulative Model Updates: 24,751
Cumulative Timesteps: 413,293,270

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,727.52351
Policy Entropy: 1.11655
Value Function Loss: 0.05197

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.06203
Policy Update Magnitude: 0.03336
Value Function Update Magnitude: 0.04043

Collected Steps per Second: 21,967.89644
Overall Steps per Second: 16,069.96147

Timestep Collection Time: 2.27778
Timestep Consumption Time: 0.83598
PPO Batch Consumption Time: 0.08904
Total Iteration Time: 3.11376

Cumulative Model Updates: 24,754
Cumulative Timesteps: 413,343,308

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 413343308...
Checkpoint 413343308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,571.39113
Policy Entropy: 1.11777
Value Function Loss: 0.05098

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.06141
Policy Update Magnitude: 0.03396
Value Function Update Magnitude: 0.04502

Collected Steps per Second: 23,780.81811
Overall Steps per Second: 16,914.33449

Timestep Collection Time: 2.10262
Timestep Consumption Time: 0.85357
PPO Batch Consumption Time: 0.08472
Total Iteration Time: 2.95619

Cumulative Model Updates: 24,757
Cumulative Timesteps: 413,393,310

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,797.65122
Policy Entropy: 1.11696
Value Function Loss: 0.05343

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04635
Policy Update Magnitude: 0.03389
Value Function Update Magnitude: 0.05131

Collected Steps per Second: 22,646.37664
Overall Steps per Second: 16,554.39684

Timestep Collection Time: 2.20901
Timestep Consumption Time: 0.81291
PPO Batch Consumption Time: 0.06944
Total Iteration Time: 3.02192

Cumulative Model Updates: 24,760
Cumulative Timesteps: 413,443,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 413443336...
Checkpoint 413443336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,643.55366
Policy Entropy: 1.11786
Value Function Loss: 0.05684

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05387
Policy Update Magnitude: 0.03400
Value Function Update Magnitude: 0.05079

Collected Steps per Second: 18,541.53793
Overall Steps per Second: 13,859.42846

Timestep Collection Time: 2.69708
Timestep Consumption Time: 0.91115
PPO Batch Consumption Time: 0.09652
Total Iteration Time: 3.60823

Cumulative Model Updates: 24,763
Cumulative Timesteps: 413,493,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,680.29576
Policy Entropy: 1.12336
Value Function Loss: 0.06084

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03753
Policy Update Magnitude: 0.03463
Value Function Update Magnitude: 0.04637

Collected Steps per Second: 23,285.95041
Overall Steps per Second: 17,658.98043

Timestep Collection Time: 2.14790
Timestep Consumption Time: 0.68442
PPO Batch Consumption Time: 0.03338
Total Iteration Time: 2.83233

Cumulative Model Updates: 24,766
Cumulative Timesteps: 413,543,360

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 413543360...
Checkpoint 413543360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,378.99831
Policy Entropy: 1.11494
Value Function Loss: 0.06019

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04213
Policy Update Magnitude: 0.03615
Value Function Update Magnitude: 0.04172

Collected Steps per Second: 20,135.83414
Overall Steps per Second: 14,499.29045

Timestep Collection Time: 2.48363
Timestep Consumption Time: 0.96550
PPO Batch Consumption Time: 0.11730
Total Iteration Time: 3.44913

Cumulative Model Updates: 24,769
Cumulative Timesteps: 413,593,370

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,802.12035
Policy Entropy: 1.11127
Value Function Loss: 0.06055

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02917
Policy Update Magnitude: 0.03558
Value Function Update Magnitude: 0.03633

Collected Steps per Second: 24,301.93387
Overall Steps per Second: 16,707.60246

Timestep Collection Time: 2.05868
Timestep Consumption Time: 0.93576
PPO Batch Consumption Time: 0.10859
Total Iteration Time: 2.99445

Cumulative Model Updates: 24,772
Cumulative Timesteps: 413,643,400

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 413643400...
Checkpoint 413643400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,827.63488
Policy Entropy: 1.09924
Value Function Loss: 0.06077

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02917
Policy Update Magnitude: 0.03749
Value Function Update Magnitude: 0.04162

Collected Steps per Second: 23,217.02619
Overall Steps per Second: 17,739.18420

Timestep Collection Time: 2.15454
Timestep Consumption Time: 0.66532
PPO Batch Consumption Time: 0.02883
Total Iteration Time: 2.81986

Cumulative Model Updates: 24,775
Cumulative Timesteps: 413,693,422

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,583.89604
Policy Entropy: 1.09161
Value Function Loss: 0.05884

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02741
Policy Update Magnitude: 0.04071
Value Function Update Magnitude: 0.05042

Collected Steps per Second: 23,878.30381
Overall Steps per Second: 16,791.95334

Timestep Collection Time: 2.09470
Timestep Consumption Time: 0.88398
PPO Batch Consumption Time: 0.08053
Total Iteration Time: 2.97869

Cumulative Model Updates: 24,778
Cumulative Timesteps: 413,743,440

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 413743440...
Checkpoint 413743440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,280.72838
Policy Entropy: 1.10164
Value Function Loss: 0.05435

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02510
Policy Update Magnitude: 0.03997
Value Function Update Magnitude: 0.05233

Collected Steps per Second: 21,365.80437
Overall Steps per Second: 16,499.66042

Timestep Collection Time: 2.34084
Timestep Consumption Time: 0.69037
PPO Batch Consumption Time: 0.03291
Total Iteration Time: 3.03121

Cumulative Model Updates: 24,781
Cumulative Timesteps: 413,793,454

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,067.09899
Policy Entropy: 1.11827
Value Function Loss: 0.05298

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03745
Policy Update Magnitude: 0.03709
Value Function Update Magnitude: 0.04740

Collected Steps per Second: 22,374.01218
Overall Steps per Second: 16,531.25830

Timestep Collection Time: 2.23500
Timestep Consumption Time: 0.78993
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 3.02494

Cumulative Model Updates: 24,784
Cumulative Timesteps: 413,843,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 413843460...
Checkpoint 413843460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,296.67857
Policy Entropy: 1.14051
Value Function Loss: 0.05668

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03096
Policy Update Magnitude: 0.03375
Value Function Update Magnitude: 0.04296

Collected Steps per Second: 21,183.74869
Overall Steps per Second: 14,981.65260

Timestep Collection Time: 2.36106
Timestep Consumption Time: 0.97743
PPO Batch Consumption Time: 0.08379
Total Iteration Time: 3.33848

Cumulative Model Updates: 24,787
Cumulative Timesteps: 413,893,476

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,918.44959
Policy Entropy: 1.14434
Value Function Loss: 0.05688

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02695
Policy Update Magnitude: 0.03243
Value Function Update Magnitude: 0.04573

Collected Steps per Second: 24,070.97790
Overall Steps per Second: 17,508.79878

Timestep Collection Time: 2.07736
Timestep Consumption Time: 0.77858
PPO Batch Consumption Time: 0.06303
Total Iteration Time: 2.85594

Cumulative Model Updates: 24,790
Cumulative Timesteps: 413,943,480

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 413943480...
Checkpoint 413943480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,641.10438
Policy Entropy: 1.14391
Value Function Loss: 0.06042

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03077
Policy Update Magnitude: 0.03323
Value Function Update Magnitude: 0.04429

Collected Steps per Second: 23,856.03842
Overall Steps per Second: 17,232.57212

Timestep Collection Time: 2.09658
Timestep Consumption Time: 0.80583
PPO Batch Consumption Time: 0.06068
Total Iteration Time: 2.90241

Cumulative Model Updates: 24,793
Cumulative Timesteps: 413,993,496

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,751.47560
Policy Entropy: 1.14228
Value Function Loss: 0.06323

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.02018
Policy Update Magnitude: 0.03569
Value Function Update Magnitude: 0.04683

Collected Steps per Second: 21,382.73784
Overall Steps per Second: 14,812.07348

Timestep Collection Time: 2.33862
Timestep Consumption Time: 1.03741
PPO Batch Consumption Time: 0.13327
Total Iteration Time: 3.37603

Cumulative Model Updates: 24,796
Cumulative Timesteps: 414,043,502

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 414043502...
Checkpoint 414043502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,183.81030
Policy Entropy: 1.14785
Value Function Loss: 0.06374

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02349
Policy Update Magnitude: 0.03945
Value Function Update Magnitude: 0.05362

Collected Steps per Second: 23,432.70913
Overall Steps per Second: 17,034.06373

Timestep Collection Time: 2.13394
Timestep Consumption Time: 0.80159
PPO Batch Consumption Time: 0.06508
Total Iteration Time: 2.93553

Cumulative Model Updates: 24,799
Cumulative Timesteps: 414,093,506

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,126.79662
Policy Entropy: 1.14778
Value Function Loss: 0.05669

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03075
Policy Update Magnitude: 0.03762
Value Function Update Magnitude: 0.04932

Collected Steps per Second: 24,421.03878
Overall Steps per Second: 16,620.85125

Timestep Collection Time: 2.04873
Timestep Consumption Time: 0.96147
PPO Batch Consumption Time: 0.12057
Total Iteration Time: 3.01019

Cumulative Model Updates: 24,802
Cumulative Timesteps: 414,143,538

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 414143538...
Checkpoint 414143538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,367.99798
Policy Entropy: 1.16241
Value Function Loss: 0.04898

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03041
Policy Update Magnitude: 0.03617
Value Function Update Magnitude: 0.04625

Collected Steps per Second: 23,862.14324
Overall Steps per Second: 17,257.87546

Timestep Collection Time: 2.09537
Timestep Consumption Time: 0.80186
PPO Batch Consumption Time: 0.06305
Total Iteration Time: 2.89723

Cumulative Model Updates: 24,805
Cumulative Timesteps: 414,193,538

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,750.71824
Policy Entropy: 1.14680
Value Function Loss: 0.05149

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03276
Policy Update Magnitude: 0.03448
Value Function Update Magnitude: 0.04512

Collected Steps per Second: 20,254.01598
Overall Steps per Second: 15,127.39922

Timestep Collection Time: 2.47032
Timestep Consumption Time: 0.83718
PPO Batch Consumption Time: 0.07778
Total Iteration Time: 3.30751

Cumulative Model Updates: 24,808
Cumulative Timesteps: 414,243,572

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 414243572...
Checkpoint 414243572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,634.33373
Policy Entropy: 1.16400
Value Function Loss: 0.05411

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02878
Policy Update Magnitude: 0.03524
Value Function Update Magnitude: 0.04459

Collected Steps per Second: 23,771.46994
Overall Steps per Second: 16,783.67353

Timestep Collection Time: 2.10403
Timestep Consumption Time: 0.87600
PPO Batch Consumption Time: 0.08587
Total Iteration Time: 2.98004

Cumulative Model Updates: 24,811
Cumulative Timesteps: 414,293,588

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,751.11060
Policy Entropy: 1.14947
Value Function Loss: 0.05263

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03580
Policy Update Magnitude: 0.03738
Value Function Update Magnitude: 0.04247

Collected Steps per Second: 24,332.25996
Overall Steps per Second: 16,767.88353

Timestep Collection Time: 2.05604
Timestep Consumption Time: 0.92752
PPO Batch Consumption Time: 0.10474
Total Iteration Time: 2.98356

Cumulative Model Updates: 24,814
Cumulative Timesteps: 414,343,616

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 414343616...
Checkpoint 414343616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,851.57502
Policy Entropy: 1.15770
Value Function Loss: 0.04710

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04387
Policy Update Magnitude: 0.03808
Value Function Update Magnitude: 0.04835

Collected Steps per Second: 23,852.80334
Overall Steps per Second: 16,741.87255

Timestep Collection Time: 2.09694
Timestep Consumption Time: 0.89065
PPO Batch Consumption Time: 0.09211
Total Iteration Time: 2.98760

Cumulative Model Updates: 24,817
Cumulative Timesteps: 414,393,634

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,690.07616
Policy Entropy: 1.14396
Value Function Loss: 0.04827

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.04497
Policy Update Magnitude: 0.03555
Value Function Update Magnitude: 0.04678

Collected Steps per Second: 24,024.16421
Overall Steps per Second: 16,732.79570

Timestep Collection Time: 2.08215
Timestep Consumption Time: 0.90731
PPO Batch Consumption Time: 0.10187
Total Iteration Time: 2.98946

Cumulative Model Updates: 24,820
Cumulative Timesteps: 414,443,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 414443656...
Checkpoint 414443656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,517.26283
Policy Entropy: 1.15495
Value Function Loss: 0.04531

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03065
Policy Update Magnitude: 0.03956
Value Function Update Magnitude: 0.04325

Collected Steps per Second: 24,187.99518
Overall Steps per Second: 16,756.17860

Timestep Collection Time: 2.06739
Timestep Consumption Time: 0.91694
PPO Batch Consumption Time: 0.09895
Total Iteration Time: 2.98433

Cumulative Model Updates: 24,823
Cumulative Timesteps: 414,493,662

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,023.01144
Policy Entropy: 1.14652
Value Function Loss: 0.04599

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03673
Policy Update Magnitude: 0.03681
Value Function Update Magnitude: 0.04292

Collected Steps per Second: 24,328.32298
Overall Steps per Second: 16,685.71953

Timestep Collection Time: 2.05522
Timestep Consumption Time: 0.94136
PPO Batch Consumption Time: 0.11404
Total Iteration Time: 2.99657

Cumulative Model Updates: 24,826
Cumulative Timesteps: 414,543,662

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 414543662...
Checkpoint 414543662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,016.34774
Policy Entropy: 1.15688
Value Function Loss: 0.04726

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03057
Policy Update Magnitude: 0.03482
Value Function Update Magnitude: 0.04549

Collected Steps per Second: 22,604.81774
Overall Steps per Second: 15,788.93544

Timestep Collection Time: 2.21289
Timestep Consumption Time: 0.95528
PPO Batch Consumption Time: 0.10807
Total Iteration Time: 3.16817

Cumulative Model Updates: 24,829
Cumulative Timesteps: 414,593,684

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,289.90704
Policy Entropy: 1.14759
Value Function Loss: 0.04761

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03124
Policy Update Magnitude: 0.03340
Value Function Update Magnitude: 0.04262

Collected Steps per Second: 24,233.47002
Overall Steps per Second: 17,314.68178

Timestep Collection Time: 2.06491
Timestep Consumption Time: 0.82512
PPO Batch Consumption Time: 0.06544
Total Iteration Time: 2.89003

Cumulative Model Updates: 24,832
Cumulative Timesteps: 414,643,724

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 414643724...
Checkpoint 414643724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,836.50967
Policy Entropy: 1.14769
Value Function Loss: 0.04599

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03132
Policy Update Magnitude: 0.03465
Value Function Update Magnitude: 0.04599

Collected Steps per Second: 21,160.07255
Overall Steps per Second: 15,174.62423

Timestep Collection Time: 2.36370
Timestep Consumption Time: 0.93233
PPO Batch Consumption Time: 0.10658
Total Iteration Time: 3.29603

Cumulative Model Updates: 24,835
Cumulative Timesteps: 414,693,740

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,731.43176
Policy Entropy: 1.14509
Value Function Loss: 0.04438

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02900
Policy Update Magnitude: 0.03606
Value Function Update Magnitude: 0.04481

Collected Steps per Second: 24,186.16013
Overall Steps per Second: 17,554.28827

Timestep Collection Time: 2.06812
Timestep Consumption Time: 0.78132
PPO Batch Consumption Time: 0.06340
Total Iteration Time: 2.84945

Cumulative Model Updates: 24,838
Cumulative Timesteps: 414,743,760

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 414743760...
Checkpoint 414743760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,771.79365
Policy Entropy: 1.14595
Value Function Loss: 0.05045

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01982
Policy Update Magnitude: 0.03370
Value Function Update Magnitude: 0.04605

Collected Steps per Second: 20,742.94080
Overall Steps per Second: 15,040.32266

Timestep Collection Time: 2.41152
Timestep Consumption Time: 0.91434
PPO Batch Consumption Time: 0.10450
Total Iteration Time: 3.32586

Cumulative Model Updates: 24,841
Cumulative Timesteps: 414,793,782

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,825.57427
Policy Entropy: 1.14055
Value Function Loss: 0.05490

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02208
Policy Update Magnitude: 0.03666
Value Function Update Magnitude: 0.05229

Collected Steps per Second: 24,050.91066
Overall Steps per Second: 16,712.73420

Timestep Collection Time: 2.08000
Timestep Consumption Time: 0.91328
PPO Batch Consumption Time: 0.09179
Total Iteration Time: 2.99329

Cumulative Model Updates: 24,844
Cumulative Timesteps: 414,843,808

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 414843808...
Checkpoint 414843808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,987.64025
Policy Entropy: 1.13369
Value Function Loss: 0.05869

Mean KL Divergence: 0.00143
SB3 Clip Fraction: 0.01233
Policy Update Magnitude: 0.03861
Value Function Update Magnitude: 0.04841

Collected Steps per Second: 22,219.04565
Overall Steps per Second: 16,751.67574

Timestep Collection Time: 2.25050
Timestep Consumption Time: 0.73451
PPO Batch Consumption Time: 0.05019
Total Iteration Time: 2.98501

Cumulative Model Updates: 24,847
Cumulative Timesteps: 414,893,812

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,797.19784
Policy Entropy: 1.12039
Value Function Loss: 0.06022

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02969
Policy Update Magnitude: 0.03858
Value Function Update Magnitude: 0.04165

Collected Steps per Second: 20,834.72246
Overall Steps per Second: 14,757.85985

Timestep Collection Time: 2.40109
Timestep Consumption Time: 0.98870
PPO Batch Consumption Time: 0.12608
Total Iteration Time: 3.38979

Cumulative Model Updates: 24,850
Cumulative Timesteps: 414,943,838

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 414943838...
Checkpoint 414943838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,995.70118
Policy Entropy: 1.11519
Value Function Loss: 0.06253

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01602
Policy Update Magnitude: 0.04018
Value Function Update Magnitude: 0.04357

Collected Steps per Second: 23,983.39921
Overall Steps per Second: 17,646.17285

Timestep Collection Time: 2.08544
Timestep Consumption Time: 0.74894
PPO Batch Consumption Time: 0.06181
Total Iteration Time: 2.83438

Cumulative Model Updates: 24,853
Cumulative Timesteps: 414,993,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,454.10908
Policy Entropy: 1.11872
Value Function Loss: 0.05841

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01705
Policy Update Magnitude: 0.03885
Value Function Update Magnitude: 0.04373

Collected Steps per Second: 21,756.82110
Overall Steps per Second: 15,851.22847

Timestep Collection Time: 2.29831
Timestep Consumption Time: 0.85627
PPO Batch Consumption Time: 0.07862
Total Iteration Time: 3.15458

Cumulative Model Updates: 24,856
Cumulative Timesteps: 415,043,858

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 415043858...
Checkpoint 415043858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,272.07834
Policy Entropy: 1.14029
Value Function Loss: 0.05480

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02557
Policy Update Magnitude: 0.03818
Value Function Update Magnitude: 0.04671

Collected Steps per Second: 23,929.14494
Overall Steps per Second: 17,295.55112

Timestep Collection Time: 2.09101
Timestep Consumption Time: 0.80199
PPO Batch Consumption Time: 0.06366
Total Iteration Time: 2.89300

Cumulative Model Updates: 24,859
Cumulative Timesteps: 415,093,894

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,266.49647
Policy Entropy: 1.13663
Value Function Loss: 0.05103

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03417
Policy Update Magnitude: 0.04109
Value Function Update Magnitude: 0.04329

Collected Steps per Second: 24,340.11358
Overall Steps per Second: 17,349.41277

Timestep Collection Time: 2.05430
Timestep Consumption Time: 0.82775
PPO Batch Consumption Time: 0.07803
Total Iteration Time: 2.88206

Cumulative Model Updates: 24,862
Cumulative Timesteps: 415,143,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 415143896...
Checkpoint 415143896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,430.53209
Policy Entropy: 1.12582
Value Function Loss: 0.05317

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02477
Policy Update Magnitude: 0.03814
Value Function Update Magnitude: 0.04075

Collected Steps per Second: 23,424.07132
Overall Steps per Second: 17,017.65755

Timestep Collection Time: 2.13524
Timestep Consumption Time: 0.80383
PPO Batch Consumption Time: 0.06648
Total Iteration Time: 2.93906

Cumulative Model Updates: 24,865
Cumulative Timesteps: 415,193,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,405.68402
Policy Entropy: 1.14010
Value Function Loss: 0.05364

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02263
Policy Update Magnitude: 0.03652
Value Function Update Magnitude: 0.03998

Collected Steps per Second: 22,768.78181
Overall Steps per Second: 16,841.78718

Timestep Collection Time: 2.19722
Timestep Consumption Time: 0.77325
PPO Batch Consumption Time: 0.05954
Total Iteration Time: 2.97047

Cumulative Model Updates: 24,868
Cumulative Timesteps: 415,243,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 415243940...
Checkpoint 415243940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,044.24107
Policy Entropy: 1.13727
Value Function Loss: 0.05245

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01849
Policy Update Magnitude: 0.03668
Value Function Update Magnitude: 0.04797

Collected Steps per Second: 23,963.61485
Overall Steps per Second: 17,584.25366

Timestep Collection Time: 2.08767
Timestep Consumption Time: 0.75738
PPO Batch Consumption Time: 0.05946
Total Iteration Time: 2.84505

Cumulative Model Updates: 24,871
Cumulative Timesteps: 415,293,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,411.60344
Policy Entropy: 1.14086
Value Function Loss: 0.05285

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01581
Policy Update Magnitude: 0.03569
Value Function Update Magnitude: 0.04847

Collected Steps per Second: 21,260.96799
Overall Steps per Second: 15,518.20856

Timestep Collection Time: 2.35220
Timestep Consumption Time: 0.87047
PPO Batch Consumption Time: 0.09404
Total Iteration Time: 3.22267

Cumulative Model Updates: 24,874
Cumulative Timesteps: 415,343,978

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 415343978...
Checkpoint 415343978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,696.85340
Policy Entropy: 1.12650
Value Function Loss: 0.05450

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02403
Policy Update Magnitude: 0.03293
Value Function Update Magnitude: 0.05006

Collected Steps per Second: 23,902.75160
Overall Steps per Second: 17,252.34259

Timestep Collection Time: 2.09357
Timestep Consumption Time: 0.80703
PPO Batch Consumption Time: 0.06354
Total Iteration Time: 2.90059

Cumulative Model Updates: 24,877
Cumulative Timesteps: 415,394,020

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,541.12161
Policy Entropy: 1.12524
Value Function Loss: 0.05460

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.01867
Policy Update Magnitude: 0.03383
Value Function Update Magnitude: 0.04455

Collected Steps per Second: 23,801.72543
Overall Steps per Second: 17,267.81032

Timestep Collection Time: 2.10178
Timestep Consumption Time: 0.79529
PPO Batch Consumption Time: 0.06602
Total Iteration Time: 2.89707

Cumulative Model Updates: 24,880
Cumulative Timesteps: 415,444,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 415444046...
Checkpoint 415444046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,705.47869
Policy Entropy: 1.12808
Value Function Loss: 0.05467

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02543
Policy Update Magnitude: 0.03233
Value Function Update Magnitude: 0.05146

Collected Steps per Second: 21,163.42739
Overall Steps per Second: 14,920.12385

Timestep Collection Time: 2.36313
Timestep Consumption Time: 0.98885
PPO Batch Consumption Time: 0.12606
Total Iteration Time: 3.35198

Cumulative Model Updates: 24,883
Cumulative Timesteps: 415,494,058

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,546.58236
Policy Entropy: 1.13478
Value Function Loss: 0.04805

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02719
Policy Update Magnitude: 0.03272
Value Function Update Magnitude: 0.05623

Collected Steps per Second: 24,166.68314
Overall Steps per Second: 17,001.07786

Timestep Collection Time: 2.06938
Timestep Consumption Time: 0.87220
PPO Batch Consumption Time: 0.07988
Total Iteration Time: 2.94158

Cumulative Model Updates: 24,886
Cumulative Timesteps: 415,544,068

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 415544068...
Checkpoint 415544068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,158.54221
Policy Entropy: 1.14868
Value Function Loss: 0.04878

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02224
Policy Update Magnitude: 0.03169
Value Function Update Magnitude: 0.05120

Collected Steps per Second: 23,533.38356
Overall Steps per Second: 16,656.58448

Timestep Collection Time: 2.12617
Timestep Consumption Time: 0.87781
PPO Batch Consumption Time: 0.06045
Total Iteration Time: 3.00398

Cumulative Model Updates: 24,889
Cumulative Timesteps: 415,594,104

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,690.44641
Policy Entropy: 1.13511
Value Function Loss: 0.05107

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02039
Policy Update Magnitude: 0.03141
Value Function Update Magnitude: 0.04695

Collected Steps per Second: 21,525.96164
Overall Steps per Second: 15,657.40300

Timestep Collection Time: 2.32278
Timestep Consumption Time: 0.87060
PPO Batch Consumption Time: 0.09878
Total Iteration Time: 3.19338

Cumulative Model Updates: 24,892
Cumulative Timesteps: 415,644,104

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 415644104...
Checkpoint 415644104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,045.59547
Policy Entropy: 1.13031
Value Function Loss: 0.05343

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02320
Policy Update Magnitude: 0.03224
Value Function Update Magnitude: 0.04745

Collected Steps per Second: 23,871.36502
Overall Steps per Second: 16,759.74508

Timestep Collection Time: 2.09473
Timestep Consumption Time: 0.88885
PPO Batch Consumption Time: 0.09129
Total Iteration Time: 2.98358

Cumulative Model Updates: 24,895
Cumulative Timesteps: 415,694,108

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,332.60502
Policy Entropy: 1.10705
Value Function Loss: 0.06009

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02849
Policy Update Magnitude: 0.03335
Value Function Update Magnitude: 0.04179

Collected Steps per Second: 24,352.20097
Overall Steps per Second: 16,792.85370

Timestep Collection Time: 2.05378
Timestep Consumption Time: 0.92451
PPO Batch Consumption Time: 0.10528
Total Iteration Time: 2.97829

Cumulative Model Updates: 24,898
Cumulative Timesteps: 415,744,122

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 415744122...
Checkpoint 415744122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,051.64898
Policy Entropy: 1.11560
Value Function Loss: 0.06656

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02705
Policy Update Magnitude: 0.03504
Value Function Update Magnitude: 0.05056

Collected Steps per Second: 23,854.33876
Overall Steps per Second: 16,712.75328

Timestep Collection Time: 2.09656
Timestep Consumption Time: 0.89589
PPO Batch Consumption Time: 0.10363
Total Iteration Time: 2.99245

Cumulative Model Updates: 24,901
Cumulative Timesteps: 415,794,134

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,546.53399
Policy Entropy: 1.12259
Value Function Loss: 0.06669

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03361
Policy Update Magnitude: 0.03444
Value Function Update Magnitude: 0.04682

Collected Steps per Second: 24,368.00095
Overall Steps per Second: 16,683.81590

Timestep Collection Time: 2.05261
Timestep Consumption Time: 0.94539
PPO Batch Consumption Time: 0.10272
Total Iteration Time: 2.99800

Cumulative Model Updates: 24,904
Cumulative Timesteps: 415,844,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 415844152...
Checkpoint 415844152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,782.48420
Policy Entropy: 1.12954
Value Function Loss: 0.06216

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02902
Policy Update Magnitude: 0.03540
Value Function Update Magnitude: 0.04701

Collected Steps per Second: 22,512.47969
Overall Steps per Second: 15,778.71415

Timestep Collection Time: 2.22179
Timestep Consumption Time: 0.94818
PPO Batch Consumption Time: 0.10944
Total Iteration Time: 3.16997

Cumulative Model Updates: 24,907
Cumulative Timesteps: 415,894,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,319.48926
Policy Entropy: 1.12919
Value Function Loss: 0.05940

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03108
Policy Update Magnitude: 0.03525
Value Function Update Magnitude: 0.04538

Collected Steps per Second: 24,057.58426
Overall Steps per Second: 17,272.47014

Timestep Collection Time: 2.07868
Timestep Consumption Time: 0.81656
PPO Batch Consumption Time: 0.06368
Total Iteration Time: 2.89524

Cumulative Model Updates: 24,910
Cumulative Timesteps: 415,944,178

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 415944178...
Checkpoint 415944178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,040.40729
Policy Entropy: 1.11682
Value Function Loss: 0.06631

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.04144
Policy Update Magnitude: 0.03334
Value Function Update Magnitude: 0.03754

Collected Steps per Second: 20,921.36654
Overall Steps per Second: 15,180.63327

Timestep Collection Time: 2.39105
Timestep Consumption Time: 0.90420
PPO Batch Consumption Time: 0.09758
Total Iteration Time: 3.29525

Cumulative Model Updates: 24,913
Cumulative Timesteps: 415,994,202

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,135.77801
Policy Entropy: 1.11227
Value Function Loss: 0.06790

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02095
Policy Update Magnitude: 0.03447
Value Function Update Magnitude: 0.03765

Collected Steps per Second: 24,405.74926
Overall Steps per Second: 17,540.24628

Timestep Collection Time: 2.05075
Timestep Consumption Time: 0.80269
PPO Batch Consumption Time: 0.06535
Total Iteration Time: 2.85344

Cumulative Model Updates: 24,916
Cumulative Timesteps: 416,044,252

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 416044252...
Checkpoint 416044252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,393.75114
Policy Entropy: 1.12511
Value Function Loss: 0.06172

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02150
Policy Update Magnitude: 0.03601
Value Function Update Magnitude: 0.04105

Collected Steps per Second: 19,943.87793
Overall Steps per Second: 14,110.60451

Timestep Collection Time: 2.50704
Timestep Consumption Time: 1.03640
PPO Batch Consumption Time: 0.12003
Total Iteration Time: 3.54343

Cumulative Model Updates: 24,919
Cumulative Timesteps: 416,094,252

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,791.22096
Policy Entropy: 1.13111
Value Function Loss: 0.06009

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.04315
Policy Update Magnitude: 0.03524
Value Function Update Magnitude: 0.04078

Collected Steps per Second: 22,664.17484
Overall Steps per Second: 16,154.97983

Timestep Collection Time: 2.20754
Timestep Consumption Time: 0.88946
PPO Batch Consumption Time: 0.06824
Total Iteration Time: 3.09700

Cumulative Model Updates: 24,922
Cumulative Timesteps: 416,144,284

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 416144284...
Checkpoint 416144284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,379.88379
Policy Entropy: 1.13430
Value Function Loss: 0.05390

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.04288
Policy Update Magnitude: 0.03547
Value Function Update Magnitude: 0.03690

Collected Steps per Second: 21,915.38676
Overall Steps per Second: 15,252.78889

Timestep Collection Time: 2.28369
Timestep Consumption Time: 0.99754
PPO Batch Consumption Time: 0.07876
Total Iteration Time: 3.28124

Cumulative Model Updates: 24,925
Cumulative Timesteps: 416,194,332

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,105.56395
Policy Entropy: 1.13084
Value Function Loss: 0.05478

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03383
Policy Update Magnitude: 0.03368
Value Function Update Magnitude: 0.04525

Collected Steps per Second: 24,494.22741
Overall Steps per Second: 17,592.57507

Timestep Collection Time: 2.04179
Timestep Consumption Time: 0.80100
PPO Batch Consumption Time: 0.06125
Total Iteration Time: 2.84279

Cumulative Model Updates: 24,928
Cumulative Timesteps: 416,244,344

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 416244344...
Checkpoint 416244344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,835.53723
Policy Entropy: 1.12497
Value Function Loss: 0.05763

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02901
Policy Update Magnitude: 0.03365
Value Function Update Magnitude: 0.04210

Collected Steps per Second: 21,571.47440
Overall Steps per Second: 15,231.35847

Timestep Collection Time: 2.31806
Timestep Consumption Time: 0.96490
PPO Batch Consumption Time: 0.11581
Total Iteration Time: 3.28296

Cumulative Model Updates: 24,931
Cumulative Timesteps: 416,294,348

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,200.03585
Policy Entropy: 1.12951
Value Function Loss: 0.05582

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03050
Policy Update Magnitude: 0.03337
Value Function Update Magnitude: 0.03801

Collected Steps per Second: 24,481.18374
Overall Steps per Second: 17,575.69447

Timestep Collection Time: 2.04238
Timestep Consumption Time: 0.80245
PPO Batch Consumption Time: 0.06093
Total Iteration Time: 2.84484

Cumulative Model Updates: 24,934
Cumulative Timesteps: 416,344,348

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 416344348...
Checkpoint 416344348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,258.86904
Policy Entropy: 1.12505
Value Function Loss: 0.05802

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02421
Policy Update Magnitude: 0.03273
Value Function Update Magnitude: 0.03897

Collected Steps per Second: 21,115.11861
Overall Steps per Second: 15,013.74238

Timestep Collection Time: 2.36826
Timestep Consumption Time: 0.96243
PPO Batch Consumption Time: 0.11916
Total Iteration Time: 3.33068

Cumulative Model Updates: 24,937
Cumulative Timesteps: 416,394,354

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,240.10971
Policy Entropy: 1.10894
Value Function Loss: 0.06004

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02090
Policy Update Magnitude: 0.03106
Value Function Update Magnitude: 0.03660

Collected Steps per Second: 23,819.32813
Overall Steps per Second: 17,581.97759

Timestep Collection Time: 2.10014
Timestep Consumption Time: 0.74504
PPO Batch Consumption Time: 0.06230
Total Iteration Time: 2.84519

Cumulative Model Updates: 24,940
Cumulative Timesteps: 416,444,378

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 416444378...
Checkpoint 416444378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,507.99866
Policy Entropy: 1.11695
Value Function Loss: 0.06316

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01905
Policy Update Magnitude: 0.03176
Value Function Update Magnitude: 0.03273

Collected Steps per Second: 21,755.27516
Overall Steps per Second: 15,878.53448

Timestep Collection Time: 2.29958
Timestep Consumption Time: 0.85109
PPO Batch Consumption Time: 0.08774
Total Iteration Time: 3.15067

Cumulative Model Updates: 24,943
Cumulative Timesteps: 416,494,406

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,773.67129
Policy Entropy: 1.10850
Value Function Loss: 0.06247

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01482
Policy Update Magnitude: 0.03270
Value Function Update Magnitude: 0.03102

Collected Steps per Second: 22,786.38894
Overall Steps per Second: 16,979.94267

Timestep Collection Time: 2.19552
Timestep Consumption Time: 0.75078
PPO Batch Consumption Time: 0.05445
Total Iteration Time: 2.94630

Cumulative Model Updates: 24,946
Cumulative Timesteps: 416,544,434

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 416544434...
Checkpoint 416544434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,000.71956
Policy Entropy: 1.11917
Value Function Loss: 0.05572

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02047
Policy Update Magnitude: 0.03269
Value Function Update Magnitude: 0.02938

Collected Steps per Second: 22,196.76566
Overall Steps per Second: 15,623.82188

Timestep Collection Time: 2.25447
Timestep Consumption Time: 0.94846
PPO Batch Consumption Time: 0.11674
Total Iteration Time: 3.20293

Cumulative Model Updates: 24,949
Cumulative Timesteps: 416,594,476

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,786.84545
Policy Entropy: 1.10823
Value Function Loss: 0.05572

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02115
Policy Update Magnitude: 0.03185
Value Function Update Magnitude: 0.02854

Collected Steps per Second: 24,376.13537
Overall Steps per Second: 16,644.01946

Timestep Collection Time: 2.05307
Timestep Consumption Time: 0.95377
PPO Batch Consumption Time: 0.10445
Total Iteration Time: 3.00685

Cumulative Model Updates: 24,952
Cumulative Timesteps: 416,644,522

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 416644522...
Checkpoint 416644522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,328.82392
Policy Entropy: 1.10224
Value Function Loss: 0.05752

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03074
Policy Update Magnitude: 0.03162
Value Function Update Magnitude: 0.02931

Collected Steps per Second: 23,919.87616
Overall Steps per Second: 16,734.41650

Timestep Collection Time: 2.09148
Timestep Consumption Time: 0.89805
PPO Batch Consumption Time: 0.09149
Total Iteration Time: 2.98953

Cumulative Model Updates: 24,955
Cumulative Timesteps: 416,694,550

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,706.55998
Policy Entropy: 1.09742
Value Function Loss: 0.06241

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03644
Policy Update Magnitude: 0.03209
Value Function Update Magnitude: 0.02960

Collected Steps per Second: 24,308.21109
Overall Steps per Second: 16,796.78343

Timestep Collection Time: 2.05807
Timestep Consumption Time: 0.92036
PPO Batch Consumption Time: 0.10500
Total Iteration Time: 2.97843

Cumulative Model Updates: 24,958
Cumulative Timesteps: 416,744,578

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 416744578...
Checkpoint 416744578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,971.75763
Policy Entropy: 1.08228
Value Function Loss: 0.06193

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02470
Policy Update Magnitude: 0.03340
Value Function Update Magnitude: 0.03344

Collected Steps per Second: 23,807.80120
Overall Steps per Second: 16,707.11060

Timestep Collection Time: 2.10091
Timestep Consumption Time: 0.89291
PPO Batch Consumption Time: 0.09862
Total Iteration Time: 2.99382

Cumulative Model Updates: 24,961
Cumulative Timesteps: 416,794,596

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,330.10422
Policy Entropy: 1.07440
Value Function Loss: 0.06106

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03192
Policy Update Magnitude: 0.03409
Value Function Update Magnitude: 0.03358

Collected Steps per Second: 24,452.65649
Overall Steps per Second: 16,512.90297

Timestep Collection Time: 2.04575
Timestep Consumption Time: 0.98364
PPO Batch Consumption Time: 0.12757
Total Iteration Time: 3.02939

Cumulative Model Updates: 24,964
Cumulative Timesteps: 416,844,620

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 416844620...
Checkpoint 416844620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,035.41029
Policy Entropy: 1.06754
Value Function Loss: 0.06233

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03043
Policy Update Magnitude: 0.03592
Value Function Update Magnitude: 0.03349

Collected Steps per Second: 23,587.86648
Overall Steps per Second: 17,163.60958

Timestep Collection Time: 2.12126
Timestep Consumption Time: 0.79398
PPO Batch Consumption Time: 0.05974
Total Iteration Time: 2.91524

Cumulative Model Updates: 24,967
Cumulative Timesteps: 416,894,656

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,219.04625
Policy Entropy: 1.06290
Value Function Loss: 0.06761

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.04131
Policy Update Magnitude: 0.03623
Value Function Update Magnitude: 0.03070

Collected Steps per Second: 22,176.74057
Overall Steps per Second: 15,590.36910

Timestep Collection Time: 2.25498
Timestep Consumption Time: 0.95265
PPO Batch Consumption Time: 0.12397
Total Iteration Time: 3.20762

Cumulative Model Updates: 24,970
Cumulative Timesteps: 416,944,664

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 416944664...
Checkpoint 416944664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,588.25879
Policy Entropy: 1.05634
Value Function Loss: 0.06556

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.04143
Policy Update Magnitude: 0.03365
Value Function Update Magnitude: 0.02926

Collected Steps per Second: 24,045.91458
Overall Steps per Second: 17,271.16492

Timestep Collection Time: 2.07969
Timestep Consumption Time: 0.81577
PPO Batch Consumption Time: 0.06415
Total Iteration Time: 2.89546

Cumulative Model Updates: 24,973
Cumulative Timesteps: 416,994,672

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,447.56599
Policy Entropy: 1.06131
Value Function Loss: 0.06297

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02350
Policy Update Magnitude: 0.03113
Value Function Update Magnitude: 0.03232

Collected Steps per Second: 21,399.49077
Overall Steps per Second: 15,232.28040

Timestep Collection Time: 2.33791
Timestep Consumption Time: 0.94657
PPO Batch Consumption Time: 0.11658
Total Iteration Time: 3.28447

Cumulative Model Updates: 24,976
Cumulative Timesteps: 417,044,702

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 417044702...
Checkpoint 417044702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,939.47240
Policy Entropy: 1.06261
Value Function Loss: 0.05596

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.01934
Policy Update Magnitude: 0.03163
Value Function Update Magnitude: 0.03042

Collected Steps per Second: 23,763.69663
Overall Steps per Second: 17,336.22557

Timestep Collection Time: 2.10439
Timestep Consumption Time: 0.78021
PPO Batch Consumption Time: 0.06262
Total Iteration Time: 2.88460

Cumulative Model Updates: 24,979
Cumulative Timesteps: 417,094,710

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,856.88914
Policy Entropy: 1.08835
Value Function Loss: 0.05205

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.01673
Policy Update Magnitude: 0.03077
Value Function Update Magnitude: 0.03194

Collected Steps per Second: 22,420.76582
Overall Steps per Second: 16,092.43265

Timestep Collection Time: 2.23079
Timestep Consumption Time: 0.87726
PPO Batch Consumption Time: 0.09355
Total Iteration Time: 3.10804

Cumulative Model Updates: 24,982
Cumulative Timesteps: 417,144,726

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 417144726...
Checkpoint 417144726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,461.14672
Policy Entropy: 1.10668
Value Function Loss: 0.04422

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01475
Policy Update Magnitude: 0.03082
Value Function Update Magnitude: 0.03122

Collected Steps per Second: 22,163.93914
Overall Steps per Second: 16,536.59785

Timestep Collection Time: 2.25646
Timestep Consumption Time: 0.76786
PPO Batch Consumption Time: 0.05412
Total Iteration Time: 3.02432

Cumulative Model Updates: 24,985
Cumulative Timesteps: 417,194,738

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,230.17589
Policy Entropy: 1.09562
Value Function Loss: 0.04342

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02188
Policy Update Magnitude: 0.03180
Value Function Update Magnitude: 0.03234

Collected Steps per Second: 21,748.27633
Overall Steps per Second: 15,830.67089

Timestep Collection Time: 2.29968
Timestep Consumption Time: 0.85963
PPO Batch Consumption Time: 0.08839
Total Iteration Time: 3.15931

Cumulative Model Updates: 24,988
Cumulative Timesteps: 417,244,752

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 417244752...
Checkpoint 417244752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,497.21343
Policy Entropy: 1.08992
Value Function Loss: 0.04520

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02395
Policy Update Magnitude: 0.02908
Value Function Update Magnitude: 0.03514

Collected Steps per Second: 23,787.20150
Overall Steps per Second: 16,767.51161

Timestep Collection Time: 2.10306
Timestep Consumption Time: 0.88044
PPO Batch Consumption Time: 0.08104
Total Iteration Time: 2.98351

Cumulative Model Updates: 24,991
Cumulative Timesteps: 417,294,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,659.63770
Policy Entropy: 1.08730
Value Function Loss: 0.04574

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01751
Policy Update Magnitude: 0.02960
Value Function Update Magnitude: 0.03987

Collected Steps per Second: 23,390.35690
Overall Steps per Second: 16,699.28421

Timestep Collection Time: 2.13840
Timestep Consumption Time: 0.85682
PPO Batch Consumption Time: 0.07765
Total Iteration Time: 2.99522

Cumulative Model Updates: 24,994
Cumulative Timesteps: 417,344,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 417344796...
Checkpoint 417344796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,231.62641
Policy Entropy: 1.09806
Value Function Loss: 0.04626

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02463
Policy Update Magnitude: 0.02934
Value Function Update Magnitude: 0.04341

Collected Steps per Second: 23,734.32096
Overall Steps per Second: 16,766.91009

Timestep Collection Time: 2.10792
Timestep Consumption Time: 0.87594
PPO Batch Consumption Time: 0.08549
Total Iteration Time: 2.98385

Cumulative Model Updates: 24,997
Cumulative Timesteps: 417,394,826

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,486.39519
Policy Entropy: 1.09251
Value Function Loss: 0.05382

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01782
Policy Update Magnitude: 0.03101
Value Function Update Magnitude: 0.04130

Collected Steps per Second: 24,158.00939
Overall Steps per Second: 16,776.94683

Timestep Collection Time: 2.07078
Timestep Consumption Time: 0.91105
PPO Batch Consumption Time: 0.10013
Total Iteration Time: 2.98183

Cumulative Model Updates: 25,000
Cumulative Timesteps: 417,444,852

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 417444852...
Checkpoint 417444852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,759.26062
Policy Entropy: 1.08792
Value Function Loss: 0.05861

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02049
Policy Update Magnitude: 0.03296
Value Function Update Magnitude: 0.04477

Collected Steps per Second: 24,179.18174
Overall Steps per Second: 16,833.41865

Timestep Collection Time: 2.06880
Timestep Consumption Time: 0.90278
PPO Batch Consumption Time: 0.10911
Total Iteration Time: 2.97159

Cumulative Model Updates: 25,003
Cumulative Timesteps: 417,494,874

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,629.11435
Policy Entropy: 1.07309
Value Function Loss: 0.06954

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03366
Policy Update Magnitude: 0.03501
Value Function Update Magnitude: 0.04896

Collected Steps per Second: 22,211.90414
Overall Steps per Second: 15,579.80084

Timestep Collection Time: 2.25150
Timestep Consumption Time: 0.95843
PPO Batch Consumption Time: 0.10131
Total Iteration Time: 3.20993

Cumulative Model Updates: 25,006
Cumulative Timesteps: 417,544,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 417544884...
Checkpoint 417544884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,022.25247
Policy Entropy: 1.08074
Value Function Loss: 0.06364

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03525
Policy Update Magnitude: 0.03560
Value Function Update Magnitude: 0.04645

Collected Steps per Second: 20,625.32849
Overall Steps per Second: 15,328.65386

Timestep Collection Time: 2.42546
Timestep Consumption Time: 0.83810
PPO Batch Consumption Time: 0.07352
Total Iteration Time: 3.26356

Cumulative Model Updates: 25,009
Cumulative Timesteps: 417,594,910

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,055.85286
Policy Entropy: 1.08781
Value Function Loss: 0.06419

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03274
Policy Update Magnitude: 0.03857
Value Function Update Magnitude: 0.04898

Collected Steps per Second: 22,969.37706
Overall Steps per Second: 16,174.95443

Timestep Collection Time: 2.17751
Timestep Consumption Time: 0.91468
PPO Batch Consumption Time: 0.10543
Total Iteration Time: 3.09219

Cumulative Model Updates: 25,012
Cumulative Timesteps: 417,644,926

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 417644926...
Checkpoint 417644926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,569.32309
Policy Entropy: 1.09713
Value Function Loss: 0.05796

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03702
Policy Update Magnitude: 0.03978
Value Function Update Magnitude: 0.04762

Collected Steps per Second: 23,973.31121
Overall Steps per Second: 16,764.09009

Timestep Collection Time: 2.08582
Timestep Consumption Time: 0.89698
PPO Batch Consumption Time: 0.10591
Total Iteration Time: 2.98280

Cumulative Model Updates: 25,015
Cumulative Timesteps: 417,694,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,359.81460
Policy Entropy: 1.10361
Value Function Loss: 0.05485

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03077
Policy Update Magnitude: 0.03585
Value Function Update Magnitude: 0.05027

Collected Steps per Second: 23,983.13327
Overall Steps per Second: 16,621.36291

Timestep Collection Time: 2.08572
Timestep Consumption Time: 0.92378
PPO Batch Consumption Time: 0.09592
Total Iteration Time: 3.00950

Cumulative Model Updates: 25,018
Cumulative Timesteps: 417,744,952

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 417744952...
Checkpoint 417744952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,943.38449
Policy Entropy: 1.09660
Value Function Loss: 0.05284

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02378
Policy Update Magnitude: 0.03306
Value Function Update Magnitude: 0.04446

Collected Steps per Second: 23,907.84757
Overall Steps per Second: 16,765.93051

Timestep Collection Time: 2.09212
Timestep Consumption Time: 0.89120
PPO Batch Consumption Time: 0.08836
Total Iteration Time: 2.98331

Cumulative Model Updates: 25,021
Cumulative Timesteps: 417,794,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,447.62823
Policy Entropy: 1.09560
Value Function Loss: 0.05114

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03488
Policy Update Magnitude: 0.03227
Value Function Update Magnitude: 0.04427

Collected Steps per Second: 24,239.79655
Overall Steps per Second: 16,742.70318

Timestep Collection Time: 2.06380
Timestep Consumption Time: 0.92413
PPO Batch Consumption Time: 0.10122
Total Iteration Time: 2.98793

Cumulative Model Updates: 25,024
Cumulative Timesteps: 417,844,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 417844996...
Checkpoint 417844996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,600.20383
Policy Entropy: 1.08663
Value Function Loss: 0.05505

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03449
Policy Update Magnitude: 0.03265
Value Function Update Magnitude: 0.04443

Collected Steps per Second: 23,476.00571
Overall Steps per Second: 16,224.48230

Timestep Collection Time: 2.12992
Timestep Consumption Time: 0.95197
PPO Batch Consumption Time: 0.09002
Total Iteration Time: 3.08189

Cumulative Model Updates: 25,027
Cumulative Timesteps: 417,894,998

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,437.84144
Policy Entropy: 1.09924
Value Function Loss: 0.05645

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03561
Policy Update Magnitude: 0.03213
Value Function Update Magnitude: 0.04458

Collected Steps per Second: 22,776.70137
Overall Steps per Second: 16,879.84382

Timestep Collection Time: 2.19531
Timestep Consumption Time: 0.76692
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 2.96223

Cumulative Model Updates: 25,030
Cumulative Timesteps: 417,945,000

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 417945000...
Checkpoint 417945000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,595.87385
Policy Entropy: 1.10924
Value Function Loss: 0.05568

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02350
Policy Update Magnitude: 0.03508
Value Function Update Magnitude: 0.04743

Collected Steps per Second: 21,262.23850
Overall Steps per Second: 15,145.43255

Timestep Collection Time: 2.35243
Timestep Consumption Time: 0.95008
PPO Batch Consumption Time: 0.11133
Total Iteration Time: 3.30251

Cumulative Model Updates: 25,033
Cumulative Timesteps: 417,995,018

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,625.96362
Policy Entropy: 1.10310
Value Function Loss: 0.05773

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02695
Policy Update Magnitude: 0.03815
Value Function Update Magnitude: 0.04874

Collected Steps per Second: 23,394.08670
Overall Steps per Second: 17,306.82361

Timestep Collection Time: 2.13772
Timestep Consumption Time: 0.75189
PPO Batch Consumption Time: 0.06191
Total Iteration Time: 2.88961

Cumulative Model Updates: 25,036
Cumulative Timesteps: 418,045,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 418045028...
Checkpoint 418045028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,045.09901
Policy Entropy: 1.09679
Value Function Loss: 0.05603

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02901
Policy Update Magnitude: 0.03797
Value Function Update Magnitude: 0.04755

Collected Steps per Second: 20,954.80378
Overall Steps per Second: 15,155.61501

Timestep Collection Time: 2.38714
Timestep Consumption Time: 0.91342
PPO Batch Consumption Time: 0.10439
Total Iteration Time: 3.30056

Cumulative Model Updates: 25,039
Cumulative Timesteps: 418,095,050

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,276.27419
Policy Entropy: 1.10487
Value Function Loss: 0.05512

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02519
Policy Update Magnitude: 0.03630
Value Function Update Magnitude: 0.05187

Collected Steps per Second: 24,094.54761
Overall Steps per Second: 16,747.25820

Timestep Collection Time: 2.07541
Timestep Consumption Time: 0.91051
PPO Batch Consumption Time: 0.10338
Total Iteration Time: 2.98592

Cumulative Model Updates: 25,042
Cumulative Timesteps: 418,145,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 418145056...
Checkpoint 418145056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,606.61493
Policy Entropy: 1.11370
Value Function Loss: 0.04658

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02811
Policy Update Magnitude: 0.03394
Value Function Update Magnitude: 0.05218

Collected Steps per Second: 23,754.78803
Overall Steps per Second: 16,675.84784

Timestep Collection Time: 2.10509
Timestep Consumption Time: 0.89362
PPO Batch Consumption Time: 0.09152
Total Iteration Time: 2.99871

Cumulative Model Updates: 25,045
Cumulative Timesteps: 418,195,062

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,611.16463
Policy Entropy: 1.11886
Value Function Loss: 0.04862

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02625
Policy Update Magnitude: 0.03420
Value Function Update Magnitude: 0.05217

Collected Steps per Second: 24,232.63954
Overall Steps per Second: 17,796.13331

Timestep Collection Time: 2.06432
Timestep Consumption Time: 0.74662
PPO Batch Consumption Time: 0.04498
Total Iteration Time: 2.81095

Cumulative Model Updates: 25,048
Cumulative Timesteps: 418,245,086

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 418245086...
Checkpoint 418245086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,562.87524
Policy Entropy: 1.11863
Value Function Loss: 0.05086

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03669
Policy Update Magnitude: 0.03284
Value Function Update Magnitude: 0.05310

Collected Steps per Second: 23,292.31002
Overall Steps per Second: 17,769.15181

Timestep Collection Time: 2.14818
Timestep Consumption Time: 0.66771
PPO Batch Consumption Time: 0.02848
Total Iteration Time: 2.81589

Cumulative Model Updates: 25,051
Cumulative Timesteps: 418,295,122

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,981.44594
Policy Entropy: 1.12014
Value Function Loss: 0.05850

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03609
Policy Update Magnitude: 0.03298
Value Function Update Magnitude: 0.05595

Collected Steps per Second: 22,803.42924
Overall Steps per Second: 16,038.05724

Timestep Collection Time: 2.19309
Timestep Consumption Time: 0.92512
PPO Batch Consumption Time: 0.10929
Total Iteration Time: 3.11821

Cumulative Model Updates: 25,054
Cumulative Timesteps: 418,345,132

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 418345132...
Checkpoint 418345132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,335.43322
Policy Entropy: 1.13319
Value Function Loss: 0.05346

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03089
Policy Update Magnitude: 0.03481
Value Function Update Magnitude: 0.05835

Collected Steps per Second: 23,646.59606
Overall Steps per Second: 17,208.23906

Timestep Collection Time: 2.11582
Timestep Consumption Time: 0.79162
PPO Batch Consumption Time: 0.06442
Total Iteration Time: 2.90744

Cumulative Model Updates: 25,057
Cumulative Timesteps: 418,395,164

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,039.69148
Policy Entropy: 1.14143
Value Function Loss: 0.05165

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02704
Policy Update Magnitude: 0.03394
Value Function Update Magnitude: 0.05491

Collected Steps per Second: 24,301.23031
Overall Steps per Second: 17,327.56307

Timestep Collection Time: 2.05825
Timestep Consumption Time: 0.82837
PPO Batch Consumption Time: 0.08906
Total Iteration Time: 2.88661

Cumulative Model Updates: 25,060
Cumulative Timesteps: 418,445,182

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 418445182...
Checkpoint 418445182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,040.12347
Policy Entropy: 1.13561
Value Function Loss: 0.04703

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02389
Policy Update Magnitude: 0.03529
Value Function Update Magnitude: 0.05392

Collected Steps per Second: 22,900.62498
Overall Steps per Second: 16,888.57480

Timestep Collection Time: 2.18457
Timestep Consumption Time: 0.77767
PPO Batch Consumption Time: 0.06114
Total Iteration Time: 2.96224

Cumulative Model Updates: 25,063
Cumulative Timesteps: 418,495,210

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,721.52503
Policy Entropy: 1.13954
Value Function Loss: 0.05100

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02460
Policy Update Magnitude: 0.03474
Value Function Update Magnitude: 0.05600

Collected Steps per Second: 21,908.74461
Overall Steps per Second: 15,583.04158

Timestep Collection Time: 2.28256
Timestep Consumption Time: 0.92657
PPO Batch Consumption Time: 0.10301
Total Iteration Time: 3.20913

Cumulative Model Updates: 25,066
Cumulative Timesteps: 418,545,218

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 418545218...
Checkpoint 418545218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,084.59664
Policy Entropy: 1.14475
Value Function Loss: 0.04992

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02385
Policy Update Magnitude: 0.03426
Value Function Update Magnitude: 0.05664

Collected Steps per Second: 23,771.03877
Overall Steps per Second: 17,072.76638

Timestep Collection Time: 2.10416
Timestep Consumption Time: 0.82554
PPO Batch Consumption Time: 0.06616
Total Iteration Time: 2.92970

Cumulative Model Updates: 25,069
Cumulative Timesteps: 418,595,236

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,967.99217
Policy Entropy: 1.14940
Value Function Loss: 0.05126

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02107
Policy Update Magnitude: 0.03256
Value Function Update Magnitude: 0.05830

Collected Steps per Second: 23,770.55993
Overall Steps per Second: 16,490.15774

Timestep Collection Time: 2.10445
Timestep Consumption Time: 0.92912
PPO Batch Consumption Time: 0.11175
Total Iteration Time: 3.03357

Cumulative Model Updates: 25,072
Cumulative Timesteps: 418,645,260

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 418645260...
Checkpoint 418645260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,882.48812
Policy Entropy: 1.13338
Value Function Loss: 0.05264

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01544
Policy Update Magnitude: 0.03189
Value Function Update Magnitude: 0.05977

Collected Steps per Second: 22,012.03054
Overall Steps per Second: 15,849.62544

Timestep Collection Time: 2.27267
Timestep Consumption Time: 0.88362
PPO Batch Consumption Time: 0.07545
Total Iteration Time: 3.15629

Cumulative Model Updates: 25,075
Cumulative Timesteps: 418,695,286

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,206.84558
Policy Entropy: 1.12823
Value Function Loss: 0.05357

Mean KL Divergence: 0.00168
SB3 Clip Fraction: 0.01478
Policy Update Magnitude: 0.03141
Value Function Update Magnitude: 0.06030

Collected Steps per Second: 19,439.32752
Overall Steps per Second: 15,013.90339

Timestep Collection Time: 2.57365
Timestep Consumption Time: 0.75860
PPO Batch Consumption Time: 0.02901
Total Iteration Time: 3.33224

Cumulative Model Updates: 25,078
Cumulative Timesteps: 418,745,316

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 418745316...
Checkpoint 418745316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,324.03494
Policy Entropy: 1.12004
Value Function Loss: 0.05707

Mean KL Divergence: 0.00125
SB3 Clip Fraction: 0.00895
Policy Update Magnitude: 0.03220
Value Function Update Magnitude: 0.05979

Collected Steps per Second: 21,756.29289
Overall Steps per Second: 15,978.26720

Timestep Collection Time: 2.29837
Timestep Consumption Time: 0.83113
PPO Batch Consumption Time: 0.07524
Total Iteration Time: 3.12950

Cumulative Model Updates: 25,081
Cumulative Timesteps: 418,795,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,450.94898
Policy Entropy: 1.12556
Value Function Loss: 0.05435

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.01896
Policy Update Magnitude: 0.03809
Value Function Update Magnitude: 0.05874

Collected Steps per Second: 21,130.68790
Overall Steps per Second: 16,538.34072

Timestep Collection Time: 2.36623
Timestep Consumption Time: 0.65705
PPO Batch Consumption Time: 0.02826
Total Iteration Time: 3.02328

Cumulative Model Updates: 25,084
Cumulative Timesteps: 418,845,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 418845320...
Checkpoint 418845320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,886.82067
Policy Entropy: 1.12369
Value Function Loss: 0.05950

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02883
Policy Update Magnitude: 0.03755
Value Function Update Magnitude: 0.05996

Collected Steps per Second: 21,530.83960
Overall Steps per Second: 15,118.57007

Timestep Collection Time: 2.32281
Timestep Consumption Time: 0.98518
PPO Batch Consumption Time: 0.11012
Total Iteration Time: 3.30798

Cumulative Model Updates: 25,087
Cumulative Timesteps: 418,895,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,258.83918
Policy Entropy: 1.12806
Value Function Loss: 0.05555

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02529
Policy Update Magnitude: 0.03814
Value Function Update Magnitude: 0.06200

Collected Steps per Second: 20,991.46993
Overall Steps per Second: 15,884.05787

Timestep Collection Time: 2.38316
Timestep Consumption Time: 0.76629
PPO Batch Consumption Time: 0.06263
Total Iteration Time: 3.14945

Cumulative Model Updates: 25,090
Cumulative Timesteps: 418,945,358

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 418945358...
Checkpoint 418945358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,669.56504
Policy Entropy: 1.13176
Value Function Loss: 0.06075

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02989
Policy Update Magnitude: 0.03734
Value Function Update Magnitude: 0.06394

Collected Steps per Second: 23,930.01540
Overall Steps per Second: 15,590.16255

Timestep Collection Time: 2.09035
Timestep Consumption Time: 1.11822
PPO Batch Consumption Time: 0.10588
Total Iteration Time: 3.20856

Cumulative Model Updates: 25,093
Cumulative Timesteps: 418,995,380

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,882.37738
Policy Entropy: 1.14137
Value Function Loss: 0.05563

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04310
Policy Update Magnitude: 0.03564
Value Function Update Magnitude: 0.06279

Collected Steps per Second: 22,685.07521
Overall Steps per Second: 15,643.10597

Timestep Collection Time: 2.20462
Timestep Consumption Time: 0.99244
PPO Batch Consumption Time: 0.11486
Total Iteration Time: 3.19706

Cumulative Model Updates: 25,096
Cumulative Timesteps: 419,045,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 419045392...
Checkpoint 419045392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,911.33401
Policy Entropy: 1.14895
Value Function Loss: 0.05955

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.05565
Policy Update Magnitude: 0.03327
Value Function Update Magnitude: 0.06328

Collected Steps per Second: 22,367.49410
Overall Steps per Second: 16,632.20130

Timestep Collection Time: 2.23682
Timestep Consumption Time: 0.77132
PPO Batch Consumption Time: 0.05837
Total Iteration Time: 3.00814

Cumulative Model Updates: 25,099
Cumulative Timesteps: 419,095,424

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,123.24273
Policy Entropy: 1.14419
Value Function Loss: 0.05536

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04285
Policy Update Magnitude: 0.03298
Value Function Update Magnitude: 0.06327

Collected Steps per Second: 19,510.16780
Overall Steps per Second: 14,029.70172

Timestep Collection Time: 2.56400
Timestep Consumption Time: 1.00158
PPO Batch Consumption Time: 0.12211
Total Iteration Time: 3.56558

Cumulative Model Updates: 25,102
Cumulative Timesteps: 419,145,448

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 419145448...
Checkpoint 419145448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,117.19135
Policy Entropy: 1.13520
Value Function Loss: 0.05918

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04520
Policy Update Magnitude: 0.03671
Value Function Update Magnitude: 0.06369

Collected Steps per Second: 21,641.81958
Overall Steps per Second: 16,008.19198

Timestep Collection Time: 2.31182
Timestep Consumption Time: 0.81358
PPO Batch Consumption Time: 0.07239
Total Iteration Time: 3.12540

Cumulative Model Updates: 25,105
Cumulative Timesteps: 419,195,480

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,492.28261
Policy Entropy: 1.13571
Value Function Loss: 0.05888

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05153
Policy Update Magnitude: 0.03861
Value Function Update Magnitude: 0.06266

Collected Steps per Second: 22,839.96638
Overall Steps per Second: 16,322.08816

Timestep Collection Time: 2.19037
Timestep Consumption Time: 0.87468
PPO Batch Consumption Time: 0.09640
Total Iteration Time: 3.06505

Cumulative Model Updates: 25,108
Cumulative Timesteps: 419,245,508

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 419245508...
Checkpoint 419245508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,224.96850
Policy Entropy: 1.14079
Value Function Loss: 0.06432

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.04837
Policy Update Magnitude: 0.03886
Value Function Update Magnitude: 0.05904

Collected Steps per Second: 22,979.42323
Overall Steps per Second: 16,929.17540

Timestep Collection Time: 2.17647
Timestep Consumption Time: 0.77784
PPO Batch Consumption Time: 0.06307
Total Iteration Time: 2.95431

Cumulative Model Updates: 25,111
Cumulative Timesteps: 419,295,522

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,010.10632
Policy Entropy: 1.15219
Value Function Loss: 0.06257

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04377
Policy Update Magnitude: 0.04025
Value Function Update Magnitude: 0.05614

Collected Steps per Second: 22,981.22670
Overall Steps per Second: 16,499.54502

Timestep Collection Time: 2.17630
Timestep Consumption Time: 0.85494
PPO Batch Consumption Time: 0.08442
Total Iteration Time: 3.03124

Cumulative Model Updates: 25,114
Cumulative Timesteps: 419,345,536

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 419345536...
Checkpoint 419345536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,719.15405
Policy Entropy: 1.15394
Value Function Loss: 0.05889

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02461
Policy Update Magnitude: 0.04066
Value Function Update Magnitude: 0.05491

Collected Steps per Second: 20,713.48587
Overall Steps per Second: 15,776.94216

Timestep Collection Time: 2.41456
Timestep Consumption Time: 0.75551
PPO Batch Consumption Time: 0.04787
Total Iteration Time: 3.17007

Cumulative Model Updates: 25,117
Cumulative Timesteps: 419,395,550

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,229.40394
Policy Entropy: 1.16087
Value Function Loss: 0.05480

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02171
Policy Update Magnitude: 0.04005
Value Function Update Magnitude: 0.05159

Collected Steps per Second: 21,539.85828
Overall Steps per Second: 15,458.57063

Timestep Collection Time: 2.32211
Timestep Consumption Time: 0.91350
PPO Batch Consumption Time: 0.10781
Total Iteration Time: 3.23562

Cumulative Model Updates: 25,120
Cumulative Timesteps: 419,445,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 419445568...
Checkpoint 419445568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,625.43013
Policy Entropy: 1.15769
Value Function Loss: 0.05078

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02095
Policy Update Magnitude: 0.04035
Value Function Update Magnitude: 0.04918

Collected Steps per Second: 23,943.52213
Overall Steps per Second: 17,568.27086

Timestep Collection Time: 2.08883
Timestep Consumption Time: 0.75800
PPO Batch Consumption Time: 0.06095
Total Iteration Time: 2.84684

Cumulative Model Updates: 25,123
Cumulative Timesteps: 419,495,582

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,464.63435
Policy Entropy: 1.13615
Value Function Loss: 0.05767

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02544
Policy Update Magnitude: 0.03760
Value Function Update Magnitude: 0.04713

Collected Steps per Second: 20,497.78724
Overall Steps per Second: 15,150.83620

Timestep Collection Time: 2.43958
Timestep Consumption Time: 0.86096
PPO Batch Consumption Time: 0.08651
Total Iteration Time: 3.30054

Cumulative Model Updates: 25,126
Cumulative Timesteps: 419,545,588

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 419545588...
Checkpoint 419545588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,656.83395
Policy Entropy: 1.14479
Value Function Loss: 0.05570

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02169
Policy Update Magnitude: 0.03764
Value Function Update Magnitude: 0.04525

Collected Steps per Second: 23,184.10307
Overall Steps per Second: 16,996.69714

Timestep Collection Time: 2.15812
Timestep Consumption Time: 0.78563
PPO Batch Consumption Time: 0.06547
Total Iteration Time: 2.94375

Cumulative Model Updates: 25,129
Cumulative Timesteps: 419,595,622

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,386.19118
Policy Entropy: 1.14736
Value Function Loss: 0.05640

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04008
Policy Update Magnitude: 0.03677
Value Function Update Magnitude: 0.04304

Collected Steps per Second: 21,799.40331
Overall Steps per Second: 15,520.87829

Timestep Collection Time: 2.29493
Timestep Consumption Time: 0.92835
PPO Batch Consumption Time: 0.10868
Total Iteration Time: 3.22327

Cumulative Model Updates: 25,132
Cumulative Timesteps: 419,645,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 419645650...
Checkpoint 419645650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,757.85530
Policy Entropy: 1.15808
Value Function Loss: 0.05299

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03134
Policy Update Magnitude: 0.03563
Value Function Update Magnitude: 0.04351

Collected Steps per Second: 22,709.09159
Overall Steps per Second: 15,693.51651

Timestep Collection Time: 2.20308
Timestep Consumption Time: 0.98486
PPO Batch Consumption Time: 0.11533
Total Iteration Time: 3.18794

Cumulative Model Updates: 25,135
Cumulative Timesteps: 419,695,680

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,698.85171
Policy Entropy: 1.15760
Value Function Loss: 0.04868

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02415
Policy Update Magnitude: 0.03279
Value Function Update Magnitude: 0.04798

Collected Steps per Second: 22,721.76912
Overall Steps per Second: 16,640.27735

Timestep Collection Time: 2.20062
Timestep Consumption Time: 0.80426
PPO Batch Consumption Time: 0.06125
Total Iteration Time: 3.00488

Cumulative Model Updates: 25,138
Cumulative Timesteps: 419,745,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 419745682...
Checkpoint 419745682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,820.05097
Policy Entropy: 1.14319
Value Function Loss: 0.05975

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.03930
Value Function Update Magnitude: 0.05331

Collected Steps per Second: 20,382.86439
Overall Steps per Second: 14,832.75520

Timestep Collection Time: 2.45304
Timestep Consumption Time: 0.91788
PPO Batch Consumption Time: 0.10305
Total Iteration Time: 3.37092

Cumulative Model Updates: 25,141
Cumulative Timesteps: 419,795,682

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,364.88552
Policy Entropy: 1.14015
Value Function Loss: 0.05594

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04637
Policy Update Magnitude: 0.04143
Value Function Update Magnitude: 0.04992

Collected Steps per Second: 22,958.02749
Overall Steps per Second: 15,781.57632

Timestep Collection Time: 2.17928
Timestep Consumption Time: 0.99100
PPO Batch Consumption Time: 0.12162
Total Iteration Time: 3.17028

Cumulative Model Updates: 25,144
Cumulative Timesteps: 419,845,714

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 419845714...
Checkpoint 419845714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,489.33410
Policy Entropy: 1.13188
Value Function Loss: 0.05713

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03869
Policy Update Magnitude: 0.03878
Value Function Update Magnitude: 0.04573

Collected Steps per Second: 21,818.72311
Overall Steps per Second: 15,694.37899

Timestep Collection Time: 2.29216
Timestep Consumption Time: 0.89446
PPO Batch Consumption Time: 0.09488
Total Iteration Time: 3.18662

Cumulative Model Updates: 25,147
Cumulative Timesteps: 419,895,726

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,963.46465
Policy Entropy: 1.14072
Value Function Loss: 0.04884

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03242
Policy Update Magnitude: 0.03698
Value Function Update Magnitude: 0.04629

Collected Steps per Second: 22,819.42495
Overall Steps per Second: 16,632.96884

Timestep Collection Time: 2.19173
Timestep Consumption Time: 0.81519
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 3.00692

Cumulative Model Updates: 25,150
Cumulative Timesteps: 419,945,740

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 419945740...
Checkpoint 419945740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,164.81368
Policy Entropy: 1.15298
Value Function Loss: 0.04909

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.01896
Policy Update Magnitude: 0.03684
Value Function Update Magnitude: 0.04596

Collected Steps per Second: 20,164.12143
Overall Steps per Second: 14,550.86683

Timestep Collection Time: 2.47965
Timestep Consumption Time: 0.95657
PPO Batch Consumption Time: 0.10226
Total Iteration Time: 3.43622

Cumulative Model Updates: 25,153
Cumulative Timesteps: 419,995,740

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,653.72619
Policy Entropy: 1.14918
Value Function Loss: 0.05377

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02599
Policy Update Magnitude: 0.03663
Value Function Update Magnitude: 0.04965

Collected Steps per Second: 22,590.18361
Overall Steps per Second: 16,656.87030

Timestep Collection Time: 2.21450
Timestep Consumption Time: 0.78882
PPO Batch Consumption Time: 0.06439
Total Iteration Time: 3.00333

Cumulative Model Updates: 25,156
Cumulative Timesteps: 420,045,766

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 420045766...
Checkpoint 420045766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,665.15644
Policy Entropy: 1.13026
Value Function Loss: 0.05644

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02840
Policy Update Magnitude: 0.03679
Value Function Update Magnitude: 0.05840

Collected Steps per Second: 20,618.66975
Overall Steps per Second: 15,064.98855

Timestep Collection Time: 2.42576
Timestep Consumption Time: 0.89425
PPO Batch Consumption Time: 0.10261
Total Iteration Time: 3.32002

Cumulative Model Updates: 25,159
Cumulative Timesteps: 420,095,782

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,639.86705
Policy Entropy: 1.12615
Value Function Loss: 0.06664

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02831
Policy Update Magnitude: 0.03429
Value Function Update Magnitude: 0.05344

Collected Steps per Second: 23,066.33754
Overall Steps per Second: 15,754.76556

Timestep Collection Time: 2.16783
Timestep Consumption Time: 1.00606
PPO Batch Consumption Time: 0.12681
Total Iteration Time: 3.17390

Cumulative Model Updates: 25,162
Cumulative Timesteps: 420,145,786

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 420145786...
Checkpoint 420145786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,217.70245
Policy Entropy: 1.13179
Value Function Loss: 0.06785

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02297
Policy Update Magnitude: 0.03579
Value Function Update Magnitude: 0.05098

Collected Steps per Second: 22,815.66277
Overall Steps per Second: 16,628.68226

Timestep Collection Time: 2.19253
Timestep Consumption Time: 0.81577
PPO Batch Consumption Time: 0.06135
Total Iteration Time: 3.00830

Cumulative Model Updates: 25,165
Cumulative Timesteps: 420,195,810

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,485.69267
Policy Entropy: 1.15502
Value Function Loss: 0.06501

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02489
Policy Update Magnitude: 0.03362
Value Function Update Magnitude: 0.04965

Collected Steps per Second: 20,481.84008
Overall Steps per Second: 14,775.20314

Timestep Collection Time: 2.44177
Timestep Consumption Time: 0.94309
PPO Batch Consumption Time: 0.11207
Total Iteration Time: 3.38486

Cumulative Model Updates: 25,168
Cumulative Timesteps: 420,245,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 420245822...
Checkpoint 420245822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,426.43429
Policy Entropy: 1.15926
Value Function Loss: 0.05982

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02407
Policy Update Magnitude: 0.03502
Value Function Update Magnitude: 0.04488

Collected Steps per Second: 22,943.73853
Overall Steps per Second: 15,805.54166

Timestep Collection Time: 2.18012
Timestep Consumption Time: 0.98460
PPO Batch Consumption Time: 0.12299
Total Iteration Time: 3.16471

Cumulative Model Updates: 25,171
Cumulative Timesteps: 420,295,842

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,924.98667
Policy Entropy: 1.14853
Value Function Loss: 0.06433

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03037
Policy Update Magnitude: 0.03389
Value Function Update Magnitude: 0.04461

Collected Steps per Second: 23,500.97752
Overall Steps per Second: 16,961.58695

Timestep Collection Time: 2.12834
Timestep Consumption Time: 0.82056
PPO Batch Consumption Time: 0.06215
Total Iteration Time: 2.94890

Cumulative Model Updates: 25,174
Cumulative Timesteps: 420,345,860

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 420345860...
Checkpoint 420345860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,109.36549
Policy Entropy: 1.14314
Value Function Loss: 0.06037

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02657
Policy Update Magnitude: 0.03262
Value Function Update Magnitude: 0.04948

Collected Steps per Second: 22,471.00824
Overall Steps per Second: 16,566.55333

Timestep Collection Time: 2.22509
Timestep Consumption Time: 0.79304
PPO Batch Consumption Time: 0.06210
Total Iteration Time: 3.01813

Cumulative Model Updates: 25,177
Cumulative Timesteps: 420,395,860

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,202.26296
Policy Entropy: 1.14466
Value Function Loss: 0.06062

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01457
Policy Update Magnitude: 0.03211
Value Function Update Magnitude: 0.05496

Collected Steps per Second: 24,171.64604
Overall Steps per Second: 17,292.78651

Timestep Collection Time: 2.06912
Timestep Consumption Time: 0.82307
PPO Batch Consumption Time: 0.06588
Total Iteration Time: 2.89219

Cumulative Model Updates: 25,180
Cumulative Timesteps: 420,445,874

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 420445874...
Checkpoint 420445874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,213.90140
Policy Entropy: 1.14301
Value Function Loss: 0.05515

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.01816
Policy Update Magnitude: 0.03258
Value Function Update Magnitude: 0.05543

Collected Steps per Second: 21,871.51984
Overall Steps per Second: 15,861.75779

Timestep Collection Time: 2.28654
Timestep Consumption Time: 0.86633
PPO Batch Consumption Time: 0.08222
Total Iteration Time: 3.15287

Cumulative Model Updates: 25,183
Cumulative Timesteps: 420,495,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,169.10295
Policy Entropy: 1.13207
Value Function Loss: 0.06013

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02057
Policy Update Magnitude: 0.03358
Value Function Update Magnitude: 0.05483

Collected Steps per Second: 23,062.49580
Overall Steps per Second: 16,829.40611

Timestep Collection Time: 2.16854
Timestep Consumption Time: 0.80316
PPO Batch Consumption Time: 0.06246
Total Iteration Time: 2.97170

Cumulative Model Updates: 25,186
Cumulative Timesteps: 420,545,896

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 420545896...
Checkpoint 420545896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,058.19693
Policy Entropy: 1.13235
Value Function Loss: 0.05627

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01784
Policy Update Magnitude: 0.03157
Value Function Update Magnitude: 0.05718

Collected Steps per Second: 20,284.28579
Overall Steps per Second: 15,794.78003

Timestep Collection Time: 2.46575
Timestep Consumption Time: 0.70086
PPO Batch Consumption Time: 0.03319
Total Iteration Time: 3.16662

Cumulative Model Updates: 25,189
Cumulative Timesteps: 420,595,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,018.76521
Policy Entropy: 1.13572
Value Function Loss: 0.05238

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02271
Policy Update Magnitude: 0.03087
Value Function Update Magnitude: 0.05445

Collected Steps per Second: 20,752.42661
Overall Steps per Second: 14,765.34937

Timestep Collection Time: 2.41157
Timestep Consumption Time: 0.97785
PPO Batch Consumption Time: 0.08049
Total Iteration Time: 3.38942

Cumulative Model Updates: 25,192
Cumulative Timesteps: 420,645,958

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 420645958...
Checkpoint 420645958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,971.26308
Policy Entropy: 1.14896
Value Function Loss: 0.04765

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03423
Policy Update Magnitude: 0.02982
Value Function Update Magnitude: 0.05273

Collected Steps per Second: 22,988.57754
Overall Steps per Second: 16,892.08742

Timestep Collection Time: 2.17734
Timestep Consumption Time: 0.78582
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 2.96316

Cumulative Model Updates: 25,195
Cumulative Timesteps: 420,696,012

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,449.46569
Policy Entropy: 1.16490
Value Function Loss: 0.04644

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03719
Policy Update Magnitude: 0.03017
Value Function Update Magnitude: 0.05161

Collected Steps per Second: 21,475.03456
Overall Steps per Second: 15,564.07450

Timestep Collection Time: 2.32959
Timestep Consumption Time: 0.88474
PPO Batch Consumption Time: 0.07880
Total Iteration Time: 3.21433

Cumulative Model Updates: 25,198
Cumulative Timesteps: 420,746,040

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 420746040...
Checkpoint 420746040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,272.42887
Policy Entropy: 1.17103
Value Function Loss: 0.04957

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04318
Policy Update Magnitude: 0.02941
Value Function Update Magnitude: 0.04808

Collected Steps per Second: 23,270.55106
Overall Steps per Second: 17,019.04909

Timestep Collection Time: 2.14993
Timestep Consumption Time: 0.78972
PPO Batch Consumption Time: 0.06538
Total Iteration Time: 2.93965

Cumulative Model Updates: 25,201
Cumulative Timesteps: 420,796,070

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,291.98912
Policy Entropy: 1.16501
Value Function Loss: 0.05291

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03783
Policy Update Magnitude: 0.02796
Value Function Update Magnitude: 0.04635

Collected Steps per Second: 24,079.19783
Overall Steps per Second: 16,596.26731

Timestep Collection Time: 2.07798
Timestep Consumption Time: 0.93692
PPO Batch Consumption Time: 0.11153
Total Iteration Time: 3.01489

Cumulative Model Updates: 25,204
Cumulative Timesteps: 420,846,106

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 420846106...
Checkpoint 420846106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,152.34352
Policy Entropy: 1.15842
Value Function Loss: 0.05226

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03127
Policy Update Magnitude: 0.02913
Value Function Update Magnitude: 0.04410

Collected Steps per Second: 23,829.68327
Overall Steps per Second: 17,221.82770

Timestep Collection Time: 2.09898
Timestep Consumption Time: 0.80536
PPO Batch Consumption Time: 0.06209
Total Iteration Time: 2.90434

Cumulative Model Updates: 25,207
Cumulative Timesteps: 420,896,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,993.58059
Policy Entropy: 1.16016
Value Function Loss: 0.04900

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03449
Policy Update Magnitude: 0.02998
Value Function Update Magnitude: 0.04573

Collected Steps per Second: 21,750.08782
Overall Steps per Second: 15,217.99032

Timestep Collection Time: 2.29903
Timestep Consumption Time: 0.98682
PPO Batch Consumption Time: 0.11130
Total Iteration Time: 3.28585

Cumulative Model Updates: 25,210
Cumulative Timesteps: 420,946,128

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 420946128...
Checkpoint 420946128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,034.51015
Policy Entropy: 1.15615
Value Function Loss: 0.04898

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02139
Policy Update Magnitude: 0.03085
Value Function Update Magnitude: 0.04329

Collected Steps per Second: 21,992.35780
Overall Steps per Second: 15,663.98443

Timestep Collection Time: 2.27479
Timestep Consumption Time: 0.91903
PPO Batch Consumption Time: 0.07862
Total Iteration Time: 3.19382

Cumulative Model Updates: 25,213
Cumulative Timesteps: 420,996,156

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,622.89018
Policy Entropy: 1.14756
Value Function Loss: 0.05043

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.01764
Policy Update Magnitude: 0.02987
Value Function Update Magnitude: 0.04922

Collected Steps per Second: 21,165.40280
Overall Steps per Second: 15,783.23092

Timestep Collection Time: 2.36357
Timestep Consumption Time: 0.80599
PPO Batch Consumption Time: 0.06919
Total Iteration Time: 3.16957

Cumulative Model Updates: 25,216
Cumulative Timesteps: 421,046,182

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 421046182...
Checkpoint 421046182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,130.05331
Policy Entropy: 1.15076
Value Function Loss: 0.05444

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02619
Policy Update Magnitude: 0.03040
Value Function Update Magnitude: 0.04693

Collected Steps per Second: 20,211.17747
Overall Steps per Second: 14,688.39481

Timestep Collection Time: 2.47526
Timestep Consumption Time: 0.93069
PPO Batch Consumption Time: 0.08641
Total Iteration Time: 3.40595

Cumulative Model Updates: 25,219
Cumulative Timesteps: 421,096,210

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,612.94931
Policy Entropy: 1.14664
Value Function Loss: 0.05928

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02604
Policy Update Magnitude: 0.03309
Value Function Update Magnitude: 0.04849

Collected Steps per Second: 22,829.74101
Overall Steps per Second: 16,678.52749

Timestep Collection Time: 2.19030
Timestep Consumption Time: 0.80781
PPO Batch Consumption Time: 0.05899
Total Iteration Time: 2.99811

Cumulative Model Updates: 25,222
Cumulative Timesteps: 421,146,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 421146214...
Checkpoint 421146214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,936.20393
Policy Entropy: 1.13955
Value Function Loss: 0.06141

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02295
Policy Update Magnitude: 0.03384
Value Function Update Magnitude: 0.05032

Collected Steps per Second: 19,499.28545
Overall Steps per Second: 14,060.13162

Timestep Collection Time: 2.56491
Timestep Consumption Time: 0.99224
PPO Batch Consumption Time: 0.12035
Total Iteration Time: 3.55715

Cumulative Model Updates: 25,225
Cumulative Timesteps: 421,196,228

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,412.33511
Policy Entropy: 1.13099
Value Function Loss: 0.05967

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01994
Policy Update Magnitude: 0.03668
Value Function Update Magnitude: 0.04698

Collected Steps per Second: 22,834.95621
Overall Steps per Second: 16,636.40636

Timestep Collection Time: 2.19076
Timestep Consumption Time: 0.81626
PPO Batch Consumption Time: 0.06008
Total Iteration Time: 3.00702

Cumulative Model Updates: 25,228
Cumulative Timesteps: 421,246,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 421246254...
Checkpoint 421246254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,058.18683
Policy Entropy: 1.13467
Value Function Loss: 0.05392

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02986
Policy Update Magnitude: 0.03436
Value Function Update Magnitude: 0.03939

Collected Steps per Second: 20,932.22248
Overall Steps per Second: 14,884.16347

Timestep Collection Time: 2.38971
Timestep Consumption Time: 0.97104
PPO Batch Consumption Time: 0.12337
Total Iteration Time: 3.36075

Cumulative Model Updates: 25,231
Cumulative Timesteps: 421,296,276

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,165.31566
Policy Entropy: 1.13433
Value Function Loss: 0.05330

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02027
Policy Update Magnitude: 0.03276
Value Function Update Magnitude: 0.04288

Collected Steps per Second: 21,228.40906
Overall Steps per Second: 15,556.66250

Timestep Collection Time: 2.35533
Timestep Consumption Time: 0.85872
PPO Batch Consumption Time: 0.08531
Total Iteration Time: 3.21406

Cumulative Model Updates: 25,234
Cumulative Timesteps: 421,346,276

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 421346276...
Checkpoint 421346276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,817.87058
Policy Entropy: 1.13595
Value Function Loss: 0.05151

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04060
Policy Update Magnitude: 0.03309
Value Function Update Magnitude: 0.04431

Collected Steps per Second: 23,999.06744
Overall Steps per Second: 17,308.80351

Timestep Collection Time: 2.08458
Timestep Consumption Time: 0.80574
PPO Batch Consumption Time: 0.06389
Total Iteration Time: 2.89032

Cumulative Model Updates: 25,237
Cumulative Timesteps: 421,396,304

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,568.11687
Policy Entropy: 1.13618
Value Function Loss: 0.05458

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03860
Policy Update Magnitude: 0.03182
Value Function Update Magnitude: 0.04244

Collected Steps per Second: 23,792.69940
Overall Steps per Second: 17,300.33598

Timestep Collection Time: 2.10182
Timestep Consumption Time: 0.78876
PPO Batch Consumption Time: 0.05945
Total Iteration Time: 2.89058

Cumulative Model Updates: 25,240
Cumulative Timesteps: 421,446,312

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 421446312...
Checkpoint 421446312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,920.56610
Policy Entropy: 1.13374
Value Function Loss: 0.05655

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02874
Policy Update Magnitude: 0.03313
Value Function Update Magnitude: 0.04197

Collected Steps per Second: 18,033.95560
Overall Steps per Second: 13,301.61773

Timestep Collection Time: 2.77355
Timestep Consumption Time: 0.98675
PPO Batch Consumption Time: 0.11138
Total Iteration Time: 3.76029

Cumulative Model Updates: 25,243
Cumulative Timesteps: 421,496,330

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,344.47129
Policy Entropy: 1.12823
Value Function Loss: 0.06044

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03183
Policy Update Magnitude: 0.03302
Value Function Update Magnitude: 0.03935

Collected Steps per Second: 21,684.05425
Overall Steps per Second: 15,878.32491

Timestep Collection Time: 2.30732
Timestep Consumption Time: 0.84364
PPO Batch Consumption Time: 0.06209
Total Iteration Time: 3.15096

Cumulative Model Updates: 25,246
Cumulative Timesteps: 421,546,362

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 421546362...
Checkpoint 421546362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,666.71157
Policy Entropy: 1.12789
Value Function Loss: 0.05718

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.04833
Policy Update Magnitude: 0.03316
Value Function Update Magnitude: 0.04361

Collected Steps per Second: 21,381.38794
Overall Steps per Second: 15,439.66152

Timestep Collection Time: 2.33960
Timestep Consumption Time: 0.90036
PPO Batch Consumption Time: 0.08059
Total Iteration Time: 3.23997

Cumulative Model Updates: 25,249
Cumulative Timesteps: 421,596,386

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,565.58582
Policy Entropy: 1.11740
Value Function Loss: 0.05359

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03817
Policy Update Magnitude: 0.03227
Value Function Update Magnitude: 0.04422

Collected Steps per Second: 22,040.27854
Overall Steps per Second: 15,692.78420

Timestep Collection Time: 2.26885
Timestep Consumption Time: 0.91771
PPO Batch Consumption Time: 0.09499
Total Iteration Time: 3.18656

Cumulative Model Updates: 25,252
Cumulative Timesteps: 421,646,392

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 421646392...
Checkpoint 421646392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,689.72571
Policy Entropy: 1.12359
Value Function Loss: 0.05256

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03299
Policy Update Magnitude: 0.03143
Value Function Update Magnitude: 0.04539

Collected Steps per Second: 23,022.21794
Overall Steps per Second: 16,970.06683

Timestep Collection Time: 2.17364
Timestep Consumption Time: 0.77520
PPO Batch Consumption Time: 0.05941
Total Iteration Time: 2.94884

Cumulative Model Updates: 25,255
Cumulative Timesteps: 421,696,434

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,122.42142
Policy Entropy: 1.12189
Value Function Loss: 0.05912

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02517
Policy Update Magnitude: 0.03230
Value Function Update Magnitude: 0.04588

Collected Steps per Second: 23,188.41117
Overall Steps per Second: 17,137.03472

Timestep Collection Time: 2.15728
Timestep Consumption Time: 0.76177
PPO Batch Consumption Time: 0.06005
Total Iteration Time: 2.91906

Cumulative Model Updates: 25,258
Cumulative Timesteps: 421,746,458

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 421746458...
Checkpoint 421746458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,276.30528
Policy Entropy: 1.12045
Value Function Loss: 0.06106

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02521
Policy Update Magnitude: 0.03372
Value Function Update Magnitude: 0.04513

Collected Steps per Second: 20,530.68011
Overall Steps per Second: 15,182.88454

Timestep Collection Time: 2.43587
Timestep Consumption Time: 0.85797
PPO Batch Consumption Time: 0.07824
Total Iteration Time: 3.29384

Cumulative Model Updates: 25,261
Cumulative Timesteps: 421,796,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,836.60486
Policy Entropy: 1.12695
Value Function Loss: 0.06474

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02503
Policy Update Magnitude: 0.03384
Value Function Update Magnitude: 0.04992

Collected Steps per Second: 22,053.21577
Overall Steps per Second: 16,301.49286

Timestep Collection Time: 2.26761
Timestep Consumption Time: 0.80009
PPO Batch Consumption Time: 0.06260
Total Iteration Time: 3.06769

Cumulative Model Updates: 25,264
Cumulative Timesteps: 421,846,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 421846476...
Checkpoint 421846476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,884.64540
Policy Entropy: 1.11152
Value Function Loss: 0.05745

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02781
Policy Update Magnitude: 0.03440
Value Function Update Magnitude: 0.05044

Collected Steps per Second: 20,620.71571
Overall Steps per Second: 15,126.62498

Timestep Collection Time: 2.42475
Timestep Consumption Time: 0.88068
PPO Batch Consumption Time: 0.08278
Total Iteration Time: 3.30543

Cumulative Model Updates: 25,267
Cumulative Timesteps: 421,896,476

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,995.38180
Policy Entropy: 1.11724
Value Function Loss: 0.05766

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02187
Policy Update Magnitude: 0.03635
Value Function Update Magnitude: 0.05501

Collected Steps per Second: 24,111.41684
Overall Steps per Second: 17,580.02464

Timestep Collection Time: 2.07487
Timestep Consumption Time: 0.77086
PPO Batch Consumption Time: 0.06365
Total Iteration Time: 2.84573

Cumulative Model Updates: 25,270
Cumulative Timesteps: 421,946,504

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 421946504...
Checkpoint 421946504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,239.57090
Policy Entropy: 1.12192
Value Function Loss: 0.05579

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02979
Policy Update Magnitude: 0.03559
Value Function Update Magnitude: 0.05460

Collected Steps per Second: 21,019.60417
Overall Steps per Second: 15,063.39765

Timestep Collection Time: 2.37997
Timestep Consumption Time: 0.94106
PPO Batch Consumption Time: 0.10515
Total Iteration Time: 3.32103

Cumulative Model Updates: 25,273
Cumulative Timesteps: 421,996,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,669.70625
Policy Entropy: 1.13365
Value Function Loss: 0.05910

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02872
Policy Update Magnitude: 0.03382
Value Function Update Magnitude: 0.06360

Collected Steps per Second: 23,847.15882
Overall Steps per Second: 17,356.78587

Timestep Collection Time: 2.09702
Timestep Consumption Time: 0.78416
PPO Batch Consumption Time: 0.06453
Total Iteration Time: 2.88118

Cumulative Model Updates: 25,276
Cumulative Timesteps: 422,046,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 422046538...
Checkpoint 422046538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,948.80910
Policy Entropy: 1.14611
Value Function Loss: 0.05748

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02133
Policy Update Magnitude: 0.03482
Value Function Update Magnitude: 0.06178

Collected Steps per Second: 21,722.75054
Overall Steps per Second: 16,098.11298

Timestep Collection Time: 2.30173
Timestep Consumption Time: 0.80422
PPO Batch Consumption Time: 0.07388
Total Iteration Time: 3.10595

Cumulative Model Updates: 25,279
Cumulative Timesteps: 422,096,538

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,513.54338
Policy Entropy: 1.16113
Value Function Loss: 0.05318

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02483
Policy Update Magnitude: 0.03514
Value Function Update Magnitude: 0.05822

Collected Steps per Second: 24,039.39396
Overall Steps per Second: 17,490.49116

Timestep Collection Time: 2.08050
Timestep Consumption Time: 0.77899
PPO Batch Consumption Time: 0.06503
Total Iteration Time: 2.85950

Cumulative Model Updates: 25,282
Cumulative Timesteps: 422,146,552

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 422146552...
Checkpoint 422146552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,061.05279
Policy Entropy: 1.17176
Value Function Loss: 0.05404

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02375
Policy Update Magnitude: 0.03519
Value Function Update Magnitude: 0.05667

Collected Steps per Second: 21,837.97021
Overall Steps per Second: 15,241.15772

Timestep Collection Time: 2.29005
Timestep Consumption Time: 0.99120
PPO Batch Consumption Time: 0.12507
Total Iteration Time: 3.28125

Cumulative Model Updates: 25,285
Cumulative Timesteps: 422,196,562

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,527.33035
Policy Entropy: 1.16937
Value Function Loss: 0.05626

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03621
Policy Update Magnitude: 0.03371
Value Function Update Magnitude: 0.05127

Collected Steps per Second: 21,396.77434
Overall Steps per Second: 15,537.11588

Timestep Collection Time: 2.33689
Timestep Consumption Time: 0.88133
PPO Batch Consumption Time: 0.08242
Total Iteration Time: 3.21823

Cumulative Model Updates: 25,288
Cumulative Timesteps: 422,246,564

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 422246564...
Checkpoint 422246564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,248.14018
Policy Entropy: 1.15289
Value Function Loss: 0.06381

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03578
Policy Update Magnitude: 0.03714
Value Function Update Magnitude: 0.05062

Collected Steps per Second: 23,519.06517
Overall Steps per Second: 17,187.71473

Timestep Collection Time: 2.12653
Timestep Consumption Time: 0.78334
PPO Batch Consumption Time: 0.06419
Total Iteration Time: 2.90987

Cumulative Model Updates: 25,291
Cumulative Timesteps: 422,296,578

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,316.71803
Policy Entropy: 1.15335
Value Function Loss: 0.05909

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03452
Policy Update Magnitude: 0.03748
Value Function Update Magnitude: 0.05015

Collected Steps per Second: 23,856.88880
Overall Steps per Second: 17,603.34426

Timestep Collection Time: 2.09709
Timestep Consumption Time: 0.74499
PPO Batch Consumption Time: 0.06077
Total Iteration Time: 2.84207

Cumulative Model Updates: 25,294
Cumulative Timesteps: 422,346,608

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 422346608...
Checkpoint 422346608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,351.77058
Policy Entropy: 1.15753
Value Function Loss: 0.05560

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04242
Policy Update Magnitude: 0.03552
Value Function Update Magnitude: 0.04656

Collected Steps per Second: 21,004.59460
Overall Steps per Second: 16,305.05013

Timestep Collection Time: 2.38062
Timestep Consumption Time: 0.68616
PPO Batch Consumption Time: 0.02862
Total Iteration Time: 3.06678

Cumulative Model Updates: 25,297
Cumulative Timesteps: 422,396,612

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,828.22535
Policy Entropy: 1.16631
Value Function Loss: 0.05105

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03826
Policy Update Magnitude: 0.03274
Value Function Update Magnitude: 0.04303

Collected Steps per Second: 23,328.40288
Overall Steps per Second: 16,734.11985

Timestep Collection Time: 2.14348
Timestep Consumption Time: 0.84466
PPO Batch Consumption Time: 0.07354
Total Iteration Time: 2.98815

Cumulative Model Updates: 25,300
Cumulative Timesteps: 422,446,616

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 422446616...
Checkpoint 422446616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,991.22019
Policy Entropy: 1.15520
Value Function Loss: 0.05281

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02214
Policy Update Magnitude: 0.03275
Value Function Update Magnitude: 0.03941

Collected Steps per Second: 21,682.23755
Overall Steps per Second: 16,010.45080

Timestep Collection Time: 2.30723
Timestep Consumption Time: 0.81735
PPO Batch Consumption Time: 0.07881
Total Iteration Time: 3.12458

Cumulative Model Updates: 25,303
Cumulative Timesteps: 422,496,642

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,786.78718
Policy Entropy: 1.13990
Value Function Loss: 0.05236

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02057
Policy Update Magnitude: 0.03347
Value Function Update Magnitude: 0.04376

Collected Steps per Second: 23,816.00772
Overall Steps per Second: 17,272.24787

Timestep Collection Time: 2.10044
Timestep Consumption Time: 0.79577
PPO Batch Consumption Time: 0.05866
Total Iteration Time: 2.89621

Cumulative Model Updates: 25,306
Cumulative Timesteps: 422,546,666

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 422546666...
Checkpoint 422546666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,157.49715
Policy Entropy: 1.14377
Value Function Loss: 0.05016

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.01838
Policy Update Magnitude: 0.03229
Value Function Update Magnitude: 0.04342

Collected Steps per Second: 22,731.77308
Overall Steps per Second: 16,226.93436

Timestep Collection Time: 2.19983
Timestep Consumption Time: 0.88184
PPO Batch Consumption Time: 0.08864
Total Iteration Time: 3.08167

Cumulative Model Updates: 25,309
Cumulative Timesteps: 422,596,672

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,685.17606
Policy Entropy: 1.13305
Value Function Loss: 0.05546

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02119
Policy Update Magnitude: 0.03249
Value Function Update Magnitude: 0.04287

Collected Steps per Second: 20,613.60136
Overall Steps per Second: 15,983.25704

Timestep Collection Time: 2.42704
Timestep Consumption Time: 0.70311
PPO Batch Consumption Time: 0.02825
Total Iteration Time: 3.13015

Cumulative Model Updates: 25,312
Cumulative Timesteps: 422,646,702

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 422646702...
Checkpoint 422646702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,337.48186
Policy Entropy: 1.14713
Value Function Loss: 0.06173

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03259
Policy Update Magnitude: 0.03461
Value Function Update Magnitude: 0.04272

Collected Steps per Second: 23,228.48554
Overall Steps per Second: 16,359.88476

Timestep Collection Time: 2.15365
Timestep Consumption Time: 0.90420
PPO Batch Consumption Time: 0.09004
Total Iteration Time: 3.05785

Cumulative Model Updates: 25,315
Cumulative Timesteps: 422,696,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,145.57463
Policy Entropy: 1.14970
Value Function Loss: 0.06409

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02603
Policy Update Magnitude: 0.03805
Value Function Update Magnitude: 0.04289

Collected Steps per Second: 22,032.87671
Overall Steps per Second: 16,452.52625

Timestep Collection Time: 2.26997
Timestep Consumption Time: 0.76993
PPO Batch Consumption Time: 0.02827
Total Iteration Time: 3.03990

Cumulative Model Updates: 25,318
Cumulative Timesteps: 422,746,742

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 422746742...
Checkpoint 422746742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,438.12392
Policy Entropy: 1.15449
Value Function Loss: 0.05810

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03125
Policy Update Magnitude: 0.03752
Value Function Update Magnitude: 0.04580

Collected Steps per Second: 23,164.06704
Overall Steps per Second: 17,616.01463

Timestep Collection Time: 2.15895
Timestep Consumption Time: 0.67995
PPO Batch Consumption Time: 0.02887
Total Iteration Time: 2.83889

Cumulative Model Updates: 25,321
Cumulative Timesteps: 422,796,752

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,288.11724
Policy Entropy: 1.15425
Value Function Loss: 0.05226

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02368
Policy Update Magnitude: 0.03486
Value Function Update Magnitude: 0.04515

Collected Steps per Second: 21,953.78407
Overall Steps per Second: 15,385.19323

Timestep Collection Time: 2.27815
Timestep Consumption Time: 0.97264
PPO Batch Consumption Time: 0.11433
Total Iteration Time: 3.25079

Cumulative Model Updates: 25,324
Cumulative Timesteps: 422,846,766

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 422846766...
Checkpoint 422846766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,637.49321
Policy Entropy: 1.15050
Value Function Loss: 0.05376

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02784
Policy Update Magnitude: 0.03441
Value Function Update Magnitude: 0.04159

Collected Steps per Second: 21,967.94506
Overall Steps per Second: 15,491.42026

Timestep Collection Time: 2.27786
Timestep Consumption Time: 0.95231
PPO Batch Consumption Time: 0.11252
Total Iteration Time: 3.23018

Cumulative Model Updates: 25,327
Cumulative Timesteps: 422,896,806

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,262.44918
Policy Entropy: 1.15564
Value Function Loss: 0.05318

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02427
Policy Update Magnitude: 0.03276
Value Function Update Magnitude: 0.04106

Collected Steps per Second: 21,755.51860
Overall Steps per Second: 16,682.53048

Timestep Collection Time: 2.29845
Timestep Consumption Time: 0.69894
PPO Batch Consumption Time: 0.02812
Total Iteration Time: 2.99739

Cumulative Model Updates: 25,330
Cumulative Timesteps: 422,946,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 422946810...
Checkpoint 422946810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,792.83067
Policy Entropy: 1.14814
Value Function Loss: 0.05089

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03253
Policy Update Magnitude: 0.03162
Value Function Update Magnitude: 0.04045

Collected Steps per Second: 21,486.77760
Overall Steps per Second: 15,849.11767

Timestep Collection Time: 2.32748
Timestep Consumption Time: 0.82790
PPO Batch Consumption Time: 0.04340
Total Iteration Time: 3.15538

Cumulative Model Updates: 25,333
Cumulative Timesteps: 422,996,820

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,643.81613
Policy Entropy: 1.15151
Value Function Loss: 0.04581

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01555
Policy Update Magnitude: 0.03143
Value Function Update Magnitude: 0.04056

Collected Steps per Second: 21,113.75701
Overall Steps per Second: 16,224.52080

Timestep Collection Time: 2.36945
Timestep Consumption Time: 0.71403
PPO Batch Consumption Time: 0.03027
Total Iteration Time: 3.08348

Cumulative Model Updates: 25,336
Cumulative Timesteps: 423,046,848

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 423046848...
Checkpoint 423046848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,744.59161
Policy Entropy: 1.15619
Value Function Loss: 0.04397

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01413
Policy Update Magnitude: 0.03071
Value Function Update Magnitude: 0.04247

Collected Steps per Second: 21,440.45523
Overall Steps per Second: 15,230.46263

Timestep Collection Time: 2.33223
Timestep Consumption Time: 0.95093
PPO Batch Consumption Time: 0.10412
Total Iteration Time: 3.28316

Cumulative Model Updates: 25,339
Cumulative Timesteps: 423,096,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,391.81493
Policy Entropy: 1.16055
Value Function Loss: 0.04594

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02257
Policy Update Magnitude: 0.03357
Value Function Update Magnitude: 0.04543

Collected Steps per Second: 21,365.09307
Overall Steps per Second: 15,681.30501

Timestep Collection Time: 2.34064
Timestep Consumption Time: 0.84838
PPO Batch Consumption Time: 0.06636
Total Iteration Time: 3.18902

Cumulative Model Updates: 25,342
Cumulative Timesteps: 423,146,860

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 423146860...
Checkpoint 423146860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,407.66271
Policy Entropy: 1.15428
Value Function Loss: 0.05072

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03377
Policy Update Magnitude: 0.03370
Value Function Update Magnitude: 0.04742

Collected Steps per Second: 21,325.04531
Overall Steps per Second: 16,279.07045

Timestep Collection Time: 2.34607
Timestep Consumption Time: 0.72720
PPO Batch Consumption Time: 0.02868
Total Iteration Time: 3.07327

Cumulative Model Updates: 25,345
Cumulative Timesteps: 423,196,890

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,239.24701
Policy Entropy: 1.15841
Value Function Loss: 0.05768

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.01827
Policy Update Magnitude: 0.03187
Value Function Update Magnitude: 0.04681

Collected Steps per Second: 22,143.20765
Overall Steps per Second: 15,914.66643

Timestep Collection Time: 2.25857
Timestep Consumption Time: 0.88394
PPO Batch Consumption Time: 0.07714
Total Iteration Time: 3.14251

Cumulative Model Updates: 25,348
Cumulative Timesteps: 423,246,902

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 423246902...
Checkpoint 423246902 saved!
