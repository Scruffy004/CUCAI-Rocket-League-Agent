{"Policy Entropy":0.7040748298168182,"Timestep Consumption Time":1.3733836000000004,"Total Iteration Time":3.5238996,"_timestamp":1.7324699544405344e+09,"z_vel":18.194427407383227,"y_vel":418.58012204937063,"Cumulative Timesteps":1350696,"Cumulative Model Updates":75,"Value Function Loss":0.02005984354764223,"_wandb":{"runtime":137},"Overall Steps per Second":14196.772234941087,"_step":69,"Timesteps Collected":50028,"Policy Reward":0.030060484381704458,"Policy Update Magnitude":0.033779602497816086,"Timestep Collection Time":2.1505159999999997,"SB3 Clip Fraction":0,"Value Function Update Magnitude":0.03643409162759781,"Mean KL Divergence":0.00016280018098768778,"x_vel":18.878937727630078,"PPO Batch Consumption Time":0.3298163414001465,"Collected Steps per Second":23263.25402833553,"_runtime":137.1521549}